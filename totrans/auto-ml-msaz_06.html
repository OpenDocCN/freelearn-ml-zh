<html><head></head><body>
		<div id="_idContainer059">
			<h1 id="_idParaDest-56"><em class="italic"><a id="_idTextAnchor056"/>Chapter 4</em>: Building an AutoML Regression Solution</h1>
			<p>You've taken the first step to becoming an Azure AutoML expert by building a solution with the AutoML guided user interface. Now, it's time to level up your skills by creating a solution with the <strong class="bold">Azure Machine Learning Python Software Development Kit</strong> (<strong class="bold">AzureML Python SDK</strong>). Using the Diabetes dataset that we built in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em>, you will build a regression solution to predict how much a person's diabetes disease has advanced over the last year.</p>
			<p>You will begin this chapter by opening up a Jupyter notebook from your compute instance, which will let you write Python code. First, you will load in the Diabetes data. Then, you will train an AutoML model and register your trained model to your <strong class="bold">Azure Machine Learning Service (AMLS)</strong> workspace. You will accomplish this by using easily reusable Python scripts. After examining your model's results, you will learn how to register your model so that it can be optimized for a variety of regression-specific metrics and fine-tune your solution to improve performance. </p>
			<p>By the end of this chapter, you will have full mastery and knowledge of Azure AutoML's regression capabilities and be able to train regression models using your own data. </p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Preparing data for AutoML regression</li>
				<li>Training an AutoML regression model</li>
				<li>Registering your trained regression model</li>
				<li>Fine-tuning your AutoML regression model</li>
			</ul>
			<h1 id="_idParaDest-57"><a id="_idTextAnchor057"/>Technical requirements</h1>
			<p>The following are the prerequisites for this chapter:</p>
			<ul>
				<li>Access to the internet</li>
				<li>A web browser, preferably Google Chrome or Microsoft Edge Chromium</li>
				<li>A Microsoft Azure account</li>
				<li>An Azure Machine Learning service workspace</li>
				<li>The <strong class="source-inline">titanic-compute-instance</strong> compute instance from <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em></li>
				<li>The <strong class="source-inline">compute-cluster</strong> compute cluster from <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em></li>
				<li>The <strong class="source-inline">Diabetes Sample</strong> dataset from <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em></li>
			</ul>
			<p>The code for this chapter is available here: <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Chapter04/Chapter-4-AutoML-on-Azure.ipynb">https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Chapter04/Chapter-4-AutoML-on-Azure.ipynb</a>.</p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor058"/>Preparing data for AutoML regression</h1>
			<p>Before you can train any model with AutoML, you must have a properly cleansed dataset. This section will walk you through how to prepare data for any AutoML regression solution. You will begin by using your compute instance to access Jupyter notebook, a code <a id="_idIndexMarker168"/>editor that will let you code in Python. Following that, you will cleanse, transform, and register your data as an Azure dataset. This will give you a dataset that's ready for training in the next section.</p>
			<p>Some of <a id="_idIndexMarker169"/>you may be new to Python or even to coding in general, but don't worry. While scripting an AutoML solution may seem much more difficult than using the <em class="italic">GUI</em>, in reality, it's a matter of making slight changes to boilerplate code. </p>
			<p>Using the code found in this book's GitHub repository, you only have to alter it slightly to adapt it to your own custom solution using your own custom data. Furthermore, for this exercise, you've already completed most of the prerequisites. You have your <strong class="bold">compute instance</strong>, <strong class="bold">compute cluster</strong>, and <strong class="bold">dataset</strong> ready, and you're only a few lines of code away from being ready to train an AutoML regression solution.</p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor059"/>Setting up your Jupyter environment</h2>
			<p>To write code yourself, you must open a Jupyter notebook. <strong class="bold">Jupyter notebook</strong> is an environment <a id="_idIndexMarker170"/>where you can write, edit, and run Python code. <strong class="bold">Python</strong> is a general-purpose <a id="_idIndexMarker171"/>programming language <a id="_idIndexMarker172"/>that is extremely popular among machine learning practitioners and forms the basis of the Azure Machine Learning service. </p>
			<p>The following steps will teach you how to access a Jupyter notebook environment through your Azure compute instance. You will then learn how to create a notebook within this environment that will allow you to script your AutoML regression solution:</p>
			<ol>
				<li>First, open Azure Machine Learning Studio by navigating to <a href="http://ml.azure.com">http://ml.azure.com</a>.</li>
				<li>Once you are in the studio, click <strong class="bold">Compute</strong> on the right-hand side of the studio, under <strong class="bold">Manage</strong>.</li>
				<li>If your compute instance is currently paused, check the circular checkbox next to <strong class="source-inline">titanic-compute-instance</strong> and click the <strong class="bold">Start</strong> button.</li>
				<li>Then, click <strong class="bold">Jupyter</strong> under <strong class="bold">Application URI</strong>, as shown in <em class="italic">Figure 4.1</em>:<div id="_idContainer048" class="IMG---Figure"><img src="image/B16595_4_01.jpg" alt="Figure 4.1 – Accessing your Jupyter environment "/></div><p class="figure-caption">Figure 4.1 – Accessing your Jupyter environment</p><p>Once you have accessed your Jupyter environment, the next step is to create a Jupyter notebook. You can create as many Jupyter notebooks as you like, and you can also <a id="_idIndexMarker173"/>use this environment to upload and download files, create folder structures, and run both Python and R scripts. <strong class="bold">R</strong> is another programming language that is popular with machine learning practitioners, but we will not cover it in this book.</p></li>
				<li>Click <strong class="bold">New</strong> in the upper right-hand corner of your screen to access the drop-down menu.</li>
				<li>Select <strong class="bold">Python 3.6 – AzureML</strong> from the drop-down menu, as shown in the <em class="italic">Figure 4.2</em>:<div id="_idContainer049" class="IMG---Figure"><img src="image/B16595_4_02.jpg" alt="Figure 4.2 – Creating a Jupyter notebook "/></div><p class="figure-caption">Figure 4.2 – Creating a Jupyter notebook</p></li>
				<li>Click the <a id="_idIndexMarker174"/>new Jupyter notebook that appears in the top-left corner of your screen; that is, <strong class="source-inline">Untitled.ipynb</strong>.</li>
				<li>Rename <strong class="source-inline">Untitled.ipynb</strong> to <strong class="source-inline">Diabetes_Regression_AutoML</strong> by clicking <strong class="bold">Untitled</strong> in the top-left corner of the screen, typing <strong class="source-inline">Diabetes_Regression_AutoML</strong> into the resulting textbox, and clicking <strong class="bold">Rename</strong>, as shown in <em class="italic">Figure 4.3</em>:</li>
			</ol>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/B16595_4_03.jpg" alt="Figure 4.3 – Renaming your Jupyter notebook "/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.3 – Renaming your Jupyter notebook</p>
			<p>By creating and renaming your Jupyter notebook, you are now ready to begin coding in Python. This is <a id="_idIndexMarker175"/>also a step-by-step, repeatable process that <a id="_idIndexMarker176"/>consists of mostly boilerplate code. <strong class="bold">Boilerplate</strong> refers to code that can be reused from project to project and requires little to no customization. As such, you can write Azure AutoML scripts with next to no Python experience.</p>
			<h2 id="_idParaDest-60"><a id="_idTextAnchor060"/>Preparing your data for AutoML</h2>
			<p>Every AutoML script begins exactly the same way. First, you load in your Python libraries. <strong class="bold">Libraries</strong> are simply <a id="_idIndexMarker177"/>collections of useful functions that let you complete complex tasks without having to write complicated code yourself. Then, you must set your <strong class="bold">workspace, datastore, compute cluster, </strong>and<strong class="bold"> dataset</strong>. Once you've done this, manipulate your data if necessary and save it to a new dataset. If this is not necessary, simply move on to the <em class="italic">Training an AutoML regression model</em> section after loading your dataset. </p>
			<p>In the following steps, you will load all the necessary libraries you'll need to run the entire notebook from start to finish. These libraries are sufficient to run the data preparation, model training, and model registration portions of this chapter. You will then load the Diabetes dataset you created previously in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a><em class="italic">, Getting Started with Azure Machine Learning Service</em>. After loading the data, you will make some slight data transformations before registering it as a new dataset. Let's get started:</p>
			<ol>
				<li value="1">Load in all the libraries you will need to run everything in this chapter by using the following code:<p class="source-code">from azureml.core import Workspace, Dataset, Datastore</p><p class="source-code">from azureml.core import Experiment</p><p class="source-code">from azureml.core.compute import ComputeTarget</p><p class="source-code">from azureml.train.automl import AutoMLConfig</p><p class="source-code">from azureml.train.automl.run import AutoMLRun</p><p class="source-code">from azureml.widgets import RunDetails</p><p><strong class="source-inline">Workspace</strong> lets you connect to your <strong class="bold">Azure Machine Learning Service (AMLS)</strong> workspace. <strong class="source-inline">Dataset</strong> and <strong class="source-inline">Datastore</strong> let you access your previously created datasets and datastores, while <strong class="source-inline">Experiment</strong> lets you log the results of your AutoML. </p><p><strong class="source-inline">ComputeTarget</strong> lets you use your compute cluster to run your AutoML job. On the other hand, <strong class="source-inline">AutoMLConfig</strong> enables you to configure your run, while <strong class="source-inline">AutoMLRun</strong> is necessary to train your model. Finally, <strong class="source-inline">RunDetails</strong> lets you track your job in real time.</p></li>
				<li>Load in <strong class="bold">pandas</strong> and <strong class="bold">numpy</strong> by using the following code. These are popular Python <a id="_idIndexMarker178"/>packages that help you transform data. <strong class="source-inline">pandas</strong>, in particular, is necessary to view the data in your dataset:<p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p></li>
				<li>Connect your Jupyter notebook to your AMLS workspace by using the following code:<p class="source-code">ws = Workspace.from_config()</p></li>
				<li>Set your compute cluster to the one you created in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a><em class="italic">, Getting Started with Azure Machine Learning Service</em>, by using the following code: <p class="source-code">compute_name = 'compute-cluster'</p><p class="source-code">compute_target = ComputeTarget(ws, compute_name)</p></li>
				<li>Set your datastore by using the following code. For this exercise, we will use the <strong class="bold">default datastore</strong> that comes with your workspace. If you want to use a different datastore, you can replace <strong class="source-inline">workspaceblobstore</strong> with the name of your datastore:<p class="source-code">datastore = Datastore.get_default(ws)</p><p class="source-code">my_datastore_name = 'workspaceblobstore'</p><p class="source-code">my_datastore = Datastore.get(ws, my_datastore_name)</p></li>
				<li>Set your <a id="_idIndexMarker179"/>dataset by using the following code. Use the <strong class="source-inline">Diabetes Sample</strong> dataset you created in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a><em class="italic">, Getting Started with Azure Machine Learning Service</em>, for this. You can reuse this code by replacing the name shown in the following code:<p class="source-code">dataset_name = "Diabetes Sample"</p><p class="source-code">dataset = Dataset.get_by_name(ws, dataset_name, </p><p class="source-code">version='latest')</p><p class="callout-heading">Important Note</p><p class="callout">For this code, you will always need to use the latest version of your dataset. If you wish to use an earlier version of your dataset, you can replace <strong class="source-inline">'latest'</strong> with a number.</p></li>
				<li>View the first 10 rows of your data, as shown in the following screenshot, by using the following code:<p class="source-code">dataset.take(10).to_pandas_dataframe()</p><p>Whenever you view your data, it's important that you make sure the data looks correct. Verify that the columns have names that match what you expect. Make sure that the values are of the correct type, numeric or string, and that the values themselves look appropriate. If you see a number higher than 120 in the <strong class="source-inline">AGE</strong> column, for example, you may have problems in the dataset.</p><p>If you do find any inconsistencies within your data, it is important that you fix them before training a model with AutoML. Leaving string values in columns that should be numeric will cause AutoML to treat those columns as categorical. </p><p>In some cases, this will result in inferior performance. Likewise, leaving errors in your data <a id="_idIndexMarker180"/>may result in models that fail to make accurate predictions. As the old data science saying goes, "<em class="italic">Garbage in, garbage out</em>." Always inspect your data to make sure it's not garbage.  </p><p>The output should resemble <em class="italic">Figure 4.4</em>:</p><div id="_idContainer051" class="IMG---Figure"><img src="image/B16595_4_04.jpg" alt="Figure 4.4 – Viewing your dataset "/></div><p class="figure-caption">Figure 4.4 – Viewing your dataset</p></li>
				<li>If you wish to change anything about your data, use pandas to do so by converting your dataset into a pandas DataFrame using the following code:<p class="source-code">dfRaw = dataset.to_pandas_dataframe()</p></li>
				<li>One common thing you may want to do is drop columns. You should drop any columns that are derived from the field that you are trying to predict that contain nearly all null values, or that will not be available when you're processing <a id="_idIndexMarker181"/>new data. For example, if you don't know the new patient's <strong class="source-inline">Sex</strong> and <strong class="source-inline">Age</strong>, you can use the pandas <strong class="source-inline">drop</strong> function, as shown in the following code:<p class="source-code">df = dfRaw.drop(['AGE','SEX'], axis=1)</p></li>
				<li>Reregister your altered data and give the dataset a new name; that is, <strong class="source-inline">Diabetes Sample Age/Sex Dropped</strong>. Using the following code, you can save your altered pandas DataFrame to your datastore:<p class="source-code">Dataset.Tabular.register_pandas_dataframe(df, </p><p class="source-code">datastore,</p><p class="source-code">                            "Diabetes Sample Age/Sex </p><p class="source-code">Dropped")</p></li>
				<li>Another common transformation you may want to try is binning. <strong class="bold">Binning</strong> simply refers <a id="_idIndexMarker182"/>to creating categorical variables out of one or more numeric columns. For example, we can bin the <strong class="source-inline">Age</strong> column into three different groups: children younger than 18 years old, adults between the ages of 18 to 64, and seniors older than 64 years old. The following code illustrates this:<p class="source-code">ageBins = [0, 18, 65, 200] </p><p class="source-code">dfRaw['BinnedFares'] = pd.cut(titanic['Age'], ageBins)</p></li>
				<li>Data scientists <a id="_idIndexMarker183"/>can also remove outliers. <strong class="bold">Outliers</strong> are values that fall outside of the normal range of values within one of your columns. One common way of removing outliers is to remove any value that falls three standard deviations away from the mean value of the column. <p><strong class="bold">Standard deviation</strong> is a measure of variance for your data that is used extensively by <a id="_idIndexMarker184"/>data scientists and statisticians. Three standard deviations from the mean means that the data points fall beyond the 99.7 percentile of the distribution and can skew your data. You can use the following code to remove outliers from the <strong class="source-inline">Age</strong> column:</p><p class="source-code">AgeThreeSD = np.std(dfRaw.Age)*3</p><p class="source-code">AgeMean = np.mean(dfRaw.Age)</p><p class="source-code">print(round(AgeThreeSD + AgeMean)) # Prints Outlier </p><p class="source-code">Threshold</p><p class="source-code"># Replace all values above Threshold with Threshold </p><p class="source-code">Value</p><p class="source-code">dfRaw['Age'] = dfRaw['Age'].mask(dfRaw.Age &gt; AgeMean, </p><p class="source-code">AgeMean)</p></li>
				<li>One last <a id="_idIndexMarker185"/>common data transformation is creating categorical columns from numeric columns based on cutoff points. Obesity is defined as having a BMI of 30 or greater. We can make a column, <strong class="source-inline">Obesity_Flag</strong>, that contains a <strong class="source-inline">1</strong> or <strong class="source-inline">0</strong> value to indicate whether an individual is obese with the following code:<p class="source-code">dfRaw['BMI'] = np.where(dfRaw['BMI'] &gt; 30, 1,0)</p></li>
				<li>Once again, save your altered data to your datastore and register it as a dataset called <strong class="source-inline">Diabetes Sample Full Transform</strong> by using the following code:<p class="source-code">Dataset.Tabular.register_pandas_dataframe(dfRaw,</p><p class="source-code"> datastore,</p><p class="source-code">                            "Diabetes Sample Full </p><p class="source-code">Transform")</p></li>
			</ol>
			<p>You have accomplished a lot in this section. Your libraries have been loaded in, your workspace <a id="_idIndexMarker186"/>has been set, and you have all the necessary resources coded to easily create an AutoML run. Additionally, you have multiple versions of your Diabetes data saved as different datasets that you will use to train three AutoML models in the next section. </p>
			<h1 id="_idParaDest-61"><a id="_idTextAnchor061"/>Training an AutoML regression model</h1>
			<p>Compared to setting up your Jupyter environment and preparing your data, training an AutoML model <a id="_idIndexMarker187"/>involves fewer steps. First, you will need to set a name for your <strong class="bold">experiment</strong>. Remember that experiments automatically log information about your AutoML runs. Next, you will need to set your <strong class="bold">Target</strong> column, which is the column you wish to predict, and a few other settings. Finally, you will use AutoML to train a model and watch the results in real time. </p>
			<p>In this section, you will create an experiment, configure the various parameters and settings specific to AutoML regression tasks, and train three AutoML regression models using the datasets you created in the previous section. Let's get started: </p>
			<ol>
				<li value="1">Set <strong class="source-inline">Experiment</strong> and give it a name by using the following code. This is where all of the logs and metrics of your run will be stored in the AML studio:<p class="source-code">experiment_name = 'Diabetes-Sample-Regression'</p><p class="source-code">exp = Experiment(workspace=ws, name=experiment_name) </p></li>
				<li>Set your <strong class="source-inline">Target</strong> column with the following code. AutoML will train a model that predicts the value of this column – in this case, the <strong class="source-inline">Y</strong> column:<p class="source-code">target_column = 'Y'</p></li>
				<li>Create a variable for your <strong class="source-inline">task</strong> using the following code. <strong class="source-inline">task</strong> is the type of AutoML model you are trying to train, and the options for this are regression, forecasting, and classification. For predicting numeric values that do not have a time element, enter <strong class="source-inline">regression</strong>:<p class="source-code">task = 'regression'</p><p class="callout-heading">Important Note</p><p class="callout">If you are trying to predict data that has a time element, use <em class="italic">forecasting</em> instead of <em class="italic">regression</em>. If <strong class="source-inline">date</strong> is one of your columns or you are trying to predict future values based on the current situation, use <em class="italic">forecasting</em>.</p></li>
				<li>Create a variable for your primary metric. This <strong class="bold">primary metric</strong> is how your model will be scored. You should use <strong class="bold">normalized root mean squared error</strong> here. This metric, referred to as <strong class="bold">RSME</strong>, takes the prediction and subtracts it from the actual value for each observation, squares it, and averages the score across <a id="_idIndexMarker188"/>all observations. The lower the score, the better your model. Other options for regression include <strong class="bold">R2 score</strong>, <strong class="bold">Spearman correlation</strong>, and <strong class="bold">normalized mean absolute error</strong>. <p>The following code creates a variable and sets it to normalized RMSE. This variable will be passed into your AutoML configuration settings later:</p><p class="source-code">primary_metric = 'normalized_root_mean_squared_error'</p></li>
				<li>Create a variable for <strong class="source-inline">featurization</strong>. You can set featurization to <strong class="source-inline">auto</strong> or <strong class="source-inline">off</strong>. If you set featurization to <strong class="source-inline">auto</strong>, you will have to drop high-cardinality features, impute null values, one-hot encode your data, and generate additional features yourself. <p>Always set it to <strong class="source-inline">auto</strong> unless you are an expert data scientist and are comfortable doing everything yourself. The following code also creates a new variable that you will pass into your AutoML configuration settings:</p><p class="source-code">featurization = 'auto'</p></li>
				<li>To configure your AutoML, run the following code. Here, you will pass in your task, primary metric, featurization settings, compute target, dataset, and target column. You created all of these previously. <p>You must also pass in how long the experiment will run for, whether it will stop early if the model's performance does not improve, the number of cross-validations, and whether your experiment will record model explanations. <strong class="bold">Cross-validation</strong> refers to how many times the algorithm will split the dataset and use those splits to train new models. Set this between <strong class="source-inline">5</strong> and <strong class="source-inline">20</strong>:</p><p class="source-code">config = AutoMLConfig(task=task,</p><p class="source-code">                     primary_metric=primary_metric,</p><p class="source-code">                     featurization=featurization,</p><p class="source-code">                     compute_target=compute_target,</p><p class="source-code">                     training_data=dataset,</p><p class="source-code">                     label_column_name=target_column,</p><p class="source-code">                     experiment_timeout_minutes=15,</p><p class="source-code">                     enable_early_stopping=True,</p><p class="source-code">                     n_cross_validations=5,</p><p class="source-code">                     model_explainability=True)</p></li>
				<li>Train your <a id="_idIndexMarker189"/>model and watch the results in real time. The following code trains the AutoML model with your configuration settings and logs the results of the run to the experiment you created earlier. <p>As it runs, this code will allow you to track the progress of your session in real time. Here, you can watch AutoML check the validity of your data, train models iteratively, and select the best model: </p><p class="source-code">AutoML_run = exp.submit(config, show_output = True)</p><p class="source-code">RunDetails(AutoML_run).show()</p></li>
			</ol>
			<p>If you've done everything correctly, your AutoML run will kick off and you can sit back, relax, and watch it train models. First, you will see it perform a <strong class="bold">data guardrails</strong> check, as shown in <em class="italic">Figure 4.5</em>:</p>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="image/B16595_4_05.jpg" alt="Figure 4.5 – Data guardrails check "/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.5 – Data guardrails check</p>
			<p>Next, AutoML will start training your models. You will notice that AutoML will train different <a id="_idIndexMarker190"/>combinations of feature transformations and algorithms. In cases where an identical feature transformation/algorithm pair is replicated, AutoML tests different hyperparameter combinations for that algorithm. As it runs, you will be able to track how long each model took to train, how well it scored, and the score of the best-performing model, as shown in <em class="italic">Figure 4.6</em>:</p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/B16595_4_06.jpg" alt="Figure 4.6 – AutoML results "/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.6 – AutoML results</p>
			<p>Notice how the AutoML trained models do not progressively get better with each run. The first model that was trained has a normalized RMSE of <strong class="source-inline">0.1808</strong>. The third model trained has a score of <strong class="source-inline">0.2027</strong>. With normalized RMSE, the lower your score, the better.</p>
			<p>By the end <a id="_idIndexMarker191"/>of the experiment, the best model has a score of <strong class="source-inline">0.1682</strong>. When you run the model, you should see similar, but not exact, results, depending on which models AutoML trains. While you can see which models and transformations are being used under the <strong class="source-inline">PIPELINE</strong> column, hyperparameters remain hidden due to their large number for some algorithms. </p>
			<p>You can also get a visualization of these results, as shown in the following graph. Given enough time, you will notice that AutoML gets better and better. This is because it's following its own internal logic of trying different feature engineering/algorithm pairs until it can no longer find a higher-performing model, upon which AutoML will finish with two ensemble algorithms and end the run. </p>
			<p>Generally speaking, either <strong class="bold">Voting Ensemble</strong> or <strong class="bold">Stack Ensemble</strong> will be your highest-performing algorithm. After examining these results, train another model using the <strong class="source-inline">Diabetes Sample Age/Sex Dropped</strong> dataset and another using the <strong class="source-inline">Diabetes Sample Full Transform</strong> dataset. </p>
			<p><em class="italic">Figure 4.7</em> provides a visualization of the results:</p>
			<div>
				<div id="_idContainer054" class="IMG---Figure">
					<img src="image/B16595_4_07.jpg" alt="Figure 4.7 – AutoML results visualized"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.7 – AutoML results visualized</p>
			<p>In addition <a id="_idIndexMarker192"/>to these two charts, both of which can be found in your Jupyter notebook, there are two more visualizations you can access via AML studio. These are the <strong class="bold">Predicted vs True</strong> graph and your <strong class="bold">Residuals</strong> histogram. <em class="italic">Predicted vs True</em> shows you how well your model performed versus an ideal model, whereas <em class="italic">Residuals</em> gives you an idea of whether your errors are normally distributed or not. </p>
			<p>You can access these graphs by following these steps:</p>
			<ol>
				<li value="1">Navigate to the front page of AML studio. </li>
				<li>Click <strong class="bold">Models</strong> on the left-hand panel, under <strong class="bold">Assets</strong>.</li>
				<li>Click <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong>. This is the name of the model you trained.</li>
				<li>Click the blue link under <strong class="bold">Run ID</strong>. It should begin with AutoML, followed by a long string of letters and digits. This is the ID that your experiment was logged under.</li>
				<li>Click <strong class="bold">Metrics</strong>.</li>
				<li>Check the boxes for <strong class="bold">predicted_true</strong> and <strong class="bold">residuals</strong>.</li>
			</ol>
			<p><em class="italic">Predicted vs True</em> shows you how well your predictions performed against a model that predicts every data point perfectly. The horizontal axis represents your true values, whereas the <a id="_idIndexMarker193"/>vertical axis represents your predicted values. Likewise, the dotted green line represents the perfect model, while the solid blue line represents your actual model. There are also light-blue boundaries around your actual model, showing you the confidence interval. Confidence intervals estimate a range of how well your model would perform in the real world. Please carefully examine <em class="italic">Figure 4.8</em>:</p>
			<div>
				<div id="_idContainer055" class="IMG---Figure">
					<img src="image/B16595_4_08.jpg" alt="Figure 4.8 – Predicted vs. True graph "/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.8 – Predicted vs. True graph</p>
			<p><em class="italic">Residuals</em>, on the other hand, is a histogram that bins your error values and counts the number of data points in each bin. Error is simply how far off your predicted value was from the true value. For example, in<em class="italic"> Figure 4.9</em>, we can see that there about 100 data points where the error fell between -38.5 and 0, and about 115 data points where the error fell between 0 and 38.5. </p>
			<p>When examining this chart, you should make sure that it's bell-shaped. If your chart isn't bell-shaped, this <a id="_idIndexMarker194"/>means that something is causing a pattern in your errors and that you need to investigate the cause; usually, this means you are missing an important variable:  </p>
			<div>
				<div id="_idContainer056" class="IMG---Figure">
					<img src="image/B16595_4_09.jpg" alt="Figure 4.9 – Residuals "/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.9 – Residuals</p>
			<p>Although you have trained a high-performing machine learning model with AutoML, your work is not over yet. Ultimately, a machine learning model is only useful if you can use it to predict new data points. The past is the past, after all, and business value always lies in future situations.</p>
			<p>In this case, you <a id="_idIndexMarker195"/>are trying to predict patient outcomes so that you can identify and preemptively treat patients whose disease will progress the most quickly. To do so, you must first register your model for future use. We will look at this in the next section.</p>
			<h1 id="_idParaDest-62"><a id="_idTextAnchor062"/>Registering your trained regression model</h1>
			<p>AutoML lets you easily register your trained models for future use. In <a href="B16595_09_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 9</em></a><em class="italic">, Implementing a Batch Scoring Solution</em>, and <a href="B16595_11_ePub.xhtml#_idTextAnchor172"><em class="italic">Chapter 11</em></a><em class="italic">, Implementing a Real-Time Scoring Solution</em>, you will create batch execution inference pipelines and real-time scoring <a id="_idIndexMarker196"/>endpoints that will use your models. When registering your model, you can add tags and descriptions for easier tracking. </p>
			<p>One especially useful feature is the ability to register models based on metrics other than the one you used to score your model. Thus, even though you trained a model using normalized RMSE, you can also register the model that had the best R2 score, even if that model is different. </p>
			<p>In this section, you will write a simple description of your model, tag it, and give it a name. After that, you will register the model to your AMLS workspace. It also contains code that will let you register different models based on other metrics. Let's get started:</p>
			<ol>
				<li value="1">First, give your model a name, a description, and some tags. <strong class="bold">Tags</strong> let you easily search for models, so think carefully as you implement them. Pay close attention to their format. You can enter as many <strong class="source-inline">tags</strong> as you wish and feel free to be verbose in your description:<p class="source-code">description = 'Best AutoML Regression Run using </p><p class="source-code">Diabetes Sample Data. This model requires the Age and </p><p class="source-code">Sex Columns.' </p><p class="source-code">tags = {'project' : "Diabetes", "creator" : "your </p><p class="source-code">name"} </p><p class="source-code">model_name = 'Diabetes-AllData-Regression-AutoML' </p></li>
				<li>Next, register your model to your AMLS workspace, passing in your model's name, tags, and description. Use the <strong class="source-inline">AutoML_run</strong> process you trained in the previous section:<p class="source-code">AutoML_run.register_model(model_name=model_name, </p><p class="source-code">description=description, tags=tags)</p><p class="callout-heading">Important Note</p><p class="callout">If time has elapsed since the time you trained your AutoML model, you can retrieve it by finding its <strong class="bold">run ID</strong> in the <strong class="bold">Experiments</strong> section of AML studio. Simply click on <strong class="bold">Experiments</strong> under <strong class="bold">Assets</strong>, select the correct experiment name, and copy the <strong class="bold">run ID</strong> provided. Then, set <strong class="source-inline">AutoML_run</strong> using this ID, as follows:</p><p class="callout"><strong class="source-inline">experiment_name = 'Diabetes-Sample-Regression'</strong></p><p class="callout"><strong class="source-inline">exp = Experiment(workspace=ws, name=experiment_name) </strong></p><p class="callout"><strong class="source-inline">AutoML_run = AutoMLRun(experiment = exp, run_id = 'your_run_id') </strong></p></li>
				<li>Try registering <a id="_idIndexMarker197"/>a different model based on R2 score. Give it a slightly different name, add an additional tag, and use an identical description:<p class="source-code">description = 'Best AutoML Regression Run using \</p><p class="source-code">Diabetes Sample Data. This model requires the Age and \</p><p class="source-code">Sex Columns.' </p><p class="source-code">tags = {'project' : "Diabetes", "creator" : "your </p><p class="source-code">name", "metric" : "R2"} </p><p class="source-code">model_name = 'Diabetes-AllData-Regression-AutoML-R2' </p><p class="source-code">AutoML_run.register_model(model_name=model_name, </p><p class="source-code">description=description, tags=tags, metric = </p><p class="source-code">'r2_score')</p></li>
			</ol>
			<p>With that, your model has been registered and is ready for use. You have created a regression model that can be used to identify how diabetes is likely to progress in a patient over a 1-year period based on their gender, age, blood pressure, BMI, and six blood serum measurements. Try registering other AutoML models you've trained using the other datasets you created in this chapter. Give them appropriate tags, names, and descriptions that differentiate them.</p>
			<p>It's important to emphasize the importance of a good tagging strategy and robust descriptions. As you are working on a machine learning project, it's not such a big deal, as you will <a id="_idIndexMarker198"/>remember which models you trained and what datasets you trained them with. However, as you move on to other projects and as time passes, your memory becomes less and less reliable. If you don't have good tags, locating your models becomes a difficult endeavor.</p>
			<p>A proper tagging strategy will include the project name, the project creator, the metric the model was trained on, the dataset the model was trained with, and other pertinent information about the model. There is no need to include a version number, as AutoML includes one automatically. If you register a different model with the same name, a new version of the model will be registered and the old one can still be accessed by specifying its version number. </p>
			<p>Once you've registered a few different models, try accessing one using the following code:</p>
			<p class="source-code">model = Model(ws,' 'Diabetes-AllData-Regression-AutoML-R2')</p>
			<p>Now, you know how to register and call models that you've trained with AutoML. With this accomplished, we can move on and look at some tips and tricks that will improve your regression models as you train them more in the future. </p>
			<h1 id="_idParaDest-63"><a id="_idTextAnchor063"/>Fine-tuning your AutoML regression model</h1>
			<p>In this section, you will first review tips and tricks for improving your AutoML regression models and then review the algorithms used by AutoML for regression.</p>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor064"/>Improving AutoML regression models</h2>
			<p>While AutoML <a id="_idIndexMarker199"/>will handle most of the complicated data transformations and feature engineering for you, there are a few tips you can follow to increase the accuracy of your model. Some of these tips are true across all three AutoML tasks – <em class="italic">regression</em>, <em class="italic">classification</em>, and <em class="italic">forecasting</em> – while others are regression-specific. Following them will yield higher-performing models and, more importantly, hone your understanding of machine learning techniques. I have listed a few tips and tricks here for quick reference:</p>
			<ul>
				<li>Fill in null values before passing them on to AutoML. Alternatively, drop any rows that contain a null value. Just because AutoML will automatically fill your null values does not mean that it will do a great job. <p>In some situations, filling in null values with the mean of the column is appropriate. For example, if you're missing the price of an item, it's very likely that the mean price will approximate the missing value. For noisier columns, think deeply about how you should go about filling in missing values or whether you should include those datapoints at all. Here's some Python code that will fill in null values for you:</p><p class="source-code">mean_age = dfRaw.AGE.mean()</p><p class="source-code">dfRaw.AGE = dfRaw.AGE.fillna(value=meanAge)</p></li>
				<li>Become <a id="_idIndexMarker200"/>familiar with all of the different AutoML configuration options. You can find them at this link: <a href="https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py">https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py</a>.</li>
				<li>Use <strong class="source-inline">y_min</strong> and <strong class="source-inline">y_max</strong> to take care of any outliers in your <strong class="source-inline">Target</strong> column. If you have values that are outliers, such as values that are <strong class="source-inline">3</strong> or more standard deviations away from the mean value of your <strong class="source-inline">Target</strong> column, setting <strong class="source-inline">y_min</strong> and <strong class="source-inline">y_max</strong> to <strong class="source-inline">3</strong> standard deviations below and above your mean, respectively, can yield better performing models. This only applies to regression models. <p>The following code calculates the mean and standard deviation of the <strong class="source-inline">Target</strong> column and uses them to set <strong class="source-inline">y_min</strong> and <strong class="source-inline">y_max</strong>:</p><p class="source-code">TargetSD = np.std(dfRaw.Y)*3</p><p class="source-code">TargetMean = np.mean(dfRaw.Y)</p><p class="source-code">y_min = TargetMean – TargetSD</p><p class="source-code">y_max = TargetMean + TargetSD</p></li>
				<li>Research the four different primary metrics to understand which metrics fit your problem best. Normalized RMSE will suffice for most regression problems, but many research papers exist on the pros and cons of using other metrics.</li>
				<li>Use <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml</a> to understand what a good regression model looks like. A good model will have unbiased residuals, meaning that your model over and under predicts equally. A good model will also more closely fit the ideal line in the <em class="italic">Predicted vs True</em> gra<a id="_idTextAnchor065"/>ph shown in <em class="italic">Figure 4.8</em>.</li>
				<li>Go to <strong class="bold">Experiments</strong> under <strong class="bold">Assets</strong> in AML studio, click your experiment's name, select your run ID, click the <strong class="bold">Models</strong> tab, select the highest-performing algorithm, and click the <strong class="bold">Metrics</strong> tab. This will provide you with all of the different <a id="_idIndexMarker201"/>metrics and charts necessary to evaluate your algorithm.</li>
				<li>You can use the <strong class="source-inline">weight_column_name</strong> configuration option to assign a weight column to your dataset. If some observations are more important to get right than others, assign a higher weight to those observations. <p>For example, you can assign a weight of 2 to an important observation while assigning a weight of 1 to normal observations, thus weighing important observations twice as heavily. For example, if you're building an algorithm that predicts electricity usage of a factory, you may want to peak usage times more heavily.</p></li>
				<li>Enable longer experiment runtimes to obtain higher-performing models. Sometimes, this enables AutoML to find better hyperparameters for the models it trains. Other times, increasing the runtime doesn't help so much, but it's always worth giving it a try.</li>
				<li>If AutoML does not provide a satisfactory model, try adding more data. You can add either more historical data (more rows) or additional information (more columns). Be careful not to add too many columns to a very small dataset, however, as this can lead to overfitting. <p><strong class="bold">Overfitting</strong> is where <a id="_idIndexMarker202"/>you produce a very good model that doesn't generalize to new datapoints. If this happens to you, try adding more historical data or removing columns from your dataset.</p></li>
				<li>In the end, if, after applying all of these tips and tricks, your model is still unsatisfactory, try changing your regression problem to a classification problem. Generally, classification problems are easier to solve than regression problems. The way you achieve this is by binning your target column. <p>Instead of <a id="_idIndexMarker203"/>trying to predict a specific number, your algorithm will try to predict a range of numbers instead. You have to be creative for this approach to work. For example, with the <strong class="source-inline">Diabetes Sample</strong> dataset, try binning the <strong class="source-inline">Target</strong> column using the following code: </p><p class="source-code">ySD = np.std(dfRaw.Y)</p><p class="source-code">yMean = np.mean(dfRaw.Y)</p><p class="source-code">yMin = np.min(dfRaw.Y)</p><p class="source-code">yMax = np.max(dfRaw.Y)</p><p class="source-code">low = yMean - ySD</p><p class="source-code">high = yMean + ySD</p><p class="source-code">yBins = [yMin, low, yMean, high, yMax] </p><p class="source-code">dfRaw['BinnedY'] = pd.cut(dfRaw['Y'], yBins)</p></li>
			</ul>
			<p>Whenever you employ the trick of turning a regression problem into a classification problem, keep in mind that the resulting target column must be meaningful. In the following screenshot, we can see the values of the <strong class="source-inline">Target</strong> column indicating the extent to which the disease has progressed in patients. </p>
			<p>If there are substantial, meaningful differences between the four different bins, then this is a valid way to approach the problem. However, if the patients in each bin do not differ from each other in terms of medical outcome, then you should bin the data to make sure patients are lumped together correctly.</p>
			<p>In <em class="italic">Figure 4.10</em>, we can see the values of the <strong class="source-inline">Target</strong> column indicating the extent to which the disease has progressed in patients:</p>
			<div>
				<div id="_idContainer057" class="IMG---Figure">
					<img src="image/B16595_4_10.jpg" alt="Figure 4.10 – Results of binning the Diabetes data"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.10 – Results of binning the Diabetes data</p>
			<p>You are now familiar with many of the little techniques that data scientists employ to achieve higher-performing models and solve business problems. This list is far from exhaustive, and you will encounter more techniques as you build more models with AutoML. Anytime you find some interesting way to improve your model's performance, it is important to write it down somewhere and store the code in a repository. </p>
			<p>Whenever you encounter a difficult problem that seems impossible to solve, reread all of the tips in this section, then search your repository. Most of the time, with the right data and the right transformations, AutoML will be able to generate a solution on par with most data scientists. Other times, it's a matter of fine-tuning settings. Sometimes, the only thing you can do is try turning your regression problem into a classification problem and try again.   </p>
			<p>One last thing that will help you use AutoML more efficiently is developing an understanding of the algorithms underlying the technology.</p>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor066"/>Understanding AutoML regression algorithms</h2>
			<p>AutoML uses many state-of-the-art machine learning algorithms. While it isn't necessary for you to understand them in order to use AutoML, learning more about them will help you develop as a data scientist. Certain algorithms perform better in certain situations. Furthermore, you can group the algorithms into roughly five groups.</p>
			<p><strong class="bold">Standard regression algorithms</strong> are those which assign coefficients to your explanatory variables in order to predict your target column. AutoML uses two of these techniques: <strong class="bold">Elastic net</strong> and <strong class="bold">LARS</strong> (<strong class="bold">least angular regression</strong>) <strong class="bold">lasso</strong>. </p>
			<p>Elastic net trains a regression model using both L1 and L2 regularization techniques. <strong class="bold">L1</strong>, also called <strong class="bold">lasso</strong>, reduces the coefficients on less important variables to 0, while <strong class="bold">L2</strong>, called <strong class="bold">ridge</strong>, reduces the value of coefficients of less important variables. Elastic net combines both techniques to create simpler models that are easier to explain while not dropping as many variables as lasso regression. LARS lasso is a technique for data with lots of columns that iteratively uses the most important columns, but doesn't perform well with noisy data.</p>
			<p><strong class="bold">Tree algorithms </strong>split data based on a series of if-then decision rules, resulting in a mapping that resembles a branching tree. As you go further down the tree, you eventually reach a point where the algorithm predicts a value based on the series of rules it creates. AutoML uses three of these techniques:</p>
			<ul>
				<li><strong class="bold">Decision tree</strong> is a simple algorithm which is easily explainable but prone to overfitting, performing well on training data at the expense of generalizing to new data. </li>
				<li><strong class="bold">Random forest</strong> creates an ensemble of decision trees and averages them together. Each tree is created from a random sample of the training set and columns are randomly chosen to create decision rules. </li>
				<li><strong class="bold">Extremely randomized trees</strong> goes one step further by also randomizing the values chosen to make splits. This randomness reduces the variance of the models when generalized to new data, creating better models.  </li>
			</ul>
			<p><strong class="bold">Gradient boosting algorithms</strong> work by combining many weak performing decision tree models, called <strong class="bold">weak learners</strong>, together. These algorithms start by creating a single weak leaner, looking for data points on which it doesn't perform well, and creating another weak learner on that subset of data. This process is repeated until a certain threshold is met. AutoML uses three of these algorithms: <strong class="bold">XGBoost</strong>, <strong class="bold">LightGBM</strong>, and <strong class="bold">gradient boosting</strong>. All three work similarly and were chosen based on their high performance, but must be carefully tuned to avoid overfitting.</p>
			<p><strong class="bold">Nearest neighbor algorithms</strong> work by looking at each row of data and calculating the mean value of similar data points, called nearest neighbors. K-nearest neighbors are the sole type of nearest neighbor algorithm used by AutoML. K refers to the number of nearest neighbors the algorithm examines when making its prediction. KNN works well when your data has a low number of columns as it tends to overfit when you use many columns to predict your target column.   </p>
			<p><strong class="bold">Optimization algorithms</strong> are those that iteratively minimize an objective function to try to converge on the best prediction. AutoML uses three of these: <strong class="bold">Stochastic gradient descent</strong> (<strong class="bold">SGD</strong>), <strong class="bold">online gradient descent regressor</strong>, and <strong class="bold">fast linear regressor</strong>. Each of these algorithms work by finding the slope of an objective function for each column and working down the slope until it gets as close to 0 as possible by adjusting weights.</p>
			<p>This is a very slow process and SGD works by randomly picking datapoints along the slope to get to the minimum as fast as possible; online gradient descent regressor works similarly but with different weighting options. Fast linear regressor uses a new state-of-the-art optimization technique called <strong class="bold">Stochastic Dual Coordinate Ascent</strong> (<strong class="bold">SDCA</strong>) which optimizes a dual loss function instead of a single loss like the other algorithms.</p>
			<p>A summary of the 12 algorithms is provided in Figure 4.11.</p>
			<div>
				<div id="_idContainer058" class="IMG---Figure">
					<img src="image/B16595_4_11.jpg" alt="Figure 4.11 – AutoML regression algorithms "/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.11 – AutoML regression algorithms</p>
			<p>In addition to the preceding 12 algorithms, AutoML also performs <strong class="bold">model ensembling</strong> at the end of each AutoML training run. Model ensembling is using the predictions of multiple machine learning models together to make a prediction. AutoML uses two ensembling techniques: voting and stacking. </p>
			<p><strong class="bold">Voting ensembles</strong> take a weighted average of your regression models and use that to make a prediction. <strong class="bold">Stack ensembles</strong>, in contrast, train an elastic net model using the output of other models. AutoML will train one voting ensemble and one stack ensemble per training run. Usually, one of these two ensemble models will be your highest performing model.</p>
			<p>For more information on these models, please consult the AutoML documentation found at <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings</a></p>
			<h1 id="_idParaDest-66"><a id="_idTextAnchor067"/>Summary</h1>
			<p>With this chapter, you have successfully constructed a regression model using the AzureML Python SDK. Regardless of whether you're a Python novice or expert, you have loaded data, transformed it extensively using pandas, and built a useful machine learning model with AutoML. You then registered your model to an AMLS workspace. You will use that same model in future chapters to create inference pipelines and real-time scoring endpoints using REST APIs.</p>
			<p>By working through all the exercises in this chapter, you have obtained a level of mastery over Azure AutoML regression solutions. You can now take any set of data that's useful in predicting a number and use it to create a high-performing machine learning model. Furthermore, you can code all of this in Python and, if the model fails to perform, you know lots of little ways to improve performance, or, if worst comes to worst, change your regression problem to a classification problem.</p>
			<p>In <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a>, <em class="italic">Building an AutoML Classification Solution</em>, you will learn how to solve these classification problems using AutoML, and then build a machine learning model that predicts a class instead of a number. </p>
		</div>
</body></html>