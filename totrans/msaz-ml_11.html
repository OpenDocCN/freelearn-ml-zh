<html><head></head><body><div class="chapter" title="Chapter&#xA0;11.&#xA0;Publishing a Model as a Web Service"><div class="titlepage"><div><div><h1 class="title"><a id="ch11"/>Chapter 11. Publishing a Model as a Web Service</h1></div></div></div><p>So far, you have explored how to build different predictive models as experiments. Now, you might be wondering how that would be of use in real-life scenarios. One use of it is after you build and test your model, you can take a dataset and make a prediction straightaway inside the experiment, but in most of the cases, the result or the predictions of a model need to be used elsewhere and probably by some other people. Consider you have built a recommender model and it recommends items that a buyer might be interested in. So, these predictions require that the e-commerce site display the recommended product items to the prospective buyers. Consider one more scenario, where you have built a model for market segmentation using clustering. The marketing executive of your company should use this model for analysis by integrating the results in their software or simply by using the familiar Microsoft Excel.</p><p>Basically, you have to make the predictive model you have built available in an environment, so that people inside or outside your organization can use it. Traditionally, it used to be a cumbersome job, where a bunch of code had to be written and tested. Then, infrastructure had to be made ready as required.</p><p>Now, Azure ML takes all the pain out. In this chapter, you will explore, how easily you can publish a model in an experiment and make it available as a web service API for others to consume.</p><p>In a nutshell, you can publish your model in the following simple steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Prepare your model to be published as a web service.</li><li class="listitem">Prepare a scoring experiment.</li><li class="listitem">Specify the input and output for the web service.</li><li class="listitem">Publish and test it as a web service.</li></ol></div><div class="section" title="Preparing an experiment to be published"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec64"/>Preparing an experiment to be published</h1></div></div></div><p>You need to get <a id="id397" class="indexterm"/>your experiment ready before you start deploying it. To do this you need to complete your experiments, run them successfully, and evaluate and identify the trained model to be used. For illustration, we have a simple model here that predicts the income of adults based on age, education, sex, and race. The model uses the <span class="strong"><strong>Two-Class Decision Forest</strong></span> module to predict whether a person has an income of more than 50K or not. The details to build the experiment can be found in <a class="link" href="ch07.html" title="Chapter 7. Classification Models">Chapter 7</a>, <span class="emphasis"><em>Classification Models</em></span>.</p><div class="mediaobject"><img src="graphics/0792EN_11_01.jpg" alt="Preparing an experiment to be published"/></div><div class="section" title="Saving a trained model"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec65"/>Saving a trained model</h2></div></div></div><p>Once you are <a id="id398" class="indexterm"/>sure about your model, you can save it as a trained model. To do this, right-click on the output port of the <span class="strong"><strong>Train Model</strong></span> module on the canvas and then click on the <span class="strong"><strong>Save as Trained Model</strong></span> option to save the trained model, which can be used later. You have to specify a name and the optional description text as the <span class="strong"><strong>Save trained model</strong></span> popup appears. Then, click on the tick mark button to the right of the screen to save the trained model, as shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/0792EN_11_02.jpg" alt="Saving a trained model"/></div><p>The saved model will be like a predictor module, which can be used by a <span class="strong"><strong>Score Model</strong></span> module to score with a given feature set. It will appear as a module on the left-hand side of the screen in the module palette under the <span class="strong"><strong>Trained Models</strong></span> group.</p><p>If you have made any <a id="id399" class="indexterm"/>changes to the model say, you've changed the parameters to the algorithm, and so on, then you have to save the trained model again, and as the popup appears, tick the <span class="strong"><strong>This is the new version of an existing trained model</strong></span> option at the top of the screen and choose the name of the previously saved model.</p></div></div></div>
<div class="section" title="Creating a scoring experiment"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec65"/>Creating a scoring experiment</h1></div></div></div><p>A <span class="strong"><strong>scoring experiment</strong></span> <a id="id400" class="indexterm"/>is one where you use a trained model module to make a prediction (scoring). You can create a new experiment, use a <span class="strong"><strong>Trained Model</strong></span> module, and make a prediction with a dataset. ML Studio makes it really easy for you with a single button, as you can see in the following screenshot:</p><div class="mediaobject"><img src="graphics/0792EN_11_13.jpg" alt="Creating a scoring experiment"/></div><p>The button becomes active when the training experiment is run successfully. Run your <span class="strong"><strong>Income Predictor</strong></span> experiment successfully and then click on the <span class="strong"><strong>CREATE SCORING EXPERIMENT</strong></span> button <a id="id401" class="indexterm"/>to create a scoring experiment corresponding to the existing one. After this is done, you will see the following screenshot:</p><div class="mediaobject"><img src="graphics/0792EN_11_14.jpg" alt="Creating a scoring experiment"/></div><p>Behind the scenes, ML Studio has done the following tasks for you:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">It saved your trained model as a module in the <span class="strong"><strong>Trained Models</strong></span> section of the module palette to the left of the screen.</li><li class="listitem">It created a copy of the existing training experiment then replaced the machine learning algorithm module and the <span class="strong"><strong>Train Model</strong></span> module with the saved trained model.</li><li class="listitem">It removed the modules that were clearly not needed in a scoring experiment—the <span class="strong"><strong>Split</strong></span> and <span class="strong"><strong>Evaluate Model</strong></span> modules in this case.</li><li class="listitem">It added the <span class="strong"><strong>Web service input</strong></span> and <span class="strong"><strong>Web service output</strong></span> modules and connected them to the default locations in the experiment.</li></ol></div><p>You can also do these steps by yourself manually and create a scoring experiment. However, by creating the experiment this way, ML Studio links up the training and scoring experiment. When you open any one link, the other will be present as a tab so that you can switch between training and scoring your experiment easily.</p><p>The <span class="strong"><strong>Web service input</strong></span> <a id="id402" class="indexterm"/>and the <span class="strong"><strong>Web service output</strong></span> modules specify where the input goes into and where the output comes from when the model is published as a web service. Now that these modules are connected to the default position, you need to plan and connect these to the right modules.</p></div>
<div class="section" title="Specifying the input and output of the web service"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec66"/>Specifying the input and output of the web service</h1></div></div></div><p>Before <a id="id403" class="indexterm"/>publishing a web service, you need to specify what the <a id="id404" class="indexterm"/>web service will take as an input and which output you are interested in. Assume that for our illustration, we need to predict a level of someone's income (that is, less than or equal to 50K or greater than or equal to 50K) from the input: age, education, sex, and race. You can achieve this using the <span class="strong"><strong>Project Columns</strong></span> module.</p><p>In your web service, the input should go to the <span class="strong"><strong>Score Model</strong></span> module. So, connect the <span class="strong"><strong>Web service input</strong></span> module to the <span class="strong"><strong>Score Model</strong></span> module. Add a <span class="strong"><strong>Project Columns</strong></span> module and connect its input port to the output of the <span class="strong"><strong>Score Model</strong></span> module. In the properties panel of the module, select the <span class="strong"><strong>Scored Labels</strong></span> option only. Let's take a look at the following screenshot:</p><div class="mediaobject"><img src="graphics/0792EN_11_15.jpg" alt="Specifying the input and output of the web service"/></div><p>After running the <a id="id405" class="indexterm"/>experiment successfully, you can check the output of <a id="id406" class="indexterm"/>the two <span class="strong"><strong>Project Columns</strong></span> modules in your scoring experiment; the output of which are as expected. Now, this experiment is ready to be published as a web service.</p></div>
<div class="section" title="Publishing a model as a web service"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec67"/>Publishing a model as a web service</h1></div></div></div><p>Publishing a <a id="id407" class="indexterm"/>model as a web service is very easy. To <a id="id408" class="indexterm"/>publish the model, click on the <span class="strong"><strong>PUBLISH WEB SERVICE</strong></span> button and click on <span class="strong"><strong>YES</strong></span> when it asks for confirmation, as shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/0792EN_11_07.jpg" alt="Publishing a model as a web service"/></div><p>It may take a while and once this is done, it would take you to the published web service dashboard page. You can get back to the parent scoring experiment by clicking on the link, which is the <span class="strong"><strong>View latest</strong></span> option (refer to <span class="strong"><strong>2</strong></span> in the following figure). The <span class="strong"><strong>View snapshot</strong></span> link also takes you to the same parent scoring experiment, but it <a id="id409" class="indexterm"/>shows the experiment in a locked view.</p><div class="mediaobject"><img src="graphics/0792EN_11_08.jpg" alt="Publishing a model as a web service"/></div><p>The default endpoint or the published web service API suggests how the web service would be called or <a id="id410" class="indexterm"/>consumed. The <span class="strong"><strong>Request/Response</strong></span> option (refer to <span class="strong"><strong>5</strong></span> in the preceding figure) specifies that you would call the web service with one feature set and get a response as a prediction based on how you defined the output. The <span class="strong"><strong>Batch Execution</strong></span> option (refer to <span class="strong"><strong>6</strong></span> in the preceding figure) requires that you pass a dataset (a feature matrix) as a file and get the output prediction also as a dataset.</p><div class="section" title="Visually testing a web service"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec66"/>Visually testing a web service</h2></div></div></div><p>You can visually <a id="id411" class="indexterm"/>test the published web service by clicking on the <span class="strong"><strong>Test</strong></span> button (refer to <span class="strong"><strong>7</strong></span> in the preceding figure). Click on the button and a popup form appears. Fill up the different features to make a prediction. Fill the form and click on the button with the tick mark in the bottom-right corner of the screen, as shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/0792EN_11_09.jpg" alt="Visually testing a web service"/></div><p>After it gets a response from the web service, you would see a message, as shown in the following figure:</p><div class="mediaobject"><img src="graphics/0792EN_11_10.jpg" alt="Visually testing a web service"/></div><p>As you can see in the preceding figure, it returned the predicted label <span class="strong"><strong>"&gt;50K"</strong></span>. You can also test the web service by <a id="id412" class="indexterm"/>downloading the Excel file (refer to <span class="strong"><strong>8</strong></span>), which is already configured to get connected with the web service. Just fill the fields to see the result.</p></div></div>
<div class="section" title="Consuming a published web service"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec68"/>Consuming a published web service</h1></div></div></div><p>Now that the web <a id="id413" class="indexterm"/>service has been published and is available as an API, you can write a program in the language of your choice and consume the API to get a prediction or the result of the API. The API needs an <span class="strong"><strong>API key</strong></span>, which you can find on the published web service dashboard page (refer to <span class="strong"><strong>4</strong></span>). Without the API key, you won't be able to connect to the web service. On the API help page, you will find the detailed documentation on the published API, including the sample code in <span class="strong"><strong>C#.Net</strong></span>, <span class="strong"><strong>Python</strong></span>, and <span class="strong"><strong>R,</strong></span> which include the necessary inline comments. You can find the links to the API help page from the same web service dashboard page (refer to <span class="strong"><strong>5</strong></span> and <span class="strong"><strong>6</strong></span>).</p></div>
<div class="section" title="Web service configuration"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec69"/>Web service configuration</h1></div></div></div><p>After you publish a <a id="id414" class="indexterm"/>model, the web service name will be available on the web services page with a link to the dashboard page of the web service, as shown in the following figure:</p><div class="mediaobject"><img src="graphics/0792EN_11_12.jpg" alt="Web service configuration"/></div><p>Click on the name of the web service and on the dashboard page, click on the <span class="strong"><strong>CONFIGURATION</strong></span> option (refer to <span class="strong"><strong>1</strong></span>). On the configuration page, you can customize the information related <a id="id415" class="indexterm"/>to the web service, for example, <span class="strong"><strong>Display Name</strong></span>, <span class="strong"><strong>Description</strong></span>, <span class="strong"><strong>Input Schema</strong></span>, <span class="strong"><strong>Output Schema</strong></span>, and so on.</p></div>
<div class="section" title="Updating the web service"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec70"/>Updating the web service</h1></div></div></div><p>You might need to <a id="id416" class="indexterm"/>update your published web service under the following two scenarios:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Your original model changed, for example, you modified the model parameters to improve performance and so on</li><li class="listitem" style="list-style-type: disc">You need to make changes to the input or output of the web service</li></ul></div><p>For the first case, you need to go back to your original training experiment, make the changes, run it, and then click on the <span class="strong"><strong>UPDATE SCORING EXPERIMENT</strong></span> link to update the scoring experiment. For both the scenarios, you have to go to the scoring experiment and publish it again, so it would overwrite the previously published experiment.</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec71"/>Summary</h1></div></div></div><p>In this chapter, you explored the complete steps to publish a model as a web service, so that others can use the API and consume the web service. You prepared an experiment to make it ready to be published and saved a trained model. You then created a scoring experiment and prepared it to set the input and output for the web service. You published the scoring experiment as a web service and tested it visually. You also explored ways to consume the web service API and how it can be maintained over a period of time by making configuration changes and updates.</p><p>In the next chapter, you will learn to build your own model with a case study exercise by solving a regression problem.</p></div></body></html>