- en: 'Chapter 2: Characterizing Your Machine Learning Problem'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will get a fundamental understanding of the various types
    of **Machine Learning** (**ML**) solutions that can be built for production, and
    will learn to categorize the relevant operations in line with the business and
    technological needs of your organization. You will learn how to curate an implementation
    roadmap for operationalizing ML solutions, followed by procuring the necessary
    tools and infrastructure for any given problem. By the end of this chapter, you
    will have a solid understanding of how to architect robust and scalable ML solutions
    and procure the required data and tools for implementing these solutions.
  prefs: []
  type: TYPE_NORMAL
- en: '**ML Operations** (**MLOps**) aims to bridge academia and industry using state-of-the-art
    engineering principles, and we will explore different elements from both industry
    and academia to get a holistic understanding and awareness of the possibilities.
    Before beginning to craft your MLOps solution, it is important to understand the
    various possibilities, setups, problems, solutions, and methodologies on offer
    for solving business-oriented problems. To achieve this understanding, we''re
    going to cover the following main topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The ML solution development process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of ML models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Characterizing your MLOps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An implementation roadmap for your solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Procuring the necessary data, tools, and infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to a real-life business problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Without further ado, let's jump in and explore the possibilities ML can enable
    by taking an in-depth look into the ML solution development process and examining
    different types of ML models to solve business problems.
  prefs: []
  type: TYPE_NORMAL
- en: The ML solution development process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'ML offers many possibilities to augment and automate business. To get the best
    from ML, teams and people engaged in ML-driven business transformation need to
    understand both ML and the business itself. Efficient business transformation
    begins with having a rough understanding of the business, including aspects such
    as value-chain analysis, use-case identification, data mapping, and business simulations
    to validate the business transformation. *Figure 2.1* presents a process to develop
    ML solutions to augment or automate business operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – ML solution development process'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.1 – ML solution development process
  prefs: []
  type: TYPE_NORMAL
- en: Business understanding is the genesis of developing an ML solution. After having
    a decent business understanding, we proceed to data analysis, where the right
    data is acquired, versioned, and stored. Data is consumed for ML modeling using
    data pipelines where feature engineering is done to get the right features to
    train the model. We evaluate the trained models and package them for deployment.
    Deployment and monitoring are done using a pipeline taking advantage of **Continuous
    Integration/Continuous Deployment** (**CI/CD**) features that enable real-time
    and continuous deployment to serve trained ML models to the users. This process
    ensures robust and scalable ML solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Types of ML models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As there is a selection of ML and deep learning models that address the same
    business problem, it is essential to understand the landscape of ML models in
    order to make an efficient algorithm selection. There are around 15 types of ML
    techniques, these being categorized into 4 categories, namely **learning models**,
    **hybrid models**, **statistical models**, and **Human-In-The-Loop** (**HITL**)
    models, as shown in the following matrix (where each grid square reflects one
    of these categories) in *Figure 2.2*. It is worth noting that there are other
    possible ways of categorizing ML models and none of them are fully complete, and
    as such, these categorizations will serve appropriately for some scenarios and
    not for others. Here is our recommended categorization with which to look at ML
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Types of ML models'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.2 – Types of ML models
  prefs: []
  type: TYPE_NORMAL
- en: Learning models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we''ll take a look at two types of standard learning models, **supervised
    learning** and **unsupervised learning**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – Supervised versus unsupervised learning'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.3 – Supervised versus unsupervised learning
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Supervised learning models or algorithms are trained based on labeled data.
    In the training data, the result of the input is marked or known. Hence a model
    is trained to predict the outcome when given an input based on the labeled data
    it learns from, and you tell the system which output corresponds with a given
    input in the system.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning models are very effective on narrow AI cases and well-defined
    tasks but can only be harnessed where there is sufficient and comprehensive labeled
    data. We can see in *Figure 2.3*, in the case of supervised learning, that the
    model has learned to predict and classify an input.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the example of an image classification model used to classify images
    of cats and dogs. A supervised learning model is trained on labeled data consisting
    of thousands of correctly labeled images of cats and dogs. The trained model then
    learns to classify a given input image as containing a dog or a cat.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unsupervised learning has nothing to do with a machine running around and doing
    things without human supervision. Unsupervised learning models or algorithms learn
    from unlabeled data. Unsupervised learning can be used to mine insights and identify
    patterns from unlabeled data. Unsupervised algorithms are widely used for clustering
    or anomaly detection without relying on any labels. These algorithms can be pattern-finding
    algorithms; when data is fed to such an algorithm, it will identify patterns and
    turn those into a recipe for taking a new data input without a label and applying
    the correct label to it.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning is used mainly for analytics, though you could also use
    it for automation and ML. It is recommended not to use these algorithms in production
    due to their dynamic nature that changes outputs on every training cycle. However,
    they can be useful to automate certain processes such as segmenting incoming data
    or identifying anomalies in real time.
  prefs: []
  type: TYPE_NORMAL
- en: Let's discuss an example of clustering news articles into relevant groups. Let's
    assume you have thousands of news articles without any labels and you would like
    to identify the types or categories of articles. To perform unsupervised learning
    on these articles, we can input a bunch of articles into the algorithm and converge
    it to put similar things together (that is, clustering) in four groups. Then,
    we look at the clusters and discover that similar articles have been grouped together
    in categories such as politics, sports, science, and health. This is a way of
    mining patterns in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There have been rapid developments in ML by combining conventional methods
    to develop hybrid models to solve diverse business and research problems. Let''s
    look into some hybrid models and how they work. *Figure 2.4* shows various hybrid
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Types of hybrid models'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.4 – Types of hybrid models
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Semi-supervised learning** is a hybrid of supervised learning, used in cases
    where only a few samples are labeled and a large number of samples are not labeled.
    Semi-supervised learning enables efficient use of the data available (though not
    all of it is labeled), including the unlabeled data. For example, a text document
    classifier is a typical example of a semi-supervised learning program. It will
    be very difficult to locate a large number of labeled text documents in this case,
    so semi-supervised learning is ideal. This is due to the fact that making someone
    read through entire text documents just to assign a basic classification is inefficient.
    As a result, semi-supervised learning enables the algorithm to learn from a limited
    number of labeled text documents while classifying the large number of unlabeled
    text documents present in the training data.'
  prefs: []
  type: TYPE_NORMAL
- en: Self-supervised learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Self-supervised learning** problems are unsupervised learning problems where
    data is not labeled; these problems are translated into supervised learning problems
    in order to apply algorithms for supervised learning to solve them sustainably.
    Usually, self-supervised algorithms are used to solve an alternate task in which
    they supervise themselves to solve the problem or generate an output. One example
    of self-supervised learning is **Generative Adversarial Networks** (**GANs**);
    these are commonly used to generate synthetic data by training on labeled and/or
    unlabeled data. With proper training, GAN models can generate a relevant output
    in a self-supervised manner. For example, a GAN could generate a human face based
    on a text description input, such as *gender: male, age: 30, color: brown*, and
    so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Multi-instance learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Multi-instance learning** is a supervised learning problem in which data
    is not labeled by individual data samples, but cumulatively in categories or classes.
    Compared to typical supervised learning, where labeling is done for each data
    sample, such as news articles labeled in categories such as politics, science,
    and sports, with multi-instance learning, labeling is done categorically. In such
    scenarios, individual samples are collectively labeled in multiple classes, and
    by using supervised learning algorithms, we can make predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: Multitask learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Multitask learning** is an incarnation of supervised learning that involves
    training a model on one dataset and using that model to solve multiple tasks or
    problems. For example, for natural language processing, we use word embeddings
    or **Bidirectional Encoder Representations from Transformers** (**BERT**) embeddings
    models, which are trained on one large corpus of data. (BERT is a pre-trained
    model, trained on a large text corpus. The model has a deep understanding of how
    a given human language works.) And these models can be used to solve many supervised
    learning tasks such as text classification, keyword extraction, sentiment analysis,
    and more.'
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Reinforcement learning** is a type of learning in which an agent, such as
    a robot system, learns to operate in a defined environment to perform sequential
    decision-making tasks or achieve a pre-defined goal. Simultaneously, the agent
    learns based on continuously evaluated feedback and rewards from the environment.
    Both feedback and rewards are used to shape the learning of the agent, as shown
    in *Figure 2.5*. An example is Google''s AlphaGo, which recently outperformed
    the world''s leading Go player. After 40 days of self-training using feedback
    and rewards, AlphaGo was able to beat the world''s best human Go player:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – Reinforcement learning'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.5 – Reinforcement learning
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Ensemble learning** is a hybrid model that involves two or more models trained
    on the same data. Predictions are made using each model individually and a collective
    prediction is made as a result of combining all outputs and averaging them to
    determine the final outcome or prediction. An example of this is the random forest
    algorithm, which is an ensemble learning method for classification or regression
    tasks. It operates by composing several decision trees while training, and creates
    a prediction as output by averaging the predictions of all the decision trees.'
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We humans have an innate ability to transfer knowledge to and from one another.
    This same principle is translated to ML, where a model is trained to perform a
    task and it is transferred to another model as a starting point for training or
    fine-tuning for performing another task. This type of learning is popular in deep
    learning, where pre-trained models are used to solve computer vision or natural
    language processing problems by fine-tuning or training using a pre-trained model.
    Learning from pre-trained models gives a huge jumpstart as models don't need to
    be trained from scratch, saving large amounts of training data. For example, we
    can train a sentiment classifier model using training data containing only a few
    labeled data samples. This is possible with transfer learning using a pre-trained
    BERT model (which is trained on a large corpus of labeled data). This enables
    the transfer of learning from one model to another.
  prefs: []
  type: TYPE_NORMAL
- en: Federated learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Federated learning** is a way of performing ML in a collaborative fashion
    (synergy between cloud and edge). The training process is distributed across multiple
    devices, storing only a local sample of the data. Data is neither exchanged nor
    transferred between devices or the cloud to maintain data privacy and security.
    Instead of sharing data, locally trained models are shared to learn from each
    other to train global models. Let''s discuss an example of federated learning
    in hospitals (as shown in *Figure 2.6*) where patient data is confidential and
    cannot be shared with third parties. In this case, ML training is done locally
    in the hospitals (at the edge) and global models are trained centrally (on the
    cloud) without sharing the data. Models trained locally are fine-tuned to produce
    global models. Instead of ingesting data in the central ML pipeline, locally trained
    models are ingested. Global models learn by tuning their parameters from local
    models to converge on optimal performance, concatenating the learning of local
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Federated learning architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.6 – Federated learning architecture
  prefs: []
  type: TYPE_NORMAL
- en: Statistical models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In some cases, statistical models are efficient at making decisions. It is
    vital to know where statistical models can be used to get the best value or decisions.
    There are three types of statistical models: inductive learning, deductive learning,
    and transductive learning. *Figure 2.7* shows the relationship between these types
    of statistical models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – Relationship between the three types of statistical models'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.7 – Relationship between the three types of statistical models
  prefs: []
  type: TYPE_NORMAL
- en: '**Inductive learning** is a statistical method that generalizes from specific
    examples in the training data, using this evidence to determine the most likely
    outcome. It involves a process of learning by example, where a system tries to
    generalize a general function or rule from a set of observed instances. For example,
    when we fit an ML model, it is a process of induction. The ML model is a generalization
    of the specific examples in the training dataset. For instance, using linear regression
    when fitting the model to the training data generalizes specific examples in the
    training data by the function *Y = a + bX*. Such generalizations are made in inductive
    learning.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deductive learning** refers to using general rules to determine specific
    outcomes. The outcomes of deductive learning are deterministic and specific, whereas
    for inductive reasoning, the conclusions are probabilistic or generalized. In
    a way, deduction is the reverse of induction. If induction goes from the specific
    to the general, deduction goes from the general to the specific.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transductive learning** is a method for reasoning about outcomes based on
    specific training data samples (in the training dataset). This method is different
    from inductive learning, where predictions are generalized over the training data.
    In transductive learning, specific or similar data samples from the training data
    are compared to reason about or predict an outcome. For example, in the case of
    the *k*-nearest neighbors algorithm, it uses specific data samples on which to
    base its outcome rather than generalizing the outcome or modeling with the training
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: HITL models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two types of **HITL** models: **human-centered reinforcement learning**
    models and **active learning** models. In these models, human-machine collaboration
    enables the algorithm to mimic human-like behaviors and outcomes. A key driver
    for these ML solutions is the *human in the loop (hence HITL)*. Humans validate,
    label, and retrain the models to maintain the accuracy of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Workflow of human-centered reinforcement learning'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.8 – Workflow of human-centered reinforcement learning
  prefs: []
  type: TYPE_NORMAL
- en: '**Human-centered reinforcement learning** is a hybrid of reinforcement learning,
    as it involves humans in the loop to monitor the agent''s learning and provide
    evaluative feedback to shape the learning of the agent. Human-centered reinforcement
    learning is also known as *interactive reinforcement learning*. Each time the
    agent takes action, the observing human expert can provide evaluative feedback
    that describes the quality of the selected action taken by the agent based on
    the human expert''s knowledge, as shown in *Figure 2.8*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the feedback received from the task environment and human expert,
    the agent augments its behavior and actions. Human reinforcement learning is highly
    efficient in environments where the agent has to learn or mimic human behavior.
    To learn more, read the paper *Human-Centered Reinforcement Learning: A Survey*
    ([https://ieeexplore.ieee.org/abstract/document/8708686](https://ieeexplore.ieee.org/abstract/document/8708686)).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Active learning** is a method where the trained model can query a HITL (the
    human user) during the inference process to resolve incertitude during the learning
    process. For example, this could be a question-answering chatbot asking the human
    user for validation by asking yes or no questions.'
  prefs: []
  type: TYPE_NORMAL
- en: These are the types of ML solutions possible to build for production to solve
    problems in the real world. Now that you are aware of the possibilities for crafting
    ML solutions, as the next step, it is critical to categorize your MLOps in line
    with your business and technological needs. It's important for you to be able
    to identify the right requirements, tools, methodology, and infrastructure needed
    to support your business and MLOps, hence we will look into structuring MLOps
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Structuring your MLOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The primary goal of MLOps is to make an organization or set of individuals collaborate
    efficiently to build data and ML-driven assets to solve their business problems.
    As a result, overall performance and transparency are increased. Working in silos
    or developing functionalities repeatedly can be extremely costly and time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will explore how MLOps can be structured within organizations.
    Getting the MLOps process right is of prime importance. By selecting the right
    process and tools for your MLOps, you and your team are all set to implement a
    robust, scalable, frugal, and sustainable MLOps process. For example, I recently
    helped one of my clients in the healthcare industry to build and optimize their
    MLOps, which resulted in 76% cost optimization (for storage and compute resources)
    compared to their previous traditional operations.
  prefs: []
  type: TYPE_NORMAL
- en: The client's team of data scientists witnessed having 30% of their time freed
    up from mundane and repetitive daily tasks (for example, data wrangling, ML pipeline,
    and hyperparameter tuning) – such can be the impact of having an efficient MLOps
    process. By implementing efficient MLOps, your team can be assured of efficiency,
    high performance, and great collaboration that is repeatable and traceable within
    your organization.
  prefs: []
  type: TYPE_NORMAL
- en: 'MLOps can be categorized into **small data ops**, **big data ops**, **large-scale
    MLOps**, and **hybrid MLOps** (this categorization is based on the author''s experience
    and is a recommended way to approach MLOps for teams and organizations):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – Categories of MLOps'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.9 – Categories of MLOps
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in *Figure 2.9*, MLOps within organizations can be broadly categorized
    into four different categories depending on team size, and the ML applications,
    business models, data scale, tools, and infrastructure used to execute operations.
    In terms of data, many scenarios do not need big data (anything above 1 TB) operations,
    as simple operations can be effective for small- or medium-scale data. The differences
    between data scales are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Big data**: A quantity of data that cannot fit in the memory of a single
    typical computer; for instance, > 1 TB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Medium-scale data**: A quantity of data that can fit in the memory of a single
    server; for instance, from 10 GB to 1 TB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Small-scale data**: A quantity of data that easily fits in the memory of
    a laptop or a PC; for instance, < 10 GB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these factors in mind, let's look into the MLOps categories to identify
    the suitable process and scale for implementing MLOps for your business problems
    or organization.
  prefs: []
  type: TYPE_NORMAL
- en: Small data ops
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A small start-up with a team of data scientists seeking to build ML models
    for narrow and well-defined problems can be agile and highly collaborative. Usually,
    in such cases, ML models are trained locally on the respective data scientists''
    computers and then forgotten about, or scaled out and deployed on the cloud for
    inference. In these scenarios, there can be some general pitfalls, such as the
    team lacking a streamlined CI/CD approach for deploying models. However, they
    might manage to have central or distributed data sources that are managed carefully
    by the team, and the training code can be versioned and maintained in a central
    repository. When operations start to scale, such teams are prone to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Running into situations where much of the work is repeated by multiple people
    including tasks such as crafting data, ML pipelines doing the same job, or training
    similar types of ML models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working in silos and having minimal understanding of the parallel work of their
    teammates. This leads to less transparency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incurring huge costs, or higher costs than expected, due to the mundane and
    repeated work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code and data starting to grow independently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artifacts not being audited and hence are non-repeatable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Any of these can be costly and unsustainable for the team. If you are working
    in a team or have a setup like the following, you can categorize your operations
    as small data ops:'
  prefs: []
  type: TYPE_NORMAL
- en: The team consists of only data scientists.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You only work with Python environments and manage everything in the Python framework.
    Choosing Python can be a result of having many ML libraries and tools ready to
    plug and play for quick prototyping and building solutions. The number of ML libraries
    for a language such as Java, for example, is quite a lot smaller compared to those
    available for Python.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Little to no big data processing is required as the data scientists use small
    data (<10 GB).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quick ML model development starts with a local computer, then scales out to
    the cloud for massive computation resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High support requirements for open source technologies such as PyTorch, TensorFlow,
    and scikit-learn for any type of ML, from classical learning to deep, supervised,
    and unsupervised learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Big data ops
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This can be a team of experienced data scientists and engineers working in
    a start-up or an SME where they have the requirement for large-scale big data
    processing to perform ML training or inference. They use big data tools such as
    **Kafka**, **Spark**, or **Hadoop** to build and orchestrate their data pipelines.
    High-powered processors such as GPUs or TPUs are used in such scenarios to speed
    up data processing and ML training. The development of ML models is led by data
    scientists and deploying the models is orchestrated by data/software engineers.
    A strong focus is given to developing models and less importance is placed on
    monitoring the models. As they continue with their operations, this type of team
    is prone to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A lack of traceability for model training and monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lack of reproducible artifacts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incurring huge costs, or more than expected, due to mundane and repeated work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code and data starting to grow independently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any of these can be costly and unsustainable for a team.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are working in a team or have a setup as described in the following
    points, you can categorize your operations as big data ops:'
  prefs: []
  type: TYPE_NORMAL
- en: The team consists of data scientists/engineers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are high requirements for big data processing capacity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Databricks is a key framework to share and collaborate inside teams and between
    organizations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML model development happens in the cloud by utilizing one of many ML workflow
    management tools such as **Spark MLlib**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are low support requirements for open source technologies such as PyTorch
    and TensorFlow for deep learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hybrid MLOps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Hybrid teams operate with experienced data scientists, data engineers, and
    DevOps engineers, and these teams make use of ML capabilities to support their
    business operations. They are further ahead in implementing MLOps compared to
    other teams. They work with big data and open source software tools such as PyTorch,
    TensorFlow, and scikit-learn, and hence have a requirement for efficient collaboration.
    They often work on well-defined problems by implementing robust and scalable software
    engineering practices. However, this team is still prone to challenges such as
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Incurring huge costs, or more than expected, due to mundane and repeated work
    to be done by data scientists, such as repeating data cleaning or feature engineering.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inefficient model monitoring and retraining mechanisms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any of these can be costly and unsustainable for the team.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are working in a team or have a setup as described in the following
    points, you can categorize your operations as Hybrid Ops:'
  prefs: []
  type: TYPE_NORMAL
- en: The team consists of data scientists, data engineers, and DevOps engineers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High requirement for efficient and effective collaboration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High requirement for big data processing capacity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High support requirements for open source technologies such as PyTorch, TensorFlow,
    and scikit-learn for any kind of ML, from classical to deep learning, and from
    supervised to unsupervised learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large-scale MLOps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Large-scale operations are common in big companies with large or medium-sized
    engineering teams consisting of data scientists, data engineers, and DevOps engineers.
    They have data operations on the scale of big data, or with various types of data
    on various scales, veracity, and velocity. Usually, their teams have multiple
    legacy systems to manage to support their business operations. Such teams or organizations
    are prone to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Incurring huge costs, or more than expected, due to mundane and repeated work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code and data starting to grow independently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having bureaucratic and highly regulated processes and quality checks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highly entangled systems and processes – when one thing breaks, everything breaks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any of these can be costly and unsustainable for the team.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are working in a team or have a setup as described in the following
    points, you can categorize your operations as large-scale ops:'
  prefs: []
  type: TYPE_NORMAL
- en: The team consists of data scientists, data engineers, and DevOps engineers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large-scale inference and operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Big data operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML model management on multiple resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Big or multiple teams.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple use cases and models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you have characterized your MLOps as per your business and technological
    needs, a solid implementation roadmap ensures smooth development and implementation
    of a robust and scalable MLOps solution for your organization. For example, a
    fintech start-up processing 0-1,000 transactions a day would need small-scale
    data ops compared to a larger financial institution that needs large-scale MLOps.
    Such categorization enables a team or organization to be more efficient and robust.
  prefs: []
  type: TYPE_NORMAL
- en: An implementation roadmap for your solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having a well-defined method and milestones ensures the successful delivery
    of the desired ML solution (using MLOps methods). In this section, we will discuss
    a generic implementation roadmap that can facilitate MLOps for any ML problem
    in detail. The goal of this roadmap is to solve the problem with the right solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – Implementation roadmap for an MLOps-based solution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.10 – Implementation roadmap for an MLOps-based solution
  prefs: []
  type: TYPE_NORMAL
- en: Using the preceding roadmap, we can transition from ML development to MLOps
    with clear milestones, as shown in these three phases for MLOps implementation.
    Now, let's look into these three phases of the roadmap in more detail. It's worth
    noting that after the following section on theory, we will get into the practical
    implementation of the roadmap and work on a real-world business use case.
  prefs: []
  type: TYPE_NORMAL
- en: Phase 1 – ML development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is the genesis of implementing the MLOps framework for your problem; before
    beginning to implement the requirements, the problem and solution must be clear
    and vivid. In this phase, we take into account the system requirements to design
    and implement a robust and scalable MLOps framework. We begin by selecting the
    right tools and infrastructure needed (storage, compute, and so on) to implement
    the MLOps.
  prefs: []
  type: TYPE_NORMAL
- en: When the infrastructure is set up, we should be provisioned with the necessary
    workspace and the development and test environments to execute ML experiments
    (training and testing). We train the ML models using the development environment
    and test the models for performance and functionality using test data in the development
    or test environments, depending on the workflow or requirement. When infrastructure
    is set up and the first ML model is trained, tested, serialized, and packaged,
    phase 1 of your MLOps framework is set up and validated for robustness. Serializing
    and containerizing is an important process to standardize and get the models ready
    for deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we move to implement phase 2\.
  prefs: []
  type: TYPE_NORMAL
- en: Phase 2 – Transition to operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Phase 2 is about transitioning to operations, and it involves serializing and
    containerizing the models trained in phase 1 and getting them ready for deployment.
    This enables standardized, efficient deployments. The models are served in the
    form of APIs or independent artifacts for batch inference. When a model is packaged
    and ready to be served, it is deployed in the production environment using streamlined
    CI/CD pipelines upon passing quality assurance checks. By the end of phase 2,
    you will have packaged models served and deployed in the production environment
    performing inference in real time.
  prefs: []
  type: TYPE_NORMAL
- en: Phase 3 – Operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Phase 3 is the core operations phase for deployed models in phase 2\. In this
    phase, we monitor the deployed model performance in terms of model drift, bias,
    or other metrics (we will delve into these terms and metrics in the coming chapters).
    Based on the model's performance, we can enable continual learning via periodic
    model retraining and enable alerts and actions. Simultaneously, we monitor logs
    in telemetry data for the production environment to detect any possible errors
    and resolve them on the go to ensure the uninterrupted working of the production
    system. We also manage data pipelines, the ML platform, and security on the go.
    With the successful implementation of this phase, we can monitor the deployed
    models and retrain them in a robust, scalable, and secure manner.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, all three phases need to be implemented for your ML solution,
    but in some cases just phases 1 and 2 are enough; for instance, when the ML models
    make batch inferences and need not do inference in real time. By achieving these
    milestones and implementing all three phases, we have set up a robust and scalable
    ML life cycle for our applications systematically and sustainably.
  prefs: []
  type: TYPE_NORMAL
- en: Procuring data, requirements, and tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implementing successful MLOps depends on certain factors such as procuring appropriate
    training data, and having high standards, and appropriate requirements, tools,
    and infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will delve into these factors that make robust and scalable
    MLOps.
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I used to believe that learning about data meant mastering tools such as Python,
    SQL, and regression. The tool is only as good as the person and their understanding
    of the context around it. The context and domain matter, from data cleaning to
    modeling to interpretation. The best tools in the world won't fix a bad problem
    definition (or lack of one). Knowing what problem to solve is a very context-driven
    and business-dependent decision. Once you are aware of the problem and context,
    it enables you to discern the right training data needed to solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Training data is a vital part of ML systems. It plays a vital role in developing
    ML systems compared to traditional software systems. As we have seen in the previous
    chapter, both code and training data work in parallel to develop and maintain
    an ML system. It is not only about the algorithm but also about the data. There
    are two aspects to ensure you have the right data for algorithm training, which
    are to provide both the right quantity and quality of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data quantity**: Data scientists echo a common argument about their models,
    arguing that model performance is not good because the quantity of data they were
    given was not sufficient to produce good model performance. If they had more data,
    the performance would have been better – are you familiar with such arguments?
    In most cases, more data might not really help, as quality also is an important
    factor. For instance, your models can learn more insights and characteristics
    from your data if you have more samples for each class. For example, if you analyze
    anomalous financial transactions with many samples in your data, you will discover
    more types of anomalous transactions. If there is only one anomalous case, then
    ML is not useful.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data requirements for ML projects should not solely focus on data quantity
    itself, but also on the quality, which means the focus should not be on the number
    of data samples but rather on the diversity of data samples. However, in some
    cases, there are constraints on the quantity of data available to tackle some
    problems. For example, let's suppose we work on models to predict the churn rate
    for an insurance company. In that case, we can be restricted to considering data
    from a limited period or using a limited number of samples due to the availability
    of data for a certain time period; for example, 5 years (whereas the insurance
    company might have operated for the last 50 years). The goal is to acquire data
    of the maximum possible quantity and quality to train the best-performing ML models.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Data quality**: Data quality is an important factor for training ML models;
    it impacts model performance. The more comprehensive or higher the quality of
    the data, the better the ML model or application will work. Hence the process
    before the training is important: cleaning, augmenting, and scaling the data.
    There are some important dimensions of data quality to consider, such as consistency,
    correctness, and completeness.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data consistency refers to the correspondence and coherence of the data samples
    throughout the dataset. Data correctness is the degree of accuracy and the degree
    to which you can rely on the data to truly reflect events. Data correctness is
    dependent on how the data was collected. The sparsity of data for each characteristic
    (for example, whether the data covers a comprehensive range of possible values
    to reflect an event) reflects data completeness.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With an appropriate quantity of good-quality data, you can be sure that your
    ML models and applications will perform above the required standards. Hence, having
    the right standards is vital for the application to perform and solve business
    problems in the most efficient ways.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The product or business/tech problem owner plays a key role in facilitating
    the building of a robust ML system efficiently by identifying requirements and
    tailoring them with regard to the scope of data, collection of data, and required
    data formats. These requirements are vital inputs for developers of ML systems,
    such as data scientists or ML engineers, to start architecting the solution to
    address the problem by analyzing and correlating the given dataset based on the
    requirements. ML solution requirements should consist of comprehensive data requirements.
    Data requirement specifications consist of information about the quality and quantity
    of the data. The requirements can be more extensive; for example, they can contain
    estimations about anticipated or expected predictive performance expressed in
    terms of the performance metrics determined during requirements analysis and elicitation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Meticulous specifications can be made, such as the specification of expected
    or anticipated performance on the training data, as these can be rapidly validated
    after the model training process. Whereas, based on the training performance,
    inference or runtime (including in production and operations) performance can
    be assessed during operations. The requirements made by the product owner or business
    owner should consider important factors such as ethical and explainability factors.
    Discrimination or bias (such as who or what is predicted or classified) is critical
    for the application and which properties should be preserved as part of data privacy
    (for example, some properties should not be used for predictions or classification,
    such as race, age, or gender). Explainability requirements must explicitly be
    taken into account to explain situations and decisions of the ML solution or system
    to the users of the system. Lastly, the requirements must stipulate regulations
    and restrictions concerning the use of the data and validation of decisions made
    by the ML system. The following table shows some requirements to consider to ensure
    that you build a robust and scalable ML solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Requirements mapping for ML solutions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16572_02_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.11 – Requirements mapping for ML solutions
  prefs: []
  type: TYPE_NORMAL
- en: The table in *Figure 2.11* illustrates the flow of the requirements characterization
    process, from elicitation to analysis to specifications to verification and validation
    of the system. This process ensures best-fit resources are procured to build and
    deploy an efficient ML system to solve your problem. When the requirements are
    well defined, selecting the right tools and infrastructure that support the established
    process and ensure the standards are met is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: Tools and infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The MLOps landscape has been developing rapidly over the last two years; many
    tools and frameworks have evolved as part of the infrastructural offering. You
    can visit [https://landscape.lfai.foundation/](https://landscape.lfai.foundation/)
    to see how many mainstream options have been developed to orchestrate ML, deep
    learning, reinforcement learning, development environments, data pipelines, model
    management, explainable AI, security, and distributed computing.
  prefs: []
  type: TYPE_NORMAL
- en: There is a surge in services provided by popular cloud service providers such
    as Microsoft, AWS, and Google, which are complemented by data processing tools
    such as Airflow, Databricks, and Data Lake. These are crafted to enable ML and
    deep learning, for which there are great frameworks available such as scikit-learn,
    Spark MLlib, PyTorch, TensorFlow, MXNet, and CNTK, among others. Tools and frameworks
    are many, but procuring the right tools is a matter of choice and the context
    of your ML solution and operations setup. Having the right tools will ensure high
    efficiency and automation for your MLOps workflow. The options are many, the sky's
    the limit, but we have to start from somewhere to reach the sky. For this reason,
    we will look to give you some hands-on experience from here onward. It is always
    better to learn from real-life problems, and we will do so by using the real-life
    business problem described in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Discussing a real-life business problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will be implementing the following business problem to get hands-on experience.
    I recommend you read this section multiple times to get a good understanding of
    the business problem; it makes it easier to implement it.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem context:'
  prefs: []
  type: TYPE_NORMAL
- en: You work as a data scientist in a small team with three other data scientists
    for a cargo shipping company based in the port of Turku in Finland. 90% of the
    goods imported into Finland come via cargo ships at the ports across the country.
    For cargo shipping, weather conditions and logistics can be challenging at times
    at the ports. Rainy conditions can distort operations and logistics at the ports,
    which can affect the supply chain operations. Forecasting rainy conditions in
    advance gives the possibility to optimize resources such as human resources, logistics,
    and transport resources for efficient supply chain operations at ports. Business-wise,
    forecasting rainy conditions in advance enables ports to reduce operational costs
    by up to ~20% by enabling efficient planning and scheduling of human resources,
    logistics, and transport resources for supply chain operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Task:'
  prefs: []
  type: TYPE_NORMAL
- en: You as a data scientist are tasked with developing an ML-driven solution to
    forecast weather conditions 4 hours in advance at the port of Turku in Finland.
    That will enable the port to optimize its resources, thereby enabling cost-savings
    of up to 20%. To get started, you are provided with a historic weather dataset
    covering a timeline of 10 years from the port of Turku (the dataset can be accessed
    in the next chapter). Your task is to build a continuous-learning-driven ML solution
    to optimize operations at the port of Turku.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this problem, we will use Microsoft Azure, one of the most widely
    used cloud services, and MLflow, an open source ML development tool, to get hands-on
    with using resources. This way, we will get experience working on the cloud and
    with open source software. Before starting the hands-on implementation in the
    next chapter, please make sure to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a free Azure subscription from [https://azure.microsoft.com/](https://azure.microsoft.com/)
    (takes 5 minutes).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an Azure Machine Learning service application with the name `MLOps_WS`.
    This can be done from your Azure portal by clicking `Machine Learning` into the
    search field and select the `MLOps_WS`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, with this, you are all set to get hands-on with implementing an MLOps framework
    for the preceding business problem.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned about the ML solution development process,
    how to identify a suitable ML solution to a problem, and how to categorize operations
    to implement suitable MLOps. We got a glimpse into a generic implementation roadmap
    and saw some tips for procuring essentials such as tools, data, and infrastructure
    to implement your ML application. Lastly, we went through the business problem
    to be solved in the next chapter by implementing an MLOps workflow (discussed
    in [*Chapter 1*](B16572_01_Final_JM_ePub.xhtml#_idTextAnchor015), *Fundamentals
    of MLOps Workflow*) in which we'll get some hands-on experience in MLOps.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will go from theory to practical implementation. The
    chapter gets hands-on when we start with setting up MLOps tools on Azure and start
    coding to clean the data to address the business problem and get plenty of hands-on
    experience.
  prefs: []
  type: TYPE_NORMAL
