- en: '*Chapter 3*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Probability Distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate different distributions in R
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimate probability distribution functions for new datasets in R
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compare the closeness of two different samples of the same distribution or different
    distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to use probability distributions as a form
    of unsupervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we're going to study another aspect of unsupervised learning,
    called **probability distributions**. Probability distributions are part of classical
    statistics covered in many mathematical textbooks and courses. With the advent
    of big data, we've started using probability distributions in exploratory data
    analysis and other modeling applications as well. So, in this chapter, we're going
    to study how to use probability distributions in unsupervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: Basic Terminology of Probability Distributions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two families of methods in statistics: parametric and non-parametric
    methods. Non-parametric methods are meant to deal with data that could take any
    shape. Parametric methods, by contrast, make assumptions about the particular
    shape that data takes on. These assumptions are often encoded as parameters. The
    following are the two main parameters that you should be aware of:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mean**: This is the average of all values in the distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standard Deviation**: This is the measure of the spread of values around
    the mean of a distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Most of the parametric methods in statistics depend in some way on those two
    parameters. The parametric distributions that we''re going to study in this chapter
    are these:'
  prefs: []
  type: TYPE_NORMAL
- en: Uniform distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normal distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log-normal distributions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binomial distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Poisson distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pareto distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uniform Distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the uniform distribution, all values between an interval, let''s say [a,b],
    are equiprobable. Mathematically, it''s defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1: Mathematical formula for uniform distribution](img/C12628_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: Mathematical formula for a uniform distribution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'It can be plotted on a graph as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2: Graph of uniform distribution](img/C12628_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2: Graph of a uniform distribution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The uniform distribution is the simplest of the parametric distributions. There
    are many processes in the real world that follow uniform sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: If it's raining in a very large area, the distribution of where raindrops will
    fall can be assumed to be uniform in a small area.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last digit of a social security number should follow a uniform distribution
    for any subset of people, such as for all the CEOs of start-ups in California.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uniform random sampling is very important for generating data for experiments
    and running controlled trials.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exercise 14: Generating and Plotting Uniform Samples in R'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will generate uniform samples and plot them. To do this,
    perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the built-in `runif` R function to generate uniform samples. Firstly, enter
    the number of samples you want to generate. Here we''re generating 1,000 samples.
    Then, enter the `min` value and `max` value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After storing the generated random numbers in the `uni` variable, we''ll plot
    their values versus their index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.3: Uniform distribution](img/C12628_03_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.3: Uniform distribution'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, the points are scattered everywhere almost equally. We can also
    plot a histogram of this to get a clearer picture of the distribution.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We''ll use the `hist()` function of R to plot a histogram of the generated
    sample:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.4: Histogram of the distribution](img/C12628_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.4: Histogram of the distribution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, it's not exactly flat, as we envisioned it previously. It's
    more or less uniform, but not exactly uniform, because it was randomly generated.
    Each time we generate a new sample, it will resemble this histogram, and most
    probably won't be exactly flat, because of the noise that comes with all random
    sampling methods.
  prefs: []
  type: TYPE_NORMAL
- en: Normal Distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The normal distribution is a type of parametric distribution that is governed
    by two parameters: mean and standard deviation from the mean. It''s symmetric
    about the mean, and most values are near the mean. Its curve is also known as
    a bell curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5: Approximate representation of a bell curve, typical with normally
    distributed data](img/C12628_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.5: Approximate representation of a bell curve, typical with normally
    distributed data'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The normal distribution is defined by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12628_03_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.6: Equation for the normal distribution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Here, ![](img/C12628_03_Formula_01.png) is the mean and ![](img/C12628_03_Formula_02.png)
    is the standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The normal distribution is a very common type of distribution in the real world.
    The following are some examples of the normal distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: The height of NBA players is approximately normally distributed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The scores of students in a class could have a distribution that is very close
    to the normal distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Nile's yearly flow volume is normally distributed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we're going to generate and plot a normal distribution in R.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 15: Generating and Plotting a Normal Distribution in R'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will generate a normal distribution to model the test
    scores (out of 100) of 1,000 school pupils and plot them. To do this, perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a normal distribution by entering the number of samples, the mean,
    and the standard deviation in the `rnorm` function in R:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the generated numbers against their index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.7: Normal distribution](img/C12628_03_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.7: Normal distribution'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see here, most values are around the mean of 50, and as we move away
    from 50, the number of points starts decreasing. This distribution will be clarified
    by with a histogram in the next step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot a histogram of the normal distribution with the `hist()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.8: Normal distribution histogram](img/C12628_03_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.8: Normal distribution histogram'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can see that this shape very much resembles the bell curve of the normal
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Skew and Kurtosis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we have seen, many of the distributions you''ll see in practice are assumed
    to be normal distributions. But not every distribution is a normal distribution.
    To measure the degree to which a distribution deviates from a standard normal
    distribution, we use two parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: Skew
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kurtosis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The **Skew** of a distribution is the measure its asymmetry compared to the
    standard normal distribution. In a dataset with high skew, the mean and mode will
    differ from each other. The skew can be of two types: positive and negative:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.9: Negative skew and positive skew](img/C12628_03_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9: Negative skew and positive skew'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Negative skew is when there is a long tail of values on the left-hand side
    of the mean, and positive skew is when there is a long tail of values on the right-hand
    side of the mean. Skewness can also be expressed with the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.10: Mathematical formula for skewness](img/C12628_03_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.10: Mathematical formula for skewness'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Here, ![](img/C12628_03_Formula_03.png) is the expected value or the mean of
    ![](img/C12628_03_Formula_04.png) , where ![](img/C12628_03_Formula_05.png) and
    ![](img/C12628_03_Formula_06.png) are the mean and standard deviation of the distribution
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kurtosis** is a measure of the fatness of tails of a distribution compared
    to the normal distribution. Kurtosis doesn''t introduce asymmetry in a distribution,
    unlike skewness. An illustration of this is provided here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.11: Kurtosis demonstration](img/C12628_03_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.11: Kurtosis demonstration'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Kurtosis can also be expressed with the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.12: Mathematical formula for Kurtosis](img/C12628_03_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.12: Mathematical formula for Kurtosis'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here, ![](img/C12628_03_Formula_07.png) is the expected or average value of
    ![](img/C12628_03_Formula_08.png), where ![](img/C12628_03_Formula_05.png) and
    ![](img/C12628_03_Formula_06.png) are the mean and standard deviation of the distribution
    respectively. A standard normal distribution has a skew of 0 and a kurtosis measure
    equal to 3\. Because normal distributions are very common, we sometimes just measure
    excess kurtosis, which is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: So, a normal distribution has excess kurtosis equal to 0.
  prefs: []
  type: TYPE_NORMAL
- en: Log-Normal Distributions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Log-normal distributions are distributions of values whose logarithm is distributed
    normally. If we show a log-normal distribution on a log scale, it is perfectly
    identical to a normal distribution, but if we show it on a standard distribution
    scale, it acquires very high positive skewness:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.13: Log-normal distribution](img/C12628_03_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.13: Log-normal distribution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To show that the log-normal distribution is a normal distribution on log scale,
    we're going to do an exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Log-normal distributions are used in the field of financial risk management
    to model stock prices. As the growth factor is assumed to be normally distributed,
    the prices of stock can be modeled log-normally. This distribution is also used
    in calculations related to option pricing, including value at risk (VaR).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 16: Generating a Log-Normal Distribution from a Normal Distribution'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will generate a log-normal distribution from a normal
    distribution. To do this, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a normal distribution and store the values in a variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot a histogram of the normal distribution with 100 different bins:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.14: Normal distribution with a mean of 5 and a standard deviation
    1](img/C12628_03_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.14: Normal distribution with a mean of 5 and a standard deviation
    of 1'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Create a vector that will store 1,000 values for a log-normal distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Enter exponential values into the `lnor` vector. The exponent function is the
    inverse function of the log function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot a histogram of `lnor`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.15: Log-normal distribution](img/C12628_03_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.15: Log-normal distribution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Notice how the preceding figure looks like a log-normal distribution plot and
    that this plot is generated from a normal distribution. If we plot a new graph
    after taking the log of values in the preceding graph, then it'll be a normal
    distribution again.
  prefs: []
  type: TYPE_NORMAL
- en: The Binomial Distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The binomial distribution is a discrete distribution, as opposed to normal or
    uniform distribution, which are continuous in nature. The binomial distribution
    is used to model the probability of multiple events occurring together where there
    are two possibilities for each event. One example where the binomial distribution
    can be applied is in finding out the probability of heads coming up for all three
    coins when we toss three coins together.
  prefs: []
  type: TYPE_NORMAL
- en: The mean and variance of a binomial distribution are n*p and n*p(1-p) respectively,
    where p is the probability of success and n is the number of trials. The binomial
    distribution is symmetric when p= 0.5\. When p is less than 0.5, it's skewed more
    toward the right, and is skewed more toward the left when p is greater than 0.5\.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula for the binomial distribution is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Here, n is the total number of trials, x is the focal number of trials, and
    p is the probability of success.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 17: Generating a Binomial Distribution'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will generate a binomial distribution to model the number
    of times that heads will come up when tossing a coin 50 times. To do this, perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To generate a binomial distribution, we''ll first need a sequence of 50 digits
    as an index, which will act as the number of successes we are interested in modeling.
    This would be x in the formula in the previous section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we will pass `s` as a parameter to the `dbinom()` function in R, which
    will calculate probabilities for every value in the `s` variable and store them
    in a new `probs` variable. Firstly, in the function, we enter the sequence that
    will encode the range of the number of successes. Then, we enter the length of
    the sequence, and then we enter the probability of success:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the final step, we plot `s` and `probs` together:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.16: Binomial distribution](img/C12628_03_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.16: Binomial distribution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Here, the x axis shows a number of heads we are interested in, and the y axis
    shows the probability of getting exactly that number of heads in 50 trials. When
    we toss a coin 50 times, the most probable outcome is that we will get 25 heads
    and 25 tails, but the probability of getting all 50 heads or tails is very low.
    This is explained very well by the preceding graph.
  prefs: []
  type: TYPE_NORMAL
- en: The Poisson Distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Poisson distribution is another type of discrete distribution that is used
    to model occurrences of an event in a given time period given the mean number
    of occurrences of that event in a particular time period.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s formulated by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.17: Formula for Poisson distribution](img/C12628_03_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.17: Formula for poisson distribution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Here, lambda is the mean number of occurrences in a given time period, **e**
    is Euler's constant, and **x** is the number of events for which you want to find
    the probability. Given the number of new people that have been observed coming
    to an event every minute so far, the, Poisson distribution can be used to calculate
    the probability of any number of people coming to that event in the next minute.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Poisson distribution plot looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.18: Plot for poisson distribution](img/C12628_03_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.18: Plot for poisson distribution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Here, we can see probabilities of the different values of **x** vary with respect
    to lambda.
  prefs: []
  type: TYPE_NORMAL
- en: The Pareto Distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The pareto distribution is an exponent-based probability distribution. This
    distribution was invented to model the 80:20 rule that is observed in many real-world
    situations. Some fascinating situations that follow the 80:20 rule are listed
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: Approximately 80% of the world's wealth is owned by 20% of people.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In business management, it was found that for most companies, 80% of their revenue
    was generated by 20% of their customers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is said that 20% of all drivers cause 80% of all accidents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are many other real-world observations that can be modeled by the Pareto
    distribution. The mathematical formula of the Pareto distribution is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.19: Mathematical formula of the Pareto distribution](img/C12628_03_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.19: Mathematical formula of the Pareto distribution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Introduction to Kernel Density Estimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we've studied parametric distributions in this chapter, but in real
    life, all distributions are either approximations of parametric distributions
    or don't resemble any parametric distributions at all. In such cases, we use a
    technique called **Kernel Density Estimation**, or **KDE**, to estimate their
    probability distributions.
  prefs: []
  type: TYPE_NORMAL
- en: KDE is used to estimate the probability density function of distributions or
    random variables with given finite points of that distribution using something
    called a kernel. This will be more clear to you after you continue further in
    the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: KDE Algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Contrary to what it might seem like given the heavy name, KDE is a very simple
    two-step process:'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a kernel
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Placing the kernel on data points and taking the sum of kernels
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A kernel is a non-negative symmetric function that is used to model distributions.
    For example, in KDE, a normal distribution function is the most commonly used
    kernel function. Kernel functions can be of different types. They are very much
    related to the distributions we studied earlier in the chapter. Some of the types
    are summarized here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a uniform kernel, all values in a range are given equal weightage. This
    is represented as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 3.20: Representation of uniform kernel function](img/C12628_03_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.20: Representation of a uniform kernel function'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In a triangular kernel, weightage increases linearly as values move toward
    the middle of the range. This is represented as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 3.21: Representation of triangular kernel function](img/C12628_03_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.21: Representation of a triangular kernel function'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In a Gaussian kernel, weightage is distributed normally. This is represented
    as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 3.22: Representation of a Gaussian kernel function](img/C12628_03_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.22: Representation of a Gaussian kernel function'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Along with the kernel, in the first step, we have to choose another parameter
    called the bandwidth of the kernel. Bandwidth is the parameter that affects the
    smoothness of the kernel. Choosing the right bandwidth is very important, even
    more important than choosing the right kernel. We'll look at an example here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 18: Visualizing and Understanding KDE'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s suppose we have a distribution of five different points (1, 2, 3, 4,
    and 5). Let''s visualize and understand KDE using this example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Store the vector of the five points in a variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the points:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.23: Plot of the five points](img/C12628_03_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.23: Plot of the five points'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Install the `kdensity` package, if you don''t have it already, and import it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compute the kernel density with the `kdensity()` function. Enter the distribution,
    `x`, and the bandwidth parameter as `.35`. The kernel is `gaussian` by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the KDE as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure3.24: Plot of the Gaussian kernel](img/C12628_03_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.24: Plot of the Gaussian kernel'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This is the final output of KDE. In this next step, it assumed that there was
    a Gaussian kernel centered on every point (1, 2, 3, 4, and 5) and summed them
    together to get this plot. The following figure will make it clearer:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: This graph is for illustration purposes rather than for generation in R.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.25: Gaussian kernel plotted on each point](img/C12628_03_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.25: Gaussian kernel plotted on each point'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see in the preceding figure, a Gaussian kernel was plotted on each
    one of the points and then all the kernels were summed to get the final curve.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, what if we were to change the bandwidth to 0.5 instead of 0.35?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Change the bandwidth to 0.5 in the `kdensity()` function and plot the `kdensity`
    plot again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.26: Plot of the Gaussian kernel with a bandwidth of .5](img/C12628_03_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.26: Plot of the Gaussian kernel with a bandwidth of .5'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You can see that the kernel is much smoother now. The following kernels were
    used:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.27: Gaussian kernel plotted on each point](img/C12628_03_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.27: Gaussian kernel plotted on each point'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The graph is for illustration purposes rather than for generation in R.
  prefs: []
  type: TYPE_NORMAL
- en: This time, the kernels are much wider.
  prefs: []
  type: TYPE_NORMAL
- en: If we were given a sufficient amount of points for estimation, the choice of
    kernel wouldn't change the shape of the final KDE as much as the choice of bandwidth
    parameter. So, choosing the ideal bandwidth parameter is an important step. There
    are many techniques that are used to select the ideal bandwidth parameter. Studying
    them is beyond the scope of this book, but the R libraries can take care of selecting
    the ideal parameter on their own. We'll study this in the next exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 19: Studying the Effect of Changing Kernels on a Distribution'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we''ll generate two normal distributions with different standard
    deviations and means, and combine them both to generate their combined KDE:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate two different normal distributions and store them in two variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Combine the generated distributions and plot them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.28: Plot of combined distributions](img/C12628_03_28.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.28: Plot of combined distributions'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: You can see there are two different distributions with different means and spreads
    (standard deviations).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot a histogram of `y3` for reference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.29: Histogram of the resultant distribution](img/C12628_03_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.29: Histogram of the resultant distribution'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Generate and plot the KDE of `y3` with a `gaussian` kernel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.30: Plot of Gaussian kernel density](img/C12628_03_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.30: Plot of Gaussian kernel density'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: In the preceding plot, we used a Gaussian kernel and the bandwidth was selected
    by the function automatically. In this distribution, we have 200 points, which
    should be enough for generating a robust KDE plot such that changing the kernel
    type won't produce a significant difference in the final KDE plot. In the next
    step, let's try and change the kernel and look at the final plot.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Generate and plot the KDE with the `triangular` kernel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.31: KDE with triangular kernel](img/C12628_03_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.31: KDE with triangular kernel'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Both plots with different kernels look almost identical. So, the choice of bandwidth
    is much more important than the choice of kernel. In this exercise, the bandwidth
    was chosen automatically by the `kdensity` library of R.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 8: Finding the Standard Distribution Closest to the Distribution of
    Variables of the Iris Dataset'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this activity, we will find the standard distribution closest to the distribution
    of variables of the Iris dataset for the setosa species. These steps will help
    you complete the activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the Iris dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select rows corresponding to the setosa species only.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the distribution generated by the `kdensity` function for sepal length
    and sepal width.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 218.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The final outcome of this activity will be a plot of KDE for sepal width, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.32: Expected plot of the KDE for sepal width ](img/C12628_03_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.32: Expected plot of the KDE for sepal width'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Introduction to the Kolmogorov-Smirnov Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we’ve learned how to generate the probability density functions of
    datasets that don't closely resemble standard distributions, we’ll learn how to
    perform some tests to distinguish these nonstandard distributions from each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, we''re given multiple observed samples of data and we want to find
    out whether those samples belong to the same distribution or not. In the case
    of standard distributions, we have multiple tests, such as Student''s t-test and
    z-test, to determine this. For non-standard distributions, or where we don''t
    know the type of distribution, we use the Kolmogorov-Smirnov test. To understand
    the Kolmogorov-Smirnov test, you first need to understand a few terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cumulative Distribution Function (CDF)**: This is a function whose value
    gives the probability of a random variable being less than or equal to the argument
    of the function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Null Hypothesis**: In hypothesis testing, a null hypothesis means there is
    no significant difference between the observed samples. In hypothesis testing,
    our aim is to falsify the null hypothesis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kolmogorov-Smirnov Test Algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In a Kolmogorov-Smirnov test, we perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a CDF for both functions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specify one of the distributions as the parent distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the CDF of the two functions together in the same plot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the greatest vertical difference between the points in both CDFs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the test statistic from the distance measured in the previous step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the critical values in the Kolmogorov-Smirnov table.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In R, these steps are automated, so we don't have to do each one of them individually.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 20: Performing the Kolmogorov-Smirnov Test on Two Samples'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To perform the Kolmogorov-Smirnov test on two samples, execute the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate two independent distributions for comparison:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the `CDF` of `x_norm` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.33: Plot of ecdf(x_norm)](img/C12628_03_33.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.33: Plot of ecdf(x_norm)'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To plot `ecdf(y_unif)`, execute the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/C12628_03_34.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.34: Plot of ecdf(y_unif)'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, the CDF of the functions look completely different, so the Kolmogorov-Smirnov
    test will return p values that are very small.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the Kolmogorov-Smirnov test with the `ks.test()` function in R:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This exercise depends on randomly generated data. So, when you run this code,
    some of the numbers might be different. In hypothesis testing, there are two hypotheses:
    the null hypothesis, and the test hypothesis. The goal of hypothesis testing is
    to determine whether we have strong enough evidence to reject the null hypothesis.
    In this case, the null hypothesis is that the two samples were generated by the
    same distribution, and the test hypothesis is that the two samples were not generated
    by the same distribution. The p-value represents the probability, assuming the
    null hypothesis is true, of observing differences as extreme or more extreme than
    what is observed. When the p-value is very close to zero, we take that as evidence
    that the null hypothesis is false and vice versa.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As you can see, `ks.test()` returns two values, `D` and p-value. The `D` value
    is the absolute maximum distance between two points in the CDF of both distributions.
    The closer it is to zero, the greater the chance that both samples belong to the
    same distribution. The p-value has the same interpretation as in any other case.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In our case, `D` is `0.29` and the p-value is very low, near zero. So, we reject
    the null hypothesis that both samples belong to the same distribution. Now, in
    the next step, let's generate a new normal distribution and see its effect on
    the p-value and `D`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Generate a new normal distribution with the same `mean` and `sd` as `xnorm`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the combined CDF of `x_norm` and `x_norm2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.35 Plot of combined cdf](img/C12628_03_35.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 3.35 Plot of combined cdf
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Run `ks.test()` on `x_norm` and `x_norm2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, the p-value is much higher this time and `D` is much lower.
    So, according to the p-value, we are less justified in rejecting the null hypothesis
    that both samples belong to the same distribution.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Activity 9: Calculating the CDF and Performing the Kolmogorov-Smirnov Test
    with the Normal Distribution'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With the help of randomly generated distributions, calculate what standard
    distribution the sample of sepal length and width is closest to:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the Iris dataset into a variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keep rows with the setosa species only.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the mean and standard deviation of sepal length.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a new normal distribution with the mean and standard deviation of the
    sepal length column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the CDF of both functions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate the results of the Kolmogorov-Smirnov test and check whether the distribution
    is a normal distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat steps 3, 4, 5, and 6 for the sepal width column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 219.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The final outcome of this activity will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Congratulations on completing the third chapter of the book! In this chapter,
    we learned the types of standard probability distribution, as well as when and
    how to generate them in R. We also learned how to find PDFs and CDFs of unknown
    distributions with KDE. In the final section, we learned how to compare two samples
    and determine whether they belong to the same distribution in R. In further chapters,
    we will learn about other types of unsupervised learning techniques that will
    help not only in exploratory data analysis but also give us other useful insights
    into data as well.
  prefs: []
  type: TYPE_NORMAL
