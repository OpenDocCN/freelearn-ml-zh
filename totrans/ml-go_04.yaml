- en: Regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归
- en: The first group of machine learning techniques that we will explore is generally
    referred to as **regression**. Regression is a process through which we can understand
    how one variable (for example, sales) changes with respect to another variable
    (for example, number of users). These techniques are useful on their own. However,
    they are also a good starting point to discuss machine learning techniques because
    they form the basis of other, more complicated, techniques that we will discuss
    later in the book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要探索的第一组机器学习技术通常被称为**回归**。回归是一个过程，通过它可以理解一个变量（例如，销售额）相对于另一个变量（例如，用户数量）是如何变化的。这些技术本身很有用。然而，它们也是讨论机器学习技术的良好起点，因为它们构成了我们将在本书后面讨论的更复杂技术的基础。
- en: Generally, regression techniques in machine learning are concerned with predicting
    continuous values (for example, stock price, temperature, or disease progression).
    **Classification**, which we will cover in the next chapter, is concerned with
    predicting discrete variables, or one of a discrete set of categories (for example,
    fraud/not fraud, sitting/standing/running, or hot dog/not hot dog). As mentioned,
    regression techniques are used throughout machine learning as part of classification
    algorithms, but in this chapter we will focus on their basic application to predict
    continuous values.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，机器学习中的回归技术关注预测连续值（例如，股价、温度或疾病进展）。下一章我们将讨论的**分类**关注预测离散变量，或一组离散类别中的一个（例如，欺诈/非欺诈，坐着/站着/跑步，或热狗/非热狗）。如前所述，回归技术作为分类算法的一部分在机器学习中使用，但本章我们将专注于它们的基本应用，以预测连续值。
- en: Understanding regression model jargon
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解回归模型术语
- en: 'As already mentioned, regression itself is a process to analyze a relationship
    between one variable and another variable, but there are some terms used in machine
    learning to describe these variables along with various types of regression and
    processes associated with regression:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，回归本身是一个分析一个变量与另一个变量之间关系的过程，但在机器学习中，有一些术语用来描述这些变量，以及与回归相关的各种类型和过程：
- en: '**Response** or **dependent variable**: These terms will be used interchangeably
    for the variable that we are trying to predict based on one or more other variables.
    This variable is often labeled *y*.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应变量**或**因变量**：这些术语将交替使用，指基于一个或多个其他变量试图预测的变量。这个变量通常被标记为 *y*。'
- en: '**Explanatory variables**, **independent variables**, **features**, **attributes**,
    or **regressors**: These terms will be used interchangeably for the variables
    that we are using to predict the response. These variables are often labeled *x*
    or *x[1], x[2],* and so on.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解释变量**、**自变量**、**特征**、**属性**或**回归变量**：这些术语将交替使用，指我们用来预测响应的变量。这些变量通常被标记为 *x*
    或 *x[1], x[2],* 等等。'
- en: '**Linear regression**: This type of regression assumes that the dependent variable
    depends on the independent variable linearly (that is, following the equation
    for a line).'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性回归**：这种回归假设因变量线性地依赖于自变量（即，遵循直线的方程）。'
- en: '**Nonlinear regression**: This type of regression assumes that the dependent
    variable depends on the independent variable in a relationship that is not linear
    (for example, polynomial or exponential).'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非线性回归**：这种回归假设因变量依赖于自变量的关系不是线性的（例如，多项式或指数）。'
- en: '**Multiple regression**: A regression with more than one independent variable.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多元回归**：包含多个自变量的回归。'
- en: '**Fitting** or **training**: The process of parameterizing a model, such as
    a regression model, so that it can predict a certain dependent variable.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拟合**或**训练**：参数化模型（如回归模型）的过程，以便它可以预测某个因变量。'
- en: '**Prediction**: The process of using a parameterized model, such as a regression
    model, to predict a certain dependent variable.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测**：使用参数化模型（如回归模型）来预测某个因变量的过程。'
- en: Some of these terms will be used both in the context of regression and in other
    contexts throughout the rest of the book.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一些这些术语将在回归的上下文中使用，并在本书其余部分的其他上下文中使用。
- en: Linear regression
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归
- en: Linear regression is one of the most simple machine learning models. However,
    you should not dismiss this model by any means. As mentioned previously, it is
    an essential building block that is utilized in other models, and it has some
    very important advantages.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是最简单的机器学习模型之一。然而，你绝对不应该忽视这个模型。如前所述，它是其他模型中使用的必要构建块，并且它有一些非常重要的优点。
- en: 'As discussed throughout this book, integrity in machine learning applications
    is crucial, and the simpler and more interpretable a model is, the easier it is
    to maintain integrity. In addition, because the model is simple and interpretable,
    it allows you to understand inferred relationships between variables and check
    your work mentally as you develop. In the words of Mike Lee Williams from Fast
    Forward Labs (in [http://blog.fastforwardlabs.com/2017/08/02/interpretability.html](http://blog.fastforwardlabs.com/2017/08/02/interpretability.html)):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本书中讨论的那样，在机器学习应用中的完整性至关重要，模型越简单、可解释性越强，就越容易保持完整性。此外，由于模型简单且可解释，它允许你理解变量之间的推断关系，并在开发过程中通过心理检查你的工作。用
    Fast Forward Labs 的 Mike Lee Williams 的话说（参见 [http://blog.fastforwardlabs.com/2017/08/02/interpretability.html](http://blog.fastforwardlabs.com/2017/08/02/interpretability.html)）：
- en: The future is algorithmic. Interpretable models offer a safer, more productive,
    and ultimately more collaborative relationship between humans and intelligent
    machines.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 未来是算法化的。可解释的模型为人类和智能机器之间提供了更安全、更富有成效、最终更协作的关系。
- en: Linear regression models are interpretable, and thus, they can provide a safe
    and productive option for data scientists. When you are searching for a model
    to predict a continuous variable, you should consider and try linear regression
    (or even multiple linear regression) if your data and problem allows you to use
    it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型是可解释的，因此，它们可以为数据科学家提供一个安全且富有成效的选项。当你正在寻找一个模型来预测一个连续变量时，你应该考虑并尝试线性回归（甚至多重线性回归），如果你的数据和问题允许你使用它。
- en: Overview of linear regression
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归概述
- en: 'In linear regression, we attempt to model our dependent variable, *y*, by an
    independent variable, *x*, using the equation for a line:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归中，我们试图通过一个独立变量 *x* 来建模我们的因变量 *y*，使用线的方程：
- en: '![](img/f3e2dab9-8cd9-4682-add5-28573549128b.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3e2dab9-8cd9-4682-add5-28573549128b.png)'
- en: 'Here, *m* is the slope of the line and *b* is the intercept. For example, let''s
    say that we want to model daily *sales* by the *number of users* on our website
    each day. To do this with linear regression, we would want to determine an *m*
    and *b* that would allow us to predict sales via the following formula:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*m* 是直线的斜率，*b* 是截距。例如，假设我们想要通过我们网站上每天的用户数量来模拟每天的 *销售*。为了使用线性回归来完成这项工作，我们需要确定一个
    *m* 和 *b*，这样我们就可以通过以下公式预测销售：
- en: '![](img/6852719e-3947-4a09-80c9-48471fd9739c.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6852719e-3947-4a09-80c9-48471fd9739c.png)'
- en: 'Thus, our trained model is really just this parameterized function. We put
    in a **Number of Users** and we get the predicted **Sales**, as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的训练模型实际上就是这个参数化函数。我们输入一个 **用户数量**，然后得到预测的 **销售**，如下所示：
- en: '![](img/f368c62d-8816-4c7e-ae7a-4b3045c1bb70.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f368c62d-8816-4c7e-ae7a-4b3045c1bb70.png)'
- en: The training or fitting of a linear regression model involves determining the
    values of *m* and *b,* such that the resulting formula has predictive power for
    our response. There are a variety of methods to determine *m* and *b*, but the
    most common and simple method is called **ordinary least squares** (**OLS**).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型的训练或拟合涉及确定 *m* 和 *b* 的值，使得得到的公式对我们的响应具有预测能力。有各种方法可以确定 *m* 和 *b*，但最常见和简单的方法被称为
    **普通最小二乘法**（**OLS**）。
- en: 'To find *m* and *b* with OLS, we first pick a value for *m* and *b* to create
    a first example line. We then measure the vertical distance between each of our
    known points (for example, from our training set) and the example line. These
    distances are called **errors** or **residuals**, similar to the errors that we
    discussed in [Chapter 3](64db3465-cd9a-42ca-b0fb-d54c59b87037.xhtml), *Evaluation
    and Validation,* and are illustrated in the following figure:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 OLS 找到 *m* 和 *b*，我们首先为 *m* 和 *b* 选择一个值来创建第一条示例线。然后，我们测量每个已知点（例如，来自我们的训练集）与示例线之间的垂直距离。这些距离被称为
    **误差** 或 **残差**，类似于我们在第 3 章 *评估和验证* 中讨论的误差，并在以下图中展示：
- en: '![](img/1828093f-2bf5-4848-a6c0-056b7bb2de0b.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1828093f-2bf5-4848-a6c0-056b7bb2de0b.png)'
- en: 'Next, we add up the sum of the squares of these errors:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们计算这些误差的平方和：
- en: '![](img/f616d895-8121-488b-baef-ca27d1da6751.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f616d895-8121-488b-baef-ca27d1da6751.png)'
- en: We adjust *m* and *b* until we minimize this sum of the squares of the errors.
    In other words, our trained linear regression line is the line that minimizes
    this sum of the squares.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调整*m*和*b*，直到我们最小化这个误差平方和。换句话说，我们的训练线性回归线是使这个误差平方和最小的线。
- en: There are a variety of methods to find the line that minimizes the sum of the
    squared errors and, for OLS, the line can be found analytically. However, a very
    popular and general optimization technique that is used to minimize the sum of
    the squared error is called **gradient descent**. This method can be more efficient
    in terms of implementation, advantageous computationally (in terms of memory,
    for example), and more flexible than analytic solutions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以找到最小化平方误差和的线，对于OLS来说，线可以通过解析方法找到。然而，一个非常流行且通用的优化技术，用于最小化平方误差和，被称为**梯度下降**。这种方法在实现方面可能更高效，在计算上（例如，在内存方面）具有优势，并且比解析解更灵活。
- en: Gradient descent is discussed in more detail in the [Appendix](718ca26d-465a-47c9-91b9-14e749be0c30.xhtml),
    *Algorithms/Techniques Related to Machine Learning*, so we will avoid a lengthy
    discussion here. Suffice it to say that many implementations of linear and other
    regressions utilize gradient descent for the fitting or training of the linear
    regression line. In fact, gradient descent is ubiquitous in machine learning and
    also powers much more complicated modeling techniques such as deep learning.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降在[附录](718ca26d-465a-47c9-91b9-14e749be0c30.xhtml)“与机器学习相关的算法/技术”中有更详细的讨论，因此我们在这里将避免进行冗长的讨论。简单来说，许多线性回归和其他回归的实现都利用梯度下降来进行线性回归线的拟合或训练。实际上，梯度下降在机器学习中无处不在，并且也推动了更复杂的建模技术，如深度学习。
- en: Linear regression assumptions and pitfalls
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归的假设和陷阱
- en: 'Like all machine learning models, linear regression does not work in all situations
    and it does make certain assumptions about your data and the relationships in
    your data. The assumptions of linear regression are as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 就像所有机器学习模型一样，线性回归并不适用于所有情况，并且它确实对你的数据和数据中的关系做出了一些假设。线性回归的假设如下：
- en: '**Linear relationship**: This might seem obvious, but linear regression assumes
    that your dependent variable depends on your independent variable linearly (by
    means of the equation for a line). If this relationship is not linear, linear
    regression will likely perform poorly.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性关系**：这看起来可能很明显，但线性回归假设你的因变量线性地依赖于你的自变量（通过线的方程）。如果这种关系不是线性的，线性回归可能表现不佳。'
- en: '**Normality**: This assumption means that your variables should be distributed
    according to a normal distribution (which looks like a bell shape). We will come
    back to this property later in the chapter and discuss some trade-offs and options
    when encountering non-normally distributed variables.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正态性**：这个假设意味着你的变量应该按照正态分布（看起来像钟形）分布。我们将在本章后面回到这个属性，并讨论在遇到非正态分布变量时的权衡和选项。'
- en: '**No multicollinearity**: Multicollinearity is a fancy term that means that
    independent variables are not really independent. They depend on each other in
    some fashion.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无多重共线性**：多重共线性是一个术语，意味着自变量实际上并不是独立的。它们以某种方式相互依赖。'
- en: '**No auto-correlation**: Auto-correlation is another fancy term that means
    that a variable depends on itself or some shifted version of itself (like in some
    predictable time series).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无自相关性**：自相关性是另一个术语，意味着一个变量依赖于它自己或其某种位移版本（如在某些可预测的时间序列中）。'
- en: '**Homoscedasticity**: This may be the fanciest word of this bunch of terms,
    but it means something relatively simple and is not really something you have
    to worry about very often. Linear regression assumes that the variance of your
    data is about the same around the regression line for all values of your independent
    variable.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**同方差性**：这可能是这一系列术语中最复杂的，但它意味着相对简单的事情，并且实际上你并不需要经常担心。线性回归假设你的数据在独立变量的所有值周围围绕回归线具有大致相同的方差。'
- en: Technically, all of these assumptions need to be fulfilled for us to use linear
    regression. It's very important that we know how our data is distributed and how
    it behaves. We will look into these assumptions when we profile data in an example
    use of linear regression.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 技术上，为了使用线性回归，所有这些假设都需要得到满足。了解我们的数据是如何分布的以及它的行为方式非常重要。当我们在一个线性回归的示例中分析数据时，我们将探讨这些假设。
- en: 'As a data scientist or analyst, you want to keep the following pitfalls in
    mind as you apply linear regression:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家或分析师，在应用线性回归时，以下陷阱您需要牢记在心：
- en: You are training your linear regression model for a certain range of your independent
    variable. You should be careful making predictions for values outside of this
    range because your regression line might not be applicable (for example, your
    dependent variable may start behaving non-linearly at extreme values).
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您正在为独立变量的某个范围训练线性回归模型。对于这个范围之外的数据值进行预测时，您应该小心，因为您的回归线可能不适用（例如，您的因变量可能在极端值处开始表现出非线性行为）。
- en: You can misspecify a linear regression model by finding some spurious relationship
    between two variables that really have nothing to do with one another. You should
    check to make sure that there is some logical reason why variables might be functionally
    related.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可能会通过发现两个实际上毫无关联的变量之间的虚假关系来错误地指定线性回归模型。您应该检查以确保变量之间可能存在某种逻辑上的功能关系。
- en: Outliers or extreme values in your data may throw off a regression line for
    certain types of fitting, such as OLS. There are ways to fit a regression line
    that is more immune to outliers, or behaves differently with respect to outliers,
    such as orthogonal least squares or ridge regression.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您数据中的异常值或极端值可能会影响某些类型的拟合的回归线，例如最小二乘法。有一些方法可以拟合对异常值更免疫的回归线，或者对异常值有不同的行为，例如正交最小二乘法或岭回归。
- en: Linear regression example
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归示例
- en: 'To illustrate linear regression, let''s take an example problem and create
    our first machine learning model! The example data that we are going to use is
    example advertising data. It is in the `.csv` format and looks as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明线性回归，让我们举一个例子问题并创建我们的第一个机器学习模型！我们将使用的是示例广告数据。它以`.csv`格式存储，如下所示：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The dataset includes a set of attributes representing spend on advertising outlets
    (`TV`, `Radio`, and `Newspaper`) along with corresponding sales (`Sales`). Our
    goal in this example will be to model the sales (our dependent variable) by one
    of the attributes of advertising spend (our independent variable).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包括一组代表广告渠道支出（`电视`、`广播`和`报纸`）的属性，以及相应的销售额（`销售额`）。在这个例子中，我们的目标将是通过广告支出的一个属性（我们的独立变量）来建模销售额（我们的因变量）。
- en: Profiling the data
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据概览
- en: To make sure that we create a model, or at least process, that we understand,
    and to make sure that we can mentally check our results, we need to start every
    machine learning model building process with data profiling. We need to gain an
    understanding of how each of our variables are distributed and their range and
    variability.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们创建的模型或至少是处理过程是我们所理解的，并且为了确保我们可以心理上检查我们的结果，我们需要从数据概览开始每一个机器学习模型构建过程。我们需要了解每个变量是如何分布的，以及它们的范围和变异性。
- en: 'To do this, we will calculate the summary statistics that we discussed earlier
    in [Chapter 2](5e7af3cb-ce60-4699-b2d3-7eeff8978a9e.xhtml), *Matrices, Probability,
    and Statistics*. Here, we will utilize a method built into the `github.com/kniren/gota/dataframe`
    package to calculate our summary statistics for all of the columns of our dataset
    in one operation:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们将计算我们在[第2章](5e7af3cb-ce60-4699-b2d3-7eeff8978a9e.xhtml)，“矩阵、概率和统计学”中讨论过的汇总统计信息。在这里，我们将利用`github.com/kniren/gota/dataframe`包内置的方法，一次性计算我们数据集所有列的汇总统计信息：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Compiling and running this gives the following result:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 编译并运行此代码将得到以下结果：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As you can see, this prints out all of our summary statistics in a nice tabular
    form and includes mean, standard deviation, minimum value, maximum value, *25%/75%*
    percentiles, and median (or 50% percentile).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，这以漂亮的表格形式打印出我们所有的汇总统计信息，包括平均值、标准差、最小值、最大值、*25%/75%* 分位数和中间值（或50% 分位数）。
- en: 'These values give us a good numerical reference for the numbers that we will
    be seeing as we train our linear regression model. However, this does not give
    us a very good visual understanding of our data. For this, we will create a histogram
    for the values in each of the columns:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值为我们提供了在训练线性回归模型时将看到的数字的良好数值参考。然而，这并没有给我们一个很好的数据视觉理解。为此，我们将为每个列中的值创建直方图：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This program will create a `.png` image for each histogram:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此程序将为每个直方图创建一个`.png`图像：
- en: '![](img/8f0052c8-b6ad-4933-8f2a-1959a33c2a0d.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f0052c8-b6ad-4933-8f2a-1959a33c2a0d.png)'
- en: Now, looking at these histograms and the summary statistics that we calculated,
    we need to consider if we are working within the assumptions of linear regression.
    In particular, we can see that not all of our variables are normally distributed
    (that is, they are in a bell shape). The sales might be somewhat bell-shaped,
    but the others do not look to be normal.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，查看这些直方图和我们计算出的汇总统计量，我们需要考虑我们是否在符合线性回归的假设下工作。特别是，我们可以看到，并不是我们所有的变量都是正态分布的（也就是说，它们呈钟形）。销售额可能有些钟形，但其他变量看起来并不正常。
- en: We could use a statistical tool, such as a **quantile-quantile** (**q-q**) plot,
    to determine how close the distributions are to normal distributions, and we could
    even perform a statistical test to determine the probability of the variables
    following a normal distribution. However, most of the time, we can get a general
    idea from the histograms.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用统计工具，如**分位数-分位数**（**q-q**）图，来确定分布与正态分布的接近程度，我们甚至可以进行统计测试，以确定变量遵循正态分布的概率。然而，大多数时候，我们可以从直方图中得到一个大致的概念。
- en: 'Now we have to make a decision. At least some of our data does not technically
    fit within the assumptions of our linear regression model. We could now do one
    of the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须做出决定。至少我们的一些数据在技术上并不符合我们的线性回归模型的假设。我们现在可以采取以下行动之一：
- en: Try to transform our variables (with, for example, a power transformation) that
    follow a normal distribution, and then use these transformed variables in our
    linear regression model. The advantage of this option is that we would be operating
    within the assumptions of the model. The disadvantage is that we would be making
    our model harder to understand, and less interpretable.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试转换我们的变量（例如，使用幂转换），使其遵循正态分布，然后使用这些转换后的变量在我们的线性回归模型中。这种选项的优势是我们将在模型的假设下操作。缺点是这将使我们的模型更难以理解，并且可解释性更差。
- en: Get different data to solve our problem.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取不同的数据来解决我们的问题。
- en: Ignore our issue with the linear regression assumptions and try to create the
    model.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 忽略我们与线性回归假设的问题，并尝试创建模型。
- en: There may be other views on this, but my recommendation is that you try the
    third option first. There is not much harm in this option because you can train
    the linear regression model quickly. If you end up with a model that performs
    nicely, you have avoided further complications and have a nice simple model. If
    you end up with a model that performs poorly, you might need to resort to one
    of the other options.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 可能还有其他的观点，但我的建议是首先尝试第三个选项。这个选项没有太大的坏处，因为你可以快速训练线性回归模型。如果你最终得到一个表现良好的模型，你就避免了进一步的复杂化，并且得到了一个简单明了的模型。如果你最终得到一个表现不佳的模型，你可能需要求助于其他选项之一。
- en: Choosing our independent variable
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择我们的独立变量
- en: So, now we have some intuition about our data and have come to terms with how
    our data fits within the assumptions of the linear regression model. Now, how
    do we choose which variable to use as our independent variable in trying to predict
    our dependent variable, and average points per game?
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在我们对我们的数据有一些直观的认识，并且已经接受了我们的数据如何符合线性回归模型的假设。现在，我们如何在尝试预测我们的因变量，即每场比赛的平均得分时，选择哪个变量作为我们的独立变量呢？
- en: 'The easiest way to make this decision is by visually exploring the correlation
    between the dependent variable and all of the choices that you have for independent
    variables. In particular, you can make scatter plots (using `gonum.org/v1/plot`)
    of your dependent variable versus each of the other variables:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 做出这个决定的最简单方法是通过直观地探索因变量与所有独立变量选择之间的相关性。特别是，你可以绘制出因变量与每个其他变量的散点图（使用`gonum.org/v1/plot`）：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will create the following scatter plots:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建以下散点图：
- en: '![](img/926090dd-21c3-40a7-a44b-404163072193.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/926090dd-21c3-40a7-a44b-404163072193.png)'
- en: As we look at these scatter plots, we want to deduce which of the attributes
    (**TV**, **Radio**, and/or **Newspaper**) have a linear relationship with our
    dependent variable, **Sales**. That is, could we draw a line on any of these scatter
    plots that would fit the trend of **Sales** versus the respective attribute? This
    is not always possible, and it likely will not be possible for all of the attributes
    that you have to work with for a given problem.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看这些散点图时，我们想要推断出哪些属性（**电视**、**广播**和/或**报纸**）与我们的因变量**销售额**之间存在线性关系。也就是说，我们能否在这些散点图中的任何一个上画一条线，这条线能符合**销售额**与相应属性的趋势？这并不总是可能的，而且对于给定问题中你必须处理的某些属性来说，可能根本不可能。
- en: 'In this case, both **Radio** and **TV** appear to be somewhat linearly correlated
    with **Sales**. **Newspaper** may be slightly correlated with **Sales**, but the
    correlation is far from obvious. The linear relationship with **TV** seems most
    obvious, so let''s start out with **TV** as our independent variable in our linear
    regression model. This would make our linear regression formula as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，**Radio** 和 **TV** 似乎与 **Sales** 有一定的线性相关性。**Newspaper** 可能与 **Sales**
    有轻微的相关性，但相关性并不明显。与 **TV** 的线性关系似乎最为明显，所以让我们以 **TV** 作为线性回归模型中的自变量开始。这将使我们的线性回归公式如下：
- en: '![](img/aed083c3-8921-4c5b-9dbb-77ff4a4af8cf.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aed083c3-8921-4c5b-9dbb-77ff4a4af8cf.png)'
- en: One other thing to note here is that the variable **TV** might not be strictly
    homoscedastic, which was discussed earlier as an assumption of linear regression.
    This is worth noting (and likely worth documenting in the project), but we will
    continue on to see if we can create the linear regression model with some predictive
    power. We can always revisit this assumption if our model is behaving poorly,
    as a possible explanation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一个需要注意的事项，即变量 **TV** 可能并不严格同方差，这之前作为线性回归的假设被讨论过。这一点值得注意（并且可能值得在项目中记录下来），但我们将继续看看我们是否可以创建具有一些预测能力的线性回归模型。如果我们的模型表现不佳，我们可以随时回顾这个假设，作为可能的解释。
- en: Creating our training and test sets
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建我们的训练集和测试集
- en: To avoid overfitting and make sure that our model can generalize, we are going
    to split our dataset into a training set and a test set, as was discussed in [Chapter
    3](64db3465-cd9a-42ca-b0fb-d54c59b87037.xhtml), *Evaluation and Validation*. We
    will not bother with a holdout set here, because we are only going to make one
    pass through our model training without an iterative back and forth between training
    and testing. However, if you are experimenting with various dependent variables
    and/or iteratively adjusting any parameters of your model, you would want to create
    a holdout set that you save until the end of your model development process for
    validation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免过拟合并确保我们的模型可以泛化，我们将按照第 3 章[评估和验证](64db3465-cd9a-42ca-b0fb-d54c59b87037.xhtml)中讨论的方法，将数据集分成训练集和测试集。在这里，我们不会使用保留集，因为我们只将进行一次模型训练，而不在训练和测试之间进行迭代往返。然而，如果你正在尝试不同的因变量，或者迭代调整模型参数，你将想要创建一个保留集，直到模型开发过程的最后阶段用于验证。
- en: We will use `github.com/kniren/gota/dataframe` to create our training and test
    datasets and then save them to respective `.csv` files. In this case, we
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `github.com/kniren/gota/dataframe` 来创建我们的训练集和测试集，并将它们保存到相应的 `.csv` 文件中。在这种情况下，我们
- en: 'will use an 80/20 split for our training and test data:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 将使用 80/20 的比例来分割我们的训练集和测试集：
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This code will output the following training and test sets that we will use:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将输出以下我们将使用的训练集和测试集：
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The data that we were using here was not sorted or ordered by data in any fashion.
    However, if you are dealing with data that is sorted by response, by date, or
    in any other way, it is important that you randomly split your data into training
    and test sets. If you do not do this, your training and test sets may include
    only certain ranges of the response, may be influenced artificially by time/date,
    and so on.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的数据并没有按照任何方式排序或排序。然而，如果你正在处理按响应、日期或其他方式排序的数据，那么将你的数据随机分成训练集和测试集是很重要的。如果你不这样做，你的训练集和测试集可能只包括响应的某些范围，可能受到时间/日期的人工影响，等等。
- en: Training our model
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练我们的模型
- en: 'Next, we are going to actually train, or fit, our linear regression model.
    If you remember, this just means that we are finding the slope (*m*) and intercept
    (*b*) for the line that minimizes the sum of the squared errors. To perform this
    training, we will use a really great package from Sajari: `github.com/sajari/regression`.
    Sajari is a web search company that relies heavily on Go and machine learning,
    and they use [github.com/sajari/regression](http://github.com/sajari/regression)
    in production.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将实际训练或拟合我们的线性回归模型。如果你还记得，这意味着我们正在寻找最小化平方误差和的线的斜率（*m*）和截距（*b*）。为了进行这项训练，我们将使用来自
    Sajari 的一个非常好的包：`github.com/sajari/regression`。Sajari 是一家依赖 Go 语言和机器学习的搜索引擎公司，他们在生产中使用
    [github.com/sajari/regression](http://github.com/sajari/regression)。
- en: 'To train a regression model using [github.com/sajari/regression](http://github.com/sajari/regression),
    we need to initialize a `regression.Regression` value, set a couple of labels,
    and fill the `regression.Regression` value with labeled training data points.
    After this, training our linear regression model is as easy as calling the `Run()`
    method on the `regression.Regression` value:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用[github.com/sajari/regression](http://github.com/sajari/regression)训练回归模型，我们需要初始化一个`regression.Regression`值，设置几个标签，并将`regression.Regression`值填充有标签的训练数据点。之后，训练我们的线性回归模型就像在`regression.Regression`值上调用`Run()`方法一样简单：
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Compiling and running this will result in the trained linear regression formula
    being printed to `stdout`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 编译并运行这将导致训练好的线性回归公式被打印到`stdout`：
- en: '[PRE8]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, we can see that the package determined our linear regression line with
    an intercept of `7.07` and a slope of `0.5`. We can perform a little mental check
    here, because we saw in the scatter plots how the correlation between **TV** and
    **Sales** was up and to the right (that is, a positive correlation). This means
    that the slope should be positive in the formula, which it is.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到该软件包确定了具有截距`7.07`和斜率`0.5`的线性回归线。在这里我们可以进行一点心理检查，因为我们已经在散点图中看到了**TV**和**Sales**之间的相关性向上向右（即正相关）。这意味着公式中的斜率应该是正的，它确实是。
- en: Evaluating the trained model
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估训练好的模型
- en: We now need to measure the performance of our model to see if we really have
    any power to predict **Sales** using **TV** as in independent variable. To do
    this, we can load in our test set, make predictions using our trained model for
    each test example, and then calculate one of the evaluation metrics discussed
    in [Chapter 3](64db3465-cd9a-42ca-b0fb-d54c59b87037.xhtml), *Evaluation and Validation*.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要衡量我们模型的性能，看看我们是否真的有使用**TV**作为自变量的能力来预测**Sales**。为此，我们可以加载我们的测试集，使用我们的训练模型对每个测试示例进行预测，然后计算第3章中讨论的评估指标之一，即*评估和验证*。
- en: For this problem, let's use the Mean Absolute Error (MAE) as our evaluation
    metric. This seems reasonable, because it results in something directly comparable
    with our `Sales` values and we do not have to be too worried about outliers or
    extreme values.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题，让我们使用平均绝对误差（MAE）作为我们的评估指标。这似乎是合理的，因为它产生的东西可以直接与我们的`Sales`值进行比较，我们也不必过于担心异常值或极端值。
- en: 'To calculate the predicted **Sales** values using our trained `regression.Regression`
    value, we just need to parse the values in our test set and call the `Predict()`
    method on the `regression.Regression` value. We will then take the difference
    of these predicted values from the observed values, get the absolute value of
    the difference, and then add up all of the absolute values to get the MAE:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用我们的训练好的`regression.Regression`值计算预测的**Sales**值，我们只需要解析测试集中的值，并在`regression.Regression`值上调用`Predict()`方法。然后我们将这些预测值与观察值之间的差异相减，得到差异的绝对值，然后将所有绝对值相加以获得MAE：
- en: '[PRE9]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Compiling and running this evaluation gives the following result:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 编译并运行此评估给出以下结果：
- en: '[PRE10]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: How do we know if `MAE = 3.01` is good or bad? This is, again, why having a
    good mental model of your data is important. If you remember, we already computed
    the mean, range, and standard deviation of sales. The mean sales value was `14.02`
    and the standard deviation was `5.21`. Thus, our MAE is less than the standard
    deviations of our sales values and is about 20% of the mean value, and our model
    has some predictive power.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何知道`MAE = 3.01`是好是坏？这又是为什么有一个良好的数据心理模型很重要的原因。如果你记得，我们已经计算了销售额的平均值、范围和标准差。平均销售额为`14.02`，标准差为`5.21`。因此，我们的MAE小于我们的销售额标准差，并且大约是平均值的20%，我们的模型具有一定的预测能力。
- en: So, congratulations! We have built our first machine learning model that has
    predictive power!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，恭喜！我们已经构建了我们第一个具有预测能力的机器学习模型！
- en: 'To get better intuition about how our model is performing, we can also create
    a plot to help us visualize the linear regression line. This can be done with
    `gonum.org/v1/plot`. First, however, let''s create a predict function that allows
    us to make our predictions without importing `github.com/sajari/regression`. This
    gives us a lightweight, in-memory version of the trained model:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解我们的模型表现如何，我们还可以创建一个图表来帮助我们可视化线性回归线。这可以通过`gonum.org/v1/plot`来完成。首先，然而，让我们创建一个预测函数，允许我们做出预测而不需要导入`github.com/sajari/regression`。这给我们提供了一个轻量级、内存中的训练模型版本：
- en: '[PRE11]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Then, we can create the visualization of our regression line:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以创建回归线的可视化：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'It will produce this plot when compiled and run:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 编译并运行时将产生以下图表：
- en: '![](img/e6a05d14-8179-452e-bb8f-358348a02708.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e6a05d14-8179-452e-bb8f-358348a02708.png)'
- en: As you can see, our trained linear regression line follows the linear trend
    of the real data points. This is another visual confirmation that we are on the
    right track!
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们训练的线性回归线遵循实际数据点的线性趋势。这是另一个视觉上的确认，表明我们正在正确的道路上！
- en: Multiple linear regression
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多元线性回归
- en: 'Linear regression is not limited to simple formulas of lines that depend on
    only one independent variable. Multiple linear regression is similar to what we
    discussed previously, but here we have multiple independent variables (*x[1]*,
    *x[2]*, and so on). In this case, our simple equation of a line is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归不仅限于只依赖于一个自变量的简单线性公式。多元线性回归与我们之前讨论的类似，但在这里我们有多个自变量（*x[1]*、*x[2]*等等）。在这种情况下，我们的简单线性方程如下：
- en: '![](img/0f9f0a8c-4d78-47ad-9338-5b3775471f11.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0f9f0a8c-4d78-47ad-9338-5b3775471f11.png)'
- en: Here, the *x*'s are the various independent variables and the *m*'s are the
    various slopes associated with those independent variables. We also still have
    an intercept, *b*.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`x`代表各种自变量，`m`代表与这些自变量相关的各种斜率。我们仍然有一个截距，`b`。
- en: Multiple linear regression is a little harder to visualize and think about because
    this is no longer a line that can be visualized in two dimensions. It is a linear
    surface in two, three, or more dimensions. However, many of the same techniques
    that we used for our single linear regression will carry through.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 多元线性回归在可视化和思考上稍微有点困难，因为这里不再是一条可以在二维中可视化的线。它是一个二维、三维或更多维度的线性表面。然而，我们用于单变量线性回归的许多相同技术仍然适用。
- en: 'Multiple linear regression has the same assumptions as regular linear regression.
    However, there are a few more pitfalls that we should keep in mind:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 多元线性回归与普通线性回归有相同的假设。然而，还有一些陷阱我们应该牢记：
- en: '**Overfitting**: By adding more and more independent variables to our model,
    we are increasing our model complexity, which puts us at risk of overfitting.
    One technique to deal with this problem, which I would recommend looking into,
    is called **regularization**. Regularization creates a penalty term in your model
    that is a function of the complexity of your model, which helps keep this effect
    in check.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合**：通过向我们的模型添加越来越多的自变量，我们增加了模型复杂性，这使我们面临过拟合的风险。处理这个问题的技术之一，我建议您了解一下，被称为**正则化**。正则化在您的模型中创建一个惩罚项，它是模型复杂度的函数，有助于控制这种影响。'
- en: '**Relative Scale**: In some cases, one of your independent variables will be
    orders of magnitude different in scale than another independent variable. The
    larger of these could wash out any effect of the smaller, and you may need to
    consider normalizing your variables.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相对尺度**：在某些情况下，您的自变量中的一个将比另一个自变量大几个数量级。较大的那个可能会抵消较小的那个的影响，您可能需要考虑对变量进行归一化。'
- en: 'With this in mind, let''s try to expand our **Sales** model from a linear regression
    model to a multiple regression model. Looking back at our scatter plots from the
    previous section, we can see that **Radio** also appears to be linearly correlated
    with **Sales**, so let''s try to create a multiple linear regression model that
    looks like the following:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，让我们尝试将我们的**销售**模型从线性回归模型扩展到多元回归模型。回顾上一节中的散点图，我们可以看到**Radio**似乎也与**销售**线性相关，所以让我们尝试创建一个类似以下的多元线性回归模型：
- en: '![](img/9f6caa9b-e5e9-4918-820b-91db3369e2f1.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9f6caa9b-e5e9-4918-820b-91db3369e2f1.png)'
- en: 'To do this with [github.com/sajari/regression](http://github.com/sajari/regression),
    we just need to label another variable in the `regression.Regression` value and
    make sure that these values get paired in the training data points. We will then
    run the regression and see how the formula comes out:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用[gihub.com/sajari/regression](http://github.com/sajari/regression)做这个，我们只需要在`regression.Regression`值中标记另一个变量，并确保这些值在训练数据点中得到配对。然后我们将运行回归，看看公式如何得出：
- en: '[PRE13]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Compiling and running this gives us the following regression formula:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 编译并运行后，我们得到以下回归公式：
- en: '[PRE14]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, the regression formula now includes an additional term for the
    `Radio` independent variable. The intercept value has also changed from our previous
    single regression model.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，回归公式现在包括一个额外的`Radio`自变量项。截距值也与我们之前的单变量回归模型不同了。
- en: 'We can test this model similarly to the single regression model using the `Predict`
    method:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`Predict`方法类似地测试这个模型：
- en: '[PRE15]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Running this reveals the following `MAE` for our new multiple regression model:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此命令会显示我们新的多重回归模型的以下`MAE`：
- en: '[PRE16]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Our new multiple regression model has improved our MAE! Now we are definitely
    in pretty good shape to predict `Sales` based on our advertising spends. You could
    also try adding `Newspaper` to the model as a follow-up exercise to see how the
    model performance is influenced.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的新多重回归模型已经提高了我们的MAE！现在我们肯定在预测基于我们的广告支出的`Sales`方面处于非常好的状态。你也可以尝试将`Newspaper`添加到模型中作为后续练习，看看模型性能是如何受到影响的。
- en: Remember that as you add more complication to the model, you are sacrificing
    simplicity and you are potentially in danger of overfitting, so you should only
    add more complication if the gains in model performance actually create more value
    for your use case.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，当你给模型增加更多复杂性时，你正在牺牲简单性，你可能会陷入过拟合的危险，因此只有当模型性能的提升实际上为你的用例创造更多价值时，你才应该增加更多的复杂性。
- en: Nonlinear and other types of regression
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非线性和其他类型的回归
- en: 'Although we have focused on linear regression in this chapter, you certainly
    are not limited to performing regression with linear formulas. You can model your
    dependent variable by one or more nonlinear terms such as powers, exponentials,
    or other transformations on your independent variables. For example, we could
    model *Sales* by a polynomial series of *TV* terms:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在这章中专注于线性回归，但你当然不仅限于使用线性公式进行回归。你可以通过在你的自变量上使用一个或多个非线性项（如幂、指数或其他变换）来建模因变量。例如，我们可以通过`TV`项的多项式级数来建模*Sales*：
- en: '![](img/7003a0ed-7126-4d23-b0a9-a68a28dd3a35.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7003a0ed-7126-4d23-b0a9-a68a28dd3a35.png)'
- en: Keep in mind, however, that as you add this complexity, you are again putting
    yourself in danger of overfitting.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，记住，当你增加这种复杂性时，你再次使自己处于过拟合的危险之中。
- en: In terms of implementing non-linear regressions, you cannot use `github.com/sajari/regression`,
    which is limited to linear regression. However, `go-hep.org/x/hep/fit` allows
    you to fit or train certain nonlinear models, and there are other various people
    in the Go community that have, or are, developing other tools for nonlinear modeling.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现非线性回归方面，你不能使用`github.com/sajari/regression`，因为它仅限于线性回归。然而，`go-hep.org/x/hep/fit`允许你拟合或训练某些非线性模型，Go社区的其他各种人也在开发其他非线性建模工具。
- en: There are also other linear regression techniques, outside of OLS, that help
    overcome some of the assumptions and weaknesses associated with least squared
    linear regression. These include **ridge regression** and **lasso regression**.
    Both of these techniques penalize regression coefficients so as to mitigate the
    effects of multicollinearity and non-normality of independent variables.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有其他线性回归技术，除了OLS之外，可以帮助克服与最小二乘线性回归相关的一些假设和弱点。这些包括**岭回归**和**Lasso回归**。这两种技术都惩罚回归系数，以减轻多重共线性和非正态独立变量的影响。
- en: In terms of Go implementations, ridge regression is implemented in `github.com/berkmancenter/ridge`.
    As opposed to `github.com/sajari/regression`, our independent variable and dependent
    variable data is input into `github.com/berkmancenter/ridge` via gonum matrices.
    Thus, to illustrate this method, let's first form a matrix containing our advertising
    spend features (`TV`, `Radio`, and `Newspaper`) and a matrix containing our `Sales`
    data. Note that in `github.com/berkmancenter/ridge`, we need to explicitly add
    a column to our input independent variable matrix for an intercept if we want
    to have an intercept in our model. Each value in this column is just `1.0`.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go实现方面，岭回归在`github.com/berkmancenter/ridge`中实现。与`github.com/sajari/regression`不同，我们的自变量和因变量数据通过gonum矩阵输入到`github.com/berkmancenter/ridge`。因此，为了说明这种方法，我们首先形成一个包含我们的广告支出特征（`TV`、`Radio`和`Newspaper`）的矩阵，以及一个包含我们的`Sales`数据的矩阵。请注意，在`github.com/berkmancenter/ridge`中，如果我们想在模型中包含截距项，我们需要明确在我们的输入自变量矩阵中添加一列。这一列中的每个值都是`1.0`。
- en: '[PRE17]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, we create a new `ridge.RidgeRegression` value with our independent and
    dependent variable matrices and call the `Regress()` method to train our model.
    We can then print out our trained regression formula:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用我们的自变量和因变量矩阵创建一个新的`ridge.RidgeRegression`值，并调用`Regress()`方法来训练我们的模型。然后我们可以打印出我们的训练回归公式：
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Compiling this program and running it gives the following regression formula:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 编译此程序并运行会得到以下回归公式：
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here, you can that see the coefficients for `TV` and `Radio` are similar to
    what we got with least squares regression, but they are slightly different. Also,
    note that we went ahead and added a term for the `Newspaper` feature.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到`TV`和`Radio`的系数与我们在最小二乘回归中得到的结果相似，但略有不同。此外，请注意，我们添加了一个关于`Newspaper`特征的项。
- en: 'We can test this ridge regression formula by creating our own `predict` function:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过创建自己的`predict`函数来测试这个岭回归公式：
- en: '[PRE20]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then, we use this `predict` function to test our ridge regression formula on
    our test examples:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用这个`predict`函数来测试我们的岭回归公式在测试示例上的效果：
- en: '[PRE21]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Compiling and running this gives us the following new `MAE`:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 编译并运行此代码后，我们得到以下新的`MAE`：
- en: '[PRE22]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Notice that adding `Newspaper` to the model did not actually improve our `MAE`.
    Thus, this would not be a good idea in this case, because it is adding further
    complications and not providing any significant changes in our model performance.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，将`Newspaper`添加到模型实际上并没有改善我们的`MAE`。因此，在这种情况下，这不是一个好主意，因为它增加了额外的复杂性，并没有在我们的模型性能上带来任何显著的变化。
- en: Any complication or sophistication that you are adding to a model should be
    accompanied by a measurable justification for this added complication. Using a
    sophisticated model because it is intellectually interesting is a recipe for headaches.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 你添加到模型中的任何复杂或高级功能都应该伴随着对这种增加复杂性的可测量理由。仅仅因为一个模型在智力上有趣而使用一个复杂模型，这可能会导致头疼。
- en: References
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Linear regression:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归：
- en: 'Ordinary least squares regression explained visually: [http://setosa.io/ev/ordinary-least-squares-regression/](http://setosa.io/ev/ordinary-least-squares-regression/)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 普通最小二乘回归的直观解释：[http://setosa.io/ev/ordinary-least-squares-regression/](http://setosa.io/ev/ordinary-least-squares-regression/)
- en: '`github.com/sajari/regression` docs: [http://godoc.org/github.com/sajari/regression](http://godoc.org/github.com/sajari/regression)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`github.com/sajari/regression`文档：[http://godoc.org/github.com/sajari/regression](http://godoc.org/github.com/sajari/regression)'
- en: 'Multiple regression:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 多元回归：
- en: 'Multiple regression visualization: [http://shiny.stat.calpoly.edu/3d_regression/](http://shiny.stat.calpoly.edu/3d_regression/)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多元回归可视化：[http://shiny.stat.calpoly.edu/3d_regression/](http://shiny.stat.calpoly.edu/3d_regression/)
- en: 'Nonlinear and other regressions:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 非线性和其他回归：
- en: '`go-hep.org/x/hep/fit` docs: [https://godoc.org/go-hep.org/x/hep/fit](https://godoc.org/go-hep.org/x/hep/fit)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`go-hep.org/x/hep/fit`文档：[https://godoc.org/go-hep.org/x/hep/fit](https://godoc.org/go-hep.org/x/hep/fit)'
- en: '`github.com/berkmancenter/ridge` docs: [https://godoc.org/github.com/berkmancenter/ridge](https://godoc.org/github.com/berkmancenter/ridge)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`github.com/berkmancenter/ridge`文档：[https://godoc.org/github.com/berkmancenter/ridge](https://godoc.org/github.com/berkmancenter/ridge)'
- en: Summary
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Congratulations! You have officially done machine learning using Go. In particular,
    you have learned about regression models, including linear regression, multiple
    regression, nonlinear regression, and ridge regression. You should be able to
    implement basic linear regressions and multiple regressions in Go.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经正式使用Go语言完成了机器学习。特别是，你学习了关于回归模型的知识，包括线性回归、多元回归、非线性回归和岭回归。你应该能够在Go语言中实现基本的线性回归和多元回归。
- en: Now that we have our feet wet with machine learning, we are going to move on
    to classification problems in the next chapter.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对机器学习有了初步的了解，我们将进入下一章，学习分类问题。
