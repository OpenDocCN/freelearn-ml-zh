<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Building a Cloud-Based Multibiometric Identity Authentication Platform</h1>
                </header>
            
            <article>
                
<p>In this chapter, <span>using </span><strong>IBM Watson Studio</strong>, we will walk through the construction of a functioning cloud-based <em>human</em> identification system using <strong>biometric traits</strong>. We will first introduce biometrics and consider what we mean by biometric data. Then, we will explain the types of preprocessing needed for each biometric. Additionally, we will learn about the process of how to extract meaningful features from biometric data. Lastly, we will cover the concepts behind <strong>multimodal data fusion</strong>.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Understanding biometrics</li>
<li>Exploring biometric data</li>
<li>Feature extraction</li>
<li>Biometric recognition</li>
<li>Multimodal fusion</li>
<li>Our example</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding biometrics</h1>
                </header>
            
            <article>
                
<p>If we start by breaking down the word itself, <strong>biometrics</strong> is derived from the Greek words <strong>bio</strong> (life) and <strong>metrics</strong> (to measure), and so biometric relates to the application of statistical analysis to biological data.</p>
<p class="mce-root"/>
<p><strong>Biometric verification</strong> is defined as the process by which someone can be uniquely identified by evaluating one (or more) distinguishing biological traits.</p>
<p>Unique identifiers typically used in the process of biometric verification include the following:</p>
<ul>
<li>Fingerprints</li>
<li>Hand geometry</li>
<li>Earlobe geometry</li>
<li>Retina/iris patterns</li>
<li>Voice (waves)</li>
<li>DNA</li>
<li>Signatures</li>
</ul>
<div class="packt_infobox">
<p>For those of us who are <em>Forensic Files</em> fans, one of the oldest forms of biometric verification is fingerprinting. You can refer to the article in the following link for more details about how the first forensic files came into implementation:  <a href="http://onin.com/fp/fphistory.html">http://onin.com/fp/fphistory.html</a>.</p>
</div>
<p>Biometric verification and authentication have advanced significantly with technology advancements, such as the digitization of analog data (not to mention IBM Watson!), which now allow for practically instantaneous personal identification to take place.</p>
<p>While it may be quite obvious that the biometric authentication process uses physical characteristics (fingerprinting) to digitally identify (or authenticate) a person, more advanced solutions may also utilize behavioral human traits (like voice cadence) as well.</p>
<p>Each of these (characteristics) is considered unique to a particular individual, and, therefore, they may be used in combination (more on combining identifiers a bit later on in this chapter) to ensure greater accuracy of identification.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Making a case</h1>
                </header>
            
            <article>
                
<p>Why is biometric verification such a topic of interest?</p>
<p>The answer is that, in an instantaneous and ever more internet-enabled world, password authentication is slow and, frankly, just not good (strong) enough.</p>
<p class="mce-root"/>
<p>According to recent popular opinion (<em>4 reasons why biometric security is the way forward</em>, Digitial Biometrics, AUG 2015), the following four reasons top the list as to why biometric verification is so important:</p>
<ul>
<li>The IoT landscape is becoming more complex </li>
<li>Passwords are not strong enough</li>
<li>Biometric security is more efficient</li>
<li>More companies and institutions are embracing biometrics</li>
</ul>
<p>Almost every one of us has had to create or choose a password and has been informed that the chosen phrase is weak or not strong enough. A weak password is one that is easy to detect both by humans or an automated process.</p>
<p>People frequently use guessable passwords such as the names of their children or their house number (so that they won't forget the password) but the simpler or the weaker the <strong>password</strong>, the easier it will be to detect or duplicate.</p>
<p>Biometric authentication is a more effective way to prove identity or authenticate someone since it cannot be simulated or replicated, and it is nearly impossible for hackers to manipulate the authentication process, even with the use of malware and other viruses.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Popular use cases</h1>
                </header>
            
            <article>
                
<p>Some of the <em>current</em> and practical areas where biometric authentication technologies are at work include the following:</p>
<ul>
<li>Border and immigration</li>
<li>Workforce management</li>
<li>Criminal identification</li>
<li>Airport security</li>
<li>Time-keeping and attendance</li>
<li>Law enforcement</li>
<li>Access control and <strong>Single Sign On</strong> (<strong>SSO</strong>)</li>
<li>Banking</li>
</ul>
<p>All indications are that this technology will continue to grow and mature as apparent in the article <em>Use of Biometrics Across the Globe</em> by John Trader of M2SYS Technology (<a href="http://www.m2sys.com/blog/biometric-hardware/top-5-uses-biometrics-across-globe/amp/">http://www.m2sys.com/blog/biometric-hardware/top-5-uses-biometrics-across-globe/amp/</a>).</p>
<p>From a financial perspective, according to the <strong>Security Industry Association</strong> (<strong>SIA</strong>), the market for electronic access controls in the USA alone is expected to top 4.47 billion in 2019 (up from just over 3 billion in 2014).</p>
<p>To further make the case for biometric authentication, an online article, <em>Millennials Accelerating the End of the Password Era</em> (January 29, 2018, by Limor Kessem), we see that although password use is not popular, when logging into applications <em>security</em> is the biggest (by far) concern for users (<a href="https://securityintelligence.com/new-ibm-study-consumers-weigh-in-on-biometrics-authentication-and-the-future-of-identity/">https://securityintelligence.com/new-ibm-study-consumers-weigh-in-on-biometrics-authentication-and-the-future-of-identity/</a>).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Privacy concerns</h1>
                </header>
            
            <article>
                
<p>With the convenience and security of biometrics comes a concern for privacy. For any biometric authentication solution to work, it requires a database containing the relevant information for each individual to be identified and authorized by the system. This means that every user's biometric signature would have to be recorded so that the solution could use the information to verify each person's identity. The safekeeping, ethical use, and governance of this information becomes critical.</p>
<p>In addition to the aforementioned, by their nature, biometric systems also collect more information than just the users' fingerprints, retinal patterns, or other biometric data. At a basic level, most systems will record the time and place a person is at the time of an authentication. This also leads to the concern over how and where this information could potentially be used.</p>
<p>Some final words on this particular topic: a recent court ruling emphasized the importance of providing (prior) notice of biometric data collection and use. Be careful when dealing with biometrics: violating the law will most likely result in you or your company being sued.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Components of a biometric authentication solution</h1>
                </header>
            
            <article>
                
<p>The components that make up a biometric authentication solution include the following:</p>
<ul>
<li>A sensor or other device to capture the biometrics</li>
<li>Data storage to save the biometrics</li>
<li>A machine learning matching algorithm(s)</li>
<li>A decision processor or how to handle the results of the previous three</li>
</ul>
<p>In the next section, we will start exploring biometric data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring biometric data</h1>
                </header>
            
            <article>
                
<p>After reading the preceding sections of this chapter and, hopefully, understanding the purpose and opportunity of using biometrics data within a solution, the next step is a walk-through, conceptually at least, for building the solution.</p>
<p>When using biometric information for authentication, we would see the following:</p>
<ul>
<li><strong>Collection of biometric data</strong>: This step uses some sort of input device to capture biometric data. The input of this information is typically referred to as biometric scanning. This scanning may be a fingerprint, the iris of the eye, vocal prompts, or other forms of biometric scanning (quite often photographs are the first biometric form that is used, since photographs are easy to understand and manage).</li>
<li class="mce-root"><strong>Conversion, labeling, and storage of biometric data</strong>: The data that is collected through scanning must then be converted into a digital format and saved in a database and appropriately labeled. This database stores the biometric data of individuals that will need to be authorized by the solution.</li>
<li class="mce-root"><strong>Selection and configuration of an ML algorithm</strong>: A <strong>matching algorithm</strong> is used to compare newly scanned data to data that is stored and labeled within the digital database. Upon a match, the individual is authenticated, and then decision logic is used to decide what the next step will be, such as granting access to a system or location.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Specific Individual identification</h1>
                </header>
            
            <article>
                
<p>So, biometric identification involves determining the identity of a specific person by comparing an individual presented (or scanned) <strong>biometric signature</strong> with that which is already cataloged in the solutions database and making a decision: does it or doesn't it match? This can be seen in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-537 image-border" src="assets/bf12c3a3-df26-419b-bb94-dcec65caf706.png" style=""/></div>
<p>A biometric signature can be an item obtained from the individual such as the following:</p>
<ul>
<li>A photo of their face</li>
<li>A record of their voice</li>
<li>An image of their fingerprint</li>
</ul>
<p>Keep in mind that <strong>biometric data</strong> is a general term used to refer to any data that is created during a <strong>biometric</strong><strong> scanning process</strong>.</p>
<p>In addition to the previously mentioned, this biometric data may also include any samples, models, fingerprints, similarity scores, and all verification or identification data including the individual's name and demographics.</p>
<p>Also included in the individualâ€™s signature can be palm veins, face recognition, DNA, palm print, hand geometry, iris recognition, retina, and odor/scent. Further, <strong>behavioral characteristics</strong> that are related to the pattern of behavior of an individual (for example, his or her a gait or typing rhythm) may also be part of the biometric database.</p>
<p>It should also be of note that, since biometric data is digital in format, it can be efficiently processed by computer systems and easily encrypted as a safeguard against unethical manipulation and use by unauthorized persons.</p>
<p>Another point is the submission of a single set of biometric samples to a biometric system for identification or verification is referred to as an attempt. For obvious reasons, solutions typically allow only a single attempt to identify or verify an individual. Attempts made by individuals who do not have a cataloged biometric signature previously scanned and cataloged within the solutions database will fail authentication. This is significant since it reduces the amount of data needing to be scanned and cataloged for the solution to work: you only need to establish digital signatures for those individuals that do need to be authenticated and granted access.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Challenge of Biometric Data Use</h1>
                </header>
            
            <article>
                
<p>Collecting, cataloging, and using biometric data can be a challenge. This form of data is, like most data, subject to uncertainty and variation. Perhaps unique to biometric data, we see that this information may be affected by changes in an individual's age, environmental influences, disease, stress, occupational factors, training and prompting, intentional alterations, sociocultural aspects of the situation in which the presentation occurs, changes in human interface with the system, and so on.</p>
<p>As a result, each interaction or attempt of an individual may be associated with different biometric information.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sample sizing</h1>
                </header>
            
            <article>
                
<p>In <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud</em> , we constructed an expression analysis model using facial images for the model to train on and use to detect human emotions: happiness, sadness, and anger. In that exercise, we chose a sample size for each emotion of just 11 images:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-538 image-border" src="assets/263dc466-cf1c-40c3-8536-38b73ddf24f8.png" style=""/></div>
<p class="mce-root"/>
<p>In that exercise, the sample size (11) was sufficient since the goal was to prove our concept. Obviously, the bigger the sample size the more accurate the model.</p>
<p>A <strong>biometric authentication</strong> solution works on the same premise; however, rather than detecting emotion from an attempt, the model will compare the <em>scanned</em> image to its cataloged database, looking for a match. Since the scanned image will not be one that is in the database, the matching algorithm must compare the databased images and detect the individual based upon its facial recognition and evaluation logics. If there is simply one image of each authenticated user within the database, the margin for error increases. Therefore, how many images (for each user) are needed? What is the optimal sample size (for a biometric authentication solution) to be used?</p>
<p>Biometric system performance is typically evaluated by collecting biometric templates (or biometric signatures) from <em>n</em> different subjects, and, for convenience, acquiring multiple instances of that biometric (for example, photographs) for each of the <em>n</em> subjects.</p>
<p>Unfortunately, you most likely found that there isn't much work available to date on constructing confidence regions based on the <strong>Receiver Operating Characteristic (ROC)</strong> curve for validating the claimed performance levels and determining the required number of biometric samples needed to establish confidence regions of prespecified width for the ROC curve.</p>
<div class="packt_infobox">
<p>ROC is widely used to determine how a predictive model can distinguish between true positives and negatives. To accomplish this task, a model needs to correctly predict not only a positive as a positive but also a negative as a negative.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Feature extraction</h1>
                </header>
            
            <article>
                
<p>Biometric feature extraction (also sometimes named minutia extraction) refers to the process by which established <em>key</em> features of a sample are selected or enhanced for more efficient processing. Typically, the process of feature extraction relies on a set of algorithms that varies depending on the type (face image or fingerprints, for example) of biometric identification used.</p>
<p>Biometric authentication is the matching of samples that have been converted (previously or upon attempt) from, for example, an image of a biometric trait into a searchable set of data.  This conversion is the process known as feature extraction.</p>
<p class="mce-root"/>
<p>If you look for example of how feature extraction fundamentally works, you see that it depends upon the type of sample, but is, for the most part, quite easy to conceptualize. You can head over to the following link to know more on how a biometric matching works: <a href="http://devtechnology.com/2013/11/emerging-biometric-technology-revocable-biometric-features/">http://devtechnology.com/2013/11/emerging-biometric-technology-revocable-biometric-features/</a>.</p>
<div class="packt_infobox">Some other examples of biometric feature extraction can also be referred to the article in the following link: <a href="http://arindamcctvaccesscontrol.blogspot.com/2010/05/access-control-index-terminology.html">http://arindamcctvaccesscontrol.blogspot.com/2010/05/access-control-index-terminology.html</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Biometric recognition</h1>
                </header>
            
            <article>
                
<p>A biometric recognition and ultimately a successful authentication depend upon the robustness of the selected machine learning algorithm used within the solution but also on (as we discussed in the <em>Feature extraction</em> section of this chapter) the sample size.</p>
<p>In addition to these requirements, it is important to consider the quality of the samples as well as the type. Poor image quality, for example, can significantly impact the accuracy of a biometric authentication. We also briefly mentioned using <strong>behavioral traits</strong> as part of a biometric signature.</p>
<p>Generally speaking though, <strong>physiological characteristics</strong> (such as a fingerprint or facial picture, for instance) are always the most static, showing little dissimilarity over time, while <strong>behavioral characteristics</strong> (that is, a gait or cadence) can and usually do experience variations, and can be prejudiced by external factors or by particular emotional conditions such as stress or strong psychological impacts.</p>
<p>Interesting <strong>behavioral</strong> <strong>characteristics</strong> already in use by some biometric authentication solutions include vocal imprints, writing and/or typing style, movements of the body, the style and the trend of walk, and so on.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multimodal fusion</h1>
                </header>
            
            <article>
                
<p>Most simply put, the more gates surrounding an individual's property, the more secure it will be, since we would need to possess the ability to successfully pass more than a single test to proceed. The same applies to any system or solution that makes a decision to proceed based upon the outcome of a test (match or no-match). Adding additional tests produces additional outcomes and additional decisions based upon those outcomes.</p>
<p>Biometric authentication solutions are typically considered unimodal (conducts only a single test) or multimodal (conducts more than a single test):</p>
<ul>
<li><strong>Multimodal biometric authentication</strong>: This describes an implemented solution that utilizes multiple biometric indicators for identifying the authenticated individuals, such as a photo/image and a signature. A successful match of both biometrics is required to succeed.</li>
<li><strong>Unimodal biometric authentication</strong>: This describes a solution that utilizes only a single level of authentication, such as only a photo/image or a signature. In this case, if the solution matches successfully to the biometric (for example, and image) the attempt is successful.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Our example</h1>
                </header>
            
            <article>
                
<p>Now that we have an idea and understanding of just what a biometric authentication solution is and how it works, we will try to build a simple but actually working prototype using the same <strong>IBM Watson Visual Recognition service</strong> we used in <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud</em>, as well as that project as a guide for our new solution.</p>
<div class="packt_infobox">
<p>As a reminder, the IBM Watson Visual Recognition service understands the image content out-of-the-box (we demonstrated this in our <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud</em> project). The pretrained models provided enable you to analyze images for objects, faces, colors, food, explicit content, and other subjects for insights into your visual content. We successfully used the service to detect faces and then determine expressions.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Premise</h1>
                </header>
            
            <article>
                
<p>The general premise will be to clone our <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud</em>, project and create a class or classes to be used as a simple biometric signature for myself; one loaded with a dozen images of, well, my face, as well as a negative class loaded with a dozen images of random faces (none will be of me).</p>
<p>In addition, there will be at least one other class, designed to be a biometric signature of another individual. So we expect that, in this chapter's project, we will have the following three classes:</p>
<ul>
<li>Jim class</li>
<li>Individual two or other classes</li>
<li>Negative class</li>
</ul>
<p>The final step will be to use a mobile device to take several photos of myself and others and, without preparation or any processing of the images, submit the facial images to our project and record the results: matched or not matched. These image submissions will be considered our attempts for biometric authentication.</p>
<p>Perhaps to test the project fairly, we will need to be sure to submit several images of myself (none of which would be part of the model's class definitions my biometric signature) and several faces that are not mine and record the results of each submission.</p>
<p>Finally, we will evaluate and record the results.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data preparation</h1>
                </header>
            
            <article>
                
<p>Straightaway, we need to have a sample of 10 images of my face. The images should be of reasonable quality and, for best results, close-up photos taken over a period of time so that the algorithm can have some accounting for variances in my appearance.</p>
<div class="packt_tip">If you have forgotten, you can review <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud,</em> for the specific file image requirements.</div>
<p>Here are the images that will be used to create my biometric signature:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-539 image-border" src="assets/7e180569-c5ed-401c-aee3-a53c6d764d51.png" style=""/></div>
<p>Next, we need to establish a biometric signature (with the same size sample) for another individual:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-540 image-border" src="assets/545ddb3a-30b1-4803-a058-95c8ca098157.png" style=""/></div>
<p>Finally, the negative class of 10 random faces (of course, borrowed from our project) needs to be set:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-541 image-border" src="assets/29ea8706-1f29-459a-b9ff-e62e4516f65d.png" style=""/></div>
<div class="packt_infobox">
<p>A reminder from Watson docs: The <strong>create a classifier</strong> call requires that you provide at least two example ZIP files: two positive examples files or one positive and one negative file. The negative examples <span>defines what the updated classifier is not. It</span> is not used to create a class within the created classifier. Negative example files will contain images <strong>that do not match the subject of any of the positive examples</strong>. In a single call, there can be only one single example specified.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Project setup</h1>
                </header>
            
            <article>
                
<p>Once again, we will assume that we have already created a new IBM Watson Studio project and now (as in <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud</em>) add a new visual recognition model by going to the <span class="packt_screen">Assets</span> tab and under <span class="packt_screen">Models</span>, click on <span class="packt_screen">New Visual Recognition model</span> (you can go back to <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud,</em> for a quick review).</p>
<p>Just like in <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud,</em> once the model is created (it should take only a few moments), you can drag and drop the image <kbd>.zip</kbd> files we prepared in the preceding sections of this chapter.</p>
<p>This will upload the image files to <strong>Cloud Object Storage</strong> (<strong>COO</strong>), making them available to be used in our project (as shown in the following screenshot):</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-542 image-border" src="assets/5b573a9c-4e4d-4929-b5d8-5edec44e772f.png" style=""/></div>
<p>From the <span class="packt_screen">Default Custom Model</span> screen (in the following screenshot), we are ready to build our model classes:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-543 image-border" src="assets/a0867f42-5b0d-42f3-b49c-bb2c5cb8d685.png" style=""/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating classes</h1>
                </header>
            
            <article>
                
<p>You can now click on the <span class="packt_screen">Create a class</span> button (shown on the bottom left in the following screenshot) to create both the <span class="packt_screen">Jim</span> and <span class="packt_screen">Other</span> classes (remember, the <span class="packt_screen">Negative</span> class is already created for you):</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-544 image-border" src="assets/847968ed-1434-45ec-996d-773d11d6aa3d.png" style=""/></div>
<div class="packt_infobox"><span>Again, you can refer back to <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud,</em> to the <em>Creating Classes for Our Model</em> section for the step-by-step instructions for creating classes.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training the model</h1>
                </header>
            
            <article>
                
<p>Once we have our three classes created (and loaded with images) and saved, and the model status shows <span class="packt_screen">Ready to train</span>, we can then c<span>lick on the</span> <span class="packt_screen">Train Model</span> <span>button to start training the model on the images we provided:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-545 image-border" src="assets/dd2e7694-c322-48ef-a626-67864320efd9.png" style=""/></div>
<p><span>Once more, this is a small model with only 30 training images; the training process will take less than 5 or 10 minutes.  Part of the beauty of using IBM Watson and services is that many of the "detailed tasks" like creating model definitions and training a model is simply a "button click". To learn more about training a visual recognition model, you can visit:</span></p>
<div class="packt_tip">https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/visual-recognition-train.html?linkInPage=true</div>
<p>Once the model training has been completed and you notice (see the following screenshot) that the model status says <span class="packt_screen">Trained</span>,<span class="packt_screen"> </span>you can proceed:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-546 image-border" src="assets/d08e02f2-88dc-45f3-ac44-e925bd7a2daa.png" style=""/></div>
<p>Just as we did in <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud,</em> to test and validate our model, we can upload images in the <span class="packt_screen">Test</span> area of the <span class="packt_screen">Default Custom Model</span> page, as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-547 image-border" src="assets/48e08013-2c97-4c76-8fb3-82ac202c9246.png" style=""/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Testing our project</h1>
                </header>
            
            <article>
                
<p>Just as we have planned, the final step of our project exercise is to use a mobile device to take several photos of myself and others and, without preparation of the images, submit the facial images to our project for authentication and record the results: matched or not matched.</p>
<p>Using my smartphone, I took the following three head shots. I tried to capture a variation in lighting and expression:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-548 image-border" src="assets/624b1f02-df8f-4725-b505-36bcd7662b3d.png" style=""/></div>
<p>In addition, as we stated earlier, to test our project fairly, we need to submit several images of faces that are not mine and record the results of each submission as well.</p>
<p>For these test subjects, I collected the following:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-549 image-border" src="assets/373b0dc4-0637-43e4-9d48-efdef1bc3520.png" style=""/></div>
<p>Now it's testing time!</p>
<p>As we can see in the following screenshot, I submitted the first four images: Jim, Jim, Jim, and other. The model correctly authenticated each image that was submitted:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-550 image-border" src="assets/d8cd12f7-557b-46fe-9ff9-b15732154c27.png" style=""/></div>
<p>That's pretty good, right? Now we can submit the fourth and final image (<em>not</em> Jim and <em>not</em> other) and zoom in on all of the scores:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-551 image-border" src="assets/fbfd6a9c-9f85-420d-93f7-fcb9544468cb.png" style=""/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Guidelines for good training</h1>
                </header>
            
            <article>
                
<p>We have now created a simple biometric authentication proof of concept using IBM Watson Studio and the IBM Watson Visual Recognition service. It works but of course this is not ready for deployment. There are many things to consider before a model is ready for deployment and production use. For example, guidelines provided with the Visual Recognition service state that it is best practice to include at least 50 positive images <em>per class</em> before you can begin to realistically assess your training results.</p>
<p>Other recommendations provided include the following:</p>
<ul>
<li>Assuming similar quality and content for your training data, more training images generally provide more accurate results than fewer images.</li>
<li>150 to 200 images per <kbd>.zip</kbd> file provides the best balance between processing time and accuracy. More than 200 images will increase the time and the accuracy, but with diminishing returns for the amount of time it takes.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation</h1>
                </header>
            
            <article>
                
<p>To the right of the <span class="packt_screen">Test</span> tab is the <span class="packt_screen">Implementation</span> tab (shown in the following screenshot). From here, you can see the the code snippets provided for you by Watson to classify images against the model you just built:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-552 image-border" src="assets/1db89612-9d62-41bf-847c-045269acaffd.png" style=""/></div>
<p class="mce-root"/>
<p>For reference, the full API specification you will need to deploy the model is available here: <a href="https://cloud.ibm.com/apidocs/visual-recognition">https://cloud.ibm.com/apidocs/visual-recognition</a>.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we introduced and discussed collecting and using biometric data in a biometric authentication solution, how such a solution works as well as feature extraction (in regard to biometric data solutions) was the idea of multimodal fusion. Finally, we expanded the expression detection and analysis solution from <a href="4ed9b065-d004-45ed-97e4-65c805d8ab3a.xhtml">Chapter 8</a>, <em>Creating a Facial Expression Platform on IBM Cloud</em>, again using the IBM Watson Visual Recognition service, to create a working biometric authentication solution proof of concept.</p>
<p>The next chapter concludes this book with an overview of what we have covered. The chapter will also shed some light on some of the practical considerations related to developing machine learning systems on the cloud with IBM Watson Studio.</p>


            </article>

            
        </section>
    </body></html>