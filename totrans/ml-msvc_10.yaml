- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building an Intelligent MSA Enterprise System
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we gradually built the ABC-MSA to demonstrate some of
    an MSA system’s features, techniques, and traffic patterns.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will combine both MSA concepts and AI concepts to build
    an ABC-Intelligent-MSA system, which is an enhanced version of our ABC-MSA. The
    intelligent version of the ABC-MSA will use various AI algorithms to enhance the
    performance and general operations of the original ABC-MSA system.
  prefs: []
  type: TYPE_NORMAL
- en: ABC-Intelligent-MSA will be able to examine different traffic patterns and detect
    potential problems and then **self-rectify** or self-adjust to try to prevent
    the problem from taking place before it actually happens.
  prefs: []
  type: TYPE_NORMAL
- en: The ABC-Intelligent-MSA will be able to **self-learn** the traffic behavior,
    API calls, and response patterns, and try to **self-heal** if a traffic anomaly
    or problematic pattern is detected for whatever reason.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics are covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The machine learning advantage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building your first AI microservice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The intelligent MSA system in action
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing AI service operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The machine learning advantage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many areas in our MSA where we can leverage AI to enhance the system’s
    reliability and operability. We will focus our system on two main potential areas
    of enhancement. One is to enhance the system response in case of a microservice
    failure or performance degradation. The second area of enhancement is to add a
    proactive circuit breaker role.
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed in [*Chapter 3*](B18934_03.xhtml#_idTextAnchor039), the circuit
    breaker pattern is used to prevent a system cascading failure when one of the
    system’s microservices fails to respond to API consumer requests promptly. Should
    a microservice fail or perform poorly, our AI will try to take proactive action
    to fix the problem rather than waiting for the problem to be manually fixed for
    the system to return to normal operation.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 7*](B18934_07.xhtml#_idTextAnchor079), we discussed the advantages
    of using **Machine Learning** (**ML**) and DL in MSA in detail. This chapter will
    focus on building two AI microservices to enhance our MSA system.
  prefs: []
  type: TYPE_NORMAL
- en: The first AI microservice is called a **Performance Baseline Watchdog** (**PBW**)
    service. The PBW is an ML microservice that creates a baseline for the expected
    performance of each microservice in the MSA system under a certain system load.
    Should the operational performance of the measured microservice fall under the
    performance baseline by the configurable value of *x*, the system should send
    a warning message to the **Operation Support System** (**OSS**) or the **Network
    Management System** (**NMS**) and should performance fall by *y* (which is also
    configurable), the system then should take predefined action(s) to try to self-rectify
    and self-heal the MSA system.
  prefs: []
  type: TYPE_NORMAL
- en: The second AI microservice we will build in this chapter is the **Performance
    Anomaly Detector** (**PAD**) service. The PAD is an ML microservice that takes
    a holistic view of the entire MSA system. The PAD learns the MSA performance patterns
    and tries to detect any anomalous behavior. It identifies “problematic patterns,”
    tries to automatically detect a problem before it happens, and accordingly takes
    proactive action to fix the faulty area of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Building your first AI microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start building our two AI microservices, we need to think about our
    training and test data first – how we will collect our training data, build the
    model accordingly, test the model and measure its reliability, and enhance the
    algorithm’s reliability if needed.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: The AI services we are building in our MSA system are only a proof of concept
    to demonstrate the value of implementing AI in MSA systems. Rather, businesses
    should consider an AI service or model that matches their unique needs, business
    process, and their deployed MSA system.
  prefs: []
  type: TYPE_NORMAL
- en: We will also need to simulate the use cases themselves. Simulate a system’s
    microservice failure or performance degradation, simulate a cascading failure,
    and we should also be able to simulate some system’s outlier patterns to see how
    the algorithm would detect and react to pattern anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: To do all this, let’s first understand how the PBW and PAD microservices fit
    with the overall system’s operation and how they would normally interact with
    the different system’s components.
  prefs: []
  type: TYPE_NORMAL
- en: The anatomy of AI enhancements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main role of both the PBW and PAD is to enhance the stability and reliability
    of our MSA system. It is therefore imperative for both services to constantly
    watch individual microservices and the overall system performance and then take
    the necessary action when performance issues are detected.
  prefs: []
  type: TYPE_NORMAL
- en: The training data is first collected in a controlled environment for a specific
    training period, where normal, stable system operations and the average user load
    are simulated and applied. This can be achieved using some of the simulation tools
    we built, which will be discussed later in this section.
  prefs: []
  type: TYPE_NORMAL
- en: This training period creates an ideal first baseline that will be the main reference
    for the AI services to use during actual production time. The collected training
    data will then be used to build the algorithm. To achieve better and more accurate
    results, the training data and algorithm can be regularly tuned later when more
    information about real-time production traffic is collected.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simulated load and system operations are tweaked through multiple simulation
    parameters. These parameters are tweaked regularly to mimic the actual acceptable
    operational performance. The algorithm tweaks would eventually stop (or become
    very minor) as the AI algorithms mature. The cycle of onboarding the AI services
    to the ABC-MSA system is demonstrated in *Figure 10**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1: AI microservices implementation in ABC-Intelligent-MSA](img/B18934_10_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.1: AI microservices implementation in ABC-Intelligent-MSA'
  prefs: []
  type: TYPE_NORMAL
- en: More information on the simulation tools and parameters is coming up in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Once the AI services are operational, they will start collecting performance
    stats from each of the system’s microservices through periodic API calls and then
    compare these performance stats with the expected performance or behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'Should an individual microservice or the overall system performance deviate
    from what the AI expects to see, a system action will be triggered to either warn
    the system administrators or self-heal whenever possible. *Figure 10**.2* shows
    the high-level architecture of the PBW and PAD services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2: PBW and PAD services in ABC-Intelligent-MSA](img/B18934_10_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.2: PBW and PAD services in ABC-Intelligent-MSA'
  prefs: []
  type: TYPE_NORMAL
- en: The PBW’s algorithm calculates the expected performance metrics based on the
    performance stats collected. Collected performance stats include API call response
    time stats, the failures or failure rate of individual microservices, the API
    response code, and the load applied on the microservice itself.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-defined actions are triggered based on how far the microservice deviates
    from the calculated performance metric. Based on the configuration of the PBW,
    the higher the deviation, the more likely a proactive action is to be triggered
    to try to self-heal. In the case of a slight deviation, however, no healing action
    is supposed to be trigged; a system warning informing the system administrator
    is sufficient.
  prefs: []
  type: TYPE_NORMAL
- en: The following table shows some of the possible system issues that could be encountered
    during the operations of an ABC-Intelligent-MSA system, and the actions the PBW
    service would take to try to rectify the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'The list shown in the table is only a sample of potential issues and can, of
    course, grow as more use cases are considered:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Microservice Issue** | **Triggered Action** |'
  prefs: []
  type: TYPE_TB
- en: '| Slow responsiveness | Scale the microservice vertically/horizontally or restart
    the microservice |'
  prefs: []
  type: TYPE_TB
- en: '| Intermittent timeouts | Scale vertically/horizontally or restart |'
  prefs: []
  type: TYPE_TB
- en: '| API call HTTP response errors | Check Apache, Flask, the JVM, the Docker
    volume, SQL service, etc. Restart the service if neededRestart the microservice’s
    container |'
  prefs: []
  type: TYPE_TB
- en: '| Service is unresponsive (down) | Restart the microservice’s container |'
  prefs: []
  type: TYPE_TB
- en: Table 10.1 – Potential ABC-Intelligent-MSA operational issues and the PBW’s
    self-healing actions
  prefs: []
  type: TYPE_NORMAL
- en: The healing mechanism can be applied to the MSA system using multiple AI services,
    not necessarily only using the PBW and PAD that we are implementing in our ABC-Intelligent-MSA.
    This is just an example.
  prefs: []
  type: TYPE_NORMAL
- en: The self-healing process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All of the PBW’s healing actions listed in *Table 10.1* should not be taken
    in isolation from the PAD’s operations, but rather should be carefully coordinated
    with the PAD’s healing actions. A single issue in a microservice could (although
    not necessarily) trigger actions from both the PBW and PAD services at the same
    time and could consequently create an operational conflict.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of the self-healing process, and to avoid conflict between the system’s
    AI services when triggering self-healing actions, whenever an action is determined
    and before it is triggered, the AI service sends an API call to the other AI services
    first (either directly or through the API gateway), declaring a **Self-Healing
    Lock State** in the troubled microservice. Accordingly, all the other AI services
    in the MSA system will hold off any actions that may have been planned related
    to that troubled microservice.
  prefs: []
  type: TYPE_NORMAL
- en: During the self-healing lock state, the only AI service allowed to work on the
    troubled microservice is the **Healer AI Service**, which is the AI service that
    locked it.
  prefs: []
  type: TYPE_NORMAL
- en: Once the healer has fixed the problem and detects a normal operation in the
    affected microservice, the healer then sends another API call to the other AI
    services in the MSA system declaring that the lock state is over.
  prefs: []
  type: TYPE_NORMAL
- en: If the healer is unable to self-heal and gives up on resolving the issue, it
    sends an alarm to the NMS/OSS and marks that microservice as **unhealable** for
    a specific configurable period of time, known as the **Unhealable Wait Period**
    (by default, 15 minutes).
  prefs: []
  type: TYPE_NORMAL
- en: The unhealable wait period allows other AI services to try to heal that microservice
    and gives the healer a breather to pace out its operation across all other microservices
    in the MSA system.
  prefs: []
  type: TYPE_NORMAL
- en: To prevent healers from consuming system resources by slipping into indefinite
    healing attempts, healers will try to heal the troubled microservices for a specific
    number of healing attempts, configured through the **Maximum Healing Attempts**
    value (four attempts, by default), and will then completely give up trying. If
    the maximum healing attempts are exhausted, a manual system intervention will
    be needed to fix the troubled microservice.
  prefs: []
  type: TYPE_NORMAL
- en: System administrators can still configure indefinite healing attempts if needed,
    but this can consume system resources and may not be effective depending on the
    nature of the problem the MSA system or a specific microservice is experiencing.
  prefs: []
  type: TYPE_NORMAL
- en: If another AI service can fix the troubled microservice or the microservice
    is manually fixed, the original healer will automatically clear the unhealable
    flag of the microservice after the unhealable wait period is over.
  prefs: []
  type: TYPE_NORMAL
- en: If on the other hand, no other AI service can fix the problem and no manual
    intervention is taken to fix the microservice, the original healer – and any other
    healer that may have tried to fix the microservice – will try to heal the microservice
    again once the unhealable wait period expires if and only if the troubled microservice
    is not in a self-healing lock state.
  prefs: []
  type: TYPE_NORMAL
- en: The following visual chart summarizes the self-healing process and may help
    better explain the entire process.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3: The self-healing process in MSA](img/B18934_10_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.3: The self-healing process in MSA'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to also understand the main terminology used to explain the
    self-healing process. The following table shows a summary of the terminology of
    the main components of our self-healing process:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Term** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| Healer | An AI service that attempts to heal a troubled microservice. |'
  prefs: []
  type: TYPE_TB
- en: '| Healing Action | An action taken by the healer to try to fix an ongoing system
    operational issue. |'
  prefs: []
  type: TYPE_TB
- en: '| Self-Healing Lock State | A microservice state in which an attempt is made
    by the healer to fix the microservice.In this state, only one healer (the one
    that initiated the lock state) is allowed to work on the troubled microservice.A
    microservice self-healing lock state is a state visible by the entire MSA system
    and not a healer-specific state. |'
  prefs: []
  type: TYPE_TB
- en: '| Retry Wait Period | The time the healer for which has to wait when a healing
    action fails before it retries. The Retry Wait Period is 2 min by default. |'
  prefs: []
  type: TYPE_TB
- en: '| Unhealable State | The state in which the troubled microservice is marked
    unfixable by a healer after a healer’s failed attempt to fix the troubled microservice.A
    microservice unhealable state is a healer-specific state and only visible to the
    healer that gave up on fixing that troubled microservice. Other healers can still
    try to fix the troubled microservice. |'
  prefs: []
  type: TYPE_TB
- en: '| Unhealable Wait Period | The time for which the healer has to wait before
    it starts to make another attempt to fix the troubled microservice. The Unhealable
    Wait Period is 15 min by default. |'
  prefs: []
  type: TYPE_TB
- en: '| Maximum Healing Attempts | The maximum number of attempts the healer will
    try after each unhealable wait period, and before the healer totally gives up
    on the troubled microservice and no longer attempt to fix it. By default, PBW
    tries 4 healing attempts. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 10.2: ABC-Intelligent-MSA operational issues with the self-rectifying
    actions of the PBW'
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have explained the value of deploying AI services in the MSA system
    and shown some practical application examples to demonstrate the value of AI in
    MSA.
  prefs: []
  type: TYPE_NORMAL
- en: In order to build, run, and tweak AI services in MSA, we need to build certain
    tools to gather and log system statuses, operational dynamics, and operational
    statistics. In the following section, we will dive into what these tools are and
    how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Building the necessary tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The purpose of creating project tools is to first be able to build the AI models,
    then simulate the entire ABC-Intelligent-MSA system, and then collect stats and
    analyze the system’s operations.
  prefs: []
  type: TYPE_NORMAL
- en: Although there may be tools available online that would help us achieve our
    purpose, instead, we will build simple tools customized specifically for our use
    cases.
  prefs: []
  type: TYPE_NORMAL
- en: We created multiple tools to help us collect training and test data, simulate
    the system and microservices load, and measure the performance of the microservices.
    All the tools are available in the `tools` directory in our GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: The tools also help us scrub some of the generated logs and data for analysis
    and potential future enhancements.
  prefs: []
  type: TYPE_NORMAL
- en: The following are the main tools we need in our ABC-Intelligent-MSA setup.
  prefs: []
  type: TYPE_NORMAL
- en: An API traffic simulator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The API traffic generator/simulator, `simulate_api_rqsts.py`, helps simulate
    the API request load for one or more of the system’s microservices.
  prefs: []
  type: TYPE_NORMAL
- en: '`simulate_api_rqsts` creates multi-threaded API requests across multiple target
    microservices. API HTTP requests are then sent to each microservice in parallel.'
  prefs: []
  type: TYPE_NORMAL
- en: The API load is measured by requests per minute and API requests can either
    be uniformly or randomly paced.
  prefs: []
  type: TYPE_NORMAL
- en: The uniformly paced requests are paced out so that the time between each API
    call is always the same, so if we are configuring a uniformly paced load of 600
    API requests/min, `simulate_api_rqsts` will send 1 API call every T = 100 ms.
  prefs: []
  type: TYPE_NORMAL
- en: In the randomly-paced case, each API call is sent after a random period, TR,
    from the time where the previous call was sent, but so that TR can never be larger
    or smaller than 95% of T. So if we are configuring a randomly-paced load of 600
    API requests/min, TR, in that case, will be equal to a value greater than 5 ms
    and smaller than 195 ms.
  prefs: []
  type: TYPE_NORMAL
- en: '`simulate_api_rqsts` will send 1 API call every:'
  prefs: []
  type: TYPE_NORMAL
- en: '*(1-95%)T <= T*R *<= (1+95%)T* (i.e., for 600 requests/min: *5 ms <= TR <=*
    *195 ms*)'
  prefs: []
  type: TYPE_NORMAL
- en: The sum of all TRs, however, will still be approximately equal to the configured
    requests/min. In our example here, the load is 600 API requests/min.
  prefs: []
  type: TYPE_NORMAL
- en: Uniformly paced requests are better when you are manually analyzing how a particular
    microservice responds to the API load, while randomly paced requests are a better
    representation of a real-time production API request load.
  prefs: []
  type: TYPE_NORMAL
- en: The microservices performance monitor
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The microservices performance monitor, `ms_perfmon.py`, is another multithreading
    tool and is initially used for collecting and building the AI training data during
    the simulation period of ideal conditions.
  prefs: []
  type: TYPE_NORMAL
- en: '`ms_perfmon` sends parallel API calls to each microservice in the system and
    then logs the API call hyperlink, the date and time at which it was sent, the
    receiving microservice response time, and the HTTP response code. The following
    is an example log entry of the collected data in a comma-separated format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Each microservice stat is collected in its own `perfmon_stats` directory in
    the `ms_perfmon` working path.
  prefs: []
  type: TYPE_NORMAL
- en: In real-time operation, both the PBW and PAD perform a similar job to `ms_perfmon`.
    They collect their own stats and measure the target microservice’s real-time performance
    against the baseline and the expected normal behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Should we extend the MSA system’s AI capabilities by including more AI services
    for different purposes and use cases, which will likely require each AI service
    to conduct its own performance statistics collection?
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the collection frequency and the type of data collected, as the
    number of collectors increases, scalability could become an issue. The `ms_perfmon`
    function, in that case, can be extended to become the main AI collector for all
    AI or non-AI services in the MSA system. This setup can help offload the system’s
    microservices and allow the MSA system to scale better.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4: A collect-once performance stats setup in ABC-Intelligent-MSA](img/B18934_10_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.4: A collect-once performance stats setup in ABC-Intelligent-MSA'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.4* shows how `ms_perfmon` can handle stats collection on behalf
    of all other services in the MSA system and then act as a proxy and respond to
    API calls requesting whatever stats are needed for each particular AI (or non-AI)
    service.'
  prefs: []
  type: TYPE_NORMAL
- en: The response delay simulator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To simulate a delayed response or a troubled microservice, and solely for simulation
    and testing purposes, we added a feature in key microservices to simulate a delayed
    API call response.
  prefs: []
  type: TYPE_NORMAL
- en: The delay response feature, when enabled in the microservice, has two configurable
    values – the minimum delay and the maximum delay. When a microservice receives
    an API call, it will automatically assign a random delay value between the configured
    minimum delay and maximum delay, and then wait for that time before it responds
    to the consumer’s API calls.
  prefs: []
  type: TYPE_NORMAL
- en: The feature is very helpful for simulating a cascading system failure. As will
    be shown later in this chapter, the response delay feature can also help demonstrate
    the value of using AI services to enhance the operations of the MSA system compared
    to using the short circuit traffic pattern previously explained in [*Chapter 3*](B18934_03.xhtml#_idTextAnchor039).
  prefs: []
  type: TYPE_NORMAL
- en: 'The response delay is enabled whenever the max delay is configured with a value
    greater than zero. When the value of max delay is higher than zero, a delay value
    is assigned to the microservice API’s call response, as shown in the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The max and min delay values can be configured using an API call. The following
    is an example of using `curl` to send an API call to configure the maximum and
    minimum delay response in milliseconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Again, this feature is only for demo and test purposes. A more secure way of
    simulating a delay is using secured configuration files or local parameters instead.
  prefs: []
  type: TYPE_NORMAL
- en: The API response error simulator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Similar to the response delay simulator, this feature is for demo purposes only.
    The API error simulator feature uses one configurable value – the average HTTP
    error per hour. When the feature is enabled in the microservice, the microservice
    will pick a randomly applicable server 500 error and respond to API requests with
    randomly paced responses that match the configured error rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'The error rate can be configured using an API call. The following is an example
    of using `curl` to send an API call to configure an API error response rate of
    `5` HTTP errors per hour:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now, we know the testing and simulation tools available for us to use for training,
    testing, and simulating production for our MSA system.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will discuss our ABC-Intelligent-MSA operations – how
    to initialize the system, how to build and use training and testing data, and
    how to simulate the system’s production traffic.
  prefs: []
  type: TYPE_NORMAL
- en: The intelligent MSA system in action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections of this chapter, we discussed how the different system
    components interact with each other and what tools we use to build the AI algorithms,
    test the system, and monitor the operations of different components.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will put our ABC-Intelligent-MSA to the test. We will run
    all system microservices and tools, and see how the different system components
    actually interact with each other, what results we see, and how we can tweak the
    system to maintain smooth end-to-end operations.
  prefs: []
  type: TYPE_NORMAL
- en: The ABC-Intelligent-MSA will first run under an ideal simulation environment
    (no error simulation and no delays) to collect the training data necessary to
    build the AI models. Once enough data has been collected, we will then train the
    models and prepare the system for actual production traffic.
  prefs: []
  type: TYPE_NORMAL
- en: 'The system initialization steps, therefore, are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start the system with no AI services to collect the necessary training data
    under an ideal operational situation and create an operational baseline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sanitize the collected data if needed and remove outliers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the AI algorithms using the training data collected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Re-initialize the system with all of its AI services.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start production operations. In our example here, we will simulate actual production
    operations by injecting errors, data delay responses, service failures, and so
    on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initializing the ABC-Intelligent-MSA system
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We start by initializing our MSA system using the system’s Docker compose file,
    `abc_ msa.yaml`, and using the `docker-compose` command as follows,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As discussed previously in [*Chapter 9*](B18934_09.xhtml#_idTextAnchor102),
    the preceding `docker-compose` command is much more convenient than using multiple
    `docker run` commands. `docker-compose` will read the system’s run parameters
    and configuration from the `abc _msa.yaml` file, and initialize all the system
    components accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, this will start the analysis and monitoring tools, along with
    all the regular microservices in the system. Since we are still collecting training
    data, no AI services need to be initialized yet.
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *Figure 10**.2* and *Figure 10**.4*, when we start the AI services
    (the PBW and PAD), they will need to be able to remotely control (start, stop,
    and restart) the system’s Docker containers. The PBW and PAD are designed to control
    the Docker containers using API calls. Therefore, we need to enable Docker Engine
    first to respond to API calls and for the PBW and PAD to be able to successfully
    communicate with Docker Engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the steps needed to enable Docker’s API remote management:'
  prefs: []
  type: TYPE_NORMAL
- en: On your Ubuntu system, use `vi`, `vim`, or any other similar tool to edit the
    `/``lib/systemd/system/docker.service` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Look for the `ExecStart` entry and make the necessary modifications for it
    to be like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will enable Docker Engine to listen to API calls. Make sure you save the
    file after the modifications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Reload Docker Engine using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To ensure Docker Engine is working properly and responding to API calls, use
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, the system is running and collecting training data. The longer you run
    the system, the more training data will be collected, and the more accurate your
    AI models will be. In our example, we will leave the system running for approximately
    48 hours.
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will go over how to run the tools, build training
    data, collect some of the system performance logs, simulate real-time system operations,
    and analyze the collected performance data.
  prefs: []
  type: TYPE_NORMAL
- en: Building and using the training data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `ms_perfmon` tool will create a separate stat file for each microservice
    in the `<ms_perfmon's working path>/perfmon_stats` directory. It is important
    that we leave the tool running and monitor the system’s performance stats under
    minimal load conditions.
  prefs: []
  type: TYPE_NORMAL
- en: We recommend at least 48 hours of training data collection. Ideally, however,
    data should be collected with seasonality load whenever applicable. In some environments,
    for example, the system load may increase on weekends over weekdays, during the
    shopping season, and so on. These situations should be considered in the training
    data to be able to build a more accurate AI model.
  prefs: []
  type: TYPE_NORMAL
- en: Performance data is pulled every 10 seconds, and accordingly, with 48h of active
    monitoring, `ms_perfmon` produces 17,280 entries for each microservice.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the length of the system’s training period, whenever enough performance
    data has been collected, the `training_data_cleanup.py` tool should be run to
    detect any outliers and sanitize the performance data before using it in our AI
    services.
  prefs: []
  type: TYPE_NORMAL
- en: The `training_data_cleanup` tool scrubs all the performance data files in the
    `<ms_perfmon's working path>/perfmon_stats` directory, and automatically creates
    a `scrubbed_stats` directory with all the scrubbed data for each microservice.
    These scrubbed files are the files that we will later use for training the AI
    services.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are now ready to write our Python code for training the PBW:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `numpy` library for array and scientific data processing, `pandas`
    for reading our CSV training data files and testing data, and `sklearn` to build
    our AI model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After importing the required libraries, we now need to copy all performance
    data into a DataFrame object. The following is a code example of this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The PBW’s AI model includes the microservice response time, the calculated request
    failure rate, and the calculated microservice load. The model should calculate
    the expected response time based on all the preceding parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our Python code, we need to point to the data column that needs to be predicted.
    In our example, that would be the response time. The following is a code snippet
    for the Payment microservice:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need now to build our model, but before doing so, we need to load the rest
    of the performance data column into an array for training and testing processing.
    We do that by removing the “response time” column (an axis of `1`) from the created
    DataFrame and then loading that DataFrame into an array to be used in our `sklearn`
    object, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The model data need to be split into training data and test data. We split
    the model data into 80% training and 20% test data as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we build the model from the training data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Save the data to a CSV file for future use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, we have the training data and the trained model. It is time to use the
    model for production traffic.
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will simulate production operations and describe
    how that can be applied to our trained MSA system, the ABC-Intelligent-MSA.
  prefs: []
  type: TYPE_NORMAL
- en: Simulating the ABC-Intelligent-MSA’s operation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to reinitialize the system now with the trained model and production
    traffic. Since no actual production traffic is applied in our example, we need
    to simulate the production operation with its potential operational challenges,
    including high traffic loads, service failures, and potential network hiccups.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by reinitializing the ABC-Intelligent-MSA system using `docker-compose`,
    as described earlier, but using the `abc_intelligent_msa.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The main difference between `abc_intelligent_msa.yaml` and `abc _msa.yaml` is
    that the first file includes the initialization of the AI services.
  prefs: []
  type: TYPE_NORMAL
- en: Once the system is running, the AI tools will start monitoring and collecting
    the microservice’s performance and trigger healing actions whenever a system problem
    is detected and metrics exceed the configured performance thresholds.
  prefs: []
  type: TYPE_NORMAL
- en: The production traffic is ready to be simulated now using the `simulate_api_rqsts`
    API traffic simulator and the response delay simulator function discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Using the API response error simulator, occasional HTTP errors can also be simulated
    if needed. A more sophisticated simulation would involve injecting HTTP 500 error
    codes as well, but we will stick to response time performance delays for simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: The `ms_perfmon` tool will still be running to collect data for our offline
    analysis whenever needed.
  prefs: []
  type: TYPE_NORMAL
- en: We now need to simulate specific production use cases and see how the AI tools
    will respond and self-heal the entire system. In the next section, we will discuss
    the operations of the PBW and PAD and look into how both AI services interact
    with system performance readings and errors.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing AI service operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding sections, we started by building our first AI service and covered
    how to use AI to enhance the MSA system’s operations and resilience, the self-healing
    process, and the tools we built to generate training data and simulate the ABC-Intelligent-MSA
    system’s operation.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will examine the system logs and check how the PBW and PAD
    interact with the system and actually enhance its operations. We will then simulate
    a cascading system failure and examine how the self-healing process is triggered
    and handled to bring the MSA system back to normal operation.
  prefs: []
  type: TYPE_NORMAL
- en: The PBW in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'During the training period, the PBW was able to build an AI model and calculate
    the expected response time of each microservice in the ABC-Intelligent-MSA system.
    As you can see from the following log sample, under a normal system load, the
    average response time of the Inventory microservice is about 20 ms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We configured the warning threshold for the PBW as 250 ms, and the action threshold
    as 750 ms. We will now start introducing an API call load to the Inventory microservice
    using `simulate_api_rqsts` and delays using the response delay simulator feature.
    Then, we will see how the PBW reacts from the PBW action logs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the PBW’s performance readings for about 1.5 minutes. As
    you can see from the readings, the response time is consistently above the 250
    ms alarm threshold, but (with the exception of one reading) still below the 750
    ms action threshold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The readings will have to be consistently above the 750 ms action threshold
    for the PBW to trigger a healing action. One reading above 750 ms is not enough
    for an action to be triggered. However, since the readings are constantly above
    the 250 ms alarm threshold, the PBW is expected to trigger an alarm to the NMS/OSS
    system.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to verify the PBW’s behavior from the NMS/OSS system or the PBW’s action
    log. The following is a snippet of the PBW’s action log during the same period
    from the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the preceding snippet’s last 4 log entries, after a consistent
    delay of more than 250 ms, an alarm was triggered and sent to the NMS/OSS system.
    We need to increase the inventory microservice’s load and response time to see
    how the PBW will react.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is another snippet of the PBW’s performance log. Only the last
    4 log entries in a series of 10 consistent response delay readings are above 750
    ms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Normally, we would have configured all healing actions shown in *Table 10.1*.
    In our demo system, however, we have configured only one healing action to demo
    the system self-healing operations in general. We only configured a microservice
    container to restart if a problem is experienced in the microservice. The response
    delay simulator feature is therefore a more relevant simulation tool than the
    other tools we have mentioned earlier.
  prefs: []
  type: TYPE_NORMAL
- en: In case of slow performance due to high API call requests volume, the most appropriate
    healing action would be to try to scale the microservice first and allocate more
    resources to respond to the high volume of API requests.
  prefs: []
  type: TYPE_NORMAL
- en: We assume in our simulation that the problem in the Inventory microservice is
    not necessarily due to the API request load, but rather some unforeseen problem
    causing the Inventory service to become unstable and unable to handle API calls
    promptly, so restarting the Inventory microservice could therefore fix the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, here is a look at the PBW’s action log during the same period. Please
    note that prior to the actionably high response time, an alarmingly high response
    time below 750 ms was previously detected. The response time was higher than 250
    ms and below 750 ms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As you see from the last 4 entries in the action log, the PBW detected a consistent
    response time (above 750 ms) and accordingly sent a red alarm to the NMS/OSS system,
    indicating a critical delay in the Inventory service and the need for a self-healing
    action to be taken. The PBW then locked the Inventory microservice to avoid clashing
    with healing actions from other AI services. The PBW then restarted the Inventory
    microservice by sending a restart API call to Docker Engine, verified that the
    Inventory microservice was back online, and finally unlocked the Inventory microservice.
  prefs: []
  type: TYPE_NORMAL
- en: 'To restart a Docker container through API, you will need to send a `POST` request
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also specify the number of seconds to wait before restarting the container
    using a `t` parameter. The following is a container restart `POST` example to
    restart the Inventory service container after a 10-second wait time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: For more information on how to control Docker Engine using API calls, check
    the Docker Engine API documentation at [https://docs.docker.com/engine/api/version-history/](https://docs.docker.com/engine/api/version-history/).
  prefs: []
  type: TYPE_NORMAL
- en: However, was the PBW able to fix the Inventory microservice problem?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go back now to the PBW’s performance log and see how this self-healing
    action impacted the Inventory service performance. The following are the log entries
    just before the healing action was triggered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Sure enough, the response time dropped from above 1 s to a maximum of 170 ms.
    Not as low as it was before the problem appeared, but the Inventory microservice
    for sure has some breathing room now. The performance issues may very well return
    if the underlying problem is not attended to and properly fixed.
  prefs: []
  type: TYPE_NORMAL
- en: In a more advanced AI model, we can train and configure the system to take more
    sophisticated actions to fully resolve the problem whenever needed, but in this
    book, we are limited to a specific scope to be able to demonstrate the idea in
    principle and pave the way for you to develop your own AI models and algorithms
    for your specific use cases.
  prefs: []
  type: TYPE_NORMAL
- en: We have demonstrated in this section how the PBW works and how an action is
    triggered when a microservice performance issue is detected. In the following
    section, we will go over the PAD AI service and how the PAD takes a rather more
    holistic view of the entire system.
  prefs: []
  type: TYPE_NORMAL
- en: The PAD in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The best way to demonstrate the operations of the PAD is to simulate a cascading
    failure and see how the PAD can bring the MSA system back to normal operation.
  prefs: []
  type: TYPE_NORMAL
- en: To simulate a cascading failure and ensure that the PAD responds to the failure
    and tries to auto-heal, we will first need to disable the PBW AI service. This
    will prevent the PBW from triggering a healing action and prevent it from trying
    to resolve the problem before the PAD’s healing action(s) kick in.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s quickly revisit what we have previously discussed in [*Chapter 3*](B18934_03.xhtml#_idTextAnchor039),
    an example of how a cascading failure happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in *Figure 10**.5*, under heavy API traffic, a failure to the Inventory
    microservice could cause the **Payment** microservice to pile up too many API
    calls in the queue, waiting for a response from the Inventory service. Eventually,
    these API calls will consume and exhaust the available resources in the **Payment**
    microservice, causing it to fail. A failure in the Payment microservice will produce
    a similar situation in the **Order** microservice, and eventually, produce a failure
    for the **Order** microservice as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5: The Payment microservice is down](img/B18934_10_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.5: The Payment microservice is down'
  prefs: []
  type: TYPE_NORMAL
- en: For the PAD to respond with healing actions, each of the PAD’s detected anomaly
    types has to have healing actions defined for it.
  prefs: []
  type: TYPE_NORMAL
- en: To successfully simulate the cascading failure, we only defined an action for
    a cascading failure situation. Otherwise, the PAD would automatically detect the
    failure in the Inventory service and self-heal it by restarting the Inventory
    microservice container, preventing a cascading failure from happening to begin
    with.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by simulating a high volume of orders for the Order microservice
    and see how the system is going to respond to this situation in general, and specifically
    how the PAD will react under the situation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To simulate a high volume of order requests, use the following `simulate_api_rqsts`
    command to target the Order microservice with a fixed uniformly paced order requests
    of 100,000 per minute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We will now shut down the Inventory microservice and examine the PAD action
    logs. The following is a snippet of the log about a minute after the PAD started
    to detect a failure in the Inventory microservice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please note that we introduced sudden high-volume traffic into the system.
    This sudden traffic increase by itself is a traffic pattern anomaly that was picked
    up by the PAD, but the PAD did not respond to that specific anomaly because no
    healing action is specifically defined for that anomaly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding snippet of the PAD log, the PAD automatically recognized the
    Inventory service failure since no response traffic was detected from the service.
    However, no action was taken by the PAD since no healing action was defined for
    that particular anomaly. Since the anomaly was consistent for more than 1 minute,
    the PAD sent an alarm to the NMS/OSS system to notify the system admins of the
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the Inventory microservice failure, the Payment microservice started
    to run out of resources, and the PAD picked up an unusually slow traffic flow
    from the Payment microservice given the API call request load applied. Accordingly,
    and as seen in the log, a little over 1 minute later, the PAD started to generate
    alarms to NMS/OSS.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the following PAD log, a few minutes after the Payment microservice
    anomaly, the Order microservice started acting up, and accordingly, the PAD was
    able to correlate all these anomalies and detect a potential cascading failure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Please note that the only microservice failure we have so far is the one we
    manually shut down, the Inventory microservice. Both the Payment and Order microservices
    are still up and running but, as it seems from the log, may be suffering from
    resource exhaustion.
  prefs: []
  type: TYPE_NORMAL
- en: The system is still running so far, and should the Inventory service return
    back online, the system will automatically recover. The user experience during
    the heavy load would only be slow performance during the ordering process, but
    no orders have been denied or failed yet.
  prefs: []
  type: TYPE_NORMAL
- en: By examining all these previously mentioned PAD action logs, and as the situation
    stands so far, we are still okay. However, if no action is taken to resolve the
    Inventory microservice problem, the system will eventually fail and user orders
    will start to be denied.
  prefs: []
  type: TYPE_NORMAL
- en: The short circuit traffic pattern discussed in [*Chapter 3*](B18934_03.xhtml#_idTextAnchor039)
    helps prevent a cascading failure from taking place, but it still cannot resolve
    the underlying problem. User orders in a traditional short circuit pattern implantation
    will still be rejected until manual intervention fixes the Inventory microservice.
  prefs: []
  type: TYPE_NORMAL
- en: That’s where the PAD comes in. Check the following PAD action log!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The PAD was able to detect the cascading failure before it actually happened,
    and was able to identify the root cause of the problem. The PAD sent a red alarm
    to the NMS/OSS system, declared a self-healing lock state on the Inventory service
    to try to fix the problem’s root cause, was able to successfully restart the Inventory
    microservice container, and then cleared the self-healing lock on the Inventory
    service.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now check the microservices performance logs and ensure that the problem
    is fixed and that the ABC-Intelligent-MSA system and all of its microservices
    are running normally.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the Inventory microservice’s performance log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the Payment microservice’s performance log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the Order microservice’s performance log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: As shown for the preceding Inventory, Payment, and Order microservices, all
    of those microservices are back online with normal performance readings. The system
    is now back to normal operation and should be able to handle the production load
    with no issues.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter walked us through how we can build AI models to build an intelligent
    MSA system step by step. We accordingly built two main AI services – the PBW and
    the PAD – and leveraged these AI services to enhance our MSA demo system, ABC-MSA,
    to build an intelligent MSA system that we named ABC-Intelligent-MSA.
  prefs: []
  type: TYPE_NORMAL
- en: We explained the self-healing process design and dynamics in detail, as well
    as the tools we built to develop AI training data, how to simulate production
    operations, and how to measure the demo system’s performance. We then put the
    ABC-Intelligent-MSA to test, simulated a couple of use cases to demonstrate AI
    functions within the MSA system, and carefully examined the logs of our demo AI
    services to showcase the value of using AI in MSA.
  prefs: []
  type: TYPE_NORMAL
- en: Everything explained in this chapter is just an example of using AI in an MSA
    system. Enterprises should consider using AI services that are specifically appropriate
    for their own MSA system and use cases. These AI tools may very well be available
    through third parties or built in-house whenever needed.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss the transformation process from a traditional
    MSA system to an intelligent MSA system – the things to consider in greenfield
    and brownfield implementations, and how to avoid integration challenges to make
    the corporate transformation as smooth as possible.
  prefs: []
  type: TYPE_NORMAL
