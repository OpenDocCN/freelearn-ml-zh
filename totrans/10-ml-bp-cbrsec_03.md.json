["```py\npip install –r requirements.txt\n```", "```py\nimport pandas as pd\nimport numpy as np\nimport os\nfrom requests import get\n```", "```py\ntrain_data_page = \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\"\ntest_data_page = \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.testdata.unlabeled_10_percent.gz\"\nlabels =\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names\"\ndatadir = \"data\"\n```", "```py\n# Download training data\nprint(\"Downloading Training Data\")\nos.system(\"wget \" + train_data_page)\ntraining_file_name = train_data_page.split(\"/\")[-1].replace(\".gz\",\"\")\nos.system(\"gunzip \" + training_file_name )\nwith open(training_file_name, \"r+\") as ff:\n  lines = [i.strip().split(\",\") for i in ff.readlines()]\nff.close()\n# Download training column labels\nprint(\"Downloading Training Labels\")\nresponse = get(labels)\nlabels = response.text\nlabels = [i.split(\",\")[0].split(\":\") for i in labels.split(\"\\n\")]\nlabels = [i for i in labels if i[0]!='']\nfinal_labels = labels[1::]\n```", "```py\ndata = pd.DataFrame(lines)\nlabels = final_labels\ndata.columns = [i[0] for i in labels]+['target']\nfor i in range(len(labels)):\n  if labels[i][1] == ' continuous.':\n    data.iloc[:,i] = data.iloc[:,i].astype(float)\n```", "```py\ndata.head()\n```", "```py\ndata['target'].value_counts()\n```", "```py\ndata_resampled = data.loc[data[\"target\"].isin([\"normal.\",\"teardrop.\"])]\ndef map_label(target):\n  if target == \"normal.\":\n    return 0\n  return 1\ndata_resampled[\"Label\"] = data_resampled [\"target\"].apply(map_label)\n```", "```py\nmu = data_resampled ['wrong_fragment'].mean()\nsigma = data_resampled ['wrong_fragment'].std()\ndata_resampled[\"Z\"] = (data_resampled ['wrong_fragment'] – mu) / sigma\n```", "```py\ndata_resampled[\"Z\"].plot.density()\n```", "```py\ndef map_z_to_label(z):\n    if z > 2 or z < -2:\n      return 1\n    return 0\ndata_resampled[\"Predicted_Label\"] = data_resampled[\"Z\"].apply(map_z_to_label)\n```", "```py\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nconfusion = confusion_matrix(data_resampled[\"Label\"],\n                data_resampled[\"Predicted_Label\"])\nplt.figure(figsize = (10,8))\nsns.heatmap(confusion, annot = True, fmt = 'd', cmap=\"YlGnBu\")\n```", "```py\nfrom sklearn.covariance import EllipticEnvelope\nactual_labels = data4[\"Label\"]\nX = data4.drop([\"Label\", \"target\",\n                \"protocol_type\", \"service\",\n                \"flag\"], axis=1)\nclf = EllipticEnvelope(contamination=.1,random_state=0)\nclf.fit(X)\npredicted_labels = clf.predict(X)\n```", "```py\npredicted_labels_rescored =\n[1 if pred == -1 else 0 for pred in predicted_labels]\n```", "```py\nfrom sklearn.neighbors import LocalOutlierFactor\nactual_labels = data[\"Label\"]\nX = data.drop([\"Label\", \"target\",\n                \"protocol_type\", \"service\",\n                \"flag\"], axis=1)\nk = 5\nclf = LocalOutlierFactor(n_neighbors=k, contamination=.1)\npredicted_labels = clf.fit_predict(X)\n```", "```py\nfrom sklearn.neighbors import LocalOutlierFactor\nactual_labels = data4[\"Label\"]\nX = data4.drop([\"Label\", \"target\",\"protocol_type\", \"service\",\"flag\"], axis=1)\nall_accuracies = []\nall_precision = []\nall_recall = []\nall_k = []\ntotal_num_examples = len(X)\nstart_k = 100\nend_k = 3000\nfor k in range(start_k, end_k,100):\n  print(\"Checking for k = {}\".format(k))\n  # Fit a model\n  clf = LocalOutlierFactor(n_neighbors=k, contamination=.1)\n  predicted_labels = clf.fit_predict(X)\n  predicted_labels_rescored = [1 if pred == -1 else 0 for pred in predicted_labels]\n  confusion = confusion_matrix(actual_labels, predicted_labels_rescored)\n  # Calculate metrics\n  accuracy = 100 * (confusion[0][0] + confusion[1][1]) / total_num_examples\n  precision = 100 * (confusion[1][1])/(confusion[1][1] + confusion[1][0] + 1)\n  recall = 100 * (confusion[1][1])/(confusion[1][1] + confusion[0][1] + 1)\n  # Record metrics\n  all_k.append(k)\n  all_accuracies.append(accuracy)\n  all_precision.append(precision)\n  all_recall.append(recall)\n```", "```py\nplt.plot(all_k, all_accuracies, color='green', label = 'Accuracy')\nplt.plot(all_k, all_precision, color='blue', label = 'precision')\nplt.plot(all_k, all_recall, color='red', label = 'Recall')\nplt.show()\n```", "```py\nfrom sklearn.neighbors import DBSCAN\nactual_labels = data4[\"Label\"]\nX = data4.drop([\"Label\", \"target\",\"protocol_type\", \"service\",\"flag\"], axis=1)\nepsilon = 0.2\nminimum_samples = 5\nclf = DBSCAN( eps = epsilon,  min_samples = minimum_samples)\npredicted_labels = clf.fit_predict(X)\n```", "```py\nfrom sklearn import svm\nactual_labels = data4[\"Label\"]\nX = data4.drop([\"Label\", \"target\",\"protocol_type\", \"service\",\"flag\"], axis=1)\nclf = svm.OneClassSVM(kernel=\"rbf\")\nclf.fit(X)\npredicted_labels = clf.predict(X)\n```", "```py\nfrom sklearn.ensemble import IsolationForest\nactual_labels = data[\"Label\"]\nX = data.drop([\"Label\", \"target\",\"protocol_type\", \"service\",\"flag\"], axis=1)\nclf = IsolationForest(random_state=0).fit(X)\npredicted_labels = clf.predict(X)\n```", "```py\npredicted_labels_rescored =\n[1 if pred == -1 else 0 for pred in predicted_labels]\n```", "```py\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,\n                        actual_labels,\n                        test_size=0.33,\n                        random_state=42,\n                        stratify=actual_labels)\nX_train = np.array(X_train, dtype=np.float)\nX_test = np.array(X_test, dtype=np.float)\n```", "```py\ninput = keras.Input(shape=(X_train.shape[1],))\nencoded = layers.Dense(30, activation='relu')(input)\nencoded = layers.Dense(16, activation='relu')(encoded)\nencoded = layers.Dense(8, activation='relu')(encoded)\n```", "```py\ndecoded = layers.Dense(16, activation='relu')(encoded)\ndecoded = layers.Dense(30, activation='relu')(decoded)\ndecoded = layers.Dense(X_train.shape[1], activation='sigmoid')(encoded)\n```", "```py\nautoencoder = keras.Model(input, decoded)\n```", "```py\n# Encoder\nencoder = keras.Model(input_img, encoded)\n# Decoder\nencoded_input = keras.Input(shape=(encoding_dim,))\ndecoder_layer = autoencoder.layers[-1]\ndecoder = keras.Model(encoded_input,decoder_layer(encoded_input))\n```", "```py\nautoencoder.compile(optimizer='adam', loss='mse')\nautoencoder.summary()\n```", "```py\nautoencoder.fit(X_train, X_train,\n                epochs=10,\n                batch_size=256,\n                shuffle=True)\n```", "```py\nfrom sklearn.metrics import mean_squared_error\npredicted = autoencoder.predict(X_test)\nerrors = [np.linalg.norm(X_test[idx] - k[idx]) for idx in range(X_test.shape[0])]\n```", "```py\nthresh = np.percentile(errors, 99)\npredicted_labels = [1 if errors[idx] > thresh else 0 for idx in range(X_test.shape[0])]\n```"]