- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Applying Power BI ML Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 10*](B19500_10.xhtml#_idTextAnchor139), we reviewed the results
    of training and testing all three of your ML models. Your options for future iterations
    and plans for your ML models were reviewed and discussed. The Predict Damage ML
    and Predict Height ML models had promising testing results, while the Predict
    Size ML model had room for improvement. For all three of your models, the best
    next steps were to review the results with your stakeholders, and, if possible,
    meet with your data science team to determine whether more advanced tooling and
    techniques could improve upon your initial work.
  prefs: []
  type: TYPE_NORMAL
- en: For this chapter, you will apply the ML models that you built to new data from
    the FAA Wildlife Strike database. The data used up to this point in the book ended
    on October 16, 2022\. The new data for this chapter will be reports that have
    been added to the publicly available data between that date and March 11, 2023\.
    The purpose of this chapter will be to review the process through which you can
    bring in new data and automate the process to score it and make predictions with
    your ML models. At the end, you will review the results of your newly scored data
    to see whether the results are similar to the ML testing done on the ML models
    by Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As always, make sure you have access to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The FAA Wildlife Strike data files from either the FAA website or the Packt
    GitHub site
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Power BI Pro license
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the following Power BI licensing options for access to Power BI dataflows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Power BI Premium
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Power BI Premium Per User
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the following options for getting data into the Power BI cloud service:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft OneDrive (with connectivity to the Power BI cloud service)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Access + Power BI Gateway
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Data Lake (with connectivity to the Power BI cloud service)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Power BI Desktop April 2023 or later (no licenses required)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bringing the new FAA Wildlife strike data into Power BI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Meetings with project stakeholders and data science teams will determine the
    best next steps for your Power BI ML models. In the meantime, you can apply these
    ML models to new data and then compare the predictions to real results. Taking
    these steps will help you learn how to add your ML models to an automated refresh
    process in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading and configuring the new FAA Wildlife Strike data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As in [*Chapter 1*](B19500_01.xhtml#_idTextAnchor015), you should begin by
    downloading a new copy of the FAA Wildlife Strike data. The copy you’ve been using
    to date for this book contained data through October 16, 2022\. Now, you’ll pull
    in new data to score with the Power BI ML models that were trained and tested
    with historical data. The new file contains data through March 1, 2023\. You can
    download a copy of the text file used for this part of the book at the Packt GitHub
    site here: [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-11/STRIKE_REPORTS_new.txt](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-11/STRIKE_REPORTS_new.txt).'
  prefs: []
  type: TYPE_NORMAL
- en: In a real-world data project, the most common path of action would be to either
    update the source file with the newer version of the file or have an automated
    incremental refresh process data from the source on a schedule. Since we are just
    using this data to test against your ML models, and since this is a simple workshop,
    the instructions for this book will pull in the new data as a separate query in
    a dataflow. As a separate query, the original source data will still exist unchanged
    in case source-to-target comparisons for the ML models are needed.
  prefs: []
  type: TYPE_NORMAL
- en: Power BI can automate data pulls from many sources, but the source of the FAA
    Wildlife Strike data is an Access database in a zip file that cannot easily be
    pulled into Power BI automatically. If you’d like to automate the process of downloading
    the FAA Wildlife Strike data from the web for your own future use, you’ll need
    to configure a nightly pull using a tool such as Azure Data Factory. Azure Data
    Factory and other data movement tools are outside the scope of this book, but
    plenty of online documentation should be able to guide you through the process
    of a nightly pull that serves up a file for storage in a destination such as Azure
    Data Lake or Azure SQL Database.
  prefs: []
  type: TYPE_NORMAL
- en: For the example provided in the book, an assumption will be made that the text
    file from the Packt GitHub site was downloaded and added to OneDrive. If you use
    another method, you should be able to easily adjust the source of the Power BI
    dataflow in the proceeding instructions.
  prefs: []
  type: TYPE_NORMAL
- en: Adding new FAA Wildlife Strike data to the Strike Reports dataflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once the new file of FAA Wildlife Strike data is in OneDrive, you can add it
    to the Power BI Cloud service using dataflows. First, open up the dataflow named
    **Strike Reports** and navigate to the **Edit Tables** screen. Follow these steps
    to add the new data to the **Raw** **Data** group:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to **Get Data** | **Text/CSV**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`STRIKE_REPORTS_new.txt` file.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Select** and then click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move the query to the **Raw** **Data** group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If `Changed column type` was added to **Applied steps**, remove it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename the query `Strike` `Reports New`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, you can add a version of the new strike reports query to the **Curated
    Queries** group, which will be prepped for use with ML queries.
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on **Strike Reports New** and select **Reference**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move the new file to the **Curated Report** **Queries** group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename the file `Strike Reports` `Curated New`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, you replicate the logic of the `02 Curated Data – Strike Reports Curated
    New.M` from the Packt GitHub site at this link: [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-11](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-11).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Your **Strike Reports** dataflow should now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – The Strike Reports dataflow with queries for new data added](img/B19500_11_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – The Strike Reports dataflow with queries for new data added
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve added the new queries, go ahead and process the dataflow. Now you
    are ready to move on to the **ML Queries** dataflow, which will be used to prep
    the data for Power BI ML. You will apply the same filter and transformation criteria
    to the new data before running it through the ML models to be scored.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming the new data to prep it for scoring with Power BI ML queries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to prep the new FAA Wildlife Strike data to be scored by the three
    Power BI ML models, start by opening up the **Edit Tables** view for the **ML
    Queries** dataflow. Once it’s open, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Get data** | **Dataflows**, and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Strike Reports Curated New**, and click **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move the new query to the **Sources** group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click **Strike Reports Curated New** and uncheck **Enable load** so that
    you don’t store a duplicate copy of the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now you are ready to create new queries that will be transformed and filtered
    to meet the criteria of your Power BI ML models!
  prefs: []
  type: TYPE_NORMAL
- en: Your next step is to recreate the logic that was created for each of the three
    ML models, and then apply that logic to the new FAA Wildlife Strike data. The
    ML models are trained for specific filter and transformation criteria applied
    to rows of data through 10/16/2022\. You will be applying that same filter and
    transformation steps to the data that was added to the database after 10/16/2022
    so that it can be scored by the ML models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rather than walking through the process of cutting and pasting from the existing
    queries, you can use the M queries from the Packt GitHub repository at this link:
    [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-11](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-11).
    Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new group in the **ML Queries** dataflow called **ML** **Scoring Queries**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Get data** | **Blank query**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the M code from the Packt GitHub site from the query titled `03 ML Scoring
    Queries - Predict Damage` `ML Score.M`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste that code into the blank query field and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename the query `Predict Damage ML Score` and move it to the **ML Scoring**
    **Queries** group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *steps 2-5* for the query from the Packt GitHub site named `04 ML Scoring
    Queries - Predict Size ML Score.M` and name the query `Predict Size` `ML Score`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *steps 2-5* for the query from the Packt GitHub site named `05 ML Scoring
    Queries - Predict Height ML Score.M` and name the query `Predict Height` `ML Score`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Save & close** to save and close your dataflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Your **ML Queries** dataflow should now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – The new group of queries added that will be used to score the
    new data with Power BI ML models](img/B19500_11_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.2 – The new group of queries added that will be used to score the
    new data with Power BI ML models
  prefs: []
  type: TYPE_NORMAL
- en: Now you have the new FAA Wildlife Strike data ready to go for scoring with Power
    BI ML models! The new data, which was not used to train or test the original ML
    models, and which was added to the source database after the original data, has
    now been prepped for scoring so that you can evaluate the utility of your ML models
    when used with newly generated data.
  prefs: []
  type: TYPE_NORMAL
- en: Applying Power BI ML models to score new FAA Wildlife Strike data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After 11 chapters of work, you are finally ready to run new data through your
    Power BI ML models and evaluate the resulting predictions! You will run through
    the process of applying each ML model to the new data, and then browse the results
    of the scoring to compare predictions with the real results.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Predict Damage ML model in Power BI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You will now reference the **Predict Damage ML Score** data from the **ML Queries**
    dataflow against the **Predict Damage ML** model so that it can be scored. *Figure
    11**.3* is a quick summary of the data that you have used to train, test, and
    now apply the **Predict Damage** **ML Model**:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Training** | **Testing** | **Apply (new)** |'
  prefs: []
  type: TYPE_TB
- en: '| Rows | 10,165 | 4,326 | 653 |'
  prefs: []
  type: TYPE_TB
- en: '| Date Range | >= 1/1/2014 & <= 10/16/2022 | >= 1/1/2014 & <= 10/16/2022 |
    > 10/16/2022 & <= 3/1/2023 |'
  prefs: []
  type: TYPE_TB
- en: Figure 11.3 – Details about data used for training, testing, and applying new
    data to Predict Damage ML
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to add the new data to the **Edit Tables** view of the **Predict
    Damage** **ML** dataflow:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Get data** | **Dataflows**, and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Predict Damage ML Score** from the **ML Queries** dataflow and click
    **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Save &** **close**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Refresh the **Predict Damage** **ML** dataflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now you can apply **Predict Damage ML** model to score the new data. First,
    navigate to the ML model and click on the icon to apply the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4 – Icon to apply the ML model](img/B19500_11_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.4 – Icon to apply the ML model
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, select the query for the new data to be scored, and enter the threshold
    you’d like to use as the cutoff for predicting damage. As you recall from [*Chapter
    9*](B19500_09.xhtml#_idTextAnchor125), the probability threshold with maximum
    profit was 0.74, but you can choose any value between **0** and **1**. The following
    example shows **0.5**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Choosing the input table and threshold for applying the ML
    model](img/B19500_11_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5 – Choosing the input table and threshold for applying the ML model
  prefs: []
  type: TYPE_NORMAL
- en: When you click **Save and apply**, the **Predict Power BI ML** model will be
    used to make predictions about incidents for the new data! If the new data were
    changing at a cadence, you could set the dataflow to refresh and it would score
    the new data automatically on a schedule.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the scoring of the dataflow has been completed, you will have access to
    two new tables in the **Predict Damage ML** dataflow. During the writing of this
    book, some queries needed to be reauthenticated. If you get an error, you may
    need to follow the prompts within a query that has a yellow warning icon and save
    your credentials again. One of these tables will contain the newly scored data,
    and the other will contain explanations about the features that were used to make
    the prediction. Connecting to these dataflow tables from Power BI Desktop, you
    can see that the first table named **Predict Damage ML Score enriched Predict
    Damage ML** contains the rows that were scored, the outcome of the prediction
    based on the probability threshold, the score used to compare with the probability
    threshold, an explanation about the prediction, and an index column, which is
    a foreign key for the second table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.6 – Table of scored new data with predictions and explanations
    added](img/B19500_11_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.6 – Table of scored new data with predictions and explanations added
  prefs: []
  type: TYPE_NORMAL
- en: 'The second table is named **Predict Damage ML Score enriched Predict Damage
    ML explanations** and contains a separate row for each feature that was used to
    make the prediction. During the writing process of this book, an occasional bug
    would show up in the Power BI Service resulting in this table showing as blank
    within the dataflow. If you encounter this bug, connecting to this table using
    Power BI Desktop will allow you to see the data. The **Contribution** field is
    added up to calculate the prediction score value for the first table, which is
    compared to the probability threshold. Negative scores reduce the resulting score,
    and positive scores increase the score:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Table of features explaining the predictions for each scored
    row](img/B19500_11_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.7 – Table of features explaining the predictions for each scored row
  prefs: []
  type: TYPE_NORMAL
- en: 'In the **Power BI Desktop Model** view, you can see that the tables have a
    one-to-many relationship:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Scored data and explanations have a one-to-many relationship](img/B19500_11_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.8 – Scored data and explanations have a one-to-many relationship
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create an interactive report using Power BI to explore the results
    of the ML model scoring new data. First, you review the explanations of the different
    features for a single row of scored data. To clarify, the following screenshot
    is for a single event, indicated by an index of **7**, which was given a prediction
    score of **18.00** and registers as predicting **No Damage** since the prediction
    score of 18 is less than the probability threshold of 50\. You can see that the
    prediction score of 18 is the result of adding up all of the **Contribution**
    values in the table (bottom right) and waterfall chart (bottom left):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Left half – Contribution of features used to predict damage
    for a single wildlife strike incident](img/B19500_11_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.9 – Left half – Contribution of features used to predict damage for
    a single wildlife strike incident
  prefs: []
  type: TYPE_NORMAL
- en: This screenshot has been split into two figures to make sure you can read it.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.10 – Right half – contribution of features used to predict damage
    for a single wildlife strike incident](img/B19500_11_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 – Right half – contribution of features used to predict damage
    for a single wildlife strike incident
  prefs: []
  type: TYPE_NORMAL
- en: 'In the waterfall chart split into *Figure 11**.9* and *Figure 11**.10*, you
    can zoom in to see that the features on the left contributed to keeping the Prediction
    Score low while the features on the right increased the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 – Features contributing to the Prediction Score of 18 for the
    incident](img/B19500_11_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11 – Features contributing to the Prediction Score of 18 for the incident
  prefs: []
  type: TYPE_NORMAL
- en: 'Switching to another incident given an **Index** value of **2**, you’ll see
    that the prediction was a false positive because it predicted damage when none
    was reported. The features that were weighted strongly within the prediction score
    of 85 can be sorted to the top of the table. This type of analysis can help you
    identify features or combinations of features that might contribute to inaccurate
    predictions or features that have little impact on the prediction. For example,
    looking at the explanations, you can see that having hit 2-10 large animals contributed
    to the high prediction score:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.12 – Left half – the incident was predicted to have damage when
    it did not](img/B19500_11_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.12 – Left half – the incident was predicted to have damage when it
    did not
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 11**.12* and *Figure 11**.13* each show half of the screen, to make
    it easier to read.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.13 – Right half – the incident was predicted to have damage when
    it did not](img/B19500_11_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.13 – Right half – the incident was predicted to have damage when it
    did not
  prefs: []
  type: TYPE_NORMAL
- en: 'Using these tables in Power BI, you can also aggregate the results to understand
    differences at scale. For example, in the following report, you can see the **Precision
    %** and **Accuracy** metrics broken down by **Size**, with an adjustable probability
    threshold, distribution buckets for prediction scores, and aggregate values for
    the feature explanations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.14 – Left half – aggregate scoring results for the new rows of
    data](img/B19500_11_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.14 – Left half – aggregate scoring results for the new rows of data
  prefs: []
  type: TYPE_NORMAL
- en: The other half of the screen is shown in *Figure 11**.15*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.15 – Right half – aggregate scoring results for the new rows of
    data](img/B19500_11_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.15 – Right half – aggregate scoring results for the new rows of data
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on **Small** under **Size** to filter the whole page, you can see
    that from an average and median perspective, **Size** being **Small** strongly
    contributes to lower prediction scores:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.16 – Left half – report filtered with Size set to Small](img/B19500_11_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.16 – Left half – report filtered with Size set to Small
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 11**.17* shows the other half of the screen.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.17 – Right half – Report filtered for Size of Small](img/B19500_11_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.17 – Right half – Report filtered for Size of Small
  prefs: []
  type: TYPE_NORMAL
- en: 'You can compare some of the metrics to the values from the Model Performance
    Report that was reviewed in [*Chapter 9*](B19500_09.xhtml#_idTextAnchor125). Remember,
    *Recall* is the percentage of incidents with damage that are likely to be predicted
    as having damage, and *Precision* is the number of records predicted to have damage
    that actually have damage:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Testing** | **New** **data scoring** |'
  prefs: []
  type: TYPE_TB
- en: '| Recall at Probability Threshold .5 | 88% | 80% |'
  prefs: []
  type: TYPE_TB
- en: '| Precision at Probability Threshold .5 | 30% | 29% |'
  prefs: []
  type: TYPE_TB
- en: '| Recall at Probability Threshold .74 | 67% | 59% |'
  prefs: []
  type: TYPE_TB
- en: '| Precision at Probability Threshold .74 | 49% | 49% |'
  prefs: []
  type: TYPE_TB
- en: Figure 11.18 – New data Recall and Precision compared to original testing results
  prefs: []
  type: TYPE_NORMAL
- en: The results for the new data appear to be somewhat consistent with the testing,
    but now you can dive into the data and judge for yourself! You are now ready to
    move on to the **Predict Size ML** model to test it on new data.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Predict Size ML model in Power BI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Applying the new data to the **Predict Size ML** model will be a repetitive
    task compared to what was just done for **Predict Damage ML**. As you recall from
    [*Chapter 10*](B19500_10.xhtml#_idTextAnchor139), the **Predict Size ML** model
    did not get very good results during testing, with a 61% AUC. The ML model probably
    needs either re-evaluation by a data science team or significant work to improve
    the AUC. Scoring new data against the model can still be a valuable exercise to
    help identify areas for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to minimize repetition, here’s a summary of the steps to add new data
    and apply the ML model. Follow these steps to add the new data to the **Edit Tables**
    view of the **Predict Size** **ML** dataflow:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Get data** | **Dataflows**, and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Predict Size ML Score** from the **ML Queries** dataflow and click
    **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Save &** **close**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Refresh the **Predict Size** **ML** dataflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the screen for **Predict Size ML Model**, and click **Apply** **ML
    model**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the **Predict Size ML Score** input table and click **Save &** **apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the scoring is complete, you can pull tables of both the scored data and
    the related feature contributions into Power BI Desktop to review the results.
    You build a similar report for the **Size** predictions as you did for **Damage**
    predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.19 – Left half – evaluation of the Predict Size ML scoring of new
    data](img/B19500_11_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.19 – Left half – evaluation of the Predict Size ML scoring of new
    data
  prefs: []
  type: TYPE_NORMAL
- en: For ease of viewing, *Figure 11**.19* shows the left half of the screen, while
    *Figure 11**.20* shows the right side.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.20 – Right half – evaluation of the Predict Size ML scoring of
    new data](img/B19500_11_020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.20 – Right half – evaluation of the Predict Size ML scoring of new
    data
  prefs: []
  type: TYPE_NORMAL
- en: 'As with the original testing of this ML model, the results were barely better
    than random guessing. Only 119 rows of data met the criteria for the testing,
    which likely adds to the lackluster results. You can compare the results that
    were correctly classified to the original testing outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Size** | **Testing** | **New** **data scoring** |'
  prefs: []
  type: TYPE_TB
- en: '| Small | 70% | 66% |'
  prefs: []
  type: TYPE_TB
- en: '| Medium | 36% | 26% |'
  prefs: []
  type: TYPE_TB
- en: '| Large | 61% | 63% |'
  prefs: []
  type: TYPE_TB
- en: Figure 11.21 – Comparing original test results versus newly scored data for
    Predict Size ML
  prefs: []
  type: TYPE_NORMAL
- en: While the new results are still not good, they do appear to be in the same range
    as the original test results. You can now move on to scoring new data for your
    final ML model, **Predict** **Height ML**!
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Predict Height ML model in Power BI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you did with the **Predict Size ML** model scoring of new data, you can
    follow similar steps starting in the **Edit Tables** view of the **Predict Height
    ML** dataflow to score the new data:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Get data** | **Dataflows**, and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Predict Height ML Score** from the **ML Queries** dataflow and click
    **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Save &** **close**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Refresh the **Predict Height** **ML** dataflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the screen for **Predict Height ML** model, and click **Apply**
    **ML model**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the **Predict Height ML Score** input table and click **Save &** **apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As with the previous two ML models, you can pull tables of both the scored data
    and the related feature contributions into Power BI Desktop to review the results.
    With a regression ML model, you aren’t predicting yes/no or categorical values,
    but rather numeric values that can be compared to the actuals. With a regression,
    there isn’t necessarily a right or wrong answer, but instead, you can compare
    how close the predicted numbers compare to reality. For example, you can predict
    that a plane struck a bird at 2,000 feet above the ground, but is that a good
    prediction if it actually happened at 2,052 feet? The answer to that question
    in the real world depends on the requirements of the stakeholders and end users!
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure illustrates the predicted height, actual height, and contribution
    information for features for the new data scored with the **Predict Height** **ML**
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.22 – Left half – comparing the predicted height to the actual height](img/B19500_11_022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.22 – Left half – comparing the predicted height to the actual height
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.23 – Right half – comparing the predicted height to the actual
    height](img/B19500_11_023.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.23 – Right half – comparing the predicted height to the actual height
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously in the book, the actual **Height** values tend to land
    on round numbers in the hundreds or thousands. For example, 8 reports in the new
    data illustrated here were recorded to be at 4,000 feet. Is this due to rounding
    by the report filer? Is it due to standard heights for aircraft that are near
    an airport? Are there other reasons? Without additional information, it is impossible
    to know the reason. On the **Average of Contribution by Field** chart in the bottom
    left of the page, you notice that at both the aggregate level and filtered level,
    the **Distance**, **Speed**, **Airport ID**, and **Phase of Flight** features
    tend to have the greatest contribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Expanding the table in *Figure 11**.24* that lists each individual incident,
    you can see the **Residual** value of the predicted height versus the actual height:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.24 – The individual event’s predicted height, actual height, and
    residual value](img/B19500_11_024.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.24 – The individual event’s predicted height, actual height, and residual
    value
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 11**.24*, notice that the range of accuracy for the predictions shifts
    considerably between incidents. There are probably many different factors contributing
    to the inaccuracies. Can the predictions be better? Or is there natural variability
    in the data due to the nature of the incidents and the process for recording data
    about the incidents? Conversations with the project stakeholders, people in charge
    of recording the data, and data science experts can help you learn more about
    this particular use case.
  prefs: []
  type: TYPE_NORMAL
- en: You’ve reached a point in your project where you have designed your ML models
    in Power BI, trained them, tested them, and then applied them to new data in a
    way that could work with an automated process in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you brought new FAA Wildlife Strike data into Power BI and
    transformed the data to match the design of your original architecture. You then
    transformed the data to meet the filtering and transformation requirements of
    the data used to train and test your **Predict Damage ML**, **Predict Size ML**,
    and **Predict Height ML** models. Then, you made predictions for the new data
    by applying the trained Power BI ML models. Finally, you reviewed the results
    of the predictions and compared them to the actual results.
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 12*](B19500_12.xhtml#_idTextAnchor165) will add a special twist to
    your project! For those of you out in the real world, changing scope and expectations
    is a frequent occurrence with data projects. When this book was being written,
    **OpenAI** and **Microsoft OpenAI** were fast becoming media sensations. Your
    stakeholders have asked you to find some use cases for OpenAI in your project.
    It’s a scope change to your project, but it will be an exciting adventure! [*Chapter
    12*](B19500_12.xhtml#_idTextAnchor165) will review the OpenAI and Microsoft OpenAI
    offerings, as they can be applied to this project for added value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 4: Integrating OpenAI with Power BI'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the final part of the book, you will see how you can make use of Open AI
    and Azure OpenAI to enhance your BI work. In the final chapter, you will look
    at some of the key ideas and lessons covered in the book, and think about how
    you can use them in your own work.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following three chapters make up *Part 4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 12*](B19500_12.xhtml#_idTextAnchor165), *Use Cases for OpenAI*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 13*](B19500_13.xhtml#_idTextAnchor173), *Using OpenAI and Azure OpenAI
    in Power BI Dataflows*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 14*](B19500_14.xhtml#_idTextAnchor186), *Project Review and Looking
    Forward*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
