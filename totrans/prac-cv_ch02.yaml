- en: Libraries, Development Platform, and Datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will be setting up a development environment to help run
    codes for the book as well as for generic development and also introduce various
    datasets for computer vision. Since there are several standard libraries which
    are used both for studying computer vision and in the industry for deployment,
    it becomes trivial to also use them in learning path. As we study the various
    sub-topics of computer vision in further chapters, we will be able to directly
    implement the codes introduced then rather than getting stuck in installations
    and other library dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter is divided into two major sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Firstly we will be setting up python based environment such Anaconda
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will then setup OpenCV and various forms of its installations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For deep learning, we will also setup Keras and TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Libraries and installation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin, it is required that we install each library. There are two
    major methods of installing a library:'
  prefs: []
  type: TYPE_NORMAL
- en: We download the source code and build binaries by compiling the code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can directly download binaries and put them in relevant directories
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While downloading pre-built binaries is a faster method, however, due to the
    difference of platforms or non-availability of binaries may force to build a library
    from source. If readers are using different OS then the mentioned in the following
    sections, they might come across such a situation. Once installed a library, it
    can be used with programs or other libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Since it is crucial to have libraries that are not affected by other installations, we
    will be using Python-based environments in most of the book. This helps in keeping
    track of libraries installed and also separates different environment if we would
    like to have multiple. Here environment refers to installed libraries with particular
    versions and their dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: For building a library from source, we will use `CMake` tool. The instructions
    to install are as shown in further sections. This helps in building cross-platform
    software by linking to relevant compilers on each platform as well as to their
    dependencies. This comes with GUI too but for convenience, we will be using command-line
    `cmake`.
  prefs: []
  type: TYPE_NORMAL
- en: For deep learning, which we will see later in this book, a GPU is highly recommended.
    To run our programs using GPUs, we need to install both CUDA and cuDNN binaries
    provided by Nvidia. Further details of installation for each of the platforms,
    such as Linux, Mac OS, or Windows, are available from Nvidia.
  prefs: []
  type: TYPE_NORMAL
- en: Let's begin by installing the required packages in order.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Anaconda
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we need to do is set up our Python environment such that rest
    of the libraries will be easily accessible through Python. Anaconda is a popular
    data science platform with a Python interface and is available here: [https://www.anaconda.com/](https://www.anaconda.com/).
    It has `conda` as a package manager, which can install, delete, and manage versions
    of Python libraries while keeping it isolated from other Python environments.
    In this book, we will use `conda` from Anaconda. Let''s go ahead and set this
    up.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, download and install Anaconda:'
  prefs: []
  type: TYPE_NORMAL
- en: 'On Linux:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'On macOS, `wget` is not directly available; use brew to install `wget`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This will install the Python libraries in the folder `$HOME/anaconda3`, since
    we are using Python 3\. A Python 2 version is also available and the installation
    process is similar. To use Anaconda, the newly installed libraries need to be
    added in `$PATH`, this can be done every time a new shell is launched by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`$PATH_TO_ANACONDA3` is the location path to the `Anaconda3` folder. For more
    convenience, add this to `.bashrc` or `.bash_profile` depending on if you are
    using Linux or macOS respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once conda is installed, many other scientific packages will also be installed.
    Some of these packages are:'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'NumPy package is used for performing operations on images as N-dimensional
    arrays. An example to create and transpose a two-dimensional array is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Matplotlib
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is a popular Python package for plotting and displaying data and images.
    To use in Python, the scripts is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to plot inside Jupyter notebook, add the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'An example function to display an image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: SciPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a Python based scientific computing library and contains several advanced
    algorithms for optimization, linear algebra, signal processing, statistics, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example to compute eigen values and eigen vectors of a two-dimensional array
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Jupyter notebook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Jupyter notebook is popularly used for creating step by step live codes with
    visualizations and texts. In [Chapter 3](prac-cv_ch03.html), *Image Filtering
    and Transformations in OpenCV* and [Chapter 4](prac-cv_ch04.html), *What is a
    Feature?, *the codes for image filtering and feature extraction can be used with
    Jupyter notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'To launch a notebook server, run the following in shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This will start the browser and we can see the files inside the folder from
    where it is launched. After launching, click on New on top left side on the browser
    page and select the notebook with desired Python. A new tab in the browser will
    open with Python interpreter format.
  prefs: []
  type: TYPE_NORMAL
- en: Other packages such as scikit-learn, pandas, seaborn, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Installing OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenCV (available at [https://opencv.org/](https://opencv.org/) ) is the most
    popular computer vision open source library and can be installed on all major
    platforms including Linux, macOS, Windows, Android, iOS, and so on. It contains
    optimized code written in C++ and has binding for Python and Java. Considering
    the versatility of OpenCV, we will be using it to explain computer vision algorithms.
    Most of the code in this book is in Python, except for external repositories.
    OpenCV can be set up in two ways depending on how we will use it. We will begin
    with the easy way.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV Anaconda installation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using Anaconda, which we installed in the previous section, OpenCV can be installed
    on both Linux and macOS as follows (this is OpenCV with only the Python library):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: OpenCV build from source
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Building OpenCV from source is quite a long process, depending on the hardware
    you are using:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Requirements on Linux (here Ubuntu):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Requirements on macOS:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Install CMake from [http://www.cmake.org/download/ ](http://www.cmake.org/download/)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The following is an install script; copy the following snippet to install the `install.sh`
    file, and run `bash install.sh`to install OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, replace `$PATH_TO_ANACONDA` with the absolute path to
    Anaconda, such as `/Users/mac`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Since there are significant changes between OpenCV2 and OpenCV3, the code in
    this book is written using only OpenCV3.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `OpenCV`, extra contributed modules are moved to a separate repository under
    the name `opencv_contrib`. In order to build `OpenCV` including with `opencv_contrib`
    , the steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download OpenCV as :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Download the extra module here, and note the path to this folder:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Build a complete OpenCV again, as follows, where `PATH_TO_CONTRIB` is the path
    to the previously downloaded `opencv_contrib` path:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here, we see that there are several options which are set on or off. The choice
    of these operations depends on the availability of the dependencies. These can
    be set to on if all of the dependencies are available.
  prefs: []
  type: TYPE_NORMAL
- en: Opencv FAQs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Though we saw an introductory OpenCV programs in previous chapter, we will see
    some more frequently used code snippets that will be used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin with importing OpenCV and will print the version of OpenCV used:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We can read an image from a file as:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The previous snippet will decode an image stored in common formats such as `.jpg`,
     `.png` , `.jpeg` , `.tiff` , `.pgm`, and so on. using image codecs either installed
    with OpenCV or available on the platform. If there are no codecs available, then
    OpenCV will not be able to read image or write image to a file. So, it is necessary
    for the user to install codecs on a non-supported platforms such as embedded devices.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can write an image to file as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In writing a file also there is need for image codecs which are generally installed
    with OpenCV. We can write the image with file formats such as JPG, PNG, JPEG,
    TIFF, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Processing a video includes opening a video file and applying algorithms on
    each frame. We will first initialize the source of frames which can be a video
    file or an attached USB camera as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Or we can also write it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to image reading and writing, video reading will also require codecs
    which are installed with OpenCV or available from the OS. Once the source is setup
    we can continue processing each frame as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Here `cv2.imshow` is to display image and `cv2.waitKey()` is time delay in the
    execution.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow for deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow is one of the popular deep learning libraries available and has APIs
    for Python, C++, Java, and so on. In this book, we will use the Python API 1.4.0\.
    Explaining TensorFlow in detail is beyond the scope of this book; the official
    documentation is a better starting place to get acquainted with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to install, we will use the `pip` based method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'If there is GPU available with CUDA and cuDNN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'For more information on TensorFlow and its use, please follow the tutorials
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.tensorflow.org/get_started/get_started](https://www.tensorflow.org/get_started/get_started).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once installed, TensorFlow version can be checked by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Keras for deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Keras is a Python based API that uses TensorFlow, CNTK, or Theano as backend
    for deep learning. Due to its high level API and simplified abstraction, it has
    been quite popular in the deep learning community. We will be using this library
    to study CNNs. To install this, first install TensorFlow as described in previous
    section, and use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'There is no separate version for GPU. For installing specific versions of Keras,
    such as Version 2.1.2, use following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The latest version of Keras at the time of writing this book is 2.1.2\. To
    check the version of installed Keras, use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: If TensorFlow is installed from previous sections, it will use it as backend.
  prefs: []
  type: TYPE_NORMAL
- en: To use Keras, one of the prerequisites is basic knowledge of deep learning.
    In this book, we will see it in [Chapter 5](prac-cv_ch05.html), *Convolutional
    Neural Networks*.
  prefs: []
  type: TYPE_NORMAL
- en: Datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In computer vision, datasets play a key role in developing efficient applications.
    Also, now, with the availability of large open source datasets, it has become
    much easier to create best performing models for computer vision tasks. In this
    section, we will see several datasets for computer vision.
  prefs: []
  type: TYPE_NORMAL
- en: ImageNet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ImageNet is one of the largest annotated datasets for computer vision. The data
    is arranged according to a hierarchical order. There are 1,000 classes with 1.4
    million images overall. Though the images are for non-commercial use, ImageNet
    is still one of the most popular datasets when it comes to learning computer vision.
    Especially in deep learning, the dataset is used to create image classification
    models due to availability of large number of varied images.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following website provides links and resources to download image URLs or
    other attributes about images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://image-net.org/download](http://image-net.org/download)'
  prefs: []
  type: TYPE_NORMAL
- en: In this book, ImageNet is not used explicitly, but we will be using a pre-trained
    model on it. There is no requirement to download this dataset for this book.
  prefs: []
  type: TYPE_NORMAL
- en: MNIST
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`MNIST` is a dataset for handwritten digits with the numbers 0-9 with 60,000
    images of size 28 x 28 as the training set and 10,000 images of size 28 x 28 as
    the test set. This has become the go to dataset for starting machine learning
    or deep learning. It is provided in most of the frameworks and there is no need
    to download it separately. In `Keras`, this can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Some of the sample images from this dataset are as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/523e4aa9-ab14-4cc0-ba57-32a23a0f0c80.png)'
  prefs: []
  type: TYPE_IMG
- en: CIFAR-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Though `MNIST` is one of the easiest datasets to get started, the lack of color
    images makes it less appealing for tasks that require a colored dataset. A slight
    more complex dataset is `CIFAR-10` by Alex and others[1], which consists of 10
    categories of images with 60,000 training images and 10,000 test images, uniformly
    from each category. The size of each image is 32 x 32 and each has three color
    channels. This dataset can also be easily loaded in Keras, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The labels, in order, are: `airplane`, `automobile`, `bird`, `cat`, `deer`,
    `dog`, `frog`, `horse`, `ship`, and `truck`.
  prefs: []
  type: TYPE_NORMAL
- en: Pascal VOC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As previous datasets like `MNIST` and `CIFAR` are limited in representation,
    we cannot use them for tasks like people detection or segmentation. Pascal VOC[4]
    has gained in popularity for such tasks as one of the major datasets for object
    recognition. During 2005-2012, there were competitions conducted that used this
    dataset and achieved the best possible accuracy on test data. The dataset is also
    usually referred to by year; for example, VOC2012 refers to the dataset available
    for the 2012 competition. In VOC2012, there are three competition categories.
    The first is the classification and detection dataset, which has 20 categories
    of objects along with rectangular region annotations around the objects. The second
    category is Segmentation with instance boundaries around objects. The third competition
    category is for action recognition from images.
  prefs: []
  type: TYPE_NORMAL
- en: 'This dataset can be downloaded from the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this dataset, a sample annotation file (in XML format) for an image is in
    the following code, where the tags represent properties of that field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding image is as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac8e0f1a-4309-4168-9600-e7ca110d227c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The available categories in this dataset are aeroplane, bicycle, boat, bottle,
    bus, car, cat, chair, cow, dining table, dog, horse, motorbike, person, potted
    plant, sheep, train, and TV.
  prefs: []
  type: TYPE_NORMAL
- en: The number of categories is, however, limited. In the next section, we will
    see a more elaborate dataset with 80 categories. Having a higher number of generic
    object categories will help in creating applications that can be used easily in
    more generic scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: MSCOCO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: COCO[2] refers to a common object in context and is a dataset for object recognition,
    with 80 categories and 330K images. After Pascal VOC'12, this became a popular
    benchmark for training and evaluating the system. The dataset can be downloaded
    from [http://cocodataset.org/#download](http://cocodataset.org/#download).
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to read the data and use it for applications, there is an API available
    at [https://github.com/cocodataset/cocoapi](https://github.com/cocodataset/cocoapi)
    which needs to be downloaded.  To get started, we can use the API provided, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This will install the Python API to read the `coco` dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Many models available online for object detection or image segmentation are
    first trained on this dataset. If we have specific data that has different object
    categories than in the MSCOCO dataset, a more common approach that we will see
    in [Chapter 5](prac-cv_ch05.html), *Convolution Neural Networks* and in [Chapter
    6](prac-cv_ch06.html), *Feature- Based Object Detection*, is to first train a
    model on an MSCOCO dataset and use a part of the trained model and re-train on
    a new dataset.
  prefs: []
  type: TYPE_NORMAL
- en: TUM RGB-D dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While previous datasets were used for object recognition, this dataset is used
    to understand the geometry of a scene. The RGB-D dataset[3] has been popular in
    SLAM research and was a benchmark for comparison too. Here, RGB-D refers to a
    dataset with both **RGB** (color) images and **Depth** images. The depth here
    refers to distance of pixel from camera and are taken using a depth camera. Since
    there is also depth information available, this dataset can also be used to evaluate
    depth based SLAM algorithms and three-dimensional reconstructions from RGB image
    and its corresponding depth image.
  prefs: []
  type: TYPE_NORMAL
- en: To download this dataset, visit [https://vision.in.tum.de/data/datasets/rgbd-dataset/download](https://vision.in.tum.de/data/datasets/rgbd-dataset/download) and
    choose the type of sequence to use.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to install the different library files of Python,
    Keras, and TensorFlow. In order to use several code snippets in further chapters,
    these libraries will be sufficient. We also had a look at different datasets like
    ImageNet, `MNIST`, `CIFAR-10`, MSCOCO and TUM RGBD datasets. These datasets are
    the backbone for computer vision applications since the ability of several software
    that we develop directly depends on the availability of these datasets.
  prefs: []
  type: TYPE_NORMAL
- en: In next chapter, we will begin with more in-depth image analysis by introducing
    different types of filters and also learn transformations on image such as translation,
    rotation or affine.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Krizhevsky, Alex, and Geoffrey Hinton. *Learning multiple layers of features
    from tiny images*. (2009).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin, Tsung-Yi, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
    Ramanan, Piotr Dollár, and C. Lawrence Zitnick. *Microsoft coco: Common objects
    in context*. In European conference on computer vision, pp. 740-755\. Springer,
    Cham, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sturm, Jürgen, Nikolas Engelhard, Felix Endres, Wolfram Burgard, and Daniel
    Cremers. *A benchmark for the evaluation of RGB-D SLAM systems*. In Intelligent
    Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on, pp. 573-580\.
    IEEE, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Everingham Mark, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew
    Zisserman. *The pascal visual object classes (voc) challenge*. International journal
    of computer vision 88, no. 2 (2010): 303-338.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
