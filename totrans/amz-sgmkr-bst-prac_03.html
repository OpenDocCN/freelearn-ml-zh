<html><head></head><body>
		<div id="_idContainer040">
			<h1 id="_idParaDest-40"><a id="_idTextAnchor039"/>Chapter 2: Data Science Environments</h1>
			<p>In this chapter, we will get an overview of how to create managed data science environments to scale and create repeatable environments for your model-building activities. In this chapter, you will get a brief overview of the <strong class="bold">machine</strong> <strong class="bold">learning</strong> (<strong class="bold">ML</strong>) use case, including the dataset that will be used throughout the chapters in this book. </p>
			<p>The topics that will be covered in this chapter are as follows: </p>
			<ul>
				<li>Machine learning use case and dataset </li>
				<li>Creating data science environments </li>
			</ul>
			<h1 id="_idParaDest-41"><a id="_idTextAnchor040"/>Technical requirements</h1>
			<p>You will need an AWS account to run the examples included in this chapter. Full code examples included in the book are available on GitHub at <a href="https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter02">https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter02</a>. You will need to install a Git client to access them (<a href="https://git-scm.com/">https://git-scm.com/</a>). Portions of the code are included within the chapter to call out specific technical concepts; however, please refer to the GitHub repository for the full code required to complete the hands-on activities that go along with this chapter.</p>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor041"/>Machine learning use case and dataset</h1>
			<p>Throughout this book, we will be using examples to demonstrate the best practices that apply across the ML life cycle. For this, we'll focus on a single ML use case<a id="_idIndexMarker048"/> and use an open dataset with data relating to the ML use case.</p>
			<p>The primary use case we'll explore in this book is predicting air quality readings. Given a location (weather station) and date, we'll try to predict a value for a particular type of air quality measurement (for example, pm25 or o3). We'll treat this as a regression problem and explore XGBoost and neural network-based model approaches.</p>
			<p>For this, we'll use a dataset<a id="_idIndexMarker049"/> from OpenAQ (<a href="https://registry.opendata.aws/openaq/">https://registry.opendata.aws/openaq/</a>) that includes air quality data from public data sources. The dataset that we will use is the <strong class="source-inline">realtime</strong> dataset (<a href="https://openaq-fetches.s3.amazonaws.com/index.html">https://openaq-fetches.s3.amazonaws.com/index.html</a>) and the <strong class="source-inline">realtime-parquet-gzipped</strong> dataset (<a href="https://openaq-fetches.s3.amazonaws.com/index.html">https://openaq-fetches.s3.amazonaws.com/index.html</a>), which includes daily reports from multiple stations. </p>
			<p>The daily reports are in JSON format. Each record contains the following:</p>
			<ul>
				<li>A timestamp (both UTC and local)</li>
				<li>Parameter ID (pm25)</li>
				<li>Location (station ID)</li>
				<li>Value (numeric)</li>
				<li>Units for value</li>
				<li>City</li>
				<li>Attribution (link to station website)</li>
				<li>Averaging period (for example, 1 hour)</li>
				<li>Coordinates (lat/lon)</li>
				<li>Country code</li>
				<li>Source name (short version of station name)</li>
				<li>Source type</li>
				<li>Mobile (true/false)</li>
			</ul>
			<p>Let's now look at how to create data science environments.</p>
			<h1 id="_idParaDest-43"><a id="_idTextAnchor042"/>Creating data science environment</h1>
			<p>In the previous section, we<a id="_idIndexMarker050"/> introduced high-level Amazon SageMaker features that can often be used in isolation or together for end-to-end capabilities. In this section, we will focus on creating consistent and repeatable governed data science environments that can take advantage of the features discussed in the first section.</p>
			<p>To build, train, and deploy <a id="_idIndexMarker051"/>models using Amazon SageMaker, ML builders need access to select AWS resources spanning the ML development life cycle. Because many different personas may be responsible for building ML models, the term ML builder refers to any individual tasked with model building. This could include data scientists, ML engineers, or data analysts. </p>
			<p><strong class="bold">Data science development</strong> environments <a id="_idIndexMarker052"/>provide ML builders with the AWS resources they need to build and train models. A data science environment could be as simple as an AWS account with access to Amazon SageMaker as well as AWS services commonly used with Amazon SageMaker, such as Amazon S3, AWS Glue, or Amazon EMR. While this may work for small teams, it does not scale well to larger teams or provide repeatability as new projects get created or new team members join the team. </p>
			<p>Amazon SageMaker offers three core options in building, training, and tuning models, including the following: </p>
			<ul>
				<li><strong class="bold">API/SDK</strong>: Training and <a id="_idIndexMarker053"/>tuning jobs can be started with the SageMaker API, which can be accessed through the high-level SageMaker Python SDK, lower-level AWS SDKs such as boto3 for Python, or the AWS CLI.</li>
				<li><strong class="bold">Amazon SageMaker Studio</strong>: Amazon<a id="_idIndexMarker054"/> SageMaker Studio has built-in notebooks as part of an integrated workbench that includes native integrations with other Amazon SageMaker features and feature visualizations. </li>
				<li><strong class="bold">Amazon SageMaker notebook instances</strong>: SageMaker notebook instances provide a compute instance with <a id="_idIndexMarker055"/>attached storage hosting the Jupyter Notebook application. These notebooks come preinstalled with packages, libraries, and kernels. </li>
			</ul>
			<p>This section will focus only on Amazon SageMaker Studio and Amazon SageMaker notebook instances for setting up data science environments. Similar approaches can be applied in using the SageMaker API or SDK from a data science environment hosted outside of SageMaker. We'll first highlight <a id="_idIndexMarker056"/>the two common approaches using <strong class="bold">Infrastructure-as-Code</strong> (<strong class="bold">IaC</strong>)/<strong class="bold">Configuration-as-Code</strong> (<strong class="bold">CaC</strong>) as well as building a common catalog of data science environments. We will expand on each option in more detail in later sections. </p>
			<p>To build a repeatable mechanism for creating data science sandbox environments, it is recommended to utilize<a id="_idIndexMarker057"/> IaC/CaC to define the intended configuration and controls to implement for your sandbox environments. Let's see what the two processes refer to:</p>
			<ul>
				<li>IaC refers<a id="_idIndexMarker058"/> to the process of provisioning and managing infrastructure using code instead of relying on manual setup, which is not only slow but also prone to error and inconsistencies across environments. </li>
				<li>Cac refers<a id="_idIndexMarker059"/> to the process of managing the configuration of resources through code. Because this is all defined via code, it can be managed as source code and reused for consistency across environments. </li>
			</ul>
			<p>Using Iac/CaC can<a id="_idIndexMarker060"/> be taken a step further by providing data science environments through a service, such as AWS Service Catalog, that is purposely built for centrally creating and managing catalogs of IT services that are approved for use on AWS. </p>
			<p><em class="italic">Figure 2.1</em> illustrates the most common approaches for setting up governed data science environments. Each of <a id="_idIndexMarker061"/>these options will be discussed in detail in this section. At a minimum, it's recommended to adopt an automated approach, which would include options 2 and 3 in the following diagram: </p>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B17249_02_01.jpg" alt="Figure 2.1 – Approaches for creating data science sandbox environments&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.1 – Approaches for creating data science sandbox environments</p>
			<p>A manual approach to<a id="_idIndexMarker062"/> provisioning and providing access to AWS services for ML builders creates challenges when scaling multiple ML builders and managing governance beyond a small team. </p>
			<p>With the introduction of AWS CloudFormation, or an equivalent service providing IaC/CaC capabilities, data science environments can be repeatedly created as well as provide additional capabilities such as the following: </p>
			<ul>
				<li><strong class="bold">Environment governance</strong>: AWS <a id="_idIndexMarker063"/>CloudFormation allows you to define the intended state of your data science environment in terms of which resources get provisioned as well as how they get provisioned. This allows you to enforce configurations such as cost allocation tags, encrypted storage, or control access to pre-approved resources such as specific instance types for notebook instance compute. </li>
				<li><strong class="bold">Consistency</strong>: As ML<a id="_idIndexMarker064"/> builder teams grow, there is a need to gain operational efficiencies by provisioning environments with reduced manual effort and increased consistency. IaC/CaC allows for data science environments to be automatically provisioned and provides consistency through code and automation. </li>
				<li><strong class="bold">Improved management capabilities</strong>: AWS CloudFormation not only allows you to automatically build a data <a id="_idIndexMarker065"/>science environment, but it also allows you to quickly deprovision a data science environment that is no longer in use. This capability reduces environment sprawl and ensures that you are not paying for resources that are no longer in use. </li>
			</ul>
			<p>Using IaC/CaC to provision and manage data science environments is often sufficient in being able to consistently enable ML builders. However, providing these data science environments through a central catalog of IT services adds an additional layer of operational efficiencies, such as <em class="italic">reducing manual approvals</em>, <em class="italic">reducing hand-offs in siloed teams</em>, and <em class="italic">providing centralized governance by ensuring environments are provisioned across teams using only approved configurations</em>. </p>
			<p>AWS Service Catalog allows administrators to centrally define and manage a portfolio of approved products or configurations defined through AWS CloudFormation templates. The addition of AWS Service Catalog for managing a portfolio of products used to create data science environments enables additional capabilities over standalone IaC/CaC, including the following:</p>
			<ul>
				<li><strong class="bold">Self-service capabilities</strong>: Using <a id="_idIndexMarker066"/>only IaC/CaC to provision and configure AWS resources can often result in delays while requests are approved, tracked, and, ultimately, the environment is provisioned by the AWS Admin. AWS Service Catalog allows ML builders, or approved designated project resources, to automatically request and provision a data science environment that is preconfigured according to standards that you define. </li>
				<li><strong class="bold">Applying constraints and access controls</strong>: With AWS Service Catalog, constraints and access controls <a id="_idIndexMarker067"/>can be centrally defined and applied consistently across<a id="_idIndexMarker068"/> teams. </li>
				<li><strong class="bold">Service management</strong>: While<a id="_idIndexMarker069"/> AWS Service Catalog utilizes AWS CloudFormation, it also includes capabilities to manage the life cycle of these templates or products across versions. </li>
			</ul>
			<p>AWS Service Catalog allows ML builders, or an approved resource, to request and instantiate a data science environment using approved products contained in an AWS Service Catalog portfolio. An AWS Service Catalog portfolio<a id="_idIndexMarker070"/> can exist in a separate AWS account and be shared across AWS accounts to establish a company or business unit standard for governing the configuration and provisioning of products. Products within a portfolio contain the pre-configured templates, using IaC/CaC, that should be used to provision or instantiate the data science environment for an ML builder:</p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B17249_02_02.jpg" alt="Figure 2.2 – AWS Service Catalog – anatomy of a portfolio&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.2 – AWS Service Catalog – anatomy of a portfolio</p>
			<p>In the rest of this chapter, we'll cover considerations to consistently create data science environments through IaC/CaC, as well as advanced capabilities allowing you to provide those environments across multiple teams through a governed catalog of IT services. Each of these will be covered for both Amazon SageMaker notebook instances as well as Amazon SageMaker Studio. First, we'll cover the use of IaC/CaC to create repeatable data science environments.</p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor043"/>Creating repeatability through IaC/CaC</h2>
			<p>Using AWS CloudFormation to<a id="_idIndexMarker071"/> provision and configure the AWS resources and access required for SageMaker model-building activities allows teams to create a repeatable pattern that can be shared across teams and used to consistently create data science environments. </p>
			<p>A CloudFormation template lets you programmatically describe the desired AWS resources, configurations, and dependencies that should be provisioned when that template is launched as a stack. Key considerations when building AWS CloudFormation templates for data science environments include what resources should be provisioned, how they should be configured, and what permissions ML builders need for model-building activities. </p>
			<h3>What resources are required?</h3>
			<p>AWS CloudFormation <a id="_idIndexMarker072"/>lets you define the AWS services to automatically provision via a template using supported resources and resource types. As an example, Amazon SageMaker is a supported resource, and a SageMaker notebook instance is a supported resource type. A CloudFormation resource type is represented in a consistent format, as shown in <em class="italic">Figure 2.3</em>, whether you are building your CloudFormation template as JSON or YAML: </p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B17249_02_03.jpg" alt="Figure 2.3 – AWS CloudFormation resource type for an Amazon SageMaker notebook instance&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.3 – AWS CloudFormation resource type for an Amazon SageMaker notebook instance</p>
			<p>This means teams can automatically provision and configure a notebook instance through a CloudFormation template. However, a notebook instance alone is typically not enough for a data science environment. For a basic environment, you typically need a notebook instance, an S3 bucket, and an AWS IAM SageMaker execution role to execute API calls from within your notebook environment. </p>
			<p>In addition to a basic environment, there may be a need to provision other resources as part of a data science environment. Additional resources to provision fall into a few key categories: </p>
			<ul>
				<li><strong class="bold">Data preparation resources</strong>: This <a id="_idIndexMarker073"/>category includes AWS resources commonly used for data preparation activities such as <strong class="bold">Amazon Elastic MapReduce</strong> (<strong class="bold">EMR</strong>). For this, you can create an EMR cluster to process and analyze vast amounts of data using the <strong class="source-inline">AWS::EMR::Cluster</strong> resource type.</li>
				<li><strong class="bold">Machine learning pipeline resources</strong>: This category includes AWS resources commonly used in<a id="_idIndexMarker074"/> creating machine learning pipelines, such as the following:<p>a. <strong class="bold">AWS CodeCommit</strong>: Create a <a id="_idIndexMarker075"/>source code repository for model training code in AWS CodeCommit using the <strong class="source-inline">AWS::CodeCommit::Repository</strong> resource type. </p><p>b. <strong class="bold">Amazon Elastic Container Registry</strong> (<strong class="bold">ECR</strong>): Create a new container image repository in ECR that can be<a id="_idIndexMarker076"/> used for your training and inference container images in the case of using SageMaker's capability to bring your own container image. A new repository can be created using the <strong class="source-inline">AWS::ECR::Repository</strong> resource type.</p></li>
				<li><strong class="bold">Identity resources</strong>: This <a id="_idIndexMarker077"/>category includes any additional policies or service roles that need to be created to use AWS resources. For example, to utilize AWS Step Functions, or the Data Science Python SDK, for creating ML workflows, a service-level IAM execution role needs to be created. The creation of this role can be specified in your CloudFormation template. The role should also include permissions that allow access to AWS services and actions that will be used in your ML workflow, such as AWS Glue for data preparation and Amazon SageMaker for training jobs. </li>
			</ul>
			<h3>How should the resources be configured?</h3>
			<p>Each resource that gets <a id="_idIndexMarker078"/>provisioned through a CloudFormation template includes a set of properties that define how a resource should be configured. Defining these properties through code allows you to consistently provision resources that are configured according to pre-defined specifications. Properties include important configuration options, such as launching environments with a VPC attached or enforcing controls such as encryption at rest. CloudFormation also allows for <strong class="bold">parameters</strong> that can be defined in the template and passed in when launching a CloudFormation stack.</p>
			<h3>What permissions are needed? </h3>
			<p>After you've identified the AWS <a id="_idIndexMarker079"/>resources and resource types that need to be provisioned for your data science environment, you need to identify the permissions that are also required to be able to access the notebook environment and the underlying APIs required for model building. </p>
			<p>There is some variance between Amazon SageMaker notebook instances and Amazon SageMaker Studio discussed in the sections below; however, in both cases, a basic environment requires an IAM SageMaker execution role. Depending on the intent of the CloudFormation template, you need to consider the additional allowed AWS API calls and actions that the SageMaker execution role will need access to. For example, if your data science team uses AWS Glue for data preparation activities, the IAM SageMaker execution role needs to allow access to the corresponding AWS Glue API actions. </p>
			<p>To build the AWS<a id="_idIndexMarker080"/> CloudFormation templates that will be used to create and consistently enforce controls in your data science environment, a few planning tasks should be considered before building those templates:</p>
			<ol>
				<li>First, you should identify the patterns for the resources that should be provisioned together. </li>
				<li>Second, you should identify how those resources should be configured. </li>
				<li>Finally, you need to identify the minimum permissions that need to be in place for the provisioned resources to integrate seamlessly as well as the permissions required for an ML builder to operate within those provisioned environments. </li>
			</ol>
			<p>Typically, several patterns are built supporting different environment patterns that may be needed for varying use cases or multiple teams. The following sections include detailed sample scenarios for both Amazon SageMaker notebook instances and Amazon SageMaker Studio. For either scenario, the sections can be read independently of one another and contain some duplicated information so that they can exist independently. </p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor044"/>Amazon SageMaker notebook instances</h2>
			<p>Building data science <a id="_idIndexMarker081"/>environments that utilize Amazon SageMaker notebook instances typically includes the provisioning of the following: </p>
			<ul>
				<li>A notebook instance (required)</li>
				<li>An S3 bucket (optional)</li>
				<li>An IAM execution role (optional if using an existing one)</li>
				<li>Any other resources identified as needed by ML builder teams</li>
			</ul>
			<p>An Amazon S3 bucket is <a id="_idIndexMarker082"/>noted as optional above because many organizations have existing S3 buckets that are used for data science model-building activities. In these cases, the data science environment may instead include permissions to access an existing S3 bucket. <em class="italic">Figure 2.2</em> shows a basic data science environment template that provisions a SageMaker notebook instance, an Amazon S3 bucket, and creates a SageMaker execution role that is attached to the notebook instance. The template can be used to <a id="_idIndexMarker083"/>instantiate multiple environments:</p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B17249_02_04.jpg" alt="Figure 2.4 – Notebook instance-based data science environment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.4 – Notebook instance-based data science environment</p>
			<p>The following code snippets from a CloudFormation template show a pattern that can be used to quickly provision a data science environment using controls pre-approved by security and administrative teams and implemented through code. In the first section of the template, we identify parameters that are configurable each time a new template is launched. Parameters allow you<a id="_idIndexMarker084"/> to pass in data used in the provisioning and configuration of resources: </p>
			<p class="source-code">AWSTemplateFormatVersion: '2010-09-09'</p>
			<p class="source-code">Metadata:</p>
			<p class="source-code">License: Apache-2.0</p>
			<p class="source-code">Description: 'Example data science environment creating a new SageMaker Notebook Instance using an existing VPC.  This template also includes the creation of an Amazon S3 Bucket and IAM Role.  A lifecycle policy is also included to pull the dataset that will be used in future book chapters.'</p>
			<p class="source-code">Parameters: #These are configuration parameters that are passed in as input on stack creation</p>
			<p class="source-code">  NotebookInstanceName:</p>
			<p class="source-code">            AllowedPattern: '[A-Za-z0-9-]{1,63}'</p>
			<p class="source-code">            ConstraintDescription: Maximum of 63 alphanumeric characters. Can include hyphens but not spaces.</p>
			<p class="source-code">            Description: SageMaker Notebook instance name</p>
			<p class="source-code">            MaxLength: '63'</p>
			<p class="source-code">            MinLength: '1'</p>
			<p class="source-code">            Type: String</p>
			<p class="source-code">            Default: 'myNotebook'</p>
			<p class="source-code">NotebookInstanceType:</p>
			<p class="source-code">  VPCSubnetIds:</p>
			<p class="source-code">  VPCSecurityGroupIds:</p>
			<p class="source-code">  KMSKeyId:</p>
			<p class="source-code">  NotebookVolumeSize:</p>
			<p>In the next section of the<a id="_idIndexMarker085"/> template, we identify the resources to provision and configure for your data science environment. The Properties of each resource identify the configuration and controls to provision. These controls can include configuration such as ensuring the storage volume attached to the notebook instance is encrypted and that the notebook instance is provisioned with a VPC attached:</p>
			<p class="source-code">Resources:</p>
			<p class="source-code">  SageMakerRole:</p>
			<p class="source-code">           Type: AWS::IAM::Role</p>
			<p class="source-code">           Properties:</p>
			<p class="source-code">            AssumeRolePolicyDocument:</p>
			<p class="source-code">            Version: 2012-10-17</p>
			<p class="source-code">             Statement:</p>
			<p class="source-code">            - Effect: Allow</p>
			<p class="source-code">             Principal:</p>
			<p class="source-code">             Service:</p>
			<p class="source-code">                       - "sagemaker.amazonaws.com"</p>
			<p class="source-code">            Action:</p>
			<p class="source-code">            - "sts:AssumeRole"</p>
			<p class="source-code">           ManagedPolicyArns:</p>
			<p class="source-code">          - "arn:aws:iam::aws:policy/AmazonSageMakerFullAccess"</p>
			<p class="source-code">          - ...</p>
			<p class="source-code">  SageMakerLifecycleConfig:   </p>
			<p class="source-code">        ... </p>
			<p class="source-code">  SageMakerNotebookInstance:</p>
			<p class="source-code">        ... </p>
			<p class="source-code"> S3Bucket:</p>
			<p class="source-code">...</p>
			<p>In the template snippets here, we are asking for a pre-configured VPC as a parameter on input; however, you could also include the creation of a new VPC within your CloudFormation template <a id="_idIndexMarker086"/>depending on your needs. We also include the notebook instance type and storage size as parameters that are configurable with each new launched template. Configurations that are likely to change for different ML use cases are good candidates that convert into configurable parameters that can be defined while launching a stack.</p>
			<p>Once the template is uploaded to Amazon S3 and validated, it can be launched repeatedly for each new data science environment needed. Launching the stack can be done through the AWS console, AWS CLI, or the AWS SDK. This is most frequently done from an administrative account using cross-account privileges to ensure control in the roles that can define and provision environments versus the users who use the provisioned environments. </p>
			<p>After the CloudFormation stack is completed, an ML builder can then access their environment through the provisioned Amazon SageMaker notebook instances via the AWS console. To access the notebook instance, the sign-in credentials for the ML builder must have the IAM permissions to send a <strong class="source-inline">CreatePresignedNotebookInstanceUrl</strong> API request. </p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor045"/>Amazon SageMaker Studio</h2>
			<p>Building data science <a id="_idIndexMarker087"/>environments that utilize Amazon SageMaker Studio includes the provisioning of the following:</p>
			<ul>
				<li>A new user within an existing Studio domain (required)</li>
				<li>An S3 bucket (optional) </li>
				<li>An IAM execution role (optional if using an existing one)</li>
				<li>Any other resources or configurations identified as needed by ML builder teams</li>
			</ul>
			<p>An Amazon S3 bucket is noted as optional above because many organizations have existing S3 buckets that are used for data science model-building activities. In these cases, the data science environment may instead include permissions to access an existing S3 bucket. <em class="italic">Figure 2.5</em> shows a basic data science environment template that provisions a new user in SageMaker Studio, an Amazon S3 bucket, and creates a SageMaker execution role that is attached to the Studio domain user. The template can be used to instantiate<a id="_idIndexMarker088"/> multiple user environments:</p>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B17249_02_05.jpg" alt="Figure 2.5 – Amazon SageMaker Studio-based data science environment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.5 – Amazon SageMaker Studio-based data science environment</p>
			<p>The CloudFormation template below shows a pattern that can be used to quickly provision an integrated data science workbench environment using Amazon SageMaker Studio, giving ML builders access to Studio notebooks as well as other integrated features inside SageMaker Studio. Again, the first section contains the parameters that allow you to define how to provision and configure the environment:</p>
			<p class="source-code">AWSTemplateFormatVersion: '2010-09-09'</p>
			<p class="source-code">Metadata:</p>
			<p class="source-code">  License: Apache-2.0</p>
			<p class="source-code">Description: 'Example data science environment creating a new SageMaker Studio User in an existing Studio Domain using an existing VPC.  This template also includes the creation of an Amazon S3 Bucket and IAM Role.'</p>
			<p class="source-code">Parameters:</p>
			<p class="source-code">  StudioDomainID:</p>
			<p class="source-code">            AllowedPattern: '[A-Za-z0-9-]{1,63}'</p>
			<p class="source-code">           Description: ID of the Studio Domain where user should be created (ex. d-xxxnxxnxxnxn)</p>
			<p class="source-code">           Default: d-xxxnxxnxxnxn</p>
			<p class="source-code">           Type: String</p>
			<p class="source-code">  Team:</p>
			<p class="source-code">             AllowedValues:</p>
			<p class="source-code">            - weatherproduct</p>
			<p class="source-code">            - weatherresearch  </p>
			<p class="source-code">            Description: Team name for user working in associated environment</p>
			<p class="source-code">            Default: weatherproduct</p>
			<p class="source-code">            Type: String</p>
			<p class="source-code">  UserProfileName:</p>
			<p class="source-code">           Description: User profile name</p>
			<p class="source-code">           AllowedPattern: '^[a-zA-Z0-9](-*[a-zA-Z0-9]){0,62}'</p>
			<p class="source-code">           Type: String</p>
			<p class="source-code">            Default: 'UserName'</p>
			<p class="source-code">  VPCSecurityGroupIds:</p>
			<p class="source-code"> ... </p>
			<p>In the next section of the template, we identify the resources to provision and configure for your data science environment. Again, the properties of each resource identify the configuration and controls to provision as follows:</p>
			<p class="source-code">Resources:</p>
			<p class="source-code">  StudioUser:</p>
			<p class="source-code">            Type: AWS::SageMaker::UserProfile</p>
			<p class="source-code">            Properties:</p>
			<p class="source-code">           DomainId: !Ref StudioDomainID</p>
			<p class="source-code">            Tags:</p>
			<p class="source-code">            - Key: "Environment"</p>
			<p class="source-code">             Value: "Development"</p>
			<p class="source-code">            - Key: "Team"</p>
			<p class="source-code">            Value: !Ref Team</p>
			<p class="source-code">            UserProfileName: !Ref UserProfileName</p>
			<p class="source-code">           UserSettings:</p>
			<p class="source-code">            ExecutionRole: !GetAtt SageMakerRole.Arn</p>
			<p class="source-code">           SecurityGroups: !Ref VPCSecurityGroupIds</p>
			<p class="source-code"> </p>
			<p class="source-code">  SageMakerRole:</p>
			<p class="source-code">          ... </p>
			<p class="source-code">  S3Bucket:</p>
			<p class="source-code">      ... </p>
			<p>In the CloudFormation <a id="_idIndexMarker089"/>template, we are adding a new user to an existing Studio domain. A <strong class="bold">Studio domain</strong> exists at the AWS account level and there is only one domain per AWS region. You can optionally include the creation of a new Studio domain within your CloudFormation template using the <strong class="source-inline">AWS:SageMaker:Domain</strong> resource type. Creating a Studio domain is a one-time activity per AWS account and per AWS region, so this would be considered a prerequisite to creating users within your Studio domain. In addition, some regulated workloads enforce account-level isolation per ML builder, so in these cases, your CloudFormation template may include the setup of a Studio domain. However, the most common pattern is multiple users per Studio domain. </p>
			<p>Once the template is <a id="_idIndexMarker090"/>built and validated, it is ready to be deployed after uploading the template to Amazon S3 and launching the stack through the AWS console, AWS CLI, or the AWS SDK. Again, this is most frequently done from an administrative account using cross-account privileges to ensure control in the roles that can define and provision environments versus the users who use the provisioned environments. </p>
			<p>After the CloudFormation stack is completed, an ML builder can access the Studio environment and create notebooks through the Studio IDE with AWS IAM sign-in credentials or through AWS SSO credentials and the generated Studio URL. </p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor046"/>Providing and creating data science environments as IT services</h2>
			<p>Creating a governed <a id="_idIndexMarker091"/>catalog of IT services that includes data science environments is a way to build on the concepts of using IaC/CaC for repeatability by adding a central catalog of approved IT services across teams. This is especially useful for large companies or enterprises that rely on central IT or infrastructure teams to provision AWS resources. Creating a central catalog using AWS Service Catalog allows the added benefits of ensuring compliance with corporate standards, accelerating the ability of ML builders to quickly gain access to data science environments, managing versions of products offered through the catalog, and integrating with third-party <strong class="bold">IT Service</strong> <strong class="bold">Management</strong> (<strong class="bold">ITSM</strong>) software<a id="_idIndexMarker092"/> for change control. </p>
			<p>For model building using Amazon SageMaker, AWS Service Catalog allows teams to take the AWS CloudFormation templates discussed in the previous section and offer those templates as versioned products inside a central portfolio of products. The approved configurations for those products can be centrally managed and governed. AWS Service Catalog lets teams control the users who have access to launch a product, which means admins can also provide self-service capabilities to ML builders to ensure that they have quick access to governed<a id="_idIndexMarker093"/> data science environments: </p>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/B17249_02_06.jpg" alt="Figure 2.6 – Centrally managed data science environments using AWS Service Catalog&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.6 – Centrally managed data science environments using AWS Service Catalog</p>
			<p>When products are added to a portfolio, you can optionally add product constraints. <strong class="bold">Product constraints</strong> allow <a id="_idIndexMarker094"/>you to add controls in terms of how an ML builder uses products. Several constraint types are allowed, including launch, notification, template, stack set, and tag update constraints. Each of these constraint types can be applied to any product; however, launch and template constraints have unique considerations for data science environments. </p>
			<p>A launch constraint<a id="_idIndexMarker095"/> allows you to specify the IAM role that AWS Service Catalog assumes for provisioning AWS resources for a product within a portfolio. This follows the recommended practice of granting least privilege by providing ML builders with access to the resources that get provisioned, but not allowing ML builders access to provision resources outside of AWS Service Catalog. </p>
			<p>For data science environments, a launch constraint can be added to a product in the portfolio using a pre-defined IAM role that is assumed for provisioning resources. This means you do not need to grant privileges for actions such as creating a new IAM role or working with AWS CloudFormation to the ML builder directly. </p>
			<p>A template constraint<a id="_idIndexMarker096"/> is a JSON-formatted text file that defines rules describing when an ML builder can use the templates, and which values they can specify for the parameters defined in the AWS CloudFormation template. Each rule has two properties: <em class="italic">a rule condition</em> (optional) and <em class="italic">assertions</em> (required). </p>
			<p>The rule condition determines when the rule takes effect, and the assertion describes the values a user can specify for a specific parameter. For data science environments, template constraints can be used for defining allowable configurations such as instance types via assertions. You can also add a rule condition to that assertion that limits the allowed instances within specific environments. </p>
			<p>AWS Service Catalog provides added benefits over using AWS CloudFormation by creating a centralized portfolio for <em class="italic">data science environments</em> that contains managed products for provisioning data science environments. The first step is to create a portfolio, which can be done through the AWS CLI, AWS SDK, or AWS console, as shown below.</p>
			<h2 id="_idParaDest-48"><a id="_idTextAnchor047"/>Creating a portfolio in AWS Service Catalog </h2>
			<p>To<a id="_idIndexMarker097"/> create a <a id="_idIndexMarker098"/>portfolio, perform the following steps:</p>
			<ol>
				<li value="1">From AWS Service Catalog service, select <strong class="bold">Create portfolio</strong>: <div id="_idContainer035" class="IMG---Figure"><img src="image/B17249_02_07.jpg" alt="Figure 2.7 – AWS Service Catalog – creating a new portfolio&#13;&#10;"/></div><p class="figure-caption">Figure 2.7 – AWS Service Catalog – creating a new portfolio</p></li>
				<li>Define your portfolio by entering the following under <strong class="bold">Create portfolio</strong>: <ul><li><strong class="bold">Portfolio name</strong>: <strong class="source-inline">Data Science Environments</strong></li><li><strong class="bold">Description</strong>: <strong class="source-inline">Service catalog portfolio of approved products for provisioning data science environments for ML builders</strong></li><li> <strong class="bold">Owner</strong>: Your name</li></ul></li>
				<li>Click the <strong class="bold">Create</strong> button to create the portfolio. You will then see a <strong class="bold">Success</strong> message, indicating the portfolio is available to add products.</li>
			</ol>
			<p>As products are<a id="_idIndexMarker099"/> added to the portfolio and provisioned, AWS Service<a id="_idIndexMarker100"/> Catalog provides visibility for admins to view all provisioned products and perform administrative tasks, such as identifying user resource allocation. ML builders also have a central view of all the provisioned products they have requested: </p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer036" class="IMG---Figure">
					<img src="image/B17249_02_08.jpg" alt="Figure 2.8 – List of all provisioned products&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.8 – List of all provisioned products</p>
			<p>The unique aspects of products for SageMaker notebook instances and SageMaker Studio are largely handled within the CloudFormation templates. The high-level steps to create a product are consistent between the two types of data science environments. The following sections include detailed sample scenarios extending the CloudFormation templates previously created for both Amazon SageMaker notebook instances and Amazon SageMaker Studio. </p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor048"/>Amazon SageMaker notebook instances</h2>
			<p>A new product can be added to an AWS Service Catalog portfolio using the AWS CLI, AWS SDK, or the AWS console. When a new product is added to a portfolio, the CloudFormation <a id="_idIndexMarker101"/>template that defines that environment must be uploaded to an S3 bucket and provided as input. In this example, the previous CloudFormation template will be used in addition to several other parameters required on input, as shown in the following: </p>
			<ol>
				<li value="1">From within the portfolio created, select <strong class="bold">Upload new product</strong>:<div id="_idContainer037" class="IMG---Figure"><img src="image/B17249_02_09.jpg" alt="Figure 2.9 – AWS Service Catalog – uploading a new product to the portfolio&#13;&#10;"/></div><p class="figure-caption">Figure 2.9 – AWS Service Catalog – uploading a new product to the portfolio</p></li>
				<li>Under <strong class="bold">Enter product details</strong>, there are three sections of information to fill out, including <strong class="bold">Product details</strong>, <strong class="bold">Version details</strong>, and <strong class="bold">Support details</strong>.<ul><li>For <strong class="bold">Product details</strong>, this section contains information about the product. Enter the following information in the fields on input and then leave any field not specified blank: <ul><li><strong class="bold">Product name</strong>: Basic SageMaker notebook instance environment.</li><li><strong class="bold">Description</strong>: Basic data science environment using Amazon SageMaker notebook instances, including (1) <strong class="bold">New Notebook Instance</strong> (2) <strong class="bold">SageMaker Execution IAM Service Role</strong> (3) <strong class="bold">S3 Bucket.</strong></li><li><strong class="bold">Owner</strong>: Your name.</li></ul></li><li>The <strong class="bold">Version details</strong> section <a id="_idIndexMarker102"/>includes the S3 location of the CloudFormation template combined with version and release details. Enter the following in the fields matching on input, leaving any field not specified blank:<ul><li><strong class="bold">Choose a method</strong>: Select the radio button for <strong class="bold">Use a CloudFormation template</strong>.</li><li><strong class="bold">Use a CloudFormation template</strong>: Enter the S3 URL for the CloudFormation template in the format <strong class="source-inline">https://…</strong>.</li></ul><p class="callout-heading">Important note</p><p class="callout">The default location for templates used on launched stacks is <strong class="source-inline">https://s3.&lt;region&gt;.amazonaws.com/cf-templates-&lt;hash&gt;-region/notebook-instance-environment.yaml</strong>, or you can upload the CloudFormation template provided for this chapter directly to an S3 bucket you choose.</p><ul><li><strong class="bold">Version name</strong>: <strong class="source-inline">release-1.0</strong>.</li><li><strong class="bold">Description</strong>: <strong class="source-inline">Initial product release</strong>.</li></ul></li><li>The <strong class="bold">Support details</strong> section includes the information about the support contacts and support information. Enter the following for each field specified and leave any field not specified blank:</li><li><strong class="bold">Email contact</strong>: Your email@mail.com.</li></ul></li>
				<li>After filling in the information as described in the preceding steps, scroll to the bottom, select <strong class="bold">Review</strong>, and then <strong class="bold">Create Product</strong>.</li>
				<li>The product will now be <a id="_idIndexMarker103"/>visible within the product list for the <strong class="bold">Data Science Environments</strong> portfolio. </li>
			</ol>
			<p>After adding the product to the portfolio, constraints can be added to the product. <strong class="bold">Constraints</strong> are <a id="_idIndexMarker104"/>optional but offer additional recommended enforcement of practices, such as least <a id="_idIndexMarker105"/>privilege, and additional controls to enforce best practices such as cost optimization. To enforce minimum privileges, a launch constraint can be added to the product by first creating a launch IAM role that will be assumed when provisioning a product as documented in AWS Service Catalog product documentation: <a href="https://docs.aws.amazon.com/servicecatalog/latest/adminguide/constraints-launch.html">https://docs.aws.amazon.com/servicecatalog/latest/adminguide/constraints-launch.html</a>.</p>
			<p>In this IAM policy for this role, you'll need to add each service that the product provisions to the action list. Therefore, in this case, the following IAM policy may be overly permissive for your needs, in which case you can scope the role down to specific actions, conditions, and resources for your use case:</p>
			<p class="source-code">{</p>
			<p class="source-code"> </p>
			<p class="source-code">{</p>
			<p class="source-code">            "Version": "2012-10-17",</p>
			<p class="source-code">            "Statement": [</p>
			<p class="source-code">            {</p>
			<p class="source-code">            "Effect": "Allow",</p>
			<p class="source-code">             "Action": [</p>
			<p class="source-code">                         "s3:*"</p>
			<p class="source-code">            ],</p>
			<p class="source-code">           "Resource": "*",</p>
			<p class="source-code">            "Condition": {</p>
			<p class="source-code">                      "StringEquals": {</p>
			<p class="source-code">                     "s3:ExistingObjectTag/servicecatalog:provisioning": "true"</p>
			<p class="source-code">                     }</p>
			<p class="source-code">          }</p>
			<p class="source-code">          },</p>
			<p class="source-code">          {</p>
			<p class="source-code">          "Effect": "Allow",</p>
			<p class="source-code">           "Action": [</p>
			<p class="source-code">                        "...",</p>
			<p class="source-code">             ],</p>
			<p class="source-code">          "Resource": "*"</p>
			<p class="source-code">           }</p>
			<p class="source-code">           ]</p>
			<p class="source-code">}</p>
			<p>After creating the launch role and the policy to dictate permissions, the role needs to be applied to the product as a launch constraint, as shown in the following screenshot. The detailed instructions to apply <a id="_idIndexMarker106"/>a launch constraint are included in the existing AWS product documentation, <a href="https://docs.aws.amazon.com/servicecatalog/latest/adminguide/constraints-launch.html">https://docs.aws.amazon.com/servicecatalog/latest/adminguide/constraints-launch.html</a>, under <strong class="bold">Applying a Launch Constraint</strong> -&gt; <strong class="bold">To assign the role to a product</strong>. After applying the IAM role to the product launch constraint, you'll see the constraint listed for the product, as shown in the following screenshot: </p>
			<div>
				<div id="_idContainer038" class="IMG---Figure">
					<img src="image/B17249_02_010.jpg" alt="Figure 2.10 – AWS Constraints&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.10 – AWS Constraints</p>
			<p>The launch constraint tells Service<a id="_idIndexMarker107"/> Catalog to assume the <strong class="source-inline">ServiceCatalog</strong>-<strong class="source-inline">DataScienceProducts</strong> role when an end user launches the product. This role contains the policy we created with the privileges needed to provision and configure all the resources in the <strong class="source-inline">CloudFormation</strong> template for that product. </p>
			<p>Finally, we will add a template constraint to limit the options for instance type size that is available to end users. This allows the implementation of cost controls on the type of instance that can be provisioned. You can optionally implement multiple constraints such as storage size. Template constraints <a id="_idIndexMarker108"/>are added as documented in the AWS product documentation: <a href="https://docs.aws.amazon.com/servicecatalog/latest/adminguide/catalogs_constraints_template-constraints.html">https://docs.aws.amazon.com/servicecatalog/latest/adminguide/catalogs_constraints_template-constraints.html</a>. The specific template constraint JSON is listed in the following code block, where we are identifying that only the noted instance types are approved and available for use:</p>
			<p class="source-code">{</p>
			<p class="source-code">  "Rules": {</p>
			<p class="source-code">            "Rule1": {</p>
			<p class="source-code">            "Assertions": [</p>
			<p class="source-code">            {</p>
			<p class="source-code">            "Assert": {</p>
			<p class="source-code">             "Fn::Contains": [</p>
			<p class="source-code">             [</p>
			<p class="source-code">                        "ml.t2.large",</p>
			<p class="source-code">                       "ml.t2.xlarge",</p>
			<p class="source-code">                         "ml.t3.large",</p>
			<p class="source-code">                         "ml.t3.xlarge"</p>
			<p class="source-code">           ],</p>
			<p class="source-code">            {</p>
			<p class="source-code">                      "Ref": "NotebookInstanceType"</p>
			<p class="source-code">             }</p>
			<p class="source-code">           ]</p>
			<p class="source-code">          },</p>
			<p class="source-code">          "AssertDescription": "Instance type should have approved types"</p>
			<p class="source-code">             }</p>
			<p class="source-code">            ]</p>
			<p class="source-code">           }</p>
			<p class="source-code">  }</p>
			<p class="source-code">}</p>
			<p>After creating the preceding template constraint, you'll now see two constraints for this product in the console:</p>
			<div>
				<div id="_idContainer039" class="IMG---Figure">
					<img src="image/B17249_02_011.jpg" alt="Figure 2.11 – AWS Service Catalog – applied constraint&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.11 – AWS Service Catalog – applied constraint</p>
			<p>The product is then available, with the <a id="_idIndexMarker109"/>constraints we identified, within the Data Science Environment portfolio and can be made available for self-service provisioning by ML builders. </p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor049"/>Amazon SageMaker Studio </h2>
			<p>In this section, the CloudFormation template<a id="_idIndexMarker110"/> to create a data science environment in SageMaker Studio will be used to create a new product inside the data science environment portfolio. Again, a new product can be added to an AWS Service Catalog portfolio using the AWS CLI, AWS SDK, or the AWS console. When a new product is added to a portfolio, the CloudFormation template that defines that environment must be uploaded to an S3 bucket and provided as input. The steps to add a product require administrative privileges in Service Catalog and are performed in the <strong class="bold">Administration</strong> view:</p>
			<ol>
				<li value="1">From within the <strong class="source-inline">Data Science Environments</strong> portfolio, click on  <strong class="bold">Upload new product</strong>.</li>
				<li>Under <strong class="bold">Enter product details</strong>, there are three sections of information to fill out, including <strong class="bold">Product details</strong>, <strong class="bold">Version details</strong>, and <strong class="bold">Support details</strong>.<p>For <strong class="bold">Product details</strong>, this section contains information about the product. Enter the following, leaving any field not specified blank: </p><p><strong class="bold">a) Product name</strong>: <strong class="source-inline">Basic SageMaker Studio Environment</strong></p><p><strong class="bold">b) Description</strong>: Basic data science environment using Amazon SageMaker Studio, including (1) <strong class="bold">New User in Existing Studio Domain</strong> (2) <strong class="bold">SageMaker Execution IAM Service Role</strong> (3) <strong class="bold">S3 Bucket</strong></p><p><strong class="bold">c) Owner</strong>: Your name</p><p>For <strong class="bold">Version details</strong>, this section includes the S3 location of the CloudFormation template combined with version and release details. Enter the following, leaving any field not specified blank:</p><p><strong class="bold">d) Choose a method</strong>: Select the radio button for <strong class="bold">Use a CloudFormation template</strong>.</p><p><strong class="bold">e) Use a CloudFormation template</strong>: Enter the S3 URL for the CloudFormation <a id="_idIndexMarker111"/>template in the format https://…<strong class="source-inline"> </strong>Note: The default location for templates used on launched stacks is <strong class="source-inline">https://s3.&lt;region&gt;.amazonaws.com/cf-templates-&lt;hash&gt;-region/studio-environment.yaml</strong>, or you can upload the CloudFormation template provided for this chapter directly to an S3 bucket of your choosing.</p><p><strong class="bold">f) Version name</strong>: <strong class="source-inline">release-1.0</strong>.</p><p><strong class="bold">g) Description</strong>: <strong class="source-inline">Initial product release</strong>.</p><p>For <strong class="bold">Support details</strong>, this section includes information about the support contacts and support information. Enter the following, leaving any field not specified blank:</p><p><strong class="bold">Email contact</strong>: Your email@mail.com</p></li>
				<li>After filling in the information as described in the preceding steps, scroll to the bottom, select <strong class="bold">Review</strong>, and then <strong class="bold">Create Product</strong>. </li>
				<li>The product will now be visible within the product list for the <strong class="bold">Data Science Environments</strong> portfolio.</li>
			</ol>
			<p>After adding the product to the portfolio, constraints can be added to the product. You can then add a launch constraint, to enforce minimum privileges, and template constraints based on your use case using the same steps performed under your notebook instance product steps. </p>
			<p>After configuring the <a id="_idIndexMarker112"/>products, they can be made available for self-service provisioning by ML builders. ML builders must be granted access to the AWS Service Catalog end user view in the AWS console. Please refer to the following documentation for details on sharing your portfolio and granting access to end users: <a href="https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-deploy.html">https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-deploy.html</a>.</p>
			<p>This section covered the advantages of using IaC/CaC (AWS CloudFormation) and a centrally managed catalog of IT services (AWS Service Catalog) to create data science environments at scale. </p>
			<p>Please head over to the <em class="italic">References</em> section to find additional reference links that you may find useful after reading this section.</p>
			<h1 id="_idParaDest-51"><a id="_idTextAnchor050"/>Summary</h1>
			<p>In this chapter, you saw how to map SageMaker capabilities to different phases of the ML life cycle. You got a quick look at important SageMaker capabilities and saw how to set up your own SageMaker environment.</p>
			<p>This chapter further covered the advantages of using IaC/CaC (AWS CloudFormation) as well as a centrally managed catalog of IT services (AWS Service Catalog) to create data science environments at scale. The approaches discussed provide the guidance needed to reduce manual effort, provide consistency, accelerate access to model-building services, and enforce governance controls within model-building environments.</p>
			<p>In the next chapter, you will learn more about labeling data for ML projects.</p>
			<h1 id="_idParaDest-52"><a id="_idTextAnchor051"/>References </h1>
			<p>The following are some of the references that you might find useful after reading this section:</p>
			<ul>
				<li>Amazon SageMaker notebook instances: <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html">https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html</a></li>
				<li>Amazon SageMaker Studio Onboarding:<p><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html">https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html</a> </p></li>
				<li>Amazon SageMaker Studio:<p><a href="https://aws.amazon.com/sagemaker/studio/">https://aws.amazon.com/sagemaker/studio/</a> <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks.html">https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks.html</a></p></li>
				<li>Notebook Comparison:<p><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-comparison.html">https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-comparison.html</a></p></li>
				<li>AWS Service Catalog:<p><a href="https://aws.amazon.com/servicecatalog/">https://aws.amazon.com/servicecatalog/</a></p></li>
				<li>AWS CloudFormation: <p><a href="https://aws.amazon.com/cloudformation/">https://aws.amazon.com/cloudformation/</a></p></li>
			</ul>
		</div>
	</body></html>