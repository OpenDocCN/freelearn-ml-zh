- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hands-On Exploring Data Labeling Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the dynamic landscape of machine learning and artificial intelligence, effective
    data annotation plays a pivotal role in enhancing model performance and fostering
    accurate predictions. As we delve into the intricacies of image, text, video,
    and audio annotation, we find ourselves immersed in the realm of the **Azure Machine
    Learning** service and its robust **data labeling** capabilities. This chapter
    serves as a comprehensive guide to leveraging Azure Machine Learning data labeling
    tools to create precise and meaningful annotations.
  prefs: []
  type: TYPE_NORMAL
- en: We will also look at another open source data labeling tool, **Label Studio**,
    for annotating image, video, and text data. Label Studio empowers data scientists,
    developers, and domain experts to collaboratively annotate various data types
    such as images, video, and text.
  prefs: []
  type: TYPE_NORMAL
- en: We also see how to annotate data using **pyOpenAnnotate**, and finally, we will
    explore **Computer Vision Annotation Tool** (**CVAT**), an open source, collaborative
    data labeling platform for streamlining the annotation process across various
    data types.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Labeling image, text, and audio data using Azure Machine Learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labeling image, video, and text data using Label Studio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labeling image and video data using pyOpenAnnotate and CVAT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join us as we navigate the intricacies of data labeling with Azure Machine Learning,
    empowering you to harness the full potential of annotated datasets and propel
    your machine learning endeavors to new heights.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s understand the prerequisites needed for each tool we’ll discuss for you
    to follow along in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning data labeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Azure Machine Learning provides labeling tools to rapidly prepare data for
    machine learning projects. Let’s create an Azure subscription and Azure Machine
    Learning workspace as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure subscription**: You can create a free Azure subscription at [https://azure.microsoft.com/en-us/free](https://azure.microsoft.com/en-us/free).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Machine Learning workspace**: Once your Azure subscription is ready,
    you can create an Azure Machine Learning workspace in that subscription.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Label Studio
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Install the `label-studio` Python library using your Python editor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, start the Label Studio development server using the following shell command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: pyOpenAnnotate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: pyOpenAnnotate is a simple tool that helps to label and annotate images and
    videos using OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s install this tool using the Python editor as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The dataset and code used in this chapter are available on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dataset**: [https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/datasets/Ch12](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/datasets/Ch12)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code**: [https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/code/Ch12](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/code/Ch12
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data labeling using Azure Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With an increasing demand for sophisticated models capable of understanding
    diverse data types, the importance of accurate annotations cannot be overstated.
    Azure Machine Learning offers a powerful solution, providing a data labeling interface
    designed to streamline the annotation process for images, text, and audio. Azure
    Machine Learning’s data labeling capability facilitates the process of creating,
    managing, and monitoring data labeling projects and enables seamless collaboration
    among data scientists, domain experts, and annotators.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the benefits of data labeling with Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of data labeling with Azure Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data labeling is used to train machine learning models and helps to improve
    the accuracy of these models. Azure Machine Learning data labeling tools can be
    used to create image, text, and audio labeling projects.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning data labeling tools provide the ability to manage and
    monitor labeling projects seamlessly from within the studio web experience and
    reduce the back-and-forth process of labeling data offline.
  prefs: []
  type: TYPE_NORMAL
- en: After labeling the data in an Azure Machine Learning data labeling project,
    the labeled data can be exported to Azure Blob storage using the **Export** option
    in the project. From there, this labeled data can be integrated as a dataset in
    the Azure Machine Learning pipeline for training machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Data that is labeled on-premises using other open source tools, such as Label
    Studio and pyOpenAnnotate, also can be integrated with Azure Machine Learning
    by creating a dataset from local files.
  prefs: []
  type: TYPE_NORMAL
- en: Let us see how to create a labeling project, how to upload data, how to create
    a labeling task, and how to manage and monitor the labeling project using Azure
    Machine Learning data labeling tools.
  prefs: []
  type: TYPE_NORMAL
- en: Data labeling steps using Azure Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is an overview of the steps to create image, text, and audio labeling
    projects using Azure Machine Learning data labeling tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Create a labeling project**: Sign into Azure Machine Learning and create
    a new labeling project. You can choose to create an image, text, or audio labeling
    project.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Create a labeling task for your data**: You can choose to create a classification,
    object detection, instance segmentation, or semantic segmentation task.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Upload data**: Upload the data you want to label to your labeling project.
    You can upload data from your local machine or from a cloud storage account.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Label your data**: Use the labeling tool to label your data. In the case
    of machine learning-assisted data labeling, machine learning algorithms may be
    triggered to assist with the data labeling task. After some data has been labeled
    manually, machine learning algorithms automatically group similar images on the
    screen with the suggested label name.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Manage and monitor your labeling project**: Monitor the progress of your
    labeling project and tasks from within the studio web experience. You can also
    export your labeled data as an Azure Machine Learning dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following sections, we are going to discuss data labeling for image,
    text, and audio data using Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: Image data labeling with Azure Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure Machine Learning is an industry-leading machine learning and AI platform
    designed to build and deploy machine learning and AI applications. Data scientists,
    machine learning engineers, and software engineers can use it in their day-to-day
    work for training, deploying their models, and managing the machine learning project
    life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing good data is key for any machine learning project. Azure Machine Learning
    provides the capability to prepare labeled data for training. Let us first see
    how to label images using Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure Machine Learning can be used to label images at a large scale and automate
    the data labeling process. We will see simple image data labeling for the following
    image. We will label this image with the labels `man` and `bike`. This image is
    available in the `Datasets` folder in the GitHub path specified in the *Technical*
    *requirements* section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1 – Bike_riding_man image](img/B18944_12_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – Bike_riding_man image
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go through the steps to label images with Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Create an Azure Machine Learning workspace
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before creating a labeling project, you need to create an Azure Machine Learning
    workspace if you have not already created one, as mentioned in the *Technical*
    *requirements* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to [portal.azure.com](https://portal.azure.com). Under **Azure services**,
    you will see the **Create a resource** option. Click on **+ Create a resource**,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2 – Create a resource](img/B18944_12_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Create a resource
  prefs: []
  type: TYPE_NORMAL
- en: Then, on the following `azure machine learning` in the search box. Click on
    **Azure Machine Learning**, create an Azure Machine Learning service, and follow
    the prompts to enter a name for it.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – Creating an Azure Machine Learning service from Marketplace](img/B18944_12_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – Creating an Azure Machine Learning service from Marketplace
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, click on the Azure Machine Learning workspace that you created. In the
    following screenshot, you can see that the name of the Azure Machine Learning
    workspace is `azuremllabelling`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.4 – Azure services](img/B18944_12_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – Azure services
  prefs: []
  type: TYPE_NORMAL
- en: 'When you click on your Azure Machine Learning workspace name, `azuremllabelling`,
    you will see the following screen. Launch the Azure Machine Learning studio by
    clicking on the blue **Launch** **studio** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5 – Azure Machine Learning workspace](img/B18944_12_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.5 – Azure Machine Learning workspace
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Create a data labeling project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We want to create a data labeling project so that we can upload images and label
    them or assign them to labelers and manage the workflow effectively.
  prefs: []
  type: TYPE_NORMAL
- en: In your Azure Machine Learning Studio, on the left-hand side, under **Manage**,
    you will see a **Data labeling** option; click on this.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6 – Azure ML studio](img/B18944_12_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 – Azure ML studio
  prefs: []
  type: TYPE_NORMAL
- en: Enter a name for your data labeling project and select **Image** for **Media
    type**. You also need to select a **Labeling task type** option from five different
    types for image labeling, as shown in *Figure 12**.7*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on your scenario, choose a labeling task type that suits your needs:'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to label an image with only one category from a list of options,
    choose **Image** **Classification Multi-class**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to label an image with multiple categories from a list of options,
    choose `dog` and `daytime` labels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to label each object in an image with a category and a bounding
    box, choose **Object Identification (****Bounding Box)**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to label each object in an image with a category and a polygon outline,
    choose **Polygon (****Instance Segmentation)**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to label each pixel in an image with a category and a mask, choose
    **Semantic** **Segmentation (Preview)**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Enter the project name `Image_data_labeling_project`. Select the **Object Identification
    (Bounding Box)** labeling task type, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.7 – Selecting the labeling task type](img/B18944_12_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.7 – Selecting the labeling task type
  prefs: []
  type: TYPE_NORMAL
- en: After entering the project details, the next step is **Add workforce**, which
    we can skip for this example. This step is only required if you want to add any
    vendor or labeling company from the Azure Marketplace to this labeling project.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Upload your data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are two options to create a data asset. You can either create a data asset
    by uploading your files from Azure Blob storage, or you can directly create a
    data asset by uploading your local files.
  prefs: []
  type: TYPE_NORMAL
- en: You can find detailed steps to create a data asset from Azure Blob storage or
    by uploading local files at [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-image-labeling-projects?view=azureml-api-2#specify-the-data-to-label](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-image-labeling-projects?view=azureml-api-2#specify-the-data-to-label).
  prefs: []
  type: TYPE_NORMAL
- en: 'To upload data, first, let’s create a data asset with the name `bike_riding_man`,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.8 – Creating a data asset](img/B18944_12_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.8 – Creating a data asset
  prefs: []
  type: TYPE_NORMAL
- en: Next, select the data source and create a data asset using one of the following
    two options.
  prefs: []
  type: TYPE_NORMAL
- en: Option 1 – Create a data asset from files in Azure Blob storage
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Generate a data asset using an Azure datastore. While local file uploads are
    common, Azure Storage Explorer offers a more efficient method for transferring
    large data assets. It is recommended as the default tool for file movement.
  prefs: []
  type: TYPE_NORMAL
- en: For the data source, select **From Azure storage** to upload files from Azure
    Blob storage and create the data asset.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.9 – Creating a data asset from Azure Blob storage](img/B18944_12_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.9 – Creating a data asset from Azure Blob storage
  prefs: []
  type: TYPE_NORMAL
- en: Option 2 – Create a data asset from files on your local system
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You can upload files from your local system and create a data asset, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.10 – Creating a data asset from local files](img/B18944_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.10 – Creating a data asset from local files
  prefs: []
  type: TYPE_NORMAL
- en: For this example, I have uploaded data from the local filesystem as the data
    asset size is small and available on the local system.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – Label image data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now, select the `bike_riding_man` data asset that we created in the previous
    step:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.11 – Selecting the data asset](img/B18944_12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.11 – Selecting the data asset
  prefs: []
  type: TYPE_NORMAL
- en: After selecting the data asset, click on **Next**. The **Incremental refresh**
    step is optional. This is required if we want to automatically refresh new data
    in the labeling project. For this example, let us skip this optional step and
    click **Next** again.
  prefs: []
  type: TYPE_NORMAL
- en: You will land on the following `Bike` and `person` for this example.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.12 – Adding label categories](img/B18944_12_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.12 – Adding label categories
  prefs: []
  type: TYPE_NORMAL
- en: After adding the categories, click on **Next**. You will land on the **Labeling
    instructions** page. Let’s skip this optional step and click on **Next** again.
    You will now be on the **Quality control (preview)** page. This is currently in
    preview. It is used to send labels to multiple labelers to get more accurate labels.
    Skip this by clicking on **Next**. You will now be on the **ML assisted** **labeling**
    page.
  prefs: []
  type: TYPE_NORMAL
- en: This step is optional. If you want to train a model to pre-label the data, then
    you can use this, but beware that it incurs additional compute costs.
  prefs: []
  type: TYPE_NORMAL
- en: If **ML assisted labeling** is enabled, after manually labeling the configured
    number of items, then the ML model will automatically label the rest of the items
    and provide suggestions for human review.
  prefs: []
  type: TYPE_NORMAL
- en: The threshold for the number of manually labeled items to commence ML assisted
    labeling isn’t fixed and can significantly vary between labeling projects. In
    some instances, pre-labeling or cluster tasks may appear after manually labeling
    around 300 items. This threshold depends on how similar your dataset is to the
    dataset that the ML model was already trained on.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.13 – ML assisted labeling](img/B18944_12_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.13 – ML assisted labeling
  prefs: []
  type: TYPE_NORMAL
- en: Finally, click on `Image_data_labeling_project`, has been created on the **Data**
    **labeling** page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the project, and it will open the next screen. Click on **Label data**
    to start labeling the data that you uploaded:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.14 – Label data](img/B18944_12_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.14 – Label data
  prefs: []
  type: TYPE_NORMAL
- en: When you click on **Label data**, it will show the images that you uploaded,
    and you can now start labeling those images.
  prefs: []
  type: TYPE_NORMAL
- en: Labeling the person
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Select the `person` tag and then create a bounding box for the person in the
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.15 – Labeling the person](img/B18944_12_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.15 – Labeling the person
  prefs: []
  type: TYPE_NORMAL
- en: Labeling the bike
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Similarly, select the `Bike` tag, draw the bounding box around the bike to label
    it, and click on the **Submit** button. This will take you to the next image.
    You can continue this process for all your images. You can navigate to images
    using the **Previous** and **Next** buttons on this screen.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.16 – Labeling the bike](img/B18944_12_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.16 – Labeling the bike
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, you can label all other images and click **Submit**. All the images
    labeled by the labelers will be shown on the dashboard under **Review labels**,
    as shown in the following screenshot, and here the reviewer can review and approve
    those labels by clicking on the **Approve** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.17 – Review labels](img/B18944_12_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.17 – Review labels
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, you can export the labeled data using the **Label export** option
    on the **Details** tab, as shown in the following screenshot, and use that exported
    data in machine learning experiments for training:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.18 – Exporting the labels](img/B18944_12_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.18 – Exporting the labels
  prefs: []
  type: TYPE_NORMAL
- en: You have seen how to create a project for image data labeling and then label
    the image data in Azure Machine Learning. Now, let’s see how to label text data
    using Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: Text data labeling with Azure Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, let’s see how to label text documents with Azure Machine Learning.
    To do this, select **Text** for **Media type**, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.19 – Text data labeling](img/B18944_12_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.19 – Text data labeling
  prefs: []
  type: TYPE_NORMAL
- en: 'In Azure Machine Learning data labeling, you can label the text in three different
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: You can label using a single tag.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can label using two tags.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can annotate entities in a text. For example, entities can be the name of
    the person, location, or organization in the text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Choose the appropriate labeling task type based on your scenario from the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Text Classification Multi-class**: In this case, you will assign only one
    label from a set of classes to the entire text entry.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text Classification Multi-label**: In this case, you can assign two labels
    to the entire text entry, as shown in the following figure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 12.20 – Text classification multi-label](img/B18944_12_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.20 – Text classification multi-label
  prefs: []
  type: TYPE_NORMAL
- en: '**Text Named Entity Recognition**: For example, in a sentence, if we want to
    identify a person or organization entity, then we can select this task type.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will see more about this in the following steps. Let’s start creating a text
    labeling project in Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Create a text data labeling project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: On the Azure Machine Learning page, the steps are similar to when we created
    a labeling project for image data labeling in the previous section but with a
    few exceptions, such as the **Labeling task** **type** step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Add project** on the **Data** **Labeling** page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.21 – Add project](img/B18944_12_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.21 – Add project
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the project name for the text data labeling project, select **Text**
    for **Media type**, and select the labeling task type as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.22 – Project details](img/B18944_12_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.22 – Project details
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Create data asset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we saw in the previous section for the image data labeling project, we can
    create a data asset with two options: either from Azure Blob storage or from local
    files.'
  prefs: []
  type: TYPE_NORMAL
- en: After selecting the data asset, click on **Next**. The next step, **Incremental
    refresh**, is optional. This is required if we want to automatically refresh new
    data in the labeling project. For this example, skip this optional step and click
    **Next**.
  prefs: []
  type: TYPE_NORMAL
- en: Then, you will land on the following **Label** **categories** screen.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Select the label category
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: On the **Label categories** page, add the label categories that you want to
    use for labeling your text data.
  prefs: []
  type: TYPE_NORMAL
- en: For this exercise, add the `animal`, `person`, and `location` label categories
    to label the text documents.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.23 – Adding label categories](img/B18944_12_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.23 – Adding label categories
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Next**, skip the optional steps as discussed in the previous section,
    and create the labeling project for text data.
  prefs: []
  type: TYPE_NORMAL
- en: 'You have now created the `textannotationproject` project and can see it on
    the **Data Labeling** page, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.24 – The textannotationproject project](img/B18944_12_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.24 – The textannotationproject project
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – Label the text data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now, click on the project name. On the following page, click on the **Label
    data** option under **textannotationproject**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.25 – Dashboard – Label data option](img/B18944_12_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.25 – Dashboard – Label data option
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, you can annotate your text data here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.26 – Annotating the text data](img/B18944_12_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.26 – Annotating the text data
  prefs: []
  type: TYPE_NORMAL
- en: We have seen how to create a project for text data labeling and then label the
    text documents in Azure Machine Learning. Now, let’s see how to label audio data
    in Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: Audio data labeling using Azure Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, let’s see how to label audio data using Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: In Azure Machine Learning, we can annotate pieces of audio using text labels.
    We are going to use the `cat_1.wav` audio dataset for this. We will play the audio
    in Azure Machine Learning and use the `cat` label for that audio. This file is
    located in the `Datasets/Ch12` folder at the GitHub path specified in the *Technical
    requirements* section. The same process can be followed to label the required
    number of audio files.
  prefs: []
  type: TYPE_NORMAL
- en: After labeling, we are going to export the labeled audio files to Azure storage,
    and from there, we can consume them in the Azure Machine Learning pipeline as
    a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to image data and text data, first, we will create a labeling project
    for audio data.
  prefs: []
  type: TYPE_NORMAL
- en: All the steps all similar to the previous section, except the labeling task
    type, for creating a new audio project.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s create the project first for audio data labeling in Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Create the project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s create an audio project by following the same steps that we have seen
    in the previous section for creating image and text data labeling projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the project name, select **Audio** for **Media type**, and select **Audio
    Transcription (Preview)** for **Labeling** **task type**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.27 – Creating a project for audio transcription](img/B18944_12_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.27 – Creating a project for audio transcription
  prefs: []
  type: TYPE_NORMAL
- en: The sample audio dataset that we are going to label is `cat_1.wav`. This is
    available in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Once the project is created, go to the **Data Labeling** page and click on the
    project name. On the project page, click on **Label data** in the same manner
    that we saw for the text labeling project.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Label the audio data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You will now be on the audio page where you can play the audio and enter the
    tag name in text format in the **Transcription** area under the audio.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you need to add the transcription label for your audio data. As shown
    in the following screenshot, there is a **Play** tab to play the audio:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.28 – Playing the audio](img/B18944_12_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.28 – Playing the audio
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the `cat` label for this audio, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.29 – Labeling the text for a piece of audio](img/B18944_12_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.29 – Labeling the text for a piece of audio
  prefs: []
  type: TYPE_NORMAL
- en: You have seen how to create a project for audio data and label the audio data
    in Azure Machine Learning. Let’s now see how to integrate this labeled data for
    training ML models in the Azure Machine Learning pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Integration of the Azure Machine Learning pipeline with the labeled dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To integrate labeled data from Azure Machine Learning data labeling into machine
    learning pipelines, you can follow these general steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Set up the Azure Machine Learning workspace**: Ensure you have an Azure Machine
    Learning workspace set up. You can create one using the Azure portal.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data labeling**: Use the Azure Machine Learning data labeling capabilities
    to label your data. You can use Azure Machine Learning Studio to create labeling
    projects, upload data, and manage labeling tasks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Store the labeled data**: After data labeling is complete, the labeled data
    is typically stored in storage. You can create a dataset in Azure Machine Learning
    that points to the location of your labeled data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Define the machine learning pipeline**: Create an Azure Machine Learning
    pipeline that includes steps for data preprocessing, model training, and evaluation.
    You can use the Azure Machine Learning SDK to define these steps in a Python script.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reference the labeled dataset**: In the pipeline, reference the labeled dataset
    you created in the *Data labeling* step. This dataset will be used for training
    your machine learning model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Run the pipeline**: Execute the pipeline in your Azure Machine Learning workspace.
    This will trigger the data preprocessing, model training, and evaluation steps
    consistently and repeatably.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Monitor and Iterate**: Monitor the pipeline execution and evaluate model
    performance. If necessary, iterate on the pipeline to improve your model by adjusting
    hyperparameters or using different algorithms.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here is a simplified example using the Azure Machine Learning SDK to give you
    an idea:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Remember to replace placeholders such as `'your_labeled_dataset_name'` and `'your_required_packages'`
    with your actual dataset name and required Python packages.
  prefs: []
  type: TYPE_NORMAL
- en: Adjust the pipeline steps according to your specific use case and requirements.
    The Azure Machine Learning SDK documentation provides detailed information on
    how to define and run pipelines, as ML pipeline implementation is beyond the scope
    of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s see how to label the data using the open source tool Label Studio.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Label Studio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Label Studio ([https://labelstud.io/](https://labelstud.io/)) is an open source
    data labeling and annotation platform designed to streamline the process of labeling
    diverse data types, including images, text, and audio. With a user-friendly interface,
    Label Studio empowers machine learning practitioners and data scientists to efficiently
    label and annotate datasets for training and evaluating models. Its versatility,
    collaborative features, and support for multiple labeling tasks make it a valuable
    tool in the development of robust and accurate machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we are going to label four types of data: image, video, text,
    and audio.'
  prefs: []
  type: TYPE_NORMAL
- en: Labeling the image data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let us label the image data using Label Studio.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have installed the Label Studio tool using the `pip` command as given
    in the *Technical requirements* section, start Label Studio, go to the browser,
    and type in the following URL: `http://localhost:8080/`. As we have deployed Label
    Studio using the Python `pip` command, our Label Studio UI is running on the local
    system on port `8080`. This is our Label Studio UI application, and we can access
    the same from the browser to label our data.'
  prefs: []
  type: TYPE_NORMAL
- en: For this exercise, we are going to use the same bike riding image that we used
    in the *Image data labeling using Azure Machine* *Learning* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an overview of the steps for labeling images using Label Studio:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Installation**: Download and install Label Studio on your local machine or
    server. Follow the installation instructions provided by Label Studio.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Initialization**: Start the Label Studio application either through a command
    line or by using the provided interface.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Account creation**: Create user accounts within Label Studio to facilitate
    project management. These accounts will be used to oversee and organize labeling
    projects.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Project setup**: Define the labeling requirements for your dataset. Specify
    the type of labeling tasks needed (e.g., image classification or object detection)
    and configure project settings such as task distribution and completion criteria.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Interface configuration**: Customize the labeling interface according to
    your project’s needs. Add and define the labels that annotators will apply during
    the labeling process. Tailor the interface to ensure efficient and accurate annotations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data import**: Import your dataset into Label Studio as labeling tasks. This
    involves uploading images or linking to data sources to create a set of tasks
    for annotators.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Labeling and annotation**: Annotators use the configured interface to label
    and annotate the images according to the defined tasks. The labeling process involves
    applying the specified labels to regions or objects within the images.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Export the labeled data**: Once labeling is complete, export the labeled
    data or annotations. Depending on your needs, you may export the data in various
    formats suitable for further analysis or integration with other tools and platforms.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By following these steps, you can effectively use Label Studio to manage and
    execute image labeling projects. Let’s see a few important steps next.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, go to **Projects** to create a new project using the Label Studio UI
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.30 – Label Studio](img/B18944_12_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.30 – Label Studio
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the project name:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.31 – Entering the project name](img/B18944_12_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.31 – Entering the project name
  prefs: []
  type: TYPE_NORMAL
- en: After you create a project, import data into Label Studio. You can import many
    types of data, including text, time series, audio, and image data. The file types
    supported depend on the type of data. Now, select the label template for labeling
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting the label template
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Go to **Settings** | **Labeling Interface**. Here, you can select a template
    from the available templates in Label Studio as shown in the project. Select **Image
    Classification**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.32 – Selecting the template](img/B18944_12_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.32 – Selecting the template
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have selected the label template, you need to set up the label names
    `bicycle` and `person`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.33 – Adding label names](img/B18944_12_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.33 – Adding label names
  prefs: []
  type: TYPE_NORMAL
- en: Applying labels in Label Studio
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, go to **Labeling** and apply the labels to the images. As per the
    selected template (**Image Classification**), select the label and then draw the
    bounding box on that object in the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.34 – Applying labels in Label Studio](img/B18944_12_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.34 – Applying labels in Label Studio
  prefs: []
  type: TYPE_NORMAL
- en: You can label the next image in a similar fashion.
  prefs: []
  type: TYPE_NORMAL
- en: We have now seen how to create a project, select a template, and label the images
    in Label Studio. Now, let’s see how to label text data in Label Studio.
  prefs: []
  type: TYPE_NORMAL
- en: Labeling the text data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, let’s see how to label text data using Label Studio.
  prefs: []
  type: TYPE_NORMAL
- en: For text data labeling, there are various natural language templates available
    in Label Studio, such as text classification templates and named entity recognition
    templates to identify the entity (person, organization, etc.) in the given sentence.
  prefs: []
  type: TYPE_NORMAL
- en: We will follow the same steps that we used for labeling image data in Label
    Studio. First, we create a project, then we import the data and select an appropriate
    label template. We have added the labels `Title` and `person` manually for this
    exercise. Finally, we apply the labels to the text. We have applied the labels
    `Title` and `person` to the entities in the sentence `"This is vijay text annotation"`
    for this example.
  prefs: []
  type: TYPE_NORMAL
- en: For more detailed documentation, go to [https://labelstud.io/](https://labelstud.io/).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.35 – Text annotation](img/B18944_12_35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.35 – Text annotation
  prefs: []
  type: TYPE_NORMAL
- en: We have now seen how to annotate the sample text using labels in Label Studio.
    Similarly, we can label the next piece of text data that we uploaded using Label
    Studio.
  prefs: []
  type: TYPE_NORMAL
- en: Labeling the video data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, let’s see how to label video data.
  prefs: []
  type: TYPE_NORMAL
- en: All the steps are similar to the image data labeling steps, except the template
    used for video data labeling. First, we will create the project in Label Studio
    and then import the video data files and select the appropriate template. Finally,
    we apply the labels to the video.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s add annotations to the project. Here, we are adding `dog` and `Man`
    labels manually for this exercise. Now, we go to the video annotation project
    and start labeling the video in Label Studio. We have created bounding boxes for
    the `dog` and `Man` objects shown in this video. We apply these labels to the
    video frames.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.36 – Video data labeling](img/B18944_12_36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.36 – Video data labeling
  prefs: []
  type: TYPE_NORMAL
- en: We have now seen how to label video data in Label Studio. All the steps are
    similar for image data labeling, text data labeling, and video data labeling,
    except for the label template. These labels can be exported from Label Studio
    and saved to the local computer. From there, a dataset can be created using local
    files in Azure Blob storage. This dataset can be used in the Azure Machine Learning
    pipeline for training the ML models.
  prefs: []
  type: TYPE_NORMAL
- en: As well as Label Studio, there are many other open source Python libraries available
    for data labeling. Now, let’s see about another Python-based open source labeling
    tool, pyOpenAnnotate. The choice of tool depends on the availability of skilled
    resources, the volume of the data, and the format of the data.
  prefs: []
  type: TYPE_NORMAL
- en: pyOpenAnnotate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**pyOpenAnnotate** is an open source Python-based annotation tool that automates
    the image annotation pipeline using OpenCV. It is particularly well-suited for
    annotating simple datasets, such as images with plain backgrounds or infrared
    images. pyOpenAnnotate is a single-class automated annotation tool that can help
    you label and annotate images and videos using computer vision techniques. It
    is built by harnessing the power of OpenCV. You can check out the Python library
    documentation to understand how pyOpenAnnotate has been designed: [https://pypi.org/project/pyOpenAnnotate/](https://pypi.org/project/pyOpenAnnotate/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can load your images in a directory and then run the following command
    to start labeling the bounding boxes for your images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The following image is available in the book’s GitHub path for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can replace the directory path with your own dataset path. This will prompt
    the tool to label the objects in your image and you can drag and drop the bounding
    boxes around the objects (blue-colored bounding boxes in the following figure):'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 12.37 – Bounding boxes on car image (created by the author of this\
    \ book using \uFEFFDALL-E)](img/B18944_12_37.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 12.37 – Bounding boxes on car image (created by the author of this book
    using DALL-E)
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, we can annotate videos using this pyOpenAnnotate tool. We can extract
    the frames for the video as shown in [*Chapter 8*](B18944_08.xhtml#_idTextAnchor176),
    and then provide the path of that video frame for drawing bounding boxes to the
    video frames. Now, let’s see another popular tool to label the image data, CVAT.
  prefs: []
  type: TYPE_NORMAL
- en: Computer Vision Annotation Tool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**CVAT** is a free, open source tool that is widely used in various industries
    for annotating images to facilitate the training of machine learning models. This
    tool is designed to handle a large volume of images for labeling. Setting up and
    using CVAT for annotating images involves several steps. The following is a guide
    that covers the process.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 1 –* *Install Docker*'
  prefs: []
  type: TYPE_NORMAL
- en: 'CVAT is containerized using Docker, so you’ll need to have Docker installed
    on your machine. Follow the installation instructions for your operating system
    on the official Docker website: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 2 – Install* *Docker Compose*'
  prefs: []
  type: TYPE_NORMAL
- en: CVAT has multiple components, including a web server, a database, and a worker
    for background tasks. Docker Compose allows you to define and manage the dependencies
    between these components in a single configuration file (`docker-compose.yml`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker Compose simplifies the management of multi-container Docker applications.
    Install Docker Compose by following the instructions on the official Docker Compose
    installation page: [https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 3 – Clone the* *CVAT repository*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone the CVAT repository from GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*Step 4 – Configure CVAT* *environment variables*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the CVAT directory and create a `.env` file with configuration
    settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Edit the `.env` file to customize settings if needed.
  prefs: []
  type: TYPE_NORMAL
- en: You will typically need to customize the `docker-compose.yml` file to configure
    various aspects of CVAT, such as database credentials and port numbers.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 5 – Build and* *run CVAT*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Build and run the CVAT containers using Docker Compose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now we have completed deploying the CVAT tool using Docker on your local environment.
    Let’s start labeling the images using the CVAT now.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 6 – Access the CVAT* *web interface*'
  prefs: []
  type: TYPE_NORMAL
- en: CVAT’s web interface is accessible at `http://localhost:8080`. Open a web browser
    and navigate to this URL.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 7 – Create a new* *annotation task*'
  prefs: []
  type: TYPE_NORMAL
- en: Create a free account and log in to the CVAT web interface. Create a new task
    by clicking on the **Tasks** tab, then click the **Create Task** button. Enter
    the task details, such as name, labels, and mode (image or video). Configure additional
    settings based on your annotation requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Next, upload images or video files for annotation. For images and videos, use
    the **Data** tab in the **Tasks** menu.
  prefs: []
  type: TYPE_NORMAL
- en: Now, annotate the data by selecting the task from the list and clicking **Go
    to the task**. Use the annotation tools to draw bounding boxes and polygons, or
    to annotate text.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 8 – Stop and remove* *CVAT containers*'
  prefs: []
  type: TYPE_NORMAL
- en: After you have finished the annotation tasks, stop and remove CVAT containers.
  prefs: []
  type: TYPE_NORMAL
- en: This step-by-step guide should help you set up and use CVAT for annotating images
    and videos. Adjustments can be made based on specific requirements and preferences,
    and CVAT’s documentation provides comprehensive details for advanced use cases.
    However, this is beyond the scope of this book. You can explore CVAT’s documentation
    for advanced features, customization, and troubleshooting at https://opencv.github.io/cvat/docs/.
  prefs: []
  type: TYPE_NORMAL
- en: Comparison of data labeling tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is a table depicting the comparison of the tools on various features:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Tool** | **Pros** | **Cons** | **Cost** | **Labeling Features** **Support**
    | **Scalability** |'
  prefs: []
  type: TYPE_TB
- en: '| Azure Machine Learning labeling | Rapid data preparation for machine learning
    projects.Assisted machine learning. | Limited to Microsoft ecosystem. Limited
    support for custom labeling interfaces. | Azure services may have associated costs
    depending on the usage | Images, text documents, and audio | Ability to scale
    labeling tasks with the power of Azure cloud services |'
  prefs: []
  type: TYPE_TB
- en: '| Label Studio | Open source and multi-type data labeling tool | Limited documentation.Limited
    support for video data. | Label Studio is available as open source software as
    well as an Enterprise cloud service | Images, text documents, and video | May
    require additional configuration for large-scale projects |'
  prefs: []
  type: TYPE_TB
- en: '| CVAT | Web-based and collaborative.Easy to use with intuitive shortcuts.
    | Limited support for custom labeling interfaces. Users need to set up and host
    the tool themselves. | Open source. No direct cost for software; users only pay
    for hosting and infrastructure. | Images and videos | Large-scale projects may
    require additional configuration |'
  prefs: []
  type: TYPE_TB
- en: '| pyOpen Annotate | Supports multiple annotation formats.Supports custom annotation
    interfaces. | Limited documentation.Limited support for video data. | Free and
    open source | Images and videos | Large-scale projects may require additional
    configuration |'
  prefs: []
  type: TYPE_TB
- en: Table 12.1 – Comparison of data labeling and annotation tools
  prefs: []
  type: TYPE_NORMAL
- en: The cost of each tool may vary depending on the number of labeling tasks and
    the features required. It is recommended to evaluate each tool based on your specific
    requirements before deciding on the labeling tool.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced methods in data labeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Active learning and semi-automated learning are popular machine learning techniques
    that help overcome the challenge of data labeling. Both involve presenting uncertain
    or challenging labels to human annotators for feedback; the key difference lies
    in the overall strategy and decision-making process. Let’s break down the distinction.
  prefs: []
  type: TYPE_NORMAL
- en: Active learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Active learning is a machine learning paradigm in which a model is trained
    on a subset of the data, and then the model actively selects the most informative
    examples for labeling to improve its performance. The following list discusses
    various features of this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Workflow**: The initial model is trained on a small labeled dataset. The
    model identifies instances where it is uncertain or likely to make errors. These
    uncertain or challenging instances are presented to human annotators for labeling.
    The model is updated with the new labeled data, and the process iterates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Benefits**: It reduces the amount of labeled data needed for model training
    and focuses annotation efforts on examples that are challenging for the current
    model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Challenges**: It requires an iterative process of model training and annotation.
    The selection of informative instances is crucial for success.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decision-making by the model**: In active learning, the model takes an active
    role in selecting which instances it finds most uncertain or challenging. The
    model employs specific query strategies to identify instances that, when labeled,
    are expected to improve its performance the most.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Iterative process**: The initial model is trained on a small labeled dataset.
    The model selects instances for annotation based on its uncertainty or expected
    improvement. Human annotators label the selected instances. The model is updated
    with the new labels, and the process iterates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-automated labeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Semi-automated labeling** involves a combination of automated tools and human
    intervention to label datasets. Automated methods assist human annotators in the
    labeling process but may not fully replace human input. The following list discusses
    various features of this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Workflow**: Automated algorithms perform an initial labeling of data. Human
    annotators review and correct the automated labels. The corrected labels are used
    to refine the model or dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Benefits**: It speeds up the labeling process by leveraging automation. It
    maintains the accuracy and quality of labels through human review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Challenges**: It is dependent on the accuracy of automated algorithms. It
    requires a balance between automation and human expertise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decision-making by automation**: In semi-automated labeling, automated algorithms
    are involved in the initial labeling of data. The automation might include pre-labeling
    based on algorithms, heuristics, or rules.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Human review and correction**: Human annotators review the automated labels
    and correct them as needed. Annotators might also add or modify labels based on
    their expertise. The corrected labels contribute to refining the dataset or model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Key points of distinction between these two methods are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Initiation of labeling**: In active learning, the model actively initiates
    the process by selecting instances for labeling. In semi-automated labeling, automation
    takes the lead in the initial labeling, and human annotators review and correct
    the labels afterward.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Query strategies**: Active learning involves specific query strategies designed
    to maximize information gain for the model. Semi-automated labeling might rely
    on heuristics or algorithms for initial labeling, but the emphasis is on human
    correction rather than model-driven query strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decision responsibility**: Active learning places more decision-making responsibility
    on the model. Semi-automated labeling involves a more collaborative approach where
    both automated algorithms and human annotators contribute to decision-making.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While both approaches aim to make the most of human annotation efforts, the
    active learning process is more driven by the model’s uncertainty and improvement
    goals, while semi-automated labeling focuses on a collaborative effort between
    automated tools and human expertise. The choice between them depends on the specific
    needs of the task and the available resources.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned how to use Azure Machine Learning to label
    image, video, and audio data. We also learned about the open source annotation
    tool Label Studio for image, video, and text annotation. Finally, we learned about
    pyOpenAnnotate and CVAT for labeling image and video data. Now, you can try using
    these open source tools to prepare the labeled data for machine learning model
    training.
  prefs: []
  type: TYPE_NORMAL
- en: As we reach the final pages of this book, I extend my heartfelt congratulations
    to you on completing this insightful journey into the world of data labeling for
    image, text, audio, and video data. Your dedication and curiosity have paved the
    way for a deeper understanding of cutting-edge technologies. May the knowledge
    gained here continue to inspire your future endeavors. Thank you for being a part
    of this enriching experience!
  prefs: []
  type: TYPE_NORMAL
