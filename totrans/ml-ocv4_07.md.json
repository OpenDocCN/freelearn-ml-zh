["```py\nIn [1]: data = [\n...       'I am Mohammed Abacha, the son of the late Nigerian Head of '\n...       'State who died on the 8th of June 1998\\. Since i have been '\n...       'unsuccessful in locating the relatives for over 2 years now '\n...       'I seek your consent to present you as the next of kin so '\n...       'that the proceeds of this account valued at US$15.5 Million '\n...       'Dollars can be paid to you. If you are capable and willing '\n...       'to assist, contact me at once via email with following '\n...       'details: 1\\. Your full name, address, and telephone number. '\n...       '2\\. Your Bank Name, Address. 3.Your Bank Account Number and '\n...       'Beneficiary Name - You must be the signatory.'\n...     ]\n```", "```py\nIn [2]: from sklearn.feature_extraction.text import CountVectorizer\n... vec = CountVectorizer()\n... X = vec.fit_transform(data)\n```", "```py\nIn [3]: function:vec.get_feature_names()[:5]\nOut[3]: ['15', '1998', '8th', 'abacha', 'account']\n```", "```py\nIn [4]: X.toarray()[0, :5]\nOut[4]: array([1, 1, 1, 1, 2], dtype=int64)\n```", "```py\nIn [5]: 'nigerian' in vec.get_feature_names()\nOut[5]: True\nIn [6]: 'prince' in vec.get_feature_names()\nOut[6]: False\n```", "```py\nimport random\n\ndef generateBasorexiaData(num_entries):\n    # We will save our new entries in this list \n    list_entries = []\n    for entry_count in range(num_entries):\n        new_entry = {}\n        new_entry['age'] = random.randint(20,100)\n        new_entry['sex'] = random.choice(['M','F'])\n        new_entry['BP'] = random.choice(['low','high','normal'])\n        new_entry['cholestrol'] = random.choice(['low','high','normal'])\n        new_entry['Na'] = random.random()\n        new_entry['K'] = random.random()\n        new_entry['drug'] = random.choice(['A','B','C','D'])\n        list_entries.append(new_entry)\n    return list_entries\n```", "```py\nIn [10]: from sklearn.feature_extraction import DictVectorizer\n...      vec = DictVectorizer(sparse=False)\n...      data_pre = vec.fit_transform(data)\n```", "```py\nIn [12]: vec.get_feature_names()\nOut[12]: ['BP=high', 'BP=low', 'BP=normal', 'K', 'Na', 'age',\n...       'cholesterol=high', 'cholesterol=normal',\n...       'sex=F', 'sex=M']\nIn [13]: data_pre[0]\nOut[13]: array([ 1\\. , 0\\. , 0\\. , 0.06, 0.66, 33\\. , 1\\. , 0\\. ,\n                 1\\. , 0\\. ])\n```", "```py\nIn [14]: import numpy as np\n...      data_pre = np.array(data_pre, dtype=np.float32)\n...      target = np.array(target, dtype=np.float32)\n```", "```py\nIn [15]: import sklearn.model_selection as ms\n...      X_train, X_test, y_train, y_test =\n...      ms.train_test_split(data_pre, target, test_size=5,\n...      random_state=42)\n```", "```py\nIn [16]: import cv2...      dtree = cv2.ml.dtree_create()\n```", "```py\nIn [17]: dtree.train(X_train, cv2.ml.ROW_SAMPLE, y_train)\n```", "```py\nIn [21]: from sklearn import tree\n```", "```py\nIn [22]: dtc = tree.DecisionTreeClassifier()\n```", "```py\nIn [23]: dtc.fit(X_train, y_train)\nOut[23]: DecisionTreeClassifier(class_weight=None, criterion='gini',\n            max_depth=None, max_features=None, max_leaf_nodes=None,\n            min_impurity_split=1e-07, min_samples_leaf=1,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best')\n```", "```py\nIn [24]: dtc.score(X_train, y_train)\nOut[24]: 1.0\nIn [25]: dtc.score(X_test, y_test)\nOut[25]: 0.40000000000000002\n```", "```py\nIn [26]: with open(\"tree.dot\", 'w') as f:\n... tree.export_graphviz(clf, out_file=f)\n```", "```py\n$ dot -Tpng tree.dot -o tree.png\n```", "```py\nIn [27]: dtc.feature_importances_\nOut[27]: array([ 0\\.        , 0\\.   , 0\\.        , 0.13554217, 0.29718876,\n                 0.24096386, 0\\.   , 0.32630522, 0\\.        , 0\\. ])\n```", "```py\nIn [28]: plt.barh(range(10), dtc.feature_importances_, align='center',\n...      tick_label=vec.get_feature_names())\n```", "```py\nIn [1]: from sklearn import datasets\n...     data = datasets.load_breast_cancer()\n```", "```py\nIn [2]: data.data.shape\nOut[2]: (569, 30)\n```", "```py\nIn [3]: data.feature_names\nOut[3]: array(['mean radius', 'mean texture', 'mean perimeter',\n               'mean area', 'mean smoothness', 'mean compactness',\n               'mean concavity', 'mean concave points',\n               'mean symmetry', 'mean fractal dimension',\n               'radius error', 'texture error', 'perimeter error',\n               'area error', 'smoothness error',\n               'compactness error', 'concavity error',\n               'concave points error', 'symmetry error',\n               'fractal dimension error', 'worst radius',\n               'worst texture', 'worst perimeter', 'worst area',\n               'worst smoothness', 'worst compactness',\n               'worst concavity', 'worst concave points',\n               'worst symmetry', 'worst fractal dimension'], \n              dtype='<U23')\n```", "```py\nIn [4]: data.target_names\nOut[4]: array(['malignant', 'benign'], dtype='<U9')\n```", "```py\nIn [5]: import sklearn.model_selection as ms\n...     X_train, X_test, y_train, y_test =\n...     ms.train_test_split(data_pre, target, test_size=0.2,\n...     random_state=42)\n```", "```py\nIn [6]: X_train.shape, X_test.shape\nOut[6]: ((455, 30), (114, 30))\n```", "```py\nIn [5]: from sklearn import tree...     dtc = tree.DecisionTreeClassifier()\n```", "```py\nIn [6]: dtc.fit(X_train, y_train)Out[6]: DecisionTreeClassifier(class_weight=None, criterion='gini',                               max_depth=None, max_features=None,                               max_leaf_nodes=None,                               min_impurity_split=1e-07,                               min_samples_leaf=1,                               min_samples_split=2,                               min_weight_fraction_leaf=0.0,                               presort=False, random_state=None,                               splitter='best')\n```", "```py\nIn [1]: import numpy as np\n...     rng = np.random.RandomState(42)\n```", "```py\nIn [2]: X = np.sort(5 * rng.rand(100, 1), axis=0)\n...     y = np.sin(X).ravel()\n```", "```py\nIn [3]: y[::2] += 0.5 * (0.5 - rng.rand(50))\n```", "```py\nIn [4]: from sklearn import tree\nIn [5]: regr1 = tree.DecisionTreeRegressor(max_depth=2,\n...     random_state=42)\n...     regr1.fit(X, y)\nOut[5]: DecisionTreeRegressor(criterion='mse', max_depth=2,\n                              max_features=None, max_leaf_nodes=None,\n                              min_impurity_split=1e-07,\n                              min_samples_leaf=1, min_samples_split=2,\n                              min_weight_fraction_leaf=0.0,\n                              presort=False, random_state=42,\n                              splitter='best')\n```", "```py\nIn [6]: regr2 = tree.DecisionTreeRegressor(max_depth=5,\n...     random_state=42)\n...     regr2.fit(X, y)\nOut[6]: DecisionTreeRegressor(criterion='mse', max_depth=5,\n                              max_features=None, max_leaf_nodes=None,\n                              min_impurity_split=1e-07,\n                              min_samples_leaf=1, min_samples_split=2,\n                              min_weight_fraction_leaf=0.0,\n                              presort=False, random_state=42,\n                              splitter='best')\n```", "```py\nIn [7]: X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n```", "```py\nIn [8]: y_1 = regr1.predict(X_test)\n...     y_2 = regr2.predict(X_test)\n```", "```py\nIn [9]: import matplotlib.pyplot as plt\n... %matplotlib inline\n... plt.style.use('ggplot')\n\n... plt.scatter(X, y, c='k', s=50, label='data')\n... plt.plot(X_test, y_1, label=\"max_depth=2\", linewidth=5)\n... plt.plot(X_test, y_2, label=\"max_depth=5\", linewidth=3)\n... plt.xlabel(\"data\")\n... plt.ylabel(\"target\")\n... plt.legend()\nOut[9]: <matplotlib.legend.Legend at 0x12d2ee345f8>\n```"]