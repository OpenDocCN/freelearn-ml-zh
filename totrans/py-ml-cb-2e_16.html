<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Unlocking Production Issues</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>In this chapter, we will cover the following recipes:</span></p>
<ul>
<li>Handling unstructured data</li>
<li>Deploying machine learning models</li>
<li>Keeping track of changes into production</li>
<li>Tracking accuracy to optimize model scaling</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>To address the recipes in this chapter, you will need the following files (available on GitHub):</p>
<ul>
<li><kbd>UNData.py</kbd></li>
<li><kbd>TextFile.txt</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>In the previous chapters, we have extensively covered the main algorithms that are used in machine learning. We have seen how many and which tools the Python programmer has at their disposal to construct algorithms that are capable of predicting or classifying specific information. The next step is to create software that can be made available for production and subsequent marketing.</p>
<p class="mce-root"/>
<p>This is not a small challenge, given that making software available for marketing involves the resolution of considerable problems that include hardware and software aspects. In fact, we must first determine which types of devices will host the software and then select the programming platform that is most suitable for that type of technology.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Handling unstructured data</h1>
                </header>
            
            <article>
                
<p>So far, we have highlighted the importance of input data in the creation of a model based on automatic learning. In particular, we have seen how important it is to adequately process this data before providing it in our algorithm. Another challenge that we must face before starting our production work is to learn how to deal with unstructured data. By unstructured data, we mean data that is stored without any scheme. An example is files containing text that has been produced by one of the most popular text editing software or a multimedia file, but this unstructured data could also take the form of emails, PDFs, and so on. Unstructured data differs from databases due to the fact that they may have irregularities that do not allow you to catalog or store them in a particular process.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>As a source, I used a passage from the novel <em>The Adventures of Huckleberry Finn</em>, by Mark Twain, which can be viewed on GitHub.</p>
<p>As you can see, it is an unstructured text. We will handle this text and remove the unnecessary elements before saving the result in a structured form.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p><span>In this recipe, we will learn how to handle unstructured data. Follow these steps to begin:</span></p>
<ol>
<li><span>Create a new Python file and import the following packages (the full code is in the <kbd>UNData.py</kbd></span><span> </span><span>file already provided):</span></li>
</ol>
<pre style="padding-left: 60px">import re</pre>
<ol start="2">
<li>Let's define the input filename:</li>
</ol>
<pre style="padding-left: 60px">input_file = 'TextFile.txt'</pre>
<ol start="3">
<li>We need to initialize the dictionary that will contain the data:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">data = {}</pre>
<ol start="4">
<li>Now, we can load and print the data:</li>
</ol>
<pre style="padding-left: 60px">data['Twain'] = open(input_file,'r').read()<br/>print(data['Twain'])</pre>
<ol start="5">
<li>Let's convert the data into lowercase:</li>
</ol>
<pre style="padding-left: 60px">for k in data:<br/>    data[k] = data[k].lower()</pre>
<ol start="6">
<li><span>Let's remove any punctuation:</span></li>
</ol>
<pre style="padding-left: 60px">for k in data:<br/>   data[k] = re.sub(r'[-./?!,":;()\']',' ',data[k])</pre>
<ol start="7">
<li><span>Let's remove the numbers:</span></li>
</ol>
<pre style="padding-left: 60px">for k in data:<br/>    data[k] = re.sub('[-|0-9]',' ',data[k])</pre>
<ol start="8">
<li><span>Let's remove any extra blank spaces:</span></li>
</ol>
<pre style="padding-left: 60px">for k in data:<br/>    data[k] = re.sub(' +',' ',data[k]) </pre>
<ol start="9">
<li>Finally, we will print and save the results in a <kbd>.csv</kbd> file:</li>
</ol>
<pre style="padding-left: 60px">print('###########################')<br/>print(data['Twain'])<br/><br/>with open('Twain.csv', 'w') as f:<br/>    for key in data.keys():<br/>        f.write("%s,%s\n"%(key,data[key]))<br/>        <br/>f.close()</pre>
<p style="padding-left: 60px">The following screenshot shows the input file (left) and the results that were obtained (right):</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1114 image-border" src="assets/4e3cd6e5-5037-4101-90a9-5f4efe8c91bb.png" style="width:162.50em;height:75.92em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>In this recipe, we learned how to<span> handle unstructured data. To do this, a piece of text from Mark Twain's novel was used. After loaded the text, punctuation, numbers, and extra blank spaces were removed. Also, all of the text was transformed into lowercase. Finally, the results was stored in a <kbd>.csv</kbd> file.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p>In this recipe, we have addressed the problem of text analysis, which represents the process of converting the unstructured text into meaningful data for a subsequent analysis phase. Several techniques can be used for text analysis, and we dealt with several in <a href="fc31e304-3301-4ebf-80e4-404ac6e26606.xhtml">Chapter 7</a>,<em> Analyzing Text Data</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to <a href="fc31e304-3301-4ebf-80e4-404ac6e26606.xhtml">Chapter 7</a>, <em>Analyzing Text Data</em></li>
<li>Refer to <em>Unstructured Data</em> (from Stanford University): <a href="https://web.stanford.edu/class/cs102/lecturenotes/UnstructuredData.pdf">https://web.stanford.edu/class/cs102/lecturenotes/UnstructuredData.pdf</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying machine learning models</h1>
                </header>
            
            <article>
                
<p>Bringing into production a project based on machine learning isn't easy. In fact, there are only a few companies that have managed to do it, at least for large projects. The difficulties lie in the fact that artificial intelligence is not something that is produced with finished software. A starting platform is needed to implement its own software model encountering problems that are not analogous to those that the developers usually encounter. The classic approach of software engineering leads to abstraction so that you arrive at simple code that can be modified and improved. Unfortunately, it is difficult to pursue abstraction in machine learning applications, just as it is difficult to control the complexity of machine learning. The best thing to do is focus on a platform that has the functions you need and, at the same time, allows you to withdraw from the mathematical foundations of machine learning. In this recipe, we will present the Amazon SageMaker platform. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Amazon SageMaker is a paid service, but thanks to the AWS free usage plan, you can start using Amazon SageMaker for free for the first two months after registration. For further information on the available tariff plans, check out the following link: <a href="https://aws.amazon.com">https://aws.amazon.com</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's see how we can make use of Amazon SageMaker:</p>
<ol>
<li>First, you need to log in to the console:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1056 image-border" src="assets/1883d625-2090-43ce-9f27-b67a21b43b85.png" style="width:65.67em;height:37.75em;"/></p>
<ol start="2">
<li>Launch a notebook instance with one of the example notebooks:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1057 image-border" src="assets/2974153a-5048-4638-a883-c695d3a719ab.png" style="width:82.67em;height:54.42em;"/></p>
<ol start="3">
<li>Change that instance by connecting to custom data sources.</li>
</ol>
<p class="mce-root"/>
<ol start="4">
<li>Follow the examples to create, form, and validate the models:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1058 image-border" src="assets/4c18d353-cf11-4b3b-b14b-fc8e30507c24.png" style="width:77.17em;height:47.17em;"/></p>
<ol start="5">
<li>Finally, distribute the result in production by following the on-screen steps.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Amazon SageMaker is a fully managed service for the creation, training, and distribution of models based on machine learning. Amazon SageMaker comes with three modules—<strong>Build</strong>, <strong>Train</strong>, and <strong>Deploy</strong>. The Build module allows us to work with data, experiment with algorithms, and view the output. The Train module trains the model and optimizes it on a large scale. Finally, there is the Deploy module, which allows us to easily test the inference of the model with low latency.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p>Amazon SageMaker allows us to create machine learning models for use in intelligent and predictive apps. From a security standpoint, Amazon SageMaker encrypts all scripts based on machine learning. Requests to the API and the Amazon SageMaker console are forwarded via a <strong>secure connection</strong> (<strong>SSL</strong>). We can use AWS Identity and Access Management to automatically assign access permissions to training and distribution resources. We can also use Bucket S3, an Amazon SageMaker KMS key, to notebook training processes and endpoints to encrypt storage volumes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to the official documentation of<span> Amazon SageMaker: <a href="https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/whatis.html">https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/whatis.html</a></span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Keeping track of changes into production</h1>
                </header>
            
            <article>
                
<p>The distribution of the model is not the end—<span>i</span>t's only the beginning. The real problems start from here. We have no control over the data in the real environment. Changes may occur and we must be ready to detect and update our model before it becomes obsolete. Monitoring is important to ensure the reliability, availability, and performance of our machine learning application. In this recipe, we will discuss some tools that we can use to keep track of changes that occur in the model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The following tools are available to monitor an Amazon SageMaker application:</p>
<ul>
<li><strong>Amazon CloudWatch</strong>: This tool, which is available in AWS, monitors the resources and applications that run in real time. Parameters can be collected and tracked, custom control panels can be created, and alerts can be set to notify or take action when a specified parameter reaches a specified threshold. The following screenshot shows an overview of Amazon CloudWatch:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1059 image-border" src="assets/c38d2062-0e36-40ff-b71d-8bd2f17c6e0e.png" style="width:143.67em;height:78.17em;"/></p>
<ul>
<li><strong>Amazon CloudWatch Logs</strong>: This tool, which is available in AWS, allows you to monitor, store, and access log files from EC2, AWS CloudTrail instances, and other sources. The CloudWatch logs monitor information in the log files and allow us to send notifications when certain thresholds are reached.</li>
<li><strong>AWS CloudTrail</strong>: This tool, which is available in AWS, retrieves API calls and related events that are created by our account and returns a log file to a specified Amazon S3 bucket. We can also retrieve useful information about the users and accounts that have called the services, and we can trace the IP address from which the calls were made and when they occurred.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>To monitor Amazon SageMaker, we can use Amazon CloudWatch, which collects raw data and transforms it into readable parameters in real time. These statistics are kept for a period of 15 months so that you can access historical information and offer a better perspective on the performance of the service or web application. However, the Amazon CloudWatch console limits the search to the parameters that have been updated in the last two weeks. This limitation allows you to view the most up-to-date processes in the namespace. It is also possible to set alarms that control certain thresholds and send notifications or take action when these thresholds are reached.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p><span>A machine learning model is based on a set of input training data with various attributes. Therefore, it is important to check whether the input data that the model was trained on still applies to the actual data in the real environment. The data change could be sudden, or it could change gradually over time. Therefore, it is essential to identify patterns of change and correct the model in advance. </span>Once the model has been distributed in a production environment, it is necessary to follow the steps mentioned in the next recipe to keep our models healthy and useful for their end users.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to the official documentation of<span> Amazon CloudWatch: <a href="https://docs.aws.amazon.com/cloudwatch/index.html">https://docs.aws.amazon.com/cloudwatch/index.html</a></span></li>
<li><span>Refer to the official documentation of</span><span> Amazon CloudWatch Logs: <a href="https://docs.aws.amazon.com/en_us/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html">https://docs.aws.amazon.com/en_us/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html</a></span></li>
<li><span>Refer to the official documentation of</span><span> Amazon </span>CloudTrail: <a href="https://docs.aws.amazon.com/cloudtrail/index.html">https://docs.aws.amazon.com/cloudtrail/index.html</a></li>
</ul>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tracking accuracy to optimize model scaling</h1>
                </header>
            
            <article>
                
<p>As we saw in <a href="8bc48ed3-a991-49e8-8c04-148505fac009.xhtml">Chapter 15</a>, <em>Automated Machine Learning and Transfer Learning</em>, most machine learning algorithms employ a series of parameters that control the functionality of the underlying algorithm. These parameters are generally called hyperparameters; their values influence the quality of trained models. Automatic model optimization is the process of finding a set of hyperparameters of an algorithm that offer an optimal model. In this recipe, we will learn how to use the Amazon SageMaker tools to optimize our model automatically.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>To perform an automatic optimization of our model, follow these steps:</p>
<ol>
<li>Open the Amazon SageMaker console.</li>
<li>Select the <span class="packt_screen">Endpoint</span> item in the navigation pane at the bottom-left.</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1054 image-border" src="assets/1e6a5090-7a69-438a-9a22-c183352cbd6e.png" style="width:67.75em;height:28.92em;"/></p>
<ol start="3">
<li>Select the endpoint you want to configure from those available.</li>
<li>Select the variant you want to configure and configure automatic scaling. Do this for the <span class="packt_screen">Endpoint</span> runtime settings.</li>
<li>Enter the average number of invocations per instance, per minute for the variant. Do this for the target value.</li>
</ol>
<ol start="6">
<li>Enter the number of seconds for each cooling period.</li>
<li>To prevent the scaling policy from deleting variant instances, select the <span class="packt_screen">Disable scale</span> option.</li>
<li>Click <span class="packt_screen">Save.</span></li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The hyperparameter optimization procedure represents a special case of regression. The problem can be framed as follows: a set of input features is available, and then this procedure optimizes a model for the adopted parameters. The choice of parameters is free as long as it is defined by the algorithm we are using. In the Amazon hyperparameter optimization procedure, SageMaker tries to find out what hyperparameter combinations are more likely to produce the best results, and tries to execute the training processes to test these attempts. To do this, the first set of values for those hyperparameters is tested, and then the procedure uses regression to choose the next set of values to be tested.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more…</h1>
                </header>
            
            <article>
                
<p>When you choose the best hyperparameters for the next training process, hyperparameter optimization takes into consideration everything you know about the problem, up to the present time. In some cases, the hyperparameter optimization procedure can choose a point that produces an incremental improvement in the best result that's been found so far. In this way, the procedure uses already known results. In other cases, you can choose a set of hyperparameters far from those you have already tested. In this way, the procedure explores the space and searches for new areas that haven't been fully analyzed yet. The compromise between exploration and exploitation is common in many machine learning problems.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Refer to <span><em>Automatically Scale Amazon SageMaker Models</em>: <a href="https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/endpoint-auto-scaling.html">https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/endpoint-auto-scaling.html</a></span></li>
</ul>


            </article>

            
        </section>
    </body></html>