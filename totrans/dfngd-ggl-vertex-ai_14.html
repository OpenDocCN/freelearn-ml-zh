<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer150">
			<h1 id="_idParaDest-203" class="chapter-number"><a id="_idTextAnchor203"/>14</h1>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor204"/>ML APIs for Vision, NLP, and Speech</h1>
			<p>Research teams at Google have put their decades of research and experience into creating state-of-the-art solutions for many complex problems. Some of these solutions, which include Vision AI, Translation AI, Natural Language AI, and Speech AI, are quite general-purpose and can be readily leveraged to get insights from complex and unstructured data. These solutions are provided as a service and thus as customers, we don’t have to worry about managing the infrastructure, availability, or scaling of these products. Many popular Google products, such as Maps, Photos, Gmail, YouTube, and others make use of these products every day to provide <span class="No-Break">AI-driven experiences.</span></p>
			<p>In this chapter, we will look at some of these popular offerings and understand what kind of problems can be solved using them. The main topics that will be covered in this chapter are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Vision AI on <span class="No-Break">Google Cloud</span></li>
				<li>Translation AI on <span class="No-Break">Google Cloud</span></li>
				<li>Natural Language AI on <span class="No-Break">Google Cloud</span></li>
				<li>Speech AI on <span class="No-Break">Google Cloud</span></li>
			</ul>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor205"/>Vision AI on Google Cloud</h1>
			<p>Computer <a id="_idIndexMarker921"/>vision is a field of <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) that enables <a id="_idIndexMarker922"/>computers and systems to derive insights from <a id="_idIndexMarker923"/>visual data such as digital images and videos. Understanding images and videos is a complex task, but with never-ending research in the field, the AI research community has led to the development of many smart ways of getting information out of unstructured data, such as images and videos. Information extracted from digital images and videos can be leveraged by businesses to take action and provide recommendations at scale. Google Cloud provides the following two offerings as a platform to solve computer <span class="No-Break">vision problems:</span></p>
			<ul>
				<li><span class="No-Break">Vision AI</span></li>
				<li><span class="No-Break">Video AI</span></li>
			</ul>
			<p>Now, let’s deep dive into each of <span class="No-Break">these offerings.</span></p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor206"/>Vision AI</h2>
			<p>Google Vision <a id="_idIndexMarker924"/>AI provides a platform for creating vision-based applications with pre-trained APIs, AutoML, or custom models. Using Vision AI, we can create image and video analytics solutions in just a few minutes. This offering allows us to train our custom classification or object detection models using AutoML, and it also allows us to train fully custom models. Vision AI provides pre-trained APIs for common vision tasks such as objection detection, handwriting recognition, image metadata creation, and more. There are three common offerings under the Google Vision <span class="No-Break">AI platform:</span></p>
			<ul>
				<li>Vertex <span class="No-Break">AI Vision</span></li>
				<li>Custom <span class="No-Break">ML models</span></li>
				<li><span class="No-Break">Vision API</span></li>
			</ul>
			<p>Let’s take a closer look <span class="No-Break">at them.</span></p>
			<h3>Vertex AI Vision</h3>
			<p>Vertex AI Vision <a id="_idIndexMarker925"/>is a fully managed end-to-end application <a id="_idIndexMarker926"/>development environment, using which we can quickly prototype vision solutions that fit our business needs. Vertex AI Vision can help us solve complex problems and create valuable solutions within minutes, hence saving a lot of development costs. Vertex AI Vision allows us to ingest real-time streams of videos and images at a massive scale to support real-time production use cases. The interface for application development is also very simple and lets us build applications quickly with <span class="No-Break">drag-and-drop functionality.</span></p>
			<p>Let’s take a look at the Vertex AI Vision interface within the Google Cloud console. Make sure you enable Vision API first and then navigate to Vertex AI Vision from the left pane. Alternatively, you can find it by searching for it at the top. The interface should look similar to <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer145" class="IMG---Figure">
					<img src="image/B17792_14_1.jpg" alt="Figure 14.1 – Vertex AI Vision interface" width="1264" height="1019"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1 – Vertex AI Vision interface</p>
			<p>We can now <a id="_idIndexMarker927"/>start building our application by clicking on the <strong class="bold">CREATE APPLICATION</strong> button, after which we’ll be asked to provide a unique name <a id="_idIndexMarker928"/>for the application. Once we click on <strong class="bold">Create</strong>, we’ll be taken to the application development studio, where we can find different options for using pre-trained or specialized models based on our application needs. The interface is quite simple and lets us build applications with <span class="No-Break">drag-and-drop functionality.</span></p>
			<p>The following screenshot shows a simple object-detection and tag-recognizer application that takes input from a GCS bucket. After performing this task, it writes the output to a Vision AI Warehouse location. We have configured this application for batch prediction and hence the input source is a GCS bucket with images, but we have other options for input types, such as streaming or live prediction use cases. Let’s take a look at the studio interface and our <span class="No-Break">sample application:</span></p>
			<div>
				<div id="_idContainer146" class="IMG---Figure">
					<img src="image/B17792_14_2.jpg" alt="Figure 14.2 – Vertex AI Vision studio for rapid application creation" width="1249" height="817"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.2 – Vertex AI Vision studio for rapid application creation</p>
			<p>This application <a id="_idIndexMarker929"/>graph can be deployed with the click of a button, and we will be able to start using it in production within minutes. Vertex AI Vision provides <a id="_idIndexMarker930"/>a few powerful pre-trained models as well as some specialized models that are ready to be deployed. It also gives us the flexibility to import or create custom models using Vertex custom training. While deploying the vision application, we also get the option to choose a streaming output type so that we can enable model monitoring for <span class="No-Break">our application.</span></p>
			<h3>Custom ML models</h3>
			<p>Vision AI <a id="_idIndexMarker931"/>supports custom ML model creation for more <a id="_idIndexMarker932"/>specialized use cases. We can use one of the following methods to create a <span class="No-Break">specialized model:</span></p>
			<ul>
				<li><strong class="bold">AutoML</strong>: The <a id="_idIndexMarker933"/>easy-to-use graphical interface of AutoML within <a id="_idIndexMarker934"/>Vertex AI lets us train our custom models with minimal effort and technical knowledge. With AutoML, we can train image or video intelligence models by simply uploading the training files. We can also optimize our models for latency, size, and accuracy as per our requirements. At the time of writing, AutoML supports object detection and classification models for image data and object tracking, action recognition, and classification for <span class="No-Break">video data.</span></li>
				<li><strong class="bold">Custom training</strong>: Custom <a id="_idIndexMarker935"/>training is useful when AutoML doesn’t support our use case. It requires more effort as well as <a id="_idIndexMarker936"/>technical depth. Custom training lets us choose the desired model development framework, the types of VMs for launching training jobs, and various types of accelerators based on training needs. With custom training, we can train our specialized models for different complex use cases and deploy them for real-time, streaming, or batch-prediction <span class="No-Break">use cases.</span></li>
			</ul>
			<p>Next, we’ll learn about the <span class="No-Break">Vision API.</span></p>
			<h3>Vision API</h3>
			<p>The Vision <a id="_idIndexMarker937"/>API provides powerful pre-trained ML models for tasks such as <a id="_idIndexMarker938"/>reading printed or handwritten text from an image, detecting objects, classifying images into millions of pre-defined categories, tagging explicit content, and more. Vision API models can be consumed through REST and RPC APIs. Solutions such as detecting text from images can be combined with other solutions such as translation to create more complex solutions for batch, stream, or live prediction tasks in production. The official Vision API documentation provides numerous code examples for rapid prototyping of <span class="No-Break">vision solutions.</span></p>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor207"/>Video AI</h2>
			<p>Video AI is <a id="_idIndexMarker939"/>specifically designed to analyze video data at scale to understand the inherent content, objects, places, or actions in a given input video. It can support real-time use cases with streaming video annotation and object-based event-triggering mechanisms to gain insights from data. Video AI can extract useful metadata from a video at the shot, frame, or video level. The following are a few common use cases from <span class="No-Break">Video AI:</span></p>
			<ul>
				<li><strong class="bold">Content moderation</strong>: Identify inappropriate content shown in videos <span class="No-Break">at scale.</span></li>
				<li><strong class="bold">Recommendation</strong>: We can use outputs of video intelligence AI and combine them with user <a id="_idIndexMarker940"/>viewing history to provide content recommendations <span class="No-Break">at scale</span></li>
				<li><strong class="bold">Media archiving</strong>: We can use metadata extracted from Video Intelligence API to efficiently store media so that it can be retrieved faster <span class="No-Break">as needed</span></li>
				<li><strong class="bold">Advertisements</strong>: We can identify the best places to put contextual advertisements within <span class="No-Break">a video</span></li>
			</ul>
			<p>Here are two common ways to start developing video AI solutions on <span class="No-Break">Google Cloud:</span></p>
			<ul>
				<li>AutoML <span class="No-Break">Video Intelligence</span></li>
				<li>Video <span class="No-Break">Intelligence API</span></li>
			</ul>
			<p>Let’s take a closer look <span class="No-Break">at them.</span></p>
			<h3>AutoML Video Intelligence</h3>
			<p>Sometimes, there <a id="_idIndexMarker941"/>are use cases where we want to <a id="_idIndexMarker942"/>identify certain kinds of objects or events within a video that are not inherently covered by Video Intelligence API. In such cases, we can develop our custom models to identify and track various new objects within videos. AutoML makes it easier to train custom video intelligence models without requiring much ML experience with the help of its graphical <span class="No-Break">user interface.</span></p>
			<p>At the <a id="_idIndexMarker943"/>time of writing, AutoML Video Intelligence supports the following <span class="No-Break">use cases:</span></p>
			<ul>
				<li><strong class="bold">Action recognition</strong>: In this use case, the solution analyzes a video and returns a list of pre-defined actions performed within the time frame in which the action happened. It can identify actions such as a soccer goal, a high-five, <span class="No-Break">and more.</span></li>
				<li><strong class="bold">Classification</strong>: A classification model can categorize videos into a list of pre-defined categories such as sports videos, cartoons, movies, <span class="No-Break">and more.</span></li>
				<li><strong class="bold">Object tracking</strong>: We can train a model to continuously track certain objects within a video – for example, we can track a soccer ball in a live-running <span class="No-Break">soccer match.</span></li>
			</ul>
			<p>If AutoML doesn’t fit our needs, we can always go back to Vertex AI custom model development and train custom video intelligence models that fit our use case. Custom training gives <a id="_idIndexMarker944"/>us the flexibility to define our custom <a id="_idIndexMarker945"/>model architectures, types of VMs to train models on, and the types of accelerators to use for training. However, it requires more technical depth and effort to develop <span class="No-Break">the solutions.</span></p>
			<p>Now that we have a good idea of image and video intelligence solutions, let’s look into Translation AI solutions, which can also be combined with various image and video use cases to solve more complex <span class="No-Break">business problems.</span></p>
			<h1 id="_idParaDest-208"><a id="_idTextAnchor208"/>Translation AI on Google Cloud</h1>
			<p>As its name suggests, Translation AI on Google Cloud is an offering that can be utilized to create <a id="_idIndexMarker946"/>applications with multi-lingual content with fast and dynamic machine translation. Multi-lingual content can help businesses take their <a id="_idIndexMarker947"/>products to global markets and engage with global audiences. Its real-time translation capabilities provide a seamless experience. Let’s take a look at translation-related offerings on <span class="No-Break">Google Cloud.</span></p>
			<p>Google Cloud provides three <span class="No-Break">translation products:</span></p>
			<ul>
				<li>Cloud <span class="No-Break">Translation API</span></li>
				<li><span class="No-Break">AutoML Translation</span></li>
				<li><span class="No-Break">Translation Hub</span></li>
			</ul>
			<p>Let’s deep dive into each of <span class="No-Break">these products.</span></p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor209"/>Cloud Translation API</h2>
			<p>Google Research has developed several <strong class="bold">neural machine translation</strong> (<strong class="bold">NMT</strong>) models over time <a id="_idIndexMarker948"/>and keeps improving them whenever there is better training data or improved techniques. The Cloud Translation API makes <a id="_idIndexMarker949"/>use of these pre-trained models or custom ML models to translate text from various source languages into target languages. With the <a id="_idIndexMarker950"/>Cloud Translation API, we can dynamically translate the contents of our websites or applications programmatically by just using API calls. By default, these pre-trained models do not use any customer data for training purposes. For a business or company that provides services or products globally, it is really important to have language translation capabilities to understand and engage the audience more effectively. The Cloud Translation API, as a product, addresses the problems of identifying a source language and translating it into the desired target language through an API call. It supports over 100 languages but if it still doesn’t fulfill your requirements, there are ways to train your custom models if you have training data with you. Now, let’s look at the AutoML Translation service for <span class="No-Break">custom models.</span></p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor210"/>AutoML Translation</h2>
			<p>As discussed before, the Cloud Translation API inherently supports over 100 languages for translation, but if there is a need to support an additional language, we have the flexibility to <a id="_idIndexMarker951"/>train our custom models given that we have a sufficient amount of training data available with us. Training custom models is also <a id="_idIndexMarker952"/>helpful when there is a need to support domain-specific translations – for example, if we are working in a financial domain, we would like the translation solution to provide results that are more specific to the <span class="No-Break">financial language.</span></p>
			<p>AutoML Translation inherently trains the state-of-the-art ML model architectures without us needing to put effort into developing our model architectures. We just need to prepare our input-output sentence pairs in the required format, after which AutoML will automatically find the best architecture and train a custom translation model <span class="No-Break">for us.</span></p>
			<p>Let’s check how it works within Cloud Console UI. If we go to the <strong class="bold">Translation</strong> tab from the left pane within Cloud Console, we will find a tab for creating datasets, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.3</em>. Here, we need to provide a unique name for our dataset with source and target languages. Once the dataset has been created, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.3</em>, we can start adding sentence pairs <span class="No-Break">to it:</span></p>
			<div>
				<div id="_idContainer147" class="IMG---Figure">
					<img src="image/B17792_14_3.jpg" alt="Figure 14.3 – Creating a dataset for translation" width="1210" height="293"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.3 – Creating a dataset for translation</p>
			<p>After adding <a id="_idIndexMarker953"/>some data, we can review the dataset’s stats by clicking on the dataset, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.4</em>. As we can see, we have splits <a id="_idIndexMarker954"/>for training, validation, and test pairs. Once the AutoML model has been trained, we can check the metrics on the test dataset to check how good our custom <span class="No-Break">model is:</span></p>
			<div>
				<div id="_idContainer148" class="IMG---Figure">
					<img src="image/B17792_14_4.jpg" alt="Figure 14.4 – Reviewing the dataset for language translation" width="980" height="508"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.4 – Reviewing the dataset for language translation</p>
			<p>Model training can be started by clicking the <strong class="bold">START TRAINING</strong> button, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.4</em>. As soon as the training is complete, we can find our trained models within the <strong class="bold">Models</strong> tab, which shows evaluation metrics on our <span class="No-Break">test partition:</span></p>
			<div>
				<div id="_idContainer149" class="IMG---Figure">
					<img src="image/B17792_14_5.jpg" alt="Figure 14.5 – Custom-trained translation models with evaluation metrics" width="1064" height="314"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.5 – Custom-trained translation models with evaluation metrics</p>
			<p>After successfully training the model, we can get the translation outputs using different methods, such as REST API calls, or by calling the API using different development languages, including Python, Java, Go, and <span class="No-Break">so on.</span></p>
			<p>The following <a id="_idIndexMarker955"/>snippets show one sample API call to a custom translation <a id="_idIndexMarker956"/>model with the Python language. This sample can be found on the official documentation page of Google <span class="No-Break">Translation AI.</span></p>
			<p>The following code shows how to set up the translation service client and <span class="No-Break">other configurations:</span></p>
			<pre class="source-code">
from google.cloud import translate
def translate_text_with_model(
    text: str = "YOUR_TEXT_FOR_TRANSLATION",
    project_id: str = "GCP_PROJECT_ID",
    model_id: str = "CUSTOM_MODEL_ID",
) -&gt; translate.TranslationServiceClient:
    """Translates a given text using custom model."""
    client = translate.TranslationServiceClient()
    location = "us-central1"
    path = f"projects/{project_id}/locations/{location}"
    model_path = f"{path}/models/{model_id}"</pre>			<p>Here, we’re <a id="_idIndexMarker957"/>calling the API with proper <span class="No-Break">language </span><span class="No-Break"><a id="_idIndexMarker958"/></span><span class="No-Break">codes:</span></p>
			<pre class="source-code">
    # With supported language codes: https://cloud.google.com/translate/docs/languages
    response = client.translate_text(
        request={
            "contents": [text],
            "target_language_code": "ja",
            "model": model_path,
            "source_language_code": "en",
            "parent": parent,
            "mime_type": "text/plain",  # mime types: text/plain, text/html
        }
    )</pre>			<p>Here, we’re checking out the <span class="No-Break">model’s response:</span></p>
			<pre class="source-code">
    # print the translation output for each input text
    for translation in response.translations:
        print(f"Translated text output: {translation.translated_text}")
    return response</pre>			<p>Cloud Translation <a id="_idIndexMarker959"/>API itself or augmented with AutoML translation <a id="_idIndexMarker960"/>to support custom models is more suitable for use cases where dynamic or near real-time translation is required on demand. Now, let’s learn about Translation Hub, which can be more suitable for large-scale <span class="No-Break">translation requirements.</span></p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor211"/>Translation Hub</h2>
			<p>Suppose there is an organization that deals with a very large volume of documents that need to be <a id="_idIndexMarker961"/>translated into many different languages quickly. Translation Hub is more suitable for such use cases as it is a fully managed solution <a id="_idIndexMarker962"/>where we don’t need to build any web application or set up infrastructure for this task. Another advantage of using Translation Hub is that it preserves the basic structure and layout of the documents while translating them into many different languages. It is quite easy to set up and inherently leverages Cloud Translation API and AutoML <span class="No-Break">translation solutions.</span></p>
			<p>Let’s discuss some benefits of using <span class="No-Break">Translation Hub.</span></p>
			<h3>Self-serve translation</h3>
			<p>In the past, the only way to translate documents was doing it manually, which was quite slow and <a id="_idIndexMarker963"/>required skilled multi-lingual professionals. Translation <a id="_idIndexMarker964"/>Hub, on the other hand, uses advancements in the field of AI to provide translation in more than 100 languages at super-fast speed. We can also keep human review as a post-processing step to improve any translations coming from the AI models. In this way, Translation Hub saves a lot of time <span class="No-Break">and costs.</span></p>
			<h3>Document translation</h3>
			<p>Suppose we have documents in PDF or DOCX format – we can pass them directly to Translation <a id="_idIndexMarker965"/>Hub and there is no need to extract <a id="_idIndexMarker966"/>text from them beforehand. Additionally, Translation Hub preserves the original structure and format of the document (paragraph breaks, headings, and so on) which is <span class="No-Break">really helpful.</span></p>
			<h3>Simplified administration</h3>
			<p>Like other <a id="_idIndexMarker967"/>Google Cloud offerings, we can manage <a id="_idIndexMarker968"/>user access and portal access within Cloud Console UI. We can also easily create translation resources such as glossaries and <span class="No-Break">translation memories.</span></p>
			<h3>Continuous improvements</h3>
			<p>Suppose we have human-in-the-loop to post-process translations; we can keep those post-edited <a id="_idIndexMarker969"/>translations within Translation Hub <a id="_idIndexMarker970"/>using translation memories. These translation memories can be reused later. Also, we can export these human-reviewed translation memories into a dataset and train a more accurate custom <span class="No-Break">translation model.</span></p>
			<h3>Page-based pricing</h3>
			<p>Translation Hub pricing is very straightforward as it charges based on the number of pages translated <a id="_idIndexMarker971"/>either from Translation API or AutoML-based custom <a id="_idIndexMarker972"/>models. There is no extra cost of deploying and maintaining custom models but the training of custom models is <span class="No-Break">charged separately.</span></p>
			<p>With that, we’ve seen that cloud-based translation is very useful for organizations dealing with large volumes of documents and reaching a global audience within their native languages. Next, let’s learn about the Natural Language AI product on <span class="No-Break">Google Cloud.</span></p>
			<h1 id="_idParaDest-212"><a id="_idTextAnchor212"/>Natural Language AI on Google Cloud</h1>
			<p>Almost every <a id="_idIndexMarker973"/>organization deals with large amounts of <a id="_idIndexMarker974"/>text data in the form of text documents, forms, contracts, PDFs, web pages, user reviews, and so on. Google Cloud offers Natural Language AI, which leverages ML models to derive insights from unstructured text data. Natural Language AI is an end-to-end product that can help in extracting, analyzing, and storing text on <span class="No-Break">Google Cloud.</span></p>
			<p>Google offers the following three natural <span class="No-Break">language solutions:</span></p>
			<ul>
				<li>AutoML for <span class="No-Break">Text Analysis</span></li>
				<li>Natural <span class="No-Break">Language API</span></li>
				<li>Healthcare Natural <span class="No-Break">Language API</span></li>
			</ul>
			<p>Let’s take a closer look at each of <span class="No-Break">these solutions.</span></p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor213"/>AutoML for Text Analysis</h2>
			<p>Imagine that there is an e-commerce company that receives customer queries related to a wide <a id="_idIndexMarker975"/>variety of issues, including payment failures, delivery address updates, product quality issues, and so on. As most of these queries <a id="_idIndexMarker976"/>are typed by customers in a text box, there is a need to classify these queries into a fixed set of categories so that they can be routed to the correct resolution team. Classifying these queries manually becomes quite difficult when the volume of such queries is large. This process can be automated using ML by training a classification model that can automatically categorize issues into <span class="No-Break">appropriate categories.</span></p>
			<p>AutoML on Google Cloud supports training ML models to understand and analyze text data. The main advantage of using AutoML is that we don’t have to write any complex model architecture, model training, or evaluation code. With AutoML, we can train and evaluate ML models without writing any code. We can just go to the AutoML page on the Google Cloud console, upload our dataset in the required format, and start training the <span class="No-Break">ML models.</span></p>
			<p>AutoML currently supports the following three categories of text analysis <span class="No-Break">use cases:</span></p>
			<ul>
				<li><strong class="bold">Classification</strong>: Text classification refers to training ML models that accept text sentences <a id="_idIndexMarker977"/>or paragraphs as input and mapping them to a fixed set of categories as output. Vertex AI also supports multi-label classification, which means that a single input sentence can also be classified into <span class="No-Break">multiple categories.</span></li>
				<li><strong class="bold">Entity extraction</strong>: An entity extraction model scans the text inputs to find and label pre-defined <a id="_idIndexMarker978"/>entities. These entities may include cities, countries, names, addresses, disease names, and so on. Entity extraction models are first trained on a fixed set of labeled entities and are then used to identify entities in unseen text paragraphs <span class="No-Break">or sentences.</span></li>
				<li><strong class="bold">Sentiment analysis</strong>: A sentiment analysis model analyzes text data to identify the emotions <a id="_idIndexMarker979"/>within it. It classifies the text input into categories such as positive, negative, neutral, and so on. Sentiment analysis can help identify the emotions of customers from <span class="No-Break">feedback forms.</span></li>
			</ul>
			<p>Now that we understand how AutoML can help us, let’s discuss the Natural <span class="No-Break">Language API.</span></p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor214"/>Natural Language API</h2>
			<p>The Natural Language API on Google Cloud provides prebuilt state-of-the-art solutions for various <a id="_idIndexMarker980"/>text analysis use cases such as sentiment analysis, entity extraction, classification, and more. As these solutions work with API requests, they can be quickly and easily integrated into any application. Google provides <a id="_idIndexMarker981"/>client libraries to use Natural Language API solutions to provide a better experience to developers by using each supported language’s styles and conventions. A quick example of using client libraries can be found on the <a id="_idIndexMarker982"/>official documentation <span class="No-Break">page (</span><a href="https://cloud.google.com/natural-language/docs/sentiment-analysis-client-libraries"><span class="No-Break">https://cloud.google.com/natural-language/docs/sentiment-analysis-client-libraries</span></a><span class="No-Break">).</span></p>
			<p>The Natural Language API currently provides the following features to support different text analysis <span class="No-Break">use cases:</span></p>
			<ul>
				<li><span class="No-Break">Sentiment analysis</span></li>
				<li><span class="No-Break">Entity extraction</span></li>
				<li>Entity <span class="No-Break">sentiment analysis</span></li>
				<li><span class="No-Break">Syntactic analysis</span></li>
				<li><span class="No-Break">Content classification</span></li>
			</ul>
			<p>The Natural <a id="_idIndexMarker983"/>Language API is a REST API and <a id="_idIndexMarker984"/>thus supports the JSON response and request formats. A sample JSON request can be written <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
{
  "document":
{
            "type":"PLAIN_TEXT",
           "language_code": "EN",
           "content": "This is a sample REST API request to the Natural Language API on Google Cloud."
    },
  "encodingType":"UTF8"
}</pre>			<p>Similarly, a sample response for a sentiment analysis query may look very similar to <span class="No-Break">the following:</span></p>
			<pre class="source-code">
{
  "documentSentiment": {
    "score": 0.1,
    "magnitude": 3.6
  },
  "language_code": "en",
   "sentences": [
    {
      "text": {
        "content": "This is a sample request text for the Natural Language API just to check how it works. In the JSON response you should see the output very close to the neutral sentiment."
        "beginOffset": 0
      },
      "sentiment": {
        "magnitude": 0.8,
        "score": 0.1
      }
    },
   ...
}</pre>			<p>Here, the <a id="_idIndexMarker985"/>sentiment score varies from -1 (negative) to +1 (positive) and anything <a id="_idIndexMarker986"/>close to zero is neutral. The magnitude shows the strength of emotion, which can take any value from 0 <span class="No-Break">to +inf.</span></p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor215"/>Healthcare Natural Language API</h2>
			<p>The Healthcare Natural Language API can be leveraged to derive real-time insights from unstructured <a id="_idIndexMarker987"/>medical text. Unstructured medical text present in medical records, discharge summaries, and insurance <a id="_idIndexMarker988"/>claim documents can be parsed into a structured data representation of medical knowledge entities using the Healthcare Natural Language API. Once this structured output is generated, we can pass it to various downstream applications or <span class="No-Break">create automations.</span></p>
			<p>The key features of the <strong class="bold">Healthcare Natural Language API</strong> are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>You can extract important medical concepts such as medications, procedures, diseases, medical devices, and <span class="No-Break">so on</span></li>
				<li>You can <a id="_idIndexMarker989"/>extract medical insights from text that can be integrated with analytics products on <span class="No-Break">Google Cloud</span></li>
				<li>You can map medical concepts to standard conventions such as RxNorm, ICD-10, MeSH, <span class="No-Break">and others</span></li>
			</ul>
			<p>A sample <a id="_idIndexMarker990"/>response JSON from <a id="_idIndexMarker991"/>the Healthcare Natural Language API is <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
{
    "entityMentions": [
        {
            "mentionId": "1",
            "type": "PROBLEM",
            "text": {
                "content": "COPD",
                "beginOffset": 38
            },
            "linkedEntities": [
                {
                    "entityId": "UMLS/C0024223"
                }
            ],
            "temporalAssessment": {
                "value": "CURRENT",
                "confidence": 0.95
            },
            "certaintyAssessment": {
                "value": "LIKELY",
                "confidence": 0.99
            },
            "subject": {
                "value": "PATIENT",
                "confidence": 0.98
            },
            "confidence": 0.999
        },
        {
            "mentionId": "2",
            "type": "SEVERITY",
            "text": {</pre>			<p>This kind <a id="_idIndexMarker992"/>of entity extraction and <a id="_idIndexMarker993"/>entity relationship extraction functionality can be very helpful for a healthcare company. Now that we have covered natural language-related offerings, let’s look into speech-related <span class="No-Break">products next.</span></p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor216"/>Speech AI on Google Cloud</h1>
			<p>Another <a id="_idIndexMarker994"/>important form of capturing and storing information is <a id="_idIndexMarker995"/>speech. Google has done decades of research to come up with state-of-the-art solutions for many speech and audio data-related use cases. A significant amount of critical information is present in the forms of audio calls and recorded messages and thus it becomes important to transcribe and extract useful insights from them. Also, there are voice assistant-related use cases that demand text-to-speech kind of functionality. Google Cloud offers several solutions for speech understanding and transcriptions. To help organizations tackle these use cases, Google has created the following product offerings related to <span class="No-Break">speech data:</span></p>
			<ul>
				<li><span class="No-Break">Speech-to-Text</span></li>
				<li><span class="No-Break">Text-to-Speech</span></li>
			</ul>
			<p>Now, let’s learn about each of them <span class="No-Break">in detail.</span></p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor217"/>Speech-to-Text</h2>
			<p>A good chunk of useful data is present in unstructured form, such as audio recordings, customer voice calls, videos, and so on, for many organizations. Thus, it becomes important to <a id="_idIndexMarker996"/>analyze this kind of data to extract actionable insights. Making use of such data is only possible if there is a way to accurately <a id="_idIndexMarker997"/>transcribe speech data into text format. Once our data has been converted into text format, we can train several NLP models to get useful business insights from it. Along similar lines, Google provides Speech-to-Text as a product offering to tackle the problem of accurately converting speech data into text. It can help organizations get better insights from their customer interactions and also provide a better experience by enabling the power <span class="No-Break">of voice.</span></p>
			<p>Some <a id="_idIndexMarker998"/>key use cases of Speech-to-Text are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Improving customer service</strong>: Speech-to-Text can help organizations improve their <a id="_idIndexMarker999"/>customer interactions by enabling <strong class="bold">interactive voice response</strong> (<strong class="bold">IVR</strong>) and agent conversations in their call centers. They can also extract insights from conversational data and perform analytics. Speech-to-Text provides specialized ML models for transcribing low-quality phone calls <span class="No-Break">very accurately.</span></li>
				<li><strong class="bold">Enabling voice control</strong>: Voice controls can enhance the user experience significantly <a id="_idIndexMarker1000"/>when applied to <strong class="bold">Internet of Things</strong> (<strong class="bold">IoT</strong>) devices. Users can now interact with devices via voice commands such as <em class="italic">Increase </em><span class="No-Break"><em class="italic">the volume</em></span><span class="No-Break">.</span></li>
				<li><strong class="bold">Multi-media content</strong>: Speech-to-Text allows audio and video to be transcribed on a near real-time basis so that we can incorporate captions to improve the audience reach and experience. Video transcription can also help us subtitle or index our video content. This feature is already being utilized <span class="No-Break">by YouTube.</span></li>
			</ul>
			<p>Some key features <a id="_idIndexMarker1001"/>of Google Speech-to-Text that enable the previously discussed use cases are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Speech adaptation</strong>: The speech recognition model can be customized to recognize rare words or phrases by providing some hints to it. It can also turn spoken numbers into <span class="No-Break">well-formatted addresses.</span></li>
				<li><strong class="bold">Streaming speech recognition</strong>: The Speech Recognition API supports real-time transcription, where audio might come directly from a microphone or <span class="No-Break">pre-recorded file.</span></li>
				<li><strong class="bold">Global vocabulary</strong>: Speech-to-Text supports over 100 languages to support the global <span class="No-Break">user base.</span></li>
				<li><strong class="bold">Multichannel recognition</strong>: Multichannel recordings from video conferences can also be annotated to preserve <span class="No-Break">the order.</span></li>
				<li><strong class="bold">Noise robustness</strong>: Speech-to-Text can handle noisy recordings and still provide very <span class="No-Break">accurate transcriptions.</span></li>
				<li><strong class="bold">Domain adaptation</strong>: Speech-to-Text provides some domain-adapted models as well. For example, phone call recordings are often low-quality audio files, and Google has specialized models for handling call recordings and providing very <span class="No-Break">accurate transcriptions.</span></li>
				<li><strong class="bold">Content filtering</strong>: Speech-to-Text has functionality to detect and remove <span class="No-Break">inappropriate words.</span></li>
				<li><strong class="bold">Speaker diarization</strong>: Speaker diarization is a problem that involves identifying which speaker spoke a phrase in a multi-speaker conversation. Google provides specialized models for <span class="No-Break">speaker diarization.</span></li>
			</ul>
			<p>All these features make Speech-to-Text a very powerful and generic tool that can be easily integrated into any business use case. As this offering has API support, we don’t even have to write a single line of code to start using this solution. Next, let’s learn about another important speech-related <span class="No-Break">solution: Text-to-Speech.</span></p>
			<h2 id="_idParaDest-218"><a id="_idTextAnchor218"/>Text-to-Speech</h2>
			<p>As its name suggests, the Text-to-Speech offering converts text into natural-sounding speech. It can help <a id="_idIndexMarker1002"/>in improving customer interactions with intelligent <a id="_idIndexMarker1003"/>and lifelike responses. We can personalize customer communication by providing responses based on the customer’s preference of language and voice. We can also engage users with voice interactions through IoT devices (for example, <span class="No-Break">Google Assistant).</span></p>
			<p>Some key <a id="_idIndexMarker1004"/>use cases of the Google Text-to-Speech offering are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Voicebots</strong>: We can deliver a better customer experience by providing intelligent voice responses within our contact centers, instead of playing pre-recorded audio. Voicebots can provide customers with a more familiar and <span class="No-Break">personalized sense.</span></li>
				<li><strong class="bold">Voice generation</strong>: We can enable our IoT kind of devices to speak like humans for better communication. Text-to-Speech can be combined with Speech-to-Text and natural language solutions to provide a better end-to-end humanlike <span class="No-Break">conversation experience.</span></li>
				<li><strong class="bold">Electronic program guides</strong> (<strong class="bold">EPGs</strong>): The Text-to-Speech solution can power EPGs to <a id="_idIndexMarker1005"/>read text out loud to provide a better user experience. We can enable blogs to read the news <span class="No-Break">out loud.</span></li>
			</ul>
			<p>To guide <a id="_idIndexMarker1006"/>these interesting use cases, Google has developed the following key features as part of its <span class="No-Break">Text-to-Speech offering:</span></p>
			<ul>
				<li><strong class="bold">Choice of language and voice</strong>: Text-to-Speech currently supports over 200 different types of voice with support of <span class="No-Break">40+ languages.</span></li>
				<li><strong class="bold">WaveNet Voices</strong>: Google Deepmind’s groundbreaking research has enabled WaveNet to generate 90+ extremely human-like voices that close the gap with <span class="No-Break">human performance.</span></li>
				<li><strong class="bold">Custom Voice</strong>: We can enable our own voice in Google Text-to-Speech models by providing some voice recordings. This feature is currently <span class="No-Break">in beta.</span></li>
				<li><strong class="bold">Pitch Tuning</strong>: We can tune the pitch of the <span class="No-Break">selected voice.</span></li>
				<li><strong class="bold">Speaking Rate Tuning</strong>: We get functionality to increase or decrease the speed <span class="No-Break">of speaking.</span></li>
				<li><strong class="bold">Audio format</strong>: Text-to-Speech <a id="_idIndexMarker1007"/>supports several audio formats to provide <span class="No-Break">as output.</span></li>
				<li><strong class="bold">Audio profiles</strong>: We can also optimize the type of devices from which we need to play the audio, such as phone lines, headphones, and <span class="No-Break">so on.</span></li>
			</ul>
			<p class="callout-heading">Warning</p>
			<p class="callout">Custom Voice is currently a private feature within Vertex AI, so we will not be able to implement Custom Voice until we contact a member of the sales <span class="No-Break">team. </span><a href="https://cloud.google.com/contact"><span class="No-Break">https://cloud.google.com/contact</span></a></p>
			<p>With all <a id="_idIndexMarker1008"/>these features, Google Text-to-Speech can be easily integrated into <a id="_idIndexMarker1009"/>applications that can send a REST or gRPC kind of request. Text-to-Speech APIs can be integrated with many different kinds of devices, including phones, tablets, PCs, and other <span class="No-Break">IoT devices.</span></p>
			<h1 id="_idParaDest-219"><a id="_idTextAnchor219"/>Summary</h1>
			<p>Not all the important data is present in a structured format. A significant amount of important information is found in unstructured forms such as audio, videos, documents, recordings, and so on. The progress that’s been made in ML has enabled us to analyze these unstructured data sources on a large scale to extract actionable insights and inform key business decisions. Google has worked on this ML research problem extensively to come up with state-of-the-art solutions for voice, vision, NLP, speech, <span class="No-Break">and more.</span></p>
			<p>In this chapter, we learned about different offerings from Google for understanding and extracting information from unstructured data formats, including audio, videos, images, documents, phone call recordings, and more. After reading this chapter, we should now have a good understanding of each of these offerings, including their key features and potential use cases. After discussing them in detail, we should now be able to find new use cases to apply these solutions to automate or enhance various business processes within an organization. In the next few chapters, we will learn how to build real-world ML solutions such as recommender systems and vision and NLP solutions on <span class="No-Break">Google Cloud.</span></p>
		</div>
	</div>
</div>


<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer151" class="Content">
			<h1 id="_idParaDest-220" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor220"/>Part 4: Building Real-World ML Solutions with Google Cloud</h1>
		</div>
		<div id="_idContainer152">
			<p>In this part, you will explore examples of developing real-world ML solutions, using the tooling provided by Vertex AI in Google Cloud. These examples will show you how to build recommender systems, custom vision-based applications, and custom NLP-based solutions, using the ML tools within <span class="No-Break">Google Cloud.</span></p>
			<p>This part has the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B17792_15.xhtml#_idTextAnchor221"><em class="italic">Chapter 15</em></a>, <em class="italic">Recommender Systems – Predict What Movies a User Would Like to Watch</em></li>
				<li><a href="B17792_16.xhtml#_idTextAnchor233"><em class="italic">Chapter 16</em></a>, <em class="italic">Vision-Based Defect Detection System – Machines Can See Now</em></li>
				<li><a href="B17792_17.xhtml#_idTextAnchor282"><em class="italic">Chapter 17</em></a>, <em class="italic">Natural Language Models – Detecting Fake News Articles</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer153">
			</div>
		</div>
		<div>
			<div id="_idContainer154" class="Basic-Graphics-Frame">
			</div>
		</div>
	</div>
</div>
</body></html>