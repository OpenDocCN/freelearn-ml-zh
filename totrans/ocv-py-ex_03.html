<html><head></head><body>
  <div><div><div><div><div><h1 class="title"><a id="ch03"/>Chapter 3. Cartoonizing an Image</h1></div></div></div><p>In this chapter, we are going to learn how to convert an image into a cartoon-like image. We will learn how to access the webcam and take keyboard/mouse inputs during a live video stream. We will also learn about some advanced image filters and see how we can use them to cartoonize an image.</p><p>By the end of this chapter, you will know:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">How to access the webcam</li><li class="listitem" style="list-style-type: disc">How to take keyboard and mouse inputs during a live video stream</li><li class="listitem" style="list-style-type: disc">How to create an interactive application</li><li class="listitem" style="list-style-type: disc">How to use advanced image filters</li><li class="listitem" style="list-style-type: disc">How to cartoonize an image</li></ul></div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec28"/>Accessing the webcam</h1></div></div></div><p>We can build <a id="id112" class="indexterm"/>very interesting applications using the live video stream from the webcam. OpenCV provides a video capture object which handles everything related to opening and closing of the webcam. All we need to do is create that object and keep reading frames from it.</p><p>The following code will open the webcam, capture the frames, scale them down by a factor of 2, and then <a id="id113" class="indexterm"/>display them in a window. You can press the <em>Esc</em> key to exit.</p><div><pre class="programlisting">import cv2

cap = cv2.VideoCapture(0)

# Check if the webcam is opened correctly
if not cap.isOpened():
    raise IOError("Cannot open webcam")

while True:
    ret, frame = cap.read()
    frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)
    cv2.imshow('Input', frame)

    c = cv2.waitKey(1)
    if c == 27:
        break

cap.release()
cv2.destroyAllWindows()</pre></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec27"/>Under the hood</h2></div></div></div><p>As we can see in the preceding code, we use <a id="id114" class="indexterm"/>OpenCV's <code class="literal">VideoCapture</code> function to create the video<a id="id115" class="indexterm"/> capture object cap. Once it's created, we start an infinite loop and keep reading frames from the webcam until we encounter a keyboard interrupt. In the first line within the while loop, we have the following line:</p><div><pre class="programlisting">ret, frame = cap.read()</pre></div><p>Here, <code class="literal">ret</code> is a Boolean value returned by the <code class="literal">read</code> function, and it indicates whether or not the frame was captured <a id="id116" class="indexterm"/>successfully. If the frame is captured correctly, it's stored in the variable <code class="literal">frame</code>. This loop will keep running until we press the <em>Esc</em> key. So we keep checking for a keyboard interrupt in the following line:</p><div><pre class="programlisting">if c == 27:</pre></div><p>As we know, the ASCII value of <em>Esc</em> is 27. Once we encounter it, we break the loop and release the video capture object. The line <code class="literal">cap.release()</code> is important because it gracefully closes the webcam.</p></div></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec29"/>Keyboard inputs</h1></div></div></div><p>Now that we know<a id="id117" class="indexterm"/> how to capture a live video stream from the webcam, let's see how to use the keyboard to interact with the window displaying the video stream.</p><div><pre class="programlisting">import argparse

import cv2

def argument_parser():
    parser = argparse.ArgumentParser(description="Change color space of the \
            input video stream using keyboard controls. The control keys are: \
            Grayscale - 'g', YUV - 'y', HSV - 'h'")
    return parser

if __name__=='__main__':
    args = argument_parser().parse_args()

    cap = cv2.VideoCapture(0)

    # Check if the webcam is opened correctly
    if not cap.isOpened():
        raise IOError("Cannot open webcam")

    cur_char = -1
    prev_char = -1

    while True:
        # Read the current frame from webcam
        ret, frame = cap.read()

        # Resize the captured image
        frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)

        c = cv2.waitKey(1)

        if c == 27:
            break

        if c &gt; -1 and c != prev_char:
            cur_char = c
        prev_char = c

        if cur_char == ord('g'):
            output = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        elif cur_char == ord('y'):
            output = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)

        elif cur_char == ord('h'):
            output = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

        else:
            output = frame

        cv2.imshow('Webcam', output)

    cap.release()
    cv2.destroyAllWindows()</pre></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec28"/>Interacting with the application</h2></div></div></div><p>This program <a id="id118" class="indexterm"/>will display the input video stream and wait for the keyboard input to change the color space. If you run the previous program, you will see the window displaying the input video stream from the webcam. If you press <em>G</em>, you will see that the color space of the input stream gets converted to grayscale. If you press <em>Y</em>, the input stream will be converted to YUV color space. Similarly, if you press <em>H</em>, you will see the image being converted to HSV color space.</p><p>As we know, we use the function <a id="id119" class="indexterm"/>
<code class="literal">waitKey()</code> to listen to the keyboard events. As and when we encounter different keystrokes, we take appropriate actions. The reason we are using the<a id="id120" class="indexterm"/> function <code class="literal">ord()</code> is because <code class="literal">waitKey()</code> returns the ASCII value of the keyboard input; thus, we need to convert the characters into their ASCII form before checking their values.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec30"/>Mouse inputs</h1></div></div></div><p>In this section, we will see how to use the mouse to interact with the display window. Let's start with something simple. We will write a program that will detect the quadrant in which the mouse<a id="id121" class="indexterm"/> click was detected. Once we detect it, we will highlight that quadrant.</p><div><pre class="programlisting">import cv2
import numpy as np

def detect_quadrant(event, x, y, flags, param):
    if event == cv2.EVENT_LBUTTONDOWN:
        if x &gt; width/2:
            if y &gt; height/2:
                point_top_left = (int(width/2), int(height/2))
                point_bottom_right = (width-1, height-1)
            else:
                point_top_left = (int(width/2), 0)
                point_bottom_right = (width-1, int(height/2))

        else:
            if y &gt; height/2:
                point_top_left = (0, int(height/2))
                point_bottom_right = (int(width/2), height-1)
            else:
                point_top_left = (0, 0)
                point_bottom_right = (int(width/2), int(height/2))

        cv2.rectangle(img, (0,0), (width-1,height-1), (255,255,255), -1)
        cv2.rectangle(img, point_top_left, point_bottom_right, (0,100,0), -1)

if __name__=='__main__':
    width, height = 640, 480
    img = 255 * np.ones((height, width, 3), dtype=np.uint8)
    cv2.namedWindow('Input window')
    cv2.setMouseCallback('Input window', detect_quadrant)

    while True:
        cv2.imshow('Input window', img)
        c = cv2.waitKey(10)
        if c == 27:
            break

    cv2.destroyAllWindows()</pre></div><p>The output will look<a id="id122" class="indexterm"/> something like the following image:</p><div><img src="img/B04554_03_01.jpg" alt="Mouse inputs"/></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec29"/>What's happening underneath?</h2></div></div></div><p>Let's start with the main function in this program. We create a white image on which we are going to click using<a id="id123" class="indexterm"/> the mouse. We then create a named window and bind the mouse callback function to this window. Mouse callback function is basically the function that will <a id="id124" class="indexterm"/>be called when a mouse event is detected. There are many kinds of mouse events such as clicking, double-clicking, dragging, and so on. In our case, we just want to detect a mouse click. In the function <code class="literal">detect_quadrant</code>, we check the first input argument event to see what action was performed. OpenCV provides a set of predefined events, and we can call them using specific keywords. If you want to see a list of all the mouse events, you can go to the Python shell and type the following:</p><div><pre class="programlisting">&gt;&gt;&gt; import cv2
&gt;&gt;&gt; print [x for x in dir(cv2) if x.startswith('EVENT')]</pre></div><p>The second and third arguments in the function <code class="literal">detect_quadrant</code> provide the X and Y coordinates of the mouse click event. Once we know these coordinates, it's pretty straightforward to <a id="id125" class="indexterm"/>determine what quadrant it's in. With this information, we just go ahead and draw a rectangle with the specified color, using <code class="literal">cv2.rectangle()</code>. This is a very handy function that takes the top left point and the bottom right point to draw a rectangle on an image with the specified color.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec31"/>Interacting with a live video stream</h1></div></div></div><p>Let's see how we <a id="id126" class="indexterm"/>can use the mouse to interact with live video stream from the webcam. We can use the mouse to select a region and then apply the "negative film" effect on that region, as shown next:</p><div><img src="img/B04554_03_02.jpg" alt="Interacting with a live video stream"/></div><p>In the following<a id="id127" class="indexterm"/> program, we will capture the video stream from the webcam, select a region of interest with the mouse, and then apply the effect:</p><div><pre class="programlisting">import cv2
import numpy as np

def draw_rectangle(event, x, y, flags, params):
    global x_init, y_init, drawing, top_left_pt, bottom_right_pt

    if event == cv2.EVENT_LBUTTONDOWN:
        drawing = True
        x_init, y_init = x, y

    elif event == cv2.EVENT_MOUSEMOVE:
        if drawing:
            top_left_pt = (min(x_init, x), min(y_init, y))
            bottom_right_pt = (max(x_init, x), max(y_init, y))
            img[y_init:y, x_init:x] = 255 - img[y_init:y, x_init:x]

    elif event == cv2.EVENT_LBUTTONUP:
        drawing = False
        top_left_pt = (min(x_init, x), min(y_init, y))
        bottom_right_pt = (max(x_init, x), max(y_init, y))
        img[y_init:y, x_init:x] = 255 - img[y_init:y, x_init:x]

if __name__=='__main__':
    drawing = False
    top_left_pt, bottom_right_pt = (-1,-1), (-1,-1)

    cap = cv2.VideoCapture(0)

    # Check if the webcam is opened correctly
    if not cap.isOpened():
        raise IOError("Cannot open webcam")

    cv2.namedWindow('Webcam')
    cv2.setMouseCallback('Webcam', draw_rectangle)

    while True:
        ret, frame = cap.read()
        img = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)
        (x0,y0), (x1,y1) = top_left_pt, bottom_right_pt
        img[y0:y1, x0:x1] = 255 - img[y0:y1, x0:x1]
        cv2.imshow('Webcam', img)

        c = cv2.waitKey(1)
        if c == 27:
            break

    cap.release()
    cv2.destroyAllWindows()</pre></div><p>If you run the<a id="id128" class="indexterm"/> preceding program, you will see a window displaying the video stream. You can just draw a rectangle on the window using your mouse and you will see that region being converted to its "negative".</p><div><div><div><div><h2 class="title"><a id="ch03lvl2sec30"/>How did we do it?</h2></div></div></div><p>As we can see<a id="id129" class="indexterm"/> in the main function of the program, we initialize a video capture object. We then bind the function <code class="literal">draw_rectangle</code> with the mouse callback in the following line:</p><div><pre class="programlisting">cv2.setMouseCallback('Webcam', draw_rectangle)</pre></div><p>We then start an infinite loop and start capturing the video stream. Let's see what is happening in the function <code class="literal">draw_rectangle</code>. Whenever we draw a rectangle using the mouse, we basically have to detect three types of mouse events: mouse click, mouse movement, and mouse button release. This is exactly what we do in this function. Whenever we detect a mouse click event, we initialize the top left point of the rectangle. As we move the mouse, we select the region of interest by keeping the current position as the bottom right point of the rectangle.</p><p>Once we have the region of interest, we just invert the pixels to apply the "negative film" effect. We subtract the current pixel value from 255 and this gives us the desired effect. When the mouse movement stops and button-up event is detected, we stop updating the bottom right position of the rectangle. We just keep displaying this image until another mouse click <a id="id130" class="indexterm"/>event is detected.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec32"/>Cartoonizing an image</h1></div></div></div><p>Now that we know how to<a id="id131" class="indexterm"/> handle the webcam and keyboard/mouse inputs, let's go ahead and see how to convert a picture into a cartoon-like image. We can either convert an image into a sketch or a colored cartoon image.</p><p>Following is an example of what a sketch will look like:</p><div><img src="img/B04554_03_03.jpg" alt="Cartoonizing an image"/></div><p>If you apply the cartoonizing effect to the color image, it will look something like this next image:</p><div><img src="img/B04554_03_04.jpg" alt="Cartoonizing an image"/></div><p>Let's see how to <a id="id132" class="indexterm"/>achieve this:</p><div><pre class="programlisting">import cv2
import numpy as np

def cartoonize_image(img, ds_factor=4, sketch_mode=False):
    # Convert image to grayscale
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Apply median filter to the grayscale image
    img_gray = cv2.medianBlur(img_gray, 7)

    # Detect edges in the image and threshold it
    edges = cv2.Laplacian(img_gray, cv2.CV_8U, ksize=5)
    ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)

    # 'mask' is the sketch of the image
    if sketch_mode:
        return cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)

    # Resize the image to a smaller size for faster computation
    img_small = cv2.resize(img, None, fx=1.0/ds_factor, fy=1.0/ds_factor, interpolation=cv2.INTER_AREA)
    num_repetitions = 10
    sigma_color = 5
    sigma_space = 7
    size = 5

    # Apply bilateral filter the image multiple times
    for i in range(num_repetitions):
        img_small = cv2.bilateralFilter(img_small, size, sigma_color, sigma_space)

    img_output = cv2.resize(img_small, None, fx=ds_factor, fy=ds_factor, interpolation=cv2.INTER_LINEAR)

    dst = np.zeros(img_gray.shape)

    # Add the thick boundary lines to the image using 'AND' operator
    dst = cv2.bitwise_and(img_output, img_output, mask=mask)
    return dst

if __name__=='__main__':
    cap = cv2.VideoCapture(0)

    cur_char = -1
    prev_char = -1

    while True:
        ret, frame = cap.read()
        frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)

        c = cv2.waitKey(1)
        if c == 27:
            break

        if c &gt; -1 and c != prev_char:
            cur_char = c
        prev_char = c

        if cur_char == ord('s'):
            cv2.imshow('Cartoonize', cartoonize_image(frame, sketch_mode=True))
        elif cur_char == ord('c'):
            cv2.imshow('Cartoonize', cartoonize_image(frame, sketch_mode=False))
        else:
            cv2.imshow('Cartoonize', frame)

    cap.release()
    cv2.destroyAllWindows()</pre></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec31"/>Deconstructing the code</h2></div></div></div><p>When you run the<a id="id133" class="indexterm"/> preceding program, you will see a window with a video stream from the webcam. If you press <em>S</em>, the video stream will change to sketch mode and you will see its pencil-like outline. If you press <em>C</em>, you will see the color-cartoonized version of the input stream. If you press any other key, it will return to the normal mode.</p><p>Let's look at<a id="id134" class="indexterm"/> the function <code class="literal">cartoonize_image</code> and see how we did it. We first convert the image to a grayscale image and run it through a median filter. Median filters are very good at removing <a id="id135" class="indexterm"/>salt and pepper noise. This is the kind of noise where you see isolated black or white pixels in the image. It is common in webcams and mobile cameras, so we need to filter it out before we proceed further. To give an example, look at the following images:</p><div><img src="img/B04554_03_05.jpg" alt="Deconstructing the code"/></div><p>As we see in the input image, there are a lot of isolated green pixels. They are lowering the quality of the image and we need to get rid of them. This is where the median filter comes in handy. We just look at the NxN neighborhood around each pixel and pick the median value of those numbers. Since the isolated pixels in this case have high values, taking the median value will get rid of these values and also smoothen the image. As you can see in the output image, the median filter got rid of all those isolated pixels and the image looks clean. Following is the code to do it:</p><div><pre class="programlisting">import cv2
import numpy as np

img = cv2.imread('input.png')
output = cv2.medianBlur(img, 7)
cv2.imshow('Input', img)
cv2.imshow('Median filter', output)
cv2.waitKey()</pre></div><p>The code is pretty straightforward. We just use the function <code class="literal">medianBlur</code> to apply the median filter to<a id="id136" class="indexterm"/> the input image. The second argument in this function specifies the size of the kernel we are using. The size of the kernel is related to the neighborhood size that we need to consider. You can play around with this parameter and see how it affects the output.</p><p>Coming back to <code class="literal">cartoonize_image</code>, we proceed to detect the edges on the grayscale image. We need to know where the edges are so that we can create the pencil-line effect. Once we detect the edges, we threshold them so that things become black and white, both literally and metaphorically!</p><p>In the next step, we check if the sketch mode is enabled. If it is, then we just convert it into a color image and return it. What if we want the lines to be thicker? Let's say we want to see something like the following image:</p><div><img src="img/B04554_03_06.jpg" alt="Deconstructing the code"/></div><p>As you can see, the lines <a id="id137" class="indexterm"/>are thicker than before. To achieve this, replace the <code class="literal">if</code> code block with the following piece of code:</p><div><pre class="programlisting">if sketch_mode:
    img_sketch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
    kernel = np.ones((3,3), np.uint8)
    img_eroded = cv2.erode(img_sketch, kernel, iterations=1)
    return cv2.medianBlur(img_eroded, 5)</pre></div><p>We are using the erode function with a 3x3 kernel here. The reason we have this in place is because it gives us a chance to play with the thickness of the line drawing. Now you might ask that if we want to increase the thickness of something, shouldn't we be using dilation? Well, the reasoning is right, but there is a small twist here. Note that the foreground is black and the background is white. Erosion and dilation treat white pixels as foreground and black pixels as background. So if we want to increase the thickness of the black foreground, we need to use erosion. After we apply erosion, we just use the median filter to clear out the noise and get the final output.</p><p>In the next step, we use bilateral filtering to smoothen the image. Bilateral filtering is an interesting concept and its performance is much better than a Gaussian filter. The good thing about bilateral<a id="id138" class="indexterm"/> filtering is that it preserves the edges, whereas the Gaussian filter smoothens everything out equally. To compare and contrast, let's look at the following input image:</p><div><img src="img/B04554_03_07.jpg" alt="Deconstructing the code"/></div><p>Let's apply the Gaussian filter to the previous image:</p><div><img src="img/B04554_03_08.jpg" alt="Deconstructing the code"/></div><p>Now, let's apply the<a id="id139" class="indexterm"/> bilateral filter to the input image:</p><div><img src="img/B04554_03_09.jpg" alt="Deconstructing the code"/></div><p>As you can see, the quality is better if we use the bilateral filter. The image looks smooth and the edges look nice and sharp! The code to achieve this is given next:</p><div><pre class="programlisting">import cv2
import numpy as np

img = cv2.imread('input.jpg')

img_gaussian = cv2.GaussianBlur(img, (13,13), 0)
img_bilateral = cv2.bilateralFilter(img, 13, 70, 50)

cv2.imshow('Input', img)
cv2.imshow('Gaussian filter', img_gaussian)
cv2.imshow('Bilateral filter', img_bilateral)
cv2.waitKey()</pre></div><p>If you closely observe the<a id="id140" class="indexterm"/> two outputs, you can see that the edges in the Gaussian filtered image look blurred. Usually, we just want to smoothen the rough areas in the image and keep the edges intact. This is where the bilateral filter comes in handy. The Gaussian filter just looks at the immediate neighborhood and averages the pixel values using a Gaussian kernel. The bilateral filter takes this concept to the next level by averaging only those pixels that are similar to each other in intensity. It also takes a color neighborhood metric to see if it can replace the current pixel that is similar in intensity as well. If you look the function call:</p><div><pre class="programlisting">img_small = cv2.bilateralFilter(img_small, size, sigma_color, sigma_space)</pre></div><p>The last two arguments here specify the color and space neighborhood. This is the reason the edges look crisp in the output of the bilateral filter. We run this filter multiple times on the image to smoothen it out, to make it look like a cartoon. We then superimpose the pencil-like mask on top of this color image to create a cartoon-like effect.</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec33"/>Summary</h1></div></div></div><p>In this chapter, we learnt how to access the webcam. We discussed how to take the keyboard and mouse inputs during live video stream. We used this knowledge to create an interactive application. We discussed the median and bilateral filters, and talked about the advantages of the bilateral filter over the Gaussian filter. We used all these principles to convert the input image into a sketch-like image, and then cartoonized it.</p><p>In the next chapter, we will learn how to detect different body parts in static images as well as in live videos.</p></div></div>
</body></html>