["```py\nimport math\nimport os, random, re, gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport mldatasets\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer,\\\n                         AutoModelForSequenceClassification, pipeline\nfrom bertviz import head_view, model_view\nfrom captum.attr import LayerIntegratedGradients,\\\n                        TokenReferenceBase, visualization\nfrom lit_nlp import notebook\nfrom lit_nlp.api import dataset as lit_dataset\nfrom lit_nlp.api import model as lit_model\nfrom lit_nlp.api import types as lit_types \n```", "```py\nreviews_df = mldatasets.load(\"nyc-reviews\", prepare=True) \n```", "```py\nreviews_df.info() \n```", "```py\nreviews_df[[\"review_title\",\"review_full\",\"label\",\"score\"]].head(3) \nFigure 8.2:\n```", "```py\nsum_cols_l = [\"score\",\"positive_sentiment\",\"rating\"]\nsummary_df = reviews_df.groupby(\"label\")[sum_cols_l].agg(\n    {\"score\":[\"count\",\"mean\"], \"positive_sentiment\":\"mean\", \"rating\":\"mean\"}\n)\nsummary_df.columns = [\"count\", \"avg. score\", \"% positive\", \"avg. rating\"]\nsummary_df.sort_values(by=\"avg. rating\", ascending=False).style.format(\n    {\n        \"count\":\"{:,}\",\n        \"avg. score\":\"{:.1%}\",\n        \"% positive\":\"{:.1%}\" ,\n        \"avg. rating\":\"{:.2f}\"\n    }\n).bar(subset=[\"avg. score\", \"% positive\", \"avg. rating\"],\\\n              color=\"#4EF\", width=60) \n```", "```py\nrand = 42\nos.environ[\"PYTHONHASHSEED\"]=str(rand)\nrandom.seed(rand)\nnp.random.seed(rand)\ntorch.manual_seed(rand) \n```", "```py\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ngoemotions_mdl_path = \"monologg/bert-base-cased-goemotions-ekman\"\ngoemotions_tok = AutoTokenizer.from_pretrained(goemotions_mdl_path)\ngoemotions_mdl = AutoModelForSequenceClassification.from_pretrained(\n    goemotions_mdl_path, output_attentions=True\n)\ngoemotions_mdl.to(device)\ngoemotions_mdl.eval() \n```", "```py\nnum_layers = goemotions_mdl.config.num_hidden_layers\nnum_attention_heads = goemotions_mdl.config.num_attention_heads\nprint(f\"The model has {num_layers} layers.\")\nprint(f\"Each layer has {num_attention_heads} attention heads.\") \n```", "```py\nsurprise_sample_reviews_l = [174067, 284154, 480395, 47659]\nline_pattern = r\"(?<=[.!?])\\s+\"\nsample_reviews_dict = {}\nfor i, review_idx in enumerate(surprise_sample_reviews_l):\n    review_s = reviews_df.loc[review_idx, :]\n    sentiment = \"Positive\" if review_s[\"positive_sentiment\"]\\\n                            else \"Negative\"\n    review_lines_l = re.split(\n        line_pattern, review_s[\"review_full\"], maxsplit=1\n    )\n    review_txt = \"\\r\\n\\t\\t\".join(review_lines_l)\n    print(f\"{review_s[\"restaurant_name\"]}\") \n    print(f\"\\tSentiment:\\t\\t{sentiment}\")\n    print(f\"\\tRating:\\t\\t\\t{review_s[\"rating\"]}\")\n    print(f\"\\tGoEmotions Label:\\t{review_s[\"label\"]}\")\n    print(f\"\\tGoEmotions Score:\\t{review_s[\"score\"]:.1%}\")\n    print(f\"\\tTitle:\\t{review_s[\"review_title\"]}\")\n    print(f\"\\tReview:\\t {review_txt}\")\n    sample_reviews_dict[i] = review_lines_l \nFigure 8.4:\n```", "```py\ndef view_attention(tokenizer, model, sentences, view=\"model\"):\n    sentence_a, sentence_b = sentences\n    # Encode sentences with tokenizer\n    inputs = tokenizer.encode_plus(\n        sentence_a, sentence_b, return_tensors=\"pt\"\n    )\n    # Extract components from inputs\n    input_ids = inputs[\"input_ids\"]\n    token_type_ids = inputs[\"token_type_ids\"]\n    # Get attention weights from model given the inputs\n    attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n    # Get 2nd sentence start and tokens\n    sentence_b_start = token_type_ids[0].tolist().index(1)\n    input_id_list = input_ids[0].tolist()\n    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n    # BertViz visualizers\n    if view==\"head\":\n        head_view(attention, tokens, sentence_b_start)\n    elif view==\"model\":\n        model_view(attention, tokens, sentence_b_start) \n```", "```py\n sentences in the 1st sample review:\n```", "```py\nview_attention(\n    goemotions_tok, goemotions_mdl, sample_reviews_dict[0], view=\"model\"\n) \n```", "```py\nview_attention(\n    goemotions_tok, goemotions_mdl, sample_reviews_dict[0], view=\"head\"\n) \n```", "```py\ngoemotions = pipeline(\n    model=goemotions_mdl,\n    tokenizer=goemotions_tok,\n    task=\"text-classification\",\n    function_to_apply=\"softmax\",\n    device=device,\n    top_k=None\n) \n```", "```py\ngoemotions([\"this restaurant was unexpectedly disgusting!\",\n            \"this restaurant was shockingly amazing!\"]) \n```", "```py\n[[{\"label\": \"disgust\", \"score\": 0.961812436580658},\n  {\"label\": \"surprise\", \"score\": 0.022211072966456413},\n  {\"label\": \"sadness\", \"score\": 0.004870257806032896},\n  {\"label\": \"anger\", \"score\": 0.0034139526542276144},\n  {\"label\": \"joy\", \"score\": 0.003016095608472824},\n  {\"label\": \"fear\", \"score\": 0.0027414397336542606},\n  {\"label\": \"neutral\", \"score\": 0.0019347501220181584}],\n [{\"label\": \"joy\", \"score\": 0.6631762385368347},\n  {\"label\": \"surprise\", \"score\": 0.3326122760772705},\n  {\"label\": \"neutral\", \"score\": 0.001732577453367412},\n  {\"label\": \"anger\", \"score\": 0.0011324150254949927},\n  {\"label\": \"sadness\", \"score\": 0.0010195496724918485},\n  {\"label\": \"fear\", \"score\": 0.00021178492170292884},\n  {\"label\": \"disgust\", \"score\": 0.00011514205834828317}]] \n```", "```py\ndef visualize_ig_review(interpret_s:pd.Series,\n                          pline:pipeline,\n                          max_prob_thresh:float=0.1,\n                          max_classes=np.PINF,\n                          concat_title=True,\n                          summary_df=None\n) -> pd.DataFrame:\n    print(f\"{interpret_s.name}: {interpret_s['restaurant_name']}\")\n    # Init some variables\n    if concat_title:\n        text = interpret_s[\"review_title\"] + \":\" + interpret_s[\"review_full\"]\n    else:\n        text = interpret_s[\"review_full\"]\n    true_label = \"Positive\" if interpret_s[\"positive_sentiment\"]\\\n                            else \"Negative\"\n    rating = interpret_s[\"rating\"]\n    # Get predictions\n    prediction = pline(text)[0]\n    prediction_df = pd.DataFrame(prediction)\n    if summary_df is not None:\n        prediction_df[\"label_avg_rating\"] = prediction_df.label.\\\n            replace(summary_df[\"avg. rating\"].to_dict())\n        prediction_df = prediction_df.sort_values(\"label_avg_rating\",\\\n           ascending=False).reset_index(drop=True)\n    # Process predictions\n    prediction_tuples = [(p[\"label\"], p[\"score\"]) for p in prediction]\n    sorted_prediction_tuples = sorted(prediction_tuples,\\\n        key=lambda x: x[1], reverse=True)\n    pred_class, pred_prob = sorted_prediction_tuples[0]\n    # Initialize Integrated Gradients\n    forward_func = lambda inputs, position=0: pline.model(\n        inputs, attention_mask=torch.ones_like(inputs)\n    )[position]\n    layer = getattr(pline.model, \"bert\").embeddings\n    lig = LayerIntegratedGradients(forward_func, layer)\n    # Prepare tokens and baseline\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available()\\\n                            else \"cpu\")\n    inputs = torch.tensor(pline.tokenizer.encode(text,\\\n        add_special_tokens=False), device = device).unsqueeze(0)\n    tokens = pline.tokenizer.convert_ids_to_tokens(\n        inputs.detach().numpy()[0]\n    )\n    sequence_len = inputs.shape[1]\n    baseline = torch.tensor(\n        [pline.tokenizer.cls_token_id]\\\n        + [pline.tokenizer.pad_token_id] * (sequence_len - 2)\\\n        + [pline.tokenizer.sep_token_id],\\\n        device=device\n    ).unsqueeze(0)\n    # Iterate over every prediction\n    vis_record_l = []\n    for i, (attr_class, attr_score) in\\ \n        enumerate(sorted_prediction_tuples):\n        if (attr_score > max_prob_thresh) and (i < max_classes):\n            # Sets the target class\n            target = pline.model.config.label2id[attr_class]\n            # Get attributions\n            with torch.no_grad():\n                attributes, delta = lig.attribute(\n                    inputs=inputs,\n                    baselines=baseline,\n                    target=target,\n                    return_convergence_delta = True\n                )\n            # Post-processing attributions\n            attr = attributes.sum(dim=2).squeeze(0)\n            attr = attr / torch.norm(attr)\n            attr = attr.cpu().detach().numpy()\n            # Generate & Append Visualization Data Record\n            vis_record = visualization.VisualizationDataRecord(\n                    word_attributions=attr,\n                    pred_prob=pred_prob,\n                    pred_class=pred_class,\n                    true_class=f\"{true_label} ({rating})\",\n                    attr_class=attr_class,\n                    attr_score=attr_score,\n                    raw_input_ids=tokens,\n                    convergence_score=delta\n            )\n            vis_record_l.append(vis_record)\n    # Display list of visualization data records\n    _ = visualization.visualize_text(vis_record_l)\n    return prediction_df \n```", "```py\nneg_surprise_df = reviews_df[\n    (reviews_df[\"label\"]==\"surprise\")\n    & (reviews_df[\"score\"]>0.9)\n    & (reviews_df[\"positive_sentiment\"]==0)\n    & (reviews_df[\"rating\"]<3)\n] #43\nneg_surprise_samp_df = neg_surprise_df.sample(\n    n=10, random_state=rand\n) \n```", "```py\nfor i in range(10):\n    sample_to_interpret = neg_surprise_samp_df.iloc[i]\n    _ = visualize_ig_review(\n        sample_to_interpret, goemotions, concat_title=True, summary_df=summary_df\n) \nFigure 8.7:\n```", "```py\npos_surprise_df = reviews_df[\n    (reviews_df[\"label\"]==\"surprise\")\n    & (reviews_df[\"score\"]>0.97)\n    & (reviews_df[\"positive_sentiment\"]==1)\n    & (reviews_df[\"rating\"]>4)\n]\npos_surprise_samp_df = pos_surprise_df[\n    ~pos_surprise_df[\"review_full\"].str.contains(\"surprise\")\n]\nfor i in range(10):\n    sample_to_interpret = pos_surprise_samp_df.iloc[i]\n    _ = visualize_ig_review(\n        sample_to_interpret, goemotions,\\\n        concat_title=False, summary_df=summary_df\n) \n```", "```py\npos_mixed_samp_df = reviews_df[\n    (~reviews_df[\"label\"].isin([\"neutral\",\"joy\"]))\n    & (reviews_df[\"score\"] < 0.5)\n    & (reviews_df[\"positive_sentiment\"]==1)\n    & (reviews_df[\"rating\"]< 5)\n].sample(n=10, random_state=rand)\nneg_mixed_samp_df = reviews_df[\n    (~reviews_df[\"label\"].isin([\"neutral\",\"joy\"]))\n    & (reviews_df[\"score\"] < 0.5)\n    & (reviews_df[\"positive_sentiment\"]==0)\n    & (reviews_df[\"rating\"]>2)\n].sample(n=10, random_state=rand) \nmldatasets.plot_polar, which plots a polar line chart for the predictions with plotly. You’ll need both plotly and kaleido to make this work:\n```", "```py\nfor i in range(10):\n    sample_to_interpret = pos_mixed_samp_df.iloc[i]\n    prediction_df = visualize_ig_review(\n        sample_to_interpret,\\\n        goemotions, concat_title=False,\\\n        summary_df=summary_df\n    )\n    rest_name = sample_to_interpret[\"restaurant_name\"]\n    mldatasets.plot_polar(\n    prediction_df, \"score\", \"label\", name=rest_name\n) \n```", "```py\nclass GEDataset(lit_dataset.Dataset):\n    GE_LABELS = [\"anger\", \"disgust\", \"fear\", \"joy\",\\\n                 \"neutral\", \"sadness\", \"surprise\"]\n    def __init__(self, df: pd.DataFrame):\n        self._examples = [{\n            \"review\": row[\"review_title\"] + \":\" + row[\"review_full\"],\n            \"label\": row[\"label\"],\n            \"rating\": row[\"rating\"],\n            \"positive\": row[\"positive_sentiment\"]\n        } for _, row in df.iterrows()]\n    def spec(self):\n        return {\n            \"review\": lit_types.TextSegment(),\n            \"label\": lit_types.CategoryLabel(vocab=self.GE_LABELS),\n            \"rating\": lit_types.CategoryLabel(),\n            \"positive\": lit_types.CategoryLabel()\n        } \n```", "```py\nclass GEModel(lit_model.Model):\n    GE_LABELS = [\"anger\", \"disgust\", \"fear\", \"joy\",\\\n                 \"neutral\", \"sadness\", \"surprise\"]\n    def __init__(self, model, tokenizer, **kw):\n        self._model = pipeline(\n            model=model,\n            tokenizer=tokenizer,\n            task=\"text-classification\",\n            function_to_apply=\"softmax\",\n            device=device,\n            top_k=None\n        )\n    def input_spec(self):\n        return {\n            \"review\": lit_types.TextSegment()\n        }\n    def output_spec(self):\n        return {\n            \"probas\": lit_types.MulticlassPreds(vocab=self.GE_LABELS,\\\n                                                parent=\"label\")\n        }\n    def predict_minibatch(self, inputs):\n        examples = [d[\"review\"] for d in inputs]\n        with torch.no_grad():\n            preds = self._model(examples)\n        preds = [{p[\"label\"]:p[\"score\"] for p in pred_dicts}\\\n                for pred_dicts in preds]\n        preds = [dict(sorted(pred_dict.items())) for pred_dict in preds]\n        preds = [{\"probas\": list(pred_dict.values())} for pred_dict in preds]\n        return preds \n```", "```py\nmodels = {\"GoEmotion\":GEModel(goemotions_mdl, goemotions_tok)}\nsamples100_df = pd.concat(\n    [\n        neg_surprise_samp_df,\n        pos_surprise_samp_df,\n        neg_mixed_samp_df,\n        pos_mixed_samp_df,\n        reviews_df.sample(n=60, random_state=rand)\n    ]\n)\ndatasets = {\"NYCRestaurants\":GEDataset(samples100_df)}\nwidget = notebook.LitWidget(models, datasets)\nwidget.render(height=600)\n# litserver = lit_nlp.dev_server.Server(models, datasets, port=4321)\n# litserver.serve() \nFigure 8.10:\n```"]