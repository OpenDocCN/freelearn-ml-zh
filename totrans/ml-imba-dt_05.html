<html><head></head><body>
		<div id="_idContainer098">
			<h1 id="_idParaDest-100" class="chapter-number"><a id="_idTextAnchor151"/>5</h1>
			<h1 id="_idParaDest-101"><a id="_idTextAnchor152"/>Cost-Sensitive Learning</h1>
			<p>So far, we have studied various sampling techniques and ways to oversample or undersample data. However, both of these techniques have their own unique set of issues. For example, oversampling can easily lead to overfitting of the model due to the exact or very similar examples being seen repeatedly. Similarly, with undersampling, we lose some information (that could have been useful for the model) because we discard the majority class examples to balance the training dataset. In this chapter, we’ll consider an alternative to the data-level techniques that we learned <span class="No-Break">about previously.</span></p>
			<p>Cost-sensitive learning is an effective strategy to tackle imbalanced data. We will go through this technique and learn why it can be useful. This will help us understand some of the details of cost functions and how machine learning models are not designed to deal with imbalanced datasets by default. While machine learning models aren’t equipped to handle imbalanced datasets, we will see how modern libraries <span class="No-Break">enable this.</span></p>
			<p>We will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>The concept <a id="_idIndexMarker325"/>of <strong class="bold">cost-sensitive </strong><span class="No-Break"><strong class="bold">learning</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">CSL</strong></span><span class="No-Break">)</span></li>
				<li>Understanding costs <span class="No-Break">in practice</span></li>
				<li>Cost-sensitive learning for <span class="No-Break">logistic regression</span></li>
				<li>Cost-sensitive learning for <span class="No-Break">decision trees</span></li>
				<li>Cost-sensitive learning using <strong class="source-inline">scikit-learn</strong> and <span class="No-Break">XGBoost models</span></li>
				<li>MetaCost – making any classification <span class="No-Break">model cost-sensitive</span></li>
				<li><span class="No-Break">Threshold adjustment</span></li>
			</ul>
			<p>By the end of this chapter, you will understand what cost means in the context of classification problems, how to adjust model parameters to account for such costs, and how to prioritize minority class predictions to mitigate the cost of misclassification. We will also look at a generic meta-algorithm that can make any algorithm cost-sensitive and a post-processing technique for adjusting <span class="No-Break">prediction thresholds.</span></p>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor153"/>Technical requirements</h1>
			<p>Similar to prior chapters, we will continue to utilize common libraries such as <strong class="source-inline">numpy</strong>, <strong class="source-inline">scikit-learn</strong>, <strong class="source-inline">xgboost</strong>, and <strong class="source-inline">imbalanced-learn</strong>. The code and notebooks for this chapter are available on GitHub at <a href="https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/main/chapter05">https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/main/chapter05</a>. You can open this GitHub notebook using Google Colab by clicking on the <strong class="bold">Open in Colab</strong> icon at the top of this chapter’s notebook or by launching it from <a href="https://colab.research.google.com">https://colab.research.google.com</a> using the GitHub URL of <span class="No-Break">the notebook<a id="_idTextAnchor154"/>.</span></p>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor155"/>The concept of Cost-Sensitive Learning</h1>
			<p><strong class="bold">Cost-Sensitive Learning</strong> (<strong class="bold">CSL</strong>) is a technique where the cost function of a machine learning <a id="_idIndexMarker326"/>model is changed to account for the imbalance in data. The key insight behind CSL is that we want our model’s cost function to reflect the relative importance of the <span class="No-Break">different classes.</span></p>
			<p>Let’s try to understand cost functions in machine learning and various types <span class="No-Break">of CSL<a id="_idTextAnchor156"/>.</span></p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor157"/>Costs and cost functions</h2>
			<p>A cost function estimates the difference between the actual outcome and the predicted outcome <a id="_idIndexMarker327"/>from a model. For example, the cost function of the logistic regression model is given by the log <span class="No-Break">loss </span><span class="No-Break">function:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">LogLoss</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">∑</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Function_v-normal">log</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">ˆ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Function_v-normal">log</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">ˆ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">i</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">)</span></span><span class="No-Break">)</span></p>
			<p>Here, <span class="_-----MathTools-_Math_Variable">N</span> is the total number of observations, <span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span> is the true label (0 or 1), and <span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">ˆ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span> is the probability value (between 0 and 1) predicted from <span class="No-Break">the model.</span></p>
			<p>One type of cost is called the cost of misclassification errors [1] – that is, the cost of predicting the majority class instead of the minority class or <span class="No-Break">vice versa.</span></p>
			<p>In practice, there can be other types of costs that we may incur, such as <span class="No-Break">the following:</span></p>
			<ul>
				<li>Cost of labeling <span class="No-Break">the dataset</span></li>
				<li>Cost of training or evaluating <span class="No-Break">the model</span></li>
				<li>Cost of training <span class="No-Break">data collection</span></li>
			</ul>
			<p>Let’s consider the <span class="No-Break">confusion matrix:</span></p>
			<table id="table001-5" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Predicted Negative</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Predicted Positive</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Actual Negative</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">True Negative</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">False Positive</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Actual Positive</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">False Negative</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">True Positive</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 5.1 – Confusion matrix for understanding the cost of classification errors</p>
			<p>Psychological <a id="_idIndexMarker328"/>studies have suggested that loss hurts twice as much as gain. Similarly, in machine learning, the “cost” captures whenever the model makes a mistake (False Positive and False Negative) and does not worry about when it’s right (True Positive and True Negative). This cost is the cost of <span class="No-Break">misclassification errors.</span></p>
			<p>Not all misclassifications are created equal. For instance, suppose we’re attempting to predict whether a patient has cancer. If our model incorrectly indicates that the patient has cancer (a false positive), this could lead to additional testing. However, if our model incorrectly suggests that the patient is cancer-free (a false negative), the consequences could be far more severe as the disease could progress undiagnosed. Therefore, a false negative is significantly more detrimental than a false positive. Our cost function should take this discrepancy <span class="No-Break">into account.</span></p>
			<p>Unfortunately, most models treat the majority and minority classes equally by default. However, modern ML frameworks such as <strong class="source-inline">scikit-learn</strong>, Keras/TensorFlow, and PyTorch provide a way to weigh the various classes differently across a variety of <span class="No-Break">learning algorithms.</span><a id="_idTextAnchor158"/></p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor159"/>Types of cost-sensitive learning</h2>
			<p>There are two major types of CSL approaches, namely weighting and meta-learning. In weighting approaches, we update the cost function of the machine learning model to reflect the <a id="_idIndexMarker329"/>importance of the different classes. In meta-learning, we can make the model cost-sensitive without changing its <span class="No-Break">cost function.</span></p>
			<p>In MetaCost, a type of meta-learning technique, for example, we alter the labels of training instances to minimize expected misclassification costs. Similarly, in the threshold adjustment method, we determine a probability threshold that minimizes total misclassification costs for predictions. <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.1</em> categorizes these methods at a high <span class="No-Break">level [2][3]:</span></p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B17259_05_01.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – Categorization of cost-sensitive learning methods<a id="_idTextAnchor160"/></p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor161"/>Difference between CSL and resampling</h2>
			<p>The key difference between previously discussed data-level techniques and CSL is that the data-level techniques adjust the frequency of the different error types, but they treat all <a id="_idIndexMarker330"/>misclassification errors the same. In certain cases, as we encountered earlier, the cost of misclassifying observations <a id="_idIndexMarker331"/>of different classes is not the same. For example, in cancer detection, the cost of misclassifying a patient who has cancer as healthy (False Negative) is much higher, as the patient is at high risk if not detected or treated early. Similarly, misclassifying a fraudulent booking as non-fraudulent can cost more money than wrongly classifying a legitimate transaction as fraud. Why? Because in the latter case, we can just call and verify with the user the legitimacy of the transaction. By applying resampling techniques such as upsampling or downsampling, we are implicitly changing the cost of different types of errors. So, CSL and resampling techniques can be considered to have an equivalent effect on the model at the end of <span class="No-Break">the day.</span></p>
			<p>However, resampling <a id="_idIndexMarker332"/>techniques may be <a id="_idIndexMarker333"/>problematic in certain cases, as we will discuss in the next section. In such cases, CSL can be <span class="No-Break">more practical:</span></p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B17259_05_02.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – Comic re-emphasizing the idea of misclassification err<a id="_idTextAnchor162"/>ors</p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor163"/>Problems with rebalancing techniques</h2>
			<p>In the previous chapters, we briefly touched on why in some cases, we would prefer not to apply <a id="_idIndexMarker334"/>any data sampling techniques. This could be because of the <span class="No-Break">following reasons:</span></p>
			<ul>
				<li>We already have too much training data, and it might be quite expensive to deal with more data, or the training time can increase by many folds due to having more <span class="No-Break">training data.</span></li>
				<li>Sometimes, we may not get the best results using sampling or data rebalancing techniques because of the dataset we <span class="No-Break">are using.</span></li>
				<li>An additional consideration is that upon rebalancing the dataset, our model’s predictive scores may become miscalibrated, necessitating a recalibration process. We will cover this topic in <a href="B17259_10.xhtml#_idTextAnchor279"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, <em class="italic">Model Calibration</em>, where we will learn about various model <span class="No-Break">calibration techniques.</span></li>
				<li>Rebalancing techniques can lead to model overfitting or underfitting issues. Overfitting can especially happen when using oversampling since they produce repeated <a id="_idIndexMarker335"/>or similar training examples. Similarly, the model may be underfitted when using undersampling because the model did not get trained on the data thrown away <span class="No-Break">during undersampling.</span></li>
			</ul>
			<p>Next, let’s try to understand what costs <span class="No-Break">really <a id="_idTextAnchor164"/>mean.</span></p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor165"/>Understanding costs in practice</h1>
			<p>We need to understand the various types of costs involved while creating weights for different classes. These costs change on a case-by-case basis. Let’s discuss an example of cost calculations <a id="_idIndexMarker336"/>to understand what we should consider while thinking about <span class="No-Break">cost calcula<a id="_idTextAnchor166"/>tions.</span></p>
			<p>Let’s take the example of pediatric pneumonia. According to UNICEF, a child dies of pneumonia every 43 seconds [4]. Imagine we are creating a new test for pediatric pneumonia – how will we decide the cost of <span class="No-Break">different errors?</span></p>
			<p>Let’s review the confusion matrix from <em class="italic">Table 5.1</em>. There will usually be no extra cost for True Negatives and True Positives. But using a False Negative – that is, when a child has pneumonia and predicting the child to be healthy – will have a very high cost. On the flip side, when a healthy child is predicted as being affected by pneumonia, there will be a cost associated with the troubles the family of the child may have to go through, but there will be much less cost than in the previous case. Furthermore, the cost of misclassification can vary depending on the child’s age. For example, younger kids will be at a higher risk than older kids. Thus, we will aim to penalize the model more if it makes an error in the case of <span class="No-Break">younger kids.</span></p>
			<p>The cost can vary depending on the duration of the symptoms. Consider it this way: if we make an error and misdiagnose a child who has only had flu symptoms for a day, it’s not ideal, but it’s not disastrous. However, if that child has been enduring flu symptoms for 2 weeks, that’s a different scenario. That mistake will cost us <span class="No-Break">significantly more.</span></p>
			<p>While we’ve discussed real-world problems so far, this chapter will pivot to utilize a synthetic dataset. This approach is intended to reinforce concepts and methods in a controlled <a id="_idIndexMarker337"/>environment, thus enhancing the <span class="No-Break">learning process:</span></p>
			<pre class="source-code">
X, y = make_classification(
    n_samples=50000, n_features=2, n_redundant=0, class_sep=2,\
    weights=[0.99], random_state=1, n_clusters_per_class=1)
X_train, X_test, y_train, y_test = train_test_split(X, y,\
    test_size = 0.2, random_state = 0, stratify=y)
print('y_train: ', Counter(y_train))
print('y_test: ', Counter(y_test))
plot_dataset(X_train, y_train)</pre>			<p>The <strong class="source-inline">make_classification</strong> function produces some overlapping points that we cleaned up. To keep things simple, we’ve omitted that cleanup code here. You can refer to the full notebook <span class="No-Break">on GitHub.</span></p>
			<p>The preceding code produces the following output and scatter plot (<span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">):</span></p>
			<pre class="source-code">
y_train:  Counter({0: 39404, 1: 596})
y_test:  Counter({0: 9851, 1: 149})</pre>			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B17259_05_03.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – Scatter plot showing the training dataset’s distribution</p>
			<p>We’ll dive <a id="_idIndexMarker338"/>into how to apply CSL to logistic regression <span class="No-Break">model<a id="_idTextAnchor167"/>s next.</span></p>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor168"/>Cost-Sensitive Learning for logistic regression</h1>
			<p>Logistic regression is a simple classification algorithm. We train a model as a linear combination <a id="_idIndexMarker339"/>of the features. Then, we pass the result of that linear combination into a sigmoid function to predict the class probabilities for <span class="No-Break">different classes.</span></p>
			<p>The <strong class="source-inline">sigmoid</strong> function (also called a <strong class="source-inline">logit</strong> function) is a mathematical tool capable of converting any real number into a value between 0 and 1. This value can be interpreted as a <span class="No-Break">probability estimate:</span></p>
			<pre class="source-code">
import numpy as np
def sigmoid(x):
     s = 1/(1+np.exp(-x))
     return s</pre>			<p>The graph of the sigmoid function has an S-shaped curve, and it appears <span class="No-Break">like this:</span></p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/B17259_05_04.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4 – Sigmoid function</p>
			<p>The class with the highest predicted probability is taken as the prediction for a <span class="No-Break">given sample.</span></p>
			<p>Let’s say we have an email to be classified as spam or non-spam, and our logistic regression model outputs the probabilities of 0.25 for non-spam and 0.75 for spam. Here, the class <a id="_idIndexMarker340"/>with the highest predicted probability is “spam” (1) since 0.75 is greater than 0.25. Therefore, the model would predict that this email is spam (<span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="image/B17259_05_05.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5 – Higher class probability determining the class for binary classification</p>
			<p>For two-class classification, we just predict the probability of one class. The probability of the other class is one minus the probability of the <span class="No-Break">first class.</span></p>
			<p>The logistic regression model is trained using a loss function. The loss function for one example from a dataset with two classes would look <span class="No-Break">like this:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">cost</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">log</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">classProbability</span><span class="_-----MathTools-_Math_Base">) </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> (</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">log</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">classProbability</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">)</span></span></p>
			<p>For true positives and true negatives, this loss will be very low. For a false positive, <span class="_-----MathTools-_Math_Variable">y</span>, the actual value would be 0; therefore, the first term will be 0, but the second term will be very high as the class probability approaches 1, and the term will approach negative infinity (since, <span class="_-----MathTools-_Math_Variable">log</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Base">) </span><span class="_-----MathTools-_Math_Operator">→</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol">∞</span>). Since there is a negative sign at the front, the cost will approach positive infinity. A similar analysis can be done for the false negative case. One part of the cost can be seen as the false positive part, and another part of the cost can be seen as the false <span class="No-Break">negative part:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">cost</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">falsePositiveCost</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">falseNegativeCost</span></span></p>
			<p>As discussed earlier, we don’t want to weigh the two types of costs equally. So, all we do is add weights, <span class="_-----MathTools-_Math_Variable">W</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FP</span> and <span class="_-----MathTools-_Math_Variable">W</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FN</span>, for the <span class="No-Break">respective </span><span class="No-Break">costs:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">cost</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">W</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FP</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">falsePositiveCost</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">W</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FN</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">falseNegativeCost</span></span></p>
			<p>This is the <a id="_idIndexMarker341"/>crux of CSL with logistic regression. To get the overall costs of the model, we take the average cost across all the <span class="No-Break">data points:</span></p>
			<pre class="source-code">
lr = LogisticRegression(random_state=0, max_iter=150).fit(
    X_train, y_train)
plot_decision_boundary(X_train, y_train, lr, 'LogisticRegression')
plt.show()
PrecisionRecallDisplay.from_estimator(
    lr, X_test, y_test, ax = plt.gca(),name = "LogisticRegression")</pre>			<p>When all <a id="_idIndexMarker342"/>errors are equally costly, the model’s decision boundary and the model’s <strong class="bold">Precision-Recall</strong> (<strong class="bold">PR</strong>) curve will look <span class="No-Break">like this:</span></p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B17259_05_06.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.6 – The decision boundary (left) and PR curve (right) of the baseline regression model</p>
			<pre class="source-code">
compute_scores(lr, X_test, y<a id="_idTextAnchor169"/>_test)</pre>			<p>The previous code outputs the following F2 score, precision, and <span class="No-Break">recall values:</span></p>
			<pre class="source-code">
f2-score: 0.921 precision: 0.926 recall: 0.919</pre>			<p>In this chapter, we will use the F2 score as our primary metric. What is the F2 score? In <a href="B17259_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Introduction to Data Imbalance in Machine Learning</em>, we studied the F-beta score. The F2 score is the F-beta score with beta=2, while the F1 score is the F-beta score with beta=1. It’s useful when recall is more important than precision – that is, false negatives are more costly (important) than <span class="No-Break">false </span><span class="No-Break">positives:</span></p>
			<p class="list-inset"><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">β</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">β</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">×</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">precision</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">×</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">recall</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">____________________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">β</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">×</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">precision</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">recall</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">5</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">×</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">precision</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">×</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">recall</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">________________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">4</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">×</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">precision</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">recall</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Space"> </span></p>
			<p><strong class="source-inline">LogisticRegression</strong> from the <strong class="source-inline">scikit-learn</strong> library provides a <strong class="source-inline">class_weight</strong> parameter. When the value of this parameter is set to “balanced,” the weight of <a id="_idIndexMarker343"/>each class is automatically computed by the <span class="No-Break">following formula:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">weightOfClass</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">totalNumberOfSamples</span><span class="_-----MathTools-_Math_Variable">   </span><span class="_-----MathTools-_Math_Base">________________________________</span><span class="_-----MathTools-_Math_Base">   </span><span class="_-----MathTools-_Math_Variable">numberOfClasses</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">numberOfSamplesPerClass</span><span class="_-----MathTools-_Math_Variable"> </span></p>
			<p>For example, we have 100 examples in the dataset – 80 in class 0 and 20 in class 1. The weights of each class are computed <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Weight for class 0 = 100/(2*80) = <span class="No-Break">0.625</span></li>
				<li>Weight for class 1 = 100/(2*20) = <span class="No-Break">2.5</span></li>
			</ul>
			<p>Given that the number of class 0 examples is four times that of class 1, the weight of class 1 is 2.5, which is four times the weight of class 0 – that is, 0.625. This makes sense since we would want to give more weight to class 1, which is smaller <span class="No-Break">in number.</span></p>
			<p>We can mention <strong class="source-inline">class_weight</strong> as a dictionary <span class="No-Break">as well:</span></p>
			<pre class="source-code">
LogisticRegression(class_weight={0: 0.5, 1:0.5})</pre>			<p>Let’s try to use the <strong class="source-inline">class_weight</strong> parameter in the <span class="No-Break"><strong class="source-inline">LogisticRegression</strong></span><span class="No-Break"> function:</span></p>
			<pre class="source-code">
lr_weighted = LogisticRegression(class_weight='balanced', \
    random_state=0, max_iter=150).fit(X_train, y_train)
plot_decision_boundary(X_train, y_train, lr_weighted, \
    'LogisticRegression')
plt.show()
PrecisionRecallDisplay.from_estimator(lr_weighted, X_test,\
    y_test, ax = plt.gca(),name = "LogisticRegressionWeighted")</pre>			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B17259_05_07.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.7 – The decision boundary (left) and PR curve (right) of the “balanced” class-weighted logistic regression model</p>
			<p>Let’s calculate the F2 score, precision, and <span class="No-Break">recall scores:</span></p>
			<pre class="source-code">
compute_scores(lr_weighted, X_test, y_test)</pre>			<p>The scores of the “balanced” class-weighted logistic regression model are <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
f2-score: 0.873 precision: 0.587 recall: 0.993</pre>			<p>Upon analyzing the results, we can see a decision boundary that correctly classifies most of the <a id="_idIndexMarker344"/>positive class examples. The precision comes down while the recall goes up. The decline in the F2 score can be attributed to changes in the recall and precision values. The model exhibits an improvement in recall, indicating its enhanced ability to correctly identify all positive class examples. However, this advancement results in a simultaneous drop in precision, suggesting an increased rate of mistakes made on the negative class examples (which we don’t really care about <span class="No-Break">as much!).</span></p>
			<p>Let’s try to tune the <strong class="source-inline">class_weight</strong> parameter using a grid search that optimizes our F2 score. We can always try to optimize any other objective, such as average precision, precision, or recall, and so on. The <strong class="source-inline">np.linspace(0.05, 0.95, 20)</strong> function is a <strong class="source-inline">numpy</strong> function <a id="_idIndexMarker345"/>that generates an array of 20 evenly spaced numbers between 0.05 <span class="No-Break">and 0.95:</span></p>
			<pre class="source-code">
from sklearn.metrics import make_scorer, fbeta_score
def f2_func(y_true, y_pred):
    f2_score = fbeta_score(y_true, y_pred, beta=2.)
    return f2_score
def f2_scorer():
    return make_scorer(f2_func)
# Define the parameter grid
param_grid = {
    'class_weight': [
        {0: x, 1: 1.0-x} for x in np.linspace(0.05, 0.95, 20)]
}
# Instantiate the grid search model
grid_search =GridSearchCV(
    LogisticRegression(),param_grid,\
    cv=3, scoring=f2_scorer(), n_jobs=-1
)
# Fit the grid search to the data
grid_search.fit(X_train, y_train)
# Get the best parameters
best_params = grid_search.best_params_
best_params</pre>			<p>This produces the <span class="No-Break">following output:</span></p>
			<pre class="source-code">
{'class_weight': {0: 0.14473684210526316, 1: 0.8552631578947368}}</pre>			<p>Our standard metrics are <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
f2-score: 0.930 precision: 0.892 recall: 0.940</pre>			<p>After incorporating these class weights, our decision boundary attempts to strike a better balance between misclassifying positive and negative class examples, as illustrated in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.8</em>. This results in a superior F2 score of 0.93, increasing the precision <a id="_idIndexMarker346"/>value while maintaining a <span class="No-Break">modest recall:</span></p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="image/B17259_05_08.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.8 – The decision boundary (left) and PR curve (right) of the class-weighted logistic regression model</p>
			<p class="callout-heading">🚀 Cost-sensitive learning in production at Microsoft</p>
			<p class="callout">In a practical <a id="_idIndexMarker347"/>application at Microsoft, the primary objective was to improve the <strong class="bold">Click-Through Rate</strong> (<strong class="bold">CTR</strong>) prediction for Bing ads [5]. Achieving accurate CTR prediction is vital for optimizing both user experience and revenue streams. A marginal improvement of just 0.1% in prediction accuracy has the potential to elevate profits by hundreds of millions of dollars. Through rigorous testing, an ensemble <a id="_idIndexMarker348"/>model that combines <strong class="bold">Neural Networks</strong> (<strong class="bold">NNs</strong>) and <strong class="bold">Gradient-Boosted Decision Trees</strong> (<strong class="bold">GBDTs</strong>) emerged as the most <span class="No-Break">effective </span><span class="No-Break"><a id="_idIndexMarker349"/></span><span class="No-Break">solution.</span></p>
			<p class="callout">For the training dataset, 56 million samples were randomly chosen from a month’s log data, each containing hundreds of statistical features. To reduce training expenses, non-click cases were <strong class="bold">downsampled</strong> by 50% and assigned a <strong class="bold">class weight</strong> of 2 to maintain the original distribution. Model performance was then assessed using a test dataset of 40 million samples randomly drawn from the subsequent week’s logs. Instead of recalibrating the model, class weighting was used to maintain the average CTR <span class="No-Break">after downsampling.</span></p>
			<p>In the <a id="_idIndexMarker350"/>next section, we will discuss how to do CSL with <span class="No-Break">de<a id="_idTextAnchor170"/>cision trees.</span></p>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor171"/>Cost-Sensitive Learning for decision trees</h1>
			<p>Decision trees are binary trees that use conditional decision-making to predict the class of the samples. Every tree node represents a set of samples corresponding to a chain of conditional <a id="_idIndexMarker351"/>statements based on the features. We divide the node into two children based on a feature and a threshold value. Imagine a set of students with height, weight, age, class, and location. We can divide the set into two parts according to the features of age and with a threshold of 8. Now, all the students with ages less than 8 will go into the left child, and all those with ages greater than or equal to 8 will go into the <span class="No-Break">right child.</span></p>
			<p>This way, we can create a tree by successively choosing features and threshold values. Every leaf node of the tree will contain nodes from only one <span class="No-Break">class, respectively.</span></p>
			<p>A question often arises during the construction of a decision tree: “Which feature and threshold pair should be selected to partition the set of samples at a given node?” The answer is straightforward: we opt for the pair that produces the most uniform (or homogeneous) subsets of data. Ideally, the two resulting subsets – referred to as the left and right children – should each contain elements predominantly from a <span class="No-Break">single class.</span></p>
			<p>The degree to which the nodes have a mixture of samples from different classes is known as the <strong class="bold">impurity</strong> of the <a id="_idIndexMarker352"/>node, which can be considered to be a measure of loss for decision trees. The more the impurity, the more heterogeneous the set of samples. Here are the two most common ways of calculating <span class="No-Break">the impurity:</span></p>
			<ul>
				<li><span class="No-Break">Gini coefficient</span></li>
				<li><span class="No-Break">Entropy</span></li>
			</ul>
			<p>Let’s look at the formula for the Gini coefficient and entropy for two classes, <span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">and</span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">c</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">2</span></span><span class="No-Break">:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">Gini</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space">  </span><span class="_-----MathTools-_Math_Variable">Proportion</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">Proportion</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">c</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">2</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">2</span></span></p>
			<p>We will get <span class="No-Break">the following:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">Entropy</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">Proportion</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">log</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">Proportion</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">c</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">1</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">)</span></span></p>
			<p><span class="_-----MathTools-_Math_Space">                                </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">Proportion</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">log</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">Proportion</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">c</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">2</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">)</span></span></p>
			<p>To do CSL with decision trees, we just multiply the class weights with the terms for each of the classes in the calculation of the Gini and entropy. If the weights for the two classes are <span class="_-----MathTools-_Math_Variable">W</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span>and <span class="_-----MathTools-_Math_Variable">W</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span>, Gini and entropy will look <span class="No-Break">as follows</span><span class="No-Break">:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">Gini</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">W</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Proportion</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">W</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Proportion</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">c</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">2</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">2</span></span></p>
			<p><span class="_-----MathTools-_Math_Variable">Entropy</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">W</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Proportion</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">log</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">(</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">Proportion</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">c</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">1</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">)</span></span></p>
			<p><span class="_-----MathTools-_Math_Space">                                </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">W</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Proportion</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">log</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">(</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">Proportion</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">c</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">2</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">)</span></span></p>
			<p>Now, the model prioritizes the class with a higher weight over the class with a lower weight. If we <a id="_idIndexMarker353"/>give more weight to the minority class, the model will make the decision that will prioritize nodes with homogeneous minority <span class="No-Break">class samples.</span></p>
			<p>In this section, we got some idea of how class weights can be accommodated into the loss function of decision trees to account for the misclassification error. In the next section, we will see how <strong class="source-inline">scikit-learn</strong> simplifies this process by integrating it into the model creation API, eliminating the need for us to manually adjust t<a id="_idTextAnchor172"/>he <span class="No-Break">loss function.</span></p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor173"/>Cost-Sensitive Learning using scikit-learn and XGBoost models</h1>
			<p><strong class="source-inline">scikit-learn</strong> provides a <strong class="source-inline">class_weight</strong> hyperparameter to adjust the weights of various <a id="_idIndexMarker354"/>classes for most models. This <a id="_idIndexMarker355"/>parameter can be specified in various ways for different learning algorithms in <strong class="source-inline">scikit-learn</strong>. However, the main idea is that this parameter specifies the weights to use for each class in the loss calculation formula. For example, this parameter specifies the values of <span class="_-----MathTools-_Math_Variable">weigh</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FP</span> and <span class="_-----MathTools-_Math_Variable">weight</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FN</span> mentioned previously for <span class="No-Break">logistic regression.</span></p>
			<p>Similar to the <strong class="source-inline">LogisticRegression</strong> function, for <strong class="source-inline">DecisionTreeClassifier</strong>, we could use <strong class="source-inline">DecisionTreeClassifier(class_weight='balanced')</strong> or <strong class="source-inline">DecisionTreeClassifier(class_weight={0: 0.5, </strong><span class="No-Break"><strong class="source-inline">1: 0.5})</strong></span><span class="No-Break">.</span></p>
			<p>Regarding SVM, it can even be extended to multi-class classification by specifying a weight value for each <span class="No-Break">class label:</span></p>
			<pre class="source-code">
svm.SVC(class_weight= {-1: 1.0, 0: 1.0, 1: 1.0})</pre>			<p>The general guidance about coming up with the <strong class="source-inline">class_weight</strong> values is to use the inverse of the ratio of the majority class to the minority class. We can find even more optimal <strong class="source-inline">class_weight</strong> values by performing hyperparameter tuning using the GridSearch algorithm (use the <strong class="source-inline">GridSearchCV</strong> function <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">scikit-learn</strong></span><span class="No-Break">).</span></p>
			<p>Similarly, XGBoost has the <strong class="source-inline">scale_pos_weight</strong> parameter to control the balance of positive and <span class="No-Break">negative weights:</span></p>
			<pre class="source-code">
XGBClassifier(scale_pos_weight)</pre>			<p>The default value of <strong class="source-inline">scale_pos_weight</strong> is 1. A recommended <strong class="source-inline">scale_pos_weight</strong> value is <strong class="source-inline">sum(negative_instances)/sum(positive_instances)</strong>, which <a id="_idIndexMarker356"/>can be computed as <strong class="source-inline">float(np.sum(label == 0)) / </strong><span class="No-Break"><strong class="source-inline">np.sum(label==1)</strong></span><span class="No-Break">.</span></p>
			<p>XGBoost <a id="_idIndexMarker357"/>has a few other parameters, such as <strong class="source-inline">max_delta_step</strong> and <strong class="source-inline">min_child_weight</strong>, that can be tuned for imbalanced datasets. During the optimization process, <strong class="source-inline">max_delta_step</strong> determines the step size of updates, affecting learning speed and stability. <strong class="source-inline">min_child_weight</strong> controls overfitting and enhances generalization by influencing the size of leaf nodes in the decision tree. When dealing with imbalanced data scenarios, adjusting these parameters can strategically improve <span class="No-Break">algorithm performance.</span></p>
			<p>First, let’s use <strong class="source-inline">DecisionTreeClassifier</strong> to solve our <span class="No-Break">classification problem:</span></p>
			<pre class="source-code">
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import PrecisionRecallDisplay
dt_clf = DecisionTreeClassifier(random_state=0, max_depth=6).fit(
    X_train, y_train)
plot_decision_boundary(X,y,dt_clf,'DecisionTreeClassifier')
plt.show()
PrecisionRecallDisplay.from_estimator(
    dt_clf, X_test, y_test, ax = plt.gca(),\
    name = "DecisionTreeClassifier")
print(classification_report_imbalanced(
    y_test,\
    dt_clf.predict(X_test), \
    target_names=['class 0', 'class 1']
    )
)
computescores(dt_clf, X_test, y_test)</pre>			<p>The output <a id="_idIndexMarker358"/>decision boundary is more <a id="_idIndexMarker359"/>complex than that of logistic regression (<span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.9</em>), separating the two classes better and giving an F2 score <span class="No-Break">of 0.932:</span></p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/B17259_05_09.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.9 – The decision boundary (left) and PR curve (right) of the decision tree classifier model</p>
			<p>We have reproduced the decision boundary and PR curve of the logistic regression model for comparison in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.10</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="image/B17259_05_10.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.10 – The decision boundary (left) and PR curve (right) of logistic regression (for comparison)</p>
			<p>Our <a id="_idIndexMarker360"/>standard metrics for the decision <a id="_idIndexMarker361"/>tree classifier are <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
f2-score: 0.932 precision: 0.892 recall: 0.94</pre>			<p>Next, let’s use the <span class="No-Break"><strong class="source-inline">class_weight='balanced'</strong></span><span class="No-Break"> parameter:</span></p>
			<pre class="source-code">
dt_clf_tuned = DecisionTreeClassifier(
    class_weight = 'balanced', random_state=0, max_depth=6
).fit(X_train, y_train)</pre>			<p>After utilizing the code from before to plot the decision boundary, the PR curve, and compute the scores, the outputs are <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/B17259_05_11.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.11 – The decision boundary (left) and PR curve (right) of the decision tree classifier model</p>
			<pre class="source-code">
f2-score: 0.934 precision: 0.770 recall: 0.987</pre>			<p>The tuned <a id="_idIndexMarker362"/>weights improve the F2 score and <span class="No-Break">recall values.</span></p>
			<p>Popular <a id="_idIndexMarker363"/>frameworks such as <strong class="source-inline">scikit-learn</strong> also let us specify <strong class="source-inline">sample_weight</strong> as a list of weights for each observation in the dataset. The <strong class="source-inline">sample_weight</strong> and <strong class="source-inline">class_weight</strong> parameters can be quite confusing, and their purpose may not be very clear from their documentation on when to use what. The following table clarifies the difference between <span class="No-Break">the two:</span></p>
			<table id="table002-3" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">sample_weight</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">class_weight</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Purpose</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Used to specify weights for <span class="No-Break">individual examples.</span></p>
							<p>Can be useful when some examples are more important than others, regardless of <span class="No-Break">their class.</span></p>
							<p>When some data is more trustworthy (say labeled using in-house human labelers), it can receive a <span class="No-Break">higher weight.</span></p>
							<p>Can be useful when you don’t have equal confidence in the samples in <span class="No-Break">your batch.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Used to correct <span class="No-Break">class imbalance.</span></p>
							<p>Should be used when the importance of examples depends on <span class="No-Break">their class.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Usage</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Can be used in training as well <span class="No-Break">as testing.</span></p>
							<p>Especially useful when comparing multiple models on different test sets with metrics such as AUC, where it’s often desirable to balance the <span class="No-Break">test set:</span></p>
							<p><span class="No-Break"><strong class="source-inline">sklearn.metrics.confusion_matrix(…, sample_weight)</strong></span></p>
							<p><span class="No-Break"><strong class="source-inline">sklearn.linear_model</strong></span></p>
							<p><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">LogisticRegression()</strong></span></p>
							<p><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">score(…,sample_weight)</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Mainly used during training to guide <span class="No-Break">the training.</span></p>
							<p>Accounts for misclassification errors because certain classes are more important <span class="No-Break">than others:</span></p>
							<p><span class="No-Break"><strong class="source-inline">sklearn.linear_model</strong></span></p>
							<p><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">LogisticRegression(</strong></span></p>
							<p><span class="No-Break"><strong class="source-inline">class_weight)</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Effect of setting the value to 0 during </strong><span class="No-Break"><strong class="bold">model training</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Model will not take into account the examples for which <strong class="source-inline">samples_weight=0</strong> (irrespective of the <span class="No-Break">example’s class).</span></p>
						</td>
						<td class="No-Table-Style">
							<p>The model will not consider any example belonging to the class for which <strong class="source-inline">class_weight = 0</strong>. Also, the model will never predict <span class="No-Break">that class.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Use </strong><span class="No-Break"><strong class="bold">case example</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>When predicting customer churn, if losing certain customers would have a larger impact on business because they tend to purchase more often or spend more, we would want to give these customers a higher weight <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">sample_weight</strong></span><span class="No-Break">.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>If we have a dataset where one class significantly outnumbers the other(s), using <strong class="source-inline">class_weight</strong> can help the model pay more attention to the <span class="No-Break">underrepresented class(es).</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 5.2 – sample_weight versus class_weight in the scikit-learn library</p>
			<p class="callout-heading">Warning</p>
			<p class="callout">If we use <strong class="source-inline">sample_weight</strong> along with <strong class="source-inline">class_weight</strong>, both will be multiplied, and we will see the effect of both parameters. The two can still be used together to balance class importance and individual instance importance with their <span class="No-Break">intended purposes.</span></p>
			<p>Using <strong class="source-inline">numpy</strong> makes it easier to create the list of weight values that are required by <strong class="source-inline">sample_weight</strong>: <strong class="source-inline">sample_weight = np.where(label==1, 80, 20)</strong>. However, <strong class="source-inline">scikit-learn</strong> has a function called <strong class="source-inline">sklearn.utils.class_weight.compute_sample_weight()</strong> that can be used to <a id="_idIndexMarker364"/>estimate the value of <strong class="source-inline">sample_weight</strong>  automatically <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">class_weight</strong></span><span class="No-Break">.</span></p>
			<p><strong class="source-inline">class_weight</strong> can also be a dict of values for each label or balanced. If we set it to balanced, class weights are determined by <strong class="source-inline">n_samples/(n_classes * </strong><span class="No-Break"><strong class="source-inline">np.bincount(y))</strong></span><span class="No-Break">.</span></p>
			<p>The returned <a id="_idIndexMarker365"/>value from <strong class="source-inline">class_weight</strong> is a dictionary: <strong class="source-inline">{class_label: weight}</strong> for each <span class="No-Break"><strong class="source-inline">class_label</strong></span><span class="No-Break"> value.</span></p>
			<p>Similarly, you can use <strong class="source-inline">sklearn.utils.class_weight.compute_sample_weight</strong> if you have to do <span class="No-Break">multi-label classification<a id="_idTextAnchor174"/>.</span></p>
			<p class="callout-heading">🚀 Cost-sensitive learning in production at Airbnb</p>
			<p class="callout">In a real-world application at Airbnb [6], the main problem to solve was improving the search and discoverability as well as personalization of their Experiences (handcrafted activities) platform. As the number of experiences grew, it became crucial to effectively rank these experiences to match user preferences and <span class="No-Break">improve bookings.</span></p>
			<p class="callout">Airbnb aimed to improve its search ranking to provide users with the most relevant and high-quality experiences. To promote the quality of their ranking model, they used sample weights (discussed in the previous section) in their <span class="No-Break">objective function.</span></p>
			<p class="callout">The data imbalance in terms of quality tiers was addressed by using sample weighting (discussed in the previous section) in the training data. High-quality experiences were given higher weights, and low-quality experiences were given lower weights in the objective function. This was done to promote high-quality experiences in the search rankings, and they successfully improved the ranking of high-quality experiences and reduced low-quality ones without affecting overall bookings, as confirmed by <span class="No-Break">A/B tests.</span></p>
			<p class="callout">Airbnb iteratively developed and tested its machine learning model, eventually integrating it into its production system to rank “Experiences” in real time. They went through multiple stages, from building a strong baseline to personalization and online scoring to handle various <span class="No-Break">business rules.</span></p>
			<p>In the <a id="_idIndexMarker366"/>next section, we will learn about a <a id="_idIndexMarker367"/>technique that can convert any model into its cost-sensitive version without us knowing about its loss function or the inner workings of <span class="No-Break">the model.</span></p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor175"/>MetaCost – making any classification model cost-sensitive</h1>
			<p>MetaCost was first introduced in a paper by Pedro Domingos [7] in 1999. MetaCost acts as a wrapper <a id="_idIndexMarker368"/>around machine learning algorithms that converts the underlying algorithm into a cost-sensitive version of itself. It treats the underlying algorithm as a black box and works best with unstable algorithms (defined below). When MetaCost was first proposed, CSL was in its early stages. Only a few algorithms, such as decision trees, had been converted into their cost-sensitive versions. For some models, creating a cost-sensitive version turned out to be easy while for others it was a non-trivial task. For algorithms where defining cost-sensitive versions of the model turned out to be difficult, people mostly relied upon data sampling techniques such as oversampling or undersampling. This was when Domingos came up with an approach for converting a large range of algorithms into their cost-sensitive versions. MetaCost can work for multi-class classification and with all types of <span class="No-Break">cost matrices.</span></p>
			<p class="callout-heading">Unstable algorithms</p>
			<p class="callout">An algorithm is called unstable [8] if a slight change in its initial conditions (for example, training <a id="_idIndexMarker369"/>data or initial weights) can create a big change in the model. Assume you are given a dataset of 1,000 items. A stable model such as a <strong class="bold">K-Nearest Neighbor</strong> (<strong class="bold">KNN</strong>) will not change much if you remove one item from the dataset. However, a model such as a decision tree might get completely restructured if you train it on 999 items instead of <span class="No-Break">1,000 items.</span></p>
			<p>Let’s delve into the mechanics of the MetaCost algorithm, as illustrated in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.12</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/B17259_05_12.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.12 – The MetaCost algorithm</p>
			<p>MetaCost works <a id="_idIndexMarker370"/>by combining the concept of bagging with a misclassification <span class="No-Break">cost matrix:</span></p>
			<ol>
				<li>First, we create multiple bootstrap samples of the <span class="No-Break">original data.</span></li>
				<li>We train one new copy of the given model for each bootstrap sample. So far, the process is the same as bagging. You can see the first two steps in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.12</em> on the left-hand side. First, we create bootstrap samples S1, S2, and S3 from the original data. Then, we train models L1, L2, and L3 on the samples (S1, S2, and <span class="No-Break">S3), respectively.</span></li>
				<li>Next, we send the original data, S, into the ensemble of L1, L2, <span class="No-Break">and L3.</span></li>
				<li>We multiply the misclassification costs obtained from the cost matrix with the class probabilities predicted by the ensemble to get the actual cost. This is shown on the right-hand side of <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.12</em></span><span class="No-Break">.</span></li>
				<li>Then, we relabel the data so that the new class labels minimize the <span class="No-Break">actual cost.</span></li>
				<li>Finally, we train a new copy of the model on the relabeled data. This copy of the model is used as the <span class="No-Break">final model.</span></li>
			</ol>
			<p>We can see the process of relabeling data using MetaCost in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.13</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/B17259_05_13.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.13 – Process of relabeling data using MetaCost</p>
			<p>On the left of <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.13</em>, we have the original data. Stars are the minority class examples and squares are the majority class examples. Here, all the samples inside the oval are predicted as stars, and all the samples outside it are predicted as squares. The oval on the left <a id="_idIndexMarker371"/>is drawn by assuming the same misclassification cost for all errors. In the center, we create a new class boundary based on the actual misclassification cost drawn as an elongated oval. Notice that all the stars are now classified correctly. Also, notice that some squares are now misclassified as stars. This is expected as the misclassification cost for the stars is much higher than that of squares. At this point, MetaCost relabels these misclassified squares as stars. Finally, MetaCost trains a model on the relabeled data. Because the majority class examples that are easily mistaken for the minority class have been relabeled as belonging to the minority class, the final model is less likely to mislabel instances of the <span class="No-Break">minority class.</span></p>
			<p>To save space, we have omitted the implementation of the MetaCost algorithm. You can find it in the GitHub repository for <span class="No-Break">this chapter.</span></p>
			<p>We will apply the algorithm to the logistic regression model. MetaCost uses a cost matrix, which is a hyperparameter. The values in the cost matrix correspond to the weight or cost of items in the confusion matrix (the transpose of the confusion matrix from <span class="No-Break"><em class="italic">Table 5.1</em></span><span class="No-Break">)</span><span class="No-Break">:</span></p>
			<p>C = <span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">TN</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FN</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FP</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">TP</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">)</span></span></p>
			<p>Let’s say we use a cost matrix with equal costs for false positives and false negatives (that is, an <span class="No-Break">identity matrix):</span></p>
			<pre class="source-code">
C = np.array([[0, 1], [1, 0]])</pre>			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.14</em> shows the <a id="_idIndexMarker372"/>decision boundary and metrics, which are very close to the ones from the logistic regression classifier (<span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.10</em></span><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="image/B17259_05_14.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.14 – The decision boundary (left) and PR curve (right) of the MetaCost variant of the logistic regression model with an identity cost matrix</p>
			<p>We can estimate the cost matrix based on the imbalance ratio of the <span class="No-Break">training data:</span></p>
			<pre class="source-code">
C = np.array([[0, 66], [1, 0]])</pre>			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.15</em> shows the output decision function and <span class="No-Break">PR curve:</span></p>
			<div>
				<div id="_idContainer093" class="IMG---Figure">
					<img src="image/B17259_05_15.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.15 – The decision boundary (left) and PR curve (right) of the MetaCost variant of the logistic regression model with a more optimal cost matrix</p>
			<p>Although the F2 score dropped compared to the baseline, the recall did <span class="No-Break">improve drastically.</span></p>
			<p>The various steps in the MetaCost algorithm, such as relabeling the whole training set, can be quite <a id="_idIndexMarker373"/>an expensive operation, and that might deter us from using this technique when our training dataset <span class="No-Break">is la<a id="_idTextAnchor176"/>rge.</span></p>
			<p class="callout-heading">Cost-sensitive ensemble techniques</p>
			<p class="callout">AdaCost [9], AdaUBoost [10], and AsymBoost [11] are cost-sensitive modifications of the AdaBoost model. AdaCost minimizes misclassification costs during iterative training. AdaUBoost handles imbalanced datasets by emphasizing the minority class. AsymBoost focuses on reducing the costliest misclassifications. They all adjust weights while considering <span class="No-Break">misclassification costs.</span></p>
			<p class="callout">The underlying principle behind these algorithms is that besides allocating high initial weights to instances where the cost of misclassification is large, the rule for updating weights should also consider costs. This means that the weights of expensive misclassifications should be increased while the weights of correct classifications should <span class="No-Break">be reduced.</span></p>
			<p>In the next section, we will learn about another cost-sensitive meta-learning technique, called <span class="No-Break">threshold adjustment.</span></p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor177"/>Threshold adjustment</h1>
			<p>The decision <a id="_idIndexMarker374"/>threshold is a very important concept to keep track of. By default, we have <span class="No-Break">the following:</span></p>
			<ul>
				<li>Prediction probability &gt;= 0.5 implies <span class="No-Break">Class 1</span></li>
				<li>Prediction probability &lt; 0.5 implies <span class="No-Break">Class 0</span></li>
			</ul>
			<p>However, the threshold is a powerful meta-parameter that we are free to adjust. <em class="italic">Table 5.3</em> shows predictions from a model versus the <span class="No-Break">true labels.</span></p>
			<p>If we use the default threshold of 0.5, the accuracy is 2/4 = 50%. If, on the other hand, the threshold chosen is 0.80, the accuracy is 100%. This shows how important the chosen threshold <span class="No-Break">can be:</span></p>
			<table id="table003-2" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Predicted Output</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">True Output</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">0.65</span></p>
						</td>
						<td class="No-Table-Style">
							<p>0</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">0.75</span></p>
						</td>
						<td class="No-Table-Style">
							<p>0</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">0.85</span></p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">0.95</span></p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 5.3 – A table showing the predicted output from a model versus the true output (labels)</p>
			<p>Most of the metrics, such as accuracy, precision, recall, and F1 score, are all <span class="No-Break">threshold-dependent metrics.</span></p>
			<p>On the <a id="_idIndexMarker375"/>other hand, metrics such as the ROC curve and the PR curve are threshold-independent, which means that these plots evaluate the performance of a model at all possible thresholds rather than a single, <span class="No-Break">fixed threshold.</span></p>
			<p>When dealing with machine learning metrics such as F1 or accuracy, it’s important to understand the role of the threshold value. These metrics, by default, utilize a threshold of 0.5. Therefore, a misconception arises, particularly among novice and intermediate machine learning practitioners, that these metrics are inevitably linked to this <span class="No-Break">particular threshold.</span></p>
			<p>However, this can lead to an inaccurate interpretation of the model’s performance, particularly in scenarios involving imbalanced datasets. The selection of the metric and the decision threshold are separate choices and should be treated as such. Establishing an appropriate threshold is a crucial step in the process, which should be considered independently of the <span class="No-Break">chosen metric.</span></p>
			<p>Furthermore, relying solely on the default threshold of 0.5 can be misleading. The threshold should be set based on the specific requirements of the project and the nature of the data. Therefore, it’s integral that machine learning practitioners understand the interplay between the threshold and the selected metric to accurately assess the performance of <span class="No-Break">their models.</span></p>
			<p>In binary classification, altering the threshold will easily change the threshold-dependent metrics such as accuracy, F1 score, TPR, or FPR. Many pieces of research [12][13] have mentioned the value of threshold adjustment, especially in the case when training data is imbalanced. A paper by Provost [14] states that using models without adjusting the <a id="_idIndexMarker376"/>output thresholds may be a critical mistake. Among deep learning domains, Buda et al. [15] show that using <strong class="bold">random oversampling</strong> (<strong class="bold">ROS</strong>) along with thresholding outperforms plain ROS on imbalanced datasets created from CIFAR and MNIST. Regardless of whether the data is imbalanced or not, choosing an optimal threshold can <a id="_idIndexMarker377"/>make a lot of difference in the performance of <span class="No-Break">the model.</span></p>
			<p>Many times, we would want to find the threshold that optimizes our threshold-dependent metric, say F1 score. Here, find the threshold at which the F1 score is the maximum (<span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.16</em></span><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer094" class="IMG---Figure">
					<img src="image/B17259_05_16.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.16 – A PR curve with the best threshold that finds the max F1 score (see the notebook in this chapter’s GitHub repository)</p>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.17</em> presents a plot that illustrates the impact of modifying the decision threshold on various classification metrics for an imbalanced dataset: <strong class="bold">True Positive Rate</strong> (<strong class="bold">TPR</strong> or recall), <strong class="bold">True Negative Rate</strong> (<strong class="bold">TNR</strong>), <strong class="bold">False Positive Rate</strong> (<strong class="bold">FPR</strong>), and precision. The model that was used was logistic regression without any class weighting or sensitivity to the minority class. For the full notebook, please refer to the GitHub repository for <span class="No-Break">this chapter:</span></p>
			<div>
				<div id="_idContainer095" class="IMG---Figure">
					<img src="image/B17259_05_17.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.17 – A plot of the different classification metrics (TPR, TNR, FPR, precision, F1 score, and accuracy) as a function of the decision threshold</p>
			<p>Here are <a id="_idIndexMarker378"/>some observations about <span class="No-Break">these plots:</span></p>
			<ul>
				<li><strong class="bold">Precision</strong>: If the threshold is increased, precision (<span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TP</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_________________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">Total</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">number</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">of</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">positive</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">predictions</span><span class="_-----MathTools-_Math_Space"> </span>) typically goes up as well. Why? Because as the threshold is increased, the total number of positive predictions would come down, and hence, as the denominator decreases, precision increases. Similarly, the opposite is true as well: if the threshold goes down, the precision goes <span class="No-Break">down too.</span></li>
				<li><strong class="bold">Recall</strong>: Let’s see the impact of threshold change on recall. The recall is defined as<span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TP</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">____________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">Total</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">number</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">of</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">positives</span><span class="_-----MathTools-_Math_Space">  </span>and the denominator is a constant value. As the threshold is lowered, TP may increase and would typically increase <span class="No-Break">the recall.</span></li>
				<li><strong class="bold">True Negative Rate</strong> (<strong class="bold">TNR</strong>): TNR measures the proportion of actual negatives that are correctly identified as such. In imbalanced datasets, where the negative class is the majority, a naive or poorly performing classifier might have a high TNR simply because it predicts the majority class for all or most instances. In such cases, the TNR could be <span class="No-Break">misleadingly high.</span></li>
				<li><strong class="bold">False Positive Rate</strong> (<strong class="bold">FPR</strong>): This is the rate at which negative instances are incorrectly classified as positive. In imbalanced datasets, a naive classifier that predicts everything as the majority (negative) class would have an FPR close <span class="No-Break">to 0.</span></li>
			</ul>
			<p>Usually, we have <a id="_idIndexMarker379"/>a trade-off between TPR and TNR that must be taken into account while selecting an optimal decision threshold, as shown in the plot in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.17</em></span><span class="No-Break">.</span></p>
			<p class="callout-heading">🚀 Cost-sensitive learning in production at Shopify</p>
			<p class="callout">In a real-world application at Shopify [16], the platform faced the challenge of categorizing products for millions of merchants selling a diverse array of items. Accurate product categorization was vital for functionalities such as enhanced search and discovery, as well as providing personalized marketing insights to merchants. Given the immense volume and variety of products, manual categorization was not feasible. Machine learning techniques were employed to automate the categorization process, adapting to the ever-expanding and diversifying product range. The dataset that was utilized was <a id="_idIndexMarker380"/>highly imbalanced, particularly due to the hierarchical structure of the <strong class="bold">Google Product Taxonomy</strong> (<strong class="bold">GPT</strong>) that Shopify employs. With over 5,500 categories, the GPT added complexity to an already <span class="No-Break">challenging problem.</span></p>
			<p class="callout">To address the issue of data imbalance, class weights were implemented. By assigning the class weights, the model could impose higher penalties for incorrect predictions in underrepresented classes, effectively mitigating the lack of data in those categories. The model was fine-tuned to strike a balance between hierarchical precision and recall. This fine-tuning was informed by specific business use cases and aimed at enhancing the merchant experience by minimizing negative interactions and friction. Manual adjustments were made to the confidence thresholds (this shows that threshold tuning is so relevant in the real world!) to ensure optimal performance in sensitive categories such as “Religious and Ceremonial.” Various metrics such as hierarchical accuracy, precision, recall, and F1 score were balanced to tailor the model to business requirements. The model is now actively used by multiple internal teams and partner ecosystems to develop derivative <span class="No-Break">data products.</span></p>
			<p>Next, we’ll look at various ways of tuning <span class="No-Break">these thresholds.</span></p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor178"/>Methods for threshold tuning</h2>
			<p>Most of the time, we aim to optimize specific business metrics or standard machine learning <a id="_idIndexMarker381"/>metrics, requiring us to select a threshold that maximizes the metric of interest. In literature, various methods for threshold tuning are discussed, such as setting a threshold equal to the priority probability of observing a positive example, using the ROC curve to optimize for high TPR and low FPR, or employing the PR curve to maximize the F1 score or F<span class="subscript">beta </span>score (see <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.18</em></span><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer096" class="IMG---Figure">
					<img src="image/B17259_05_18.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.18 – Popular ways of tuning the threshold</p>
			<p>We will discuss these methods one <span class="No-Break">by one.</span></p>
			<p>We will continue to use the same dataset we created earlier. The following code block fits a logistic regression model and obtains predicted probabilities for the <span class="No-Break">test set:</span></p>
			<pre class="source-code">
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred = lr.predict_proba(X_test)
y_pred = y_pred[:, 1]</pre>			<h3>Threshold tuning using the prior threshold</h3>
			<p>An obvious threshold that can be used is equal to the probability of the positive class in the training <a id="_idIndexMarker382"/>dataset [10]. Let’s implement <span class="No-Break">this idea:</span></p>
			<pre class="source-code">
num_pos, num_neg = Counter(y)[1], Counter(y)[0]
prior_threshold = num_pos /(num_pos + num_neg)
print('Prior threshold=%f'% prior_threshold)
# Find the closest threshold from thresholds from ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
min_threshold_index = np.absolute( \
    thresholds-prior_threshold).argmin()
print('Best threshold using prior threshold from ROC \
    function=%f'% thresholds[min_threshold_index])
print("TPR at threshold=%f" % tpr[min_threshold_index])
print("FPR at threshold=%f" % fpr[min_threshold_index])
print("TNR at threshold=%f" % (1-fpr[min_threshold_index]))</pre>			<p>This prints the <span class="No-Break">following threshold:</span></p>
			<pre class="source-code">
Prior threshold=0.014900
Best threshold using prior threshold from ROC function=0.014232
TPR value at the threshold=0.675676
FPR value at the threshold=0.147990
TNR value at the threshold=0.852010</pre>			<h3>Threshold tuning using the ROC curve</h3>
			<p>For the <a id="_idIndexMarker383"/>ROC curve, Youden’s J statistic [17] can be used to find the optimal threshold. Youden’s J statistic has roots in the clinical field and is a single statistic that captures the performance of a diagnostic test. In the context of binary classification, the statistic, J, is defined <span class="No-Break">as follows:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">J</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">Sensitivity</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">Specificity</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">TPR</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">TNR</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">TPR</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">FPR</span></span></p>
			<p>Its value can range from -1 (TPR=0 and TNR=0 – that is, always wrong results) to 1 (TPR=1 and FPR=0 – that is, perfect results). This is a common choice for selecting a threshold in an ROC analysis since it balances both sensitivity (TPR) and specificity (TNR). Please note that TNR = <span class="No-Break">1-FPR.</span></p>
			<p>The reason that maximizing Youden’s J is equivalent to choosing the optimal threshold is that it <a id="_idIndexMarker384"/>essentially finds the point on the ROC curve that is farthest from the line of no discrimination (the diagonal). This means that it selects a threshold that achieves a balance between TPR and FPR, which is often what we want in <span class="No-Break">a classifier.</span></p>
			<p>The “optimal” threshold can depend heavily on the cost of false positives versus false negatives in our specific application. The following code block identifies the optimal classification threshold using the Youden index, which is calculated from the <span class="No-Break">ROC curve:</span></p>
			<pre class="source-code">
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
youden_index = tpr - fpr
max_youden_index = np.argmax(youden_index)
best_thresh = thresholds[max_youden_index]
print('Best threshold using Youden index=%f'% best_thresh)
print('Max Youden index value=%f'% youden_index[max_youden_index])
print("TPR value at the threshold=%f" % tpr[max_youden_index])
print("FPR value at the threshold=%f" % fpr[max_youden_index])
print("TNR value at the threshold=%f" % (1-fpr[max_youden_index]))</pre>			<p>This outputs the <span class="No-Break">following values:</span></p>
			<pre class="source-code">
Best threshold using Youden index=0.098879
Max Youden index value=0.622143
TPR value at the threshold=0.635135
FPR value at the threshold=0.012992
TNR value at the threshold=0.987008</pre>			<p>Another threshold adjustment method that uses ROC curves that’s often used in literature is maximizing the geometric mean of TPR (also known as sensitivity) and TNR (also known <span class="No-Break">as specificity)</span><span class="No-Break">:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">G</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">mean</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">__________________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">Sensitivity</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">Specificity</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TPR</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">TNR</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">______________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">TPR</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FPR</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Space"> </span></p>
			<p>Maximizing the <a id="_idIndexMarker385"/>geometric mean is equivalent to finding a good balance between TPR and TNR. The following code block calculates the best threshold for classification using the G-mean metric, along with its corresponding TPR, FPR, and TNR values. We import <strong class="source-inline">roc_curve</strong> <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">sklearn.metrics</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
gmean = np.sqrt(tpr*(1-fpr))
max_gmean_index = np.argmax(gmean)
best_thresh = thresholds[max_gmean_index]
print('Best threshold using G-mean=%f'% (best_thresh))
print('Max G-mean value=%f'% (gmean[max_gmean_index]))
print("TPR value at the threshold=%f" % tpr[max_gmean_index])
print("FPR value at the threshold=%f" % fpr[max_gmean_index])
print("TNR value at the threshold=%f" % (1 - fpr[max_youden_index]))</pre>			<p>This <a id="_idIndexMarker386"/>outputs the following <span class="No-Break">optimal values:</span></p>
			<pre class="source-code">
Best threshold using G-mean=0.098879
Max G-mean value=0.791760
TPR value at the threshold=0.635135
FPR value at the threshold=0.012992
TNR value at the threshold=0.987008</pre>			<h3>Threshold tuning using the PR curve</h3>
			<p>As we discussed in <a href="B17259_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Introduction to Data Imbalance in Machine Learning</em>, the PR curve is generally preferred over ROC curves for imbalanced datasets when the positive <a id="_idIndexMarker387"/>class is more important than the negative class. As a reminder, the simple reason for this is that the PR curve ignores the true negatives, and hence, it can represent a stark difference between model performance when using imbalanced datasets in comparison to a balanced dataset. While ROC curves won’t change much as an imbalance in the data increases, they can be a preferred option if both classes are <span class="No-Break">equally important.</span></p>
			<p>We want the maximum possible values for both precision and recall, ideally both being 1. Thus, the point of optimality on a PR curve <span class="No-Break">is (1,1).</span></p>
			<p>When we move away from this point of optimality, both the precision and recall values decrease, and we are <span class="No-Break">less optimal.</span></p>
			<p>One measure that captures this trade-off between precision and recall is the F1 score. The F1 score is defined as the harmonic mean of the precision <span class="No-Break">and recall:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">Precision</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">Recall</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">/</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">Precision</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">Recall</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">)</span></span></p>
			<p>If we analyze this equation, we will see that the F1 score is highest (reaching its maximum at 1) when both precision and recall are 1, which is exactly the optimal point we defined on the <span class="No-Break">PR curve.</span></p>
			<p>Therefore, optimizing for the maximum F1 score would ensure that we are striving to maximize both precision and recall, effectively pushing us toward the optimal point on the <span class="No-Break">PR curve.</span></p>
			<p>Maximizing the F1 score is a common and effective method for determining the optimal threshold. The following code block calculates the best threshold using the F1 score metric derived from the <span class="No-Break">PR curve:</span></p>
			<pre class="source-code">
from numpy import argmax
from sklearn.metrics import precision_recall_curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
fscore = 2*precision*recall/(precision+recall)
max_fscore_idx = argmax(fscore)
print('max_fscore_idx==%d' % max_fscore_idx)
print('best threshold using PR curve=%f' % thresholds[max_fscore_idx])</pre>			<p>This <a id="_idIndexMarker388"/>outputs the following <span class="No-Break">optimal values:</span></p>
			<pre class="source-code">
max_fscore_idx==4950
best threshold using PR curve=0.258727
max(fscore)= 0.661290</pre>			<p>Let’s plot the PR curve with the optimal <span class="No-Break">threshold value:</span></p>
			<pre class="source-code">
pyplot.plot(recall, precision, marker='.', \
    label='precision vs recall for various thresholds')
result = pyplot.scatter(recall[max_fscore_idx], \
    precision[max_fscore_idx], \
    marker='x', color='red', \
    label='Best threshold with highest\
    f1-score')
plt.legend(handles=result.legend_elements()[0], \
    labels="legend", loc='upper center', \
    bbox_to_anchor=(1, 1))
pyplot.xlabel('recall')
pyplot.ylabel('precision')</pre>			<p>The <a id="_idIndexMarker389"/>PR curve looks <span class="No-Break">like this:</span></p>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="image/B17259_05_19.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.19 – The PR curve with the best F1 score threshold value</p>
			<h3>General threshold tuning</h3>
			<p>As a general method, we may have to optimize any metric, such as average precision, accuracy, and <a id="_idIndexMarker390"/>so on, or any other business metric. In such cases, we can write a function to optimize that metric directly. Let’s take the <a id="_idIndexMarker391"/>example of the <strong class="bold">Index of Union</strong> (<strong class="bold">IU</strong>) metric defined by I. Unal et al. in their research [18], where the metric is defined by the threshold value, <span class="_-----MathTools-_Math_Variable">c</span>, at which <span class="_-----MathTools-_Math_Variable">IU</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Base">)</span> <span class="No-Break">is minimized:</span></p>
			<p><span class="_-----MathTools-_Math_Variable">IU</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(|</span><span class="_-----MathTools-_Math_Variable">Sensitivity</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">ROC</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">AUC</span><span class="_-----MathTools-_Math_Base">|</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">|</span><span class="_-----MathTools-_Math_Variable">Specificity</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">ROC</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Operator">_</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">AUC</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">|)</span></span></p>
			<p>Here, <span class="_-----MathTools-_Math_Variable">Sensitivity</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Base">)</span> is the sensitivity at <span class="_-----MathTools-_Math_Variable">c</span>, <span class="_-----MathTools-_Math_Variable">Specificity</span> is the specificity at <span class="_-----MathTools-_Math_Variable">c</span>, and <span class="_-----MathTools-_Math_Variable">ROC</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">AUC</span> is the <strong class="bold">Area Under the Curve</strong> (<strong class="bold">AUC</strong>) of the <span class="No-Break">ROC plot.</span></p>
			<p>Let’s implement the IU metric, as defined here, as a custom metric to find the optimal threshold that <span class="No-Break">minimizes it:</span></p>
			<pre class="source-code">
from sklearn.metrics import f1_score, auc
def custom_metric(y_test, y_pred):
    fpr, tpr, thresholds = roc_curve(y_test, y_pred)
    sensitivity = tpr
    specificity = 1-fpr #same as tnr
    roc_auc = auc(fpr, tpr)
    index_of_union = abs(sensitivity-roc_auc) + \
        abs(specificity-roc_auc)
    return index_of_union
scores = custom_metric(y_test, y_pred)
min_score_idx = np.argmin(scores)
print('max_score_idx=%d' % min_score_idx)
print('best threshold=%f'% thresholds[min_score_idx])
print('minimum IU-value at the best threshold=%f' % \
    scores[min_score_idx])</pre>			<p>This produces <a id="_idIndexMarker392"/>the following <span class="No-Break">optimal values:</span></p>
			<pre class="source-code">
max_score_idx=34
best threshold=0.000042
minimum IU-value at the best threshold=0.112514</pre>			<p>This wraps up our discussion on classical modeling techniques. We are now ready to venture into studying data imbalance in the realm of deep learning. We’ll explore how the insights gained from the general techniques learned from previous chapters can be adapted to enhance our deep learning models when dealing with <span class="No-Break">imba<a id="_idTextAnchor179"/>lanced data.</span></p>
			<h1 id="_idParaDest-115"><a id="_idTextAnchor180"/>Summary</h1>
			<p>In this chapter, we delved into CSL, an alternative to oversampling and undersampling. Unlike data-level techniques that treat all misclassification errors equally, CSL adjusts the cost function of a model to account for the significance of different classes. It includes class weighting and <span class="No-Break">meta-learning techniques.</span></p>
			<p>Libraries such as <strong class="source-inline">scikit-learn</strong>, Keras/TensorFlow, and PyTorch support cost-sensitive learning. For instance, <strong class="source-inline">scikit-learn</strong> offers a <strong class="source-inline">class_weight</strong> hyperparameter to adjust class weights in loss calculation. XGBoost has a <strong class="source-inline">scale_pos_weight</strong> parameter for balancing positive and negative weights. MetaCost transforms any algorithm into its cost-sensitive version using bagging and a misclassification cost matrix. Additionally, threshold adjustment techniques can enhance metrics such as F1 score, precision, and recall by post-processing <span class="No-Break">model predictions.</span></p>
			<p>Experiments with various data sampling and CSL techniques can help determine the best approach. We’ll extend these concepts to deep learning models in <a href="B17259_08.xhtml#_idTextAnchor235"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Algorithm-Level Deep Learning Techniques</em>. This concludes our discussion of classical machine learning models, and we have graduated to move on to deep learning techniques. In the next chapter, we will briefly introduce deep learning concepts and see how imbalanced datasets could be a problem in the deep <span class="No-Break">lea<a id="_idTextAnchor181"/>rning world.</span></p>
			<h1 id="_idParaDest-116"><a id="_idTextAnchor182"/>Questions</h1>
			<ol>
				<li>Apply the CSL technique to the SVM model from <strong class="source-inline">scikit-learn</strong> while utilizing the dataset that was used in this chapter. Use the <strong class="source-inline">class_weight</strong> and <strong class="source-inline">sample_weight</strong> parameters, similar to how we used them for other models in this chapter. Compare the performance of this model with the ones that we already encountered in <span class="No-Break">this chapter.</span></li>
				<li>LightGBM is another gradient-boosting framework similar to XGBoost. Apply the cost-sensitive learning technique to a LightGBM model while utilizing the dataset we used in this chapter. Use the <strong class="source-inline">class_weight</strong> and <strong class="source-inline">sample_weight</strong> parameters similar to how we used them for other models in this chapter. Compare the performance of this model with the ones that we already encountered in <span class="No-Break">this chapter.</span></li>
				<li>AdaCost [10] is a variant of AdaBoost that combines boosting with CSL. It updates the training distribution for successive boosting rounds by utilizing the misclassification cost. Extend <strong class="source-inline">AdaBoostClassifier</strong> from <strong class="source-inline">scikit-learn</strong> to implement the AdaCost algorithm. Compare the performance of AdaCost with MetaCost on the dataset that was used in <span class="No-Break">this chapter.</span></li>
				<li>Tune the hyperparameters, specifically <strong class="source-inline">max_depth</strong>,  <strong class="source-inline">max_delta_step</strong>, and <strong class="source-inline">min_child_weight</strong>, for the XGBoost model using the dataset that we used in this chapter. After tuning, evaluate whether the weighted XGBoost model outperforms the <span class="No-Break">non-weight<a id="_idTextAnchor183"/>ed version.</span></li>
			</ol>
			<h1 id="_idParaDest-117"><a id="_idTextAnchor184"/>References</h1>
			<ol>
				<li value="1">P. Turney, <em class="italic">Types of cost in inductive concept learning</em>, Proc. Workshop on CostSensitive Learning at the 17th Int. Conf. Mach. Learn., Stanford University, CA (2000), <span class="No-Break">pp. 15–21.</span></li>
				<li>C. X. Ling and V. S. Sheng, <em class="italic">Cost-Sensitive Learning and the Class </em><span class="No-Break"><em class="italic">Imbalance Problem</em></span><span class="No-Break">.</span></li>
				<li>Sheng, V. S., &amp; Ling, C. X. (2006). <em class="italic">Thresholding for making classifiers cost-sensitive</em>. AAAI’06: Proceedings of the 21st national conference on artificial intelligence, vol. 6, <span class="No-Break">pp. 476–481.</span></li>
				<li><em class="italic">Pneumonia in Children Statistics</em> – UNICEF <span class="No-Break">data: </span><a href="https://data.unicef.org/topic/child-health/pneumonia/"><span class="No-Break">https://data.unicef.org/topic/child-health/pneumonia/</span></a><span class="No-Break">.</span></li>
				<li>X. Ling, W. Deng, C. Gu, H. Zhou, C. Li, and F. Sun, Model Ensemble for Click Prediction in Bing Search Ads, in Proceedings of the 26th International Conference on World Wide Web Companion – WWW ’17 Companion, Perth, Australia: ACM Press, 2017, pp. 689–698. <span class="No-Break">doi: </span><span class="No-Break">10.1145/3041021.3054192</span><span class="No-Break">.</span></li>
				<li><em class="italic">Machine Learning-Powered Search Ranking of Airbnb Experiences</em> (<span class="No-Break">2019), </span><a href="https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789"><span class="No-Break">https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789</span></a><span class="No-Break">.</span></li>
				<li>P. Domingos, MetaCost: A general method for making classifiers cost-sensitive, in Proceedings of International Conference on Knowledge Discovery and Data Mining, pp. <span class="No-Break">155–164, 1999.</span></li>
				<li><em class="italic">Unstable Learner</em>. In: Sammut, C., Webb, G.I. (eds) Encyclopedia of Machine Learning and Data Mining. Springer, Boston, MA. <span class="No-Break">doi: </span><a href="https://doi.org/10.1007/978-1-4899-7687-1_866"><span class="No-Break">https://doi.org/10.1007/978-1-4899-7687-1_866</span></a><span class="No-Break">.</span></li>
				<li>W. Fan, S. J. Stolfo, J. Zhang, and P. K. Chan, <em class="italic">AdaCost: Misclassiﬁcation </em><span class="No-Break"><em class="italic">Cost-sensitive Boosting</em></span><span class="No-Break">.</span></li>
				<li>G. I. Karakoulas and J. Shawe-Taylor, <em class="italic">Optimizing Classifiers for Imbalanced </em><span class="No-Break"><em class="italic">Training Sets</em></span><span class="No-Break">.</span></li>
				<li>P. Viola and M. Jones, <em class="italic">Fast and Robust Classification using Asymmetric AdaBoost and a </em><span class="No-Break"><em class="italic">Detector Cascade</em></span><span class="No-Break">.</span></li>
				<li>J. M. Johnson and T. M. Khoshgoftaar, <em class="italic">Output Thresholding for Ensemble Learners and Imbalanced Big Data</em>, in 2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI), Washington, DC, USA: IEEE, Nov. 2021, pp. 1449–1454. <span class="No-Break">doi: </span><span class="No-Break">10.1109/ICTAI52525.2021.00230</span><span class="No-Break">.</span></li>
				<li>J. M. Johnson and T. M. Khoshgoftaar, <em class="italic">Deep Learning and Thresholding with Class-Imbalanced Big Data</em>, in 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), Boca Raton, FL, USA, Dec. 2019, pp. 755–762. <span class="No-Break">doi: 10.1109/ICMLA.2019.00134.</span></li>
				<li>F. Provost, <em class="italic">Machine Learning from Imbalanced Data </em><span class="No-Break"><em class="italic">Sets 101</em></span><span class="No-Break">.</span></li>
				<li>M. Buda, A. Maki, and M. A. Mazurowski, <em class="italic">A systematic study of the class imbalance problem in convolutional neural networks</em>, Neural Networks, vol. 106, pp. 249–259, Oct. 2018, <span class="No-Break">doi: </span><span class="No-Break">10.1016/j.neunet.2018.07.011</span><span class="No-Break">.</span></li>
				<li><em class="italic">Using Rich Image and Text Data to Categorize Products at Scale</em> (<span class="No-Break">2021), </span><a href="https://shopify.engineering/using-rich-image-text-data-categorize-products"><span class="No-Break">https://shopify.engineering/using-rich-image-text-data-categorize-products</span></a><span class="No-Break">.</span></li>
				<li>W. J. Youden, <em class="italic">Index for rating diagnostic tests</em>, Cancer, vol. 3, no. 1, pp. 32–35, 1950, <span class="No-Break">doi: 10.1002/1097-0142(1950)3:1&lt;32::AID-CNCR2820030106&gt;3.0.CO;2-3.</span></li>
				<li>I. Unal, <em class="italic">Defining an Optimal Cut-Point Value in ROC Analysis: An Alternative Approach</em>, Computational and Mathematical Methods in Medicine, vol. 2017, pp. 1–14, 2017, <span class="No-Break">doi: </span><span class="No-Break">10.1155/2017/3762651</span><span class="No-Break">.</span></li>
				<li>X. Ling, W. Deng, C. Gu, H. Zhou, C. Li, and F. Sun, <em class="italic">Model Ensemble for Click Prediction in Bing Search Ads</em>, in Proceedings of the 26th International Conference on World Wide Web Companion – WWW ’17 Companion, Perth, Australia: ACM Press, 2017, pp. 689–698. <span class="No-Break">doi: </span><span class="No-Break">10.1145/3041021.3054192</span><span class="No-Break">.</span></li>
			</ol>
		</div>
	</body></html>