- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Building Your First Machine Learning Model
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建您的第一个机器学习模型
- en: In the previous chapter, you learned about **Redshift Machine Learning** (**ML**)
    benefits such as eliminating data movement and how models can be created using
    simple **Structured Query Language** (**SQL**) commands.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您学习了**Redshift机器学习**（**ML**）的好处，例如消除数据移动，以及如何使用简单的**结构化查询语言**（**SQL**）命令创建模型。
- en: In this chapter, you are going to build your first machine learning model by
    using the standard SQL dialect. Amazon Redshift makes it very easy to use familiar
    SQL dialect to train, deploy, and run inferences against machine learning models.
    This approach makes it easy for different data personas, for example, database
    developers, database engineers, and citizen data scientists, to train and build
    machine learning models without moving data outside of their data warehouse platform
    and without having to learn a new programming language.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将使用标准SQL方言构建您的第一个机器学习模型。Amazon Redshift使得使用熟悉的SQL方言来训练、部署和运行机器学习模型变得非常容易。这种方法使得不同的数据角色，例如，数据库开发者、数据库工程师和公民数据科学家，能够在不将数据移出他们的数据仓库平台的情况下，并且无需学习新的编程语言的情况下，训练和构建机器学习模型变得容易。
- en: In this chapter, you will learn about using Amazon Redshift ML simple CREATE
    MODEL, which uses the `CREATE MODEL` command and different methods used to evaluate
    your ML model.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解使用Amazon Redshift ML简单CREATE MODEL，它使用`CREATE MODEL`命令和用于评估您的ML模型的不同方法。
- en: 'In this chapter, to build your first machine learning model, we will go through
    the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，为了构建您的第一个机器学习模型，我们将探讨以下主要主题：
- en: Redshift ML simple CREATE MODEL
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redshift ML简单CREATE MODEL
- en: Evaluating model performance
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型性能
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires a web browser and the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要网络浏览器和以下内容：
- en: An AWS account.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个AWS账户。
- en: An Amazon Redshift Serverless endpoint.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Amazon Redshift Serverless端点。
- en: Amazon Redshift Query Editor v2.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Redshift查询编辑器v2。
- en: Completing the *Getting started with Amazon Redshift Serverless* section in[*Chapter
    1*](B19071_01.xhtml#_idTextAnchor015).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成在[*第一章*](B19071_01.xhtml#_idTextAnchor015)中的“Amazon Redshift Serverless 入门”部分。
- en: 'You can find the code used in this chapter here: [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处找到本章中使用的代码：[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/)
- en: )
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'Data files required for this chapter are located in a public S3 bucket: [s3://packt-serverless-ml-redshift/](https://s3://packt-serverless-ml-redshift/'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章所需的数据文件位于公共S3存储桶中：[s3://packt-serverless-ml-redshift/](https://s3://packt-serverless-ml-redshift/)
- en: )
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: Let’s begin!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Redshift ML simple CREATE MODEL
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Redshift ML简单CREATE MODEL
- en: Redshift ML simple CREATE MODEL is a feature in Amazon Redshift that allows
    users to create machine learning models using SQL commands, without the need for
    specialized skills or software. It simplifies the process of creating and deploying
    machine learning models by allowing users to use familiar SQL syntax to define
    the model structure and input data, and then automatically generates and trains
    the model using Amazon SageMaker. This feature can be used for a variety of machine
    learning tasks, including regression, classification, and clustering.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Redshift ML简单CREATE MODEL是Amazon Redshift中的一个功能，允许用户使用SQL命令创建机器学习模型，无需专业技能或软件。它通过允许用户使用熟悉的SQL语法来定义模型结构和输入数据，然后自动生成并使用Amazon
    SageMaker训练模型，从而简化了创建和部署机器学习模型的过程。此功能可用于各种机器学习任务，包括回归、分类和聚类。
- en: Before we dive into building the first ML model, let us set the stage by defining
    a problem statement that will form the basis of our model-building solution.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入构建第一个ML模型之前，让我们通过定义一个将构成我们模型构建解决方案基础的问题陈述来设定场景。
- en: We are going to use a customer sales dataset to build the first machine learning
    model. Business leaders at the fictitious *ABC Company* are grappling with dwindling
    sales. The data team at *ABC Company* has performed descriptive and diagnostic
    analytics and determined that the cause of decreasing sales is departing customers.
    To stop this problem, data analysts who are familiar with SQL language and some
    machine learning concepts have tapped into Redshift ML. Business users have documented
    which customers have and have not churned and teamed up with data analysts.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用客户销售数据集来构建第一个机器学习模型。虚构的*ABC公司*的商务领导正面临着销售下降的问题。*ABC公司*的数据团队已执行描述性和诊断分析，并确定销售下降的原因是客户流失。为了解决这个问题，熟悉SQL语言和一些机器学习概念的数据分析师利用了Redshift
    ML。商务用户记录了哪些客户已经流失和未流失，并与数据分析师团队合作。
- en: To solve the business problem, the data analysts start by analyzing the sales
    dataset. With Redshift SQL commands, they will write SQL aggregate queries and
    create visualizations to understand the trends. The data analyst team then creates
    an ML model using the Redshift ML simple `CREATE MODEL` command. Finally, the
    data analysts evaluate the model performance to make sure the model is useful.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决业务问题，数据分析师首先分析销售数据集。他们将通过Redshift SQL命令编写SQL聚合查询并创建可视化来了解趋势。然后，数据分析师团队使用Redshift
    ML的简单`CREATE MODEL`命令创建机器学习模型。最后，数据分析师评估模型性能以确保模型有用。
- en: Uploading and analyzing the data
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传和分析数据
- en: 'The dataset used for this chapter is located here: [s3://packt-serverless-ml-redshift/](https://s3://packt-serverless-ml-redshift/).
    We have modified the dataset to better fit the chapter’s requirements.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节所使用的数据集位于此处：[s3://packt-serverless-ml-redshift/](https://s3://packt-serverless-ml-redshift/)。我们已修改数据集以更好地满足章节要求。
- en: Dataset citation
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: 'This dataset is attributed to the University of California Irvine Repository
    of Machine Learning Datasets (Jafari-Marandi, R., Denton, J., Idris, A., Smith,
    B. K., & Keramati, A. (2020). *Optimum Profit-Driven Churn Decision Making: Innovative
    Artificial Neural Networks in Telecom Industry. Neural Computing* *and Applications*.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '此数据集归功于加州大学欧文分校机器学习数据集存储库（Jafari-Marandi, R., Denton, J., Idris, A., Smith,
    B. K., & Keramati, A. (2020). *Optimum Profit-Driven Churn Decision Making: Innovative
    Artificial Neural Networks in Telecom Industry. Neural Computing* *and Applications*）。'
- en: 'This dataset contains customer churn information. The following table lists
    the metadata of the dataset:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集包含客户流失信息。以下表格列出了数据集的元数据：
- en: '| **Name** | **Data Type** | **Definition** |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **数据类型** | **定义** |'
- en: '| `state` | `varchar(2)` | US state in which the customer is located |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| `state` | `varchar(2)` | 客户所在的美国州 |'
- en: '| `account_length` | `int` | Length of customer account |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| `account_length` | `int` | 客户账户长度 |'
- en: '| `area_code` | `int` | Area code or zip code of the customer |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| `area_code` | `int` | 客户的地区代码或邮政编码 |'
- en: '| `phone` | `varchar(8)` | Phone number of the customer |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| `phone` | `varchar(8)` | 客户的电话号码 |'
- en: '| `intl_plan` | `varchar(3)` | International plan subscriber |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| `intl_plan` | `varchar(3)` | 国际计划订阅者 |'
- en: '| `vMail_plan` | `varchar(3)` | Voicemail plan subscriber |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `vMail_plan` | `varchar(3)` | 语音邮件计划订阅者 |'
- en: '| `vMail_message` | `int` | Voicemail message subscriber |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| `vMail_message` | `int` | 语音邮件消息订阅者 |'
- en: '| `day_mins` | `float` | Aggregated daily minutes |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| `day_mins` | `float` | 每日累计分钟数 |'
- en: '| `day_calls` | `int` | Aggregated daily calls |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| `day_calls` | `int` | 每日累计通话次数 |'
- en: '| `day_charge` | `float` | Aggregated daily charges |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| `day_charge` | `float` | 每日累计费用 |'
- en: '| `total_charge` | `float` | Total charges |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| `total_charge` | `float` | 总费用 |'
- en: '| `eve_mins` | `float` | Evening minutes |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| `eve_mins` | `float` | 晚间分钟数 |'
- en: '| `eve_calls` | `int` | Evening calls |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `eve_calls` | `int` | 晚间通话次数 |'
- en: '| `eve_charge` | `float` | Evening charges |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `eve_charge` | `float` | 晚间费用 |'
- en: '| `night_mins` | `float` | Nightly minutes |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `night_mins` | `float` | 夜间分钟数 |'
- en: '| `night_calls` | `int` | Nightly calls |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `night_calls` | `int` | 夜间通话次数 |'
- en: '| `night_charge` | `float` | Nightly charges |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `night_charge` | `float` | 夜间费用 |'
- en: '| `intl_mins` | `float` | International minutes |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| `intl_mins` | `float` | 国际分钟数 |'
- en: '| `intl_calls` | `int` | International calls |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| `intl_calls` | `int` | 国际通话次数 |'
- en: '| `intl_charge` | `float` | International charges |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `intl_charge` | `float` | 国际费用 |'
- en: '| `cust_serv_calls` | `int` | Number of calls to customer service |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| `cust_serv_calls` | `int` | 客户服务通话次数 |'
- en: '| `churn` | `varchar(6)` | Whether customer churned or not |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| `churn` | `varchar(6)` | 客户是否流失 |'
- en: '| `record_date` | `date` | Record updated date |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `record_date` | `date` | 记录更新日期 |'
- en: Table 5.1 – Customer call data
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1 – 客户通话数据
- en: 'After successfully connecting to Redshift as an admin or database developer,
    create the schema and load data into Amazon Redshift as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功连接到 Redshift 作为管理员或数据库开发者后，创建架构并将数据加载到 Amazon Redshift 中，如下所示：
- en: Navigate to **Redshift query editor v2**, connect to the **Serverless:default**
    endpoint, and connect to the **dev** database.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 **Redshift 查询编辑器 v2**，连接到 **Serverless:default** 端点，并连接到 **dev** 数据库。
- en: 'Create a new editor and rename the `untitled` query editor by saving it as
    `Chapter5`, as shown in *Figure 5**.1*:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的编辑器，并将未命名的查询编辑器保存为 `Chapter5`，如图 *图 5**.1* 所示：
- en: '![Figure 5.1 – Connecting to query editor v2](img/B19071_05_01.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.1 – 连接到查询编辑器 v2](img/B19071_05_01.jpg)'
- en: Figure 5.1 – Connecting to query editor v2
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – 连接到查询编辑器 v2
- en: 'Create a Redshift schema named `Chapter5_buildfirstmodel`. Redshift schemas
    contain tables, views, and other named objects. For this chapter, tables and machine
    learning models will be created in this schema:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `Chapter5_buildfirstmodel` 的 Redshift 架构。Redshift 架构包含表、视图和其他命名对象。对于本章，将在该架构中创建表和机器学习模型：
- en: '[PRE0]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create a Redshift table named `customer_calls_fact`. This table is used to
    load the dataset that has customer call information. This table is natively created
    in Redshift and used for training and validating the Redshift ML model:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `customer_calls_fact` 的 Redshift 表。此表用于加载包含客户通话信息的数据集。此表在 Redshift 中原生创建，用于训练和验证
    Redshift ML 模型：
- en: '[PRE1]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Load the customer call data into the Redshift table by using the following
    command:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将客户通话数据加载到 Redshift 表中：
- en: '[PRE26]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We use the Redshift `COPY` command to load the data into our table. `COPY` commands
    load data in parallel into a Redshift table. You can load terabytes of data by
    using the `COPY` command.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 Redshift `COPY` 命令将数据加载到我们的表中。`COPY` 命令将数据并行加载到 Redshift 表中。你可以使用 `COPY`
    命令加载数以千计的数据。
- en: 'In the final step, we will analyze the customer churn fact table by creating
    a histogram for customer churn. To do this, let’s use the query editor v2 chart
    feature to create a histogram chart. In order to create the histogram, we need
    to count the number of customers who have churned and not churned. To get this
    information, first, run the following command:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在最后一步，我们将通过创建客户流失直方图来分析客户流失事实表。为此，让我们使用查询编辑器 v2 图表功能来创建直方图图表。为了创建直方图，我们需要统计流失和未流失的客户数量。要获取这些信息，首先，运行以下命令：
- en: '[PRE31]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, click on the **Chart** option found on the right-hand side in the **Result**
    pane to view the histogram:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，点击 **结果** 窗格右侧的 **图表** 选项，以查看直方图：
- en: "![Figure 5.2 – Customers churned \uFEFFversus not churned histogram](img/B19071_05_02.jpg)"
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2 – 流失客户与未流失客户直方图](img/B19071_05_02.jpg)'
- en: Figure 5.2 – Customers churned versus not churned histogram
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – 流失客户与未流失客户直方图
- en: From the preceding chart, you can see that the `customer_calls_fact` table has
    **3333** customers, of which **483** have churned.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中，你可以看到 `customer_calls_fact` 表有 **3333** 名客户，其中 **483** 名已经流失。
- en: Now, we analyzed the dataset and found that there are customers who have churned.
    The next step is to create a machine learning model. For this, we will use the
    Redshift ML simple `CREATE` `MODEL` method.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经分析了数据集，并发现有一些客户已经流失。下一步是创建一个机器学习模型。为此，我们将使用 Redshift ML 简单的 `CREATE`
    `MODEL` 方法。
- en: Diving deep into the Redshift ML CREATE MODEL syntax
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨 Redshift ML `CREATE MODEL` 语法
- en: Since this is the first time you are going to use the `CREATE MODEL` syntax,
    let’s refresh the basic constructs of the command here.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是你第一次使用 `CREATE MODEL` 语法，让我们在这里刷新一下命令的基本结构。
- en: Redshift ML provides the easy-to-use `CREATE MODEL` syntax to create ML models.
    In this section, we will focus on a simple form of the `CREATE MODEL` command.
    In later chapters, you will learn about other forms of creating model statements.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Redshift ML 提供了易于使用的 `CREATE MODEL` 语法来创建机器学习模型。在本节中，我们将重点介绍 `CREATE MODEL`
    命令的简单形式。在后面的章节中，你将学习到其他形式的创建模型语句。
- en: Simple `CREATE MODEL` is the most basic form of Redshift `CREATE MODEL` statement.
    It is geared toward the personas who are not yet ready to deal with all the intricacies
    of the machine learning process. This form of model creation is also used by experienced
    personas such as citizen data scientists for its simplicity in creating a machine
    learning model. Data cleaning is an essential step for any ML problem, otherwise,
    it follows the principle of *garbage in, garbage out*. Data cleaning still remains
    a necessary task, however, with Redshift ML data transformation, standardization
    and model selection won’t be necessary.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 简单 `CREATE MODEL` 是 Redshift `CREATE MODEL` 语句的最基本形式。它面向尚未准备好处理机器学习过程所有复杂性的用户。这种模型创建形式也由经验丰富的用户，如公民数据科学家，用于其创建机器学习模型的简单性。数据清洗是任何机器学习问题的一个基本步骤，否则，它遵循“垃圾输入，垃圾输出”的原则。然而，数据清洗仍然是必要的任务，但在
    Redshift ML 数据转换、标准化和模型选择将不再必要。
- en: 'We use the following command for simple model creation:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下命令进行简单模型创建：
- en: '[PRE34]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In the preceding `CREATE MODEL` syntax, as a user, you specify your dataset
    – in our case, `customer_calls_fact` – in the `FROM` clause. We set the variable
    that we are targeting to predict, in our case `churn`, in the `TARGET` parameter.
    As a user, you also give a name to the function, which you will use in select
    queries to run predictions.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的 `CREATE MODEL` 语法中，作为用户，你指定你的数据集 – 在我们的案例中，`customer_calls_fact` – 在 `FROM`
    子句中。我们将我们想要预测的目标变量设置为 `churn`，在 `TARGET` 参数中。作为用户，你还需要为该函数命名，你将在选择查询中运行预测时使用该函数。
- en: 'For more information about simple `CREATE MODEL` parameters, please refer to
    the Redshift public document here: [https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_simple_create_model](https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_simple_create_model'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于简单 `CREATE MODEL` 参数的信息，请参阅以下 Redshift 公共文档：[https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_simple_create_model](https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_simple_create_model
- en: )
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: We’ve learned about the generic simple `CREATE MODEL` syntax. Now, let’s create
    the syntax for our dataset and run it.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了通用的简单 `CREATE MODEL` 语法。现在，让我们为我们的数据集创建语法并运行它。
- en: Creating your first machine learning model
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建你的第一个机器学习模型
- en: 'Finally, we will now build our first ML model to predict customer churn events.
    As this is our first machine learning model, let’s use the simple `CREATE MODEL`
    command. This option uses Amazon SageMaker Autopilot, which means, without the
    heavy lifting of building ML models, you simply provide a tabular dataset and
    select the target column to predict and SageMaker Autopilot automatically explores
    different solutions to find the best model. This includes data preprocessing,
    model training, and model selection and deployment. AutoMode is the default mode:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将构建我们的第一个机器学习模型来预测客户流失事件。由于这是我们第一个机器学习模型，让我们使用简单的 `CREATE MODEL` 命令。此选项使用
    Amazon SageMaker Autopilot，这意味着，无需进行构建机器学习模型的繁重工作，你只需提供一个表格数据集并选择要预测的目标列，SageMaker
    Autopilot将自动探索不同的解决方案以找到最佳模型。这包括数据预处理、模型训练、模型选择和部署。AutoMode 是默认模式：
- en: 'Redshift ML shares training data and artifacts between Amazon Redshift and
    SageMaker through an S3 bucket. If you don’t have one already, you will need to
    create an S3 bucket. To do this, navigate to the Amazon S3 console and click on
    the **Create** **bucket** button:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Redshift ML 通过 S3 存储桶在 Amazon Redshift 和 SageMaker 之间共享训练数据和工件。如果你还没有，你需要创建一个
    S3 存储桶。为此，导航到 Amazon S3 控制台并点击 **创建** **存储桶** 按钮：
- en: '![Figure 5.3 – S3 console](img/B19071_05_03.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.3 – S3 控制台](img/B19071_05_03.jpg)'
- en: Figure 5.3 – S3 console
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 – S3 控制台
- en: On the `serverlessmachinelearningwithredshift-<your account id>`, where `<your
    account id>` is your AWS account number.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `serverlessmachinelearningwithredshift-<your account id>` 上，其中 `<your account
    id>` 是你的 AWS 账号。
- en: '![Figure 5.4 – Creating an S3 bucket](img/B19071_05_04.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.4 – 创建 S3 存储桶](img/B19071_05_04.jpg)'
- en: Figure 5.4 – Creating an S3 bucket
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 – 创建 S3 存储桶
- en: 'Before we send our dataset to the `CREATE MODEL` command, we will split the
    dataset into two parts – one is the training dataset, which is used to train the
    machine learning model, and the other one is for testing the model once it is
    created. We do this by filtering customer records that have `record_date` of less
    than `''2020-08-01''` for training and `record_date` greater than `''2020-07-31''`
    for testing. Run the following queries to check our record split:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们将数据集发送到 `CREATE MODEL` 命令之前，我们将数据集分成两部分——一部分是训练数据集，用于训练机器学习模型，另一部分是在模型创建后用于测试模型。我们通过过滤
    `record_date` 小于 `'2020-08-01'` 的客户记录进行训练，以及 `record_date` 大于 `'2020-07-31'` 的记录进行测试。运行以下查询以检查我们的记录拆分：
- en: '[PRE35]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In *Figure 5**.5*, we can see we have **2714** records in the training set and
    **619** records in the test set.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 5.5* 中，我们可以看到训练集中有 **2714** 条记录，测试集中有 **619** 条记录。
- en: '![Figure 5.5 – Training and test dataset record count](img/B19071_05_05.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.5 – 训练和测试数据集记录数](img/B19071_05_05.jpg)'
- en: Figure 5.5 – Training and test dataset record count
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 – 训练和测试数据集记录数
- en: We apply the filtering condition when training and testing the model on our
    dataset. In the next step, we are going to create the model using this filter
    condition on our dataset.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在训练和测试我们的数据集时应用过滤条件。在下一步中，我们将使用数据集上的这个过滤条件来创建模型。
- en: 'Now run the following code to create `customer_churn_model`. Make sure to replace
    `<your account id>` with the correct AWS account number. Please note that since
    we are going to use simple `CREATE MODEL`, we set the max allowed time through
    the `MAX_RUNTIME` parameter. This is the maximum training time that Autopilot
    will take. We have set it to 1,800 seconds, which is 30 minutes. If you don’t
    specify a value for `MAX_RUNTIME` it will use the default value of 5,400 seconds
    (90 minutes):'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在运行以下代码以创建 `customer_churn_model`。请确保将 `<your account id>` 替换为正确的 AWS 账号。请注意，由于我们将使用简单的
    `CREATE MODEL`，我们通过 `MAX_RUNTIME` 参数设置了最大允许时间。这是 Autopilot 将花费的最大训练时间。我们将其设置为
    1,800 秒，即 30 分钟。如果您未指定 `MAX_RUNTIME` 的值，它将使用默认值 5,400 秒（90 分钟）：
- en: '[PRE38]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Let us understand more about the preceding command:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地了解前面的命令：
- en: The `SELECT` query in the `FROM` clause specifies the training data
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FROM` 子句中的 `SELECT` 查询指定了训练数据'
- en: The `TARGET` clause specifies which column is the label for which the `CREATE
    MODEL` statement builds a model to predict
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TARGET` 子句指定了 `CREATE MODEL` 语句构建模型以预测的标签所在的列'
- en: The other columns in the training query are the features (input) used to predict
    the churn variable
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练查询中的其他列是用于预测流失变量的特征（输入）
- en: The `predict_customer_churn` function is the name of an inference function used
    in `SELECT` queries to generate predictions
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predict_customer_churn` 函数是在 `SELECT` 查询中使用的推理函数的名称，用于生成预测'
- en: '`S3_Bucket` is the location where Redshift ML saves artifacts when working
    with SageMaker'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`S3_Bucket` 是 Redshift ML 在与 SageMaker 一起工作时保存工件的位置'
- en: Having `MAX_RUNTIME` set as 1,800 seconds specifies the maximum time that SageMaker
    will take to train our model
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 `MAX_RUNTIME` 设置为 1,800 秒指定了 SageMaker 训练我们的模型的最大时间
- en: 'After you run the `CREATE MODEL` command, run the following command to check
    the status of the model:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在您运行 `CREATE MODEL` 命令后，运行以下命令以检查模型的状态：
- en: '[PRE72]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: The Redshift ML `CREATE MODEL` statement is asynchronous, which means that when
    the model is under training, the query shows it is completed and the training
    is happening in Amazon SageMaker. To find out the status of the model, run the
    `SHOW` `MODEL` command.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Redshift ML 的 `CREATE MODEL` 语句是异步的，这意味着当模型处于训练状态时，查询显示已完成，而训练正在 Amazon SageMaker
    中进行。要了解模型的状态，请运行 `SHOW MODEL` 命令。
- en: 'In the following screenshot, you can see the `SHOW MODEL` output shows **Model
    State** as **TRAINING**:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下屏幕截图中，您可以看到 `SHOW MODEL` 输出显示 **模型状态** 为 **训练**：
- en: '![Figure 5.6 – Model State TRAINING](img/B19071_05_06.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.6 – 模型状态训练](img/B19071_05_06.jpg)'
- en: Figure 5.6 – Model State TRAINING
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 – 模型状态训练
- en: When the same `SHOW MODEL` command is run after a while, **Model State** is
    displayed as **READY**, which means data processing, model training, model selection,
    and model deployment to Redshift is completed successfully. From the following
    screenshot, you can see that **Model Status** now shows **READY**. You can also
    see the **Estimated Cost** value, which represents Amazon SageMaker training hours.
    This value does not equal the elapsed training time as it is an accumulation of
    training time on the SageMaker instances used.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在一段时间后运行相同的`SHOW MODEL`命令后，**模型状态**显示为**READY**，这意味着数据处理、模型训练、模型选择和模型部署到Redshift已成功完成。从以下屏幕截图，您可以看到**模型状态**现在显示为**READY**。您还可以看到**预估成本**值，这代表Amazon
    SageMaker训练小时数。这个值不等于已过训练时间，因为它是在SageMaker实例上累积的训练时间。
- en: '![Figure 5.7 – Model State READY](img/B19071_05_07.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图5.7 – 模型状态为READY](img/B19071_05_07.jpg)'
- en: Figure 5.7 – Model State READY
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 – 模型状态为READY
- en: 'Apart from `SHOW MODEL` command gives you other useful information about the
    model, for example, the query used, **Target Column**, **Model Type**, and **Function
    Name** to use when predicting. You can see that **Model Type** in our example
    is **xgboost**, which tells you that Amazon SageMaker has chosen the XGBoost algorithm
    to build the binary classification model:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`SHOW MODEL`命令提供有关模型的其它有用信息外，例如，查询使用情况、**目标列**、**模型类型**和预测时使用的**函数名称**。您可以看到，在我们的示例中**模型类型**是**xgboost**，这表明Amazon
    SageMaker已选择XGBoost算法来构建二元分类模型：
- en: '![Figure 5.8 – Model State READY continuation](img/B19071_05_08.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图5.8 – 模型状态为READY的延续](img/B19071_05_08.jpg)'
- en: Figure 5.8 – Model State READY continuation
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 – 模型状态为READY的延续
- en: 'If you read further into the output, Redshift ML has done the bulk of the work
    for you, for example, it has selected and set the following parameters:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您进一步阅读输出，Redshift ML已经为您做了大部分工作，例如，它已选择并设置了以下参数：
- en: '**Problem Type** is set to **BinaryClassification**. This is true since our
    target variable has two distinct values in it, true and false. So, this is a binary
    classification problem.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题类型**设置为**二元分类**。这是真的，因为我们的目标变量中有两个不同的值，即true和false。因此，这是一个二元分类问题。'
- en: '**Validation** and **Objective** is set to **F1**. F1 score is a recommended
    approach when evaluating binary scores since it considers both precision and recall.
    Other objectives that SageMaker Autopilot may select for a binary classification
    model are **accuracy** and **area under** **curve** (**AUC**).'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证**和**目标**设置为**F1**。F1分数是评估二元分数时推荐的方法，因为它考虑了精确度和召回率。SageMaker Autopilot可能为二元分类模型选择的其它目标还包括**准确率**和**曲线下面积**（**AUC**）。'
- en: We have created the model successfully as `SELECT` queries. The next sections
    show how to do so.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功创建模型，作为`SELECT`查询。下一节将展示如何做到这一点。
- en: Evaluating model performance
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型性能
- en: Now we have created the model, let’s dive into the details of its performance.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了模型，让我们深入了解其性能细节。
- en: When building machine learning models, it is very important to understand the
    model performance. You do this to make sure your model is useful and is not biased
    to one class over another and to make sure that the model is not under-trained
    or over-trained, which will mean the model is either not predicting classes correctly
    or is predicting only some instances and not others.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建机器学习模型时，了解模型性能非常重要。您这样做是为了确保您的模型是有用的，并且不会对某一类有偏见，以及确保模型不是欠训练或过训练，这意味着模型要么没有正确预测类别，要么只预测了一些实例而没有预测其他实例。
- en: To address this problem, Redshift ML provides various objectives to measure
    the performance of the model. It is prudent that we test the model performance
    with the test dataset that we set aside in the previous section. This section
    explains how to review the Redshift ML objectives and also validate the model
    performance with our test data.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，Redshift ML提供了各种目标来衡量模型的性能。我们明智的做法是使用上一节中预留的测试数据集来测试模型性能。本节将解释如何审查Redshift
    ML目标，并使用我们的测试数据验证模型性能。
- en: Redshift ML uses several objective methods to measure the predictive quality
    of machine learning models.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Redshift ML使用几种目标方法来衡量机器学习模型的预测质量。
- en: Checking the Redshift ML objectives
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查Redshift ML目标
- en: '*Figure 5**.9* shows the `SHOW MODEL` output. It displays two values that are
    of interest to us. One is **Objective** and the other is **validation:f1_binary**.
    The first value to look at is **Objective**. It is set to **F1** for us. F1 or
    F-score is the most commonly used performance evaluation metric used for classification
    models. It is a measure for validating dataset accuracy. It is calculated from
    the precision and recall of the validations where precision is the number of true
    positive results divided by the number of all positive results included, and recall
    is the number of true positive results divided by the number of all records that
    should have been identified as positive. You can learn more about F-score here:
    [https://en.wikipedia.org/wiki/F-score](https://en.wikipedia.org/wiki/F-score).'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5.9* 显示了 `SHOW MODEL` 的输出。它显示了两个对我们来说有趣的价值。一个是 **Objective**，另一个是 **validation:f1_binary**。首先需要查看的是
    **Objective**。它被设置为 **F1**。F1 或 F-score 是分类模型中最常用的性能评估指标。它是验证数据集准确性的一个度量。它是从验证的精确度和召回率计算得出的，其中精确度是真实阳性结果的数量除以所有阳性结果的数量，召回率是真实阳性结果的数量除以所有应被识别为阳性的记录的数量。您可以在这里了解更多关于
    F-score 的信息：[https://en.wikipedia.org/wiki/F-score](https://en.wikipedia.org/wiki/F-score)。'
- en: 'Run the following command in query editor v2:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询编辑器 v2 中运行以下命令：
- en: '[PRE73]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: The output in *Figure 5**.9* shows the value of F1 is found in **validation:****f****1_binary**,
    which is **0.90**. The highest possible value for an F1 score is 1 and the lowest
    is 0\. The highest score of 1 would signify perfect precision and recall by a
    model. In our case, it is 90%, which is really good.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5.9* 中的输出显示了 F1 的值位于 **validation:****f****1_binary** 中，其值为 **0.90**。F1
    分数的最高可能值为 1，最低为 0。得分为 1 表示模型具有完美的精确度和召回率。在我们的情况下，它是 90%，这非常好。'
- en: '![Figure 5.9 – Model objective values](img/B19071_05_09.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.9 – 模型目标值](img/B19071_05_09.jpg)'
- en: Figure 5.9 – Model objective values
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 – 模型目标值
- en: We have seen that the model created by Autopilot has a good F-score and is ready
    to use to predict whether customers are going to churn or not. In the next section,
    we will use the prediction function to generate the prediction values along with
    probability scores.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，由 Autopilot 创建的模型具有很好的 F-score，并且可以用来预测客户是否会流失。在下一节中，我们将使用预测函数来生成预测值以及概率分数。
- en: Running predictions
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行预测
- en: 'Now let’s invoke our `predict_customer_churn` and `predict_customer_churn_prob`
    prediction functions through the `SELECT` command. Redshift ML creates two functions
    for us to use:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过 `SELECT` 命令调用我们的 `predict_customer_churn` 和 `predict_customer_churn_prob`
    预测函数。Redshift ML 为我们创建了两个函数来使用：
- en: One is created with the same name as the one we gave when creating the model,
    in this case, `predict_customer_churn`, which returns the class label or predicted
    value, for example, `0` or `1`.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其中一个与我们在创建模型时给出的名称相同，在本例中为 `predict_customer_churn`，它返回类别标签或预测值，例如，`0` 或 `1`。
- en: The other function, `predict_customer_churn_prob`, in addition to returning
    the class label or predicted value, also returns the probability that the predicted
    value is correct.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个函数 `predict_customer_churn_prob`，除了返回类别标签或预测值外，还返回预测值正确的概率。
- en: To test these functions, run the following query. In the following query, you’ll
    notice that we are using two prediction functions inside a `SELECT` command and
    passing all the input columns that were passed when creating the ML model. These
    two functions will return a label and probability score as output. We are also
    testing the prediction function by filtering rows where `record_date` is greater
    than `'2022-07-31'`. Since this is an unseen dataset, it should act as a challenging
    dataset for our ML model.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试这些函数，请运行以下查询。在以下查询中，您会注意到我们在 `SELECT` 命令中使用两个预测函数，并传递创建 ML 模型时传递的所有输入列。这两个函数将返回标签和概率分数作为输出。我们还通过过滤
    `record_date` 大于 `'2022-07-31'` 的行来测试预测函数。由于这是一个未见过的数据集，它应该作为对我们 ML 模型具有挑战性的数据集。
- en: 'It is also important to note that all the predictions are happening locally
    on a Redshift cluster. When the `SELECT` query is run, there are no calls made
    to Amazon SageMaker. This makes all predictions free of cost:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要注意的是，所有预测都是在 Redshift 集群上本地进行的。当运行 `SELECT` 查询时，没有调用 Amazon SageMaker。这使得所有预测都是免费的：
- en: '[PRE74]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'You can see the output in the following screenshot:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下屏幕截图中查看输出：
- en: '![Figure 5.10 – Running predictions](img/B19071_05_10.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.10 – 运行预测](img/B19071_05_10.jpg)'
- en: Figure 5.10 – Running predictions
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – 运行预测
- en: In the preceding screenshot, observe that the `predicted_class` values and `probability_score`
    values for each customer are shown. From the `predicted_class` column, you can
    understand that our model is predicting whether the customer is going to churn
    or not, and from the `probability_score` column, you can understand that the model
    is, for example, for the first row, 99% confident that the customer with account
    ID **415382-4657** is not going to churn.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的屏幕截图中，请注意，每个客户的`predicted_class`值和`probability_score`值都显示出来。从`predicted_class`列中，您可以理解我们的模型正在预测客户是否会流失，而从`probability_score`列中，您可以理解模型，例如，对于第一行，模型有99%的信心认为账户ID为**415382-4657**的客户不会流失。
- en: We have witnessed that prediction is working without any issues. In the next
    section, let’s check how the model is performing compared to ground truth.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经见证了预测工作没有出现任何问题。在下一节中，我们将检查模型与真实值相比的表现。
- en: Comparing ground truth to predictions
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较真实值与预测值
- en: 'Run the following query to compare actual versus predicted customer churn:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下查询以比较实际与预测的客户流失：
- en: '[PRE75]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The following screenshot shows the customers where the ML model made a mistake:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了ML模型犯错的客户：
- en: Note
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Results will vary as each trained model will have slight differences.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将因每个训练模型略有不同而有所变化。
- en: '![Figure 5.11 – Incorrect predictions](img/B19071_05_11.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图5.11 – 错误预测](img/B19071_05_11.jpg)'
- en: Figure 5.11 – Incorrect predictions
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11 – 错误预测
- en: We have seen the model predictions and compared them with ground truth. In the
    next section, we will learn about feature importance.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了模型预测，并与真实值进行了比较。在下一节中，我们将学习关于特征重要性的内容。
- en: Feature importance
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征重要性
- en: '`explain_model` functions to retrieve feature importance. This will help you
    to understand which features are strongly related to the target variable, which
    features are important to the model and which are not, and from this you can reduce
    the number of dimensions that you feed into your machine learning model.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`explain_model`函数用于检索特征重要性。这将帮助您了解哪些特征与目标变量高度相关，哪些特征对模型很重要，哪些则不是，从而您可以减少输入到机器学习模型中的维度数量。'
- en: 'The following is the SQL code that you can run to retrieve the feature importance
    of our model:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可以运行的SQL代码，用于检索我们模型的特征重要性：
- en: '[PRE76]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: The following is the JSON format output of feature importance. You can read
    and understand the importance of each feature.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是特征重要性的JSON格式输出。您可以阅读和理解每个特征的重要性。
- en: '![Figure 5.12 – Feature importance raw output](img/B19071_05_12.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![图5.12 – 特征重要性原始输出](img/B19071_05_12.jpg)'
- en: Figure 5.12 – Feature importance raw output
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.12 – 特征重要性原始输出
- en: 'For better readability of the feature importance, you may execute the following
    SQL code:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地阅读特征重要性，您可以执行以下SQL代码：
- en: '[PRE77]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '![Figure 5.13 – Feature Importance](img/B19071_05_13.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图5.13 – 特征重要性](img/B19071_05_13.jpg)'
- en: Figure 5.13 – Feature Importance
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13 – 特征重要性
- en: You can use feature importance to understand the relationship between each feature
    and target variable and the features that are not important.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用特征重要性来理解每个特征与目标变量之间的关系，以及哪些特征不重要。
- en: We have seen what features contribute highly to the model, now let’s look at
    how model performance metrics are calculated on our test dataset.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了对模型贡献很大的特征，现在让我们看看模型性能指标是如何在我们的测试数据集上计算的。
- en: Model performance
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型性能
- en: 'Let’s use Redshift SQL to compute a **confusion matrix** to evaluate the performance
    of the classification model. Using a confusion matrix, you can identify true positives,
    true negatives, false positives, and false negatives, based on which various statistical
    measures such as accuracy, precision, recall, sensitivity, specificity, and finally,
    F1 score are calculated. You can read more about the concept of the confusion
    matrix here: [https://en.wikipedia.org/wiki/Confusion_matrix](https://en.wikipedia.org/wiki/Confusion_matrix).'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Redshift SQL计算一个**混淆矩阵**来评估分类模型的表现。使用混淆矩阵，您可以识别真实正例、真实负例、假正例和假负例，基于这些，可以计算出各种统计指标，如准确率、精确率、召回率、灵敏度、特异性和最终，F1分数。您可以在此处了解更多关于混淆矩阵的概念：[https://en.wikipedia.org/wiki/Confusion_matrix](https://en.wikipedia.org/wiki/Confusion_matrix)。
- en: 'The following query uses a `WITH` clause, which implements a common table expression
    in Redshift. This query has the following three parts:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 以下查询使用了`WITH`子句，这在Redshift中实现了公共表表达式。此查询包含以下三个部分：
- en: The first part is about the `SELECT` statement within the `WITH` clause, where
    we predict customer churn and save it in memory. This dataset is named `infer_data`.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一部分是关于`WITH`子句中的`SELECT`语句，在这里我们预测客户流失并保存在内存中。这个数据集被命名为`infer_data`。
- en: The second part, which is below the first `SELECT` statement, reads `infer_data`
    and builds the confusion matrix, and these details are stored in memory in a dataset
    called `confusionmatrix`.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二部分位于第一个`SELECT`语句下方，读取`infer_data`并构建混淆矩阵，这些详细信息存储在名为`confusionmatrix`的数据集中。
- en: In the third part of the statement, note that the `SELECT` statement builds
    the model performance metrics such as F1 score, accuracy, recall, and so on.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在语句的第三部分，请注意，`SELECT`语句构建了模型性能指标，如F1分数、准确率、召回率等。
- en: 'Run the following query to build a confusion matrix for the test dataset:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下查询以构建测试数据集的混淆矩阵：
- en: '[PRE78]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'We get the following output:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: "![Figure 5.14 – Confusion \uFEFFmatrix for the test dataset](img/B19071_05_14.jpg)"
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图5.14 – 测试数据集的混淆矩阵](img/B19071_05_14.jpg)'
- en: Figure 5.14 – Confusion matrix for the test dataset
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14 – 测试数据集的混淆矩阵
- en: By looking at the `record_date` > `'2020-07-31'`). These records have not been
    seen by the model before, but 97% of the time, the model is able to correctly
    predict the class value. This proves that the model is useful and correctly predicts
    both classes – churn and no churn. This model can now be given to the business
    units so it can be used to proactively predict the customers who are about to
    churn and build marketing campaigns for them.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看`record_date` > `'2020-07-31'`)）。这些记录之前没有被模型看到，但97%的时间，模型能够正确预测类值。这证明了模型是有用的，并且能够正确预测两个类别——流失和非流失。现在可以将这个模型交给业务部门，以便它可以主动预测即将流失的客户并为他们制定营销活动。
- en: Summary
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you have learned how to create your first machine learning
    model using a simple `CREATE MODEL` statement. While doing so, you explored `customer_calls_fact`
    table data using query editor v2, learned about the basic syntax of the `CREATE
    MODEL` statement, created a simple ML model, learned how to read the model’s output,
    and finally, used Redshift SQL to compute some of the model evaluation metrics
    yourself.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何使用简单的`CREATE MODEL`语句创建你的第一个机器学习模型。在这个过程中，你使用了查询编辑器v2来探索`customer_calls_fact`表数据，了解了`CREATE
    MODEL`语句的基本语法，创建了一个简单的ML模型，学习了如何读取模型的输出，并最终使用Redshift SQL自己计算了一些模型评估指标。
- en: In the next chapter, you will use the basics that you have learned in this chapter
    to build various classification models using Redshift ML.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将使用本章学到的基本知识来使用Redshift ML构建各种分类模型。
