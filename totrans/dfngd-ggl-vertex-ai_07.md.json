["```py\nimport numpy as np\nimport tensorflow\nimport glob\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n```", "```py\nwget https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\nwget https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz\n```", "```py\n!mkdir data\n!tar -xf images.tar.gz -C data\n!mkdir labels\n!tar -xf annotations.tar.gz -C labels\n```", "```py\nall_image_files = glob.glob(\"data/images/*.jpg\")\nprint(\"Total number of image files : \", \\\n    len(all_image_files))\n```", "```py\nTotal number of image files :  7390\n```", "```py\nfor i in range(3):\n    plt.figure(figsize=(13, 13))\n    for j in range(6):\n        img_path = np.random.choice(all_image_files)\n        img = cv2.imread(img_path)\n        img_class = img_path.split(\"/\")[-1].split(\"_\")[0]\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        plt.subplot(660 + 1 + j)\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title(img_class)\n    plt.show()\n```", "```py\ntrain_files = all_image_files[:int( \\\n    len(all_image_files)*0.6)]\nvalidation_files = all_image_files[int( \\\n    len(all_image_files)*0.6):int(len(all_image_files)*0.8)]\ntest_files = all_image_files[int( \\\n    len(all_image_files)*0.8):]\nprint(len(train_files), len(validation_files), \\\n    len(test_files))\n```", "```py\ntrain_x = []\ntrain_y = []\nval_x = []\nval_y = []\ntest_x = []\ntest_y = []\n```", "```py\nfor file in train_files:\n    try:\n        img = cv2.imread(file)\n        img = cv2.resize(img, (80,80))\n        color_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        black_n_white_img = cv2.cvtColor(color_img, \\\n            cv2.COLOR_RGB2GRAY)\n    except:\n        continue\n    train_x.append((black_n_white_img-127.5)/127.5)\n    train_y.append((color_img-127.5)/127.5)\n```", "```py\nfor file in validation_files:\n    try:\n        img = cv2.imread(file)\n        img = cv2.resize(img, (80,80))\n        color_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        black_n_white_img = cv2.cvtColor(color_img, \\\n            cv2.COLOR_RGB2GRAY)\n    except:\n        continue\n    val_x.append((black_n_white_img-127.5)/127.5)\n    val_y.append((color_img-127.5)/127.5)\n```", "```py\nfor file in test_files:\n    try:\n        img = cv2.imread(file)\n        img = cv2.resize(img, (80,80))\n        color_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        black_n_white_img = cv2.cvtColor(color_img, \\\n            cv2.COLOR_RGB2GRAY)\n    except:\n        continue\n    test_x.append((black_n_white_img-127.5)/127.5)\n    test_y.append((color_img-127.5)/127.5)\n```", "```py\n# input images\nindexes = np.random.choice(range(0,4000), size=3)\nprint(\"Input Samples (black and white): \")\nplt.figure(figsize=(7,7))\nfor i in range(3):\n    plt.subplot(330+1+i)\n    plt.imshow((train_x[indexes[i]]+1.0)/2.0, cmap='gray')\n    plt.axis('off')\nplt.show()\n```", "```py\n# corresponding output images\nprint(\"Output Samples (colored): \")\nplt.figure(figsize=(7,7))\nfor i in range(3):\n    plt.subplot(330+1+i)\n    plt.imshow((train_y[indexes[i]]+1.0)/2.0)\n    plt.axis('off')\nplt.show()\n```", "```py\ntrain_x = np.expand_dims(np.array(train_x),-1)\nval_x = np.expand_dims(np.array(val_x),-1)\ntest_x = np.expand_dims(np.array(test_x),-1)\ntrain_y = np.array(train_y)\nval_y = np.array(val_y)\ntest_y = np.array(test_y)\n```", "```py\nprint(train_x.shape, train_y.shape, val_x.shape, \\\n    val_y.shape, test_x.shape, test_y.shape)\n```", "```py\n(4430, 80, 80, 1) (4430, 80, 80, 3) (1478, 80, 80, 1) (1478, 80, 80, 3) (1476, 80, 80, 1) (1476, 80, 80, 3)\n```", "```py\ndef tf_model():\n    black_n_white_input = tensorflow.keras.layers.Input( \\\n        shape=(80, 80, 1))\n    enc = black_n_white_input\n```", "```py\n    #Encoder part\n    enc = tensorflow.keras.layers.Conv2D(32, kernel_size=3, \\\n        strides=2, padding='same')(enc)\n    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)\n    enc = tensorflow.keras.layers.Conv2D(64, kernel_size=3, \\\n        strides=2, padding='same')(enc)\n    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)\n    enc = tensorflow.keras.layers.Conv2D(128, \\\n        kernel_size=3, strides=2, padding='same')(enc)\n    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)\n    enc = tensorflow.keras.layers.Conv2D(256, \\\n        kernel_size=1, strides=2, padding='same')(enc)\n    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n    enc = tensorflow.keras.layers.Dropout(0.5)(enc)\n```", "```py\n    #Decoder part\n    dec = enc\n    dec = tensorflow.keras.layers.Conv2DTranspose(256, \\\n        kernel_size=3, strides=2, padding='same')(dec)\n    dec = tensorflow.keras.layers.Activation('relu')(dec)\n    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n    dec = tensorflow.keras.layers.Conv2DTranspose(128, \\\n        kernel_size=3, strides=2, padding='same')(dec)\n    dec = tensorflow.keras.layers.Activation('relu')(dec)\n    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n    dec = tensorflow.keras.layers.Conv2DTranspose(64, \\\n        kernel_size=3, strides=2, padding='same')(dec)\n    dec = tensorflow.keras.layers.Activation('relu')(dec)\n    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n    dec = tensorflow.keras.layers.Conv2DTranspose(32, \\\n        kernel_size=3, strides=2, padding='same')(dec)\n    dec = tensorflow.keras.layers.Activation('relu')(dec)\n    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n    dec = tensorflow.keras.layers.Conv2D(3, kernel_size=3,\\\n        padding='same')(dec)\n```", "```py\n    color_image = tensorflow.keras.layers.Activation('tanh')(dec)\n    return black_n_white_input, color_image\n```", "```py\nblack_n_white_input, color_image = tf_model()\nmodel = tensorflow.keras.models.Model( \\\n    inputs=black_n_white_input, outputs=color_image)\nmodel.summary()\n```", "```py\n_optimizer = tensorflow.keras.optimizers.Adam(\\\n    learning_rate=0.0002, beta_1=0.5)\nmodel.compile(loss='mse', optimizer=_optimizer)\n```", "```py\nhistory = model.fit(\n    train_x,\n    train_y,\n    batch_size=128,\n    epochs=100,\n    validation_data=(val_x, val_y),\n)\n```", "```py\nEpoch 1/100\n35/35 [==============================] - 25s 659ms/step - loss: 0.2940 - val_loss: 0.1192\nEpoch 2/100\n35/35 [==============================] - 20s 585ms/step - loss: 0.1117 - val_loss: 0.0917\nEpoch 3/100\n35/35 [==============================] - 20s 580ms/step - loss: 0.0929 - val_loss: 0.0784\nEpoch 4/100\n35/35 [==============================] - 20s 577ms/step - loss: 0.0832 - val_loss: 0.0739\nEpoch 5/100\n35/35 [==============================] - 20s 573ms/step - loss: 0.0778 - val_loss: 0.0698\n. . . . .\n. . . . .\n. . . . .\n. . . . .\nEpoch 100/100\n35/35 [==============================] - 20s 559ms/step - loss: 0.0494 - val_loss: 0.0453\n```", "```py\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper right')\nplt.show()\n```", "```py\nsamples = np.random.choice(range(0, len(test_files)), size=5)\n```", "```py\n# show input images\nprint(\"Black-n-White Input images!\")\nplt.figure(figsize=(8,8))\nfor i in range(5):\n    plt.subplot(550+1+i)\n    plt.imshow((test_x[samples[i]]+1.0)/2.0, cmap='gray')\n    plt.axis('off')\nplt.show()\n```", "```py\n# generate color images from model\nprint(\"Model Outputs!\")\nplt.figure(figsize=(8,8))\nfor i in range(5):\n    plt.subplot(550+1+i)\n    model_input = test_x[samples[i]]\n    output = model.predict(np.array([model_input]))\n    plt.imshow((output[0]+1.0)/2.0)\n    plt.axis('off')\nplt.show()\n```", "```py\n# show real color output images\nprint(\"Real Color Version!\")\nplt.figure(figsize=(8,8))\nfor i in range(5):\n    plt.subplot(550+1+i)\n    plt.imshow((test_y[samples[i]]+1.0)/2.0)\n    plt.axis('off')\nplt.show()\n```", "```py\nfrom io import BytesIO\nimport numpy as np\nfrom tensorflow.python.lib.io import file_io\ndest = 'gs://data-bucket-417812395597/' # Destination to save in GCS\n## saving training data\nnp.save(file_io.FileIO(dest+'train_x', 'w'), train_x)\nnp.save(file_io.FileIO(dest+'train_y', 'w'), train_y)\n## saving validation data\nnp.save(file_io.FileIO(dest+'val_x', 'w'), val_x)\nnp.save(file_io.FileIO(dest+'val_y', 'w'), val_y)\n## saving test data\nnp.save(file_io.FileIO(dest+'test_x', 'w'), test_x)\nnp.save(file_io.FileIO(dest+'test_y', 'w'), test_y)\n```", "```py\ntrain_x = np.load(BytesIO(file_io.read_file_to_string( \\\n    dest+'train_x', binary_mode=True)))\ntrain_y = np.load(BytesIO(file_io.read_file_to_string( \\\n    dest+'train_y', binary_mode=True)))\nval_x = np.load(BytesIO(file_io.read_file_to_string( \\\n    dest+'val_x', binary_mode=True)))\nval_y = np.load(BytesIO(file_io.read_file_to_string( \\\n    dest+'val_y', binary_mode=True)))\ntest_x = np.load(BytesIO(file_io.read_file_to_string( \\\n    dest+'test_x', binary_mode=True)))\ntest_y = np.load(BytesIO(file_io.read_file_to_string( \\\n    dest+'test_y', binary_mode=True)))\n```", "```py\n# Install the packages\n! pip3 install --upgrade google-cloud-aiplatform \\\n                        google-cloud-storage \\\n                        pillow\n```", "```py\nimport numpy as np\nimport glob\nimport matplotlib.pyplot as plt\nimport os\nfrom google.cloud import aiplatform\n%matplotlib inline\n```", "```py\nPROJECT_ID='41xxxxxxxxx7'\nREGION='us-west2'\nBUCKET_URI='gs://my-training-artifacts'\n```", "```py\naiplatform.init(project=PROJECT_ID, location=REGION, \\\n    staging_bucket=BUCKET_URI)\n```", "```py\nTRAIN_VERSION = \"tf-cpu.2-9\"\nDEPLOY_VERSION = \"tf2-cpu.2-9\"\nTRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/{}:latest\".format(TRAIN_VERSION)\nDEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(DEPLOY_VERSION)\n```", "```py\nJOB_NAME = \"vertex_custom_training\"\nMODEL_DIR = \"{}/{}\".format(BUCKET_URI, JOB_NAME)\nTRAIN_STRATEGY = \"single\"\nEPOCHS = 20\nSTEPS = 100\nCMDARGS = [\n    \"--epochs=\" + str(EPOCHS),\n    \"--steps=\" + str(STEPS),\n    \"--distribute=\" + TRAIN_STRATEGY,\n]\n```", "```py\n%%writefile task.py\n# Single, Mirror and Multi-Machine Distributed Training\nimport tensorflow as tf\nimport tensorflow\nfrom tensorflow.python.client import device_lib\nimport argparse\nimport os\nimport sys\nfrom io import BytesIO\nimport numpy as np\nfrom tensorflow.python.lib.io import file_io\n```", "```py\n# parse required arguments\nparser = argparse.ArgumentParser()\nparser.add_argument('--lr', dest='lr', \\\n                    default=0.001, type=float, \\\n                    help='Learning rate.')\nparser.add_argument('--epochs', dest='epochs', \\\n                    default=10, type=int, \\\n                    help='Number of epochs.')\nparser.add_argument('--steps', dest='steps', \\\n                    default=35, type=int, \\\n                    help='Number of steps per epoch.')\nparser.add_argument('--distribute', dest='distribute', \\\n                    type=str, default='single', \\\n                    help='distributed training strategy')\nargs = parser.parse_args()\n```", "```py\nprint('Python Version = {}'.format(sys.version))\nprint('TensorFlow Version = {}'.format(tf.__version__))\nprint('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', \\\n    'Not found')))\nprint('DEVICES', device_lib.list_local_devices())\n```", "```py\n# Single Machine, single compute device\nif args.distribute == 'single':\n    if tf.test.is_gpu_available():\n        strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n    else:\n        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n# Single Machine, multiple compute device\nelif args.distribute == 'mirror':\n    strategy = tf.distribute.MirroredStrategy()\n# Multiple Machine, multiple compute device\nelif args.distribute == 'multi':\n    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n# Multi-worker configuration\nprint('num_replicas_in_sync = {}'.format(strategy.num_replicas_in_sync))\n```", "```py\n# Preparing dataset\nBUFFER_SIZE = 10000\nBATCH_SIZE = 128\ndef make_datasets_unbatched():\n    # Load train, validation and test sets\n    dest = 'gs://data-bucket-417812395597/'\n    train_x = np.load(BytesIO(\n        file_io.read_file_to_string(dest+'train_x', \\\n            binary_mode=True)\n    ))\n    train_y = np.load(BytesIO(\n        file_io.read_file_to_string(dest+'train_y', \\\n            binary_mode=True)\n    ))\n    val_x = np.load(BytesIO(\n        file_io.read_file_to_string(dest+'val_x', \\\n            binary_mode=True)\n    ))\n    val_y = np.load(BytesIO(\n        file_io.read_file_to_string(dest+'val_y', \\\n            binary_mode=True)\n    ))\n    test_x = np.load(BytesIO(\n        file_io.read_file_to_string(dest+'test_x', \\\n            binary_mode=True)\n    ))\n    test_y = np.load(BytesIO(\n        file_io.read_file_to_string(dest+'test_y', \\\n            binary_mode=True)\n    ))\n    return train_x, train_y, val_x, val_y, test_x, test_y\n```", "```py\ndef tf_model():\n    black_n_white_input = tensorflow.keras.layers.Input(shape=(80, 80, 1))\n    enc = black_n_white_input\n```", "```py\n    #Encoder part\n    enc = tensorflow.keras.layers.Conv2D(\n        32, kernel_size=3, strides=2, padding='same'\n    )(enc)\n    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)\n    enc = tensorflow.keras.layers.Conv2D(\n        64, kernel_size=3, strides=2, padding='same'\n    )(enc)\n    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)\n    enc = tensorflow.keras.layers.Conv2D(\n        128, kernel_size=3, strides=2, padding='same'\n    )(enc)\n    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n    enc = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(enc)\n    enc = tensorflow.keras.layers.Conv2D(\n        256, kernel_size=1, strides=2, padding='same'\n    )(enc)\n    enc = tensorflow.keras.layers.LeakyReLU(alpha=0.2)(enc)\n    enc = tensorflow.keras.layers.Dropout(0.5)(enc)\n```", "```py\n    #Decoder part\n    dec = enc\n    dec = tensorflow.keras.layers.Conv2DTranspose(\n        256, kernel_size=3, strides=2, padding='same'\n    )(dec)\n    dec = tensorflow.keras.layers.Activation('relu')(dec)\n    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n    dec = tensorflow.keras.layers.Conv2DTranspose(\n        128, kernel_size=3, strides=2, padding='same'\n    )(dec)\n    dec = tensorflow.keras.layers.Activation('relu')(dec)\n    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n    dec = tensorflow.keras.layers.Conv2DTranspose(\n        64, kernel_size=3, strides=2, padding='same'\n    )(dec)\n    dec = tensorflow.keras.layers.Activation('relu')(dec)\n    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n    dec = tensorflow.keras.layers.Conv2DTranspose(\n        32, kernel_size=3, strides=2, padding='same'\n    )(dec)\n    dec = tensorflow.keras.layers.Activation('relu')(dec)\n    dec = tensorflow.keras.layers.BatchNormalization(momentum=0.8)(dec)\n    dec = tensorflow.keras.layers.Conv2D(\n        3, kernel_size=3, padding='same'\n    )(dec)\nHere, we apply tanh activation function to get the colored output image -\n    color_image = tensorflow.keras.layers.Activation('tanh')(dec)\n    return black_n_white_input, color_image\n```", "```py\n# Build the and compile TF model\ndef build_and_compile_tf_model():\n    black_n_white_input, color_image = tf_model()\n    model = tensorflow.keras.models.Model(\n        inputs=black_n_white_input,\n        outputs=color_image\n    )\n    _optimizer = tensorflow.keras.optimizers.Adam(\n        learning_rate=0.0002,\n        beta_1=0.5\n    )\n    model.compile(\n        loss='mse',\n        optimizer=_optimizer\n    )\n    return model\n```", "```py\n# Train the model\nNUM_WORKERS = strategy.num_replicas_in_sync\n# Here the batch size scales up by number of workers since\n# `tf.data.Dataset.batch` expects the global batch size.\nGLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS\nMODEL_DIR = os.getenv(\"AIP_MODEL_DIR\")\ntrain_x, train_y, _, _, _, _ = make_datasets_unbatched()\nwith strategy.scope():\n    # Creation of dataset, and model building/compiling need to be within\n    # `strategy.scope()`.\n    model = build_and_compile_tf_model()\nmodel.fit(\n    train_x,\n    train_y,\n    epochs=args.epochs,\n    steps_per_epoch=args.steps\n)\nmodel.save(MODEL_DIR)\n```", "```py\njob = aiplatform.CustomTrainingJob(\n    display_name=JOB_NAME,\n    script_path=\"task.py\",\n    container_uri=TRAIN_IMAGE,\n    requirements=[],\n    model_serving_container_image_uri=DEPLOY_IMAGE,\n)\n```", "```py\nMODEL_DISPLAY_NAME = \"tf_bnw_to_color\"\n# Start the training job\nmodel = job.run(\n    model_display_name=MODEL_DISPLAY_NAME,\n    args=CMDARGS,\n    machine_type = \"n1-standard-16\",\n    replica_count=1,\n)\n```", "```py\n### Create a TensorBoard callback and write to the gcs path provided by AIP_TENSORBOARD_LOG_DIR\ntensorboard_callback = tf.keras.callbacks.TensorBoard(\n    log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'],\n    histogram_freq=1)\nmodel.fit(\n    train_x,\n    train_y,\n    epochs=args.epochs,\n    steps_per_epoch=args.steps,\n    callbacks=[tensorboard_callback],\n)\n```", "```py\nSERVICE_ACCOUNT=\"dummy-sa\"\nIS_COLAB=False\nif (\n    SERVICE_ACCOUNT == \"\"\n    or SERVICE_ACCOUNT is None\n    or SERVICE_ACCOUNT == \"dummy-sa\"\n):\n    # Get your service account from gcloud\n    if not IS_COLAB:\n        shell_output = ! gcloud auth list 2>/dev/null\n        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \\\n            \"\").strip()\n```", "```py\n    else:  # IS_COLAB:\n        shell_output = ! gcloud projects describe  $PROJECT_ID\n        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n    print(\"Service Account:\", SERVICE_ACCOUNT)\n```", "```py\nTENSORBOARD_NAME = \"training-monitoring\"  # @param {type:\"string\"}\nif (\n    TENSORBOARD_NAME == \"\"\n    or TENSORBOARD_NAME is None\n    or TENSORBOARD_NAME == \"training-monitoring\"\n):\n    TENSORBOARD_NAME = PROJECT_ID + \"-tb-\" + TIMESTAMP\ntensorboard = aiplatform.Tensorboard.create(\n    display_name=TENSORBOARD_NAME, project=PROJECT_ID, \\\n        location=REGION\n)\nLet's verify if the TensorBoard instance was successfully created or not - TENSORBOARD_RESOURCE_NAME = tensorboard.gca_resource.name\nprint(\"TensorBoard resource name:\", TENSORBOARD_RESOURCE_NAME)\n```", "```py\nBUCKET_URI = \"gs://tensorboard-staging\"  # @param {type:\"string\"}\nif BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n    BUCKET_URI = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP\n! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}\nGCS_BUCKET_OUTPUT = BUCKET_URI + \"/output/\"\n```", "```py\nJOB_NAME = \"tensorboard-example-job-{}\".format(TIMESTAMP)\nBASE_OUTPUT_DIR = \"{}{}\".format(GCS_BUCKET_OUTPUT, JOB_NAME)\njob = aiplatform.CustomTrainingJob(\n    display_name=JOB_NAME,\n    script_path=\"task2.py\",\n    container_uri=TRAIN_IMAGE,\n    requirements=[],\n    model_serving_container_image_uri=DEPLOY_IMAGE,\n    staging_bucket=BASE_OUTPUT_DIR,\n)\n```", "```py\nMODEL_DISPLAY_NAME = \"tf_bnw_to_color_tb\"\n# Start the training job\nmodel = job.run(\n    model_display_name=MODEL_DISPLAY_NAME,\n    service_account=SERVICE_ACCOUNT,\n    tensorboard=TENSORBOARD_RESOURCE_NAME,\n    args=CMDARGS,\n    machine_type = \"n1-standard-8\",\n    replica_count=1,\n)\n```", "```py\nfrom io import BytesIO\nimport numpy as np\nfrom tensorflow.python.lib.io import file_io\ndest = 'gs://data-bucket-417812395597/'\ntest_x = np.load(BytesIO(file_io.read_file_to_string(dest+'test_x',\\\n    binary_mode=True)))\ntest_y = np.load(BytesIO(file_io.read_file_to_string(dest+'test_y',\\\n    binary_mode=True)))\nprint(test_x.shape, test_y.shape)\n```", "```py\nimport json\nBATCH_PREDICTION_INSTANCES_FILE = \"batch_prediction_instances.jsonl\"\nBATCH_PREDICTION_GCS_SOURCE = (\n    BUCKET_URI + \"/batch_prediction_instances/\" + BATCH_PREDICTION_INSTANCES_FILE\n)\n```", "```py\n# converting to serializable format\nx_test = [(image).astype(np.float32).tolist() for image in test_x]\n# Write instances at JSONL\nwith open(BATCH_PREDICTION_INSTANCES_FILE, \"w\") as f:\n    for x in x_test:\n        f.write(json.dumps(x) + \"\\n\")\n# Upload to Cloud Storage bucket\n! gsutil cp batch_prediction_instances.jsonl BATCH_PREDICTION_GCS_SOURCE\nprint(\"Uploaded instances to: \", BATCH_PREDICTION_GCS_SOURCE)\n```", "```py\nMIN_NODES = 1\nMAX_NODES = 1\n# The name of the job\nBATCH_PREDICTION_JOB_NAME = \"bnw_to_color_batch_prediction\"\n# Folder in the bucket to write results to\nDESTINATION_FOLDER = \"batch_prediction_results\"\n# The Cloud Storage bucket to upload results to\nBATCH_PREDICTION_GCS_DEST_PREFIX = BUCKET_URI + \"/\" + DESTINATION_FOLDER\n```", "```py\n# Make SDK batch_predict method call\nbatch_prediction_job = model.batch_predict(\n    instances_format=\"jsonl\",\n    predictions_format=\"jsonl\",\n    job_display_name=BATCH_PREDICTION_JOB_NAME,\n    gcs_source=BATCH_PREDICTION_GCS_SOURCE,\n    gcs_destination_prefix = BATCH_PREDICTION_GCS_DEST_PREFIX,\n    model_parameters=None,\n    starting_replica_count=MIN_NODES,\n    max_replica_count=MAX_NODES,\n    machine_type=\"n1-standard-4\",\n    sync=True,\n)\n```"]