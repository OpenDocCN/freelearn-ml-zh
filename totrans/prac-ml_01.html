<html><head></head><body><div class="chapter" title="Chapter&#xA0;1.&#xA0;Introduction to Machine learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch01"/>Chapter 1. Introduction to Machine learning</h1></div></div></div><p>The goal of this chapter is to take you through the Machine learning landscape and lay out the basic concepts upfront for the chapters that follow. More importantly, the focus is to help you explore various learning strategies and take a deep dive into the different subfields of Machine learning. The techniques and algorithms under each subfield, and the overall architecture that forms the core for any Machine learning project implementation, are covered in depth.</p><p>There are many publications on Machine learning, and a lot of work has been done in past in this field. Further to the concepts of Machine learning, the focus will be primarily on specific practical implementation aspects through real-world examples. It is important that you already have a relatively high degree of knowledge in basic programming techniques and algorithmic paradigms; although for every programming section, the required primers are in place.</p><p>The following topics listed are covered in depth in this chapter:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Introduction to Machine learning</li><li class="listitem" style="list-style-type: disc">A basic definition and the usage context</li><li class="listitem" style="list-style-type: disc">The differences and similarities<a id="id0" class="indexterm"/> between Machine learning and data mining, <span class="strong"><strong>Artificial Intelligence</strong></span> (<span class="strong"><strong>AI</strong></span>), statistics, and data science</li><li class="listitem" style="list-style-type: disc">The relationship with big data</li><li class="listitem" style="list-style-type: disc">The terminology and mechanics: model, accuracy, data, features, complexity, and evaluation measures</li><li class="listitem" style="list-style-type: disc">Machine learning subfields: supervised learning, unsupervised learning, semi-supervised learning, reinforcement learning, and deep learning. Specific Machine learning techniques and algorithms are also covered under each of the machine learning subfields</li><li class="listitem" style="list-style-type: disc">Machine learning problem categories: Classification, Regression, Forecasting, and Optimization</li><li class="listitem" style="list-style-type: disc">Machine learning architecture, process lifecycle, and practical problems</li><li class="listitem" style="list-style-type: disc">Machine learning technologies, tools, and frameworks</li></ul></div><div class="section" title="Machine learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec08"/>Machine learning</h1></div></div></div><p>Machine learning has <a id="id1" class="indexterm"/>been around for many years now and all social media users, at some point in time, have been consumers of Machine learning technology. One of the common examples is face recognition software, which is the capability to identify whether a digital photograph includes a given person. Today, Facebook users can see automatic suggestions to tag their friends in the digital photographs that are uploaded. Some cameras and software such as iPhoto also have this capability. There are many examples and use cases that will be discussed in more detail later in this chapter.</p><p>The following concept map represents the key aspects and semantics of Machine learning that will be covered throughout this chapter:</p><div class="mediaobject"><img src="graphics/B03980_01_01.jpg" alt="Machine learning"/></div><div class="section" title="Definition"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec08"/>Definition</h2></div></div></div><p>Let's start with defining what Machine learning is. There are many technical and functional definitions<a id="id2" class="indexterm"/> for Machine learning, and some of them are as follows:</p><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p><span class="emphasis"><em>"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E."</em></span></p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top" style="text-align: center">--<span class="attribution"><span class="emphasis"><em>Tom M. Mitchell</em></span></span></td></tr></table></div><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p><span class="emphasis"><em>"Machine learning is the training of a model from data that generalizes a decision against a performance measure."</em></span></p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top" style="text-align: center">--<span class="attribution"><span class="emphasis"><em>Jason Brownlee</em></span></span></td></tr></table></div><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p><span class="emphasis"><em>"A branch of artificial intelligence in which a computer generates rules underlying or based on raw data that has been fed into it."</em></span></p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top" style="text-align: center">--<span class="attribution"><span class="emphasis"><em>Dictionary.com</em></span></span></td></tr></table></div><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p><span class="emphasis"><em>"Machine learning is a scientific discipline that is concerned with the design and development of algorithms that allow computers to evolve behaviors based on empirical data, such as from sensor data or databases."</em></span></p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top" style="text-align: center">--<span class="attribution"><span class="emphasis"><em>Wikipedia</em></span></span></td></tr></table></div><p>The preceding definitions are fascinating and relevant. They either have an algorithmic, statistical, or mathematical perspective.</p><p>Beyond these definitions, a single term or definition for Machine learning is the key to facilitating the definition of a problem-solving platform. Basically, it is <span class="emphasis"><em>a mechanism for pattern search</em></span> and building intelligence into a machine to be able to learn, implying that it will be able to do better in the future from its own experience.</p><p>Drilling down a little more into what a pattern <a id="id3" class="indexterm"/>typically is, pattern search or pattern recognition is <a id="id4" class="indexterm"/>essentially the study of how machines perceive the environment, learn to discriminate behavior of interest from the rest, and be able to take reasonable decisions about categorizing the behavior. This is more often performed by humans. The goal is to foster accuracy, speed, and avoid the possibility of inappropriate use of the system.</p><p>Machine learning<a id="id5" class="indexterm"/> algorithms that are constructed this way handle building intelligence. Essentially, machines make sense of data in much the same way that humans do.</p><p>The primary goal of a Machine learning implementation is to develop a general purpose algorithm that solves a practical and focused problem. Some of the aspects that are important and need to be considered in this process include data, time, and space requirements. Most importantly, with the ability to be applied to a broad class of learning problems, the goal of a learning algorithm is to produce a result that is a rule and is as accurate as possible.</p><p>Another important aspect is the big data context; that is, Machine learning methods are known to be effective even in cases where insights need to be uncovered from datasets that are large, diverse, and rapidly changing. More on the large scale data aspect of Machine learning will be covered in <a class="link" href="ch02.html" title="Chapter 2. Machine learning and Large-scale datasets">Chapter 2</a>, <span class="emphasis"><em>Machine Learning and Large-scale Datasets</em></span>.</p></div><div class="section" title="Core Concepts and Terminology"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec09"/>Core Concepts and Terminology</h2></div></div></div><p>At the heart of Machine learning is knowing and using the data appropriately. This includes collecting the <span class="emphasis"><em>right</em></span> data, cleansing the data, and processing the data using learning algorithms iteratively to build models using certain key features of data, and based on the hypotheses<a id="id6" class="indexterm"/> from these models, making predictions.</p><p>In this section, we will <a id="id7" class="indexterm"/>cover the standard nomenclature or terminology used in machine learning, starting from how to describe data, learning, modeling, algorithms, and specific machine learning tasks.</p></div><div class="section" title="What is learning?"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec10"/>What is learning?</h2></div></div></div><p>Now, let us look at the definition of "learning" in the context of Machine learning. In simple terms, historical data or observations are used to predict or derive actionable tasks. Very clearly, one mandate for an intelligent system is its ability to learn. The following are some considerations to define a learning problem:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Provide a definition of what the learner should learn and the need for learning.</li><li class="listitem" style="list-style-type: disc">Define the data requirements and the sources of the data.</li><li class="listitem" style="list-style-type: disc">Define if the learner should operate on the dataset in entirety or a subset will do.</li></ul></div><p>Before we plunge<a id="id10" class="indexterm"/> into understanding the internals of each learning type in the following sections, you need to understand the simple process that is followed to solve a learning problem, which involves building and validating models that solve a problem with maximum accuracy.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip02"/>Tip</h3><p>A model is nothing but an output from applying an algorithm to a dataset, and it is usually a representation of the data. We cover more on models in the later sections.</p></div></div><p>In general, for performing Machine learning, there are primarily two types of datasets required. The first dataset is usually manually prepared, where the input data and the expected output data are available and prepared. It is important that every piece of input data has an expected output data point available as this will be used in a supervised manner to build the rule. The second dataset is where we have the input data, and we are interested in predicting the expected output.</p><p>As a first step, the given data is segregated into three datasets: training, validation, and testing. There is no one hard rule on what percentage of data should be training, validation, and testing datasets. It can be 70-10-20, 60-30-10, 50-25-25, or any other values.</p><p>The training dataset refers to the data examples that are used to learn or build a classifier, for example. The validation dataset refers to the data examples that are verified against the built classifier and can help tune the accuracy of the output. The testing dataset refers to the data examples that help assess the performance of the classifier.</p><p>There are typically three phases for performing Machine learning:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Phase 1—Training Phase</strong></span>: This is the phase where training data is used to train the model by pairing<a id="id11" class="indexterm"/> the given input with the expected <a id="id12" class="indexterm"/>output. The output of this phase is the learning model itself.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Phase 2—Validation and Test Phase</strong></span>: This phase is to measure how good the learning model that has<a id="id13" class="indexterm"/> been trained is and estimate the model properties, such as error measures, recall, precision, and others. This phase uses a validation dataset, and the output is a sophisticated learning model.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Phase 3—Application Phase</strong></span>: In this <a id="id14" class="indexterm"/>phase, the model is subject to the real-world data for which the results need to be derived.</li></ul></div><p>The following figure depicts how<a id="id15" class="indexterm"/> learning can be applied to predict the behavior:</p><div class="mediaobject"><img src="graphics/B03980_01_02.jpg" alt="What is learning?"/></div><div class="section" title="Data"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec01"/>Data</h3></div></div></div><p>Data forms the main source of learning in Machine learning. The data that is being referenced here can be in any format, can be received at any frequency, and can be of any size. When it comes to handling large datasets in the Machine learning context, there are some new techniques<a id="id16" class="indexterm"/> that have evolved and are being experimented with. There are also more big data aspects, including parallel processing, distributed storage, and execution. More on the large-scale aspects of data will be covered in the next chapter, including some unique differentiators.</p><p>When we think of data, dimensions come to mind. To start with, we have rows and columns when it comes to structured and unstructured data. This book will cover handling both structured and unstructured data in the machine learning context. In this section, we will cover the terminology related to data within the Machine learning context.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Term</p>
</th><th style="text-align: left" valign="bottom">
<p>Purpose or meaning in the context of Machine learning</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Feature, attribute, field, or variable</p>
</td><td style="text-align: left" valign="top">
<p>This is a <a id="id17" class="indexterm"/>single column of data being referenced by the learning algorithms. Some features can<a id="id18" class="indexterm"/> be input to the learning<a id="id19" class="indexterm"/> algorithm, and some<a id="id20" class="indexterm"/> can be the outputs.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Instance</p>
</td><td style="text-align: left" valign="top">
<p>This is a<a id="id21" class="indexterm"/> single row of data in the dataset.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Feature vector or tuple</p>
</td><td style="text-align: left" valign="top">
<p>This is<a id="id22" class="indexterm"/> a list of features.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Dimension</p>
</td><td style="text-align: left" valign="top">
<p>This is a<a id="id23" class="indexterm"/> subset of attributes used to describe a property of data. For example, a date dimension consists of three attributes: day, month, and year.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Dataset</p>
</td><td style="text-align: left" valign="top">
<p>A collection<a id="id24" class="indexterm"/> of rows or instances is called a dataset. In the context of Machine learning, there are different types of datasets that are meant to be used for different purposes. An algorithm is run on different <a id="id25" class="indexterm"/>datasets at different stages to measure the accuracy of the model. There are three types of dataset: training, testing, and evaluation datasets. Any given comprehensive dataset is split into three categories of datasets and is usually in the following proportions: 60% training, 30% testing, and 10% evaluation.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>a. Training Dataset</p>
</td><td style="text-align: left" valign="top">
<p>The training dataset is the dataset that is the base dataset against which the model is built or trained.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>b. Testing Dataset</p>
</td><td style="text-align: left" valign="top">
<p>The testing<a id="id26" class="indexterm"/> dataset is the dataset that is used to validate the model built. This dataset is also referred to as a validating dataset.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>c. Evaluation Dataset</p>
</td><td style="text-align: left" valign="top">
<p>The evaluation dataset is the dataset that is used for final verification of the model (and can be treated more as user acceptance testing).</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Data Types</p>
</td><td style="text-align: left" valign="top">
<p>Attributes <a id="id27" class="indexterm"/>or features can have different data types. Some of the data types are listed here:</p>
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Categorical (for example: young, old).</li><li class="listitem" style="list-style-type: disc">Ordinal (for example: 0, 1).</li><li class="listitem" style="list-style-type: disc">Numeric (for example: 1.3, 2.1, 3.2, and so on).</li></ul></div>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Coverage</p>
</td><td style="text-align: left" valign="top">
<p>The<a id="id28" class="indexterm"/> percentage of a dataset for which a prediction is made or the model is covered. This determines the confidence of the prediction model.</p>
</td></tr></tbody></table></div></div><div class="section" title="Labeled and unlabeled data"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec02"/>Labeled and unlabeled data</h3></div></div></div><p>Data in the <a id="id29" class="indexterm"/>Machine learning context can either be labeled or unlabeled. Before we go deeper into the Machine learning basics, you need to understand this categorization, and what data is used when, as this terminology will be used throughout this book.</p><p>Unlabeled data is usually <a id="id30" class="indexterm"/>the raw form of the data. It consists of samples of natural or human-created artifacts. This category of data is easily available in abundance. For example, video streams, audio, photos, and tweets among others. This form of data usually has no explanation of the meaning attached.</p><p>The unlabeled data becomes labeled data the moment a meaning is attached. Here, we are talking about attaching a "tag" or "label" that is required, and is mandatory, to interpret and define the relevance. For example, labels for a photo can be the details of what it contains, such as animal, tree, college, and so on, or, in the context of an audio file, a political meeting, a farewell party, and so on. More often, the labels are mapped or defined by humans and are significantly more expensive to obtain than the unlabeled raw data.</p><p>The learning models can be applied to both labeled and unlabeled data. We can derive more accurate models using a combination of labeled and unlabeled datasets. The following diagram represents labeled and unlabeled data. Both triangles and bigger circles represent labeled data and small circles represent unlabeled data.</p><div class="mediaobject"><img src="graphics/B03980_01_03.jpg" alt="Labeled and unlabeled data"/></div><p>The application of labeled <a id="id31" class="indexterm"/>and unlabeled data is discussed in more detail in the following sections. You will see that supervised learning adopts labeled data and unsupervised learning adopts unlabeled data. Semi-supervised learning and deep<a id="id32" class="indexterm"/> learning techniques apply a combination of labeled and unlabeled data in a variety of ways to build accurate models.</p></div><div class="section" title="Tasks"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec03"/>Tasks</h3></div></div></div><p>A task is a problem<a id="id33" class="indexterm"/> that the Machine learning algorithm is built to solve. It is important that we measure the performance on a task. The term "performance" in this context is nothing but the extent or confidence with which the problem is solved. Different algorithms when run on different datasets produce a different model. It is important that the models thus generated are not compared, and instead, the consistency of the results with different datasets and different models is measured.</p></div><div class="section" title="Algorithms"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec04"/>Algorithms</h3></div></div></div><p>After getting a clear<a id="id34" class="indexterm"/> understanding of the Machine learning problem at hand, the focus is on what data and algorithms are relevant or applicable. There are several algorithms available. These algorithms are either grouped by the learning subfields (such as supervised, unsupervised, reinforcement, semi-supervised, or deep) or the problem categories (such as Classification, Regression, Clustering or Optimization). These algorithms are applied iteratively on different datasets, and output models that evolve with new data are captured.</p></div><div class="section" title="Models"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec05"/>Models</h3></div></div></div><p>Models are <a id="id35" class="indexterm"/>central to any Machine learning implementation. A model describes data that is observed in a system. Models are the output of algorithms applied to a dataset. In many cases, these models are applied to new datasets that help the<a id="id36" class="indexterm"/> models learn new behavior and also predict them. There is a vast range of machine learning algorithms that can be applied to a given problem. At a very high level, models are categorized as the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Logical models</li><li class="listitem" style="list-style-type: disc">Geometric models</li><li class="listitem" style="list-style-type: disc">Probabilistic models</li></ul></div><div class="section" title="Logical models"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec01"/>Logical models</h4></div></div></div><p>Logical models are more algorithmic in nature and help us derive a set of rules by running the algorithms iteratively. A Decision <a id="id37" class="indexterm"/>tree is one such example:</p><div class="mediaobject"><img src="graphics/B03980_01_04.jpg" alt="Logical models"/></div></div><div class="section" title="Geometric models"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec02"/>Geometric models</h4></div></div></div><p>Geometric <a id="id38" class="indexterm"/>models use geometric concepts such as lines, planes, and distances. These models usually operate, or can operate, on high volumes of data. Usually, linear transformations help compare different Machine learning methods:</p><div class="mediaobject"><img src="graphics/B03980_01_05.jpg" alt="Geometric models"/></div></div><div class="section" title="Probabilistic models"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec03"/>Probabilistic models</h4></div></div></div><p>Probabilistic models are statistical models that employ statistical techniques. These models are based <a id="id39" class="indexterm"/>on a strategy that defines the relationship between two variables. This relationship can be derived for sure as this involves using a random background process. In most cases, a subset of the overall data can be considered for processing:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Viagra</p>
</th><th style="text-align: left" valign="bottom">
<p>Lottery</p>
</th><th style="text-align: left" valign="bottom">
<p>P(Y= Spam (Viagra, lottery))</p>
</th><th style="text-align: left" valign="bottom">
<p>P(Y= ham (Viagra, lottery))</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>0</p>
</td><td style="text-align: left" valign="top">
<p> 0</p>
</td><td style="text-align: left" valign="top">
<p> 0.31</p>
</td><td style="text-align: left" valign="top">
<p>0.69</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>0</p>
</td><td style="text-align: left" valign="top">
<p> 1</p>
</td><td style="text-align: left" valign="top">
<p> 0.65</p>
</td><td style="text-align: left" valign="top">
<p>0.35</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top">
<p> 0</p>
</td><td style="text-align: left" valign="top">
<p> 0.80</p>
</td><td style="text-align: left" valign="top">
<p>0.20</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top">
<p> 1</p>
</td><td style="text-align: left" valign="top">
<p> 0.40</p>
</td><td style="text-align: left" valign="top">
<p>0.60</p>
</td></tr></tbody></table></div></div></div></div><div class="section" title="Data and inconsistencies in Machine learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec11"/>Data and inconsistencies in Machine learning</h2></div></div></div><p>This section details all the possible data inconsistencies that may be encountered while implementing <a id="id40" class="indexterm"/>Machine learning projects, such as:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Under-fitting</li><li class="listitem" style="list-style-type: disc">Over-fitting</li><li class="listitem" style="list-style-type: disc">Data instability</li><li class="listitem" style="list-style-type: disc">Unpredictable future</li></ul></div><p>Fortunately, there are some established processes in place today to address these inconsistencies. The following sections cover these inconsistencies.</p><div class="section" title="Under-fitting"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec06"/>Under-fitting</h3></div></div></div><p>A model is said to be <a id="id41" class="indexterm"/>under-fitting when it doesn't take into consideration enough information to accurately model the actual data. For example, if only two points on an exponential curve are mapped, this possibly becomes a linear representation, but there could be a case where a pattern does not exist. In cases like these, we will see increasing errors and subsequently an inaccurate model. Also, in cases where the classifier is too rigid or is not complex enough, under-fitting is caused not just due to a lack of data, but can also be a result of incorrect modeling. For example, if the two classes form concentric circles and we try to fit a linear model, assuming they were linearly separable, this could potentially result in under-fitting.</p><p>The accuracy of the model is determined by a measure called "power" in the statistical world. If the dataset size is too small, we can never target an optimal solution.</p></div><div class="section" title="Over-fitting"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec07"/>Over-fitting</h3></div></div></div><p>This case is just the opposite of the under-fitting case explained before. While too small a sample is not appropriate to define an optimal solution, a large dataset also runs the risk of having the model over-fit the data. Over-fitting usually occurs when the statistical model describes noise instead of describing the relationships. Elaborating on the preceding example in this context, let's say we have 500,000 data points. If the model ends up catering to accommodate all 500,000 data points, this becomes over-fitting. This will in effect mean<a id="id42" class="indexterm"/> that the model is memorizing the data. This model works well as long as the dataset does not have points outside the curve. A model that is over-fit demonstrates poor performance as minor fluctuations in data tend to be exaggerated. The primary reason for over-fitting also could be that the criterion used to train the model is different from the criterion used to judge the efficacy of the model. In simple terms, if the model memorizes the training data rather than learning, this situation is seen to occur more often.</p><p>Now, in the process of mitigating the problem of under-fitting the data, by giving it more data, this can in itself be a risk and end up in over-fitting. Considering that more data can mean more complexity and noise, we could potentially end up with a solution model that fits the current data at hand and nothing else, which makes it unusable. In the following graph, with the increasing model complexity and errors, the conditions for over-fit and under-fit are pointed out:</p><div class="mediaobject"><img src="graphics/B03980_01_06.jpg" alt="Over-fitting"/></div></div><div class="section" title="Data instability"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec08"/>Data instability</h3></div></div></div><p>Machine learning <a id="id43" class="indexterm"/>algorithms are usually robust to noise within the data. A problem will occur if the outliers are due to manual error or misinterpretation of the relevant data. This will result in a skewing of the data, which will ultimately end up in an incorrect model.</p><p>Therefore, there is a strong need to have a process to correct or handle human errors that can result in building an incorrect model.</p></div><div class="section" title="Unpredictable data formats"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec09"/>Unpredictable data formats</h3></div></div></div><p>Machine learning is <a id="id44" class="indexterm"/>meant to work with new data constantly coming into the system and learning from that data. Complexity will creep in when the new data entering the system comes in formats that are not supported by the machine learning system. It is now difficult to say if our models work well for the new data given the instability in the formats that we receive the data, unless there<a id="id45" class="indexterm"/> is a mechanism built to handle this.</p></div></div><div class="section" title="Practical Machine learning examples"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec12"/>Practical Machine learning examples</h2></div></div></div><p>In this section, let's explore some real-world machine learning applications. We covered various examples <a id="id46" class="indexterm"/>within the introductory section of this chapter and we will now cover some domain-specific examples with a brief description of each problem.</p><p>For online and offline applications, some of the following examples can easily be guessed. In the chapters to follow, a subset of these examples will be picked to demonstrate the practical implementation aspects using suitable Machine learning algorithms.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Problem / problem Domain</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Spam detection</p>
</td><td style="text-align: left" valign="top">
<p>The problem <a id="id47" class="indexterm"/>statement here is to identify which e-mails are "spam". A Machine learning algorithm can categorize an e-mail to be marked as spam based on some rules that it builds using some key features of e-mail data. Once an e-mail is marked as spam, that e-mail is then moved to the spam folder and the rest are left in the inbox.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Credit card fraud detection</p>
</td><td style="text-align: left" valign="top">
<p>This is <a id="id48" class="indexterm"/>one of the recent problems that credit card firms need a solution for. Based on the usage patterns of the credit card by the consumer and the purchase behavior of the customer, the need is to identify any transaction that is not potentially made by the customer and mark them as fraudulent for necessary action to be taken.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Digit recognition</p>
</td><td style="text-align: left" valign="top">
<p>This is a<a id="id49" class="indexterm"/> very simple use case that requires the ability to group posts based on the zip code. This includes the need to interpret a handwritten numeric accurately and bucket the posts based on the zip code for faster processing.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Speech recognition</p>
</td><td style="text-align: left" valign="top">
<p>Automated call<a id="id50" class="indexterm"/> centers need this capability where a user's request on the phone is interpreted and mapped to one of the tasks for execution. The moment the user request can be mapped to a task, its execution can be automated. A model of this problem will allow a program to understand and make an attempt to fulfill that request. The iPhone with Siri has this capability.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Face detection</p>
</td><td style="text-align: left" valign="top">
<p>This is one <a id="id51" class="indexterm"/>of the key features that today's social media websites provide. This feature provides an ability to tag a person across many digital photographs. This gives aptitude to a group or categorizes the photographs by a person. Some cameras and software such as iPhoto have this capability.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Product recommendation or customer segmentation</p>
</td><td style="text-align: left" valign="top">
<p>This<a id="id52" class="indexterm"/> capability is found in almost all of the top online shopping websites today. Given a purchase history for a customer and a large inventory of products, the idea is to identify those products<a id="id53" class="indexterm"/> that the customer will most likely be interested in buying, thus motivating more product<a id="id54" class="indexterm"/> purchases. There are many online shopping and social websites that support this feature (for example: Amazon, Facebook, Google+, and many others).</p>
<p>There are other cases like the ability to predict whether a trial version customer opts for the paid version of the product.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Stock trading</p>
</td><td style="text-align: left" valign="top">
<p>This means <a id="id55" class="indexterm"/>predicting stock performance based on the current past stock movement. This task is critical to financial analysts and helps provide decision support when buying <a id="id56" class="indexterm"/>and selling stocks.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Sentiment analysis</p>
</td><td style="text-align: left" valign="top">
<p>Many<a id="id57" class="indexterm"/> times, we find that the customers make decisions based on opinions shared by others. For example, we buy a product because it has received positive feedback from the majority of its users. Not only in commercial businesses as detailed earlier, but sentiment analysis is also being used by political strategists to gauge public opinion on policy announcements or campaign messages.</p>
</td></tr></tbody></table></div></div><div class="section" title="Types of learning problems"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec13"/>Types of learning problems</h2></div></div></div><p>This section focuses on elaborating different learning problem categories. Machine learning algorithms <a id="id58" class="indexterm"/>are also <a id="id59" class="indexterm"/>classified under these learning problems. The following figure depicts various types of learning problems:</p><div class="mediaobject"><img src="graphics/B03980_01_07.jpg" alt="Types of learning problems"/></div><div class="section" title="Classification"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec10"/>Classification</h3></div></div></div><p>Classification is a way to identify a grouping technique for a given dataset in such a way that depending on <a id="id60" class="indexterm"/>a value of the target or output attribute, the entire dataset can be qualified to belong to a class. This technique helps in identifying the data behavior patterns. This is, in short, a discrimination mechanism.</p><p>For example, a sales manager needs help in identifying a prospective customer and wants to determine whether it is worth spending the effort and time the customer demands. The key input for the manager is the customer's data, and this case is commonly referred to as<a id="id61" class="indexterm"/> <span class="strong"><strong>Total Lifetime Value</strong></span> (<span class="strong"><strong>TLV</strong></span>).</p><p>We take the data and start plotting blindly on a graph (as shown in the following graph) with the <span class="emphasis"><em>x</em></span> axis representing the total items purchased and the <span class="emphasis"><em>y</em></span> axis representing the total money spent (in multiples of hundreds of dollars). Now we define the criteria to determine, for example, whether a customer is good or bad. In the following graph, all the customers who spend more than 800 dollars in a single purchase are categorized as good customers (note that this is a hypothetical example or analysis).</p><div class="mediaobject"><img src="graphics/B03980_01_08.jpg" alt="Classification"/></div><p>Now when new<a id="id62" class="indexterm"/> customer data comes in, the sales manager can plot the new customers on this graph and based on which side they fall, predict whether the customer is likely to be good or bad.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip03"/>Tip</h3><p>Note that classification need not always be binary (yes or no, male or female, good or bad, and so on) and any number of classifications can be defined (poor, below average, average, above average, good) based on the problem definition.</p></div></div></div><div class="section" title="Clustering"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec11"/>Clustering</h3></div></div></div><p>In many cases, the <a id="id63" class="indexterm"/>data analyst is just given some data and is expected to unearth interesting patterns that may help derive intelligence. The main difference between this task and that of a classification is that in the classification problem, the business user specifies what he/she is looking for (a good customer or a bad customer, a success or a failure, and so on).</p><p>Let's now expand on the same example considered in the classification section. Here the patterns to classify the customers are identified without any target in mind or any prior classification, and unlike running a classification, the results may always not be the same (for example, depending on how the initial centroids are picked). An example modeling method for clustering is k-means clustering. More details on k-means clustering is covered in the<a id="id64" class="indexterm"/> next section and in detail in the following chapters.</p><p>In short, clustering is a classification analysis that does not start with a specific target in mind (good/bad, will buy/will not buy).</p></div><div class="section" title="Forecasting, prediction or regression"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec12"/>Forecasting, prediction or regression</h3></div></div></div><p>Similar to classification, forecasting or prediction is also about identifying the way things would happen in<a id="id65" class="indexterm"/> the future. This information is derived from past experience or knowledge. In some cases, there is not enough data, and there is a need to define the future through regression. Forecasting and prediction results are always<a id="id66" class="indexterm"/> presented along with the degree of uncertainty or probability. This classification of the problem type is also <a id="id67" class="indexterm"/>called <span class="strong"><strong>rule extraction</strong></span>.</p><p>Let's take an example<a id="id68" class="indexterm"/> here, an agricultural scientist working on a new crop that she developed. As a trial, this seed was planted at various altitudes and the yield was computed. The requirement here is to predict the yield of the crop given the altitude details (and some more related data points). The relationship between yield gained and the altitude is determined by plotting a graph between the parameters. An equation is noted that fits most of the data points, and in cases where data does not fit the curve, we can get rid of the data. This technique is called regression.</p><div class="mediaobject"><img src="graphics/B03980_01_09.jpg" alt="Forecasting, prediction or regression"/></div></div><div class="section" title="Simulation"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec13"/>Simulation</h3></div></div></div><p>In addition to all the techniques we defined until now, there might be situations where the data in context itself has many uncertainty. For example, an outsourcing manager is given a task and can estimate with experience that the task can be done by an identified team with certain<a id="id69" class="indexterm"/> skills in 2-4 hours.</p><p>Let's say the cost of input material may vary between $100-120 and the number of employees who come to work on any given day may be between 6 and 9. An analyst then estimates how much time the project might take. Solving such problems requires the simulation of a vast amount of alternatives.</p><p>Typically in forecasting, classification, and unsupervised learning, we are given data and we really do not know how the data is interconnected. There is no equation to describe one variable as a function of others.</p><p>Essentially, data scientists combine one or more of the preceding techniques to solve challenging problems, which are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Web search and information extraction</li><li class="listitem" style="list-style-type: disc">Drug design</li><li class="listitem" style="list-style-type: disc">Predicting capital market behavior</li><li class="listitem" style="list-style-type: disc">Understanding<a id="id70" class="indexterm"/> customer behavior</li><li class="listitem" style="list-style-type: disc">Designing robots</li></ul></div></div><div class="section" title="Optimization"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec14"/>Optimization</h3></div></div></div><p>Optimization, in simple terms, is a mechanism to make something better or define a context for a solution that makes it the best.</p><p>Considering a production <a id="id71" class="indexterm"/>scenario, let's assume there are two machines that produce the desired product but one machine requires more energy for high speed in production and lower raw materials while the other requires higher raw materials and less energy to produce the same output in the same time. It is important to understand the patterns in the output based on the variation in inputs; a combination that gives the highest profits would probably be the one the production manager would want to know. You, as an analyst, need to identify the best possible way to distribute the production between the machines that gives him the highest profit.</p><p>The following image shows the point of highest profit when a graph was plotted for various distribution options between the two machines. Identifying this point is the goal of this technique.</p><div class="mediaobject"><img src="graphics/B03980_01_10.jpg" alt="Optimization"/></div><p>Unlike the case<a id="id72" class="indexterm"/> of simulations where there is uncertainty associated with the input data, in optimization we not only have access to data, but also have the information on the dependencies and relationships between data attributes.</p><p>One of the key concepts in Machine learning is a process<a id="id73" class="indexterm"/> called <span class="strong"><strong>induction</strong></span>. The following learning subfields use the induction process to build models. Inductive learning is a reasoning process that uses the results of one experiment to run the next set of experiments and iteratively evolve a model from specific information.</p><p>The following figure <a id="id74" class="indexterm"/>depicts various subfields of Machine learning. These subfields are one of the ways the machine learning algorithms are classified.</p><div class="mediaobject"><img src="graphics/B03980_01_11.jpg" alt="Optimization"/></div></div><div class="section" title="Supervised learning"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec15"/>Supervised learning</h3></div></div></div><p>Supervised learning is all about operating to a known expectation and in this case, what needs to be analyzed from the data being defined. The input datasets in this context are also referred to as "labeled" datasets. Algorithms classified under this category focus on establishing a<a id="id75" class="indexterm"/> relationship between the input and output attributes, and use this relationship speculatively to generate an output for new input data points. In the preceding section, the example defined for the classification problem is also an example of supervised learning. Labeled data helps build reliable models but is usually expensive and limited.</p><p>When the input and output attributes of the data are known, the key in supervised learning is the mapping between the inputs to outputs. There are quite a few examples of these mappings, but the complicated function that links up the input and output attributes is not known. A supervised learning algorithm takes care of this linking, and given a large dataset of input/output pairs, these functions help predict the output for any new input value.</p></div><div class="section" title="Unsupervised learning"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec16"/>Unsupervised learning</h3></div></div></div><p>In some of the learning<a id="id76" class="indexterm"/> problems, we do not have any specific target in mind to solve. In the earlier section, we discussed clustering, which is a classification analyses where we do not start with a specific target in mind (good/bad, will buy/will not buy) and is hence referred to as unsupervised analyses or learning. The goal in this case is to decipher the structure in the data against the build mapping between input and output attributes of data and, in fact, the output attributes are not defined. These learning algorithms operate on an "unlabeled" dataset for this reason.</p></div><div class="section" title="Semi-supervised learning"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec17"/>Semi-supervised learning</h3></div></div></div><p>Semi-supervised learning<a id="id77" class="indexterm"/> is about using both labeled and unlabeled data to learn models better. It is important that there are appropriate assumptions for the unlabeled data and any inappropriate assumptions can invalidate the model. Semi-supervised learning gets its motivation from the human way of learning.</p></div><div class="section" title="Reinforcement learning"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec18"/>Reinforcement learning</h3></div></div></div><p>Reinforcement learning<a id="id78" class="indexterm"/> is learning that focuses on maximizing the rewards from the result. For example, while teaching toddlers new habits, rewarding them every time they follow instructions works very well. In fact, they figure out what behavior helps them earn rewards. This is reinforcement learning, and it is also called credit assessment learning.</p><p>The most important thing is that in reinforcement learning the model is additionally responsible for making decisions for which a periodic reward is received. The results in this case, unlike supervised learning, are not immediate and may require a sequence of steps to be executed before the final result is seen. Ideally, the algorithm will generate a sequence of decisions that helps achieve the highest reward or utility.</p><p>The goal in this<a id="id79" class="indexterm"/> learning technique is to measure the trade-offs effectively by exploring and exploiting the data. For example, when a person has to travel from a point A to point B, there will be many ways that include travelling by air, water, road or by walking, and there is significant value in considering this data by measuring the trade-offs for each of these options. Another important aspect is the significance of a delay in the rewards. How would this affect learning? For example, in games like chess, any delay in reward identification may change the result.</p></div><div class="section" title="Deep learning"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec19"/>Deep learning</h3></div></div></div><p>Deep learning is an area of <a id="id80" class="indexterm"/>Machine learning that focuses on unifying Machine learning with artificial intelligence. In terms of the relationship with artificial neural networks, this field is more of an advancement to artificial neural networks that work on large amounts of common data to derive practical insights. It deals with building more complex neural networks to solve problems classified under semi-supervised learning and operates on datasets that have little labeled data. Some Deep learning techniques are listed as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Convolutional <a id="id81" class="indexterm"/>Networks</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Restricted Boltzmann </strong></span><a id="id82" class="indexterm"/><span class="strong"><strong>Machine</strong></span> (<span class="strong"><strong>RBM</strong></span>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Deep Belief </strong></span><a id="id83" class="indexterm"/><span class="strong"><strong>Networks</strong></span> (<span class="strong"><strong>DBN</strong></span>)</li><li class="listitem" style="list-style-type: disc">Stacked<a id="id84" class="indexterm"/> Autoencoders</li></ul></div></div></div></div></div>
<div class="section" title="Performance measures"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec09"/>Performance measures</h1></div></div></div><p>Performance measures are used to <a id="id85" class="indexterm"/>evaluate learning algorithms and form an important aspect of machine learning. In some cases, these measures are also used as heuristics to build learning models.</p><p>Now let's explore the concept <a id="id86" class="indexterm"/>of the <span class="strong"><strong>Probably Approximately Correct </strong></span>(<span class="strong"><strong>PAC</strong></span>) theory. While we describe the accuracy of hypothesis, we usually talk about two types of uncertainties as per<a id="id87" class="indexterm"/> the PAC theory:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Approximate</strong></span>: This measures<a id="id88" class="indexterm"/> the extent to which an error is accepted for a hypothesis</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Probability</strong></span>: This measure is the <a id="id89" class="indexterm"/>percentage certainty of the hypothesis being correct</li></ul></div><p>The following graph shows how the number of samples grow with error, probability, and hypothesis:</p><div class="mediaobject"><img src="graphics/B03980_01_12.jpg" alt="Performance measures"/></div><div class="section" title="Is the solution good?"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec14"/>Is the solution good?</h2></div></div></div><p>The error measures for a classification and prediction problem are different. In this section, we will cover some<a id="id90" class="indexterm"/> of these error measures followed by how they can be addressed.</p><p>In a classification problem, you can have two different types of errors, which can be elegantly represented using the "confusion matrix". Let's say in our target marketing problem, we work on 10,000 customer records to predict which customers are likely to respond to our marketing effort.</p><p>After analyzing<a id="id91" class="indexterm"/> the campaign, you can construct the following table, where the columns are your predictions and the rows are the real observations:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Action</p>
</th><th style="text-align: left" valign="bottom">
<p>Predicted (that there will be a buy)</p>
</th><th style="text-align: left" valign="bottom">
<p>Predicted (that there will be no buy)</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Actually bought</p>
</td><td style="text-align: left" valign="top">
<p> TP: 500</p>
</td><td style="text-align: left" valign="top">
<p>FN: 400</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Actually did not buy</p>
</td><td style="text-align: left" valign="top">
<p> FP: 100</p>
</td><td style="text-align: left" valign="top">
<p>TN: 9000</p>
</td></tr></tbody></table></div><p>In the principal diagonal, we have buyers and non-buyers for whom the prediction matched with reality. These are correct predictions. They are called true positive and true negative respectively. In the upper right-hand side, we have those who we predicted are non-buyers, but in reality are buyers. This is an error known as a false negative error. In the lower left-hand side, we have those we predicted as buyers, but are non-buyers. This is another error known as false positive.</p><p>Are both errors equally expensive for the customers? Actually no! If we predict that someone is a buyer and they turn out to be a non-buyer, the company at most would have lost money spent on a mail or a call. However, if we predicted that someone would not buy and they were in fact buyers, the company would not have called them based on this prediction and lost a customer. So, in this case, a false negative is much more expensive than a false positive error.</p><p>The Machine learning community uses three different error measures for classification problems:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Measure 1: Accuracy</strong></span> is the percent <a id="id92" class="indexterm"/>of predictions that were correct.<p>Example: The "accuracy" was (9,000+500) out of 10,000 = 95%</p></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Measure 2: Recall</strong></span> is the percent<a id="id93" class="indexterm"/> of positives cases that you were able to catch. If false positives are low, recall will be high.<p>Example: The "recall" was 500 out of 600 = 83.33%</p></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Measure 3: Precision</strong></span> is the percent of positive predictions that were correct. If false negatives are<a id="id94" class="indexterm"/> low, precision is high.<p>Example: The "precision" was 500 out of 900 = 55.55%</p></li></ul></div><p>In forecasting, you are predicting a continuous variable. So, the error measures are fairly different here. As usual, the error metrics are obtained by comparing the predictions of the models with the real values of the target variables and calculating the average error. Here are a few metrics.</p><div class="section" title="Mean squared error (MSE)"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec20"/>Mean squared error (MSE)</h3></div></div></div><p>To compute the MSE, we <a id="id95" class="indexterm"/>first take the square of the <a id="id96" class="indexterm"/>difference between the actual and predicted values of every record. We then take the average value of these squared errors. If the predicted value of the <span class="emphasis"><em>i<sup>th</sup></em></span> record is <span class="emphasis"><em>Pi</em></span> and the actual value is <span class="emphasis"><em>Ai</em></span>, then the MSE is:</p><div class="mediaobject"><img src="graphics/B03980_01_18.jpg" alt="Mean squared error (MSE)"/></div><p>It is also common to use the square root of this quantity <a id="id97" class="indexterm"/>called <span class="strong"><strong>root mean square error</strong></span> (<span class="strong"><strong>RMSE</strong></span>).</p></div><div class="section" title="Mean absolute error (MAE)"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec21"/>Mean absolute error (MAE)</h3></div></div></div><p>To compute the MAE, we take the absolute difference between the predicted and actual values of every record. We<a id="id98" class="indexterm"/> then take the <a id="id99" class="indexterm"/>average of those absolute differences. The choice of performance metric depends on the application. The MSE is a good performance metric for many applications as it has more statistical grounding with variance. On the other hand, the MAE is more intuitive and less sensitive to outliers. Looking at the MAE and RMSE gives us additional information about the distribution of the errors. In <a id="id100" class="indexterm"/>regression, if the RMSE is close to the MAE, the model makes many relatively small errors. If the RMSE is close to the MAE2, the model <a id="id101" class="indexterm"/>makes a few but large errors.</p><div class="mediaobject"><img src="graphics/B03980_01_19.jpg" alt="Mean absolute error (MAE)"/></div></div><div class="section" title="Normalized MSE and MAE (NMSE and NMAE)"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec22"/>Normalized MSE and MAE (NMSE and NMAE)</h3></div></div></div><p>Both the MSE <a id="id102" class="indexterm"/>and MAE do not indicate how big<a id="id103" class="indexterm"/> the error is as they are numeric values depending on the scale of the target variable. Comparing with a<a id="id104" class="indexterm"/> benchmarking index provides a better insight. The common practice is to take the mean of the<a id="id105" class="indexterm"/> primary attribute we are predicting and assume that our naïve prediction model is just the mean. Then we compute the MSE based on the naïve model and the original model. The ratio provides an insight into how good or bad our model is compared to the naïve model.</p><div class="mediaobject"><img src="graphics/B03980_01_20.jpg" alt="Normalized MSE and MAE (NMSE and NMAE)"/></div><p>A similar definition can also be used for the MAE.</p></div><div class="section" title="Solving the errors: bias and variance"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec23"/>Solving the errors: bias and variance</h3></div></div></div><p>This trap of building highly customized higher order models is called over-fitting and is a critical concept. The resulting error is<a id="id106" class="indexterm"/> known as the <span class="strong"><strong>variance</strong></span> of <a id="id107" class="indexterm"/>the model. Essentially, if we had taken a different training set, we would have obtained a very different model. Variance is a measure of the dependency of model on the training <a id="id108" class="indexterm"/>set. By the way, the model you see on the right most side (linear fit) is called under-fitting and the error caused due to under-fitting is called bias. In an under-fitting or high bias situation, the model does not explain the relationship between the data. Essentially, we're trying to fit an overly <a id="id109" class="indexterm"/>simplistic hypothesis, for example, linear where we should be looking for a higher order polynomial.</p><p>To avoid the trap of over-fitting and under-fitting, data scientists build the model on a training set and then find the error on a test set. They refine the model until the error in the test set comes down. As the model starts getting customized to the training data, the error on the test set starts going up. They stop refining the model after that point.</p><p>Let's analyze bias<a id="id110" class="indexterm"/> and variance a bit more in this chapter and learn a few <a id="id111" class="indexterm"/>practical ways of dealing with them. The error in any model can be represented as a combination of bias, variance, and random error. With <span class="emphasis"><em>Err(x)=Bias2+Variance+Irreducible Error</em></span> in less complex models, the bias term is high, and in models with higher complexity, the variance term is high, as shown in the following figure:</p><div class="mediaobject"><img src="graphics/B03980_01_13.jpg" alt="Solving the errors: bias and variance"/></div><p>To reduce bias or variance, let's first ask this question. If a model has a high bias, how does its error vary as a function of the amount of data?</p><p>At a very low data size, any model can fit the data well (any model fits a single point, any linear model can fit two points, a quadratic can fit three points, and so on). So, the error of a high bias model on a training set starts minuscule and goes up with increasing data points. However, on the test set, the error remains high initially as the model is highly customized to the training set. As the model gets more and more refined, the error reduces and becomes <a id="id112" class="indexterm"/>equal to that of the training set.</p><p> The following graph <a id="id113" class="indexterm"/>depicts the situation clearly:</p><div class="mediaobject"><img src="graphics/B03980_01_14.jpg" alt="Solving the errors: bias and variance"/></div><p>The remedy for this situation could be one of the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Most likely, you are working with very few features, so you must find more features</li><li class="listitem" style="list-style-type: disc">Increase the complexity of the model by increasing polynomials and depth</li><li class="listitem" style="list-style-type: disc">Increasing the data size will not be of much help if the model has a high bias</li></ul></div><div class="mediaobject"><img src="graphics/B03980_01_15.jpg" alt="Solving the errors: bias and variance"/></div><p>When you face<a id="id114" class="indexterm"/> such situations, you can try the following<a id="id115" class="indexterm"/> remedies (the reverse of the previous ones):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Most likely, you are working with too many features, so, you must reduce the features</li><li class="listitem" style="list-style-type: disc">Decrease the complexity of the model</li><li class="listitem" style="list-style-type: disc">Increasing the data size will be some help</li></ul></div></div></div></div>
<div class="section" title="Some complementing fields of Machine learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec10"/>Some complementing fields of Machine learning</h1></div></div></div><p>Machine learning<a id="id116" class="indexterm"/> has a close relationship to many<a id="id117" class="indexterm"/> related fields including artificial intelligence, data mining, statistics, data science, and others listed shortly. In fact, Machine learning is in that way a multi-disciplinary field, and in some ways is linked to all of these fields.</p><p>In this section, we will define some of these fields, draw parallels to how they correlate to Machine learning, and understand the similarities and dissimilarities, if any. Overall, we will start with the core Machine learning definition as a field of science that includes developing self-learning algorithms. Most of the fields we are going to discuss now either use machine learning<a id="id118" class="indexterm"/> techniques or a superset or subset of machine learning techniques.</p><div class="section" title="Data mining"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec15"/>Data mining</h2></div></div></div><p>Data mining is a process <a id="id119" class="indexterm"/>of analyzing data and deriving insights from a (large) dataset by applying business rules to it. The focus here is on the data and the domain of the data. Machine learning techniques are adopted in the process of identifying which rules are relevant and which aren't.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th colspan="3" style="text-align: center" valign="bottom">
<p>Machine learning versus Data mining</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Similarities with Machine learning</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Dissimilarities with Machine learning</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Relationship with Machine learning</strong></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Both Machine learning and data mining look at data with the goal of extracting value from it.</p>
<p>Most of the tools used for Machine learning and data mining are common. For example, R and Weka among others.</p>
</td><td style="text-align: left" valign="top">
<p>While <a id="id120" class="indexterm"/>Machine learning focuses on using known knowledge or experience, data mining focuses on discovering unknown knowledge, like the existence of a specific structure<a id="id121" class="indexterm"/> in data that will be of help in analyzing the data.</p>
<p>Intelligence derived is meant to be consumed by machines in Machine learning compared to data mining where the target consumers are humans.</p>
</td><td style="text-align: left" valign="top">
<p>The fields of Machine learning and data mining are intertwined, and there is a significant overlap in the underlying principles and methodologies.</p>
</td></tr></tbody></table></div></div><div class="section" title="Artificial intelligence (AI)"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec16"/>Artificial intelligence (AI)</h2></div></div></div><p>Artificial intelligence focuses on building systems that can mimic human behavior. It has been around for a while now and the modern AI has been continuously evolving, now includes specialized data<a id="id122" class="indexterm"/> requirements. Among many other capabilities, AI should demonstrate the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Knowledge storage and representation to hold all the data that is subject to interrogation and investigation</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Natural Language Processing</strong></span> (<span class="strong"><strong>NLP</strong></span>) capabilities to be able to process text</li><li class="listitem" style="list-style-type: disc">Reasoning capabilities to be able to answer questions and facilitate conclusions</li><li class="listitem" style="list-style-type: disc">The ability to plan, schedule, and automate</li><li class="listitem" style="list-style-type: disc">Machine learning to be able to build self-learning algorithms</li><li class="listitem" style="list-style-type: disc">Robotics and more</li></ul></div><p>Machine learning is a subfield of artificial intelligence.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th colspan="3" style="text-align: center" valign="bottom">
<p>Machine learning versus Artificial Intelligence</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Similarities with Machine learning</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Dissimilarities with Machine learning</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Relationship with Machine learning</strong></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Both machine learning and artificial intelligence employ learning algorithms and focus on automation <a id="id123" class="indexterm"/>when reasoning or decision-making.</p>
</td><td style="text-align: left" valign="top">
<p>Though Machine learning is considered to be in the AI's range<a id="id124" class="indexterm"/> of interests, Machine learning's primary focus is to improve on a machine's performance of a task, and the experience built need not always be human behavior. In the case of artificial intelligence, human inspired algorithms are employed.</p>
</td><td style="text-align: left" valign="top">
<p>Machine learning is often considered as a subfield of artificial intelligence.</p>
</td></tr></tbody></table></div></div><div class="section" title="Statistical learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec17"/>Statistical learning</h2></div></div></div><p>In statistical learning, the predictive functions are arrived at and primarily derived from samples of data. It is of <a id="id125" class="indexterm"/>great importance how the data is collected, cleansed, and managed in this process. Statistics is<a id="id126" class="indexterm"/> pretty close to mathematics, as it is about quantifying data and operating on numbers.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th colspan="3" style="text-align: center" valign="bottom">
<p>Machine learning versus Statistical learning</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Similarities with Machine learning</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Dissimilarities with Machine learning</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Relationship with Machine learning</strong></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Just like Machine learning, statistical learning is also about building the ability to infer from the data that in some cases represents experience.</p>
</td><td style="text-align: left" valign="top">
<p>Statistical learning<a id="id127" class="indexterm"/> focuses on coming up with valid conclusions while Machine learning is about predictions. Statistical learning works on and allows assumptions as against Machine learning. Machine learning and statistics are practiced by different groups. Machine learning is a relatively new field when compared to statistics.</p>
</td><td style="text-align: left" valign="top">
<p>The Machine learning technology implements statistical techniques.</p>
</td></tr></tbody></table></div></div><div class="section" title="Data science"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec18"/>Data science</h2></div></div></div><p>Data science<a id="id128" class="indexterm"/> is all about turning data into products. It is <a id="id129" class="indexterm"/>analytics and machine<a id="id130" class="indexterm"/> learning put into action to draw inferences and insights out of data. Data science is perceived to<a id="id131" class="indexterm"/> be a first step from traditional data analysis and knowledge systems, such as <span class="strong"><strong>Data Warehouses</strong></span> (<span class="strong"><strong>DW</strong></span>) and <span class="strong"><strong>Business Intelligence</strong></span> (<span class="strong"><strong>BI</strong></span>), which<a id="id132" class="indexterm"/> considers all aspects of big data.</p><p>The data science lifecycle includes steps from data availability/loading to deriving and communicating data<a id="id133" class="indexterm"/> insights up to operationalizing the process, and Machine learning often forms a subset of this process.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th colspan="3" style="text-align: center" valign="bottom">
<p>Machine learning versus Data science</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Similarities with Machine learning</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Dissimilarities with Machine learning</strong></span>
</p>
</td><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Relationship with Machine learning</strong></span>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Machine learning and data science have prediction as a common binding outcome given the problem's context.</p>
</td><td style="text-align: left" valign="top">
<p>One <a id="id134" class="indexterm"/>of the important differences between Machine learning and data science is the need for domain expertise. Data science focuses on solving domain-specific problems, while Machine<a id="id135" class="indexterm"/> learning focuses on building models that can generically fit a problem context.</p>
</td><td style="text-align: left" valign="top">
<p>Data science is a superset of Machine learning, data mining, and related subjects. It extensively covers the complete process starting from data loading until production.</p>
</td></tr></tbody></table></div></div></div>
<div class="section" title="Machine learning process lifecycle and solution architecture"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec11"/>Machine learning process lifecycle and solution architecture</h1></div></div></div><p>In this section, we will discuss the<a id="id136" class="indexterm"/> machine learning implementation process and solution architecture:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The first step<a id="id137" class="indexterm"/> toward defining the solution architecture<a id="id138" class="indexterm"/> is defining the problem statement, which includes defining the goal, process, and assumptions.</li><li class="listitem">Determine what problem type is this problem classified under? Whether it is a classification, regression, or optimization problem?</li><li class="listitem">Choose a<a id="id139" class="indexterm"/> metric that will be used to measure the accuracy of the model.</li><li class="listitem">In order to ensure the model works well with the unseen data:<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Build the model using training data.</li><li class="listitem">Tweak the model using test data.</li><li class="listitem">Declare an accuracy based on the final version.</li></ol></div></li></ol></div><p>The<a id="id140" class="indexterm"/> following figure<a id="id141" class="indexterm"/> explains the<a id="id142" class="indexterm"/> flow and architecture <a id="id143" class="indexterm"/>of the underlying system:</p><div class="mediaobject"><img src="graphics/B03980_01_16.jpg" alt="Machine learning process lifecycle and solution architecture"/></div></div>
<div class="section" title="Machine learning algorithms"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec12"/>Machine learning algorithms</h1></div></div></div><p>Now, let's look at the<a id="id144" class="indexterm"/> important machine learning algorithms and <a id="id145" class="indexterm"/>some brief details about each of them. In-depth implementation aspects for each of the algorithms will be covered in later chapters. These algorithms are either classified under the problem type or the learning type. There is a simple classification of the algorithms given but it is intuitive and not necessarily exhaustive.</p><p>There are many <a id="id146" class="indexterm"/>ways of classifying or grouping machine learning algorithms, and in this book we will use the learning model based grouping. In each chapter, starting from <a class="link" href="ch05.html" title="Chapter 5. Decision Tree based learning">Chapter 5</a>, <span class="emphasis"><em>Decision Tree based learning</em></span>, we will cover one or more learning models and associated algorithms. The following concept model depicts a listing of learning models:</p><div class="mediaobject"><img src="graphics/B03980_01_17.jpg" alt="Machine learning algorithms"/></div><div class="section" title="Decision tree based algorithms"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec19"/>Decision tree based algorithms</h2></div></div></div><p>Decision tree<a id="id147" class="indexterm"/> based algorithms define models that are iteratively or recursively constructed based on the data provided. The goal of Decision tree based algorithms is to predict the value of a target variable given a set of input variables. Decision trees help solve classification and regression problems using<a id="id148" class="indexterm"/> tree based methods. Decisions fork in tree structures until a prediction decision is made for a given record. Some<a id="id149" class="indexterm"/> of the <a id="id150" class="indexterm"/>algorithms are <a id="id151" class="indexterm"/>as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Random forest</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Classification and</strong></span><a id="id152" class="indexterm"/><span class="strong"><strong> Regression Tree</strong></span> (<span class="strong"><strong>CART</strong></span>)</li><li class="listitem" style="list-style-type: disc">C4.5 and <a id="id153" class="indexterm"/>C5.0</li><li class="listitem" style="list-style-type: disc">Chi-square</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Gradient </strong></span><a id="id154" class="indexterm"/><span class="strong"><strong>boosting machines</strong></span> (<span class="strong"><strong>GBM</strong></span>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Chi-Squared Automatic </strong></span><a id="id155" class="indexterm"/><span class="strong"><strong>Interaction </strong></span><a id="id156" class="indexterm"/><span class="strong"><strong>Detection</strong></span> (<span class="strong"><strong>CHAID</strong></span>)</li><li class="listitem" style="list-style-type: disc">Decision<a id="id157" class="indexterm"/> stump</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Multivariate adaptive</strong></span><a id="id158" class="indexterm"/><span class="strong"><strong> regression splines</strong></span> (<span class="strong"><strong>MARS</strong></span>)</li></ul></div></div><div class="section" title="Bayesian method based algorithms"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec20"/>Bayesian method based algorithms</h2></div></div></div><p>Bayesian methods are those<a id="id159" class="indexterm"/> that explicitly apply the Bayesian inference theorem and again solve classification and regression problems. Bayesian methods facilitate subjective probability in modeling. The following<a id="id160" class="indexterm"/> are some of the Bayesian based algorithms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Naïve<a id="id161" class="indexterm"/> Bayes</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Averaged one-dependence</strong></span><a id="id162" class="indexterm"/><span class="strong"><strong> estimators</strong></span> (<span class="strong"><strong>AODE</strong></span>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Bayesian belief </strong></span><a id="id163" class="indexterm"/><span class="strong"><strong>network</strong></span> (<span class="strong"><strong>BBN</strong></span>)</li></ul></div></div><div class="section" title="Kernel method based algorithms"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec21"/>Kernel method based algorithms</h2></div></div></div><p>When we hear about kernel methods, the first thing that comes to<a id="id164" class="indexterm"/> mind is <span class="strong"><strong>Support Vector Machines</strong></span> (<span class="strong"><strong>SVM</strong></span>). These methods are usually a group of methods in themselves. kernel methods are concerned <a id="id165" class="indexterm"/>with pattern analysis and as explained in the preceding sections, that crux of pattern analysis includes various mapping techniques. Here, the mapping datasets include vector spaces. Some examples<a id="id166" class="indexterm"/> of kernel method based learning <a id="id167" class="indexterm"/>algorithms are<a id="id168" class="indexterm"/> listed as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">SVM</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Linear discriminant analysis</strong></span> (<span class="strong"><strong>LDA</strong></span>)</li></ul></div></div><div class="section" title="Clustering methods"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec22"/>Clustering methods</h2></div></div></div><p>Clustering, like regression, describes a class of problems and a class of methods. Clustering methods are<a id="id169" class="indexterm"/> typically organized by the modeling <a id="id170" class="indexterm"/>approaches such as centroid-based and hierarchical. These methods organize data into groups by assessing the similarity in the structure of input data:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">K-means</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Expectation </strong></span><a id="id171" class="indexterm"/><span class="strong"><strong>maximization</strong></span> (<span class="strong"><strong>EM</strong></span>) and <span class="strong"><strong>Gaussian</strong></span><a id="id172" class="indexterm"/><span class="strong"><strong> mixture models</strong></span> (<span class="strong"><strong>GMM</strong></span>)</li></ul></div></div><div class="section" title="Artificial neural networks (ANN)"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec23"/>Artificial neural networks (ANN)</h2></div></div></div><p>Similar to kernel methods, artificial <a id="id173" class="indexterm"/>neural networks are again a class of pattern matching techniques, but these models are inspired by the structure of biological neural networks. These methods are again used to solve classifications and regression problems. They relate to Deep learning modeling and have many subfields of algorithms that help solve specific problems in context.</p><p>Some of the<a id="id174" class="indexterm"/> methods in this category include:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Learning </strong></span><a id="id175" class="indexterm"/><span class="strong"><strong>vector</strong></span><a id="id176" class="indexterm"/><span class="strong"><strong> quantization</strong></span> (<span class="strong"><strong>LVQ</strong></span>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Self-organizing</strong></span><a id="id177" class="indexterm"/><span class="strong"><strong> maps</strong></span> (<span class="strong"><strong>SOM</strong></span>)</li><li class="listitem" style="list-style-type: disc">Hopfield<a id="id178" class="indexterm"/> network</li><li class="listitem" style="list-style-type: disc">Perceptron</li><li class="listitem" style="list-style-type: disc">Backpropagation</li></ul></div></div><div class="section" title="Dimensionality reduction"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec24"/>Dimensionality reduction</h2></div></div></div><p>Like clustering<a id="id179" class="indexterm"/> methods, dimensionality reduction methods work iteratively and on the data structure in an unsupervised manner. Given the dataset and the dimensions, more dimensions would <a id="id180" class="indexterm"/>mean more work in the Machine learning implementation. The idea is to iteratively reduce the dimensions and bring more relevant dimensions forward. This technique is usually used to simplify high-dimensional data and then apply a supervised learning technique. Some example dimensionality reduction <a id="id181" class="indexterm"/>methods are listed as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Multidimensional </strong></span><a id="id182" class="indexterm"/><span class="strong"><strong>scaling</strong></span> (<span class="strong"><strong>MDS</strong></span>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Principal component</strong></span><a id="id183" class="indexterm"/><span class="strong"><strong> analysis</strong></span> (<span class="strong"><strong>PCA</strong></span>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Projection</strong></span><a id="id184" class="indexterm"/><span class="strong"><strong> pursuit</strong></span> (<span class="strong"><strong>PP</strong></span>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Partial least</strong></span><a id="id185" class="indexterm"/><span class="strong"><strong> squares</strong></span> (<span class="strong"><strong>PLS</strong></span>) regression</li><li class="listitem" style="list-style-type: disc">Sammon <a id="id186" class="indexterm"/>mapping</li></ul></div></div><div class="section" title="Ensemble methods"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec25"/>Ensemble methods</h2></div></div></div><p>As the name suggests, ensemble <a id="id187" class="indexterm"/>methods encompass multiple models that are built independently and the results of these models are combined and responsible for overall predictions. It is critical to identify what independent models are to be combined or included, how the results need to be combined, and in what way to achieve the required result. The subset of models that are combined is sometimes referred to as weaker models as the results of these models need not completely fulfill the expected outcome in isolation. This is a very powerful and widely adopted class of<a id="id188" class="indexterm"/> techniques. The following are some of the<a id="id189" class="indexterm"/> Ensemble method <a id="id190" class="indexterm"/>algorithms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Random<a id="id191" class="indexterm"/> forest</li><li class="listitem" style="list-style-type: disc">Bagging</li><li class="listitem" style="list-style-type: disc">AdaBoost</li><li class="listitem" style="list-style-type: disc">Bootstrapped <a id="id192" class="indexterm"/>Aggregation (Boosting)</li><li class="listitem" style="list-style-type: disc">Stacked<a id="id193" class="indexterm"/> generalization (blending)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Gradient</strong></span><a id="id194" class="indexterm"/><span class="strong"><strong> boosting machines</strong></span> (<span class="strong"><strong>GBM</strong></span>)</li></ul></div></div><div class="section" title="Instance based learning algorithms"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec26"/>Instance based learning algorithms</h2></div></div></div><p>Instances are nothing but <a id="id195" class="indexterm"/>subsets of datasets, and instance based learning models work on an identified instance or groups of instances that are critical to the problem. The results across instances are compared, which can include an instance of new data as well. This comparison uses a particular similarity measure to find the best match and predict. Instance based methods are also called case-based or memory-based learning. Here the focus is on the representation of the instances and similarity measures for comparison between instances. Some<a id="id196" class="indexterm"/> of the instance based learning algorithms are listed as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>k-Nearest </strong></span><a id="id197" class="indexterm"/><span class="strong"><strong>Neighbour</strong></span> (<span class="strong"><strong>k-NN</strong></span>)</li><li class="listitem" style="list-style-type: disc">Self-Organizing</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Learning </strong></span><a id="id198" class="indexterm"/><span class="strong"><strong>vector</strong></span><a id="id199" class="indexterm"/><span class="strong"><strong> quantization</strong></span> (<span class="strong"><strong>LVQ</strong></span>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Self-organizing</strong></span><a id="id200" class="indexterm"/><span class="strong"><strong> maps</strong></span> (<span class="strong"><strong>SOM</strong></span>)</li></ul></div></div><div class="section" title="Regression analysis based algorithms"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec27"/>Regression analysis based algorithms</h2></div></div></div><p>Regression is a process of refining the model iteratively based on the error generated by the model. Regression<a id="id201" class="indexterm"/> also is used to define a machine learning problem type. Some example algorithms in<a id="id202" class="indexterm"/> regression are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Ordinary least squares linear regression</li><li class="listitem" style="list-style-type: disc">Logistic<a id="id203" class="indexterm"/> regression</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Multivariate adaptive regression splines</strong></span> (<span class="strong"><strong>MARS</strong></span>)</li><li class="listitem" style="list-style-type: disc">Stepwise regression</li></ul></div></div><div class="section" title="Association rule based learning algorithms"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec28"/>Association rule based learning algorithms</h2></div></div></div><p>Given the variables, association<a id="id204" class="indexterm"/> rule based learning algorithms extract and define rules that can be applied on a dataset and demonstrate experienced-based learning, and thus prediction. These rules when associated in a multi-dimensional data context can be useful in a commercial context as well. Some of the examples of Association rule based algorithms are given<a id="id205" class="indexterm"/> as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The Apriori <a id="id206" class="indexterm"/>algorithm</li><li class="listitem" style="list-style-type: disc">The Eclat <a id="id207" class="indexterm"/>algorithm</li></ul></div></div></div>
<div class="section" title="Machine learning tools and frameworks"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec13"/>Machine learning tools and frameworks</h1></div></div></div><p>Machine learning<a id="id208" class="indexterm"/> adoption is rapidly increasing among technology and business organizations. Every organization is actively strategizing on how to capitalize on their data<a id="id209" class="indexterm"/> and use it to augment their client's experiences and build new businesses. When it comes to tools or frameworks for Machine learning, there are many open source and commercial options on the market. The new age tools are all built to support big data, distributed storage, and parallel processing. In the next chapter, we will cover some aspects of handling large scale data in the context of Machine learning.</p><p>At a very high level, there are three generations of Machine learning tools.</p><p>The first generation <a id="id210" class="indexterm"/>of Machine learning tools is focused on providing a richness of the Machine learning algorithms and supporting deep analytics. These tools<a id="id211" class="indexterm"/> haven't been built to focus on handling large scale data or for supporting distributed storage and parallel processing. Some of them still handle volumes as a result of their support for vertical scalability. Some of the tools that come under this category are SAS, SPSS, Weka, R, and more. Having said that, most of these tools are now being upgraded to support big data requirements too.</p><p>The second generation tools are focused on supporting big data requirements, most of them work on the Hadoop platform, and they provide capabilities to run machine learning algorithms in a MapReduce paradigm. Some of the tools that are categorized here are Mahout, RapidMiner, Pentaho, and MADlib. Some of these tools do not support all the machine learning algorithms.</p><p>The third generations<a id="id212" class="indexterm"/> tools are the smart kids on the road, breaking the traditional norms of operating in batch<a id="id213" class="indexterm"/> mode, supporting real-time analytics, providing support for advanced data types of big data, and at the same time supporting deeper analytics. Some of the tools that are categorized under this are Spark, HaLoop, and Pregel.</p><p>In <a class="link" href="ch04.html" title="Chapter 4. Machine Learning Tools, Libraries, and Frameworks">Chapter 4</a>, <span class="emphasis"><em>Machine Learning Tools, Libraries, and Frameworks</em></span>, we will cover some of the key machine learning tools and demonstrate how they can be used based on the problem's context. Implementation details for tools such as R, Julia, Python, Mahout, and Spark will be covered in depth. Required technology primers and installation or setup-related guidance will be provided.</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec14"/>Summary</h1></div></div></div><p>In this chapter, which forms the basis for the rest of the chapters of this book, we covered the basics of Machine learning and the landscape of Machine learning semantics. We started by defining Machine learning in simple terms and introduced Machine learning jargon or the commonly used terms.</p><p>There are many competing and complementing fields of Machine learning. We have thoroughly explained the similarities, dissimilarities, and the relationship of Machine learning with fields such as artificial intelligence, data mining, data science, and statistics. Overall, all these fields are very similar and have overlapping goals. In most cases, the practitioners of these fields were different. Even in terms of the tools being used, there were many common points.</p><p>We have also looked at some of the latest and best-of-breed tools that can be employed in Machine learning. Some of these tools will be demonstrated in the chapters using practical examples.</p><p>In the next chapter, we will cover a unique aspect of Machine learning that has pretty much changed the way Machine learning implementations have been looked at. We will explore how the big data, or large dataset, aspect of Machine learning has impacted the choice of tools and implementation approaches.</p></div></body></html>