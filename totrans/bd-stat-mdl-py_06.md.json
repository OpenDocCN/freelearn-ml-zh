["```py\ndef least_squares_method(x,y):\n    x_mean=x.mean()\n    y_mean=y.mean()\n    beta1 = ((x-x_mean)*(y-y_mean)).sum(axis=0)/ ((x-x.mean())**2).sum(axis=0)\n    beta0 = y_mean-(beta1*x_mean)\n    return beta0, beta1\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom statsmodels.nonparametric.smoothers_lowess import lowess\ndf = sm.datasets.macrodata.load().data\n```", "```py\ndf = sm.add_constant(df, prepend=False)\ndf_mod = df[['realinv','realdpi','const']]\n```", "```py\nols_model = sm.OLS(df_mod['realdpi'], df_mod[['const','realinv']])\ncompiled_model = ols_model.fit()\n```", "```py\nprint(compiled_model.summary())\n```", "```py\nmodel_residuals = compiled_model.resid\nfitted_value = compiled_model.fittedvalues\nstandardized_residuals = compiled_model.resid_pearson # Residuals, normalized to have unit variance.\nsqrt_standardized_residuals = np.sqrt(np.abs(compiled_model.get_influence().resid_studentized_internal))\ninfluence = compiled_model.get_influence()\nleverage = influence.hat_matrix_diag\ncooks_distance = compiled_model.get_influence().cooks_distance[0]\nfig, ax = plt.subplots(2, 2, figsize=(10,8))\n# Residuals vs. Fitted\nax[0, 0].set_xlabel('Fitted Values')\nax[0, 0].set_ylabel('Residuals')\nax[0, 0].set_title('Residuals vs. Fitted')\nlocally_weighted_line1 = lowess(model_residuals, fitted_value)\nsns.scatterplot(x=fitted_value, y=model_residuals, ax=ax[0, 0])\nax[0, 0].axhline(y=0, color='grey', linestyle='--')\nax[0,0].plot(locally_weighted_line1[:,0], locally_weighted_line1[:,1], color = 'red')\n# Normal Q-Q\nax[0, 1].set_title('Normal Q-Q')\nsm.qqplot(model_residuals, fit=True, line='45',ax=ax[0, 1], c='blue')\n# Scale-Location\nax[1, 0].set_xlabel('Fitted Values')\nax[1, 0].set_ylabel('Square Root of Standardized Residuals')\nax[1, 0].set_title('Scale-Location')\nlocally_weighted_line2 = lowess(sqrt_standardized_residuals, fitted_value)\nsns.scatterplot(x=fitted_value, y=sqrt_standardized_residuals, ax=ax[1, 0])\nax[1,0].plot(locally_weighted_line2[:,0], locally_weighted_line2[:,1], color = 'red')\n# Residual vs. Leverage Influence\nax[1, 1].set_xlabel('Leverage')\nax[1, 1].set_ylabel('Standardized Residuals')\nax[1, 1].set_title('Residuals vs. Leverage Influence')\nlocally_weighted_line3 = lowess(standardized_residuals, leverage)\nsns.scatterplot(x=leverage, y=standardized_residuals, ax=ax[1, 1])\nax[1, 1].plot(locally_weighted_line3[:,0], locally_weighted_line3[:,1], color = 'red')\nax[1, 1].axhline(y=0, color='grey', linestyle='--')\nax[1, 1].axhline(3, color='orange', linestyle='--', label='Outlier Demarkation')\nax[1, 1].axhline(-3, color='orange', linestyle='--')\nax[1, 1].legend(loc='upper right')\nleverages = []\nfor i in range(len(cooks_distance)):\n    if cooks_distance[i] > 0.5:\n        leverages.append(leverage[i])\n        ax[1, 1].annotate(str(i) + \" Cook's D > 0.5\",xy=(leverage[i], standardized_residuals[i]))\nif leverages:\n    ax[1, 1].axvline(min(leverages), color='red', linestyle='--', label=\"Cook's Distance\")\nfor i in range(len(standardized_residuals)):\n    if standardized_residuals[i] > 3 or standardized_residuals[i] < -3:\n        ax[1, 1].annotate(i,xy=(leverage[i], standardized_residuals[i]))\nfig.tight_layout()\n```", "```py\nfrom statsmodels.graphics.tsaplots import plot_pacf\nplot_pacf(compiled_model.resid, alpha=0.05, lags=50);\n```", "```py\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfig, ax = plt.subplots(2,3, figsize=(15,10))\nplot_acf(df_mod['realdpi'], alpha=0.05, lags=50, ax=ax[0,0])\nax[0,0].set_title('Original ACF')\nplot_pacf(df_mod['realdpi'], alpha=0.05, lags=50, ax=ax[0,1])\nax[0,1].set_title('Original PACF')\nax[0,2].set_title('Original Data')\nax[0,2].plot(df_mod['realdpi'])\nplot_acf(np.diff(df_mod['realdpi'], n=1), alpha=0.05, lags=50, ax=ax[1,0])\nax[1,0].set_title('Once-Differenced ACF')\nplot_pacf(np.diff(df_mod['realdpi'], n=1), alpha=0.05, lags=50, ax=ax[1,1])\nax[1,1].set_title('Once-Differenced PACF')\nax[1,2].set_title('Once-Differenced Data')\nax[1,2].plot(np.diff(df_mod['realdpi'], n=1))\n```", "```py\nols_model_1diff = sm.OLS(np.diff(df_mod['realdpi'], n=1), pd.concat([df_mod['const'].iloc[:-1], pd.Series(np.diff(df_mod['realinv'], n=1))], axis=1))\ncompiled_model_1diff = ols_model_1diff.fit()\n```", "```py\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df_mod, train_size=0.75, shuffle=True)\n```", "```py\nols_model_train = sm.OLS(train['realdpi'], train[['const','realinv']])\ncompiled_model_train = ols_model_train.fit()\nprint(compiled_model_train.summary())\n```", "```py\nols_model_test = sm.OLS(test['realdpi'], test[['const','realinv']])\ncompiled_model_test = ols_model_test.fit()\nprint(compiled_model_test.summary())\n```", "```py\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(train['realdpi'], compiled_model_train.predict(train[['const','realinv']]))\nmae\n#438.5872081797031\n```", "```py\nimport numpy as np\nerrors = []\nfor i in range(len(train)):\n    errors.append(abs(train['realdpi'].iloc[i] - train['realdpi'].mean()))\nnp.mean(errors)\n#2065.440235457064\n```", "```py\nmae_test = mean_absolute_error(test['realdpi'], compiled_model_train.predict(test[['const','realinv']]))\nmae_test\n#408.0253171549187\n```", "```py\nerrors = []\nfor i in range(len(test)):\n    errors.append(abs(test['realdpi'].iloc[i] - test['realdpi'].mean()))\nnp.mean(errors)\n#1945.5873125720873\n```"]