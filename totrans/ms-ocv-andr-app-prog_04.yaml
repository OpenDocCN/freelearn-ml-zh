- en: Chapter 4. Drilling Deeper into Object Detection – Using Cascade Classifiers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章.深入对象检测——使用级联分类器
- en: In the previous chapter, we looked at some very sophisticated algorithms used
    for object detection. In this chapter, we plan to look further into a different
    set of algorithms, known as cascade classifiers and HOG descriptors. These algorithms
    are widely used to detect human expressions and find application in surveillance
    systems, face recognition systems, and other simple biometric systems. Face detection
    was one of the first applications of **cascade classifiers** (Haar-cascade classifier)
    and from then on, there have been many different applications that have been developed.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们探讨了用于对象检测的一些非常复杂的算法。在本章中，我们计划进一步探讨另一组被称为级联分类器和HOG描述符的算法。这些算法广泛用于检测人类表情，并在监控系统、人脸识别系统和其他简单的生物识别系统中得到应用。人脸检测是**级联分类器**（Haar级联分类器）的第一个应用之一，从那时起，已经开发了许多不同的应用。
- en: Have you ever wondered how cameras detect smiling faces in an image and click
    a picture automatically? It is no rocket science. This chapter will talk about
    the different ways of detecting human expressions, using which you can build your
    own version of the aforementioned applications on an Android platform.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾经想过相机是如何在图像中检测到微笑的面孔并自动拍照的？这并不是什么火箭科学。本章将讨论检测人类表情的不同方法，使用这些方法你可以在Android平台上构建上述应用的自己的版本。
- en: 'We will take a look at the following algorithms in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨以下算法：
- en: Cascade classifiers
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 级联分类器
- en: HOG descriptors
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HOG描述符
- en: An introduction to cascade classifiers
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 级联分类器简介
- en: What are cascade classifiers? Let's take a look at both the words individually
    and then combine them to see what the phrase actually means. Classifiers are like
    black boxes that classify objects into various classes on the basis of a training
    set. Initially, we take a large set of training data, feed it to any learning
    algorithm, and compute a trained model (classifier), which is capable of classifying
    new unknown data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是级联分类器？让我们分别看看这两个词的含义，然后再将它们结合起来，看看这个短语实际上是什么意思。分类器就像黑盒，根据训练集将对象分类到不同的类别。最初，我们取一个大的训练数据集，将其输入到任何学习算法中，并计算一个训练好的模型（分类器），该模型能够对新的未知数据进行分类。
- en: Let's understand the word cascade. In the literal sense of the word, cascading
    means to form a chain. In the current context, cascading implies forming a multistage
    classifier, where the output of one stage is passed on to the next stage, and
    so on. Cascade classifiers are used in situations where you have low computational
    power and you do not want to compromise on the speed of your algorithm.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解一下“级联”这个词。在字面上，级联意味着形成一条链。在当前语境中，级联意味着形成一个多阶段分类器，其中前一阶段的输出传递到下一阶段，依此类推。级联分类器用于那些你拥有较低的计算能力且不想在算法速度上妥协的情况。
- en: 'Cascade classifiers that will be covered in this chapter are as follows:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖的级联分类器如下：
- en: Haar cascades (Viola and Jones – face detection)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haar级联（Viola和Jones – 人脸检测）
- en: LBP cascades
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LBP级联
- en: Let's briefly understand Haar and LBP Cascades and then build an Android application
    that uses these cascades to detect faces in images.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要了解Haar级联和LBP级联，然后构建一个使用这些级联在图像中检测人脸的Android应用程序。
- en: Haar cascades
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Haar级联
- en: One of the first real-time face detection algorithms, developed by Viola and
    Jones, was inspired by the concept of Haar wavelets. The algorithm exploits the
    inherent structure and similarities in human faces. For example, in every human
    face, the eye region is darker than the cheeks, and the nose bridge region is
    darker than the eyes. Using such characteristics of a human face, we learn the
    generic models of the face and then use these trained models to detect faces in
    images.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Viola和Jones开发的第一种实时人脸检测算法，其灵感来源于Haar小波的概念。该算法利用人脸固有的结构和相似性。例如，在每个人的脸上，眼区域比脸颊暗，鼻梁区域比眼睛暗。利用人脸的这些特征，我们学习人脸的通用模型，然后使用这些训练好的模型在图像中检测人脸。
- en: Initially, we feed a learning algorithm with positive images (images with faces)
    and negative images (images with out faces) and learn the classifier. Then we
    extract Haar features from the images using convolutional kernels (as shown in
    the following image). Feature values are obtained by subtracting the sum of white
    pixels under the white rectangle from the sum of pixels under the black rectangle.
    We slide these kernels (nothing but Haar features) over the entire image and calculate
    the feature values. If the value is above a certain user-defined threshold, we
    say that there is a match, otherwise we reject that region. To reduce calculations,
    we make use of integral images.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 初始时，我们向学习算法提供正面图像（含人脸的图像）和负面图像（不含人脸的图像）并学习分类器。然后我们使用卷积核从图像中提取Haar特征（如下面的图像所示）。特征值是通过从白色矩形下的白色像素总和减去黑色矩形下的像素总和得到的。我们将这些核（即Haar特征）在整个图像上滑动并计算特征值。如果值高于某个用户定义的阈值，我们说存在匹配，否则我们拒绝该区域。为了减少计算，我们使用了积分图像。
- en: Tip
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: An explanation of integral images can be found at [http://en.wikipedia.org/wiki/Summed_area_table](http://en.wikipedia.org/wiki/Summed_area_table).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在[http://en.wikipedia.org/wiki/Summed_area_table](http://en.wikipedia.org/wiki/Summed_area_table)可以找到积分图像的解释。
- en: '![Haar cascades](img/B02052_04_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![Haar级联](img/B02052_04_01.jpg)'
- en: Haar features
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Haar特征
- en: Training the classifier every time before using it is unacceptable in terms
    of the performance because it takes a lot of time; sometimes up to 6-7 hours or
    more. Hence, we use the pretrained classifiers provided by OpenCV (or any other
    source).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用分类器之前每次都对其进行训练在性能方面是不可接受的，因为它需要花费很多时间；有时多达6-7小时或更长。因此，我们使用OpenCV（或任何其他来源）提供的预训练分类器。
- en: LBP cascades
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LBP级联
- en: The **Local Binary Patterns** (**LBP**) cascade is another type of a cascade
    classifier that is used widely in computer vision. Compared to Haar cascades,
    LBP cascades deal with integers rather than double values. So, both training and
    testing is faster with LBP cascades and hence is preferred while developing embedded
    applications. Another important property of LBP is their tolerance against illumination
    variations.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**局部二值模式**（**LBP**）级联是另一种广泛用于计算机视觉的级联分类器。与Haar级联相比，LBP级联处理整数而不是双精度值。因此，使用LBP级联进行训练和测试更快，因此在开发嵌入式应用程序时更受欢迎。LBP的另一个重要特性是对光照变化的容忍度。'
- en: In LBP, an 8-bit binary feature vector is created for each pixel in the image
    by considering the eight neighboring pixels (top-left, top-right, left, right,
    bottom-left, and bottom-right). For every neighboring pixel, there is a corresponding
    bit which is assigned a value 1 if the pixel value is greater than the center
    pixel's value, otherwise 0\. The 8-bit feature vector is treated as a binary number
    (later convert it to a decimal value), and using the decimal values for each pixel,
    a 256-bin histogram is computed. This histogram is used as a representative of
    the image.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在LBP中，对于图像中的每个像素，通过考虑八个相邻像素（左上、右上、左、右、左下和右下）创建一个8位二进制特征向量。对于每个相邻像素，都有一个相应的位，如果像素值大于中心像素的值，则分配值为1，否则为0。8位特征向量被视为一个二进制数（稍后将其转换为十进制值），并使用每个像素的十进制值计算一个256个分箱的直方图。这个直方图被用作图像的代表性。
- en: 'LBP features have some primitives coded in them, as shown in the following
    image:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: LBP特征中包含一些原语，如下面的图像所示：
- en: '![LBP cascades](img/B02052_04_02.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![LBP级联](img/B02052_04_02.jpg)'
- en: Examples of texture primitives
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 纹理原语示例
- en: For Haar cascade, we also make a set of positive images (with faces) and negative
    images (without faces). We compute histograms for each image and feed it to any
    learning algorithm.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Haar级联，我们也制作了一组正面图像（含人脸）和负面图像（不含人脸）。我们为每个图像计算直方图并将其输入到任何学习算法中。
- en: Face detection using the cascade classifier
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用级联分类器进行人脸检测
- en: 'One of the most common applications of the cascade classifier is face detection.
    Implementation for both Haar and LBP classifiers on Android using OpenCV is very
    similar; the only difference is in the model that we use to detect faces. Let''s
    work on a generic application for face detection and make relevant changes to
    the application to accommodate both Haar and LBP cascades. The application will
    display the camera preview on the entire screen (landscape orientation) and make
    rectangles around faces in each frame. It will also provide an option to switch
    between the front and back camera. Following are the steps to create this application:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 级联分类器最常见的一个应用是面部检测。在 Android 上使用 OpenCV 实现 Haar 和 LBP 分类器的实现非常相似；唯一的区别在于我们用来检测面部的模型。让我们为面部检测创建一个通用应用程序，并对应用程序进行相关更改以适应
    Haar 和 LBP 级联。该应用程序将在整个屏幕上显示相机预览（横屏方向），并在每一帧周围绘制矩形。它还将提供一个选项来切换前后摄像头。以下是创建此应用程序的步骤：
- en: Create a new Eclipse (or Android Studio) project with a blank activity and call
    the application *Face Detection*. It will be a landscape application with a fullscreen
    camera preview.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的 Eclipse（或 Android Studio）项目，包含一个空白活动，并将应用程序命名为 *Face Detection*。它将是一个横屏应用，具有全屏相机预览。
- en: 'In the application tag, add the following line to make a fullscreen application:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在应用程序标签中，添加以下行以创建全屏应用程序：
- en: '[PRE0]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Give the following permissions in `AndroidManifest.xml`:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `AndroidManifest.xml` 中授予以下权限：
- en: '[PRE1]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the main activity, add a camera preview view. This will display the camera''s
    output on the screen. Add the view using the following lines:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主活动中，添加一个相机预览视图。这将显示相机输出到屏幕上。使用以下行添加视图：
- en: '[PRE2]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'OpenCV provides two camera preview views: `JavaCameraView` and `NativeCameraView`.
    Both the views work in a similar way except for a few differences. Refer to [http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/dev_with_OCV_on_Android.html?highlight=nativecameraview](http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/dev_with_OCV_on_Android.html?highlight=nativecameraview)
    for a detailed explanation of the differences.'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: OpenCV 提供了两种相机预览视图：`JavaCameraView` 和 `NativeCameraView`。这两个视图的工作方式相似，但有一些不同。有关差异的详细说明，请参阅
    [http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/dev_with_OCV_on_Android.html?highlight=nativecameraview](http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/dev_with_OCV_on_Android.html?highlight=nativecameraview)。
- en: In this application, we will implement the `CvCameraViewListener2` interface
    that has function definitions that provide some control over the camera (refer
    to the camera preview tutorial of OpenCV). We will take a look at these functions
    later in this section.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在此应用程序中，我们将实现 `CvCameraViewListener2` 接口，该接口具有提供一些对相机控制的功能定义（请参阅 OpenCV 的相机预览教程）。我们将在本节稍后查看这些函数。
- en: Unlike other applications seen so far in this book, this application has a different
    implementation of the `BaseLoaderCallback` class (for those who are not able to
    recollect, the `BaseLoaderCallback` class initializes and loads OpenCV modules
    in the application).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书中迄今为止看到的其它应用程序不同，此应用程序对 `BaseLoaderCallback` 类有不同的实现（对于那些无法回忆起的人来说，`BaseLoaderCallback`
    类在应用程序中初始化和加载 OpenCV 模块）。
- en: 'For this application, we will load the cascade classifiers after we have loaded
    OpenCV in our application. Here is the `BaseLoaderCallback` class for this application:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此应用程序，我们将在我们的应用程序中加载 OpenCV 之后加载级联分类器。以下是此应用程序的 `BaseLoaderCallback` 类：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the preceding code snippet, we first check whether OpenCV was successfully
    loaded. After doing this, we copy the cascade file from the project resources
    to our application using `InputStream` and `FileOutputStream`, as shown next.
    Create a new folder `cascade` and copy the contents of the cascade file to a new
    file in that folder. Now comes the difference between using Haar cascades and
    LBP cascades. Replace `<INSERT_RESOURCE_IDENTIFIER>` with your favorite cascade
    file.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们首先检查 OpenCV 是否成功加载。完成此操作后，我们使用 `InputStream` 和 `FileOutputStream`
    将级联文件从项目资源复制到我们的应用程序中，如下所示。创建一个新的文件夹 `cascade`，并将级联文件的副本复制到该文件夹中的新文件中。现在来看看使用
    Haar 级联和 LBP 级联的区别。将 `<INSERT_RESOURCE_IDENTIFIER>` 替换为你喜欢的级联文件。
- en: 'Note: The rest of the code works independently of your choice of the type of
    cascade.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：其余的代码与您选择的级联类型无关。
- en: Note
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: OpenCV provides pre-learnt cascades for both Haar and LBP. Copy the cascade
    file to the `res/raw` folder in your Android project. Let's assume that your cascade
    files for Haar and LBP are named `haar_cascade.xml` and `lbp_cascade.xml` respectively.
    Replace `<INSERT_RESOURCE_IDENTIFIER>` with `R.raw.id.haar_casacde` or `R.raw.id.lbp_cascade`,
    depending on which classifier you want to use.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV为 Haar 和 LBP 都提供了预学习的级联。将级联文件复制到你的 Android 项目中的 `res/raw` 文件夹。假设你的 Haar
    和 LBP 的级联文件分别命名为 `haar_cascade.xml` 和 `lbp_cascade.xml`。将 `<INSERT_RESOURCE_IDENTIFIER>`
    替换为 `R.raw.id.haar_casacde` 或 `R.raw.id.lbp_cascade`，具体取决于你想使用哪个分类器。
- en: 'The reason why we copy and save at the same time is to bring the file from
    your project directory into your phone''s filesystem:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们同时复制和保存文件的原因是将文件从你的项目目录传输到手机的文件系统中：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After this is done, create a new `CascadeClassifier` object that will be used
    later to detect faces in the camera feed, as shown in the following code snippet:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此操作后，创建一个新的 `CascadeClassifier` 对象，稍后将在摄像头流中检测人脸，如下代码片段所示：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'So far, we have been able to initialize OpenCV in our project, and we have
    loaded our favorite cascade classifier in to the application. The next step is
    to get our camera preview ready. As mentioned earlier, we are implementing the
    `CvCameraViewListener2` interface and hence, we need to implement its member functions:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经能够在项目中初始化 OpenCV，并将我们喜欢的级联分类器加载到应用程序中。下一步是准备摄像头预览。如前所述，我们正在实现 `CvCameraViewListener2`
    接口，因此我们需要实现其成员函数：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Another function that needs to be implemented is `onCameraFrame()`. This is
    where all the magic happens. In this function, we will process each frame and
    find faces in it:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要实现的功能是 `onCameraFrame()`。这里发生所有魔法。在这个函数中，我们将处理每一帧并找到其中的面孔：
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here, we first store the output of the camera in `mRgba`, and `mGray` stores
    the grayscale image of the camera output. Then we check whether we are using the
    front camera or the back camera of our phone (how to handle the front camera is
    explained later in this chapter) through a Boolean value `mIsFrontCamera` (data
    member of the class). If the front camera is being used, just flip the image.
    Now create a `MatOfRect` object that will store the rectangles that bound the
    faces in the frame. Then, call the magical function:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们首先将摄像头的输出存储在 `mRgba` 中，`mGray` 存储摄像头的灰度图像输出。然后我们检查是否正在使用手机的正面摄像头或背面摄像头（如何处理正面摄像头将在本章后面解释）通过一个布尔值
    `mIsFrontCamera`（类的数据成员）。如果正在使用正面摄像头，只需翻转图像。现在创建一个 `MatOfRect` 对象，它将存储在帧中包围人脸的矩形。然后，调用神奇的功能：
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `detectMultiScale()` function takes in a grayscale image and returns rectangles
    that bound the faces (if any). The third parameter of the function is the scaling
    factor that specifies how much the image size is reduced at each image scale.
    For more accurate results, face detection happens at different scales. The last
    two parameters are the minimum and maximum size of the face that can be detected.
    These parameters sort of decide the speed at which your application runs. Having
    a minimum size can make your application perform poorly, that is, have very few
    frames per second. Be careful while setting these parameters.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`detectMultiScale()` 函数接收一个灰度图像并返回包含人脸（如果有）的矩形。该函数的第三个参数是缩放因子，它指定了在每次图像缩放时图像大小减少的程度。为了获得更准确的结果，人脸检测会在不同的尺度上进行。最后两个参数是可以检测到的最小和最大人脸尺寸。这些参数在一定程度上决定了应用程序的运行速度。设置最小尺寸可能会导致应用程序性能不佳，即每秒帧数非常少。设置这些参数时要小心。'
- en: 'Done! The application is almost complete with just one bit of functionality
    remaining: handling the front camera. In order to do this, follow these steps:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 完成！应用程序几乎完成了，只剩下一项功能尚未实现：处理前置摄像头。为了做到这一点，请遵循以下步骤：
- en: 'We first add a menu option in the application''s menu that allows the user
    to switch between the front and back camera, as follows:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先在应用程序菜单中添加一个菜单选项，允许用户在前后摄像头之间切换，如下所示：
- en: '[PRE9]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the `onOptionsItemSelected()` function, add the functionality to switch
    between cameras:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `onOptionsItemSelected()` 函数中，添加在摄像头之间切换的功能：
- en: '[PRE10]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Whenever the user selects this option, we first toggle the `isFrontCamera`
    value. After this, we change the camera index of the `mOpenCvCameraView` object
    by running the following code:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当用户选择此选项时，我们首先切换 `isFrontCamera` 的值。之后，通过运行以下代码更改 `mOpenCvCameraView` 对象的摄像头索引：
- en: '[PRE11]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The default camera index in Android is `-1`, which represents the back camera.
    The front camera's index is 1 (this is not a fixed number; it can vary from one
    phone to another). Set the camera index according to the `isFrontCamera` value,
    as shown in the preceding code, and set the toast message to notify the user.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Android中的默认相机索引是`-1`，代表后置摄像头。前置摄像头的索引是1（这不是一个固定的数字；它可能因手机而异）。根据前面的代码中的`isFrontCamera`值设置相机索引，并设置通知用户的消息。
- en: With this, we have successfully built our own version of a face detection application!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个，我们成功构建了我们自己的面部检测应用程序版本！
- en: HOG descriptors
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HOG描述符
- en: '**Histogram of Oriented Gradients** (**HOG**) descriptors are feature descriptors
    that use the direction of intensity of the gradients and edge directions. For
    HOG descriptors, we divide the image into small cells, compute a histogram for
    each cell, and further combine these histograms to compute one single descriptor.
    They are similar to SIFT descriptors in the sense that both use image gradients
    and both divide the image into spatial bins and form a histogram, but SIFT descriptors
    help you to match local regions (using keypoint locations), while HOG descriptors
    use sliding windows to detect objects. The HOG descriptor works well with geometric
    and illumination transformations, but does not work well with object orientations
    (unlike SIFT, which works well with change in orientations).'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**方向梯度直方图**（**HOG**）描述符是使用梯度强度方向和边缘方向的特性描述符。对于HOG描述符，我们将图像划分为小的单元，为每个单元计算一个直方图，并将这些直方图进一步组合以计算一个单一的描述符。在这一点上，它们与SIFT描述符类似，因为两者都使用图像梯度，并且都将图像划分为空间箱并形成直方图，但SIFT描述符帮助您匹配局部区域（使用关键点位置），而HOG描述符使用滑动窗口来检测对象。HOG描述符在几何和光照变换方面表现良好，但在对象方向上表现不佳（与SIFT不同，SIFT在方向变化方面表现良好）。'
- en: 'The HOG descriptor is divided into multiple steps:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: HOG描述符被分为多个步骤：
- en: '**Computing gradient**: We first calculate the gradient values for all the
    pixels in the image using any derivative mask over the image in horizontal and
    vertical directions (you can choose from either one direction or both directions).
    Some common derivative masks are the Sobel operator, Prewitt operator, and the
    likes, but the original algorithm recommends that you use a 1D derivative mask,
    that is, [-1, 0, +1].'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算梯度**：我们首先使用任何导数掩模在图像的水平方向和垂直方向上计算图像中所有像素的梯度值（您可以选择一个方向或两个方向）。一些常见的导数掩模是Sobel算子、Prewitt算子等，但原始算法建议您使用1D导数掩模，即[-1,
    0, +1]。'
- en: '**Orientation binning**: Create a histogram of the weighted gradients that
    were computed in the previous step. The gradient values are divided into bin values,
    ranging from 0 to 180, or 0 to 360 (depending on whether we are using signed or
    unsigned gradient values).'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方向分箱**：创建一个直方图，该直方图包含之前步骤中计算的加权梯度。梯度值被分为箱值，范围从0到180，或0到360（取决于我们是否使用有符号或无符号梯度值）。'
- en: '**Combining cells to form blocks**: After computing histograms for each cell,
    we combine these cells into blocks and form a combined histogram of the block
    using its constituent cell''s normalized histograms. The final HOG descriptor
    is a vector of the normalized histograms.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组合单元格形成块**：在为每个单元格计算直方图之后，我们将这些单元格组合成块，并使用其构成单元格的归一化直方图形成块的组合直方图。最终的HOG描述符是归一化直方图的向量。'
- en: '**Building the classifier**: In the final step of the algorithm, feed the HOG
    feature vectors that were computed in the previous step in to your favorite learning
    algorithm, and build a model that will later be used to detect objects in images:![HOG
    descriptors](img/B02052_04_03.jpg)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**构建分类器**：在算法的最后一步，将之前步骤中计算出的HOG特征向量输入到您喜欢的学习算法中，并构建一个模型，该模型将用于在图像中检测对象：![HOG描述符](img/B02052_04_03.jpg)'
- en: Flowchart of a HOG Descriptor
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: HOG描述符流程图
- en: Let's now take a look at an Android application that detects objects using HOG
    descriptors.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个使用HOG描述符检测对象的Android应用程序。
- en: Since OpenCV provides a pretrained HOG descriptor to detect people in images,
    we will write an Android application that can detect people in images (we won't
    have to train our descriptor). Since the calculations involved in computing HOG
    descriptors are expensive, making a real-time application for a mobile platform
    with limited computational resources turns out to be a difficult task. So instead,
    we will build an application that will only detect people in single images.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 由于OpenCV提供了用于在图像中检测人员的预训练HOG描述符，我们将编写一个Android应用程序，可以检测图像中的人员（我们不需要训练我们的描述符）。由于计算HOG描述符所需的计算量很大，在有限的计算资源移动平台上制作实时应用程序变得非常困难。因此，我们将构建一个应用程序，它将只检测单张图像中的人员。
- en: For this, let's refer to [Chapter 2](ch02.html "Chapter 2. Detecting Basic Features
    in Images"), *Detecting Basic Features in Images*, where we built an application
    that could read images from your phone's gallery and perform any operation based
    on the user's choice (hopefully, you still have that project saved somewhere in
    your computer). We won't need the entire application. We will only take the base
    of that application and make a new function to detect people in any image from
    the gallery.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个，让我们参考[第2章](ch02.html "第2章. 图像中的基本特征检测")，*图像中的基本特征检测*，在那里我们构建了一个应用程序，可以从你的手机相册中读取图像并根据用户的选择执行任何操作（希望你仍然在某处保存了那个项目）。我们不需要整个应用程序。我们只需取那个应用程序的基础部分，并创建一个新的函数来检测相册中的任何图像中的人。
- en: 'If you have the project from [Chapter 2](ch02.html "Chapter 2. Detecting Basic
    Features in Images"), *Detecting Basic Features in Images*, saved, make the following
    changes to it. Add a new menu option *Detect Face* to the application menu (refer
    to [Chapter 2](ch02.html "Chapter 2. Detecting Basic Features in Images"), *Detecting
    Basic Features in Images*), and in the `onSelectedOptionItem()` function, add
    the following lines:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你保存了[第2章](ch02.html "第2章. 图像中的基本特征检测")的项目，*图像中的基本特征检测*，对其进行以下修改。向应用程序菜单中添加一个新的菜单选项*检测面部*（参考[第2章](ch02.html
    "第2章. 图像中的基本特征检测")，*图像中的基本特征检测*），并在`onSelectedOptionItem()`函数中添加以下行：
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Make a new function `HOGDescriptor()`, where we''ll implement people detection
    as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的函数`HOGDescriptor()`，我们将按照以下方式实现人员检测：
- en: '[PRE13]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the preceding code snippet, we first convert the image to a grayscale image.
    Then, we initialize `HOGDescriptor` with a pretrained model (using SVM) using
    the following lines:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们首先将图像转换为灰度图像。然后，我们使用以下行初始化`HOGDescriptor`，使用预训练模型（使用SVM）：
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The next step is simple; we will call the `detectMultiScale()` function, which
    will return all the faces in the image. The second parameter in the function stores
    the regions where people were detected. We will then iterate through all such
    regions and draw rectangles around them on the image.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步很简单；我们将调用`detectMultiScale()`函数，该函数将返回图像中的所有面孔。函数的第二个参数存储了检测到人的区域。然后我们将遍历所有这些区域，并在图像上围绕它们绘制矩形。
- en: Project – Happy Camera
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目 – 快乐相机
- en: Practice is better than theory. It's time to apply your learning from this chapter
    and build a cool camera application, which automatically clicks a picture when
    it detects smiling faces.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 实践胜于理论。现在是时候应用本章所学，构建一个酷炫的相机应用程序，当它检测到微笑的面孔时会自动拍照。
- en: 'The trick is that we will use two different types of cascade classifiers. First,
    we will use Haar cascades to find faces on the image and store the positions of
    all the faces. Then we will use the Haar cascades to detect smiles in an image
    and store them. Now we try to match the face with a smile. For each smile, we
    find the corresponding face in the image. This is simple: if the smiling region
    is within any detected face region, we say that it''s a match.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 诀窍在于我们将使用两种不同类型的级联分类器。首先，我们将使用Haar级联在图像中找到面孔并存储所有面孔的位置。然后我们将使用Haar级联在图像中检测微笑并存储它们。现在我们尝试匹配带有微笑的面孔。对于每个微笑，我们在图像中找到相应的面孔。这是简单的：如果微笑区域在任何检测到的面孔区域内，我们就说这是一个匹配。
- en: After locating all the smiling faces in the image, find the ratio of the smiling
    faces to all faces to nonsmiling faces, and if that ratio is greater than a certain
    threshold we say that it's a happy picture and click the image. Though one thing
    to note here is the ratio that we are using. We can use a different metric to
    tag an image as a happy image. If we calculate the ratio of smiling faces to total
    faces, there is a problem that if you have just two people in the image and one
    of them is not smiling (or has a standard expression), then our application will
    not click an image. Hence, to avoid such situations, we choose to have a relaxed
    ratio of smiling faces to nonsmiling faces in order to classify images as happy
    images.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在定位到图像中所有微笑的面部后，计算微笑面部与所有面部（微笑和不微笑）的比例，如果这个比例超过某个阈值，我们就说这是一张快乐的图片，然后点击图片。不过这里要注意的一点是我们使用的比例。我们可以使用不同的指标来标记图像为快乐图像。如果我们计算微笑面部与总面部的比例，会存在一个问题，如果你图像中只有两个人，其中一个人没有微笑（或者有标准表情），那么我们的应用程序将不会点击图片。因此，为了避免这种情况，我们选择对微笑面部与不微笑面部的比例采取宽松的策略，以便将图像分类为快乐图像。
- en: 'How do we go about building this application? Most parts of the application
    have already been discussed in this chapter. The remaining parts of the application
    are as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何构建这个应用程序？本章已经讨论了应用程序的大部分内容。应用程序剩余的部分如下：
- en: '**Adding a smile detector**: This is very simple. It is exactly the same as
    what we did to detect faces; instead here, we will use Haar cascades for smiles.
    You can find a pretrained model at [https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_smile.xml](https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_smile.xml).'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**添加微笑检测器**：这非常简单。它与我们检测面部的方法完全相同；在这里，我们将使用Haar级联来检测微笑。你可以在[https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_smile.xml](https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_smile.xml)找到预训练模型。'
- en: '**Correlating faces and smiles**: Once we have faces and smiles, we need to
    find matching pairs of faces and smiles in the image. Why do we want to correlate
    them? Why not use the number of smiles directly? Yes, we can do that. It is not
    necessary to correlate faces and smiles. The only advantage of doing this extra
    step is to reduce the false positives. If there is no corresponding face for a
    smile, we can choose to ignore that smile in our calculations.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**关联面部和微笑**：一旦我们有了面部和微笑，我们需要在图像中找到匹配的面部和微笑对。我们为什么要关联它们？为什么不直接使用微笑的数量呢？是的，我们可以这样做。没有必要关联面部和微笑。这样做额外步骤的唯一优势是减少误报。如果一个微笑没有对应的面部，我们可以在计算中忽略那个微笑。'
- en: '**Tagging happy images**: Once you have the face and smile pairs ready, calculate
    the ratio (explained earlier) and make a decision on whether you want to save
    that image or not.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**标记快乐图像**：一旦你准备好了面部和微笑对，计算（前面解释过）的比例，并决定是否保存那张图像。'
- en: '**Actually saving the image**: After tagging the image as a happy image, make
    a function that will actually save the image to your phone.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实际上保存图像**：在标记图像为快乐图像后，创建一个函数，将图像实际保存到你的手机上。'
- en: You just made a cool camera application!
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚创建了一个酷炫的相机应用程序！
- en: Only after you have tried to build this application yourself, you can take a
    look at a sample implementation from the code bundle that accompanies this book.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在你自己尝试构建这个应用程序之后，你才能查看本书附带的代码包中的示例实现。
- en: Summary
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter was a continuation of the last chapter, where we saw some basic
    feature detection algorithms. Here we have learnt a few more algorithms that can
    be used in face, eye, and person detection. Cascade classifiers are a type of
    supervised learning models, where we first train a classifier with some labelled
    data, and then use the trained model to detect new unencountered data.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是上一章的延续，其中我们看到了一些基本特征检测算法。在这里，我们学习了更多可以用于面部、眼睛和人体检测的算法。级联分类器是一种监督学习模型，我们首先使用一些标记数据训练一个分类器，然后使用训练好的模型来检测新的未遇到的数据。
- en: In the coming chapters, we will take a look at topics such as image stitching
    and how to use machine learning in computer vision algorithms.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探讨图像拼接以及如何在计算机视觉算法中使用机器学习等主题。
