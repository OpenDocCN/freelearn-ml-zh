["```py\n# load essential libraries\nimport math\nimport os\n\nimport tensorflow as tf\n\n%pylab inline\n```", "```py\n# load Tensorflow/Google Brain base code\n# https://github.com/tensorflow/models/tree/master/research/im2txt\n\nfrom im2txt import configuration\nfrom im2txt import inference_wrapper\nfrom im2txt.inference_utils import caption_generator\nfrom im2txt.inference_utils import vocabulary\n```", "```py\n# tell our function where to find the trained model and vocabulary\ncheckpoint_path = './model'\nvocab_file = './model/word_counts.txt'\n```", "```py\n# this is the function we'll call to produce our captions \n# given input file name(s) -- separate file names by a,\n# if more than one\n\ndef gen_caption(input_files):\n    # only print serious log messages\n    tf.logging.set_verbosity(tf.logging.FATAL)\n    # load our pretrained model\n    g = tf.Graph()\n    with g.as_default():\n        model = inference_wrapper.InferenceWrapper()\n        restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n                                                 checkpoint_path)\n    g.finalize()\n```", "```py\n    # Create the vocabulary.\n    vocab = vocabulary.Vocabulary(vocab_file)\n```", "```py\n    filenames = []\n    for file_pattern in input_files.split(\",\"):\n```", "```py\n        filenames.extend(tf.gfile.Glob(file_pattern))\n```", "```py\n    tf.logging.info(\"Running caption generation on %d files matching %s\",\n                    len(filenames), input_files)\n```", "```py\n    with tf.Session(graph=g) as sess:\n        # Load the model from checkpoint.\n        restore_fn(sess)\n```", "```py\n# this is the function we'll call to produce our captions \n# given input file name(s) -- separate file names by a,\n# if more than one\n\ndef gen_caption(input_files):\n    # only print serious log messages\n    tf.logging.set_verbosity(tf.logging.FATAL)\n    # load our pretrained model\n    g = tf.Graph()\n    with g.as_default():\n        model = inference_wrapper.InferenceWrapper()\n        restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n                                                 checkpoint_path)\n    g.finalize()\n\n    # Create the vocabulary.\n    vocab = vocabulary.Vocabulary(vocab_file)\n\n    filenames = []\n    for file_pattern in input_files.split(\",\"):\n        filenames.extend(tf.gfile.Glob(file_pattern))\n    tf.logging.info(\"Running caption generation on %d files matching %s\",\n                    len(filenames), input_files)\n\n    with tf.Session(graph=g) as sess:\n        # Load the model from checkpoint.\n        restore_fn(sess)\n```", "```py\n        generator = caption_generator.CaptionGenerator(model, vocab)\n```", "```py\n        captionlist = []\n```", "```py\n        for filename in filenames:\n            with tf.gfile.GFile(filename, \"rb\") as f:\n                image = f.read()\n            captions = generator.beam_search(sess, image)\n```", "```py\n            print(\"Captions for image %s:\" % os.path.basename(filename))\n```", "```py\n            for i, caption in enumerate(captions):\n                # Ignore begin and end words.\n                sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n                sentence = \" \".join(sentence)\n                print(\" %d) %s (p=%f)\" % (i, sentence, math.exp(caption.logprob)))\n                captionlist.append(sentence)\n```", "```py\n    return captionlist\n```", "```py\n    # Prepare the caption generator. Here we are implicitly using the default\n    # beam search parameters. See caption_generator.py for a description of the\n    # available beam search parameters.\n        generator = caption_generator.CaptionGenerator(model, vocab)\n\n        captionlist = []\n\n        for filename in filenames:\n            with tf.gfile.GFile(filename, \"rb\") as f:\n                image = f.read()\n            captions = generator.beam_search(sess, image)\n            print(\"Captions for image %s:\" % os.path.basename(filename))\n            for i, caption in enumerate(captions):\n                # Ignore begin and end words.\n                sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n                sentence = \" \".join(sentence)\n                print(\" %d) %s (p=%f)\" % (i, sentence, math.exp(caption.logprob)))\n                captionlist.append(sentence)\n    return captionlist\n```", "```py\ntestfile = 'test_images/dog.jpeg'\n\nfigure()\nimshow(imread(testfile))\n\ncapts = gen_caption(testfile)\n```", "```py\ninput_files = 'test_images/ballons.jpeg,test_images/bike.jpeg,test_images/dog.jpeg,test_images/fireworks.jpeg,test_images/football.jpeg,test_images/giraffes.jpeg,test_images/headphones.jpeg,test_images/laughing.jpeg,test_images/objects.jpeg,test_images/snowboard.jpeg,test_images/surfing.jpeg'\n\ncapts = gen_caption(input_files)\n```", "```py\n# First download pretrained Inception (v3) model\n\nimport webbrowser \nwebbrowser.open(\"http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\")\n\n# Completely unzip tar.gz file to get inception_v3.ckpt,\n# --recommend storing in im2txt/data directory\n```", "```py\n# Now gather and prepare the MSCOCO data\n\n# Comment out cd magic command if already in data directory\n%cd im2txt/data\n# This command will take an hour or more to run typically.\n# Note, you will need a lot of HD space (>100 GB)!\n%run build_mscoco_data.py\n\n# At this point you have files in im2txt/data/mscoco/raw-data that you can train\n# on, or you can substitute your own data\n\n%cd ..\n\n# load needed modules\n\nimport tensorflow as tf\n\nfrom im2txt import configuration\nfrom im2txt import show_and_tell_model\n```", "```py\n# Initial training\ninput_file_pattern = 'im2txt/data/mscoco/train-?????-of-00256'\n\n# change these if you put your stuff somewhere else\ninception_checkpoint_file = 'im2txt/data/inception_v3.ckpt'\ntrain_dir = 'im2txt/model'\n\n# Don't train inception for initial run\ntrain_inception = False\nnumber_of_steps = 1000000\nlog_every_n_steps = 1\n```", "```py\ndef train():\n    model_config = configuration.ModelConfig()\n    model_config.input_file_pattern = input_file_pattern\n    model_config.inception_checkpoint_file = inception_checkpoint_file\n    training_config = configuration.TrainingConfig()  \n```", "```py\n    train_dir = train_dir\n    if not tf.gfile.IsDirectory(train_dir):\n        tf.logging.info(\"Creating training directory: %s\", train_dir)\n        tf.gfile.MakeDirs(train_dir)\n\n```", "```py\n    g = tf.Graph()\n    with g.as_default():\n\n```", "```py\n        model = show_and_tell_model.ShowAndTellModel(\n                model_config, mode=\"train\", train_inception=train_inception)\n        model.build()\n\n```", "```py\n        learning_rate_decay_fn = None\n        if train_inception:\n            learning_rate = tf.constant(training_config.train_inception_learning_rate)\n        else:\n            learning_rate = tf.constant(training_config.initial_learning_rate)\n            if training_config.learning_rate_decay_factor > 0:\n                num_batches_per_epoch = (training_config.num_examples_per_epoch /\n                                 model_config.batch_size)\n                decay_steps = int(num_batches_per_epoch *\n                          training_config.num_epochs_per_decay)\n\n                def _learning_rate_decay_fn(learning_rate, global_step):\n                    return tf.train.exponential_decay(\n                                      learning_rate,\n                                      global_step,\n                                      decay_steps=decay_steps,\n                                      decay_rate=training_config.learning_rate_decay_factor,\n                                      staircase=True)\n\n                learning_rate_decay_fn = _learning_rate_decay_fn\n\n```", "```py\n        train_op = tf.contrib.layers.optimize_loss(\n                                        loss=model.total_loss,\n                                        global_step=model.global_step,\n                                        learning_rate=learning_rate,\n                                        optimizer=training_config.optimizer,\n                                        clip_gradients=training_config.clip_gradients,\n                                        learning_rate_decay_fn=learning_rate_decay_fn)\n\n```", "```py\n        saver = tf.train.Saver(max_to_keep=training_config.max_checkpoints_to_keep)\n\n    # Run training.\n    tf.contrib.slim.learning.train(\n                                train_op,\n                                train_dir,\n                                log_every_n_steps=log_every_n_steps,\n                                graph=g,\n                                global_step=model.global_step,\n                                number_of_steps=number_of_steps,\n                                init_fn=model.init_fn,\n                                saver=saver)\n```", "```py\ntrain()\n```", "```py\n# Fine tuning\ninput_file_pattern = 'im2txt/data/mscoco/train-?????-of-00256'\n\n# change these if you put your stuff somewhere else\ninception_checkpoint_file = 'im2txt/data/inception_v3.ckpt'\ntrain_dir = 'im2txt/model'\n\n# This will refine our results\ntrain_inception = True\nnumber_of_steps = 3000000\nlog_every_n_steps = 1\n\n# Now run the training (warning: takes even longer than initial training!!!)\ntrain()\n```", "```py\n# tell our function where to find the trained model and vocabulary\ncheckpoint_path = './model'\nvocab_file = './model/word_counts.txt'\n```", "```py\ntestfile = 'test_images/ballons.jpeg'\n\nfigure()\nimshow(imread(testfile))\n\ncapts = gen_caption(testfile)\n```"]