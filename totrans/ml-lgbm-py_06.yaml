- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Solving Real-World Data Science Problems with LightGBM
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LightGBM解决现实世界的数据科学问题
- en: With the preceding chapters, we have slowly been building out a toolset for
    us to be able to solve machine learning problems. We’ve seen examples of examining
    our data, addressing data issues, and creating models. This chapter formally defines
    and applies the data science process to two case studies.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们逐渐构建了一套工具集，使我们能够解决机器学习问题。我们看到了检查数据、解决数据问题和创建模型的例子。本章正式定义并应用数据科学流程到两个案例研究中。
- en: The chapter gives a detailed overview of the data science life cycle and all
    the steps it encompasses. The concepts of problem definition, data exploration,
    data cleaning, modeling, and reporting are discussed in a regression and classification
    problem context. We also look at preparing data for modeling and building optimized
    LightGBM models using our learned techniques. Finally, we look deeper at utilizing
    a trained model as an introduction to **machine learning** **operations** (**MLOps**).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章详细概述了数据科学生命周期及其包含的所有步骤。在回归和分类问题背景下，讨论了问题定义、数据探索、数据清洗、建模和报告的概念。我们还探讨了使用所学技术准备数据以及构建优化后的LightGBM模型。最后，我们深入探讨了如何利用训练好的模型作为机器学习**操作**（**MLOps**）的介绍。
- en: 'The main topics of this chapter are as follows:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要内容包括：
- en: The data science life cycle
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学生命周期
- en: Predicting wind turbine power generation with LightGBM
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LightGBM预测风力涡轮机发电量
- en: Classifying individual credit scores with LightGBM
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LightGBM对个人信用评分进行分类
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The chapter includes examples and code excerpts illustrating how to perform
    parameter optimization studies for LightGBM using Optuna. Complete examples and
    instructions for setting up a suitable environment for this chapter are available
    at [https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含示例和代码片段，展示了如何使用Optuna对LightGBM进行参数优化研究。关于设置本章所需环境的完整示例和说明可在[https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6)找到。
- en: The data science life cycle
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学生命周期
- en: Data science has emerged as a critical discipline, enabling organizations to
    derive valuable insights from their data and drive better decision-making. At
    the heart of data science lies the data science life cycle, a systematic, iterative
    process that guides data-driven problem-solving across various industries and
    domains. This life cycle outlines a series of steps that data scientists follow
    to ensure they address the right problem and deliver actionable insights that
    create real-world impact.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学已成为一门关键学科，使组织能够从其数据中提取有价值的见解并推动更好的决策。数据科学的核心是数据科学生命周期，这是一个系统、迭代的流程，指导数据驱动的解决问题的各种行业和领域。此生命周期概述了一系列数据科学家遵循的步骤，以确保他们解决正确的问题，并提供可操作见解，以产生实际影响。
- en: The first stage of the data science life cycle involves defining the problem,
    which entails understanding the business context, articulating objectives, and
    formulating hypotheses. This crucial stage establishes the entire project’s foundation
    by establishing a clear direction and scope. Subsequent stages in the life cycle
    focus on data collection, preparation, and exploration, collectively involving
    gathering relevant data, cleaning and preprocessing it, and conducting exploratory
    data analysis to unveil patterns and trends.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学生命周期的第一阶段涉及定义问题，这包括理解业务背景、阐述目标和制定假设。这一关键阶段通过确立明确的方向和范围，为整个项目奠定了基础。生命周期中的后续阶段侧重于数据收集、准备和探索，共同涉及收集相关数据、清洗和预处理它，以及进行探索性数据分析以揭示模式和趋势。
- en: Once the data is analyzed, the data science life cycle progresses to model selection,
    training, evaluation, and tuning. These stages are central to developing accurate
    and reliable predictive or descriptive models by choosing the most appropriate
    algorithms, training them on the preprocessed data, and optimizing their performance.
    The goal is to build a robust model that generalizes well to unseen data and addresses
    the problem at hand effectively.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析完成后，数据科学生命周期进入模型选择、训练、评估和调整阶段。这些阶段通过选择最合适的算法、在预处理数据上训练它们并优化其性能，对于开发准确和可靠的预测或描述性模型至关重要。目标是构建一个健壮的模型，能够很好地泛化到未见数据，并有效地解决当前问题。
- en: Lastly, the data science life cycle emphasizes the importance of deploying the
    final model into a production environment, monitoring its performance, and maintaining
    it to ensure its ongoing relevance and accuracy. Equally important is the communication
    of results and insights to stakeholders, which is vital for driving informed decision-making
    and realizing the full potential of data science. By following the data science
    life cycle, organizations can systematically extract value from their data and
    unlock new opportunities for growth and innovation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，数据科学生命周期强调将最终模型部署到生产环境中的重要性，监控其性能，并维护它以确保其持续的相关性和准确性。同样重要的是将结果和见解传达给利益相关者，这对于推动明智的决策和实现数据科学全部潜力至关重要。通过遵循数据科学生命周期，组织可以系统地从数据中提取价值，并解锁增长和创新的新机会。
- en: With previous examples, we followed a loose recipe of steps for working with
    data and creating models. In the next section, we formally define and discuss
    the steps of the data science life cycle.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的示例中，我们遵循了一个松散的步骤食谱来处理数据和创建模型。在下一节中，我们将正式定义并讨论数据科学生命周期的步骤。
- en: Defining the data science life cycle
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义数据科学生命周期
- en: The following are the key steps broadly applied in the data science life cycle.
    The steps are also shown in *Figure 6**.1*, which illustrates the cyclical nature
    of the life cycle.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在数据科学生命周期中广泛应用的几个关键步骤。这些步骤也在*图 6.1*中展示，该图说明了生命周期的循环性质。
- en: '![Figure 6.1 – Diagram depicting the data science life cycle](img/B16690_06_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.1 – 描述数据科学生命周期的图](img/B16690_06_01.jpg)'
- en: Figure 6.1 – Diagram depicting the data science life cycle
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1 – 描述数据科学生命周期的图
- en: 'These are the key steps:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是关键步骤：
- en: '**Define the problem**: Clearly articulate the business problem, goals, and
    objectives. This stage involves understanding stakeholder requirements, formulating
    hypotheses, and determining the project’s scope. Defining the problem also sets
    the stage for data collection and can determine how we’ll utilize our models.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定义问题**：明确阐述业务问题、目标和目标。这一阶段涉及理解利益相关者的需求、制定假设和确定项目的范围。定义问题还为数据收集设定了舞台，并可能决定我们将如何利用我们的模型。'
- en: '**Data collection**: Gather the required data from various sources, such as
    databases, APIs, web scraping, or third-party data providers. Ensure the data
    is representative, accurate, and relevant to the problem. It is important to document
    where data originates and how it is moved around to establish the **data lineage**.
    Further, build a **data dictionary** that documents the data’s format, structure,
    content, and meaning. Importantly, validate any potential bias in the collection
    or sampling of data.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据收集**：从各种来源收集所需数据，例如数据库、API、网络抓取或第三方数据提供商。确保数据具有代表性、准确性和与问题的相关性。记录数据的来源和移动方式对于建立**数据血缘**很重要。此外，构建一个**数据字典**来记录数据的格式、结构、内容和意义。重要的是，验证数据收集或抽样过程中可能存在的任何潜在偏差。'
- en: '**Data preparation**: Clean and preprocess the data to make it suitable for
    analysis. This stage includes tasks such as **data cleansing** (e.g., handling
    missing values and removing duplicates), **data transformation** (e.g., normalization
    and encoding categorical variables), and **feature engineering** (e.g., creating
    new variables or aggregating existing ones). Moving and joining the data to where
    it can be analyzed and modeled might also be necessary.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据准备**：清洁和预处理数据，使其适合分析。这一阶段包括诸如**数据清洗**（例如，处理缺失值和删除重复项）、**数据转换**（例如，归一化和编码分类变量）和**特征工程**（例如，创建新变量或聚合现有变量）等任务。将数据移动和合并到可以进行分析和建模的地方可能也是必要的。'
- en: '**Data exploration**: Conduct **exploratory data analysis** (**EDA**) to gain
    insights into the data. This step involves visualizing data distributions, identifying
    trends and patterns, detecting outliers and anomalies, and checking for relationships
    and correlations between features.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据探索**：通过进行**探索性数据分析**（EDA）来深入了解数据。这一步骤包括可视化数据分布，识别趋势和模式，检测异常值和异常，以及检查特征之间的关系和相关性。'
- en: '**Model selection**: Choose the most appropriate data modeling techniques based
    on the problem type (e.g., regression, classification, or clustering) and the
    data characteristics. It’s important to choose multiple model algorithms to validate
    performance on the data set.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型选择**：根据问题类型（例如，回归、分类或聚类）和数据特征选择最合适的数据建模技术。选择多个模型算法来验证数据集上的性能是很重要的。'
- en: '**Model training**: Train the selected models using the prepared data. This
    step involves splitting the data into training and validation sets, setting model
    parameters (hyperparameters), and fitting the models to the data.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型训练**：使用准备好的数据训练选定的模型。这一步骤包括将数据分为训练集和验证集，设置模型参数（超参数），并将模型拟合到数据中。'
- en: '**Model evaluation**: Assess the performance of the trained models using appropriate
    evaluation metrics (e.g., accuracy, precision, recall, F1-score, **Area under
    the ROC Curve** (**AUC-ROC**), or **root mean square error** (**RMSE**)) and compare
    them to select the best-performing model(s). Perform cross-validation or use holdout
    test sets to ensure an unbiased evaluation.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型评估**：使用适当的评估指标（例如，准确率、精确率、召回率、F1分数、**ROC曲线下面积**（AUC-ROC）或**均方根误差**（RMSE））评估训练模型的性能，并将它们进行比较以选择性能最佳的模型。进行交叉验证或使用保留测试集以确保无偏评估。'
- en: '**Model tuning**: Fine-tune the selected model by optimizing hyperparameters,
    feature selection, or incorporating domain knowledge. This step aims to improve
    the model’s performance and generalization to unseen data. It might also be appropriate
    to tune the model for the specific problem; for instance, when recognizing faces,
    a higher precision is more appropriate than a high recall.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型调优**：通过优化超参数、特征选择或结合领域知识来微调选定的模型。这一步骤旨在提高模型性能和泛化到未见数据的能力。对于特定问题调整模型也可能是合适的；例如，在识别面部时，更高的精确度比高召回率更合适。'
- en: '**Model deployment**: If the model is to be part of a more extensive software
    system, deploy the final model into a production environment, where it can be
    used to make predictions or inform decision-making. Deployment may involve integrating
    the model into existing systems, creating APIs, or setting up monitoring and maintenance
    procedures.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型部署**：如果模型要成为更广泛软件系统的一部分，将其最终模型部署到生产环境中，以便用于做出预测或提供决策信息。部署可能涉及将模型集成到现有系统中，创建API，或设置监控和维护程序。'
- en: '**Model monitoring and maintenance**: Continuously monitor the model’s performance
    and update it as necessary to ensure it remains accurate and relevant. Techniques
    such as detecting model and data drift should be used to ensure model performance.
    Model maintenance may involve retraining the model with new data, updating features,
    or refining the problem definition.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型监控和维护**：持续监控模型的性能，并在必要时更新它，以确保其保持准确性和相关性。应使用检测模型和数据漂移等技术来确保模型性能。模型维护可能涉及使用新数据重新训练模型，更新特征，或细化问题定义。'
- en: '**Communicate results**: Share insights and results with stakeholders, including
    any recommendations or actions based on the analysis. Communicating the results
    may involve creating visualizations, dashboards, or reports to communicate the
    findings effectively.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**沟通结果**：与利益相关者分享见解和结果，包括基于分析的任何建议或行动。沟通结果可能涉及创建可视化、仪表板或报告，以有效地传达发现。'
- en: We now examine two case studies to see how the data science life cycle is applied
    practically to real-world data. We look at a regression problem, predicting wind
    turbine power generation, and a classification problem, classifying individual
    credit scores.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在考察两个案例研究，以了解数据科学生命周期如何实际应用于现实世界的数据。我们研究了一个回归问题，即预测风力涡轮机发电量，以及一个分类问题，即对个人信用评分进行分类。
- en: Predicting wind turbine power generation with LightGBM
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LightGBM预测风力涡轮机发电量
- en: Our first case study is a problem where we aim to predict the power generation
    of wind turbines. The dataset for the problem is available from [https://www.kaggle.com/datasets/mukund23/hackerearth-machine-learning-challenge](https://www.kaggle.com/datasets/mukund23/hackerearth-machine-learning-challenge).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个案例研究是一个旨在预测风力涡轮机发电功率的问题。该问题的数据集可以从[https://www.kaggle.com/datasets/mukund23/hackerearth-machine-learning-challenge](https://www.kaggle.com/datasets/mukund23/hackerearth-machine-learning-challenge)获取。
- en: We work through the problem using the steps defined in the previous section,
    articulating the details involved in each step alongside code snippets. The complete
    end-to-en[d solution is available at https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/wind](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/wind-turbine-power-output.ipynb)-turbine-power-output.ipynb.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用前一部分中定义的步骤来处理这个问题，同时详细说明每个步骤中涉及的内容以及代码片段。完整的最终解决方案可在https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/wind-turbine-power-output.ipynb处找到。
- en: Problem definition
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题定义
- en: The dataset consists of power generation (in kW/h) measurements of wind turbines
    taken at a specific date and time. Alongside each measurement are the parameters
    of the wind turbine, which include physical measurements of the windmill (including
    windmill height, blade breadth, and length), operating measurements for the turbine
    (including resistance in ohms, motor torque, generator temperature, and rotor
    torque) and atmospheric conditions (including wind speed, temperature, and pressure).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含在特定日期和时间测量的风力涡轮机发电功率（kW/h）测量值。每个测量值旁边都有风力涡轮机的参数，包括风车的物理测量（包括风车高度、叶片宽度和长度）、涡轮机的运行测量（包括电阻（欧姆）、电机扭矩、发电机温度和转子扭矩）以及大气条件（包括风速、温度和压力）。
- en: Given the set of parameters, we must build a regression model to predict the
    generated power in kW/h. Therefore, we employ regression modeling. The quality
    of the model is measured using the **mean squared error** (**MSE**) and the coefficient
    of determination (R 2). We must also determine which factors have the most significant
    impact on power generation.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 给定参数集，我们必须构建一个回归模型来预测生成的功率（kW/h）。因此，我们采用回归建模。模型的质量通过**均方误差**（MSE）和决定系数（R²）来衡量。我们还必须确定哪些因素对发电影响最大。
- en: Data collection
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据收集
- en: The dataset comprises 22,800 samples collected within 11 months, from October
    2018 to September 2019\. The data is available as CSV files and is released as
    public domain data. No additional data is collected.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含在2018年10月至2019年9月11个月内收集的22,800个样本。数据以CSV文件形式提供，并作为公共领域数据发布。没有收集额外的数据。
- en: Data preparation
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'We can now look at preparing the data for cleaning and exploration. The dataset
    consists of 18 numerical features, 2 categorical features, and the date feature,
    as we can see by getting the information from our pandas DataFrame:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以查看准备数据以进行清洗和探索。通过从我们的pandas DataFrame获取信息，我们可以看到数据集包含18个数值特征、2个分类特征和日期特征：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can immediately see that the dataset has missing values, with some features
    having fewer than 28,200 values. We can get a better sense of the data distribution
    by calculating the statistical description:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以立即看到数据集中存在缺失值，一些特征少于28,200个值。我们可以通过计算统计描述来更好地了解数据分布：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This prints out the following:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出以下内容：
- en: '| **Feature** | **count** | **mean** | **std** | **min** | **max** |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| **特征** | **计数** | **平均值** | **标准差** | **最小值** | **最大值** |'
- en: '| wind_speed(m/s) | 27927 | 69.04 | 76.28 | -496.21 | 601.46 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 风速(m/s) | 27927 | 69.04 | 76.28 | -496.21 | 601.46 |'
- en: '| atmospheric_temperature(°C) | 24750 | 0.38 | 44.28 | -99.00 | 80.22 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 大气温度(°C) | 24750 | 0.38 | 44.28 | -99.00 | 80.22 |'
- en: '| shaft_temperature(°C) | 28198 | 40.09 | 27.20 | -99.00 | 169.82 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 轴温度(°C) | 28198 | 40.09 | 27.20 | -99.00 | 169.82 |'
- en: '| blades_angle(°) | 27984 | -9.65 | 47.92 | -146.26 | 165.93 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 叶片角度(°) | 27984 | -9.65 | 47.92 | -146.26 | 165.93 |'
- en: '| gearbox_temperature(°C) | 28199 | 41.03 | 43.66 | -244.97 | 999.00 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 传动箱温度(°C) | 28199 | 41.03 | 43.66 | -244.97 | 999.00 |'
- en: '| engine_temperature(°C) | 28188 | 42.61 | 6.12 | 3.17 | 50.00 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 发动机温度(°C) | 28188 | 42.61 | 6.12 | 3.17 | 50.00 |'
- en: '| motor_torque(N-m) | 28176 | 1710 | 827 | 500 | 3000.00 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 电机扭矩(N-m) | 28176 | 1710 | 827 | 500 | 3000.00 |'
- en: '| generator_temperature(°C) | 28188 | 65.03 | 19.82 | 33.89 | 100.00 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 发电机温度(°C) | 28188 | 65.03 | 19.82 | 33.89 | 100.00 |'
- en: '| atmospheric_pressure(Pascal) | 25493 | 53185 | 187504 | -1188624 | 1272552
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 大气压力(Pascal) | 25493 | 53185 | 187504 | -1188624 | 1272552 |'
- en: '| area_temperature(°C) | 28200 | 32.74 | 7.70 | -30.00 | 55.00 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 面积温度(°C) | 28200 | 32.74 | 7.70 | -30.00 | 55.00 |'
- en: '| windmill_body_temperature(°C) | 25837 | 20.80 | 54.36 | -999.00 | 323.00
    |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 风机本体温度(°C) | 25837 | 20.80 | 54.36 | -999.00 | 323.00 |'
- en: '| wind_direction(°) | 23097 | 306.89 | 134.06 | 0.00 | 569.97 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 风向(°) | 23097 | 306.89 | 134.06 | 0.00 | 569.97 |'
- en: '| resistance(ohm) | 28199 | 1575.6 | 483.33 | -1005.22 | 4693.48 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 阻抗(欧姆) | 28199 | 1575.6 | 483.33 | -1005.22 | 4693.48 |'
- en: '| rotor_torque(N-m) | 27628 | 25.85 | 32.42 | -136.73 | 236.88 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 转子扭矩(N-m) | 27628 | 25.85 | 32.42 | -136.73 | 236.88 |'
- en: '| blade_length(m) | 23107 | 2.25 | 11.28 | -99.00 | 18.21 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 叶片长度(m) | 23107 | 2.25 | 11.28 | -99.00 | 18.21 |'
- en: '| blade_breadth(m) | 28200 | 0.40 | 0.06 | 0.20 | 0.50 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 叶片宽度(m) | 28200 | 0.40 | 0.06 | 0.20 | 0.50 |'
- en: '| windmill_height(m) | 27657 | 25.89 | 7.77 | -30.30 | 78.35 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 风机高度(m) | 27657 | 25.89 | 7.77 | -30.30 | 78.35 |'
- en: '| windmill_generated_power (kW/h) | 27993 | 6.13 | 2.70 | 0.96 | 20.18 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 风机发电功率 (kW/h) | 27993 | 6.13 | 2.70 | 0.96 | 20.18 |'
- en: Table 6.1 – Statistical description of numerical features in the Wind Turbine
    dataset
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.1 – 风机数据集中数值特征的统计描述
- en: 'Looking at the statistical description of the features in *Table 6.1*, we can
    see the following irregularities:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 观察表6.1中特征的统计描述，我们可以看到以下不规则性：
- en: '**Many features have outliers**: Generally, a standard deviation larger than
    the mean may indicate outlying values. Examples include wind speed, atmospheric
    temperature, and atmospheric pressure. Similarly, a minimum or maximum far away
    from the mean may indicate outliers in the data. We can further verify this by
    visualizing the data distribution using a histogram.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**许多特征存在异常值**：通常，标准差大于平均值可能表明存在异常值。例如，风速、大气温度和大气压力。同样，远离平均值的最大值或最小值可能表明数据中存在异常值。我们可以通过使用直方图可视化数据分布来进一步验证这一点。'
- en: '**Physical impossibilities**: The data shows impossibilities in the data of
    some of the measurements: lengths (in meters) less than 0 (e.g., blade length)
    and temperatures outside of natural ranges (a body temperature of -999).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**物理不可能性**：数据显示某些测量数据中存在不可能性：长度（以米为单位）小于0（例如，叶片长度）和温度超出自然范围（体温为-999）。'
- en: '`-99.0` and `-999.0` repeat for a few features. It’s improbable that these
    values occur naturally across features. We can infer that these indicate missing
    or erroneous measurements in the sample.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-99.0`和`-999.0`在几个特征中重复。这些值在特征之间自然发生的可能性很小。我们可以推断这些值表明样本中存在缺失或错误的测量。'
- en: 'We can visualize the distribution of features to investigate the outlying values.
    For example, for atmospheric temperature, we have the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以可视化特征的分布，以调查异常值。例如，对于大气温度，我们有以下：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Figure 6.2 – Histogram showing atmospheric temperature in Celsius](img/B16690_06_02.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图6.2 – 以摄氏度显示的大气温度直方图](img/B16690_06_02.jpg)'
- en: Figure 6.2 – Histogram showing atmospheric temperature in Celsius
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 以摄氏度显示的大气温度直方图
- en: '*Figure 6**.2* illustrates two of the issues found in the data: a high frequency
    of measurements with a value of precisely `-99.0`, indicating an error. A few
    outlying values are also far removed from the mean.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.2* 展示了数据中发现的问题中的两个：精确值为`-99.0`的测量值的高频率，表明存在错误。一些异常值也远离平均值。'
- en: 'Finally, we can check for duplicate data using the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用以下方法检查重复数据：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: No rows are returned, indicating no duplicates in the dataset.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 没有返回行，表示数据集中没有重复项。
- en: Data cleaning
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据清洗
- en: 'We have identified multiple issues in the dataset that we need to address as
    part of the *data* *cleaning* step:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在数据集中识别出多个问题，这些问题需要作为数据清洗步骤的一部分来解决：
- en: '**Outliers**: Many features have outlier values that skew the distribution
    of values for the feature.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值**：许多特征具有使该特征值分布扭曲的异常值。'
- en: '**Measurement errors**: Some features have values that fall out of the bounds
    of physical impossibilities (lengths smaller than 0 or temperatures in impossible
    ranges).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测量误差**：一些特征具有超出物理不可能性范围（长度小于0或温度在不可能范围内）的值。'
- en: '`-99.0` and `-999.0`) that we consider missing.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-99.0`和`-999.0`被视为缺失值。'
- en: We first address the outliers and measurement errors, as this impacts how we
    handle the missing values.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先解决异常值和测量误差，因为这会影响我们处理缺失值的方式。
- en: Dealing with outliers
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 处理异常值
- en: 'There are two parts to dealing with outliers in a dataset: accurately identifying
    outliers and choosing appropriate values for replacement. Ways to identify outliers
    are as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 处理数据集中的异常值有两个方面：准确识别异常值和选择适当的替换值。识别异常值的方法如下：
- en: '**Visualization**: As shown previously, histograms or other plots that visualize
    the data distribution (such as box plots or scatter plots) can be used'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可视化**: 如前所述，可以使用直方图或其他可视化数据分布的图表（如箱线图或散点图）。'
- en: '**Domain knowledge**: Like how we identify measurement errors, domain knowledge
    can be leveraged to decide whether values are outlying'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域知识**: 就像我们识别测量误差一样，可以利用领域知识来决定值是否异常'
- en: '**Statistical analysis**: Two popular methods for determining whether values
    are outlying using statistics are the **interquartile range** (**IQR**) and the
    standard deviation.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统计分析**: 使用统计方法确定值是否异常的两种流行方法是**四分位数间距（IQR**）和标准差。'
- en: The IQR is the difference between the 25th and 75th quartiles. Values over 1.5
    times the IQR away from the 25th or 75th quartiles are considered outlying.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 四分位数间距（IQR）是第25百分位数和第75百分位数之间的差值。距离第25或第75百分位数超过1.5倍IQR的值被认为是异常值。
- en: 'Alternatively, we can leverage the standard deviation: we calculate the mean
    and standard deviation of the dataset. Any values over two or three times removed
    from the mean are outlying. Setting bounds to twice or three times the standard
    deviation depends on the underlying data. Using twice the standard deviation could
    lead to many false positives, but it is appropriate if a lot of data is centered
    around the mean. Using three times the standard deviation is more conservative
    and only marks values very far from the mean as outlying.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以利用标准差：我们计算数据集的均值和标准差。任何超过均值两倍或三倍的数据值都是异常值。将界限设置为标准差的二倍或三倍取决于基础数据。使用两倍标准差可能导致许多误报，但如果大量数据集中在均值附近，则这是合适的。使用三倍标准差更为保守，并且仅将非常远离均值的值标记为异常值。
- en: 'When the outlying values are detected, we must do something about them. Generally,
    our options are as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当检测到异常值时，我们必须对它们采取行动。通常，我们的选择如下：
- en: '**Remove**: If an outlier results from an error in data entry, measurement,
    or collection, it may be reasonable to remove it from the dataset. However, this
    should be done cautiously, as removing too many data points can lead to a loss
    of information and biased results. Removing instances with outliers in our dataset
    would result in close to 70% data loss and isn’t an option.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**移除**: 如果异常值是由于数据输入、测量或收集中的错误造成的，那么从数据集中移除它可能是合理的。但是，应该谨慎行事，因为移除过多的数据点可能导致信息丢失和结果偏差。在我们的数据集中移除包含异常值的实例将导致近70%的数据丢失，这不是一个选择。'
- en: '**Impute**: Similar to missing values, replace the outlier value with a more
    representative value, such as the mean, median, or mode of the variable, or use
    more sophisticated imputation methods such as **k-nearest neighbors** or **regression-based
    imputation**.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**插补**: 与缺失值类似，用更具有代表性的值替换异常值，例如变量的均值、中位数或众数，或者使用更复杂的插补方法，如**k近邻**或**基于回归的插补**。'
- en: '**Cap or truncate**: Set a threshold (either upper or lower) and cap or truncate
    the outlier values at that threshold. This method retains the data’s original
    structure while reducing the influence of extreme values.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**截断或限制**: 设置一个阈值（可以是上限或下限），并将异常值在该阈值处截断或限制。这种方法保留了数据的原始结构，同时减少了极端值的影响。'
- en: 'For the Wind Turbine dataset, we detect the outliers using bounds set to three
    times the standard deviation and map the values to `np.nan`, so we may replace
    them later:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于风力涡轮机数据集，我们使用设置为标准差三倍的范围来检测异常值，并将值映射到`np.nan`，因此我们可以在以后替换它们：
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Handling measurement errors
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 处理测量误差
- en: The values detected as types of measurement errors could also be considered
    outliers, although not in the statistical sense of the word. However, we can handle
    these values slightly differently than with the statistical outliers.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 被检测为测量误差类型的值也可以被认为是异常值，尽管不是在统计意义上的异常值。然而，我们可以用稍微不同的方式处理这些值，而不是用统计意义上的异常值处理。
- en: 'We apply our domain knowledge and some research surrounding the weather to
    identify appropriate ranges for these features. We then cap the erroneous values
    to these ranges:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用我们的领域知识以及一些关于天气的研究，来确定这些特征的适当范围。然后我们将错误值限制在这些范围内：
- en: '[PRE5]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, we set any negative lengths, heights, and electrical resistance to `0`.
    We also cap the windspeed to `113` m/s, the maximum gust speed on record.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将任何负长度、高度和电阻值设置为`0`。我们还把风速限制在`113` m/s，这是记录中的最大阵风速度。
- en: Finally, we can deal with the missing values in the dataset.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以处理数据集中的缺失值。
- en: Handling missing values
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 处理缺失值
- en: 'We have discussed working with missing values in earlier chapters. To summarize
    here, some of the potential approaches we can take are as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面章节中讨论了处理缺失值的方法。在此总结一下，我们可以采取的一些潜在方法如下：
- en: Remove instances with missing values
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除含有缺失值的实例
- en: Impute the missing values using descriptive statistics (the mean, median, or
    mode)
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用描述性统计（均值、中位数或众数）来填补缺失值
- en: Use other machine learning algorithms, typically unsupervised techniques such
    as clustering, to calculate more robust statistics
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用其他机器学习算法，通常是聚类等无监督技术来计算更稳健的统计量
- en: Removing the missing values would discard a significant portion of our dataset.
    Here, we decide to replace missing values using descriptive statistics to retain
    as much data as possible.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 移除缺失值将丢弃我们数据集的很大一部分。在这里，我们决定使用描述性统计来替换缺失值，以尽可能保留数据。
- en: 'First, we mark the `-99.0` and `-999.0` values as missing:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将`-99.0`和`-999.0`值标记为缺失：
- en: '[PRE6]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We then replace missing numerical values with the mean and categorical values
    with the mode:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们用均值替换缺失的数值，用众数替换分类值：
- en: '[PRE7]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Usually, we would have to be careful when using the mean since the mean is
    affected by outliers. However, since we have already marked the outlier values
    as `np.nan`, they are excluded when calculating the mean. An additional caveat
    comes into play when replacing missing values in the test set: since the test
    set should be treated as unseen data, we must use the mean from the training dataset
    to replace missing values in the test set.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在使用均值时我们必须小心，因为均值会受到异常值的影响。然而，由于我们已经将异常值标记为`np.nan`，它们在计算均值时被排除。当在测试集中替换缺失值时，还有一个额外的注意事项：由于测试集应被视为未见过的数据，我们必须使用训练数据集的均值来替换测试集中的缺失值。
- en: This concludes the necessary data cleaning for our dataset. We should validate
    our work by rechecking for missing values and recalculating the descriptive statistics
    and data histograms.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了我们数据集所需的数据清洗。我们应该通过重新检查缺失值和重新计算描述性统计和数据直方图来验证我们的工作。
- en: 'With the dataset clean, we can move to the next data preparation step: feature
    engineering.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集清洗完毕后，我们可以进行下一步数据准备：特征工程。
- en: Feature engineering
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征工程
- en: '**Feature engineering** refers to the process of creating new features or modifying
    existing ones to improve the performance of a machine learning model. In essence,
    feature engineering is using domain knowledge and data understanding to create
    features that make machine learning algorithms work more effectively. It’s an
    art as much as a science, requiring creativity, intuition, and a deep understanding
    of the problem.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征工程**指的是创建新特征或修改现有特征以提升机器学习模型性能的过程。本质上，特征工程是利用领域知识和数据理解来创建使机器学习算法更有效工作的特征。它既是艺术也是科学，需要创造力、直觉和对问题的深刻理解。'
- en: The feature engineering process often starts with exploring the data to understand
    its characteristics, distributions, and relationships between variables. This
    exploration phase can reveal potential opportunities for feature creation, such
    as interaction terms, aggregate features, or temporal features; for example, if
    you’re working with a dataset containing customer transaction data, you might
    engineer features that capture the frequency of transactions, the average transaction
    value, or the time since the last transaction.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程过程通常从探索数据以了解其特征、分布和变量之间的关系开始。这一探索阶段可以揭示创建特征的可能机会，例如交互项、聚合特征或时间特征；例如，如果你正在处理包含客户交易数据的集合，你可能设计出捕捉交易频率、平均交易价值或自上次交易以来时间的特征。
- en: There are also several standard techniques used in feature engineering. These
    include encoding categorical variables, normalizing numerical variables, creating
    polynomial features, and binning continuous variables. For instance, categorical
    variables are often encoded into numerical formats (such as one-hot or ordinal
    encoding) to be used in mathematical models. Similarly, numerical variables are
    often normalized (such as min-max scaling or standardization) to ensure they’re
    on a comparable scale and to prevent certain variables from dominating others
    simply because of their scale.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征工程中，也有一些标准技术被广泛使用。这些包括对分类变量进行编码、对数值变量进行归一化、创建多项式特征和对连续变量进行分箱。例如，分类变量通常被编码为数值格式（如独热编码或顺序编码）以用于数学模型。同样，数值变量通常被归一化（如最小-最大缩放或标准化）以确保它们处于可比较的尺度上，并防止某些变量仅仅因为其尺度而支配其他变量。
- en: However, feature engineering is not a one-size-fits-all process. The appropriate
    features for a model can depend heavily on the specific problem, the algorithm
    used, and the nature of the data. Therefore, feature engineering often requires
    iterative experimentation and evaluation. Despite its challenges, effective feature
    engineering can significantly enhance model performance.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，特征工程不是一个一刀切的过程。模型适用的特征可能严重依赖于具体问题、使用的算法和数据性质。因此，特征工程通常需要迭代实验和评估。尽管存在挑战，有效的特征工程可以显著提高模型性能。
- en: Note
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'As you may have noticed, feature engineering requires understanding and exploration
    of the data, which depends on the engineered features’ availability. This highlights
    the cyclical process within the data science life cycle: we iterate between data
    preparation and exploration.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经注意到的，特征工程需要理解和探索数据，这取决于工程特征的可用性。这突出了数据科学生命周期中的循环过程：我们在数据准备和探索之间迭代。
- en: For example, a feature suitable for further engineering in our data is the `datetime`
    field. The specific date and time a measurement was taken are not informative
    to the model for future predictions.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们数据中适合进一步工程的特征是`datetime`字段。对于未来的预测，测量所采取的具体日期和时间对模型来说并不具有信息性。
- en: 'However, suppose we extract the year, month, day of the month, and hour of
    the day into new features. In that case, the model can capture potential relationships
    between the power generated and different time cycles. The `date` decomposition
    allows questions such as: Does the time of year, seasons, specific months, and
    so on influence the power generated? Or does the time of day, morning, noon, or
    night have any impact?'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们提取年份、月份、月份中的日期和一天中的小时作为新特征，那么模型可以捕捉到电力生成与不同时间周期之间的潜在关系。`日期`分解允许提出如下问题：年份、季节、特定月份等是否会影响电力生成？或者一天中的时间，早上、中午或晚上是否有任何影响？
- en: 'We can decompose the date into new features as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将日期分解为以下新特征：
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If, after modeling, we find these features to be uninformative, we can do further
    work with the `time` fields to assist in modeling. Future directions to explore
    are aggregations based on specific periods or creating a time series by ordering
    measurements to study trends in power generation over time.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在建模之后，我们发现这些特征缺乏信息，我们可以进一步使用`时间`字段来协助建模。未来要探索的方向包括基于特定时期的聚合或通过排序测量来创建时间序列，以研究电力生成随时间的变化趋势。
- en: We now proceed to our case study’s EDA portion to visualize and better understand
    our data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在继续进行案例研究的EDA部分，以可视化和更好地理解我们的数据。
- en: EDA
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EDA
- en: We have already done some EDA to find missing values and outliers in our dataset.
    There is no fixed methodology for performing EDA on a dataset; some experience
    and creativity are required to guide the process.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经对数据集进行了一些探索性数据分析（EDA），以找到缺失值和异常值。对数据集进行EDA没有固定的方法；需要一些经验和创造力来指导这个过程。
- en: 'Besides gaining insight and understanding of the data, the main goal is to
    attempt to identify patterns and relationships within the data. Here, we start
    with a correlation heatmap to explore any direct correlations between features:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 除了获取对数据的洞察和理解之外，主要目标是尝试在数据中识别模式和关系。在这里，我们从一个相关性热图开始，以探索特征之间的直接相关性：
- en: '![Figure 6.3 – Correlation heatmap for the Wind Turbine dataset](img/B16690_06_03.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图6.3 – 风力涡轮机数据集的相关性热图](img/B16690_06_03.jpg)'
- en: Figure 6.3 – Correlation heatmap for the Wind Turbine dataset
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 – 风力涡轮机数据集的相关性热图
- en: The correlation heatmap in *Figure 6**.3* shows a few notable correlations between
    wind speed and atmospheric temperature, engine metrics such as engine temperature,
    generator temperature, and motor torque, and weaker correlations between our date
    features and atmospheric conditions.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.3*中的相关性热图显示了风速和大气温度、发动机温度、发电机温度和电机扭矩等发动机指标之间的一些显著相关性，以及我们日期特征与大气条件之间的较弱相关性。'
- en: 'Notably, a very strong correlation exists between motor torque and generator
    temperature. Intuitively, this makes sense: if the motor produces more torque,
    it will produce more heat. Since torque is the causative feature, we can consider
    dropping the generator temperature for modeling.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，电机扭矩和发电机温度之间存在非常强的相关性。直观上，这是有道理的：如果电机产生更多的扭矩，它会产生更多的热量。由于扭矩是因果关系特征，我们可以考虑在建模时忽略发电机温度。
- en: We can also see correlations between power generation and engine metrics, including
    electrical resistance and wind direction. We can anticipate that these features
    will have a significant impact on the model’s performance.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到发电量和发动机指标之间的相关性，包括电阻和风向。我们可以预期这些特征将对模型的性能产生重大影响。
- en: 'We can also explore correlations between the categorical features and the power
    generated. The turbine status has seemingly little effect (in isolation) on the
    power generated. However, the cloud level has a significant impact. Plotting the
    cloud level against power generated, we have the following:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以探索分类特征与发电量之间的相关性。涡轮机状态似乎对发电量影响很小（单独来看）。然而，云层级别有显著影响。将云层级别与发电量绘制成图，我们得到以下结果：
- en: '[PRE9]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Figure 6.4 – Average power generated under the various cloud levels](img/B16690_06_04.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图6.4 – 不同云层下的平均发电量](img/B16690_06_04.jpg)'
- en: Figure 6.4 – Average power generated under the various cloud levels
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – 不同云层下的平均发电量
- en: As shown in *Figure 6**.4*, extremely low clouds strongly correlate with reduced
    power generation. In further exploration of the data, it is helpful to control
    for cloud level to ensure the effect of the cloud level doesn’t dominate any emergent
    patterns.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图6.4*所示，极低云层与发电量减少有很强的相关性。在进一步探索数据时，控制云层级别有助于确保云层级别不会主导任何出现的模式。
- en: Another helpful visualization to see the effect of various features is the scatterplot.
    Plotting each value makes it straightforward to spot features by visually identifying
    patterns and clusters in the data.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有助于观察各种特征影响的可视化方法是散点图。绘制每个值使得通过视觉识别数据中的模式和聚类来识别特征变得简单。
- en: Next, we provide examples of scatterplots that reveal patterns within our data.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们提供了一些散点图的例子，这些图揭示了数据中的模式。
- en: 'To investigate any effect the blade angle might have on power generation, we
    can create a scatterplot as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了研究叶片角度可能对发电量产生的影响，我们可以创建以下散点图：
- en: '[PRE10]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the scatterplot, we also add hue differentiation for the cloud level so
    we can visually verify that any effect isn’t stemming from the cloud level alone:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在散点图中，我们还添加了云层级别的色调区分，这样我们可以直观地验证任何影响不是仅来自云层级别：
- en: '![Figure 6.5 – Scatterplot of power generated (y axis) against the blade angle
    (x axis)](img/B16690_06_05.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图6.5 – 发电量（y轴）与叶片角度（x轴）的散点图](img/B16690_06_05.jpg)'
- en: Figure 6.5 – Scatterplot of power generated (y axis) against the blade angle
    (x axis)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 发电量（y轴）与叶片角度（x轴）的散点图
- en: 'The blade angle scatterplot is shown in *Figure 6**.5*. The scatterplot indicates
    that specific blade angle ranges correlate with increased power generated: [0,
    10] degrees and [65, 75] degrees (both reciprocated in the other direction). Tree-based
    algorithms model correlations such as these as well.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 叶片角度散点图显示在*图6.5*中。散点图表明，特定的叶片角度范围与发电量的增加相关：[0, 10]度和[65, 75]度（在另一方向上也是相反的）。基于树的算法也能模拟这种相关性。
- en: 'Another example that illustrates the power of our feature engineering is a
    scatterplot of the month against the power generated. We again control for the
    cloud level via a different hue for those points:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个说明我们特征工程强大功能的例子是月份与发电量的散点图。我们再次通过不同色调控制云层级别：
- en: '[PRE11]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Figure 6.6 – Scatterplot of power generated (y axis) by month (x axis)](img/B16690_06_06.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图6.6 – 发电量（y轴）按月份（x轴）的散点图](img/B16690_06_06.jpg)'
- en: Figure 6.6 – Scatterplot of power generated (y axis) by month (x axis)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 – 发电量（y轴）按月份（x轴）的散点图
- en: '*Figure 6**.6* shows that April to September is correlated with a significant
    decrease in power generated. We could conclude that the wind turbines’ location
    isn’t particularly windy these months, and other sources would have to supplement
    the lack of power generation. By decomposing our date feature, we enable our learning
    algorithm to exploit this correlation.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6**.6*显示，4月至9月与发电量的显著下降相关。我们可以得出结论，这些月份风力涡轮机的位置不太 windy，其他来源将不得不补充电力生产的不足。通过分解我们的日期特征，我们使我们的学习算法能够利用这种相关性。'
- en: 'There is no definitive end goal with EDA. For large, complex datasets, the
    analysis can go deeper and deeper into the data, iteratively exploring further
    facets and nuances almost indefinitely. However, two sanity checks that are useful
    in determining whether data has been explored sufficiently are as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: EDA没有明确的目标。对于大型、复杂的数据集，分析可以深入到数据中，迭代地探索更深入的方面和细微差别，几乎无限期地进行。然而，有两个有助于确定数据是否已充分探索的合理性检查如下：
- en: Do we sufficiently understand the meaning of each feature and the potential
    effect on the model’s output?
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否充分理解了每个特征的含义及其对模型输出的潜在影响？
- en: Is the data well prepared for modeling? To the best of our knowledge, are the
    features informative, the data clean and unbiased, and formatted so that the model
    can be trained on it?
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是否已准备好进行建模？据我们所知，特征是否具有信息性，数据是否干净且无偏见，以及格式是否适合在它上进行训练？
- en: We now move on to modeling the data, leveraging the techniques of previous chapters
    to build a well-optimized model.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们继续对数据进行建模，利用前几章的技术构建一个优化良好的模型。
- en: Modeling
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建模
- en: The first step of modeling is model selection. It’s best practice to first model
    the data using a straightforward algorithm to validate our data preparation and
    establish a baseline. If the modeling fails with a simple algorithm, it’s easier
    to debug what might be going wrong or isolate data instances that may be causing
    the issue.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 建模的第一步是模型选择。最好的做法是首先使用简单的算法对数据进行建模，以验证我们的数据准备并建立基线。如果建模失败，使用简单算法更容易调试可能出错的地方或隔离可能引起问题的数据实例。
- en: Model selection
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型选择
- en: For our wind turbine data, we use a linear regression model to establish a baseline
    and validate the data’s suitability for modeling.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的风力涡轮机数据，我们使用线性回归模型来建立基线并验证数据建模的适用性。
- en: We also train a random forest regression model as a point of comparison against
    our LightGBM model. It’s also good practice, if budget allows, to train more than
    one model using a different learning algorithm, as specific problems may be better
    suited to particular algorithms.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还训练了一个随机森林回归模型，作为与我们的LightGBM模型进行比较的基准。如果预算允许，使用不同的学习算法训练多个模型也是一个好的实践，因为特定问题可能更适合特定的算法。
- en: Finally, we train a LightGBM regressor as our primary model.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们训练了一个LightGBM回归器作为我们的主要模型。
- en: Model training and evaluation
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练和评估
- en: 'From the EDA, we saw that the generator temperature is redundant (due to the
    correlation with motor torque). As such, we exclude it from the training data:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 从EDA中，我们看到生成器温度是多余的（由于与电机扭矩的相关性）。因此，我们从训练数据中排除了它：
- en: '[PRE12]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Unlike LightGBM, neither linear regression nor scikit-learn’s random forest
    regressor can automatically deal with categorical features.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 与LightGBM不同，线性回归和scikit-learn的随机森林回归器都不能自动处理分类特征。
- en: 'We, therefore, use `get_dummies` from pandas to encode the features for training.
    The `get_dummies` operation performs a process known as `0` or `1`) columns as
    there are unique values. The corresponding value is marked with `1` (one-hot)
    for each pattern, and other values are marked with `0`. For example, consider
    the cloud level feature: there are three categories (medium, low, and extremely
    low). A row in our dataset with a medium cloud level would be encoded as `100`
    (three separate columns). Similarly, a low cloud level is encoded as `010`, and
    so on.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们使用pandas的`get_dummies`来对特征进行编码以进行训练。`get_dummies`操作执行一个称为`0`或`1`列的过程，因为有唯一值。相应的值用`1`（独热编码）标记每个模式，其他值用`0`标记。例如，考虑云层特征：有三个类别（中等、低和极低）。我们的数据集中中等云层的行将被编码为`100`（三个单独的列）。同样，低云层被编码为`010`，以此类推。
- en: Performing one-hot encoding allows algorithms, such as linear regression, that
    only support numerical columns to model the data at the cost of increased memory
    usage for the additional columns.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 执行独热编码允许算法，如线性回归，仅支持数值列，以增加额外列的内存使用成本为代价来对数据进行建模。
- en: 'As stated in the problem definition, we’ll use two metrics to evaluate the
    models: the coefficient of determination and the MSE. Both are calculated using
    five-fold cross-validation.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如问题定义所述，我们将使用两个指标来评估模型：确定系数和 MSE。两者都是使用五折交叉验证计算的。
- en: 'We can now proceed to train our linear, random forest, and LightGBM regressors:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以继续训练我们的线性、随机森林和 LightGBM 回归器：
- en: '[PRE13]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following table summarizes the performance of each model:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 下表总结了每个模型的性能：
- en: '| Algorithm | R 2 | MSE |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | R² | MSE |'
- en: '| Linear Regression | 0.558 | 2.261 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 线性回归 | 0.558 | 2.261 |'
- en: '| Random Forest | 0.956 | 0.222 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林 | 0.956 | 0.222 |'
- en: '| LightGBM | 0.956 | 0.222 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| LightGBM | 0.956 | 0.222 |'
- en: Table 6.2 – Five-fold cross-validated performance metrics on the Wind Turbine
    dataset
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.2 – Wind Turbine 数据集上五折交叉验证的性能指标
- en: The LightGBM and random forest regressors show almost identical performance
    with the same rounded R 2 and MSE scores. Both algorithms significantly outperformed
    linear regression.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: LightGBM 和随机森林回归器在四舍五入的 R² 和 MSE 分数上表现出几乎相同的表现。这两种算法都显著优于线性回归。
- en: Our model performs very well, with an absolute error of around 471 W/h. However,
    there’s a problem that’s easy to spot if we plot the feature importance of our
    trained model.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模式表现非常好，绝对误差约为 471 W/h。然而，如果我们绘制训练模型的特征重要性，问题就很容易被发现。
- en: '*Figure 6**.7* shows each feature’s relative importance for our LightGBM model.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6**.7* 展示了每个特征对我们 LightGBM 模型的相对重要性。'
- en: '![Figure 6.7 – Relative feature importance of each feature to our LightGBM
    model](img/B16690_06_07.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图6.7 – 每个特征相对于我们的 LightGBM 模型的相对特征重要性](img/B16690_06_07.jpg)'
- en: Figure 6.7 – Relative feature importance of each feature to our LightGBM model
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 – 每个特征相对于我们的 LightGBM 模型的相对特征重要性
- en: 'As we can see from the features’ importance, three features stand out: `blades_angle`,
    `motor_torque`, and `resistance`. However, for two of the features, `motor_torque`
    and `resistance`, we could ask: Do these features lead to improved generated power,
    or do they result from an increase in the power generated? These features are
    examples of **target leakage**, as explained next.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们从特征的重要性中可以看到，有三个特征突出：`blades_angle`、`motor_torque` 和 `resistance`。然而，对于其中两个特征，`motor_torque`
    和 `resistance`，我们可以问：这些特征是导致生成的功率提高，还是它们是功率增加的结果？这些特征是**目标泄露**的例子，如以下所述。
- en: Target leakage
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 目标泄露
- en: Target leakage, often called “leakage,” is a common pitfall in designing and
    training machine learning models. It occurs when the model is inadvertently given
    access to the target variable (or some proxy of the target variable) during the
    training process. As a result, the model’s performance during training may seem
    impressive, but it performs poorly on new, unseen data because it has effectively
    “cheated” during training.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 目标泄露，通常称为“泄露”，是设计和训练机器学习模型时常见的陷阱。它发生在模型在训练过程中无意中获得了对目标变量（或目标变量的某些代理）的访问。因此，模型在训练过程中的表现可能看起来很令人印象深刻，但在新的、未见过的数据上表现不佳，因为它在训练过程中实际上“作弊”了。
- en: 'Some common examples of how leakage can occur are as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 泄露可能发生的一些常见例子如下：
- en: '**Time-based leakage**: Suppose you’re trying to predict stock prices for tomorrow.
    If you include data from tomorrow in your training set (maybe accidentally), that
    would cause leakage. Similarly, data only available after the fact (such as aggregate
    data over all stocks) is another example of time-based leakage.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于时间的泄露**：假设你正在尝试预测明天的股价。如果你在训练集中包含明天的数据（可能是无意中），这将导致泄露。同样，仅在事后可用的数据（如所有股票的汇总数据）也是基于时间的泄露的另一个例子。'
- en: '**Preprocessing mistakes**: These happen when you perform a specific operation,
    such as scaling or normalizing, using statistics that include both the training
    and test set.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预处理错误**：这些发生在你使用包括训练集和测试集的统计数据执行特定操作，如缩放或归一化时。'
- en: '**Incorrect data splits**: For time-series data, using a simple random split
    might result in future data being present in the training set.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误的数据分割**：对于时间序列数据，使用简单的随机分割可能会导致训练集中出现未来的数据。'
- en: '**Contaminated validation sets**: Sometimes, when creating validation or test
    sets, some data might overlap or be very closely related to the training data,
    causing optimistic and unrepresentative validation scores.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**受污染的验证集**：有时，在创建验证集或测试集时，一些数据可能重叠或与训练数据非常接近，导致乐观且不具有代表性的验证分数。'
- en: 'In our example, `motor_torque` and `resistance` are examples of time-based
    leakage: both metrics can only be measured after power is generated, which is
    what we are trying to predict. This also illustrates the importance of performing
    baseline training tests, as problems like these may not be easily found beforehand.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，`motor_torque`和`resistance`是时间相关的泄漏的例子：这两个指标只能在发电后才能测量，这正是我们试图预测的。这也说明了进行基线训练测试的重要性，因为像这些问题可能不容易在事先发现。
- en: We fix this error by removing the features from our dataset. We can then proceed
    with model tuning to further improve the model’s performance.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过从我们的数据集中删除特征来修复这个错误。然后我们可以继续模型调优以进一步提高模型性能。
- en: Model tuning
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型调优
- en: 'We utilize Optuna to perform our parameter optimization study. We’ll leverage
    Optuna’s **Tree-structured Parzen Estimator** (**TPE**) sampling algorithm with
    Hyperband pruning for efficiency. We define our objective function with the required
    parameters, a pruning callback, and measure the MSE:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Optuna来执行我们的参数优化研究。我们将利用Optuna的**树结构帕累托估计器**（**TPE**）采样算法和Hyperband剪枝以提高效率。我们定义我们的目标函数所需的参数、剪枝回调，并测量均方误差：
- en: '[PRE14]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We then create our Optuna study with a TPE sampler, Hyperband pruning, and
    an optimization budget of 200 trails:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后使用TPE采样器、Hyperband剪枝和200个试验的优化预算创建我们的Optuna研究：
- en: '[PRE15]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Using the optimized parameters found through Optuna, we further improve the
    performance of the LightGBM model to an R 2 of `0.93` and an MSE of `0.21` in
    our run. Your results may differ slightly due to the stochastic nature of Optuna
    studies.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Optuna找到的优化参数，我们进一步提高了LightGBM模型在运行中的性能，将其R²提高到`0.93`，均方误差为`0.21`。由于Optuna研究的随机性质，您的结果可能会有所不同。
- en: 'With an optimized model trained, we can proceed to the next phases of the data
    science process: deployment and reporting.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练出一个优化的模型后，我们可以继续数据科学流程的下一阶段：部署和报告。
- en: Model deployment
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型部署
- en: We can now use our trained model to make predictions on unseen data. The coming
    chapters focus on various ways to deploy and monitor models as part of the MLOps
    process.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用我们的训练模型对未见数据做出预测。接下来的章节将重点介绍作为MLOps过程一部分的各种部署和监控模型的方法。
- en: However, the simplest way of using our model is to save the model and write
    a simple script that loads the model and makes the prediction.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用我们的模型最简单的方法是保存模型并编写一个简单的脚本，该脚本加载模型并做出预测。
- en: 'We can save our model using standard Python serialization or the LightGBM API.
    Here, we illustrate using standard Python tooling:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用标准的Python序列化或LightGBM API来保存我们的模型。在这里，我们展示了使用标准的Python工具：
- en: '[PRE16]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'A simple script to load the model and make predictions would be as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 加载模型并做出预测的简单脚本如下：
- en: '[PRE17]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Importantly, we must repeat the data preparation for any data we want to predict
    to add engineered features and drop columns that aren’t used.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，我们必须为任何我们想要预测的数据重复数据准备，以添加工程化特征并删除未使用的列。
- en: Communicating results
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 沟通结果
- en: The final step of the data science process is to communicate results. A data
    scientist typically compiles a report with salient findings and visualizations
    to present the results to stakeholders.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学流程的最后一步是沟通结果。数据科学家通常会编制一份包含显著发现和可视化的报告，向利益相关者展示结果。
- en: A report would look similar to the write-up of this case study. We might present
    the correlations found between our features, for example, the correlation between
    the month and the power generated. We would also highlight problems in the data,
    such as the outliers and missing values, to improve future data collection efforts.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 报告看起来会与这个案例研究的撰写类似。我们可能会展示我们找到的特征之间的相关性，例如，月份与发电量的相关性。我们还会突出数据中的问题，如异常值和缺失值，以改善未来的数据收集工作。
- en: We would further highlight features important to the model, such that wind turbines
    can be optimized to maximize the power generated.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将进一步突出对模型重要的特征，以便风力涡轮机可以优化以最大化发电量。
- en: Focus on the quality of the report. Use well-designed and detailed visualizations
    and other supporting material instead of solely relying on text. An infographic
    or interactive chart can be more helpful than a detailed write-up. Check your
    writing for errors, and be sure to have the report proofread before sending it
    out.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 专注于报告的质量。使用精心设计和详细的可视化以及其他支持材料，而不是仅仅依赖文本。信息图表或交互式图表可能比详细的撰写更有帮助。检查您的写作错误，并在发送之前确保报告经过校对。
- en: The content of a report should address the problem as defined by the problem
    statement. Any hypothesis that was tested must be answered in the report. But,
    the report also strongly depends on and should be tailored to your audience. For
    example, if your audience is business executives, include content that’s understandable
    to them and answers questions they could have, which would be centered around
    the business impact of your findings.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 报告的内容应解决问题陈述中定义的问题。任何被测试过的假设都必须在报告中回答。但是，报告也强烈依赖于并应针对您的受众进行调整。例如，如果您的受众是商业高管，请包括他们能理解的内容，并回答他们可能有的问题，这些问题将围绕您发现的业务影响为中心。
- en: We now look at a case study for a classification problem. We show that, though
    each dataset is unique and has specific challenges, the overall data science process
    remains the same.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一个分类问题的案例研究。我们表明，尽管每个数据集都是独特的，并且具有特定的挑战，但整体的数据科学流程仍然是相同的。
- en: Classifying individual credit scores with LightGBM
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LightGBM对个人信用评分进行分类
- en: Our second case study is a problem of credit score classification for individuals.
    The dataset is [available from https://www.kaggle.com/datasets/parisrohan/credit-score-classification?da](https://www.kaggle.com/datasets/parisrohan/credit-score-classification?datasetId=2289007)tasetId=2289007.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二个案例研究是一个针对个人信用评分分类的问题。数据集可在[https://www.kaggle.com/datasets/parisrohan/credit-score-classification?datasetId=2289007](https://www.kaggle.com/datasets/parisrohan/credit-score-classification?datasetId=2289007)找到。
- en: The dataset is significantly larger than the previous problem and has unique
    data formatting problems. For brevity, we will not go through the solution in
    as much detail as with the previous problem (as much of the work is the same),
    but the end-to-end solution i[s available at https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/credit-score-class](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/credit-score-classification.ipynb)ification.ipynb.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一个问题相比，数据集显著更大，并且存在独特的数据格式问题。为了简洁，我们不会像以前的问题那样详细地介绍解决方案（因为大部分工作都是相同的），但端到端解决方案可在[https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/credit-score-classification.ipynb](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/credit-score-classification.ipynb)找到。
- en: Problem definition
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题定义
- en: The dataset consists of 100,000 rows and 27 columns representing individuals’
    demographic and financial information, including a credit score rating. The data
    includes information regarding individual income, number of loans, payment behavior,
    and investments. The credit score may be rated as good, standard, or poor.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含10万行和27列，代表个人的人口和财务信息，包括信用评分评级。数据包括有关个人收入、贷款数量、支付行为和投资的信息。信用评分可能被评为良好、标准或较差。
- en: Our task is to analyze the data and build a model that accurately classifies
    the credit scores of unseen individuals. The quality of predictions is measured
    using classification accuracy and the F1-score.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的任务是分析数据并构建一个模型，该模型能够准确地对未见过的个人的信用评分进行分类。预测质量使用分类准确率和F1分数来衡量。
- en: Data collection
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据收集
- en: The data is collected from the database of customers of a US financial institution.
    Individuals aged 14 to 65 form part of the dataset. There is no documented bias
    toward sampling specific demographics (low-income brackets, age, or racial groups),
    but this must be validated. No additional data is collected.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 数据来自一家美国金融机构的客户数据库。14至65岁的个人构成了数据集的一部分。没有记录表明采样特定人口统计特征（低收入群体、年龄或种族群体）存在偏差，但这必须得到验证。没有收集额外的数据。
- en: Data preparation
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'As before, we start with simple data exploration tasks to determine the cleanliness
    of the data. We first check the data structure and types:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们首先从简单的数据探索任务开始，以确定数据的清洁度。我们首先检查数据结构和类型：
- en: '[PRE18]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We notice that there are missing values for some features. Also, many of the
    features we expect to be numeric (annual income, number of loans, and others)
    are interpreted as objects instead of integers or floats. These features have
    to be coerced into numeric features.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到某些特征存在缺失值。此外，我们期望许多特征是数值型（如年收入、贷款数量等），但它们被解释为对象而不是整数或浮点数。这些特征必须被强制转换为数值特征。
- en: We also check the descriptive statistics of the features and for duplicated
    rows. Two features are found to have outlier values, age and the number of bank
    accounts, and need to be cleaned.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还检查了特征的描述性统计和重复行。发现有两个特征有异常值，年龄和银行账户数量，需要清理。
- en: Notably, the `Type_of_Loan` field has a comma-separated list, including conjunctions,
    of the types of loans for each individual. For example “`student_loan, mortgage_loan,
    and personal_loan`”. The modeling algorithm could not extract the loan types as
    part of a string. We have to engineer new fields to enable effective modeling.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，`Type_of_Loan`字段包含一个以逗号分隔的列表，包括连词，列出每个个体的贷款类型。例如，“`student_loan, mortgage_loan,
    and personal_loan`”。建模算法无法将贷款类型作为字符串的一部分提取出来。我们必须构建新的字段来启用有效的建模。
- en: Data cleaning
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据清理
- en: 'We can now proceed with cleaning the data. In summary, the following issues
    have to be addressed:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以继续清理数据。总的来说，以下问题需要解决：
- en: Coercing object columns to numeric columns where appropriate
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在适当的地方将对象列强制转换为数值列
- en: Handling outliers in the age, number of bank accounts, and monthly balance columns
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理年龄、银行账户数量和月度余额列中的异常值
- en: Engineering new features for the types of loans
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为贷款类型构建新特征
- en: Handling missing values and duplicate rows
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理缺失值和重复行
- en: Coercing to numeric columns
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将列强制转换为数值列
- en: One of the main issues with the dataset is the mixed types found in columns
    that are supposed to be numeric, but due to error values, pandas interprets them
    as objects. For example, the `Annual_Income` column contains values such as `100000.0_`,
    which is then interpreted as a string.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的主要问题之一是应表示数值的列中发现的混合类型，但由于错误值，pandas将其解释为对象。例如，`Annual_Income`列包含`100000.0_`之类的值，然后被解释为字符串。
- en: 'To clean and convert the features to numbers, we first remove character symbols
    using a regular expression:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清理并将特征转换为数字，我们首先使用正则表达式删除字符符号：
- en: '[PRE19]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This allows us to use pandas to coerce the column to a numeric feature, turning
    any errors (empty values) into `np.nan` values:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够使用pandas将列强制转换为数值特征，将任何错误（空值）转换为`np.nan`值：
- en: '[PRE20]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The `Credit_History_Age` feature requires more work from our side. The age
    is specified using natural language such as “12 years and 3 months.” Here, we
    use Python string processing to convert the years and months to a floating-point
    number:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`Credit_History_Age`特征需要我们更多的工作。年龄使用自然语言指定，例如“12年3个月”。在这里，我们使用Python字符串处理将年和月转换为浮点数：'
- en: '[PRE21]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Splitting delimiter-separated strings
  id: totrans-246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分割分隔符分隔的字符串
- en: As mentioned previously, the `Type_of_Loan` feature is a comma-separated list
    of the types of loans the individual has. Although we could approach the problem
    in multiple ways, the most helpful technique is to parse the fields and build
    a Boolean array of columns indicating which loans an individual has.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`Type_of_Loan`特征是个人拥有的贷款类型的逗号分隔列表。尽管我们可以以多种方式处理这个问题，但最有帮助的技术是解析字段并构建一个布尔数组列，指示个人拥有哪些贷款。
- en: There are eight unique types of loans and a specific category if the loan type
    is unspecified. These are `Auto Loan`, `Credit-Builder Loan`, `Debt Consolidation
    Loan`, `Home Equity Loan`, `Mortgage Loan`, `Payday Loan`, `Personal Loan`, and
    `Student Loan`.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 有八种独特的贷款类型，以及如果贷款类型未指定，有一个特定类别。这些是`Auto Loan`、`Credit-Builder Loan`、`Debt Consolidation
    Loan`、`Home Equity Loan`、`Mortgage Loan`、`Payday Loan`、`Personal Loan`和`Student
    Loan`。
- en: 'Our encoding strategy would then process the feature as follows. We create
    nine new columns (one per loan type and unspecified) and set the column to true
    if the individual has that loan type. For example, here we have three conjoined
    loan descriptions:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的编码策略将按以下方式处理特征。我们创建九个新的列（每个贷款类型和一个未指定的），如果个体有那种贷款类型，则将该列设置为true。例如，这里我们有三个连接的贷款描述：
- en: '[PRE22]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*Table 6.3* shows the encoding results for these examples, where a true flag
    is set if the individual has that type of loan.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '*表6.3*显示了这些示例的编码结果，其中如果个体有那种类型的贷款，则设置true标志。'
- en: '| Auto | Credit-Builder | Debt Cons. | Home Equity | Mortgage | Payday | Personal
    | Student | Unspecified |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| Auto | Credit-Builder | Debt Cons. | Home Equity | Mortgage | Payday | Personal
    | Student | Unspecified |'
- en: '| F | F | F | T | F | T | F | F | F |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| F | F | F | T | F | T | F | F | F |'
- en: '| F | F | F | F | F | T | T | F | F |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| F | F | F | F | F | T | T | F | F |'
- en: '| T | F | T | F | F | F | F | T | F |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| T | F | T | F | F | F | F | T | F |'
- en: Table 6.3 – Loan type columns encode customers’ types of loans
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.3 – 贷款类型列编码客户贷款类型
- en: 'We can utilize pandas’ String utilities to accomplish the preceding encoding,
    as in this example:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用pandas的字符串工具来完成前面的编码，如下例所示：
- en: '[PRE23]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Outliers and missing values
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 异常值和缺失值
- en: 'We follow the same general strategy as before: we impute missing values using
    descriptive statistics and, where able, set outlier values to boundaries we define
    using domain knowledge.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循之前相同的一般策略：使用描述性统计来填补缺失值，并在可能的情况下，将异常值设置为使用领域知识定义的边界。
- en: Duplicate rows are dropped.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 删除重复行。
- en: 'In terms of outliers, the age, number of bank accounts, and monthly balance
    features have outlying values (which we confirm using the mean and standard deviation
    and distribution plots). We set the outlying values to the upper bound for these
    features:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在异常值方面，年龄、银行账户数量和月余额特征具有异常值（我们通过均值、标准差和分布图进行确认）。我们将这些特征的异常值设置为上限：
- en: '[PRE24]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'After our data cleaning, we can verify that all features have the correct type
    and that missing values have been handled:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据清洗后，我们可以验证所有特征都有正确的类型，并且缺失值已得到处理：
- en: '[PRE25]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We can proceed with a more thorough exploratory analysis with the clean dataset.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用清洗后的数据集进行更彻底的探索性分析。
- en: EDA
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EDA
- en: Next, we highlight some of the patterns found during our EDA.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们强调在EDA过程中发现的一些模式。
- en: As described in the problem description, we need to validate whether any potential
    bias exists in the data.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 如问题描述所述，我们需要验证数据中是否存在任何潜在的偏差。
- en: 'We start by visualizing the customers’ ages:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先可视化客户的年龄：
- en: '[PRE26]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![Figure 6.8 – Histogram showing the count of customers by age](img/B16690_06_08.jpg)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图6.8 – 按年龄统计客户数量的直方图](img/B16690_06_08.jpg)'
- en: Figure 6.8 – Histogram showing the count of customers by age
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8 – 按年龄统计客户数量的直方图
- en: '*Figure 6**.8* shows that all age groups are represented, with data mainly
    normally distributed around the middle-aged.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.8*显示所有年龄段都有数据，数据主要围绕中年人呈正态分布。'
- en: 'We also check monthly income. A lack of data in lower income brackets could
    indicate that minorities were excluded:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还检查月收入。低收入群体数据缺失可能表明少数族裔被排除在外：
- en: '[PRE27]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![Figure 6.9 – Histogram showing the count of customers by monthly in-hand
    salary](img/B16690_06_09.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![图6.9 – 按月到手工资统计客户数量的直方图](img/B16690_06_09.jpg)'
- en: Figure 6.9 – Histogram showing the count of customers by monthly in-hand salary
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9 – 按月到手工资统计客户数量的直方图
- en: As seen in *Figure 6**.9*, monthly income follows an expected distribution and
    lower income brackets are well represented.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图6.9*所示，月收入遵循预期的分布，低收入群体有很好的代表性。
- en: 'We again visualize the correlation heatmap for the numeric features to highlight
    and direct correlations:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次可视化数值特征的关联热图，以突出和直接关联：
- en: '![Figure 6.10 – Correlation heatmap for the Credit Score dataset](img/B16690_06_10.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图6.10 – 信用评分数据集的关联热图](img/B16690_06_10.jpg)'
- en: Figure 6.10 – Correlation heatmap for the Credit Score dataset
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10 – 信用评分数据集的关联热图
- en: 'Two strong correlations are notable: monthly balance and monthly salary, and
    outstanding debt and delay in due date. Further visualization of these correlations
    indicates that a customer’s monthly balance increases with salary and that poor
    credit scores are associated with lower balances and salaries.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 两个显著的关联值得关注：月余额和月工资，以及逾期债务和还款延迟。进一步可视化这些关联表明，客户的月余额随着工资的增加而增加，并且不良的信用评分与较低的余额和工资相关。
- en: 'A similar correlation exists between outstanding debt and credit score: an
    increase in debt is associated with poor credit scores, and vice versa. The analysis
    confirms that our model should be able to capture both of these correlations.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 逾期债务和信用评分之间存在类似的关联：债务的增加与不良的信用评分相关，反之亦然。分析确认我们的模型应该能够捕捉到这两个关联。
- en: 'Finally, and importantly, we also have to check the class distribution for
    the dataset:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，并且非常重要，我们还要检查数据集的类别分布：
- en: '[PRE28]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![Figure 6.11 – Histogram of the class distribution for the credit scoring
    dataset](img/B16690_06_11.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![图6.11 – 信用评分数据集类别分布的直方图](img/B16690_06_11.jpg)'
- en: Figure 6.11 – Histogram of the class distribution for the credit scoring dataset
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11 – 信用评分数据集类别分布的直方图
- en: The class distribution for our dataset is shown in *Figure 6**.11*. As we can
    see in the figure, there is a significant class imbalance. The imbalance has to
    be addressed before we can proceed with modeling.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集类别分布如图*6.11*所示。如图所示，存在显著的类别不平衡。在建模之前，我们必须解决这种不平衡问题。
- en: Modeling
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建模
- en: As before, we proceed with model selection first.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们首先进行模型选择。
- en: Model selection
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型选择
- en: Due to the dataset’s size and complexity, a linear model is not expected to
    perform very well. As such, we use a regular decision tree as a baseline model
    and include a random forest for comparison.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集的大小和复杂性，线性模型不太可能表现良好。因此，我们使用常规决策树作为基线模型，并包括随机森林进行比较。
- en: Model training and evaluation
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练和评估
- en: 'We are almost ready to train our models, but one issue remains: we must address
    the class imbalance.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎准备好训练我们的模型了，但一个问题仍然存在：我们必须解决类别不平衡问题。
- en: Handling class imbalance
  id: totrans-296
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 处理类别不平衡
- en: Class imbalance potentially biases any trained models to the majority class
    or classes. Although tree-based algorithms are better at dealing with imbalanced
    classes than most other learning algorithms, it’s still best practice to address
    class imbalance before modeling.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 类别不平衡可能会使任何训练好的模型偏向多数类或多个类别。尽管基于树的算法在处理类别不平衡方面比大多数其他学习算法更擅长，但在建模之前解决类别不平衡问题仍然是最佳实践。
- en: 'Generally, the following strategies may be employed to deal with imbalanced
    classes:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，以下策略可以用来处理类别不平衡问题：
- en: '**Resampling techniques**:'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重采样技术**：'
- en: '**Oversampling**: This involves increasing the number of samples in the minority
    class to match the majority class. One common technique is the **Synthetic Minority
    Over-sampling Technique** (**SMOTE**), where new samples are created based on
    the existing ones.'
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上采样**：这涉及到增加少数类中的样本数量以匹配多数类。一种常见的技术是**合成少数类过采样技术**（**SMOTE**），其中基于现有样本创建新的样本。'
- en: '**Undersampling**: This involves reducing the number of samples in the majority
    class to match the minority class. One risk with this approach is the loss of
    potentially valuable data.'
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**下采样**：这涉及到减少多数类中的样本数量以匹配少数类。这种方法的潜在风险是丢失可能有价值的数据。'
- en: '`class_weight` (for multi-class) and `scale_pos_weight` (for binary classes)
    parameters. Examples of applying these parameters are given in [*Chapter 4*](B16690_04.xhtml#_idTextAnchor067),
    *Comparing LightGBM, XGBoost, and* *Deep Learning*.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_weight`（用于多类）和`scale_pos_weight`（用于二分类）参数。这些参数的应用示例在[*第4章*](B16690_04.xhtml#_idTextAnchor067)，*比较LightGBM、XGBoost和深度学习*中给出。'
- en: '**Data augmentation**: This involves creating new instances in the dataset
    by adding small perturbations to existing instances. This method is prevalent
    in image classification tasks.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据增强**：这涉及到通过向现有实例添加小的扰动来在数据集中创建新的实例。这种方法在图像分类任务中很常见。'
- en: '**Use of appropriate evaluation metrics**: Accuracy is often misleading in
    class imbalance. Instead, metrics such as precision, recall, F1-score, **Area
    under the ROC Curve** (**AUC-ROC**), and confusion matrix can provide a more comprehensive
    view of model performance.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用适当的评估指标**：在类别不平衡的情况下，准确率往往具有误导性。相反，如精确率、召回率、F1分数、**ROC曲线下的面积**（**AUC-ROC**）和混淆矩阵等指标可以提供对模型性能的更全面了解。'
- en: In our case study, we are already employing robust evaluation metrics against
    imbalanced classes. For this problem, we use SMOTE, an oversampling technique,
    to balance our classes while preserving our data.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例研究中，我们已经采用了对类别不平衡具有鲁棒性的评估指标。对于这个问题，我们使用SMOTE，一种过采样技术，来平衡我们的类别，同时保留我们的数据。
- en: SMOTE
  id: totrans-306
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: SMOTE
- en: SMOTE was developed to overcome some of the shortcomings of simple oversampling
    of the minority class, which can lead to overfitting due to the exact duplication
    of instances *[1]*. Instead of simply duplicating minority samples, SMOTE creates
    synthetic, or “fake,” samples that are similar, but not identical, to existing
    samples in the minority class.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: SMOTE是为了克服简单上采样少数类的某些不足而开发的，这可能导致由于实例的精确复制而过度拟合*[1]*。SMOTE不是简单地复制少数样本，而是创建与少数类中现有样本相似但不完全相同的合成或“假”样本。
- en: The SMOTE algorithm proceeds as follows. New sample points, called synthetic
    samples, are synthesized by choosing points between samples close to minority
    class samples. Specifically, for each minority class sample, SMOTE calculates
    the k-nearest neighbors, chooses one of these neighbors, and then multiplies the
    difference between the feature vectors of the sample and its chosen neighbor by
    a random number between 0 and 1, adding this to the original sample to create
    a new, synthetic sample.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: SMOTE 算法按以下步骤进行。通过选择接近少数类样本的样本之间的点来合成新的样本点，称为合成样本。具体来说，对于每个少数类样本，SMOTE 计算其 k
    个最近邻，选择这些邻居中的一个，然后将样本与其所选邻居的特征向量之间的差异乘以 0 到 1 之间的随机数，并将这个值加到原始样本上，以创建一个新的、合成的样本。
- en: By creating synthetic examples, SMOTE presents a more robust solution to the
    imbalance problem, encouraging the model to draw more generalizable decision boundaries.
    It’s important to note, however, that while SMOTE can improve the performance
    of models on imbalanced datasets, it’s not always the best choice. For instance,
    it can introduce noise if the minority samples are not sufficiently close in the
    feature space, leading to overlapping classes. As with all sampling techniques,
    it’s essential to use cross-validation or a separate validation set to carefully
    evaluate the impact of SMOTE on your model’s performance.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 通过创建合成示例，SMOTE 提供了一种更稳健的解决方案来解决不平衡问题，鼓励模型绘制更具泛化能力的决策边界。然而，需要注意的是，尽管 SMOTE 可以提高不平衡数据集上模型的性能，但它并不总是最佳选择。例如，如果少数样本在特征空间中不够接近，它可能会引入噪声，导致类别重叠。与所有采样技术一样，使用交叉验证或单独的验证集仔细评估
    SMOTE 对模型性能的影响是至关重要的。
- en: 'SMOTE over-sampling is implemented in the `imblearn` Python library. We can
    fit and resample our data as follows:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: SMOTE 过采样在 `imblearn` Python 库中实现。我们可以如下拟合和重采样我们的数据：
- en: '[PRE29]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '*Figure 6**.12* shows the class distribution for the dataset after resampling
    with SMOTE. As shown in the figure, the classes are now perfectly balanced.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6**.12* 展示了使用 SMOTE 重采样后的数据集类别分布。如图所示，类别现在完全平衡。'
- en: '![Figure 6.12 – Histogram of the class distribution for the Credit Score dataset
    after resampling the data using SMOTE; classes are now balanced](img/B16690_06_12.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.12 – 使用 SMOTE 重采样后的信用评分数据集类别分布直方图；类别现在平衡](img/B16690_06_12.jpg)'
- en: Figure 6.12 – Histogram of the class distribution for the Credit Score dataset
    after resampling the data using SMOTE; classes are now balanced
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.12 – 使用 SMOTE 重采样后的信用评分数据集类别分布直方图；类别现在平衡
- en: Training and evaluation
  id: totrans-315
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 训练和评估
- en: We can now proceed with the modeling. The following table shows the results
    of our run from the decision tree classifier, random forest, and LightGBM models
    using default parameters.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以继续进行建模。下表展示了我们的决策树分类器、随机森林和 LightGBM 模型使用默认参数的运行结果。
- en: '| Algorithm | Accuracy | F1 score |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | 准确率 | F1 分数 |'
- en: '| Decision tree | 59.87% | 0.57 |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 决策树 | 59.87% | 0.57 |'
- en: '| Random forest | 69.35% | 0.67 |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林 | 69.35% | 0.67 |'
- en: '| LightGBM | 70.00% | 0.68 |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| LightGBM | 70.00% | 0.68 |'
- en: Table 6.4 – Five-fold cross-validated performance metrics on the Credit Score
    dataset
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6.4 – 在信用评分数据集上五折交叉验证的性能指标
- en: As shown in *Table 6.4*, the LightGBM model performs the best, slightly outperforming
    the random forest model accuracy. Both algorithms perform better than the decision
    tree baseline. The LightGBM model also trained the fastest, more than seven times
    faster than the random forest model.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *表 6.4* 所示，LightGBM 模型的性能最佳，略优于随机森林模型的准确率。两种算法的性能都优于决策树基线。LightGBM 模型的训练速度也最快，比随机森林模型快七倍以上。
- en: We now proceed with parameter optimization of the LightGBM model.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在继续进行 LightGBM 模型的参数优化。
- en: Model tuning
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型调优
- en: Similar to the previous case study, we use Optuna for parameter optimization.
    We again use the TPE sampler with an optimization budget of 50 trials.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的案例研究类似，我们使用 Optuna 进行参数优化。我们再次使用 TPE 采样器，优化预算为 50 次试验。
- en: Model deployment and results
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型部署和结果
- en: Our model is now prepared and ready to be deployed to a platform of our choice.
    Potential deployment options would include building a web API around our model,
    deploying with a tool such as **PostgresML**, or using a cloud platform such as
    **AWS SageMaker**. These and other options are discussed in detail in the coming
    chapters.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模式现在已准备就绪，可以部署到我们选择的平台上。可能的部署选项包括围绕我们的模型构建一个Web API，使用**PostgresML**等工具进行部署，或者使用如**AWS
    SageMaker**这样的云平台。这些以及其他选项将在接下来的章节中详细讨论。
- en: 'We could also use the model as part of a data science report. See the previous
    section for details on writing a good report. Keep in mind the most important
    aspects of communicating data science results, as follows:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将模型作为数据科学报告的一部分使用。参见上一节，了解撰写良好报告的详细信息。请记住沟通数据科学结果最重要的方面，如下所示：
- en: Always report results in an unbiased and fair way
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总是以无偏见和公平的方式报告结果
- en: Keep your audience in mind and focus on the report’s details that provide them
    with the most value
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑你的受众，并关注报告中提供他们最大价值的细节
- en: Summary
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter presented two case studies on how to apply the data science process
    with LightGBM. The data science life cycle and the typical constituent steps were
    discussed in detail.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了两个案例研究，说明了如何使用LightGBM应用数据科学流程。详细讨论了数据科学生命周期和典型的组成部分步骤。
- en: A case study involving wind turbine power generation was presented as an example
    of approaching a data problem while working through the life cycle. Feature engineering
    and how to handle outliers were discussed in detail. An example exploratory data
    analysis was performed with samples given for visualization. Model training and
    tuning were shown alongside a basic script for exporting and using the model as
    a program.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 以风力涡轮机发电为例，介绍了一个在生命周期中处理数据问题的案例研究。详细讨论了特征工程以及如何处理异常值。进行了一次示例性探索性数据分析，并提供了用于可视化的样本。同时展示了模型训练和调优，以及导出和使用模型作为程序的基本脚本。
- en: A second case study involving multi-class credit score classification was also
    presented. The data science process was again followed, with particular attention
    given to data cleaning and class imbalance problems in the dataset.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 还介绍了一个涉及多类信用评分分类的第二个案例研究。再次遵循数据科学流程，特别关注数据清洗和数据集中类别不平衡问题。
- en: The next chapter discusses the AutoML framework FLAML and introduces the concept
    of machine learning pipelines.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章讨论了AutoML框架FLAML，并介绍了机器学习管道的概念。
- en: References
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '| *[**1]* | *N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer,
    “SMOTE: Synthetic Minority Over-sampling Technique,” Journal of Artificial Intelligence
    Research, vol. 16, p. 321–357,* *June 2002.* |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| *[**1**] | *N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer,
    “SMOTE: Synthetic Minority Over-sampling Technique,” Journal of Artificial Intelligence
    Research, vol. 16, p. 321–357, 六月 2002.* |'
