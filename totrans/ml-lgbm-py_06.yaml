- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Solving Real-World Data Science Problems with LightGBM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the preceding chapters, we have slowly been building out a toolset for
    us to be able to solve machine learning problems. We’ve seen examples of examining
    our data, addressing data issues, and creating models. This chapter formally defines
    and applies the data science process to two case studies.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter gives a detailed overview of the data science life cycle and all
    the steps it encompasses. The concepts of problem definition, data exploration,
    data cleaning, modeling, and reporting are discussed in a regression and classification
    problem context. We also look at preparing data for modeling and building optimized
    LightGBM models using our learned techniques. Finally, we look deeper at utilizing
    a trained model as an introduction to **machine learning** **operations** (**MLOps**).
  prefs: []
  type: TYPE_NORMAL
- en: 'The main topics of this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The data science life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting wind turbine power generation with LightGBM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifying individual credit scores with LightGBM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The chapter includes examples and code excerpts illustrating how to perform
    parameter optimization studies for LightGBM using Optuna. Complete examples and
    instructions for setting up a suitable environment for this chapter are available
    at [https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6).
  prefs: []
  type: TYPE_NORMAL
- en: The data science life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data science has emerged as a critical discipline, enabling organizations to
    derive valuable insights from their data and drive better decision-making. At
    the heart of data science lies the data science life cycle, a systematic, iterative
    process that guides data-driven problem-solving across various industries and
    domains. This life cycle outlines a series of steps that data scientists follow
    to ensure they address the right problem and deliver actionable insights that
    create real-world impact.
  prefs: []
  type: TYPE_NORMAL
- en: The first stage of the data science life cycle involves defining the problem,
    which entails understanding the business context, articulating objectives, and
    formulating hypotheses. This crucial stage establishes the entire project’s foundation
    by establishing a clear direction and scope. Subsequent stages in the life cycle
    focus on data collection, preparation, and exploration, collectively involving
    gathering relevant data, cleaning and preprocessing it, and conducting exploratory
    data analysis to unveil patterns and trends.
  prefs: []
  type: TYPE_NORMAL
- en: Once the data is analyzed, the data science life cycle progresses to model selection,
    training, evaluation, and tuning. These stages are central to developing accurate
    and reliable predictive or descriptive models by choosing the most appropriate
    algorithms, training them on the preprocessed data, and optimizing their performance.
    The goal is to build a robust model that generalizes well to unseen data and addresses
    the problem at hand effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, the data science life cycle emphasizes the importance of deploying the
    final model into a production environment, monitoring its performance, and maintaining
    it to ensure its ongoing relevance and accuracy. Equally important is the communication
    of results and insights to stakeholders, which is vital for driving informed decision-making
    and realizing the full potential of data science. By following the data science
    life cycle, organizations can systematically extract value from their data and
    unlock new opportunities for growth and innovation.
  prefs: []
  type: TYPE_NORMAL
- en: With previous examples, we followed a loose recipe of steps for working with
    data and creating models. In the next section, we formally define and discuss
    the steps of the data science life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the data science life cycle
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following are the key steps broadly applied in the data science life cycle.
    The steps are also shown in *Figure 6**.1*, which illustrates the cyclical nature
    of the life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Diagram depicting the data science life cycle](img/B16690_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Diagram depicting the data science life cycle
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the key steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Define the problem**: Clearly articulate the business problem, goals, and
    objectives. This stage involves understanding stakeholder requirements, formulating
    hypotheses, and determining the project’s scope. Defining the problem also sets
    the stage for data collection and can determine how we’ll utilize our models.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data collection**: Gather the required data from various sources, such as
    databases, APIs, web scraping, or third-party data providers. Ensure the data
    is representative, accurate, and relevant to the problem. It is important to document
    where data originates and how it is moved around to establish the **data lineage**.
    Further, build a **data dictionary** that documents the data’s format, structure,
    content, and meaning. Importantly, validate any potential bias in the collection
    or sampling of data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data preparation**: Clean and preprocess the data to make it suitable for
    analysis. This stage includes tasks such as **data cleansing** (e.g., handling
    missing values and removing duplicates), **data transformation** (e.g., normalization
    and encoding categorical variables), and **feature engineering** (e.g., creating
    new variables or aggregating existing ones). Moving and joining the data to where
    it can be analyzed and modeled might also be necessary.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data exploration**: Conduct **exploratory data analysis** (**EDA**) to gain
    insights into the data. This step involves visualizing data distributions, identifying
    trends and patterns, detecting outliers and anomalies, and checking for relationships
    and correlations between features.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model selection**: Choose the most appropriate data modeling techniques based
    on the problem type (e.g., regression, classification, or clustering) and the
    data characteristics. It’s important to choose multiple model algorithms to validate
    performance on the data set.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model training**: Train the selected models using the prepared data. This
    step involves splitting the data into training and validation sets, setting model
    parameters (hyperparameters), and fitting the models to the data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model evaluation**: Assess the performance of the trained models using appropriate
    evaluation metrics (e.g., accuracy, precision, recall, F1-score, **Area under
    the ROC Curve** (**AUC-ROC**), or **root mean square error** (**RMSE**)) and compare
    them to select the best-performing model(s). Perform cross-validation or use holdout
    test sets to ensure an unbiased evaluation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model tuning**: Fine-tune the selected model by optimizing hyperparameters,
    feature selection, or incorporating domain knowledge. This step aims to improve
    the model’s performance and generalization to unseen data. It might also be appropriate
    to tune the model for the specific problem; for instance, when recognizing faces,
    a higher precision is more appropriate than a high recall.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model deployment**: If the model is to be part of a more extensive software
    system, deploy the final model into a production environment, where it can be
    used to make predictions or inform decision-making. Deployment may involve integrating
    the model into existing systems, creating APIs, or setting up monitoring and maintenance
    procedures.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model monitoring and maintenance**: Continuously monitor the model’s performance
    and update it as necessary to ensure it remains accurate and relevant. Techniques
    such as detecting model and data drift should be used to ensure model performance.
    Model maintenance may involve retraining the model with new data, updating features,
    or refining the problem definition.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Communicate results**: Share insights and results with stakeholders, including
    any recommendations or actions based on the analysis. Communicating the results
    may involve creating visualizations, dashboards, or reports to communicate the
    findings effectively.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We now examine two case studies to see how the data science life cycle is applied
    practically to real-world data. We look at a regression problem, predicting wind
    turbine power generation, and a classification problem, classifying individual
    credit scores.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting wind turbine power generation with LightGBM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our first case study is a problem where we aim to predict the power generation
    of wind turbines. The dataset for the problem is available from [https://www.kaggle.com/datasets/mukund23/hackerearth-machine-learning-challenge](https://www.kaggle.com/datasets/mukund23/hackerearth-machine-learning-challenge).
  prefs: []
  type: TYPE_NORMAL
- en: We work through the problem using the steps defined in the previous section,
    articulating the details involved in each step alongside code snippets. The complete
    end-to-en[d solution is available at https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/wind](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/wind-turbine-power-output.ipynb)-turbine-power-output.ipynb.
  prefs: []
  type: TYPE_NORMAL
- en: Problem definition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset consists of power generation (in kW/h) measurements of wind turbines
    taken at a specific date and time. Alongside each measurement are the parameters
    of the wind turbine, which include physical measurements of the windmill (including
    windmill height, blade breadth, and length), operating measurements for the turbine
    (including resistance in ohms, motor torque, generator temperature, and rotor
    torque) and atmospheric conditions (including wind speed, temperature, and pressure).
  prefs: []
  type: TYPE_NORMAL
- en: Given the set of parameters, we must build a regression model to predict the
    generated power in kW/h. Therefore, we employ regression modeling. The quality
    of the model is measured using the **mean squared error** (**MSE**) and the coefficient
    of determination (R 2). We must also determine which factors have the most significant
    impact on power generation.
  prefs: []
  type: TYPE_NORMAL
- en: Data collection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset comprises 22,800 samples collected within 11 months, from October
    2018 to September 2019\. The data is available as CSV files and is released as
    public domain data. No additional data is collected.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can now look at preparing the data for cleaning and exploration. The dataset
    consists of 18 numerical features, 2 categorical features, and the date feature,
    as we can see by getting the information from our pandas DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We can immediately see that the dataset has missing values, with some features
    having fewer than 28,200 values. We can get a better sense of the data distribution
    by calculating the statistical description:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This prints out the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Feature** | **count** | **mean** | **std** | **min** | **max** |'
  prefs: []
  type: TYPE_TB
- en: '| wind_speed(m/s) | 27927 | 69.04 | 76.28 | -496.21 | 601.46 |'
  prefs: []
  type: TYPE_TB
- en: '| atmospheric_temperature(°C) | 24750 | 0.38 | 44.28 | -99.00 | 80.22 |'
  prefs: []
  type: TYPE_TB
- en: '| shaft_temperature(°C) | 28198 | 40.09 | 27.20 | -99.00 | 169.82 |'
  prefs: []
  type: TYPE_TB
- en: '| blades_angle(°) | 27984 | -9.65 | 47.92 | -146.26 | 165.93 |'
  prefs: []
  type: TYPE_TB
- en: '| gearbox_temperature(°C) | 28199 | 41.03 | 43.66 | -244.97 | 999.00 |'
  prefs: []
  type: TYPE_TB
- en: '| engine_temperature(°C) | 28188 | 42.61 | 6.12 | 3.17 | 50.00 |'
  prefs: []
  type: TYPE_TB
- en: '| motor_torque(N-m) | 28176 | 1710 | 827 | 500 | 3000.00 |'
  prefs: []
  type: TYPE_TB
- en: '| generator_temperature(°C) | 28188 | 65.03 | 19.82 | 33.89 | 100.00 |'
  prefs: []
  type: TYPE_TB
- en: '| atmospheric_pressure(Pascal) | 25493 | 53185 | 187504 | -1188624 | 1272552
    |'
  prefs: []
  type: TYPE_TB
- en: '| area_temperature(°C) | 28200 | 32.74 | 7.70 | -30.00 | 55.00 |'
  prefs: []
  type: TYPE_TB
- en: '| windmill_body_temperature(°C) | 25837 | 20.80 | 54.36 | -999.00 | 323.00
    |'
  prefs: []
  type: TYPE_TB
- en: '| wind_direction(°) | 23097 | 306.89 | 134.06 | 0.00 | 569.97 |'
  prefs: []
  type: TYPE_TB
- en: '| resistance(ohm) | 28199 | 1575.6 | 483.33 | -1005.22 | 4693.48 |'
  prefs: []
  type: TYPE_TB
- en: '| rotor_torque(N-m) | 27628 | 25.85 | 32.42 | -136.73 | 236.88 |'
  prefs: []
  type: TYPE_TB
- en: '| blade_length(m) | 23107 | 2.25 | 11.28 | -99.00 | 18.21 |'
  prefs: []
  type: TYPE_TB
- en: '| blade_breadth(m) | 28200 | 0.40 | 0.06 | 0.20 | 0.50 |'
  prefs: []
  type: TYPE_TB
- en: '| windmill_height(m) | 27657 | 25.89 | 7.77 | -30.30 | 78.35 |'
  prefs: []
  type: TYPE_TB
- en: '| windmill_generated_power (kW/h) | 27993 | 6.13 | 2.70 | 0.96 | 20.18 |'
  prefs: []
  type: TYPE_TB
- en: Table 6.1 – Statistical description of numerical features in the Wind Turbine
    dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at the statistical description of the features in *Table 6.1*, we can
    see the following irregularities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Many features have outliers**: Generally, a standard deviation larger than
    the mean may indicate outlying values. Examples include wind speed, atmospheric
    temperature, and atmospheric pressure. Similarly, a minimum or maximum far away
    from the mean may indicate outliers in the data. We can further verify this by
    visualizing the data distribution using a histogram.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Physical impossibilities**: The data shows impossibilities in the data of
    some of the measurements: lengths (in meters) less than 0 (e.g., blade length)
    and temperatures outside of natural ranges (a body temperature of -999).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-99.0` and `-999.0` repeat for a few features. It’s improbable that these
    values occur naturally across features. We can infer that these indicate missing
    or erroneous measurements in the sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can visualize the distribution of features to investigate the outlying values.
    For example, for atmospheric temperature, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 6.2 – Histogram showing atmospheric temperature in Celsius](img/B16690_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – Histogram showing atmospheric temperature in Celsius
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6**.2* illustrates two of the issues found in the data: a high frequency
    of measurements with a value of precisely `-99.0`, indicating an error. A few
    outlying values are also far removed from the mean.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can check for duplicate data using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: No rows are returned, indicating no duplicates in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Data cleaning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have identified multiple issues in the dataset that we need to address as
    part of the *data* *cleaning* step:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Outliers**: Many features have outlier values that skew the distribution
    of values for the feature.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Measurement errors**: Some features have values that fall out of the bounds
    of physical impossibilities (lengths smaller than 0 or temperatures in impossible
    ranges).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-99.0` and `-999.0`) that we consider missing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We first address the outliers and measurement errors, as this impacts how we
    handle the missing values.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with outliers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There are two parts to dealing with outliers in a dataset: accurately identifying
    outliers and choosing appropriate values for replacement. Ways to identify outliers
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Visualization**: As shown previously, histograms or other plots that visualize
    the data distribution (such as box plots or scatter plots) can be used'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain knowledge**: Like how we identify measurement errors, domain knowledge
    can be leveraged to decide whether values are outlying'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Statistical analysis**: Two popular methods for determining whether values
    are outlying using statistics are the **interquartile range** (**IQR**) and the
    standard deviation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The IQR is the difference between the 25th and 75th quartiles. Values over 1.5
    times the IQR away from the 25th or 75th quartiles are considered outlying.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, we can leverage the standard deviation: we calculate the mean
    and standard deviation of the dataset. Any values over two or three times removed
    from the mean are outlying. Setting bounds to twice or three times the standard
    deviation depends on the underlying data. Using twice the standard deviation could
    lead to many false positives, but it is appropriate if a lot of data is centered
    around the mean. Using three times the standard deviation is more conservative
    and only marks values very far from the mean as outlying.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When the outlying values are detected, we must do something about them. Generally,
    our options are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Remove**: If an outlier results from an error in data entry, measurement,
    or collection, it may be reasonable to remove it from the dataset. However, this
    should be done cautiously, as removing too many data points can lead to a loss
    of information and biased results. Removing instances with outliers in our dataset
    would result in close to 70% data loss and isn’t an option.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Impute**: Similar to missing values, replace the outlier value with a more
    representative value, such as the mean, median, or mode of the variable, or use
    more sophisticated imputation methods such as **k-nearest neighbors** or **regression-based
    imputation**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cap or truncate**: Set a threshold (either upper or lower) and cap or truncate
    the outlier values at that threshold. This method retains the data’s original
    structure while reducing the influence of extreme values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the Wind Turbine dataset, we detect the outliers using bounds set to three
    times the standard deviation and map the values to `np.nan`, so we may replace
    them later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Handling measurement errors
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The values detected as types of measurement errors could also be considered
    outliers, although not in the statistical sense of the word. However, we can handle
    these values slightly differently than with the statistical outliers.
  prefs: []
  type: TYPE_NORMAL
- en: 'We apply our domain knowledge and some research surrounding the weather to
    identify appropriate ranges for these features. We then cap the erroneous values
    to these ranges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here, we set any negative lengths, heights, and electrical resistance to `0`.
    We also cap the windspeed to `113` m/s, the maximum gust speed on record.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can deal with the missing values in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Handling missing values
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We have discussed working with missing values in earlier chapters. To summarize
    here, some of the potential approaches we can take are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Remove instances with missing values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Impute the missing values using descriptive statistics (the mean, median, or
    mode)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use other machine learning algorithms, typically unsupervised techniques such
    as clustering, to calculate more robust statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing the missing values would discard a significant portion of our dataset.
    Here, we decide to replace missing values using descriptive statistics to retain
    as much data as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we mark the `-99.0` and `-999.0` values as missing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We then replace missing numerical values with the mean and categorical values
    with the mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Usually, we would have to be careful when using the mean since the mean is
    affected by outliers. However, since we have already marked the outlier values
    as `np.nan`, they are excluded when calculating the mean. An additional caveat
    comes into play when replacing missing values in the test set: since the test
    set should be treated as unseen data, we must use the mean from the training dataset
    to replace missing values in the test set.'
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the necessary data cleaning for our dataset. We should validate
    our work by rechecking for missing values and recalculating the descriptive statistics
    and data histograms.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the dataset clean, we can move to the next data preparation step: feature
    engineering.'
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Feature engineering** refers to the process of creating new features or modifying
    existing ones to improve the performance of a machine learning model. In essence,
    feature engineering is using domain knowledge and data understanding to create
    features that make machine learning algorithms work more effectively. It’s an
    art as much as a science, requiring creativity, intuition, and a deep understanding
    of the problem.'
  prefs: []
  type: TYPE_NORMAL
- en: The feature engineering process often starts with exploring the data to understand
    its characteristics, distributions, and relationships between variables. This
    exploration phase can reveal potential opportunities for feature creation, such
    as interaction terms, aggregate features, or temporal features; for example, if
    you’re working with a dataset containing customer transaction data, you might
    engineer features that capture the frequency of transactions, the average transaction
    value, or the time since the last transaction.
  prefs: []
  type: TYPE_NORMAL
- en: There are also several standard techniques used in feature engineering. These
    include encoding categorical variables, normalizing numerical variables, creating
    polynomial features, and binning continuous variables. For instance, categorical
    variables are often encoded into numerical formats (such as one-hot or ordinal
    encoding) to be used in mathematical models. Similarly, numerical variables are
    often normalized (such as min-max scaling or standardization) to ensure they’re
    on a comparable scale and to prevent certain variables from dominating others
    simply because of their scale.
  prefs: []
  type: TYPE_NORMAL
- en: However, feature engineering is not a one-size-fits-all process. The appropriate
    features for a model can depend heavily on the specific problem, the algorithm
    used, and the nature of the data. Therefore, feature engineering often requires
    iterative experimentation and evaluation. Despite its challenges, effective feature
    engineering can significantly enhance model performance.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may have noticed, feature engineering requires understanding and exploration
    of the data, which depends on the engineered features’ availability. This highlights
    the cyclical process within the data science life cycle: we iterate between data
    preparation and exploration.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, a feature suitable for further engineering in our data is the `datetime`
    field. The specific date and time a measurement was taken are not informative
    to the model for future predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, suppose we extract the year, month, day of the month, and hour of
    the day into new features. In that case, the model can capture potential relationships
    between the power generated and different time cycles. The `date` decomposition
    allows questions such as: Does the time of year, seasons, specific months, and
    so on influence the power generated? Or does the time of day, morning, noon, or
    night have any impact?'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can decompose the date into new features as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If, after modeling, we find these features to be uninformative, we can do further
    work with the `time` fields to assist in modeling. Future directions to explore
    are aggregations based on specific periods or creating a time series by ordering
    measurements to study trends in power generation over time.
  prefs: []
  type: TYPE_NORMAL
- en: We now proceed to our case study’s EDA portion to visualize and better understand
    our data.
  prefs: []
  type: TYPE_NORMAL
- en: EDA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already done some EDA to find missing values and outliers in our dataset.
    There is no fixed methodology for performing EDA on a dataset; some experience
    and creativity are required to guide the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides gaining insight and understanding of the data, the main goal is to
    attempt to identify patterns and relationships within the data. Here, we start
    with a correlation heatmap to explore any direct correlations between features:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Correlation heatmap for the Wind Turbine dataset](img/B16690_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – Correlation heatmap for the Wind Turbine dataset
  prefs: []
  type: TYPE_NORMAL
- en: The correlation heatmap in *Figure 6**.3* shows a few notable correlations between
    wind speed and atmospheric temperature, engine metrics such as engine temperature,
    generator temperature, and motor torque, and weaker correlations between our date
    features and atmospheric conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notably, a very strong correlation exists between motor torque and generator
    temperature. Intuitively, this makes sense: if the motor produces more torque,
    it will produce more heat. Since torque is the causative feature, we can consider
    dropping the generator temperature for modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: We can also see correlations between power generation and engine metrics, including
    electrical resistance and wind direction. We can anticipate that these features
    will have a significant impact on the model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also explore correlations between the categorical features and the power
    generated. The turbine status has seemingly little effect (in isolation) on the
    power generated. However, the cloud level has a significant impact. Plotting the
    cloud level against power generated, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 6.4 – Average power generated under the various cloud levels](img/B16690_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – Average power generated under the various cloud levels
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *Figure 6**.4*, extremely low clouds strongly correlate with reduced
    power generation. In further exploration of the data, it is helpful to control
    for cloud level to ensure the effect of the cloud level doesn’t dominate any emergent
    patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Another helpful visualization to see the effect of various features is the scatterplot.
    Plotting each value makes it straightforward to spot features by visually identifying
    patterns and clusters in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we provide examples of scatterplots that reveal patterns within our data.
  prefs: []
  type: TYPE_NORMAL
- en: 'To investigate any effect the blade angle might have on power generation, we
    can create a scatterplot as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In the scatterplot, we also add hue differentiation for the cloud level so
    we can visually verify that any effect isn’t stemming from the cloud level alone:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Scatterplot of power generated (y axis) against the blade angle
    (x axis)](img/B16690_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – Scatterplot of power generated (y axis) against the blade angle
    (x axis)
  prefs: []
  type: TYPE_NORMAL
- en: 'The blade angle scatterplot is shown in *Figure 6**.5*. The scatterplot indicates
    that specific blade angle ranges correlate with increased power generated: [0,
    10] degrees and [65, 75] degrees (both reciprocated in the other direction). Tree-based
    algorithms model correlations such as these as well.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example that illustrates the power of our feature engineering is a
    scatterplot of the month against the power generated. We again control for the
    cloud level via a different hue for those points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 6.6 – Scatterplot of power generated (y axis) by month (x axis)](img/B16690_06_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 – Scatterplot of power generated (y axis) by month (x axis)
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6**.6* shows that April to September is correlated with a significant
    decrease in power generated. We could conclude that the wind turbines’ location
    isn’t particularly windy these months, and other sources would have to supplement
    the lack of power generation. By decomposing our date feature, we enable our learning
    algorithm to exploit this correlation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is no definitive end goal with EDA. For large, complex datasets, the
    analysis can go deeper and deeper into the data, iteratively exploring further
    facets and nuances almost indefinitely. However, two sanity checks that are useful
    in determining whether data has been explored sufficiently are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Do we sufficiently understand the meaning of each feature and the potential
    effect on the model’s output?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the data well prepared for modeling? To the best of our knowledge, are the
    features informative, the data clean and unbiased, and formatted so that the model
    can be trained on it?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We now move on to modeling the data, leveraging the techniques of previous chapters
    to build a well-optimized model.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step of modeling is model selection. It’s best practice to first model
    the data using a straightforward algorithm to validate our data preparation and
    establish a baseline. If the modeling fails with a simple algorithm, it’s easier
    to debug what might be going wrong or isolate data instances that may be causing
    the issue.
  prefs: []
  type: TYPE_NORMAL
- en: Model selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For our wind turbine data, we use a linear regression model to establish a baseline
    and validate the data’s suitability for modeling.
  prefs: []
  type: TYPE_NORMAL
- en: We also train a random forest regression model as a point of comparison against
    our LightGBM model. It’s also good practice, if budget allows, to train more than
    one model using a different learning algorithm, as specific problems may be better
    suited to particular algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we train a LightGBM regressor as our primary model.
  prefs: []
  type: TYPE_NORMAL
- en: Model training and evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'From the EDA, we saw that the generator temperature is redundant (due to the
    correlation with motor torque). As such, we exclude it from the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Unlike LightGBM, neither linear regression nor scikit-learn’s random forest
    regressor can automatically deal with categorical features.
  prefs: []
  type: TYPE_NORMAL
- en: 'We, therefore, use `get_dummies` from pandas to encode the features for training.
    The `get_dummies` operation performs a process known as `0` or `1`) columns as
    there are unique values. The corresponding value is marked with `1` (one-hot)
    for each pattern, and other values are marked with `0`. For example, consider
    the cloud level feature: there are three categories (medium, low, and extremely
    low). A row in our dataset with a medium cloud level would be encoded as `100`
    (three separate columns). Similarly, a low cloud level is encoded as `010`, and
    so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Performing one-hot encoding allows algorithms, such as linear regression, that
    only support numerical columns to model the data at the cost of increased memory
    usage for the additional columns.
  prefs: []
  type: TYPE_NORMAL
- en: 'As stated in the problem definition, we’ll use two metrics to evaluate the
    models: the coefficient of determination and the MSE. Both are calculated using
    five-fold cross-validation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now proceed to train our linear, random forest, and LightGBM regressors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The following table summarizes the performance of each model:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Algorithm | R 2 | MSE |'
  prefs: []
  type: TYPE_TB
- en: '| Linear Regression | 0.558 | 2.261 |'
  prefs: []
  type: TYPE_TB
- en: '| Random Forest | 0.956 | 0.222 |'
  prefs: []
  type: TYPE_TB
- en: '| LightGBM | 0.956 | 0.222 |'
  prefs: []
  type: TYPE_TB
- en: Table 6.2 – Five-fold cross-validated performance metrics on the Wind Turbine
    dataset
  prefs: []
  type: TYPE_NORMAL
- en: The LightGBM and random forest regressors show almost identical performance
    with the same rounded R 2 and MSE scores. Both algorithms significantly outperformed
    linear regression.
  prefs: []
  type: TYPE_NORMAL
- en: Our model performs very well, with an absolute error of around 471 W/h. However,
    there’s a problem that’s easy to spot if we plot the feature importance of our
    trained model.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6**.7* shows each feature’s relative importance for our LightGBM model.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Relative feature importance of each feature to our LightGBM
    model](img/B16690_06_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – Relative feature importance of each feature to our LightGBM model
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see from the features’ importance, three features stand out: `blades_angle`,
    `motor_torque`, and `resistance`. However, for two of the features, `motor_torque`
    and `resistance`, we could ask: Do these features lead to improved generated power,
    or do they result from an increase in the power generated? These features are
    examples of **target leakage**, as explained next.'
  prefs: []
  type: TYPE_NORMAL
- en: Target leakage
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Target leakage, often called “leakage,” is a common pitfall in designing and
    training machine learning models. It occurs when the model is inadvertently given
    access to the target variable (or some proxy of the target variable) during the
    training process. As a result, the model’s performance during training may seem
    impressive, but it performs poorly on new, unseen data because it has effectively
    “cheated” during training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some common examples of how leakage can occur are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Time-based leakage**: Suppose you’re trying to predict stock prices for tomorrow.
    If you include data from tomorrow in your training set (maybe accidentally), that
    would cause leakage. Similarly, data only available after the fact (such as aggregate
    data over all stocks) is another example of time-based leakage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preprocessing mistakes**: These happen when you perform a specific operation,
    such as scaling or normalizing, using statistics that include both the training
    and test set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incorrect data splits**: For time-series data, using a simple random split
    might result in future data being present in the training set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Contaminated validation sets**: Sometimes, when creating validation or test
    sets, some data might overlap or be very closely related to the training data,
    causing optimistic and unrepresentative validation scores.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In our example, `motor_torque` and `resistance` are examples of time-based
    leakage: both metrics can only be measured after power is generated, which is
    what we are trying to predict. This also illustrates the importance of performing
    baseline training tests, as problems like these may not be easily found beforehand.'
  prefs: []
  type: TYPE_NORMAL
- en: We fix this error by removing the features from our dataset. We can then proceed
    with model tuning to further improve the model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: Model tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We utilize Optuna to perform our parameter optimization study. We’ll leverage
    Optuna’s **Tree-structured Parzen Estimator** (**TPE**) sampling algorithm with
    Hyperband pruning for efficiency. We define our objective function with the required
    parameters, a pruning callback, and measure the MSE:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We then create our Optuna study with a TPE sampler, Hyperband pruning, and
    an optimization budget of 200 trails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Using the optimized parameters found through Optuna, we further improve the
    performance of the LightGBM model to an R 2 of `0.93` and an MSE of `0.21` in
    our run. Your results may differ slightly due to the stochastic nature of Optuna
    studies.
  prefs: []
  type: TYPE_NORMAL
- en: 'With an optimized model trained, we can proceed to the next phases of the data
    science process: deployment and reporting.'
  prefs: []
  type: TYPE_NORMAL
- en: Model deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can now use our trained model to make predictions on unseen data. The coming
    chapters focus on various ways to deploy and monitor models as part of the MLOps
    process.
  prefs: []
  type: TYPE_NORMAL
- en: However, the simplest way of using our model is to save the model and write
    a simple script that loads the model and makes the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can save our model using standard Python serialization or the LightGBM API.
    Here, we illustrate using standard Python tooling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'A simple script to load the model and make predictions would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Importantly, we must repeat the data preparation for any data we want to predict
    to add engineered features and drop columns that aren’t used.
  prefs: []
  type: TYPE_NORMAL
- en: Communicating results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final step of the data science process is to communicate results. A data
    scientist typically compiles a report with salient findings and visualizations
    to present the results to stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: A report would look similar to the write-up of this case study. We might present
    the correlations found between our features, for example, the correlation between
    the month and the power generated. We would also highlight problems in the data,
    such as the outliers and missing values, to improve future data collection efforts.
  prefs: []
  type: TYPE_NORMAL
- en: We would further highlight features important to the model, such that wind turbines
    can be optimized to maximize the power generated.
  prefs: []
  type: TYPE_NORMAL
- en: Focus on the quality of the report. Use well-designed and detailed visualizations
    and other supporting material instead of solely relying on text. An infographic
    or interactive chart can be more helpful than a detailed write-up. Check your
    writing for errors, and be sure to have the report proofread before sending it
    out.
  prefs: []
  type: TYPE_NORMAL
- en: The content of a report should address the problem as defined by the problem
    statement. Any hypothesis that was tested must be answered in the report. But,
    the report also strongly depends on and should be tailored to your audience. For
    example, if your audience is business executives, include content that’s understandable
    to them and answers questions they could have, which would be centered around
    the business impact of your findings.
  prefs: []
  type: TYPE_NORMAL
- en: We now look at a case study for a classification problem. We show that, though
    each dataset is unique and has specific challenges, the overall data science process
    remains the same.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying individual credit scores with LightGBM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our second case study is a problem of credit score classification for individuals.
    The dataset is [available from https://www.kaggle.com/datasets/parisrohan/credit-score-classification?da](https://www.kaggle.com/datasets/parisrohan/credit-score-classification?datasetId=2289007)tasetId=2289007.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is significantly larger than the previous problem and has unique
    data formatting problems. For brevity, we will not go through the solution in
    as much detail as with the previous problem (as much of the work is the same),
    but the end-to-end solution i[s available at https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/credit-score-class](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-6/credit-score-classification.ipynb)ification.ipynb.
  prefs: []
  type: TYPE_NORMAL
- en: Problem definition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset consists of 100,000 rows and 27 columns representing individuals’
    demographic and financial information, including a credit score rating. The data
    includes information regarding individual income, number of loans, payment behavior,
    and investments. The credit score may be rated as good, standard, or poor.
  prefs: []
  type: TYPE_NORMAL
- en: Our task is to analyze the data and build a model that accurately classifies
    the credit scores of unseen individuals. The quality of predictions is measured
    using classification accuracy and the F1-score.
  prefs: []
  type: TYPE_NORMAL
- en: Data collection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data is collected from the database of customers of a US financial institution.
    Individuals aged 14 to 65 form part of the dataset. There is no documented bias
    toward sampling specific demographics (low-income brackets, age, or racial groups),
    but this must be validated. No additional data is collected.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As before, we start with simple data exploration tasks to determine the cleanliness
    of the data. We first check the data structure and types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We notice that there are missing values for some features. Also, many of the
    features we expect to be numeric (annual income, number of loans, and others)
    are interpreted as objects instead of integers or floats. These features have
    to be coerced into numeric features.
  prefs: []
  type: TYPE_NORMAL
- en: We also check the descriptive statistics of the features and for duplicated
    rows. Two features are found to have outlier values, age and the number of bank
    accounts, and need to be cleaned.
  prefs: []
  type: TYPE_NORMAL
- en: Notably, the `Type_of_Loan` field has a comma-separated list, including conjunctions,
    of the types of loans for each individual. For example “`student_loan, mortgage_loan,
    and personal_loan`”. The modeling algorithm could not extract the loan types as
    part of a string. We have to engineer new fields to enable effective modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Data cleaning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can now proceed with cleaning the data. In summary, the following issues
    have to be addressed:'
  prefs: []
  type: TYPE_NORMAL
- en: Coercing object columns to numeric columns where appropriate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling outliers in the age, number of bank accounts, and monthly balance columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Engineering new features for the types of loans
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling missing values and duplicate rows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coercing to numeric columns
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the main issues with the dataset is the mixed types found in columns
    that are supposed to be numeric, but due to error values, pandas interprets them
    as objects. For example, the `Annual_Income` column contains values such as `100000.0_`,
    which is then interpreted as a string.
  prefs: []
  type: TYPE_NORMAL
- en: 'To clean and convert the features to numbers, we first remove character symbols
    using a regular expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This allows us to use pandas to coerce the column to a numeric feature, turning
    any errors (empty values) into `np.nan` values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Credit_History_Age` feature requires more work from our side. The age
    is specified using natural language such as “12 years and 3 months.” Here, we
    use Python string processing to convert the years and months to a floating-point
    number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Splitting delimiter-separated strings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As mentioned previously, the `Type_of_Loan` feature is a comma-separated list
    of the types of loans the individual has. Although we could approach the problem
    in multiple ways, the most helpful technique is to parse the fields and build
    a Boolean array of columns indicating which loans an individual has.
  prefs: []
  type: TYPE_NORMAL
- en: There are eight unique types of loans and a specific category if the loan type
    is unspecified. These are `Auto Loan`, `Credit-Builder Loan`, `Debt Consolidation
    Loan`, `Home Equity Loan`, `Mortgage Loan`, `Payday Loan`, `Personal Loan`, and
    `Student Loan`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our encoding strategy would then process the feature as follows. We create
    nine new columns (one per loan type and unspecified) and set the column to true
    if the individual has that loan type. For example, here we have three conjoined
    loan descriptions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 6.3* shows the encoding results for these examples, where a true flag
    is set if the individual has that type of loan.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Auto | Credit-Builder | Debt Cons. | Home Equity | Mortgage | Payday | Personal
    | Student | Unspecified |'
  prefs: []
  type: TYPE_TB
- en: '| F | F | F | T | F | T | F | F | F |'
  prefs: []
  type: TYPE_TB
- en: '| F | F | F | F | F | T | T | F | F |'
  prefs: []
  type: TYPE_TB
- en: '| T | F | T | F | F | F | F | T | F |'
  prefs: []
  type: TYPE_TB
- en: Table 6.3 – Loan type columns encode customers’ types of loans
  prefs: []
  type: TYPE_NORMAL
- en: 'We can utilize pandas’ String utilities to accomplish the preceding encoding,
    as in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Outliers and missing values
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We follow the same general strategy as before: we impute missing values using
    descriptive statistics and, where able, set outlier values to boundaries we define
    using domain knowledge.'
  prefs: []
  type: TYPE_NORMAL
- en: Duplicate rows are dropped.
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of outliers, the age, number of bank accounts, and monthly balance
    features have outlying values (which we confirm using the mean and standard deviation
    and distribution plots). We set the outlying values to the upper bound for these
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'After our data cleaning, we can verify that all features have the correct type
    and that missing values have been handled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We can proceed with a more thorough exploratory analysis with the clean dataset.
  prefs: []
  type: TYPE_NORMAL
- en: EDA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, we highlight some of the patterns found during our EDA.
  prefs: []
  type: TYPE_NORMAL
- en: As described in the problem description, we need to validate whether any potential
    bias exists in the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by visualizing the customers’ ages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 6.8 – Histogram showing the count of customers by age](img/B16690_06_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – Histogram showing the count of customers by age
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6**.8* shows that all age groups are represented, with data mainly
    normally distributed around the middle-aged.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We also check monthly income. A lack of data in lower income brackets could
    indicate that minorities were excluded:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 6.9 – Histogram showing the count of customers by monthly in-hand
    salary](img/B16690_06_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – Histogram showing the count of customers by monthly in-hand salary
  prefs: []
  type: TYPE_NORMAL
- en: As seen in *Figure 6**.9*, monthly income follows an expected distribution and
    lower income brackets are well represented.
  prefs: []
  type: TYPE_NORMAL
- en: 'We again visualize the correlation heatmap for the numeric features to highlight
    and direct correlations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Correlation heatmap for the Credit Score dataset](img/B16690_06_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 – Correlation heatmap for the Credit Score dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Two strong correlations are notable: monthly balance and monthly salary, and
    outstanding debt and delay in due date. Further visualization of these correlations
    indicates that a customer’s monthly balance increases with salary and that poor
    credit scores are associated with lower balances and salaries.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A similar correlation exists between outstanding debt and credit score: an
    increase in debt is associated with poor credit scores, and vice versa. The analysis
    confirms that our model should be able to capture both of these correlations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, and importantly, we also have to check the class distribution for
    the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 6.11 – Histogram of the class distribution for the credit scoring
    dataset](img/B16690_06_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.11 – Histogram of the class distribution for the credit scoring dataset
  prefs: []
  type: TYPE_NORMAL
- en: The class distribution for our dataset is shown in *Figure 6**.11*. As we can
    see in the figure, there is a significant class imbalance. The imbalance has to
    be addressed before we can proceed with modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As before, we proceed with model selection first.
  prefs: []
  type: TYPE_NORMAL
- en: Model selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Due to the dataset’s size and complexity, a linear model is not expected to
    perform very well. As such, we use a regular decision tree as a baseline model
    and include a random forest for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: Model training and evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We are almost ready to train our models, but one issue remains: we must address
    the class imbalance.'
  prefs: []
  type: TYPE_NORMAL
- en: Handling class imbalance
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Class imbalance potentially biases any trained models to the majority class
    or classes. Although tree-based algorithms are better at dealing with imbalanced
    classes than most other learning algorithms, it’s still best practice to address
    class imbalance before modeling.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, the following strategies may be employed to deal with imbalanced
    classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resampling techniques**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Oversampling**: This involves increasing the number of samples in the minority
    class to match the majority class. One common technique is the **Synthetic Minority
    Over-sampling Technique** (**SMOTE**), where new samples are created based on
    the existing ones.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Undersampling**: This involves reducing the number of samples in the majority
    class to match the minority class. One risk with this approach is the loss of
    potentially valuable data.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`class_weight` (for multi-class) and `scale_pos_weight` (for binary classes)
    parameters. Examples of applying these parameters are given in [*Chapter 4*](B16690_04.xhtml#_idTextAnchor067),
    *Comparing LightGBM, XGBoost, and* *Deep Learning*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data augmentation**: This involves creating new instances in the dataset
    by adding small perturbations to existing instances. This method is prevalent
    in image classification tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use of appropriate evaluation metrics**: Accuracy is often misleading in
    class imbalance. Instead, metrics such as precision, recall, F1-score, **Area
    under the ROC Curve** (**AUC-ROC**), and confusion matrix can provide a more comprehensive
    view of model performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our case study, we are already employing robust evaluation metrics against
    imbalanced classes. For this problem, we use SMOTE, an oversampling technique,
    to balance our classes while preserving our data.
  prefs: []
  type: TYPE_NORMAL
- en: SMOTE
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SMOTE was developed to overcome some of the shortcomings of simple oversampling
    of the minority class, which can lead to overfitting due to the exact duplication
    of instances *[1]*. Instead of simply duplicating minority samples, SMOTE creates
    synthetic, or “fake,” samples that are similar, but not identical, to existing
    samples in the minority class.
  prefs: []
  type: TYPE_NORMAL
- en: The SMOTE algorithm proceeds as follows. New sample points, called synthetic
    samples, are synthesized by choosing points between samples close to minority
    class samples. Specifically, for each minority class sample, SMOTE calculates
    the k-nearest neighbors, chooses one of these neighbors, and then multiplies the
    difference between the feature vectors of the sample and its chosen neighbor by
    a random number between 0 and 1, adding this to the original sample to create
    a new, synthetic sample.
  prefs: []
  type: TYPE_NORMAL
- en: By creating synthetic examples, SMOTE presents a more robust solution to the
    imbalance problem, encouraging the model to draw more generalizable decision boundaries.
    It’s important to note, however, that while SMOTE can improve the performance
    of models on imbalanced datasets, it’s not always the best choice. For instance,
    it can introduce noise if the minority samples are not sufficiently close in the
    feature space, leading to overlapping classes. As with all sampling techniques,
    it’s essential to use cross-validation or a separate validation set to carefully
    evaluate the impact of SMOTE on your model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'SMOTE over-sampling is implemented in the `imblearn` Python library. We can
    fit and resample our data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 6**.12* shows the class distribution for the dataset after resampling
    with SMOTE. As shown in the figure, the classes are now perfectly balanced.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Histogram of the class distribution for the Credit Score dataset
    after resampling the data using SMOTE; classes are now balanced](img/B16690_06_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.12 – Histogram of the class distribution for the Credit Score dataset
    after resampling the data using SMOTE; classes are now balanced
  prefs: []
  type: TYPE_NORMAL
- en: Training and evaluation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We can now proceed with the modeling. The following table shows the results
    of our run from the decision tree classifier, random forest, and LightGBM models
    using default parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '| Algorithm | Accuracy | F1 score |'
  prefs: []
  type: TYPE_TB
- en: '| Decision tree | 59.87% | 0.57 |'
  prefs: []
  type: TYPE_TB
- en: '| Random forest | 69.35% | 0.67 |'
  prefs: []
  type: TYPE_TB
- en: '| LightGBM | 70.00% | 0.68 |'
  prefs: []
  type: TYPE_TB
- en: Table 6.4 – Five-fold cross-validated performance metrics on the Credit Score
    dataset
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *Table 6.4*, the LightGBM model performs the best, slightly outperforming
    the random forest model accuracy. Both algorithms perform better than the decision
    tree baseline. The LightGBM model also trained the fastest, more than seven times
    faster than the random forest model.
  prefs: []
  type: TYPE_NORMAL
- en: We now proceed with parameter optimization of the LightGBM model.
  prefs: []
  type: TYPE_NORMAL
- en: Model tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Similar to the previous case study, we use Optuna for parameter optimization.
    We again use the TPE sampler with an optimization budget of 50 trials.
  prefs: []
  type: TYPE_NORMAL
- en: Model deployment and results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our model is now prepared and ready to be deployed to a platform of our choice.
    Potential deployment options would include building a web API around our model,
    deploying with a tool such as **PostgresML**, or using a cloud platform such as
    **AWS SageMaker**. These and other options are discussed in detail in the coming
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could also use the model as part of a data science report. See the previous
    section for details on writing a good report. Keep in mind the most important
    aspects of communicating data science results, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Always report results in an unbiased and fair way
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep your audience in mind and focus on the report’s details that provide them
    with the most value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter presented two case studies on how to apply the data science process
    with LightGBM. The data science life cycle and the typical constituent steps were
    discussed in detail.
  prefs: []
  type: TYPE_NORMAL
- en: A case study involving wind turbine power generation was presented as an example
    of approaching a data problem while working through the life cycle. Feature engineering
    and how to handle outliers were discussed in detail. An example exploratory data
    analysis was performed with samples given for visualization. Model training and
    tuning were shown alongside a basic script for exporting and using the model as
    a program.
  prefs: []
  type: TYPE_NORMAL
- en: A second case study involving multi-class credit score classification was also
    presented. The data science process was again followed, with particular attention
    given to data cleaning and class imbalance problems in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter discusses the AutoML framework FLAML and introduces the concept
    of machine learning pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| *[**1]* | *N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer,
    “SMOTE: Synthetic Minority Over-sampling Technique,” Journal of Artificial Intelligence
    Research, vol. 16, p. 321–357,* *June 2002.* |'
  prefs: []
  type: TYPE_TB
