- en: Fair Value of House and Property
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 房屋和财产的公允价值
- en: In this chapter, we are going to expand our knowledge and skills in building
    regression **machine learning** (**ML**) models in C#. In the last chapter, we
    built a linear regression and linear support vector machine model on a foreign
    exchange rate dataset, where all the features were continuous variables. However,
    we are going to be dealing with a more complex dataset, where some features are
    categorical variables and some others are continuous variables.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将扩展我们在C#中构建回归机器学习（ML）模型的知识和技能。在上一章中，我们在外汇汇率数据集上构建了线性回归和线性支持向量机模型，其中所有特征都是连续变量。然而，我们将处理一个更复杂的数据集，其中一些特征是分类变量，而其他一些是连续变量。
- en: In this chapter, we will be using a house prices dataset that contains numerous
    attributes of houses with mixed variable types. Using this data, we will start
    looking at the two common types of categorical variables (ordinal versus non-ordinal)
    and the distributions of some of the categorical variables in the housing dataset.
    We will also look at the distributions of some of the continuous variables in
    the dataset and the benefits of using log transformations for variables that show
    skewed distributions. Then, we are going to learn how to encode and engineer such
    categorical features so that we can fit machine learning models. Unlike the last
    chapter, where we explored the basics of **Support Vector Machine** (**SVM**),
    we are going to apply different Kernel methods for our SVM models and see how
    it affects the model performances.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用一个包含房屋众多属性且变量类型混合的房价数据集。使用这些数据，我们将开始研究两种常见的分类变量类型（有序与无序）以及住房数据集中一些分类变量的分布。我们还将研究数据集中一些连续变量的分布以及使用对数变换对显示偏态分布的变量的好处。然后，我们将学习如何编码和工程化这些分类特征，以便我们可以拟合机器学习模型。与上一章我们探索支持向量机（SVM）基础知识不同，我们将为我们的SVM模型应用不同的核方法，并观察它如何影响模型性能。
- en: Similar to the last chapter, we will be using **root mean squared error** (**RMSE**),
    R², and a plot of actual versus predicted values to evaluate the performances
    of our ML models. By the end of this chapter, you will have a better understanding
    of how to handle categorical variables, how to encode and engineer such features
    for regression models, how to apply various kernel methods for building SVM models,
    and how to build models that predict the fair values of houses.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一章类似，我们将使用**均方根误差**（**RMSE**）、R²以及实际值与预测值的对比图来评估我们的机器学习模型的性能。在本章结束时，你将更好地理解如何处理分类变量，如何为回归模型编码和工程化这些特征，如何应用各种核方法来构建支持向量机（SVM）模型，以及如何构建预测房屋公允价值的模型。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Problem definition for the fair value of house/property project
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 房屋/财产公允价值项目的问题定义
- en: Data analysis for categorical versus continuous variables
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类变量与连续变量的数据分析
- en: Feature engineering and encoding
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程和编码
- en: Linear regression versus Support Vector Machine with kernels
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归与带核的支持向量机
- en: Model validations using RMSE, R², and actual versus predicted plot
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用RMSE、R²和实际值与预测值对比图进行模型验证
- en: Problem definition
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题定义
- en: Let's start this chapter by understanding exactly what ML models we are going
    to build. When you are looking for a house or a property to purchase, you consider
    numerous attributes of those houses or properties that you look at. You might
    be looking at the number of bedrooms and bathrooms, how many cars you can park
    in your garage, the neighborhoods, the materials or finishes of the house, and
    so forth. All of these attributes of a house or property go into how you decide
    the price you want to pay for the given property or how you negotiate the price
    with the seller. However, it is very difficult to understand and estimate what
    the fair value of a property is. By having a model that predicts the fair value
    or the final price of each property, you can make better informed decisions when
    you are negotiating with the seller.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从了解我们将要构建的机器学习模型的具体内容开始这一章。当你寻找要购买的房屋或财产时，你会考虑你看到的这些房屋或财产的众多属性。你可能正在查看卧室和浴室的数量，你能在你的车库中停放多少辆车，社区，房屋的材料或装饰，等等。所有这些房屋或财产的属性都进入了你决定为特定财产支付的价格，或者你如何与卖家协商价格的决定。然而，理解并估计财产的公允价值是非常困难的。通过拥有一个预测每个财产公允价值或最终价格的模型，你可以在与卖家协商时做出更明智的决定。
- en: In order to build such models for fair value of a house predictions, we are
    going to use a dataset that contains 79 explanatory variables that cover almost
    all attributes of residential homes in Ames, Iowa, U.S.A. and their final sale
    prices from 2006 to 2010\. This dataset was compiled by Dean De Cock ([https://ww2.amstat.org/publications/jse/v19n3/decock.pdf](https://ww2.amstat.org/publications/jse/v19n3/decock.pdf))
    at the Truman State University and can be downloaded from this link: [https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data).
    With this data, we are going to build features that contain information about
    square footage or sizes of different parts of the houses, the styles and materials
    used for the houses, the conditions and finishes of different parts of the houses,
    and various other attributes that further describe the information of each house.
    Using these features, we are going to explore different regression machine learning
    models, such as linear regression, Linear Support Vector Machine, and **Support
    Vector Machines** (**SVMs**) with polynomial and Gaussian kernels. Then, we will
    evaluate these models by looking at RMSE, R², and a plot of actual versus predicted
    values.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建预测房屋公平价值的模型，我们将使用一个包含79个解释变量的数据集，这些变量涵盖了美国爱荷华州艾姆斯市几乎所有住宅的属性及其2006年至2010年的最终销售价格。这个数据集由杜鲁门州立大学的迪安·德·科克([https://ww2.amstat.org/publications/jse/v19n3/decock.pdf](https://ww2.amstat.org/publications/jse/v19n3/decock.pdf))编制，可以通过此链接下载：[https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)。利用这些数据，我们将构建包含关于房屋面积或不同部分尺寸、房屋使用的风格和材料、房屋不同部分的状况和表面处理以及描述每栋房屋信息的其他各种属性的特征。使用这些特征，我们将探索不同的回归机器学习模型，如线性回归、线性支持向量机以及具有多项式和高斯核的**支持向量机（SVMs**）。然后，我们将通过查看RMSE、R²以及实际值与预测值之间的图表来评估这些模型。
- en: 'To summarize our problem definition for the fair value of house and property
    project:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结我们对房屋和财产公平价值项目的定义问题：
- en: What is the problem? We need a regression model that predicts the fair values
    of residential homes in Ames, Iowa, U.S.A., so that we can understand and make
    better informed decisions when purchasing houses.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题是什么？ 我们需要一个回归模型来预测美国爱荷华州艾姆斯市的住宅公平价值，这样我们就可以在购买房屋时更好地理解和做出更明智的决策。
- en: Why is it a problem? Due to the complex nature and numerous moving parts in
    deciding the fair value of a house or a property, it is advantageous to have a
    machine learning model that can predict and inform home buyers what the expected
    values of houses that they are looking at are.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么这是一个问题？ 由于决定房屋或财产公平价值具有复杂性和众多变量，拥有一个能够预测并告知购房者他们所看房屋预期价值的机器学习模型是有利的。
- en: What are some of the approaches to solving this problem? We are going to use
    a pre-compiled dataset that contains 79 explanatory variables that contain information
    of residential homes in Ames, Iowa, U.S.A., and build and encode features of mixed
    types (both categorical and continuous). Then, we will explore linear regression
    and support vector machines with different Kernels for making predictions of fair
    values of houses. We will evaluate the model candidates by looking at RMSE, R²,
    and an actual versus predicted values plot.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决这个问题的方法有哪些？ 我们将使用一个包含79个解释变量的预编译数据集，这些变量包含了美国爱荷华州艾姆斯市住宅的信息，并构建和编码混合类型（既是分类变量也是连续变量）的特征。然后，我们将探索使用不同核函数的线性回归和支持向量机来预测房屋的公平价值。我们将通过查看RMSE、R²以及实际值与预测值之间的图表来评估模型候选者。
- en: What are the success criteria? As we want our predictions of house prices to
    be as close to the actual house sale prices as possible, we want to gain as low
    an RMSE as possible, without hurting our goodness of fit measure, R², and the
    plot of actual versus predicted values.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功的标准是什么？ 我们希望我们的房价预测尽可能接近实际的房屋销售价格，因此我们希望获得尽可能低的RMSE（均方根误差），同时不损害我们的拟合优度指标R²，以及实际值与预测值之间的图表。
- en: Categorical versus continuous variables
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类变量与连续变量
- en: Now let's start looking at the actual dataset. You can follow this link: [https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)
    and download the `train.csv` and `data_description.txt` files. We are going to
    build models using the `train.csv` file, and the `data_description.txt` file will
    help us better understand the structure of the dataset, especially concerning
    the categorical variables we have.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始查看实际的数据集。您可以点击以下链接：[https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)
    下载`train.csv`和`data_description.txt`文件。我们将使用`train.csv`文件来构建模型，而`data_description.txt`文件将帮助我们更好地理解数据集的结构，特别是关于我们已有的分类变量。
- en: If you look at the train data file and the description file, you can easily
    find that there are some variables with certain names or codes that represent
    specific types of each house's attributes. For example, the `Foundation` variable
    can take one of the values among `BrkTil`, `CBlock`, `PConc`, `Slab`, `Stone`,
    and `Wood`, where each of those values or codes represents the type of foundation
    that a house is built with—Brick and Tile, Cinder Block, Poured Contrete, Slab, Stone,
    and Wood respectively. On the other hand, if you look at the `TotalBsmtSF` variable
    in the data, you can see that it can take any numerical values and the values
    are continuous. As mentioned previously, this dataset contains mixed types of
    variables and we need to approach carefully when we are dealing with a dataset
    with both categorical and continuous variables.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看训练数据文件和描述文件，你可以很容易地找到一些具有特定名称或代码的变量，它们代表每栋房屋属性的特定类型。例如，`Foundation`变量可以取`BrkTil`、`CBlock`、`PConc`、`Slab`、`Stone`和`Wood`中的任何一个值，其中这些值或代码分别代表房屋建造时所用的地基类型——砖和瓦、混凝土块、浇筑混凝土、板、石头和木材。另一方面，如果你查看数据中的`TotalBsmtSF`变量，你可以看到它可以取任何数值，并且这些值是连续的。如前所述，这个数据集包含混合类型的变量，我们在处理既有分类变量又有连续变量的数据集时需要谨慎处理。
- en: Non-ordinal categorical variables
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非序数分类变量
- en: 'Let''s first look at some categorical variables and their distributions. The
    first house attribute that we are going to look at is the building type. The code
    to build a bar chart that shows the distributions of the building type is as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看看一些分类变量及其分布。我们将首先查看的建筑属性是建筑类型。显示建筑类型分布的柱状图的代码如下：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When you run this code, it will display a bar chart like the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，它将显示一个类似于以下的柱状图：
- en: '![](img/00066.jpeg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00066.jpeg)'
- en: As you can tell from this bar chart, the majority of the building types in our
    dataset is 1Fam, which represents the *Single-family Detached* building type.
    The second most common building type is TwnhsE, which represents the *Townhouse
    End Unit* building type.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从这张柱状图中可以看出，我们数据集中大多数的建筑类型是1Fam，这代表着*独立单户住宅*建筑类型。第二常见的建筑类型是TwnhsE，代表着*联排别墅端单元*建筑类型。
- en: 'Let''s take a look at one more categorical variable, Lot Configuration (`LotConfig`
    field in the dataset). The code to build a bar chart for lot configuration distributions
    is as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看看一个分类变量，地块配置（数据集中的`LotConfig`字段）。绘制地块配置分布柱状图的代码如下：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When you run this code, it will display the following bar chart:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，它将显示以下柱状图：
- en: '![](img/00067.jpeg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00067.jpeg)'
- en: As you can see from this bar chart, inside lot is the most common lot configuration
    in our dataset, and corner lot is the second most common log configuration.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从这张柱状图中可以看出，内部地块是我们数据集中最常见的地块配置，其次是角地块。
- en: Ordinal categorical variable
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序数分类变量
- en: The two categorical variables that we just looked at have no natural ordering.
    One type does not come before another or one type does not have more weight than
    another. However, there are some categorical variables that have natural ordering,
    and we call such categorical variables ordinal categorical variables. For example,
    when you rank a quality of a material from 1 to 10, where 10 represents the best
    and 1 represents the worst, there is a natural ordering. Let's look at some of
    the ordinal categorical variables in this dataset.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才查看的两个分类变量没有自然的顺序。一种类型并不在另一种类型之前，或者一种类型并不比另一种类型更重要。然而，有些分类变量具有自然顺序，我们称这样的分类变量为序数分类变量。例如，当你将材料的品质从1到10进行排名时，其中10代表最佳，1代表最差，这就存在一个自然顺序。让我们看看这个数据集中的一些序数分类变量。
- en: 'The first ordinal categorical variable that we are going to look at is the
    `OverallQual` attribute, which represents the overall material and finish of the
    house. The code to look at the distributions of this variable is as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要查看的第一个有序分类变量是`OverallQual`属性，它代表房屋的整体材料和装修。查看该变量分布的代码如下：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'When you run this code, it will display the following bar chart in order from
    10 to 1:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，它将按从10到1的顺序显示以下条形图：
- en: '![](img/00068.jpeg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00068.jpeg)'
- en: As expected, there is a smaller number of houses in the *Very Excellent, *encoded
    as 10, or *Excellent*,encoded as 9, categories than there are in the *Above Average*,
    encoded as 6, or *Average* categories, encoded as 5.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，在*非常优秀*（编码为10）或*优秀*（编码为9）类别中的房屋数量比在*高于平均水平*（编码为6）或*平均水平*（编码为5）类别中的房屋数量要少。
- en: 'Another ordinal categorical variable that we will be looking at is the `ExterQual`
    variable, which represents the exterior quality. The code to look at the distributions
    of this variable is as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要查看的另一个有序分类变量是`ExterQual`变量，它代表外部质量。查看该变量分布的代码如下：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When you run this code, it will display the following bar chart:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，它将显示以下条形图：
- en: '![](img/00069.jpeg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00069.jpeg)'
- en: 'Unlike the `OverallQual` variable, the `ExterQual` variable does not have numerical
    values for the ordering. In our dataset, it has one of the following values: `Ex`,
    `Gd`, `TA`, and `FA`, and these represent excellent, good, average/typical, and
    fair respectively. Although this variable does not have numerical values, it clearly
    has a natural ordering, where the excellent category (Ex) represents the best
    quality of material on the exterior and the good category (Gd) represents the
    second best quality of material on the exterior. In the feature engineering step,
    we will discuss how we can encode this type of variable for our future model building
    step.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 与`OverallQual`变量不同，`ExterQual`变量没有用于排序的数值。在我们的数据集中，它有以下几种值：`Ex`、`Gd`、`TA`和`FA`，分别代表优秀、良好、平均/典型和公平。尽管这个变量没有数值，但它显然有一个自然排序，其中优秀类别（Ex）代表外部材料质量的最佳，良好类别（Gd）代表外部材料质量的第二佳。在特征工程步骤中，我们将讨论如何为我们的未来模型构建步骤编码此类变量。
- en: Continuous variable
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连续变量
- en: 'We have so far looked at two types of categorical variables in our dataset.
    However, there is another type of variable in the dataset; the continuous variable.
    Unlike categorical variables, continuous variables have no limited number of values
    they can take. For example, square footage for basement area of a house can be
    any positive number. A house can have a 0 square foot basement area (or no basement)
    or a house can have a 1,000 square feet basement area. The first continuous variable
    that we are going to look at is `1stFlrSF`, which represents the first floor square
    feet. The following code shows how we can build a histogram for `1stFlrSF`:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经查看了我们数据集中的两种类型的分类变量。然而，数据集中还有另一种类型的变量；连续变量。与分类变量不同，连续变量可以取无限多个值。例如，房屋地下室面积的平方英尺可以是任何正数。一栋房屋可以有0平方英尺的地下室面积（或没有地下室），或者一栋房屋可以有1,000平方英尺的地下室面积。我们将要查看的第一个连续变量是`1stFlrSF`，它代表一楼平方英尺。以下代码展示了我们如何为`1stFlrSF`构建直方图：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When you run this code, the following histogram will be displayed:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，将显示以下直方图：
- en: '![](img/00070.gif)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00070.gif)'
- en: 'One thing that is obvious from this chart is that it has a long tail in the
    positive direction, or in other words, the distribution is right skewed. The skewness
    in the data can adversely affect us when we build ML models. One way to handle
    this skewness in the dataset is to apply some transformations. One frequently
    used transformation is the log transformation, where you take log values of a
    given variable. In this example, the following code shows how we can apply log
    transformation to the `1stFlrSF` variable and show a histogram for the transformed
    variable:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从这张图表中明显可以看出，它在正方向上有一个长尾，换句话说，分布是右偏的。数据中的偏斜性可能会在我们构建机器学习模型时对我们产生不利影响。处理数据集中这种偏斜性的一种方法是对数据进行一些转换。一种常用的转换方法是对数转换，即取给定变量的对数值。在这个例子中，以下代码展示了我们如何对`1stFlrSF`变量应用对数转换并显示转换变量的直方图：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'When you run this code, you will see the following histogram:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，你将看到以下直方图：
- en: '![](img/00071.jpeg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00071.jpeg)'
- en: 'As you can see from this chart, the distribution looks more symmetric and closer
    to the bell shape that we are familiar with, compared to the previous histogram
    that we looked at for the same variable. Log transformation is frequently used
    to handle skewness in the dataset and make the distribution closer to the normal
    distribution. Let''s look at another continuous variable in our dataset. The following
    code is used to show the distribution of the `GarageArea` variable, which represents
    the size of the garage in square feet:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从这张图表中可以看到，与之前查看的同一变量的直方图相比，分布看起来更加对称，更接近我们熟悉的钟形。对数变换通常用于处理数据集中的偏斜，并使分布更接近正态分布。让我们看看我们数据集中的另一个连续变量。以下代码用于展示
    `GarageArea` 变量的分布，它代表车库的面积（平方英尺）：
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'When you run this code, you will see the following histogram:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行此代码时，你会看到以下直方图：
- en: '![](img/00072.jpeg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00072.jpeg)'
- en: 'Similar to the previous case of `1stFlrSF`, it is also right skewed, although
    it seems the degree of skewness is less than `1stFlrSF`. We used the following
    code to apply log transformation for the `GarageArea` variable:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `1stFlrSF` 的前一个案例类似，它也是右偏斜的，尽管看起来偏斜的程度小于 `1stFlrSF`。我们使用了以下代码对 `GarageArea`
    变量应用对数变换：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following histogram chart will be displayed when you run this code:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行此代码时，将显示以下直方图图表：
- en: '![](img/00073.jpeg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00073.jpeg)'
- en: As expected, the distribution looks closer to the normal distribution when the
    log transformation is applied to the variable.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，当对变量应用对数变换时，分布看起来更接近正态分布。
- en: Target variable – sale price
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标变量 - 销售价格
- en: 'There is one last variable we need to take a look at before we move onto the
    feature engineering step; the target variable. In this fair value of a house project,
    our target variable for predictions is `SalePrice`, which represents the final
    sale price in U.S. dollar amounts for each residential home sold in Ames, Iowa,
    U.S.A. from 2006 to 2010\. Since the sale price can take any positive numerical
    value, it is a continuous variable. Let''s first look at how we built a histogram
    for the sale price variable:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进行特征工程步骤之前，还有一个变量需要查看；即目标变量。在这个房屋公允价值项目中，我们的预测目标变量是 `SalePrice`，它代表美国爱荷华州艾姆斯市从2006年到2010年销售的每套住宅的最终销售价格（以美元计）。由于销售价格可以取任何正数值，因此它是一个连续变量。让我们首先看看我们是如何为销售价格变量构建直方图的：
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'When you run this code, the following histogram chart will be shown:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行此代码时，将显示以下直方图图表：
- en: '![](img/00074.gif)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00074.gif)'
- en: 'Similar to the previous cases of continuous variables, the distribution of
    *SalePrice* has a long right tail and it''s heavily skewed to the right. This
    skewness often adversely affects the regression models, as some of those models,
    such as the linear regression model, assume that variables are normally distributed. 
    As discussed previously, we can fix this issue by applying log transformation.
    The following code shows how we log transformed the sale price variable and built
    a histogram chart:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前连续变量的案例类似，*SalePrice* 的分布具有较长的右尾，并且严重向右偏斜。这种偏斜通常会对回归模型产生不利影响，因为一些模型，例如线性回归模型，假设变量是正态分布的。正如之前所讨论的，我们可以通过应用对数变换来解决这个问题。以下代码展示了我们如何对销售价格变量进行对数变换并构建直方图：
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'When you run this code, you will see the following histogram for the log-transformed
    sale price variable:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行此代码时，你会看到以下针对对数变换后的销售价格变量的直方图：
- en: '![](img/00075.gif)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00075.gif)'
- en: As expected, the distribution of the `SalePrice` variable looks much closer
    to the normal distribution. We are going to use this log-transformed `SalePrice`
    variable as the target variable for our future model building steps.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，`SalePrice` 变量的分布看起来与正态分布非常接近。我们将使用这个对数变换后的 `SalePrice` 变量作为我们未来模型构建步骤的目标变量。
- en: The full code for this data analysis step can be found at this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/DataAnalyzer.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/DataAnalyzer.cs).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据分析步骤的完整代码可以在以下链接中找到：[https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/DataAnalyzer.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/DataAnalyzer.cs)。
- en: Feature engineering and encoding
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程和编码
- en: Now that we have looked at our dataset and the distributions of the categorical,
    continuous, and target variables, let's start building features for our ML models.
    As we discussed previously, categorical variables in our dataset have certain
    string values to represent each type of variable. However, as it might already
    be clear to you, we cannot use string types to train our ML models. All the values
    of variables need to be numerical to be able to used for fitting the models. One
    way to handle categorical variables with multiple types or categories is to create
    dummy variables.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经查看过我们的数据集以及分类、连续和目标变量的分布，让我们开始为我们的机器学习模型构建特征。正如我们之前讨论的，我们数据集中的分类变量有特定的字符串值来表示每种变量类型。然而，正如你可能已经清楚的那样，我们不能使用字符串类型来训练我们的机器学习模型。所有变量的值都需要是数值型的，以便能够用于拟合模型。处理具有多种类型或类别的分类变量的一种方法是通过创建虚拟变量。
- en: Dummy variables
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚拟变量
- en: 'A dummy variable is a variable that takes a value of 0 or 1 to indicate whether
    a given category or type exists or not. For example, in the case of `BldgType`
    variable, where it has the five different categories `1Fam`, `2FmCon`, `Duplx`, `TwnhsE`,
    and `Twnhs`, we will create five dummy variables, where each dummy variable represents
    the existence or absence of each of those five categories in a given record. The
    following shows an example of how dummy variable encoding works:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟变量是一个变量，它取0或1的值来指示给定的类别或类型是否存在。例如，在`BldgType`变量的情况下，它有五个不同的类别`1Fam`、`2FmCon`、`Duplx`、`TwnhsE`和`Twnhs`，我们将创建五个虚拟变量，其中每个虚拟变量代表在给定记录中这些五个类别中的每一个的存在或不存在。以下是如何进行虚拟变量编码的一个示例：
- en: '![](img/00076.gif)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00076.gif)'
- en: As you can see from this example, the absence and existence of each category
    of the building types is encoded into a separate dummy variable as `0` or `1`.
    For example, for the record with the ID `1`, the building type is `1Fam` and this
    is encoded with the value 1 for the new variable, `BldgType_1Fam`, and 0 for the
    other four new variables, `BldgType_2fmCon`, `BldgType_Duplex`, `BldgType_TwnhsE`,
    and `BldgType_Twnhs`. On the other hand, for the record with the ID `10`, the
    building type is `2fmCon` and this is encoded with the value 1 for the variable `BldgType_2fmCon` and
    0 for the other four new variables, `BldgType_1Fam`, `BldgType_Duplex`, `BldgType_TwnhsE`,
    and `BldgType_Twnhs`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从本例中可以看到，建筑类型中每个类别的存在和不存在都被编码为单独的虚拟变量，值为`0`或`1`。例如，对于ID为`1`的记录，建筑类型是`1Fam`，这在新变量`BldgType_1Fam`中编码为值1，而在其他四个新变量`BldgType_2fmCon`、`BldgType_Duplex`、`BldgType_TwnhsE`和`BldgType_Twnhs`中编码为0。另一方面，对于ID为`10`的记录，建筑类型是`2fmCon`，这在新变量`BldgType_2fmCon`中编码为值1，而在其他四个新变量`BldgType_1Fam`、`BldgType_Duplex`、`BldgType_TwnhsE`和`BldgType_Twnhs`中编码为0。
- en: 'For this chapter, we created dummy variables for the following list of categorical
    variables:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，我们为以下列表中的分类变量创建了虚拟变量：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following code shows a method we wrote to create and encode dummy variables:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了我们所编写的一种创建和编码虚拟变量的方法：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see from line 8 of this method, we prefix the newly created dummy
    variables with the original categorical variable's names and append them with
    each category. For example, `BldgType` variables in the `1Fam` category will be
    encoded as `BldgType_1Fam`. Then, in line 15 of the `CreateCategories` method,
    we are encoding all the other values with 0s to indicate the absence of such categories
    in the given categorical variable.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从该方法的第8行中可以看到，我们在新创建的虚拟变量前加上原始分类变量的名称，并在其后加上每个类别。例如，属于`1Fam`类别的`BldgType`变量将被编码为`BldgType_1Fam`。然后，在第15行的`CreateCategories`方法中，我们将所有其他值编码为0，以表示在给定的分类变量中不存在此类类别。
- en: Feature encoding
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征编码
- en: 'Now that we know which categorical variables to encode and have created a method
    for dummy variable encoding for those categorical variables, it is time to build
    a data frame with features and their values. Let''s first take a look at how we
    went about creating a features data frame in the following code snippet:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了哪些分类变量需要编码，并为这些分类变量创建了一个虚拟变量编码方法，是时候构建一个包含特征及其值的DataFrame了。让我们首先看看以下代码片段中我们是如何创建特征DataFrame的：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Once we have created and encoded all the features for our model training, we
    then export this `featuresDF` data frame into a `.csv` file. The following code
    shows how we export the data frame into a `.csv` file:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们为模型训练创建了并编码了所有特征，我们就将这个`featuresDF` DataFrame导出为`.csv`文件。以下代码显示了如何将DataFrame导出为`.csv`文件：
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We now have all the necessary features that we can use to start building machine
    learning models to predict fair values of houses. The full code for feature encoding
    and engineering can be found in this link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/FeatureEngineering.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/FeatureEngineering.cs).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了所有必要的特征，我们可以开始构建机器学习模型来预测房屋的公允价值。特征编码和工程的全代码可以在以下链接中找到：[https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/FeatureEngineering.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/FeatureEngineering.cs)。
- en: Linear regression versus SVM with kernels
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归与核支持向量机
- en: 'The first thing we need to do before we start training our machine learning
    models is to split our dataset into train and test sets. In this section, we will
    split the sample set into train and test sets by randomly sub-selecting and dividing
    the indexes at a pre-defined proportion. The code we used to split the dataset
    into train and test sets is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始训练机器学习模型之前，我们需要将我们的数据集分成训练集和测试集。在本节中，我们将通过随机子选择和按预定义比例划分索引来将样本集分成训练集和测试集。我们将用于将数据集分成训练集和测试集的代码如下：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once we have these train and test data frames ready, we need to filter out
    unnecessary columns from the data frames, since the train and test data frames
    currently have values for columns, such as `SalePrice` and `Id`. Then, we will
    have to cast the two data frames into arrays of double arrays, which will be input
    to our learning algorithms. The code to filter out unwanted columns from the train
    and test data frames and to cast the two data frames into arrays of arrays is
    as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们准备好了这些训练和测试数据框，我们需要从数据框中过滤掉不必要的列，因为训练和测试数据框目前有诸如`SalePrice`和`Id`等列的值。然后，我们将不得不将这两个数据框转换为双精度数组数组，这些数组将被输入到我们的学习算法中。过滤掉训练和测试数据框中不需要的列以及将两个数据框转换为数组数组的代码如下：
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Linear regression
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归
- en: 'The first ML model we are going to explore for this chapter''s housing price
    prediction project is the linear regression model. You should already be familiar
    with building linear regression models in C# using the Accord.NET framework. We
    use the following code to build a linear regression model:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将要探索的第一个机器学习模型用于房屋价格预测项目是线性回归模型。你应该已经熟悉使用Accord.NET框架在C#中构建线性回归模型。我们使用以下代码构建线性回归模型：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The only difference between this chapter's linear regression model code and
    the previous chapter's code is the `IsRobust` parameter to the `OrdinaryLeastSquares`
    learning algorithm. As the name suggests, it makes the learning algorithm fit
    a more robust linear regression model, meaning it is less sensitive to outliers.
    When we have variables that are not normally distributed, as is the case for this
    project, it often causes problems when fitting a linear regression model as traditional
    linear regression models are sensitive to outliers from non-normal distributions.
    Setting this parameter to `true` helps resolve this issue.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的线性回归模型代码与上一章代码的唯一区别是传递给`OrdinaryLeastSquares`学习算法的`IsRobust`参数。正如其名所示，它使学习算法拟合一个更稳健的线性回归模型，这意味着它对异常值不太敏感。当我们有非正态分布的变量时，就像本项目的情况一样，在拟合线性回归模型时，这通常会导致问题，因为传统的线性回归模型对非正态分布的异常值很敏感。将此参数设置为`true`有助于解决这个问题。
- en: Linear SVM
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性支持向量机
- en: 'The second learning algorithm we are going to experiment with in this chapter
    is the linear SVM. The following code shows how we build a linear SVM model:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将要实验的第二种学习算法是线性支持向量机。以下代码展示了我们如何构建线性支持向量机模型：
- en: '[PRE17]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As you might have noticed, and similar to the previous chapter, we used `LinearRegressionNewtonMethod`
    as a learning algorithm to fit a linear SVM.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如你可能已经注意到的，并且与上一章类似，我们使用`LinearRegressionNewtonMethod`作为学习算法来拟合线性支持向量机。
- en: SVM with a polynomial kernel
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多项式核支持向量机
- en: The next model we are going to experiment with is an SVM with a polynomial kernel.
    We will not go into too much detail about the kernel methods, but simply put,
    kernels are functions of input feature variables that can transform and project
    the original variables into a new feature space that is more linearly separable.
    The polynomial kernel looks at the combinations of input features, on top of the
    original input features. These combinations of input feature variables are often
    called **interaction variables** in regression analysis. Using different kernel
    methods will make SVM models learn and behave differently with the same dataset.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来要实验的下一个模型是具有多项式核的SVM。我们不会过多地介绍核方法，简单来说，核是输入特征变量的函数，可以将原始变量转换并投影到一个新的特征空间，这个空间更易于线性分离。多项式核考虑了原始输入特征的组合，这些输入特征变量的组合通常在回归分析中被称为**交互变量**。使用不同的核方法会使SVM模型在相同的数据集上学习并表现出不同的行为。
- en: 'The following code shows how you can build a SVM model with a polynomial kernel:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何构建具有多项式核的SVM模型：
- en: '[PRE18]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We are using the `FanChenLinSupportVectorRegression` learning algorithm for
    a support vector machine with a polynomial kernel. In this example, we used a
    degree 3 polynomial, but you can experiment with different degrees. However, the
    higher the degrees are, the more likely it is to overfit to the training data.
    So, you will have to take cautious steps when you are using high degree polynomial
    kernels.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`FanChenLinSupportVectorRegression`学习算法来构建具有多项式核的支持向量机。在这个例子中，我们使用了3次多项式，但您可以尝试不同的次数。然而，次数越高，越有可能过拟合训练数据。因此，当您使用高次多项式核时，必须谨慎行事。
- en: SVM with a Gaussian kernel
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有高斯核的SVM
- en: Another commonly used kernel method is the Gaussian kernel. Simply put, the
    Gaussian kernel looks at the distance between the input feature variables and
    results in higher values for close or similar features and lower values for more
    distanced features. The Gaussian kernel can help transform and project a linearly
    inseparable dataset into a more linearly separable feature space and can improve
    the model performances.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常用的核方法是高斯核。简单来说，高斯核考虑了输入特征变量之间的距离，对于接近或相似的特征给出较高的值，而对于距离较远的特征给出较低的值。高斯核可以帮助将线性不可分的数据集转换为一个更易于线性分离的特征空间，并可以提高模型性能。
- en: 'The following code shows how you can build a SVM model with a Gaussian kernel:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何构建具有高斯核的SVM模型：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Similar to the case of the polynomial kernel, we used the `FanChenLinSupportVectorRegression`
    learning algorithm, but replaced the kernel with the `Gaussian` method.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 与多项式核的情况类似，我们使用了`FanChenLinSupportVectorRegression`学习算法，但将核替换为`Gaussian`方法。
- en: We have discussed how we can use different kernel methods for SVMs so far. We
    will now compare the performances of these models on the housing price dataset.
    You can find the full code we used for building and evaluating models at this
    link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/Modeling.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/Modeling.cs).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了如何为SVM使用不同的核方法。现在，我们将比较这些模型在房价数据集上的性能。您可以在以下链接找到我们构建和评估模型所使用的完整代码：[https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/Modeling.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.5/Modeling.cs)。
- en: Model validations
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型验证
- en: 'Before we start looking into the performances of the linear regression and
    SVM models that we built in the previous section, let''s refresh our memory on
    the metrics and the diagnostics plot we discussed in the previous chapter. We
    are going to look at RMSE, R², and a plot of actual versus predicted values to
    evaluate the performances of our models. The code we are going to use throughout
    this section for model evaluation is as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始查看上一节中构建的线性回归和SVM模型的性能之前，让我们回顾一下上一章中讨论的指标和诊断图。我们将查看RMSE、R²以及实际值与预测值对比的图表来评估我们模型的性能。本节中我们将用于模型评估的代码如下：
- en: '[PRE20]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The way we use this method for our models is as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这种方法构建模型的方式如下：
- en: '[PRE21]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](img/00077.gif)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00077.gif)'
- en: When looking at the values of the goodness of fit, R², and the RMSE values,
    the linear SVM model seems to have the best fit to the dataset, and the SVM model
    with the Gaussian kernel seems to have the second best fit to the dataset. Looking
    at this output, the SVM model with the polynomial kernel does not seem to work
    well for predicting the fair values of house prices. Now, let's look at the diagnostic
    plots to evaluate how well our models predict the house prices.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot shows the diagnostic plot for the linear regression model:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00078.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: This diagnostic plot for the linear regression model looks good. Most of the
    points seem to be aligned on a diagonal line, which suggests that the linear regression
    model's predictions are well aligned with the actual values.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot shows the diagnostic plot for the linear SVM model:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00079.jpeg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: As expected from the previous R² metrics value, the goodness of fit for the
    linear SVM model looks good, even though there seems to be one prediction that
    is far off from the actual value. Most of the points seem to be aligned on a diagonal
    line, which suggests that the linear SVM model's predictions are well aligned
    with the actual values.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot shows the diagnostic plot for the SVM model with the polynomial
    kernel:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00080.jpeg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
- en: This diagnostic plot for the SVM model with the polynomial kernel suggests that
    the goodness of fit for this model is not so good. Most of the predictions lie
    on a straight line at around 12\. This is well aligned with the other metrics,
    where we have seen that RMSE and R² measures were the worst among the four models
    we tried.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot shows the diagnostic plot for the SVM model with the Gaussian
    kernel:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00081.jpeg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
- en: This diagnostic plot result for the SVM model with the Gaussian kernel is rather
    surprising. From the RMSE and R² measures, we expected the model fit using SVM
    with Gaussian kernel will be good. However, most of the predictions by this model
    are on a straight line, without showing any patterns of a diagonal line. Looking
    at this diagnostic plot, we cannot conclude that the model fit for the SVM model
    with the Gaussian kernel is good, even though the R² metrics showed a strong positive
    sign of the goodness of model fit.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: By looking at both the metrics numbers and the diagnostic plots, we can conclude
    that the linear regression model and the linear SVM model seem to work the best
    for predicting the fair values of house prices. This project shows us a good example
    of the importance of looking at the diagnostic plots. Looking at and optimizing
    for single metrics might be tempting, but it is always better to evaluate models
    with more than one validation metric, and looking at diagnostic plots, such as
    the plot of actual values against predicted values, is especially helpful for
    regression models.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we expanded our knowledge and skills regarding building regression
    models. We built prediction models using the sale price data of residential homes
    in Ames, Iowa, U.S.A. Unlike other chapters, we had a more complex dataset, where
    the variables had mixed types, categorical and continuous. We looked at the categorical
    variables, where there were no natural orderings (non-ordinal) and where there
    were natural orderings (ordinal) in the categories. We then looked at continuous
    variables, whose distributions had long right tails. We also discussed how we
    can use log transformations on such variables with high skewness in the data to
    mediate the skewness and make those variables' distributions closer to normal
    distributions.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们扩展了关于构建回归模型的知识和技能。我们使用了美国爱荷华州艾姆斯市的住宅房屋的销售价格数据来构建预测模型。与其他章节不同，我们有一个更复杂的数据库，其中的变量具有混合类型，包括分类和连续变量。我们研究了分类变量，其中没有自然顺序（非序数）和有自然顺序（序数）的类别。然后我们研究了连续变量，其分布具有长的右尾。我们还讨论了如何使用对数变换来处理数据中具有高偏度的变量，以调节偏度并使这些变量的分布更接近正态分布。
- en: We discussed how to handle categorical variables in our dataset. We learned
    how to create and encode dummy variables for each type of categorical variable.
    Using these features, we experimented with four different machine learning models—linear
    regression, linear support vector machine, SVM with a polynomial kernel, and SVM
    with a Gaussian kernel. We briefly discussed the purpose and usage of kernel methods
    and how they can be used for linearly inseparable datasets. Using RMSE, R², and
    the plot of the actual values against the predicted values, we evaluated the performances
    of those four models we built for predicting the fair values of house prices in
    Ames, Iowa, U.S.A. During our model validation step, we saw a case where the validation
    metrics results contradict with the diagnostic plots results and we have learned
    the importance of looking at more than one metric and diagnostic plots to be sure
    of our model's performance.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了如何处理数据集中的分类变量。我们学习了如何为每种类型的分类变量创建和编码虚拟变量。使用这些特征，我们尝试了四种不同的机器学习模型——线性回归、线性支持向量机、具有多项式核的支持向量机和具有高斯核的支持向量机。我们简要讨论了核方法的目的和用法以及它们如何用于线性不可分的数据集。使用RMSE、R²以及实际值与预测值的图表，我们评估了我们构建的四个模型在预测美国爱荷华州艾姆斯市房屋公平价值方面的性能。在我们的模型验证步骤中，我们看到了一个案例，其中验证指标的结果与诊断图的结果相矛盾，我们学到了查看多个指标和诊断图的重要性，以确保我们模型的表现。
- en: In the next chapter, we are going to switch gear again. So far, we have been
    learning how to use and build supervised learning algorithms. However, in the
    next chapter, we are going to learn unsupervised learning and more specifically
    clustering algorithms. We will discuss how to use clustering algorithms to gain
    insights on the customer segments using an online retail dataset.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将再次转换方向。到目前为止，我们一直在学习如何使用和构建监督学习算法。然而，在下一章中，我们将学习无监督学习，特别是聚类算法。我们将讨论如何使用聚类算法通过在线零售数据集来深入了解客户细分。
