["```py\n    pip install evidently==0.1.17.dev0\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    from sklearn import datasets\n    from sklearn.model_selection import train_test_split\n    from evidently.dashboard import Dashboard\n    from evidently.tabs import DataDriftTab, NumTargetDriftTab,CatTargetDriftTab\n    ```", "```py\n    reference_data = \\\n    pd.read_csv(\"training_data.csv\", header=None,\n                names=[ \"day{}\".format(i) for i in \\\n                        range(0,14) ]+[\"target\"] )\n    ```", "```py\n    latest_input_data = \\\n    pd.read_csv(\"to_score_input_data.csv\", header=None,\n                 names=[ \"day{}\".format(i) for i in \\\n                         range(0,14) ] )\n    ```", "```py\n    EXPERIMENT_NAME=\"./reports_data_drift\"\n    mlflow.set_experiment(EXPERIMENT_NAME)\n    with mlflow.start_run():\n        drift_dashboard = Dashboard(tabs=[DataDriftTab])\n        drift_dashboard.calculate(reference_data,\n                                  latest_input_data)\n        drift_dashboard.save(EXPERIMENT_NAME+\"/input_data_drift.html\")\n        drift_dashboard._save_to_json(EXPERIMENT_NAME+\"/input_data_drift.json\")\n        mlflow.log_artifacts(EXPERIMENT_NAME)\n    ```", "```py\n    production_scored_data = \\\n    pd.read_csv(\"scored_data.csv\", header=None,\n                names=[ \"day{}\".format(i) for i in \\\n                        range(0,14) ]+[\"target\"] )\n    bcancer_data_and_target_drift = \\\n    Dashboard(reference_data, production_scored_data,\n              tabs=[ CatTargetDriftTab])\n    bcancer_data_and_target_drift.save('reports/target_drift.html')\n    ```", "```py\n    EXPERIMENT_NAME=\"./reports_target_drift\"\n    mlflow.set_experiment(EXPERIMENT_NAME)\n    with mlflow.start_run():\n        model_target_drift = \\\n        Dashboard(reference_data, production_scored_data,\n                  tabs=[CatTargetDriftTab])\n        model_target_drift.save(EXPERIMENT_NAME+\"/target_drift.html\")\n        drift_dashboard._save_to_json(EXPERIMENT_NAME+\"/target_drift.json\")\n        mlflow.log_artifacts(EXPERIMENT_NAME)\n    ```", "```py\n    import xgboost as xgb\n    import mlflow\n    from evidently.tabs import ClassificationPerformanceTab\n    ```", "```py\n    X=reference_data.iloc[:,:-1]\n    Y=reference_data.iloc[:,-1]\n    reference, production, y_train, y_test = \\\n    train_test_split(X, Y, test_size=0.33,\n                     random_state=4284, stratify=Y)\n    reference_train = xgb.DMatrix(reference,label=y_train)\n    dproduction= xgb.DMatrix(production)\n    dreference=xgb.DMatrix(reference)\n    ```", "```py\n    mlflow.xgboost.autolog()\n    EXPERIMENT_NAME=\"reports_model_performance\"\n    mlflow.set_experiment(EXPERIMENT_NAME)\n    with mlflow.start_run() as run:\n        model=xgb.train(dtrain=reference_train,params={})\n    ```", "```py\n        train_proba_predict = model.predict(dreference)\n        test_proba_predict = model.predict(dproduction)\n        test_predictions = [1\\. if y_cont > threshold else 0\\. for y_cont in test_proba_predict]\n        train_predictions = [1\\. if y_cont > threshold else 0\\. for y_cont in train_proba_predict]\n        reference['target'] = y_train\n        reference['prediction'] = train_predictions\n        production['target'] = y_test\n        production['prediction'] = test_predictions\n    ```", "```py\n        classification_performance = Dashboard( \n                      tabs=[ClassificationPerformanceTab])\n        classification_performance.calculate(reference,\n                                             production)\n        classification_performance.save('.reports/'+EXPERIMENT_NAME+'.html')\n        mlflow.log_artifact('.reports/'+EXPERIMENT_NAME+'.html')\n    ```"]