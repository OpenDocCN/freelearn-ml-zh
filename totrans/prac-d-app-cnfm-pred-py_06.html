<html><head></head><body>
<div id="_idContainer027">
<h1 class="chapter-number" id="_idParaDest-60"><a id="_idTextAnchor058"/><span class="koboSpan" id="kobo.1.1">6</span></h1>
<h1 id="_idParaDest-61"><a id="_idTextAnchor059"/><span class="koboSpan" id="kobo.2.1">Conformal Prediction for Classification</span></h1>
<p><span class="koboSpan" id="kobo.3.1">This chapter dives deeper into the topic of conformal prediction for classification problems. </span><span class="koboSpan" id="kobo.3.2">We will explore the concept of classifier calibration and demonstrate how conformal prediction compares to other calibration methods before introducing Venn-ABERS predictors as specialized techniques within conformal prediction. </span><span class="koboSpan" id="kobo.3.3">Additionally, we will provide an overview of open source tools that can be utilized to implement conformal prediction for </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">classifier calibration.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">We will cover the following topics in </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">this chapter:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.7.1">Classifier calibration</span></span></li>
<li><span class="koboSpan" id="kobo.8.1">Evaluating </span><span class="No-Break"><span class="koboSpan" id="kobo.9.1">calibration performance</span></span></li>
<li><span class="koboSpan" id="kobo.10.1">Various approaches to </span><span class="No-Break"><span class="koboSpan" id="kobo.11.1">classifier calibration</span></span></li>
<li><span class="koboSpan" id="kobo.12.1">Conformal prediction for </span><span class="No-Break"><span class="koboSpan" id="kobo.13.1">classifier calibration</span></span></li>
<li><span class="koboSpan" id="kobo.14.1">Open source tools for conformal prediction in </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">classification problems</span></span></li>
</ul>
<h1 id="_idParaDest-62"><a id="_idTextAnchor060"/><span class="koboSpan" id="kobo.16.1">Classifier calibration</span></h1>
<p><span class="koboSpan" id="kobo.17.1">Most statistical, machine</span><a id="_idIndexMarker173"/><span class="koboSpan" id="kobo.18.1"> learning, and deep learning models output predicted class labels, and the models are typically evaluated in terms of </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">their accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.20.1">Accuracy is a prevalent measure for assessing the performance of a machine learning classification model. </span><span class="koboSpan" id="kobo.20.2">It quantifies the ratio of instances that are correctly identified to the overall count in the dataset. </span><span class="koboSpan" id="kobo.20.3">In other words, accuracy tells us how often the model’s predictions align with the true labels of </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.22.1">The accuracy score measures how often the model’s predictions match the true observed labels. </span><span class="koboSpan" id="kobo.22.2">It is calculated as the fraction of correct predictions out of all predictions made. </span><span class="koboSpan" id="kobo.22.3">Accuracy scores between 0 and 1 quantify how accurate the model’s predictions are compared to the ground truth data. </span><span class="koboSpan" id="kobo.22.4">A higher accuracy score close to 1 signifies that the model is performing very accurately overall, with most of its predictions being</span><a id="_idIndexMarker174"/><span class="koboSpan" id="kobo.23.1"> correct. </span><span class="koboSpan" id="kobo.23.2">A lower accuracy approaching 0 indicates poor performance, with the majority of the model’s predictions being incorrect compared to the </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">true labels.</span></span></p>
<p><span class="koboSpan" id="kobo.25.1">The closer the accuracy is to 1, the better the model is performing. </span><span class="koboSpan" id="kobo.25.2">The closer it is to 0, the worse the model is at predicting the true labels in </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.27.1">Accuracy is a straightforward and intuitive metric that is easy to understand and interpret. </span><span class="koboSpan" id="kobo.27.2">However, it may not always be the most suitable metric, especially when dealing with imbalanced datasets. </span><span class="koboSpan" id="kobo.27.3">In imbalanced datasets, where the number of instances in different classes is significantly different, accuracy alone may be misleading. </span><span class="koboSpan" id="kobo.27.4">In an imbalanced dataset, a classifier that consistently predicts the majority class can attain a high accuracy based on the class distribution, even if it doesn’t identify the </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">minority class.</span></span></p>
<p><span class="koboSpan" id="kobo.29.1">In these scenarios, it’s crucial to look at other evaluation measures, such as precision, recall, F1 score, or ROC-AUC, to gain a fuller insight into the </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">model’s efficacy.</span></span></p>
<p><span class="koboSpan" id="kobo.31.1">Depending on the specific problem and the requirements, other metrics and considerations, such as the cost of false positives or false negatives, might be more relevant. </span><span class="koboSpan" id="kobo.31.2">Therefore, it is essential to assess the model’s performance using multiple evaluation metrics and consider the context in which the classification model will </span><span class="No-Break"><span class="koboSpan" id="kobo.32.1">be applied.</span></span></p>
<p><span class="koboSpan" id="kobo.33.1">Accuracy alone may be insufficient, particularly in critical applications, for </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">several reasons:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.35.1">Imbalanced datasets</span></strong><span class="koboSpan" id="kobo.36.1">: In scenarios where the dataset is imbalanced, accuracy can be misleading. </span><span class="koboSpan" id="kobo.36.2">If the majority class dominates the dataset, a model that predicts only the majority </span><a id="_idIndexMarker175"/><span class="koboSpan" id="kobo.37.1">class can achieve high accuracy but fails to capture the minority class effectively. </span><span class="koboSpan" id="kobo.37.2">This can be problematic in critical applications where correctly identifying rare events or detecting anomalies </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1">is crucial.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.39.1">Cost of errors</span></strong><span class="koboSpan" id="kobo.40.1">: In many real-world applications, the cost of false positives and false negatives can vary significantly. </span><span class="koboSpan" id="kobo.40.2">Accuracy treats all errors equally and does not consider the consequences of misclassifications. </span><span class="koboSpan" id="kobo.40.3">For instance, in a medical diagnosis, a false negative (failing to detect a disease) can be far more critical than a false positive. </span><span class="koboSpan" id="kobo.40.4">In such cases, accuracy alone does not provide sufficient information about the model’s performance in terms of the actual impact on decision-making</span><a id="_idIndexMarker176"/> <span class="No-Break"><span class="koboSpan" id="kobo.41.1">and outcomes.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.42.1">Probability estimation</span></strong><span class="koboSpan" id="kobo.43.1">: Accuracy does not take into account the confidence or uncertainty of the model’s predictions. </span><span class="koboSpan" id="kobo.43.2">It is essential to assess the model’s ability to provide well-calibrated probability estimates. </span><span class="koboSpan" id="kobo.43.3">Calibration refers to the </span><a id="_idIndexMarker177"/><span class="koboSpan" id="kobo.44.1">alignment between predicted probabilities and the true probabilities of events. </span><span class="koboSpan" id="kobo.44.2">A poorly calibrated model may provide overly confident or unreliable probability estimates, which can lead to incorrect decisions or the misinterpretation </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">of risks.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.46.1">Decision threshold</span></strong><span class="koboSpan" id="kobo.47.1">: Accuracy does not consider the decision threshold used for classification. </span><span class="koboSpan" id="kobo.47.2">Different decision thresholds can result in varying trade-offs between precision and recall. </span><span class="koboSpan" id="kobo.47.3">Depending on the application, certain misclassification errors may be more tolerable than others. </span><span class="koboSpan" id="kobo.47.4">Evaluating only accuracy does not provide insights into the model’s performance at different </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">decision thresholds.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.49.1">Let’s get to understanding the concepts of classifier </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">calibration next.</span></span></p>
<h2 id="_idParaDest-63"><a id="_idTextAnchor061"/><span class="koboSpan" id="kobo.51.1">Understanding the concepts of classifier calibration</span></h2>
<p><span class="koboSpan" id="kobo.52.1">In the previous chapters, we</span><a id="_idIndexMarker178"/><span class="koboSpan" id="kobo.53.1"> defined and discussed the concept of </span><span class="No-Break"><span class="koboSpan" id="kobo.54.1">classifier calibration.</span></span></p>
<p><span class="koboSpan" id="kobo.55.1">Classifier calibration involves adjusting the predicted probabilities from a classification model so that they better reflect the true likelihood of each class. </span><span class="koboSpan" id="kobo.55.2">The goal is to make the predictions </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">better calibrated.</span></span></p>
<p><span class="koboSpan" id="kobo.57.1">A well-calibrated classifier is one where the predicted probabilities match the empirical probabilities. </span><span class="koboSpan" id="kobo.57.2">For example, if the model predicts “class A” with 60% probability across 100 examples, then class A </span><a id="_idIndexMarker179"/><span class="koboSpan" id="kobo.58.1">should occur approximately 60 times out of those </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">100 predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.60.1">More formally, a well calibrated classifier satisfies the </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">following formula:</span></span></p>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.62.1">P</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.63.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.64.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.65.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.66.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.67.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.68.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.69.1">l</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.70.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.71.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.72.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.73.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.74.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.75.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.76.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.77.1">c</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.78.1">|</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.79.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.80.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.81.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.82.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.83.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.84.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.85.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.86.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.87.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.88.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.89.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.90.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.91.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.92.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.93.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.94.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.95.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.96.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.97.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.98.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.99.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.100.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.101.1">c</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.102.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.103.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.104.1">p</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.105.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.106.1">≈</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.107.1">p</span></span></p>
<p><span class="koboSpan" id="kobo.108.1">This means the observed frequency of class c should be close to p when the model predicts class c with </span><span class="No-Break"><span class="koboSpan" id="kobo.109.1">probability p.</span></span></p>
<p><span class="koboSpan" id="kobo.110.1">Calibration adjustment ensures the predicted probabilities are aligned with the relative frequencies in the actual data. </span><span class="koboSpan" id="kobo.110.2">The predictions are calibrated to the empirical evidence so that a predicted probability of </span><strong class="source-inline"><span class="koboSpan" id="kobo.111.1">0.7</span></strong><span class="koboSpan" id="kobo.112.1"> corresponds to a 70% chance based on the data. </span><span class="koboSpan" id="kobo.112.2">This calibration is essential for probability estimates to be meaningful </span><span class="No-Break"><span class="koboSpan" id="kobo.113.1">and reliable.</span></span></p>
<p><span class="koboSpan" id="kobo.114.1">For instance, consider a binary classifier that predicts whether an email is spam or not. </span><span class="koboSpan" id="kobo.114.2">For each email, it might predict a probability, say, </span><strong class="source-inline"><span class="koboSpan" id="kobo.115.1">0.8</span></strong><span class="koboSpan" id="kobo.116.1">, which means it believes there’s an 80% chance that the email is spam. </span><span class="koboSpan" id="kobo.116.2">If the classifier is well calibrated, then out of all emails that it assigns a spam probability of </span><strong class="source-inline"><span class="koboSpan" id="kobo.117.1">0.8</span></strong><span class="koboSpan" id="kobo.118.1">, about 80% should </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">be spam.</span></span></p>
<p><span class="koboSpan" id="kobo.120.1">Without calibration, the output probabilities of a classifier might not correspond to the true likelihood of the predicted class, which can be problematic for decision-making. </span><span class="koboSpan" id="kobo.120.2">Calibration methods adjust these probabilities to better reflect reality. </span><span class="koboSpan" id="kobo.120.3">The goal is to have the output probabilities of the classifier be as close as possible to the </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">true probabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.122.1">Model calibration is crucial because of the </span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">following aspects:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.124.1">Reliable probability estimates</span></strong><span class="koboSpan" id="kobo.125.1">: Calibrated classifiers provide accurate and reliable probability </span><a id="_idIndexMarker180"/><span class="koboSpan" id="kobo.126.1">estimates for the predicted classes. </span><span class="koboSpan" id="kobo.126.2">Probability estimates reflect the model’s confidence in its predictions and can be interpreted as the likelihood of a particular class being correct. </span><span class="koboSpan" id="kobo.126.3">In many real-world applications, such as medical diagnosis, risk assessment, or fraud detection, having well-calibrated probability estimates is crucial for making informed decisions and assessing the level of uncertainty associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">the predictions.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.128.1">Reliable risk assessment</span></strong><span class="koboSpan" id="kobo.129.1">: In many domains, accurate risk assessment is paramount. </span><span class="koboSpan" id="kobo.129.2">Calibrated classifiers provide well-calibrated probability estimates that reflect the true likelihood of events. </span><span class="koboSpan" id="kobo.129.3">This allows for more accurate and reliable risk assessment, enabling</span><a id="_idIndexMarker181"/><span class="koboSpan" id="kobo.130.1"> decision-makers to allocate resources, prioritize actions, or estimate the impact of certain events more effectively. </span><span class="koboSpan" id="kobo.130.2">For instance, in credit scoring, a calibrated classifier can provide accurate estimates of the probability of default, aiding in better </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">risk management.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.132.1">Decision threshold determination</span></strong><span class="koboSpan" id="kobo.133.1">: In classification tasks, decisions are often made by setting a threshold on the predicted probabilities. </span><span class="koboSpan" id="kobo.133.2">This threshold determines the trade-off between precision and recall, or equivalently, between false positives and false negatives. </span><span class="koboSpan" id="kobo.133.3">Calibrated classifiers help in selecting an appropriate decision threshold by aligning the probability estimates with the desired trade-off, considering the specific costs or consequences associated with different types of errors. </span><span class="koboSpan" id="kobo.133.4">This ensures that decision-making aligns with the objectives and requirements of </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">the application.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.135.1">Interpretability and trust</span></strong><span class="koboSpan" id="kobo.136.1">: Calibration enhances the interpretability of the model’s predictions. </span><span class="koboSpan" id="kobo.136.2">Calibrated probability estimates can be used to understand the level of confidence the model has in its predictions. </span><span class="koboSpan" id="kobo.136.3">This transparency helps in building trust with users, stakeholders, and regulatory authorities, particularly in domains where decision-making is critical and must be justified. </span><span class="koboSpan" id="kobo.136.4">By providing well-calibrated probability estimates, the model’s predictions can be better understood and validated, instilling confidence in </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">its reliability.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.138.1">Improved fairness</span></strong><span class="koboSpan" id="kobo.139.1">: Calibrated classifiers can contribute to fairness in decision-making processes. </span><span class="koboSpan" id="kobo.139.2">By providing well-calibrated probability estimates, they can help in identifying and mitigating biases that may arise from the underlying training data or model assumptions. </span><span class="koboSpan" id="kobo.139.3">This allows for fairer and more equitable predictions, ensuring that different groups are treated consistently and without </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">undue bias.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.141.1">It is essential to evaluate model calibration to ensure that the model’s predictions align with the underlying uncertainties in the data. </span><span class="koboSpan" id="kobo.141.2">This evaluation helps in making informed decisions, understanding the model’s limitations, and managing the risks associated with misclassifications or incorrect </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">probability estimates.</span></span></p>
<p><span class="koboSpan" id="kobo.143.1">Traditionally, many classifiers, such as logistic regression or support vector machines, generate probability estimates based on their internal models. </span><span class="koboSpan" id="kobo.143.2">However, these probability estimates are</span><a id="_idIndexMarker182"/><span class="koboSpan" id="kobo.144.1"> not always accurate or well calibrated, leading to overconfidence or under confidence in the predictions. </span><span class="koboSpan" id="kobo.144.2">For instance, a classifier may assign probabilities close to </span><strong class="source-inline"><span class="koboSpan" id="kobo.145.1">1.0</span></strong><span class="koboSpan" id="kobo.146.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.147.1">0.0</span></strong><span class="koboSpan" id="kobo.148.1"> to certain examples when it should have assigned probabilities closer to </span><strong class="source-inline"><span class="koboSpan" id="kobo.149.1">0.7</span></strong><span class="koboSpan" id="kobo.150.1"> or </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.151.1">0.3</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">, respectively.</span></span></p>
<p><span class="koboSpan" id="kobo.153.1">To address this issue, various techniques have been proposed to calibrate classifiers and improve the reliability of their probability estimates. </span><span class="koboSpan" id="kobo.153.2">These techniques aim to map the original probability scores to more accurate and calibrated probabilities. </span><span class="koboSpan" id="kobo.153.3">The goal is to ensure that, on average, the predicted probabilities match the observed frequencies or likelihoods of the </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">predicted events.</span></span></p>
<h1 id="_idParaDest-64"><a id="_idTextAnchor062"/><span class="koboSpan" id="kobo.155.1">Evaluating calibration performance</span></h1>
<p><span class="koboSpan" id="kobo.156.1">Evaluating the calibration performance of a classifier is crucial to assessing the reliability and accuracy of its probability estimates. </span><span class="koboSpan" id="kobo.156.2">Calibration evaluation allows us to determine how well the predicted probabilities align with the true probabilities or likelihoods of the predicted events. </span><span class="koboSpan" id="kobo.156.3">Here are</span><a id="_idIndexMarker183"/><span class="koboSpan" id="kobo.157.1"> some commonly used techniques for evaluating the calibration performance </span><span class="No-Break"><span class="koboSpan" id="kobo.158.1">of classifiers:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.159.1">Calibration plot</span></strong><span class="koboSpan" id="kobo.160.1">:  A calibration plot visually</span><a id="_idIndexMarker184"/><span class="koboSpan" id="kobo.161.1"> assesses how well a classifier’s predicted probabilities</span><a id="_idIndexMarker185"/><span class="koboSpan" id="kobo.162.1"> match the true class frequencies. </span><span class="koboSpan" id="kobo.162.2">The </span><em class="italic"><span class="koboSpan" id="kobo.163.1">x</span></em><span class="koboSpan" id="kobo.164.1"> axis shows the predicted probabilities for each class, while the </span><em class="italic"><span class="koboSpan" id="kobo.165.1">y</span></em><span class="koboSpan" id="kobo.166.1"> axis shows the empirically observed frequencies for </span><span class="No-Break"><span class="koboSpan" id="kobo.167.1">those predictions.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.168.1">For a well-calibrated model, the calibration curve should closely match the diagonal, representing a 1:1 relationship between predicted and actual probabilities. </span><span class="koboSpan" id="kobo.168.2">Deviations from the diagonal indicate miscalibration, where the predictions are inconsistent with </span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">empirical evidence.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.170.1">Calibration plots provide an intuitive way to identify if a classifier is over confident or under confident in its estimates across different probability ranges. </span><span class="koboSpan" id="kobo.170.2">The closer the curve</span><a id="_idIndexMarker186"/><span class="koboSpan" id="kobo.171.1"> aligns with the diagonal, the better calibrated the predicted probabilities are. </span><span class="koboSpan" id="kobo.171.2">Significant</span><a id="_idIndexMarker187"/><span class="koboSpan" id="kobo.172.1"> deviations signal that recalibration is needed for the model’s outputs to </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">be reliable:</span></span></p></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer025">
<span class="koboSpan" id="kobo.174.1"><img alt="Figure 6.1 – Calibration plot" src="image/B19925_06_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.175.1">Figure 6.1 – Calibration plot</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.176.1">Calibration error</span></strong><span class="koboSpan" id="kobo.177.1">: Calibration error </span><a id="_idIndexMarker188"/><span class="koboSpan" id="kobo.178.1">measures the average difference between the predicted probabilities and the </span><a id="_idIndexMarker189"/><span class="koboSpan" id="kobo.179.1">actual probabilities of the forecasted events. </span><span class="koboSpan" id="kobo.179.2">It’s determined by the mean absolute deviation between the estimated probabilities and the observed probabilities. </span><span class="koboSpan" id="kobo.179.3">Lower calibration error values indicate better </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">calibration performance.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.181.1">Calibration metrics</span></strong><span class="koboSpan" id="kobo.182.1">: Several metrics can be used to evaluate the calibration performance of a classifier. </span><span class="koboSpan" id="kobo.182.2">Commonly </span><a id="_idIndexMarker190"/><span class="koboSpan" id="kobo.183.1">used metrics</span><a id="_idIndexMarker191"/><span class="koboSpan" id="kobo.184.1"> include the </span><strong class="bold"><span class="koboSpan" id="kobo.185.1">expected calibration error</span></strong><span class="koboSpan" id="kobo.186.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.187.1">ECE</span></strong><span class="koboSpan" id="kobo.188.1">), log loss, and the Brier score. </span><span class="koboSpan" id="kobo.188.2">ECE measures the calibration</span><a id="_idIndexMarker192"/><span class="koboSpan" id="kobo.189.1"> error by partitioning the predicted probabilities into bins and calculating the difference between the average predicted probabilities and the average empirical probabilities within each bin. </span><span class="koboSpan" id="kobo.189.2">The Brier score assesses the overall accuracy of the predicted probabilities, considering both calibration and resolution (sharpness) of the probability estimates. </span><span class="koboSpan" id="kobo.189.3">The Brier score is a commonly used scoring rule for assessing the calibration of probabilistic forecasts. </span><span class="koboSpan" id="kobo.189.4">It measures the mean squared difference between the predicted probabilities and the </span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">actual outcomes.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.191.1">For a set of </span><em class="italic"><span class="koboSpan" id="kobo.192.1">N</span></em><span class="koboSpan" id="kobo.193.1"> predictions, the Brier score is calculated as </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.194.1">B</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.195.1">S</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.196.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.197.1"> </span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.198.1">1</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.199.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.200.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.201.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.202.1">N</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.203.1">∑</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.204.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.205.1">t</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.206.1">=</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.207.1">1</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.208.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.209.1">N</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.210.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.211.1"> </span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.212.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.213.1">f</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.214.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.215.1">t</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.216.1">−</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.217.1">o</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.218.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.219.1">t</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.220.1">)</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.221.1"> </span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.222.1">2</span></span><span class="koboSpan" id="kobo.223.1">, where </span><em class="italic"><span class="koboSpan" id="kobo.224.1">ft,i</span></em><span class="koboSpan" id="kobo.225.1"> is the forecasted probability for an event, </span><em class="italic"><span class="koboSpan" id="kobo.226.1">i</span></em><span class="koboSpan" id="kobo.227.1">, at time </span><em class="italic"><span class="koboSpan" id="kobo.228.1">t</span></em><span class="koboSpan" id="kobo.229.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.230.1">ot,i</span></em><span class="koboSpan" id="kobo.231.1"> is the actual outcome of an event, </span><em class="italic"><span class="koboSpan" id="kobo.232.1">i,</span></em><span class="koboSpan" id="kobo.233.1"> at time </span><em class="italic"><span class="koboSpan" id="kobo.234.1">t</span></em><span class="koboSpan" id="kobo.235.1"> (0 </span><span class="No-Break"><span class="koboSpan" id="kobo.236.1">or 1).</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.237.1">Squaring the errors gives more weight to large mistakes. </span><span class="koboSpan" id="kobo.237.2">The average squared error is then taken across </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">all predictions.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.239.1">A lower Brier score indicates better calibration, with a minimum of 0 for a perfect probabilistic forecaster. </span><span class="koboSpan" id="kobo.239.2">It penalizes both inaccurate and </span><span class="No-Break"><span class="koboSpan" id="kobo.240.1">over/underconfident predictions.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.241.1">Cross-validation</span></strong><span class="koboSpan" id="kobo.242.1">: Cross-validation is a technique for estimating the calibration performance. </span><span class="koboSpan" id="kobo.242.2">It does</span><a id="_idIndexMarker193"/><span class="koboSpan" id="kobo.243.1"> this by partitioning the dataset into multiple folds and training the model on one fold </span><a id="_idIndexMarker194"/><span class="koboSpan" id="kobo.244.1">while evaluating calibration on the remaining folds. </span><span class="koboSpan" id="kobo.244.2">This helps in assessing the calibration performance across different subsets of the data and provides a more </span><span class="No-Break"><span class="koboSpan" id="kobo.245.1">robust evaluation.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.246.1">When evaluating the calibration performance, it is important to compare the results against an appropriate baseline. </span><span class="koboSpan" id="kobo.246.2">A well-calibrated classifier should outperform random or uncalibrated </span><span class="No-Break"><span class="koboSpan" id="kobo.247.1">probability </span></span><span class="No-Break"><a id="_idIndexMarker195"/></span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">estimates.</span></span></p>
<h1 id="_idParaDest-65"><a id="_idTextAnchor063"/><span class="koboSpan" id="kobo.249.1">Various approaches to classifier calibration</span></h1>
<p><span class="koboSpan" id="kobo.250.1">Before exploring how</span><a id="_idIndexMarker196"/><span class="koboSpan" id="kobo.251.1"> conformal prediction can provide calibrated probabilities, we will first discuss some common non-conformal calibration techniques and their strengths and weaknesses. </span><span class="koboSpan" id="kobo.251.2">These include histogram binning, Platt scaling, and </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">isotonic regression.</span></span></p>
<p><span class="koboSpan" id="kobo.253.1">It is important to note that the following methods are not part of the conformal prediction framework. </span><span class="koboSpan" id="kobo.253.2">We are covering them to build intuition about calibration and highlight some of the challenges with conventional calibration approaches. </span><span class="koboSpan" id="kobo.253.3">This background will motivate the need for and benefits of the conformal prediction perspective so that we can obtain reliable </span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">probability estimates.</span></span></p>
<p><span class="koboSpan" id="kobo.255.1">The calibration techniques we will explore, including histogram binning, Platt scaling, and isotonic regression, represent widely used approaches for adjusting classifier confidence values. </span><span class="koboSpan" id="kobo.255.2">However, as we will discuss, they have certain limitations regarding model flexibility, computational expense, </span><span class="No-Break"><span class="koboSpan" id="kobo.256.1">and generalization.</span></span></p>
<p><span class="koboSpan" id="kobo.257.1">By first understanding these existing calibration methods and their drawbacks, we will be equipped to better comprehend the value of conformal prediction’s inherent calibration properties. </span><span class="koboSpan" id="kobo.257.2">This background provides context into the calibration problem before presenting conformal prediction as an attractive </span><span class="No-Break"><span class="koboSpan" id="kobo.258.1">modern solution.</span></span></p>
<h2 id="_idParaDest-66"><a id="_idTextAnchor064"/><span class="koboSpan" id="kobo.259.1">Histogram binning</span></h2>
<p><span class="koboSpan" id="kobo.260.1">Histogram binning is a technique that’s </span><a id="_idIndexMarker197"/><span class="koboSpan" id="kobo.261.1">commonly used in classifier </span><a id="_idIndexMarker198"/><span class="koboSpan" id="kobo.262.1">calibration to improve the calibration performance of probability estimates. </span><span class="koboSpan" id="kobo.262.2">It involves dividing the predicted probabilities into bins or intervals and mapping them to more accurate and reliable probabilities based on the empirical frequencies or observed proportions of the predicted events within each bin. </span><span class="koboSpan" id="kobo.262.3">The goal of histogram binning is to align the predicted probabilities with the true probabilities of the events, resulting in a </span><span class="No-Break"><span class="koboSpan" id="kobo.263.1">better-calibrated classifier.</span></span></p>
<p><span class="koboSpan" id="kobo.264.1">The process of histogram binning can be summarized </span><span class="No-Break"><span class="koboSpan" id="kobo.265.1">as follows:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.266.1">Partitioning</span></strong><span class="koboSpan" id="kobo.267.1">: The predicted probabilities are divided into a predefined number of bins or intervals. </span><span class="koboSpan" id="kobo.267.2">The </span><a id="_idIndexMarker199"/><span class="koboSpan" id="kobo.268.1">number of bins can vary based on the dataset and the desired granularity </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">of calibration.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.270.1">Bin assignment</span></strong><span class="koboSpan" id="kobo.271.1">: Each instance in the dataset is assigned to the corresponding bin based on its predicted probability. </span><span class="koboSpan" id="kobo.271.2">For example, if we have five bins with equal width intervals (for example, </span><em class="italic"><span class="koboSpan" id="kobo.272.1">0-0.2</span></em><span class="koboSpan" id="kobo.273.1">, </span><em class="italic"><span class="koboSpan" id="kobo.274.1">0.2-0.4</span></em><span class="koboSpan" id="kobo.275.1">, </span><em class="italic"><span class="koboSpan" id="kobo.276.1">0.4-0.6</span></em><span class="koboSpan" id="kobo.277.1">, </span><em class="italic"><span class="koboSpan" id="kobo.278.1">0.6-0.8</span></em><span class="koboSpan" id="kobo.279.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.280.1">0.8-1.0</span></em><span class="koboSpan" id="kobo.281.1">), an instance with a predicted probability of 0.45 would be assigned to the </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">third bin.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.283.1">Calibration mapping</span></strong><span class="koboSpan" id="kobo.284.1">: Within each bin, the empirical proportion or frequency of the true events (positives) is calculated. </span><span class="koboSpan" id="kobo.284.2">This can be obtained by computing the ratio of the number of positive</span><a id="_idIndexMarker200"/><span class="koboSpan" id="kobo.285.1"> instances to the total number of instances within the bin. </span><span class="koboSpan" id="kobo.285.2">For instance, if the third bin contains 100 instances, and 70 of them are true positives, the empirical proportion of positives within that bin would </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">be </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.287.1">0.7</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.289.1">Mapping to calibrated probabilities</span></strong><span class="koboSpan" id="kobo.290.1">: The predicted probabilities within each bin are then mapped or adjusted to more accurate and calibrated probabilities based on the empirical proportions of positives. </span><span class="koboSpan" id="kobo.290.2">This mapping can be performed using various techniques, such as isotonic regression or </span><span class="No-Break"><span class="koboSpan" id="kobo.291.1">Platt scaling.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.292.1">Overall calibration</span></strong><span class="koboSpan" id="kobo.293.1">: Once the mapping has been applied to all the bins, the calibrated probabilities are obtained by combining the probabilities from all the bins. </span><span class="koboSpan" id="kobo.293.2">The result is a set of calibrated probabilities that better align with the true probabilities or likelihoods of </span><span class="No-Break"><span class="koboSpan" id="kobo.294.1">the events.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.295.1">Here are some potential disadvantages of using histogram binning for </span><span class="No-Break"><span class="koboSpan" id="kobo.296.1">classifier calibration:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.297.1">Inflexibility</span></strong><span class="koboSpan" id="kobo.298.1">: Histogram binning divides</span><a id="_idIndexMarker201"/><span class="koboSpan" id="kobo.299.1"> the prediction space into fixed intervals. </span><span class="koboSpan" id="kobo.299.2">It lacks the flexibility to model complex, nonlinear </span><span class="No-Break"><span class="koboSpan" id="kobo.300.1">miscalibration patterns.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.301.1">Data underutilization</span></strong><span class="koboSpan" id="kobo.302.1">: Hard binning discards information within each bin. </span><span class="koboSpan" id="kobo.302.2">The calibration mapping uses only the bin averages rather than the </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">full distribution.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.304.1">Sensitivity to the binning scheme</span></strong><span class="koboSpan" id="kobo.305.1">: The calibration quality is dependent on the specific binning thresholds chosen, which can be arbitrary. </span><span class="koboSpan" id="kobo.305.2">Optimal binning is often not </span><span class="No-Break"><span class="koboSpan" id="kobo.306.1">known beforehand.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.307.1">Discontinuities</span></strong><span class="koboSpan" id="kobo.308.1">: Adjacent bins may have very different adjustments, leading to abrupt discontinuities in the calibration mapping. </span><span class="koboSpan" id="kobo.308.2">This can </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">introduce artifacts.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.310.1">Difficulty extrapolating</span></strong><span class="koboSpan" id="kobo.311.1">: The binning calibration is based only on the training data distribution. </span><span class="koboSpan" id="kobo.311.2">It may not</span><a id="_idIndexMarker202"/><span class="koboSpan" id="kobo.312.1"> extrapolate well to unseen data with sparse or </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">no coverage.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.314.1">Curse of dimensionality</span></strong><span class="koboSpan" id="kobo.315.1">: Histograms do not scale well to high-dimensional feature spaces. </span><span class="koboSpan" id="kobo.315.2">The data becomes too sparse within </span><span class="No-Break"><span class="koboSpan" id="kobo.316.1">each bin.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.317.1">Limited model expressiveness</span></strong><span class="koboSpan" id="kobo.318.1">: Histograms can only represent simple, low-order calibration relationships. </span><span class="koboSpan" id="kobo.318.2">They cannot model complex </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">miscalibration patterns.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.320.1">Histogram binning can be simple to implement but provides an inflexible, discontinuous calibration mapping. </span><span class="koboSpan" id="kobo.320.2">More sophisticated dense modeling and smoothing are often required for optimal </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">calibration quality.</span></span></p>
<h2 id="_idParaDest-67"><a id="_idTextAnchor065"/><span class="koboSpan" id="kobo.322.1">Platt scaling</span></h2>
<p><span class="koboSpan" id="kobo.323.1">Platt scaling, sometimes</span><a id="_idIndexMarker203"/><span class="koboSpan" id="kobo.324.1"> referred to as Platt’s method or sigmoid </span><a id="_idIndexMarker204"/><span class="koboSpan" id="kobo.325.1">calibration, is a post-processing approach that’s employed to refine the output probabilities of a binary classification model. </span><span class="koboSpan" id="kobo.325.2">It was introduced by John C. </span><span class="koboSpan" id="kobo.325.3">Platt in 1999 to transform the raw output scores of a support vector machines classifier into </span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">well-calibrated probabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.327.1">The goal of Platt scaling is to adjust the predicted scores or logits produced by the classifier in such a way that they reflect more accurate estimates of the true probabilities. </span><span class="koboSpan" id="kobo.327.2">This is achieved by fitting a logistic regression model on the classifier’s scores while using a labeled validation set or a holdout set. </span><span class="koboSpan" id="kobo.327.3">The logistic regression model is trained to map the original scores to </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">calibrated probabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.329.1">The steps involved in Platt </span><a id="_idIndexMarker205"/><span class="koboSpan" id="kobo.330.1">scaling are </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">as follows:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.332.1">Collect a labeled validation set or a holdout set that is distinct from the training data used to train </span><span class="No-Break"><span class="koboSpan" id="kobo.333.1">the classifier.</span></span></li>
<li><span class="koboSpan" id="kobo.334.1">Use the classifier to generate the raw output scores or logits for the instances in the </span><span class="No-Break"><span class="koboSpan" id="kobo.335.1">validation set.</span></span></li>
<li><span class="koboSpan" id="kobo.336.1">Fit a logistic regression model on the validation set, treating the raw scores as the independent variable and the true class labels as the </span><span class="No-Break"><span class="koboSpan" id="kobo.337.1">dependent variable.</span></span></li>
<li><span class="koboSpan" id="kobo.338.1">Train the logistic regression model using standard techniques such as maximum likelihood estimation or gradient descent to estimate the </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">model’s parameters.</span></span></li>
<li><span class="koboSpan" id="kobo.340.1">Once the logistic</span><a id="_idIndexMarker206"/><span class="koboSpan" id="kobo.341.1"> regression model has been trained, it can be used as a calibration function. </span><span class="koboSpan" id="kobo.341.2">Given a new instance, the raw score produced by the classifier is input into the logistic regression model, which transforms it into a calibrated </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">probability estimate.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.343.1">The logistic regression model essentially learns the transformation from the raw scores to calibrated probabilities by estimating the intercept and slope parameters. </span><span class="koboSpan" id="kobo.343.2">This transformation is represented by the sigmoid function, which maps the scores to probabilities between </span><strong class="source-inline"><span class="koboSpan" id="kobo.344.1">0</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.345.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.346.1">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.348.1">Platt scaling aims to achieve better calibration by adjusting the predicted probabilities to match the true probabilities or likelihoods of </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">the events.</span></span></p>
<p><span class="koboSpan" id="kobo.350.1">It’s important to note that Platt scaling assumes that the relationship between the raw scores and the true probabilities can be modeled by a logistic function. </span><span class="koboSpan" id="kobo.350.2">If the underlying relationship is more complex, other calibration methods such as conformal prediction may be </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">more suitable.</span></span></p>
<p><span class="koboSpan" id="kobo.352.1">While Platt scaling can be an effective technique for calibrating classifier probabilities, it is important to be aware of its limitations and </span><span class="No-Break"><span class="koboSpan" id="kobo.353.1">potential disadvantages:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.354.1">Requirement for a separate validation set</span></strong><span class="koboSpan" id="kobo.355.1">: Platt scaling requires a labeled validation set or holdout</span><a id="_idIndexMarker207"/><span class="koboSpan" id="kobo.356.1"> set that is distinct from the training data. </span><span class="koboSpan" id="kobo.356.2">This means additional data may be needed for calibration, which can be a limitation in situations where obtaining labeled data is challenging </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">or costly.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.358.1">Assumption of a logistic relationship</span></strong><span class="koboSpan" id="kobo.359.1">: Platt scaling assumes that the relationship between the raw scores and the true probabilities can be accurately modeled by a logistic function. </span><span class="koboSpan" id="kobo.359.2">If the underlying relationship is more complex or different, the logistic</span><a id="_idIndexMarker208"/><span class="koboSpan" id="kobo.360.1"> regression model may not be able to capture the true calibration </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">mapping adequately.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.362.1">Sensitivity to extreme scores</span></strong><span class="koboSpan" id="kobo.363.1">: Platt scaling can be sensitive to extreme scores or outliers in the validation set. </span><span class="koboSpan" id="kobo.363.2">Outliers may disproportionately influence the calibration function, leading to potential overfitting or a </span><span class="No-Break"><span class="koboSpan" id="kobo.364.1">suboptimal calibration.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.365.1">Lack of flexibility for different calibration shapes</span></strong><span class="koboSpan" id="kobo.366.1">: The logistic regression model used in Platt scaling is constrained to fit a sigmoid function, which may not be suitable for all calibration shapes. </span><span class="koboSpan" id="kobo.366.2">If the desired calibration shape deviates significantly from a sigmoid curve, Platt scaling may not achieve </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">optimal calibration.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.368.1">Limited applicability to multiclass problems</span></strong><span class="koboSpan" id="kobo.369.1">: Platt scaling is primarily designed for binary classification problems. </span><span class="koboSpan" id="kobo.369.2">Extending it to multiclass classification can be challenging as it requires adapting the calibration mapping to handle multiple classes and their </span><span class="No-Break"><span class="koboSpan" id="kobo.370.1">respective probabilities.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.371.1">Potential overconfidence in extreme probabilities</span></strong><span class="koboSpan" id="kobo.372.1">: Platt scaling may introduce overconfidence in extreme predicted probabilities. </span><span class="koboSpan" id="kobo.372.2">The calibrated probabilities near the boundaries (close to 0 or 1) might be more extreme than they should be, leading to overconfident predictions in </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">those regions.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.374.1">Dependence on the quality of the validation set</span></strong><span class="koboSpan" id="kobo.375.1">: The effectiveness of Platt scaling is dependent on the quality and representativeness of the labeled validation set. </span><span class="koboSpan" id="kobo.375.2">If the</span><a id="_idIndexMarker209"/><span class="koboSpan" id="kobo.376.1"> validation set does not accurately capture the true distribution of the target variable, the resulting calibration may </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">be suboptimal.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.378.1">It’s important to consider these disadvantages and assess whether Platt scaling is suitable for a specific application or if alternative calibration methods, such as methods based on conformal prediction, may be more appropriate based on the specific characteristics of the problem </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">and dataset.</span></span></p>
<h2 id="_idParaDest-68"><a id="_idTextAnchor066"/><span class="koboSpan" id="kobo.380.1">Isotonic regression</span></h2>
<p><span class="koboSpan" id="kobo.381.1">Isotonic regression is a</span><a id="_idIndexMarker210"/><span class="koboSpan" id="kobo.382.1"> non-parametric regression technique that’s used for calibration and monotonicity modeling. </span><span class="koboSpan" id="kobo.382.2">It is commonly applied to adjust the output scores or predicted probabilities of a classifier to improve their calibration. </span><span class="koboSpan" id="kobo.382.3">Isotonic</span><a id="_idIndexMarker211"/><span class="koboSpan" id="kobo.383.1"> regression seeks to find a monotonic function that maps the original scores to calibrated probabilities while preserving the ordering of </span><span class="No-Break"><span class="koboSpan" id="kobo.384.1">the scores.</span></span></p>
<p><span class="koboSpan" id="kobo.385.1">The primary goal of isotonic regression is to determine a non-decreasing function that reduces the sum of squared discrepancies between the predicted probabilities and the target probabilities or actual occurrences. </span><span class="koboSpan" id="kobo.385.2">By fitting a piecewise linear or piecewise constant function to the data, isotonic regression ensures that the predicted probabilities are monotonically increasing </span><span class="No-Break"><span class="koboSpan" id="kobo.386.1">or non-decreasing.</span></span></p>
<p><span class="koboSpan" id="kobo.387.1">The steps involved in isotonic regression are </span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">as follows:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.389.1">Collect a labeled </span><a id="_idIndexMarker212"/><span class="koboSpan" id="kobo.390.1">validation set or a holdout set that is separate from the </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1">training data.</span></span></li>
<li><span class="koboSpan" id="kobo.392.1">Use the classifier to generate the raw output scores or probabilities for the instances in the </span><span class="No-Break"><span class="koboSpan" id="kobo.393.1">validation set.</span></span></li>
<li><span class="koboSpan" id="kobo.394.1">Sort the instances in the validation set based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">raw scores.</span></span></li>
<li><span class="koboSpan" id="kobo.396.1">Initialize the isotonic regression function as the identity function, where the initial predicted probabilities are equal to the </span><span class="No-Break"><span class="koboSpan" id="kobo.397.1">raw scores.</span></span></li>
<li><span class="koboSpan" id="kobo.398.1">Iteratively update the isotonic regression function by adjusting the predicted probabilities to minimize the squared differences between the predicted probabilities and the target probabilities. </span><span class="koboSpan" id="kobo.398.2">This adjustment is subject to the constraint of </span><a id="_idIndexMarker213"/><span class="No-Break"><span class="koboSpan" id="kobo.399.1">non-decreasing probabilities.</span></span></li>
<li><span class="koboSpan" id="kobo.400.1">Repeat the updating process until convergence or a stopping criterion </span><span class="No-Break"><span class="koboSpan" id="kobo.401.1">is reached:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer026">
<span class="koboSpan" id="kobo.402.1"><img alt="Figure 6.2 – Isotonic regression" src="image/B19925_06_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.403.1">Figure 6.2 – Isotonic regression</span></p>
<p><span class="koboSpan" id="kobo.404.1">Once the isotonic regression model has been trained, it can be used to map the raw scores of new instances to calibrated probabilities. </span><span class="koboSpan" id="kobo.404.2">The model ensures that the predicted probabilities are monotonically increasing and better aligned with the true probabilities or likelihoods of </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">the events.</span></span></p>
<p><span class="koboSpan" id="kobo.406.1">While isotonic</span><a id="_idIndexMarker214"/><span class="koboSpan" id="kobo.407.1"> regression is a valuable technique for calibrating classifier</span><a id="_idIndexMarker215"/><span class="koboSpan" id="kobo.408.1"> probabilities, it is important to consider its limitations and </span><span class="No-Break"><span class="koboSpan" id="kobo.409.1">potential disadvantages:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.410.1">Potential overfitting</span></strong><span class="koboSpan" id="kobo.411.1">: Isotonic regression can suffer from overfitting if the calibration function is overly complex or if the calibration dataset is small. </span><span class="koboSpan" id="kobo.411.2">Regularization techniques, such as using a limited number of segments in the piecewise linear function, can help </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1">prevent overfitting.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.413.1">Complexity and computational cost</span></strong><span class="koboSpan" id="kobo.414.1">: Isotonic regression can be resource-intensive, especially with vast datasets or when navigating high-dimensional features. </span><span class="koboSpan" id="kobo.414.2">As the number of data points and unique scores or probabilities grow, so does the complexity of isotonic regression. </span><span class="koboSpan" id="kobo.414.3">It’s crucial to weigh up the computational limitations when using isotonic regression for </span><span class="No-Break"><span class="koboSpan" id="kobo.415.1">extensive tasks.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.416.1">Sensitivity to outliers</span></strong><span class="koboSpan" id="kobo.417.1">: Isotonic regression can be sensitive to outliers in the data. </span><span class="koboSpan" id="kobo.417.2">Outliers may have a</span><a id="_idIndexMarker216"/><span class="koboSpan" id="kobo.418.1"> significant impact on the estimated calibration function, potentially leading to</span><a id="_idIndexMarker217"/><span class="koboSpan" id="kobo.419.1"> suboptimal calibration. </span><span class="koboSpan" id="kobo.419.2">Careful data preprocessing or outlier detection techniques may be necessary to mitigate </span><span class="No-Break"><span class="koboSpan" id="kobo.420.1">this issue.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.421.1">Limited flexibility for complex calibration shapes</span></strong><span class="koboSpan" id="kobo.422.1">: Isotonic regression assumes a monotonic relationship between the scores and the probabilities, which constrains the calibration function to be piecewise constant or piecewise linear. </span><span class="koboSpan" id="kobo.422.2">This limits the model’s flexibility to capture more complex or nonlinear calibration shapes. </span><span class="koboSpan" id="kobo.422.3">If the desired calibration shape deviates significantly from monotonicity, isotonic regression may not provide an </span><span class="No-Break"><span class="koboSpan" id="kobo.423.1">optimal fit.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.424.1">Need for sufficient data</span></strong><span class="koboSpan" id="kobo.425.1">: Isotonic regression requires a sufficient amount of labeled data to estimate the calibration function accurately. </span><span class="koboSpan" id="kobo.425.2">If the calibration dataset is small or imbalanced, the estimation may be suboptimal. </span><span class="koboSpan" id="kobo.425.3">Ensuring a representative and adequately sized calibration dataset is important for reliable </span><span class="No-Break"><span class="koboSpan" id="kobo.426.1">calibration results.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.427.1">Difficulty in handling multiclass problems</span></strong><span class="koboSpan" id="kobo.428.1">: Isotonic regression is inherently designed for binary classification problems, so extending it to multiclass problems is not straightforward. </span><span class="koboSpan" id="kobo.428.2">Adapting isotonic regression to handle multiple classes and their respective probabilities requires careful consideration and modification of </span><span class="No-Break"><span class="koboSpan" id="kobo.429.1">the algorithm.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.430.1">Lack of probabilistic interpretation</span></strong><span class="koboSpan" id="kobo.431.1">: Unlike Platt scaling, which explicitly models probabilities using logistic regression, isotonic regression does not provide a probabilistic interpretation of the calibrated scores. </span><span class="koboSpan" id="kobo.431.2">It focuses solely on ensuring monotonicity and may not directly estimate </span><span class="No-Break"><span class="koboSpan" id="kobo.432.1">well-calibrated probabilities.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.433.1">It is important to evaluate these limitations and consider the characteristics of the problem at hand when </span><a id="_idIndexMarker218"/><span class="koboSpan" id="kobo.434.1">deciding whether</span><a id="_idIndexMarker219"/><span class="koboSpan" id="kobo.435.1"> isotonic regression is the most appropriate </span><span class="No-Break"><span class="koboSpan" id="kobo.436.1">calibration method.</span></span></p>
<p><span class="koboSpan" id="kobo.437.1">Comparing the advantages and disadvantages of different calibration techniques, such as conformal prediction and Platt scaling, can help determine the best approach for achieving well-calibrated probabilities in a </span><span class="No-Break"><span class="koboSpan" id="kobo.438.1">specific application.</span></span></p>
<h1 id="_idParaDest-69"><a id="_idTextAnchor067"/><span class="koboSpan" id="kobo.439.1">Conformal prediction for classifier calibration</span></h1>
<p><span class="koboSpan" id="kobo.440.1">Conformal prediction is </span><a id="_idIndexMarker220"/><span class="koboSpan" id="kobo.441.1">a powerful framework for probabilistic prediction that provides valid and well-calibrated prediction sets and prediction intervals. </span><span class="koboSpan" id="kobo.441.2">It </span><a id="_idIndexMarker221"/><span class="koboSpan" id="kobo.442.1">offers a principled approach to quantify and control the uncertainty associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.443.1">the predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.444.1">We have already seen how conformal prediction approaches, such as </span><strong class="bold"><span class="koboSpan" id="kobo.445.1">inductive conformal prediction</span></strong><span class="koboSpan" id="kobo.446.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.447.1">ICP</span></strong><span class="koboSpan" id="kobo.448.1">) and </span><strong class="bold"><span class="koboSpan" id="kobo.449.1">transductive conformal prediction</span></strong><span class="koboSpan" id="kobo.450.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.451.1">TCP</span></strong><span class="koboSpan" id="kobo.452.1">), aim to generate sets that have</span><a id="_idIndexMarker222"/><span class="koboSpan" id="kobo.453.1"> accurate coverage probabilities. </span><span class="koboSpan" id="kobo.453.2">To recap, conformal </span><a id="_idIndexMarker223"/><span class="koboSpan" id="kobo.454.1">prediction computes p-values and constructs prediction sets by comparing the p-values of each potential label with a selected </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">significance level.</span></span></p>
<p><span class="koboSpan" id="kobo.456.1">Unlike Platt scaling, histogram binning, and isotonic regression, which focus on calibrating the predicted probabilities or scores, conformal prediction takes a more comprehensive approach by providing prediction sets that encompass the uncertainty associated with the predictions and enhances the reliability and interpretability of predictions by providing valid measures of confidence </span><span class="No-Break"><span class="koboSpan" id="kobo.457.1">or significance.</span></span></p>
<h2 id="_idParaDest-70"><a id="_idTextAnchor068"/><span class="koboSpan" id="kobo.458.1">Venn-ABERS conformal prediction</span></h2>
<p><span class="koboSpan" id="kobo.459.1">Classical methods such as Platt </span><a id="_idIndexMarker224"/><span class="koboSpan" id="kobo.460.1">scaling was initially developed as parametric solutions for calibrating classifiers. </span><span class="koboSpan" id="kobo.460.2">However, these methods are becoming somewhat outdated and have limitations </span><a id="_idIndexMarker225"/><span class="koboSpan" id="kobo.461.1">due to their simplistic assumptions, resulting in suboptimal calibration </span><span class="No-Break"><span class="koboSpan" id="kobo.462.1">of probabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.463.1">Platt scaling assumes a logistic relationship between scores and probabilities, which may not adequately capture the actual calibration shape in practical scenarios. </span><span class="koboSpan" id="kobo.463.2">It is worth noting that Platt’s original paper in 1999 did not explicitly discuss the underlying assumptions of this approach. </span><span class="koboSpan" id="kobo.463.3">However, recent research (see </span><em class="italic"><span class="koboSpan" id="kobo.464.1">Beta calibration: a well-founded and easily implemented improvement on logistic calibration for binary classifiers</span></em><span class="koboSpan" id="kobo.465.1">: https://proceedings.mlr.press/v54/kull17a.html) has revealed that these assumptions are essentially equivalent to assuming both normality and homoscedasticity, which are overly restrictive assumptions for real-world datasets. </span><span class="koboSpan" id="kobo.465.2">Real datasets often exhibit more complex and diverse patterns that cannot be accurately captured by such assumptions. </span><span class="koboSpan" id="kobo.465.3">Therefore, relying solely on Platt scaling with its underlying assumptions </span><a id="_idIndexMarker226"/><span class="koboSpan" id="kobo.466.1">may result in suboptimal calibration and poorly </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">calibrated probabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.468.1">Isotonic regression, as an approach, assumes a monotonic relationship between scores and probabilities. </span><span class="koboSpan" id="kobo.468.2">However, this assumption may not capture the intricate nature of the calibration curve in all cases. </span><span class="koboSpan" id="kobo.468.3">Furthermore, isotonic regression relies on the assumption of perfect ranking (an ROC AUC of 1) on the test dataset, which is rarely achievable in real-world datasets. </span><span class="koboSpan" id="kobo.468.4">Additionally, it has been demonstrated that isotonic regression can overfit when applied to </span><span class="No-Break"><span class="koboSpan" id="kobo.469.1">smaller datasets.</span></span></p>
<p><span class="koboSpan" id="kobo.470.1">The assumption of a monotonic relationship limits the flexibility of isotonic regression to model more complex calibration curves that may exhibit non-monotonic patterns. </span><span class="koboSpan" id="kobo.470.2">Moreover, the requirement of perfect ranking on the test dataset is often unrealistic as datasets typically involve inherent noise and uncertainty. </span><span class="koboSpan" id="kobo.470.3">This assumption can lead to suboptimal calibration results </span><span class="No-Break"><span class="koboSpan" id="kobo.471.1">in practice.</span></span></p>
<p><span class="koboSpan" id="kobo.472.1">Furthermore, the issue of overfitting with isotonic regression becomes more prominent when dealing with smaller datasets. </span><span class="koboSpan" id="kobo.472.2">When the dataset’s size is limited, isotonic regression may overly adjust to the noise or specific characteristics of the training data, resulting in poor </span><span class="No-Break"><span class="koboSpan" id="kobo.473.1">generalization performance.</span></span></p>
<p><span class="koboSpan" id="kobo.474.1">Because of their simplistic assumptions, Platt scaling and isotonic regression may not achieve optimal calibration and may not deliver well-calibrated probabilities. </span><span class="koboSpan" id="kobo.474.2">These methods may struggle to capture nonlinear or more intricate calibration patterns, limiting their effectiveness in </span><span class="No-Break"><span class="koboSpan" id="kobo.475.1">certain applications.</span></span></p>
<p><span class="koboSpan" id="kobo.476.1">To address the limitations of classical calibrators, such as Platt scaling and isotonic regression, a powerful solution </span><a id="_idIndexMarker227"/><span class="koboSpan" id="kobo.477.1">called Venn-ABERS has been developed by the creator of conformal prediction, Vladimir Vovk , Ivan Petej and Valentina Fedorova”, Venn-ABERS is a conformal prediction method that offers mathematical guarantees of validity, regardless of the data distribution, dataset size, or underlying </span><span class="No-Break"><span class="koboSpan" id="kobo.478.1">classification model.</span></span></p>
<p><span class="koboSpan" id="kobo.479.1">This work is detailed in the NeurIPS paper titled </span><em class="italic"><span class="koboSpan" id="kobo.480.1">Large-scale probabilistic predictors with and without guarantees of validity</span></em><span class="koboSpan" id="kobo.481.1"> (</span><a href="https://papers.nips.cc/paper_files/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html"><span class="koboSpan" id="kobo.482.1">https://papers.nips.cc/paper_files/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html</span></a><span class="koboSpan" id="kobo.483.1">). </span><span class="koboSpan" id="kobo.483.2">For a more mathematical understanding, watch the associated presentation, </span><em class="italic"><span class="koboSpan" id="kobo.484.1">Large-Scale Probabilistic Prediction With and Without Validity Guarantees</span></em><span class="koboSpan" id="kobo.485.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.486.1">at </span></span><a href="https://www.youtube.com/watch?v=ksrUJdb2tA8"><span class="No-Break"><span class="koboSpan" id="kobo.487.1">https://www.youtube.com/watch?v=ksrUJdb2tA8</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.488.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.489.1">The name Venn-ABERS is </span><a id="_idIndexMarker228"/><span class="koboSpan" id="kobo.490.1">derived from a combination of Venn predictors, another class of conformal predictors, and the initials of the authors who contributed to a classical paper called </span><em class="italic"><span class="koboSpan" id="kobo.491.1">An Empirical Distribution Function for Sampling with Incomplete Information</span></em><span class="koboSpan" id="kobo.492.1"> (M. </span><span class="koboSpan" id="kobo.492.2">Ayer, H.D. </span><span class="koboSpan" id="kobo.492.3">Brunk, G.M. </span><span class="koboSpan" id="kobo.492.4">Ewing, W.T. </span><span class="koboSpan" id="kobo.492.5">Reid, and E. </span><span class="No-Break"><span class="koboSpan" id="kobo.493.1">Silverman: </span></span><a href="https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-26/issue-4/An-Empirical-Distribution-Function-for-Sampling-with-Incomplete-Information/10.1214/aoms/1177728423.full"><span class="No-Break"><span class="koboSpan" id="kobo.494.1">https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-26/issue-4/An-Empirical-Distribution-Function-for-Sampling-with-Incomplete-Information/10.1214/aoms/1177728423.full</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.495.1">)</span></span><span class="No-Break"><span class="koboSpan" id="kobo.496.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.497.1">So, how do Venn-ABERS predictors work? </span><span class="koboSpan" id="kobo.497.2">Rather than constructing isotonic regression once, Venn-ABERS fits isotonic regression twice by assuming that each test object can have both label 0 and label 1. </span><span class="koboSpan" id="kobo.497.3">This means that each test object is added to the calibration set twice, once with label 0 and once with label 1. </span><span class="koboSpan" id="kobo.497.4">Two separate isotonic regressions are then fitted, resulting in two probabilities, </span><em class="italic"><span class="koboSpan" id="kobo.498.1">p0</span></em><span class="koboSpan" id="kobo.499.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.500.1">p1</span></em><span class="koboSpan" id="kobo.501.1">, for each </span><span class="No-Break"><span class="koboSpan" id="kobo.502.1">test object.</span></span></p>
<p><span class="koboSpan" id="kobo.503.1">It is important to note that both </span><em class="italic"><span class="koboSpan" id="kobo.504.1">p0</span></em><span class="koboSpan" id="kobo.505.1"> (lower bound) and </span><em class="italic"><span class="koboSpan" id="kobo.506.1">p1</span></em><span class="koboSpan" id="kobo.507.1"> (upper bound) represent probabilities of the object belonging to class 1. </span><span class="koboSpan" id="kobo.507.2">These probabilities create a prediction interval for the probability of class 1, with mathematical guarantees that the actual probability falls within </span><span class="No-Break"><span class="koboSpan" id="kobo.508.1">this interval.</span></span></p>
<p><span class="koboSpan" id="kobo.509.1">Consequently, Venn-ABERS solves the problem beautifully, without requiring assumptions about score distributions such as Platt scaling and without suffering </span><span class="No-Break"><span class="koboSpan" id="kobo.510.1">from overfitting.</span></span></p>
<p><span class="koboSpan" id="kobo.511.1">The Venn-ABERS prediction is a multi-predictor, and the width of the interval (</span><em class="italic"><span class="koboSpan" id="kobo.512.1">p0, p1</span></em><span class="koboSpan" id="kobo.513.1">) contains valuable information about the confidence of classification. </span><span class="koboSpan" id="kobo.513.2">In larger datasets, </span><em class="italic"><span class="koboSpan" id="kobo.514.1">p0</span></em><span class="koboSpan" id="kobo.515.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.516.1">p1</span></em><span class="koboSpan" id="kobo.517.1"> are typically very close to each other. </span><span class="koboSpan" id="kobo.517.2">However, for smaller and more challenging datasets, </span><em class="italic"><span class="koboSpan" id="kobo.518.1">p0</span></em><span class="koboSpan" id="kobo.519.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.520.1">p1</span></em><span class="koboSpan" id="kobo.521.1"> may diverge, indicating that certain objects are difficult to classify due to factors such as data distribution, insufficient data, or the underlying </span><span class="No-Break"><span class="koboSpan" id="kobo.522.1">classifier’s performance.</span></span></p>
<p><span class="koboSpan" id="kobo.523.1">Importantly, in critical </span><a id="_idIndexMarker229"/><span class="koboSpan" id="kobo.524.1">situations, the Venn-ABERS predictor not only outputs accurate and well-calibrated probabilities but also issues an “alert” by widening the (</span><em class="italic"><span class="koboSpan" id="kobo.525.1">p0, p1</span></em><span class="koboSpan" id="kobo.526.1">) interval. </span><span class="koboSpan" id="kobo.526.2">This alert indicates that the decision-making process should consider the </span><span class="No-Break"><span class="koboSpan" id="kobo.527.1">increased uncertainty.</span></span></p>
<p><span class="koboSpan" id="kobo.528.1">For practical decision-making purposes, the probabilities can be combined into a single value using </span><em class="italic"><span class="koboSpan" id="kobo.529.1">p = p1 / (1 - p0 + p1)</span></em><span class="koboSpan" id="kobo.530.1">. </span><span class="koboSpan" id="kobo.530.2">This combined probability of class </span><em class="italic"><span class="koboSpan" id="kobo.531.1">1</span></em><span class="koboSpan" id="kobo.532.1">, </span><em class="italic"><span class="koboSpan" id="kobo.533.1">p</span></em><span class="koboSpan" id="kobo.534.1">, can then be utilized for decision-making tasks such</span><a id="_idIndexMarker230"/><span class="koboSpan" id="kobo.535.1"> as loan granting or determining whether to disable autopilot in autonomous car. </span><span class="koboSpan" id="kobo.535.2">With the inclusion of </span><em class="italic"><span class="koboSpan" id="kobo.536.1">p</span></em><span class="koboSpan" id="kobo.537.1">, the decision-making process can be </span><span class="No-Break"><span class="koboSpan" id="kobo.538.1">successfully concluded.</span></span></p>
<h2 id="_idParaDest-71"><a id="_idTextAnchor069"/><span class="koboSpan" id="kobo.539.1">Comparing calibration methods</span></h2>
<p><span class="koboSpan" id="kobo.540.1">Given the range of</span><a id="_idIndexMarker231"/><span class="koboSpan" id="kobo.541.1"> calibration methods, you might be wondering how they are compared to each other. </span><span class="koboSpan" id="kobo.541.2">We have already seen that classical methods such as Platt scaling and isotonic regression rely on restrictive assumptions and, unlike the conformal prediction Venn-ABERS method, do not have validity guarantees. </span><span class="koboSpan" id="kobo.541.3">An interesting question is also how the performance of different methods compares empirically across a range </span><span class="No-Break"><span class="koboSpan" id="kobo.542.1">of datasets.</span></span></p>
<p><span class="koboSpan" id="kobo.543.1">Such a study was performed, and the results were summarized in the paper </span><em class="italic"><span class="koboSpan" id="kobo.544.1">Probabilistic Prediction in scikit-learn</span></em><span class="koboSpan" id="kobo.545.1"> (</span><a href="http://www.diva-portal.org/smash/get/diva2:1603345/FULLTEXT01.pdf"><span class="koboSpan" id="kobo.546.1">http://www.diva-portal.org/smash/get/diva2:1603345/FULLTEXT01.pdf</span></a><span class="koboSpan" id="kobo.547.1">). </span><span class="koboSpan" id="kobo.547.2">In this paper, a large experimental study was conducted to investigate the calibration of scikit-learn models out of the box. </span><span class="koboSpan" id="kobo.547.3">In addition, the study looked at whether calibration techniques such as Platt scaling, isotonic regression, and Venn-ABERs can </span><span class="No-Break"><span class="koboSpan" id="kobo.548.1">improve calibration.</span></span></p>
<p><span class="koboSpan" id="kobo.549.1">The result of the study showed that of the seven algorithms evaluated (logistic regression, random forest, AdaBoost, gradient boosting, kNN, naïve Bayes, and decision tree), the only model that obtained well-calibrated predictions was logistic regression. </span><span class="koboSpan" id="kobo.549.2">Calibration enhances all models, especially decision trees, boosted trees (such as XGBoost, LightGBM, and CatBoost), and naïve Bayes. </span><span class="koboSpan" id="kobo.549.3">This underscores the clear advice for professionals: obtained relatively well-calibrated predictions was </span><span class="No-Break"><span class="koboSpan" id="kobo.550.1">logistic regression</span></span><span class="No-Break"><span class="koboSpan" id="kobo.551.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.552.1">Additionally, the study uncovered a notable finding that miscalibrated models tend to exhibit a high level of overconfidence. </span><span class="koboSpan" id="kobo.552.2">Surprisingly, even logistic regression, although to a lesser extent compared to other models, displayed systematic optimism in </span><span class="No-Break"><span class="koboSpan" id="kobo.553.1">its predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.554.1">In other words, these miscalibrated models tended to assign higher probabilities or confidence to their predictions than what was warranted by the actual outcomes. </span><span class="koboSpan" id="kobo.554.2">This overconfidence could potentially lead to misguided decision-making or misplaced trust in the reliability of </span><span class="No-Break"><span class="koboSpan" id="kobo.555.1">the predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.556.1">It is crucial to recognize that </span><a id="_idIndexMarker232"/><span class="koboSpan" id="kobo.557.1">while logistic regression demonstrated better calibration compared to other models, it still exhibited a certain level of systematic optimism. </span><span class="koboSpan" id="kobo.557.2">This highlights the importance of thoroughly evaluating and calibrating models, even those considered to be well-calibrated, to ensure accurate and reliable </span><span class="No-Break"><span class="koboSpan" id="kobo.558.1">probabilistic predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.559.1">When examining the calibration techniques in terms of their benefits for calibration, their order of effectiveness is typically observed to be Venn-ABERS, followed by Platt scaling and </span><span class="No-Break"><span class="koboSpan" id="kobo.560.1">isotonic regression.</span></span></p>
<p><span class="koboSpan" id="kobo.561.1">Venn-ABERS tends to demonstrate the most significant improvement in calibration, providing notable benefits in terms of achieving well-calibrated predictions. </span><span class="koboSpan" id="kobo.561.2">Its utilization within the conformal prediction framework allows for reliable estimation of uncertainty and enhanced </span><span class="No-Break"><span class="koboSpan" id="kobo.562.1">calibration performance.</span></span></p>
<p><span class="koboSpan" id="kobo.563.1">To summarize, the comparison of calibration techniques revealed that Venn-ABERS tends to yield the most substantial benefits, followed by Platt scaling and isotonic regression. </span><span class="koboSpan" id="kobo.563.2">It is important to select the appropriate technique based on the specific requirements of the problem at hand, considering factors such as the complexity of the calibration curve and the desired level of </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1">calibration improvement.</span></span></p>
<p><span class="koboSpan" id="kobo.565.1">The study’s findings emphasized that miscalibrated models often exhibit overconfidence, and even logistic regression, although more calibrated than other models, can display systematic optimism. </span><span class="koboSpan" id="kobo.565.2">This underlines the necessity of assessing and enhancing the calibration of models to avoid unwarranted confidence and make informed decisions based on accurate probabilistic predictions. </span><span class="koboSpan" id="kobo.565.3">The research further indicated that uncalibrated models frequently exhibit overconfidence. </span><span class="koboSpan" id="kobo.565.4">This includes logistic regression, which tends to be systematically optimistic, although to a </span><span class="No-Break"><span class="koboSpan" id="kobo.566.1">lesser extent.</span></span></p>
<h1 id="_idParaDest-72"><a id="_idTextAnchor070"/><span class="koboSpan" id="kobo.567.1">Open source tools for conformal prediction in classification problems</span></h1>
<p><span class="koboSpan" id="kobo.568.1">While deep-diving into the intricacies of conformal prediction for classification, it has become evident that the right tools can significantly enhance our implementation efficiency. </span><span class="koboSpan" id="kobo.568.2">Recognizing this, the </span><a id="_idIndexMarker233"/><span class="koboSpan" id="kobo.569.1">open source community has made remarkable contributions by providing various tools tailored for this purpose. </span><span class="koboSpan" id="kobo.569.2">In this section, we will explore some of the prominent open source tools for conformal prediction that can seamlessly integrate into your projects and elevate your </span><span class="No-Break"><span class="koboSpan" id="kobo.570.1">predictive capabilities.</span></span></p>
<h2 id="_idParaDest-73"><a id="_idTextAnchor071"/><span class="koboSpan" id="kobo.571.1">Nonconformist</span></h2>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.572.1">nonconformist</span></strong><span class="koboSpan" id="kobo.573.1"> (</span><a href="https://github.com/donlnz/nonconformist"><span class="koboSpan" id="kobo.574.1">https://github.com/donlnz/nonconformist</span></a><span class="koboSpan" id="kobo.575.1">) is a classical conformal prediction package that can be used for </span><a id="_idIndexMarker234"/><span class="koboSpan" id="kobo.576.1">conformal prediction in </span><span class="No-Break"><span class="koboSpan" id="kobo.577.1">classification problems.</span></span></p>
<p><span class="koboSpan" id="kobo.578.1">Let’s illustrate how to create an ICP using </span><strong class="source-inline"><span class="koboSpan" id="kobo.579.1">nonconformist</span></strong><span class="koboSpan" id="kobo.580.1">. </span><span class="koboSpan" id="kobo.580.2">You can find the Jupyter notebook containing the relevant code </span><span class="No-Break"><span class="koboSpan" id="kobo.581.1">at </span></span><a href="https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_06.ipynb"><span class="No-Break"><span class="koboSpan" id="kobo.582.1">https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_06.ipynb</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.583.1">:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.584.1">You can find the </span><strong class="source-inline"><span class="koboSpan" id="kobo.585.1">nonconformist</span></strong><span class="koboSpan" id="kobo.586.1"> documentation here: http://donlnz.github.io/nonconformist/index.html. </span><span class="koboSpan" id="kobo.586.2">First, we will install </span><strong class="source-inline"><span class="koboSpan" id="kobo.587.1">nonconformist</span></strong><span class="koboSpan" id="kobo.588.1"> using the standard functionality – that is, </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.589.1">pip install</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.591.1">!pip install nonconformist</span></pre></li>
<li><span class="koboSpan" id="kobo.592.1">We can import the relevant modules </span><span class="No-Break"><span class="koboSpan" id="kobo.593.1">as follows:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.594.1">from nonconformist.base import ClassifierAdapter</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.595.1">from nonconformist.cp import IcpClassifier</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.596.1">from nonconformist.nc import NcFactory</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.597.1">from nonconformist.nc import ClassifierNc,</span></pre><pre class="source-code"><strong class="source-inline"><span class="koboSpan" id="kobo.598.1">InverseProbabilityErrFunc</span></strong><span class="koboSpan" id="kobo.599.1">, and</span><strong class="source-inline"><span class="koboSpan" id="kobo.600.1">MarginErrFunc</span></strong><span class="koboSpan" id="kobo.601.1"> specify the nonconformity measure using </span><strong class="source-inline"><span class="koboSpan" id="kobo.602.1">NcFactory.create_nc</span></strong></pre><p class="list-inset"><span class="koboSpan" id="kobo.603.1">In this case, we created an ICP with a </span><a id="_idIndexMarker235"/><span class="koboSpan" id="kobo.604.1">margin nonconformity measure; we looked at this in previous chapters. </span><span class="koboSpan" id="kobo.604.2">This ICP uses logistic regression as the </span><span class="No-Break"><span class="koboSpan" id="kobo.605.1">underlying classifier:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.606.1">icp=IcpClassifier(ClassifierNc(ClassifierAdapter (LogisticRegression()), MarginErrFunc()))</span></pre></li>
<li><span class="koboSpan" id="kobo.607.1">Then, we must fit the ICP using the proper training set and calibrate it using the </span><span class="No-Break"><span class="koboSpan" id="kobo.608.1">calibration set:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.609.1">icp.fit(X_train, y_train)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.610.1">icp.calibrate(X_calib, y_calib)</span></pre></li>
<li><span class="koboSpan" id="kobo.611.1">Using the trained model, we can obtain the predicted class scores on the calibration and </span><span class="No-Break"><span class="koboSpan" id="kobo.612.1">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.613.1">y_pred_calib = model.predict(X_calib)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.614.1">y_pred_score_calib = model.predict_proba(X_calib)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.615.1">y_pred_test = model.predict(X_test)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.616.1">y_pred_score_test = model.predict_proba(X_test)</span></pre></li>
</ol>
<p><span class="koboSpan" id="kobo.617.1">In the notebook, we use a bank marketing dataset (</span><a href="https://archive.ics.uci.edu/dataset/222/bank+marketing"><span class="koboSpan" id="kobo.618.1">https://archive.ics.uci.edu/dataset/222/bank+marketing</span></a><span class="koboSpan" id="kobo.619.1">) related to the direct marketing campaigns of a Portuguese banking institution. </span><span class="koboSpan" id="kobo.619.2">This dataset contains the </span><span class="No-Break"><span class="koboSpan" id="kobo.620.1">following features:</span></span></p>
<ul>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.621.1">age</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.622.1"> (numeric)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.623.1">job</span></strong><span class="koboSpan" id="kobo.624.1">: Type of job (categorical: </span><strong class="source-inline"><span class="koboSpan" id="kobo.625.1">admin</span></strong><span class="koboSpan" id="kobo.626.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.627.1">unknown</span></strong><span class="koboSpan" id="kobo.628.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.629.1">unemployed</span></strong><span class="koboSpan" id="kobo.630.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.631.1">management</span></strong><span class="koboSpan" id="kobo.632.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.633.1">housemaid</span></strong><span class="koboSpan" id="kobo.634.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.635.1">entrepreneur</span></strong><span class="koboSpan" id="kobo.636.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.637.1">student</span></strong><span class="koboSpan" id="kobo.638.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.639.1">blue-collar</span></strong><span class="koboSpan" id="kobo.640.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.641.1">self-employed</span></strong><span class="koboSpan" id="kobo.642.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.643.1">retired</span></strong><span class="koboSpan" id="kobo.644.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.645.1">technician</span></strong><span class="koboSpan" id="kobo.646.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.647.1">or </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.648.1">services</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.649.1">)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.650.1">marital</span></strong><span class="koboSpan" id="kobo.651.1">: Marital status (categorical: </span><strong class="source-inline"><span class="koboSpan" id="kobo.652.1">married</span></strong><span class="koboSpan" id="kobo.653.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.654.1">divorced</span></strong><span class="koboSpan" id="kobo.655.1">, or </span><strong class="source-inline"><span class="koboSpan" id="kobo.656.1">single</span></strong><span class="koboSpan" id="kobo.657.1">; note that </span><strong class="source-inline"><span class="koboSpan" id="kobo.658.1">divorced</span></strong><span class="koboSpan" id="kobo.659.1"> means divorced </span><span class="No-Break"><span class="koboSpan" id="kobo.660.1">or widowed)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.661.1">education</span></strong><span class="koboSpan" id="kobo.662.1"> (categorical: </span><strong class="source-inline"><span class="koboSpan" id="kobo.663.1">unknown</span></strong><span class="koboSpan" id="kobo.664.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.665.1">secondary</span></strong><span class="koboSpan" id="kobo.666.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.667.1">primary</span></strong><span class="koboSpan" id="kobo.668.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.669.1">or </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.670.1">tertiary</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.671.1">)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.672.1">default</span></strong><span class="koboSpan" id="kobo.673.1">: Has credit in default? </span><span class="koboSpan" id="kobo.673.2">(binary: </span><strong class="source-inline"><span class="koboSpan" id="kobo.674.1">yes</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.675.1">or </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.676.1">no</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.677.1">)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.678.1">balance</span></strong><span class="koboSpan" id="kobo.679.1">: Average yearly balance, in </span><span class="No-Break"><span class="koboSpan" id="kobo.680.1">euros (numeric)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.681.1">housing</span></strong><span class="koboSpan" id="kobo.682.1">: Has a housing loan? </span><span class="koboSpan" id="kobo.682.2">(binary: </span><strong class="source-inline"><span class="koboSpan" id="kobo.683.1">yes</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.684.1">or </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.685.1">no</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.686.1">)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.687.1">loan</span></strong><span class="koboSpan" id="kobo.688.1">: Has a personal loan? </span><span class="koboSpan" id="kobo.688.2">(binary: </span><strong class="source-inline"><span class="koboSpan" id="kobo.689.1">yes</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.690.1">or </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.691.1">no</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.692.1">)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.693.1">The following features are</span><a id="_idIndexMarker236"/><span class="koboSpan" id="kobo.694.1"> related to the last contact of the </span><span class="No-Break"><span class="koboSpan" id="kobo.695.1">current campaign:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.696.1">contact</span></strong><span class="koboSpan" id="kobo.697.1">: Contact communication type (categorical: </span><strong class="source-inline"><span class="koboSpan" id="kobo.698.1">unknown</span></strong><span class="koboSpan" id="kobo.699.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.700.1">telephone</span></strong><span class="koboSpan" id="kobo.701.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.702.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.703.1">cellular</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.704.1">)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.705.1">day</span></strong><span class="koboSpan" id="kobo.706.1">: Last contact day of the </span><span class="No-Break"><span class="koboSpan" id="kobo.707.1">month (numeric)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.708.1">month</span></strong><span class="koboSpan" id="kobo.709.1">: Last contact month of the year (categorical: </span><strong class="source-inline"><span class="koboSpan" id="kobo.710.1">jan</span></strong><span class="koboSpan" id="kobo.711.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.712.1">feb</span></strong><span class="koboSpan" id="kobo.713.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.714.1">mar</span></strong><span class="koboSpan" id="kobo.715.1">, ..., </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.716.1">nov</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.717.1">, </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.718.1">dec</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.719.1">)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.720.1">duration</span></strong><span class="koboSpan" id="kobo.721.1">: Last contact duration, in </span><span class="No-Break"><span class="koboSpan" id="kobo.722.1">seconds (numeric)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.723.1">The other attributes are </span><span class="No-Break"><span class="koboSpan" id="kobo.724.1">as follows:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.725.1">campaign</span></strong><span class="koboSpan" id="kobo.726.1">: Number of contacts performed during this campaign and for this client (numeric; this includes the </span><span class="No-Break"><span class="koboSpan" id="kobo.727.1">last contact)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.728.1">pdays</span></strong><span class="koboSpan" id="kobo.729.1">: The number of days that passed by after the client was last contacted from a previous campaign (numeric; </span><strong class="source-inline"><span class="koboSpan" id="kobo.730.1">-1</span></strong><span class="koboSpan" id="kobo.731.1"> means that the client was not </span><span class="No-Break"><span class="koboSpan" id="kobo.732.1">previously contacted)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.733.1">previous</span></strong><span class="koboSpan" id="kobo.734.1">: The number of contacts performed before this campaign and for this </span><span class="No-Break"><span class="koboSpan" id="kobo.735.1">client (numeric)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.736.1">poutcome</span></strong><span class="koboSpan" id="kobo.737.1">: The outcome of the previous marketing campaign (categorical: </span><strong class="source-inline"><span class="koboSpan" id="kobo.738.1">unknown</span></strong><span class="koboSpan" id="kobo.739.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.740.1">other</span></strong><span class="koboSpan" id="kobo.741.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.742.1">failure</span></strong><span class="koboSpan" id="kobo.743.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.744.1">or </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.745.1">success</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.746.1">)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.747.1">The output variable (the desired target) is </span><strong class="source-inline"><span class="koboSpan" id="kobo.748.1">y</span></strong><span class="koboSpan" id="kobo.749.1"> – has the client subscribed to a term deposit? </span><span class="koboSpan" id="kobo.749.2">(Binary: </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.750.1">yes</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.751.1">, </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.752.1">no</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.753.1">.)</span></span></p>
<p><span class="koboSpan" id="kobo.754.1">The objective is to predict the </span><strong class="source-inline"><span class="koboSpan" id="kobo.755.1">Class</span></strong><span class="koboSpan" id="kobo.756.1"> target variable to indicate whether the marketing campaign was successful in terms of whether the client subscribed to a term deposit. </span><span class="koboSpan" id="kobo.756.2">The dataset is mildly imbalanced with ~12% of clients subscribing to a term deposit as a result of the </span><span class="No-Break"><span class="koboSpan" id="kobo.757.1">marketing campaign.</span></span></p>
<p><span class="koboSpan" id="kobo.758.1">We will use OpenML API to </span><a id="_idIndexMarker237"/><span class="koboSpan" id="kobo.759.1">access and read the dataset. </span><span class="koboSpan" id="kobo.759.2">As discussed in previous chapters, ICP requires a separate calibration set that should not be used to train the underlying machine learning classifier. </span><span class="koboSpan" id="kobo.759.3">In the following code, we’re creating three datasets – </span><em class="italic"><span class="koboSpan" id="kobo.760.1">the proper training dataset for the classifier</span></em><span class="koboSpan" id="kobo.761.1">, </span><em class="italic"><span class="koboSpan" id="kobo.762.1">calibration datasets to calibrate the classifier using ICP</span></em><span class="koboSpan" id="kobo.763.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.764.1">the test dataset that will be used to evaluate the performance</span></em><span class="koboSpan" id="kobo.765.1">. </span><span class="koboSpan" id="kobo.765.2">The dataset contains 45,211 instances; we must split it so that it has 1,000 instances for each of the training and </span><span class="No-Break"><span class="koboSpan" id="kobo.766.1">calibration sets:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.767.1">X_train_calib, X_test, y_train_calib, y_test = train_test_split(X, y, test_size=1000, random_state=42, stratify=y)</span></pre>
<pre class="source-code"><span class="koboSpan" id="kobo.768.1">X_train, X_calib, y_train, y_calib = train_test_split(X_train_calib, y_train_calib, test_size=1000, random_state=42, stratify=y_train_calib)</span></pre>
<p><span class="koboSpan" id="kobo.769.1">Now, we can build the underlying classifier using logistic regression and compute the accuracy and ROC AUC on the </span><span class="No-Break"><span class="koboSpan" id="kobo.770.1">test set:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.771.1">First, let’s train logistic regression using standard </span><span class="No-Break"><span class="koboSpan" id="kobo.772.1">scikit-learn functionality:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.773.1">model = LogisticRegression()</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.774.1">model.fit(X_train, y_train)</span></pre></li>
<li><span class="koboSpan" id="kobo.775.1">Next, we must use the trained logistic regression classifier model to predict class labels and obtain class scores on the calibration and </span><span class="No-Break"><span class="koboSpan" id="kobo.776.1">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.777.1">y_pred_calib = model.predict(X_calib)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.778.1">y_pred_score_calib = model.predict_proba(X_calib)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.779.1">y_pred_test = model.predict(X_test)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.780.1">y_pred_score_test = model.predict_proba(X_test)</span></pre></li>
<li><span class="koboSpan" id="kobo.781.1">Now, compute the classification accuracy and ROC AUC on the </span><span class="No-Break"><span class="koboSpan" id="kobo.782.1">test set:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.783.1">print('Classification accuracy on the test: {}'.format(accuracy_score(y_test, y_pred_test)))</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.784.1">print('ROC AUC on the test set: {}'.format(roc_auc_score(y_test, y_pred_score_test[:,1])))</span></pre></li>
</ol>
<p><span class="koboSpan" id="kobo.785.1">So far, we have only used standard</span><a id="_idIndexMarker238"/><span class="koboSpan" id="kobo.786.1"> classification functionality. </span><span class="koboSpan" id="kobo.786.2">Now, let’s build ICP </span><span class="No-Break"><span class="koboSpan" id="kobo.787.1">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.788.1">nonconformist</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.789.1">:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.790.1">First, we must create ICP classifiers by using a wrapper </span><span class="No-Break"><span class="koboSpan" id="kobo.791.1">from </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.792.1">nonconformist</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.793.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.794.1">icp = IcpClassifier(ClassifierNc(ClassifierAdapter (LogisticRegression()),MarginErrFunc()))</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.795.1">This code snippet constructs an ICP using logistic regression as the underlying machine learning model. </span><span class="koboSpan" id="kobo.795.2">Here’s a breakdown of </span><span class="No-Break"><span class="koboSpan" id="kobo.796.1">what’s happening:</span></span></p></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.797.1">`LogisticRegression()`</span></strong><span class="koboSpan" id="kobo.798.1">: This is a classifier from the scikit-learn library in Python that’s used for binary classification tasks. </span><span class="koboSpan" id="kobo.798.2">It predicts the class score of an instance belonging to a </span><span class="No-Break"><span class="koboSpan" id="kobo.799.1">particular class.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.800.1">`ClassifierAdapter(LogisticRegression())`</span></strong><span class="koboSpan" id="kobo.801.1">: This wraps the logistic regression model so that it’s compatible with the nonconformity scorer. </span><span class="koboSpan" id="kobo.801.2">The adapter makes sure that the underlying classifier’s methods align with the expectations of the </span><span class="No-Break"><span class="koboSpan" id="kobo.802.1">nonconformity scorer.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.803.1">`ClassifierNc(ClassifierAdapter(LogisticRegression()))`</span></strong><span class="koboSpan" id="kobo.804.1">: Here, a nonconformity scorer is created. </span><span class="koboSpan" id="kobo.804.2">Nonconformity scorers, in the context of conformal prediction, are used to measure how much an instance deviates from the norm according to the training data. </span><span class="koboSpan" id="kobo.804.3">In this case, </span><strong class="source-inline"><span class="koboSpan" id="kobo.805.1">ClassifierNc</span></strong><span class="koboSpan" id="kobo.806.1"> is using </span><strong class="source-inline"><span class="koboSpan" id="kobo.807.1">ClassifierAdapter</span></strong><span class="koboSpan" id="kobo.808.1"> to create a scorer that measures nonconformity based on the logistic </span><span class="No-Break"><span class="koboSpan" id="kobo.809.1">regression classifier.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.810.1">`MarginErrFunc()`</span></strong><span class="koboSpan" id="kobo.811.1">: This is the nonconformity measure we have looked at in previous chapters. </span><span class="koboSpan" id="kobo.811.2">In </span><strong class="source-inline"><span class="koboSpan" id="kobo.812.1">nonconformist</span></strong><span class="koboSpan" id="kobo.813.1">, the margin error is defined as </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.814.1">0.5</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.815.1">−</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.816.1">ˆ</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.817.1"> </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.818.1">P</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.819.1">(</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.820.1">y</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.821.1"> </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.822.1">i</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator_Extended"><span class="koboSpan" id="kobo.823.1">∣</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.824.1">x</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.825.1">)</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.826.1">−</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.827.1">m</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.828.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.829.1">x</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.830.1"> </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.831.1">y</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.832.1">!</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.833.1">=</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.834.1">y</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.835.1"> </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.836.1">i</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.837.1"> </span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.838.1">ˆ</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.839.1"> </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.840.1">P</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.841.1">(</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.842.1">y</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator_Extended"><span class="koboSpan" id="kobo.843.1">∣</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.844.1">x</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.845.1">)</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.846.1">  </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.847.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.848.1">____________</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.849.1"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.850.1">2</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.851.1"> </span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.852.1">.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.853.1">`</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.854.1">IcpClassifier(ClassifierNc(ClassifierAdapter</span></strong></span><strong class="source-inline"><span class="koboSpan" id="kobo.855.1">
(LogisticRegression())), MarginErrFunc())`</span></strong><span class="koboSpan" id="kobo.856.1">: Finally, an ICP is created. </span><span class="koboSpan" id="kobo.856.2">An ICP is a type of conformal predictor that separates the calibration set from the training set, thereby providing valid predictions even under distribution shift. </span><span class="koboSpan" id="kobo.856.3">It uses the defined nonconformity scorer (based on the logistic regression classifier) and the</span><a id="_idIndexMarker239"/><span class="koboSpan" id="kobo.857.1"> margin error function to </span><span class="No-Break"><span class="koboSpan" id="kobo.858.1">make predictions.</span></span></li>
<li><span class="koboSpan" id="kobo.859.1">Then, we must train the ICP classifier on the proper training set and calibrate it on the </span><span class="No-Break"><span class="koboSpan" id="kobo.860.1">calibration set:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.861.1">icp.fit(X_train, y_train)</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.862.1">icp.calibrate(X_calib, y_calib)</span></pre></li>
<li><span class="koboSpan" id="kobo.863.1">Now that we have trained the conformal predictor, we can compute predictions on the test set using the specified </span><span class="No-Break"><span class="koboSpan" id="kobo.864.1">significance level:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.865.1"># Produce predictions for the test set, with confidence 95%</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.866.1">prediction = icp.predict(X_test.values, significance=0.05)</span></pre></li>
</ol>
<p><span class="koboSpan" id="kobo.867.1">Note that </span><strong class="source-inline"><span class="koboSpan" id="kobo.868.1">nonconformist</span></strong><span class="koboSpan" id="kobo.869.1"> uses classical conformal prediction and outputs </span><span class="No-Break"><span class="koboSpan" id="kobo.870.1">prediction sets.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.871.1">nonconformist</span></strong><span class="koboSpan" id="kobo.872.1"> is a Python library built on top of scikit-learn that focuses on implementing conformal prediction methods for classification tasks. </span><span class="koboSpan" id="kobo.872.2">It provides a comprehensive set of tools and algorithms to generate prediction intervals, estimate uncertainty, and enhance calibration in classification models. </span><span class="koboSpan" id="kobo.872.3">Here is an overview of the main features and capabilities of the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.873.1">nonconformist</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.874.1"> library:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.875.1">Conformal prediction algorithms</span></strong><span class="koboSpan" id="kobo.876.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.877.1">nonconformist</span></strong><span class="koboSpan" id="kobo.878.1"> offers various conformal prediction algorithms </span><a id="_idIndexMarker240"/><span class="koboSpan" id="kobo.879.1">specifically designed for classification. </span><span class="koboSpan" id="kobo.879.2">These algorithms include </span><span class="No-Break"><span class="koboSpan" id="kobo.880.1">the</span></span><span class="No-Break"><a id="_idIndexMarker241"/></span><span class="No-Break"><span class="koboSpan" id="kobo.881.1"> following:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.882.1">Inductive conformal classifier</span></strong><span class="koboSpan" id="kobo.883.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.884.1">ICC</span></strong><span class="koboSpan" id="kobo.885.1">): This constructs a nonconformity measure and a prediction region</span><a id="_idIndexMarker242"/><span class="koboSpan" id="kobo.886.1"> based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.887.1">training set</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.888.1">Transductive conformal classifier</span></strong><span class="koboSpan" id="kobo.889.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.890.1">TCC</span></strong><span class="koboSpan" id="kobo.891.1">): This incorporates the test set into the construction of </span><a id="_idIndexMarker243"/><span class="No-Break"><span class="koboSpan" id="kobo.892.1">prediction regions</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.893.1">Venn predictors</span></strong><span class="koboSpan" id="kobo.894.1">: This generates</span><a id="_idIndexMarker244"/><span class="koboSpan" id="kobo.895.1"> prediction intervals using nested Venn regions to control the number of </span><span class="No-Break"><span class="koboSpan" id="kobo.896.1">false positives</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.897.1">Random forest conformal predictor</span></strong><span class="koboSpan" id="kobo.898.1">: This utilizes a random forest model as the underlying</span><a id="_idIndexMarker245"/><span class="koboSpan" id="kobo.899.1"> classifier for </span><span class="No-Break"><span class="koboSpan" id="kobo.900.1">conformal prediction</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.901.1">Model compatibility</span></strong><span class="koboSpan" id="kobo.902.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.903.1">nonconformist</span></strong><span class="koboSpan" id="kobo.904.1"> seamlessly integrates with scikit-learn, allowing users to leverage scikit-learn’s extensive collection of classifiers. </span><span class="koboSpan" id="kobo.904.2">It provides a wrapper class that allows scikit-learn classifiers to be used within the conformal </span><span class="No-Break"><span class="koboSpan" id="kobo.905.1">prediction framework.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.906.1">Calibration and uncertainty estimation</span></strong><span class="koboSpan" id="kobo.907.1">: The library includes functions for calibrating the output of conformal prediction models. </span><span class="koboSpan" id="kobo.907.2">These functions help refine the prediction intervals and ensure reliable estimates of the prediction uncertainty. </span><strong class="source-inline"><span class="koboSpan" id="kobo.908.1">nonconformist</span></strong><span class="koboSpan" id="kobo.909.1"> also offers tools to assess the calibration quality, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.910.1">reliability diagrams.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.911.1">Evaluation and performance metrics</span></strong><span class="koboSpan" id="kobo.912.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.913.1">nonconformist</span></strong><span class="koboSpan" id="kobo.914.1"> provides evaluation metrics to assess the performance of conformal prediction models. </span><span class="koboSpan" id="kobo.914.2">These metrics include accuracy, error rate, p-values, and efficiency measures, enabling thorough evaluation and comparison of </span><span class="No-Break"><span class="koboSpan" id="kobo.915.1">different models.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.916.1">Cross-validation support</span></strong><span class="koboSpan" id="kobo.917.1">: The library offers support for performing cross-validation with conformal prediction models. </span><span class="koboSpan" id="kobo.917.2">This enables robust evaluation and validation of the models across different folds of </span><span class="No-Break"><span class="koboSpan" id="kobo.918.1">the dataset.</span></span></li>
</ul>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.919.1">nonconformist</span></strong><span class="koboSpan" id="kobo.920.1"> is a powerful tool for applying conformal prediction techniques to classification problems. </span><span class="koboSpan" id="kobo.920.2">With its extensive range of algorithms, compatibility with scikit-learn, calibration and uncertainty estimation capabilities, evaluation metrics, and cross-validation support, </span><strong class="source-inline"><span class="koboSpan" id="kobo.921.1">nonconformist</span></strong><span class="koboSpan" id="kobo.922.1"> provides a comprehensive framework for implementing and evaluating conformal prediction models in classification tasks. </span><span class="koboSpan" id="kobo.922.2">It is a valuable resource for</span><a id="_idIndexMarker246"/><span class="koboSpan" id="kobo.923.1"> researchers and practitioners looking to incorporate conformal prediction into their </span><span class="No-Break"><span class="koboSpan" id="kobo.924.1">classification projects.</span></span></p>
<h1 id="_idParaDest-74"><a id="_idTextAnchor072"/><span class="koboSpan" id="kobo.925.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.926.1">In this chapter, we embarked on an enlightening exploration of conformal prediction specifically tailored to classification tasks. </span><span class="koboSpan" id="kobo.926.2">We began by underscoring the significance of calibration in the realm of classification, emphasizing its role in ensuring the reliability and trustworthiness of model predictions. </span><span class="koboSpan" id="kobo.926.3">Through our journey, we were introduced to various calibration methods, including the various approaches to conformal prediction. </span><span class="koboSpan" id="kobo.926.4">We observed how conformal prediction uniquely addresses the challenges of calibration, providing both a theoretical and practical edge over </span><span class="No-Break"><span class="koboSpan" id="kobo.927.1">traditional methods.</span></span></p>
<p><span class="koboSpan" id="kobo.928.1">We also delved into the nuanced realms of Venn-ABERS predictors, shedding light on their roles and implications in the </span><span class="No-Break"><span class="koboSpan" id="kobo.929.1">calibration process.</span></span></p>
<p><span class="koboSpan" id="kobo.930.1">Lastly, we underscored the invaluable contribution of the open source community in this domain. </span><span class="koboSpan" id="kobo.930.2">We highlighted tools such as the </span><strong class="source-inline"><span class="koboSpan" id="kobo.931.1">nonconformist</span></strong><span class="koboSpan" id="kobo.932.1"> library, which serve as essential resources for practitioners who are keen on implementing conformal prediction in their </span><span class="No-Break"><span class="koboSpan" id="kobo.933.1">classification challenges.</span></span></p>
<p><span class="koboSpan" id="kobo.934.1">As we conclude this chapter, it’s evident that calibration, and more specifically conformal prediction, plays a pivotal role in enhancing the robustness and reliability of classification models. </span><span class="koboSpan" id="kobo.934.2">With the tools and knowledge we have at our disposal, we’re well equipped to tackle classification problems with greater confidence </span><span class="No-Break"><span class="koboSpan" id="kobo.935.1">and precision.</span></span></p>
<p><span class="koboSpan" id="kobo.936.1">In the next chapter, we will cover conformal prediction for </span><span class="No-Break"><span class="koboSpan" id="kobo.937.1">regression problems.</span></span></p>
</div>
</body></html>