<html><head></head><body>
<div id="_idContainer098">
<h1 class="chapter-number" id="_idParaDest-142"><a id="_idTextAnchor147"/><span class="koboSpan" id="kobo.1.1">7</span></h1>
<h1 id="_idParaDest-143"><a id="_idTextAnchor148"/><span class="koboSpan" id="kobo.2.1">Labeling Text Data</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In this chapter, we will explore techniques for labeling text data for classification in cases where an insufficient amount of labeled data is available. </span><span class="koboSpan" id="kobo.3.2">We are going to use Generative AI to label the text data, in addition to Snorkel and k-means clustering. </span><span class="koboSpan" id="kobo.3.3">The chapter focuses on the essential process of annotating textual data for NLP and text analysis. </span><span class="koboSpan" id="kobo.3.4">It aims to provide readers with practical knowledge and insights into various labeling techniques. </span><span class="koboSpan" id="kobo.3.5">The chapter will specifically cover automatic labeling using OpenAI, rule-based labeling using Snorkel labeling functions, and unsupervised learning using k-means clustering. </span><span class="koboSpan" id="kobo.3.6">By understanding these techniques, readers will be equipped to effectively label text data and extract meaningful insights from unstructured </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">textual information.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">We will cover the following sections in </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">this chapter:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.7.1">Real-world applications of text </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">data labeling</span></span></li>
<li><span class="koboSpan" id="kobo.9.1">Tools and frameworks for text </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">data labeling</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">Exploratory data analysis </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">of text</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Generative AI and OpenAI for labeling </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">text data</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">Labeling text data </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">using Snorkel</span></span></li>
<li><span class="koboSpan" id="kobo.17.1">Labeling text data using </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">logistic regression</span></span></li>
<li><span class="koboSpan" id="kobo.19.1">Labeling text data using </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">K-means clustering</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">Labeling customer reviews (sentiment analysis) using </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">neural networks</span></span></li>
</ul>
<h1 id="_idParaDest-144"><a id="_idTextAnchor149"/><span class="koboSpan" id="kobo.23.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.24.1">The code files used in this chapter are located </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">at </span></span><a href="https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/code/Ch07"><span class="No-Break"><span class="koboSpan" id="kobo.26.1">https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/code/Ch07</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.27.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.28.1">The Gutenberg Corpus and movie review dataset can be </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">found here:</span></span></p>
<ul>
<li><a href="https://pypi.org/project/Gutenberg/"><span class="No-Break"><span class="koboSpan" id="kobo.30.1">https://pypi.org/project/Gutenberg/</span></span></a></li>
<li><a href="https://www.nltk.org/api/nltk.sentiment.util.html?highlight=movie#nltk.sentiment.util.demo_movie_reviews"><span class="No-Break"><span class="koboSpan" id="kobo.31.1">https://www.nltk.org/api/nltk.sentiment.util.html?highlight=movie#nltk.sentiment.util.demo_movie_reviews</span></span></a></li>
</ul>
<p><span class="koboSpan" id="kobo.32.1">You also need to create an Azure account and add the OpenAI resource for working with Generative AI. </span><span class="koboSpan" id="kobo.32.2">To sign up for a free Azure subscription, visit https://azure.microsoft.com/free. </span><span class="koboSpan" id="kobo.32.3">To request access to the Azure OpenAI service, </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">visit </span></span><a href="https://aka.ms/oaiapply"><span class="No-Break"><span class="koboSpan" id="kobo.34.1">https://aka.ms/oaiapply</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.35.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.36.1">Once you have provisioned the Azure OpenAI service, set up the following </span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">environment variables:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.38.1">
os.environ['AZURE_OPENAI_KEY'] = 'your_api_key'
os.environ['AZURE_OPENAI_ENDPOINT") ='your_azure_openai_endpoint'</span></pre> <p><span class="koboSpan" id="kobo.39.1">Your endpoint should look </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">like </span></span><a href="https://YOUR_RESOURCE_NAME.openai.azure.com/"><span class="No-Break"><span class="koboSpan" id="kobo.41.1">https://YOUR_RESOURCE_NAME.openai.azure.com/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.42.1">.</span></span></p>
<h1 id="_idParaDest-145"><a id="_idTextAnchor150"/><span class="koboSpan" id="kobo.43.1">Real-world applications of text data labeling</span></h1>
<p><span class="koboSpan" id="kobo.44.1">Text data labeling</span><a id="_idIndexMarker475"/><span class="koboSpan" id="kobo.45.1"> or classification is widely used across various industries and applications to extract valuable information, automate processes, and improve decision-making. </span><span class="koboSpan" id="kobo.45.2">Here are some real-world examples</span><a id="_idIndexMarker476"/><span class="koboSpan" id="kobo.46.1"> across different </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">use cases:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.48.1">Customer support </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">ticket classification:</span></span><ul><li><span class="koboSpan" id="kobo.50.1">Use case: Companies receive a large volume of customer </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">support tickets.</span></span></li><li><span class="koboSpan" id="kobo.52.1">Application: Automated</span><a id="_idIndexMarker477"/><span class="koboSpan" id="kobo.53.1"> classification of support tickets into categories such as Billing, Technical Support, and Product Inquiry. </span><span class="koboSpan" id="kobo.53.2">This helps prioritize and route tickets to the </span><span class="No-Break"><span class="koboSpan" id="kobo.54.1">right teams.</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.55.1">Spam </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">email filtering:</span></span><ul><li><span class="koboSpan" id="kobo.57.1">Use case: Sorting emails into spam and </span><span class="No-Break"><span class="koboSpan" id="kobo.58.1">non-spam categories.</span></span></li><li><span class="koboSpan" id="kobo.59.1">Application: Email providers use text classification to identify and filter out unwanted emails, providing users with a cleaner inbox and reducing the risk of </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">phishing attacks.</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.61.1">Sentiment analysis in </span><span class="No-Break"><span class="koboSpan" id="kobo.62.1">social media:</span></span><ul><li><span class="koboSpan" id="kobo.63.1">Use case: Analyzing social media comments </span><span class="No-Break"><span class="koboSpan" id="kobo.64.1">and posts.</span></span></li><li><span class="koboSpan" id="kobo.65.1">Application: Brands use sentiment analysis to gauge public opinion, track brand sentiment, and respond to customer feedback. </span><span class="koboSpan" id="kobo.65.2">It helps with reputation management and understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.66.1">customer preferences.</span></span></li></ul></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.67.1">News categorization:</span></span><ul><li><span class="koboSpan" id="kobo.68.1">Use case: Sorting news articles </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">into categories.</span></span></li><li><span class="koboSpan" id="kobo.70.1">Application: News websites use text classification to automatically categorize articles into sections such as Politics, Technology, and Entertainment, making it easier for readers to find </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">relevant content.</span></span></li></ul></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.72.1">Resume screening:</span></span><ul><li><span class="koboSpan" id="kobo.73.1">Use case: Sorting </span><span class="No-Break"><span class="koboSpan" id="kobo.74.1">job applications.</span></span></li><li><span class="koboSpan" id="kobo.75.1">Application: Human resources departments use text classification to quickly identify resumes that match specific job requirements. </span><span class="koboSpan" id="kobo.75.2">This accelerates the hiring process and ensures a more efficient </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">candidate screening.</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.77.1">Medical </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">document</span></span><span class="No-Break"><a id="_idIndexMarker478"/></span><span class="No-Break"><span class="koboSpan" id="kobo.79.1"> classification:</span></span><ul><li><span class="koboSpan" id="kobo.80.1">Use case: Sorting</span><a id="_idIndexMarker479"/><span class="koboSpan" id="kobo.81.1"> medical records </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">and documents.</span></span></li><li><span class="koboSpan" id="kobo.83.1">Application: Healthcare organizations use text classification to categorize and organize medical records, lab reports, and patient notes. </span><span class="koboSpan" id="kobo.83.2">This aids in efficient data retrieval </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">and analysis.</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.85.1">Legal </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1">document classification:</span></span><ul><li><span class="koboSpan" id="kobo.87.1">Use case: Sorting </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">legal documents.</span></span></li><li><span class="koboSpan" id="kobo.89.1">Application: Law firms use text classification to categorize and manage legal documents, contracts, and case-related information, streamlining legal research and </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">case management.</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.91.1">Fraud detection in </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">financial transactions:</span></span><ul><li><span class="koboSpan" id="kobo.93.1">Use case: Identifying </span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">fraudulent activity.</span></span></li><li><span class="koboSpan" id="kobo.95.1">Application: Financial institutions use text classification to analyze transaction descriptions and identify potential cases of fraud or suspicious activities, enhancing </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">security measures.</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.97.1">Product </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">review analysis:</span></span><ul><li><span class="koboSpan" id="kobo.99.1">Use case: Analyzing </span><span class="No-Break"><span class="koboSpan" id="kobo.100.1">customer reviews.</span></span></li><li><span class="koboSpan" id="kobo.101.1">Application: E-commerce platforms use sentiment analysis to categorize and understand product reviews. </span><span class="koboSpan" id="kobo.101.2">This helps in improving products, addressing customer concerns, and enhancing overall </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">customer satisfaction.</span></span></li></ul></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.103.1">Language identification:</span></span><ul><li><span class="koboSpan" id="kobo.104.1">Use case: Determining the language of a </span><span class="No-Break"><span class="koboSpan" id="kobo.105.1">given text.</span></span></li><li><span class="koboSpan" id="kobo.106.1">Application: Social media platforms and translation services use text classification to automatically identify the language of a user’s post or content, enabling</span><a id="_idIndexMarker480"/><span class="koboSpan" id="kobo.107.1"> accurate </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">language-specific interactions.</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.109.1">These examples highlight the versatility of text classification across different domains, showcasing its significance in automating tasks, improving efficiency, and gaining valuable insights from </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">textual data.</span></span></p>
<h1 id="_idParaDest-146"><a id="_idTextAnchor151"/><span class="koboSpan" id="kobo.111.1">Tools and frameworks for text data labeling</span></h1>
<p><span class="koboSpan" id="kobo.112.1">There are </span><a id="_idIndexMarker481"/><span class="koboSpan" id="kobo.113.1">several open source tools and frameworks available for text data analysis and labeling. </span><span class="koboSpan" id="kobo.113.2">Here are some popular ones, along with their pros </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">and cons:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-2">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.115.1">Tools </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.116.1">and frameworks</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.117.1">Pros</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.118.1">Cons</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.119.1">Natural Language </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.120.1">Toolkit</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.121.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.122.1">NLTK</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">)</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.124.1">Comprehensive </span><a id="_idIndexMarker482"/><span class="koboSpan" id="kobo.125.1">library for</span><a id="_idIndexMarker483"/> <span class="No-Break"><span class="koboSpan" id="kobo.126.1">NLP tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.127.1">Rich set of tools for tokenization, stemming, tagging, parsing, </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">and more.</span></span></p>
<p><span class="koboSpan" id="kobo.129.1">Active </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">community support.</span></span></p>
<p><span class="koboSpan" id="kobo.131.1">Suitable for educational purposes and </span><span class="No-Break"><span class="koboSpan" id="kobo.132.1">research projects.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.133.1">Some components may not be as efficient for large-scale </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">industrial applications.</span></span></p>
<p><span class="koboSpan" id="kobo.135.1">Steep learning curve </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">for beginners.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.137.1">spaCy</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.138.1">Fast</span><a id="_idIndexMarker484"/><span class="koboSpan" id="kobo.139.1"> and efficient, designed</span><a id="_idIndexMarker485"/><span class="koboSpan" id="kobo.140.1"> for </span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">production use.</span></span></p>
<p><span class="koboSpan" id="kobo.142.1">Pre-trained models for </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1">various languages.</span></span></p>
<p><span class="koboSpan" id="kobo.144.1">Provides </span><a id="_idIndexMarker486"/><span class="koboSpan" id="kobo.145.1">robust support for tokenization, named entity recognition, and </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">dependency parsing.</span></span></p>
<p><span class="No-Break"><span class="koboSpan" id="kobo.147.1">Easy-to-use </span></span><span class="No-Break"><a id="_idIndexMarker487"/></span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">API.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.149.1">Less emphasis on educational resources compared </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1">to NLTK.</span></span></p>
<p><span class="koboSpan" id="kobo.151.1">Limited support for </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">some languages.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.153.1">scikit-learn</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.154.1">General-purpose </span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.155.1">machine learning</span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.156.1"> library with </span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.157.1">excellent text </span><span class="No-Break"><span class="koboSpan" id="kobo.158.1">processing capabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.159.1">Easy integration with other scikit-learn modules for feature extraction and </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">model training.</span></span></p>
<p><span class="koboSpan" id="kobo.161.1">Well-documented and widely used in the machine </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">learning community.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.163.1">May not have specialized tools for certain </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">NLP tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.165.1">Limited support for deep </span><span class="No-Break"><span class="koboSpan" id="kobo.166.1">learning-based models.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.167.1">TextBlob</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.168.1">Simple</span><a id="_idIndexMarker491"/><span class="koboSpan" id="kobo.169.1"> API for common NLP</span><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.170.1"> tasks such as part-of-speech tagging, noun phrase extraction, and </span><span class="No-Break"><span class="koboSpan" id="kobo.171.1">sentiment analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.172.1">Built on NLTK and provides an easy entry point </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">for beginners.</span></span></p>
<p><span class="koboSpan" id="kobo.174.1">Useful for</span><a id="_idIndexMarker493"/><span class="koboSpan" id="kobo.175.1"> quick prototyping</span><a id="_idIndexMarker494"/><span class="koboSpan" id="kobo.176.1"> and </span><span class="No-Break"><span class="koboSpan" id="kobo.177.1">small projects.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.178.1">Limited customization options compared to </span><span class="No-Break"><span class="koboSpan" id="kobo.179.1">lower-level libraries.</span></span></p>
<p><span class="koboSpan" id="kobo.180.1">May not be as performant for </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">large-scale applications.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.182.1">Gensim</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.183.1">Focus on </span><a id="_idIndexMarker495"/><span class="koboSpan" id="kobo.184.1">topic modeling, document similarity, and </span><a id="_idIndexMarker496"/><span class="koboSpan" id="kobo.185.1">vector </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">space modeling.</span></span></p>
<p><span class="koboSpan" id="kobo.187.1">Efficient implementation of algorithms such </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1">as Word2Vec.</span></span></p>
<p><span class="koboSpan" id="kobo.189.1">Suitable for large text corpora and document </span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">similarity tasks.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.191.1">Less versatile for general-purpose </span><span class="No-Break"><span class="koboSpan" id="kobo.192.1">NLP tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.193.1">Limited support for some advanced </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">NLP functionalities.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.195.1">Transformers (</span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">Hugging Face)</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.197.1">Provides </span><a id="_idIndexMarker497"/><span class="koboSpan" id="kobo.198.1">pre-trained models for a </span><a id="_idIndexMarker498"/><span class="koboSpan" id="kobo.199.1">wide range of NLP</span><a id="_idIndexMarker499"/><span class="koboSpan" id="kobo.200.1"> tasks (BERT, </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">GPT, etc.).</span></span></p>
<p><span class="koboSpan" id="kobo.202.1">Easy-to-use interfaces for integrating</span><a id="_idIndexMarker500"/> <span class="No-Break"><span class="koboSpan" id="kobo.203.1">state-of-the-art models.</span></span></p>
<p><span class="koboSpan" id="kobo.204.1">Excellent </span><a id="_idIndexMarker501"/><span class="No-Break"><span class="koboSpan" id="kobo.205.1">community support.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.206.1">Heavy computational requirements for fine-tuning </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">large models.</span></span></p>
<p><span class="koboSpan" id="kobo.208.1">May not be as straightforward </span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">for beginners.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.210.1">Stanford NLP</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.211.1">Comprehensive </span><a id="_idIndexMarker502"/><span class="koboSpan" id="kobo.212.1">suite of NLP tools, including tokenization, part-of-speech </span><a id="_idIndexMarker503"/><span class="koboSpan" id="kobo.213.1">tagging, and named </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">entity recognition.</span></span></p>
<p><span class="koboSpan" id="kobo.215.1">Java-based, making it suitable for </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">Java projects.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.217.1">Heavier resource usage compared to </span><span class="No-Break"><span class="koboSpan" id="kobo.218.1">Python-based libraries.</span></span></p>
<p><span class="koboSpan" id="kobo.219.1">May have a steeper learning curve for </span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">certain tasks.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.221.1">Flair</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.222.1">Focus</span><a id="_idIndexMarker504"/><span class="koboSpan" id="kobo.223.1"> on state-of-the-art</span><a id="_idIndexMarker505"/><span class="koboSpan" id="kobo.224.1"> NLP models </span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">and embeddings.</span></span></p>
<p><span class="koboSpan" id="kobo.226.1">Provides embeddings for a variety </span><span class="No-Break"><span class="koboSpan" id="kobo.227.1">of languages.</span></span></p>
<p><span class="No-Break"><span class="koboSpan" id="kobo.228.1">Easy-to-use </span></span><span class="No-Break"><a id="_idIndexMarker506"/></span><span class="No-Break"><span class="koboSpan" id="kobo.229.1">API.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.230.1">May not have as many pre-built models as </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1">other libraries.</span></span></p>
<p><span class="koboSpan" id="kobo.232.1">May not be as established as some </span><span class="No-Break"><span class="koboSpan" id="kobo.233.1">older frameworks.</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.234.1">Table 7.1 – Popular tools with their pros and cons</span></p>
<p><span class="koboSpan" id="kobo.235.1">In addition to this list is OpenAI’s </span><strong class="bold"><span class="koboSpan" id="kobo.236.1">Generative Pre-trained Transformer</span></strong><span class="koboSpan" id="kobo.237.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.238.1">GPT</span></strong><span class="koboSpan" id="kobo.239.1">), which is a state-of-the-art language model</span><a id="_idIndexMarker507"/><span class="koboSpan" id="kobo.240.1"> that utilizes transformer architecture. </span><span class="koboSpan" id="kobo.240.2">It’s pre-trained on a massive amount of diverse data and can be fine-tuned for specific tasks. </span><span class="koboSpan" id="kobo.240.3">GPT is known for its ability to generate coherent and contextually </span><a id="_idIndexMarker508"/><span class="koboSpan" id="kobo.241.1">relevant text, making it a powerful tool for various </span><strong class="bold"><span class="koboSpan" id="kobo.242.1">natural language processing</span></strong><span class="koboSpan" id="kobo.243.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.244.1">NLP</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.245.1">) applications.</span></span></p>
<p><span class="koboSpan" id="kobo.246.1">The transformer architecture, introduced by Vaswani et al. </span><span class="koboSpan" id="kobo.246.2">in the paper </span><em class="italic"><span class="koboSpan" id="kobo.247.1">Attention is All You Need</span></em><span class="koboSpan" id="kobo.248.1">, revolutionized NLP. </span><span class="koboSpan" id="kobo.248.2">It relies on self-attention mechanisms to capture contextual relationships between words in a sequence, enabling parallelization and scalability. </span><span class="koboSpan" id="kobo.248.3">Transformers have become the foundation of numerous advanced language models, including GPT and BERT, due to their ability to capture long-range dependencies in sequential data efficiently. </span><span class="koboSpan" id="kobo.248.4">Its pros include versatility and the ability to understand context in text which is why it is used for various natural language understanding tasks. </span><span class="koboSpan" id="kobo.248.5">Its cons are that it is resource-intensive, requiring substantial computing power, and fine-tuning requires access to significant </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">computational resources.</span></span></p>
<p><span class="koboSpan" id="kobo.250.1">Each of these tools has strengths and weaknesses, and the choice depends on project requirements, available resources, and the desired level of customization. </span><span class="koboSpan" id="kobo.250.2">It’s common to see a combination of these tools being used together in more complex NLP pipelines. </span><span class="koboSpan" id="kobo.250.3">When selecting a tool, it’s important to consider factors such as ease of use, community support, and compatibility with the specific tasks </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">at hand.</span></span></p>
<h1 id="_idParaDest-147"><a id="_idTextAnchor152"/><span class="koboSpan" id="kobo.252.1">Exploratory data analysis of text</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.253.1">Exploratory Data Analysis</span></strong><span class="koboSpan" id="kobo.254.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.255.1">EDA</span></strong><span class="koboSpan" id="kobo.256.1">) is a </span><a id="_idIndexMarker509"/><span class="koboSpan" id="kobo.257.1">crucial step in any data science project. </span><span class="koboSpan" id="kobo.257.2">When it comes to text data, EDA can help us understand the structure and characteristics of the data, identify potential issues or inconsistencies, and inform our choice of data preprocessing and modeling techniques. </span><span class="koboSpan" id="kobo.257.3">In this section, we will walk through the steps involved in performing EDA on </span><span class="No-Break"><span class="koboSpan" id="kobo.258.1">text data.</span></span></p>
<h2 id="_idParaDest-148"><a id="_idTextAnchor153"/><span class="koboSpan" id="kobo.259.1">Loading the data</span></h2>
<p><span class="koboSpan" id="kobo.260.1">The </span><a id="_idIndexMarker510"/><span class="koboSpan" id="kobo.261.1">first step in EDA is to load the text data into our environment. </span><span class="koboSpan" id="kobo.261.2">Text data can come in many formats, including plain text files, CSV files, or database tables. </span><span class="koboSpan" id="kobo.261.3">Once we have the data loaded, we can begin to explore its structure </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">and content.</span></span></p>
<h2 id="_idParaDest-149"><a id="_idTextAnchor154"/><span class="koboSpan" id="kobo.263.1">Understanding the data</span></h2>
<p><span class="koboSpan" id="kobo.264.1">The </span><a id="_idIndexMarker511"/><span class="koboSpan" id="kobo.265.1">next step in EDA is to gain an understanding of the data. </span><span class="koboSpan" id="kobo.265.2">For text data, this may involve examining the size of the dataset, the number of documents or samples, and the overall structure of the text (e.g., whether it is structured or unstructured). </span><span class="koboSpan" id="kobo.265.3">We can use descriptive statistics to gain insights into the data, such as the distribution of text lengths or the frequency of certain words </span><span class="No-Break"><span class="koboSpan" id="kobo.266.1">or phrases.</span></span></p>
<h2 id="_idParaDest-150"><a id="_idTextAnchor155"/><span class="koboSpan" id="kobo.267.1">Cleaning and preprocessing the data</span></h2>
<p><span class="koboSpan" id="kobo.268.1">After </span><a id="_idIndexMarker512"/><span class="koboSpan" id="kobo.269.1">understanding the data, the next step in EDA is to clean and preprocess the text data. </span><span class="koboSpan" id="kobo.269.2">This can involve a number of steps, such as removing punctuation and stop words, stemming or lemmatizing words, and converting text to lowercase. </span><span class="koboSpan" id="kobo.269.3">Cleaning and preprocessing the data is important for preparing the data for modeling and ensuring that we are working with </span><span class="No-Break"><span class="koboSpan" id="kobo.270.1">high-quality data.</span></span></p>
<h2 id="_idParaDest-151"><a id="_idTextAnchor156"/><span class="koboSpan" id="kobo.271.1">Exploring the text’s content</span></h2>
<p><span class="koboSpan" id="kobo.272.1">Once we</span><a id="_idIndexMarker513"/><span class="koboSpan" id="kobo.273.1"> have cleaned and preprocessed the data, we can begin to explore the content of the text itself. </span><span class="koboSpan" id="kobo.273.2">This can involve examining the most frequent words or phrases, identifying patterns or themes in the text, and visualizing the data using techniques such as word clouds or frequency histograms. </span><span class="koboSpan" id="kobo.273.3">We can also use NLP techniques to extract features from the text, such as named entities, part-of-speech tags, or </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">sentiment scores.</span></span></p>
<h2 id="_idParaDest-152"><a id="_idTextAnchor157"/><span class="koboSpan" id="kobo.275.1">Analyzing relationships between text and other variables</span></h2>
<p><span class="koboSpan" id="kobo.276.1">In some</span><a id="_idIndexMarker514"/><span class="koboSpan" id="kobo.277.1"> cases, we may want to explore the relationships between the text data and other variables, such as demographic or behavioral data. </span><span class="koboSpan" id="kobo.277.2">For example, we may want to examine whether the sentiment of movie reviews varies by genre, or whether the topics discussed in social media posts differ by user age or location. </span><span class="koboSpan" id="kobo.277.3">This type of analysis can help us gain deeper insights into the text data and inform our </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">modeling approach.</span></span></p>
<h2 id="_idParaDest-153"><a id="_idTextAnchor158"/><span class="koboSpan" id="kobo.279.1">Visualizing the results</span></h2>
<p><span class="koboSpan" id="kobo.280.1">Finally, we </span><a id="_idIndexMarker515"/><span class="koboSpan" id="kobo.281.1">can visualize the results of our EDA using a variety of techniques, such as word clouds, bar charts, scatterplots, or heat maps. </span><span class="koboSpan" id="kobo.281.2">Visualization is an important tool for communicating insights and findings to stakeholders, and can help us identify patterns and relationships in the data that might not be immediately apparent from the </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">raw text.</span></span></p>
<p><span class="koboSpan" id="kobo.283.1">In conclusion, exploratory data analysis is a critical step in any text data project. </span><span class="koboSpan" id="kobo.283.2">By understanding the structure and content of the data, cleaning and preprocessing it, exploring the text’s content, analyzing relationships between text and other variables, and visualizing the results, we can gain deep insights into the textual data and inform our modeling approach. </span><span class="koboSpan" id="kobo.283.3">With the right tools and techniques, EDA can help us uncover hidden patterns and insights in text data that can be used to drive business decisions and </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">improve outcomes.</span></span></p>
<h2 id="_idParaDest-154"><a id="_idTextAnchor159"/><span class="koboSpan" id="kobo.285.1">Exploratory data analysis of sample text data set</span></h2>
<p><span class="koboSpan" id="kobo.286.1">Here’s an </span><a id="_idIndexMarker516"/><span class="koboSpan" id="kobo.287.1">example Python code for performing EDA on a</span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.288.1"> text dataset. </span><span class="koboSpan" id="kobo.288.2">We will be using the Gutenberg corpus (</span><a href="https://pypi.org/project/Gutenberg/"><span class="koboSpan" id="kobo.289.1">https://pypi.org/project/Gutenberg/</span></a><span class="koboSpan" id="kobo.290.1">), which is a publicly available collection of over 60,000 </span><span class="No-Break"><span class="koboSpan" id="kobo.291.1">electronic books.</span></span></p>
<p><span class="koboSpan" id="kobo.292.1">The NLTK corpus is a collection of publicly available datasets for NLP research and development. </span><span class="koboSpan" id="kobo.292.2">The Gutenberg corpus (</span><a href="https://www.nltk.org/book/ch02.html"><span class="koboSpan" id="kobo.293.1">https://www.nltk.org/book/ch02.html</span></a><span class="koboSpan" id="kobo.294.1">), which is one of the datasets included in NLTK, specifically contains a selection of public domain texts from Project Gutenberg. </span><span class="koboSpan" id="kobo.294.2">Project Gutenberg is a digital library that offers free access to books and other texts that are no longer protected </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">by copyright.</span></span></p>
<p><span class="koboSpan" id="kobo.296.1">Therefore, the Gutenberg corpus </span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.297.1">within the NLTK is based on public domain texts, making it a publicly available dataset. </span><span class="koboSpan" id="kobo.297.2">It can be used for various NLP tasks, such as text classification, language modeling, and information retrieval, without any commercial restrictions or</span><a id="_idIndexMarker519"/> <span class="No-Break"><span class="koboSpan" id="kobo.298.1">licensing requirements:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.299.1">
import nltk
from nltk.corpus import gutenberg
import string
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns</span></pre> <p><span class="koboSpan" id="kobo.300.1">Let’s download the Gutenberg corpus using the </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">NLTK library:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.302.1">
# Download the Gutenberg corpus
nltk.download('gutenberg')</span></pre> <p><span class="koboSpan" id="kobo.303.1">Let’s load the text data into a Pandas DataFrame by iterating the fields from Gutenberg and appending documents to the list data. </span><span class="koboSpan" id="kobo.303.2">Then we’ll convert the list data to dataframe, </span><strong class="source-inline"><span class="koboSpan" id="kobo.304.1">df</span></strong><span class="koboSpan" id="kobo.305.1">, with a single column, </span><strong class="source-inline"><span class="koboSpan" id="kobo.306.1">text</span></strong><span class="koboSpan" id="kobo.307.1">, to store </span><span class="No-Break"><span class="koboSpan" id="kobo.308.1">the document:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.309.1">
# Load the data
data = []
for file_id in gutenberg.fileids():
    document = ' '.join(gutenberg.words(file_id))
    data.append(document)
df = pd.DataFrame(data, columns=['text'])
# View the first few rows of the data
print(df.head())</span></pre> <p><span class="koboSpan" id="kobo.310.1">Let’s </span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.311.1">check the dataframe’s size by calling the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.312.1">shape</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.313.1"> function:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.314.1">
# Check the size of the dataset
print("Dataset size:", df.shape)</span></pre> <p><span class="koboSpan" id="kobo.315.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.316.1">the output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer087">
<span class="koboSpan" id="kobo.317.1"><img alt="Figure 7.1 – The first few rows of data" src="image/B18944_07_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.318.1">Figure 7.1 – The first few rows of data</span></p>
<p><span class="koboSpan" id="kobo.319.1">Let’s check the length of each document by calling the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.320.1">apply</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.321.1"> function:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.322.1">
# Check the length of each document
df['text_length'] = df['text'].apply(len)
 Let us plot the histogram plot of the 'text_length' column using seaborn library sns.
</span><span class="koboSpan" id="kobo.322.2"># Visualize the distribution of document lengths
plt.figure(figsize=(8, 6))
sns.distplot(df['text_length'], bins=50, kde=False, color='blue')
plt.title('Distribution of Text Lengths')
plt.xlabel('Text Length')
plt.ylabel('Count')
plt.show()</span></pre> <p><span class="koboSpan" id="kobo.323.1">Here’s</span><a id="_idIndexMarker521"/> <span class="No-Break"><span class="koboSpan" id="kobo.324.1">the output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer088">
<span class="koboSpan" id="kobo.325.1"><img alt="Figure 7.2 – Distribution of document length" src="image/B18944_07_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.326.1">Figure 7.2 – Distribution of document length</span></p>
<p><span class="koboSpan" id="kobo.327.1">In text analysis, removing stopwords and punctuation is one of the most common tasks because stopwords do not tell us anything about </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">the text:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.329.1">
# Remove punctuation and stop words
def remove_punctuation(text):
    return text.translate(str.maketrans('', '', string.punctuation))</span></pre> <p><span class="koboSpan" id="kobo.330.1">We will use the stopwords list from the </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">NLTK corpus:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.332.1">
def remove_stopwords(text):
    stopwords_list = nltk.corpus.stopwords.words('english')
    return " ".join([word for word in text.split() if \
        word.lower() not in stopwords_list])
df['text_clean'] = df['text'].apply(remove_punctuation)
df['text_clean'] = df['text_clean'].apply(remove_stopwords)</span></pre> <p><span class="koboSpan" id="kobo.333.1">Now let’s </span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.334.1">count the frequency of words in the clean text using the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.335.1">value_counts</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.336.1"> function:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.337.1">
# Count the frequency of each word
word_freq = pd.Series(np.concatenate([x.split() for x in \
    df['text_clean']])).value_counts()</span></pre> <p><span class="koboSpan" id="kobo.338.1">Finally, plot a bar chart to visualize the most </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">frequent words:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.340.1">
# Visualize the most frequent words
plt.figure(figsize=(12, 8))
word_freq[:20].plot(kind='bar', color='blue')
plt.title('Most Frequent Words')
plt.xlabel('Word')
plt.ylabel('Frequency')
plt.show()</span></pre> <p><span class="koboSpan" id="kobo.341.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">the output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer089">
<span class="koboSpan" id="kobo.343.1"><img alt="Figure 7.3 – Most frequent words" src="image/B18944_07_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.344.1">Figure 7.3 – Most frequent words</span></p>
<p><span class="koboSpan" id="kobo.345.1">In this </span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.346.1">code, we first downloaded the Gutenberg corpus using the NLTK library. </span><span class="koboSpan" id="kobo.346.2">We then loaded the text data into a Pandas DataFrame and performed some initial checks on the size and structure of </span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">the dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.348.1">Next, we calculated the length of each document and visualized the distribution of document lengths using a histogram. </span><span class="koboSpan" id="kobo.348.2">We then removed punctuation and stop words from the text data and calculated the frequency of each word. </span><span class="koboSpan" id="kobo.348.3">We visualized the most frequent words using a </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">bar chart.</span></span></p>
<p><span class="koboSpan" id="kobo.350.1">Note that this code is just a basic example of EDA on text data, and you may need to modify it to suit your </span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.351.1">specific dataset and research question. </span><span class="koboSpan" id="kobo.351.2">Now we have clean </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">text data.</span></span></p>
<p><span class="koboSpan" id="kobo.353.1">Let’s see how to use Generative AI to label text data in the </span><span class="No-Break"><span class="koboSpan" id="kobo.354.1">following section.</span></span></p>
<h1 id="_idParaDest-155"><a id="_idTextAnchor160"/><span class="koboSpan" id="kobo.355.1">Exploring Generative AI and OpenAI for labeling text data</span></h1>
<p><span class="koboSpan" id="kobo.356.1">Generative AI </span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.357.1">refers to a category of artificial intelligence</span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.358.1"> that involves training models to generate new content or data based on patterns and information present in the training data. </span><span class="koboSpan" id="kobo.358.2">OpenAI is a prominent organization that has developed and released powerful generative models for various NLP tasks. </span><span class="koboSpan" id="kobo.358.3">One of the notable models is GPT, such as GPT-3, GPT-3.5, and GPT-4. </span><span class="koboSpan" id="kobo.358.4">These models have been influential in the fields of text data labeling </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">and classification.</span></span></p>
<p><span class="koboSpan" id="kobo.360.1">Generative AI focuses on training models to generate new data instances that resemble existing examples. </span><span class="koboSpan" id="kobo.360.2">It is often used for tasks such as text generation, image synthesis, and more. </span><span class="koboSpan" id="kobo.360.3">Generative models are trained on large datasets to learn underlying patterns, allowing them to generate coherent and contextually relevant content. </span><span class="koboSpan" id="kobo.360.4">In text-related tasks, generative AI can be applied to text completion, summarization, question answering, and even creative writing. </span><span class="koboSpan" id="kobo.360.5">Let’s take a look at some key concepts that will help us with labeling </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">text data.</span></span></p>
<h2 id="_idParaDest-156"><a id="_idTextAnchor161"/><span class="koboSpan" id="kobo.362.1">GPT models by OpenAI</span></h2>
<p><span class="koboSpan" id="kobo.363.1">OpenAI has developed </span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.364.1">a series of sophisticated language models, with GPT-4 being among the most advanced. </span><span class="koboSpan" id="kobo.364.2">These models undergo pre-training on diverse datasets, enabling them to excel in various natural language understanding and </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">generation tasks.</span></span></p>
<h2 id="_idParaDest-157"><a id="_idTextAnchor162"/><span class="koboSpan" id="kobo.366.1">Zero-shot learning capabilities</span></h2>
<p><span class="koboSpan" id="kobo.367.1">GPT models are renowned for </span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.368.1">their zero-shot learning capabilities, enabling them to make predictions or generate content for tasks they were not explicitly trained on. </span><span class="koboSpan" id="kobo.368.2">This versatility enhances their applicability across </span><span class="No-Break"><span class="koboSpan" id="kobo.369.1">diverse domains.</span></span></p>
<h2 id="_idParaDest-158"><a id="_idTextAnchor163"/><span class="koboSpan" id="kobo.370.1">Text classification with OpenAI models</span></h2>
<p><span class="koboSpan" id="kobo.371.1">Leveraging the language understanding and </span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.372.1">generation capabilities of OpenAI models, they can be effectively utilized for text classification tasks. </span><span class="koboSpan" id="kobo.372.2">This includes sentiment analysis, topic categorization, and other </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">classification-based applications.</span></span></p>
<h2 id="_idParaDest-159"><a id="_idTextAnchor164"/><span class="koboSpan" id="kobo.374.1">Data labeling assistance</span></h2>
<p><span class="koboSpan" id="kobo.375.1">Although GPT models are</span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.376.1"> not specifically designed for traditional data labeling tasks, they can offer assistance in generating labeled data. </span><span class="koboSpan" id="kobo.376.2">This can be achieved through natural language instructions or by providing context that aids in making </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">labeling decisions.</span></span></p>
<h2 id="_idParaDest-160"><a id="_idTextAnchor165"/><span class="koboSpan" id="kobo.378.1">OpenAI API overview</span></h2>
<p><span class="koboSpan" id="kobo.379.1">The OpenAI API is a </span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.380.1">service provided by OpenAI that allows users to access their advanced language models through an API. </span><span class="koboSpan" id="kobo.380.2">It serves as a gateway for integrating OpenAI’s language capabilities into </span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">various applications.</span></span></p>
<p><span class="koboSpan" id="kobo.382.1">Let’s see the pros and cons of OpenAI’s </span><span class="No-Break"><span class="koboSpan" id="kobo.383.1">GPT models:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.384.1">Pros:</span></span><ul><li><span class="koboSpan" id="kobo.385.1">Versatility: OpenAI’s</span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.386.1"> GPT models are versatile and can be adapted for various text-related tasks, including data labeling </span><span class="No-Break"><span class="koboSpan" id="kobo.387.1">and classification</span></span></li><li><span class="koboSpan" id="kobo.388.1">Large scale: These models are trained on massive amounts of data, enabling them to capture intricate patterns and nuances present in </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">natural language</span></span></li></ul></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.390.1">Cons:</span></span><ul><li><span class="koboSpan" id="kobo.391.1">Interpretability: The </span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.392.1">generated content might lack interpretability, making it challenging to understand the model’s </span><span class="No-Break"><span class="koboSpan" id="kobo.393.1">decision-making process</span></span></li><li><span class="koboSpan" id="kobo.394.1">Resource intensive: Training and using large generative models such as GPT-4 can be </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">computationally </span></span><span class="No-Break"><a id="_idIndexMarker534"/></span><span class="No-Break"><span class="koboSpan" id="kobo.396.1">expensive</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.397.1">In summary, OpenAI’s generative models, particularly GPT-3 , GPT-3.5, and GPT-4, have made significant contributions to the field of text data processing, and they can be used creatively for tasks such as data labeling and classification by utilizing their language-understanding capabilities. </span><span class="koboSpan" id="kobo.397.2">However, careful consideration and evaluation are needed, especially regarding ethical concerns and potential bias in </span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">generated content.</span></span></p>
<p><span class="koboSpan" id="kobo.399.1">In the realm of language processing, text classification serves to categorize documents based on their content. </span><span class="koboSpan" id="kobo.399.2">Traditionally, this task relied on labeled training data; however, advanced models such as OpenAI’s GPT have revolutionized the process by autonomously generating labels with the assistance of explicit </span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.400.1">instructions </span><span class="No-Break"><span class="koboSpan" id="kobo.401.1">or </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.402.1">prompts</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.403.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.404.1">Exploring text data labeling with </span><strong class="bold"><span class="koboSpan" id="kobo.405.1">Azure OpenAI</span></strong><span class="koboSpan" id="kobo.406.1">, a </span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.407.1">collaborative initiative within Microsoft Azure’s cloud, unlocks the potential of powerful language models. </span><span class="koboSpan" id="kobo.407.2">This section acts as a guide, facilitating efficient text data labeling by harnessing the capabilities of Generative AI and OpenAI models, and providing users with custom tools for typical tasks in text </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">data analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.409.1">Let’s take a look at some use cases with Python and Azure OpenAI for text </span><span class="No-Break"><span class="koboSpan" id="kobo.410.1">data labeling.</span></span></p>
<h2 id="_idParaDest-161"><a id="_idTextAnchor166"/><span class="koboSpan" id="kobo.411.1">Use case 1 – summarizing the text</span></h2>
<p><span class="koboSpan" id="kobo.412.1">Summarization</span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.413.1"> is a crucial NLP task that involves condensing a piece of text while retaining</span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.414.1"> its essential information and main ideas. </span><span class="koboSpan" id="kobo.414.2">In the context of Azure OpenAI, the following code exemplifies the application of summarization using the GPT-3.5-turbo model deployed on the </span><span class="No-Break"><span class="koboSpan" id="kobo.415.1">Azure platform.</span></span></p>
<p><span class="koboSpan" id="kobo.416.1">The following code example begins by setting the necessary environment variables for the Azure OpenAI API, including the API key and endpoint. </span><span class="koboSpan" id="kobo.416.2">The OpenAI API is then configured with the deployment name of the model, allowing the code to interact with the specific </span><span class="No-Break"><span class="koboSpan" id="kobo.417.1">GPT-3.5-turbo instance.</span></span></p>
<p><span class="koboSpan" id="kobo.418.1">The input text, which is a detailed description of Dachepalli, a town in Andhra Pradesh, India, is provided for summarization. </span><span class="koboSpan" id="kobo.418.2">The code utilizes the Azure OpenAI Completion API to generate a summary, employing parameters such as temperature, max tokens, and penalties for frequency </span><span class="No-Break"><span class="koboSpan" id="kobo.419.1">and presence.</span></span></p>
<p><span class="koboSpan" id="kobo.420.1">The output of the code includes the generated summary, showcasing the main ideas extracted from the input text. </span><span class="koboSpan" id="kobo.420.2">The summarized content emphasizes key aspects such as the author’s connection to Dachepalli, the town’s features, and notable historical events. </span><span class="koboSpan" id="kobo.420.3">This example demonstrates how Azure OpenAI can effectively summarize information, providing concise and </span><span class="No-Break"><span class="koboSpan" id="kobo.421.1">informative outputs.</span></span></p>
<p><span class="koboSpan" id="kobo.422.1">Let’s start by </span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.423.1">importing the required libraries and getting the configuration values (the Azure OpenAI key </span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.424.1">and endpoint, API version, and the GPT model deployment name) that we have </span><span class="No-Break"><span class="koboSpan" id="kobo.425.1">set already:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.426.1">
import os
openai.api.key=os.getenv("AZURE_OPENAI_KEY")
Openai.api_base=os.getenv("AZURE_OPENAI_ENDPOINT")
Openai.api_type='azure'
Openai.api_version='2023-5-15' # this might change in the future
#this will correspond to the custom name you choose for your deployment when you deployed a model.
</span><span class="koboSpan" id="kobo.426.2">model_deployment_name = 'your_azure_openai_model_name'
# Set the input text
text = "</span><strong class="bold"><span class="koboSpan" id="kobo.427.1">create a summary of below text and provide main idea.\n\n Dachepalli is popular town in palnadu district in Andhra pradesh, India.I love dachepalli because i born and brought up at Dachepalli. </span><span class="koboSpan" id="kobo.427.2">I studied at Dachepalli zph school and got school first and my name was written on school toppers board at high school.My father worked in the same high school as hindi pandit for 20 years.The famous palnadu battle has took place near Naguleru river of Karempudi which flows across Dachepalli.It has lime mines and number of cement factories around Dachepalli.The Nadikudi railway junction connect Dachepalli to Hyderbad and Guntur. </span><span class="koboSpan" id="kobo.427.3">being born in Dachepalli and studied at Dachepalli high school, I love Dachepalli.</span></strong><span class="koboSpan" id="kobo.428.1">"
response = openai.Completion.create(
    engine=model_deployment_name,
    prompt=text,
    temperature=0,
    max_tokens=118,
    top_p=1,
    frequency_penalty=0,
    presence_penalty=0,
    stop=None)</span></pre> <p><span class="koboSpan" id="kobo.429.1">Let’s </span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.430.1">understand </span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.431.1">the parameters used in this OpenAI </span><span class="No-Break"><span class="koboSpan" id="kobo.432.1">completion API.</span></span></p>
<p><span class="koboSpan" id="kobo.433.1">OpenAI’s parameters control the behavior of the language model during text generation. </span><span class="koboSpan" id="kobo.433.2">Here’s a brief description of the </span><span class="No-Break"><span class="koboSpan" id="kobo.434.1">provided parameters:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.435.1">Temperature (</span><strong class="source-inline"><span class="koboSpan" id="kobo.436.1">temperature=0</span></strong><span class="koboSpan" id="kobo.437.1">): It determines the randomness of the model’s output. </span><span class="koboSpan" id="kobo.437.2">A high value (e.g., </span><strong class="source-inline"><span class="koboSpan" id="kobo.438.1">0.8</span></strong><span class="koboSpan" id="kobo.439.1">) makes the output more diverse, while a low value (e.g., </span><strong class="source-inline"><span class="koboSpan" id="kobo.440.1">0.2</span></strong><span class="koboSpan" id="kobo.441.1">) makes it </span><span class="No-Break"><span class="koboSpan" id="kobo.442.1">more deterministic.</span></span></li>
<li><span class="koboSpan" id="kobo.443.1">Max tokens (</span><strong class="source-inline"><span class="koboSpan" id="kobo.444.1">max_tokens=118</span></strong><span class="koboSpan" id="kobo.445.1">): This specifies the maximum number of tokens (words or characters) to generate in the output. </span><span class="koboSpan" id="kobo.445.2">It’s useful for limiting </span><span class="No-Break"><span class="koboSpan" id="kobo.446.1">response length.</span></span></li>
<li><span class="koboSpan" id="kobo.447.1">Top P (</span><strong class="source-inline"><span class="koboSpan" id="kobo.448.1">top_p=1</span></strong><span class="koboSpan" id="kobo.449.1">): Also known as nucleus sampling, it controls the diversity of the generated output. </span><span class="koboSpan" id="kobo.449.2">Setting it to </span><strong class="source-inline"><span class="koboSpan" id="kobo.450.1">1</span></strong><span class="koboSpan" id="kobo.451.1"> ensures that only the top probability tokens are considered </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">during sampling.</span></span></li>
<li><span class="koboSpan" id="kobo.453.1">Frequency penalty (</span><strong class="source-inline"><span class="koboSpan" id="kobo.454.1">frequency_penalty=0</span></strong><span class="koboSpan" id="kobo.455.1">): This discourages the repetition of specific tokens in the output. </span><span class="koboSpan" id="kobo.455.2">A non-zero value penalizes the model for choosing frequently </span><span class="No-Break"><span class="koboSpan" id="kobo.456.1">occurring tokens.</span></span></li>
<li><span class="koboSpan" id="kobo.457.1">Presence Penalty (</span><strong class="source-inline"><span class="koboSpan" id="kobo.458.1">presence_penalty=0</span></strong><span class="koboSpan" id="kobo.459.1">): Similar to frequency penalty, presence penalty discourages the repetition of entire phrases or concepts, promoting more </span><span class="No-Break"><span class="koboSpan" id="kobo.460.1">diverse responses.</span></span></li>
<li><span class="koboSpan" id="kobo.461.1">Stop (</span><strong class="source-inline"><span class="koboSpan" id="kobo.462.1">stop=None</span></strong><span class="koboSpan" id="kobo.463.1">): This allows users to specify a custom stopping criterion for generation. </span><span class="koboSpan" id="kobo.463.2">When the model encounters the specified token, it stops generating </span><span class="No-Break"><span class="koboSpan" id="kobo.464.1">further content.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.465.1">These</span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.466.1"> parameters provide users with fine-grained control over the generation process, allowing customization of the model’s output based on factors such as randomness, length, diversity, and repetition. </span><span class="koboSpan" id="kobo.466.2">Adjusting these parameters enables users to tailor the language </span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.467.1">model’s behavior to meet specific requirements in various applications, such as chatbots, content generation, </span><span class="No-Break"><span class="koboSpan" id="kobo.468.1">and more:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.469.1">
# Print the generated summary
print("Generated summary:", summary.choices[0].text.strip())</span></pre> <p><span class="koboSpan" id="kobo.470.1">Running this code will output the </span><span class="No-Break"><span class="koboSpan" id="kobo.471.1">following summary:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.472.1">
Generated summary: Main Idea: The author loves Dachepalli because he was born and brought up there and studied at Dachepalli high school. </span><span class="koboSpan" id="kobo.472.2">The town is located in Palnadu district in Andhra Pradesh, India and is known for its lime mines and cement factories. </span><span class="koboSpan" id="kobo.472.3">The Nadikudi railway junction connects Dachepalli to Hyderabad and Guntur. </span><span class="koboSpan" id="kobo.472.4">The famous Palnadu battle took place near Naguleru river of Karempudi which flows across Dachepalli. </span><span class="koboSpan" id="kobo.472.5">The author's father worked in the same high school as a Hindi pandit for 20 years.</span></pre> <p><span class="koboSpan" id="kobo.473.1">We have seen</span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.474.1"> how to </span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.475.1">generate a summary using the OpenAI GPT-3.5 model. </span><span class="koboSpan" id="kobo.475.2">Now let’s see how to generate the topic for news articles using OpenAI’s </span><span class="No-Break"><span class="koboSpan" id="kobo.476.1">GPT model.</span></span></p>
<h2 id="_idParaDest-162"><a id="_idTextAnchor167"/><span class="koboSpan" id="kobo.477.1">Use case 2 – topic generation for news articles</span></h2>
<p><span class="koboSpan" id="kobo.478.1">Let’s explore generating topic names for news articles using a generative model, specifically, </span><span class="No-Break"><span class="koboSpan" id="kobo.479.1">Azure OpenAI.</span></span></p>
<p><span class="koboSpan" id="kobo.480.1">Topic generation</span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.481.1"> is a powerful application of NLP that involves creating relevant and</span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.482.1"> coherent content based on a given prompt. </span><span class="koboSpan" id="kobo.482.2">In the context of Azure OpenAI prompts, the ability to generate topics is demonstrated using a news headline </span><span class="No-Break"><span class="koboSpan" id="kobo.483.1">classification example.</span></span></p>
<p><span class="koboSpan" id="kobo.484.1">In this code snippet, the task is to categorize a news headline into one of the predefined categories, which are Business, Tech, Politics, Sport, and Entertainment. </span><span class="koboSpan" id="kobo.484.2">The news headline, provided as input, is </span><em class="italic"><span class="koboSpan" id="kobo.485.1">“Trump is ready to contest in Nov 2024 elections.”</span></em><span class="koboSpan" id="kobo.486.1"> The code uses the Azure OpenAI API to generate a response that predicts the most appropriate category for the </span><span class="No-Break"><span class="koboSpan" id="kobo.487.1">given headline.</span></span></p>
<p><span class="koboSpan" id="kobo.488.1">The completion engine is configured with specific parameters, such as temperature, max tokens, and penalties for frequency and presence. </span><span class="koboSpan" id="kobo.488.2">After generating the response, the code extracts and prints the predicted category from </span><span class="No-Break"><span class="koboSpan" id="kobo.489.1">the output.</span></span></p>
<p><span class="koboSpan" id="kobo.490.1">This example showcases how Azure OpenAI prompts can be utilized for the automatic categorization of news headlines, demonstrating the versatility and effectiveness of NLP in </span><span class="No-Break"><span class="koboSpan" id="kobo.491.1">topic-generation tasks:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.492.1">
news_headline="</span><strong class="bold"><span class="koboSpan" id="kobo.493.1">Label the following news headline into 1 of the following categories: Business, Tech, Politics, Sport, Entertainment\n\n Headline 1: Trump is ready to contest in nov 2024 elections\nCategory:</span></strong><span class="koboSpan" id="kobo.494.1">",
response = openai.Completion.create(
    engine=model_deployment_name,
    prompt= news_headline,
    temperature=0,
    max_tokens=118,
    top_p=1,
    frequency_penalty=0,
    presence_penalty=0,
    stop=None)
index_of_newline=response.choice[0].text.find('\n')
print('category:',response.choices[0].text[:index_of_newline])</span></pre> <p><span class="koboSpan" id="kobo.495.1">Here’s</span><a id="_idIndexMarker549"/> <span class="No-Break"><span class="koboSpan" id="kobo.496.1">the </span></span><span class="No-Break"><a id="_idIndexMarker550"/></span><span class="No-Break"><span class="koboSpan" id="kobo.497.1">output:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.498.1">
category: Politics</span></pre> <h2 id="_idParaDest-163"><a id="_idTextAnchor168"/><span class="koboSpan" id="kobo.499.1">Use case 3 – classification of customer queries using the user-defined categories and sub-categories</span></h2>
<p><span class="koboSpan" id="kobo.500.1">Let’s see how to classify the customer queries into user-defined categories and sub-categories</span><a id="_idIndexMarker551"/><span class="koboSpan" id="kobo.501.1"> using </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.502.1">Azure OpenAI</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.503.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.504.1">Text classification</span><a id="_idIndexMarker552"/><span class="koboSpan" id="kobo.505.1"> is a fundamental NLP task that involves assigning predefined </span><a id="_idIndexMarker553"/><span class="koboSpan" id="kobo.506.1">categories to textual input. </span><span class="koboSpan" id="kobo.506.2">In the provided code, a customer support system utilizes text classification to categorize customer queries related to their orders. </span><span class="koboSpan" id="kobo.506.3">The system employs user-defined primary and secondary categories, each with </span><span class="No-Break"><span class="koboSpan" id="kobo.507.1">specific sub-categories.</span></span></p>
<p><span class="koboSpan" id="kobo.508.1">The system message serves as a guide for the classification task, outlining the primary categories (Order Status, Product Inquiries, Shipping and Delivery, and Payment Assistance) and their corresponding secondary categories. </span><span class="koboSpan" id="kobo.508.2">The primary and secondary categories are structured to capture various aspects of customer queries, such as tracking information, product availability, and </span><span class="No-Break"><span class="koboSpan" id="kobo.509.1">payment confirmation.</span></span></p>
<p><span class="koboSpan" id="kobo.510.1">For example, when a user submits a query to cancel an order, the code uses the OpenAI ChatCompletion API to generate a response. </span><span class="koboSpan" id="kobo.510.2">The output includes a JSON-formatted response indicating the primary and secondary categories assigned to the user’s query. </span><span class="koboSpan" id="kobo.510.3">In this case, the primary category is Order Status, and the secondary category is Order Modification </span><span class="No-Break"><span class="koboSpan" id="kobo.511.1">or Cancellation.</span></span></p>
<p><span class="koboSpan" id="kobo.512.1">This example </span><a id="_idIndexMarker554"/><span class="koboSpan" id="kobo.513.1">demonstrates how text classification can be applied in a customer</span><a id="_idIndexMarker555"/><span class="koboSpan" id="kobo.514.1"> support context, allowing for the efficient handling and categorization of customer queries based on predefined categories. </span><span class="koboSpan" id="kobo.514.2">The system provides a structured approach to address diverse aspects of order-related inquiries, enhancing the overall customer </span><span class="No-Break"><span class="koboSpan" id="kobo.515.1">support experience:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.516.1">
system_message = f"""
</span><strong class="bold"><span class="koboSpan" id="kobo.517.1">Welcome to Customer Order Support!</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.518.1">You will receive customer queries related to their orders, each delimited by {delimiter} characters.</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.519.1">Your task is to classify each query into a primary and secondary category.</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.520.1">Provide your response in JSON format with the keys: "primary" and "secondary."</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.521.1">Primary Categories:</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.522.1">1. </span><span class="koboSpan" id="kobo.522.2">Order Status</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.523.1">2. </span><span class="koboSpan" id="kobo.523.2">Product Inquiries</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.524.1">3. </span><span class="koboSpan" id="kobo.524.2">Shipping and Delivery</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.525.1">4. </span><span class="koboSpan" id="kobo.525.2">Payment Assistance</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.526.1">Order Status Secondary Categories:</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.527.1">- Tracking Information</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.528.1">- Order Confirmation</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.529.1">- Order Modification or Cancellation</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.530.1">- Refund Status</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.531.1">Product Inquiries Secondary Categories:</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.532.1">- Product Availability</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.533.1">- Size and Color Options</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.534.1">- Product Specifications</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.535.1">- Return and Exchange Policies</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.536.1">Shipping and Delivery Secondary Categories:</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.537.1">- Delivery Timeframe</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.538.1">- Shipping Methods</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.539.1">- Address Changes</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.540.1">- Lost or Delayed Shipments</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.541.1">Payment Assistance Secondary Categories:</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.542.1">- Payment Confirmation</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.543.1">- Refund Process</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.544.1">- Payment Errors</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.545.1">- Billing Inquiries</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.546.1">Please review each query and provide the appropriate primary and secondary category in your response.</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.547.1">Thank you for assisting our customers with their orders!</span></strong><span class="koboSpan" id="kobo.548.1">"""
user_message=f"""\
 I want to cancel my order """
response = openai.ChatCompletion.create(
    engine=deployment_name, # engine = "deployment_name".
</span><span class="koboSpan" id="kobo.548.2">    messages=[
        {"role": "system", "content": system_message},
        {"role": "user", "content": f"{delimiter}{user_message}
        {delimiter}"},],
    temperature=0,
    max_tokens=60,
    top_p=1,
    frequency_penalty=0,
    presence_penalty=0,
    stop=None
)
print(response)
print(response['choices'][0]['message']['content'])</span></pre> <p><span class="koboSpan" id="kobo.549.1">Here’s </span><a id="_idIndexMarker556"/><span class="No-Break"><span class="koboSpan" id="kobo.550.1">the</span></span><span class="No-Break"><a id="_idIndexMarker557"/></span><span class="No-Break"><span class="koboSpan" id="kobo.551.1"> output:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.552.1">
{ "id": "chatcmpl-8eEc86GxAO4BePuRepvve9XhTQZfa", "object": "chat.completion", "created": 1704599988, "model": "gpt-35-turbo", "choices": [ { "finish_reason": "stop", "index": 0, "message": { "role": "assistant", "content": "{\n \"primary\": \"Order Status\",\n \"secondary\": \"Order Modification or Cancellation\"\n}" } } ], "usage": { "prompt_tokens": 232, "completion_tokens": 21, "total_tokens": 253 } } { "primary": "Order Status", "secondary": "Order Modification or Cancellation" }</span></pre> <h2 id="_idParaDest-164"><a id="_idTextAnchor169"/><span class="koboSpan" id="kobo.553.1">Use case 4 – information retrieval using entity extraction</span></h2>
<p><span class="koboSpan" id="kobo.554.1">Let us see how to extract the entity names from the text data using </span><span class="No-Break"><span class="koboSpan" id="kobo.555.1">Azure OpenAI.</span></span></p>
<p><span class="koboSpan" id="kobo.556.1">Entity extraction</span><a id="_idIndexMarker558"/><span class="koboSpan" id="kobo.557.1"> is a vital aspect of NLP, involving the identification </span><a id="_idIndexMarker559"/><span class="koboSpan" id="kobo.558.1">and extraction of specific entities, such as names, organizations, locations, and contact numbers, from a given text. </span><span class="koboSpan" id="kobo.558.2">In the presented code snippet, the task is to identify and extract people’s names, organization names, geographical locations, and contact numbers from various </span><span class="No-Break"><span class="koboSpan" id="kobo.559.1">text passages.</span></span></p>
<p><span class="koboSpan" id="kobo.560.1">The prompt provides clear instructions for the entity extraction task, specifying the entities of interest and their corresponding categories. </span><span class="koboSpan" id="kobo.560.2">It includes examples that illustrate how to extract information from different texts, showcasing the versatility of the entity </span><span class="No-Break"><span class="koboSpan" id="kobo.561.1">extraction process.</span></span></p>
<p><span class="koboSpan" id="kobo.562.1">The code utilizes the OpenAI API to generate responses that include extracted entities, such as people’s names, organization names, locations, and contact numbers, from the given text passages. </span><span class="koboSpan" id="kobo.562.2">The output is structured in a JSON format, making it easy to parse and integrate the extracted entities into further processing </span><span class="No-Break"><span class="koboSpan" id="kobo.563.1">or analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.564.1">This example demonstrates the practical application of entity extraction for extracting relevant information from diverse textual data, showcasing its potential in various domains, such as customer relationship management, information retrieval, and </span><span class="No-Break"><span class="koboSpan" id="kobo.565.1">data analysis:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.566.1">
response = openai.Completion.create(
    engine="gpt3.5 deployment name",
    prompt = </span><strong class="bold"><span class="koboSpan" id="kobo.567.1">"Identify the individual's name, organization, geographical location, and contact number in the following text.\n\nHello. </span><span class="koboSpan" id="kobo.567.2">I'm Sarah Johnson, and I'm reaching out on behalf of XYZ Tech Solutions based in Austin, Texas. </span><span class="koboSpan" id="kobo.567.3">Our team believes that our innovative products could greatly benefit your business. </span><span class="koboSpan" id="kobo.567.4">Please feel free to contact me at (555) 123-4567 at your convenience, and we can discuss how our solutions align with your needs."</span></strong><span class="koboSpan" id="kobo.568.1">,
    temperature=0.2,
    max_tokens=150,
    top_p=1,
    frequency_penalty=0,
    presence_penalty=0,
    stop=None)
print(response['choices'])</span></pre> <p><span class="koboSpan" id="kobo.569.1">Here’s</span><a id="_idIndexMarker560"/> <span class="No-Break"><span class="koboSpan" id="kobo.570.1">the </span></span><span class="No-Break"><a id="_idIndexMarker561"/></span><span class="No-Break"><span class="koboSpan" id="kobo.571.1">output:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.572.1">
[&lt;OpenAIObject at 0x215d2c40770&gt; JSON: {
    "text": " Thank you for your time, and I look forward to hearing from you soon. </span><span class="koboSpan" id="kobo.572.2">\n\nName: Sarah Johnson\nOrganization: XYZ Tech Solutions\nGeographical location: Austin, Texas\nContact number: (555) 123-4567",
    "index": 0,
    "finish_reason": "stop",
    "logprobs": null,
    "content_filter_results": {
    "hate": {
        "filtered": false,
        "severity": "safe"
    },
    "self_harm": {
        "filtered": false,
        "severity": "safe"
    },
    "sexual": {
        "filtered": false,
        "severity": "safe"
    },
    "violence": {
        "filtered": false,
        "severity": "safe"
    }
}
}]</span></pre> <p><span class="koboSpan" id="kobo.573.1">Now let’s</span><a id="_idIndexMarker562"/><span class="koboSpan" id="kobo.574.1"> extract the required information name, organization, location, and contact information </span><a id="_idIndexMarker563"/><span class="koboSpan" id="kobo.575.1">from the output JSON, </span><span class="No-Break"><span class="koboSpan" id="kobo.576.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.577.1">
import json
# Parse JSON
json_data = response['choices']
# Extract information
# Extracting information from the JSON object
for entry in json_data:
    text = entry.get("text", "")
    # Extracting information using string manipulation or regular expressions
    name = text.split("Name:")[1].split("\n")[0].strip()
    organization = text.split("Organization:")[1].split("\n")[0].strip()
    location = text.split("Geographical location:")[1].split("\n")[0].strip()
    contact_number = text.split("Contact number:")[1].split("\n")[0].strip()
    # Print the extracted information
    print("Name:", name)
    print("Organization:", organization)
    print("Location:", location)
    print("Contact Number:", contact_number)</span></pre> <p><span class="koboSpan" id="kobo.578.1">Here’s</span><a id="_idIndexMarker564"/> <span class="No-Break"><span class="koboSpan" id="kobo.579.1">the </span></span><span class="No-Break"><a id="_idIndexMarker565"/></span><span class="No-Break"><span class="koboSpan" id="kobo.580.1">output:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.581.1">
Name: Sarah Johnson Organization: XYZ Tech Solutions Location: Austin, Texas Contact Number: (555) 123-4567</span></pre> <h2 id="_idParaDest-165"><a id="_idTextAnchor170"/><span class="koboSpan" id="kobo.582.1">Use case 5 – aspect-based sentiment analysis</span></h2>
<p><span class="koboSpan" id="kobo.583.1">Sentiment </span><a id="_idIndexMarker566"/><span class="koboSpan" id="kobo.584.1">aspect analysis</span><a id="_idIndexMarker567"/><span class="koboSpan" id="kobo.585.1"> is a sophisticated NLP task that involves evaluating the sentiment expressed towards specific aspects or features within a given text. </span><span class="koboSpan" id="kobo.585.2">In the provided code snippet, aspect-based sentiment analysis is conducted on product reviews, aiming to assess both the overall sentiment of the reviews and the sentiment polarity associated with individual </span><span class="No-Break"><span class="koboSpan" id="kobo.586.1">aspects mentioned.</span></span></p>
<p><span class="koboSpan" id="kobo.587.1">The</span><a id="_idIndexMarker568"/><span class="koboSpan" id="kobo.588.1"> prompt</span><a id="_idIndexMarker569"/><span class="koboSpan" id="kobo.589.1"> outlines the objectives of the sentiment analysis task, which include providing an overall sentiment score for each review on a scale from 0 to 5, assigning sentiment polarity scores between 0 and 5 for each aspect, and identifying the top positive and </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">negative aspects.</span></span></p>
<p><span class="koboSpan" id="kobo.591.1">The code processes multiple product reviews, extracting sentiments associated with aspects such as camera quality, battery life, design, speaker quality, performance, keyboard, display, trackpad responsiveness, sound quality, touch controls, graphics, load times, online community, subscription fee, </span><span class="No-Break"><span class="koboSpan" id="kobo.592.1">and controller.</span></span></p>
<p><span class="koboSpan" id="kobo.593.1">The output includes comprehensive sentiment scores, polarity scores, and the identification of the most positively and negatively rated aspects in each review. </span><span class="koboSpan" id="kobo.593.2">This example illustrates how aspect-based sentiment analysis can provide detailed insights into the nuanced opinions expressed in diverse reviews, assisting businesses in understanding customer sentiments towards specific </span><span class="No-Break"><span class="koboSpan" id="kobo.594.1">product features.</span></span></p>
<p><span class="koboSpan" id="kobo.595.1">Let’s see the code example for aspect-based </span><span class="No-Break"><span class="koboSpan" id="kobo.596.1">sentiment analysis:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.597.1">
response = openai.Completion.create(
    engine="gpt3.5 deployment name",
prompt = </span><strong class="bold"><span class="koboSpan" id="kobo.598.1">"Conduct aspect-based sentiment analysis on the following product reviews:\n Provide an overall sentiment score between 0 and 5 for each review.\n Assign a sentiment polarity score between 0 and 5 for each aspect mentioned. </span><span class="koboSpan" id="kobo.598.2">\n Identify the top positive and negative aspects, if any. </span><span class="koboSpan" id="kobo.598.3">\n Review 1: \n I recently purchased this smartphone, and it has exceeded my expectations! </span><span class="koboSpan" id="kobo.598.4">The camera quality is superb, capturing vivid and detailed photos. </span><span class="koboSpan" id="kobo.598.5">The battery life is impressive, easily lasting a full day with regular use. </span><span class="koboSpan" id="kobo.598.6">The sleek design adds a premium feel to the device. </span><span class="koboSpan" id="kobo.598.7">However, the speaker quality could be improved. </span><span class="koboSpan" id="kobo.598.8">Overall sentiment score: 4.8 \nAspects with sentiment polarity score: \n - Camera: 5 \n - Battery Life: 5 \n - Design: 5 \n - Speaker: 3 \n \n Top positive aspect: Camera \n Top negative aspect: Speaker \n \n Review 2: \n This laptop offers powerful performance and a sleek design. </span><span class="koboSpan" id="kobo.598.9">The keyboard is comfortable for extended typing sessions, and the display is vibrant with accurate colors. </span><span class="koboSpan" id="kobo.598.10">However, the trackpad responsiveness can be inconsistent at times."</span></strong><span class="koboSpan" id="kobo.599.1">,
    temperature=0,
    max_tokens=100,
    top_p=1,
    frequency_penalty=0,
    presence_penalty=0,
    stop=None)
print(response.choices[0].text.strip())</span></pre> <p><span class="koboSpan" id="kobo.600.1">Here’s </span><a id="_idIndexMarker570"/><span class="No-Break"><span class="koboSpan" id="kobo.601.1">the </span></span><span class="No-Break"><a id="_idIndexMarker571"/></span><span class="No-Break"><span class="koboSpan" id="kobo.602.1">output:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.603.1">
Overall sentiment score: 4.5
Aspects with sentiment polarity score:
 - Performance: 5
 - Design: 5
 - Keyboard: 5
 - Display: 5
 - Trackpad: 3
 Top positive aspects: Performance, Design, Keyboard, Display
 Top negative aspect: Trackpad</span></pre> <p><span class="koboSpan" id="kobo.604.1">Next, let’s use the Snorkel API to classify this text data and generate labels by creating rule-based </span><span class="No-Break"><span class="koboSpan" id="kobo.605.1">labeling functions.</span></span></p>
<h1 id="_idParaDest-166"><a id="_idTextAnchor171"/><span class="koboSpan" id="kobo.606.1">Hands-on labeling of text data using the Snorkel API</span></h1>
<p><span class="koboSpan" id="kobo.607.1">In this section, we are going to learn how to label text data using the </span><span class="No-Break"><span class="koboSpan" id="kobo.608.1">Snorkel API.</span></span></p>
<p><span class="koboSpan" id="kobo.609.1">Snorkel</span><a id="_idIndexMarker572"/><span class="koboSpan" id="kobo.610.1"> provides an API for programmatically labeling text data using a small set of ground truth labels that are created by domain experts. </span><span class="koboSpan" id="kobo.610.2">Snorkel, an open source data labeling and training platform, is used by various companies and organizations across different industries, such as Google, Apple, Facebook, IBM, </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1">and SAP.</span></span></p>
<p><span class="koboSpan" id="kobo.612.1">It has unique features that differentiate it from other competitors, especially in the context of weak supervision and programmatically generating labeled data. </span><span class="koboSpan" id="kobo.612.2">Here’s a comparison with some of the </span><span class="No-Break"><span class="koboSpan" id="kobo.613.1">other tools:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.614.1">Weak supervision</span></strong><span class="koboSpan" id="kobo.615.1">: Snorkel excels in scenarios where labeled data is scarce, and manual labeling is expensive. </span><span class="koboSpan" id="kobo.615.2">It allows users to programmatically label large amounts of data using heuristics, patterns, and </span><span class="No-Break"><span class="koboSpan" id="kobo.616.1">external resources.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.617.1">Flexible labeling functions</span></strong><span class="koboSpan" id="kobo.618.1">: Snorkel enables the creation of labeling functions, which are essentially heuristic functions that assign labels to data. </span><span class="koboSpan" id="kobo.618.2">This provides a flexible and scalable way to generate </span><span class="No-Break"><span class="koboSpan" id="kobo.619.1">labeled data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.620.1">Probabilistic labeling</span></strong><span class="koboSpan" id="kobo.621.1">: Snorkel generates probabilistic labels, acknowledging that labeling functions may have varying levels of accuracy. </span><span class="koboSpan" id="kobo.621.2">This probabilistic framework is useful in </span><span class="No-Break"><span class="koboSpan" id="kobo.622.1">downstream tasks.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.623.1">There can be a </span><a id="_idIndexMarker573"/><span class="koboSpan" id="kobo.624.1">learning curve with Snorkel, especially for </span><a id="_idIndexMarker574"/><span class="koboSpan" id="kobo.625.1">users who are new to weak supervision concepts. </span><span class="koboSpan" id="kobo.625.2">Other tools, such as Prodigy and Labelbox, are commercial tools and may involve </span><span class="No-Break"><span class="koboSpan" id="kobo.626.1">licensing costs.</span></span></p>
<p><span class="koboSpan" id="kobo.627.1">When choosing between these tools, the specific requirements of the project, the available budget, and the expertise of the users play crucial roles. </span><span class="koboSpan" id="kobo.627.2">Snorkel stands out when weak supervision and programmatically generated labels are essential for the task at hand. </span><span class="koboSpan" id="kobo.627.3">It’s particularly well suited for scenarios where manual labeling is impractical or cost-prohibitive. </span><span class="koboSpan" id="kobo.627.4">Other tools may be more appropriate based on different use cases, interface preferences, and </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1">integration requirements.</span></span></p>
<p><span class="koboSpan" id="kobo.629.1">We will </span><a id="_idIndexMarker575"/><span class="koboSpan" id="kobo.630.1">create rule-based labeling functions</span><a id="_idIndexMarker576"/><span class="koboSpan" id="kobo.631.1"> using Snorkel and then apply these labeling functions to classify and </span><span class="No-Break"><span class="koboSpan" id="kobo.632.1">label text.</span></span></p>
<p><span class="koboSpan" id="kobo.633.1">We have seen what a labeling function is and how to create labeling functions in </span><a href="B18944_02.xhtml#_idTextAnchor043"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.634.1">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.635.1">. </span><span class="koboSpan" id="kobo.635.2">Let’s recap. </span><span class="koboSpan" id="kobo.635.3">In Snorkel, a labeling function is a Python function that heuristically generates labels for a dataset. </span><span class="koboSpan" id="kobo.635.4">These functions are used in the process of weak supervision, where instead of relying solely on manually labeled data, a machine learning model is trained using noisy, imperfect, or weakly </span><span class="No-Break"><span class="koboSpan" id="kobo.636.1">labeled data.</span></span></p>
<p><span class="koboSpan" id="kobo.637.1">Here is an example Python code that uses the Snorkel API to label text data using rule-based </span><span class="No-Break"><span class="koboSpan" id="kobo.638.1">labeling functions.</span></span></p>
<p><span class="koboSpan" id="kobo.639.1">Let’s install Snorkel using pip and import the required Python libraries for labeling </span><span class="No-Break"><span class="koboSpan" id="kobo.640.1">as follows:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.641.1">
!pip install snorkel</span></pre> <p><span class="koboSpan" id="kobo.642.1">Let’s break down the code into four steps and explain </span><span class="No-Break"><span class="koboSpan" id="kobo.643.1">each one.</span></span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.644.1">Step 1</span></em><span class="koboSpan" id="kobo.645.1">: Data preparation and labeling function definition. </span><span class="koboSpan" id="kobo.645.2">This step prepares the data and defines the labeling functions. </span><span class="koboSpan" id="kobo.645.3">It first imports the Pandas library and defines some constants for the labels. </span><span class="koboSpan" id="kobo.645.4">It then creates a DataFrame with movie reviews and splits it into a training set and a test set. </span><span class="koboSpan" id="kobo.645.5">The true labels for the test set are defined and converted to a NumPy array. </span><span class="koboSpan" id="kobo.645.6">Finally, it defines three labeling functions that label a review as positive, negative, or abstain based on the presence of </span><span class="No-Break"><span class="koboSpan" id="kobo.646.1">certain words:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.647.1">
import pandas as pd
# Define the constants
ABSTAIN = -1
POS = 0
NEG = 1
# Create a DataFrame with more data
df = pd.DataFrame({
    'id': [1, 2, 3, 4, 5, 6, 7, 8],
    'review': [
        "This movie was absolutely wonderful!",
        "The film was terrible and boring.",
        "I have mixed feelings about the movie.",
        "I have no opinion about the movie.",
        "The movie was fantastic and exciting!",
        "I didn't like the movie, it was too slow.",
        "The movie was okay, not great but not bad either.",
        "The movie was confusing and dull."
</span><span class="koboSpan" id="kobo.647.2">    ]
})
# Split the DataFrame into a training set and a test set
df_train = df.iloc[:6]  # First 6 records for training
df_test = df.iloc[6:]  # Remaining records for testing
# Define the true labels for the test set
Y_test = [ABSTAIN, NEG]  # Replace this with the actual labels
# Convert Y_test to a NumPy array
Y_test = np.array(Y_test)</span></pre> <p><span class="koboSpan" id="kobo.648.1">Now let’s</span><a id="_idIndexMarker577"/><span class="koboSpan" id="kobo.649.1"> define the labeling functions, one </span><a id="_idIndexMarker578"/><span class="koboSpan" id="kobo.650.1">for positive reviews, one for negative reviews, and one for neutral reviews, using regular expressions </span><span class="No-Break"><span class="koboSpan" id="kobo.651.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.652.1">
# Define rule-based labeling functions using regular expressions
@labeling_function()
def lf_positive_review(x):
    return POS if 'wonderful' in x.review or 'fantastic' in x.review else ABSTAIN
@labeling_function()
def lf_negative_review(x):
    return NEG if 'terrible' in x.review or 'boring' in \
        x.review or 'slow' in x.review or 'dull' in \
        x.review else ABSTAIN
@labeling_function()
def lf_neutral_review(x):
    return ABSTAIN if 'mixed feelings' in x.review or \
        'no opinion' in x.review or 'okay' in x.review \
        else ABSTAIN</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.653.1">Step 2</span></em><span class="koboSpan" id="kobo.654.1">: Applying </span><a id="_idIndexMarker579"/><span class="koboSpan" id="kobo.655.1">labeling functions and majority voting. </span><span class="koboSpan" id="kobo.655.2">This</span><a id="_idIndexMarker580"/><span class="koboSpan" id="kobo.656.1"> chunk of code applies the labeling functions to the training and test sets, and then uses a majority vote model to predict the labels. </span><span class="koboSpan" id="kobo.656.2">It first creates a list of the labeling functions and applies them to the training and test sets using </span><strong class="source-inline"><span class="koboSpan" id="kobo.657.1">PandasLFApplier</span></strong><span class="koboSpan" id="kobo.658.1">. </span><span class="koboSpan" id="kobo.658.2">It then prints the resulting label matrices and their shapes. </span><span class="koboSpan" id="kobo.658.3">It imports the </span><strong class="source-inline"><span class="koboSpan" id="kobo.659.1">MajorityLabelVoter</span></strong><span class="koboSpan" id="kobo.660.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.661.1">LabelModel</span></strong><span class="koboSpan" id="kobo.662.1"> classes from Snorkel, creates a majority vote mode, and uses it to predict the labels for the </span><span class="No-Break"><span class="koboSpan" id="kobo.663.1">training set:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.664.1">
# Apply the labeling functions to the training set and the test set
lfs = [lf_positive_review, lf_negative_review, lf_neutral_review]
applier = PandasLFApplier(lfs=lfs)
L_train = applier.apply(df=df_train)
L_test = applier.apply(df=df_test)
print(L_train)
print(L_test)
print(L_test.shape)
print(Y_test.shape)</span></pre> <p><span class="koboSpan" id="kobo.665.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.666.1">the output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer090">
<span class="koboSpan" id="kobo.667.1"><img alt="Figure 7.﻿4 – Label matrices" src="image/B18944_07_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.668.1">Figure 7.4 – Label matrices</span></p>
<p><span class="koboSpan" id="kobo.669.1">Let’s </span><a id="_idIndexMarker581"/><span class="koboSpan" id="kobo.670.1">calculate the accuracy of the model </span><a id="_idIndexMarker582"/><span class="koboSpan" id="kobo.671.1">using </span><strong class="source-inline"><span class="koboSpan" id="kobo.672.1">MajorityLabelVoter</span></strong><span class="koboSpan" id="kobo.673.1"> model on the test set and </span><span class="No-Break"><span class="koboSpan" id="kobo.674.1">print it:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.675.1">
from snorkel.labeling.model import MajorityLabelVoter, LabelModel
majority_model = MajorityLabelVoter()
majority_model.predict(L=L_train)
majority_acc = majority_model.score(L=L_test, Y=Y_test, \
    tie_break_policy="random")["accuracy"]
print( majority_acc)</span></pre> <p><span class="koboSpan" id="kobo.676.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.677.1">the output:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.678.1">
1.0</span></pre> <p><span class="koboSpan" id="kobo.679.1">Finally, it predicts the labels for the training set and </span><span class="No-Break"><span class="koboSpan" id="kobo.680.1">prints them:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.681.1">
preds_train = majority_model.predict(L=L_train)
print(preds_train)</span></pre> <p><span class="koboSpan" id="kobo.682.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.683.1">the output:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.684.1">
[ 0  1 -1 -1  0  1]</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.685.1">Step 3</span></em><span class="koboSpan" id="kobo.686.1">: Training </span><a id="_idIndexMarker583"/><span class="koboSpan" id="kobo.687.1">a label model and predicting labels. </span><span class="koboSpan" id="kobo.687.2">This</span><a id="_idIndexMarker584"/><span class="koboSpan" id="kobo.688.1"> chunk of code trains a label model and uses it to predict the labels. </span><span class="koboSpan" id="kobo.688.2">It creates a </span><strong class="source-inline"><span class="koboSpan" id="kobo.689.1">LabelModel</span></strong><span class="koboSpan" id="kobo.690.1"> with a </span><strong class="source-inline"><span class="koboSpan" id="kobo.691.1">cardinality</span></strong><span class="koboSpan" id="kobo.692.1"> of </span><strong class="source-inline"><span class="koboSpan" id="kobo.693.1">2</span></strong><span class="koboSpan" id="kobo.694.1"> (for the two labels, positive and negative), fits it to the training set, and calculates its accuracy on the </span><span class="No-Break"><span class="koboSpan" id="kobo.695.1">test set:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.696.1">
label_model = LabelModel(cardinality=2, verbose=True)
label_model.fit(L_train=L_train, n_epochs=500, \
    log_freq=100, seed=123)
label_model_acc = label_model.score(L=L_test, Y=Y_test, \
    tie_break_policy="random")[
    "accuracy"
]
print(label_model_acc)</span></pre> <p><span class="koboSpan" id="kobo.697.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.698.1">the output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer091">
<span class="koboSpan" id="kobo.699.1"><img alt="Figure 7.﻿5 – Training a LabelModel" src="image/B18944_07_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.700.1">Figure 7.5 – Training a LabelModel</span></p>
<p><span class="koboSpan" id="kobo.701.1">It then predicts the labels for the training set and </span><span class="No-Break"><span class="koboSpan" id="kobo.702.1">prints them:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.703.1">
# Predict the labels for the training data
Y_train_pred = label_model.predict(L=L_train)
# Print the predicted labels
print(Y_train_pred)</span></pre> <p><span class="koboSpan" id="kobo.704.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.705.1">the output:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.706.1">
[ 0  1 -1 -1  0  1]</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.707.1">Step 4</span></em><span class="koboSpan" id="kobo.708.1">: Analyzing</span><a id="_idIndexMarker585"/><span class="koboSpan" id="kobo.709.1"> labeling functions and creating a </span><a id="_idIndexMarker586"/><span class="koboSpan" id="kobo.710.1">DataFrame with predicted labels. </span><span class="koboSpan" id="kobo.710.2">We can use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.711.1">LFAnalysis</span></strong><span class="koboSpan" id="kobo.712.1"> class to analyze the labeling functions by passing the labels (</span><strong class="source-inline"><span class="koboSpan" id="kobo.713.1">L</span></strong><span class="koboSpan" id="kobo.714.1">) and the list of labeling functions (</span><strong class="source-inline"><span class="koboSpan" id="kobo.715.1">lfs</span></strong><span class="koboSpan" id="kobo.716.1">). </span><span class="koboSpan" id="kobo.716.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.717.1">lf_summary()</span></strong><span class="koboSpan" id="kobo.718.1"> method provides an overview of the labeling functions and </span><span class="No-Break"><span class="koboSpan" id="kobo.719.1">their coverage:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.720.1">
# Analyze the labeled data
LFAnalysis(L=L_train, lfs=lfs).lf_summary()</span></pre> <p><span class="koboSpan" id="kobo.721.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.722.1">the output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer092">
<span class="koboSpan" id="kobo.723.1"><img alt="Figure 7.﻿6 – LFAnalysis summary" src="image/B18944_07_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.724.1">Figure 7.6 – LFAnalysis summary</span></p>
<p><span class="koboSpan" id="kobo.725.1">The table is a summary of the results from LFAnalysis, specifically for three labeling functions: </span><strong class="source-inline"><span class="koboSpan" id="kobo.726.1">lf_positive_review</span></strong><span class="koboSpan" id="kobo.727.1">,  </span><strong class="source-inline"><span class="koboSpan" id="kobo.728.1">lf_negative_review</span></strong><span class="koboSpan" id="kobo.729.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.730.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.731.1">if_neutral_review</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.732.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.733.1">Let’s break down </span><span class="No-Break"><span class="koboSpan" id="kobo.734.1">the columns:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.735.1">j</span></strong><span class="koboSpan" id="kobo.736.1">: The index of the labeling function in the list of labeling functions. </span><span class="koboSpan" id="kobo.736.2">Here, </span><strong class="source-inline"><span class="koboSpan" id="kobo.737.1">j=0</span></strong><span class="koboSpan" id="kobo.738.1"> corresponds to </span><strong class="source-inline"><span class="koboSpan" id="kobo.739.1">lf_positive_review</span></strong><span class="koboSpan" id="kobo.740.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.741.1">j=1</span></strong><span class="koboSpan" id="kobo.742.1"> corresponds </span><span class="No-Break"><span class="koboSpan" id="kobo.743.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.744.1">lf_negative_review</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.745.1">.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.746.1">Polarity</span></strong><span class="koboSpan" id="kobo.747.1">: The polarity assigned to the labeling function, representing the label value assigned by the function. </span><span class="koboSpan" id="kobo.747.2">In this case, </span><strong class="source-inline"><span class="koboSpan" id="kobo.748.1">lf_positive_review</span></strong><span class="koboSpan" id="kobo.749.1"> has a polarity of </span><strong class="source-inline"><span class="koboSpan" id="kobo.750.1">[0, 1]</span></strong><span class="koboSpan" id="kobo.751.1">, meaning it assigns both label </span><strong class="source-inline"><span class="koboSpan" id="kobo.752.1">0</span></strong><span class="koboSpan" id="kobo.753.1"> and label </span><strong class="source-inline"><span class="koboSpan" id="kobo.754.1">1</span></strong><span class="koboSpan" id="kobo.755.1">. </span><span class="koboSpan" id="kobo.755.2">On the other hand, </span><strong class="source-inline"><span class="koboSpan" id="kobo.756.1">lf_negative_review</span></strong><span class="koboSpan" id="kobo.757.1"> has a polarity of </span><strong class="source-inline"><span class="koboSpan" id="kobo.758.1">[0]</span></strong><span class="koboSpan" id="kobo.759.1">, indicating it only assigns </span><span class="No-Break"><span class="koboSpan" id="kobo.760.1">label </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.761.1">0</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.762.1">.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.763.1">Coverage</span></strong><span class="koboSpan" id="kobo.764.1">: The set of labels predicted by the labeling function. </span><span class="koboSpan" id="kobo.764.2">For </span><strong class="source-inline"><span class="koboSpan" id="kobo.765.1">lf_positive_review</span></strong><span class="koboSpan" id="kobo.766.1">, it predicts both label </span><strong class="source-inline"><span class="koboSpan" id="kobo.767.1">0</span></strong><span class="koboSpan" id="kobo.768.1"> and label </span><strong class="source-inline"><span class="koboSpan" id="kobo.769.1">1</span></strong><span class="koboSpan" id="kobo.770.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.771.1">[0, 1]</span></strong><span class="koboSpan" id="kobo.772.1">), indicating it provides a non-abstain output for all examples. </span><span class="koboSpan" id="kobo.772.2">However, </span><strong class="source-inline"><span class="koboSpan" id="kobo.773.1">lf_negative_review</span></strong><span class="koboSpan" id="kobo.774.1"> predicts only label </span><strong class="source-inline"><span class="koboSpan" id="kobo.775.1">0</span></strong><span class="koboSpan" id="kobo.776.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.777.1">[0]</span></strong><span class="koboSpan" id="kobo.778.1">), meaning it provides a non-abstain output for only 55.25% of </span><span class="No-Break"><span class="koboSpan" id="kobo.779.1">the examples.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.780.1">Overlaps</span></strong><span class="koboSpan" id="kobo.781.1">: The percentage of examples for which the labeling function provides a non-abstain output. </span><span class="koboSpan" id="kobo.781.2">It represents the extent to which the labeling function is applicable. </span><span class="koboSpan" id="kobo.781.3">In this case, both </span><strong class="source-inline"><span class="koboSpan" id="kobo.782.1">lf_positive_review</span></strong><span class="koboSpan" id="kobo.783.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.784.1">lf_negative_review</span></strong><span class="koboSpan" id="kobo.785.1"> have a coverage of 0.5525, indicating that they provide a non-abstain label for 55.25% of </span><span class="No-Break"><span class="koboSpan" id="kobo.786.1">the examples.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.787.1">Conflicts</span></strong><span class="koboSpan" id="kobo.788.1">: The percentage of examples for which the labeling function disagrees with at least one other labeling function. </span><span class="koboSpan" id="kobo.788.2">It measures the level of conflict between the labeling function and other functions. </span><span class="koboSpan" id="kobo.788.3">Both </span><strong class="source-inline"><span class="koboSpan" id="kobo.789.1">lf_positive_review</span></strong><span class="koboSpan" id="kobo.790.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.791.1">lf_negative_review</span></strong><span class="koboSpan" id="kobo.792.1"> have a conflict value of 0.2105, indicating they have conflicts with other labeling functions in approximately 21.05% of </span><span class="No-Break"><span class="koboSpan" id="kobo.793.1">the examples.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.794.1">This summary </span><a id="_idIndexMarker587"/><span class="koboSpan" id="kobo.795.1">provides insights into the performance, coverage, and </span><a id="_idIndexMarker588"/><span class="koboSpan" id="kobo.796.1">conflicts of the labeling functions, allowing you to assess their effectiveness and identify areas of improvement in your </span><span class="No-Break"><span class="koboSpan" id="kobo.797.1">labeling process.</span></span></p>
<p><span class="koboSpan" id="kobo.798.1">Lastly, the following chunk of code analyzes the labeling functions and creates a DataFrame with the predicted labels. </span><span class="koboSpan" id="kobo.798.2">It uses the </span><strong class="source-inline"><span class="koboSpan" id="kobo.799.1">LFAnalysis</span></strong><span class="koboSpan" id="kobo.800.1"> class from Snorkel to analyze the labeling functions and print a summary. </span><span class="koboSpan" id="kobo.800.2">It then creates a DataFrame with the </span><span class="No-Break"><span class="koboSpan" id="kobo.801.1">predicted labels:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.802.1">
# Create a DataFrame with the predicted labels
df_train_pred = df_train.copy()
df_train_pred['predicted_label'] = Y_train_pred
# Display the DataFrame
print(df_train_pred)</span></pre> <p><span class="koboSpan" id="kobo.803.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.804.1">the output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer093">
<span class="koboSpan" id="kobo.805.1"><img alt="Figure 7.﻿7 – Predicted labels" src="image/B18944_07_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.806.1">Figure 7.7 – Predicted labels</span></p>
<p><span class="koboSpan" id="kobo.807.1">In this example, we first created the </span><strong class="source-inline"><span class="koboSpan" id="kobo.808.1">Movie Reviews</span></strong><span class="koboSpan" id="kobo.809.1"> DataFrame. </span><span class="koboSpan" id="kobo.809.2">We then defined three rule-based labeling functions using regular expressions to label reviews as positive, negative, or neutral based on the presence of certain keywords. </span><span class="koboSpan" id="kobo.809.3">We applied these labeling functions to the text data using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.810.1">PandasLFApplier</span></strong><span class="koboSpan" id="kobo.811.1"> provided by the Snorkel API. </span><span class="koboSpan" id="kobo.811.2">Finally, we analyzed the labeled data using </span><strong class="source-inline"><span class="koboSpan" id="kobo.812.1">LFAnalysis</span></strong><span class="koboSpan" id="kobo.813.1"> and printed a summary of </span><span class="No-Break"><span class="koboSpan" id="kobo.814.1">the results.</span></span></p>
<p><span class="koboSpan" id="kobo.815.1">Note that this is</span><a id="_idIndexMarker589"/><span class="koboSpan" id="kobo.816.1"> a simple example and you may need to </span><a id="_idIndexMarker590"/><span class="koboSpan" id="kobo.817.1">adjust the code depending on the specific requirements of your use case. </span><span class="koboSpan" id="kobo.817.2">Also, you can add more labeling functions depending on your task, and these functions should be carefully designed and tested to ensure </span><span class="No-Break"><span class="koboSpan" id="kobo.818.1">high-quality labels.</span></span></p>
<p><span class="koboSpan" id="kobo.819.1">Now, let’s look into labeling the data using </span><span class="No-Break"><span class="koboSpan" id="kobo.820.1">logistic regression.</span></span></p>
<h1 id="_idParaDest-167"><a id="_idTextAnchor172"/><span class="koboSpan" id="kobo.821.1">Hands-on text labeling using Logistic Regression</span></h1>
<p><span class="koboSpan" id="kobo.822.1">Text labeling</span><a id="_idIndexMarker591"/><span class="koboSpan" id="kobo.823.1"> is a crucial task in NLP, enabling the categorization of textual data into predefined classes or sentiments. </span><span class="koboSpan" id="kobo.823.2">Logistic Regression, a popular machine learning</span><a id="_idIndexMarker592"/><span class="koboSpan" id="kobo.824.1"> algorithm, proves effective in text classification scenarios. </span><span class="koboSpan" id="kobo.824.2">In the following code, we walk through the process of using Logistic Regression to classify movie reviews into positive or negative sentiments. </span><span class="koboSpan" id="kobo.824.3">Here’s a breakdown of </span><span class="No-Break"><span class="koboSpan" id="kobo.825.1">the code.</span></span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.826.1">Step 1</span></em><span class="koboSpan" id="kobo.827.1">. </span><span class="koboSpan" id="kobo.827.2">Import necessary libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.828.1">and modules.</span></span></p>
<p><span class="koboSpan" id="kobo.829.1">The code begins</span><a id="_idIndexMarker593"/><span class="koboSpan" id="kobo.830.1"> by importing the necessary libraries </span><a id="_idIndexMarker594"/><span class="koboSpan" id="kobo.831.1">and modules. </span><span class="koboSpan" id="kobo.831.2">These include NLTK for NLP, scikit-learn for machine learning, and specific modules for sentiment analysis, text preprocessing, </span><span class="No-Break"><span class="koboSpan" id="kobo.832.1">and classification:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.833.1">
    from nltk.corpus import stopwords
    from nltk.stem import WordNetLemmatizer
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LogisticRegression
    import nltk
    from nltk.corpus import movie_reviews
    from nltk.sentiment import SentimentAnalyzer
    from nltk.classify import NaiveBayesClassifier</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.834.1">Step 2</span></em><span class="koboSpan" id="kobo.835.1">. </span><span class="koboSpan" id="kobo.835.2">Download the necessary NLTK data. </span><span class="koboSpan" id="kobo.835.3">The code downloads the movie reviews dataset and other necessary NLTK data, such as the WordNet lemmatizer and the </span><span class="No-Break"><span class="koboSpan" id="kobo.836.1">Punkt tokenizer:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.837.1">
    nltk.download('movie_reviews')
    nltk.download('wordnet')
    nltk.download('omw-1.4')
    nltk.download('punkt')</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.838.1">Step 3</span></em><span class="koboSpan" id="kobo.839.1">. </span><span class="koboSpan" id="kobo.839.2">Initialize the sentiment analyzer and get movie review IDs. </span><span class="koboSpan" id="kobo.839.3">The code initializes a sentiment analyzer and gets the IDs of the </span><span class="No-Break"><span class="koboSpan" id="kobo.840.1">movie reviews:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.841.1">
    sentiment_analyzer = SentimentAnalyzer()
    ids = movie_reviews.fileids()</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.842.1">Step 4</span></em><span class="koboSpan" id="kobo.843.1">. </span><span class="koboSpan" id="kobo.843.2">Preprocessing setup. </span><span class="koboSpan" id="kobo.843.3">The code sets up the preprocessing tools, including a lemmatizer and a list of English stopwords. </span><span class="koboSpan" id="kobo.843.4">It also defines a preprocessing function that tokenizes the text, removes stop words, and lemmatizes </span><span class="No-Break"><span class="koboSpan" id="kobo.844.1">the words:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.845.1">
    lemmatizer = WordNetLemmatizer()
    stop_words = set(stopwords.words('english'))
    def preprocess(document):
        words = word_tokenize(document)
        words = [lemmatizer.lemmatize(word) for word in \
            words if word not in stop_words]
        return ' '.join(words)</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.846.1">Step 5</span></em><span class="koboSpan" id="kobo.847.1">. </span><span class="koboSpan" id="kobo.847.2">Feature extraction. </span><span class="koboSpan" id="kobo.847.3">The code sets up a TF-IDF vectorizer with the preprocessing function and uses it to transform the movie reviews into a </span><span class="No-Break"><span class="koboSpan" id="kobo.848.1">feature matrix:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.849.1">
    vectorizer = TfidfVectorizer(preprocessor=preprocess, ngram_range=(1, 2))
    X = vectorizer.fit_transform( \
        [movie_reviews.raw(fileid) for fileid in ids])</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.850.1">Step 6</span></em><span class="koboSpan" id="kobo.851.1">. </span><span class="koboSpan" id="kobo.851.2">Create</span><a id="_idIndexMarker595"/><span class="koboSpan" id="kobo.852.1"> a target vector. </span><span class="koboSpan" id="kobo.852.2">The code creates a target </span><a id="_idIndexMarker596"/><span class="koboSpan" id="kobo.853.1">vector with the categories of the </span><span class="No-Break"><span class="koboSpan" id="kobo.854.1">movie reviews:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.855.1">
    y = [movie_reviews.categories([f])[0] for f in ids]</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.856.1">Step 7</span></em><span class="koboSpan" id="kobo.857.1">. </span><span class="koboSpan" id="kobo.857.2">Split the data. </span><span class="koboSpan" id="kobo.857.3">The code splits the data into training and </span><span class="No-Break"><span class="koboSpan" id="kobo.858.1">test sets:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.859.1">
    X_train, X_test, y_train, y_test = train_test_split( \
        X, y, test_size=0.2, random_state=42)</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.860.1">Step 8</span></em><span class="koboSpan" id="kobo.861.1">. </span><span class="koboSpan" id="kobo.861.2">Model training. </span><span class="koboSpan" id="kobo.861.3">The code initializes a Logistic Regression classifier and trains it on the </span><span class="No-Break"><span class="koboSpan" id="kobo.862.1">training data:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.863.1">
    model = LogisticRegression()
    model.fit(X_train, y_train)</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.864.1">Step 9</span></em><span class="koboSpan" id="kobo.865.1">. </span><span class="koboSpan" id="kobo.865.2">Model evaluation. </span><span class="koboSpan" id="kobo.865.3">The code evaluates the model on the test data and prints </span><span class="No-Break"><span class="koboSpan" id="kobo.866.1">the accuracy:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.867.1">
    accuracy = model.score(X_test, y_test)
    print(f"Accuracy: {accuracy:.2%}")</span></pre> <p><span class="koboSpan" id="kobo.868.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.869.1">the output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer094">
<span class="koboSpan" id="kobo.870.1"><img alt="Figure 7.﻿8 – Accuracy of  logistic regression" src="image/B18944_07_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.871.1">Figure 7.8 – Accuracy of  logistic regression</span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.872.1">Step 10</span></em><span class="koboSpan" id="kobo.873.1">. </span><span class="koboSpan" id="kobo.873.2">Testing </span><a id="_idIndexMarker597"/><span class="koboSpan" id="kobo.874.1">with custom sentences. </span><span class="koboSpan" id="kobo.874.2">The code </span><a id="_idIndexMarker598"/><span class="koboSpan" id="kobo.875.1">tests the model with custom sentences. </span><span class="koboSpan" id="kobo.875.2">It preprocesses the sentences, transforms them into features, predicts their sentiment, and prints </span><span class="No-Break"><span class="koboSpan" id="kobo.876.1">the results:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.877.1">
    custom_sentences = [
        "I loved the movie and it was amazing. </span><span class="koboSpan" id="kobo.877.2">Best movie I have seen this year.",
        "The movie was terrible. </span><span class="koboSpan" id="kobo.877.3">The plot was non-existent and the acting was subpar.",
        "I have mixed feelings about the movie. </span><span class="koboSpan" id="kobo.877.4">Some parts were good, but some were not.",
    ]
    for sentence in custom_sentences:
        preprocessed_sentence = preprocess(sentence)
        features = vectorizer.transform([preprocessed_sentence])
        sentiment = model.predict(features)
        print(f"Sentence: {sentence}\nSentiment: {sentiment[0]}\n")</span></pre> <p><span class="koboSpan" id="kobo.878.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.879.1">the output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer095">
<span class="koboSpan" id="kobo.880.1"><img alt="Figure 7.﻿9 – Predicted labels" src="image/B18944_07_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.881.1">Figure 7.9 – Predicted labels</span></p>
<p><span class="koboSpan" id="kobo.882.1">This code serves as</span><a id="_idIndexMarker599"/><span class="koboSpan" id="kobo.883.1"> a comprehensive guide to text labeling </span><a id="_idIndexMarker600"/><span class="koboSpan" id="kobo.884.1">using logistic regression, encompassing data preprocessing, model training, evaluation, and application to </span><span class="No-Break"><span class="koboSpan" id="kobo.885.1">custom sentences.</span></span></p>
<p><span class="koboSpan" id="kobo.886.1">Now, let’s look into the second method, K-means clustering, to label the text data by grouping similar text together and creating labels for that group </span><span class="No-Break"><span class="koboSpan" id="kobo.887.1">or cluster.</span></span></p>
<h1 id="_idParaDest-168"><a id="_idTextAnchor173"/><span class="koboSpan" id="kobo.888.1">Hands-on label prediction using K-means clustering</span></h1>
<p><span class="koboSpan" id="kobo.889.1">K-means clustering </span><a id="_idIndexMarker601"/><span class="koboSpan" id="kobo.890.1">is a powerful unsupervised machine learning technique used for grouping similar data points into clusters. </span><span class="koboSpan" id="kobo.890.2">In the context of text data, K-means clustering can be employed to predict labels or categories for the given text based on their similarity. </span><span class="koboSpan" id="kobo.890.3">The provided code showcases how to utilize K-Means clustering to predict labels for movie reviews, breaking down the process into several </span><span class="No-Break"><span class="koboSpan" id="kobo.891.1">key steps.</span></span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.892.1">Step 1</span></em><span class="koboSpan" id="kobo.893.1">: Importing</span><a id="_idIndexMarker602"/><span class="koboSpan" id="kobo.894.1"> libraries and </span><span class="No-Break"><span class="koboSpan" id="kobo.895.1">downloading </span></span><span class="No-Break"><a id="_idIndexMarker603"/></span><span class="No-Break"><span class="koboSpan" id="kobo.896.1">data.</span></span></p>
<p><span class="koboSpan" id="kobo.897.1">The following code begins by importing essential libraries such as scikit-learn and NLTK. </span><span class="koboSpan" id="kobo.897.2">It then downloads the necessary NLTK data, including the movie </span><span class="No-Break"><span class="koboSpan" id="kobo.898.1">reviews dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.899.1">
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from nltk.corpus import movie_reviews
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import nltk
import re
# Download the necessary NLTK data
nltk.download('movie_reviews')
nltk.download('stopwords')
nltk.download('wordnet')</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.900.1">Step 2</span></em><span class="koboSpan" id="kobo.901.1">: Retrieving and preprocessing </span><span class="No-Break"><span class="koboSpan" id="kobo.902.1">movie reviews.</span></span></p>
<p><span class="koboSpan" id="kobo.903.1">Retrieve movie reviews from the NLTK dataset and preprocess them. </span><span class="koboSpan" id="kobo.903.2">This involves lemmatization, removal of stop words, and converting text </span><span class="No-Break"><span class="koboSpan" id="kobo.904.1">to lowercase:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.905.1">
# Get the reviews
reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]
# Preprocess the text
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
reviews = [' '.join(lemmatizer.lemmatize(word) for word in re.sub('[^a-zA-Z]', ' ', review).lower().split() if word not in stop_words) for review in reviews]</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.906.1">Step 3</span></em><span class="koboSpan" id="kobo.907.1">: Creating the TF-IDF vectorizer and </span><span class="No-Break"><span class="koboSpan" id="kobo.908.1">transforming data.</span></span></p>
<p><span class="koboSpan" id="kobo.909.1">Create a TF-IDF vectorizer to convert the preprocessed reviews into numerical features. </span><span class="koboSpan" id="kobo.909.2">This step is crucial for preparing the data </span><span class="No-Break"><span class="koboSpan" id="kobo.910.1">for clustering:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.911.1">
# Create a TF-IDF vectorizer
vectorizer = TfidfVectorizer()
# Transform the reviews into TF-IDF features
X_tfidf = vectorizer.fit_transform(reviews)</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.912.1">Step 4</span></em><span class="koboSpan" id="kobo.913.1">: Applying </span><span class="No-Break"><span class="koboSpan" id="kobo.914.1">K-means clustering.</span></span></p>
<p><span class="koboSpan" id="kobo.915.1">Apply K-means clustering to the TF-IDF features, specifying the number of clusters. </span><span class="koboSpan" id="kobo.915.2">In this case, the code </span><span class="No-Break"><span class="koboSpan" id="kobo.916.1">sets </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.917.1">n_clusters=3</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.918.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.919.1">
# Cluster the reviews using K-means
kmeans = KMeans(n_clusters=3).fit(X_tfidf)</span></pre> <p><em class="italic"><span class="koboSpan" id="kobo.920.1">Step 5</span></em><span class="koboSpan" id="kobo.921.1">: Labeling </span><a id="_idIndexMarker604"/><span class="koboSpan" id="kobo.922.1">and testing with </span><span class="No-Break"><span class="koboSpan" id="kobo.923.1">custom</span></span><span class="No-Break"><a id="_idIndexMarker605"/></span><span class="No-Break"><span class="koboSpan" id="kobo.924.1"> sentences.</span></span></p>
<p><span class="koboSpan" id="kobo.925.1">Define labels for the clusters and test the K-means classifier with custom sentences. </span><span class="koboSpan" id="kobo.925.2">The code preprocesses the sentences, transforms them into TF-IDF features, predicts the cluster, and assigns a label based on the predefined </span><span class="No-Break"><span class="koboSpan" id="kobo.926.1">cluster labels:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.927.1">
# Define the labels for the clusters
cluster_labels = {0: "positive", 1: "negative", 2: "neutral"}
# Test the classifier with custom sentences
custom_sentences = ["I loved the movie and Best movie I have seen this year.",
"The movie was terrible. </span><span class="koboSpan" id="kobo.927.2">The plot was non-existent and the acting was subpar.",
"I have mixed feelings about the movie.it is partly good and partly not good."]
for sentence in custom_sentences:
    # Preprocess the sentence
    sentence = ' '.join(lemmatizer.lemmatize(word) for word in re.sub('[^a-zA-Z]', ' ', sentence).lower().split() if word not in stop_words)
    # Transform the sentence into TF-IDF features
    features = vectorizer.transform([sentence])
    # Predict the cluster of the sentence
    cluster = kmeans.predict(features)
    # Get the label for the cluster
    label = cluster_labels[cluster[0]]
    print(f"Sentence: {sentence}\nLabel: {label}\n")</span></pre> <p><span class="koboSpan" id="kobo.928.1">Here’s </span><a id="_idIndexMarker606"/><span class="No-Break"><span class="koboSpan" id="kobo.929.1">the </span></span><span class="No-Break"><a id="_idIndexMarker607"/></span><span class="No-Break"><span class="koboSpan" id="kobo.930.1">output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer096">
<span class="koboSpan" id="kobo.931.1"><img alt="Figure 7.﻿10 – K-means clustering for text" src="image/B18944_07_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.932.1">Figure 7.10 – K-means clustering for text</span></p>
<p><span class="koboSpan" id="kobo.933.1">This</span><a id="_idIndexMarker608"/><span class="koboSpan" id="kobo.934.1"> code demonstrates a comprehensive</span><a id="_idIndexMarker609"/><span class="koboSpan" id="kobo.935.1"> process of utilizing K-means clustering for text label prediction, covering data preprocessing, feature extraction, clustering, and testing with </span><span class="No-Break"><span class="koboSpan" id="kobo.936.1">custom sentences.</span></span></p>
<h1 id="_idParaDest-169"><a id="_idTextAnchor174"/><span class="koboSpan" id="kobo.937.1">Generating labels for customer reviews (sentiment analysis)</span></h1>
<p><span class="koboSpan" id="kobo.938.1">Customer reviews are a </span><a id="_idIndexMarker610"/><span class="koboSpan" id="kobo.939.1">goldmine of information for businesses. </span><span class="koboSpan" id="kobo.939.2">Analyzing sentiment in customer reviews helps in understanding customer satisfaction, identifying areas for improvement, and making data-driven </span><span class="No-Break"><span class="koboSpan" id="kobo.940.1">business decisions.</span></span></p>
<p><span class="koboSpan" id="kobo.941.1">In the following </span><a id="_idIndexMarker611"/><span class="koboSpan" id="kobo.942.1">example, we delve into sentiment analysis</span><a id="_idIndexMarker612"/><span class="koboSpan" id="kobo.943.1"> using a neural network model. </span><span class="koboSpan" id="kobo.943.2">The code utilizes TensorFlow and Keras to create a simple neural network architecture with an embedding layer, a flatten layer, and a dense layer. </span><span class="koboSpan" id="kobo.943.3">The model is trained on a small labeled dataset for sentiment classification, distinguishing between positive and negative sentiments. </span><span class="koboSpan" id="kobo.943.4">Following training, the model is employed to classify new sentences. </span><span class="koboSpan" id="kobo.943.5">The provided Python code demonstrates each step, from tokenizing and padding sequences to compiling, training, and </span><span class="No-Break"><span class="koboSpan" id="kobo.944.1">making predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.945.1">The </span><a id="_idIndexMarker613"/><span class="koboSpan" id="kobo.946.1">following dataset is used for training on </span><span class="No-Break"><span class="koboSpan" id="kobo.947.1">sentiment </span></span><span class="No-Break"><a id="_idIndexMarker614"/></span><span class="No-Break"><span class="koboSpan" id="kobo.948.1">analysis:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.949.1">
sentences = ["I love this movie", "This movie is terrible", "The acting was amazing", "The plot was confusing"]
labels = [1, 0, 1, 0]  # 1 for positive, 0 for negative</span></pre> <p><span class="koboSpan" id="kobo.950.1">We then use a tokenizer to convert the text into sequences of numbers, and then pad the sequences so that they have the same length. </span><span class="koboSpan" id="kobo.950.2">We then define a generative AI model with an embedding layer, a flatten layer, and a dense layer. </span><span class="koboSpan" id="kobo.950.3">Then, we compile and train the model on the training data. </span><span class="koboSpan" id="kobo.950.4">Finally, we use the trained model to classify a new sentence as either positive </span><span class="No-Break"><span class="koboSpan" id="kobo.951.1">or negative.</span></span></p>
<p><span class="koboSpan" id="kobo.952.1">Here is a complete Python code example with a dataset of four sentences labeled as positive or negative. </span><span class="koboSpan" id="kobo.952.2">We begin by </span><span class="No-Break"><span class="koboSpan" id="kobo.953.1">importing libraries:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.954.1">
import numpy as np
from tensorflow import keras
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences</span></pre> <p><span class="koboSpan" id="kobo.955.1">The NumPy library is imported as </span><strong class="source-inline"><span class="koboSpan" id="kobo.956.1">np</span></strong><span class="koboSpan" id="kobo.957.1"> for numerical computations. </span><span class="koboSpan" id="kobo.957.2">The necessary modules from the TensorFlow library are imported for text preprocessing and model creation. </span><span class="koboSpan" id="kobo.957.3">Then we define the </span><span class="No-Break"><span class="koboSpan" id="kobo.958.1">labeled dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.959.1">
sentences = ["I love this movie", "This movie is terrible", "The acting was amazing", "The plot was confusing"]
labels = [1, 0, 1, 0]</span></pre> <p><span class="koboSpan" id="kobo.960.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.961.1">sentences</span></strong><span class="koboSpan" id="kobo.962.1"> list contains textual sentences. </span><span class="koboSpan" id="kobo.962.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.963.1">labels</span></strong><span class="koboSpan" id="kobo.964.1"> list contains corresponding labels where 1 represents a positive sentiment and 0 represents a negative sentiment. </span><span class="koboSpan" id="kobo.964.2">Next, we tokenize the text and convert it </span><span class="No-Break"><span class="koboSpan" id="kobo.965.1">to sequences:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.966.1">
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences)
sequences = tokenizer.texts_to_sequences(sentences)
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentences)
sequences = tokenizer.texts_to_sequences(sentences)</span></pre> <p><span class="koboSpan" id="kobo.967.1">A </span><strong class="source-inline"><span class="koboSpan" id="kobo.968.1">Tokenizer</span></strong><span class="koboSpan" id="kobo.969.1"> object </span><a id="_idIndexMarker615"/><span class="koboSpan" id="kobo.970.1">is created to tokenize the text. </span><span class="koboSpan" id="kobo.970.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.971.1">fit_on_texts</span></strong><span class="koboSpan" id="kobo.972.1"> method is used to fit the tokenizer on the provided sentences. </span><span class="koboSpan" id="kobo.972.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.973.1">texts_to_sequences</span></strong><span class="koboSpan" id="kobo.974.1"> method is used to convert the sentences into</span><a id="_idIndexMarker616"/><span class="koboSpan" id="kobo.975.1"> sequences of tokens. </span><span class="koboSpan" id="kobo.975.2">Now we need to pad the sequences so they are the </span><span class="No-Break"><span class="koboSpan" id="kobo.976.1">same length:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.977.1">
max_sequence_length = max([len(seq) for seq in sequences])
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)</span></pre> <p><span class="koboSpan" id="kobo.978.1">The maximum sequence length is determined by finding the length of the longest sequence. </span><span class="koboSpan" id="kobo.978.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.979.1">pad_sequences</span></strong><span class="koboSpan" id="kobo.980.1"> function is used to pad the sequences to the maximum length. </span><span class="koboSpan" id="kobo.980.2">Next, we define the </span><span class="No-Break"><span class="koboSpan" id="kobo.981.1">model architecture:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.982.1">
model = keras.Sequential([
    keras.layers.Embedding(len(tokenizer.word_index) + 1, \
        16, input_length=max_sequence_length),
    keras.layers.Flatten(),
    keras.layers.Dense(1, activation='sigmoid')
])</span></pre> <p><span class="koboSpan" id="kobo.983.1">A sequential model is created using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.984.1">Sequential</span></strong><span class="koboSpan" id="kobo.985.1"> class from Keras. </span><span class="koboSpan" id="kobo.985.2">The model consists of an embedding layer, a flatten layer, and a dense layer. </span><span class="koboSpan" id="kobo.985.3">The embedding layer converts the tokens into dense vectors. </span><span class="koboSpan" id="kobo.985.4">The flatten layer flattens the input for the subsequent dense layer. </span><span class="koboSpan" id="kobo.985.5">The dense layer is used for binary classification with sigmoid activation. </span><span class="koboSpan" id="kobo.985.6">Now, we need to compile </span><span class="No-Break"><span class="koboSpan" id="kobo.986.1">the model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.987.1">
model.compile(optimizer='adam', loss='binary_crossentropy', \
    metrics=['accuracy'])</span></pre> <p><span class="koboSpan" id="kobo.988.1">The </span><a id="_idIndexMarker617"/><span class="koboSpan" id="kobo.989.1">model is compiled with the Adam optimizer, binary </span><a id="_idIndexMarker618"/><span class="koboSpan" id="kobo.990.1">cross-entropy loss, and accuracy as the metric. </span><span class="koboSpan" id="kobo.990.2">Now, we train </span><span class="No-Break"><span class="koboSpan" id="kobo.991.1">the model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.992.1">
model.fit(padded_sequences, np.array(labels), epochs=10)</span></pre> <p><span class="koboSpan" id="kobo.993.1">The model is trained on the padded sequences and corresponding labels for a specified number of epochs. </span><span class="koboSpan" id="kobo.993.2">Next, we classify a </span><span class="No-Break"><span class="koboSpan" id="kobo.994.1">new sentence:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.995.1">
new_sentence = ["This movie is good"]
new_sequence = tokenizer.texts_to_sequences(new_sentence)
padded_new_sequence = pad_sequences(new_sequence, \
    maxlen=max_sequence_length)
raw_prediction = model.predict(padded_new_sequence)
print("raw_prediction:",raw_prediction)
prediction = (raw_prediction &gt; 0.5).astype('int32')
print("prediction:",prediction)</span></pre> <p><span class="koboSpan" id="kobo.996.1">A new sentence is provided for classification. </span><span class="koboSpan" id="kobo.996.2">The sentence is converted to a sequence of tokens using the tokenizer. </span><span class="koboSpan" id="kobo.996.3">The sequence is padded to match the maximum sequence length used during training. </span><span class="koboSpan" id="kobo.996.4">The model predicts the sentiment class for the new sentence. </span><span class="koboSpan" id="kobo.996.5">Finally, we print the </span><span class="No-Break"><span class="koboSpan" id="kobo.997.1">predicted label:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.998.1">
if prediction[0][0] == 1:
     print("Positive")
else:
     print("Negative")</span></pre> <p><span class="koboSpan" id="kobo.999.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.1000.1">the output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer097">
<span class="koboSpan" id="kobo.1001.1"><img alt="Figure 7.1﻿1 – Prediction with a neural network model" src="image/B18944_07_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1002.1">Figure 7.11 – Prediction with a neural network model</span></p>
<p><span class="koboSpan" id="kobo.1003.1">The predicted</span><a id="_idIndexMarker619"/><span class="koboSpan" id="kobo.1004.1"> label is printed based on the prediction </span><a id="_idIndexMarker620"/><span class="koboSpan" id="kobo.1005.1">output. </span><span class="koboSpan" id="kobo.1005.2">If the predicted label is </span><strong class="source-inline"><span class="koboSpan" id="kobo.1006.1">1</span></strong><span class="koboSpan" id="kobo.1007.1">, it is considered a positive sentiment, and if it is </span><strong class="source-inline"><span class="koboSpan" id="kobo.1008.1">0</span></strong><span class="koboSpan" id="kobo.1009.1">, it is considered a negative sentiment. </span><span class="koboSpan" id="kobo.1009.2">In summary, the provided code demonstrates a sentiment analysis task using a neural </span><span class="No-Break"><span class="koboSpan" id="kobo.1010.1">network model.</span></span></p>
<h1 id="_idParaDest-170"><a id="_idTextAnchor175"/><span class="koboSpan" id="kobo.1011.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.1012.1">In this chapter, we delved into the realm of text data exploration using Python, gaining a comprehensive understanding of harnessing Generative AI and OpenAI models for effective text data labeling. </span><span class="koboSpan" id="kobo.1012.2">Through code examples, we explored diverse text data labeling tasks, including classification, summarization, and </span><span class="No-Break"><span class="koboSpan" id="kobo.1013.1">sentiment analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.1014.1">We then extended our knowledge by exploring Snorkel labeling functions, allowing us to label text data with enhanced flexibility. </span><span class="koboSpan" id="kobo.1014.2">Additionally, we delved into the application of K-means clustering for labeling text data and concluded by discovering how to label customer reviews using </span><span class="No-Break"><span class="koboSpan" id="kobo.1015.1">neural networks.</span></span></p>
<p><span class="koboSpan" id="kobo.1016.1">With these acquired skills, you now possess the tools to unlock the full potential of your text data, extracting valuable insights for various applications. </span><span class="koboSpan" id="kobo.1016.2">The next chapter awaits, where we will shift our focus to video data exploration, exploring different methods to gain insights from this dynamic </span><span class="No-Break"><span class="koboSpan" id="kobo.1017.1">data type.</span></span></p>
</div>
</body></html>