["```py\nMat object = imread(\"Object.png\"); \nMat objectGr; \ncvtColor(object, objectGr, COLOR_BGR2GRAY); \nMat scene = imread(\"Scene.png\"); \nMat sceneGr; \ncvtColor(scene, sceneGr, COLOR_BGR2GRAY); \n\nTemplateMatchModes method = TM_CCOEFF_NORMED; \n\nMat result; \nmatchTemplate(sceneGr, objectGr, result, method); \n```", "```py\nnormalize(result, result, 0.0, 1.0, NORM_MINMAX, -1); \n```", "```py\ndouble minVal, maxVal; \nPoint minLoc, maxLoc; \nminMaxLoc(result, &minVal, &maxVal, &minLoc, &maxLoc); \n```", "```py\nRect rect(minLoc.x, \n          minLoc.y, \n          object.cols, \n          object.rows); \n\nScalar color(0, 0, 255); \nint thickness = 2; \nrectangle(scene, \n          rect, \n          color, \n          thickness);\n```", "```py\nMat image = imread(\"Test.png\"); \ncvtColor(image, image, COLOR_BGR2GRAY); \n\nMat result; \nint blockSize = 2; \nint ksize = 3; \ndouble k = 1.0; \ncornerHarris(image, \n             result, \n             blockSize, \n             ksize, \n             k);\n```", "```py\nnormalize(result, result, 0.0, 1.0, NORM_MINMAX, -1); \n```", "```py\nMat image = imread(\"Test.png\"); \nMat imgGray; \ncvtColor(image, imgGray, COLOR_BGR2GRAY); \n\nvector<Point2f> corners; \nint maxCorners = 500; \ndouble qualityLevel = 0.01; \ndouble minDistance = 10; \nMat mask; \nint blockSize = 3; \nint gradientSize = 3; \nbool useHarrisDetector = false; \ndouble k = 0.04; \ngoodFeaturesToTrack(imgGray, \n                    corners, \n                    maxCorners, \n                    qualityLevel, \n                    minDistance, \n                    mask, \n                    blockSize, \n                    gradientSize, \n                    useHarrisDetector, \n                    k); \n```", "```py\nScalar color(0, 0, 255); \nMarkerTypes markerType = MARKER_TILTED_CROSS; \nint markerSize = 8; \nint thickness = 2; \nfor(int i=0; i<corners.size(); i++) \n{ \n    drawMarker(image, \n               corners[i], \n               color, \n               markerType, \n               markerSize, \n               thickness); \n}\n```", "```py\nPtr<GFTTDetector> detector =  \n    GFTTDetector::create(maxCorners, \n                         qualityLevel, \n                         minDistance, \n                         blockSize, \n                         gradientSize, \n                         useHarrisDetector, \n                         k); \n\nvector<KeyPoint> keypoints; \ndetector->detect(image, keypoints); \n```", "```py\nPtr<GFTTDetector> detector = GFTTDetector::create();\n```", "```py\nMat outImg; \ndrawKeypoints(image, \n              keypoints, \n              outImg); \n```", "```py\nint threshold = 10; \nbool nonmaxSuppr = true; \nint type = FastFeatureDetector::TYPE_9_16; \nPtr<FastFeatureDetector> fast = \n        FastFeatureDetector::create(threshold, \n                                    nonmaxSuppr, \n                                    type); \n\nvector<KeyPoint> keypoints; \nfast->detect(image, keypoints);\n```", "```py\nint threshold = 10; \nbool nonmaxSuppr = true; \nint type = AgastFeatureDetector::OAST_9_16; \nPtr<AgastFeatureDetector> agast = \n        AgastFeatureDetector::create(threshold, \n                                     nonmaxSuppr, \n                                     type); \n\nvector<KeyPoint> keypoints; \nagast->detect(image, keypoints); \n```", "```py\nPtr<Feature2D> detector; \nswitch (algorithm) \n{ \n\ncase 1: \n    detector = GFTTDetector::create(); \n    break; \n\ncase 2: \n    detector = FastFeatureDetector::create(); \n    break; \n\ncase 3: \n    detector = AgastFeatureDetector::create(); \n    break; \n\ndefault: \n    cout << \"Wrong algorithm!\" << endl; \n    return 0; \n\n} \n\nvector<KeyPoint> keypoints; \ndetector->detect(image, keypoints); \n```", "```py\nMat image = imread(\"Test.png\"); \nMat imgGray; \ncvtColor(image, imgGray, COLOR_BGR2GRAY); \n\nPtr<LineSegmentDetector> detector = createLineSegmentDetector(); \n\nvector<Vec4f> lines; \ndetector->detect(imgGray, \n                 lines); \n```", "```py\nMat result(image.size(), \n           CV_8UC3, \n           Scalar(0, 0, 0)); \n\ndetector->drawSegments(result, \n                       lines); \n```", "```py\nMat result(image.size(), \n           CV_8UC3, \n           Scalar(0, 0, 0)); \n\nScalar color(0,0,255); \nint thickness = 2; \nfor(int i=0; i<lines.size(); i++) \n{ \n    line(result, \n         Point(lines.at(i)[0], \n            lines.at(i)[1]), \n         Point(lines.at(i)[2], \n            lines.at(i)[3]), \n         color, \n         thickness); \n} \n```", "```py\nvector<Vec4f> lines1, lines2; \ndetector->detect(imgGray1, \n                 lines1); \n\ndetector->detect(imgGray2, \n                 lines2); \n\nMat resultImg(imageSize, CV_8UC3, Scalar::all(0)); \nint result = detector->compareSegments(imageSize, \n                                       lines1, \n                                       lines2, \n                                       resultImg); \n```", "```py\nMat image = imread(\"Test.png\"); \n\ndouble threshold1 = 100.0; \ndouble threshold2 = 200.0; \nint apertureSize = 3; \nbool L2gradient = false; \nMat edges; \nCanny(image, \n      edges, \n      threshold1, \n      threshold2, \n      apertureSize, \n      L2gradient); \n```", "```py\nMat image = imread(\"Test.png\"); \n\ndouble threshold1 = 100.0; \ndouble threshold2 = 200.0; \nint apertureSize = 3; \nbool L2gradient = false; \nMat edges; \nCanny(image, \n      edges, \n      threshold1, \n      threshold2, \n      apertureSize, \n      L2gradient); \n```", "```py\nvector<Vec2f> lines; \ndouble rho = 1.0; // 1 pixel, r resolution \ndouble theta = CV_PI / 180.0; // 1 degree, theta resolution \nint threshold = 100; // minimum number of intersections to \"detect\" a line \nHoughLines(edges, \n           lines, \n           rho, \n           theta, \n           threshold); \n```", "```py\nScalar color(0,0,255); \nint thickness = 2; \nfor(int i=0; i<lines.size(); i++) \n{ \n    float rho = lines.at(i)[0]; \n    float theta = lines.at(i)[1]; \n    Point pt1, pt2; \n    double a = cos(theta); \n    double b = sin(theta); \n    double x0 = a*rho; \n    double y0 = b*rho; \n    pt1.x = int(x0 + 1000*(-b)); \n    pt1.y = int(y0 + 1000*(a)); \n    pt2.x = int(x0 - 1000*(-b)); \n    pt2.y = int(y0 - 1000*(a)); \n    line( image, pt1, pt2, color, thickness); \n} \n```", "```py\nvector<Vec4f> lines; \ndouble rho = 1.0; // 1 pixel, r resolution \ndouble theta = CV_PI / 180.0; // 1 degree, theta resolution \nint threshold = 100; // minimum number of intersections to \"detect\" a line \nHoughLinesP(edges, \n            lines, \n            rho, \n            theta, \n            threshold); \n\nScalar color(0,0,255); \nint thickness = 2; \nfor(int i=0; i<lines.size(); i++) \n{ \n    line(image, \n         Point(lines.at(i)[0], \n            lines.at(i)[1]), \n         Point(lines.at(i)[2], \n            lines.at(i)[3]), \n         color, \n         thickness); \n} \n```", "```py\nMat image = imread(\"Test.png\"); \nMat imgGray; \ncvtColor(image, imgGray, COLOR_BGR2GRAY); \n\ndouble threshold1 = 100.0; \ndouble threshold2 = 200.0; \nint apertureSize = 3; \nbool L2gradient = false; \nMat edges; \nCanny(image, \n      edges, \n      threshold1, \n      threshold2, \n      apertureSize, \n      L2gradient); \n```", "```py\nvector<vector<Point> > contours; \nint mode = CV_RETR_TREE; \nint method = CV_CHAIN_APPROX_TC89_KCOS; \nfindContours(edges, \n             contours, \n             mode, \n             method);\n```", "```py\nRNG rng(12345); // any random number \n\nMat result(edges.size(), CV_8UC3, Scalar(0)); \nint thickness = 2; \nfor( int i = 0; i< contours.size(); i++ ) \n{ \n    Scalar color = Scalar(rng.uniform(0, 255), \n                          rng.uniform(0,255), \n                          rng.uniform(0,255) ); \n\n    drawContours(result, \n                 contours, \n                 i, \n                 color, \n                 thickness); \n} \n```", "```py\ndouble area = contourArea(contour); \n```", "```py\nfor( int i = 0; i< contours.size(); i++ ) \n{ \n    if(contourArea(contours[i]) > thresholdArea) \n    { \n        drawContours(result, \n                     contours, \n                     i, \n                     color, \n                     thickness); \n    } \n} \n```", "```py\nPoint pt(x, y); \ndouble result = pointPolygonTest(contours[i], Point(x,y), true); \n```", "```py\nbool isIt = isContourConvex(contour);\n```", "```py\nShapeMatchModes method = CONTOURS_MATCH_I1; \ndouble result = matchShapes(cntr1, cntr2, method, 0); \n```", "```py\nRect br = boundingRect(contour);\n```", "```py\nRotatedRect br = minAreaRect(contour); \n```", "```py\nPoint2f points[4]; \nbr.points(points); \nfor (int i=0; i<4; i++) \n    line(image, \n         points[i], \n         points[(i+1)%4], \n         Scalar(0,0,255), \n         2); \n```", "```py\n// to detect the minimal bounding circle \nPoint2f center; \nfloat radius; \nminEnclosingCircle(contour, center, radius); \n\n// to detect the minimal bounding triangle \nvector<Point2f> triangle; \nminEnclosingTriangle(contour, triangle); \n```", "```py\nMat object = imread(\"object.png\"); \nMat scene = imread(\"Scene.png\"); \n```", "```py\nPtr<KAZE> detector = KAZE::create(); \nvector<KeyPoint> objKPs, scnKPs; \ndetector->detect(object, objKPs); \ndetector->detect(scene, scnKPs); \n```", "```py\nMat objDesc, scnDesc; \ndetector->compute(object, objKPs, objDesc); \ndetector->compute(scene, scnKPs, scnDesc); \n```", "```py\nPtr<BFMatcher> matcher = BFMatcher::create(); \nvector<DMatch> matches; \nmatcher->match(objDesc, scnDesc, matches); \n```", "```py\nMat result; \ndrawMatches(object, \n            objKPs, \n            scene, \n            scnKPs, \n            matches, \n            result, \n            Scalar(0, 255, 0), // green for matched \n            Scalar::all(-1), // unmatched color (not used) \n            vector<char>(), // empty mask \n            DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS); \n```", "```py\nvector<DMatch> goodMatches; \ndouble thresh = 0.1; \nfor(int i=0; i<objDesc.rows; i++) \n{ \n    if(matches[i].distance < thresh) \n        goodMatches.push_back(matches[i]); \n} \n\nif(goodMatches.size() > 0) \n{ \n    cout << \"Found \" << goodMatches.size() << \" good matches.\"; \n} \nelse \n{ \n    cout << \"Didn't find a single good match. Quitting!\"; \n    return -1; \n} \n```", "```py\nvector<Point2f> goodP1, goodP2; \nfor(int i=0; i<goodMatches.size(); i++) \n{ \n    goodP1.push_back(objKPs[goodMatches[i].queryIdx].pt); \n    goodP2.push_back(scnKPs[goodMatches[i].trainIdx].pt); \n} \nMat homoChange = findHomography(goodP1, goodP2); \n```", "```py\nvector<Point2f> corners1(4), corners2(4); \ncorners1[0] = Point2f(0,0); \ncorners1[1] = Point2f(object.cols-1, 0); \ncorners1[2] = Point2f(object.cols-1, object.rows-1); \ncorners1[3] = Point2f(0, object.rows-1); \nperspectiveTransform(corners1, corners2, homoChange);\n```", "```py\nline(result, corners2[0], corners2[1], Scalar::all(255), 2); \nline(result, corners2[1], corners2[2], Scalar::all(255), 2); \nline(result, corners2[2], corners2[3], Scalar::all(255), 2); \nline(result, corners2[3], corners2[0], Scalar::all(255), 2); \n```", "```py\nfor(int i=0; i<4; i++) \n    corners2[i].x += object.cols; \n```", "```py\ndouble freq = getTickFrequency(); \ndouble countBefore = getTickCount(); \n\n// your code goes here .. \n\ndouble countAfter = getTickCount(); \ncout << \"Duration: \" << \n          (countAfter - countBefore) / freq << \" seconds\"; \n```"]