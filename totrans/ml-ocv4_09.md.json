["```py\nIn [1]: from sklearn import datasets...     X, y = datasets.make_blobs(100, 2, centers=2,        random_state=1701, cluster_std=2)\n```", "```py\nIn [2]: import matplotlib.pyplot as plt...     plt.style.use('ggplot')...     %matplotlib inlineIn [3]: plt.scatter(X[:, 0], X[:, ...\n```", "```py\nIn [5]: import cv2\n...     model_norm = cv2.ml.NormalBayesClassifier_create()\n```", "```py\nIn [6]: model_norm.train(X_train, cv2.ml.ROW_SAMPLE, y_train)\nOut[6]: True\n```", "```py\nIn [7]: _, y_pred = model_norm.predict(X_test)\nIn [8]: from sklearn import metrics\n...     metrics.accuracy_score(y_test, y_pred)\nOut[8]: 1.0\n```", "```py\nIn [9]: def plot_decision_boundary(model, X_test, y_test):\n...         # create a mesh to plot in\n...         h = 0.02 # step size in mesh\n...         x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() +\n            1\n...         y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() +\n            1\n...         xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n...                              np.arange(y_min, y_max, h))\n```", "```py\n...         X_hypo = np.column_stack((xx.ravel().astype(np.float32),\n...                                   yy.ravel().astype(np.float32)))\n```", "```py\n...         ret = model.predict(X_hypo)\n```", "```py\n...         if isinstance(ret, tuple):\n...             zz = ret[1]\n...         else:\n...             zz = ret\n...         zz = zz.reshape(xx.shape)\n```", "```py\n...         plt.contourf(xx, yy, zz, cmap=plt.cm.coolwarm, alpha=0.8)\n...         plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=200)\n```", "```py\nIn [10]: plot_decision_boundary(model_norm, X, y)\n```", "```py\nIn [11]: ret, y_pred, y_proba = model_norm.predictProb(X_test)\n```", "```py\nIn [12]: y_proba.round(2)\nOut[12]: array([[ 0.15000001,  0.05      ],\n                [ 0.08      ,  0\\.        ],\n                [ 0\\.        ,  0.27000001],\n                [ 0\\.        ,  0.13      ],\n                [ 0\\.        ,  0\\.        ],\n                [ 0.18000001,  1.88      ],\n                [ 0\\.        ,  0\\.        ],\n                [ 0\\.        ,  1.88      ],\n                [ 0\\.        ,  0\\.        ],\n                [ 0\\.        ,  0\\.        ]], dtype=float32)\n```", "```py\nIn [13]: from sklearn import naive_bayes...      model_naive = naive_bayes.GaussianNB()\n```", "```py\nIn [14]: model_naive.fit(X_train, y_train)Out[14]: GaussianNB(priors=None)\n```", "```py\nIn [15]: model_naive.score(X_test, y_test)Out[15]: 1.0\n```", "```py\nIn [16]: yprob = model_naive.predict_proba(X_test) ...\n```", "```py\nIn [18]: def plot_proba(model, X_test, y_test):\n...          # create a mesh to plot in\n...          h = 0.02 # step size in mesh\n...          x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n...          y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n...          xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n...                               np.arange(y_min, y_max, h))\n```", "```py\n\n...          X_hypo = np.column_stack((xx.ravel().astype(np.float32),\n...                                    yy.ravel().astype(np.float32)))\n```", "```py\n...          if hasattr(model, 'predictProb'):\n...             _, _, y_proba = model.predictProb(X_hypo)\n...          else:\n...             y_proba = model.predict_proba(X_hypo)\n```", "```py\n...          zz = y_proba[:, 1] - y_proba[:, 0]\n...          zz = zz.reshape(xx.shape)\n```", "```py\n... plt.contourf(xx, yy, zz, cmap=plt.cm.coolwarm, alpha=0.8)\n... plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=200)\n```", "```py\nIn [19]: plot_proba(model_naive, X, y)\n```", "```py\nIn [1]: HAM = 0\n...     SPAM = 1\n...     datadir = 'data/chapter7'\n...     sources = [\n...        ('beck-s.tar.gz', HAM),\n...        ('farmer-d.tar.gz', HAM),\n...        ('kaminski-v.tar.gz', HAM),\n...        ('kitchen-l.tar.gz', HAM),\n...        ('lokay-m.tar.gz', HAM),\n...        ('williams-w3.tar.gz', HAM),\n...        ('BG.tar.gz', SPAM),\n...        ('GP.tar.gz', SPAM),\n...        ('SH.tar.gz', SPAM)\n...     ]\n```", "```py\nIn [2]: def extract_tar(datafile, extractdir):\n...         try:\n...             import tarfile\n...         except ImportError:\n...             raise ImportError(\"You do not have tarfile installed. \"\n...                               \"Try unzipping the file outside of \"\n...                               \"Python.\")\n...         tar = tarfile.open(datafile)\n...         tar.extractall(path=extractdir)\n...         tar.close()\n...         print(\"%s successfully extracted to %s\" % (datafile,\n...                                                    extractdir))\n```", "```py\nIn [3]: for source, _ in sources:\n...         datafile = '%s/%s' % (datadir, source)\n...         extract_tar(datafile, datadir)\nOut[3]: data/chapter7/beck-s.tar.gz successfully extracted to data/chapter7\n        data/chapter7/farmer-d.tar.gz successfully extracted to\n            data/chapter7\n        data/chapter7/kaminski-v.tar.gz successfully extracted to\n            data/chapter7\n        data/chapter7/kitchen-l.tar.gz successfully extracted to\n            data/chapter7\n        data/chapter7/lokay-m.tar.gz successfully extracted to\n            data/chapter7\n        data/chapter7/williams-w3.tar.gz successfully extracted to\n            data/chapter7\n        data/chapter7/BG.tar.gz successfully extracted to data/chapter7\n        data/chapter7/GP.tar.gz successfully extracted to data/chapter7\n        data/chapter7/SH.tar.gz successfully extracted to data/chapter7\n```", "```py\nIn [4]: import os\n...     def read_single_file(filename):\n...         past_header, lines = False, []\n```", "```py\n...         if os.path.isfile(filename):\n...             f = open(filename, encoding=\"latin-1\")\n...             for line in f:\n```", "```py\n...                 if past_header:\n...                     lines.append(line)\n...                 elif line == '\\n':\n...                     past_header = True\n...             f.close()\n```", "```py\n...         content = '\\n'.join(lines)\n...         return filename, content\n```", "```py\nIn [5]: def read_files(path):\n...         for root, dirnames, filenames in os.walk(path):\n...             for filename in filenames:\n...                 filepath = os.path.join(root, filename)\n...                 yield read_single_file(filepath)\n```", "```py\nIn [6]: import pandas as pd\n```", "```py\nIn [7]: pd.DataFrame({...         'model': [...             'Normal Bayes',...             'Multinomial Bayes',...             'Bernoulli Bayes'...         ],...         'class': [...             'cv2.ml.NormalBayesClassifier_create()',...             'sklearn.naive_bayes.MultinomialNB()',... 'sklearn.naive_bayes.BernoulliNB()' ...\n```", "```py\nIn [10]: from sklearn import feature_extraction\n...      counts = feature_extraction.text.CountVectorizer()\n...      X = counts.fit_transform(data['text'].values)\n...      X.shape\nOut[10]: (52076, 643270)\n```", "```py\nIn [11]: X\nOut[11]: <52076x643270 sparse matrix of type '<class 'numpy.int64'>'\n                 with 8607632 stored elements in Compressed Sparse Row \n                 format>\n```", "```py\nIn [12]: y = data['class'].values\n```", "```py\nIn [13]: from sklearn import model_selection as ms...      X_train, X_test, y_train, y_test = ms.train_test_split(...          X, y, test_size=0.2, random_state=42...      )\n```", "```py\nIn [14]: import cv2...      model_norm = cv2.ml.NormalBayesClassifier_create()\n```", "```py\nIn [17]: from sklearn import naive_bayes\n...      model_naive = naive_bayes.MultinomialNB()\n...      model_naive.fit(X_train, y_train)\nOut[17]: MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n```", "```py\nIn [18]: model_naive.score(X_train, y_train)\nOut[18]: 0.95086413826212191\nIn [19]: model_naive.score(X_test, y_test)\nOut[19]: 0.94422043010752688\n```"]