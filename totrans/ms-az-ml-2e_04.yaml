- en: '*Chapter 3*: Preparing the Azure Machine Learning Workspace'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第三章*：准备Azure Machine Learning工作区'
- en: In the previous chapter, we learned how to navigate different Azure services
    for implementing ML solutions in the cloud. We realized that the best service
    for training custom ML models programmatically and automating infrastructure and
    deployments is the Azure Machine Learning service. In this chapter, we will set
    up and explore the Azure Machine Learning workspace, create a cloud training cluster,
    and perform data experimentation locally and on cloud compute, while collecting
    all the artifacts of the ML runs in Azure Machine Learning.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何导航不同的Azure服务以在云中实现ML解决方案。我们意识到，对于程序化训练自定义ML模型并自动化基础设施和部署来说，最佳服务是Azure
    Machine Learning服务。在本章中，我们将设置并探索Azure Machine Learning工作区，创建云训练集群，并在本地和云计算上执行数据实验，同时收集Azure
    Machine Learning中ML运行的全部工件。
- en: In the first section, we will learn how to manage Azure resources using different
    tools such as the Azure **Command-Line Interface (CLI)**, the Azure SDKs, and
    **Azure Resource Manager (ARM)** templates. We will set up and explore the Azure
    CLI, as well as Azure Machine Learning extensions, and subsequently deploy an
    Azure Machine Learning workspace.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一部分，我们将学习如何使用不同的工具管理Azure资源，例如Azure **命令行界面 (CLI**)、Azure SDKs和**Azure资源管理器
    (ARM**)模板。我们将设置并探索Azure CLI以及Azure Machine Learning扩展，然后部署Azure Machine Learning工作区。
- en: We will then look under the hood of Azure Machine Learning by exploring the
    resources that were deployed as part of Azure Machine Learning, such as the storage
    account, Azure Key Vault, Azure Application Insights, and Azure Container Registry.
    Following that, we will dive into Azure Machine Learning and explore the workspace
    to better understand the individual components.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将通过探索作为Azure Machine Learning一部分部署的资源来深入了解Azure Machine Learning，例如存储账户、Azure
    Key Vault、Azure Application Insights和Azure Container Registry。随后，我们将深入研究Azure
    Machine Learning并探索工作区，以更好地理解各个组件。
- en: Finally, in the last section, we will put all this knowledge into practice and
    run our first experiment with Azure Machine Learning. After setting up our environment,
    we will enhance a simple ML Keras training script to log metrics, logs, models,
    and code snapshots into Azure Machine Learning. We will then progress to schedule
    training runs on our local machine as well as on a training cluster in Azure.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在最后一部分，我们将把所有这些知识付诸实践，并使用Azure Machine Learning运行我们的第一个实验。在设置好我们的环境后，我们将增强一个简单的ML
    Keras训练脚本，将其指标、日志、模型和代码快照记录到Azure Machine Learning。然后，我们将继续在本地机器以及Azure的训练集群上安排训练运行。
- en: By the end of this chapter, you will see all your successful training runs,
    metrics, and tracked models in your Azure Machine Learning workspace, and you
    will have a good understanding of Azure Machine Learning to start your ML journey.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将在Azure Machine Learning工作区中看到所有成功的训练运行、指标和跟踪的模型，并且您将对Azure Machine
    Learning有一个良好的理解，从而开始您的ML之旅。
- en: 'The following are the topics that will be covered in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Deploying an Azure Machine Learning workspace
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署Azure Machine Learning工作区
- en: Exploring the Azure Machine Learning service
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索Azure Machine Learning服务
- en: Running ML experiments with Azure Machine Learning
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Azure Machine Learning运行ML实验
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will use the following Python libraries and versions to
    perform and manage experiment runs on Azure Machine Learning:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下Python库和版本在Azure Machine Learning上执行和管理实验运行：
- en: '`azureml-core 1.34.0`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`azureml-core 1.34.0`'
- en: '`azureml-sdk 1.34.0`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`azureml-sdk 1.34.0`'
- en: '`azureml-widgets 1.34.0`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`azureml-widgets 1.34.0`'
- en: '`tensorflow 2.6.0`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow 2.6.0`'
- en: You can run this code using either a local Python interpreter or a notebook
    environment hosted in Azure Machine Learning. However, some scripts need to be
    scheduled to execute in Azure.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用本地Python解释器或Azure Machine Learning中托管的笔记本环境运行此代码。然而，某些脚本需要计划在Azure中执行。
- en: 'All code examples in this chapter can be found in the GitHub repository for
    this book: [https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter03](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter03).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中所有的代码示例都可以在本书的GitHub仓库中找到：[https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter03](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter03)。
- en: Deploying an Azure Machine Learning workspace
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署Azure Machine Learning工作区
- en: Before we can start delving deep into ML on Azure itself, we need to understand
    how to deploy an Azure Machine Learning workspace or Azure services in general,
    what tooling is supported, and which one of those we will use to work with throughout
    the book.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够深入探讨Azure上的机器学习之前，我们需要了解如何部署Azure机器学习工作区或Azure服务，支持哪些工具，以及我们将在整本书中使用哪一个来工作。
- en: As a first step, we will require an Azure subscription.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们需要一个Azure订阅。
- en: If you are working in an organization and want to use your work account, you
    can go to portal.azure.com and log in with your work account. If the login works,
    you will land on the portal itself, and your work account is shown at the top
    right. This means that your company already has an **Azure Active Directory**
    (**AAD**) instance set up. In this case, talk to your Azure Global Administrator,
    if you haven't already, to discuss which Azure subscription to use for your purpose.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在组织中工作并想使用您的工账户，您可以访问portal.azure.com并使用您的工账户登录。如果登录成功，您将进入门户本身，您的工账户将显示在右上角。这意味着您的公司已经设置了**Azure
    Active Directory**（**AAD**）实例。在这种情况下，如果您还没有，请与您的Azure全球管理员联系，讨论您应该使用哪个Azure订阅来满足您的需求。
- en: If you are new to Azure and want to use your private account, go to azure.com
    and click on **Free Account** to create an AAD for yourself with a free trial
    subscription. This trial gives you a certain amount of money to spend for 30 days
    on Azure services.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是Azure的新用户并想使用您的私人账户，请访问azure.com并点击**免费账户**创建一个带有免费试用订阅的AAD。这个试用订阅在30天内为您提供了在Azure服务上花费的一定金额。
- en: In any case, in the end, you should have the capability to log in to the Azure
    portal with your identity, and you should know which Azure subscription (name
    and/or subscription ID) you want to deploy your ML services to.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，最终，您应该能够使用您的身份登录到Azure门户，并且您应该知道您想要将机器学习服务部署到哪个Azure订阅（名称和/或订阅ID）。
- en: With this all done, we will now have a look at how to deploy and manage our
    Azure environment in general and what options and tooling there are to choose
    from.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有这些后，我们现在将看看如何部署和管理我们的Azure环境，以及有哪些选项和工具可供选择。
- en: Understanding the available tooling for Azure deployments
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解Azure部署的可用工具
- en: 'In Azure, any action that deploys or changes an Azure service goes through
    the so-called ARM. As shown in *Figure 3.1*, ARM accepts requests from either
    the **Azure portal**, **Azure PowerShell** (a PowerShell extension), the **Azure
    CLI**, or the **Azure REST API**:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure中，任何部署或更改Azure服务的操作都通过所谓的ARM（Azure资源管理器）进行。如图*图3.1*所示，ARM接受来自**Azure门户**、**Azure
    PowerShell**（PowerShell扩展）、**Azure CLI**或**Azure REST API**的请求：
- en: '![Figure 3.1 – Azure Resource Manager ](img/B17928_03_001.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1 – Azure资源管理器](img/B17928_03_001.jpg)'
- en: Figure 3.1 – Azure Resource Manager
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – Azure资源管理器
- en: In the Azure portal, you can select `machine learning`, the set of results set
    will show a service called **Machine Learning** from Microsoft. Clicking on this
    card and then **Create** will open the deployment wizard for this service. This
    will give you a sense of what is required to deploy this service.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure门户中，您可以选择“机器学习”，结果集将显示一个来自微软的名为**机器学习**的服务。点击这张卡片然后**创建**将打开此服务的部署向导。这将让您了解部署此服务所需的内容。
- en: 'But we will not go any further on the portal itself, as we want to facilitate
    a more programmatic approach in this book. Using this approach will greatly enable
    the reproducibility and automation of all the tasks performed in Azure. Therefore,
    we will concentrate on the latter solutions – let''s take a look at them:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们不会在门户本身上进一步讨论，因为我们想在这本书中促进一种更程序化的方法。使用这种方法将极大地提高在Azure中执行的所有任务的重复性和自动化。因此，我们将专注于后者的解决方案——让我们来看看它们：
- en: '**Azure CLI**: This is a fully fledged command-line environment that you can
    install on every major operating system. The latest version can be downloaded
    from [https://docs.microsoft.com/en-us/cli/azure/install-azure-cli](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure CLI**：这是一个完整的命令行环境，您可以在每个主要操作系统上安装。最新版本可以从[https://docs.microsoft.com/en-us/cli/azure/install-azure-cli](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli)下载。'
- en: '**Azure Power Shell**: As the name suggests, this is a library of PowerShell
    modules, which can be added to a PowerShell environment. Previously, PowerShell
    was only available on Windows, but the new PowerShell Core 7.x now officially
    supports the major Linux releases and macOS. The following description shows how
    to install it on your system: https://docs.microsoft.com/en-us/powershell/azure/install-az-ps.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure Power Shell**：正如其名所示，这是一个 PowerShell 模块库，可以添加到 PowerShell 环境中。以前，PowerShell
    只在 Windows 上可用，但新的 PowerShell Core 7.x 现在正式支持主要的 Linux 版本和 macOS。以下描述展示了如何在您的系统上安装它：https://docs.microsoft.com/en-us/powershell/azure/install-az-ps。'
- en: '`curl` or the popular Python `requests` library. The following article describes
    the given syntax: https://docs.microsoft.com/en-us/rest/api/resources/.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`curl` 或流行的 Python `requests` 库。以下文章描述了给定的语法：https://docs.microsoft.com/en-us/rest/api/resources/。'
- en: All of these options allow the use of so-called **ARM templates** (https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview),
    Azure's version of **Infrastructure as Code** (**IaC**). It gives you the ability
    to save and version-control infrastructure definitions in files. This way is highly
    recommended when dealing with complex infrastructure deployment, but we will not
    dive any further into this topic. The only additional point to make here is that
    there are other tools on the market for IaC management. The most prominent tool
    is called **Terraform** (https://www.terraform.io/), which allows infrastructure
    management of any cloud vendor or on-premises environment, including Azure. To
    achieve this, Terraform utilizes the Azure CLI under the hood.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些选项都允许使用所谓的 **ARM 模板**（https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview），这是
    Azure 的 **基础设施即代码**（**IaC**）版本。它使您能够将基础设施定义保存到文件中并进行版本控制。在处理复杂的架构部署时，这种方式非常推荐，但我们不会深入探讨这个话题。这里要补充的唯一一点是，市场上还有其他用于
    IaC 管理的工具。最突出的工具称为 **Terraform**（https://www.terraform.io/），它允许管理任何云供应商或本地环境的架构，包括
    Azure。为了实现这一点，Terraform 在底层使用 Azure CLI。
- en: In summary, you can choose any of the aforementioned options for the tasks at
    hand, especially if you have a strong preference for one of them.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，您可以选择上述任何一种选项来完成手头的任务，尤其是如果您对其中之一有强烈的偏好。
- en: 'As we will not manage complex infrastructure and want to avoid any unnecessary
    additional levels of complexity, we will utilize the Azure CLI throughout the
    rest of the book. Furthermore, the new ML CLI extension offers a couple of neat
    features for Azure Machine Learning, which we will discover throughout the chapter:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不会管理复杂的架构并希望避免任何不必要的额外复杂性层级，我们将在本书的其余部分使用 Azure CLI。此外，新的 ML CLI 扩展为 Azure
    机器学习提供了一些实用的功能，我们将在本章中逐一发现：
- en: '![Figure 3.2 – The Azure CLI ](img/B17928_03_002.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.2 – Azure CLI](img/B17928_03_002.jpg)'
- en: Figure 3.2 – The Azure CLI
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – Azure CLI
- en: If you haven't already, please feel free to download and install or update the
    CLI with the latest version. When you are ready, open your favorite command line
    or terminal and type `az` into the console. You should be greeted by the screen
    shown in *Figure 3.2*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有做，请随意下载并安装或更新 CLI 到最新版本。准备好后，打开您喜欢的命令行或终端，并在控制台中输入 `az`。您应该会看到如图 3.2 所示的屏幕。
- en: Deploying the workspace
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署工作区
- en: 'After this short introduction to ARM, let''s deploy our first ML workspace.
    We will deploy a workspace using the Azure CLI. If you would like to rather deploy
    it via the Azure portal, you can follow this tutorial: https://docs.microsoft.com/en-us/azure/machine-learning/quickstart-create-resources.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在对 ARM 进行了简短的介绍之后，让我们部署我们的第一个 ML 工作区。我们将使用 Azure CLI 来部署工作区。如果您想通过 Azure 门户部署它，可以遵循这个教程：https://docs.microsoft.com/en-us/azure/machine-learning/quickstart-create-resources。
- en: 'If you had a short look through the list of commands in the CLI, you might
    have noticed that there seems to be no command referencing ML. Let''s rectify
    this and set up our first Azure Machine Learning workspace via the CLI following
    these steps:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您简要地浏览了 CLI 命令列表，可能会注意到似乎没有命令引用 ML。让我们纠正这一点，并按照以下步骤通过 CLI 设置我们的第一个 Azure 机器学习工作区：
- en: 'Log in to your Azure environment through the CLI:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 CLI 登录到您的 Azure 环境：
- en: '[PRE0]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This command will open a website with an AAD login screen. After you have done
    this, return to the console. The screen will now show you some information about
    your AAD tenant (`homeTenantId`), your subscriptions (`id`, `name`), and your
    user.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将打开一个带有AAD登录界面的网站。完成此操作后，请返回控制台。现在屏幕将显示有关您的AAD租户（`homeTenantId`）、您的订阅（`id`、`name`）以及您的用户的一些信息。
- en: 'If you have more than one subscription shown to you and need to check which
    subscription is active, use the following command:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果显示给您多个订阅，并且您需要检查哪个订阅是活动的，请使用以下命令：
- en: '[PRE1]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the output, check whether the `IsDefault` column shows `True` for your preferred
    subscription. If not, use the following command to set it to your chosen one by
    typing in the name of it – `<yoursub>` – and checking again:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在输出中，检查`IsDefault`列是否显示为`True`以表示您首选的订阅。如果不是，请使用以下命令将其设置为所选订阅，输入其名称 – `<yoursub>`
    – 然后再次检查：
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now that we are deploying to the correct subscription in the correct tenant,
    let''s check the situation with the installed extension. Type in the following
    command in your terminal:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们正在将部署到正确的租户中的正确订阅，让我们检查已安装扩展的情况。在您的终端中输入以下命令：
- en: '[PRE3]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If neither `azure-cli-ml` nor `ml` is shown in the list, you are missing an
    extension for using Azure Machine Learning via the CLI. The first of them denotes
    `Azure ML CLI 1.0`, the second one `Azure ML CLI 2.0`. Version 2 of the ML CLI
    was announced at Microsoft Build 2021 ([https://techcommunity.microsoft.com/t5/azure-ai/announcing-the-new-cli-and-arm-rest-apis-for-azure-machine/ba-p/2393447](https://techcommunity.microsoft.com/t5/azure-ai/announcing-the-new-cli-and-arm-rest-apis-for-azure-machine/ba-p/2393447)),
    offering fine-grained control of the ML workspace. Therefore, we will be using
    the new version of the CLI extension.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果列表中既没有显示`azure-cli-ml`也没有显示`ml`，则您缺少用于通过CLI使用Azure机器学习的扩展。第一个表示`Azure ML CLI
    1.0`，第二个表示`Azure ML CLI 2.0`。ML CLI的2.0版本在2021年Microsoft Build上宣布（[https://techcommunity.microsoft.com/t5/azure-ai/announcing-the-new-cli-and-arm-rest-apis-for-azure-machine/ba-p/2393447](https://techcommunity.microsoft.com/t5/azure-ai/announcing-the-new-cli-and-arm-rest-apis-for-azure-machine/ba-p/2393447)），提供了对ML工作区的精细控制。因此，我们将使用新的CLI扩展版本。
- en: Important Note
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Azure ML CLI 2.0 offers new abilities to directly control the jobs, clusters,
    and pipelines of the ML workspace from the command line. It also offers support
    for YAML configuration files, which are crucial for MLOps.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Azure ML CLI 2.0提供了从命令行直接控制ML工作区的作业、集群和管道的新功能。它还提供了对YAML配置文件的支持，这对于MLOps至关重要。
- en: 'If you are running the old version, you should remove that version, but be
    aware that, as some commands are slightly different, you might break a script
    you are already using. To clean up the namespace and remove the previous version,
    you can use the following commands:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您正在运行旧版本，应删除该版本，但请注意，由于一些命令略有不同，您可能会破坏您正在使用的脚本。要清理命名空间并删除旧版本，可以使用以下命令：
- en: '[PRE4]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let''s install the ML extension using the following command:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用以下命令安装ML扩展：
- en: '[PRE5]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After that, feel free to check the installed extensions again.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，您可以随意再次检查已安装的扩展。
- en: 'Now, we will be able to use it. First off, we will have a look at the help
    page for the extension:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将能够使用它。首先，我们将查看扩展的帮助页面：
- en: '[PRE6]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This will show you the following subgroups:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示以下子组：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As you can see, we have a lot of options to control our workspace from the CLI.
    We will come back to many of them later in the book. For now, we are interested
    in managing our workspace.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们有大量的选项可以从CLI控制我们的工作区。我们将在本书的后面回到许多这些选项。现在，我们感兴趣的是管理我们的工作区。
- en: 'If you type the following command, we will have a look to see whether we are
    still missing requirements for the creation of the ML workspace:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您输入以下命令，我们将查看是否仍缺少创建ML工作区所需的要求：
- en: '[PRE8]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Going through the arguments, you will see that a **resource group** is required.
    A resource group in Azure is a logical construct where resources need to be deployed
    to. It is one vital part of the **Azure management hierarchy**. For further reading,
    have a look at access management in Azure: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-setup-guide/organize-resources.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看参数时，您会看到需要一个**资源组**。Azure中的资源组是一个逻辑结构，资源需要部署到其中。它是**Azure管理层次结构**的一个重要部分。有关进一步阅读，请参阅Azure中的访问管理：https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-setup-guide/organize-resources。
- en: Furthermore, if you scroll down to the examples in the console output, you will
    also see that the new version of the CLI has a neat property that lets us deploy
    the workspace from a **Yet Another Markup Language** (**YAML**) file. We will
    not do this now, but it is something to keep in mind.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果您在控制台输出中向下滚动到示例，您还会看到新的 CLI 版本有一个整洁的特性，允许我们从 **另一种标记语言** (**YAML**) 文件中部署工作区。我们现在不会这样做，但这是需要记住的事情。
- en: Important Note
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The Azure Machine Learning service can be completely operated using the Azure
    ML CLI 2.0 extension, YAML configuration files, and a training or inference script.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习服务可以完全使用 Azure ML CLI 2.0 扩展、YAML 配置文件和训练或推理脚本来操作。
- en: 'A resource group in Azure also requires a location. Therefore, let''s have
    a look at the available data center locations for the Azure cloud by running this
    command:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure 中的资源组也需要一个位置。因此，让我们运行以下命令来查看 Azure 云可用的数据中心位置：
- en: '[PRE9]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Have a look at the name of your preferred region and use it in the following
    command to create the resource group. Our example here will create a resource
    group in West US 2 with the name `mldemo`:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 查看您首选区域的名称，并在以下命令中使用它来创建资源组。我们在此的示例将在西 US 2 创建一个名为 `mldemo` 的资源组：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Important Note
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Even though we define the resource group to be in West US 2, resources inside
    a resource group can be in different regions. It is just best practice to define
    a group in a specific region and let the resources inside that group be in the
    same region.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们定义资源组位于西 US 2，但资源组内的资源可以位于不同的区域。这只是将组定义在特定区域并让该组内的资源位于同一区域的最佳实践。
- en: 'Now, we can create the workspace itself by using the following command:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用以下命令创建工作区本身：
- en: '[PRE11]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will create a workspace named `mldemows` in the `mldemo` resource group.
    If we remove the location setting, it will take the location of the resource group.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在 `mldemo` 资源组中创建一个名为 `mldemows` 的工作区。如果我们删除位置设置，它将采用资源组的位置。
- en: 'This command can take a bit of time. When it is done, you will see output like
    this:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令可能需要一些时间。完成后，您将看到如下输出：
- en: '[PRE12]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As you can see, the preceding command created multiple resources, together with
    the Azure Machine Learning workspace, that are required for running ML experiments.
    We will come back to the reasons in the next section.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，前面的命令创建了多个资源，包括 Azure 机器学习工作区，这些资源对于运行 ML 实验是必需的。我们将在下一节中回到这些原因。
- en: 'Finally, to have a look at the deployment at any point, you can run the following
    command:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，要查看任何时间点的部署，您可以运行以下命令：
- en: '[PRE13]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We have created our first Azure Machine Learning workspace. Good work! In the
    next section, we will have a look at what this entails.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已创建了第一个 Azure 机器学习工作区。做得好！在下一节中，我们将探讨这包含哪些内容。
- en: Exploring the Azure Machine Learning service
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 Azure 机器学习服务
- en: Before we continue to set up our own development environment and do some ML,
    we will have a look at what was just deployed besides the main workspace, get
    a base understanding of all features available in the service, which we will utilize
    throughout the book, and have a first short look at **Azure Machine Learning**
    **Studio**.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续设置自己的开发环境并进行一些 ML 之前，我们将查看除了主要工作区之外已部署的内容，了解服务中所有可用的功能的基础知识，这些功能我们将贯穿整本书，并首次简要了解
    **Azure 机器学习** **工作室**。
- en: Analyzing the deployed services
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析已部署的服务
- en: 'We will start by navigating to the Azure portal again. There, type the name
    of the workspace as `mldemows` in the top search bar. You should see something
    like the result shown in *Figure 3.3*:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先再次导航到 Azure 门户。在那里，在顶部搜索栏中键入工作区的名称为 `mldemows`。您应该会看到类似于 *图 3.3* 中所示的结果：
- en: '![Figure 3.3 – An Azure portal search for an ML workspace ](img/B17928_03_003.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.3 – Azure 门户中搜索 ML 工作区](img/B17928_03_003.jpg)'
- en: Figure 3.3 – An Azure portal search for an ML workspace
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 – Azure 门户中搜索 ML 工作区
- en: As you can see, besides the main `mldemows` workspace, three other services
    were deployed, namely **Storage account**, **Key vault**, and **Application Insights**.
    As most of them require unique names, you will see a random alphanumeric code
    at the end of each name. For each one of these additional services, we can provide
    our own already existing service when we deploy the workspace.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，除了主要的 `mldemows` 工作区外，还部署了三个其他服务，即**存储账户**、**密钥保管库**和**应用程序洞察**。由于它们大多数需要唯一的名称，您将在每个名称的末尾看到一个随机的字母数字代码。对于这些附加服务中的每一个，我们可以在部署工作区时提供我们自己的已存在服务。
- en: In addition, an **Azure container registry** will be required at a later stage
    but does not need to be there during the initial deployment of the workspace.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在稍后的阶段将需要**Azure 容器注册库**，但在工作区初始部署期间不需要它。
- en: Knowing now what additional services were deployed, let's discuss why they are
    there.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了部署了哪些附加服务，让我们来讨论它们为什么存在。
- en: The storage account for an ML workspace
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习工作区的存储账户
- en: The storage account, typically referred to as the **default storage account**,
    is the main datastore for the workspace. This storage is vital for the operation
    of the service. It stores among other things experiment runs, models, snapshots,
    and even source files, such as Jupyter notebooks. We will have a more in-depth
    look at default workspace storage, many other datastores in and around Azure,
    and how they can be integrated in [*Chapter 4*](B17928_04_ePub.xhtml#_idTextAnchor071),
    *Ingesting Data and Managing Datasets*.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 存储账户，通常被称为**默认存储账户**，是工作区的主要数据存储。这种存储对于服务的运行至关重要。它存储了实验运行、模型、快照，甚至源文件，如 Jupyter
    笔记本。我们将在[*第 4 章*](B17928_04_ePub.xhtml#_idTextAnchor071)中更深入地探讨默认工作区存储、Azure 中的许多其他数据存储以及它们如何集成，*数据摄取和管理数据集*。
- en: Important Note
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Be aware that if you would want to use your own storage account as default storage
    when deploying the workspace, it cannot have a hierarchical namespace (Azure Data
    Lake) and it cannot be premium storage (high-performant SSDs).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果你想在部署工作区时使用自己的存储账户作为默认存储，它不能有分层命名空间（Azure 数据湖）并且不能是高级存储（高性能 SSD）。
- en: Azure Key Vault for an ML workspace
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习工作区的 Azure 密钥保管库
- en: Key Vault is a cloud-managed service that can store *secrets* such as passwords,
    API keys, certificates, and cryptographic keys. Secrets in the service are held
    either in a software vault or a managed **Hardware Security Module** (**HSM**).
    For the ML workspace, and any other service for that matter, it is crucial to
    store your access keys in a secure environment.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 密钥保管库是一种云托管服务，可以存储诸如密码、API 密钥、证书和加密密钥等密钥。服务中的密钥要么存储在软件保管库中，要么存储在托管的**硬件安全模块**（HSM）中。对于机器学习工作区以及任何其他服务，将访问密钥存储在安全环境中至关重要。
- en: So far, we have only handled relatively unimportant information such as a subscription
    ID, but if we want, for example, to pull data from external storage, we will either
    need a key to access it or call a function to another service, where this information
    is stored securely. You can be the judge of what is the better choice.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只处理了相对不重要的信息，例如订阅 ID，但如果我们想从外部存储中拉取数据，我们可能需要一个访问它的密钥或调用另一个服务中的函数，该服务安全地存储了这些信息。你可以判断哪种选择更好。
- en: The developers of the ML workspace chose the latter options. Due to that, an
    Azure key vault is required to store the internal secrets for the workspace and
    give you the possibility to store any secret necessary to read out datasets, perform
    ML training on compute targets, and deploy your final models to internal or external
    targets.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习工作区的开发者选择了后者。因此，需要一个 Azure 密钥保管库来存储工作区的内部密钥，并为你提供存储任何必要密钥的可能性，以便读取数据集、在计算目标上进行机器学习训练以及将最终模型部署到内部或外部目标。
- en: Now, the question might arise of how to get secure access to Key Vault itself.
    This is done through a so-called **managed identity**, which gives the workspace
    (the app) itself an identity to assign rights to.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，可能会出现如何安全访问密钥保管库本身的问题。这是通过所谓的**管理身份**来完成的，它为工作区（应用程序）本身提供了一个身份来分配权限。
- en: Managed Identities on Azure
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 上的管理身份
- en: A managed identity is an identity given to an application that behaves the same
    way as a user identity.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 管理身份是赋予应用程序的身份，其行为方式与用户身份相同。
- en: As with the other services, you could have linked an already existing key vault
    during deployment without any restrictions.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他服务一样，在部署过程中，你可以没有任何限制地将已经存在的密钥保管库链接到应用洞察。
- en: Application Insights for an ML workspace
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习工作区的应用洞察
- en: '**Applications Insights** is a module of **Azure Monitor**, which in turn is
    a suite in Azure to monitor infrastructure and applications, which stores and
    surfaces infrastructure metrics such as CPU usage and log files of applications.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**应用程序洞察**是**Azure Monitor**的一个模块，而**Azure Monitor**是 Azure 中用于监控基础设施和应用程序的套件，它存储和显示基础设施指标，如
    CPU 使用率和应用程序的日志文件。'
- en: The Azure Machine Learning workspace uses Application Insights to store compute
    infrastructure logs, ML script logs, and defined metrics of the ML model runs
    and is therefore required for the operation of the workspace.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习工作区使用 Application Insights 存储计算基础设施日志、ML 脚本日志以及 ML 模型运行的定义度量标准，因此对于工作区的操作是必需的。
- en: Azure Container Registry for an ML workspace
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Azure 容器注册表用于 ML 工作区
- en: '**Azure Container Registry** (**ACR**) is a service based on the **Docker Registry**.
    It is used to store and manage Docker container images and artifacts. For the
    workspace, the registry is required at the point when we start running training
    on or deploying models to a compute that is not our local machine. In this process,
    a container is packed and registered to ACR, which then can be tracked and utilized
    in ML scripts or by deployment pipelines.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**Azure 容器注册表**（**ACR**）是基于 **Docker 注册表**的服务。它用于存储和管理 Docker 容器镜像和工件。对于工作区，当我们在本地机器之外的计算机上开始运行训练或部署模型时，需要该注册表。在这个过程中，容器被打包并注册到
    ACR，然后可以在 ML 脚本或部署管道中跟踪和使用。'
- en: Important Note
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Please be aware that the ML service by default deploys ACR in the basic service
    tier. To reduce the time for building and deploying an image to a compute target,
    you might want to change the Container Registry service level to Standard or Premium.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，默认情况下，ML 服务在基本服务层中部署 ACR。为了减少构建和部署镜像到计算目标的时间，您可能希望将容器注册表服务级别更改为标准或高级。
- en: Understanding the workspace interior
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解工作区内部结构
- en: 'Now that we understand the additional deployed service, we will have a look
    at the interior of the workspace itself. *Figure 3.4* shows nearly every aspect
    of note of an Azure Machine Learning workspace:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了额外部署的服务，我们将查看工作区本身的内部结构。*图 3.4* 展示了 Azure 机器学习工作区的几乎所有重要方面：
- en: '![Figure 3.4 – A structural view of an Azure Machine Learning workspace ](img/B17928_03_04.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.4 – Azure 机器学习工作区的结构视图](img/B17928_03_04.jpg)'
- en: Figure 3.4 – A structural view of an Azure Machine Learning workspace
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 – Azure 机器学习工作区的结构视图
- en: Let's get an understanding of each of these aspects, except for **Associated
    Azure resources**, as we already discussed that in the *Analyzing the deployed
    services* section.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解这些方面的每一个，除了 **关联的 Azure 资源**，因为我们已经在 *分析已部署的服务* 部分讨论过这一点。
- en: User roles
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户角色
- en: As with any other service in Azure, user authentication and authorization are
    performed through AAD and so-called **Azure Role-Based Access Control** (**Azure
    RBAC**).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Azure 中的任何其他服务一样，用户身份验证和授权是通过 AAD 以及所谓的 **Azure 基于角色的访问控制**（**Azure RBAC**）来执行的。
- en: Role-based Access Control on Azure
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 上的基于角色的访问控制
- en: Azure RBAC is used to assign to an identity from AAD (a user, a service principal,
    or a managed identity) a specific role on a resource, which defines the level
    of access to the resource and the type of granular action that can be performed.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Azure RBAC 用于将 AAD 中的身份（用户、服务主体或托管身份）分配到资源上的特定角色，该角色定义了对资源的访问级别和可以执行的具体细粒度操作。
- en: 'In the case of the ML workspace, we can assign an identity the Azure predefined
    base roles (**Owner**, **Contributor**, or **Reader**) and two custom roles named
    **AzureML Data Scientist** and **AzureML Metrics Writer**. Here are their details:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ML 工作区的情况下，我们可以分配 Azure 预定义的基本角色（**所有者**、**贡献者**或**读者**）以及两个自定义角色，名为 **AzureML
    数据科学家** 和 **AzureML Metrics Writer**。以下是它们的详细信息：
- en: '**Reader**: This role is allowed to look at everything but cannot change any
    data or action anything that would change the state of the resource (for example,
    deploying a compute or changing a network configuration).'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**读者**：此角色允许查看所有内容，但不能更改任何数据或执行任何会改变资源状态的操作（例如，部署计算或更改网络配置）。'
- en: '**Contributor**: This role is allowed to look at and change everything but
    is not allowed to change the user roles and rights on the resource.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贡献者**：此角色允许查看和更改所有内容，但不允许更改资源上的用户角色和权限。'
- en: '**Owner**: This role is allowed to do any action on a specific resource.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**所有者**：此角色允许在特定资源上执行任何操作。'
- en: '**AzureML Data Scientist**: This role is not allowed any action in the workspace
    except creating or deleting compute resources or modifying the workspace settings.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AzureML 数据科学家**：此角色在工作区中不允许执行任何操作，除了创建或删除计算资源或修改工作区设置。'
- en: '**AzureML Metrics Writer**: This role is only allowed to write metrics to the
    workspace.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AzureML Metrics Writer**：此角色仅允许将度量标准写入工作区。'
- en: Besides these, the ML workspace does not offer additional custom roles.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些，机器学习工作区不提供额外的自定义角色。
- en: To give you more fine-grained control in this matter, RBAC lets you build your
    own custom roles, as a lot of actions a user can perform in the ML workspace are
    defined as so-called **actions** in RBAC. All available actions for the Azure
    Machine Learning service can be found in this list of resource providers, [https://docs.microsoft.com/en-us/azure/role-based-access-control/resource-provider-operations](https://docs.microsoft.com/en-us/azure/role-based-access-control/resource-provider-operations),
    under the operation group named **Microsoft.MachineLearningServices**.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在此方面给您提供更精细的控制，基于角色的访问控制（RBAC）允许您构建自己的自定义角色，因为许多用户在机器学习工作区中可以执行的操作在RBAC中定义为所谓的**操作**。Azure机器学习服务所有可用的操作都可以在这个资源提供者列表中找到，[https://docs.microsoft.com/en-us/azure/role-based-access-control/resource-provider-operations](https://docs.microsoft.com/en-us/azure/role-based-access-control/resource-provider-operations)，在名为**Microsoft.MachineLearningServices**的操作组下。
- en: 'To get some inspiration for different roles, have a look at common scenarios
    and custom roles suggested by Microsoft: [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-assign-roles#common-scenarios](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-assign-roles#common-scenarios).
    We will have a look in the next section where you can define and assign them.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得不同角色的灵感，请查看Microsoft建议的常见场景和自定义角色：[https://docs.microsoft.com/en-us/azure/machine-learning/how-to-assign-roles#common-scenarios](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-assign-roles#common-scenarios)。我们将在下一节中查看，您可以在那里定义和分配它们。
- en: Experiments
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实验
- en: The goal of ML – in a nutshell – is to find a mathematical function, which would
    be hard to find algorithmically, that when given specific input results in as
    many cases as possible in the expected output. This function is typically referred
    to as an **ML model**. A model we train might be a function that assigns voices
    in a sound file to specific speakers or that recommends products for customers
    on a web shop based on the buying behavior of similar buyers (see [*Chapter 13*](B17928_13_ePub.xhtml#_idTextAnchor202),
    *Building a Recommendation Engine in Azure*).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的目标——简而言之——是找到一个数学函数，这个函数在算法上很难找到，当给定特定的输入时，尽可能多地产生预期的输出。这个函数通常被称为**机器学习模型**。我们训练的模型可能是一个将声音文件中的声音分配给特定说话者的函数，或者基于类似购买者的购买行为向网络商店中的客户推荐产品的函数（参见[*第13章*](B17928_13_ePub.xhtml#_idTextAnchor202)，“在Azure中构建推荐引擎”）。
- en: To achieve this, we need to train ML models utilizing already existing ML algorithms,
    with the goal to lower the output of the so-called **loss function** of said model.
    This requires tweaking the settings of our models and, mathematically speaking,
    in the best case, finding the global minimum of the loss function on the *n*-dimensional
    room of all possible functions. Depending on the complexity of our model, this
    requires a lot of reiterations.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这一点，我们需要利用现有的机器学习算法来训练机器学习模型，目标是降低该模型所谓的**损失函数**的输出。这需要调整我们模型的设置，从数学上讲，在最佳情况下，找到所有可能函数的**n**维空间中损失函数的全局最小值。根据我们模型的复杂性，这可能需要大量的迭代。
- en: Therefore, to keep track of the iterations of our model training, we define
    them as **runs** and align them to a construct called an **experiment**, which
    collects all information concerning a specific model we want to train. To do this,
    we will connect any training script run we perform to a specific experiment.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了跟踪我们模型训练的迭代过程，我们将它们定义为**运行**，并将它们与一个称为**实验**的结构对齐，该结构收集了我们想要训练的特定模型的全部信息。为此，我们将我们执行的任何训练脚本运行与一个特定的实验关联起来。
- en: Datasets and datastores
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集和数据存储
- en: Any ML model requires data to operate with, either for training or for testing
    purposes. Instead of linking data sources and different data files directly in
    our scripts, we can reference **datasets**, which we can define inside the workspace.
    Datasets, in turn, curate data from **datastores**, which we can define and attach
    in the workspace. We will go into more detail on how to handle data, datasets,
    and datastores in [*Chapter 4*](B17928_04_ePub.xhtml#_idTextAnchor071), *Ingesting
    Data and Managing Datasets*.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 任何机器学习模型都需要数据来操作，无论是用于训练还是测试。我们可以在脚本中直接链接数据源和不同的数据文件，而不是引用**数据集**，我们可以在工作区内部定义这些数据集。反过来，数据集会从**数据存储**中整理数据，我们可以定义并在工作区中附加这些数据存储。我们将在[*第4章*](B17928_04_ePub.xhtml#_idTextAnchor071)“导入数据和管理数据集”中更详细地介绍如何处理数据、数据集和数据存储。
- en: Compute targets
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算目标
- en: 'In order to run experiments and, later on, host models for inferencing, we
    require a **compute target**. The ML service comes with two options in this area,
    namely the following:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行实验，并在以后托管用于推理的模型，我们需要一个**计算目标**。ML服务在此领域提供了两个选项，如下所示：
- en: '**Compute instance**: A single virtual machine typically used for development,
    as a notebook server, or as a target for training and inference'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算实例**：一个单独的虚拟机，通常用于开发、作为笔记本服务器或作为训练和推理的目标'
- en: '**Compute cluster**: A multi-node cluster of machines typically used for complex
    training and production environments for inference'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算集群**：一个多节点集群，通常用于复杂训练和推理生产环境'
- en: 'You can find a list of supported compute targets (virtual machines) here: [https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target#supported-vm-series-and-sizes](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target#supported-vm-series-and-sizes).
    There are more details concerning their pricing in the following overview: [https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/](https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处找到支持的计算目标（虚拟机）列表：[https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target#supported-vm-series-and-sizes](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target#supported-vm-series-and-sizes)。有关它们定价的更多详细信息，请参阅以下概述：[https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/](https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/)。
- en: Besides these two options, the workspace offers a bunch of other possible targets
    for both training and inferencing. Popular compute options are your own local
    computer, any type of Spark engine (**Apache Spark**, **Azure Databricks**, or
    **Synapse**) for training, and **Azure Kubernetes Service** (**AKS**) for inferencing.
    For a full updated list of options, refer to [https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这两个选项之外，工作区还提供了一系列其他可能的训练和推理目标。流行的计算选项包括您自己的本地计算机、任何类型的Spark引擎（**Apache Spark**、**Azure
    Databricks**或**Synapse**）用于训练，以及**Azure Kubernetes Service**（**AKS**）用于推理。有关选项的完整更新列表，请参阅[https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target)。
- en: Environments
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 环境
- en: When you write a simple Python script and run it in the Python interpreter,
    you run it in a so-called `numpy`), and certainly the operating system you are
    running it on. This is also true for any ML script that we run.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当你编写一个简单的Python脚本并在Python解释器中运行它时，你就是在所谓的`numpy`环境中运行它，当然还有你正在运行的操作系统。对于任何我们运行的ML脚本也是如此。
- en: For our purpose, we operate in an environment that requires a specific Python
    version and certain libraries such as the Azure Machine Learning Python SDK and
    libraries containing ML algorithms and tooling, such as **TensorFlow**. For our
    own local machine, and especially if we want to run our script on a much faster
    compute cluster in the workspace, we need a good way to define the environment
    for the compute target.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的，我们在一个需要特定Python版本和某些库的环境中操作，例如Azure Machine Learning Python SDK以及包含ML算法和工具的库，如**TensorFlow**。对于我们的本地机器，尤其是如果我们想在工作区中的更快计算集群上运行我们的脚本，我们需要一种良好的方法来定义计算目标的
    环境。
- en: 'To facilitate this, the workspace gives us the ability to define and register
    ML environments. These are typically **Docker containers** encompassing the OS
    and every runtime, library, and dependency required. For defining libraries and
    dependencies for Python inside the container, the package manager **Conda** ([https://conda.io/](https://conda.io/))
    is used in most cases under the hood. Speaking of that, let''s classify the types
    of environments we can work with or create:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于操作，工作区为我们提供了定义和注册ML环境的能力。这些通常是包含操作系统和每个运行时、库以及依赖项的**Docker容器**。对于在容器内定义Python的库和依赖项，大多数情况下在幕后使用包管理器**Conda**（[https://conda.io/](https://conda.io/））。说到这一点，让我们来分类我们可以工作或创建的环境类型：
- en: '**Curated environments** use predefined environments containing typical runtimes
    and ML frameworks.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精选环境**使用包含典型运行时和ML框架的预定义环境。'
- en: '**System-managed environments** (using default behavior) build environments
    starting from a base image with dependency management through Conda.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统管理的环境**（使用默认行为）从基础镜像开始构建环境，通过Conda进行依赖管理。'
- en: '**User-managed environments** build environments by either starting from a
    base image but allowing you to handle all libraries and dependencies yourself
    through Docker steps, or by creating a complete custom Docker image.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户管理的环境**通过从基础镜像开始但允许您通过Docker步骤自行处理所有库和依赖项，或者通过创建一个完整的自定义Docker镜像来构建环境。'
- en: When we start our first experiments at the end of this chapter, we will see
    how to use environments in our ML runs.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在本章末尾开始我们的第一次实验时，我们将看到如何在我们的机器学习运行中使用环境。
- en: Azure Machine Learning Environments
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning环境
- en: An environment in Azure Machine Learning is a Docker container encompassing
    an OS and any runtimes, libraries, and additional dependencies required.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning环境中的环境是一个包含操作系统以及任何运行时、库和额外依赖项的Docker容器。
- en: We can conclude that we require a defined environment to run experiments on
    compute clusters in the workspace. For our local computer, on the other hand,
    we could just run on the *environment* we curated on the machine and ignore the
    ML workspace environments. But if we were to use the environment methods of the
    Azure Machine Learning Python SDK in our ML scripts, the run would require some
    type of defined environment. This can either be the given environment our machine
    exists in, a local Docker runtime, or a runtime powered by a Conda environment
    definition.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出结论，我们需要在工作区中的计算集群上运行实验时定义一个环境。另一方面，对于我们的本地计算机，我们可以在机器上精心制作的*环境*上运行，并忽略机器学习工作区环境。但是，如果我们要在我们的机器学习脚本中使用Azure
    Machine Learning Python SDK的环境方法，运行将需要某种类型定义的环境。这可以是机器存在的给定环境、本地Docker运行时或由Conda环境定义支持的运行时。
- en: Runs
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行
- en: 'A **run** is the actual execution of a model training on a compute target.
    Before executing a run, it requires (in most cases) a so-called **run configuration**.
    This configuration is composed of the following:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**运行**是在计算目标上实际执行模型训练的过程。在执行运行之前，它需要（在大多数情况下）所谓的**运行配置**。此配置由以下内容组成：'
- en: '**A training script**: The training script that performs the actual ML training
    (which basically takes your source folder with all source files, zips it, and
    sends it to the compute target)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练脚本**：执行实际机器学习训练的脚本（基本上是将包含所有源文件的源文件夹压缩，并将其发送到计算目标）'
- en: '**An environment**: The ML environment described previously'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**环境**：之前描述的机器学习环境'
- en: '**A compute target**: The target compute instance or cluster that the run will
    be executed in'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算目标**：运行将在其中执行的目标计算实例或集群'
- en: We will see later in the chapter when we do our first experiments that there
    is a `RunConfiguration` class in the Azure Machine Learning Python library that
    needs to be used to execute the run.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章稍后当我们进行第一次实验时，我们将看到Azure Machine Learning Python库中有一个名为`RunConfiguration`的类，需要使用它来执行运行。
- en: Azure Machine Learning Experiment Runs
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning实验运行
- en: A run is the execution of a training script in a given environment on a specified
    compute target.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 运行是在指定计算目标上给定环境中执行训练脚本的过程。
- en: 'On top of that, during and after the execution of the run, it tracks and collects
    the following information:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在运行执行期间和之后，它跟踪和收集以下信息：
- en: '**Log files**: Includes the log files generated during the execution and any
    statement we add to the logging'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志文件**：包括执行过程中生成的日志文件以及我们添加到日志中的任何语句'
- en: '**Metrics**: Includes standard run metrics and any type of object (values,
    images, and tables) that we want to track specifically during the run'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标**：包括标准运行指标以及我们希望在运行期间特别跟踪的任何类型的对象（值、图像和表格）'
- en: '**Snapshots**: Includes a copy of the source directory containing our training
    scripts (using the ZIP file that we already required for the run configuration)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快照**：包括包含我们的训练脚本的源目录的副本（使用我们已为运行配置所需的ZIP文件）'
- en: '**Output files**: Includes the files generated by the algorithm (the model)
    and any file we additionally want to attach to the run'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出文件**：包括算法（模型）生成的文件以及我们希望附加到运行中的任何其他文件'
- en: We will see later that we can utilize the `Run` class in the Azure Machine Learning
    Python library to influence what is tracked.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在稍后看到，我们可以利用Azure Machine Learning Python库中的`Run`类来影响跟踪的内容。
- en: Registered models
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 已注册的模型
- en: As said before, the output of our experiment runs is an ML model. This model
    is basically a mathematical function or, to be more precise, a piece of code implementing
    a function. Depending on the ML framework we utilize, the function is stored in
    binary format in one or multiple output files found in the identically named folder.
    Popular formats for serialized ML models are **pickle** (Python), **H5** (Keras),
    **Protobuf** (TensorFlow and Caffe), and other custom formats.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们实验输出的结果是机器学习模型。这个模型基本上是一个数学函数，或者更准确地说，是一个实现函数的代码片段。根据我们使用的机器学习框架，函数以二进制格式存储在一个或多个同名的输出文件中。流行的序列化机器学习模型格式有**pickle**（Python）、**H5**（Keras）、**Protobuf**（TensorFlow和Caffe）以及其他自定义格式。
- en: As all models from different runs would *just* be stored in the output files
    of the run itself, the workspace offers the ability to register a model to the
    *model registry*. In the registry, the models are stored with a name and a version.
    Each time you add a model with the same name, the registry adds a new version
    of the existing model with a new version number. In addition, you can tag each
    model with metainformation, such as the framework utilized.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有不同运行的结果都会**仅仅**存储在运行本身的输出文件中，工作区提供了将模型注册到**模型注册表**的能力。在注册表中，模型以名称和版本存储。每次添加具有相同名称的模型时，注册表都会添加一个新版本的新模型，并带有新的版本号。此外，您还可以使用元信息标记每个模型，例如所使用的框架。
- en: Azure Machine Learning Model Registry
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning模型注册表
- en: The model registry in Azure Machine Learning stores names and versions of registered
    models for tracking and deployment.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning中的模型注册表存储已注册模型的名称和版本，以进行跟踪和部署。
- en: In the end, the model registry helps you to keep track of the different results
    you achieved through training and allows you to deploy different versions of the
    model for production, development, and test environments.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，模型注册表帮助您跟踪通过训练获得的不同结果，并允许您将不同版本的模型部署到生产、开发和测试环境。
- en: Deployments and deployment endpoints
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署和部署端点
- en: Once a model is trained and registered, it can be packaged as a service – by
    defining an entry script and environment – and deployed to a compute target. The
    entry script's job is to load the model during initialization, as well as parse
    user inputs, evaluate the model, and return the results for a user request. This
    process is called **deployment** in Azure Machine Learning. Compute targets for
    deployments can be either managed services such as **Azure Container Instances**
    (**ACI**) or **Azure Kubernetes Service** (**AKS**), or a completely custom user-managed
    AKS cluster. Every deployment typically serves a single model.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型经过训练并注册，就可以将其打包为一个服务——通过定义入口脚本和环境——并部署到计算目标。入口脚本的任务是在初始化期间加载模型，以及解析用户输入、评估模型并返回用户请求的结果。这个过程在Azure
    Machine Learning中被称为**部署**。部署的计算目标可以是管理服务，如**Azure容器实例（ACI）**或**Azure Kubernetes服务（AKS）**，或者一个完全由用户管理的AKS集群。每个部署通常只服务于单个模型。
- en: If you want to abstract multiple model deployments behind a common endpoint,
    you can define an **endpoint service**. This is a common requirement for rolling
    out multiple model versions, performing **blue-green deployments**, or **A/B testing**.
    An endpoint is a separate service in Azure Machine Learning that provides a common
    domain for multiple model deployments, performs **Secure Socket Layer (SSL)**/**Transport
    Layer Security (TLS)** termination, and allows traffic allocation between deployments.
    Endpoints can also be deployed to multiple compute targets, including ACI and
    AKS.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想将多个模型部署抽象为一个共同的端点，您可以定义一个**端点服务**。这是推出多个模型版本、执行**蓝绿部署**或**A/B测试**的常见需求。端点是Azure
    Machine Learning中的一个独立服务，为多个模型部署提供了一个共同的域名，执行**安全套接字层（SSL）**/**传输层安全性（TLS）**终止，并允许在部署之间分配流量。端点也可以部署到多个计算目标，包括ACI和AKS。
- en: Azure Machine Learning Endpoints
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning端点
- en: A deployment endpoint in Azure Machine Learning is a service offering a common
    domain for accessing and testing multiple versions of a model.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning中的部署端点是一个提供访问和测试多个模型版本共同域名的服务。
- en: 'For both deployments and endpoints, we differentiate between **online scoring**
    and **batch scoring**:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于部署和端点，我们区分了**在线评分**和**批量评分**：
- en: '**Online scoring**: A model is evaluated synchronously for a single input record
    (or small batch of input records) where the input data, as well as the scoring
    results, are passed directly in the request and response.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在线评分**：对单个输入记录（或小批量的输入记录）进行同步评估，其中输入数据和评分结果直接在请求和响应中传递。'
- en: '**Batch scoring**: A user typically passes a location to the input data instead
    of sending input data with the request. In this case, the model is evaluated asynchronously
    and provides the results in an output location.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量评分**：用户通常将输入数据的位置传递给请求，而不是在请求中发送输入数据。在这种情况下，模型异步评估并提供输出位置的结果。'
- en: We will discuss the deployment of models and endpoints in more detail in [*Chapter
    14*](B17928_14_ePub.xhtml#_idTextAnchor217), *Model Deployments, Endpoints, and
    Operations*.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第14章*](B17928_14_ePub.xhtml#_idTextAnchor217)“模型部署、端点和操作”中更详细地讨论模型的部署和端点。
- en: Pipelines
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管道
- en: The final part to mention is **ML pipelines**. Everything we have discussed
    so far might be enough to do some data preparation, model training, model deployment,
    and inferencing for ourselves. But even that would entail multiple manual steps.
    Certainly, we can automate most parts of this using the Azure CLI through some
    scripting and be quite happy with our setup.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 最后要提到的是**ML管道**。到目前为止，我们所讨论的内容可能已经足够我们自己进行一些数据准备、模型训练、模型部署和推理。但即使这样，我们也可以通过一些脚本使用Azure
    CLI自动化大多数步骤，并对我们的设置感到非常满意。
- en: Now, imagine that we want to work with a team and build automated retraining
    and deployment of our model whenever there is new data to train on. We would have
    to run similar steps again, such as preprocessing, training, and optimization
    – just this time with new training data. This process is typically repeated whenever
    there is significant data drift between the training data and the inferencing
    data. This is the point where we need to think about bringing in ideas and proven
    solutions from DevOps, as in the end, we will also write code and deploy infrastructure
    into a production environment.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们想要与团队合作，并在有新的训练数据时自动重新训练和部署我们的模型。我们可能需要再次运行类似的步骤，例如预处理、训练和优化——只是这次使用新的训练数据。这个过程通常在训练数据和推理数据之间存在重大数据漂移时重复。这就是我们需要考虑引入来自DevOps的想法和解决方案的时候，因为最终，我们也将编写代码并将基础设施部署到生产环境。
- en: Therefore, pipelines are used to facilitate workflows and bring automation to
    every step of the ML chain; we will take a closer look at them in [*Chapter 8*](B17928_08_ePub.xhtml#_idTextAnchor135),
    *Azure Machine Learning Pipelines*. Pipelines are also one of the integral parts
    of MLOps, and we will see them in action in [*Chapter 16*](B17928_16_ePub.xhtml#_idTextAnchor252),
    *Bringing Models into Production with MLOps*.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们使用管道来简化工作流程，并将自动化引入ML链的每个步骤；我们将在[*第8章*](B17928_08_ePub.xhtml#_idTextAnchor135)“Azure机器学习管道”中更详细地探讨它们。管道也是MLOps的组成部分之一，我们将在[*第16章*](B17928_16_ePub.xhtml#_idTextAnchor252)“使用MLOps将模型投入生产”中看到它们的应用。
- en: Surveying Azure Machine Learning Studio
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查Azure机器学习工作室
- en: 'Now that we have a good understanding of the features of the workspace, let''s
    continue where we left off before and have a look into the Azure portal and **Azure
    Machine Learning Studio**, the web service to operate every aspect of the ML process.
    This time, search again for our workspace name and click on **mldemows**, the
    ML workspace. You will be shown the typical menu structure for an Azure resource
    on the left and the **Overview** page of the service on the right, as shown in
    *Figure 3.5*:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经很好地了解了工作空间的功能，那么让我们继续之前中断的地方，看看Azure门户和**Azure机器学习工作室**，这是操作ML流程每个方面的网络服务。这次，再次搜索我们的工作空间名称，并点击**mldemows**，ML工作空间。您将看到左侧典型的Azure资源菜单结构和右侧服务的**概述**页面，如图3.5所示：
- en: '![Figure 3.5 – The Azure resource view ](img/B17928_03_005.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5 – Azure资源视图](img/B17928_03_005.jpg)'
- en: Figure 3.5 – The Azure resource view
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – Azure资源视图
- en: 'This is the administration view from an infrastructure perspective. The major
    points of interest for you to keep in mind are the following:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 从基础设施的角度来看，这是管理视图。您需要记住的主要关注点是以下内容：
- en: '**Overview**: The panel showing the names and attached services of the workspace
    and the button to launch the ML studio.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概述**：显示工作空间名称和附加服务的面板以及启动ML工作室的按钮。'
- en: '**Access control (IAM)**: The panel to set user access rights on every aspect
    of the workspace, as discussed in the last section.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**访问控制（IAM**）：设置用户对工作区每个方面的访问权限的面板，如上一节所述。'
- en: '**Networking**: The panel to integrate the service into a private virtual network
    by activating a **private endpoint** for the workspace.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络**：通过激活工作区的**私有端点**，将服务集成到私有虚拟网络中的面板。'
- en: '**Identity**: The panel showing the already created managed identity of the
    workspace, which can be used to give the workspace access to external Azure services,
    such as a storage account using RBAC.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**身份**：显示工作区已创建的管理身份的面板，可用于通过RBAC授予工作区访问外部Azure服务（如存储帐户）的权限。'
- en: '**Usage + quotas**: The panel to access the available quota on the subscription,
    which defines how many cores of which type of virtual machine the user is allowed
    to deploy within the subscription.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用量 + 配额**：访问订阅中可用配额的面板，该配额定义了用户在订阅内可以部署多少个类型的虚拟机核心。'
- en: By clicking on the **Launch studio** button on the overview page, the actual
    Azure Machine Learning Studio will open in a new tab, greeting you with the view
    shown in *Figure 3.6*.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在概述页上点击**启动工作室**按钮，实际的Azure机器学习工作室将在新标签页中打开，并以*图3.6*中显示的视图欢迎您。
- en: '![Figure 3.6 – The Azure Machine Learning Studio home page ](img/B17928_03_006.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![图3.6 – Azure机器学习工作室主页](img/B17928_03_006.jpg)'
- en: Figure 3.6 – The Azure Machine Learning Studio home page
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 – Azure机器学习工作室主页
- en: You can theoretically do everything we will do in this book through this web
    application, but in certain areas, this can be cumbersome. We will discuss in
    detail how we set up and operate our development environment in the next section,
    but it is a good idea to get an understanding of this web service, as we will
    come back to it throughout the book.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过这个网络应用完成本书中将要做的所有事情，但在某些领域，这可能会很麻烦。我们将在下一节中详细讨论我们如何设置和操作我们的开发环境，但了解这个网络服务是一个好主意，因为我们将贯穿全书回到它。
- en: Looking at the menu to the left, there are three major categories, namely **Author**,
    **Assets**, and **Manage**. Let's match what we already know about the workspace
    to what is shown to us in the web service.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 看看左侧的菜单，有三个主要类别，即**作者**、**资产**和**管理**。让我们将我们对工作区的了解与我们在网络服务中看到的内容进行匹配。
- en: Author
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作者
- en: 'The first section of the menu shows you the options for authoring your ML experiments.
    They are as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 菜单的第一部分显示了您编写机器学习实验的选项。具体如下：
- en: '**Notebooks**: Create and author Jupyter notebooks utilizing a notebook **virtual
    machine (VM)** (compute instance) in the cloud.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**笔记本**：通过云中的笔记本**虚拟机（VM**）（计算实例）创建和编写Jupyter笔记本。'
- en: '**Automated ML**: Create ML models through a wizard, offering insights and
    suggestions based on your given dataset and problem to solve.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化机器学习**：通过向导创建机器学习模型，根据您提供的数据集和要解决的问题提供见解和建议。'
- en: '**Designer**: Build ML models through a GUI interface using logical building
    blocks.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设计器**：通过GUI界面使用逻辑构建块构建机器学习模型。'
- en: We have already discussed why we prefer using code and notebooks in [*Chapter
    2*](B17928_02_ePub.xhtml#_idTextAnchor034), *Choosing the Right Machine Learning
    Service in Azure*. We will come back to automated ML later in this book in [*Chapter
    11*](B17928_11_ePub.xhtml#_idTextAnchor178), *Hyperparameter Tuning and Automated
    Machine Learning*.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[*第2章*](B17928_02_ePub.xhtml#_idTextAnchor034)中讨论了为什么我们更喜欢在Azure中选择合适的机器学习服务，即*选择Azure中的正确机器学习服务*。我们将在本书的[*第11章*](B17928_11_ePub.xhtml#_idTextAnchor178)中回到自动化机器学习，即*超参数调整和自动化机器学习*。
- en: For now, the options to author our notebooks are to either work in the web service
    environment and utilize a Jupyter server on a compute instance in the cloud, or
    to work from our local computer with a local Jupyter server.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们可以通过两种方式来创建我们的笔记本：要么在云服务环境中工作并利用云中的计算实例上的Jupyter服务器，要么使用本地计算机上的本地Jupyter服务器进行工作。
- en: Important Note
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We will stay in our own local environment for most of the book, but be aware
    that in a bigger team, it might be of value to have a notebook server in the cloud.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的大部分内容中保持在我们自己的本地环境中，但请注意，在一个更大的团队中，可能有必要在云中有一个笔记本服务器。
- en: Assets
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 资产
- en: 'The second section of the menu shows you the assets available to utilize in
    your scripts. They are as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 菜单的第二部分显示了您在脚本中可以使用的资产。具体如下：
- en: '**Datasets**: View and create datasets in the workspace and configure dataset
    monitoring for understanding data drift between your training data and the inference
    data from a deployed model (imaging a sensor that is placed differently in production
    than when gathering test data or that is suddenly broken).'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集**：在工作区中查看和创建数据集，并配置数据集监控以了解训练数据和部署模型的推理数据之间的数据漂移（想象一下在生产中放置位置不同的传感器，或者在收集测试数据时突然损坏）。'
- en: '**Experiments**: View all experiments and all runs that have been tracked,
    including their detailed run statistics (metrics, snapshots, logs, and outputs)
    and infrastructure monitoring logs of the compute target.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验**：查看所有实验和所有已跟踪的运行，包括它们的详细运行统计信息（指标、快照、日志和输出）以及计算目标的监控日志。'
- en: '**Pipelines**: Create pipelines, view pipeline runs, and define endpoints for
    pipelines.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道**：创建管道、查看管道运行并定义管道端点。'
- en: '**Models**: Register models and view their properties, including their version,
    the datasets they are using, the artifacts they are made of, and the endpoints
    they are actively deployed to.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：注册模型并查看它们的属性，包括它们的版本、它们使用的数据集、它们由哪些工件组成以及它们正在积极部署到的端点。'
- en: '**Endpoints**: View and create web service endpoints.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端点**：查看和创建 Web 服务端点。'
- en: Going through these pages, we can see a lot of the workspace items we already
    discussed, from datasets to model training through experiments and their runs,
    registering models, and surfacing service endpoints for our deployments, up to
    managing all of this through ML pipelines.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些页面，我们可以看到我们已经讨论过的许多工作区项目，从数据集到模型训练，通过实验及其运行，注册模型，以及为我们的部署公开服务端点，直到通过 ML
    管道管理所有这些。
- en: You might have seen some other additional features, such as **Dataset Monitoring**,
    which we will come back to in [*Chapter 4*](B17928_04_ePub.xhtml#_idTextAnchor071),
    *Ingestion Data and Managing Datasets*.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经看到了一些其他附加功能，例如 **数据集监控**，我们将在 [*第 4 章*](B17928_04_ePub.xhtml#_idTextAnchor071)
    *数据摄取和管理数据集* 中再次讨论。
- en: We will have a closer look at the experiment and run statistics at the end of
    this chapter when we have an experiment and a run has been shown in Azure Machine
    Learning Studio.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在 Azure Machine Learning Studio 中展示了实验和运行时，我们将在本章末尾更详细地查看实验和运行统计信息。
- en: Manage
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理
- en: 'The final section of the menu shows us the machines and services that we can
    manage in our workspace. They are as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 菜单的最后部分显示了我们可以管理的工作区中的机器和服务。它们如下：
- en: '**Compute**: Create, view, and manage compute instances, compute clusters,
    inference clusters, and other attached computes (for example, external VMs or
    Databricks clusters), including performed runs, distribution of runs on nodes
    (if existing), and monitoring of the infrastructure itself (for example, CPU usage).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算**：创建、查看和管理计算实例、计算集群、推理集群以及其他附加的计算（例如，外部虚拟机或 Databricks 集群），包括已执行的运行、节点上的运行分布（如果存在）以及基础设施本身的监控（例如，CPU
    使用率）。'
- en: '**Environments**: View available curated environments and create your own custom
    environments from a Python virtual environment, a Conda YAML configuration, a
    Docker image stored in the container registry, or from your own Docker file.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**环境**：查看可用的精选环境，并从 Python 虚拟环境、Conda YAML 配置、存储在容器注册表的 Docker 镜像或您的 Docker
    文件中创建自己的自定义环境。'
- en: '`workspacefilestore` and `workspaceblobstore`), the global Azure Machine Learning
    dataset repository (`azureml_globaldatasets`), and any already attached external
    storage or attach new ones, including Azure Data Lake, Azure Blob storage, Azure
    file shares, and Azure SQL, MySQL, and PostgreSQL databases.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`workspacefilestore` 和 `workspaceblobstore`）、全局 Azure Machine Learning 数据集存储库
    (`azureml_globaldatasets`)、以及任何已附加的外部存储或附加新的存储，包括 Azure Data Lake、Azure Blob 存储空间、Azure
    文件共享和 Azure SQL、MySQL 以及 PostgreSQL 数据库。'
- en: '**Data Labeling**: Create labeling projects for image classification and object
    detection.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据标注**：为图像分类和目标检测创建标注项目。'
- en: '**Linked Services**: Link an Azure Synapse Spark pool to the workspace.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**链接服务**：将 Azure Synapse Spark 池链接到工作区。'
- en: In these views, we find the final missing pieces, the compute targets in the
    workspace, the environments, and our available datastores, from which we source
    our datasets for modeling. Furthermore, we find a service to help us with data
    labeling of source files (typically images) and the possibility to link Azure
    Synapse to our workspace.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些视图中，我们发现了一些缺失的最终组件，包括工作区中的计算目标、环境以及我们可用的数据存储，我们从这些数据存储中获取数据集用于建模。此外，我们还发现了一个服务，可以帮助我们对源文件（通常是图像）进行数据标注，以及将Azure
    Synapse链接到我们的工作区的可能性。
- en: We will go into more detail on the datastores in the next chapter and on data
    labeling in [*Chapter 6*](B17928_06_ePub.xhtml#_idTextAnchor102), *Feature Engineering
    and Labeling*. We will not cover the Azure Synapse integration in detail in this
    book.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章中详细介绍数据存储，并在第6章“特征工程和标注”中详细介绍数据标注。我们不会在本书中详细讨论Azure Synapse集成。
- en: Now that we have a good overview of the features and tooling of the Azure Machine
    Learning service, we can now return to our local machine and start our first experiments
    with Azure Machine Learning.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对Azure机器学习服务的功能和工具有了良好的概述，我们可以回到我们的本地机器，并开始使用Azure机器学习进行我们的第一次实验。
- en: Running ML experiments with Azure Machine Learning
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Azure机器学习运行ML实验
- en: So far, we have installed the Azure CLI locally, deployed our ML workspace to
    our Azure subscription, and had a look through the features and functionalities
    of the Azure Machine Learning workspace.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经在本地上安装了Azure CLI，将我们的ML工作区部署到我们的Azure订阅中，并查看了Azure机器学习工作区的功能和功能。
- en: In this final section of the chapter, we will set up our local environment,
    including Python, the Azure Machine Learning Python SDK, and optionally Visual
    Studio Code, and embark on our first experiments locally and with compute targets
    in the cloud.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后部分，我们将设置我们的本地环境，包括Python、Azure机器学习Python SDK，以及可选的Visual Studio Code，并在本地以及云中的计算目标上进行我们的第一次实验。
- en: Setting up a local environment
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置本地环境
- en: 'In the beginning, we discussed briefly the tooling available for deploying
    Azure resources through Azure Resource Manager. In the same vein, let''s have
    a look at the options for authoring and orchestrating the workspace from our local
    environment. The options are as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在一开始，我们简要讨论了通过Azure资源管理器部署Azure资源的工具。同样，让我们看看从我们的本地环境编写和编排工作区的选项。选项如下：
- en: Using Python 3, the Azure Machine Learning Python SDK, a Jupyter Python extension,
    and the Azure ML CLI (1.0/2.0) extension (and an editor of choice)
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python 3、Azure机器学习Python SDK、Jupyter Python扩展和Azure ML CLI（1.0/2.0）扩展（以及选择的编辑器）
- en: Using Python3, the Azure Machine Learning Python SDK, an Azure ML CLI (1.0/2.0)
    extension, **Visual Studio Code (VS Code)**, and VS Code extensions (Azure, Azure
    Machine Learning, Jupyter, and so on)
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python3、Azure机器学习Python SDK、Azure ML CLI（1.0/2.0）扩展、**Visual Studio Code (VS
    Code**)以及VS Code扩展（Azure、Azure机器学习、Jupyter等）
- en: Using Python3, an Azure ML CLI 2.0 extension, YAML, and VS Code (or an editor
    of choice)
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python3、Azure ML CLI 2.0扩展、YAML和VS Code（或选择的编辑器）
- en: Using R, an Azure ML CLI 2.0 extension, YAML, and VS Code (or an editor of choice)
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用R、Azure ML CLI 2.0扩展、YAML和VS Code（或选择的编辑器）
- en: The first two options are the de facto standard at the time of writing and the
    ones we will focus on primarily in this book. We will use the Azure Machine Learning
    Python SDK with Python 3 and leave it to you if you prefer to work mostly from
    the console with source files and optionally an editor of choice, or if you want
    to use an **integrated development environment (IDE)** such as VS Code, which
    comes with a feature-rich editor and helpful extensions for Azure, Azure Machine
    Learning, and Jupyter.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，前两种选项是事实上的标准，我们将主要关注本书中的这两种选项。我们将使用Azure机器学习Python SDK和Python 3，如果您更喜欢主要从控制台使用源文件和可选的编辑器，或者如果您想使用**集成开发环境（IDE）**，如VS
    Code，它自带功能丰富的编辑器和针对Azure、Azure机器学习和Jupyter的有用扩展，那么请由您决定。
- en: In both cases, we will author a Jupyter notebook to orchestrate our ML experiments
    on the workspace and one or more Python source files to implement the training
    procedures.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，我们将编写一个Jupyter笔记本来编排我们在工作区上的ML实验，以及一个或多个Python源文件来实现训练过程。
- en: 'The latter two options were introduced with the more extensive **Azure ML CLI
    2.0**. Instead of writing a Jupyter notebook, we completely detach the orchestration
    of the workspace (run configuration, environments, deployments, and endpoints)
    from the training and inference source code. This is done through YAML configuration
    files. An example of an ML experiment run looks like this:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 后两个选项是在更广泛的 **Azure ML CLI 2.0** 中引入的。我们不再将工作区的编排（运行配置、环境、部署和端点）与训练和推理源代码分离，而是通过
    YAML 配置文件来实现。一个 ML 实验运行的示例如下：
- en: '[PRE14]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, this YAML structure references the actual code to be executed
    (`code`), the runtime to use (`command`), and defines every part (`environment`,
    `compute`, and `data`) necessary for the training run in a descriptive manner.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这种 YAML 结构引用了要执行的实际代码（`code`）、要使用的运行时（`command`），并以描述性的方式定义了训练运行所需的每个部分（`environment`、`compute`
    和 `data`）。
- en: YAML Configurations
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: YAML 配置
- en: YAML configuration files are a descriptive way to run experiments, create compute
    services and endpoints, and deploy models in Azure Machine Learning.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: YAML 配置文件是一种描述性的方法来运行实验、创建计算服务和端点，并在 Azure Machine Learning 中部署模型。
- en: This is a more structural way of thinking about the task we will perform and
    will come in handy when we talk about production systems and MLOps in [*Chapter
    16*](B17928_16_ePub.xhtml#_idTextAnchor252), *Bringing Models into Production
    with MLOps*. Finally, this option is the only one allowing source files to be
    written in **R**, the domain-specific language for data science, and is highly
    supported in VS Code through the Azure Machine Learning VS Code extension.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种更结构化的思考任务的方式，当我们在 [*第 16 章*](B17928_16_ePub.xhtml#_idTextAnchor252) “使用
    MLOps 将模型投入生产”中讨论生产系统和 MLOps 时会很有用。最后，这是唯一允许以 **R** 语言（数据科学的领域特定语言）编写源文件的选项，并且通过
    Azure Machine Learning VS Code 扩展在 VS Code 中得到了高度支持。
- en: Setting up the Python environment
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置 Python 环境
- en: 'Now that we have a good idea about the possible local development environments
    we can work with, let''s set up our Python environment:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对可以与之一起工作的可能本地开发环境有了很好的了解，让我们设置我们的 Python 环境：
- en: Important Note
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The following actions only have to be done if you run your experiments on your
    own local machine and not if you are using a notebook compute instance in the
    Azure Machine Learning Studio authoring environment or a **Data Science Virtual
    Machine** (**DSVM**) in Azure.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在自己的本地机器上运行实验，而不是在 Azure Machine Learning Studio 编写环境中使用笔记本计算实例或 Azure 中的
    **数据科学虚拟机**（**DSVM**），则必须执行以下操作。
- en: 'First, check whether there is already a Python version installed on your system
    by running the following command:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，通过运行以下命令检查您的系统上是否已安装 Python 版本：
- en: '[PRE15]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Next, please check the metadata of the Azure Machine Learning Python extension
    on https://pypi.org/project/azureml-sdk/. There are certain times when the extension
    is behind the most recent Python release. If you already have an unsupported Python
    version on your system, either uninstall that version or read up on how to operate
    multiple Python environments on the same machine.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，请检查 https://pypi.org/project/azureml-sdk/ 上的 Azure Machine Learning Python
    扩展的元数据。有时，扩展可能落后于最新的 Python 版本。如果您已经在系统上安装了不受支持的 Python 版本，请卸载该版本或查阅如何在同一台机器上操作多个
    Python 环境的说明。
- en: 'After you have verified the supported Python release, either go to [https://www.python.org/](https://www.python.org/)
    and find the supported version for Windows and macOS or use the Terminal and the
    `apt-get` command under your Linux distribution. An example for Python 3.8 would
    look like this:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您验证了支持的 Python 版本后，您可以选择访问 [https://www.python.org/](https://www.python.org/)
    并查找 Windows 和 macOS 的支持版本，或者使用 Linux 发行版的终端和 `apt-get` 命令。以 Python 3.8 为例，它看起来可能如下所示：
- en: '[PRE16]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If you have installed Python for the first time or reinstalled it again, please
    check that Python is correctly integrated into the path environment variable by
    checking for the Python version (see *step 1*). If all is good, we can move forward
    and install the SDK by running the following command:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您是第一次安装 Python 或重新安装了它，请检查 Python 是否已正确集成到路径环境变量中，方法是检查 Python 版本（见 *步骤 1*）。如果一切正常，我们可以继续运行以下命令来安装
    SDK：
- en: '[PRE17]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: If this command is trying to resolve a lot of dependencies, you might still
    be operating with an unsupported version of Python or the package installer **PIP**.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 如果此命令正在尝试解析大量依赖项，您可能仍在使用不受支持的 Python 版本或包安装程序 **PIP**。
- en: 'If you want to work with VS Code, you can jump to the next paragraph now. If
    you prefer to work primarily with the command line, please install either a local
    JupyterLab or a local Jupyter notebook server ([https://jupyter.org/index.html](https://jupyter.org/index.html))
    with one of the following commands:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您想使用 VS Code，现在可以跳到下一段。如果您主要使用命令行，请安装本地 JupyterLab 或本地 Jupyter 笔记本服务器 ([https://jupyter.org/index.html](https://jupyter.org/index.html))，可以使用以下命令之一：
- en: '[PRE18]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'After that, you can start either environment from the command line, like this:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，您可以从命令行启动任一环境，如下所示：
- en: '[PRE19]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: With this version of the setup, you can now proceed to the *Running a simple
    experiment with Azure Machine Learning* section.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此版本的设置，您现在可以继续到 *使用 Azure 机器学习运行简单实验* 部分。
- en: Setting up Visual Studio Code
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置 Visual Studio Code
- en: VS Code is a lightweight but very powerful IDE. It is highly integrated with
    Azure, Azure Machine Learning, and Git, and has a very good editor, an integrated
    terminal, and a long list of useful extensions to choose from.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: VS Code 是一个轻量级但功能强大的集成开发环境。它与 Azure、Azure 机器学习和 Git 高度集成，拥有一个非常好的编辑器、一个集成终端以及一个长长的可选扩展列表。
- en: 'Let''s have a look at it:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看它：
- en: Download the tool either from [https://code.visualstudio.com/](https://code.visualstudio.com/)
    or through Azure Marketplace and install it.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以从 [https://code.visualstudio.com/](https://code.visualstudio.com/) 或通过 Azure
    市场下载此工具并安装。
- en: 'After you open it, you will be greeted by the view shown in *Figure 3.7* (probably
    with a darker theme):'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开它后，您将看到如图 3.7 所示的视图（可能主题较暗）：
- en: '![Figure 3.7 – The VS Code interface ](img/B17928_03_007.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.7 – VS Code 界面](img/B17928_03_007.jpg)'
- en: Figure 3.7 – The VS Code interface
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7 – VS Code 界面
- en: 'If you click on the top menu on `>Theme` and look for `>Preferences: Color
    Themes`.'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您点击顶部的 `>主题` 并查找 `>首选项：颜色主题`。
- en: Clicking on it will give you a quick way to set the theme of the UI.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 点击它将为您提供快速设置 UI 主题的方法。
- en: Now, to open the terminal, you can click on the top menu on `az` again to see
    the same as shown in *Figure 3.7*.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，要打开终端，您可以再次点击顶部的 `az` 菜单，以查看如图 3.7 所示的内容。
- en: Looking at the left menu, you will find an **EXPLORER** tab, where you can add
    your source folders and files, a **Source Control** tab to connect to Git, a **Run
    and Debug** tab that lets you handle the debugging of your code, and an **Extensions**
    tab where you can search for VS Code extensions.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看左侧菜单，您将找到一个 **资源管理器** 选项卡，您可以在此添加源文件夹和文件，一个 **源代码管理** 选项卡以连接到 Git，一个 **运行和调试**
    选项卡，它允许您处理代码的调试，以及一个 **扩展** 选项卡，您可以在此搜索 VS Code 扩展。
- en: 'Go to the **Extensions** tab and search and install the following extensions,
    if they are not already installed: **Azure Tools**, **Azure Machine Learning**,
    **Python**, **Pylance**, **YAML**, and **Jupyter**.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 切换到 **扩展** 选项卡，搜索并安装以下扩展（如果尚未安装）：**Azure Tools**、**Azure Machine Learning**、**Python**、**Pylance**、**YAML**
    和 **Jupyter**。
- en: After the installation, you will find a new tab in the left menu called `sign
    in azure`, you will find a way to sign in.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成后，您将在左侧菜单中找到一个名为 `sign in azure` 的新选项卡，您将找到登录的方法。
- en: 'After you are through with signing in to Azure, the **Azure** tab will populate
    with your subscription names, resource groups, and any resource you might have.
    If you look under the **MACHINE LEARNING** headline, you will also find your previously
    deployed workspace, as shown in *Figure 3.8*:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在您完成 Azure 登录后，**Azure** 选项卡将填充您的订阅名称、资源组以及您可能拥有的任何资源。如果您查看 **机器学习** 标题下，您也会找到之前部署的工作区，如图
    3.8 所示：
- en: '![Figure 3.8 – The VS Code Azure Machine Learning extension ](img/B17928_03_008.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.8 – VS Code Azure 机器学习扩展](img/B17928_03_008.jpg)'
- en: Figure 3.8 – The VS Code Azure Machine Learning extension
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8 – VS Code Azure 机器学习扩展
- en: In the next section, download the files for this chapter to work with. Just
    open the folder via **File** | **Open Folder…**, which will add them to the **Explorer**
    tab, from where you can start the journey.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一节中，下载本章所需的文件以进行操作。只需通过 **文件** | **打开文件夹…** 打开文件夹，它们将被添加到 **资源管理器** 选项卡中，从这里您可以开始旅程。
- en: VS Code has much more to offer, but we will concentrate primarily on understanding
    ML and the Azure Machine Learning workspace from now on, not on operating every
    aspect of this editor. If you need more help using VS Code, please feel free to
    visit [https://code.visualstudio.com/docs/introvideos/basics](https://code.visualstudio.com/docs/introvideos/basics)
    or any other resource that can help you with it.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: VS Code 有更多功能，但我们将主要集中理解机器学习（ML）和 Azure 机器学习工作区，而不是操作此编辑器的各个方面。如果您需要更多关于使用 VS
    Code 的帮助，请随时访问 [https://code.visualstudio.com/docs/introvideos/basics](https://code.visualstudio.com/docs/introvideos/basics)
    或任何其他可以帮助您的资源。
- en: Enhancing a simple experiment
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强简单实验
- en: One great use case for starting with Azure Machine Learning is to add advanced
    logging, tracking, and monitoring capabilities to your existing ML scripts and
    pipelines. Imagine you have a central place to track all ML experiments from all
    your data scientists, monitor training, and validation metrics, upload your trained
    models and other output files, and save a snapshot of the current environment
    every time a new training run is executed. You can achieve this with Azure Machine
    Learning by simply adding a few lines of code to your training scripts.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习的伟大用例之一是将高级日志记录、跟踪和监控功能添加到您现有的机器学习脚本和管道中。想象一下，您有一个中央位置来跟踪所有数据科学家的所有机器学习实验，监控训练和验证指标，上传您的训练模型和其他输出文件，并在每次执行新的训练运行时保存当前环境的快照。您可以通过在训练脚本中添加几行代码来实现这一点。
- en: We will start by adding Azure Machine Learning workspace functionality to a
    **Keras** ([https://keras.io](https://keras.io)) ML training script. Keras is
    one of many ML libraries we can choose from, depending on the ML algorithms we
    require.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先向一个 **Keras** ([https://keras.io](https://keras.io)) 机器学习训练脚本添加 Azure 机器学习工作区功能。Keras
    是我们可以选择的许多机器学习库之一，具体取决于我们需要的机器学习算法。
- en: A working directory and preparation
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作目录和准备
- en: Before we begin, please download the code files for this chapter from the repository
    and extract them to your preferred working directory. After that, either switch
    to this directory in the console or open it as a folder in VS Code.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，请从存储库下载本章的代码文件，并将它们提取到您首选的工作目录中。之后，您可以在控制台中切换到该目录，或者在 VS Code 中将其打开为文件夹。
- en: 'In either case, you will find the following files in the directory:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，您都会在目录中找到以下文件：
- en: '`.azureml/config.json`: The Azure Machine Learning workspace configuration
    file'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.azureml/config.json`: Azure 机器学习工作区配置文件'
- en: '`.azureml/requirements.txt`: The Python PIP environment requirements'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.azureml/requirements.txt`: Python PIP 环境需求'
- en: '`00_setup_env.sh`: A shell script to set up the Azure CLI and Python environment
    from scratch (as we already did)'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`00_setup_env.sh`: 一个 shell 脚本，用于从头开始设置 Azure CLI 和 Python 环境（就像我们之前做的那样）'
- en: '`01_setup_azure_ml_ws.sh`: A shell script to set up the Azure Machine Learning
    workspace (as we did already)'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`01_setup_azure_ml_ws.sh`: 一个 shell 脚本，用于设置 Azure 机器学习工作区（就像我们之前做的那样）'
- en: '`0x_run_experiment_*.ipynb`: Multiple Jupyter notebooks for the upcoming experiments'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0x_run_experiment_*.ipynb`: 为即将进行的实验提供的多个 Jupyter 笔记本'
- en: '`04_setup_azure_ml_compute.sh`: A shell script to create a workspace compute
    instance from a YAML configuration'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`04_setup_azure_ml_compute.sh`: 一个 shell 脚本，用于从 YAML 配置创建工作区计算实例'
- en: '`compute.yml`: A YAML configuration file for a workspace compute instance'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`compute.yml`: 工作区计算实例的 YAML 配置文件'
- en: '`code/*.py`: A folder containing the Python model training scripts we will
    use'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`code/*.py`: 包含我们将使用的 Python 模型训练脚本的文件夹'
- en: '`.amlignore`: A file denoting everything that should be ignored by the run
    snapshot'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.amlignore`: 一个文件，表示运行快照应该忽略的所有内容'
- en: 'Let''s start with our first experiment:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从我们的第一个实验开始：
- en: 'First, we need to install the missing Python package we will need for the following
    experiments. Run the following command, which will install the packages defined
    in the PIP requirements file:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要安装我们将需要的缺失 Python 包，以便进行以下实验。运行以下命令，该命令将安装 PIP 需求文件中定义的包：
- en: '[PRE20]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: PIP will point out that the Azure Machine Learning SDK is already installed.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: PIP 将指出 Azure 机器学习 SDK 已经安装。
- en: 'Next, open the `config.json` file and enter your subscription ID after the
    `subscription_id` key. This is necessary, as we will load this configuration in
    all notebooks using the following code:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，打开 `config.json` 文件，在 `subscription_id` 键之后输入您的订阅 ID。这是必要的，因为我们将在所有笔记本中使用以下代码加载此配置：
- en: '[PRE21]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `from_config()` method looks for a file called `config.json` either in the
    current working directory or in a directory called `.azureml`. We will choose
    to add it to the folder, as it is part of the `.amlignore` file.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '`from_config()`方法会在当前工作目录或名为`.azureml`的目录中寻找一个名为`config.json`的文件。我们将选择将其添加到文件夹中，因为它包含在`.amlignore`文件中。'
- en: Open the `02_run_experiment_keras_base.ipynb` notebook.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`02_run_experiment_keras_base.ipynb`笔记本。
- en: In the following, we will have a look through the notebook in order to understand
    the actual model training script, how we can add snapshots, outputs, and logs
    to the Azure Machine Learning experiment, and how we can catalog the best model
    in the model registry.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下内容中，我们将查看笔记本，以了解实际的模型训练脚本，如何将快照、输出和日志添加到Azure机器学习实验中，以及如何将最佳模型编目到模型注册表中。
- en: A training script for Keras
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Keras的训练脚本
- en: Navigate to the second block in the notebook. Imagine this part to be your original
    ML training file (plus the `model.fit()` function that you will find in the final
    block).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到笔记本中的第二个块。想象这部分是你的原始机器学习训练文件（加上你将在最后一段找到的`model.fit()`函数）。
- en: Let's understand the actual training code.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解实际的训练代码。
- en: 'First, we import the classes we require for the training from the `tensorflow`
    library (Keras is a part of TensorFlow):'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从`tensorflow`库（Keras是TensorFlow的一部分）导入所需的类：
- en: '[PRE22]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We then proceed to get our training and test data from the CIFAR-10 dataset
    and change it into a useful format. The `cifar10.load_data()` function will fill
    the training set with 50,000 datapoints and the test set with 10,000 data points:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们继续从CIFAR-10数据集中获取我们的训练和测试数据，并将其转换为有用的格式。`cifar10.load_data()`函数将训练集填充50,000个数据点，测试集填充10,000个数据点：
- en: '[PRE23]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Test and Training Datasets
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 测试和训练数据集
- en: The training dataset is made up of the data points we train our model on; the
    test dataset is made up of the data points we will evaluate our model against
    after it has been trained. These should be completely distinct from each other.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集由我们训练模型的数据点组成；测试数据集由我们在模型训练后用于评估模型的数据点组成。这些数据点应该完全不同。
- en: 'After that, we start defining our model – in this case, a `Sequential` model
    ([https://keras.io/guides/sequential_model/](https://keras.io/guides/sequential_model/))
    – and we set the name of the model and the location for the output. We will use
    the **HDF5** file format (or H5 for short) for Keras, as mentioned before:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们开始定义我们的模型——在这种情况下，一个`Sequential`模型（[https://keras.io/guides/sequential_model/](https://keras.io/guides/sequential_model/））——并设置模型的名称和输出位置。我们将使用之前提到的**HDF5**文件格式（或简称H5）：
- en: '[PRE24]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'After that, we define an optimizer (`RMSProp` in this case), a checkpoint `loss`
    function, `optimizer`, and additional `metrics` to track during the training run:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们定义了一个优化器（在这种情况下是`RMSProp`），一个检查点`loss`函数，`optimizer`，以及训练运行期间要跟踪的额外`metrics`：
- en: '[PRE25]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The part that would otherwise complete our original script is the one found
    in the last block of the notebook, which we will discuss in a moment:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 原脚本中本应完成的部分位于笔记本的最后一段，我们稍后会讨论：
- en: '[PRE26]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As you can see, this is most of the notebook code. The rest of the code you
    can see is what you need to add to your script to enable tracking of your experiment
    runs, which we will analyze next.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这是笔记本中的大部分代码。其余的代码是你需要添加到脚本中以启用实验运行跟踪的部分，我们将在下面分析。
- en: Tracking snapshots, output, and logs
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪快照、输出和日志
- en: 'We will now have a look at the code we have ignored so far. First, return to
    the first block of the notebook we skipped before:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将查看我们之前忽略的代码。首先，回到我们之前跳过的笔记本的第一个块：
- en: '[PRE27]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In this snippet, we define a workspace object called `ws` using our config file,
    and as a second step, we define an experiment object, `exp`, to be tracked in
    the defined workspace under a chosen name. As you can see, we name it `cifar10_cnn_local`
    because we will utilize the CIFAR-10 dataset ([https://www.kaggle.com/c/cifar-10](https://www.kaggle.com/c/cifar-10)),
    we will run a **Convolutional Neural Network** (**CNN**), and we will do so on
    a local machine. If an experiment with the same name already exists, this invocation
    returns the existing experiment as a handle; otherwise, a new experiment will
    be created. Through the given name, all the runs in this experiment are now grouped
    together and can be displayed and analyzed on a single dashboard.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在此片段中，我们使用配置文件定义了一个名为`ws`的工作区对象，作为第二步，我们定义了一个名为`exp`的实验对象，以便在指定的名称下跟踪定义的工作区。如您所见，我们将其命名为`cifar10_cnn_local`，因为我们将利用CIFAR-10数据集([https://www.kaggle.com/c/cifar-10](https://www.kaggle.com/c/cifar-10))，我们将运行一个**卷积神经网络**（**CNN**），并且我们将在本地机器上运行。如果已存在具有相同名称的实验，则此调用将返回现有实验的句柄；否则，将创建一个新的实验。通过给定的名称，现在所有此实验中的运行都分组在一起，可以在单个仪表板上显示和分析。
- en: Important Note
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'Running this code block might open a website to log in to your Azure account.
    This is called interactive authentication. Please do this to grant your current
    execution environment access to your Azure Machine Learning workspace. If you
    run a non-interactive Python script rather than a notebook environment, you can
    provide the Azure CLI credentials through other means described here: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication#use-interactive-authentication.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码块可能会打开一个网站以登录您的Azure账户。这被称为交互式身份验证。请执行此操作以授予您的当前执行环境访问Azure机器学习工作区的权限。如果您运行的是非交互式Python脚本而不是笔记本环境，您可以通过此处描述的其他方式提供Azure
    CLI凭据：https://docs.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication#use-interactive-authentication。
- en: Once you have successfully linked the workspace into the `ws` object, you can
    continue adding tracking capabilities to your ML experiments. We will use this
    object to create experiments, runs, and log metrics, and register models in our
    Azure Machine Learning workspace.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您已成功将工作区链接到`ws`对象，您就可以继续为您的ML实验添加跟踪功能。我们将使用此对象创建实验、运行、记录指标，并在我们的Azure机器学习工作区中注册模型。
- en: Now, let's jump to the final block, where we will perform a run of the experiment.
    As described before, a run is a single execution of your experiment (your training
    script), with different settings, models, code, and data but the same comparable
    metric. You use runs to test multiple hypotheses for a given experiment and track
    all the results within the same experiments.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们跳到最后一个代码块，我们将在此处运行实验。如前所述，运行是您实验（您的训练脚本）的单次执行，具有不同的设置、模型、代码和数据，但具有相同的可比较指标。您使用运行来测试给定实验的多个假设，并在同一实验中跟踪所有结果。
- en: 'Typically, we can create a `run` object and start logging this run here by
    invoking the following function:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们可以创建一个`run`对象，并通过调用以下函数来开始在此处记录这个运行：
- en: '[PRE28]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The preceding code not only creates and initializes a new run; it also takes
    a snapshot of the current environment, defined through the `snapshot_directory`
    argument, and uploads it to the Azure Machine Learning workspace. To disable this
    feature, you need to explicitly pass `snapshot_directory=None` to the `start_logging()`
    function.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码不仅创建并初始化了一个新的运行，还通过`snapshot_directory`参数定义的当前环境快照，并将其上传到Azure机器学习工作区。要禁用此功能，您需要明确将`snapshot_directory=None`传递给`start_logging()`函数。
- en: In this case, the snapshot will take every file and folder existing in the current
    directory. To restrict this, we can specify the files and folders to ignore using
    a `.amlignore` file.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，快照将获取当前目录中存在的所有文件和文件夹。为了限制这一点，我们可以使用`.amlignore`文件指定要忽略的文件和文件夹。
- en: Looking at the code itself in the last notebook block, you can see that this
    is not the same line of code shown previously.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个笔记本代码块中查看代码本身，您可以看到这并不是之前显示的相同行代码。
- en: 'This is because it is good practice to wrap your training code in a `try` and
    `except` block in order to propagate the status of your run in Azure. If the training
    run fails, then the run will be reported as a failed run in Azure. You can achieve
    this by using the following code snippet:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为将训练代码包裹在`try`和`except`块中是一种良好的实践，以便在Azure中传播运行状态。如果训练运行失败，那么该运行将在Azure中报告为失败的运行。您可以通过以下代码片段实现这一点：
- en: '[PRE29]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We included the `raise` statement in order to fail the script when an error
    occurs. This would normally not happen, as all exceptions are caught. You can
    simplify the preceding code by using the `with` statement in Python. This will
    yield the same result and is much easier to read:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了 `raise` 语句，以便在脚本发生错误时失败。这通常不会发生，因为所有异常都被捕获。你可以通过在 Python 中使用 `with` 语句来简化前面的代码。这将产生相同的结果，并且更容易阅读：
- en: '[PRE30]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: By using only this single line of code, you can track a snapshot for each execution
    of your experimentation runs automatically and, hence, never lose code or configurations
    and always come back to specific code, parameters, or models used for one of your
    ML runs. This is not very impressive yet, but we are just getting started using
    the features of Azure Machine Learning.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仅使用这一行代码，你可以自动跟踪每次实验运行执行的快照，因此永远不会丢失代码或配置，并且始终可以回到用于你的 ML 运行之一的特定代码、参数或模型。这目前可能并不那么令人印象深刻，但我们只是刚开始使用
    Azure Machine Learning 的功能。
- en: Now, execute every code block in this notebook and wait for completion.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，执行这个笔记本中的每个代码块，并等待完成。
- en: Once executed, go back to Azure Machine Learning Studio and navigate to the
    `cifar10_cnn_local`. When you click on it, you will see some metrics in a graph
    and a list of runs associated with the experiment. Click on the most recent run
    and then on `.azureml`).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 执行后，回到 Azure Machine Learning Studio，导航到 `cifar10_cnn_local`。当你点击它时，你会在图表中看到一些指标以及与实验关联的运行列表。点击最近的运行，然后点击
    `.azureml`）。
- en: '*Figure 3.9* shows the uploaded snapshot files of a run in our experiment:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.9* 显示了实验中运行的已上传快照文件：'
- en: '![Figure 3.9 – A snapshot view of an experiment run ](img/B17928_03_009.jpg)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.9 – 实验运行快照视图](img/B17928_03_009.jpg)'
- en: Figure 3.9 – A snapshot view of an experiment run
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.9 – 实验运行快照视图
- en: Besides the `snapshot` directory, which is uploaded before the run starts, we
    also end up with two additional directories after the run created by the ML script,
    namely `outputs` and `logs`.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在运行开始之前上传的 `snapshot` 目录之外，我们还会在运行结束后由 ML 脚本创建两个额外的目录，即 `outputs` 和 `logs`。
- en: 'Once a run is completed using `run.complete()`, all content of the `outputs`
    directory is automatically uploaded to the Azure Machine Learning workspace. In
    our simple example using Keras, we can use a checkpoint callback to only store
    the *best model* of all epochs to the `outputs` directory, which then is tracked
    with our run. Have a look at this sample code:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦使用 `run.complete()` 完成一次运行，`outputs` 目录中的所有内容将自动上传到 Azure Machine Learning
    工作区。在我们的简单示例中，使用 Keras，我们可以使用检查点回调来仅将所有 epoch 中的 *最佳模型* 存储到 `outputs` 目录，然后与我们的运行一起跟踪。看看这个示例代码：
- en: '[PRE31]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: In the preceding code, we trained a Keras model for five epochs. The process
    sets apart 20% (`validation_split`) of the training data as a so-called validation
    set.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们训练了一个 Keras 模型五个 epoch。这个过程将 20% (`validation_split`) 的训练数据作为所谓的验证集分开。
- en: Validation Datasets
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 验证数据集
- en: The validation set is the third set of datapoints, which the model is evaluated
    against during model training. It should neither be a subset of the training data
    nor the test data.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 验证集是第三组数据点，模型在模型训练期间将针对这些数据点进行评估。它既不应是训练数据的子集，也不应是测试数据。
- en: After that, the function runs through every epoch with a shuffled (`shuffle=True`)
    training dataset. In every epoch, it takes and overwrites the model file in the
    defined `output` folder if the model of this epoch is performing better on the
    validation set, which we defined by having a lower validation loss (`monitor='val_loss'`).
    Therefore, we will only have the best model stored in the `output` folder at the
    end. Hence, whenever we run the training with the previous experiment tracking,
    the model gets uploaded automatically once the run is completed.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，该函数会遍历每个 epoch，使用打乱顺序的 (`shuffle=True`) 训练数据集。在每个 epoch 中，如果该 epoch 的模型在验证集上表现更好，它将覆盖定义的
    `output` 文件夹中的模型文件，我们通过具有更低的验证损失 (`monitor='val_loss'`) 来定义验证集。因此，我们最终只会在 `output`
    文件夹中存储最佳模型。因此，每次我们使用之前的实验跟踪运行训练时，一旦运行完成，模型就会自动上传。
- en: If you go back to the second code block in the notebook, you will see that we
    already added the checkpoint callback in our code. Let's check what we got then.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回到笔记本中的第二个代码块，你会看到我们已经在代码中添加了检查点回调。那么让我们看看我们得到了什么。
- en: In Azure Machine Learning Studio, navigate to `keras_cifar10_trained_model.h5`,
    was uploaded to the Azure Machine Learning workspace.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure Machine Learning Studio 中，导航到 `keras_cifar10_trained_model.h5`，已上传到
    Azure Machine Learning 工作区。
- en: This is also very convenient, as you won't lose track of your trained models
    anymore. On top of that, all artifacts you see here are stored in the workspace
    Blob storage, which is highly scalable and inexpensive.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 这也非常方便，因为你不会再失去对训练好的模型的跟踪。除此之外，你在这里看到的所有工件都存储在工作区的 Blob 存储中，它具有高度可扩展性和低成本。
- en: '*Figure 3.10* shows the additional output and log information of a run in our
    experiment:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.10* 展示了实验运行中产生的额外输出和日志信息：'
- en: '![Figure 3.10 – Outputs and logs of an experiment run ](img/B17928_03_010.jpg)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![图3.10 – 实验运行输出和日志](img/B17928_03_010.jpg)'
- en: Figure 3.10 – Outputs and logs of an experiment run
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 – 实验运行输出和日志
- en: The `logs` directory contains the log output from Keras, which you also saw
    in the Jupyter notebook when executing the last block. In the current run, this
    was uploaded after the run, together with the `output` folder and the model.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '`logs` 目录包含来自 Keras 的日志输出，你也在执行最后一个块时的 Jupyter 笔记本中看到了。在当前运行中，这是在运行完成后上传的，包括
    `output` 文件夹和模型。'
- en: Azure Machine Learning Log Streaming
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning 日志流式传输
- en: Log streaming in Azure Machine Learning allows you to see logs in Azure Machine
    Learning Studio while a run is being executed.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning 日志流式传输允许你在运行执行时在 Azure Machine Learning Studio 中查看日志。
- en: We will see later that if the training script run is invoked through `ScriptRunConfig`
    rather than being executed directly, the logging will **stream** to the workspace
    (see also the **Enable log streaming** button). This will allow you to see the
    logs here while the run is still going on.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后会看到，如果通过 `ScriptRunConfig` 而不是直接执行来调用训练脚本，日志将会 **流式传输** 到工作区（也请参阅 **启用日志流式传输**
    按钮）。这将允许你在运行进行时在这里查看日志。
- en: Cataloging models to the model registry
  id: totrans-364
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将模型编目到模型注册库
- en: As a final step, we want to register our best model, which we have stored in
    the `output` folder, to the model registry in the Azure Machine Learning workspace.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们希望将存储在 `output` 文件夹中的最佳模型注册到 Azure Machine Learning 工作空间中的模型注册库。
- en: 'If we navigate to the final block of the notebook again, we can see that the
    last lines read like this:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再次导航到笔记本的最后一个块，我们可以看到最后几行是这样的：
- en: '[PRE32]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Here, we first force the upload of the model. This is needed because all output
    resources are only uploaded when the run is completed and not immediately. Hence,
    after uploading the model, we can simply register it in the model registry by
    invoking the `run.register_model()` method.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们首先强制上传模型。这是必要的，因为所有输出资源只有在运行完成后才会上传，而不是立即上传。因此，在模型上传后，我们可以通过调用 `run.register_model()`
    方法简单地将其注册到模型注册库中。
- en: If you navigate in Azure Machine Learning Studio to `keras_cifar10_trained_model.h5`
    from the `cifar10_cnn_local` experiment. If you click on it, you will find details
    about the model under **Details**, including the version number, and you will
    find the actual model file we created under **Artifacts**.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从 `cifar10_cnn_local` 实验导航到 Azure Machine Learning Studio 中的 `keras_cifar10_trained_model.h5`。如果你点击它，你将在
    **详细信息** 下找到关于模型的详细信息，包括版本号，你将在 **工件** 下找到我们创建的实际模型文件。
- en: '*Figure 3.11* shows the model details of the registered model:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.11* 展示了注册模型的详细信息：'
- en: '![Figure 3.11 – A registered model in the Azure Machine Learning model registry
    ](img/B17928_03_011.jpg)'
  id: totrans-371
  prefs: []
  type: TYPE_IMG
  zh: '![图3.11 – Azure Machine Learning 模型注册库中的注册模型](img/B17928_03_011.jpg)'
- en: Figure 3.11 – A registered model in the Azure Machine Learning model registry
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11 – Azure Machine Learning 模型注册库中的注册模型
- en: The model can then be used for automatic deployments from the Azure Machine
    Learning service. We will look at this in a lot more detail in [*Chapter 14*](B17928_14_ePub.xhtml#_idTextAnchor217),
    *Model Deployments, Endpoints, and Operations*, and [*Chapter 11*](B17928_11_ePub.xhtml#_idTextAnchor178),
    *Hyperparameter Tuning and Automated Machine Learning*.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型可以从 Azure Machine Learning 服务进行自动部署。我们将在 [*第14章*](B17928_14_ePub.xhtml#_idTextAnchor217)，*模型部署、端点和操作*
    和 [*第11章*](B17928_11_ePub.xhtml#_idTextAnchor178)，*超参数调整和自动化机器学习* 中更详细地探讨这一点。
- en: Now that we know how to run a simple experiment, let's learn how to log metrics
    and track results in the next section.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何运行一个简单的实验，接下来让我们学习如何在下一节中记录指标和跟踪结果。
- en: Logging metrics and tracking results
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 记录指标和跟踪结果
- en: We already saw three useful features to track snapshot code, upload output artifacts,
    and register trained model files in our Azure Machine Learning workspace. As we
    saw, these features can be added to any existing experimentation and training
    Python script or notebook with a few lines of code. In a similar way, we can extend
    the experimentation script to also track all kinds of variables, such as training
    accuracy and validation loss per epoch, as well as the test set accuracy of the
    best model.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在我们的Azure Machine Learning工作区中看到了三个用于跟踪快照代码、上传输出工件和注册训练模型文件的有用功能。正如我们所见，这些功能可以通过几行代码添加到任何现有的实验和训练Python脚本或笔记本中。以类似的方式，我们也可以扩展实验脚本以跟踪所有类型的变量，例如每个epoch的训练准确率和验证损失，以及最佳模型的测试集准确率。
- en: Using the `run.log()` method, you can track any parameter during training and
    experimentation. You simply supply a name and a value, and Azure will do the rest
    for you. The backend automatically detects whether you send a list of values –
    hence multiple values with the same key when you log the same value multiple times
    in the same run – or a single value per run, such as the test performance. In
    Azure Machine Learning Studio, these values will be used automatically to visualize
    your overall training performance.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`run.log()`方法，你可以在训练和实验过程中跟踪任何参数。你只需提供一个名称和值，Azure就会为你完成剩余的工作。后端会自动检测你是否发送了一个值列表——因此当你多次记录相同值时，会有多个具有相同键的值——或者每个运行一个单独的值，例如测试性能。在Azure
    Machine Learning Studio中，这些值将自动用于可视化你的整体训练性能。
- en: Our Keras model so far is tracking the *loss* as a metric by default and the
    *accuracy* of the model through our model compilation. We just don't log them
    to the workspace.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的Keras模型默认通过模型编译跟踪*损失*作为指标，并通过我们的模型编译跟踪模型的*准确率*。我们只是没有将它们记录到工作区中。
- en: We previously talked about the different datasets we are using in the script,
    namely the training dataset, the validation dataset, and the test dataset. Remember
    that the validation dataset is evaluated at the end of each epoch, which also
    means we can get the **validation loss** and the **validation accuracy** at the
    end of each epoch. Further, after we have found the best model of all epochs,
    we want to evaluate this model against the test data, which we have not done yet.
    This then results in the *test loss* and *test accuracy* of the model.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论了脚本中使用的不同数据集，即训练数据集、验证数据集和测试数据集。请记住，验证数据集在每个epoch结束时进行评估，这也意味着我们可以在每个epoch结束时获得**验证损失**和**验证准确率**。进一步地，在我们找到所有epoch的最佳模型之后，我们希望评估这个模型与测试数据，而这我们还没有做。这导致了模型的*测试损失*和*测试准确率*。
- en: In the following, we will first add the test metrics to our run, then the validation
    metrics, and then have a look at them in Azure Machine Learning Studio. Finally,
    we will enhance the code so that we only register a model if it is better than
    all of the models from previous runs. Feel free to have the `02_run_experiment_keras_enhanced.ipynb`
    notebook open to follow along.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下内容中，我们将首先将测试指标添加到我们的运行中，然后是验证指标，然后在Azure Machine Learning Studio中查看它们。最后，我们将增强代码，以便只有当模型比之前运行中的所有模型都好时才注册模型。请随意打开`02_run_experiment_keras_enhanced.ipynb`笔记本以跟随操作。
- en: Evaluation of the best model
  id: totrans-381
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最佳模型的评估
- en: 'The goal is to evaluate the best training model of all epochs against the test
    dataset to get the overall test metrics. In order to do this, we need to load
    it back into our model object. Luckily, we already only stored the best model
    of the whole run in our `output` folder using the checkpoint callback that we
    defined before. Let''s look at the code:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是评估所有epoch的最佳训练模型与测试数据集以获得整体测试指标。为了做到这一点，我们需要将其重新加载到我们的模型对象中。幸运的是，我们已经在之前定义的checkpoint回调中，只将整个运行的最好模型存储到了我们的`output`文件夹中。让我们看看代码：
- en: '[PRE33]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: As you can see, we get back the best model and then evaluate it, extracting
    the loss (`scores[0]`) and the accuracy (`scores[1]`). Having done this part,
    let's have a look at the validation metrics.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们得到了最佳模型，然后对其进行评估，提取损失（`scores[0]`）和准确率（`scores[1]`）。完成这部分后，让我们看看验证指标。
- en: A Keras callback for validation metrics
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Keras的验证指标回调
- en: The goal is to evaluate the model created in each epoch against the validation
    dataset to get the validation metrics for each epoch. We already used an existing
    callback to check for the best model in each epoch, so it might be a good idea
    to write one ourselves to track the metrics in each epoch.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是在每个epoch中评估创建的模型与验证数据集，以获取每个epoch的验证指标。我们已使用现有的回调在每个epoch中检查最佳模型，所以自己编写一个来跟踪每个epoch的指标可能是个好主意。
- en: 'Open the `keras_azure_ml_cb.py` file in the `code` directory. You will be greeted
    by the following:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在`code`目录下打开`keras_azure_ml_cb.py`文件。你会看到以下内容：
- en: '[PRE34]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The preceding code implements a simple Keras callback function. When the callback
    is executed, Keras passes the current epoch as well as all training and validation
    metrics as a dictionary (`logs`).
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码实现了一个简单的Keras回调函数。当回调执行时，Keras会将当前epoch以及所有训练和验证指标作为字典（`logs`）传递。
- en: What then happens is that for all dictionary entries, we pull out the name and
    the value to log them to the experiment run with the `run.log(metric_name,metric_val)`
    function. We only have to check whether the value is a single value or an array
    type, as the Azure Machine Learning SDK has a different function called `run.log_list()`
    for multi-value entries.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于所有字典条目，我们提取名称和值，使用`run.log(metric_name,metric_val)`函数将它们记录到实验运行中。我们只需检查值是单个值还是数组类型，因为Azure
    Machine Learning SDK有一个名为`run.log_list()`的不同函数，用于多值条目。
- en: 'We can now use this callback in our model training the same way as we did with
    the previous callback, by adding it to the `model.fit()` function:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用这个回调在我们的模型训练中，就像我们之前使用回调一样，通过将其添加到`model.fit()`函数中：
- en: '[PRE35]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This extends Keras naturally using a callback function to track the training
    and validation loss and accuracy in the Azure Machine Learning service. Any metric
    defined on the model itself will now be tracked automatically in the experiment
    run.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过使用回调函数在Azure Machine Learning服务中跟踪训练和验证损失以及准确度，自然地扩展了Keras。现在，模型本身上定义的任何指标都将自动在实验运行中跟踪。
- en: Running metric visualization in Azure Machine Learning Studio
  id: totrans-394
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Azure Machine Learning Studio中运行指标可视化
- en: After we have added a bunch of metrics to the experiment run, let's run the
    notebook as is and have a look at the run statistics in Azure Machine Learning
    Studio.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们向实验运行添加了一堆指标之后，让我们按原样运行笔记本，并在Azure Machine Learning Studio中查看运行统计信息。
- en: 'When you open the run, the **Metrics** list of types, as with both validation
    metrics, are automatically converted into line charts and plotted, as shown in
    *Figure 3.12*:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 当你打开运行时，**指标**列表的类型，就像验证指标一样，都会自动转换为折线图并绘制出来，如图*图3.12*所示：
- en: '![Figure 3.12 – The metrics view of an experiment run ](img/B17928_03_012.jpg)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![图3.12 – 实验运行的指标视图](img/B17928_03_012.jpg)'
- en: Figure 3.12 – The metrics view of an experiment run
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 – 实验运行的指标视图
- en: We can see that the test metrics and validation metrics are all accounted for.
    In addition, we can see **Test loss** and **Test accuracy** as metrics, which
    are also provided by Keras for each epoch as the evaluation of the model against
    the training dataset.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到测试指标和验证指标都已考虑在内。此外，我们还可以看到**测试损失**和**测试准确率**作为指标，这些指标也是Keras为每个epoch提供的，作为模型对训练数据集的评估。
- en: Another nifty feature is that the ML workspace experiment gives you an overview
    of all your runs. It automatically uses both the scalar values and training and
    validation metrics that were logged per run and displays them on a dashboard.
    You can modify the displayed values and the aggregation method used to aggregate
    those values over the individual runs.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个很酷的功能是，ML工作区实验为你提供了所有运行的概览。它自动使用每个运行的标量值和训练以及验证指标，并在仪表板上显示它们。你可以修改显示的值和用于聚合这些值的聚合方法。
- en: '*Figure 3.13* shows the accuracy and the validation accuracy of all experiment
    runs:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.13*显示了所有实验运行的准确率和验证准确率：'
- en: '![Figure 3.13 – The visualized metrics of all experiment runs ](img/B17928_03_013.jpg)'
  id: totrans-402
  prefs: []
  type: TYPE_IMG
  zh: '![图3.13 – 所有实验运行的可视化指标](img/B17928_03_013.jpg)'
- en: Figure 3.13 – The visualized metrics of all experiment runs
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13 – 所有实验运行的可视化指标
- en: This is the simplest method of tracking values from the runs and displaying
    them with the corresponding experiments. Adding a few lines of code to your existing
    ML training scripts – independent of which framework you are using – automatically
    tracks your model scores and displays all experiments in a dashboard.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 这是跟踪运行值并显示相应实验的最简单方法。在现有的机器学习训练脚本中添加几行代码——无论你使用哪个框架——可以自动跟踪你的模型分数并在仪表板上显示所有实验。
- en: Enhancing the registration of models
  id: totrans-405
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 增强模型的注册
- en: Now that we have metrics to read out and work with, we can, as a final step,
    enhance the way we save the best model to the model registry.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了可以读取和处理的指标，作为最后一步，我们可以增强将最佳模型保存到模型注册的方式。
- en: So far, we always update the model with a new version as soon as a new model
    is available. However, this doesn't automatically mean that the new model has
    a better performance than the last model we registered in the workspace. As we
    want a new **version** of the model to actually be better than the last version,
    we need to check for that.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们总是在新模型可用时立即用新版本更新模型。然而，这并不意味着新模型的实际性能比我们在工作区中注册的最后一个模型更好。因为我们希望新**版本**的模型实际上比上一个版本更好，所以我们需要检查这一点。
- en: Therefore, a common approach is to register the new model only if the specified
    metric is better than the highest previously stored metric for the experiment.
    Let's implement this functionality.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个常见的做法是，只有当指定的指标比实验中之前存储的最高指标更好时，才注册新的模型。让我们实现这个功能。
- en: 'We can define a function that returns a generator of metrics from an experiment,
    like this:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以定义一个函数，它从一个实验中返回指标的生成器，如下所示：
- en: '[PRE36]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The preceding generator function yields the specified tracked metric for each
    run that is completed. We can use this function to return the best metric from
    all previous experiment runs to compare the evaluated score from the current model
    and decide whether we should register a new version of the model. We should do
    this only if the current model performs better than the previous recorded model.
    For that, we need to compare a metric. Using the **test accuracy** is a good idea,
    as it is the model tested against unknown data:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的生成器函数为每个完成的运行产生指定的跟踪指标。我们可以使用这个函数来返回所有先前实验运行中的最佳指标，以比较当前模型的评估分数并决定是否应该注册新版本的模型。我们只有在当前模型的表现优于之前记录的模型时才应该这样做。为此，我们需要比较一个指标。使用**测试准确率**是一个好主意，因为它是对未知数据进行测试的模型：
- en: '[PRE37]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As you can see, we get the result for the test accuracy metric of all previously
    runs tracked in this experiment and select the largest. We then register the model
    only if the test accuracy of the new model is higher than the previously stored
    best score. Nevertheless, we still upload and track the model binaries with the
    experiment run.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们得到了在此实验中跟踪的所有先前运行的测试准确率指标的结果，并选择了最大的一个。然后，只有当新模型的测试准确率高于之前存储的最佳分数时，我们才注册该模型。尽管如此，我们仍然将模型二进制文件与实验运行一起上传和跟踪。
- en: We now have an enhanced version of our notebook, including metrics tracking
    and a better version to register a model in the model registry.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了笔记本的增强版本，包括指标跟踪和更好的模型注册版本。
- en: Scheduling the script execution
  id: totrans-415
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度脚本执行
- en: In the previous section, we saw how you can annotate your existing ML experimentation
    and training code with a few lines of code in order to track relevant metrics
    and run artifacts in your workspace. In this section, we move from invoking the
    training script directly to scheduling the training script on the local machine.
    You might ask why this extra step is useful because there are not many differences
    between invoking the training script directly and scheduling the training script
    to run locally.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到了如何通过几行代码来注释现有的机器学习实验和训练代码，以便跟踪相关指标并在工作区中运行工件。在本节中，我们将从直接调用训练脚本转变为在本地机器上调度训练脚本。你可能会问为什么这一额外步骤是有用的，因为直接调用训练脚本和调度本地运行训练脚本之间并没有太多区别。
- en: The main motivation behind this exercise is that in the subsequent step, we
    can change the execution target to a remote compute target and run the training
    code on a compute cluster in the cloud instead of the local machine. This will
    be a huge benefit, as we can now easily test code locally and later deploy the
    same code to a highly scalable compute environment in the cloud.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习的主要动机是，在后续步骤中，我们可以将执行目标更改为远程计算目标，并在云中的计算集群上运行训练代码，而不是在本地机器上。这将是一个巨大的好处，因为我们现在可以轻松地在本地测试代码，然后将其部署到云中高度可扩展的计算环境中。
- en: One more thing to note is that when scheduling the training script instead of
    invoking it, the standard output and error streams, as well as all files in the
    **logs** directory, will be streamed directly to the Azure Machine Learning workspace
    run. This has the benefit of tracking the script output in real time in your ML
    workspace, even if your code is running on the remote compute cluster.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 另一点需要注意的是，当安排训练脚本而不是调用它时，标准输出和错误流以及**日志**目录中的所有文件都将直接流式传输到 Azure Machine Learning
    工作区运行。这有一个好处，即您可以在您的 ML 工作区实时跟踪脚本输出，即使您的代码正在远程计算集群上运行。
- en: Let's implement this in a so-called **authoring script**. We call it an authoring
    script (or authoring environment) when the script or environment's job is to schedule
    another training or experimentation script. In addition, we will now refer to
    the script that runs and executes the training as the **execution script** (or
    execution environment).
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在所谓的**编写脚本**中实现这一点。当我们说脚本或环境的任务是安排另一个训练或实验脚本时，我们称之为编写脚本（或编写环境）。此外，我们现在将运行和执行训练的脚本称为**执行脚本**（或执行环境）。
- en: We need to define two things in the authoring script – an environment we will
    run on and a run configuration, to which we will hand over the execution script,
    the environment, and a possible compute target.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写脚本中，我们需要定义两件事——我们将运行的环境和运行配置，我们将执行脚本、环境和可能的计算目标传递给它。
- en: Open the `03_run_experiment_local.ipynb` notebook file. Compared to our previous
    notebooks, you can see that this is a very short file, as the actual Keras training
    is happening now in the execution script, which you can find in the `cifar10_cnn_remote.py`
    file in the `code` folder.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 `03_run_experiment_local.ipynb` 笔记本文件。与我们的前一个笔记本相比，你可以看到这是一个非常短的文件，因为实际的
    Keras 训练现在正在执行脚本中进行，你可以找到 `code` 文件夹中的 `cifar10_cnn_remote.py` 文件。
- en: 'First, we need to define an environment. As we are still running locally, we
    create an environment with `user-managed-env`. This will just take our environment
    as is from our local machine:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要定义一个环境。由于我们仍在本地运行，我们使用 `user-managed-env` 创建一个环境，这将直接从我们的本地机器获取我们的环境：
- en: '[PRE38]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'In the next block, we define the location and name of the execution script
    we want to run locally:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个块中，我们定义了我们想要在本地运行的执行脚本的地址和名称：
- en: '[PRE39]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Finally, we define a run configuration using a `ScriptRunConfig` object and
    attach to it the source directory, the script name, and our previously defined
    local environment:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`ScriptRunConfig`对象定义一个运行配置，并将其源目录、脚本名称以及我们之前定义的本地环境附加到它：
- en: '[PRE40]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Now, execute the whole notebook, and while doing so, navigate to Azure Machine
    Learning Studio and look for the current run for our experiment called `cifar10_cnn_remote`.
    When it is visible, go to the `azureml-logs` and `logs/azureml` folders will now
    be populated with the logging output during the run.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，执行整个笔记本，同时导航到 Azure Machine Learning Studio，查找名为 `cifar10_cnn_remote` 的当前实验运行。当它可见时，转到
    `azureml-logs` 和 `logs/azureml` 文件夹，现在将填充运行期间的日志输出。
- en: '*Figure 3.14* shows an example of the ingested streaming logs:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.14* 展示了摄入的流式日志的一个示例：'
- en: '![Figure 3.14  – The streaming logs of an Azure Machine Learning experiment
    run ](img/B17928_03_014.jpg)'
  id: totrans-430
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.14 – Azure Machine Learning 实验运行的流式日志](img/B17928_03_014.jpg)'
- en: Figure 3.14 – The streaming logs of an Azure Machine Learning experiment run
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.14 – Azure Machine Learning 实验运行的流式日志
- en: This is very handy, as now we don't really need to know where the code is ultimately
    executed. All we care about is seeing the output, the progress of the run while
    tracking all metrics, generated models, and all other artifacts. The link to the
    current run can be retrieved by calling the `print(run.get_portal_url())` method.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常方便，因为现在我们实际上并不需要知道代码最终在哪里执行。我们唯一关心的是看到输出，运行进度，同时跟踪所有指标，生成的模型以及所有其他工件。可以通过调用
    `print(run.get_portal_url())` 方法检索当前运行的链接。
- en: 'However, instead of navigating to the Azure portal every time we run a training
    script, we can embed a widget in our notebook environment to give us the same
    (and more) functionality, directly within Jupyter, JupyterLab, or VS Code. To
    do so, we need to replace the `run.wait_for_completion()` line with the following
    snippet:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们不必每次运行训练脚本时都导航到Azure门户，我们可以在笔记本环境中嵌入一个小部件，以提供相同（甚至更多）的功能，直接在Jupyter、JupyterLab或VS
    Code中。为此，我们需要将`run.wait_for_completion()`行替换为以下代码片段：
- en: '[PRE41]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Please be aware that you need to add the **Azure Widgets Python extension**
    to your environment. Please refer to this installation guide for the extension:
    [https://docs.microsoft.com/en-us/python/api/azureml-widgets/azureml.widgets.rundetails?view=azure-ml-py](https://docs.microsoft.com/en-us/python/api/azureml-widgets/azureml.widgets.rundetails?view=azure-ml-py).'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您需要将**Azure Widgets Python扩展**添加到您的环境中。请参阅此安装指南了解扩展：[https://docs.microsoft.com/en-us/python/api/azureml-widgets/azureml.widgets.rundetails?view=azure-ml-py](https://docs.microsoft.com/en-us/python/api/azureml-widgets/azureml.widgets.rundetails?view=azure-ml-py)。
- en: Finally, let's have a look at the execution script we are using. Open the file
    named `cifar10_cnn_remote.py` in the `code` directory. Scanning through this,
    you should find two additional parts that we added to the original model training
    code.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看我们正在使用的执行脚本。在`code`目录中打开名为`cifar10_cnn_remote.py`的文件。扫描这个文件，你应该会找到我们添加到原始模型训练代码中的两个附加部分。
- en: 'The first one is the part where we write debug logs into the `logs` folder:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个部分是我们将调试日志写入`logs`文件夹的部分：
- en: '[PRE42]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The second part looks like this:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 第二部分看起来是这样的：
- en: '[PRE43]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The reason for this call is that when we want to move to a remote execution
    environment, we need to infer the run context. Therefore, we need to load the
    `run` object from the current execution context instead of creating a new run,
    as shown in the previous sections, where we used the `exp.start_logging()` call.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 进行此调用的原因是，当我们想要迁移到远程执行环境时，我们需要推断运行上下文。因此，我们需要从当前执行上下文中加载`run`对象，而不是像之前章节中所示的那样创建一个新的运行，当时我们使用了`exp.start_logging()`调用。
- en: The `run` object will be automatically linked with the experiment when it was
    scheduled through the authoring script. This is handy for remote execution, as
    we don't need to explicitly specify the `run` object in the execution script anymore.
    Using this inferred `run` object, we can log values, upload files and folders,
    and register models exactly as in the previous sections.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 当通过作者脚本进行调度时，`run` 对象将自动与实验关联。这对于远程执行来说很方便，因为我们不再需要在执行脚本中显式指定`run`对象。使用这个推断的`run`对象，我们可以记录值、上传文件和文件夹，以及注册模型，就像在之前的章节中做的那样。
- en: Running experiments on a cloud compute
  id: totrans-443
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在云计算上运行实验
- en: After running our experiments so far on our local machine, let's proceed now
    as a final step in this chapter to run the same ML model on a compute target in
    the ML workspace.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们已经在本地机器上运行了实验之后，现在让我们在本章的最后一个步骤中，在ML工作空间中的计算目标上运行相同的ML模型。
- en: The recommended compute target for training ML models in Azure is the managed
    Azure Machine Learning compute cluster, an auto-scaling compute cluster that is
    directly managed within your Azure subscription. If you have already used Azure
    for batch workloads, you will find it similar to Azure Batch and Azure Batch AI,
    with less configuration and tightly embedded in the Azure Machine Learning service.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure中训练ML模型推荐的计算目标是受管理的Azure Machine Learning计算集群，这是一个直接在您的Azure订阅内管理的自动扩展计算集群。如果您已经使用Azure进行批量工作负载，您会发现它与Azure
    Batch和Azure Batch AI类似，配置更少，并且紧密集成在Azure Machine Learning服务中。
- en: There are three options to deploy a cluster, either through the Azure CLI and
    YAML, through the Python SDK, or through Azure Machine Learning Studio. In the
    following steps, we will use the first options, as they are becoming more prevalent,
    especially with MLOps. After that, we will see how with Python code the second
    option works as well.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种方式可以部署集群，要么通过Azure CLI和YAML，要么通过Python SDK，要么通过Azure Machine Learning Studio。在以下步骤中，我们将使用第一种方式，因为它们越来越普遍，尤其是在MLOps中。之后，我们将看到如何使用Python代码实现第二种方式。
- en: 'Open the `compute.yml` file in the working directory. You will see the following:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作目录中打开`compute.yml`文件。您将看到以下内容：
- en: compute.yml
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: compute.yml
- en: '[PRE44]'
  id: totrans-449
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This describes a compute cluster named `mldemocompute` that we want to deploy.
    This configuration defines a compute type (`amlcompute`) in the ML workspace with
    0–2 nodes with a VM size of **Standard D2v2** (2 CPUs, 7 GB of RAM, and 100 GB
    HDD) in the West US 2 Azure region. In addition, we define the idle time before
    the cluster scales down (shuts off) to be 15 minutes (which equals 900 seconds).
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 这描述了一个名为 `mldemocompute` 的计算集群，我们希望部署。此配置在 ML 工作区中定义了一个计算类型（`amlcompute`），具有
    0-2 个节点，VM 大小为 **Standard D2v2**（2 个 CPU，7 GB 的 RAM 和 100 GB 的 HDD），位于美国西部 2 的
    Azure 区域。此外，我们定义了集群缩放（关闭）前的空闲时间为 15 分钟（等于 900 秒）。
- en: There are many other settings for compute clusters, including diverse network
    and load balancing settings. You can also define VM types with GPUs as your worker
    nodes – for example, **Standard_NC6** (6 CPUs, 56 GB of RAM, 340 GB SSD, 1 GPU,
    and 12 GB GPU memory) – by simply changing the configuration.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 计算集群有许多其他设置，包括各种网络和负载均衡设置。你也可以通过简单地更改配置来定义带有 GPU 的 VM 类型作为你的工作节点 – 例如，**Standard_NC6**（6
    个 CPU，56 GB 的 RAM，340 GB 的 SSD，1 个 GPU 和 12 GB 的 GPU 内存）。
- en: In contrast to other managed clusters, such as Azure Databricks, you don't pay
    for a head or master node, just for worker nodes. We will go into a lot more detail
    about VM types for deep learning in [*Chapter 10*](B17928_10_ePub.xhtml#_idTextAnchor165),
    *Training Deep Neural Networks on Azure*, and run distributed training on GPU
    clusters in [*Chapter 12*](B17928_12_ePub.xhtml#_idTextAnchor189), *Distributed
    Machine Learning on Azure*.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他托管集群（如 Azure Databricks）相比，你不需要为头节点或主节点付费，只需为工作节点付费。我们将在 [*第 10 章*](B17928_10_ePub.xhtml#_idTextAnchor165)
    *在 Azure 上训练深度神经网络* 和 [*第 12 章*](B17928_12_ePub.xhtml#_idTextAnchor189) *在 Azure
    上进行分布式机器学习* 中详细介绍深度学习的 VM 类型，并运行 GPU 集群的分布式训练。
- en: 'If you are working with VS Code, the **Azure ML** extension (reachable in the
    Azure tab on the left) can show you YAML templates. Just go to your ML workspace,
    and under **mldemows** | **Compute** | **Compute clusters**, click on the **+**
    sign on the right. It will generate a template file, which looks like a bare version
    of the preceding one. In addition, if you have installed the YAML extension, it
    will understand the schema link in the file and will autocomplete your typing:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用 VS Code，可以在左侧的 Azure 选项卡中找到 **Azure ML** 扩展（可显示 YAML 模板）。只需转到你的 ML 工作区，然后在
    **mldemows** | **Compute** | **Compute clusters** 下，点击右侧的 **+** 号。它将生成一个模板文件，看起来像是前面版本的裸版本。此外，如果你已安装
    YAML 扩展，它将理解文件中的模式链接并自动完成你的输入：
- en: 'Open the console and run the following CLI command to create the compute instance
    from the YAML file:'
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开控制台并运行以下 CLI 命令，从 YAML 文件创建计算实例：
- en: '[PRE45]'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: You can also call the shell script in the working directory called `04_setup_azure_ml_compute.sh`.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以调用工作目录中名为 `04_setup_azure_ml_compute.sh` 的 shell 脚本。
- en: After a short while, it will give you an output showing the properties of the
    created compute cluster.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 稍等片刻，它将显示创建的计算集群的属性。
- en: Open the notebook called `05_run_experiment_remote.ipynb`.
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开名为 `05_run_experiment_remote.ipynb` 的笔记本。
- en: 'The second block in that notebook shows you the following code:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 那个笔记本中的第二个块展示了以下代码：
- en: '[PRE46]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The `except` clause of the `try` construct shows you the way you can create
    a compute cluster through the Python SDK. As the name of the cluster is the same
    as the one we already deployed via the CLI, when executing this block, it will
    just link our compute to the `aml_cluster` object through the `try` clause.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: '`try` 构造的 `except` 子句展示了你可以通过 Python SDK 创建计算集群的方式。由于集群的名称与我们之前通过 CLI 部署的名称相同，当执行此块时，它将通过
    `try` 子句将我们的计算链接到 `aml_cluster` 对象。'
- en: Either way, this `try..except` clause is very handy, as it either gives us back
    the already existing cluster or creates a new one for us. The final line of code
    is necessary if the compute target does not already exist, as we need to wait
    for the compute target to be ready to receive the run configuration in the next
    steps.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 无论哪种方式，这个 `try..except` 子句都非常方便，因为它要么返回已经存在的集群，要么为我们创建一个新的集群。如果计算目标尚未存在，则代码的最后一行是必要的，因为我们需要等待计算目标在下一步准备好接收运行配置。
- en: 'If we now have a look at the environment definition and the run configuration,
    we will see some minor changes to the code from the `03_run_experiment_local.ipynb`
    notebook. Our environment definition now looks like this:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在查看环境定义和运行配置，我们将看到从 `03_run_experiment_local.ipynb` 笔记本中代码的一些细微变化。我们现在的环境定义如下所示：
- en: '[PRE47]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'As you can see, we attach to the environment our PIP configuration file we
    worked with locally. In the backend, the SDK will convert this to a **Conda properties
    file** and create a container from a Docker base image. If you run the cells up
    to this one, you will see which base image and configuration Azure Machine Learning
    builds based on this input. A small excerpt of this is shown here:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们附上了我们在本地工作的PIP配置文件。在后台，SDK将将其转换为**Conda属性文件**，并从Docker基础镜像创建一个容器。如果您运行到这一步，您将看到Azure机器学习基于此输入构建的基础镜像和配置。这里展示的是其中一小部分：
- en: '[PRE48]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Having a look at the final block in the notebook, we can see that the only difference
    is that we now define the compute target to be our `aml_cluster` in the run configuration
    and pass the new environment.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本的最后一个块中查看，我们可以看到唯一的区别是，我们现在在运行配置中将计算目标定义为我们的`aml_cluster`，并传递新的环境。
- en: Finally, we now run the whole notebook.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们现在运行整个笔记本。
- en: 'The training script is now executed in the remote compute target on Azure.
    In the experiment run in Azure Machine Learning Studio, the snapshot, outputs,
    and logs look very similar to the local run. However, we can now also see the
    logs of the Docker environment build process for the compute target, as shown
    in *Figure 3.15*:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本现在在Azure的远程计算目标上执行。在Azure机器学习工作室中的实验运行中，快照、输出和日志看起来与本地运行非常相似。然而，我们现在还可以看到计算目标的Docker环境构建过程的日志，如图3.15所示：
- en: '![Figure 3.15 – The Docker build phase for a remote experiment run ](img/B17928_03_015.jpg)'
  id: totrans-470
  prefs: []
  type: TYPE_IMG
  zh: '![图3.15 – 远程实验运行的Docker构建阶段](img/B17928_03_015.jpg)'
- en: Figure 3.15 – The Docker build phase for a remote experiment run
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 – 远程实验运行的Docker构建阶段
- en: 'As a final exercise, let''s understand the steps that are performed when we
    submit this run to the Azure Machine Learning workspace:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的练习，让我们了解当我们提交这次运行到Azure机器学习工作区时执行的步骤：
- en: The Azure Machine Learning service builds a Docker container from the defined
    environment if it doesn't exist already.
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果不存在，Azure机器学习服务将根据定义的环境构建Docker容器。
- en: The Azure Machine Learning service registers your environment in the private
    container registry so that it can be reused for other scripts and deployments.
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure机器学习服务在私有容器注册表中注册您的环境，以便它可以用于其他脚本和部署。
- en: The Azure Machine Learning service queues your script execution.
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure机器学习服务排队执行您的脚本。
- en: The Azure Machine Learning compute initializes and scales up a compute node
    using the defined container.
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure机器学习计算服务使用定义的容器初始化和扩展计算节点。
- en: The Azure Machine Learning compute executes the script.
  id: totrans-477
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure机器学习计算服务执行脚本。
- en: The Azure Machine Learning compute captures logs, artifacts, and metrics and
    streams them to the Azure Machine Learning service, and inlines the logs in the
    Jupyter notebook through the widget.
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure机器学习计算服务捕获日志、工件和指标，并将它们流式传输到Azure机器学习服务，并通过小部件在Jupyter笔记本中内联日志。
- en: The Azure Machine Learning service stores all artifacts in the workspace storage
    and your metrics in Application Insights.
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure机器学习服务将所有工件存储在工作区存储中，并将您的指标存储在Application Insights中。
- en: The Azure Machine Learning service provides you with all the information about
    the run through Azure Machine Learning Studio or the Python SDK.
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure机器学习服务通过Azure机器学习工作室或Python SDK为您提供有关运行的全部信息。
- en: The Azure Machine Learning compute automatically scales itself down after 15
    minutes (in our case) of inactivity.
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure机器学习计算服务在15分钟（在我们的情况下）的无操作后自动缩小自身。
- en: Congratulations on following along with this exercise. Given that it took us
    maybe 5 minutes to set up the Azure Machine Learning workspace, we get a fully
    fledged batch compute scheduling and execution environment for all our ML workloads.
    Many bits and pieces of this environment can be tuned and configured to our liking,
    and best of all, everything can be automated through the Azure CLI or the Azure
    Python SDK. Throughout the book, we will use these tools to configure, start,
    scale, and delete clusters for training and scoring.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您跟随着这个练习。鉴于我们可能花费了5分钟来设置Azure机器学习工作区，我们得到了一个完整的批量计算调度和执行环境，用于我们所有的机器学习工作负载。这个环境中的许多部分都可以根据我们的喜好进行调整和配置，最好的是，一切都可以通过Azure
    CLI或Azure Python SDK自动化。在整个书中，我们将使用这些工具来配置、启动、扩展和删除用于训练和评分的集群。
- en: Summary
  id: totrans-483
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This concludes the first part of this book. By now, you should have a good idea
    of what ML in general entails, what services and options are available in Azure,
    and how to utilize the Azure Machine Learning service to do ML experimentation
    and enhance your existing ML modeling scripts.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的第一部分到此结束。到目前为止，你应该对机器学习（ML）的一般概念有了很好的了解，Azure中可用的服务和选项，以及如何利用Azure机器学习服务进行ML实验并增强你现有的ML建模脚本。
- en: In the next part of the book, we will concentrate on one of the aspects of ML
    often overlooked, the data itself. It is extremely vital to get this right. You
    might have heard the phrase *garbage in, garbage out* before, which holds true.
    Therefore, we will be working on removing as many pitfalls as possible by running
    automated data ingestion, cleaning and preparing data, extracting features, and
    performing labeling. In the end, we will bring all our knowledge together to discuss
    how to set up an ingestion and training ML pipeline.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的下一部分，我们将专注于机器学习经常被忽视的一个方面，即数据本身。正确处理这一点至关重要。你可能之前听说过“垃圾输入，垃圾输出”这个短语，这是真的。因此，我们将通过运行自动数据摄取、数据清理和准备、特征提取以及执行标注来尽可能多地消除陷阱。最后，我们将把我们的知识汇总起来，讨论如何设置数据摄取和训练ML管道。
- en: As the first step of this process, we need to understand different data sources
    and formats and bring our data to the Azure Machine Learning workspace, which
    we will discuss in the next chapter.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这个过程的第一步，我们需要了解不同的数据源和格式，并将我们的数据带到Azure机器学习工作区，我们将在下一章中讨论这一点。
