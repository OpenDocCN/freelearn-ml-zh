# *第五章*: 探索启发式搜索

**启发式搜索**是四组超参数调整方法中的第三组。这一组与其他组的关键区别在于，属于这一组的所有方法都是通过进行*试错*来达到最优解。类似于贝叶斯优化中的获取函数（参见[*第四章*](B18753_04_ePub.xhtml#_idTextAnchor036)*，探索贝叶斯优化*），这一组的所有方法也采用了*探索与利用*的概念。**探索**意味着在未探索的空间中进行搜索，以降低陷入局部最优的概率，而**利用**则意味着在已知有很大可能包含最优解的局部空间中进行搜索。

在本章中，我们将讨论属于启发式搜索组的几种方法，包括**模拟退火**（**SA**）、**遗传算法**（**GAs**）、**粒子群优化**（**PSO**）和**基于种群的训练**（**PBT**）。类似于[*第四章*](B18753_04_ePub.xhtml#_idTextAnchor036)，我们将讨论每种方法的定义、它们之间的区别、它们的工作原理以及每种方法的优缺点。

到本章结束时，你将理解上述属于启发式搜索组的超参数调整方法的概念。当有人以高层次和详细的方式询问你时，你将能够自信地解释这些方法，并包括它们的优缺点。一旦你足够自信地向其他人解释它们，这意味着你已经理解了每种方法的来龙去脉。因此，在实践中，如果你遇到错误或没有得到预期的结果，你可以理解发生了什么；你还将知道如何配置该方法，使其与你的特定问题相匹配。

在本章中，我们将涵盖以下主题：

+   理解模拟退火

+   理解遗传算法

+   理解粒子群优化

+   理解基于种群的训练

# 理解模拟退火

**SA**是受冶金中**金属退火**过程启发的启发式搜索方法。这种方法与随机搜索超参数调整方法（参见[*第三章*](B18753_03_ePub.xhtml#_idTextAnchor031)*，探索穷举搜索*）类似，但存在一个指导超参数调整过程如何工作的标准。换句话说，SA就像是一个*平滑版的随机搜索*。就像随机搜索一样，建议在每次试验所需时间不多且你有足够的计算资源时使用SA。

在金属退火过程中，金属被加热到非常高的温度一段时间，然后缓慢冷却以增加其强度，降低其硬度，使其更容易加工。给予非常高的热量的目的是激发金属的原子，使它们可以自由且随机地移动。在随机的移动过程中，原子通常会倾向于形成更好的配置。然后，执行缓慢的冷却过程，以便我们可以得到材料的晶体形式。

就像在金属退火过程中一样，SA通过随机选择要测试的超参数集来工作。在每次试验中，该方法将考虑当前集的一些“邻居”，随机地。如果满足接受准则，那么方法将改变其焦点到那个“邻居”集。接受准则不是一个确定性函数，它是一个随机函数，这意味着在过程中会涉及到概率。这种决定方式与金属退火过程中的冷却阶段相似，在那里我们接受更少的坏超参数集，因为更多的搜索空间被探索。

SA是最受欢迎的启发式优化方法之一——**随机爬山法**（**SHC**）的改进版本。SHC非常易于理解和实现，这意味着SA也是如此。*一般来说*，SHC通过在预定义的边界内初始化随机点（在我们的案例中是超参数空间）并将其视为当前最佳解来工作。然后，它会在所选点的周围随机搜索下一个候选点。然后，我们需要比较所选候选点与当前最佳解。如果候选点比当前最佳解更好或相等，SHC将候选点视为新的最佳解。这个过程会重复进行，直到满足停止准则。

以下步骤展示了SHC优化在一般情况下是如何工作的：

1.  定义空间边界*B*和步长*S*。

1.  定义停止准则。通常，它被定义为迭代次数，但其他停止准则的定义也适用。

1.  在边界*B*内初始化随机点。

1.  将从*步骤3*中选定的点设置为当前点*current_point*，以及最佳点*best_point*。

1.  在距离*best_point*的*S*距离内，从边界*B*内随机采样下一个候选点，并将其存储为*candidate_point*。

1.  如果*candidate_point*比*best_point*更好或相等，则用*candidate_point*替换*best_point*。

1.  将*current_point*替换为*candidate_point*。

1.  重复*步骤5*到*步骤7*，直到满足停止准则。

SA（模拟退火）和SHC（基于热力学的冷却）之间的主要区别在于 *步骤 5* 和 *步骤 6*。在SHC中，我们总是从 *最佳点* 的周围采样下一个候选点，而在SA中，我们从 *当前点* 的周围采样。在SHC中，我们只接受比当前最佳解更好或相等的候选点，而在SA中，我们 *可能也会以一定的概率接受更差的候选点*，这个概率由接受标准 *AC* 指导，该标准定义如下：

![公式 B18753_05_001.png](img/Formula_B18753_05_001.png)

在这里，![公式 B18753_05_002.png](img/Formula_B18753_05_002.png) 和 ![公式 B18753_05_003.png](img/Formula_B18753_05_003.png) 是目标函数，![公式 B18753_05_004.png](img/Formula_B18753_05_004.png) 是具有正值的 *温度*。如果您不熟悉目标函数术语，请参阅 [*第 4 章*](B18753_04_ePub.xhtml#_idTextAnchor036)。

![公式 B18753_05_005.png](img/Formula_B18753_05_005.png) 公式的结果在 0 和 1 之间，当 *候选点* 比当前点更好或相等时，它总是产生 1 的值。换句话说，当 *候选点* 比当前点更好或相等时，我们总是接受它。值得注意的是，*更好* 并不一定意味着具有更大的值。如果您正在处理一个最大化问题，那么更好意味着更大。然而，如果您正在处理一个最小化问题，那么情况则相反。例如，如果您正在测量的交叉验证分数是 **均方误差**（MSE），其中较低的分数对应于更好的性能，那么如果 ![公式 B18753_05_006.png](img/Formula_B18753_05_006.png) 的值小于 ![公式 B18753_05_007.png](img/Formula_B18753_05_007.png)，则认为 *候选点* 比当前点更好。

尽管以下公式 ![公式 B18753_05_008.png](img/Formula_B18753_05_008.png) 受到 ![公式 B18753_05_009.png](img/Formula_B18753_05_009.png) 和 ![公式 B18753_05_010.png](img/Formula_B18753_05_010.png) 的影响，但我们只能控制 ![公式 B18753_05_011.png](img/Formula_B18753_05_011.png) 的值。在实践中，![公式 B18753_05_012.png](img/Formula_B18753_05_012.png) 的 *初始值* 被视为一个超参数，通常设置为一个较高的值。在多次试验中，![公式 B18753_05_013.png](img/Formula_B18753_05_013.png) 的值会根据所谓的 **退火计划** 或冷却计划方案而降低。我们可以遵循几种退火计划方案。以下是最受欢迎的三种方案：

+   **几何冷却**：这种退火计划通过冷却因子 ![公式 B18753_05_014.png](img/Formula_B18753_05_014.png) 降低温度。在几何冷却中，初始温度 ![公式 B18753_05_015.png](img/Formula_B18753_05_015.png) 被冷却因子 ![公式 B18753_05_016.png](img/Formula_B18753_05_016.png) 乘以 ![公式 B18753_05_017.png](img/Formula_B18753_05_017.png) 次数，其中 ![公式 B18753_05_017.png](img/Formula_B18753_05_017.png) 是当前的迭代次数：

![公式 B18753_05_018.png](img/Formula_B18753_05_018.png)

这可以在以下图表中看到：

![图 5.1 – 几何冷却中初始温度对可接受标准的影响](img/Formula_B18753_05_001.png)

![图片 B18753_05_001.jpg](img/B18753_05_001.jpg)

图 5.1 – 几何冷却中初始温度对可接受标准的影响

+   **线性冷却**：这种退火计划通过冷却因子线性降低温度，![](img/Formula_B18753_05_019.png)。选择![](img/Formula_B18753_05_020.png)的值，使得![](img/Formula_B18753_05_021.png)在![](img/Formula_B18753_05_022.png)次迭代后仍然保持正值。例如，![](img/Formula_B18753_05_023.png)，其中![](img/Formula_B18753_05_024.png)是经过![](img/Formula_B18753_05_025.png)次迭代后的预期最终温度：

![](img/Formula_B18753_05_026.png)

下面的图表显示了这种退火计划：

![图5.2 – 线性冷却中初始温度对可接受标准的影响

![图片](img/B18753_05_002.jpg)

图5.2 – 线性冷却中初始温度对可接受标准的影响

+   **快速SA**：这种退火计划通过按当前迭代次数成比例降低温度来实现，![](img/Formula_B18753_05_027.png)：

![](img/Formula_B18753_05_028.png)

这种退火计划可以在以下图表中看到：

![图5.3 – 快速SA中初始温度对可接受标准的影响

![图片](img/B18753_05_003.jpg)

图5.3 – 快速SA中初始温度对可接受标准的影响

根据图5.1至图5.3，我们可以看到，无论我们使用什么退火计划方案以及初始温度是多少，随着迭代次数的增加，我们总是会得到一个更低的![](img/Formula_B18753_05_029.png)值，这意味着随着迭代次数的增加，我们将*接受更少的坏候选者*。然而，我们最初为什么要接受坏候选者呢？模拟退火（SA）方法的主要目的不是直接拒绝更差的候选者，正如在SHC方法中那样，而是*平衡探索和利用的权衡*。较高的初始温度值允许SA探索超参数空间的大部分区域，随着迭代次数的增加，逐渐聚焦于空间的具体部分，就像金属退火过程一样。

记住，![](img/Formula_B18753_05_030.png)仅在*候选点*比*当前点*更差时才考虑![](img/Formula_B18753_05_031.png)。这意味着，根据图5.4，我们可以这样说，建议的候选者越差（![](img/Formula_B18753_05_032.png)越高），![](img/Formula_B18753_05_033.png)的值就越低，因此，接受建议的坏候选者的概率就越低。对于![](img/Formula_B18753_05_034.png)来说，情况正好相反，![](img/Formula_B18753_05_035.png)的值越高，![](img/Formula_B18753_05_036.png)的值就越高，因此，接受建议的坏候选者的概率就越高（参见图5.1至图5.3）：

![图5.4 – Δf对可接受标准的影响

![图片](img/B18753_05_004.jpg)

图5.4 – Δf对可接受标准的影响

总结来说，以下步骤展示了 *SA* 作为超参数调整方法的工作原理：

1.  将原始完整数据分割成训练集和测试集（见 [*第1章*](B18753_01_ePub.xhtml#_idTextAnchor014)*，评估机器学习模型*）。

1.  使用伴随的分布定义超参数空间，*H*。

1.  定义初始温度，*T0*。

1.  根据训练集定义目标函数，*f*（见 [*第4章*](B18753_04_ePub.xhtml#_idTextAnchor036)）。

1.  定义停止标准。通常使用试验次数。然而，也可以使用时间或收敛性作为停止标准。

1.  使用 *T0* 的值设置当前温度，*T*。

1.  初始化一组从超参数空间，*H*，中采样的随机超参数。

1.  将从 *步骤 7* 中选择的集合设置为当前集合，*current_set*，以及最佳集合，*best_set*。

1.  从超参数空间，*H*，的“邻居”中随机采样下一个候选集合，*candidate_set*。不同类型的超参数分布中“邻居”的定义可能不同。

1.  从均匀分布中生成一个介于0和1之间的随机数，并将其存储为 *rnd*。

1.  决定是否接受 *candidate_set*：

    1.  使用 *T*、*f(candidate_set)* 和 *f(current_set)* 的值计算 ![](img/Formula_B18753_05_038.png) 的值。

    1.  如果 *rnd* 的值小于 ![](img/Formula_B18753_05_039.png)，则用 *candidate_set* 替换 *current_set*。

    1.  如果 *candidate_set* 比 *current_set* 更好或相等，则用 *candidate_set* 替换 *best_set*。

1.  将退火计划应用于温度，*T*。

1.  重复 *步骤 9* 到 *12*，直到满足停止标准。

1.  使用 *best_set* 超参数在完整训练集上训练。

1.  在测试集上评估最终训练的模型。

以下表格列出了SA作为超参数调整方法的优缺点列表：

![图5.5 – SA的优缺点

](img/B18753_05_005.jpg)

图5.5 – SA的优缺点

在本节中，我们从了解SA是什么、它是如何工作的、它区别于SHC和随机搜索的特点，以及它的优缺点开始，学习了SA。在下一节中，我们将讨论另一个有趣的启发式搜索方法，该方法受到自然选择理论的影响。

# 理解遗传算法

**遗传算法（GAs**）是受查尔斯·达尔文*自然选择理论*启发的流行启发式搜索方法。与被归类为**单点基于**启发式搜索方法的SA不同，GAs被归类为**基于群体**的方法，因为它们在每个试验中维护一组可能的候选解，而不是只维护一个候选解。作为一个超参数调整方法，当每个试验不需要太多时间并且你有足够的计算资源，如并行计算资源时，建议使用GA。

为了更好地理解遗传算法（GAs），让我们从一个简单的例子开始。假设我们有一个任务，基于**仅**由26个小写字母组成的单词集合生成一个预定义的目标单词。例如，目标单词是“big”，我们有一个由单词“sea”、“pig”、“dog”、“bus”和“tie”组成的集合。

基于给定的单词集合，我们应该如何生成“big”这个单词？这无疑是一个非常简单且直接的任务。我们只需从“bus”这个单词中挑选字母“b”，从“pig”或“tie”这个单词中挑选字母“i”，从“dog”这个单词中挑选字母“g”。就这样！我们得到了“big”这个单词。你可能想知道这个例子如何与GA方法或自然选择理论相关。这个例子是一个非常简单的任务，没有必要利用GA来解决问题。然而，我们需要这样的例子，以便你更好地理解GAs是如何工作的，因为你一开始就知道正确的答案。

要使用遗传算法（GA）解决这个问题，你必须了解与进化理论相关的GA中的三个关键项目。第一个关键项目是**变异**。想象一下，如果给定的单词集合只包含“sea”这个单词。我们无法仅基于“sea”这个单词生成“big”这个单词。这就是为什么在**初始群体**（在我们的例子中是单词集合）中需要变异。如果没有足够的变异，我们可能无法达到最优解（在我们的例子中是生成“big”这个单词），因为群体中没有**个体**（在我们的例子中是单词集合中的每个单词）能够进化到目标单词。

重要提示

人口**不是超参数空间**。在遗传算法（GAs）或其他基于群体的启发式搜索方法中，群体指的是最优超参数集的候选者。

第二个关键项目是**选择**。你可以将这个项目视为类似于现实世界中发生的自然选择的概念。这是关于选择更适合周围环境的个体（在我们的例子中是类似于“big”这个单词的单词）并且因此能够在世界上生存下来。在GAs中，我们需要定量指导来执行选择，这通常被称为**适应度函数**。这个函数帮助我们判断一个个体相对于我们想要实现的目标有多好。在我们的例子中，我们可以创建一个适应度函数，该函数衡量单词中与目标单词在相应索引中具有相同字母的索引的比例。例如，“tie”这个单词的适应度分数为 ![](img/Formula_B18753_05_041.png)，因为只有一个索引包含与目标单词相同的字母，即索引一，它包含字母“i”。

使用这个适应度函数，我们可以评估群体中每个个体的适应度分数，然后选择哪些个体应该被添加到**配对池**中作为**父母**。配对池是一组被认为是高质量个体的集合，因此被称为父母。

第三个关键要素是**遗传**。这个要素指的是**繁殖**或传递父母的**基因**（在我们的例子中是单词中的每个字母）给他们的孩子或**后代**。在GA中如何进行繁殖？遵循自然选择的相同精神，在GA中，我们只从配对池中的父母进行繁殖步骤，这意味着我们只想让高质量个体交配，希望在下一次**世代**（在下一个迭代中创建一个新的群体）中得到只有高质量的后代。繁殖阶段有两个步骤，即**交叉**和**变异**步骤。交叉步骤是我们随机混合或排列父母的基因以生成后代的基因，而变异步骤是我们随机改变后代的基因值以增加基因的变异（参见*图5.6*）。被变异的个体被称为**突变体**。变异步骤中使用的随机值应该来自相同的基因分布，这意味着在我们的例子中，我们只能使用小写字母作为随机值，不能使用浮点数或整数：

![Figure 5.6 – 遗传算法中的交叉和变异步骤]

![img/B18753_05_006.jpg]

图5.6 – 遗传算法中的交叉和变异步骤

现在你已经了解了遗传算法（GA）中的三个关键要素，我们可以从上一个示例开始使用GA来解决问题。假设我们没有给出单词集合，这样我们可以学习GA的完整过程。目标单词仍然是“big”。

首先，我们必须使用*NPOP*数量初始化一个个体群体。初始化过程通常是随机进行的，以确保我们在群体中拥有足够的变异。这里的随机意味着群体中每个个体的基因都是随机生成的。假设我们想要生成一个初始群体，该群体由七个个体组成，生成的结果为“bee”、“tea”、“pie”、“bit”、“dog”、“cat”和“dig”。

现在，我们可以评估群体中每个个体的适应度分数。假设我们使用之前定义的适应度函数。因此，我们得到了每个个体的以下分数；“bee:” ![](img/Formula_B18753_05_042.png)，“tea:” ![](img/Formula_B18753_05_043.png)，“pie:” ![](img/Formula_B18753_05_044.png)，“bit:” ![](img/Formula_B18753_05_045.png)，”dog:” ![](img/Formula_B18753_05_046.png)，“cat:” ![](img/Formula_B18753_05_047.png)，和“dig:” ![](img/Formula_B18753_05_048.png)。

根据每个个体的适应度分数，我们可以选择哪些个体应该作为父母添加到交配池中。我们可以采用许多策略来从种群中选择最佳个体，但在这个例子中，我们只是根据适应度分数选择前三个个体，并随机选择具有相同适应度分数的个体。比如说，在执行选择策略后，我们得到了一个由“bit”、“dig”和“bee”作为父母的交配池。

下一步是执行交叉和变异步骤。然而，在此之前，我们需要指定交叉概率*CXPB*和变异概率*MUTPB*，这定义了在交配池中交叉两个父母和变异一个后代的概率。这意味着我们既不对所有父母对执行交叉，也不对所有后代执行变异——我们只会根据预定义的概率执行这些步骤。比如说，只有“dig”和“bee”选择了交叉，交叉的结果是“deg”和“bie”。所以，当前的交配池由“bit”、“deg”和“bie”组成。现在，我们需要对“deg”和“bie”执行变异。比如说，变异后，我们得到了“den”和“tie”。这意味着当前的交配池由“bit”、“den”和“tie”组成。

在执行交叉和变异步骤之后，我们需要为下一代生成一个新的种群。这个新种群将包括所有交叉的父母、变异的后代以及来自当前种群的其他个体。因此，下一个种群将包括“bit”、“den”、“tie”、“tea”、“pie”、“dog”和“cat”。

根据新种群，我们必须重复选择、交叉和变异过程。这个程序需要执行*NGEN*次，其中NGEN代表代数，由开发者预先定义。

以下步骤定义了通用遗传算法（GA）作为优化方法的工作方式：

1.  定义种群大小*NPOP*、交叉概率*CXPB*、变异概率*MUTPB*以及代数或试验次数*NGEN*。

1.  定义适应度函数*f*。

1.  使用*NPOP*个个体初始化一个种群，其中每个个体的基因都是随机初始化的。

1.  根据适应度函数*f*评估种群中的所有个体。

1.  根据*步骤 4*选择最佳个体并将它们存储在交配池中。

1.  以*CXPB*的概率对交配池中的父母执行交叉过程。

1.  以*MUTPB*的概率对*步骤 8*产生的后代执行变异过程。

1.  生成一个新的种群，该种群由来自*步骤 6*、*步骤 7*以及当前种群中剩余的所有个体组成。

1.  用新种群替换当前种群。

1.  重复*步骤 6*到*步骤 9*共*NGEN*次。

现在，让我们看看一个更具体的例子，说明 GA 通常是如何工作的。我们将使用与 [*第 4 章*](B18753_04_ePub.xhtml#_idTextAnchor036)*，评估机器学习模型* 中相同的目标函数，并将其视为一个最小化问题。目标函数定义如下：

![](img/Formula_B18753_05_049.png)

这里，![](img/Formula_B18753_05_050.png) 是遵循标准正态分布的噪声。我们只将在 ![](img/Formula_B18753_05_051.png) 范围内进行搜索。值得注意的是，在这个例子中，我们假设我们知道真正的目标函数是什么。然而，在实践中，这个函数是未知的。在这种情况下，每个个体将只有一个基因，即 ![](img/Formula_B18753_05_052.png) 的值本身。

假设我们定义 GA 方法的超参数为 *NPOP = 25*, *CXPB = 0.5*, *MUTPB = 0.15*, 和 *NGEN = 6*。至于每个 **遗传算子** 的策略，我们分别使用 **锦标赛**、**混合** 和 **多项式边界** 策略来进行选择、交叉和变异操作。*锦标赛* 选择策略通过在 *tournsize* 个个体中选出最佳个体，以及随机选择的个体的 *NPOP* 倍，其中 *tournsize* 是参加锦标赛的个体数量。*混合* 交叉策略通过执行两个连续个体基因的线性组合来实现，其中线性组合的权重由 *alpha* 超参数控制。*多项式边界* 变异策略通过将连续个体基因传递到一个预定义的多项式映射中来实现。

根据您的超参数空间定义，有许多可用的策略可供选择。我们将在 [*第 10 章*](B18753_10_ePub.xhtml#_idTextAnchor092)*，使用 DEAP 和 Microsoft NNI 进行高级超参数调整* 中更多地讨论不同的策略以及如何使用 **DEAP** 包实现 GA 方法。现在，让我们看看对虚拟目标函数 *f* 应用 GA 的结果。请注意，每个图中的点对应于种群中的每个个体：

![图 5.7 – GA 流程

](img/B18753_05_007.jpg)

图 5.7 – GA 流程

根据前一个图表，我们可以看到在第一代，由于是随机初始化，个体分布在整个地方。在第二代，围绕点 -1.0 初始化的几个个体移动到了具有较低适应度分数的其他地方。然而，在第三代，围绕点 -1.0 又出现了新的个体。这可能是由于应用了随机变异算子。还有一些个体陷入了局部最优，大约在点 -0.5 附近。在第四代，大多数个体已经移动到了具有较低适应度分数的地方，尽管其中一些个体仍然陷入了局部最优。在第五代，个体开始在几个地方开始收敛。

最后，在第六代，所有个体都收敛到了接近全局最优解，大约在点 1.5 附近。请注意，我们仍然在第六代有 *NPOP=25* 个个体，但它们都位于同一个地方，这就是为什么在图表中只能看到一个点。这也适用于其他世代，如果你在图表中看到少于 25 个个体。各个世代的收敛趋势可以在以下图表中看到：

![图 5.8 – 收敛图

![img/B18753_05_008.jpg]

图 5.8 – 收敛图

前一个图表中显示的趋势与我们的先前分析相符。然而，我们可以从这个图中获得更多信息。起初，许多个体位于具有高适应度分数的地方，但一些个体已经获得了最佳的适应度分数。在各个世代中，大多数个体开始收敛，最终，在最后一代，所有个体都获得了最佳的适应度分数。值得注意的是，在实践中，并不能保证 GA 会达到全局最优解。

到目前为止，你可能想知道，如何将 GA 作为超参数调整方法采用？在超参数调整的上下文中，GA 中所有术语的对应定义是什么？当使用 GA 进行超参数调整时，“个体”意味着什么？

*作为超参数调整方法*，GA 方法将一组超参数视为一个个体，其中超参数的值是基因。为了更好地理解 GA 方法中每个重要术语的含义，在超参数调整的上下文中，请参考以下表格：

![图 5.9 – 超参数调整上下文中 GA 方法术语的定义

![img/B18753_05_009.jpg]

图 5.9 – 超参数调整上下文中 GA 方法术语的定义

既然你已经了解了 GA 方法中每个重要术语的相应定义，我们可以定义正式的程序来利用 *GA 方法作为超参数调整方法*：

1.  将原始完整数据集分为训练集和测试集。

1.  定义超参数空间，*H*，以及伴随的分布。

1.  定义种群大小，*NPOP*。

1.  定义交叉概率，*CXPB*，和变异概率，*MUTPB*。

1.  将试验次数，*NGEN*，定义为停止标准。

1.  根据训练集定义目标函数，*f*。

1.  *初始化*一个包含 *NPOP* 组超参数的种群，每组超参数都是从超参数空间，*H*，中随机抽取的。

1.  根据目标函数，*f*，评估种群中的所有超参数集。

1.  根据 *Step 8* 选择几个最佳候选集。

1.  以 *CXPB* 的概率对 *Step 9* 中的候选集进行交叉。

1.  以 *MUTPB* 的概率对 *Step 10* 中的交叉候选集进行变异。

1.  生成一个新的种群，该种群由 *Step 10*、*Step 11* 和当前种群中的其余超参数集的所有组合组成。新种群也将包含 *NPOP* 组超参数。

1.  重复 *Steps 8* 到 *12* *NGEN* 次。

1.  使用最终的超参数值在完整的训练集上进行训练。

1.  在测试集上评估最终训练好的模型。

值得注意的是，当利用 GA 作为超参数调整方法时，GA 本身有四个超参数，即 *NPOP*、*CXPB*、*MUTPB* 和 *NGEN*，它们控制超参数调整结果的表现，以及探索与利用之间的权衡。更精确地说，*CXPB* 和 *MUTPB*，即交叉和变异概率，分别负责控制 *探索* 速率，而选择步骤及其策略控制 *利用* 速率。

下表列出了使用 GA 作为超参数调整方法的优缺点：

![Figure 5.10 – Pros and Cons of the GA method

![img/B18753_05_010.jpg]

图 5.10 – GA 方法的优缺点

评估每一代中所有个体的需求意味着我们将我们目标函数的原始时间复杂度乘以 *NPOP * NGEN*。这非常昂贵！这就是为什么如果你有一个昂贵的目标函数和/或有限的计算资源，GA 方法可能不适合你。然而，如果你有等待实验完成的时间，并且你有大量的并行计算资源，那么 GA 方法适合你。从理论角度来看，GA 方法也可以与各种类型的超参数一起工作——我们只需要为相应的超参数选择合适的交叉和变异策略。与 SA 相比，GA 方法在拥有一个种群来指导需要更多探索的子空间部分方面更有优势。然而，值得注意的是，GA 方法仍然可能陷入局部最优。

在本节中，我们讨论了 GA 方法，从它是什么，以及它在一般设置和超参数调整环境中的工作方式，以及它的优缺点。在下一节中，我们将讨论另一个有趣的基于种群的启发式搜索方法。

# 理解粒子群优化

**PSO**也是一种基于种群的启发式搜索方法，类似于遗传算法（GA）方法。PSO受到自然界中鱼群和鸟群社会互动的启发。作为一种超参数调整方法，如果您的搜索空间包含许多非分类超参数，每次试验所需时间不多，并且您有足够的计算资源——特别是并行计算资源，建议使用PSO。

PSO是更大群体智能（SI）方法组中最受欢迎的方法之一。群体智能中有各种方法，这些方法受到自然界中动物社会互动的启发，例如陆地动物的群、蚂蚁的群体、鸟群、鱼群等等。群体智能方法的共同特征是**基于种群**的，种群内的个体相对**相似**，种群能够系统性地在种群内部或外部没有单个协调者的情况下向特定方向移动。换句话说，种群可以根据个体之间以及与周围环境的**局部交互**来组织自己。

当一群鸟在寻找食物时，人们认为每只鸟可以通过分享它们所看到的关于信息来为群体做出贡献，从而使群体能够朝正确的方向移动。粒子群优化（PSO）是一种模拟鸟群运动以优化目标函数的方法。在PSO中，鸟群被称为**群**，每只鸟被称为**粒子**。

每个粒子由其**位置**向量和**速度**向量定义。每个粒子的运动由随机和确定性成分组成。换句话说，每个粒子的运动不仅基于预定义的规则，还受到随机成分的影响。每个粒子还记住自己的**最佳位置**，这给出了它在轨迹上经过的最佳目标函数值。然后，结合**全局最佳位置**，它被用来在特定时间更新每个粒子的速度和位置。全局最佳位置只是上一步中最佳粒子的位置。

假设![](img/Formula_B18753_05_053.png)是群中m个粒子中第![](img/Formula_B18753_05_054.png)个粒子在d维空间中的位置向量，而![](img/Formula_B18753_05_055.png)是相同大小的![](img/Formula_B18753_05_056.png)粒子的速度向量，如图所示：

![](img/Formula_B18753_05_057.png)

![](img/Formula_B18753_05_058.png)

让我们也分别定义每个粒子的最佳位置和全局最佳位置向量：

![](img/Formula_B18753_05_059.png)

![](img/Formula_B18753_05_060.png)

以下公式定义了每个粒子在每次迭代中位置和速度向量的更新方式：

![](img/Formula_B18753_05_061.png)

![](img/Formula_B18753_05_062.png)

在这里，![](img/Formula_B18753_05_063.png)、![](img/Formula_B18753_05_064.png) 和 ![](img/Formula_B18753_05_065.png) 是控制*探索与利用权衡*的超参数。![](img/Formula_B18753_05_066.png) 的值通常在零到一之间，被称为**惯性权重系数**，而 ![](img/Formula_B18753_05_067.png) 和 ![](img/Formula_B18753_05_068.png) 分别被称为**认知**和**社会**系数。![](img/Formula_B18753_05_069.png) 和 ![](img/Formula_B18753_05_070.png) 是介于零和一之间的随机值，充当粒子运动的随机成分。请注意，位置和速度向量的 *d* 维数指的是我们在搜索空间中的超参数数量，而 *m* 个粒子指的是从超参数空间中采样的候选超参数的数量。

第一次更新速度向量可能看起来有些令人畏惧，但实际上，通过将公式视为三个独立的部分，你可以更容易地理解它。第一部分，或者公式的最左侧，旨在按比例更新下一个速度，与当前速度成正比。第二部分，或者公式的中间部分，旨在将速度更新到 ![](img/Formula_B18753_05_071.png) 粒子所具有的最佳位置的方向，同时向其中添加一个随机成分。第三部分，或者公式的最右侧，旨在将 ![](img/Formula_B18753_05_072.png) 粒子带到全局最佳位置附近，并对其应用额外的随机行为。以下图示有助于说明这一点：

![图 5.11 – 更新粒子的位置和速度

](img/B18753_05_011.jpg)

图 5.11 – 更新粒子的位置和速度

前面的图示与所给出的公式并不相同，因为图中缺少了随机成分和超参数。然而，这张图可以帮助我们理解每个粒子在每个迭代中位置和速度向量的更新高级概念。我们可以看到，最终更新的速度（*见橙色线*）是基于三个向量计算的，即当前速度（*见棕色线*）、粒子最佳位置（*见绿色线*）和全局最佳位置（*见紫色线*）。基于最终更新的速度，我们可以得到粒子的更新位置 – 那就是图中的 ![](img/Formula_B18753_05_073.png)。

现在，让我们讨论超参数如何影响公式。惯性权重系数，![公式](img/Formula_B18753_05_075.png)，控制我们在更新速度向量时想要将多少注意力放在当前速度上。另一方面，认知系数，![公式](img/Formula_B18753_05_076.png)，和社会系数，![公式](img/Formula_B18753_05_077.png)，分别控制我们应该在多大程度上关注粒子的过去轨迹历史和群搜索结果。当我们设置![公式](img/Formula_B18753_05_078.png)时，我们不考虑最佳位置![公式](img/Formula_B18753_05_079.png)粒子的影响，这可能导致我们陷入*局部最优解*。当我们设置![公式](img/Formula_B18753_05_080.png)时，我们忽略了全局最佳位置的影响，这可能导致*收敛速度较慢*。

现在你已经了解了群中每个粒子的位置和速度分量，请查看以下步骤，这些步骤定义了粒子群优化（PSO）作为优化方法的一般工作方式：

1.  定义群大小*N*，惯性权重系数*w*，认知系数*c1*，社会系数*c2*和最大尝试次数。

1.  定义适应度函数*f*。

1.  初始化一个包含*N*个粒子的群，其中每个粒子的位置和速度向量都是随机初始化的。

1.  将每个粒子的当前位置向量设置为它们的最佳位置向量，*pbi*。

1.  通过从所有*N*个粒子中选择具有最佳适应度分数的位置向量来设置当前全局最佳位置，*gb*。

1.  根据更新公式更新每个粒子的位置和速度向量。

1.  根据适应度函数*f*评估群中的所有粒子。

1.  更新每个粒子的最佳位置向量，*pbi*：

    1.  将每个粒子的当前适应度分数与*步骤7*中的*pbi*适应度分数进行比较。

    1.  如果当前适应度分数优于*pbi*适应度分数，则使用当前位置向量更新*pbi*。

1.  更新全局最佳位置向量，*gb*：

    1.  将每个粒子的当前适应度分数与*步骤7*中的先前*gb*适应度分数进行比较。

    1.  如果当前适应度分数优于*gb*适应度分数，则使用当前位置向量更新*gb*。

1.  根据更新公式更新每个粒子的位置和速度向量。

1.  重复*步骤7*到*10*，直到达到最大尝试次数。

1.  返回最终的全球最佳位置，*gb*。

值得注意的是，最优适应度分数（或先前所述程序中的更好适应度分数）的定义将取决于你试图解决的优化问题类型。如果是最小化问题，则较小的适应度分数较好。如果是最大化问题，则情况相反。

为了更好地理解PSO的工作原理，让我们通过一个例子来分析。让我们定义适应度函数如下：

![公式](img/Formula_B18753_05_081.png)

在这里，![](img/Formula_B18753_05_082.png) 和 ![](img/Formula_B18753_05_083.png) 仅在 ![](img/Formula_B18753_05_084.png) 范围内定义。下面的 *等高线图* 展示了我们的目标函数看起来是什么样子。我们将在 [*第 10 章*](B18753_10_ePub.xhtml#_idTextAnchor092)*，使用 DEAP 和 Microsoft NNI 进行高级超参数调整中学习如何使用 **DEAP** 包实现 PSO：

![图 5.12 – 显示目标函数及其全局最小值的等高线图

![图片 B18753_05_012.jpg]

图 5.12 – 显示目标函数及其全局最小值的等高线图

在这里，您可以看到全局最小值 (*见红色十字标记*) 位于 (0.497, 0.295)，目标函数值为 –0.649。让我们尝试使用 PSO 来看看它如何估计目标函数的最小值与真实全局最小值相比。假设我们定义 PSO 的超参数为 *N=20*，*w=0.5*，*c1=0.3*，和 *c2=0.5*，并将最大尝试次数设置为 16。

您可以在以下等高线图中看到初始群体示意图。蓝色点代表每个粒子，每个粒子上的蓝色箭头代表粒子的速度向量，黑色点代表每个粒子的最佳位置向量，红色星形标记代表特定迭代时的当前全局最佳位置向量：

![图 5.13 – 一个 PSO 初始群体

![图片 B18753_05_013.jpg]

图 5.13 – 一个 PSO 初始群体

由于群体中的初始粒子是随机初始化的，因此速度向量的方向遍布各处（参见 *图 5.13*）。您可以看到每个粒子的位置和速度向量在每个迭代中是如何更新的，以及全局最佳位置向量，如下所示：

![图 5.14 – PSO 过程

![图片 B18753_05_014.jpg]

图 5.14 – PSO 过程

即使在第一次迭代中，每个粒子的速度向量都指向全局最小值，该最小值位于图的左下角。在每个迭代中，位置和速度向量都会更新并接近全局最小值。在迭代循环结束时，大多数粒子都位于全局最小值位置附近，最终全局最佳位置向量位于 (0.496, 0.290)，适应度分数约为 –0.648。这个估计非常接近目标函数的真实全局最小值！

值得注意的是，每个粒子的速度向量包含两个分量：大小和方向。大小将影响 *图 5.14* 中速度向量的长度。虽然您可能看不到每个粒子速度向量长度之间的差异，但它们彼此是不同的！

重要提示

作为超参数调整方法，在PSO方法中，*粒子*和*群体*分别指从超参数空间和超参数集候选集合中采样的候选超参数集。每个粒子的位置向量指代粒子中每个超参数的值。最后，速度向量指用于更新粒子中每个超参数值的*超参数值变化量*。

以下步骤定义了*PSO作为超参数调整方法的工作原理*：

1.  将原始完整数据集分为训练集和测试集。

1.  使用伴随分布定义超参数空间，*H*。

1.  定义集合大小*N*、惯性权重系数*w*、认知系数*c1*、社会系数*c2*和最大尝试次数。

1.  根据训练集定义目标函数*f*。

1.  初始化一个包含*N*个超参数集的集合，其中每个集是从超参数空间*H*中随机抽取的。

1.  随机初始化集合中每个超参数集的速度向量。

1.  将每个集的当前超参数值设置为它们的最佳值*pbi*。

1.  设置当前全局最佳超参数集，*gb*，通过从所有 *N* 个超参数集中选择一个具有最佳目标函数分数的集。

1.  根据更新公式更新每个集的超参数值和速度向量。

1.  根据目标函数*f*评估集合中所有超参数集。

1.  更新每个集的最佳超参数值*pbi*：

    1.  将第10步中每个集的当前分数与它的*pbi*分数进行比较。

    1.  如果当前分数优于*pbi*分数，则使用当前超参数值更新*pbi*。

1.  更新全局最佳超参数集*gb*：

    1.  将第10步中每个集的当前分数与之前的*gb*分数进行比较。

    1.  如果当前分数优于*gb*分数，则使用当前超参数集更新*gb*。

1.  根据更新公式更新每个集的超参数值和速度向量。

1.  重复*步骤10*到*13*，直到达到最大尝试次数。

1.  使用全局最佳超参数集在完整训练集上进行训练。

1.  在测试集上评估最终训练好的模型。

在PSO方法中的更新公式有一个问题，那就是它只适用于数值变量，尤其是连续变量，这意味着如果我们的超参数空间包含离散超参数，我们就不能直接利用原始PSO作为超参数调整方法。受此问题的启发，有几个PSO的变体被设计出来，以便能够在离散空间中也能工作。第一个变体是为了专门针对二进制变量设计的，被称为**二进制PSO**。在这个变体中，速度向量的更新公式是相同的，这意味着我们仍然将速度向量视为连续空间中的，但位置向量的更新公式被修改了，如下所示：

![](img/Formula_B18753_05_085.png)

这里，![](img/Formula_B18753_05_086.png)是从![](img/Formula_B18753_05_087.png)，![](img/Formula_B18753_05_088.png)区间内均匀分布中抽取的一个随机数，*j*下标指的是第*i*个粒子的每个分量。正如你所见，在二进制PSO变体中，我们可以在离散空间中工作，但我们被限制只能使用二进制变量。

当我们有一个离散和连续数值超参数的组合时怎么办？例如，我们的神经网络模型超参数空间包含学习率、dropout率和层数。由于层数超参数期望的是整数输入，而不是连续或浮点输入，所以我们不能直接利用原始PSO方法。我们也不能利用二进制PSO变体，因为学习率和dropout率是连续的，而层数超参数也不是二进制的。

我们可以做的简单事情之一是*四舍五入更新后的速度向量分量值*，但只针对与离散位置分量相对应的分量，在将其传递给位置向量更新公式之前。这样，我们可以确保我们的离散超参数仍然始终在离散空间内。然而，这个解决方案仍然存在问题。四舍五入操作可能会使速度向量的更新过程次优。为什么？因为速度向量的更新值无论是什么，只要它们仍然在一个整数点的相似范围内，位置向量就不再更新。这将导致大量的冗余计算成本。

有另一种方法可以使PSO在连续和离散空间中都能良好地运行。除了四舍五入更新的速度向量分量值之外，我们还可以动态地更新惯性权重系数。动机是帮助粒子关注其过去的速度值，这样它就不会陷入局部或全局最优，这受到![](img/Formula_B18753_05_089.png)或![](img/Formula_B18753_05_090.png)的影响。动态惯性权重更新过程可以根据多个因素进行，例如其当前位置向量和最佳位置向量之间的相对距离，当前试验次数与最大试验次数之间的差异，等等。

在试验过程中，我们可以有多种方式动态更新惯性权重系数的变体；我们将把它留给你来选择对你特定情况效果最好的方式。

尽管我们可以修改PSO中的更新公式，使其不仅适用于连续变量，也适用于离散变量，但我们仍然面临几个问题，如前所述。因此，为了在连续空间中充分利用PSO的最大功效，还有一种PSO的变体，试图将PSO与贝叶斯优化方法相结合，称为**PSO-BO**。PSO-BO的目标是将PSO作为贝叶斯优化获取函数优化器的替代品（参见[*第4章*](B18753_04_ePub.xhtml#_idTextAnchor036)）。因此，我们不需要使用二阶优化方法来优化获取函数，而可以使用PSO作为优化器来帮助决定在贝叶斯优化超参数调整过程的下一个试验中要测试的超参数集。

以下表格总结了利用PSO作为超参数调整方法的优缺点：

![图5.15 – PSO的优缺点

![图5.15 – PSO的优缺点](img/B18753_05_015.jpg)

图5.15 – PSO的优缺点

现在你已经了解了PSO是什么，它是如何工作的，它的几个变体以及它的优缺点，让我们来讨论另一种有趣的基于群体的启发式搜索方法。

# 理解基于群体的训练

**PBT**是一种基于群体的启发式搜索方法，就像GA方法和PSO一样。然而，PBT不是一个像GA或PSO那样的自然启发算法。相反，它受到GA方法本身的启发。当你在使用基于神经网络类型的模型，并且只需要最终的训练模型而不需要知道具体选择的超参数配置时，建议使用PBT。

PBT 是专门设计来**仅与基于神经网络的模型**一起工作的，例如多层感知器、深度强化学习、转换器、生成对抗网络以及任何其他基于神经网络的模型。可以说，PBT 既能进行超参数调整，也能进行**模型训练**，因为在过程中神经网络模型的权重会被继承。因此，PBT 不仅是为了选择最优化超参数配置，也是为了将模型的权重或参数转移到种群中的其他个体。这就是为什么 PBT 的输出不是一个超参数配置，而是一个模型。

PBT 是**随机搜索**和**顺序搜索**方法的**混合**方法，例如手动搜索和贝叶斯搜索（详见[*第 3 章*](B18753_03_ePub.xhtml#_idTextAnchor031)*，探索穷举搜索*和[*第 4 章*](B18753_04_ePub.xhtml#_idTextAnchor036)*，探索贝叶斯优化*以获取更多详细信息）。随机搜索是寻找对敏感超参数良好子空间的一个非常好的方法。如果我们在执行优化过程时有足够的计算资源和时间，顺序搜索方法往往比随机搜索给出更好的性能。然而，这些方法需要顺序执行的事实使得实验运行时间非常长。PBT 提供了一种解决方案，将两种方法的优点结合成一个**单一的训练优化过程**，这意味着模型训练和超参数调整过程被合并成一个单一的过程。

PBT 中的术语**基于种群**来源于它受到 GA 方法启发，即利用整个种群的知识来产生性能更好的个体。请注意，PBT 中的**个体**部分指的是种群中具有不同参数和超参数的每一个**N 个模型**，或者所有这些 N 个模型的集合。

PBT 的搜索过程首先**初始化一个包含 N 个模型**的种群 P，这些模型具有各自随机采样的参数，![](img/Formula_B18753_05_091.png)，以及随机采样的超参数，![](img/Formula_B18753_05_092.png)，![](img/Formula_B18753_05_093.png)。在搜索过程的每一轮迭代中，都会为 N 个模型中的每一个触发**训练步骤**。训练步骤包括前向和反向传播过程，这些过程使用基于梯度的优化方法，就像基于神经网络的模型通常的训练过程一样。一旦完成训练步骤，下一步就是执行**评估步骤**。评估步骤的目的是评估当前模型在未见过的验证数据上的**Mi**性能。

一旦模型，*Mi*，被认为*准备就绪*，PBT将触发*利用*和*探索*步骤。模型准备就绪的定义可能有所不同，但我们可以将“准备就绪”定义为通过预定义的步骤数或通过预定义的性能阈值。利用和探索步骤的目标相同，即更新模型的参数和超参数。它们之间的区别在于它们如何进行更新过程。

根据整个种群的评估结果，*利用*步骤将决定是否继续使用当前的一组参数和超参数，或者关注更有希望的一组。例如，利用步骤可以通过用从种群顶部X%中随机采样的模型替换整个种群中被认为是底部X%模型的模型来完成。请注意，一个模型由所有参数和超参数组成。另一方面，*探索*步骤通过提出一组新参数来更新模型的超参数集，而不是参数。您可以通过以预定义的概率随机扰动当前的超参数集或从种群顶部X%中重新采样超参数集来提出一组新参数。请注意，此探索步骤仅在利用步骤中选择的模型上执行。

重要提示

PBT中的探索步骤受到随机搜索的启发。此步骤可以通过从利用步骤中选择的部分训练模型来识别需要更多探索的超参数子空间。在搜索过程中进行的评估步骤也使我们能够消除顺序优化过程的缺点。

PBT方法中的利用和探索过程使我们能够以*在线方式*更新模型的一组超参数，同时更加关注有希望的超参数和权重空间。对于种群中的每个*N*个个体，执行train-eval-exploit-explore的迭代过程是*异步并行*的，直到满足停止标准。

以下步骤总结了*PBT作为单个训练优化过程的工作原理*：

1.  将原始完整数据分割成训练、验证和测试集（见[*第1章*](B18753_01_ePub.xhtml#_idTextAnchor014)*，评估机器学习模型*）。

1.  定义超参数空间，*H*，以及伴随的分布。

1.  定义种群大小，*N*，探索扰动因子，*perturb_fact*，探索重采样概率，*resample_prob*，以及利用分数，*frac*。

1.  定义模型的*准备就绪标准*。通常，使用SGD优化步骤的数量。然而，也可以使用模型性能阈值作为标准。

1.  定义用于存储模型权重和超参数的*检查点目录*。

1.  定义评估函数，*f*。

1.  初始化一个包含**N**个模型的人口，**P**，每个模型都有自己随机采样的参数，![](img/Formula_B18753_05_094.png)，以及从超参数空间**H**中随机采样的超参数，![](img/Formula_B18753_05_095.png)，和![](img/Formula_B18753_05_096.png)。

1.  对于人口**P**中的每个模型，**并行**运行以下步骤：

    1.  使用![](img/Formula_B18753_05_097.png)参数和一组超参数![](img/Formula_B18753_05_098.png)对模型**M*i**执行训练过程的单步。

    1.  如果满足**准备标准**，请执行以下操作。如果不满足，请返回**步骤I**：

        +   根据验证集上的**f**值执行**评估**步骤。

        +   根据预定义的利用分数**frac**，对模型**M*i**执行**利用**步骤。这一步骤将产生一组新的参数和超参数。

        +   根据预定义的**扰动因子**和**重采样概率**，在利用步骤的超参数集上执行**探索**步骤。

        +   根据验证集上的**f**值，对新的参数集和超参数集执行**评估**步骤。

        +   **更新**模型**M*i**的新参数集和超参数集。

    1.  重复步骤I和II，直到训练循环结束。通常，它由epoch的数量定义。

1.  返回人口**P**中评估分数最高的模型。

1.  在测试集上评估最终模型。

值得注意的是，在实践中，例如在**NNI**包的实现中（见[*第10章*](B18753_10_ePub.xhtml#_idTextAnchor092)*，使用DEAP和Microsoft NNI进行高级超参数调整），第4步中定义的准备标准是一个epoch。换句话说，第8步中的第二步将在每个训练epoch结束后运行，而不是在epoch的中间。还值得注意的是，第5步中定义的检查点目录是必需的，因为在PBT中，我们需要从人口中的另一个模型复制权重，而其他我们之前学过的超参数调整方法并不需要这样做。

尽管原始的PBT算法声称我们可以异步并行地运行**步骤8**，但在本书中将使用的**NNI**包的实现中并非如此。在NNI包的实现中，过程是**同步**运行的，这意味着一旦人口中的所有个体或模型完成了上一个epoch，我们就可以继续到下一个epoch。

以下表格列出了PBT方法的优缺点：

![图5.16 – PBT的优缺点

![图片](img/B18753_05_016.jpg)

图5.16 – PBT的优缺点

在本节中，你学习了关于PBT所需了解的所有内容，包括它是什么，它是如何工作的，它与其他启发式搜索方法的不同之处，以及它的优缺点。

# 摘要

在本章中，我们讨论了四种超参数调整方法中的第三组，称为启发式搜索组。我们一般讨论了启发式搜索方法是什么，以及包括模拟退火（SA）、遗传算法（GA）方法、粒子群优化（PSO）和参数贝叶斯树（PBT）在内的几种启发式搜索方法的变体。我们看到了这些变体之间的不同之处，以及每种方法的优缺点。此时，当有人询问你时，你应该能够自信地解释启发式搜索。你也应该能够调试并设置所选方法最适合你特定问题定义的最优配置。

在下一章中，我们将开始讨论多保真优化，这是超参数调整方法的最后一组。下一章的目标与这一章类似：为了更好地理解属于多保真优化组的那些方法，以便当有人询问你时，你能自信地解释这些方法。通过这样做，你将能够为你的特定问题配置每种方法！
