- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Starting Our Travel – Surviving the Titanic Disaster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will start our journey around the data world. The first
    dataset we will analyze is from the competition *Titanic - Machine Learning from
    Disaster* (refer *Reference 1* at the end of this chapter for a link to this dataset).
    It is a rather small dataset and, because it is related to a competition, it is
    split between train and test sets.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, besides the competition approach, we will introduce our systematic
    approach to exploratory data analysis and apply it to get familiar with the data,
    understand it in more detail, and extract useful insights. We will also provide
    a short introduction to the process of using the results of data analysis to build
    model training pipelines. Before diving into the actual data, it is useful to
    understand the context, and, ideally, define the possible objectives of the analysis.
  prefs: []
  type: TYPE_NORMAL
- en: All the code snapshots and the figures in this chapter are extracted from the
    accompanying notebook, *Titanic - start of a journey around data world* (refer
    *Reference 2*). The notebook is also available in the `Chapter-03` folder of the
    GitHub repository for the book (see *References 3* and *4*).
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, we will do the following in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Find out the story behind the Titanic dataset. We will learn what happened on
    that fateful day in 1912 when the Titanic sank, and we will find out the size
    of the crew, how many passengers were aboard, and how many fatalities there were.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get familiar with the data, explain the meaning of the features, get a first
    view of the data quality, and explore some statistical information about the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Continue the data exploration with univariate analysis after we introduce the
    graphical elements used through the analysis: a customized color palette and a
    derived color map.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add more insights into the data using multivariate analysis to capture complex
    interactions between the features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform a detailed analysis using the recorded passengers’ names, from which
    we will extract multiple features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explore the richness of features using an aggregated view of feature variation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prepare a baseline model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A closer look at the Titanic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Titanic was a British passenger ship that sank on its first voyage in the
    North Atlantic in April 1912\. The tragic event, caused by striking an iceberg,
    resulted in more than 1,500 fatalities (the estimate by US officials was 1,517
    and by the British investigating committee, it was 1,503) from the 2,224 total
    number of crew and passengers. Most of the casualties were part of the crew, followed
    by third-class passengers.
  prefs: []
  type: TYPE_NORMAL
- en: How was this possible? The Titanic was considered an unsinkable vessel when
    it was built using state-of-the-art technology in the early 20^(th) century. This
    confidence was the recipe for disaster. As we know, it did sink, as the contact
    with the iceberg damaged several water-tight compartments – enough to compromise
    its integrity. The ship was originally designed to carry 48 lifeboats but only
    20 were present on board, and most of those were carrying less than 60% of their
    full capacity when they were lowered into the water.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Titanic was 269 meters in length and had a maximum breadth of 28 meters.
    It had seven decks identified with letters from A to G (A and B were for first-class
    passengers, C was mostly reserved for crew, and D to G were for second- and third-class
    passengers). It also had two additional decks: the boat deck (from where the boats
    were lowered into the water) and the Orlop deck (below the waterline). Although
    third-class and second-class amenities were not as luxurious and comfortable as
    those in first-class, all classes had common leisure facilities, like a library,
    smoking rooms, and even a gymnasium. Passengers could also use open-air or indoor
    promenade areas. The Titanic was advanced in terms of comfort and amenities compared
    to other liners of the era.'
  prefs: []
  type: TYPE_NORMAL
- en: The Titanic started its voyage from Southampton and had two other stops scheduled
    – one in Cherbourg, France, and one in Queenstown, Ireland. The passengers were
    shuttled with special trains from London and Paris to Southampton and Cherbourg,
    respectively. The crew on the Titanic consisted of around 885 people for this
    first trip. The majority of the crew were not sailors but stewards, who took care
    of the passengers, firemen, stockers, and engineers, who were in charge of the
    engines of the ship.
  prefs: []
  type: TYPE_NORMAL
- en: Conducting data inspection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The story of the Titanic is fascinating. For those interested in data exploration,
    the data about the tragedy is also captivating. Let’s start with a short introduction
    to the competition data. The dataset from *Titanic - Machine Learning from Disaster*
    contains three **CSV** (**comma-separated values**) files, as in many Kaggle competitions
    that you will encounter:'
  prefs: []
  type: TYPE_NORMAL
- en: '`train.csv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test.csv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sample_submission.csv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will start by loading these files into a new notebook. You learned how to
    do this in the previous chapter, in the *Basic capabilities* section. You can
    also create a notebook by forking one that already exists. In our case, we will
    start a new notebook from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Usually, notebooks start with a cell in which we import packages. We will do
    the same here. In one of the next cells, we would like to read train and test
    data. In general, the CSV files that you need have similar directories as in this
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: After we load the data, we will manually inspect it, looking at what each column
    contains – that is, samples of data. We will do this for each file in the dataset,
    but mostly, we will focus on the train and test files for now.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In *Figures 3.1* and *3.2*, we get a glimpse of a selection of values. From
    this visual inspection, we can already see some characteristics of the data. Let’s
    try to summarize them. The following columns are common to both train and test
    files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PassengerId`: A unique identifier for each patient.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Pclass`: The class in which each passenger was traveling. We know from our
    background information that possible values are 1, 2, or 3\. This can be considered
    a categorical data type. Because the order of the class conveys meaning and is
    ordered, we can consider it as ordinal or numerical.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Name`: This is a text type of field. It is the full name of the passenger,
    with their family name, first name, and, in some cases, their name before marriage,
    as well as a nickname. It also contains their title regarding social class, background,
    profession, or, in some cases, royalty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Sex`: This is also a categorical field. We can assume that this was important
    information at the time, considering that they prioritized saving women and children
    first.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Age`: This is a numerical field. Also, their age was an important feature
    since children were prioritized for saving.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SibSp`: This field provides the siblings or the spouse of each passenger.
    It is an indicator of the size of the family or group with which the passenger
    was traveling. This is important information since we can safely assume that one
    would not board a lifeboat without their brothers, sisters, or partner.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Parch`: This is the number of parents (for child passengers) or children (for
    parent passengers). Considering that parents would wait for all their children
    before boarding a lifeboat, this is also an important feature. Together with `SibSp`,
    `Parch` can be used to calculate the size of the family for each passenger.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Ticket`: This is a code associated with the ticket. It is an alphanumerical
    field, neither categorical nor numerical.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Fare`: This is a numerical field. From the sample we see, we can observe that
    `Fare` values varied considerably (with one order of magnitude from class 3 to
    class 1) but we can also see that some of the passengers in the same class had
    quite different `Fare` values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Cabin`: This is an alphanumerical field. From the small sample that we see
    in *Figures 3.1* and *3.2*, we can see that some of the values are missing. In
    other cases, there are multiple cabins reserved for the same passenger (presumably
    a well-to-do passenger traveling with their family). The name of a cabin starts
    with a letter (C, D, E, or F). We remember that there are multiple decks on the
    Titanic so we can guess that the letter represents the deck and then that is followed
    by the cabin number on that deck.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Embarked`: This is a categorical field. In the sample here, we only see the
    letters C, S, and Q, and we already know that the Titanic started from Southampton
    and had a stop at Cherbourg, France, and one at Queenstown (today, this is called
    Cobh, the port for Cork, Ireland). We can infer that S stands for Southampton
    (the starting port), C stands for Cherbourg, and Q for Queenstown.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The train file contains a `Survived` field as well, which is the target feature.
    This has either a value of `1` or `0`, where `1` means the passenger survived
    and `0` means they sadly didn’t.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: Sample of the train data file'
  prefs: []
  type: TYPE_NORMAL
- en: 'The test file does not include the target feature, as you can see in the following
    sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2: Sample of the test data file'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have had a look at the columns in the train and test files, we can
    continue with a few additional checks to find the dimensions of the datasets and
    the feature distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: Check the shape of each dataset (`train_df` and `test_df`), using the `shape()`
    function. This will give us the dimension of the train and test files (number
    of rows and columns).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the `info()` function for each dataset. This will give us more complex information,
    such as the amount of non-null data per column, and the type of the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the `describe()` function for each dataset. This only applies to numerical
    data and will create a statistic on the data distribution, including minimum,
    maximum, and first 25%, 50%, and 75% values, as well as the average value and
    standard deviation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The preceding checks give us preliminary information on the data distribution
    for the numerical values in the train and test datasets. We can continue later
    in our analysis with more sophisticated and detailed tools, but for now, you may
    consider these steps a general preliminary approach for investigating any tabular
    dataset that you put your hands on.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By evaluating the shape of the dataset, the types of values, the number of null
    values, and the feature distribution, we will form a preliminary image of the
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We can build our own tools for inspecting data statistics. I will introduce
    here three small scripts to get the missing value stats, the unique values, and
    the most frequent values.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the code to retrieve missing data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, the code to display the most frequent values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, the code for unique values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the next chapter, we will reuse these functions. On Kaggle, you can do this
    by implementing utility scripts. We will include these functions in a reusable
    utility script that will then be included in other notebooks as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, we see the result of applying the `missing_data` function
    to the train (*a*) and test (*b*) datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_03.png)'
  prefs: []
  type: TYPE_IMG
- en: a
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_04.png)'
  prefs: []
  type: TYPE_IMG
- en: b
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.3: Missing values in (a) train and (b) test sets, respectively'
  prefs: []
  type: TYPE_NORMAL
- en: Some of the fields, like `Age` and `Cabin`, show a considerable percentage of
    missing data, both for train and test datasets. From the inspection of the missing
    data percentage, we can also preliminarily evaluate the quality of the data with
    respect to the train-test split. If the percentages of missing values for a certain
    feature are very different in train and test data, we can already suspect that
    the splitting did not capture the overall data distribution. In our case, the
    percentages of missing values have close values for each feature in the train
    and test datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, we can see the most frequent values for the features
    in the train (*a*) and test (*b*) datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_05.png)'
  prefs: []
  type: TYPE_IMG
- en: a
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_06.png)'
  prefs: []
  type: TYPE_IMG
- en: b
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.4: Most frequent values in (a) train and (b) test sets, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: We already can see from the preceding data that most of the people on the Titanic
    were male (and this majority is reflected in both the train and test datasets),
    and most of the passengers and crew embarked in Southampton (`S`). For features
    with more granular values, like `Age`, the most frequent value differs in train
    and test data, although the values with maximum frequency are close (`Age` value
    of `21` in train versus `24` in the test dataset). This hints at the limitations
    of using `Age` directly as a feature in a machine learning model since we can
    already observe that the overall distribution is different between train and test
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the results of applying the `unique_values` function
    to obtain the unique values stats for train and test datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_07.png)'
  prefs: []
  type: TYPE_IMG
- en: a
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_08.png)'
  prefs: []
  type: TYPE_IMG
- en: b
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.5: Unique values in (a) train and (b) test sets, respectively'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, for the categorical type of fields, all categories present in
    the train dataset are also present in the test dataset. Ideally, we would like
    the same results to show for numerical features such as `SibSp` or `Parch`. However,
    in the case of `Parch`, we can see that the number of unique values is `7` in
    train and `8` in test data.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we started with an initial data inspection to understand the
    dataset features, followed by checking the data quality to see whether we had
    missing values. We also conducted a statistical analysis of the features in both
    train and test datasets. Next in our data exploration, we will perform univariate
    analysis on the categorical and numerical features of the train and test datasets.
    The images with plots of various features provide more information and are easier
    to understand and interpret, even for a non-technical reader.
  prefs: []
  type: TYPE_NORMAL
- en: Performing univariate analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before starting to build our first plots, we will set a unique color scheme
    for the notebook. Ensuring color and style unity across the entire notebook helps
    us to maintain the consistency of the presentation and ensures a well-balanced
    experience for the reader. The notebook will have a consistent presentation and
    the visuals will coherently support the notebook narrative.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we will define the set of colors that we will use throughout the
    notebook in our graphics. We will select a palette that will create a visual identity
    specific to our work. This can be one of the already-defined palettes or color
    sets or we can define our own palette, based on a set of colors chosen to match
    the subject. For this sea-faring (or nautical) related notebook, I chose a set
    of marine colors with several shades of blue. Based on this set of colors, I also
    defined a palette. The code for defining and displaying the palette is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following figure, we show the reduced set of colors that compose our
    custom palette. The notebook color scheme uses shades of blue, from a pale clear-sky
    color to a dark ultramarine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart  Description automatically generated](img/B20963_03_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.6: The notebook color scheme'
  prefs: []
  type: TYPE_NORMAL
- en: We will define two plotting functions (one for categorical, and one for continuous/numerical
    values) to represent the distribution of one feature on the same image, grouped
    by survival or grouped by the train/test set.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will concatenate train and test in a single dataset (and add a new column
    storing the original/source dataset). The functions use two of the most common
    libraries for data plotting: `matplotlib` and `seaborn`. As we will plot these
    graphs for multiple features, it is preferable to define a few plotting functions,
    so that we don’t repeat the code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the first function, we display two sets of values using the option `hue`
    of the `countplot` function from `seaborn`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In the second function, to display feature distribution, we call `histplot`
    from `seaborn` twice – once for each feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To see the complete list of images, go to the book repository and check the
    *Titanic - start of a journey around data world* notebook (*Reference 3*). Alternatively,
    you can access the same content on Kaggle, by following this path: [https://www.kaggle.com/code/gpreda/titanic-start-of-a-journey-around-data-world](https://www.kaggle.com/code/gpreda/titanic-start-of-a-journey-around-data-world)
    (*Reference 2*).'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we only show a small selection of images, for only two features – one
    for a categorical value and one for a numerical value. In the notebook, we represent
    the graphs for `Sex`, `Pclass`, `SibSp`, `Parch`, and `Embark`, as well as `Age`
    and `Fare`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will represent each of these features in two graphs: one shows the distribution
    of the feature for all passengers, grouped by train/test. The other shows, for
    the same feature, the distribution only for train data, and the split between
    `Survived`/`Not Survived`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with `Pclass` (which is a categorical feature), showing the distribution
    of the feature for all passengers, grouped by train/test datasets. Notice in the
    following screenshot, there are three classes, `1`, `2`, and `3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.7: Number of passengers per passenger class, grouped by train and
    test'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the same `Pclass` feature, but only from the train set, we represent the
    data grouped by `Survived`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.8: Number of passengers per passenger class in the train set, grouped
    by Survived'
  prefs: []
  type: TYPE_NORMAL
- en: We follow with `Age` (which is a numerical value). In *Figure 3.9*, we show
    the histogram of `Age` in all the data (train and test), grouped by train/test.
    We are using a histogram here because this feature, although not a continuous
    number (is still discrete), has many values (from the stats we ran, it appears
    that there are at least 88 unique `Age` values), and is, from the point of view
    of our analysis, just like a continuous number.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9: Number of passengers per Age, grouped by train and test'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.10* shows the histogram of `Age` in the train set, grouped by survival
    status.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.10: Number of passengers per Age in the train set, grouped by survival
    status'
  prefs: []
  type: TYPE_NORMAL
- en: By simple inspection of these univariate distributions for either categorical
    or continuous (numerical) data, we can already understand some interesting facts
    from the data. For example, in *Figures 3.7* and *3.8*, we can see that the ratio
    between data in the train and test sets is quite similar with respect to the distribution
    in the three classes (`1`, `2`, and `3`). At the same time, from the Survived/Not
    Survived distribution, we can see that while around 60% of first-class passengers
    survived, the split of Survived/Not Survived in second class was around 50-50%,
    while in third class, only around 25% of the passengers survived. Similarly, we
    can extract useful insights from the univariate distributions of `Sex`, `SibSp`
    (siblings or spouses), or `Parch` (number of parents or children).
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, we would like to build new features from existing features –
    in other words, perform feature engineering. Feature engineering involves the
    extraction and transformation of useful information from raw data. One technique
    for feature engineering is to define a new feature as a function of other features.
    We saw that `Parch` and `SibSp` together give information about families that
    were present on the Titanic. By summing up `Parch` and `SibSp` and adding `1`
    (for the actual passenger), for each passenger, we get the size of their family
    onboard the Titanic.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 3.11*, we can see the graph for family size, from all passengers,
    grouped by train/test datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.11: Number of passengers per family size, grouped by train and test'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next figure, we see the graph for train data, for the same family size,
    grouped by Survived/Not Survived:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.12: Number of passengers per family size, grouped by survival status'
  prefs: []
  type: TYPE_NORMAL
- en: We can observe that prevalent is the number of single passengers (and the large
    number also highlights the high frequency of this type of passenger in third class).
    This number is then followed by families without children and single parents,
    followed by small and large families of up to 8 and even 11 members. As you can
    see, this pattern came from data analysis using an exploratory approach before
    modeling.
  prefs: []
  type: TYPE_NORMAL
- en: If we look then at the survival rate, we can see that single passengers had
    a small survival rate (around 30%) while small families (with 2, 3, or 4 members)
    had a survival rate above 50%. As the size of the family became larger than 4,
    we can see that the survival rate decreased severely, with families with 8 or
    11 members having a zero survival rate.
  prefs: []
  type: TYPE_NORMAL
- en: This might be because they were traveling in cheaper classes (we know that survival
    in third class was inferior to survival in first class) or because they spent
    too much time trying to gather all their family members before heading to the
    lifeboats. We will investigate these details a bit later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We can observe that `Age` and `Fare` are distributed values. While it is useful
    to know the exact age of a certain passenger, there is not much value when we
    build a model to include the exact age. Actually, by learning a large variety
    of ages, the model risks overfitting the training data, and its generalization
    will degrade. For analysis and modeling purposes, it makes sense to aggregate
    the age (or fare) in value intervals.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code block calculates a new feature called `Fare Interval`, where
    the values from `0` to `3` (four classes) are obtained from values of `Fare` between
    `0` and `7.91`, `7.91` and `14.454`, `14.454` and `31`, and above `31`, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The feature transformations for `Age` and `Fare` described above have the effect
    of regularization. In the following graph, we show the `Age` Intervals for all
    passengers, separated by train and test:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.13: Number of passengers per Age intervals, grouped by train and test'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the distribution of `Age` intervals for Survived
    versus Not Survived passengers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.14: Number of passengers per Age intervals, grouped by Survived status'
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have analyzed individual features. We merged train and test and represented,
    on the same graph, the data split between train and test. We also showed the train
    data only for one feature, split between Survived and Not Survived, and we visualized
    a few engineered features. In the next section, we will follow by representing
    multiple features on the same graph using multivariate analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Performing multivariate analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We saw how, by using graphs for the distribution of each feature, we can get
    very interesting insights into the data. Then, we experimented with feature engineering
    to get useful, more relevant features. While observing variables separately can
    help us get an initial image of the data distribution, grouping values and looking
    at more than one feature at a time can reveal correlations and more insights into
    how different features interact.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will use various graphics to explore correlations of features while
    we also explore the visualization options. We will continue for now with our initial
    option of using a combination of the `matplotlib` and `seaborn` graphical libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.15* shows the number of passengers per Age Interval, grouped by passenger
    class. We can see from this image that in third class, the majority of passengers
    were in the first and second Age interval (that is, between 0–16 and 16–32 years
    old), while in first class, we have the most well-balanced age groups. The most
    balanced age interval between the three classes is the third age interval.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.15: Number of passengers per Age Interval, grouped by class'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the next graph in *Figure 3.16*, most passengers embarked at
    Southampton (identified by the initial **S**). Also, most of these passengers
    were of a young age, under 32 (age intervals **0** and **1**). For people embarking
    in Cherbourg (identified by the initial **C**), the age groups are more balanced.
    The passengers who embarked in Queensland (identified by the initial **Q**) were
    mostly in the first age group.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.16: Number of passengers per Age Interval, grouped by embarked port'
  prefs: []
  type: TYPE_NORMAL
- en: From the following figure, we can see that with increased family size and lower
    passenger class, the likelihood of surviving decreased. The worst survival rate
    was for large families in third class, where almost no one survived. Even for
    small families, being in third class drastically reduced their likelihood of survival.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.17: Distribution of family size and passenger class (Pclass), grouped
    by Survived status'
  prefs: []
  type: TYPE_NORMAL
- en: We can also create composed features – for example, we can merge `Sex` and `Pclass`,
    two of the most predictive factors, into one single feature; let’s call it `Sex_Pclass`.
    The following figure shows the distribution of this new feature when we split
    the values based on survival status. Females in first and second class had a survival
    rate above 90%. In third class, females had around a 50% survival rate. Males
    in first and second class had survival rates of around 30% and 20%, respectively.
    Most of the males in third class died.
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, bar chart  Description automatically generated](img/B20963_03_21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.18: Distribution composed feature Sex_Pclass, grouped by Survived
    status'
  prefs: []
  type: TYPE_NORMAL
- en: After the data quality assessment, we demonstrated how to perform univariate
    analysis. Then, we gave a few examples of feature engineering for numerical data,
    and performed multivariate analysis. Next, we will explore the richness of information
    we can find in the passengers’ names. Let’s see *what is in a name*.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting meaningful information from passenger names
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We continue now with our analysis, including analyzing the passengers’ names
    to extract meaningful information. As you will remember from the beginning of
    this chapter, the `Name` column also contains some additional information. After
    our preliminary visual analysis, it became apparent that all names follow a similar
    structure. They begin with a `Family Name`, followed by a comma, then a `Title`
    (short version, followed by a period), then a `Given Name`, and, in cases where
    a new name was acquired through marriage, the previous or `Maiden Name`. Let’s
    process the data to extract this information. The code to extract this information
    will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you might’ve noticed, we opted to use the `split` function to implement the
    extraction of `Family Name`, `Title`, `Given Name`, and `Maiden Name`. We can
    also use a more compact implementation, with regex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s inspect the results, by looking first at the distribution of `Title`
    and `Sex` in parallel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.19: Distribution of Title by Sex'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that most of the titles are gender-specific, with the most frequent
    being `Miss` (with a `Mlle.` version) and `Mrs.` (with `Mme.` and `Dona.` versions)
    for females, and `Mr.` (and `Ms.` or `Don.` versions) and `Master` for males.
    Some titles are rare, like military (`Capt.`, `Col.`, `Major`, and `Jonkheer`),
    occupational (`Dr.` and `Rev.`), or nobility (`Sir`, `Lady`, and `Countess`).
    `Dr.` is the only title that is used by both genders, and we will take a closer
    look at it a bit later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look now at the distribution of `Title` by `Age Interval`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.20: Distribution of Title by Age Interval'
  prefs: []
  type: TYPE_NORMAL
- en: From this new view, we can see that some of the titles are reserved for certain
    age intervals, while others are distributed across all age intervals. `Master`
    appears to be used only for males under 18 years of age, but `Mr.` is also used
    for this age interval. From what we have seen, the `Master` title was only used
    for male children traveling with their families, whereas males of a young age
    with the title `Mr.` were traveling alone and, because independent already, were
    considered young adults. The title `Miss` doesn’t respect the same pattern, since
    it is attributed equally to female children, young, or unmarried women (but less
    frequently for advanced ages). It is interesting to see that `Dr.` is a title
    well distributed in a wide range of ages.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look now at a few of the large families from third class. If we sort the
    data by `Family Name`, `Family Size`, `Ticket` (to keep together those who traveled
    with the same ticket), and `Age`, we will obtain sequences of passengers from
    the same real family. The `Family Name` values with the highest occurrence are
    Andersson (11 entries), Sage (11 entries), Goodwin (8 entries), Asplund (8 entries)
    and Davies (7 entries). We don’t yet know whether they are also from the same
    family or just share the same family name. Let’s look at the data for the passengers
    who share the Andersson family name.
  prefs: []
  type: TYPE_NORMAL
- en: From *Figure 3.21*, we see that there is one family called Andersson with a
    father called Anders Johan and a mother called Alfrida Konstantia, accompanied
    by their five children (four daughters and one son) with ages between 2 and 11
    years. The married women in the family are registered with their title followed
    by their husband’s name, and their maiden name added within brackets. No one from
    this family traveling in third class survived.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated](img/B20963_03_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.21: Passengers sharing the Andersson family name'
  prefs: []
  type: TYPE_NORMAL
- en: Only those who traveled on the same ticket were part of the same family. This
    means that only those traveling with ticket number 347082 were part of the Andersson
    family, while the others were traveling separately. The data seems to not be very
    accurate in their cases since some of them appear to be part of a larger family
    but we cannot find their relatives.
  prefs: []
  type: TYPE_NORMAL
- en: The next largest family is Sage, as we can see from *Figure 3.22*. This was
    an 11-member family (two parents and nine children). We do not know their ages
    (apart from one of the boys’ who was 14.5 years old); we just know their names
    and the fact that there were five boys and four girls. We suppose that three of
    the boys were grown-up since their titles were `Mr.`. We only know that 9 out
    of the 11 did not survive (the other family members, for which **Survived** has
    no assigned value, are part of the test set).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.22: Passengers sharing the Sage family name'
  prefs: []
  type: TYPE_NORMAL
- en: 'The stories of these families who were looking for a better life in the New
    World are moving, especially when we realize that, sadly, these large families
    with lots of children didn’t manage to save themselves. We don’t know what the
    decisive factor was: they might have waited too long until they headed for the
    boat deck, hoping to reunite, or maybe they were struggling to keep together on
    their way to the lifeboats. Either way, adding the family size information into
    the model might give us a useful feature to predict survival, since we can see
    that people in larger families had a lower chance of survival.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also other interesting analyses we can make, with fewer predictive
    values for survival, but which can give us some more insights into the data distribution.
    The following figure shows the `Given Name` distribution (grouped by sex) for
    the overall data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.23: Passengers’ given names (girls/unmarried women and boys/men)'
  prefs: []
  type: TYPE_NORMAL
- en: The following figure shows the Family Name distribution overall and according
    to embarking port. We saw that most passengers embarked in Southampton (identified
    with **S**); therefore, the distribution of embarked passengers’ names in this
    port will dominate the overall case. The other two embarking ports were Cherbourg,
    France (identified with **C**) and Queenstown, Ireland (identified with **Q**).
    We can observe the prevalence of ethnic names in various embarkment ports, with
    Scandinavian in Southampton; French, Italian, Greek, and North African in Cherbourg;
    and Irish and Scottish in Queenstown.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.24: Family names grouped by embarking port'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 3.25*, we see the two passengers sharing cabin **D17**. One of them
    had the title `Dr.` and was also a female. She was traveling with another female
    companion, Mrs. Swift, in first class. Both of them survived.
  prefs: []
  type: TYPE_NORMAL
- en: We created an engineered feature, `Title`, because Dr. Leader was both a `Mrs.`
    (we know she was married because her maiden name is also mentioned) and a `Dr.`;
    we had to choose which title to assign to her. `Dr.` was a title associated mostly
    with males (with lower survival likelihood) at that time. As a female, she would
    have had a higher survival probability. While that is matter of debate, of course,
    I mention it here just to give you a better image of the depth we can get while
    engineering the candidate features for a predictive model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_03_28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.25: Passengers sharing cabin D17 – one of them was a female and had
    the Dr. title'
  prefs: []
  type: TYPE_NORMAL
- en: 'After introducing univariate and multivariate analysis and a few types of feature
    engineering, including the processing of names to extract titles, we also performed
    some detailed analysis of large families and some rare cases: very large families
    and passengers with unusual titles. In the next section, we will create a dashboard
    figure with multiple plots, each with univariate or bivariate analysis. We can
    use such complex figures to better capture the complex feature interactions, without
    loading one graph with too many features.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a dashboard showing multiple plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have explored categorical and numerical data, as well as text data. We have
    learned how to extract various features from text data, and we built aggregated
    features from some of the numerical ones. Let’s now build two more features by
    grouping **Title** and **Family Size**. We will create two new features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Titles**: By clustering together similar titles (like `Miss` with `Mlle.`,
    or `Mrs.` and `Mme.`) or rare (like `Dona.`, `Don.`, `Capt.`, `Jonkheer`, `Rev.`,
    and `Countess`) and keeping the most frequent ones – `Mr.`, `Mrs.`, `Master`,
    and `Miss`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Family Type**: By creating three clusters from the **Family Size** values
    – **Single** for a family size of 1, **Small** for families made of up to 4 members,
    and **Large** for families with more than 4 members'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, we will represent, on a single graph, several simple or derived features
    that we learned have an important predictive value. We show the passengers’ survival
    rates for `Sex`, Passenger Class (`Pclass`), `Age Interval`, `Fare Interval`,
    `Family Type`, and `Title` (clustered). The graphs also show the percentage that
    the subset (given by both the category and survived status) represents from all
    passengers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, bar chart  Description automatically generated](img/B20963_03_29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.26: Passenger survival rates for different features (original or derived)'
  prefs: []
  type: TYPE_NORMAL
- en: With that, we have performed a step-by-step exploratory data analysis of the
    *Titanic - Machine Learning from Disaster* competition dataset. Now, with the
    knowledge we gathered about data distribution, the relationship between features,
    and the correlation between various features and the target feature (the `Survived`
    field), we will create a baseline model.
  prefs: []
  type: TYPE_NORMAL
- en: Building a baseline model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a result of our data analysis, we were able to identify some of the features
    with predictive value. We can now build a model by using this knowledge to select
    relevant features. We will start with a model that will use just two out of the
    many features we investigated. This is called a baseline model and it is used
    as a starting point for the incremental refinement of the solution.
  prefs: []
  type: TYPE_NORMAL
- en: For the baseline model, we chose a `RandomForestClassifier` model. The model
    is simple to use, gives good results with the default parameters, and can be interpreted
    easily, using feature importance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin with the following code block to implement the model. First, we
    import a few libraries that are needed to prepare the model. Then, we convert
    the categorical data to numerical. We need to do this since the model we chose
    deals with numbers only. The operation of converting the categorical feature values
    to numbers is called label encoding. Then, we split the train dataset into train
    and validation subsets, using an 80-20% split. The model is then fitted using
    the train subset and we use the validation subset to evaluate the trained (fitted)
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In *Figure 3.27*, we show the `precision`, `recall`, and `f1-score` for the
    validation set (values obtained using the `classification_report` function from
    the `sklearn.metrics` module).
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated](img/B20963_03_30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.27: Classification report for the validation data for the baseline
    model trained with Sex and Pclass features'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding results obtained with this baseline model are still poor. We will
    have to refine the model using the techniques for model refinement, starting with
    the observations on training and validation errors. Based on these observations,
    we might want to improve the training first before focusing on improving model
    generalization. We might, therefore, opt for adding more features (with predictive
    values), either by selecting from existing features or creating new features via
    feature engineering, performing hyperparameter optimization, choosing a better
    classification algorithm, or combining different algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started our journey around the data world on board the Titanic.
    We started with a preliminary statistical analysis of each feature and then continued
    with univariate analysis and feature engineering to create derived or aggregated
    features. We extracted multiple features from text, and we also created complex
    graphs to visualize multiple features at the same time and reveal their predictive
    value. We then learned how to assign a uniform visual identity for our analysis
    by using a custom color map across the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: For some of the features – most notably, those derived from names – we performed
    a deep-dive exploration to learn about the fate of large families on the Titanic
    and about name distribution according to the embarking port. Some of the analysis
    and visualization tools are easily reusable and, in the next chapter, we will
    see how to extract them to be used as utility scripts in other notebooks as well.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will perform a detailed exploratory data analysis on
    two datasets with geospatial data. For each of the datasets, we will start with
    a data quality assessment, and then continue with data exploration, introducing
    analysis methods, tools, and libraries specific for geographical data analysis.
    We will learn how to manipulate polygon data, and how to merge, fusion, and clip
    sets of geographical data stored as collections of polygons. We will also introduce
    various libraries for the visualization of geospatial data. After performing the
    individual analyses on both datasets, we will combine the information from the
    two datasets to build advanced maps with several layers of information from the
    two datasets.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Titanic - Machine Learning from Disaster, Kaggle competition: [https://www.kaggle.com/competitions/titanic](https://www.kaggle.com/competitions/titanic)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Gabriel Preda, Titanic – start of a journey around data world, Kaggle notebook:
    [https://www.kaggle.com/code/gpreda/titanic-start-of-a-journey-around-data-world](https://www.kaggle.com/code/gpreda/titanic-start-of-a-journey-around-data-world)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Developing-Kaggle-Notebooks, Packt Publishing GitHub repository: [https://github.com/PacktPublishing/Developing-Kaggle-Notebooks/](https://github.com/PacktPublishing/Developing-Kaggle-Notebooks/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Developing-Kaggle-Notebooks, Packt Publishing GitHub repository, Chapter 3:
    [https://github.com/PacktPublishing/Developing-Kaggle-Notebooks/tree/main/Chapter-03](https://github.com/PacktPublishing/Developing-Kaggle-Notebooks/tree/main/Chapter-03)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/kaggle](https://packt.link/kaggle)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code9220780366773140.png)'
  prefs: []
  type: TYPE_IMG
