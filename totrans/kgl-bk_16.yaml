- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating Your Portfolio of Projects and Ideas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Participation on Kaggle has its benefits: scoring well in the four areas and
    consequently ranking high in the esteem of other Kagglers certainly brings satisfaction
    and a sense of accomplishment. However, your experience on Kaggle also has an
    impact beyond Kaggle and can help advance your career. It is not just the experience
    you gain from participating in competitions, experimenting on data you have never
    worked on before, or repeating experiments with new techniques; it is also the
    connections you create with other data scientists and the attention you may get
    from companies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although Kaggle is not fully recognized as a qualification by many companies,
    the work you do in competitions can demonstrate a lot about your capabilities
    and help you to stand out from the crowd. In this chapter, we will explore ways
    you can stand out by showcasing your work on Kaggle itself and other sites in
    an appropriate way. We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Building your portfolio with Kaggle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arranging your online presence beyond Kaggle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring competition updates and newsletters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we will conclude the book by exploring how Kaggle can directly
    affect your career by enhancing your professional network and providing you with
    career opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: Building your portfolio with Kaggle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kaggle’s claim to be the “*home of data science*” has to be taken into perspective.
    As we have discussed at length, Kaggle is open to everyone willing to compete
    to figure out the best models in predictive tasks according to a given evaluation
    metric.
  prefs: []
  type: TYPE_NORMAL
- en: There are no restrictions based on where you are in the world, your education,
    or your proficiency in predictive modeling. Sometimes there are also competitions
    that are not predictive in nature, for instance, reinforcement learning competitions,
    algorithmic challenges, and analytical contests that accommodate a larger audience
    than just data scientists. However, making the best predictions from data according
    to a metric is the core purpose of Kaggle competitions.
  prefs: []
  type: TYPE_NORMAL
- en: Real-world data science, instead, has many facets. First, your priority is to
    solve problems, and the metric for scoring your model is simply a more or less
    exact measurement of how well it solves the problem. You may not only be dealing
    with a single metric but have to take into account multiple ones. In addition,
    problems are open to being solved in different ways and much depends on how you
    formulate them.
  prefs: []
  type: TYPE_NORMAL
- en: 'As for data, you seldom get specifications about the data you have to use,
    and you can modify any existing dataset to fit your needs. Sometimes you can even
    create your own dataset from scratch if you need to. There are no indications
    about how to put data together or process it. When solving a problem, you also
    have to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: Technical debt
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintainability of the solution over time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time and computational costs for running the solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explainability of the workings of the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Impact on the operating income (if the real-world project is a business one,
    increasing profits and/or reducing costs is the leitmotif)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communication of the results at different levels of complexity and abstraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often, all these aspects count more than raw performance against evaluation
    metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '**Technical debt** is a term more common in software development than data
    science, though it is a relevant one. For technical debt, you should consider
    whatever you have to do in order to deliver your project faster but that you will
    have to redo again later at a higher cost. The classic paper *Hidden Technical
    Debt in Machine Learning Systems* by *David Sculley* and other Google researchers
    should enlighten you on the relevance of the problem for data science: [https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf](https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Not all this expertise can be supplemented by Kaggle competitions. Most of this
    should be gained by direct practice and experience-building in an enterprise environment.
    Yet, the knowledge and skills attached to Kaggle competitions are not completely
    separate from many of the considerations we discussed above, and they are a good
    complement to many of the enterprise-level data science processes. By competing
    on Kaggle, you are being exposed to different types of data and problems; you
    need to execute extensive feature engineering and fast iterations of model hypotheses;
    you also have to devise methods of putting together state-of-the-art solutions
    using common open-source packages. This is a set of valuable skills, and it should
    be promoted on your side. The best way to do so is to build a **portfolio**, a
    collection of your solutions and work based on Kaggle competitions and other resources
    from Kaggle.
  prefs: []
  type: TYPE_NORMAL
- en: In order to build a portfolio from Kaggle competitions, you can take multiple
    approaches. The easiest is to leverage the facilities offered by Kaggle, especially
    the Datasets, Notebooks, and Discussions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Gilberto_Titericz.png)'
  prefs: []
  type: TYPE_IMG
- en: Gilberto Titericz
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/titericz](https://www.kaggle.com/titericz)'
  prefs: []
  type: TYPE_NORMAL
- en: Before we proceed, we present a discussion on career opportunities derived from
    Kaggle in our interview with *Gilberto Titericz*. He is a Grandmaster in Competitions
    and Discussions, the former number 1 in rankings, and the current number 1 in
    total gold medals from Kaggle competitions. He is also a Senior Data Scientist
    at NVIDIA and was featured not long ago in an article on Wired on the topic ([https://www.wired.com/story/solve-these-tough-data-problems-and-watch-job-offers-roll-in/](https://www.wired.com/story/solve-these-tough-data-problems-and-watch-job-offers-roll-in/)).
  prefs: []
  type: TYPE_NORMAL
- en: What’s your favourite kind of competition and why? In terms of techniques and
    solving approaches, what is your specialty on Kaggle?
  prefs: []
  type: TYPE_NORMAL
- en: '*Since I started to compete on Kaggle in 2011, the types of competitions that
    I prefer are the ones with structured tabular data. The techniques that I use
    more in Kaggle are target encoding of categorical features (there are infinite
    ways to do it wrong) and stacking ensembles.*'
  prefs: []
  type: TYPE_NORMAL
- en: How do you approach a Kaggle competition? How different is this approach to
    what you do in your day-to-day work?
  prefs: []
  type: TYPE_NORMAL
- en: '*Kaggle is a great playground for machine learning. The main difference from
    real-life projects is that in Kaggle we already have the problem very well defined
    and formatted, the dataset created, the target variable built, and the metric
    chosen. So, I always start a Kaggle competition playing with EDA**.* *Understanding
    the problem and knowing the dataset is one of the keys to an advantage over other
    players. After that, I spend some time defining a proper validation strategy.
    This is very important to validate your model correctly and in line with the way
    that Kaggle scores the private test set. Besides the fact that using a stratified
    Kfold is something that works for most binary classification problems, we must
    evaluate if a grouped Kfold or a time-based split must be used in order to* *validate
    correctly, avoid overfitting, and mimic, as much as possible, the private test
    set. After that, it is important to spend some time running experiments on feature
    engineering and hyperparameter optimization. Also, I always end a competition
    with at least one Gradient Boosted Tree model and one deep learning-based approach.
    A blend of such diverse approaches is very important to increase diversity in
    the predictions and boost the competition metric.*'
  prefs: []
  type: TYPE_NORMAL
- en: Has Kaggle helped you in your career? If so, how?
  prefs: []
  type: TYPE_NORMAL
- en: '*Yes, Kaggle was the main reason I changed the direction of my career. Up to
    2016 I worked as an electronic engineer, and due to everything that I learned
    competing since 2011 I was able to switch to the data science area. Kaggle helped
    me to understand the concepts of machine learning and apply everything I learned
    from the theory. In addition, Kaggle is an excellent place for experimentation,
    where you can download a dataset and play with it to extract the maximum information
    possible from the data. That, combined with the competition environment, makes
    it perfect to learn coding and machine learning, and at the same time, it gets
    addictive and makes you want to learn more and more. Winning a few competitions
    puts your name at the top of the leaderboard and this is priceless for anyone’s
    career. Headhunters all around the world look at Kaggle to find good matches for
    their positions and the knowledge and experience gained from competitions can
    boost any career.*'
  prefs: []
  type: TYPE_NORMAL
- en: How have you built up your portfolio thanks to Kaggle?
  prefs: []
  type: TYPE_NORMAL
- en: '*Once I joined Kaggle, I spent some years learning all the techniques, algorithms,
    and tricks to extract more information from data and boost the metrics as much
    as possible. High accuracy is the main goal of most of the competitions, but to
    do that relying on luck alone is almost impossible; knowledge and experience play
    a big role when the goal is to win or at least finish in the gold medal zone.
    The number of medals I have in Kaggle competitions is my portfolio; up to now
    (11/2021) it’s 58 gold and 47 silver, which summarizes well the ML experience
    I got from Kaggle. Taking into account that each competition runs for at least
    1 month, this is more than 105 consecutive months of experience doing competitive
    ML.*'
  prefs: []
  type: TYPE_NORMAL
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  prefs: []
  type: TYPE_NORMAL
- en: '*Novices often* *overlook a proper validation strategy. That doesn’t just happen
    in Kaggle; I’ve seen data scientists all around the world building models and
    neglecting one of the most important things in the experimentation theory. There
    is no general rule when setting a proper validation strategy, but the data scientist
    must take into account how the model is going to be used in the future, and make
    the validation as close as possible to that.*'
  prefs: []
  type: TYPE_NORMAL
- en: What mistakes have you made in competitions in the past?
  prefs: []
  type: TYPE_NORMAL
- en: '*Several mistakes; it is impossible to list them all. I have probably made
    all the possible combinations of mistakes. The good thing about mistakes is that
    you can learn from them. Once you make a mistake and you detect it, it is very
    likely that you won’t make it again. The main mistake people make in Kaggle is
    to trust in the leaderboard score and not in their local validation score. Overfitting
    to the leaderboard is a constant in Kaggle and this is the main difference from
    the real world. In a real project, we must build a strong validation strategy
    that we can trust, because in the real world the models will be tested on real
    data and you have only one chance to hit the mark, not multiple submissions per
    day.*'
  prefs: []
  type: TYPE_NORMAL
- en: Are there any particular tools or libraries that you would recommend using for
    data analysis and machine learning?
  prefs: []
  type: TYPE_NORMAL
- en: '*Some years ago I would have recommended R, but taking into account how fast
    Python is growing in the ML space and how generic and easy it is to use in production,
    I recommend to anyone starting ML that they learn it. In terms of libraries for
    tabular data, I recommend pandas for manipulation, and if you want speed then
    go with cuDF (the RAPIDS.ai GPU version of pandas). For EDA, I recommend using
    DataFrame with the Seaborn or Matplotlib libraries, and for machine learning Scikit-learn,
    SciPy, cuML (GPU), XGBoost, LightGBM, CatBoost, and PyTorch. Keep in mind that
    building a simple XGBoost model using the raw features is fast and can give you
    a good benchmark to compare with further models.*'
  prefs: []
  type: TYPE_NORMAL
- en: What’s the most important thing someone should keep in mind or do when they’re
    entering a competition?
  prefs: []
  type: TYPE_NORMAL
- en: '*Entering a Kaggle competition and submitting a public Notebook is easy, but
    finishing a competition in the gold zone can be extremely challenging. So the
    most important thing, at least for me, is to keep in mind that independent of
    the final ranking, we should use Kaggle to have fun and learn as much as possible
    from the discussion forums, from the public Notebooks, and even from the post-deadline
    winners’ posts describing their ideas and what worked.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Also keep in mind that what makes a competition winner is not just replicating
    what everyone else is doing, but thinking out of the box and coming up with novel
    ideas, strategies, architectures, and approaches.*'
  prefs: []
  type: TYPE_NORMAL
- en: Do you use other competition platforms? How do they compare to Kaggle?
  prefs: []
  type: TYPE_NORMAL
- en: '*I have won a couple* *of competitions on other competition platforms, but
    the main difference compared to Kaggle is the number of users. Kaggle has 171k
    active users as of November 2021, which makes the forums, Notebooks, and dataset
    interactions much richer in terms of content. Also, Kaggle offers something unique:
    Notebooks where you can write and run code for free using Google servers, which
    can be priceless if you don’t have access to good hardware.*'
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging Notebooks and discussions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Besides rankings themselves, Notebooks are the way to get you noticed on Kaggle
    because they simultaneously demonstrate how you solve problems, how you present
    ideas, and how you code them. Conceived as a way to easily and openly share solutions
    and ideas among participants, Notebooks are the most important tool (after rankings)
    for demonstrating abilities that are appreciated by employers.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, one of the most important changes in the world of data science in recent
    years has been its transition from a game of outstanding talents (unicorn data
    scientists) to a team game, where data scientists have to collaborate with each
    other and with other departments to ensure the success of a project. Consequently,
    in their hiring processes, companies often care more about you being able to communicate
    ideas and results, as well as coding in a clean and effective way.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous section, we discussed how real-world projects require a wider
    range of skills, ranging from dealing with technical debt to designing cost-effective
    solutions. You can still demonstrate these skills on Kaggle, even if they are
    not the ones that will make you win a competition. Notebooks are the best tools
    for doing this.
  prefs: []
  type: TYPE_NORMAL
- en: Refer to *Chapter 3*, *Working and Learning with Kaggle Notebooks*, for an introduction
    to Kaggle Notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will find different types of Notebooks on Kaggle. As a good approximation,
    we can group them into four categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Solutions and ideas for ranking in a competition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exploratory data analysis** (**EDA**) on the data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tutorials explaining machine learning models or data science principles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fresh implementations of models derived from papers or other original solutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each of these can provide you with an edge by means of an interesting set of
    skills. If solutions and ideas for competitions are the classic way to demonstrate
    that you know how to tackle a complex problem in data science, the other three
    can show the world that you can:'
  prefs: []
  type: TYPE_NORMAL
- en: Manipulate, represent, and extract visual and non-visual insights from data
    (EDA), which is a skill deemed very important in every setting, from scientific
    research to business
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Educate on data science, opening the door to roles in education, mentorship,
    and developer advocacy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translate research into practice, a key skill at a time when innovations in
    data science (especially in deep learning) appear daily and need to be translated
    into working solutions quickly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even if you don’t rank highly in Kaggle competitions or have astonishing solutions
    to present, these other three kinds of Notebooks (EDA, tutorials, and paper implementations)
    can provide you opportunities in the real world if you can promote them in the
    best way. To do so, you need to understand how to code readable and interesting
    Notebooks, which is something that you learn from practice and experience. Since
    it is an art, our suggestion is to learn from others, especially from the Notebooks
    Grandmasters who place high in the Notebooks user ranking ([https://www.kaggle.com/rankings?group=notebooks&page=1&pageSize=20](https://www.kaggle.com/rankings?group=notebooks&page=1&pageSize=20)).
  prefs: []
  type: TYPE_NORMAL
- en: We recommend you look at what kind of Notebooks they have developed, how they
    have arranged their work using figures, how they have structured their code, and
    then, finally, based on your skills and interests, try to imitate one of their
    Notebooks. We also suggest that you do not bet your chances for success only on
    code and charts, but also on the **narrative** that you present. No matter whether
    you are showing off a solution, teaching, or implementing a neural architecture
    in TensorFlow, how you explain the Notebook’s cells with words is very important
    in terms of leaving a lasting positive impression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside from browsing the Notebooks of high rankers, there is also a way to be
    notified about less mainstream – yet still finely crafted – Notebooks that have
    recently appeared on Kaggle. The astrophysicist and passionate Kaggle user Heads
    or Tails, *Martin Henze* ([https://www.kaggle.com/headsortails](https://www.kaggle.com/headsortails)),
    publishes on the discussion forums a weekly *Notebooks of the Week: Hidden Gems*
    post, a collection of the most interesting Notebooks around. At the moment, there
    are already over 100 volumes and the author continues to search Kaggle for anything
    that could prove interesting. If you would like to be updated about cool Notebooks,
    just follow Martin Henze’s profile on Kaggle or check if he has published something
    new under his discussions from time to time.'
  prefs: []
  type: TYPE_NORMAL
- en: If you love digging through Notebooks looking for ideas and learning from them,
    we never tire of stressing that you should not brainlessly copy other people’s
    work. There are many Notebooks on Kaggle, and often someone copies one, makes
    some small changes, and re-presents the Notebook to other Kagglers as if it were
    their own original idea. It is also customary to cherry-pick a function, or part
    of the code from a Notebook, and insert it into your own. In both these cases,
    please remember always to quote the source and the author. If you cannot retrace
    something to the original author, even referring to the last Notebook where you
    found the code you used is enough. While the main purpose of a showcase is to
    display your own efforts and skills, it is very important to recognize that some
    parts of your code or some ideas are taken from elsewhere. Aside from being a
    sign of respect toward your fellow Kagglers, a source attribution highlights that
    you are knowledgeable enough to recognize other people’s efforts and inventions,
    and that you know how to employ them in your own work.
  prefs: []
  type: TYPE_NORMAL
- en: In a minor way, discussions on Kaggle’s forums can help you get noticed for
    specific roles in data science and software development. Initially, discussions
    on Kaggle were just for communicating with organizers or for asking pressing questions
    about the competition itself. At the end of competitions, participants seldom
    felt compelled to present or discuss their solutions. However, since discussions
    obtained their own user rankings and mastery grades, you have been able to find
    much more information on forums.
  prefs: []
  type: TYPE_NORMAL
- en: Refer to *Chapter 4*, *Leveraging Discussion Forums*, for an introduction to
    discussions on Kaggle.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our experience, discussions on Kaggle can be split into four categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Competition solutions that explain in detail (sometimes with the help of an
    associated Notebook) how a team managed to reach a certain position on the private
    leaderboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Help with and an explanation of requirements during a competition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thanks, compliments, and chit-chat
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Posts that help and tutor other competitors, explaining things to them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have observed that excelling in the last type of post and being widely noticed
    for it can help you achieve the role of developer advocate, especially if you
    also have other active channels where you interact with your fellow data scientists
    (for instance, a Twitch or YouTube channel, a Twitter account, or a Medium blog).
  prefs: []
  type: TYPE_NORMAL
- en: 'With the growth of developer advocate roles in both large companies and start-ups,
    there is an important demand for experts skilled at helping other data scientists
    and developers in their projects. If you want to learn more about this role, the
    following article on [draft.dev](https://draft.dev) is quite explanatory and exhaustive:
    [https://draft.dev/learn/what-is-a-developer-advocate](https://draft.dev/learn/what-is-a-developer-advocate).'
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kaggle competitions are often criticized for presenting data that is already
    cleaned, well arranged, and far from representative of data found in the real
    world. Our point of view is slightly different; we find the data that Kaggle presents
    in competitions can also be quite messy or noisy. Sometimes the data presented
    will not actually suffice in terms of quality and quantity for getting a top score,
    and you will need to look around for additional data on the internet.
  prefs: []
  type: TYPE_NORMAL
- en: What Kaggle does miss out with regard to data in a data science project is the
    process of collecting and gathering data in organized repositories and files,
    a process that, in real-world settings, is not possible to standardize because
    it differs from company to company and problem to problem. Data handling in the
    real world should mostly be learned on the field.
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of datasets into Kaggle was aimed at mitigating the idea that
    Kaggle was just focused on modeling problems. Kaggle Datasets are very helpful
    in this sense because they allow you to create and upload your own data and document
    the features and their values; they also require you to manage your data over
    time by planning the frequency with which you are going to update or completely
    replace it.
  prefs: []
  type: TYPE_NORMAL
- en: Refer to *Chapter 2*, *Organizing Data with Datasets*, for an introduction to
    Kaggle Datasets.
  prefs: []
  type: TYPE_NORMAL
- en: More interestingly, in Kaggle Datasets, you are also given the opportunity to
    attach different analyses and models built using Kaggle Notebooks, uploaded from
    your data or a competition. These models could be work you came up with during
    a competition, or something you devised because you studied the uploaded data
    attentively and found a set of interesting problems you could solve with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, Kaggle Datasets offer you a template to check for the completeness
    of the meta-information accompanying your data. A description, tags, a license,
    sources, and the frequency of updates: these are only a few of the required pieces
    of information (used to calculate a usability score) that will help anyone using
    your data to understand how to use it. You may even point out (in the description
    or in discussions) tasks for the dataset that relate to pending work you would
    like to do with it. This is a good way to communicate your full understanding
    of the potential value of the data you have uploaded.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Previously, Tasks were part of the Kaggle Dataset functionality, but they have
    recently been removed: [https://www.kaggle.com/product-feedback/292674](https://www.kaggle.com/product-feedback/292674).
    Nevertheless, you can use the data description and discussions to point out what
    you expect your data could be used for.'
  prefs: []
  type: TYPE_NORMAL
- en: 'All these characteristics make Kaggle Datasets a very good way to show off
    your experience with problems on Kaggle and, in general, your ability with data
    and machine learning algorithms, because they allow you to:'
  prefs: []
  type: TYPE_NORMAL
- en: Publish and maintain a dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrate that you have understood the value of the data with a tasks roadmap
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Show coded and fully working solutions (since Kaggle Notebooks can immediately
    work on the same data, without any preparation), ranging from data preparation
    to explanatory data analysis to predictive modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We strongly recommend using Kaggle Datasets for showing off the work you have
    done during Kaggle competitions or on any other project, because they separate
    your work from others’ and integrate data and Notebooks. In short, Kaggle Datasets
    can demonstrate to anyone a working solution that you have implemented. There
    is a downside, though: you are mostly tied to a Notebook environment (even when
    you use scripting), which is not perfectly transparent in terms of the package
    and version requirements necessary for someone to know to run the code in other
    environments.'
  prefs: []
  type: TYPE_NORMAL
- en: In fact, Kaggle Notebooks depend on a Docker environment ([https://www.docker.com/](https://www.docker.com/))
    set by a configuration file, a **Dockerfile**, that determines which versions
    have been installed. When browsing a Notebook, it is not immediately evident what
    version of packages are being used until you inspect this configuration file.
    For this purpose, as well as for replicating the settings, the Dockerfile can
    be found on the Kaggle repository on GitHub ([https://github.com/Kaggle/docker-python/blob/main/Dockerfile.tmpl](https://github.com/Kaggle/docker-python/blob/main/Dockerfile.tmpl)),
    though it changes over time and you may need to keep track of the one used in
    your work.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in addition to this aspect, don’t forget that getting even a glimpse
    of a Dataset and its related Notebooks requires access to the Kaggle community.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Gabriel_Preda.png)'
  prefs: []
  type: TYPE_IMG
- en: Gabriel Preda
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/gpreda](https://www.kaggle.com/gpreda)'
  prefs: []
  type: TYPE_NORMAL
- en: We had an inspiring career-oriented talk with *Gabriel Preda*, a Kaggle Grandmaster
    in Datasets, Notebooks, and Discussions, and Principal Data Scientist at Endava.
    Gabriel has a PhD in Computational Electromagnetics and had a long career in software
    development before devoting himself completely to data science. When he discovered
    Kaggle, he felt at home on the platform and invested a lot of time and effort
    into it, which paid dividends for him professionally.
  prefs: []
  type: TYPE_NORMAL
- en: Has Kaggle helped you in your career? How?
  prefs: []
  type: TYPE_NORMAL
- en: '*Kaggle helped me to accelerate my learning curve in data science. Before Kaggle,
    I was looking all around for sources of information or problems to solve, but
    it was not very methodical or effective. On Kaggle, I found a community of people
    interested in the same things as me. I was able to see the work of top experts
    in the field, learn from their published Notebooks with analyses or models, get
    insights from them, ask them questions, and even compete against them. I was mostly
    in data analysis at the time I joined Kaggle, but very quickly I started to compete;
    that means learning how to build, validate, and iteratively improve models. After
    around two years on Kaggle, I switched my career; I went from managing software
    projects to a full-time data science job. Kaggle also gave me some visibility,
    and during interviews with candidates at my present company they mentioned that
    they wanted to join because they saw that I worked there.*'
  prefs: []
  type: TYPE_NORMAL
- en: Have you ever used something you have done on Kaggle as part of your portfolio
    to show potential employers?
  prefs: []
  type: TYPE_NORMAL
- en: '*I use my Kaggle portfolio as the main source of information for potential
    employers; my LinkedIn profile points to my Kaggle profile. Also, in recent years,
    employers have become more aware about Kaggle, and some of them ask specifically
    about your Kaggle profile. There are also potential employers that make very clear
    that they do not consider Kaggle relevant. I disagree with this view; personally,
    before interviewing candidates, I normally check their GitHub and Kaggle profiles.
    I find them extremely relevant. A good Kaggle profile will demonstrate not only
    technical skills and experience with certain languages, tools, techniques, or
    problem-solving skills, but also how well someone is able to communicate through
    discussions and Notebooks. This is a very important quality for a data scientist.*'
  prefs: []
  type: TYPE_NORMAL
- en: You reached Grandmaster in Notebooks (Kernels) first, then in Discussions, and
    finally in Datasets. Can you tell us about your journey?
  prefs: []
  type: TYPE_NORMAL
- en: '*I became the seventh Kernels Grandmaster and I got as high as the third rank.
    For maybe two* *years I think I was in the top 10 in the Kernels hierarchy as
    well. I started writing Kernels primarily to improve my knowledge of the R language
    while analyzing datasets I found more interesting. I also experimented with all
    kinds of techniques, including polygon clips, building dual meshes of Voronoi
    polygons, and 2D Delaunay tessellation. I gradually started to focus on exploratory
    data analysis, followed by building models for datasets and then for competitions.
    Also, once I started to compete more, I started to write Kernels for competing
    in Python. About the same time, I began to notice that some of my Kernels attracted
    attention from Kagglers, primarily upvotes and forks but also favorable comments.
    Some of my Kernels written for exploration of data in active competitions reached
    a very wide audience and brought me many gold medals; therefore, I reached the
    Master and then Grandmaster tier. Currently, I do not publish many Kernels related
    to competitions; mostly I create starting Kernels related to datasets that I publish.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Next, I also obtained the Discussions Grandmaster level. I never anticipated
    that I would reach this tier in discussions. First, I started commenting on other
    people’s Kernels. Then, gradually, as I got more involved in competitions, most
    of my comments were in the discussion sections of active competitions, either
    asking questions about topics of interest in these competitions or starting new
    topics, for example, suggesting solutions for one problem in a competition or
    collections of resources to address various open issues related to the competition.
    I want to mention a special set of comments that I added. As a Kaggle Kernels
    Grandmaster (one of the first), I frequently upvoted new Kagglers’ Notebooks when
    I discovered very good content.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*In such cases, I try to find a few moments to also praise (especially if the
    content is of good quality) the achievement of the author. Especially to beginners,
    giving not only the expression of your appreciation by upvoting their work, but
    also adding some positive feedback about their contribution, might give them a
    boost of confidence so that they will invest more in learning and contributing
    even more on Kaggle. I like to do this, and I hope it helps. I once also compiled
    a list of recommendations about how to comment on Kaggle. This is the list: be
    short (but not too short); be specific; provide information, not opinions; praise
    other people’s work when you have the opportunity; keep calm and try to be helpful;
    do not tag people in your comments unless it makes sense (for example, if it is
    a discussion, and you need to direct your comment to someone that addressed you
    in that thread).*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The last Grandmaster tier I reached is in Datasets. This is also the tier
    where I reached the highest ranking, second. My progress through the ranks was
    slow. I started with something I liked. Getting a high profile in Datasets requires
    investment in curating, cleaning, and documenting the data. If it is not something
    that you really like, you most probably will not keep going. I pursued things
    that were important to me but also to a wider community: to my country, my continent,
    or the whole world. I published datasets about elections in my country, and about
    various social, demographic, and economic topics in Europe. I focused on subjects
    of actuality, that were both relevant and of high importance for the community.
    For example, during the pandemic, I published datasets on COVID-19 cases, about
    vaccinations, tests, and virus variants both from my country* *and worldwide.
    I captured data that went beyond simple numerical, tabular values. Text data,
    especially originating from direct contributions from people, provided important
    insights for many people. One of my most upvoted datasets consists of collections
    of Reddit posts and comments or Twitter posts (tweets) on subjects as diverse
    as vaccine myths, cricket, pandemics, sports events, and political personalities.
    I invested significantly in automating data collection, data cleaning, and data
    processing scripts. This saved me precious time (especially for datasets updated
    frequently – some of them were collected continuously, with scripts triggered
    every hour) but also made it possible to have better control of the process. Every
    time I publish a new dataset, I also write one or more starting Kernels. These
    Kernels are not intended to reach a large audience. I create them as helper Kernels
    for potential users of my Datasets, so that they find it easier to use the data.
    In many cases, I prefer to keep the original data (as I collected it, or downloaded
    from an alternative source) and include a Kernel for data cleaning, transformation,
    and preliminary analysis as well as the result of this process, the data in a
    more accessible format. In this way, I try to capture in the dataset more than
    the data itself; I also provide information about techniques for data transformation.*'
  prefs: []
  type: TYPE_NORMAL
- en: Arranging your online presence beyond Kaggle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since Kaggle Datasets and Notebooks require a Kaggle account, you have to take
    into account that not everyone may already have one or want to create one just
    to look at your work. You also have to consider alternatives that are more accessible.
    More frequently, Kagglers choose to use a project on GitHub ([https://github.com/](https://github.com/)),
    write an article on Medium ([https://medium.com/](https://medium.com/)) as well
    as other publishing platforms, or post on their own blog. There are other opportunities
    to promote your work and skills, however, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Publishing code relevant to Kaggle competitions that can be executed from the
    browser on [https://deepnote.com/](https://deepnote.com/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Setting up a Discord community that gathers Kagglers, such as *Abhishek Thakur*’s
    MLSpace ([https://discord.com/invite/4RMwz64gdH](https://discord.com/invite/4RMwz64gdH)),
    or running a YouTube channel (also from Abhishek Thakur: [https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A](https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Setting up a Twitch channel like *Rob Mulla*’s, where he demonstrates coding
    relevant to Kaggle competitions: [https://www.twitch.tv/medallionstallion](https://www.twitch.tv/medallionstallion)
    (also on GitHub: [https://github.com/RobMulla/twitch-stream-projects](https://github.com/RobMulla/twitch-stream-projects))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Delivering a weekly newsletter on Kaggle news, like *Shotaro Ishihara*: [https://www.getrevue.co/profile/upura](https://www.getrevue.co/profile/upura)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Interviewing Kagglers and other data science experts as *Sanyam Bhutani* is
    doing, and broadcasting the interviews using videos, podcasts, and blog posts:
    [https://chaitimedatascience.com/](https://chaitimedatascience.com/) (you can
    browse the dataset containing all the data about the interviews held so far, prepared
    by *Rohan Rao*: [https://www.kaggle.com/rohanrao/chai-time-data-science](https://www.kaggle.com/rohanrao/chai-time-data-science))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can deduce, there are really quite a lot of opportunities and media through
    which you can diffuse your work and skills on Kaggle, depending on what you want
    to achieve. In this chapter, our focus is on just blogs and a GitHub presence
    (which are the most common choices and quite effective), but you are free to decide
    on any different approach you deem suitable for your purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Blogs and publications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Writing can be a way both to refine your knowledge – because you need to read
    up on a topic in order to write about it – and to let others know about you and
    your skills. Getting famous for your writing helps you in various ways, from being
    spotted by recruiters and companies to building your connections for both Kaggle
    competitions and your wider professional life.
  prefs: []
  type: TYPE_NORMAL
- en: Social media (LinkedIn, Twitter, and Facebook) allows you to post ideas and
    short pieces of text, and this is something that we do suggest you leverage. Given
    that data science and Kaggle competition topics require discussion and reasoning
    at length, the best approach, however, is to write **long articles** and publish
    them by means of a blog or a website that publishes writing. Ideally, we suggest
    you coordinate your communication between social media and your articles in order
    to promote them, with dedicated posts announcing them or discussing key points
    in your writing.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s first discuss how and where you could publish your articles.
  prefs: []
  type: TYPE_NORMAL
- en: 'An article on Medium, especially on **Medium publications** such as Towards
    Data Science ([https://towardsdatascience.com/](https://towardsdatascience.com/)),
    can get a lot of attention. Medium publications are shared spaces for stories
    written around a common theme or topic, usually by multiple authors. As a website,
    Medium can reach a wide audience of readers and some publications have a very
    good reputation in the data science community for the quality of their articles.
    A publication can have one or more editors who select the pieces and assure that
    their contents are consistent with the policies of the publication and its quality
    level. Medium publications where you could post your articles are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Towards Data Science**, as mentioned ([https://towardsdatascience.com/questions-96667b06af5](https://towardsdatascience.com/questions-96667b06af5))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Better Programming** ([https://betterprogramming.pub/write-for-us-5c4bcba59397](https://betterprogramming.pub/write-for-us-5c4bcba59397))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mlearning.ai** ([https://medium.com/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb](https://medium.com/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Becoming Human** ([https://becominghuman.ai/write-for-us-48270209de63](https://becominghuman.ai/write-for-us-48270209de63))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Towards AI** ([https://pub.towardsai.net/submit-your-medium-story-to-towards-ai-a4fa7e8b141d](https://pub.towardsai.net/submit-your-medium-story-to-towards-ai-a4fa7e8b141d))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these publications has the great advantage of already having a large
    audience, probably larger than your following on social media. You will get more
    readers than you would probably expect, reaching people at companies as well as
    other professionals you can network with.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides Medium, these other websites might also accept your publications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hacker Noon** ([https://www.publish.hackernoon.com/](https://www.publish.hackernoon.com/)):
    Quite popular among tech bloggers and contains anything tech-related (it is quite
    generalist). With a monthly audience of four million people, it is the right place
    if you want to reach many tech lovers with anything tech-related. Being featured
    on the top pages is extremely difficult and a double-edged sword: you will get
    a lot of attention, as well as many critics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dev.to** ([https://dev.to/](https://dev.to/)): Mainly has an audience of
    developers (almost eight hundred thousand) and features articles and tutorials
    on coding. Your posts should be more focused on the quality and efficacy of your
    code (modeling is in the background).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FreeCodeCamp** ([https://www.freecodecamp.org/news/developer-news-style-guide/](https://www.freecodecamp.org/news/developer-news-style-guide/)):
    More focused on tutorials; people go there to learn how to code. It is ideal for
    promoting courses on machine learning and promoting new packages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Analytics Vidhya** ([https://www.analyticsvidhya.com/about/write/](https://www.analyticsvidhya.com/about/write/)):
    Quite popular in India; it is more centered around articles explaining machine
    learning and deep learning building blocks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**KDnuggets** ([https://www.kdnuggets.com/news/submissions.html](https://www.kdnuggets.com/news/submissions.html)):
    One of the oldest publications in data mining. It still has quite a lot of followers
    (one million unique visitors in March 2021) among the old guard of data scientists
    and academics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each publication has strong and weak points and differs in the audience it reaches,
    so you have to decide which one better suits your content. Start by browsing the
    publications they offer in order to understand how your writing could fit in.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, if you would prefer, you can instead use your own blog. Having your
    own blog has its advantages, such as no advertising or editorial scrutiny over
    what you write. On the other hand, you cannot leverage a pre-existing audience
    and you will have to work to create one by promoting your articles on social media.
    You can set up your own website from scratch on a web domain of your choice or
    you could create your own blog on GitHub, too.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you decide to use GitHub (since it is free and you may already use it as
    a repository for your code), here is a simple and fast guide to creating GitHub
    blog posts: [http://jmcglone.com/guides/github-pages/](http://jmcglone.com/guides/github-pages/)'
  prefs: []
  type: TYPE_NORMAL
- en: If you need something even more automated, using a platform such as *Jeremy
    Howard*’s **fastpages** ([https://github.com/fastai/fastpages](https://github.com/fastai/fastpages))
    can simplify the way you deal with writing content together with code examples,
    because it automatically converts notebooks and Word documents into blog pages
    and publishes them for you.
  prefs: []
  type: TYPE_NORMAL
- en: If you prefer to be completely independent and set up your own website, this
    will require more effort and some expense; domain names and web space are not
    free. In this case, self-promotion of your content becomes critical.
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage of writing about your solutions is the storytelling element,
    because you have to accompany your code snippets with descriptions and explanations
    and you need to write in a more verbose way than you could do in a Notebook. In
    a sense, how you describe your work becomes as important as the code you write.
    By adjusting the tone of your writing, you can reach different types of audiences.
    Writing concepts in an accessible way means you will enlarge your audience and
    connect with more professionals. Writing in a highly technical way instead could
    impress more potential companies that may consider hiring you, though limiting
    the number of readers you get.
  prefs: []
  type: TYPE_NORMAL
- en: Since writing is a very personal act and our hints and suggestions won’t apply
    to every scenario, our general suggestion is to decide beforehand the purpose
    of your writing and who you would like to reach with it.
  prefs: []
  type: TYPE_NORMAL
- en: GitHub
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Aside from writing articles and having a code repository you can direct readers
    to, having your code on GitHub will also help you not to reinvent the wheel in
    every competition you enter. You can store the code you want to reuse in a project
    or in **Gists** ([https://docs.github.com/en/github/writing-on-github/editing-and-sharing-content-with-gists](https://docs.github.com/en/github/writing-on-github/editing-and-sharing-content-with-gists)),
    which are small snippets of code that can be accessed individually.
  prefs: []
  type: TYPE_NORMAL
- en: Even if it may appeal to you to leave all your code on Kaggle, with time you
    will find it difficult to access and you may even have trouble finding it altogether.
    This is because you cannot arrange your Kaggle Notebooks into separate projects;
    they will just be presented as a long list that you can order by a few attributes
    such as the number of votes or when you last ran the Notebook. GitHub makes it
    much easier to find what you need and reuse it. For instance, you can create scripts
    containing all your code and then download and import them into a Kaggle Notebook
    without needing to copy anything.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we download and reuse helper functions for a `tabular`
    neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'A `wget` command will directly access code on GitHub and download it onto the
    disk of the Notebook; afterward, you can just import the functions and classes
    that you need from it. To obtain the link providing direct access to your code,
    you just need to look for the file containing it on the GitHub repository and
    then click on the **Raw** button on the header of the page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17574_13_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.1: The header of a visualized file on GitHub. Notice the Raw button
    on the upper right part of the header bar.'
  prefs: []
  type: TYPE_NORMAL
- en: After clicking on the **Raw** button, you will be taken to the web address where
    the file is stored on GitHub. You can use that web address to refer to the file
    from outside of GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: GitHub is also useful also for storing images that you can use on Kaggle discussions
    (since you can no longer upload images on the Kaggle forums). In the case of images,
    you won’t have a **Raw** button to click, but you can instead right-click on the
    image and open the file in another tab; this will have the same effect.
  prefs: []
  type: TYPE_NORMAL
- en: GitHub is another great way to showcase your work, but given the nature of the
    website (it is targeted at developers) and the content you can put on it (files
    containing code), you should expect a very technical audience. In companies, human
    resources probably won’t look too deeply at your GitHub account, instead stopping
    at the `README.md`, which should therefore be well written and visually appealing.
    Recruiting managers, on the other hand, will be more interested in the code in
    your projects. You should put some effort into having well-structured code in
    your files, procedures, and classes, also including the instructions necessary
    for the installation and replication of your results.
  prefs: []
  type: TYPE_NORMAL
- en: You will have to use tools such as `conda` ([https://docs.conda.io/en/latest/](https://docs.conda.io/en/latest/))
    or `poetry` ([https://python-poetry.org/](https://python-poetry.org/)) to ensure
    the correct packages are installed for your code to work. In order to give the
    best structure to your project, you’ll probably need something like `CookieCutter`
    ([https://drivendata.github.io/cookiecutter-data-science/](https://drivendata.github.io/cookiecutter-data-science/)).
    Using a `template` for your projects, like the ones CookieCutter provides, enables
    your code to be arranged into specific directories easily and will provide the
    files that allow its usage and understanding. A CookieCutter template will make
    your project easier to read, understand, and maintain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, for managing your experiments and data sources, you will also need
    some **version control system** for the data being used, not just for your code,
    for instance using **Data Version Control** (**DVC**: [https://dvc.org/](https://dvc.org/)).
    All these resources and the skills you need to run them properly (creating your
    environment, structuring your project, versioning data and models) are closer
    to software engineering than data science competencies. They are not so relevant
    on Kaggle – or can be done in simple ways – and will require effort and learning.
    Yet, they will become part of the capabilities that you will present with your
    projects on GitHub, improving your chances of making a good impression on job
    interviewers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to put in live demonstrations of your models, you have a few different
    options. The easiest is having the code running on the original Notebooks (just
    by putting a link to your Kaggle Notebook in the `README.md` file of your GitHub
    project) or on **Google Colab**. To have the Notebook you stored on GitHub run
    automatically in Google Colab, just post its link with the domain changed from
    [github.com](https://github.com) to [githubtocolab.com](https://githubtocolab.com):
    the link will open your Notebook in Colab.'
  prefs: []
  type: TYPE_NORMAL
- en: The most impressive showcase you can prepare, however, is using **HuggingFace
    Spaces** ([https://huggingface.co/spaces](https://huggingface.co/spaces)) to demonstrate
    how your Kaggle model could be used in an online application. Spaces are a simple
    way to host machine learning demonstrations and create online portfolios of your
    work, as explained in the documentation ([https://huggingface.co/docs/hub/spaces](https://huggingface.co/docs/hub/spaces)).
    They are limited to 16GB of RAM and 8 CPU cores, but they are free and sufficient
    for demonstrating how your model can run in a dedicated application. You can install
    your dependencies on the HuggingFace remote machine, sync code and models with
    GitHub, or build an app using `Streamlit` ([https://streamlit.io/](https://streamlit.io/))
    or `Gradio` ([https://gradio.app/](https://gradio.app/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, *Rashmi Banthia*, a Kaggle Expert and a Teaching Fellow at Harvard
    University ([https://www.kaggle.com/rashmibanthia](https://www.kaggle.com/rashmibanthia)),
    has posted a demonstration of her model from the *Sartorious Cell Instance Segmentation*
    competition: [https://huggingface.co/spaces/rashmi/Cell-Instance-Segmentation-MMDetection](https://huggingface.co/spaces/rashmi/Cell-Instance-Segmentation-MMDetection).
    By presenting your model together with a few examples in a real-time demonstration,
    you can immediately convey its effectiveness even to a non-machine learning audience.'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring competition updates and newsletters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By now, you can see that it is important to showcase your work on Kaggle so
    you can communicate to the world your interest in certain types of models and
    data problems. From this perspective, it is important that you are always aware
    of the opportunities offered by competitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main way to do this is to visit the Kaggle website frequently and agree
    to receive emails from them. You can set this option from your profile, on the
    **Notification and e-mail settings** page, where you can agree to receive notifications
    both on the site and by email. You can also choose to receive emails containing
    tips on new features and initiatives on Kaggle, along with news about recently
    launched competitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17574_13_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.2: A Kaggle email announcing a series of videos from the Kaggle Team'
  prefs: []
  type: TYPE_NORMAL
- en: If you are a Twitter user, you’ll find it useful to follow a couple of profiles
    to keep you updated about new stuff on Kaggle. **Kagoole** ([https://twitter.com/kagoole](https://twitter.com/kagoole))
    is a web application that can inform you about new competitions and also, in its
    Heroku app form ([https://kagoole.herokuapp.com/](https://kagoole.herokuapp.com/)),
    provides you with solutions for past competitions. It was created by `Doarakko`
    ([https://github.com/Doarakko/](https://github.com/Doarakko/)). The other Twitter
    profile you could follow is **Is he Kerneler?** ([https://twitter.com/HKerneler](https://twitter.com/HKerneler)),
    created by `Regonn` ([https://github.com/regonn/](https://github.com/regonn/)),
    which tells you how much time is left before each active Kaggle competition closes.
  prefs: []
  type: TYPE_NORMAL
- en: As we know from *Chapter 1*, Kaggle is not the only organization that holds
    data science competitions. In order to keep better track of what is actually happening
    both on Kaggle and other data science competition websites, we suggest using websites
    such as [https://mlcontests.com/](https://mlcontests.com/) or [https://ods.ai/competitions](https://ods.ai/competitions)
    that monitor all ongoing competitions on Kaggle, as well as on other platforms
    such as AICrowd and DrivenData. For instance, [mlcontests.com](https://mlcontests.com)
    provides you with information on prizes, deadlines, and useful links for each
    competition.
  prefs: []
  type: TYPE_NORMAL
- en: It also gives you cloud GPU comparisons in terms of performance, machines, and
    prices. You can register your email and receive much of this information directly
    to your inbox.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed how to showcase your work and how this can be
    valuable for progressing your career. It helps you to demonstrate capabilities
    that, while (of course) not covering the entire span of your data science knowledge
    and experience, still represent a great asset.
  prefs: []
  type: TYPE_NORMAL
- en: In order to display your work, you can either use Kaggle resources or external
    resources. Kaggle resources offer you an integrated environment and, provided
    you have everything at hand, are quite accessible and quick to set up. External
    resources (Medium publications, GitHub, HuggingFace Spaces, and so on) are more
    widely known and accessible for the majority of recruiters, human resource officers,
    and hiring managers because they use them routinely.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will complete our discussion of the opportunities that
    Kaggle competitions offer you by talking about network building and how to use
    your Kaggle efforts to get an interview.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/KaggleDiscord](https://packt.link/KaggleDiscord)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code40480600921811704671.png)'
  prefs: []
  type: TYPE_IMG
