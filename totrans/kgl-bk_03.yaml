- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Organizing Data with Datasets
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数据集组织数据
- en: 'In his story *The Adventure of the Copper Beeches*, Arthur Conan Doyle has
    Sherlock Holmes shout “*Data! Data! Data! I cannot make bricks without clay*.”
    This mindset, which served the most famous detective in literature so well, should
    be adopted by every data scientist. For that reason, we begin the more technical
    part of this book with a chapter dedicated to data: specifically, in the Kaggle
    context, leveraging the power of the Kaggle Datasets functionality for our purposes.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在他的故事《铜 Beeches 的冒险》中，亚瑟·柯南·道尔让夏洛克·福尔摩斯喊道“*数据！数据！数据！没有粘土我无法制造砖块*。”这种心态为文学中最著名的侦探提供了很好的服务，每个数据科学家都应该采纳这种心态。因此，我们以一个专门介绍数据的章节开始这本书的更技术性部分：具体来说，在
    Kaggle 的背景下，利用 Kaggle 数据集功能为我们服务。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Setting up a dataset
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置数据集
- en: Gathering the data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集数据
- en: Working with datasets
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与数据集一起工作
- en: Using Kaggle Datasets in Google Colab
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Google Colab 中使用 Kaggle 数据集
- en: Legal caveats
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 法律注意事项
- en: Setting up a dataset
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置数据集
- en: 'In principle, any data you can use you can upload to Kaggle (subject to limitations;
    see the *Legal caveats* section later on). The specific limits at the time of
    writing are **100 GB per private dataset** and a **100 GB total** quota. Keep
    in mind that the size limit per single dataset is calculated uncompressed; uploading
    compressed versions speeds up the transfer but does not help against the limits.
    You can check the most recent documentation for the datasets at this link: [https://www.kaggle.com/docs/datasets](https://www.kaggle.com/docs/datasets).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，你可以使用的任何数据都可以上传到 Kaggle（受限制；请参阅后面的 *法律注意事项* 部分）。写作时的具体限制是 **每个私有数据集 100
    GB** 和 **总共 100 GB** 的配额。请注意，单个数据集的大小限制是计算未压缩的；上传压缩版本可以加快传输速度，但不会帮助克服限制。你可以通过此链接检查数据集的最新文档：[https://www.kaggle.com/docs/datasets](https://www.kaggle.com/docs/datasets)。
- en: Kaggle promotes itself as a “home of data science” and the impressive collection
    of datasets available from the site certainly lends some credence to that claim.
    Not only can you find data on topics ranging from oil prices to anime recommendations,
    but it is also impressive how quickly data ends up there. When the emails of *Anthony
    Fauci* were released under the *Freedom of Information Act* in May 2021 ([https://www.washingtonpost.com/politics/interactive/2021/tony-fauci-emails/](https://www.washingtonpost.com/politics/interactive/2021/tony-fauci-emails/)),
    they were uploaded as a Kaggle dataset a mere 48 hours later.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle 自称为“数据科学之家”，并且从该网站提供的令人印象深刻的数据集集合确实为这一说法增添了一些可信度。你不仅可以找到从石油价格到动漫推荐等主题的数据，而且数据迅速出现在那里的速度也令人印象深刻。当2021年5月根据《信息自由法》发布
    *安东尼·福奇* 的电子邮件时([https://www.washingtonpost.com/politics/interactive/2021/tony-fauci-emails/](https://www.washingtonpost.com/politics/interactive/2021/tony-fauci-emails/))，它们仅仅在48小时后就被上传为一个
    Kaggle 数据集。
- en: '![](img/B17574_02_01.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17574_02_01.png)'
- en: 'Figure 2.1: Trending and popular datasets on Kaggle'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1：Kaggle 上的趋势和热门数据集
- en: Before uploading the data for your project into a dataset, make sure to check
    the existing content. For several popular applications (image classification,
    NLP, financial time series), there is a chance it has already been stored there.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在将你的项目数据上传到数据集之前，请确保检查现有内容。对于几个流行的应用（图像分类、NLP、金融时间序列），有可能它已经被存储在那里。
- en: 'For the sake of this introduction, let us assume the kind of data you will
    be using in your project is not already there, so you need to create a new dataset.
    When you head to the menu with three lines on the left-hand side and click on
    **Data**, you will be redirected to the **Datasets** page:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了介绍的目的，让我们假设你将在项目中使用的数据尚未存在，因此你需要创建一个新的数据集。当你点击左侧带有三条线的菜单并点击 **数据** 时，你将被重定向到
    **数据集** 页面：
- en: '![Obraz zawierający tekst  Opis wygenerowany automatycznie](img/B17574_02_02.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本的图像 自动生成的描述](img/B17574_02_02.png)'
- en: 'Figure 2.2: The Datasets page'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2：数据集页面
- en: 'When you click on **+ New Dataset**, you will be prompted for the basics: uploading
    the actual data and giving it a title:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当你点击 **+ 新数据集** 时，你将被提示输入基本信息：上传实际数据和给它一个标题：
- en: '![Obraz zawierający tekst  Opis wygenerowany automatycznie](img/B17574_02_03.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本的图像 自动生成的描述](img/B17574_02_03.png)'
- en: 'Figure 2.3: Entering dataset details'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3：输入数据集详细信息
- en: 'The icons on the left-hand side correspond to the different sources you can
    utilize for your dataset. We describe them in the order they are shown on the
    page:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧的图标对应于您可以为数据集利用的不同来源。我们按页面显示的顺序描述它们：
- en: Upload a file from a local drive (shown in the figure)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从本地驱动器上传文件（如图所示）
- en: Create from a remote URL
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从远程URL创建
- en: Import a GitHub repository
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入GitHub仓库
- en: Use output files from an existing Notebook
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用现有笔记本的输出文件
- en: Import a Google Cloud Storage file
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入Google Cloud Storage文件
- en: '**An important point about the GitHub option**: This feature is particularly
    handy when it comes to experimental libraries. While frequently offering hitherto
    unavailable functionality, they are usually not included in the Kaggle environment,
    so if you want to use such a library in your code, you can import it as a dataset,
    as demonstrated below:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**关于GitHub选项的一个重要观点**：当涉及到实验性库时，此功能特别有用。虽然它们经常提供以前不可用的功能，但它们通常不包括在Kaggle环境中，因此如果您想在代码中使用此类库，您可以将其作为数据集导入，如下所示：'
- en: Go to **Datasets** and click **+ New Dataset**.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往**数据集**并点击**新建数据集**。
- en: Select the GitHub icon.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择GitHub图标。
- en: Insert the link to the repository, as well as the title for the dataset.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 插入仓库链接以及数据集的标题。
- en: 'Click on **Create** at the bottom right:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在右下角点击**创建**：
- en: '![Obraz zawierający tekst  Opis wygenerowany automatycznie](img/B17574_02_04.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本的图像 自动生成的描述](img/B17574_02_04.png)'
- en: 'Figure 2.4: Dataset from GitHub repository'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4：来自GitHub仓库的数据集
- en: 'Next to the **Create** button, there is another one marked **Private**. By
    default, any dataset you create is private: only you, its creator, can view and
    edit it. It is probably a good idea to leave this setting at default at the dataset
    creation stage and only at a later stage make it public (available to either a
    select list of contributors, or everyone).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在**创建**按钮旁边，还有一个标记为**私有**的按钮。默认情况下，您创建的任何数据集都是私有的：只有您，即创建者，可以查看和编辑它。在数据集创建阶段保持此设置为默认值，并在稍后阶段将其公开（可供选定列表的参与者或所有人使用）可能是一个好主意。
- en: Keep in mind that Kaggle is a popular platform and many people upload their
    datasets – including private ones – so try to think of a non-generic title. This
    will increase the chance of your dataset actually being noticed.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，Kaggle是一个流行的平台，许多人上传他们的数据集——包括私有的——所以尽量想一个非通用标题。这将增加您的数据集真正被注意到的机会。
- en: 'Once you have completed all the steps and clicked **Create**, voilà! Your first
    dataset is ready. You can then head to the **Data** tab:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有步骤并点击**创建**后，哇！您的第一个数据集就准备好了。然后您可以前往**数据**选项卡：
- en: '![](img/B17574_02_05.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17574_02_05.png)'
- en: 'Figure 2.5: The Data tab'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5：数据选项卡
- en: The screenshot above demonstrates the different information you can provide
    about your dataset; the more you do provide, the higher the **usability index**.
    This index is a synthetic measure summarizing how well your dataset is described.
    Datasets with higher usability indexes appear higher up in the search results.
    For each dataset, the usability index is based on several factors, including the
    level of documentation, the availability of related public content like Notebooks
    as references, file types, and coverage of key metadata.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图展示了您可以提供有关数据集的不同信息；您提供的信息越多，**可用性指数**就越高。这个指数是一个综合指标，总结了您的数据集描述得有多好。具有更高可用性指数的数据集在搜索结果中显示得更高。对于每个数据集，可用性指数基于多个因素，包括文档水平、相关公共内容（如笔记本）的可用性、文件类型和关键元数据的覆盖范围。
- en: 'In principle, you do not have to fill out all the fields shown in the image
    above; your newly created dataset is perfectly usable without them (and if it
    is a private one, you probably do not care; after all, you know what is in it).
    However, community etiquette would suggest filling out the information for the
    datasets you make public: the more you specify, the more usable the data will
    be to others.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在原则上，您不需要填写上图所示的所有字段；您新创建的数据集无需它们即可完全使用（如果它是私有的，您可能也不在乎；毕竟，您知道里面有什么）。然而，社区礼仪建议填写您公开的数据集的信息：您指定的信息越多，数据对他人就越有用。
- en: Gathering the data
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集数据
- en: 'Apart from legal aspects, there is no real limit on the kind of content you
    can store in the datasets: tabular data, images, text; if it fits within the size
    requirements, you can store it. This includes data harvested from other sources;
    tweets by hashtag or topic are among the popular datasets at the time of writing:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 除了法律方面，在数据集中存储的内容类型实际上没有真正的限制：表格数据、图像、文本；如果它符合大小要求，就可以存储。这包括从其他来源收集的数据；在撰写本文时，按标签或主题收集的推文是流行的数据集之一：
- en: '![Obraz zawierający tekst  Opis wygenerowany automatycznie](img/B17574_02_06.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本的图像 自动生成的描述](img/B17574_02_06.png)'
- en: 'Figure 2.6: Tweets are among the most popular datasets'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6：推文是最受欢迎的数据集之一
- en: Discussion of the different frameworks for harvesting data from social media
    (Twitter, Reddit, and so on) is outside the scope of this book.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论从社交媒体（Twitter、Reddit等）收集数据的不同框架超出了本书的范围。
- en: '![](img/Andrew_Maranhao.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![安德烈·马拉尼亚奥的图片](img/Andrew_Maranhao.png)'
- en: Andrew Maranhão
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 安德烈·马拉尼亚奥
- en: '[https://www.kaggle.com/andrewmvd](https://www.kaggle.com/andrewmvd)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/andrewmvd](https://www.kaggle.com/andrewmvd)'
- en: We spoke to Andrew Maranhão (aka Larxel), Datasets Grandmaster (number 1 in
    Datasets at time of writing) and Senior Data Scientist at the Hospital Albert
    Einstein in São Paulo, about his rise to Datasets success, his tips for creating
    datasets, and his general experiences on Kaggle.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采访了安德烈·马拉尼亚奥（又名Larxel），数据集大师（在撰写本文时数据集排名第一）和圣保罗艾伯特·爱因斯坦医院的资深数据科学家，关于他如何取得数据集的成功，他创建数据集的技巧以及他在Kaggle上的总体经验。
- en: What’s your favourite kind of competition and why? In terms of techniques and
    solving approaches, what is your specialty on Kaggle?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你最喜欢的比赛类型是什么？为什么？在技术和解决方法方面，你在Kaggle上的专长是什么？
- en: '*Medical imaging is usually my favourite. It speaks to my purpose and job.
    Among medical competitions, NLP is language-bound, tabular data varies widely
    among hospitals, but imaging is mostly the same, so any advancement in this context
    can bring about benefits for many countries across the world, and I love this
    impact potential. I also have a liking for NLP and tabular data, but I suppose
    this is pretty standard.*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*医学影像通常是我在Kaggle上最喜欢的。它与我的人生目标和职业相关。在医学竞赛中，NLP受语言限制，表格数据在医院之间差异很大，但影像学大多是相同的，因此在这个背景下任何进步都可以为世界上的许多国家带来好处，我热爱这种影响潜力。我也喜欢NLP和表格数据，但我想这很常见。*'
- en: Tell us about a particularly challenging competition you entered, and what insights
    you used to tackle the task.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 告诉我们你参加的一个特别具有挑战性的比赛，以及你用来应对任务的见解。
- en: '*In a tuberculosis detection in x-ray images competition, we had around 1,000
    images, which is a pretty small number for capturing all the manifestations of
    the disease. I came up with two ideas to offset this:*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*在X光图像结核病检测比赛中，我们有大约1,000张图像，这对于捕捉疾病的全部表现来说数量相当少。我提出了两个想法来弥补这一点：*'
- en: '*Pre-train on external data of pneumonia detection (~20k images), as pneumonia
    can be mistaken for tuberculosis.*'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在外部肺炎检测数据（约20k张图像）上进行预训练，因为肺炎可能会被误诊为肺结核。*'
- en: '*Pre-train on multilabel classification of lung abnormalities (~600k images)
    and use grad-CAM with a simple SSD to generate bounding box annotations of classification
    labels.*'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在肺异常的多标签分类（约600k张图像）上进行预训练，并使用简单的SSD与grad-CAM生成分类标签的边界框注释。*'
- en: '*In the end, a simple blend of these two achieved 22% more compared to the
    result that the second-place team had. It happened at a medical convention, with
    about 100 teams participating.*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*最终，这两种简单混合的方法比第二名团队的结果高出22%。这发生在一次医学会议上，大约有100个团队参加。*'
- en: You have become a Dataset Grandmaster and achieved the number 1 rank in Datasets.
    How do you choose topics and find, gather, and publish data for your datasets
    on Kaggle?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成为数据集大师，并在数据集上取得了第一名。你是如何选择主题，以及如何在Kaggle上找到、收集和发布数据集的？
- en: '*This is a big question; I’ll try to break it down piece by piece.*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*这是一个很大的问题；我会一点一点地把它分解。*'
- en: '**Set yourself a purpose**'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设定自己的目标**'
- en: '*The first thing that I have in mind when choosing a topic is the reason I
    am doing this in the first place.*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*在选择主题时，我首先考虑的是我最初为什么要做这件事。*'
- en: '*When there is a deeper reason underneath, great datasets just come off as
    a result, not as a goal in itself. Fei Fei Li, the head of the lab that created
    ImageNet, revealed in a TED talk that she* *wanted to create a world where machines
    would be able to reason and appreciate the world with their vision in the same
    way her children did.*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*当有一个更深层次的原因时，伟大的数据集只是作为一个结果出现，而不是作为一个目标本身。ImageNet创建实验室的负责人李飞飞在TED演讲中透露，她*
    *希望创造一个世界，机器能够用他们的视觉以她孩子的方式推理和欣赏世界。*'
- en: '*Having a purpose in mind will make it more likely that you’ll engage and improve
    over time, and will also differentiate you and your datasets. You can certainly
    live off tabular data on everyday topics, though I find that unlikely to leave
    a lasting impact.*'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*有一个目的在心中会使你更有可能参与并随着时间的推移而改进，这也会使你和你数据集与众不同。你当然可以靠日常主题的表格数据为生，尽管我发现这不太可能留下持久的影响。*'
- en: '**A great dataset is the embodiment of a great question**'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一个伟大的数据集是一个伟大问题的体现**'
- en: '*If we look at the greatest datasets in current literature, such as ImageNet
    and others, we can see some common themes:*'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果我们看看当前文献中最伟大的数据集，比如ImageNet和其他数据集，我们可以看到一些共同的主题：*'
- en: '*It is a daring, relevant question with great potential for all of us (scientific
    or real-world application)*'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*这是一个大胆、相关的问题，对我们所有人（科学或现实世界应用）都有巨大的潜力。*'
- en: '*The data was well collected, controlled for quality, and well documented*'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据收集得很好，质量得到控制，并且有很好的记录*'
- en: '*There is an adequate amount of data and diversity for our current hardware*'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*当前硬件的数据量和多样性是足够的*'
- en: '*It has an active community that continuously improves the data and/or builds
    upon that question*'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*它有一个活跃的社区，不断改进数据并/或在此基础上构建问题*'
- en: '*As I mentioned before, I feel that asking questions is a primary role of a
    data scientist and is likely to become even more prominent as automated machine
    and deep learning solutions advance. This is where datasets can certainly exercise
    something unique to your skillset.*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*正如我之前提到的，我认为提问是数据科学家的主要角色，并且随着自动机器学习和深度学习解决方案的进步，它可能会变得更加突出。这正是数据集可以肯定地发挥你技能的独特之处。*'
- en: '**Create your process for success, rather than only pursuing success for the
    sake of success**'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创造你的成功过程，而不仅仅是追求成功本身**'
- en: '*Quality far overshadows quantity; you only need 15 datasets to become a Grandmaster
    and the flagship datasets of AI are few and well made.*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*质量远远超过数量；你只需要15个数据集就可以成为大师，而AI的旗舰数据集很少且制作精良。*'
- en: '*I have thrown away as many datasets as I have published. It takes time, and
    it is not a one and done type of thing as many people treat it – datasets have
    a maintenance and continuous improvement side to them.*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*我已经丢弃了与我发布的同样多的数据集。这需要时间，而且它不是许多人所认为的一次性事情——数据集有维护和持续改进的一面。*'
- en: '*One thing that is very often overlooked is supporting the community that gathers
    around your data. Notebooks and datasets are mutual efforts, so supporting those
    who take the time to analyze your data goes a long way for your dataset too. Analyzing
    their bottlenecks and choices can give directions as to what pre-processing steps
    could be done and provided, and also the clarity of your documentation.*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*经常被忽视的一点是支持围绕你的数据聚集的社区。笔记本和数据集是共同努力的结果，因此支持那些花时间分析你数据的人对你的数据集也有很大的帮助。分析他们的瓶颈和选择可以为你提供指导，关于哪些预处理步骤可以完成和提供，以及你文档的清晰度。*'
- en: '*All in all, the process that I recommend starts with setting your purpose,
    breaking it down into objectives and topics, formulating questions to fulfil these
    topics, surveying possible sources of data, selecting and gathering, pre-processing,
    documenting, publishing, maintaining and supporting, and finally, improvement
    actions.*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '*总的来说，我推荐的过程是从设定你的目的开始，将其分解为目标和主题，制定问题以满足这些主题，调查可能的数据来源，选择和收集，预处理，记录，发布，维护和支持，最后是改进措施。*'
- en: '*For instance, let’s say that you would like to increase social welfare; you
    break it down into an objective, say, racial equity. From there, you analyze topics
    related to the objective and find the Black Lives Matter movement. From here,
    you formulate the question: how can I make sense of the millions of voices talking
    about it?*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*例如，假设你想要提高社会福利；你将其分解为一个目标，比如，种族平等。从那里，你分析与目标相关的主题，并找到“黑人的命也是命”运动。从这里，你提出问题：我如何理解数百万人在谈论它？*'
- en: '*This narrows down your data type to NLP, which you can gather data for from
    news articles, YouTube comments, and tweets (which you choose, as it seems more
    representative of your question and feasible). You pre-process the data, removing
    identifiers, and document the collection process and dataset purpose.*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*这缩小了你的数据类型到NLP，你可以从新闻文章、YouTube评论和推文中（你选择的，因为它似乎更能代表你的问题和可行性）收集数据。你预处理数据，去除标识符，并记录收集过程和数据集用途。*'
- en: '*With that done, you publish it, and a few Kagglers attempt topic modeling
    but struggle to do so because some tweets contain many foreign languages that
    create encoding problems. You* *support them by giving them advice and highlighting
    their work, and decide to go back and narrow the tweets down to English, to fix
    this for good.*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*完成这些后，你发布它，一些Kagglers尝试主题建模，但很难做到，因为一些推文中包含许多外语，这造成了编码问题。你通过提供建议和突出他们的工作来支持他们，并决定回到推文，将其缩小到英语，以彻底解决这个问题。*'
- en: '*Their analysis reveals the demands, motivations, and fears relating to the
    movement. With their efforts, it was possible to break down millions of tweets
    into a set of recommendations that may improve racial equity in society.*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*他们的分析揭示了与运动相关的需求、动机和恐惧。通过他们的努力，有可能将数百万条推文分解成一系列可能改善社会种族平等的建议。*'
- en: 4. **Doing a good job is all that is in your control**
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 4. **做好工作是你在控制范围内的所有事情*
- en: '*Ultimately, it is other people that turn you into a Grandmaster, and votes
    don’t always translate into effort or impact. In one of my datasets, about Cyberpunk
    2077, I worked on it for about 40 hours total and, to this day, it is still one
    of my least upvoted datasets.*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*最终，是其他人让你成为大师，投票并不总是转化为努力或影响。在我的一个关于《赛博朋克2077》的数据集中，我总共工作了大约40小时，时至今日，它仍然是我最少点赞的数据集之一。*'
- en: '*But it doesn’t matter. I put in the effort, I tried, and I learned what I
    could — that’s what is in my control, and next week I’ll do it again no matter
    what. Do your best and keep going.*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*但这没关系。我付出了努力，我尝试了，我学到了我能学到的东西——那是我能控制的，下周无论发生什么，我都会再次尝试。尽你所能，继续前进。*'
- en: Are there any particular tools or libraries that you would recommend using for
    data analysis/machine learning?
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你会推荐哪些特定的工具或库用于数据分析/机器学习？
- en: '*Strangely enough, I both* *recommend and unrecommend libraries. LightGBM is
    a great tabular ML library with a fantastic ratio of performance to compute time,
    CatBoost can sometimes outperform it, but it comes at the cost of increased compute
    time, during which you could be having and testing new ideas. Optuna is great
    for hyperparameter tuning, Streamlit for frontends, Gradio for MVPs, Fast API
    for microservices, Plotly and Plotly Express for charts, PyTorch and its derivatives
    for deep learning.*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*奇怪的是，我既推荐也不建议使用库。LightGBM是一个出色的表格机器学习库，具有出色的性能与计算时间的比率，CatBoost有时可以超越它，但代价是增加了计算时间，在这段时间里，你可以尝试和测试新的想法。Optuna非常适合超参数调整，Streamlit适用于前端，Gradio适用于MVP，Fast
    API适用于微服务，Plotly和Plotly Express适用于图表，PyTorch及其衍生品适用于深度学习。*'
- en: '*While libraries are great, I also suggest that at some point in your career
    you take the time to implement it yourself. I first heard this advice from Andrew
    Ng and then from many others of equal calibre. Doing this creates very in-depth
    knowledge that sheds new light on what your model does and how it responds to
    tuning, data, noise, and more.*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*虽然图书馆很棒，但我还建议在职业生涯的某个阶段，你花些时间自己实现它。我第一次从Andrew Ng那里听到这个建议，后来又从许多同等水平的人那里听到。这样做可以创造非常深入的知识，这些知识可以让你对模型的功能以及它如何响应调整、数据、噪声等有新的认识。*'
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的经验中，不经验的Kagglers经常忽视什么？你现在知道什么，而你在最初开始时希望知道的呢？
- en: '*Over the years, the things I wished I realized sooner the most were:*'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*多年来，我最希望早点意识到的事情是：*'
- en: '*Absorbing all the knowledge at the end of a competition*'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在竞赛结束时吸收所有知识*'
- en: '*Replication of winning solutions in finished competitions*'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在完成竞赛中复制获胜的解决方案*'
- en: '*In the pressure of a competition drawing to a close, you can see the leaderboard
    shaking more than ever before. This makes it less likely that you will take risks
    and take the time to see things in all their detail. When a competition is over,
    you don’t have that rush and can take as long as you need; you can also replicate
    the rationale of the winners who made their solutions known.*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*在一场即将结束的竞争压力下，你可以看到排行榜比以往任何时候都更加动荡。这使得你不太可能冒险，也不太愿意花时间去细致观察。当比赛结束后，你不再有那种紧迫感，可以花尽可能多的时间去思考；你也可以复制获胜者的逻辑，让他们知道他们的解决方案。*'
- en: '*If you have the discipline, this will do wonders for your data science skills,
    so the bottom line is: stop when you are done, not when the competition ends.
    I have also heard this advice from an Andrew Ng keynote, where he recommended
    replicating papers as one of his best ways to develop yourself as an AI practitioner.*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你有自律，这将对你的数据科学技能产生神奇的效果，所以底线是：在你完成时停止，而不是在比赛结束时停止。我还从Andrew Ng的闭幕演讲中听到过这个建议，他建议复制论文是他作为AI实践者自我发展的最佳方式之一。*'
- en: '*Also, at the end of a competition , you are likely to be exhausted and just
    want to call it a day. No problem there; just keep in mind that the discussion
    forum after the competition is done is one of the most knowledge-rich places on
    Planet Earth, primarily because* *many rationales and code for winning solutions
    are made public there. Take the time to read and study what the winners did; don’t
    give into the desire to move on to something else, as you might miss a great learning
    opportunity.*'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*此外，在比赛结束时，你可能会感到筋疲力尽，只想结束这一天。没问题；但请记住，比赛结束后，讨论论坛是地球上知识最丰富的地方之一，主要是因为* *许多获胜解决方案的理据和代码都公开发布在那里。花时间去阅读和学习获胜者所做的事情；不要屈服于想要转向其他事物的欲望，因为你可能会错过一个极好的学习机会。*'
- en: Has Kaggle helped you in your career? If so, how?
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle是否帮助了你的职业生涯？如果是的话，是如何帮助的？
- en: '*Kaggle helped my career by providing a wealth of knowledge, experience and
    also building my portfolio. My first job as a data scientist was largely due to
    Kaggle and DrivenData competitions. All throughout my career, I studied competition
    solutions and participated in a few more. Further engagement on Datasets and Notebooks
    also proved very fruitful in learning new techniques and asking better questions.*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*Kaggle通过提供丰富的知识、经验和建立我的作品集来帮助了我的职业生涯。我作为数据科学家的第一份工作很大程度上得益于Kaggle和DrivenData竞赛。在我的整个职业生涯中，我研究了竞赛解决方案，并参与了一些更多的竞赛。在数据集和笔记本上的进一步参与也在学习新技术和提出更好的问题方面证明非常有益。*'
- en: '*In my opinion, asking great questions is the primary challenge faced by a
    data scientist. Answering them is surely great as well, although I believe we
    are not far from a future where automated solutions will be more and more prevalent
    in modeling. There will always be room for modeling, but I suppose a lot of work
    will be streamlined in that regard. Asking great questions, however, is far harder
    to automate – if the question is not good, even the best solution could be meaningless.*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*在我看来，提出优秀问题是数据科学家面临的主要挑战。回答它们当然也很棒，尽管我相信我们离一个自动化解决方案在建模中越来越普遍的未来并不遥远。建模始终有空间，但我认为在这方面会有很多工作流程简化。然而，提出优秀问题要远比自动化困难——如果问题本身不好，即使是最好的解决方案也可能毫无意义。*'
- en: Have you ever used something you have done in Kaggle competitions in order to
    build your portfolio to show to potential employers?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾使用在Kaggle竞赛中完成的项目来构建你的作品集，以展示给潜在雇主？
- en: '*Absolutely. I landed my first job as a data scientist in 2017 using Kaggle
    as proof of knowledge. To this day, it is still a fantastic CV component, as educational
    backgrounds and degrees are less representative of data science knowledge and
    experience than a portfolio is.*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*绝对如此。我于2017年通过Kaggle作为知识证明，获得了我的第一份数据科学家工作。时至今日，它仍然是一个极好的简历组成部分，因为教育背景和学位在数据科学知识和经验方面不如作品集来得有代表性。*'
- en: '*A portfolio with projects with competitions shows not just added experience
    but also a willingness to going above and beyond for development, which is arguably
    more important for long-term success.*'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*拥有竞赛项目的作品集不仅展示了额外的经验，还显示了超越常规进行发展的意愿，这在长期成功中可能更为重要。*'
- en: Do you use other competition platforms? How do they compare to Kaggle?
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用其他竞赛平台吗？它们与Kaggle相比如何？
- en: '*I also use DrivenData and AICrowd. The great thing about them is that they
    allow organizations that don’t have the same access to financial resources, such
    as start-ups and research institutions, to create competitions.*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*我也使用 DrivenData 和 AICrowd。它们的好处是允许那些没有相同财务资源访问权的组织，如初创公司和研究机构，创建比赛。*'
- en: '*Great competitions come from a combination of great questions and great data,
    and this can happen regardless of company size. Kaggle has a bigger and more active
    community, and the* *hardware they provide, coupled with the data and Notebook
    capabilities, make it the best option; yet both DrivenData and AICrowd introduce
    just as interesting challenges and allow for more diversity.*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*伟大的竞赛来自于优秀的问题和优秀的数据的结合，这无论公司规模大小都是可能的。Kaggle 拥有一个更大、更活跃的社区，以及他们提供的硬件，结合数据集和笔记本功能，使其成为最佳选择；然而，DrivenData
    和 AICrowd 也提供了同样有趣挑战，并允许更多样化的选择。*'
- en: What’s the most important thing someone should keep in mind or do when they’re
    entering a competition?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当人们参加比赛时，他们应该记住或做什么最重要的事情？
- en: '*Assuming your primary goal is development, my recommendation is that you pick
    a competition on a topic that interests you and a task that you haven’t done before.
    Critical sense and competence require depth and diversity. Focusing and giving
    your best will guarantee depth, and diversity is achieved by doing things you
    have not done before or have not done in the same way.*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设你的主要目标是开发，我的建议是选择一个你感兴趣的主题和之前没有做过的任务的比赛。批判性思维和技能需要深度和多样性。专注于并全力以赴将保证深度，而多样性是通过做你以前没有做过的事情或以不同的方式做事情来实现的。*'
- en: Working with datasets
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与数据集一起工作
- en: Once you have created a dataset, you probably want to use it in your analysis.
    In this section, we discuss different methods of going about this.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你创建了一个数据集，你可能希望将其用于你的分析。在本节中，我们将讨论不同的实现方法。
- en: 'Very likely, the most important one is starting a Notebook where you use your
    dataset as a primary source. You can do this by going to the dataset page and
    then clicking on **New Notebook**:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，最重要的是在参加比赛时，应该记住或做的事情是开始一个笔记本，其中你使用你的数据集作为主要来源。你可以通过访问数据集页面，然后点击**新建笔记本**来完成：
- en: '![](img/B17574_02_07.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17574_02_07.png)'
- en: 'Figure 2.7: Creating a Notebook from the dataset page'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7：从数据集页面创建笔记本
- en: 'Once you have done this, you will be redirected to your **Notebook** page:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些操作后，你将被重定向到你的**笔记本**页面：
- en: '![Obraz zawierający tekst  Opis wygenerowany automatycznie](img/B17574_02_08.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本的图像 自动生成的描述](img/B17574_02_08.png)'
- en: 'Figure 2.8: Starting a Notebook using your dataset'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8：使用你的数据集开始笔记本
- en: 'Here are a few pointers around this:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这一点，这里有一些提示：
- en: The alphanumeric title is generated automatically; you can edit it by clicking
    on it.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阿拉伯数字和字母标题是自动生成的；你可以通过点击它来编辑它。
- en: On the right-hand side under **Data**, you see the list of data sources attached
    to your Notebook; the dataset I selected can be accessed under `../input/` or
    from `/kaggle/input/`.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在右侧的**数据**部分，你可以看到附加到你的笔记本上的数据源列表；我选择的数据集可以在`../input/`或`/kaggle/input/`下访问。
- en: The opening block (with the imported packages, descriptive comments, and printing
    the list of available files) is added automatically to a new Python Notebook.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开头块（包含导入的包、描述性注释和打印可用文件列表）会自动添加到新的 Python 笔记本中。
- en: With this basic setup, you can start to write a Notebook for your analysis and
    utilize your dataset as a data source. We will discuss Notebooks at greater length
    in *Chapter 4*, *Leveraging Discussion Forums*.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个基本设置下，你可以开始编写用于分析的笔记本，并将你的数据集作为数据源使用。我们将在*第4章*，*利用讨论论坛*中更详细地讨论笔记本。
- en: Using Kaggle Datasets in Google Colab
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Google Colab 中使用 Kaggle 数据集
- en: 'Kaggle Notebooks are free to use, but not without limits (more on that in *Chapter
    4*), and the first one you are likely to hit is the time limit. A popular alternative
    is to move to Google Colab, a free Jupyter Notebook environment that runs entirely
    in the cloud: [https://colab.research.google.com](https://colab.research.google.com).'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle 笔记本免费使用，但并非没有限制（更多内容请见*第4章*），你很可能会遇到的时间限制。一个流行的替代方案是迁移到 Google Colab，这是一个完全在云端运行的免费
    Jupyter Notebook 环境：[https://colab.research.google.com](https://colab.research.google.com)。
- en: Even once we’ve moved the computations there, we might still want to have access
    to the Kaggle datasets, so importing them into Colab is a rather handy feature.
    The remainder of this section discusses the steps necessary to use Kaggle Datasets
    through Colab.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们将计算移动到那里，我们可能仍然需要访问 Kaggle 数据集，因此将它们导入 Colab 是一个相当方便的功能。本节剩余部分将讨论使用 Colab
    通过 Kaggle 数据集所需的步骤。
- en: 'The first thing we do, assuming we are already registered on Kaggle, is head
    to the account page to generate the **API token** (an access token containing
    security credentials for a login session, user identification, privileges, and
    so on):'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经在 Kaggle 上注册，我们首先去账户页面生成**API 令牌**（一个包含登录会话安全凭证、用户标识、权限等的访问令牌）：
- en: 'Go to your account, which can be found at `https://www.kaggle.com/USERNAME/account`,
    and click on **Create New API Token**:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往你的账户，可以在 `https://www.kaggle.com/USERNAME/account` 找到，然后点击**创建新的 API 令牌**：
- en: '![Obraz zawierający tekst  Opis wygenerowany automatycznie](img/B17574_02_09.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本的图片 自动生成的描述](img/B17574_02_09.png)'
- en: 'Figure 2.9: Creating a new API token'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9：创建新的 API 令牌
- en: A file named kaggle.json containing your username and token will be created.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 将包含你的用户名和令牌的名为 kaggle.json 的文件创建出来。
- en: 'The next step is to create a folder named `Kaggle` in your Google Drive and
    upload the `.json` file there:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是在你的 Google Drive 中创建一个名为 `Kaggle` 的文件夹，并将 `.json` 文件上传到那里：
- en: '![](img/B17574_02_10.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B17574_02_10.png]'
- en: 'Figure 2.10: Uploading the .json file into Google Drive'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10：将 .json 文件上传到 Google Drive
- en: 'Once done, you need to create a new Colab notebook and mount your drive by
    running the following code in the notebook:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，你需要在 Colab 中创建一个新的笔记本，并通过在笔记本中运行以下代码来挂载你的驱动器：
- en: '[PRE0]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Get the authorization code from the URL prompt and provide it in the empty
    box that appears, and then execute the following code to provide the path to the
    `.json` config:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 URL 提示中获取授权代码，并在出现的空框中提供，然后执行以下代码以提供 `.json` 配置的路径：
- en: '[PRE1]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can download the dataset now. Begin by going to the dataset’s page on Kaggle,
    clicking on the three dots next to **New Notebook**, and selecting **Copy API
    command**:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以下载数据集了。首先前往数据集在 Kaggle 上的页面，点击**新建笔记本**旁边的三个点，然后选择**复制 API 命令**：
- en: '![](img/B17574_02_11.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B17574_02_11.png]'
- en: 'Figure 2.11: Copying the API command'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11：复制 API 命令
- en: 'Run the API command to download the Dataset (readers interested in details
    of the commands used can consult the official documentation: [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api))
    :'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 API 命令以下载数据集（对命令细节感兴趣的读者可以查阅官方文档：[https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api)）：
- en: '[PRE2]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The dataset will be downloaded to the `Kaggle` folder as a `.zip` archive –
    unpack it and you are good to go.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集将以 `.zip` 归档的形式下载到 `Kaggle` 文件夹中——解压后即可使用。
- en: As you can see from the list above, using a Kaggle dataset in Colab is a straightforward
    process – all you need is an API token, and making the switch gives you the possibility
    of using more GPU hours than what is granted by Kaggle.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如上表所示，在 Colab 中使用 Kaggle 数据集是一个简单的过程——你只需要一个 API 令牌，切换后你就有可能使用比 Kaggle 授予的更多
    GPU 小时数。
- en: Legal caveats
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 法律免责声明
- en: 'Just because you can put some data on Kaggle does not necessarily mean that
    you should. An excellent example would be the *People of Tinder* dataset. In 2017,
    a developer used the Tinder API to scrape the website for semi-private profiles
    and uploaded the data on Kaggle. After the issue became known, Kaggle ended up
    taking the dataset down. You can read the full story here: [https://www.forbes.com/sites/janetwburns/2017/05/02/tinder-profiles-have-been-looted-again-this-time-for-teaching-ai-to-genderize-faces/?sh=1afb86b25454](https://www.forbes.com/sites/janetwburns/2017/05/02/tinder-profiles-have-been-looted-again-this-time-for-teaching-ai-to-genderize-faces/?sh=1afb86b25454).'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 只因为你可以在 Kaggle 上放置一些数据，并不意味着你一定应该这样做。一个很好的例子是 *Tinder 的人* 数据集。2017 年，一位开发者使用
    Tinder API 爬取了网站上的半私密资料，并将数据上传到了 Kaggle。问题曝光后，Kaggle 最终将该数据集下架。你可以在这里阅读完整的故事：[https://www.forbes.com/sites/janetwburns/2017/05/02/tinder-profiles-have-been-looted-again-this-time-for-teaching-ai-to-genderize-faces/?sh=1afb86b25454](https://www.forbes.com/sites/janetwburns/2017/05/02/tinder-profiles-have-been-looted-again-this-time-for-teaching-ai-to-genderize-faces/?sh=1afb86b25454)。
- en: 'In general, before you upload anything to Kaggle, ask yourself two questions:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在将任何内容上传到 Kaggle 之前，问问自己两个问题：
- en: '**Is it allowed from a copyright standpoint?** Remember to always check the
    licenses. When in doubt, you can always consult [https://opendefinition.org/guide/data/](https://opendefinition.org/guide/data/)
    or contact Kaggle.'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**从版权角度来看，这是否允许？** 记得始终检查许可证。如有疑问，您始终可以咨询[https://opendefinition.org/guide/data/](https://opendefinition.org/guide/data/)或联系Kaggle。'
- en: '**Are there privacy risks associated with this dataset?** Just because posting
    certain types of information is not, strictly speaking, illegal, doing so might
    be harmful to another person’s privacy.'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**这个数据集是否有隐私风险？** 仅因为发布某些类型的信息在严格意义上并不违法，但这可能对另一人的隐私造成伤害。'
- en: The limitations speak to common sense, so they are not too likely to hamper
    your efforts on Kaggle.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这些限制符合常识，因此不太可能妨碍您在Kaggle上的努力。
- en: Summary
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we introduced Kaggle Datasets, the standardized manner of
    storing and using data in the platform. We discussed dataset creation, ways of
    working outside of Kaggle, and the most important functionality: using a dataset
    in your Notebook. This provides a good segue to our next chapter, where we focus
    our attention on Kaggle Notebooks.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了Kaggle数据集，这是在平台上存储和使用数据的标准化方式。我们讨论了数据集创建、在Kaggle之外工作的方法以及最重要的功能：在您的笔记本中使用数据集。这为我们下一章提供了一个很好的过渡，我们将重点关注Kaggle笔记本。
- en: Join our book’s Discord space
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们本书的Discord空间
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 加入本书的Discord工作空间，参加每月一次的作者“问我任何问题”活动：
- en: '[https://packt.link/KaggleDiscord](https://packt.link/KaggleDiscord)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/KaggleDiscord](https://packt.link/KaggleDiscord)'
- en: '![](img/QR_Code40480600921811704671.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code40480600921811704671.png)'
