- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML APIs for Vision, NLP, and Speech
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Research teams at Google have put their decades of research and experience into
    creating state-of-the-art solutions for many complex problems. Some of these solutions,
    which include Vision AI, Translation AI, Natural Language AI, and Speech AI, are
    quite general-purpose and can be readily leveraged to get insights from complex
    and unstructured data. These solutions are provided as a service and thus as customers,
    we don’t have to worry about managing the infrastructure, availability, or scaling
    of these products. Many popular Google products, such as Maps, Photos, Gmail,
    YouTube, and others make use of these products every day to provide AI-driven
    experiences.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at some of these popular offerings and understand
    what kind of problems can be solved using them. The main topics that will be covered
    in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Vision AI on Google Cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translation AI on Google Cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Natural Language AI on Google Cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speech AI on Google Cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vision AI on Google Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Computer vision is a field of **artificial intelligence** (**AI**) that enables
    computers and systems to derive insights from visual data such as digital images
    and videos. Understanding images and videos is a complex task, but with never-ending
    research in the field, the AI research community has led to the development of
    many smart ways of getting information out of unstructured data, such as images
    and videos. Information extracted from digital images and videos can be leveraged
    by businesses to take action and provide recommendations at scale. Google Cloud
    provides the following two offerings as a platform to solve computer vision problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Vision AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Video AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s deep dive into each of these offerings.
  prefs: []
  type: TYPE_NORMAL
- en: Vision AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Google Vision AI provides a platform for creating vision-based applications
    with pre-trained APIs, AutoML, or custom models. Using Vision AI, we can create
    image and video analytics solutions in just a few minutes. This offering allows
    us to train our custom classification or object detection models using AutoML,
    and it also allows us to train fully custom models. Vision AI provides pre-trained
    APIs for common vision tasks such as objection detection, handwriting recognition,
    image metadata creation, and more. There are three common offerings under the
    Google Vision AI platform:'
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI Vision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom ML models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vision API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a closer look at them.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex AI Vision
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Vertex AI Vision is a fully managed end-to-end application development environment,
    using which we can quickly prototype vision solutions that fit our business needs.
    Vertex AI Vision can help us solve complex problems and create valuable solutions
    within minutes, hence saving a lot of development costs. Vertex AI Vision allows
    us to ingest real-time streams of videos and images at a massive scale to support
    real-time production use cases. The interface for application development is also
    very simple and lets us build applications quickly with drag-and-drop functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at the Vertex AI Vision interface within the Google Cloud
    console. Make sure you enable Vision API first and then navigate to Vertex AI
    Vision from the left pane. Alternatively, you can find it by searching for it
    at the top. The interface should look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.1 – Vertex AI Vision interface](img/B17792_14_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.1 – Vertex AI Vision interface
  prefs: []
  type: TYPE_NORMAL
- en: We can now start building our application by clicking on the **CREATE APPLICATION**
    button, after which we’ll be asked to provide a unique name for the application.
    Once we click on **Create**, we’ll be taken to the application development studio,
    where we can find different options for using pre-trained or specialized models
    based on our application needs. The interface is quite simple and lets us build
    applications with drag-and-drop functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows a simple object-detection and tag-recognizer
    application that takes input from a GCS bucket. After performing this task, it
    writes the output to a Vision AI Warehouse location. We have configured this application
    for batch prediction and hence the input source is a GCS bucket with images, but
    we have other options for input types, such as streaming or live prediction use
    cases. Let’s take a look at the studio interface and our sample application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.2 – Vertex AI Vision studio for rapid application creation](img/B17792_14_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.2 – Vertex AI Vision studio for rapid application creation
  prefs: []
  type: TYPE_NORMAL
- en: This application graph can be deployed with the click of a button, and we will
    be able to start using it in production within minutes. Vertex AI Vision provides
    a few powerful pre-trained models as well as some specialized models that are
    ready to be deployed. It also gives us the flexibility to import or create custom
    models using Vertex custom training. While deploying the vision application, we
    also get the option to choose a streaming output type so that we can enable model
    monitoring for our application.
  prefs: []
  type: TYPE_NORMAL
- en: Custom ML models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Vision AI supports custom ML model creation for more specialized use cases.
    We can use one of the following methods to create a specialized model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AutoML**: The easy-to-use graphical interface of AutoML within Vertex AI
    lets us train our custom models with minimal effort and technical knowledge. With
    AutoML, we can train image or video intelligence models by simply uploading the
    training files. We can also optimize our models for latency, size, and accuracy
    as per our requirements. At the time of writing, AutoML supports object detection
    and classification models for image data and object tracking, action recognition,
    and classification for video data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Custom training**: Custom training is useful when AutoML doesn’t support
    our use case. It requires more effort as well as technical depth. Custom training
    lets us choose the desired model development framework, the types of VMs for launching
    training jobs, and various types of accelerators based on training needs. With
    custom training, we can train our specialized models for different complex use
    cases and deploy them for real-time, streaming, or batch-prediction use cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we’ll learn about the Vision API.
  prefs: []
  type: TYPE_NORMAL
- en: Vision API
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Vision API provides powerful pre-trained ML models for tasks such as reading
    printed or handwritten text from an image, detecting objects, classifying images
    into millions of pre-defined categories, tagging explicit content, and more. Vision
    API models can be consumed through REST and RPC APIs. Solutions such as detecting
    text from images can be combined with other solutions such as translation to create
    more complex solutions for batch, stream, or live prediction tasks in production.
    The official Vision API documentation provides numerous code examples for rapid
    prototyping of vision solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Video AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Video AI is specifically designed to analyze video data at scale to understand
    the inherent content, objects, places, or actions in a given input video. It can
    support real-time use cases with streaming video annotation and object-based event-triggering
    mechanisms to gain insights from data. Video AI can extract useful metadata from
    a video at the shot, frame, or video level. The following are a few common use
    cases from Video AI:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Content moderation**: Identify inappropriate content shown in videos at scale.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recommendation**: We can use outputs of video intelligence AI and combine
    them with user viewing history to provide content recommendations at scale'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Media archiving**: We can use metadata extracted from Video Intelligence
    API to efficiently store media so that it can be retrieved faster as needed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Advertisements**: We can identify the best places to put contextual advertisements
    within a video'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are two common ways to start developing video AI solutions on Google Cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: AutoML Video Intelligence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Video Intelligence API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a closer look at them.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML Video Intelligence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sometimes, there are use cases where we want to identify certain kinds of objects
    or events within a video that are not inherently covered by Video Intelligence
    API. In such cases, we can develop our custom models to identify and track various
    new objects within videos. AutoML makes it easier to train custom video intelligence
    models without requiring much ML experience with the help of its graphical user
    interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the time of writing, AutoML Video Intelligence supports the following use
    cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Action recognition**: In this use case, the solution analyzes a video and
    returns a list of pre-defined actions performed within the time frame in which
    the action happened. It can identify actions such as a soccer goal, a high-five,
    and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Classification**: A classification model can categorize videos into a list
    of pre-defined categories such as sports videos, cartoons, movies, and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object tracking**: We can train a model to continuously track certain objects
    within a video – for example, we can track a soccer ball in a live-running soccer
    match.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If AutoML doesn’t fit our needs, we can always go back to Vertex AI custom model
    development and train custom video intelligence models that fit our use case.
    Custom training gives us the flexibility to define our custom model architectures,
    types of VMs to train models on, and the types of accelerators to use for training.
    However, it requires more technical depth and effort to develop the solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good idea of image and video intelligence solutions, let’s
    look into Translation AI solutions, which can also be combined with various image
    and video use cases to solve more complex business problems.
  prefs: []
  type: TYPE_NORMAL
- en: Translation AI on Google Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As its name suggests, Translation AI on Google Cloud is an offering that can
    be utilized to create applications with multi-lingual content with fast and dynamic
    machine translation. Multi-lingual content can help businesses take their products
    to global markets and engage with global audiences. Its real-time translation
    capabilities provide a seamless experience. Let’s take a look at translation-related
    offerings on Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'Google Cloud provides three translation products:'
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Translation API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AutoML Translation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translation Hub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s deep dive into each of these products.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Translation API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Google Research has developed several **neural machine translation** (**NMT**)
    models over time and keeps improving them whenever there is better training data
    or improved techniques. The Cloud Translation API makes use of these pre-trained
    models or custom ML models to translate text from various source languages into
    target languages. With the Cloud Translation API, we can dynamically translate
    the contents of our websites or applications programmatically by just using API
    calls. By default, these pre-trained models do not use any customer data for training
    purposes. For a business or company that provides services or products globally,
    it is really important to have language translation capabilities to understand
    and engage the audience more effectively. The Cloud Translation API, as a product,
    addresses the problems of identifying a source language and translating it into
    the desired target language through an API call. It supports over 100 languages
    but if it still doesn’t fulfill your requirements, there are ways to train your
    custom models if you have training data with you. Now, let’s look at the AutoML
    Translation service for custom models.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML Translation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed before, the Cloud Translation API inherently supports over 100
    languages for translation, but if there is a need to support an additional language,
    we have the flexibility to train our custom models given that we have a sufficient
    amount of training data available with us. Training custom models is also helpful
    when there is a need to support domain-specific translations – for example, if
    we are working in a financial domain, we would like the translation solution to
    provide results that are more specific to the financial language.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML Translation inherently trains the state-of-the-art ML model architectures
    without us needing to put effort into developing our model architectures. We just
    need to prepare our input-output sentence pairs in the required format, after
    which AutoML will automatically find the best architecture and train a custom
    translation model for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check how it works within Cloud Console UI. If we go to the **Translation**
    tab from the left pane within Cloud Console, we will find a tab for creating datasets,
    as shown in *Figure 14**.3*. Here, we need to provide a unique name for our dataset
    with source and target languages. Once the dataset has been created, as shown
    in *Figure 14**.3*, we can start adding sentence pairs to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.3 – Creating a dataset for translation](img/B17792_14_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.3 – Creating a dataset for translation
  prefs: []
  type: TYPE_NORMAL
- en: 'After adding some data, we can review the dataset’s stats by clicking on the
    dataset, as shown in *Figure 14**.4*. As we can see, we have splits for training,
    validation, and test pairs. Once the AutoML model has been trained, we can check
    the metrics on the test dataset to check how good our custom model is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.4 – Reviewing the dataset for language translation](img/B17792_14_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.4 – Reviewing the dataset for language translation
  prefs: []
  type: TYPE_NORMAL
- en: 'Model training can be started by clicking the **START TRAINING** button, as
    shown in *Figure 14**.4*. As soon as the training is complete, we can find our
    trained models within the **Models** tab, which shows evaluation metrics on our
    test partition:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.5 – Custom-trained translation models with evaluation metrics](img/B17792_14_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.5 – Custom-trained translation models with evaluation metrics
  prefs: []
  type: TYPE_NORMAL
- en: After successfully training the model, we can get the translation outputs using
    different methods, such as REST API calls, or by calling the API using different
    development languages, including Python, Java, Go, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The following snippets show one sample API call to a custom translation model
    with the Python language. This sample can be found on the official documentation
    page of Google Translation AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows how to set up the translation service client and other
    configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we’re calling the API with proper language codes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we’re checking out the model’s response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Cloud Translation API itself or augmented with AutoML translation to support
    custom models is more suitable for use cases where dynamic or near real-time translation
    is required on demand. Now, let’s learn about Translation Hub, which can be more
    suitable for large-scale translation requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Translation Hub
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose there is an organization that deals with a very large volume of documents
    that need to be translated into many different languages quickly. Translation
    Hub is more suitable for such use cases as it is a fully managed solution where
    we don’t need to build any web application or set up infrastructure for this task.
    Another advantage of using Translation Hub is that it preserves the basic structure
    and layout of the documents while translating them into many different languages.
    It is quite easy to set up and inherently leverages Cloud Translation API and
    AutoML translation solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s discuss some benefits of using Translation Hub.
  prefs: []
  type: TYPE_NORMAL
- en: Self-serve translation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the past, the only way to translate documents was doing it manually, which
    was quite slow and required skilled multi-lingual professionals. Translation Hub,
    on the other hand, uses advancements in the field of AI to provide translation
    in more than 100 languages at super-fast speed. We can also keep human review
    as a post-processing step to improve any translations coming from the AI models.
    In this way, Translation Hub saves a lot of time and costs.
  prefs: []
  type: TYPE_NORMAL
- en: Document translation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Suppose we have documents in PDF or DOCX format – we can pass them directly
    to Translation Hub and there is no need to extract text from them beforehand.
    Additionally, Translation Hub preserves the original structure and format of the
    document (paragraph breaks, headings, and so on) which is really helpful.
  prefs: []
  type: TYPE_NORMAL
- en: Simplified administration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like other Google Cloud offerings, we can manage user access and portal access
    within Cloud Console UI. We can also easily create translation resources such
    as glossaries and translation memories.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous improvements
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Suppose we have human-in-the-loop to post-process translations; we can keep
    those post-edited translations within Translation Hub using translation memories.
    These translation memories can be reused later. Also, we can export these human-reviewed
    translation memories into a dataset and train a more accurate custom translation
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Page-based pricing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Translation Hub pricing is very straightforward as it charges based on the number
    of pages translated either from Translation API or AutoML-based custom models.
    There is no extra cost of deploying and maintaining custom models but the training
    of custom models is charged separately.
  prefs: []
  type: TYPE_NORMAL
- en: With that, we’ve seen that cloud-based translation is very useful for organizations
    dealing with large volumes of documents and reaching a global audience within
    their native languages. Next, let’s learn about the Natural Language AI product
    on Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Natural Language AI on Google Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Almost every organization deals with large amounts of text data in the form
    of text documents, forms, contracts, PDFs, web pages, user reviews, and so on.
    Google Cloud offers Natural Language AI, which leverages ML models to derive insights
    from unstructured text data. Natural Language AI is an end-to-end product that
    can help in extracting, analyzing, and storing text on Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'Google offers the following three natural language solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: AutoML for Text Analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Natural Language API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Healthcare Natural Language API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a closer look at each of these solutions.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML for Text Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine that there is an e-commerce company that receives customer queries related
    to a wide variety of issues, including payment failures, delivery address updates,
    product quality issues, and so on. As most of these queries are typed by customers
    in a text box, there is a need to classify these queries into a fixed set of categories
    so that they can be routed to the correct resolution team. Classifying these queries
    manually becomes quite difficult when the volume of such queries is large. This
    process can be automated using ML by training a classification model that can
    automatically categorize issues into appropriate categories.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML on Google Cloud supports training ML models to understand and analyze
    text data. The main advantage of using AutoML is that we don’t have to write any
    complex model architecture, model training, or evaluation code. With AutoML, we
    can train and evaluate ML models without writing any code. We can just go to the
    AutoML page on the Google Cloud console, upload our dataset in the required format,
    and start training the ML models.
  prefs: []
  type: TYPE_NORMAL
- en: 'AutoML currently supports the following three categories of text analysis use
    cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification**: Text classification refers to training ML models that accept
    text sentences or paragraphs as input and mapping them to a fixed set of categories
    as output. Vertex AI also supports multi-label classification, which means that
    a single input sentence can also be classified into multiple categories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Entity extraction**: An entity extraction model scans the text inputs to
    find and label pre-defined entities. These entities may include cities, countries,
    names, addresses, disease names, and so on. Entity extraction models are first
    trained on a fixed set of labeled entities and are then used to identify entities
    in unseen text paragraphs or sentences.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sentiment analysis**: A sentiment analysis model analyzes text data to identify
    the emotions within it. It classifies the text input into categories such as positive,
    negative, neutral, and so on. Sentiment analysis can help identify the emotions
    of customers from feedback forms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we understand how AutoML can help us, let’s discuss the Natural Language
    API.
  prefs: []
  type: TYPE_NORMAL
- en: Natural Language API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Natural Language API on Google Cloud provides prebuilt state-of-the-art
    solutions for various text analysis use cases such as sentiment analysis, entity
    extraction, classification, and more. As these solutions work with API requests,
    they can be quickly and easily integrated into any application. Google provides
    client libraries to use Natural Language API solutions to provide a better experience
    to developers by using each supported language’s styles and conventions. A quick
    example of using client libraries can be found on the official documentation page
    ([https://cloud.google.com/natural-language/docs/sentiment-analysis-client-libraries](https://cloud.google.com/natural-language/docs/sentiment-analysis-client-libraries)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The Natural Language API currently provides the following features to support
    different text analysis use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Entity extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Entity sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Syntactic analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Natural Language API is a REST API and thus supports the JSON response
    and request formats. A sample JSON request can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, a sample response for a sentiment analysis query may look very similar
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, the sentiment score varies from -1 (negative) to +1 (positive) and anything
    close to zero is neutral. The magnitude shows the strength of emotion, which can
    take any value from 0 to +inf.
  prefs: []
  type: TYPE_NORMAL
- en: Healthcare Natural Language API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Healthcare Natural Language API can be leveraged to derive real-time insights
    from unstructured medical text. Unstructured medical text present in medical records,
    discharge summaries, and insurance claim documents can be parsed into a structured
    data representation of medical knowledge entities using the Healthcare Natural
    Language API. Once this structured output is generated, we can pass it to various
    downstream applications or create automations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key features of the **Healthcare Natural Language API** are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: You can extract important medical concepts such as medications, procedures,
    diseases, medical devices, and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can extract medical insights from text that can be integrated with analytics
    products on Google Cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can map medical concepts to standard conventions such as RxNorm, ICD-10,
    MeSH, and others
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A sample response JSON from the Healthcare Natural Language API is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This kind of entity extraction and entity relationship extraction functionality
    can be very helpful for a healthcare company. Now that we have covered natural
    language-related offerings, let’s look into speech-related products next.
  prefs: []
  type: TYPE_NORMAL
- en: Speech AI on Google Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another important form of capturing and storing information is speech. Google
    has done decades of research to come up with state-of-the-art solutions for many
    speech and audio data-related use cases. A significant amount of critical information
    is present in the forms of audio calls and recorded messages and thus it becomes
    important to transcribe and extract useful insights from them. Also, there are
    voice assistant-related use cases that demand text-to-speech kind of functionality.
    Google Cloud offers several solutions for speech understanding and transcriptions.
    To help organizations tackle these use cases, Google has created the following
    product offerings related to speech data:'
  prefs: []
  type: TYPE_NORMAL
- en: Speech-to-Text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text-to-Speech
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s learn about each of them in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Speech-to-Text
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A good chunk of useful data is present in unstructured form, such as audio recordings,
    customer voice calls, videos, and so on, for many organizations. Thus, it becomes
    important to analyze this kind of data to extract actionable insights. Making
    use of such data is only possible if there is a way to accurately transcribe speech
    data into text format. Once our data has been converted into text format, we can
    train several NLP models to get useful business insights from it. Along similar
    lines, Google provides Speech-to-Text as a product offering to tackle the problem
    of accurately converting speech data into text. It can help organizations get
    better insights from their customer interactions and also provide a better experience
    by enabling the power of voice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some key use cases of Speech-to-Text are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Improving customer service**: Speech-to-Text can help organizations improve
    their customer interactions by enabling **interactive voice response** (**IVR**)
    and agent conversations in their call centers. They can also extract insights
    from conversational data and perform analytics. Speech-to-Text provides specialized
    ML models for transcribing low-quality phone calls very accurately.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enabling voice control**: Voice controls can enhance the user experience
    significantly when applied to **Internet of Things** (**IoT**) devices. Users
    can now interact with devices via voice commands such as *Increase* *the volume*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-media content**: Speech-to-Text allows audio and video to be transcribed
    on a near real-time basis so that we can incorporate captions to improve the audience
    reach and experience. Video transcription can also help us subtitle or index our
    video content. This feature is already being utilized by YouTube.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some key features of Google Speech-to-Text that enable the previously discussed
    use cases are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Speech adaptation**: The speech recognition model can be customized to recognize
    rare words or phrases by providing some hints to it. It can also turn spoken numbers
    into well-formatted addresses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Streaming speech recognition**: The Speech Recognition API supports real-time
    transcription, where audio might come directly from a microphone or pre-recorded
    file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Global vocabulary**: Speech-to-Text supports over 100 languages to support
    the global user base.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multichannel recognition**: Multichannel recordings from video conferences
    can also be annotated to preserve the order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Noise robustness**: Speech-to-Text can handle noisy recordings and still
    provide very accurate transcriptions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain adaptation**: Speech-to-Text provides some domain-adapted models as
    well. For example, phone call recordings are often low-quality audio files, and
    Google has specialized models for handling call recordings and providing very
    accurate transcriptions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Content filtering**: Speech-to-Text has functionality to detect and remove
    inappropriate words.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speaker diarization**: Speaker diarization is a problem that involves identifying
    which speaker spoke a phrase in a multi-speaker conversation. Google provides
    specialized models for speaker diarization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All these features make Speech-to-Text a very powerful and generic tool that
    can be easily integrated into any business use case. As this offering has API
    support, we don’t even have to write a single line of code to start using this
    solution. Next, let’s learn about another important speech-related solution: Text-to-Speech.'
  prefs: []
  type: TYPE_NORMAL
- en: Text-to-Speech
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As its name suggests, the Text-to-Speech offering converts text into natural-sounding
    speech. It can help in improving customer interactions with intelligent and lifelike
    responses. We can personalize customer communication by providing responses based
    on the customer’s preference of language and voice. We can also engage users with
    voice interactions through IoT devices (for example, Google Assistant).
  prefs: []
  type: TYPE_NORMAL
- en: 'Some key use cases of the Google Text-to-Speech offering are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Voicebots**: We can deliver a better customer experience by providing intelligent
    voice responses within our contact centers, instead of playing pre-recorded audio.
    Voicebots can provide customers with a more familiar and personalized sense.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Voice generation**: We can enable our IoT kind of devices to speak like humans
    for better communication. Text-to-Speech can be combined with Speech-to-Text and
    natural language solutions to provide a better end-to-end humanlike conversation
    experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Electronic program guides** (**EPGs**): The Text-to-Speech solution can power
    EPGs to read text out loud to provide a better user experience. We can enable
    blogs to read the news out loud.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To guide these interesting use cases, Google has developed the following key
    features as part of its Text-to-Speech offering:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Choice of language and voice**: Text-to-Speech currently supports over 200
    different types of voice with support of 40+ languages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**WaveNet Voices**: Google Deepmind’s groundbreaking research has enabled WaveNet
    to generate 90+ extremely human-like voices that close the gap with human performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Custom Voice**: We can enable our own voice in Google Text-to-Speech models
    by providing some voice recordings. This feature is currently in beta.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pitch Tuning**: We can tune the pitch of the selected voice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speaking Rate Tuning**: We get functionality to increase or decrease the
    speed of speaking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Audio format**: Text-to-Speech supports several audio formats to provide
    as output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Audio profiles**: We can also optimize the type of devices from which we
    need to play the audio, such as phone lines, headphones, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Warning
  prefs: []
  type: TYPE_NORMAL
- en: Custom Voice is currently a private feature within Vertex AI, so we will not
    be able to implement Custom Voice until we contact a member of the sales team.
    [https://cloud.google.com/contact](https://cloud.google.com/contact)
  prefs: []
  type: TYPE_NORMAL
- en: With all these features, Google Text-to-Speech can be easily integrated into
    applications that can send a REST or gRPC kind of request. Text-to-Speech APIs
    can be integrated with many different kinds of devices, including phones, tablets,
    PCs, and other IoT devices.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Not all the important data is present in a structured format. A significant
    amount of important information is found in unstructured forms such as audio,
    videos, documents, recordings, and so on. The progress that’s been made in ML
    has enabled us to analyze these unstructured data sources on a large scale to
    extract actionable insights and inform key business decisions. Google has worked
    on this ML research problem extensively to come up with state-of-the-art solutions
    for voice, vision, NLP, speech, and more.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we learned about different offerings from Google for understanding
    and extracting information from unstructured data formats, including audio, videos,
    images, documents, phone call recordings, and more. After reading this chapter,
    we should now have a good understanding of each of these offerings, including
    their key features and potential use cases. After discussing them in detail, we
    should now be able to find new use cases to apply these solutions to automate
    or enhance various business processes within an organization. In the next few
    chapters, we will learn how to build real-world ML solutions such as recommender
    systems and vision and NLP solutions on Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 4: Building Real-World ML Solutions with Google Cloud'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, you will explore examples of developing real-world ML solutions,
    using the tooling provided by Vertex AI in Google Cloud. These examples will show
    you how to build recommender systems, custom vision-based applications, and custom
    NLP-based solutions, using the ML tools within Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 15*](B17792_15.xhtml#_idTextAnchor221), *Recommender Systems – Predict
    What Movies a User Would Like to Watch*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 16*](B17792_16.xhtml#_idTextAnchor233), *Vision-Based Defect Detection
    System – Machines Can See Now*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 17*](B17792_17.xhtml#_idTextAnchor282), *Natural Language Models
    – Detecting Fake News Articles*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
