["```py\nfraction_of_positives, mean_pred_bin = calibration_curve( \\\n    y_true,probs, n_bins=8)\n```", "```py\nimport numpy as np\nfrom sklearn.metrics import brier_score_loss\ny_pred = np.array([0.1, 0.2,0.8,0.9])\ny_actual = np.array([1,0,0,1])\nbrier_score_loss(y_actual, y_pred)\n# order of parameters here is important!\n```", "```py\n0.37500000000000006\n```", "```py\ndf = pd.read_csv('HR_comma_sep.csv')\ndf\n```", "```py\nimport seaborn as sns\nprint(df['left'].value_counts())\ndf['left'].value_counts().plot(kind='bar')\n```", "```py\n0     11428\n1      3571\n```", "```py\nmodel = RandomForestClassifier(n_estimators=100, random_state=49)\nmodel.fit(X_train, y_train)\n```", "```py\n# Get model probabilities on test set(uncalibrated model)\nprobs_uncalibrated = model.predict_proba(X_test)[:, 1]\n# Calculate Brier score for the uncalibrated model\nbrier_uncalibrated = brier_score_loss(y_test, probs_uncalibrated)\nprint(f\"Brier Score for Uncalibrated Model: \\\n    {round(brier_uncalibrated, 4)}\")\n# Compute the calibration curve for the uncalibrated model\nfraction_of_positives_uncalibrated,mean_predicted_value_uncalibrated=\\\n    calibration_curve(y_test, probs_uncalibrated, n_bins=10)\n```", "```py\nBrier Score for Uncalibrated Model: 0.0447\n```", "```py\nplt.figure(figsize=(6, 4))\nplt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\nplt.plot(mean_predicted_value_uncalibrated, \\\n    fraction_of_positives_uncalibrated, label=\"Uncalibrated\")\nplt.xlabel('Mean Predicted Value')\nplt.ylabel('Fraction of Positives')\nplt.title('Calibration Curve (Test Set)')\nplt.legend()\nplt.show()\n```", "```py\n# Calibrate the model on the validation data using Platt's scaling\nplatt_scaling = CalibratedClassifierCV(model, \\\n    method='sigmoid', cv='prefit')\nplatt_scaling.fit(X_val, y_val)\n# Get model probabilities on test set (calibrated model)\nprobs_ps = platt_scaling.predict_proba(X_test)[:, 1]\n# Compute Brier score for Platt's scaling calibrated model\nbrier_platt = brier_score_loss(y_test, probs_ps)\nprint(f\"Brier Score for Platt's Scaled Model: \\\n    {round(brier_platt, 4)}\")\n# Compute the calibration curve for Platt's scaling\nfraction_of_positives_ps, mean_predicted_value_ps = \\\n    calibration_curve(y_test, probs_ps, n_bins=10)\n```", "```py\nBrier Score for Platt's Scaled Model: 0.032\n```", "```py\nisotonic_regression = CalibratedClassifierCV(model, \\\n    method='isotonic', cv='prefit')\nisotonic_regression.fit(X_val, y_val)\nprobs_ir = isotonic_regression.predict_proba(X_test)[:, 1]\nbrier_isotonic = brier_score_loss(y_test, probs_ir)\nprint(f\"Brier Score for Isotonic Regression Calibrated \\\n    Model: {round(brier_isotonic, 4)}\")\nfraction_of_positives_ir, mean_predicted_value_ir = \\\n    calibration_curve(y_test, probs_ir, n_bins=10)\n```", "```py\nBrier Score for Isotonic Regression Calibrated Model: 0.0317\n```", "```py\nplt.figure(figsize=(6, 4))\nplt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\nplt.plot(mean_predicted_value_uncalibrated, \\\n    fraction_of_positives_uncalibrated, label=\"Uncalibrated\")\nplt.plot(mean_predicted_value_ps, fraction_of_positives_ps, \\\n    label=\"Platt's scaling\", linestyle='-.')\nplt.plot(mean_predicted_value_ir, fraction_of_positives_ir, \\\n    label=\"Isotonic regression\", linestyle='--')\nplt.xlabel('Mean predicted value')\nplt.ylabel('Fraction of positives')\nplt.title('Calibration curves (Test Set)')\nplt.legend()\nplt.show()\n```", "```py\nOriginal one-hot encoded label: [1, 0]\nSmoothed one-hot encoded label: [0.9, 0.1]\n```", "```py\ntorch.nn.CrossEntropyLoss(label_smoothing=0.1, …)\n```", "```py\n    import torch\n    import torch.nn.functional as F\n    def Tversky(y_true, y_pred, smooth=1, alpha=0.8):\n        y_true_pos = y_true.view(-1)\n        y_pred_pos = y_pred.view(-1)\n        true_pos = torch.sum(y_true_pos * y_pred_pos)\n        false_neg = torch.sum(y_true_pos * (1 - y_pred_pos))\n        false_pos = torch.sum((1 - y_true_pos) * y_pred_pos)\n        return (true_pos + smooth) / (true_pos + alpha * false_pos \\\n            + (1 - alpha) * false_neg + smooth)\n    ```", "```py\n    import torch\n    import torch.nn as nn\n    from torch.nn import functional as F\n    class TripletLoss(nn.Module):\n        def __init__(self, margin=1.0):\n            super(TripletLoss, self).__init__()\n            self.margin = margin\n        def forward(self, anchor, pos, neg):\n            pos_dist = F.pairwise_distance(anchor, pos)\n            neg_dist = F.pairwise_distance(anchor, neg)\n            loss = torch.relu(pos_dist - neg_dist + self.margin)\n            return loss.mean()\n    ```", "```py\n    def generate_triplets(images, labels):\n        triplets = []\n        classes_present = labels.unique()\n        for c in classes_present:\n            # Find indices of anchor and positive examples\n            pos_indices = (labels == c).nonzero(as_tuple=True)[0]\n            anchor_idx, positive_idx = \\\n                torch.choice(pos_indices, 2, replace=False)\n            anchor, positive = images[anchor_idx], \\\n                images[positive_idx]\n            # Find index of negative example\n            neg_indices = (labels != c).nonzero(as_tuple=True)[0]\n            negative_idx = torch.choice(neg_indices)\n            negative = images[negative_idx]\n            # Add the triplet to the list\n            triplets.append((anchor, positive, negative))\n        return triplets\n    ```", "```py\n    from sklearn.datasets import make_classification\n    from sklearn.calibration import calibration_curve\n    import matplotlib.pyplot as plt\n    import numpy as np\n    # Make an imbalanced binary classification dataset\n    y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, \\\n        1, 0, 0, 0, 0, 0, 0])\n    # Dummy model always predicts not-1 (i.e., 0) with full confidence\n    y_pred = np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\\\n        0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\\\n        0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n    y_pred_labels = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n    # Calculate the calibration curve\n    fraction_of_positives, mean_predicted_value = \\\n        calibration_curve(y, y_pred)\n    # Calculate accuracy\n    accuracy = (y == y_pred_labels).mean()\n    print('accuracy: ', accuracy)\n    # Plot calibration curves\n    plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n    plt.plot(mean_predicted_value, fraction_of_positives,\\\n        \"s-\", label=\"Model A\")\n    plt.legend()\n    plt.show()\n    ```", "```py\n    accuracy:  0.9\n    ```"]