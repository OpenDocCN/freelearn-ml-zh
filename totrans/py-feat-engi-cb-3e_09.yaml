- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Extracting Features from Relational Data with Featuretools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we worked with data organized in rows and columns, where
    the columns are the variables, the rows are the observations, and each observation
    is independent. In this chapter, we will focus on creating features from relational
    datasets. In relational datasets, data is structured across various tables, which
    can be joined together via unique identifiers. These unique identifiers indicate
    relationships that exist between the different tables.
  prefs: []
  type: TYPE_NORMAL
- en: A classic example of relational data is that held by retail companies. One table
    contains information about customers, such as names and addresses. A second table
    has information about the purchases made by the customers, such as the type and
    number of items bought per purchase. A third table contains information about
    the customers’ interactions with the company’s website, variables such as session
    duration, the mobile device used, and pages visited. Customers, purchases, and
    sessions are identified with unique identifiers. These unique identifiers allow
    us to put these tables together, and in this way, we can get information about
    customers’ purchases or sessions.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to know more about the types of customers we have (that is, customer
    segmentation) or make predictions about whether they would buy a product, we can
    create features that aggregate or summarize information across different tables
    at the customer level. For example, we can create features that capture the maximum
    amount spent by a customer on a purchase, the number of purchases they have made,
    the time between sessions, or the average session duration. The number of features
    we can create and the various ways we can aggregate data across tables are abundant.
    In this chapter, we will discuss some common ways of creating aggregated views
    of relational data utilizing the `featuretools` Python library. We will begin
    by setting up various data tables and their relationships and automatically creating
    features, and next, we will follow up with more detail on the different features
    we can create.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up an entity set and creating features automatically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating features with general and cumulative operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining numerical features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting features from date and time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting features from text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating features with aggregation primitives
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will use `pandas`, `matplotlib`, and `featuretools` open
    source Python libraries. You can install `featuretools` with `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, you can do so with `conda`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'These commands install the basic `featuretools` functionality, but we can install
    add-ons for creating features with `dask` as the backend instead of `pandas`.
    For more information on how to install `featuretools` add-ons, including `graphviz`,
    check out their documentation here: [https://docs.featuretools.com/en/v0.16.0/getting_started/install.html](https://docs.featuretools.com/en/v0.16.0/getting_started/install.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will work with the *Online Retail II* dataset from the UCI Machine Learning
    Repository, which is available at [https://archive.ics.uci.edu/ml/datasets/Online+Retail+II](https://archive.ics.uci.edu/ml/datasets/Online+Retail+II)
    and licensed under a **Creative Commons Attribution 4.0 International** (**CC
    BY 4.0**) license: [https://creativecommons.org/licenses/by/4.0/legalcode](https://creativecommons.org/licenses/by/4.0/legalcode).
    The corresponding citation for this data is provided here: *Chen, Daqing* (*2019*).
    *Online Retail II*. *UCI Machine Learning* *Repository* ([https://doi.org/10.24432/C5CG6D](https://doi.org/10.24432/C5CG6D)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'I downloaded and modified the data as shown in this notebook: [https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch09-featuretools/prepare-retail-dataset.ipynb](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch09-featuretools/prepare-retail-dataset.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll find a copy of the modified dataset in the accompanying GitHub repository:
    [https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch09-featuretools/retail.csv](https://github.com/PacktPublishing/Python-Feature-engineering-Cookbook-Third-Edition/blob/main/ch09-featuretools/retail.csv)'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up an entity set and creating features automatically
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Relational datasets or databases contain data spread across multiple tables,
    and the relationships between tables are dictated by a unique identifier that
    tells us how we can join those tables. To automate feature creation with `featuretools`,
    we first need to enter the different data tables and establish their relationships
    within what is called an `featuretools` how these tables are connected so that
    the library can automatically create features based on those relationships.
  prefs: []
  type: TYPE_NORMAL
- en: We will work with a dataset containing information about customers, invoices,
    and products. First, we will set up an entity set highlighting the relationships
    between these three items. This entity set will be the starting point for the
    remaining recipes in this chapter. Next, we will create features automatically
    by aggregating the data at the customer, invoice, and product levels, utilizing
    the default parameters from `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to correctly set up an entity set and extract
    a bunch of features automatically for each entity. In the upcoming recipes, we
    will dig deeper into the different types of features that we can create with `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we will use the *Online Retail II* dataset from the UCI Machine
    Learning Repository. In this table, there are customers, which are businesses
    that buy in bulk from the retail company. Customers are identified with a `customer_id`
    unique identifier. Each customer makes one or more purchases, which are flagged
    by an `invoice` unique identifier, containing the invoice number. In each invoice,
    there are one or more items that have been bought by the customer. Each item or
    product sold by the company is also identified with a unique stock code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the data has the following relations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Diagram showing the relationships in the data](img/B22396_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – Diagram showing the relationships in the data
  prefs: []
  type: TYPE_NORMAL
- en: Each customer made one or more purchases, identified by the invoice number.
    Each invoice contains one or more items, identified by the stock code. Each item
    can be bought by one or more customers and is therefore present in several invoices.
    With these relationships in mind, let’s proceed to the recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we will set up an entity set with the data, and then highlight
    the different relationships in the dataset. Finally, we will create features by
    aggregating information in the dataset at the customer, invoice, and product levels:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s import the required libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s load the retail dataset described in the *Getting ready* section and
    display its first five rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following screenshot, we see the unique identifiers for customers (`customer_id`)
    and invoices (`invoice`), and additional information about the items bought in
    each invoice, such as the item’s code (`stock_code`), description, quantity, and
    unit price, as well as the date of the invoice:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Online Retail II dataset](img/B22396_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Online Retail II dataset
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Use `pandas`’ `unique()` function to identify the number of unique items, customers,
    and invoices – for example, by executing `df["customer_id"].nunique()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s initialize an entity set with an arbitrary name, such as `data`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s add a DataFrame to the entity set; we give the DataFrame a name (`data`).
    We need to add a unique identifier for each row, which we call `rows`, and since
    we do not have a unique row identifier in this dataset, we will create it as an
    additional column by setting `make_index=True`. Finally, we indicate that `invoice_date`
    is of the `datetime` type and `customer_id` should be handled as `Categorical`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we add the relationship between the original `data` DataFrame and `invoices`.
    To do this, we indicate the original or base DataFrame, which we called `data`
    in *step 4*, we give the new DataFrame a name, `invoices`, we add the unique identifier
    for invoices, and we add the column containing `customer_id` to this DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We copy the `customer_id` variable to the `invoices` data because we want to
    create a subsequent relationship between customers and invoices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we add a second relationship, which is between customers and invoices.
    To do this, we indicate the base DataFrame, which we named `invoices` in *step
    5*, then we give the new DataFrame a name, `customers`, and add the unique customer
    identifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can add a third relationship between the original data and the products:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s display the information in the entity set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see that the entity set contains four DataFrames:
    the original data, the `invoices` DataFrame, the `customers` DataFrame, and the
    product or `items` DataFrame. The entity also contains the relationships between
    invoices or items with the original data, as well as between customers and invoices:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: es["invoices"].head()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 9.3 – DataFrame with information at the invoice level](img/B22396_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – DataFrame with information at the invoice level
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now display the `customers` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can see in the following output that `featuretools` automatically created
    a DataFrame containing the customer’s unique identifier, followed by the date
    of the first invoice for this customer:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.4 – DataFrame with information at the customer level](img/B22396_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – DataFrame with information at the customer level
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Go ahead and display the DataFrame containing the products by executing `es["items"].head()`.
    You can also evaluate the size of the different DataFrames using `pandas`’ `shape`
    function. You will notice that the number of rows in each DataFrame coincides
    with the number of unique invoices, customers, and products.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also display the relationships between these data tables as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'To visualize the data relationships, you need to have `graphviz` installed.
    If you don’t, follow the instructions in the `featuretools` documentation to install
    it: [https://featuretools.alteryx.com/en/stable/install.html#installing-graphviz](https://featuretools.alteryx.com/en/stable/install.html#installing-graphviz).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following output, we can see the relational datasets and their relationships:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Relationships between the tables containing invoices, customers,
    and products](img/B22396_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Relationships between the tables containing invoices, customers,
    and products
  prefs: []
  type: TYPE_NORMAL
- en: After entering the data and their relationships, we can start automatically
    creating features for each one of our new DataFrames – that is, customers, invoices,
    and products – using the default parameters from `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create features by aggregating the data at the customer level. To do
    this, we set up the `featuretools`, indicating `customers` as the target DataFrame.
    When creating features, we want to ignore the two columns with unique identifiers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The command from *step 12* triggered the creation of 114 features with different
    aggregations of data at the customer level. The `feature_matrix` variable is a
    DataFrame with the feature values, and `feature_defs` is a list with the names
    of the new features. Go ahead and execute `feature_defs` or visit our accompanying
    GitHub repository ([https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/blob/main/ch09-featuretools/Recipe1-Setting-up-an-entitity-set.ipynb](https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/blob/main/ch09-featuretools/Recipe1-Setting-up-an-entitity-set.ipynb))
    to check the names of the created features. You will find more details about these
    features in the *How it* *works…* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For reasons of space, we can’t print out all the features in the book, so instead,
    let’s display the names of five of the created features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see 5 of the 114 features created by `featuretools`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The `featuretools` library names the new features with the function used to
    create them, followed by the DataFrame that was used to perform the aggregation,
    followed by the aggregated variable name. Thus, `MIN(data.quantity)` is equivalent
    to `df.groupby(["customer_id"])["quantity"].min()`, if you are familiar with `pandas`.
    We will give more details in the *How it* *works…* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s display the first five rows of the DataFrame containing five of the created
    features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we can see the first five rows containing the values
    of the five new features:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.6 – DataFrame with five features created by aggregating the data
    at the customer level](img/B22396_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – DataFrame with five features created by aggregating the data at
    the customer level
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we can create features automatically by aggregating information
    at the invoice level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The previous step returns 24 features – let’s display their names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can see the names of the features in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Go ahead and display the DataFrame containing the new features by executing
    `feature_matrix.head()` or check our accompanying GitHub repository for the result.
  prefs: []
  type: TYPE_NORMAL
- en: To wrap up, by using the code from *step 16* and changing the target DataFrame
    name from `invoices` to `items`, go ahead and create features automatically at
    the product level.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we set up an entity set containing the data and the relationships
    between some of its variables (unique identifiers). After that, we automatically
    created features by aggregating the information in the dataset for each of the
    unique identifiers. We used two main classes from `featuretools`, `EntitySet`
    and `dfs`, to create the features. Let’s discuss each of these in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: The `EntitySet` class stores the data, the logical types of the variables, and
    the relationships between the variables. The variable types (whether numeric or
    categorical) are automatically assigned by `featuretools`. We can also set up
    specific variable types when adding a DataFrame to the entity set. In *step 4*,
    we added the data to the entity set and set the logical type of `customer_id`
    to `Categorical`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To inspect the datatypes inferred by `featuretools`, you can execute `es["data"].ww`,
    where `es` is the entity set and `data` is the name of the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: The `EntitySet` class has the `add_dataframe` method, which we used in *step
    4* to add a new DataFrame. When using this method, we need to specify the unique
    identifier, and if there is none, then we need to create one, as we did in *step
    4*, by setting `make_index` to `True`. Note that in the `index` parameter from
    `add_dataframe`, we passed the `"rows"` string. With this configuration, `EntitySet`
    added a `rows` column containing the unique identifier for each row to the DataFrame,
    which is a new sequence of integers starting at 0.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Instead of using the `add_dataframe` method to add a DataFrame to an entity
    set, we can add it by executing `es["df_name"]=df`, where `"df_name"` is the name
    we want to give to the DataFrame and `df` is the DataFrame we want to add.
  prefs: []
  type: TYPE_NORMAL
- en: The `EntitySet` class has the `normalize_dataframe` method, which is used to
    create a new DataFrame and relationship from the unique values of an existing
    column. The method takes the name of the DataFrame to which the new DataFrame
    will be related and a name for the new DataFrame. We also need to indicate the
    unique identifier for the new DataFrame in the `index` parameter. By default,
    this method creates a new DataFrame containing the unique identifier, followed
    by a `datetime` column containing the first date each unique identifier was registered.
    We can add more columns to this DataFrame by using the `copy_columns` parameters,
    as we did in *step 5*. Adding more columns to the new DataFrame is useful if we
    want to follow up with relationships to this new DataFrame, as we did in *step
    6*.
  prefs: []
  type: TYPE_NORMAL
- en: The `EntitySet` class also has the `plot()` method, which displays existing
    relationships in the entity set. In *Figure 9**.5*, we saw the relationships between
    our data tables; the `invoices` and `items` (products) tables were related to
    the original data, whereas the `customers` table was related to the `invoices`
    table, which was, in turn, related to the original data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The relationship between the tables dictates how features will be created. The
    `invoices` and `items` tables are related to the original data. Thus, we can only
    create features with depth 1\. The `customers` table is, on the other hand, related
    to invoices, which is related to data. Thus, we can create features with depth
    2\. That means that new features will consist of aggregations from the entire
    dataset or aggregations for invoices first, which will then be subsequently aggregated
    for customers. We can regulate the features to create with the `max_depth` parameter
    in `dfs`.
  prefs: []
  type: TYPE_NORMAL
- en: After setting up the data and the relationships, we used `dfs` from `featuretools`
    to automatically create features. When creating features with `dfs`, we need to
    set the target DataFrame – that is, the data table for which the features should
    be created. The `dfs` class creates features by *transforming* and *aggregating*
    existing variables, through what are called **transform** and **aggregate primitives**.
  prefs: []
  type: TYPE_NORMAL
- en: A transform primitive transforms variables. For example, from datetime variables,
    using a transform primitive, `dfs` extracts the `month`, `year`, `day`, and `week`
    values.
  prefs: []
  type: TYPE_NORMAL
- en: An aggregate primitive aggregates information for a unique identifier. It uses
    mathematical operations such as the mean, standard deviation, maximum and minimum
    values, the sum, and the skew coefficient for numerical variables. For categorical
    variables, aggregate primitives use the mode and the count of unique items. For
    unique identifiers, they count the number of occurrences.
  prefs: []
  type: TYPE_NORMAL
- en: With the functionality of transform and aggregate primitives in mind, let’s
    try to understand the features that we created in this recipe. We used the default
    parameters of `dfs` to create the default features.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For more details on the default features returned by `featuretools`, visit [https://featuretools.alteryx.com/en/stable/generated/featuretools.dfs.html#featuretools.dfs](https://featuretools.alteryx.com/en/stable/generated/featuretools.dfs.html#featuretools.dfs).
  prefs: []
  type: TYPE_NORMAL
- en: We first created features for each customer. `featuretools` returned 114 features
    for each customer. Because the `customers` data is related to the `invoices` data,
    which is related to the entire dataset, the features were created by aggregating
    data at two levels. First, the data was aggregated for each customer using the
    entire dataset. Next, it was aggregated for each invoice first, and then the pre-aggregated
    data was aggregated again for each customer.
  prefs: []
  type: TYPE_NORMAL
- en: The `featuretools` library names the new features with the function used to
    aggregate the data – for example, `COUNT`, `MEAN`, `STD`, and `SKEW`, among others.
    Next, it uses the data that was used for the aggregation and follows it with the
    variable that was aggregated. For example, the `MEAN(data.quantity)` feature contains
    the mean quantity of items bought by the customer calculated from the entire dataset,
    which is the equivalent of `df.groupby("customer_id"])["quantity"].mean()`, if
    you are familiar with `pandas`. On the other hand, the `MEAN(invoices.MEAN(data.quantity))`
    feature first takes the mean quantity of items for each invoice – that is, `df.groupby("invoice"])["quantity"].mean()`
    – and from the resulting series, it takes the mean value, considering the invoices
    for a particular customer.
  prefs: []
  type: TYPE_NORMAL
- en: For categorical features, `featuretools` determines the mode and the unique
    values. For example, from the `description` variable, we’ve got the `NUM_UNIQUE(data.description)`
    and `MODE(data.description)` features. The description is just the name of the
    item. Thus, these features highlight the number of unique items the customer bought
    and the item the customer bought the most times.
  prefs: []
  type: TYPE_NORMAL
- en: Note something interesting
  prefs: []
  type: TYPE_NORMAL
- en: The `NUM_UNIQUE(data.description)` and `MODE(data.description)` variables are
    numeric after the aggregation of the categorical features. The `featuretools`
    library creates more features by using numerical aggregations of these newly created
    variables. In this way, the `MAX(invoices.NUM_UNIQUE(data.description)` feature
    first finds the number of unique items per invoice and then returns the maximum
    from those values for a particular customer, considering all the customer’s invoices.
  prefs: []
  type: TYPE_NORMAL
- en: From datetime features, `featuretools` extracts date components by default.
    Remember that the `customers` DataFrame contains the `customer_id` variable and
    the date of the first invoice for each customer, as we saw in the output of *step
    10*. From this datetime feature, `featuretools` created `DAY(first_invoices_time)`,
    `MONTH(first_invoices_time)`, `WEEKDAY(first_invoices_time)`, and `YEAR(first_invoices_time)`
    features containing the different date parts.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `featuretools` also returned the total number of invoices per customer
    (`COUNT(invoices)`) and the total number of rows (`COUNT(data)`) per customer.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For more details into what inspired `featuretools`, check the original article
    *Deep Feature Synthesis: Towards Automating Data Science Endeavors* by Kanter
    and Veeramachaneni at [https://www.jmaxkanter.com/papers/DSAA_DSM_2015.pdf](https://www.jmaxkanter.com/papers/DSAA_DSM_2015.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Creating features with general and cumulative operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `featuretools` library uses what are called **transform primitives** to
    create features. Transform primitives take one or more columns in a dataset as
    input and return one or more columns as output. They are applied to a *single*
    DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: The `featuretools` library divides its transform primitives into various categories
    depending on the type of operation they perform or the type of variable they modify.
    For example, **general transform primitives** apply mathematical operations, such
    as the square root, the sine, and the cosine. **Cumulative transform primitives**
    create new features by comparing a row’s value to the previous row’s value. For
    example, the cumulative sum, cumulative mean, and cumulative minimum and maximum
    values belong to this category, as well as the difference between row values.
    There is another cumulative transformation that can be applied to datetime variables,
    which is the **time since previous** transformation, which determines the time
    passed between two consecutive timestamps.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will create features using the general and cumulative transform
    primitives from `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Variable transformations such as the square root or the logarithm are useful
    when we want to change the distribution of a variable, as we saw in [*Chapter
    3*](B22396_03.xhtml#_idTextAnchor351), *Transforming Numerical Variables*. Other
    mathematical derivations such as the sine and cosine help to capture underlying
    data patterns, as we described in the *Creating periodic features from cyclical
    variables* recipe in [*Chapter 8*](B22396_08.xhtml#_idTextAnchor987), *Creating
    New Features*. From the transformations described in those chapters, `featuretools`
    supports the square root and the logarithm transformation and the sine and cosine
    (but without the normalization between 0 and 2π).
  prefs: []
  type: TYPE_NORMAL
- en: 'With a cumulative transformation, we can, for example, get the total number
    of items bought per invoice by adding up the item’s quantity on each row at the
    invoice level. To understand the features that we will create in this recipe,
    let’s create them with `pandas` first:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s import `pandas` and `numpy`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s load the retail dataset described in the *Technical* *requirements* section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s capture the two numerical variables, `price` and `quantity`, in a list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s capture the names of the cumulative functions in a list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s create a list with new names for the variables that we will create:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s create new variables using the cumulative functions from *step 4*, applied
    to the variables from *step 3*, and add them to the DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The previous step returns the cumulative sum, cumulative maximum value, and
    the difference between rows, within each invoice. As soon as it encounters a new
    invoice number, it starts afresh.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s display the original and new features for one particular invoice:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we can see that `quantity_cumsum` is the cumulative
    sum for the variable quantity and `price_diff` is the price difference row after
    row:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.7 – DataFrame showing cumulative functions applied to numerical
    features in a single entity (invoice)](img/B22396_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – DataFrame showing cumulative functions applied to numerical features
    in a single entity (invoice)
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now apply the sine and cosine transformation to the entire DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a list with names for the new variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s transform the price and quantity with the sine and cosine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The transformation in *step 9* was applied to the entire dataset, irrespective
    of the invoice number, which is fine because it maps from one row to the same
    row, as opposed to from one row to the next, as with cumulative functions. You
    can inspect the result by executing `df[new_names].head()`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now that we understand the types of features we want to create, let’s automate
    the process with `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will apply cumulative transformations for each invoice and general transformations
    to the entire dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we’ll import `pandas`, `featuretools`, and the `Categorical` logical
    type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s load the dataset described in the *Technical* *requirements* section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s set up an entity set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s add the DataFrame to the entity set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: By default, `featuretools` only retains categorical, numeric, and Boolean features
    in the feature matrix that is generated *after* creating new features. The type
    of the `invoice` variable is not accurately inferred, so we need to enforce it
    as categorical by setting its logical type as we do in *step 4*, if we want `featuretools`
    to retain it in the dataset containing the new features. To learn the datatypes
    inferred by `featuretools`, you can execute `es["data"].ww`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a new DataFrame with a relationship to the DataFrame from *step
    4*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For more details about *steps 4* and *5*, visit the *Setting up an entity set
    and creating features* *automatically* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make a list with the cumulative transformations that we’ll use to create
    features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find `featuretools`-supported cumulative transformations at this link:
    [https://featuretools.alteryx.com/en/stable/api_reference.html#cumulative-transform-primitives](https://featuretools.alteryx.com/en/stable/api_reference.html#cumulative-transform-primitives)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make a list of the general transformations to carry out:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find `featuretools`-supported general transformations at this link:
    [https://featuretools.alteryx.com/en/stable/api_reference.html#general-transform-primitives](https://featuretools.alteryx.com/en/stable/api_reference.html#general-transform-primitives)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s create the features. We use the `dfs` class, setting the original
    DataFrame as the target DataFrame – that is, the one whose variables we’ll use
    as a template for the new features. Note that we pass an empty list to the `agg_primitives`
    parameter; this is to avoid returning the default aggregation primitives. We pass
    the general primitives from *step 7* to the `trans_primitives` parameter and the
    cumulative primitives from *step 6* to the `groupby_trans_primitives` parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 8* triggers the creation of features, which may take some time depending
    on how big the data is, how many aggregation levels it has, and the number of
    features to create. You can check out the output features *before* creating them,
    by setting the `features_only` parameter to `True`. This will return just the
    feature names; you can check them out, make sure they show what you need, and
    only then trigger the feature synthesis by setting that parameter back to `False`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now display the names of the created features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see the names of the features that we created,
    including the sine and cosine of the price and quantity, and the cumulative transformations
    of these variables after grouping them by invoice number:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The sine and cosine transformation of price and quantity will probably not add
    much value because these are not cyclical features. I kept these transformations
    in the recipe to show you how to apply transformation primitives in general, if
    you ever need them.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see from the previous list, the new features were appended as new
    columns to the original DataFrame. You can display the final DataFrame by executing
    `feature_matrix.head()`:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 9.8 – DataFrame resulting from the deep feature synthesis, containing\
    \ the \uFEFForiginal variables and the new features](img/B22396_09_08.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 – DataFrame resulting from the deep feature synthesis, containing
    the original variables and the new features
  prefs: []
  type: TYPE_NORMAL
- en: For more details about the created features, check the *How it* *works…* section.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create features using general and cumulative transformations with `featuretools`,
    we first need to set up an entity set with the data and define the relationships
    between its variables. We described how to set up an entity set in the *Setting
    up an entity set and creating features* *automatically* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: To apply cumulative and general transforms, we used the `dfs` class from `featuretools`.
    General transformations are applied to the entire DataFrame without grouping by
    a specific variable. To perform general transformations, we passed a list of strings
    with the transformation names to the `trans_primitives` parameter from `dfs`.
  prefs: []
  type: TYPE_NORMAL
- en: We applied cumulative transformation after grouping by `invoice`. To do this,
    we passed a list of strings with the names of the cumulative transformation to
    the `groupby_trans_primitives` parameter from `dfs`. The `featuretools` library
    knows it should group by invoice because we established this unique identifier
    by using the `normalize_dataframe` method from `EntitySet` in *step 5*.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we did not want features created from the variables in the `invoices`
    DataFrame; thus, we set `dfs` to ignore this DataFrame by setting `ignore_dataframes
    = ["``invoices"]`.
  prefs: []
  type: TYPE_NORMAL
- en: The `dfs` class returned two variables, the DataFrame with the original and
    new features, and the name of the features in a list. The new features are named
    with the operations applied to create them, such as `SINE`, `COSINE`, `CUM_MAX`,
    or `DIFF`, followed by the variable to which the transformation was applied and,
    when corresponding, the variable that was used for grouping.
  prefs: []
  type: TYPE_NORMAL
- en: Note that `featuretools` automatically recognizes and selects the variables
    over which the transformations should be applied. The sine, cosine, cumulative
    sum, maximum, and difference were applied to numerical variables, whereas the
    `time_since_previous` transformation was applied to the datetime variable.
  prefs: []
  type: TYPE_NORMAL
- en: Combining numerical features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 8*](B22396_08.xhtml#_idTextAnchor987), *Creating New Features*,
    we saw that we can create new features by combining variables with mathematical
    operations. The `featuretools` library supports several operations for combining
    variables, including addition, division, modulo, and multiplication. In this recipe,
    we will learn how to combine these features with `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s begin by importing the libraries and getting the dataset ready:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we’ll import `pandas`, `featuretools`, and the `Categorical` logical
    type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s load the dataset that described in the *Technical* *requirements* section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s set up an entity set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s add the DataFrame to the entity set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s create a new DataFrame with a relationship to the DataFrame from *step
    4*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For more details about *steps 4* and *5*, visit the *Setting up an entity set
    and creating features* *automatically* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will multiply the `quantity` and `price` variables, which reflect the number
    of items bought and the unit price, respectively, to obtain the total amount paid:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We set `agg_primitives` to an empty list to avoid the creation of default primitives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now display the name of the new features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see the feature names, the last one of which corresponds
    to the combination of the `price` and `quantity` variables:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To finish off, let’s inspect the new DataFrame created in *step 6*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we can see that the new feature was appended to the
    right of the original DataFrame:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.9 – DataFrame with the new feature resulting from the product of
    price with quantity](img/B22396_09_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.9 – DataFrame with the new feature resulting from the product of price
    with quantity
  prefs: []
  type: TYPE_NORMAL
- en: Combining features with `featuretools` may seem like a lot of work compared
    to the `df["price"].mul(df["quantity"])` `pandas` functionality. The real power
    comes in when we create new features in this way and follow it up with aggregations
    at the invoice or customer level. We will discuss aggregation functions in the
    *Creating features with aggregation* *primitives* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To multiply features, we used the `MultiplyNumeric` primitive from `featuretools`,
    which can be accessed from `dfs` using the `multiply_numeric` string. We passed
    the former string to the `trans_primitive` parameter and then used the `primitive_options`
    parameter to specify which variables to multiply. Note that in addition, we passed
    an empty list to the `agg_primitives` parameter to avoid returning the default
    aggregation primitives, and we ignored the features coming from the `invoices`
    DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check out other functions that allow you to combine variables, visit [https://featuretools.alteryx.com/en/stable/api_reference.html#binary-transform-primitives](https://featuretools.alteryx.com/en/stable/api_reference.html#binary-transform-primitives).
    At the time of writing, I noticed that `MultiplyNumeric` and `DivideNumeric` are
    not in the documentation. You can always double-check which functions are supported
    by inspecting the source code: [https://github.com/alteryx/featuretools/tree/main/featuretools/primitives/standard/transform/binary](https://github.com/alteryx/featuretools/tree/main/featuretools/primitives/standard/transform/binary).
    You can also check out which operations you can perform on your data by running
    the following command after you set up the entity set and its relationships: `ft.get_valid_primitives(es,
    target_dataframe_name="data", max_depth=2)`. Here, `es` is the entity set resulting
    from *step 5*.'
  prefs: []
  type: TYPE_NORMAL
- en: Extracting features from date and time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B22396_06.xhtml#_idTextAnchor748), *Extracting Features from
    Date and Time* *Variables*, we discussed how we can enrich our datasets by extracting
    features from the date and time parts of datetime variables, such as the year,
    the month, the day of the week, the hour, and much more. We can extract those
    features automatically utilizing `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: The `featuretools` library supports the creation of various features from datetime
    variables using its **datetime transform primitives**. These primitives include
    common variables such as year, month, and day, and other features such as *is
    it lunch time* or *is it weekday*. In addition, we can extract features indicating
    if the date was a federal or bank holiday (as they call it in the UK) or features
    that determine the distance in time to a certain date. For a retail company, the
    proximity to dates such as Boxing Day, Black Fridays, or Christmas normally signals
    an increase in sales, and if they are forecasting demand, these will make useful
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For more details on the features that can be created from datetime variables,
    visit [https://featuretools.alteryx.com/en/stable/api_reference.html#datetime-transform-primitives](https://featuretools.alteryx.com/en/stable/api_reference.html#datetime-transform-primitives).
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will automatically create multiple features from a datetime
    variable with `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s begin by importing the libraries and getting the dataset ready:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we’ll import `pandas`, `featuretools`, and some special datetime primitives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s load the dataset described in the *Technical* *requirements* section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s set up an entity set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s add the DataFrame to the entity set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s create a new DataFrame with a relationship to the DataFrame from *step
    4*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For more details about *steps 4* and *5*, visit the *Setting up an entity set
    and creating features* *automatically* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a primitive that returns a Boolean vector indicating if the date
    coincides with a UK bank holiday (that is, a non-working day):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: When setting up the primitive to determine bank holidays, it is important to
    choose the right country. For a list of supported countries, visit [https://github.com/dr-prodigy/python-holidays#available-countries](https://github.com/dr-prodigy/python-holidays#available-countries).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check out which bank holidays are included in this primitive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we execute `available_hols`, we’ll see a list of bank holidays supported
    for the UK:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s create another primitive that determines the days to a certain date –
    in this case, the distance to Boxing Day:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s make a list containing strings that identify common features that
    we can get from `datetime` and include the primitives from *steps 6* and *8*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s now create date and time features from *step 9* based on the `invoice_date`
    date variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In *step 4*, we entered the `invoice_date` variable as a time variable. Thus,
    `featuretools` will use this variable to create date- and time-related features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s display the names of the created features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see the names of the original and time features:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s display the resulting DataFrame containing three of the new features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see the DataFrame with the new features:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: "![Figure 9.10 – DataF\uFEFFrame with some of the features derived from datetime](img/B22396_09_10.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 9.10 – DataFrame with some of the features derived from datetime
  prefs: []
  type: TYPE_NORMAL
- en: Note that some of the created features are numeric, such as `HOUR` or `DAY`,
    some are Booleans, such as `IS_FEDERAL_HOLIDAY`, and some are categorical, such
    as `PART_OF_DAY`. To take a look at the values of `PART_OF_DAY`, execute `feature_matrix["PART_OF_DAY(first_data_time)"].unique()`.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create features from datetime variables, we used datetime transform primitives
    from `featuretools` ([https://featuretools.alteryx.com/en/stable/api_reference.html#datetime-transform-primitives](https://featuretools.alteryx.com/en/stable/api_reference.html#datetime-transform-primitives)).
    These primitives can be accessed from `dfs` using the strings and functions we
    specified in *steps 6* to *9* through the `trans_primitive` parameter. Note that
    in addition, we passed an empty list to the `agg_primitives` parameter not to
    return the default aggregation primitives that would have been otherwise applied
    to our datetime features. We also ignored the features coming from the `invoices`
    DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We set `agg_primitives` to an empty list and ignored the `invoices` DataFrame
    to keep the outputs simple and be able to focus on datetime features. However,
    note that the real power of `featuretools` consists in creating primitives from
    `datetime` and then aggregating them further at different entity levels.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting features from text
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 11*](B22396_11.xhtml#_idTextAnchor1459), *Extracting Features from
    Text Variables*, we will discuss various features that we can extract from text
    pieces utilizing `pandas` and `scikit-learn`. We can also extract multiple features
    from text automatically by utilizing `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: The `featuretools` library supports the creation of several basic features from
    text as part of its default functionality, such as the number of characters, the
    number of words, the mean character count per word, and the median word length
    in a piece of text, among others.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For a full list of the default text primitives, visit [https://featuretools.alteryx.com/en/stable/api_reference.html#naturallanguage-transform-primitives](https://featuretools.alteryx.com/en/stable/api_reference.html#naturallanguage-transform-primitives).
  prefs: []
  type: TYPE_NORMAL
- en: In addition, there is an accompanying Python library, `nlp_primitives`, which
    contains additional primitives to create more advanced features based on NLP.
    Among these functions, we find primitives for determining the diversity score,
    the polarity score, or the count of stop words.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'There is no documentation at the time of writing to learn more about the primitives
    supported by the `nlp_primitives` library, so to find out more, you need to check
    the source code: [https://github.com/alteryx/nlp_primitives/tree/6243ef2379501bfec2c3f19e35a30b5954605e57/nlp_primitives](https://github.com/alteryx/nlp_primitives/tree/6243ef2379501bfec2c3f19e35a30b5954605e57/nlp_primitives).'
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will first create multiple features from a text variable
    utilizing `featuretools`’ default functionality and then highlight how to use
    primitives from the `nlp_primitives` library.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To follow along with this recipe, you need to install the `nlp_primitives`
    library, which you can do with `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Otherwise, you can use `conda`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'For more details, visit the `nlp_primitives` GitHub repository: [https://github.com/alteryx/nlp_primitives](https://github.com/alteryx/nlp_primitives)'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s begin by importing the libraries and getting the dataset ready:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we’ll import `pandas`, `featuretools`, and the logical types:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s load the dataset described in the *Technical* *requirements* section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s set up an entity set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s add the DataFrame to the entity set, highlighting that the `description`
    variable is a text variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For the `featuretools` library‘s text primitives to work, we need to indicate
    which variables are text by using the `NaturalLanguage` logical type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a new DataFrame with a relationship to the DataFrame from *step
    4*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For more details about *steps 4* and *5*, visit the *Setting up an entity set
    and creating features* *automatically* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make a list with strings corresponding to the text features we want to
    create:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s now extract the text features from the `description` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s display the names of the created features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see the names of the original features, followed
    by those created from the `description` variable:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s display a slice of the DataFrame containing the text-derived features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see a DataFrame with the features created from
    the text:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.11 – DataFrame with the features created from text](img/B22396_09_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.11 – DataFrame with the features created from text
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The `featuretools` library removes the original text variable, `description`,
    and in its place, it returns the new features.
  prefs: []
  type: TYPE_NORMAL
- en: To create features using the primitives from the `nlp_primitives` package, you
    need to import them first – for example, by executing from `nlp_primitives import
    DiversityScore` – and then add the primitives to the text primitive list that
    we created in *step 6*. Note that these are complex functions, so they may take
    some time to create the features.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create features from text variables, we used the default text primitives
    from `featuretools`. These primitives can be accessed from `dfs` by passing a
    list with strings corresponding to the primitive names, such as those from *step
    6*, to the `trans_primitives` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: For more advanced primitives, you need to import the primitive functions from
    the `nlp_primitives` library and then pass them on to the `trans_primitives` parameter
    from `dfs`. With this, `dfs` can tap into the functionality of these primitives
    to create new features from the text. The `nlp_primitives` library uses the `nltk`
    Python library under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: Creating features with aggregation primitives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this chapter, we’ve created features automatically by mapping existing
    variables into new features through various functions. For example, we extracted
    date and time parts from datetime variables, counted the number of words, characters,
    and punctuation in texts, combined numerical features into new variables, and
    transformed features with functions such as sine and cosine. To create these features,
    we worked with transform primitives.
  prefs: []
  type: TYPE_NORMAL
- en: The `featuretools` library also supports `price`, related to an invoice, an
    aggregation primitive would take all the price observations for a single invoice
    and return a single value, such as the mean price or the sum (that is, the total
    amount paid), for that invoice.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The `featuretools` aggregation functionality is the equivalent of `groupby`
    in `pandas`, followed by `pandas` functions such as `mean`, `sum`, `std`, and
    `count`, among others.
  prefs: []
  type: TYPE_NORMAL
- en: Some aggregation primitives work with numerical variables, such as the mean,
    sum, or maximum and minimum values. Other aggregation primitives are specific
    to categorical variables, such as the number of unique values and the most frequent
    value (mode).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For a complete list of supported aggregation primitives, visit [https://featuretools.alteryx.com/en/stable/api_reference.html#aggregation-primitives](https://featuretools.alteryx.com/en/stable/api_reference.html#aggregation-primitives).
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will first create multiple features by aggregating existing
    variables. After that, we will combine the use of transform and aggregation primitives
    to highlight the true power of `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we will use the *Online Retail II* dataset from the UCI Machine
    Learning Repository. This dataset has information about products (items), invoices,
    and customers. To follow along with this recipe, it is important to understand
    the nature of and the relationships between these entities and how to correctly
    set up an entity set with `featuretools`, which we described in the *Setting up
    an entity set and creating features automatically* recipe. Make sure you checked
    that recipe out before proceeding with the next section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s begin by importing the libraries and getting the dataset ready:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we’ll import `pandas`, `featuretools`, and the logical types:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s load the dataset described in the *Technical* *requirements* section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s set up an entity set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s add the DataFrame to the entity set, highlighting that the `description`
    variable is a text variable, `customer_id` is categorical, and `invoice_date`
    is a datetime feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s create a new DataFrame with a relationship to the DataFrame from *step
    4*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we add the second relationship, which is between customers and invoices.
    To do this, we indicate the base DataFrame, which we called `invoices` in *step
    5*, we give the new DataFrame a name, `customers`, and we add a unique customer
    identifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For more details about *steps 4* to *5*, visit the *Setting up an entity set
    and creating features* *automatically* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make a list with string names that identify the aggregation primitives
    we want to use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s create features by aggregating the data at the customer level. To do
    this, we set up the `dfs` class from `featuretools`, indicating `customers` as
    the target DataFrame and passing the aggregation primitives from *step 7* and
    an empty list to the `trans_primitives` parameter to prevent `dfs` from returning
    the default transformations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s display the names of the created features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see the name features that were aggregated at the
    customer level:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Remember that `featuretools` names features with the function used to create
    them, followed by the DataFrame that was used in the computation, followed by
    the variable that was used in the computation. Thus, `MAX(data.price)` is the
    maximum price seen in the dataset for each customer. On the other hand, `MEAN(invoices.MAX(data.price))`
    is the mean value of all maximum prices observed in each invoice for a particular
    customer. That is, if a customer has six invoices, we first find the maximum price
    for each of the six invoices and then take the average of those values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now display the resulting DataFrame containing the original data and
    new features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see *some* of the variables in the DataFrame returned
    by `dfs`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.12 – DataFrame with some of the features resulting from aggregations
    at the customer level](img/B22396_09_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.12 – DataFrame with some of the features resulting from aggregations
    at the customer level
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to space limitations, we can’t display the entire output of *step 10*,
    so make sure you execute it on your computer or visit our accompanying GitHub
    repository for more details: [https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/blob/main/ch09-featuretools/Recipe6-Creating-features-with-aggregation-primitives.ipynb](https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/blob/main/ch09-featuretools/Recipe6-Creating-features-with-aggregation-primitives.ipynb).'
  prefs: []
  type: TYPE_NORMAL
- en: To follow up, let’s combine what we learned from the recipes using transform
    primitives with the aggregation functions from this recipe. First, we will create
    new features from existing datetime and text variables; then, we will aggregate
    those features along with the numerical variables, at the customer level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make lists with date and text primitives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s make a list with an aggregation primitive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s now automatically create features by transforming and then aggregating
    variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The code from *step 13* triggers the creation of the features and their subsequent
    aggregation at the customer level.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s display the names of the new features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following output, we see the names of the created variables:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that in our recipes, we keep the creation of features to a minimum due
    to space limitations, but you can create as many features as you want and enrich
    your datasets dramatically with the functionality built into `featuretools`.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we brought together the creation of features using transform
    primitives, which we discussed throughout the chapter, with the creation of features
    using aggregation primitives.
  prefs: []
  type: TYPE_NORMAL
- en: To create features with `featuretools` automatically, we first need to enter
    the data into an entity set and establish the relationships between the data.
    We discussed how to set up an entity set in the *Setting up an entity set and
    creating features* *automatically* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: To aggregate existing features, we used the `dfs` class. We created a list with
    a string corresponding to the aggregation primitives and passed it to the `agg_primitives`
    parameter from `dfs`. To aggregate existing variables without creating new features,
    we passed an empty list to the `trans_primitives` parameter of `dfs`.
  prefs: []
  type: TYPE_NORMAL
- en: The `customers` DataFrame is the child of the `invoice` DataFrame, which is,
    in turn, the child of the original data. Thus, `dfs` created aggregations from
    the original data and the pre-aggregated data for each invoice. Thus, the `MEAN(data.price)`
    feature consists of the mean price for an item bought by a customer calculated
    from the entire data, whereas `MEAN(invoices.MEAN(data.price))` calculates the
    mean price per invoice first and then takes the mean of those values for a customer.
    Thus, if a customer has five invoices, `featuretools` first calculates the mean
    price paid for each of those invoices and then takes the mean of those values.
    As such, `MEAN(data.price)` and `MEAN(invoices.MEAN(data.price))` are not the
    same feature.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: An aggregate primitive aggregates information for a unique identifier. Aggregate
    primitives use mathematical operations such as the mean, standard deviation, maximum
    and minimum values, the sum, and the skew coefficient for numerical variables.
    For categorical variables, aggregate primitives use the mode and the count of
    unique items. For unique identifiers, aggregate primitives count the number of
    occurrences.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we combined the creation of new features from date and text variables
    with aggregation. To do this, we passed a list of strings corresponding to the
    transform primitives to the `trans_primitives` parameter, and another list of
    strings corresponding to the aggregation primitives to the `agg_primitives` parameter
    of `dfs`.
  prefs: []
  type: TYPE_NORMAL
- en: One of the outputs of *step 13* is a list of the new features. From these, we
    can identify features created from the first invoice date for each customer, such
    as `MONTH(first_invoices_time)` and `WEEKDAY(first_invoices_time)`. We can also
    see features that were aggregated from features created from text, such as `MEAN(data.NUM_WORDS(description))`
    and `MEAN(invoices.MEAN(data.NUM_WORDS(description)))`. Finally, we can see the
    aggregations of existing numerical variables, such as `MEAN(data.price)` and `MEAN(invoices.MEAN(data.price))`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to apply transform and aggregation primitives to specific variables,
    you can do so by specifying the primitive options as discussed here: [https://docs.featuretools.com/en/stable/guides/specifying_primitive_options.html](https://docs.featuretools.com/en/stable/guides/specifying_primitive_options.html).'
  prefs: []
  type: TYPE_NORMAL
