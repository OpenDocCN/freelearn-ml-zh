- en: Image Classification and Detection with SageMaker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have studied a type of deep learning algorithm called a **Convolutional Neural
    Network** (**CNN**), which is capable of classifying images. However, implementing
    such an algorithm in practice is extremely complex and requires a lot of expertise. Amazon SageMaker
    offers features that allow you to train machine learning models such as image
    classification algorithms using deep learning capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Amazon SageMaker for image classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a deep learning model using Amazon SageMaker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifying images using Amazon SageMaker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing Amazon SageMaker for image classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The field of data science has been revolutionized because of services such as
    Tensorflow and SageMaker. Complex algorithms, such as Deep learning, were only
    accessible to large corporations and research labs in the past. However, thanks
    to services such as SageMaker, anyone who can write code to call these services
    can train and use sophisticated machine learning algorithms. This has enabled
    teenagers, with a working knowledge of machine learning, to create applications
    that can perform complex machine learning tasks. You will have the power to perform
    machine learning tasks at the same level as the world's top scientists by accessing
    state-of-the-art machine learning models in SageMaker marketplace.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker offers a large number of algorithms that data scientists can
    use to train their machine learning models, and it also offers tools to generate
    predictions on a batch of test data or create an endpoint to use the model as
    a service. When we work on smaller test datasets, we can use Python machine learning
    libraries, such as `scikit-learn`. However, when we are working on a larger dataset,
    we have to rely on frameworks, such as Apache Spark, and use the libraries, such
    as `MLLib`.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon offers a suite of machine learning libraries in SageMaker where we can
    use pre-tuned models from various vendors to train our machine learning models.
    Hence, when you are working on a problem, you can search the Amazon SageMaker
    marketplace to find algorithms that are already available. If there are multiple
    algorithms and models available from different vendors, you can choose between
    algorithms based on their pricing models and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: The SageMaker marketplace can be used to select models offered by vendors other
    than Amazon. Hence, if you need a specialized algorithm that is tuned to functions
    in the field of genetic engineering or a specialized version of an image classification
    algorithm, such as **Construction-worker Detector**, you can select one of the
    pre-trained models and directly get predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker also offers jobs to tune parameters of the algorithms that
    are available in the marketplace so that they can be adapted to your cluster size
    and applications. Such jobs are called **Hyperparameter-tuning Jobs**. You can
    provide various values of parameters to check an algorithm. Amazon SageMaker can
    then automatically train to select what tuning parameters would work best for
    your application. You can also set the values of these parameters manually.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll present how to use Amazon SageMaker using an example
    of an image classifier. This algorithm learns from a labeled set of images and
    then detects objects in the testing dataset by assigning a probability of the
    existence of each object in the test image. For this test, we use a publicly available
    dataset called `Caltech265` ([http://www.vision.caltech.edu/Image_Datasets/Caltech256/](http://www.vision.caltech.edu/Image_Datasets/Caltech256/)).
    This dataset contains 30,608 images. The dataset is labeled with 256 objects.
  prefs: []
  type: TYPE_NORMAL
- en: Please download the following dataset files to your AWS S3 bucket: [http://data.mxnet.io/data/caltech-256/caltech-256-60-train.rec](http://data.mxnet.io/data/caltech-256/caltech-256-60-train.rec) 
    and   [http://data.mxnet.io/data/caltech-256/caltech-256-60-val.rec](http://data.mxnet.io/data/caltech-256/caltech-256-60-val.rec)
  prefs: []
  type: TYPE_NORMAL
- en: For the purpose of our experiment, we'll store the training data files in the
    AWS bucket under the `image-classification-full-training/train` folder. This file
    contains 15,420 image files that are resized to 224 x 224 pixels.
  prefs: []
  type: TYPE_NORMAL
- en: Training a deep learning model using Amazon SageMaker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will show how to train image classification models using
    this dataset. Similarly, download the `validation` file to the AWS bucket under
    the `image-classification-full-training/validation` folder.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 7](c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml), *Implementing Deep
    Learning Algorithms*, we studied an algorithm called a CNN, which uses deep neural
    networks to build an object detection model. This model trains on labeled images
    and learns how to identify objects in an image using various layers of deep neural
    networks. Building this deep learning model from scratch is difficult. Amazon
    SageMaker offers an easy way to train image classification algorithms using your
    own dataset and then deploys that model to detect objects in images. We'll provide
    a code example of training a model using the `caltech256` dataset and then we'll
    test it on image files in the next section, *Classifying images using Amazon SageMaker*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to Chapter 8, *Implementing Deep Learning with TensorFlow on AWS*,
    you will have to start a new SageMaker instance and use Jupyter Notebooks to start
    the test. Amazon SageMaker already offers a large amount of example code for you
    to get started. To access these examples, please refer to the SageMaker Examples
    tab:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fd2105b1-8f7c-445e-b19e-766c8774aadb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The code that we use in this chapter is also a modification of the image classification
    example provided by SageMaker. You can create a new notebook with the kernel of `conda_python3`:'
  prefs: []
  type: TYPE_NORMAL
- en: In chapters such as Chapter 5, *Customer Segmentation Using Clustering Algorithms*, and
    Chapter 6, *Analyzing Visitor Patterns to Make Recommendations*, we used the high-level
    `sagemaker` Python library provided by Amazon. Here, we have chosen to show how
    to use the SageMaker generic client from the `boto3` library. This library provides
    a declarative interface that more closely resembles the API behind SageMaker.
    Hopefully, you the reader can grasp the lower-level calls made to the API through
    the examples in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We provide a code example here on how to use the boto3 client to create an image
    classification model using Amazon Sagemaker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Initialize the role and the image-classification image that we want to use
    in SageMaker, then specify the name of our bucket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The training image called **image-classification** is a Docker image of the
    image-classification algorithm. Amazon SageMaker provides a large variety of such
    images, which you can use to train your classifiers. Each image has its own tuning
    parameters, which you can also provide when training that algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will declare these tuning parameters, in the following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: An image classification algorithm uses deep neural networks; these parameters
    will be familiar to you as we studied them in [Chapter 7](c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml), *Implementing
    Deep Learning Algorithms*.
  prefs: []
  type: TYPE_NORMAL
- en: We define the number of hidden layers that will be used by the deep learning
    algorithm. We also have to specify the number of channels and the size of each
    image. We define the number of training images and the number of classes (object
    types). The number of epochs defines the number of times we will iterate over
    the training dataset. The accuracy of the deep learning classifier increases with
    the number of iterations we have over the dataset. The learning rate defines the
    number of changes the deep learning algorithm is allowed to make to the weights.
  prefs: []
  type: TYPE_NORMAL
- en: We would recommend that you run this algorithm with different parameters to
    observe the effects on evaluation and training time.
  prefs: []
  type: TYPE_NORMAL
- en: Once we define the parameters, we initialize the boto3 client for S3, where
    we have stored our training and validation files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We construct a JSON with all the parameters required to train our image classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: There are a lot of things to learn in this JSON. We define the algorithm that
    we want to use for training in the `AlgorithmSpecification` section. `OutputDataConfig`
    defines where the model will be stored. `ResourceConfig` defines the instance
    type to be used for a training job. Note that tasks such as image classification
    run faster on GPU-based instances on AWS. All the parameters for the algorithm
    are defined in the `HyperParameters` section. We set the training dataset and
    the validation dataset under the `InputDataConfig` section of JSON. This JSON
    configuration will be used in the next code block to set parameters for the training
    job.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block starts a `sagemaker` training job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'After you start the training job, you can observe its progress of the training
    job on your Amazon SageMaker dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/229b3113-8c8b-41d0-8177-b633091ff6d0.png)'
  prefs: []
  type: TYPE_IMG
- en: This dashboard also shows you statistics for your model, including the CPU and
    GPU usage, and the memory utilization. You can also observe the training and validation
    accuracy of the model we're training on this dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we are only using two epochs, the training accuracy of this model is
    low:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02b8ba3c-aeca-420c-a9b0-34140709c671.png)'
  prefs: []
  type: TYPE_IMG
- en: You have successfully trained an image classification model using SageMaker.
    SageMaker is very easy to use, as you just have to select the algorithm image,
    select the training dataset, and set the parameters for the algorithm. SageMaker
    automatically trains the model based on this information and also stores the model
    on your S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying images using Amazon SageMaker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The SageMaker models that you have trained are now available to be used to predict
    objects in images. As we discussed at the beginning of the chapter, SageMaker
    offers a marketplace where you can use many models directly to perform your tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Since we trained our own machine learning model, we will have to create a SageMaker
    model that can be used for prediction. The following code shows how to generate
    a usable model in Amazon Sagemaker
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: To create a model in SageMaker, we have to specify the model name that was generated
    in the previous steps. In our example, the model name was set to `example-full-image-classification-model`.
    We also have to specify the container in which the model will be stored. Since
    we used the image-classification Docker image to generate this model, we have
    to specify it as a parameter. This image will help SageMaker read the trained
    model and define how it can be used for prediction.
  prefs: []
  type: TYPE_NORMAL
- en: The `create_model` function will create the model and return an **Amazon Resource
    Name** (**ARN **) for the model. This can be used to call the model to generate
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'For testing, we will download the raw images from the `Caltech256` dataset
    and store them in an `S3` bucket. We will use these images to generate predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have downloaded all the images and stored them in an S3 bucket, we
    specify the parameters for running a batch prediction job. This job will predict
    the probability of each of the 256 objects being present in an image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As you might have guessed, we have to specify the model name in the `ModelName`
    parameter and the input folder in the `TransformInput` parameter. We also have
    to specify the `output` folder where the predictions are stored. We have to specify
    the instance type that we are using in the `TransformResources` parameter and
    the max number of files to process in the `MaxConcurrentTransforms` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code uses the parameters and starts the `create_transform_job`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You can monitor your transforms job on the SageMaker dashboard under Inference
    | Batch Transforms Jobs section. Once the task is finished, you can access the
    predictions in the S3 bucket you specified as the `output` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'The predictions can be seen in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Since our model had 256 object categories, the output specifies the probability
    of each object being present in the image. You can run the model on various datasets
    to check whether your model can predict the objects in the dataset correctly.
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker offers a very easy-to-use service to not only train deep learning
    models but also to use them in applications to generate predictions. Although
    the service is very intuitive, SageMaker is expensive when you use the pre-built
    models on a large dataset to generate predictions. Based on the application being
    developed, data scientists should always consider the overall cost they would
    incur when using such services compared to building the same models on their own
    clusters in Apache Spark.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we studied how Amazon SageMaker offers various ready-to-use
    machine learning models to generate predictions, as well as algorithm images that
    can be used to train your models. Amazon SageMaker generates a layer of abstraction
    between you and the messy details of setting up your own clusters to train and
    create your own machine learning model. Amazon SageMaker dashboards also offer
    a place to store your trained models and monitor your batch-processing jobs for
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: You can also train your own machine learning models using your own datasets
    in SageMaker. We presented an example of training a machine learning model that
    is capable of performing object detection in images. We demonstrated how this
    model can then be deployed on SageMaker and used for running batch-prediction
    jobs. You will be able to use this as a template to work on other algorithms in
    Amazon SageMaker.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, our aim is to provide you with an understanding of how machine
    learning algorithms work and how you can utilize powerful tools such as Apache
    Spark, Tensorflow, and SageMaker to deploy large-scale training and prediction
    jobs using machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For each of the examples provide in previous chapters, find an algorithm in
    Amazon SageMaker Marketplace that would be applicable to solve that problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon SageMaker also provides a service to create endpoints to generate predictions.
    For the preceding example, create an endpoint for the model that we trained and
    generate predictions for one image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
