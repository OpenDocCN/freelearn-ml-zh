- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Kubernetes Container Orchestration Infrastructure Management
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 容器编排基础设施管理
- en: While establishing a local data science setup for individual use for simple
    ML tasks may seem straightforward, creating a robust and scalable data science
    environment for multiple users (catering to diverse ML tasks and effectively tracking
    ML experiments) poses significant challenges. To overcome the scalability and
    control challenges of having a large number of users, companies normally implement
    ML platforms. There are different approaches to building ML platforms including
    build-your-own using open-source technologies or fully managed cloud ML platforms.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然为简单的机器学习任务建立个人使用的本地数据科学设置可能看起来很简单，但为多个用户创建一个强大且可扩展的数据科学环境（满足多样化的机器学习任务并有效跟踪机器学习实验）则面临着重大挑战。为了克服大量用户带来的可扩展性和控制挑战，公司通常实施机器学习平台。构建机器学习平台的方法有很多，包括使用开源技术自行构建或使用完全托管的云机器学习平台。
- en: In this chapter, we will explore the open-source option, and specifically, Kubernetes,
    an indispensable open-source container orchestration platform that serves as a
    critical foundation for constructing open-source ML platforms. Kubernetes offers
    a wealth of capabilities, enabling the seamless management and orchestration of
    containers at scale. By leveraging Kubernetes, organizations can efficiently deploy
    and manage ML workloads, ensuring high availability, scalability, and resource
    utilization optimization.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨开源选项，特别是 Kubernetes，这是一个不可或缺的开源容器编排平台，它是构建开源机器学习平台的关键基础。Kubernetes
    提供了丰富的功能，能够无缝管理和编排大规模容器。通过利用 Kubernetes，组织可以高效地部署和管理机器学习工作负载，确保高可用性、可扩展性和资源利用率优化。
- en: We will delve into the core concepts of Kubernetes, gaining insights into its
    networking architecture and essential components. Furthermore, we will explore
    its robust security features and granular access control mechanisms, crucial for
    safeguarding ML environments and sensitive data. Through practical exercises,
    you will have the opportunity to build your own Kubernetes cluster and leverage
    its power to deploy containerized applications.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将深入研究 Kubernetes 的核心概念，了解其网络架构和基本组件。此外，我们还将探索其强大的安全特性和细粒度的访问控制机制，这对于保护机器学习环境和敏感数据至关重要。通过实际练习，你将有机会构建自己的
    Kubernetes 集群，并利用其力量部署容器化应用程序。
- en: 'Specifically, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将涵盖以下主题：
- en: Introduction to containers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器简介
- en: Kubernetes overview and core concepts
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 概述和核心概念
- en: Kubernetes networking
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 网络
- en: Kubernetes security and access control
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 安全性和访问控制
- en: Hands-on lab – building a Kubernetes infrastructure on AWS
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实践实验室 - 在 AWS 上构建 Kubernetes 基础设施
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You will continue to use services in your AWS account for the hands-on portion
    of the chapter. We will be using several AWS services, including the AWS **Elastic
    Kubernetes Service** (**EKS**), AWS **CloudShell**, and AWS **EC2**. All code
    files used in this chapter are located on GitHub: [https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/tree/main/Chapter06](https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/tree/main/Chapter06).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的实践部分，你将继续使用 AWS 账户中的服务。我们将使用多个 AWS 服务，包括 AWS **弹性 Kubernetes 服务**（**EKS**）、AWS
    **CloudShell** 和 AWS **EC2**。本章中使用的所有代码文件都位于 GitHub 上：[https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/tree/main/Chapter06](https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/tree/main/Chapter06)。
- en: Introduction to containers
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器简介
- en: To understand Kubernetes, we first need to understand containers as they are
    the core building blocks of Kubernetes. A **container** is a form of operating
    system virtualization and is a very popular computing platform for software deployment
    and running modern software based on microservices architecture. A container allows
    you to package and run computer software with isolated dependencies. Compared
    to server virtualization, such as Amazon EC2 or **VMware** virtual machines, containers
    are more lightweight and portable, as they share the same operating system and
    do not contain operating system images in each container. Each container has its
    own filesystem, shares of computing resources, and process space for the custom
    applications running inside it.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解Kubernetes，我们首先需要了解容器，因为它们是Kubernetes的核心构建块。**容器**是一种操作系统虚拟化形式，并且是软件部署和基于微服务架构的现代软件的非常流行的计算平台。容器允许您将计算机软件打包并运行，同时具有隔离的依赖关系。与Amazon
    EC2或**VMware**虚拟机等服务器虚拟化相比，容器更轻量级、更便携，因为它们共享相同的操作系统，并且每个容器中不包含操作系统镜像。每个容器都有自己的文件系统、共享的计算资源以及运行在其内部的自定义应用程序的进程空间。
- en: The concept of containerization technology traced back to the 1970s with the
    **chroot system** and **Unix Version 7**. However, container technology did not
    gain much attention in the software development community for the next two decades
    and remained dormant. While it picked up some steam and made remarkable advances
    from 2000 to 2011, it was the introduction of **Docker** in 2013 that started
    a renaissance of container technology.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 容器技术的概念可以追溯到20世纪70年代的**chroot系统**和**Unix Version 7**。然而，在接下来的二十年里，容器技术在软件开发社区中并没有引起太多关注，一直处于休眠状态。虽然它在2000年到2011年期间取得了一些进展，但直到2013年**Docker**的引入才使容器技术迎来了复兴。
- en: You can run all kinds of applications inside containers, such as simple programs
    like data processing scripts or complex systems like databases. The following
    diagram illustrates how container deployment is different from other types of
    deployment. With bare metal deployment, all different applications share the same
    hosting operating systems. If there is an issue with the hosting operating system,
    all applications will be impacted on the same physical machine.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在容器内运行各种应用程序，例如数据处理脚本等简单程序或数据库等复杂系统。以下图表说明了容器部署与其他类型部署的不同之处。在裸金属部署中，所有不同的应用程序共享相同的宿主操作系统。如果宿主操作系统出现问题，所有应用程序都会在同一台物理机器上受到影响。
- en: 'With the virtualized deployment, multiple guest operating systems can share
    the same hosting operating system. If one guest operating system has an issue,
    only the applications running in that guest operating system are impacted. Each
    guest operating system would have a full installation, thus consuming a lot of
    resources. With container deployment, a container runtime runs on a single host
    operating system, allowing the sharing of some common resources, while still providing
    the isolation of different environments for running different applications. A
    container is a lot more lightweight than a guest operating system, thus much more
    resource-efficient and faster. Note that a container runtime can also run in the
    guest operating system of a virtualized environment to host containerized applications:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在虚拟化部署中，多个虚拟操作系统可以共享相同的宿主操作系统。如果一个虚拟操作系统出现问题，只有在该虚拟操作系统上运行的应用程序会受到影響。每个虚拟操作系统都会有一个完整的安装，因此会消耗大量资源。在容器部署中，容器运行时在单个宿主操作系统上运行，允许共享一些公共资源，同时仍然为运行不同应用程序的不同环境提供隔离。容器比虚拟操作系统轻得多，因此资源效率更高，速度更快。请注意，容器运行时也可以在虚拟化环境的虚拟操作系统上运行，以托管容器化应用程序：
- en: '![Figure 6.1 – The differences between bare metal, virtualized, and container
    deployment ](img/B20836_06_01.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图6.1 – 裸金属、虚拟化和容器部署之间的差异](img/B20836_06_01.png)'
- en: 'Figure 6.1: The differences between bare metal, virtualized, and container
    deployment'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1：裸金属、虚拟化和容器部署之间的差异
- en: Containers are packaged as Docker images, which are made of all the files (such
    as installation, application code, and dependencies) that are essential for running
    the containers and the applications in them. One way to build a Docker image is
    the use of a `Dockerfile` – a plain-text file that provides specifications on
    how to build a Docker image. Once a Docker image is created, it can be executed
    in a container runtime environment.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 容器被打包成Docker镜像，这些镜像包含了运行容器及其中的应用程序所必需的所有文件（例如安装文件、应用程序代码和依赖项）。构建Docker镜像的一种方法就是使用`Dockerfile`
    – 这是一个纯文本文件，它提供了如何构建Docker镜像的规范。一旦创建了Docker镜像，它就可以在容器运行时环境中执行。
- en: 'The following is an example `Dockerfile` for building a Docker image to create
    a runtime environment based on the **Ubuntu** operating system (the `FROM` instruction)
    and install various **Python** packages, such as `python3`, `numpy`, `scikit-learn`,
    and `pandas` (the `RUN` instructions):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例`Dockerfile`，用于构建基于**Ubuntu**操作系统（`FROM`指令）的运行环境，并安装各种**Python**包，如`python3`、`numpy`、`scikit-learn`和`pandas`（`RUN`指令）：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To build a Docker image from this `Dockerfile`, you can use the `Docker build
    - < Dockerfile` command, which is a utility that comes as part of the Docker installation.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要从此`Dockerfile`构建Docker镜像，你可以使用`Docker build - < Dockerfile`命令，这是一个作为Docker安装的一部分提供的实用工具。
- en: Now we have an understanding of containers, next, let’s dive into Kubernetes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了容器，接下来，让我们深入了解Kubernetes。
- en: Overview of Kubernetes and its core concepts
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes及其核心概念概述
- en: Managing and orchestrating a small number of containers and containerized applications
    manually within a compute environment can be relatively manageable. However, as
    the number of containers and servers grows, the task becomes increasingly complex.
    Enter Kubernetes, a powerful open-source system specifically designed to address
    these challenges. First introduced in 2014, Kubernetes (commonly abbreviated to
    K8s, derived from replacing “ubernete” with the digit 8) offers a comprehensive
    solution for efficiently managing containers at scale across clusters of servers.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算环境中手动管理和编排少量容器和容器化应用程序相对容易管理。然而，随着容器和服务器数量的增加，这项任务变得越来越复杂。Kubernetes应运而生，这是一个专门设计来应对这些挑战的强大开源系统。Kubernetes（通常简称为K8s，由将“ubernete”替换为数字8而来）首次于2014年推出，为在服务器集群中高效管理大规模容器提供了一个全面的解决方案。
- en: Kubernetes follows a distributed architecture consisting of a master node and
    multiple worker nodes within a server cluster. Here, a server cluster refers to
    the set of machines and resources that Kubernetes manages, and a node is a single
    physical or virtual machine in the cluster.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes遵循分布式架构，由一个主节点和服务器集群内的多个工作节点组成。在这里，服务器集群指的是Kubernetes管理的机器和资源集合，而节点是集群中的单个物理或虚拟机。
- en: 'The master node, often referred to as the control plane, assumes the primary
    role in managing the entire Kubernetes cluster. It receives data about internal
    cluster events, external systems, and third-party applications, then processes
    the data and makes and executes decisions in response. It comprises four essential
    components, each playing a distinct role in the overall system:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点，通常被称为控制平面，在管理整个Kubernetes集群中扮演主要角色。它接收有关内部集群事件、外部系统和第三方应用程序的数据，然后处理这些数据，并据此做出和执行决策。它由四个基本组件组成，每个组件在整体系统中都扮演着独特的角色：
- en: '**API server**: The API server acts as the central communication hub for all
    interactions with the Kubernetes cluster. It provides a RESTful interface through
    which users, administrators, and other components can interact with the cluster.
    The API server handles authentication, authorization, and validation of requests,
    ensuring secure and controlled access to the cluster’s resources.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API服务器**：API服务器充当与Kubernetes集群所有交互的中心通信枢纽。它提供了一个RESTful接口，用户、管理员和其他组件可以通过该接口与集群交互。API服务器处理请求的认证、授权和验证，确保对集群资源的访问既安全又受控。'
- en: '**Scheduler:** The scheduler component is responsible for determining the optimal
    placement of workloads or Pods across the available worker nodes within the cluster.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调度器**：调度器组件负责确定工作负载或Pod在集群内可用工作节点中的最佳放置位置。'
- en: '**Controller:** The controller manager oversees the cluster’s overall state
    and manages various background tasks to maintain the desired system state.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制器**：控制器管理器负责监控集群的整体状态，并管理各种后台任务以维护所需的系统状态。'
- en: '**etcd:** etcd is a distributed key-value store that serves as the cluster’s
    reliable data store, ensuring consistent and consistent access to critical configuration
    and state information. It stores the cluster’s current state, configuration details,
    and other essential data, providing a reliable source of truth for the entire
    system.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**etcd**：etcd 是一个分布式键值存储，作为集群的可靠数据存储，确保对关键配置和状态信息的持续和一致访问。它存储集群的当前状态、配置细节和其他必要数据，为整个系统提供可靠的真实来源。'
- en: Lastly, worker nodes are machines that run containerized workloads.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，工作节点是运行容器化工作负载的机器。
- en: 'The following figure shows the core architecture components of a Kubernetes
    cluster:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 Kubernetes 集群的核心理念组件：
- en: '![Figure 6.2 – Kubernetes architecture ](img/B20836_06_02.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.2 – Kubernetes 架构](img/B20836_06_02.png)'
- en: 'Figure 6.2: Kubernetes architecture'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.2：Kubernetes 架构
- en: The master node exposes the **API server** layer, which allows programmatic
    control of the cluster. An example of an API call could be the deployment of a
    web application on the cluster. The control plane also tracks and manages all
    configuration data in **etcd**, which is responsible for storing all the cluster
    data, such as the desired number of container images to run, compute resource
    specification, and size of storage volume for a web application running on the
    cluster. Kubernetes uses the **controller** to monitor the current states of Kubernetes
    resources and take the necessary actions (for example, request the change via
    the API server) to move the current states to the desired states if there are
    differences (such as the difference in the number of the running containers) between
    the two states. The controller manager in the master node is responsible for managing
    all the Kubernetes controllers. Kubernetes comes with a set of built-in controllers
    such as **scheduler**, which is responsible for scheduling **Pods** (units of
    deployment, which we will discuss in more detail later) to run on worker nodes
    when there is a change request.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点暴露了 **API 服务器** 层，它允许对集群进行程序化控制。一个 API 调用的例子可能是将一个网络应用程序部署到集群中。控制平面还跟踪和管理所有配置数据在
    **etcd** 中，它负责存储所有集群数据，例如要运行的容器镜像数量、计算资源规范以及运行在集群上的网络应用程序的存储卷大小。Kubernetes 使用
    **控制器** 来监控 Kubernetes 资源当前的状态，并采取必要的行动（例如，通过 API 服务器请求更改）将当前状态移动到所需状态，如果两个状态之间存在差异（例如运行容器的数量差异），则进行操作。主节点中的控制器管理器负责管理所有的
    Kubernetes 控制器。Kubernetes 随带一套内置控制器，例如 **调度器**，它负责在出现更改请求时将 **Pods**（部署的单位，我们将在后面详细讨论）调度到工作节点上。
- en: Other examples include the **Job controller**, which is responsible for running
    and stopping one or more Pods for a task, and the **Deployment controller**, which
    is responsible for deploying Pods based on a deployment manifest, such as a deployment
    manifest for a web application.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其他例子包括 **作业控制器**，它负责运行和停止一个或多个 Pod 以完成任务，以及 **部署控制器**，它负责根据部署清单部署 Pods，例如网络应用程序的部署清单。
- en: To interact with a Kubernetes cluster control plane, you can use the `kubectl`
    command-line utility, the Kubernetes Python client ([https://github.com/kubernetes-client/python](https://github.com/kubernetes-client/python)),
    or access it directly using the RESTful API. You can find a list of supported
    `kubectl` commands at [https://kubernetes.io/docs/reference/kubectl/cheatsheet/](https://kubernetes.io/docs/reference/kubectl/cheatsheet/).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要与 Kubernetes 集群控制平面交互，你可以使用 `kubectl` 命令行工具、Kubernetes Python 客户端([https://github.com/kubernetes-client/python](https://github.com/kubernetes-client/python))，或者直接通过
    RESTful API 访问。你可以在 [https://kubernetes.io/docs/reference/kubectl/cheatsheet/](https://kubernetes.io/docs/reference/kubectl/cheatsheet/)
    找到支持的 `kubectl` 命令列表。
- en: There are several fundamental technical concepts that form the core of the Kubernetes
    architecture. These concepts are essential to understanding and effectively working
    with Kubernetes. Let’s look at some of the key concepts in detail.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 架构的核心由几个基本的技术概念构成。这些概念对于理解和有效地使用 Kubernetes 是必不可少的。让我们详细看看一些关键概念。
- en: Namespaces
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命名空间
- en: Namespaces organize clusters of worker machines into virtual sub-clusters. They
    are used to provide logical separation of resources owned by different teams and
    projects while still allowing ways for different namespaces to communicate. A
    namespace can span multiple worker nodes, and it can be used to group a list of
    permissions under a single name to allow authorized users to access resources
    in a namespace. Resource usage controls can be enforced to namespaces such as
    quotas for CPU and memory resources. Namespaces also make it possible to name
    resources with identical names if the resources reside in different namespaces
    to avoid naming conflicts. By default, there is a `default` namespace in Kubernetes.
    You can create additional namespaces as needed. The default namespace is used
    if a namespace is not specified.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间将工作机器集群组织成虚拟子集群。它们被用来提供不同团队和项目拥有的资源的逻辑分离，同时仍然允许不同命名空间之间的通信。命名空间可以跨越多个工作节点，并且可以用来将一组权限分组在单个名称下，以便授权用户访问命名空间中的资源。可以对命名空间实施资源使用控制，例如
    CPU 和内存资源的配额。命名空间还使得当资源位于不同的命名空间中时，可以以相同的名称命名资源，以避免命名冲突。默认情况下，Kubernetes 中有一个
    `default` 命名空间。根据需要，你可以创建额外的命名空间。如果没有指定命名空间，则使用默认命名空间。
- en: Pods
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pod
- en: Kubernetes deploys computing in a logical unit called a Pod. All Pods must belong
    to a Kubernetes namespace (either the default namespace or a specified namespace).
    One or more containers can be grouped into a Pod, and all containers in the Pod
    are deployed and scaled together as a single unit and share the same context,
    such as Linux namespaces and filesystems. Each Pod has a unique IP address that’s
    shared by all the containers in the Pod. A Pod is normally created as a workload
    resource, such as a Kubernetes Deployment or Kubernetes Job.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 以一个称为 Pod 的逻辑单元来部署计算。所有 Pod 必须属于一个 Kubernetes 命名空间（无论是默认命名空间还是指定的命名空间）。一个或多个容器可以被组合成一个
    Pod，并且 Pod 中的所有容器作为一个单一单元一起部署和扩展，并共享相同的环境，例如 Linux 命名空间和文件系统。每个 Pod 都有一个唯一的 IP
    地址，该地址由 Pod 中的所有容器共享。Pod 通常作为工作负载资源创建，例如 Kubernetes Deployment 或 Kubernetes Job。
- en: '![Figure 6.3 – Namespaces, Pods, and containers ](img/B20836_06_03.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.3 – 命名空间、Pod 和容器](img/B20836_06_03.png)'
- en: 'Figure 6.3: Namespaces, Pods, and containers'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3：命名空间、Pod 和容器
- en: The preceding figure shows the relationship between namespaces, Pods, and containers
    in a Kubernetes cluster. In this figure, each namespace contains its own set of
    Pods and each Pod can contain one or more containers running in it.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图示展示了 Kubernetes 集群中命名空间、Pod 和容器之间的关系。在这个图中，每个命名空间包含其自己的 Pod 集合，并且每个 Pod
    可以包含一个或多个在其中运行的容器。
- en: Deployment
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Deployment
- en: 'A Deployment is used by Kubernetes to create or modify Pods that run containerized
    applications. For example, to deploy a containerized application, you create a
    configuration manifest file (usually in a `YAML` file format) that specifies details,
    such as the container deployment name, namespaces, container image URI, number
    of Pod replicas, and the communication port for the application. After the Deployment
    is applied using a Kubernetes client utility (`kubectl`), the corresponding Pods
    running the specified container images will be created on the worker nodes. The
    following example creates a Deployment of Pods for an `nginx` server with the
    desired specification:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用 Deployment 来创建或修改运行容器化应用程序的 Pod。例如，要部署一个容器化应用程序，你需要创建一个配置清单文件（通常以
    `YAML` 文件格式），该文件指定了详细信息，例如容器部署名称、命名空间、容器镜像 URI、Pod 副本数量以及应用程序的通信端口。使用 Kubernetes
    客户端工具（`kubectl`）应用 Deployment 后，将在工作节点上创建运行指定容器镜像的相应 Pod。以下示例创建了一个具有所需规范的 `nginx`
    服务器 Pod 的 Deployment：
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following figure shows the flow of applying the preceding deployment manifest
    file to a Kubernetes cluster and creating two Pods to host two copies of the `nginx`
    container:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示展示了将前面的部署清单文件应用到 Kubernetes 集群中，并创建两个 Pod 来托管两个 `nginx` 容器副本的过程：
- en: '![Figure 6.4 – Creating an Nginx deployment ](img/B20836_06_04.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.4 – 创建 Nginx 部署](img/B20836_06_04.png)'
- en: 'Figure 6.4: Creating an nginx deployment'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.4：创建 nginx 部署
- en: After the Deployment, a Deployment controller monitors the deployed container
    instances. If an instance goes down, the controller will replace it with another
    instance on the worker node.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Deployment 之后，一个 Deployment 控制器会监控已部署的容器实例。如果一个实例宕机，控制器将用工作节点上的另一个实例替换它。
- en: Kubernetes Job
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes Job
- en: 'A Kubernetes Job is a controller that creates one or more Pods to run some
    tasks and ensures the job is successfully completed. If a number of Pods fail
    due to node failure or other system issues, a Kubernetes Job will recreate the
    Pods to complete the task. A Kubernetes Job can be used to run batch-oriented
    tasks, such as running batch data processing scripts, ML model training scripts,
    or ML batch inference scripts on a large number of inference requests. After a
    Job is completed, the Pods are not terminated, so you can access the Job logs
    and inspect the detailed status of the Job. The following is an example template
    for running a training job:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes作业是一个控制器，用于创建一个或多个Pod来运行一些任务，并确保作业成功完成。如果由于节点故障或其他系统问题导致多个Pod失败，Kubernetes作业将重新创建Pod以完成任务。Kubernetes作业可用于运行面向批处理的任务，例如在大量推理请求上运行批数据处理脚本、ML模型训练脚本或ML批推理脚本。作业完成后，Pod不会终止，因此您可以访问作业日志并检查作业的详细状态。以下是一个运行训练作业的示例模板：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that this configuration contains a parameter called `restartPolicy`, which
    controls how the Pod is restarted when the container exits and fails. There are
    three configurations:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，此配置包含一个名为`restartPolicy`的参数，它控制容器退出并失败时Pod的重新启动方式。有三个配置：
- en: '`OnFailure`: Only restart the Pod if it fails, not if it succeeds. This is
    the default.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OnFailure`：只有当Pod失败时才重新启动Pod，而不是成功时。这是默认设置。'
- en: '`Never`: Do not restart the Pod under any circumstances.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Never`：在任何情况下都不重新启动Pod。'
- en: '`Always`: Always restart the Pod regardless of its exit status.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Always`：无论Pod的退出状态如何，总是重新启动Pod。'
- en: You can use this parameter to control whether you want to restart training if
    the container terminates on failure.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用此参数来控制是否希望在容器失败时重新启动训练。
- en: Kubernetes custom resources and operators
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes自定义资源和操作符
- en: Kubernetes provides a list of built-in resources, such as Pods or Deployments
    for different needs. It also allows you to create **custom resources** (**CRs**)
    and manage them just like the built-in resources, and you can use the same tools
    (such as `kubectl`) to manage them. When you create the CR in Kubernetes, Kubernetes
    creates a new API (for example, `<custom resource name>/<version>`) for each version
    of the resource. This is also known as *extending* the Kubernetes APIs. To create
    a CR, you create a **custom resource definition** (**CRD**) `YAML` file. To register
    the CRD in Kubernetes, you simply run `kubectl apply -f <name of the CRD yaml
    file>` to apply the file. After that, you can use it just like any other Kubernetes
    resource. For example, to manage a custom model training job on Kubernetes, you
    can define a CRD with specifications such as algorithm name, data encryption setting,
    training image, input data sources, number of job failure retries, number of replicas,
    and job liveness probe frequency.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes提供了一系列内置资源，例如Pod或Deployment，以满足不同的需求。它还允许您创建**自定义资源**（**CR**）并像管理内置资源一样管理它们，您可以使用相同的工具（例如`kubectl`）来管理它们。当您在Kubernetes中创建CR时，Kubernetes为资源的每个版本创建一个新的API（例如，`<自定义资源名称>/<版本>`）。这也被称为*扩展*Kubernetes
    API。要创建CR，您创建一个**自定义资源定义**（**CRD**）`YAML`文件。要在Kubernetes中注册CRD，您只需运行`kubectl apply
    -f <CRD yaml文件名称>`来应用文件。之后，您就可以像使用任何其他Kubernetes资源一样使用它。例如，要管理Kubernetes上的自定义模型训练作业，您可以定义一个CRD，其中包含算法名称、数据加密设置、训练镜像、输入数据源、作业失败重试次数、副本数量和作业存活探测频率等规范。
- en: 'A Kubernetes operator is a controller that operates on a custom resource. The
    operator watches the CR types and takes specific actions to make the current state
    match the desired state, just as a built-in controller does. For example, if you
    want to create a training job for the training job CRD mentioned previously, you
    create an operator that monitors training job requests and performs application-specific
    actions to start up the Pods and run the training job throughout the lifecycle.
    The following figure shows the components involved with an operator deployment:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes操作符是一个在自定义资源上操作的控制器。操作符监视CR类型并采取特定操作以使当前状态与所需状态相匹配，就像内置控制器一样。例如，如果您想为之前提到的训练作业CRD创建一个训练作业，您将创建一个操作符来监控训练作业请求并执行特定于应用程序的操作以启动Pod并在整个生命周期中运行训练作业。以下图显示了与操作符部署相关的组件：
- en: '![Figure 6.5 – A Kubernetes custom resource and its interaction with the operator
    ](img/B20836_06_05.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图6.5 – Kubernetes自定义资源和它与操作符的交互](img/B20836_06_05.png)'
- en: 'Figure 6.5: A Kubernetes custom resource and its interaction with the operator'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5：Kubernetes自定义资源和它与操作符的交互
- en: The most common way to deploy an operator is to deploy a CR definition and the
    associated controller. The controller runs outside of the Kubernetes control plane,
    similar to running a containerized application in a Pod.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 部署操作员的最常见方式是部署CR定义和相关控制器。控制器在Kubernetes控制平面外部运行，类似于在Pod中运行容器化应用程序。
- en: Services
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务
- en: Kubernetes Services play a crucial role in enabling reliable and scalable communication
    between various components and applications within a Kubernetes cluster.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes服务在Kubernetes集群内各种组件和应用程序之间实现可靠和可扩展的通信中发挥着关键作用。
- en: As applications in a cluster are often dynamic and can be scaled up or down,
    Services provide a stable and abstracted endpoint that other components can use
    to access the running instances of those applications.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 由于集群中的应用程序通常是动态的，并且可以扩展或缩减，因此服务提供了一种稳定和抽象的端点，其他组件可以使用它来访问这些应用程序的运行实例。
- en: At its core, a Kubernetes Service is an abstraction layer that exposes a set
    of Pods as a single, well-defined network endpoint. It acts as a load balancer,
    distributing incoming network traffic to the available Pods behind the Service.
    This abstraction allows applications to interact with the Service without needing
    to know the specific details of the underlying Pods or their IP addresses.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，Kubernetes服务是一个抽象层，它将一组Pod作为单个、定义良好的网络端点暴露出来。它充当负载均衡器，将进入的网络流量分发到服务后面的可用Pod。这种抽象允许应用程序与服务交互，而无需了解底层Pod或其IP地址的详细信息。
- en: Networking on Kubernetes
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes上的网络
- en: 'Kubernetes operates a flat private network among all the resources in a Kubernetes
    cluster. Within a cluster, all Pods can communicate with each other cluster-wide
    without a **network address translation** (**NAT**). Kubernetes gives each Pod
    its own cluster private IP address, which is the same IP address seen by the Pod
    itself and what others see it as. All containers inside a single Pod can reach
    each container’s port on the localhost. All nodes in a cluster have their individually
    assigned IP addresses as well and can communicate with all Pods without a NAT.
    The following figure shows the different IP assignments for Pods and nodes, and
    communication flows from different resources:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes在Kubernetes集群中的所有资源之间运行一个扁平的私有网络。在集群内部，所有Pod都可以在集群范围内相互通信，无需**网络地址转换**（**NAT**）。Kubernetes为每个Pod分配其自己的集群私有IP地址，这个IP地址既是Pod自身看到的，也是其他人看到的。单个Pod内部的全部容器都可以到达本地主机上每个容器的端口。集群中的所有节点也有各自分配的IP地址，并且可以无需NAT与所有Pod进行通信。以下图显示了Pod和节点的不同IP分配，以及来自不同资源的通信流程：
- en: '![Figure 6.6 – IP assignments and communication flow ](img/B20836_06_06.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图6.6 – IP分配和通信流程](img/B20836_06_06.png)'
- en: 'Figure 6.6: IP assignments and communication flow'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6：IP分配和通信流程
- en: 'Sometimes, you might need a set of Pods running the same application container
    (the container for an `nginx` application) for high availability and load balancing,
    for example. Instead of calling each Pod by its private IP address separately
    to access the application running in a Pod, you want to call an abstraction layer
    for this set of Pods, and this abstraction layer can dynamically send traffic
    to each Pod behind it. In this case, you can create a Kubernetes Service as an
    abstraction layer for a logical set of Pods. A Kubernetes Service can dynamically
    select the Pod behind it by matching an `app` label for the Pod using a Kubernetes
    feature called `selector`. The following example shows the specification that
    would create a Service called `nginx-service`, which sends traffic to Pods with
    the app `nginx` label on port `9376`. A service is also assigned with its own
    cluster private IP address, so it is reachable by other resources inside a cluster:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，你可能需要运行相同应用程序容器（例如`nginx`应用程序的容器）的一组Pod，以实现高可用性和负载均衡，例如。而不是分别通过每个Pod的私有IP地址调用每个Pod以访问Pod中运行的应用程序，你希望调用一个用于该组Pod的抽象层，并且这个抽象层可以动态地将流量发送到它后面的每个Pod。在这种情况下，你可以创建一个Kubernetes服务作为一组逻辑Pod的抽象层。Kubernetes服务可以通过匹配Pod的`app`标签来动态选择其后面的Pod，这是通过Kubernetes的一个名为`selector`的功能实现的。以下示例显示了创建名为`nginx-service`的服务规范，该服务将流量发送到具有`nginx`标签的Pod，并在端口`9376`上。服务也分配了其自己的集群私有IP地址，因此它可以在集群内部被其他资源访问：
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In addition to using `selector` to automatically detect Pods behind the service,
    you can also manually create an `Endpoint` and map a fixed IP address and port
    to a service, as shown in the following example:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用`selector`自动检测服务后面的Pod之外，您还可以手动创建一个`Endpoint`，并将固定的IP地址和端口映射到服务，如下例所示：
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'While nodes, Pods, and services are all assigned with cluster private IPs,
    these IPs are not routable from outside of a cluster. To access Pods or services
    from outside of a cluster, you have the following options:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然节点、Pod和服务都被分配了集群私有IP，但这些IP在集群外部是不可路由的。要从集群外部访问Pod或服务，您有以下几种选择：
- en: '**Access from a node or Pod**: You can connect to the shell of a running Pod
    using the `kubectl exec` command and access other Pods, nodes, and services from
    the shell.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从节点或Pod访问**：您可以使用`kubectl exec`命令连接到正在运行的Pod的shell，并通过shell访问其他Pod、节点和服务。'
- en: '**Kubernetes proxy**: You can start a Kubernetes proxy to access services by
    running the `kubectl proxy --port=<port number>` command on your local machine.
    Once the proxy is running, you can access nodes, Pods, or services. For example,
    you can access a service using the following scheme:'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes代理**：您可以在本地机器上运行`kubectl proxy --port=<端口号>`命令来启动Kubernetes代理以访问服务。一旦代理启动，您就可以访问节点、Pod或服务。例如，您可以使用以下方案访问服务：'
- en: '[PRE5]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**NodePort**: `NodePort` opens a specific port on all the worker nodes, and
    any traffic sent to this port on the IP address of any of the nodes is forwarded
    to the service behind the port. The nodes’ IP addresses need to be routable from
    external sources. The following figure shows the communication flow using `NodePort`:![Figure
    6.7 – Accessing Kubernetes Service via NodePort ](img/B20836_06_07.png)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NodePort**：`NodePort`在所有工作节点上打开一个特定的端口，并将发送到任何节点IP地址上此端口的任何流量转发到端口后面的服务。节点的IP地址需要从外部源可路由。以下图显示了使用`NodePort`的通信流程：![图6.7
    – 通过NodePort访问Kubernetes服务](img/B20836_06_07.png)'
- en: 'Figure 6.7: Accessing a Kubernetes Service via NodePort'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.7：通过NodePort访问Kubernetes服务
- en: '`NodePort` is simple to use, but it has some limitations, such as one service
    per `NodePort`, a fixed port range to use (`3000` to `32767`), and you need to
    know the IP addresses of individual worker nodes.'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`NodePort`使用简单，但有一些限制，例如每个服务一个`NodePort`，使用固定的端口范围（`3000`到`32767`），并且您需要知道各个工作节点的IP地址。'
- en: '**Load balancer**: A load balancer is a way to expose services to the internet
    when you use a cloud provider such as AWS. With a load balancer, you get a public
    IP address that’s accessible to the internet, and all traffic sent to the IP address
    will be forwarded to the service behind the load balancer. A load balancer is
    not part of Kubernetes and it is provided by whatever cloud infrastructure a Kubernetes
    cluster resides on (for example, AWS). The following figure shows the communication
    flow from a load balancer to services and Pods:![Figure 6.8 – Accessing a Kubernetes
    service via a load balancer ](img/B20836_06_08.png)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载均衡器**：当您使用像AWS这样的云提供商时，负载均衡器是一种将服务暴露给互联网的方式。使用负载均衡器，您将获得一个可访问互联网的公网IP地址，并将发送到该IP地址的所有流量都会转发到负载均衡器后面的服务。负载均衡器不是Kubernetes的一部分，它由Kubernetes集群所在的云基础设施提供（例如，AWS）。以下图显示了从负载均衡器到服务和Pod的通信流程：![图6.8
    – 通过负载均衡器访问Kubernetes服务](img/B20836_06_08.png)'
- en: 'Figure 6.8: Accessing a Kubernetes Service via a load balancer'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.8：通过负载均衡器访问Kubernetes服务
- en: A load balancer allows you to choose the exact port to use and can support multiple
    ports per service. However, it does require a separate load balancer per service.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 负载均衡器允许您选择要使用的确切端口，并且可以支持每个服务多个端口。但是，它确实需要为每个服务配置一个单独的负载均衡器。
- en: '**Ingress**: An Ingress gateway is the entry point to a cluster. It acts as
    a load balancer and routes incoming traffic to the different services based on
    routing rules.![Figure 6.9 – Accessing a Kubernetes service via Ingress ](img/B20836_06_09.png)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ingress**：Ingress网关是集群的入口点。它充当负载均衡器，并根据路由规则将传入流量路由到不同的服务。![图6.9 – 通过Ingress访问Kubernetes服务](img/B20836_06_09.png)'
- en: 'Figure 6.9: Accessing a Kubernetes Service via Ingress'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.9：通过Ingress访问Kubernetes服务
- en: An Ingress is different from a load balancer and `NodePort` in that it acts
    as a proxy to manage traffic to clusters. It works with the `NodePort` and load
    balancer and routes the traffic to the different services. The Ingress way is
    becoming more commonly used, especially in combination with a load balancer.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress 与负载均衡器和 `NodePort` 不同，它充当代理来管理集群的流量。它与 `NodePort` 和负载均衡器协同工作，将流量路由到不同的服务。Ingress
    方式越来越普遍地被使用，尤其是在与负载均衡器结合使用时。
- en: 'In addition to network traffic management from outside of the cluster, another
    important aspect of Kubernetes network management is to control the traffic flow
    between different Pods and services within a cluster. For example, you might want
    to allow certain traffic to access a Pod or service while denying traffic from
    other sources. This is especially important for applications built on microservices
    architecture, as there could be many services or Pods that need to work together.
    Such a network of microservices is also called a **service mesh**. As the number
    of services grows larger, it becomes challenging to understand and manage the
    networking requirements, such as *service discovery*, *network routing*, *network
    metrics*, and *failure recovery*. **Istio** is an open-source service mesh management
    software that makes it easy to manage a large service mesh on Kubernetes, and
    it provides the following core functions:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 除了从集群外部管理网络流量外，Kubernetes 网络管理的另一个重要方面是控制集群内不同 Pods 和服务之间的流量。例如，你可能希望允许某些流量访问一个
    Pod 或服务，同时拒绝来自其他来源的流量。这对于基于微服务架构的应用程序尤为重要，因为可能有多个服务或 Pods 需要协同工作。这样的微服务网络也被称为
    **服务网格**。随着服务数量的增加，理解和管理工作量变得具有挑战性，例如 *服务发现*、*网络路由*、*网络指标* 和 *故障恢复*。**Istio**
    是一款开源的服务网格管理软件，它使得在 Kubernetes 上管理大型服务网格变得简单，并提供以下核心功能：
- en: '**Ingress**: Istio provides an Ingress gateway that can be used to expose Pods
    and services inside a service mesh to the internet. It acts as a load balancer
    that manages the inbound and outbound traffic for the service mesh. A gateway
    only allows traffic to come in/out of a mesh – it does not do routing of the traffic.
    To route traffic from the gateway to the service inside the service mesh, you
    create an object called `VirtualService` to provide routing rules to route incoming
    traffic to different destinations inside a cluster, and you create a binding between
    virtual services and the gateway object to connect the two.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ingress**：Istio 提供了一个 Ingress 网关，可以用来将服务网格内部的服务暴露给互联网。它充当负载均衡器，管理服务网格的入站和出站流量。网关只允许流量进入/离开一个网格——它不进行流量路由。要将流量从网关路由到服务网格内的服务，你需要创建一个名为
    `VirtualService` 的对象来提供路由规则，将入站流量路由到集群内部的不同目的地，并且创建虚拟服务与网关对象之间的绑定来连接两者。'
- en: '**Network traffic management**: Istio provides easy rule-based network routing
    to control the flow of traffic and API calls between different services. When
    Istio is installed, it automatically detects services and endpoints in a cluster.
    Istio uses an object called `VirtualService` to provide routing rules to route
    incoming traffic to different destinations inside a cluster. Istio uses a load
    balancer called `gateway` to manage the inbound and outbound traffic for the network
    mesh. The `gateway` load balancer only allows traffic to come in/out of a mesh
    – it does not do routing of the traffic. To route traffic from the gateway, you
    create a binding between virtual services and the `gateway` object.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络流量管理**：Istio 提供基于规则的简单网络路由，以控制不同服务之间的流量和 API 调用。当 Istio 安装后，它会自动检测集群中的服务和端点。Istio
    使用名为 `VirtualService` 的对象来提供路由规则，将入站流量路由到集群内部的不同目的地。Istio 使用名为 `gateway` 的负载均衡器来管理网络网格的入站和出站流量。`gateway`
    负载均衡器只允许流量进入/离开一个网格——它不进行流量路由。要从网关路由流量，你需要创建虚拟服务与 `gateway` 对象之间的绑定。'
- en: 'In order to manage the traffic in and out of a Pod, an Envoy proxy component
    (aka `sidecar`) is injected into a Pod, and it intercepts and decides how to route
    all traffic. The Istio component that manages the traffic configurations of the
    sidecars and service discovery is called the `Pilot`. The `Citadel` component
    manages authentication for service to service and end user. The `Gallery` component
    is responsible for insulating other Istio components from the underlying Kubernetes
    infrastructure. The following figure shows the architecture of Istio on Kubernetes:'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了管理Pod进出流量，一个Envoy代理组件（也称为`sidecar`）被注入到Pod中，并拦截并决定如何路由所有流量。管理sidecar和服务的流量配置的Istio组件称为`Pilot`。`Citadel`组件负责服务到服务和最终用户身份验证。`Gallery`组件负责隔离其他Istio组件与底层Kubernetes基础设施。以下图显示了Kubernetes上Istio的架构：
- en: '![Figure 6.10 – Istio architecture ](img/B20836_06_10.png)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图6.10 – Istio架构](img/B20836_06_10.png)'
- en: 'Figure 6.10: Istio architecture'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.10：Istio架构
- en: 'Istio also has support for security and observability, which are critical for
    building production systems:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Istio还支持安全和可观察性，这对于构建生产系统至关重要：
- en: '**Security**: Istio provides authentication and authorization for inter-service
    communications.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全**：Istio为服务间通信提供身份验证和授权。'
- en: '**Observability**: Istio captures metrics, logs, and traces of all service
    communications within a cluster. Examples of metrics include network latency,
    errors, and saturation. Examples of traces include call flows and service dependencies
    within a mesh.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可观察性**：Istio捕获集群内所有服务通信的指标、日志和跟踪。指标示例包括网络延迟、错误和饱和度。跟踪示例包括网格内的调用流程和服务依赖。'
- en: Istio can handle a wide range of Deployment needs, such as load balancing and
    service-to-service authentication. It can even extend to other clusters.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Istio可以处理各种部署需求，例如负载均衡和服务间认证。它甚至可以扩展到其他集群。
- en: Security and access management
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全性和访问管理
- en: Security is a critical consideration for building production-grade systems on
    Kubernetes. As a practitioner planning to use Kubernetes as the foundational platform
    for ML, it is important to become familiar with the various security aspects of
    Kubernetes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性是构建Kubernetes上生产级系统的关键考虑因素。作为一名计划将Kubernetes作为ML基础平台的从业者，了解Kubernetes的各种安全方面非常重要。
- en: Kubernetes has many built-in security features. These security features allow
    you to implement fine-grained network traffic control and access control to different
    Kubernetes APIs and services. In this section, we will discuss network security,
    authentication, and authorization.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes有许多内置的安全功能。这些安全功能允许您实现细粒度的网络流量控制和访问控制到不同的Kubernetes API和服务。在本节中，我们将讨论网络安全、身份验证和授权。
- en: API authentication and authorization
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: API身份验证和授权
- en: Access to Kubernetes APIs can be authenticated and authorized for both users
    and Kubernetes **service accounts** (a service account provides an identity for
    processes running in a Pod).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes API的访问可以为用户和Kubernetes **服务帐户**（服务帐户为在Pod中运行的过程提供身份）进行身份验证和授权。
- en: 'Users are handled outside of Kubernetes, and there are a number of user authentication
    strategies for Kubernetes:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 用户在Kubernetes外部处理，并且Kubernetes有多种用户身份验证策略：
- en: '**X.509 client certificate**: A signed certificate is sent to the API server
    for authentication. The API server verifies this with the certificate authority
    to validate the user.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**X.509客户端证书**：一个签名证书被发送到API服务器进行身份验证。API服务器通过与证书颁发机构验证来验证用户。'
- en: '**Single sign-on with OpenID Connect** (**OIDC**): The user authenticates with
    the OIDC provider and receives a bearer token (**JSON** **Web Token** (**JWT**))
    that contains information about the user. The user passes the bearer token to
    the API server, which verifies the validity of the token by checking the certificate
    in the token.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用OpenID Connect进行单点登录**（**OIDC**）：用户通过OIDC提供者进行身份验证，并接收一个包含用户信息的载体令牌（**JSON
    Web Token**（**JWT**））。用户将载体令牌传递给API服务器，API服务器通过检查令牌中的证书来验证令牌的有效性。'
- en: '**HTTP basic authentication**: HTTP basic authentication requires a user ID
    and password to be sent as part of the API request, and it validates the user
    ID and password against a password file associated with the API server.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HTTP基本身份验证**：HTTP基本身份验证要求将用户ID和密码作为API请求的一部分发送，并验证用户ID和密码是否与API服务器关联的密码文件匹配。'
- en: '**Authentication proxy**: The API server extracts the user identity in the
    HTTP header and verifies the user with the certificate authority.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**身份验证代理**：API 服务器从 HTTP 头中提取用户身份，并使用证书颁发机构验证用户。'
- en: '**Authentication webhook**: An external service is used for handling the authentication
    for the API server.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**身份验证网关**：用于处理 API 服务器身份验证的外部服务。'
- en: Service accounts are used to provide identity for processes running in a Pod.
    They are created and managed in Kubernetes. Service accounts need to reside within
    a namespace, by default. There is also a *default* service account in each namespace.
    If a Pod is not assigned a service account, the default service account will be
    assigned to the Pod. A service account has an associated authentication token,
    saved as a Kubernetes Secret, and used for API authentication. A Kubernetes Secret
    is used for storing sensitive information such as passwords, authentication tokens,
    and SSH keys. We will cover Secrets in more detail later in this chapter.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 服务帐户用于为在 Pod 中运行的进程提供身份。它们在 Kubernetes 中创建和管理。默认情况下，服务帐户需要位于命名空间内。每个命名空间还有一个
    *默认* 服务帐户。如果 Pod 未分配服务帐户，则默认服务帐户将被分配给 Pod。服务帐户有一个相关的身份验证令牌，以 Kubernetes Secret
    的形式保存，并用于 API 身份验证。Kubernetes Secret 用于存储敏感信息，如密码、身份验证令牌和 SSH 密钥。我们将在本章后面更详细地介绍
    Secrets。
- en: 'After a user or service account is authenticated, the request needs to be authorized
    to perform allowed operations. Kubernetes authorizes authenticated requests using
    the API server in the control plane, and it has several modes for authorization:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 用户或服务帐户经过身份验证后，请求需要授权以执行允许的操作。Kubernetes 使用控制平面中的 API 服务器授权经过身份验证的请求，并且它有几种授权模式：
- en: '**Attribute-based access control** (**ABAC**): Access rights are granted to
    users through policies. Note that every service account has a corresponding username.
    The following sample policy allows the `joe` user access to all APIs in all namespaces.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于属性的访问控制**（**ABAC**）：通过策略授予用户访问权限。请注意，每个服务帐户都有一个相应的用户名。以下示例策略允许 `joe` 用户访问所有命名空间中的所有
    API。'
- en: '[PRE6]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following policy allows the `system:serviceaccount:kube-system:default`
    service account access to all APIs in all namespaces:'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下策略允许 `system:serviceaccount:kube-system:default` 服务帐户访问所有命名空间中的所有 API：
- en: '[PRE7]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Role-based access control** (**RBAC**): Access rights are granted based on
    the role of a user. RBAC authorizes using the `rbac.authorization.k8s.io` API
    group. The RBAC API works with four Kubernetes objects: `Role`, `ClusterRole`,
    `RoleBinding`, and `ClusterRoleBinding`.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于角色的访问控制**（**RBAC**）：根据用户的角色授予访问权限。RBAC 使用 `rbac.authorization.k8s.io` API
    组进行授权。RBAC API 与四个 Kubernetes 对象一起工作：`Role`、`ClusterRole`、`RoleBinding` 和 `ClusterRoleBinding`。'
- en: '`Role` and `ClusterRole` contain a set of permissions. The permissions are
    *additive*, meaning there are no deny permissions, and you need to explicitly
    add permission to resources. The `Role` object is namespaced and is used to specify
    permissions within a namespace. The `ClusterRole` object is non-namespaced but
    can be used for granting permission for a given namespace or cluster-scoped permissions.
    See the following illustration:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`Role` 和 `ClusterRole` 包含一组权限。权限是 *累加的*，这意味着没有拒绝权限，并且您需要显式添加权限到资源。`Role` 对象是命名空间级别的，用于在命名空间内指定权限。`ClusterRole`
    对象是非命名空间级别的，但可以用于为特定命名空间或集群范围权限授权。请参阅以下插图：'
- en: '![](img/B20836_06_11.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B20836_06_11.png)'
- en: 'Figure 6.11: Role versus ClusterRole'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.11：Role 与 ClusterRole
- en: 'The following .`yaml` file provides get, watch, and list access to all Pods
    resources in the default namespace for the core API group:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `.yaml` 文件为默认命名空间中核心 API 组的所有 Pod 资源提供获取、观看和列表访问权限：
- en: '[PRE8]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following policy allows get, watch, and list access for all Kubernetes
    nodes across the cluster:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下策略允许对集群中所有 Kubernetes 节点的获取、观看和列表访问：
- en: '[PRE9]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`RoleBinding` and `ClusterRoleBinding` grant permissions defined in a `Role`
    or `ClusterRole` object to a user or set of users with reference to a `Role` or
    `ClusterRole` object. The following policy binds the `joe` user to the `pod-reader`
    role:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`RoleBinding` 和 `ClusterRoleBinding` 将定义在 `Role` 或 `ClusterRole` 对象中的权限授予具有对
    `Role` 或 `ClusterRole` 对象引用的用户或一组用户。以下策略将 `joe` 用户绑定到 `pod-reader` 角色：'
- en: '[PRE10]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following `RoleBinding` object binds a service account, `SA-name`, to the
    `ClusterRole` `secret-reader`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `RoleBinding` 对象将服务帐户 `SA-name` 绑定到 `ClusterRole` `secret-reader`：
- en: '[PRE11]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Kubernetes has a built-in feature for storing and managing sensitive information
    such as passwords. Instead of storing this sensitive information directly in plain
    text in a Pod, you can store this information as Kubernetes Secrets, and provide
    specific access to them using Kubernetes RBAC to create and/or read these Secrets.
    By default, Secrets are stored as unencrypted plain-text Base64-encoded strings,
    and data encryption at rest can be enabled for the Secrets. The following policy
    shows how to create a secret for storing AWS access credentials:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 有一个内置功能用于存储和管理敏感信息，如密码。您不必直接在 Pod 中以纯文本形式存储这些敏感信息，而是可以将这些信息作为 Kubernetes
    Secrets 存储，并使用 Kubernetes RBAC 提供对这些 Secrets 的特定访问权限。默认情况下，Secrets 以未加密的纯文本 Base64
    编码字符串的形式存储，并且可以为 Secrets 启用静态数据加密。以下策略显示了如何创建用于存储 AWS 访问凭证的 secret：
- en: '[PRE12]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'There are several ways to use a secret in a Pod:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Pod 中使用密钥的方式有几种：
- en: 'As environment variables in the Pod specification template:'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为 Pod 规范模板中的环境变量：
- en: '[PRE13]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The application code inside the container can access the Secrets just like other
    environment variables.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 容器内的应用程序代码可以像其他环境变量一样访问 Secrets。
- en: 'As a file in a volume mounted on a Pod:'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为挂载在 Pod 上的卷中的文件：
- en: '[PRE14]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In the previous examples, you will see files in the `/etc/aws` folder in a Pod
    for each corresponding secret name (such as `SECRET_AWS_ACCESS_KEY`) that contains
    the values for the Secrets.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，您将看到每个对应的密钥名称（如 `SECRET_AWS_ACCESS_KEY`）在 Pod 的 `/etc/aws` 文件夹中的文件，这些文件包含
    Secrets 的值。
- en: We now know what containers are and how they can be deployed on a Kubernetes
    cluster. We also understand how to configure networking on Kubernetes to allow
    Pods to communicate with each other and how to expose a Kubernetes container for
    external access outside of the cluster using different networking options.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在知道了容器是什么，以及它们如何在 Kubernetes 集群上部署。我们还了解了如何在 Kubernetes 上配置网络，以允许 Pods 之间相互通信，以及如何使用不同的网络选项将
    Kubernetes 容器暴露给集群外部的访问。
- en: Kubernetes can serve as the foundational infrastructure for running ML workloads.
    For example, you can run a **Jupyter** **notebook** as a containerized application
    on Kubernetes as your data science environment for experimentation and model building.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 可以作为运行 ML 工作负载的基础基础设施。例如，您可以在 Kubernetes 上作为您的数据科学实验和模型构建环境，将 **Jupyter**
    **笔记本** 运行为一个容器化应用程序。
- en: You can also run a model training job as a Kubernetes Job if you need additional
    resources, and then serve the model as a containerized web service application
    or run batch inferences on trained models as a Kubernetes Job. In the following
    hands-on exercise, you will learn how to use Kubernetes as the foundational infrastructure
    for running ML workloads.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要额外的资源，也可以将模型训练作业作为 Kubernetes Job 运行，然后将模型作为容器化的 Web 服务应用程序提供服务，或者作为 Kubernetes
    Job 在训练模型上运行批量推理。在接下来的动手练习中，您将学习如何使用 Kubernetes 作为运行 ML 工作负载的基础基础设施。
- en: Hands-on – creating a Kubernetes infrastructure on AWS
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践操作 - 在 AWS 上创建 Kubernetes 基础设施
- en: In this section, you will create a Kubernetes environment using Amazon EKS,
    a managed Kubernetes environment on AWS, which makes it easier to set up a Kubernetes
    cluster. Let’s first look at the problem statement.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将使用 Amazon EKS 创建一个 Kubernetes 环境，这是 AWS 上的托管 Kubernetes 环境，这使得设置 Kubernetes
    集群变得更加容易。让我们首先看看问题陈述。
- en: Problem statement
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题陈述
- en: As an ML solutions architect, you have been tasked with evaluating Kubernetes
    as a potential infrastructure platform for building an ML platform for one business
    unit in your bank. You need to build a sandbox environment on AWS and demonstrate
    that you can deploy a Jupyter notebook as a containerized application for your
    data scientists to use.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 ML 解决方案架构师，您被分配评估 Kubernetes 作为构建您银行一个业务单元的 ML 平台潜在基础设施平台的任务。您需要在 AWS 上构建一个沙盒环境，并证明您可以将
    Jupyter 笔记本作为容器化应用程序部署，供您的数据科学家使用。
- en: Lab instruction
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验室说明
- en: In this hands-on exercise, you are going to create a Kubernetes environment
    using Amazon EKS, which is a managed service for Kubernetes on AWS that creates
    and configures a Kubernetes cluster with both master and worker nodes automatically.
    EKS provisions and scales the control plane, including the API server and backend
    persistent layer. It also runs the open-source Kubernetes and is compatible with
    all Kubernetes-based applications.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: After the EKS cluster is created, you will explore the EKS environment to inspect
    some of its core components, and then you will learn how to deploy a containerized
    Jupyter Notebook application and make it accessible from the internet.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s complete the following steps to get started:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Launch the AWS CloudShell service.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log on to your AWS account, select the **Oregon** Region, and launch AWS CloudShell.
    CloudShell is an AWS service that provides a browser-based **Linux** terminal
    environment to interact with AWS resources. With CloudShell, you authenticate
    using your AWS console credential and can easily run **AWS** **CLI**, **AWS**
    **SDK**, and other tools.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Install the `eksctl` utility.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Follow the installation instructions for Unix at [https://github.com/weaveworks/eksctl/blob/main/README.md#installation](https://github.com/weaveworks/eksctl/blob/main/README.md#installation)
    to install eksctl. The `eksctl` utility is a command-line utility for managing
    the EKS cluster. We will use the `eksctl` utility to create a Kubernetes cluster
    on Amazon EKS in *Step 3*:'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following command to start creating an EKS cluster in the **Oregon**
    Region inside your AWS account. It will take about 15 minutes to complete running
    the setup:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The command will launch a `cloudformation` template and this will create the
    following resources:'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: An Amazon EKS cluster with two worker nodes inside a new Amazon **virtual private
    cloud** (**VPC**). Amazon EKS provides fully managed Kubernetes master nodes,
    so you won’t see the master nodes inside your private VPC.
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An EKS cluster configuration file saved in the `/home/cloudshell-user/.kube/config`
    directory on CloudShell. The `config` file contains details such as the API server
    `url` address, the name of the admin user for managing the cluster, and the client
    certificate for authenticating to the Kubernetes cluster. The `kubectl` utility
    uses information in the `config` file to connect and authenticate to the Kubernetes
    API server.
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'EKS organizes worker nodes into logical groups called `nodegroup`. Run the
    following command to look up the `nodegroup` name. You can look up the name of
    the cluster in the EKS management console. The name of the node group should look
    something like `ng-xxxxxxxx`:'
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Install the `kubectl` utility.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Follow the instructions at [https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html](https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html)
    to install kubectl for Linux. You will need to know the version of the Kubernetes
    server to install the matching kubectl version. You can find the version of the
    Kubernetes server using the `kubectl version --short` command.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Explore the cluster.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now the cluster is up, let’s explore it a bit. Try running the following commands
    in the CloudShell terminal and see what is returned:'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Table 6.1 – kubectl commands ](img/B20836_06_12.png)'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 6.12: kubectl commands'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Deploy a Jupyter notebook.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s deploy a Jupyter Notebook server as a containerized application. Copy
    and run the following code block. It should create a file called `deploy_Jupyter_notebook.yaml`.
    We will use a container image from the Docker Hub image repository:'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, let’s create a Deployment by running the following:'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Check to make sure the Pod is running by executing `kubectl get pods`.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Check the logs of the Jupyter server Pod by running `kubectl logs <name of notebook
    pod>`. Find the section in the logs that contains `http://jupyter-notebook-598f56bf4b-spqn4:8888/?token=XXXXXXX...`,
    and copy the token (`XXXXXX…`) portion. We will use the token for *Step 8*.
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also access the Pod using an interactive shell by running `kubectl exec
    --stdin --tty <name of notebook pod> -- /bin/sh`. Run `ps aux` to see a list of
    running processes. You will see a process related to the Jupyter notebook.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Expose the Jupyter notebook to the internet.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, we have a Jupyter server running in a Docker container in a Kubernetes
    Pod on top of two EC2 instances in an AWS VPC but we can’t get to it because the
    Kubernetes cluster doesn’t expose a route to the container. We will create a Kubernetes
    Service to expose the Jupyter Notebook server to the internet so it can be accessed
    from a browser.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following code block to create a specification file for a new Service.
    It should create a file called `jupyter_svc.yaml`:'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: After the file is created, run `kubectl apply -f jupyter_svc.yaml` to create
    the service. A new Kubernetes Service called `jupyter-service`, as well as a new
    `LoadBalancer` object, should be created. You can verify the service by running
    `kubectl get service`. Note and copy the `EXTERNAL-IP` address associated with
    the `jupyter-service` service.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Paste the `EXTERNAL-IP` address into a new browser window and enter the token
    you copied earlier into the **Password or token** field to log in as shown in
    the following screenshot. You should see a Jupyter Notebook window showing up:'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.11 – Jupyter login screen ](img/B20836_06_13.png)'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 6.13: Jupyter login screen'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The following diagram shows the environment that you have created after working
    through the hands-on exercise.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Jupyter notebook deployment on the EKS cluster ](img/B20836_06_14.png)'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 6.14: Jupyter Notebook deployment on the EKS cluster'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.14：EKS 集群上的 Jupyter Notebook 部署
- en: Congratulations, you have successfully created a new Amazon EKS cluster on AWS
    and deployed a Jupyter server instance as a container on the cluster. We will
    reuse this EKS cluster for the next chapter. However, if you don’t plan to use
    this EKS for a period of time, it is recommended to shut down the cluster to avoid
    unnecessary costs. To shut down the cluster, run `kubectl delete svc <service
    name>` to delete the service first. Then run `eksctl delete cluster --name <cluster
    name>` to delete the cluster.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你，你已经在 AWS 上成功创建了一个新的 Amazon EKS 集群，并在集群上部署了一个 Jupyter 服务器实例作为容器。我们将重用这个 EKS
    集群进行下一章的内容。然而，如果你计划一段时间内不使用这个 EKS，建议关闭集群以避免不必要的费用。要关闭集群，请运行 `kubectl delete svc
    <service name>` 来删除服务。然后运行 `eksctl delete cluster --name <cluster name>` 来删除集群。
- en: Summary
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered Kubernetes, a robust container management platform
    that forms the infrastructure foundation for constructing open-source ML platforms.
    Throughout this chapter, you gained an understanding of containers and insights
    into the functioning of Kubernetes. Moreover, you acquired hands-on experience
    in establishing a Kubernetes cluster on AWS by leveraging AWS EKS. Additionally,
    we explored the process of deploying a containerized Jupyter Notebook application
    onto the cluster, thereby creating a fundamental data science environment. In
    the next chapter, we will shift our focus toward exploring a selection of open-source
    ML platforms that seamlessly integrate with the Kubernetes infrastructure.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了 Kubernetes，这是一个强大的容器管理平台，是构建开源 ML 平台的基础设施基础。在本章中，你了解了容器和 Kubernetes
    的工作原理。此外，通过利用 AWS EKS，你获得了在 AWS 上建立 Kubernetes 集群的实际经验。此外，我们探讨了将容器化的 Jupyter Notebook
    应用程序部署到集群上的过程，从而创建了一个基本的数据科学环境。在下一章中，我们将转向探索与 Kubernetes 基础设施无缝集成的开源 ML 平台的选择。
- en: Join our community on Discord
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的社区 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/mlsah](https://packt.link/mlsah )'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/mlsah](https://packt.link/mlsah)'
- en: '![](img/QR_Code7020572834663656.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code7020572834663656.png)'
