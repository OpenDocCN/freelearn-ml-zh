<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Classification - Spam Email Detection</h1>
                </header>
            
            <article>
                
<p class="mce-root">What makes you you? I have dark hair, pale skin, and Asiatic features. I wear glasses. My facial structure is vaguely round, with extra subcutaneous fat in my cheeks compared to my peers. What I have done is describe the features of my face. Each of these features described can be thought of as a point within a probability continuum. What is the probability of having dark hair? Among my friends, dark hair is a very common feature, and so are glasses (a remarkable statistic is out of the 300 people or so I polled on my Facebook page, 281 of them require prescription glasses). The epicanthic folds of my eyes are probably less common, as is the extra subcutaneous fat in my cheeks.</p>
<p class="mce-root">Why am I bringing up my facial features in a chapter about spam classification? It's because the principles are the same. If I show you a photo of a human face, what is the probability that the photo is of me? We can say that the probability that the photo is a photo of my face is a combination of the probability of having dark hair, the probability of having pale skin, the probability of having an epicanthic fold, and so on, and so forth. From a Naive point of view, we can think of each of the features independently contributing to the probability that the photo is me—the fact that I have an epicanthic fold in my eyes is independent from the fact that my skin is of a yellow pallor. But, of course, with recent advancements in genetics, this has been shown to be patently untrue. These features are, in real life, correlated with one another. We will explore this in a future chapter.</p>
<p class="mce-root">Despite a real-life dependence of probability, we can still assume the Naive position and think of these probabilities as independent contributions to the probability that the photo is one of my face.</p>
<p class="mce-root">In this chapter, we will build a email spam classification system using a Naive Bayes algorithm, which can be used beyond email spam classification. Along the way, we will explore the very basics of natural language processing, and how probability is inherently tied to the very language we use. A probabilistic understanding of language will be built up from the ground with the introduction of the <strong><span>term</span> <span>frequency-inverse document frequency</span></strong> (<strong>TF-IDF</strong>), which will then be translated into Bayesian probabilities, which is used to classify the emails.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The project </h1>
                </header>
            
            <article>
                
<p class="mce-root">What we want to do is simple: given an email, is it kosher (which we call ham), or is it a spam email? We will be using the <kbd>LingSpam</kbd> database. The emails from that database are a little dated—spammers update their techniques and words all the time. However, I chose the <kbd>LingSpam</kbd> corpus for a good reason: it is already nicely preprocessed. The original scope of this chapter was to introduce the preprocessing of emails; however, the topic of preprocessing options for natural language is itself a topic for an entire book, so we will use a dataset that has already been preprocessed. This allows us to focus more on the mechanics of a very elegant algorithm.</p>
<p class="mce-root">Fear not, though, as I will actually walk through the brief basics of preprocessing. Be warned, however, that the level of complexity jumps up in a very steep curve, so be prepared to be sucked into a black hole of many hours on preprocessing natural language. At the end of this chapter, I will also recommend some libraries that will be useful for preprocessing.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Exploratory data analysis </h1>
                </header>
            
            <article>
                
<p class="mce-root">Let's jump into the data. The <kbd>LingSpam</kbd> corpus comes with four variants of the same corpus: <kbd>bare</kbd>, <kbd>lemm</kbd>, <kbd>lemm_stop</kbd>, and <kbd>stop</kbd>. In each variant, there are ten parts and each part contains multiple files. Each file represents an email. Files with a <kbd>spmsg</kbd> prefix in its name are spam, while the rest are ham. An example email looks as follows (from the <kbd>bare</kbd> variant):</p>
<pre>Subject: re : 2 . 882 s - &gt; np np<br/>&gt; date : sun , 15 dec 91 02 : 25 : 02 est &gt; from : michael &lt; mmorse @ vm1 . yorku . ca &gt; &gt; subject : re : 2 . 864 queries &gt; &gt; wlodek zadrozny asks if there is " anything interesting " to be said &gt; about the construction " s &gt; np np " . . . second , &gt; and very much related : might we consider the construction to be a form &gt; of what has been discussed on this list of late as reduplication ? the &gt; logical sense of " john mcnamara the name " is tautologous and thus , at &gt; that level , indistinguishable from " well , well now , what have we here ? " . to say that ' john mcnamara the name ' is tautologous is to give support to those who say that a logic-based semantics is irrelevant to natural language . in what sense is it tautologous ? it supplies the value of an attribute followed by the attribute of which it is the value . if in fact the value of the name-attribute for the relevant entity were ' chaim shmendrik ' , ' john mcnamara the name ' would be false . no tautology , this . ( and no reduplication , either . )</pre>
<p class="mce-root">Here are some things to note about this particular email:</p>
<ul>
<li class="mce-root">This is an email about linguistics—specifically, about the parsing of a natural sentence into multiple <strong>noun phrases</strong> (<strong>np</strong>). This is a largely irrelevant fact to the project at hand. I do, however, think it's a good idea to go through the topics, if only to provide a sanity check on manual occasions.</li>
<li class="mce-root">There is an email and a person attached to this email<span>—</span>the dataset is not particularly anonymized. This has some implications in the future of machine learning, which I will explore in the final chapter of this book.</li>
<li class="mce-root">The email is very nicely split into fields (that is, space separated for each word).</li>
<li class="mce-root">The email has a <kbd>Subject</kbd> line.</li>
</ul>
<p class="mce-root"><span><span>The first two points are particularly noteworthy. Sometimes, the subject matter actually matters in machine learning. In our case, we can build our algorithms to be blind—they can be used generically across all emails. But there are times where being context-sensitive will bring new heights to your machine-learning algorithms. The second thing to note is anonymity. We live in an age where software flaws are often the downfall of companies. Doing machine learning on non-anonymous datasets are often fraught with biases. We should try to anonymize data as much as possible.</span></span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Tokenization</h1>
                </header>
            
            <article>
                
<p class="mce-root">When dealing with natural language sentences, the first activity is typically to tokenize the sentence. Given a sentence that reads such as <kbd>The child was learning a new word and was using it excessively. "Shan't!", she cried</kbd>. We need to split the sentence into the components that make up the sentence. We call each component a token, hence the name of the process is <strong>tokenization</strong>. Here's one possible tokenization method, in which we do a simple <kbd>strings.Split(a, " ")</kbd>.</p>
<p class="mce-root">Here's a simple program:</p>
<pre class="mce-root">func main() {<br/>  a := "The child was learning a new word and was using it excessively. \"shan't!\", she cried"<br/>  dict := make(map[string]struct{}) <br/>  words := strings.Split(a, " ")<br/>  for _, word := range words{<br/>    fmt.Println(word)<br/>    dict[word] = struct{}{} // add the word to the set of words already seen before.<br/>  }<br/>}</pre>
<p class="mce-root">This is the output we will get:</p>
<pre class="mce-root"><strong>The</strong><br/><strong>child</strong><br/><strong>was</strong><br/><strong>learning</strong><br/><strong>a</strong><br/><strong>new</strong><br/><strong>word</strong><br/><strong>and</strong><br/><strong>was</strong><br/><strong>using</strong><br/><strong>it</strong><br/><strong>excessively.</strong><br/><strong>"shan't!",</strong><br/><strong>she</strong><br/><strong>cried</strong></pre>
<p class="mce-root">Now think about this in the context of adding words to a dictionary to learn. Let's say we want to use the same set of English words to form a new sentence: <kbd>she shan't be learning excessively.</kbd> (Forgive the poor implications in the sentence). We add it to our program, and see if it shows up in the dictionary:</p>
<pre class="mce-root">func main() {<br/>  a := "The child was learning a new word and was using it excessively. \"shan't!\", she cried"<br/>  dict := make(map[string]struct{}) <br/>  words := strings.Split(a, " ")<br/>  for _, word := range words{<br/>    dict[word] = struct{}{} // add the word to the set of words already seen before.<br/>  }<br/><br/>  b := "she shan't be learning excessively."<br/>  words = strings.Split(b, " ")<br/>  for _, word := range words {<br/>    _, ok := dict[word]<br/>    fmt.Printf("Word: %v - %v\n", word, ok)<br/>  }<br/>}</pre>
<p class="mce-root">This leads to the following result:</p>
<pre class="mce-root"><strong>Word: she - true</strong><br/><strong>Word: shan't - false</strong><br/><strong>Word: be - false</strong><br/><strong>Word: learning - true</strong><br/><strong>Word: excessively. - true</strong></pre>
<p class="mce-root">A superior tokenization algorithm would yield a result as follows:</p>
<pre class="mce-root"><strong>The</strong><br/><strong>child</strong><br/><strong>was</strong><br/><strong>learning</strong><br/><strong>a</strong><br/><strong>new</strong><br/><strong>word</strong><br/><strong>and</strong><br/><strong>was</strong><br/><strong>using</strong><br/><strong>it</strong><br/><strong>excessively</strong><br/><strong>.</strong><br/><strong>"</strong><br/><strong>sha</strong><br/><strong>n't</strong><br/><strong>!</strong><br/><strong>"</strong><br/><strong>,</strong><br/><strong>she</strong><br/><strong>cried</strong></pre>
<p class="mce-root">A particular thing to note is that the symbols and punctuation are now tokens. Another particular thing to note is <kbd>shan't</kbd> is now split into two tokens: <kbd>sha</kbd> and <kbd>n't</kbd>. The word <kbd>shan't</kbd> is a contraction of <em>shall</em> and <em>not</em>; therefore, it is tokenized into two words. This is a tokenization strategy that is unique to English. Another unique point of English is that words are separated by a boundary marker—the humble space. In languages where there are no word boundary markers, such as Chinese or Japanese, the process of tokenization becomes significantly more complicated. Add to that languages such as Vietnamese, where there are markers for boundaries of syllables, but not words, and you have a very complicated tokenizer at hand.</p>
<p class="mce-root">The details of a good tokenization algorithm are fairly complicated, and tokenization is worthy of a book to itself, so we <kbd>shan't</kbd> cover it here.</p>
<p class="mce-root">The best part about the <kbd>LingSpam</kbd> corpus is that the tokenization has already been done. Some notes such as compound words and contractions are not tokenized into different tokens such as the example of <kbd>shan't</kbd>. They are treated as a single word. For the purposes of a spam classifier, this is fine. However, when working with different types of NLP projects, the reader might want to consider better tokenization strategies.</p>
<div class="mce-root packt_infobox">Here is a final note about tokenization strategies: English is not a particularly regular language. Despite this, regular expressions are useful for small datasets. For <span>this project, you may get away with the following regular expression: </span><br/>
<kbd>const re = `([A-Z])(\.[A-Z])+\.?|\w+(-\w+)*|\$?\d+(\.\d+)?%?|\.\.\.|[][.,;"'?():-_` + "`]"</kbd></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Normalizing and lemmatizing</h1>
                </header>
            
            <article>
                
<p class="mce-root">In the previous section, I wrote that all the words in the second example, <kbd>she shan't be excessively learned</kbd>, are already in the dictionary from the first sentence. The observant reader might note the word <kbd>be</kbd> isn't actually in the dictionary. From a linguistics point of view, that isn't necessarily false. The word <kbd>be</kbd> is the root word of <kbd>is</kbd>, of which <kbd>was</kbd> is the past tense. Here, there is a notion that instead of just adding the words directly, we should add the root word. This is called <strong>lemmatization</strong>. Continuing from the previous example, the following are the lemmatized words from the first sentence:</p>
<pre class="mce-root">the<br/>child<br/>be<br/>learn<br/>a<br/>new<br/>word<br/>and<br/>be<br/>use<br/>it<br/>excessively<br/>shall<br/>not<br/>she<br/>cry</pre>
<p class="mce-root">Again, here I would like to point out some inconsistencies that will be immediately obvious to the observant reader. Specifically, the word <kbd>excessively</kbd> has the root word of <kbd>excess</kbd>. So why was <kbd>excessively</kbd> listed? Again, the task of lemmatization isn't exactly a straightforward lookup of the root word in a dictionary. Often, in complex NLP related tasks, the words have to be lemmatized according to the context they are in. That's beyond the scope of this chapter because, as before, it's a fairly involved topic that could span an entire chapter of a book on NLP preprocessing.</p>
<p class="mce-root">So, let's go back to the topic of adding a word to a dictionary. Another useful thing to do is to normalize the words. In English, this typically means lowercasing the text, replacing unicode combination characters and the like. In the Go ecosystem, there is an extended standard library package that does just this: <kbd>golang.org/x/text/unicode/norm</kbd>. In particular, if we are going to work on real datasets, I personally prefer a NFC normalization schema. A good resource on string normalization is on the Go blog post as well: <a href="https://blog.golang.org/normalization">https://blog.golang.org/normalization</a>. The content is not specific to Go, and is a good guide to string normalization in general.</p>
<p class="mce-root">The <kbd>LingSpam</kbd> corpus comes with variants that are normalized (by lowercasing and NFC) and lemmatized. They can be found in the <kbd>lemm</kbd> and <kbd>lemm_stop</kbd> variants of the corpus.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Stopwords</h1>
                </header>
            
            <article>
                
<p class="mce-root">By reading this, I would assume the reader is familiar with English. And you may have noticed that some words are used more often than others. Words such as <kbd>the</kbd>, <kbd>there</kbd>, <kbd>from</kbd>, and so on. The task of classifying whether an email is spam or ham is inherently statistical in nature. When certain words are used often in a document (such as an email), it conveys more weight about what that document is about. For example, I received an email today about cats (I am a patron of the Cat Protection Society). The word <kbd>cat</kbd> or <kbd>cats</kbd> occurred eleven times out of the 120 or so words. It would not be difficult to assume that the email is about cats.</p>
<p class="mce-root">However, the word <kbd>the</kbd> showed up 19 times. If we were to classify the topic of the email by a count of words, the email would be classified under the topic <kbd>the</kbd>. Connective words such as these are useful in understanding the specific context of the sentences, but for a Naïve statistical analysis, they often add nothing more than noise. So, we have to remove them.</p>
<p class="mce-root">Stopwords are often specific to projects, and I'm not a particular fan of removing them outright. However, the <kbd>LingSpam</kbd> corpus has two variants: <kbd>stop</kbd> and <kbd>lemm_stop</kbd>, which has the stopwords list applied, and the stopwords removed.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Ingesting the data</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now, without much further ado, let's write some code to ingest the data. First, we need a data structure of a training example:</p>
<pre class="mce-root">// Example is a tuple representing a classification example<br/>type Example struct {<br/>    Document []string<br/>    Class<br/>}</pre>
<p class="mce-root">The reason for this is so that we can parse our files into a list of <kbd>Example</kbd>. The function is shown here:</p>
<pre class="mce-root">func ingest(typ string) (examples []Example, err error) {<br/>  switch typ {<br/>  case "bare", "lemm", "lemm_stop", "stop":<br/>  default:<br/>    return nil, errors.Errorf("Expected only \"bare\", \"lemm\", \"lemm_stop\" or \"stop\"")<br/>  }<br/><br/>  var errs errList<br/>  start, end := 0, 11<br/><br/>  for i := start; i &lt; end; i++ { // hold 30% for crossval<br/>    matches, err := filepath.Glob(fmt.Sprintf("data/lingspam_public/%s/part%d/*.txt", typ, i))<br/>    if err != nil {<br/>      errs = append(errs, err)<br/>      continue<br/>    }<br/><br/>    for _, match := range matches {<br/>      str, err := ingestOneFile(match)<br/>      if err != nil {<br/>        errs = append(errs, errors.WithMessage(err, match))<br/>        continue<br/>      }<br/><br/>      if strings.Contains(match, "spmsg") {<br/>        // is spam<br/>        examples = append(examples, Example{str, Spam})<br/>      } else {<br/>        // is ham<br/>        examples = append(examples, Example{str, Ham})<br/>      }<br/>    }<br/>  }<br/>  if errs != nil {<br/>    err = errs<br/>  }<br/>  return<br/>}</pre>
<p class="mce-root">Here, I used <kbd>filepath.Glob</kbd> to find a list of files that matches the pattern within the specific directory, which is hardcoded. It doesn't have to be hardcoded in your actual code, but hardcoding the path makes for simpler demo programs. For each of the matching filenames, we parse the file using the <kbd>ingestOneFile</kbd> function. Then we check whether the filename contains <kbd>spmsg</kbd> as a prefix. If it does, we create an <kbd>Example</kbd> that has <kbd>Spam</kbd> as its class. Otherwise, it will be marked as <kbd>Ham</kbd>. In the later sections of this chapter, I will walk through the <kbd>Class</kbd> type and the rationale for choosing it. For now, here's the <kbd>ingestOneFile</kbd> function. Take note of its simplicity:</p>
<pre class="mce-root">func ingestOneFile(abspath string) ([]string, error) {<br/>  bs, err := ioutil.ReadFile(abspath)<br/>  if err != nil {<br/>    return nil, err<br/>  }<br/>  return strings.Split(string(bs), " "), nil<br/>}</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Handling errors</h1>
                </header>
            
            <article>
                
<p class="mce-root">There is a central thesis in some programming language theories that errors in most programs happen at the boundary. While there are many interpretations of this thesis (boundaries of what? Some scholars think it's at the boundaries of functions; some think it's at the boundaries of computation), what is certainly true from experience is that boundaries of I/O are where the most errors happen. Hence, we have to be extra careful when dealing with input and output.</p>
<p class="mce-root">For the purposes of ingesting the files, we define an <kbd>errList</kbd> type as follows:</p>
<pre class="mce-root">type errList []error<br/><br/>func (err errList) Error() string {<br/>  var buf bytes.Buffer<br/>  fmt.Fprintf(&amp;buf, "Errors Found:\n")<br/>  for _, e := range err {<br/>    fmt.Fprintf(&amp;buf, "\t%v\n", e)<br/>  }<br/>  return buf.String()<br/>}</pre>
<p class="mce-root">That way we can continue, even if an error happens while reading a file. The error will be bubbled back all the way to the top without causing any panic.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The classifier</h1>
                </header>
            
            <article>
                
<p class="mce-root">Before we continue to build our classifier, let's imagine what the main function will look as follows. It will look something similar to this:</p>
<pre class="mce-root">unc main() {<br/>  examples, err := ingest("bare")<br/>  log.Printf("Examples loaded: %d, Errors: %v", len(examples), err)<br/>  shuffle(examples)<br/><br/>  if len(examples) == 0 {<br/>    log.Fatal("Cannot proceed: no training examples")<br/>  }<br/><br/>  // create new classifier<br/>  c := New()<br/><br/>  // train new classifier<br/>  c.Train(examples)<br/><br/>  // predict<br/>  predicted := c.Predict(aDocument)<br/>  fmt.Printf("Predicted %v", predicted)<br/>}</pre>
<p class="mce-root">The use of <kbd>Train</kbd> and <kbd>Predict</kbd> as exported methods are useful in guiding us on what to build next. From the sketch in the preceding code block, we need a <kbd>Classifier</kbd> type, that has <kbd>Train</kbd> and <kbd>Predict</kbd> at the very least. So we'll start by doing that:</p>
<pre class="mce-root">type Classifier {}<br/><br/>func (c *Classifier) Train(examples []Example) {}<br/><br/>func (c *Classifier) Predict(document []string) Class { ... }</pre>
<p class="mce-root">So, now, it becomes a question of how the classifier works.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Naive Bayes</h1>
                </header>
            
            <article>
                
<p class="mce-root">The classifier is a Naive Bayes classifier. To break it down, Naive in the phrase Naive Bayes means that we are assuming that all the input features are independent. To understand how the classifier works, an additional component needs to be introduced first: the <strong>term frequency</strong>-<strong>inverse frequency</strong> (<strong>TF</strong>-<strong>IF</strong>) pair of statistics.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">TF-IDF </h1>
                </header>
            
            <article>
                
<p class="mce-root">TF-IDF, per its namesake, is comprised of two statistics: <strong>term frequency</strong> (<strong>TF</strong>) and <strong>inverse document frequency</strong> (<strong>IDF</strong>).</p>
<p class="mce-root">The central thesis to TF is that if a word (called a <strong>term</strong>) occurs many times in a document, it means that the document revolves more around that word. It makes sense; look at your emails. The keywords typically revolve around a central topic. But TF is a lot more simplistic than that. There is no notion of topics. It's just a count of how many times a word happens in a document.</p>
<p class="mce-root">IDF, on the other hand, is a statistic that determines how important a term is to a document. In the examples we've seen, do note that the word <kbd>Subject</kbd>, with a capital <kbd>S</kbd> occurs once in both types of documents: spam and ham. In broad strokes, IDF is calculated by the following:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/ef3186a5-8b35-4ae4-9d6c-169b821834dc.png" style="width:26.67em;height:2.50em;" width="4790" height="450"/>.</p>
<p class="mce-root">The exact formula varies and there are subtleties to each variation, but all adhere to the notion of dividing the total number of documents over the frequency of the term.</p>
<p class="mce-root">For the purposes of our project, we will be using the <kbd>tf-idf</kbd> library from <kbd>go-nlp</kbd>, which is a repository of NLP-related libraries for Go. To install it, simply run the following command:</p>
<pre class="mce-root"><strong>go get -u github.com/go-nlp/tfidf</strong></pre>
<p class="mce-root"> It is an extremely well, tested library, with 100% test coverage.</p>
<p>When used together, <img class="fm-editor-equation" src="Images/45393d95-43fe-4cf0-874e-c4c23c09f1ea.png" style="width:3.33em;height:1.00em;" width="660" height="200"/> represents a useful weighting scheme for calculating the importance of a word in a document. It may seem simple, but it is very powerful, especially when used in the context of probability.</p>
<div class="packt_infobox">Do note that TF-IDF cannot strictly be interpreted as a probability. There are some theoretical nastiness that presents itself when strictly interpreting IDF as a probability. Hence, in the context of this project, we will be treating TF-IDF as a sort of weighting scheme to a probability.</div>
<p class="mce-root">Now we are ready to talk about the basics of the Naive Bayes algorithm. But first I'd like to further emphasize certain intuitions of Bayes' theorem.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Conditional probability</h1>
                </header>
            
            <article>
                
<p class="mce-root">We'll start with the notion of conditional probability. To set a scene, we'll consider several fruit types:</p>
<ul>
<li class="mce-root">Apple</li>
<li class="mce-root">Avocado</li>
<li class="mce-root">Banana</li>
<li class="mce-root">Pineapple</li>
<li class="mce-root">Nectarine</li>
<li class="mce-root">Mango</li>
<li class="mce-root">Strawberry</li>
</ul>
<p class="mce-root">For each fruit type, we will have several instances of those fruits—so we could have a green Granny Smith and a red Red Delicious in the class of apples. Likewise, we could have ripe and unripe fruits—mangoes and bananas could be yellow (ripe) or green (unripe), for example. Lastly, we can also classify these fruits by what kind of fruit it is—tropical (avocado, banana, pineapple, and mango) versus non-tropical fruits:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<thead>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Fruit</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Can be green</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Can be yellow</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Can be red</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Is tropical</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Apple</strong></p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>no</p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>no</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Avocado</strong></p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>no</p>
</td>
<td>
<p>no</p>
</td>
<td>
<p>yes</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Banana</strong></p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>no</p>
</td>
<td>
<p>yes</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Lychee</strong></p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>no</p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>yes</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Mango</strong></p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>no</p>
</td>
<td>
<p>yes</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Nectarine</strong></p>
</td>
<td>
<p>no</p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>no</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Pineapple</strong></p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>no</p>
</td>
<td>
<p>yes</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Strawberry</strong></p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>no</p>
</td>
<td>
<p>yes</p>
</td>
<td>
<p>no</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root">I would like you to now imagine you're blindfolded and you pick a fruit. I will then describe a feature of the fruit, and you would guess the fruit.</p>
<p class="mce-root">Let's say the fruit you picked has a yellow outside. What are the possible fruits? Nectarines, bananas, pineapples, and mangoes come to mind. If you pick one of the options you would have a one in four chance of being correct. We call this the probability of yellow <img class="fm-editor-equation" src="Images/dce6e753-bfdf-40ed-9684-1a0af16d0bad.png" style="width:7.83em;height:1.83em;" width="1760" height="410"/>. The numerator is the number of yeses along the <kbd>Can be yellow</kbd> column, and the denominator is the total number of rows.</p>
<p class="mce-root">If I give you another feature about the fruit, you can improve your odds. Let's say I tell you that the fruit is tropical. Now you have a one in three chance of being right—nectarines has been eliminated from the possible choices.</p>
<p class="mce-root">We can ask this question: If we know a fruit is tropical, what is the probability that the fruit is yellow? The answer is 3/5. From the preceding table, we can see that there are five tropical fruits and three of them are yellow. This is called a <strong>conditional probability</strong>. We write it in a formula such as this (for the more mathematically inclined, this is the Kolmogorov definition of conditional probability):</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/e921c7f2-f074-4779-b639-d00531b48477.png" style="width:10.83em;height:3.08em;" width="1700" height="480"/></div>
<p class="mce-root">This is how you read the formula: the probability of <em>A</em> given <em>B</em> is known, and we will need to get the probability of <em>A AND B</em> happening at the same time and the probability of <em>B</em> itself.</p>
<p class="mce-root">The conditional probability of a fruit being yellow, given that it's tropical is three in five; there are actually a lot of tropical fruits that are yellow—tropical conditions allow for greater depositions of carotinoids and vitamin C during the growth of the fruit.</p>
<p class="mce-root">Looking at a tabulated result can yield an easier understanding of conditional probability. However, it must be noted that the conditional probability <em>can</em> be calculated. Specifically, to calculate the conditional probability, this is the formula:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/5d0ea89d-9e2a-49d1-a27c-95425ba0b4b5.png" style="width:24.00em;height:3.17em;" width="3660" height="480"/></div>
<p class="mce-root">The probability of a fruit being yellow <em>and</em> tropical (<img class="fm-editor-equation" src="Images/2ca0214e-2b30-4f5f-890d-f3d377d1c099.png" style="width:9.92em;height:1.25em;" width="1750" height="220"/> ) is three in eight; there are three such fruits, out of a total of eight. The probability of a fruit being tropical (<img class="fm-editor-equation" src="Images/d379de41-c16a-4b6b-97de-6fa1633949e1.png" style="width:5.17em;height:1.17em;" width="980" height="220"/>) is five in eight; there are five topical fruits out of the eight listed.</p>
<p class="mce-root">And now, we are finally ready to figure out how we got to that one in three number. The probability of each class of fruits is uniform. If you had to choose randomly, you would get it right one in eight of the time. We can rephrase the question to this: What is the probability of a fruit being a banana given that it's yellow and tropical?</p>
<p class="mce-root">Let's rewrite this as a formula:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/d03e4a8c-f03d-464a-971a-5b17c15c517d.png" style="width:46.33em;height:9.50em;" width="7640" height="1570"/></div>
<p class="mce-root">It is important that we relied on a special trick to perform the analysis of the preceding probabilities. Specifically, we acted as though each <em>yes</em> represents a singular example existing, while a <em>no</em> indicates that there are no examples, or, in short, this table:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Fruit</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Is Green</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Is Yellow</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Is Red</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Is Tropical</strong></p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Apple</strong></p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Avocado</strong></p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Banana</strong></p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Lychee </strong></p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Mango</strong></p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Nectarine</strong></p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Pineapple</strong></p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Strawberry</strong></p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>0</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root">This will be important for analysis for the spam detection project. The numbers in each would be the number of occurrences within the dataset.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Features</h1>
                </header>
            
            <article>
                
<p class="mce-root">We've seen from the previous examples, that we need features, such as whether a fruit can be green, yellow, or red, or whether it's tropical. We're now focused on the project at hand. What should the features be?:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<thead>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Class</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>???</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>???</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>???</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Spam</strong></p>
</td>
<td/>
<td/>
<td/>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Ham</strong></p>
</td>
<td/>
<td/>
<td/>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root">What makes up an email? Words make an email. So, it would be appropriate to consider the appearance of each word feature. <span>We can take it further, and take the intuition that we have developed previously with TF-IDF and instead use the frequency of the words among the document types. Instead of counting 1 for the existence, we count the total number of times a word exists in the document types.</span></p>
<p class="mce-root">The table would look something as follows:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Class</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Has XXX</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Has Site</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Has Free</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Has Linguistics</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>...</strong></p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Spam</strong></p>
</td>
<td>
<p>200</p>
</td>
<td>
<p>189</p>
</td>
<td>
<p>70</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>...</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Ham</strong></p>
</td>
<td>
<p>1</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>55</p>
</td>
<td>
<p>120</p>
</td>
<td>
<p>...</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root">That also means that there are many features. We can certainly try to enumerate all possible calculations. But doing so would be tedious and quite computationally intensive. Instead, we can try to be clever about it. Specifically, we will use another definition of conditional probability to do the trick to reduce the amount of computations that needs to be done.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Bayes' theorem</h1>
                </header>
            
            <article>
                
<p class="mce-root">A conditional probability formula can also be written as Bayes' theorem:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/a0a5ddfe-b14b-4efa-8c8b-e41b9e0c7dc6.png" style="width:10.67em;height:2.58em;" width="1970" height="480"/></div>
<p class="mce-root">We call <img class="fm-editor-equation" src="Images/163c55c0-c926-4f98-ac7b-3d89861ee3d7.png" style="width:2.33em;height:1.25em;" width="420" height="220"/> the prior probability. <img class="fm-editor-equation" src="Images/b453362e-b08e-403e-a7d9-d12feb0a7520.png" style="width:3.25em;height:1.17em;" width="620" height="220"/> is called the <strong>likelihood</strong>. These are the things we're interested in, as <img class="fm-editor-equation" src="Images/6a6f5b33-fc93-4124-887a-b1284152abf6.png" style="width:2.17em;height:1.08em;" width="430" height="220"/> is essentially a constant anyway.</p>
<p class="mce-root">The theory at this point is a little dry. How does this relate to our project?</p>
<p class="mce-root">For one, we can rewrite the generic Bayes' theorem to one that fits our project:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/3841b295-8be7-4370-9e26-37628bba8f67.png" style="width:25.92em;height:2.83em;" width="4400" height="480"/></div>
<p class="mce-root">This formula perfectly encapsulates our project; given a document made up of words, what is the probability that it's <kbd>Ham</kbd> or <kbd>Spam</kbd>? In the next section, I will show you how to translate this formula into a very powerful classifier, in fewer than 100 lines of code.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Implementating the classifier</h1>
                </header>
            
            <article>
                
<p class="mce-root">In the earlier parts of the chapter, we sketched out a dummy <kbd>Classifier</kbd> type that does nothing. Let's make it do something now:</p>
<pre class="mce-root">type Classifier struct {<br/>  corpus *corpus.Corpus<br/><br/>  tfidfs [MAXCLASS]*tfidf.TFIDF<br/>  totals [MAXCLASS]float64<br/><br/>  ready bool<br/>  sync.Mutex<br/>}</pre>
<p class="mce-root">Here, there are introductions to a few things. Let's walk them through one by one:</p>
<ul>
<li class="mce-root">We'll start with the <kbd>corpus.Corpus</kbd> type.</li>
<li class="mce-root">This is a type imported from the <kbd>corpus package</kbd>, which is a subpackage of the NLP library for Go, <kbd>lingo</kbd>.</li>
<li class="mce-root">To install <kbd>lingo</kbd>, simply run <kbd>go get -u github.com/chewxy/lingo/...</kbd>.</li>
<li class="mce-root">To use the <kbd>corpus </kbd>package, simply import it like so: <kbd>import "github.com/chewxy/lingo/corpus"</kbd>.</li>
</ul>
<div class="mce-root packt_infobox">Bear in mind that in the near future, the package will change to <kbd>github.com/go-nlp/lingo</kbd>. If you are reading this after January 2019, use the new address.</div>
<p class="mce-root">A <kbd>corpus.Corpus</kbd> object simply maps from a word to an integer. The reason for doing this is twofold:</p>
<ul>
<li class="mce-root"><strong>It saves on memory</strong>: A <kbd>[]int</kbd> uses considerably less memory than <kbd>[]string</kbd>. Once a corpus has been converted to be IDs, the memory for the strings can be freed. The purpose of this is to provide an alternative to string interning.</li>
<li class="mce-root"><strong>String interning is fickle</strong>: String interning is a procedure where for the entire program's memory, only exactly one copy of the string exists. This turns out to be harder than expected for most tasks. Integers provide a more stable interning procedure.</li>
</ul>
<p class="mce-root">Next, we are faced with two fields which are arrays. Specifically, <kbd>tfidfs [MAXCLASS]*tfidf.TFIDF</kbd> and <kbd>totals [MAXCLASS]float64</kbd>. At this point, it might be a good idea to talk about the <kbd>Class</kbd> type.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Class</h1>
                </header>
            
            <article>
                
<p class="mce-root">We were introduced to the <kbd>Class</kbd> type when we were writing the ingestion code. This is the definition of <kbd>Class</kbd>:</p>
<pre class="mce-root">type Class byte<br/><br/>const (<br/>  Ham Class = iota<br/>  Spam<br/>  MAXCLASS<br/>)</pre>
<p class="mce-root">In other words, <kbd>Ham</kbd> is <kbd>0</kbd>, <kbd>Spam</kbd> is <kbd>1</kbd>, and <kbd>MAXCLASS</kbd> is <kbd>2</kbd>. They're all constant values and can't be changed at runtime.</p>
<p class="mce-root">It would be prudent to note upfront, that there are limitations to this approach. In particular, it means that you have to know before running the program how many classes there will be. In our case, we know that there will be at most two classes: <kbd>Spam</kbd> or <kbd>Ham</kbd>. If we know there is a third class, say <kbd>Prosciutto</kbd>, for example, then we can code it as a value before <kbd>MAXCLASS</kbd>. There are many reasons for using a constant numerical value typed as a <kbd>Class</kbd>. Two of the primary reasons would be correctness and performance.</p>
<p class="mce-root">Imagine we have a function that takes <kbd>Class</kbd> as an input:</p>
<pre class="mce-root">func ExportedFn(a Class) error {<br/>  // does some decision making with a<br/>}</pre>
<p class="mce-root">Someone who uses this function outside this library may pass in <kbd>3</kbd> as the class: <kbd>ExportedFn(Class(3))</kbd>. We can instantly tell if the value is valid if we have a validation function that looks something as follows:</p>
<pre class="mce-root">func (c Class) isValid() bool { return c &lt; MAXCLASS }</pre>
<p class="mce-root">Granted, this is not as nice as other languages, such as Haskell, where you could just do this:</p>
<pre class="mce-root">data Class = Ham <br/>            |Spam</pre>
<p class="mce-root">And let the compiler check for you if that is at the call site, whether the value passed in was valid or not. We still want the correctness, so we defer the checks to the runtime. <kbd>ExportedFn</kbd> now reads as follows:</p>
<pre class="mce-root">func ExportedFn(a Class) error {<br/>  if !a.isValid() {<br/>    return errors.New("Invalid class")<br/>  }<br/>  // does some decision making with a<br/>  }<br/>}</pre>
<p class="mce-root">The notion of data types with ranges of valid value is not a revolutionary notion. Ada for example, has bounded ranges since the 1990s. And the best part about using a constant value as a range with <kbd>MAXCLASS</kbd> is that we can fake the range checks and do them at runtime. In this respect, Go is more or less the same as Python, Java, or other unsafe languages. Where this truly shines however, is in performance.</p>
<div class="packt_tip">A tip for good software engineering practice is to make your program as knowable by the human as possible without sacrificing understanding or neatness. Using constant numerical values (or enums) generally allows the human programmer to understand the constrains that the value is allowed to have. Having constant string values, as we will see in the next section, exposes the programmer to unconstrained values. This is where bugs usually happen.</div>
<p class="mce-root">Note that in the <kbd>Classifier</kbd> struct, both <kbd>tfidfs</kbd> and <kbd>totals</kbd> are arrays. Unlike slices, arrays in Go do not require an extra layer of indirection when accessing values. This makes things a tiny bit faster. But in order to truly understand the tradeoffs of this design, we need to look at alternative designs for <kbd>Class</kbd> and with them the alternative designs of the fields, <kbd>tfidfs</kbd> and <kbd>totals</kbd>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Alternative class design</h1>
                </header>
            
            <article>
                
<p class="mce-root">Here, we imagine an alternative design of <kbd>Class</kbd>:</p>
<pre class="mce-root">type Class string<br/><br/>const (<br/>  Ham Class = "Ham"<br/>  Spam Class = "Spam"<br/>)</pre>
<p class="mce-root">With this change, we will have to update the definition of <kbd>Classifier</kbd>:</p>
<pre class="mce-root">type Classifier struct {<br/>  corpus *corpus.Corpus<br/><br/>  tfidfs map[Class]*tfidf.TFIDF<br/>  totals map[Class]float64<br/><br/>  ready bool<br/>  sync.Mutex<br/>}</pre>
<p class="mce-root">Consider now the steps required to get the totals of class <kbd>Ham</kbd>:</p>
<ol>
<li class="mce-root">The string has to be hashed</li>
<li class="mce-root">The hash will be used to look up the bucket where the data for <kbd>totals</kbd> is stored</li>
<li class="mce-root">An indirection is made to the bucket and the data is retrieved and returned to the user</li>
</ol>
<p class="mce-root"/>
<p class="mce-root">Consider now the steps required to get the totals of class <kbd>Ham</kbd> if the class design was the original:</p>
<ul>
<li class="mce-root">Since <kbd>Ham</kbd> is a number, we can directly compute the location of the data for retrieval and return to the user.</li>
</ul>
<p class="mce-root">By using a constant value and a numeric definition of the type <kbd>Class</kbd>, and an array type for <kbd>totals</kbd>, we are able to skip two steps. This yields very slight performance improvements. In this project, they're mostly negligible, until your data gets to a certain size.</p>
<p class="mce-root">The aim of this section on the <kbd>Class</kbd> design is to instill a sense of mechanical sympathy. If you understand how the machine works, you can design very fast machine learning algorithms.</p>
<p class="mce-root">All this said and done, there is one assumption that underpins this entire exercise. This is a <kbd>main</kbd> package. If you're designing a package that will be reused on different datasets, the tradeoff considerations are significantly different. In the context of software engineering, overgeneralizing your package often leads to leaky abstractions that are hard to debug. Better to write slightly more concrete and specific data structures that are purpose built.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Classifier part II</h1>
                </header>
            
            <article>
                
<p class="mce-root">One of the main considerations is that a Naive Bayes classifier is a very simple program, and very difficult to get wrong. The entire program is in fact fewer than 100 lines. Let's look at it further.</p>
<p class="mce-root">We have sketched out so far the method <kbd>Train</kbd>, which will train the classifier on a given set of inputs. Here's how it looks:</p>
<pre class="mce-root">func (c *Classifier) Train(examples []Example) {<br/>  for _, ex := range examples {<br/>    c.trainOne(ex)<br/>  }<br/>}<br/><br/>func (c *Classifier) trainOne(example Example) {<br/>  d := make(doc, len(example.Document))<br/>  for i, word := range example.Document {<br/>    id := c.corpus.Add(word)<br/>    d[i] = id<br/>  }<br/>  c.tfidfs[example.Class].Add(d)<br/>  c.totals[example.Class]++<br/>}</pre>
<p class="mce-root">So here it's very clear that <kbd>Train</kbd> is an <img class="fm-editor-equation" src="Images/8becaf0d-f9e5-4b14-a6a7-dba5530d07d9.png" style="width:3.67em;height:1.25em;" width="650" height="220"/> operation. But the function is structured in such a way that it would be trivial to parallelize the calls to <kbd>c.trainOne</kbd>. Within the context of this project, this wasn't necessary because the program was able to complete in under a second. However, if you are adapting this program for larger and more varied datasets, it may be instructive to parallelize the calls. The <kbd>Classifier</kbd> and <kbd>tfidf.TFIDF</kbd> structs have mutexes in them to allow for these sorts of extensions.</p>
<p class="mce-root">But what's more interesting is the <kbd>trainOne</kbd> example. Looking at it, all it seems to do is to add each word to the corpus, get its ID, and then add the ID to the <kbd>doc</kbd> type. <kbd>doc</kbd>, incidentally, is defined as such:</p>
<pre class="mce-root">type doc []int<br/><br/>func (d doc) IDs() []int { return []int(d) }</pre>
<p class="mce-root">This definition is done to fit into the interface that <kbd>tfidf.TFIDF.Add</kbd> accepts.</p>
<p class="mce-root">Let's look closer at the <kbd>trainOne</kbd> method. After making the <kbd>doc</kbd>, the words from the example are added to the corpus, while the IDs are then put into the <kbd>doc</kbd>. The <kbd>doc</kbd> is then added to the <kbd>tfidf.TFIDF</kbd> of the relevant class.</p>
<p class="mce-root">At first glance, there isn't much training here; we're just adding to the TF statistic.</p>
<p class="mce-root">The real magic happens in the <kbd>Predict</kbd> and <kbd>Score </kbd>methods.</p>
<p class="mce-root"><kbd>Score</kbd> is defined as such:</p>
<pre class="mce-root">func (c *Classifier) Score(sentence []string) (scores [MAXCLASS]float64) {<br/>  if !c.ready {<br/>    c.Postprocess()<br/>  }<br/><br/>  d := make(doc, len(sentence))<br/>  for i, word := range sentence {<br/>    id := c.corpus.Add(word)<br/>    d[i] = id<br/>  }<br/><br/>  priors := c.priors()<br/><br/>  // score per class<br/>  for i := range c.tfidfs {<br/>    score := math.Log(priors[i])<br/>    // likelihood<br/>    for _, word := range sentence {<br/>      prob := c.prob(word, Class(i))<br/>      score += math.Log(prob)<br/>    }<br/><br/>    scores[i] = score<br/>  }<br/>  return<br/>}</pre>
<p class="mce-root">Given a tokenized sentence, we want to return the <kbd>scores</kbd> of each class. The idea is so that we can then look through the <kbd>scores</kbd> and find the class with the highest score:</p>
<pre class="mce-root">func (c *Classifier) Predict(sentence []string) Class {<br/>  scores := c.Score(sentence)<br/>  return argmax(scores)<br/>}</pre>
<p class="mce-root">The <kbd>Score</kbd> function is worth a deeper look because that's where all the magic happens. First, we check the classifier is ready to score. An online machine learning system learns as new data comes in. This design means that the classifier cannot be used in an online fashion. All the training needs to be done up front. Once that training is done, the classifier will be locked, and won't train any further. Any new data will have to be part of a different run.</p>
<p class="mce-root">The <kbd>Postprocess</kbd> method is quite simple. Having recorded all the TF statistics, we now want to calculate the relative importance of each term to the documents. The <kbd>tfidf</kbd> package comes with a simple <kbd>Log</kbd>-based calculation of the IDF, but you can use any other IDF calculating function, as follows:</p>
<pre class="mce-root">func (c *Classifier) Postprocess() {<br/>  c.Lock()<br/>  if c.ready {<br/>    c.Unlock()<br/>    return<br/>  }<br/><br/>  var docs int<br/>  for _, t := range c.tfidfs {<br/>    docs += t.Docs<br/>  }<br/>  for _, t := range c.tfidfs {<br/>    t.Docs = docs<br/>    // t.CalculateIDF()<br/>    for k, v := range t.TF {<br/>      t.IDF[k] = math.Log1p(float64(t.Docs) / v)<br/>    }<br/>  }<br/>  c.ready = true<br/>  c.Unlock()<br/>}</pre>
<p class="mce-root">It is important to note that there is an update to the document count of each class: <kbd>t.Docs = docs</kbd> to the sum of all the documents seen. This was because as we were adding to the term frequency of each class, the <kbd>tfidf.TFIDF</kbd> struct wouldn't be aware of documents in other classes.</p>
<p class="mce-root">The reason we would want to calculate the IDF is to control the values a bit more.</p>
<p class="mce-root">Recall that the conditional probability can be written in the Bayes' theorem form:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/badb5fed-45e2-4754-9e26-b828ab836786.png" style="width:25.92em;height:2.83em;" width="4400" height="480"/></div>
<p class="mce-root">Let's familiarize ourselves with the formula, once again by restating it in English, first by familiarizing ourselves with the terms:</p>
<ul>
<li class="mce-root"> <img class="fm-editor-equation" src="Images/cd6757b2-66c0-4bb3-aef7-7d932918498b.png" style="width:3.42em;height:1.00em;" width="750" height="220"/>: This is the <strong>prior probability</strong> of a class. If we have a pool of email messages and we randomly pick one out, what is the probability that the email is <kbd>Ham</kbd> or <kbd>Spam</kbd>? This largely corresponds to the dataset that we have. From the exploratory analysis, we know that the ratio between <kbd>Ham</kbd> and <kbd>Spam</kbd> is around 80:20.</li>
<li class="mce-root"><img class="fm-editor-equation" src="Images/75331005-fca9-4cb6-aa00-a1f76789cbb0.png" style="width:8.83em;height:1.17em;" width="1670" height="220"/>: This is the <strong>likelihood</strong> of any random document belongs to a class. Because a document is comprised of individual words, we simply make a Naïve assumption that these words are independent of one another. So we want the probability of <img class="fm-editor-equation" src="Images/14e84a1b-e473-4149-bcfa-66b3ec599b4c.png" style="width:13.50em;height:0.92em;" width="3240" height="220"/>. Assuming the words are independent gives us the ability to simply multiply the probabilities.</li>
</ul>
<p class="mce-root">So, to put it in English:</p>
<div class="mce-root packt_quote">The conditional probability of a class being Ham given a document is the result of multiplying the prior probability of a document being ham and the likelihood that the document is Ham.</div>
<p class="mce-root">The observant reader may note that I have elided explanation of <img class="fm-editor-equation" src="Images/9001d080-13de-44e8-87e2-29688dc8aca6.png" style="width:6.92em;height:1.33em;" width="1140" height="220"/>. The reason is simple. Consider what the probability of the document is. It's simply the multiplication of all the probabilities of a word in the corpus. It doesn't in anyway interact with the <kbd>Class</kbd>. It could well be a constant.</p>
<p class="mce-root">Furthermore, we run into another problem if we do use probabilities multiplied. Multiplying probabilities tend to yield smaller and smaller numbers. Computers do not have true rational numbers. <kbd>float64</kbd> is a neat trick to mask the fundamental limitations that a computer has. You will frequently run into edge cases where the numbers become too small or too big when working on machine learning problems.</p>
<p class="mce-root">Fortunately, for this case, we have an elegant solution: We can elect to work in the log domain. Instead of considering the likelihood, we would consider the log likelihood. Upon taking logs, multiplication becomes addition. This allows us to keep it out of sight, and out of mind. For most cases, this project included, this is a fine choice. There may be cases where you wish to normalize the probabilities. Then, ignoring the denominator wouldn't work well.</p>
<p class="mce-root">Let's look at some code on how to write <kbd>priors</kbd>:</p>
<pre class="mce-root">func (c *Classifier) priors() (priors []float64) {<br/>  priors = make([]float64, MAXCLASS)<br/>  var sum float64<br/>  for i, total := range c.totals {<br/>    priors[i] = total<br/>    sum += total<br/>  }<br/>  for i := Ham; i &lt; MAXCLASS; i++ {<br/>    priors[int(i)] /= sum<br/>  }<br/>  return<br/>}</pre>
<p class="mce-root">The priors are essentially the proportion of <kbd>Ham</kbd> or <kbd>Spam</kbd> to the sum of all documents. This is fairly simple. To compute the likelihood, let's look at the loop in <kbd>Score</kbd>:</p>
<pre class="mce-root">  // likelihood<br/>  for _, word := range sentence {<br/>    prob := c.prob(word, Class(i))<br/>    score += math.Log(prob)<br/>  }</pre>
<p class="mce-root">We incorporate the likelihood function into the scoring function simply for ease of understanding. But the important takeaway of the likelihood function is that we're summing the probabilities of the word given the class. How do you calculate <img class="fm-editor-equation" src="Images/6a3e0ad0-7fa3-4a97-8b09-49bea7234a2b.png" style="width:7.42em;height:1.17em;" width="1410" height="220"/> ? such as the following:</p>
<pre class="mce-root">func (c *Classifier) prob(word string, class Class) float64 {<br/>  id, ok := c.corpus.Id(word)<br/>  if !ok {<br/>    return tiny<br/>  }<br/><br/>  freq := c.tfidfs[class].TF[id]<br/>  idf := c.tfidfs[class].IDF[id]<br/>  // idf := 1.0<br/><br/>  // a word may not appear at all in a class.<br/>  if freq == 0 {<br/>    return tiny<br/>  }<br/><br/>  return freq * idf / c.totals[class]<br/>}</pre>
<p class="mce-root CDPAlignLeft CDPAlign">First, we check whether the word has been seen. If the word hasn't been seen before, then we return a default value <kbd>tiny</kbd>—a small non-zero value that won't cause a division-by-zero error.</p>
<p class="mce-root">The probability of a word occurring in a class is simply its frequency divided by the number of words seen by the class. But we want to go a bit further; we want to control for frequent words being too important a factor in deciding the probability of the class, so we multiply it by the IDF that we had calculated earlier. And that's how you'd get the probabilities of the word given a class.</p>
<p class="mce-root">After we have the probability, we take the log of it, and then add it to the score.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Putting it all together</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now we have all the pieces. Let's look at how to put it all together:</p>
<ol>
<li class="mce-root">We first <kbd>ingest</kbd> the dataset and then split the data out into training and cross validation sets. The dataset is split into ten parts for a k-fold cross-validation. We won't do that. Instead, we'll do a single fold cross-validation by holding out 30% of the data for cross-validation:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">  typ := "bare"<br/>  examples, err := ingest(typ)<br/>  log.Printf("errs %v", err)<br/>  log.Printf("Examples loaded: %d", len(examples))<br/>  shuffle(examples)<br/>  cvStart := len(examples) - len(examples)/3<br/>  cv := examples[cvStart:]<br/>  examples = examples[:cvStart]</pre>
<ol start="2">
<li class="mce-root">We then train the classifier and then check to see whether the classifier can predict its own dataset well:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">  c := New()<br/>  c.Train(examples)<br/><br/>  var corrects, totals float64<br/>  for _, ex := range examples {<br/>    // log.Printf("%v", c.Score(ham.Document))<br/>    class := c.Predict(ex.Document)<br/>    if class == ex.Class {<br/>      corrects++<br/>    }<br/>    totals++<br/>  }<br/>  log.Printf("Corrects: %v, Totals: %v. Accuracy %v", corrects, totals, corrects/totals)</pre>
<ol start="3">
<li class="mce-root">After training the classifier, we perform a cross-validation on the data:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">  log.Printf("Start Cross Validation (this classifier)")<br/>  corrects, totals = 0, 0<br/>  hams, spams := 0.0, 0.0<br/>  var unseen, totalWords int<br/>  for _, ex := range cv {<br/>    totalWords += len(ex.Document)<br/>    unseen += c.unseens(ex.Document)<br/>    class := c.Predict(ex.Document)<br/>    if class == ex.Class {<br/>      corrects++<br/>    }<br/>    switch ex.Class {<br/>    case Ham:<br/>      hams++<br/>    case Spam:<br/>      spams++<br/>    }<br/>    totals++<br/>  }</pre>
<ol start="4">
<li class="mce-root">Here, I also added an <kbd>unseen</kbd> and <kbd>totalWords</kbd> count, as a simple statistic to see how well the classifier can generalize when encountering previously unseen words.</li>
</ol>
<p class="mce-root">Additionally, because we know ahead of time that the dataset comprises roughly 80% <kbd>Ham</kbd> and 20% <kbd>Spam</kbd>, we have a baseline to beat. Simply put, we could write a classifier that does this:</p>
<pre class="mce-root">type Classifier struct{}<br/>func (c Classifier) Predict(sentence []string) Class { return Ham }</pre>
<p class="mce-root">Imagine we have such a classifier. Then it would be right 80% of the time! For us to know that our classifier is good, it would have to beat a baseline. For the purposes of this chapter, we simply print out the statistics and tweak accordingly:</p>
<pre class="mce-root">  fmt.Printf("Dataset: %q. Corrects: %v, Totals: %v. Accuracy %v\n", typ, corrects, totals, corrects/totals)<br/>  fmt.Printf("Hams: %v, Spams: %v. Ratio to beat: %v\n", hams, spams, hams/(hams+spams))<br/>  fmt.Printf("Previously unseen %d. Total Words %d\n", unseen, totalWords)</pre>
<p class="mce-root">So, this is what the final <kbd>main</kbd> function looks as follows:</p>
<pre class="mce-root">func main() {<br/>  typ := "bare"<br/>  examples, err := ingest(typ)<br/>  if err != nil {<br/>    log.Fatal(err)<br/>  }<br/><br/>  fmt.Printf("Examples loaded: %d\n", len(examples))<br/>  shuffle(examples)<br/>  cvStart := len(examples) - len(examples)/3<br/>  cv := examples[cvStart:]<br/>  examples = examples[:cvStart]<br/><br/>  c := New()<br/>  c.Train(examples)<br/><br/>  var corrects, totals float64<br/>  for _, ex := range examples {<br/>    // fmt.Printf("%v", c.Score(ham.Document))<br/>    class := c.Predict(ex.Document)<br/>    if class == ex.Class {<br/>      corrects++<br/>    }<br/>    totals++<br/>  }<br/>  fmt.Printf("Dataset: %q. Corrects: %v, Totals: %v. Accuracy %v\n", typ, corrects, totals, corrects/totals)<br/><br/>  fmt.Println("Start Cross Validation (this classifier)")<br/>  corrects, totals = 0, 0<br/>  hams, spams := 0.0, 0.0<br/>  var unseen, totalWords int<br/>  for _, ex := range cv {<br/>    totalWords += len(ex.Document)<br/>    unseen += c.unseens(ex.Document)<br/>    class := c.Predict(ex.Document)<br/>    if class == ex.Class {<br/>      corrects++<br/>    }<br/>    switch ex.Class {<br/>    case Ham:<br/>      hams++<br/>    case Spam:<br/>      spams++<br/>    }<br/>    totals++<br/>  }<br/><br/>  fmt.Printf("Dataset: %q. Corrects: %v, Totals: %v. Accuracy %v\n", typ, corrects, totals, corrects/totals)<br/>  fmt.Printf("Hams: %v, Spams: %v. Ratio to beat: %v\n", hams, spams, hams/(hams+spams))<br/>  fmt.Printf("Previously unseen %d. Total Words %d\n", unseen, totalWords)<br/>}</pre>
<p class="mce-root">Running it on <kbd>bare</kbd>, this is the result I get the following:</p>
<pre class="mce-root"><strong>Examples loaded: 2893</strong><br/><strong>Dataset: "bare". Corrects: 1917, Totals: 1929. Accuracy 0.9937791601866252</strong><br/><strong>Start Cross Validation (this classifier)</strong><br/><strong>Dataset: "bare". Corrects: 946, Totals: 964. Accuracy 0.9813278008298755</strong><br/><strong>Hams: 810, Spams: 154. Ratio to beat: 0.8402489626556017</strong><br/><strong>Previously unseen 17593. Total Words 658105</strong></pre>
<p class="mce-root">To see the effects of removing stopwords and lemmatization, we simply switch to using the <kbd>lemm_stop</kbd> dataset, and this is the result I get the following:</p>
<pre class="mce-root"><strong>Dataset: "lemm_stop". Corrects: 1920, Totals: 1929. Accuracy 0.995334370139969</strong><br/><strong>Start Cross Validation (this classifier)</strong><br/><strong>Dataset: "lemm_stop". Corrects: 948, Totals: 964. Accuracy 0.983402489626556</strong><br/><strong>Hams: 810, Spams: 154. Ratio to beat: 0.8402489626556017</strong><br/><strong>Previously unseen 16361. Total Words 489255</strong></pre>
<p class="mce-root">Either way, the classifier is brutally effective.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, I have shown the basics of what a Naive Bayes classifier looks like—a classifier written with the fundamental understanding of statistics will trump any publicly available library any day.</p>
<p class="mce-root">The classifier itself is fewer than 100 lines of code, but with it comes a great deal of power. Being able to perform classification with 98% or greater accuracy is no mean feat.</p>
<p class="mce-root">A note on the 98% figure: This is not state of the art. State of the art is in the high 99.xx%. The main reason why there is a race for that final percent is because of scale. Imagine you're Google and you're running Gmail. A 0.01% error means millions of emails being misclassified. That means many unhappy customers.</p>
<p class="mce-root">For the most part, in machine learning, the case of whether to go for newer untested methods really depends on the scale of your problems. In my experience from the past 10 years doing machine learning, most companies do not reach that scale of data. As such, the humble Naive Bayes classifier would serve very well.</p>
<p>In the next chapter, we shall look at one of the most vexing issues that humans face: time.</p>


            </article>

            
        </section>
    </div>



  </body></html>