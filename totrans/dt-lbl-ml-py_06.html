<html><head></head><body>
<div id="_idContainer084">
<h1 class="chapter-number" id="_idParaDest-119"><a id="_idTextAnchor124"/><span class="koboSpan" id="kobo.1.1">6</span></h1>
<h1 id="_idParaDest-120"><a id="_idTextAnchor125"/><span class="koboSpan" id="kobo.2.1">Labeling Image Data Using Data Augmentation</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In this chapter, we will learn how to label image data using data augmentation for semi-supervised machine learning. </span><span class="koboSpan" id="kobo.3.2">We will use the CIFAR-10 dataset and the MNIST dataset of handwritten digits to generate labels using data augmentation. </span><span class="koboSpan" id="kobo.3.3">From there we will build an image classification machine </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">learning model.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">Data augmentation plays a crucial role in data labeling by enhancing the diversity, size, and quality of the dataset. </span><span class="koboSpan" id="kobo.5.2">Data augmentation techniques generate additional samples by applying transformations to existing data. </span><span class="koboSpan" id="kobo.5.3">This effectively increases the size of the dataset, providing more examples for training and improving the model’s ability </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">to generalize.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">In this chapter, we will cover </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.9.1">How to prepare training data with image data augmentation and implement support </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">vector machines</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">How to implement convolutional neural networks with augmented </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">image data</span></span></li>
</ul>
<h1 id="_idParaDest-121"><a id="_idTextAnchor126"/><span class="koboSpan" id="kobo.13.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.14.1">For this chapter, we will use the CIFAR-10 dataset, which is a publicly available image dataset consisting of 60,000 32x32 color images in 10 classes (</span><a href="http://www.cs.toronto.edu/~kriz/cifar.html"><span class="koboSpan" id="kobo.15.1">http://www.cs.toronto.edu/~kriz/cifar.html</span></a><span class="koboSpan" id="kobo.16.1">), along with the famous MNIST handwritten </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">digits dataset.</span></span></p>
<h1 id="_idParaDest-122"><a id="_idTextAnchor127"/><span class="koboSpan" id="kobo.18.1">Training support vector machines with augmented image data</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.19.1">Support Vector Machines</span></strong><span class="koboSpan" id="kobo.20.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.21.1">SVMs</span></strong><span class="koboSpan" id="kobo.22.1">) are </span><a id="_idIndexMarker386"/><span class="koboSpan" id="kobo.23.1">widely used in machine learning to solve classification problems. </span><span class="koboSpan" id="kobo.23.2">SVMs are known for their high accuracy and ability to handle complex datasets. </span><span class="koboSpan" id="kobo.23.3">One of the challenges in training SVMs is the availability of large and diverse datasets. </span><span class="koboSpan" id="kobo.23.4">In this section, we will discuss the</span><a id="_idIndexMarker387"/><span class="koboSpan" id="kobo.24.1"> importance of </span><a id="_idIndexMarker388"/><span class="koboSpan" id="kobo.25.1">data augmentation in training SVMs for image classification problems. </span><span class="koboSpan" id="kobo.25.2">We will also provide Python code examples for </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">each technique.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer083">
<span class="koboSpan" id="kobo.27.1"><img alt="" role="presentation" src="image/B18944_06_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.28.1">Figure 6.1 – SVM separates class A and class B with largest margin</span></p>
<p><span class="koboSpan" id="kobo.29.1">SVMs are a type of supervised learning algorithm used for classification and regression analysis. </span><span class="koboSpan" id="kobo.29.2">SVMs can be used for outlier detection. </span><span class="koboSpan" id="kobo.29.3">SVMs were originally designed for classification tasks, but can also be adapted for anomaly or outlier detection </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">as well.</span></span></p>
<p><span class="koboSpan" id="kobo.31.1">The objective of SVMs is to find the hyperplane that maximizes the margin between two classes of data. </span><span class="koboSpan" id="kobo.31.2">The hyperplane is defined as the decision boundary that separates the data points of two classes. </span><span class="koboSpan" id="kobo.31.3">The margin is the distance between the hyperplane and the nearest data point of </span><span class="No-Break"><span class="koboSpan" id="kobo.32.1">each class.</span></span></p>
<p><span class="koboSpan" id="kobo.33.1">SVMs use something called</span><a id="_idIndexMarker389"/><span class="koboSpan" id="kobo.34.1"> the </span><em class="italic"><span class="koboSpan" id="kobo.35.1">kernel trick</span></em><span class="koboSpan" id="kobo.36.1">. </span><span class="koboSpan" id="kobo.36.2">Let’s understand what this </span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">is next.</span></span></p>
<h2 id="_idParaDest-123"><a id="_idTextAnchor128"/><span class="koboSpan" id="kobo.38.1">Kernel trick</span></h2>
<p><span class="koboSpan" id="kobo.39.1">Let’s say you have data points on a sheet of paper, and you want to separate them into two groups. </span><span class="koboSpan" id="kobo.39.2">Imagine you have a magic wand (i.e., the kernel trick) that allows you to lift the points off the paper into the air. </span><span class="koboSpan" id="kobo.39.3">In the air, you can easily draw a line or a curve to separate the </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">floating points.</span></span></p>
<p><span class="koboSpan" id="kobo.41.1">Now, when you’re satisfied with the separation in the air, you use the magic wand again to bring everything back down to the paper. </span><span class="koboSpan" id="kobo.41.2">Miraculously, the separation you drew in the air translates to a more complex decision boundary on the paper that effectively separates your original </span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">data points.</span></span></p>
<p><span class="koboSpan" id="kobo.43.1">In the SVM world, this “magic wand” is the </span><a id="_idIndexMarker390"/><span class="koboSpan" id="kobo.44.1">kernel trick. </span><span class="koboSpan" id="kobo.44.2">It allows SVMs to implicitly work in a higher-dimensional space, making it possible to find more intricate decision boundaries that weren’t achievable in the original space. </span><span class="koboSpan" id="kobo.44.3">The key is that you don’t have to explicitly compute the coordinates of the higher-dimensional space; the kernel trick does this </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">for you.</span></span></p>
<p><span class="koboSpan" id="kobo.46.1">In summary, the kernel trick lifts your data into a higher-dimensional space, where SVMs can find more sophisticated ways to separate different classes. </span><span class="koboSpan" id="kobo.46.2">It’s a powerful tool for handling complex </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">data scenarios.</span></span></p>
<p><span class="koboSpan" id="kobo.48.1">SVMs leverage the </span><a id="_idIndexMarker391"/><span class="koboSpan" id="kobo.49.1">kernel trick to transform the input data into a higher-dimensional space, where a linear decision boundary can be found. </span><span class="koboSpan" id="kobo.49.2">The kernel function plays a crucial role in this process, mapping the input data into a feature space where the relationships between variables may be more </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">easily separable.</span></span></p>
<p><span class="koboSpan" id="kobo.51.1">The most commonly used kernel functions are the linear kernel, which represents a linear decision boundary, the polynomial kernel, which introduces non-linearity with higher-order polynomial features, and </span><a id="_idIndexMarker392"/><span class="koboSpan" id="kobo.52.1">the </span><strong class="bold"><span class="koboSpan" id="kobo.53.1">radial basis function</span></strong><span class="koboSpan" id="kobo.54.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.55.1">RBF</span></strong><span class="koboSpan" id="kobo.56.1">) kernel, which allows for a more flexible and non-linear decision boundary. </span><span class="koboSpan" id="kobo.56.2">The choice of the kernel function and its parameters significantly influences the SVM’s ability to model complex relationships in </span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.58.1">As we now have a basic idea about SVMs, let us next understand data augmentation, image data augmentation, and the various techniques used </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">for this.</span></span></p>
<h2 id="_idParaDest-124"><a id="_idTextAnchor129"/><span class="koboSpan" id="kobo.60.1">Data augmentation</span></h2>
<p><span class="koboSpan" id="kobo.61.1">Data augmentation is the </span><a id="_idIndexMarker393"/><span class="koboSpan" id="kobo.62.1">process of creating new data points from the existing data points by applying various transformations such as rotation, translation, and scaling. </span><span class="koboSpan" id="kobo.62.2">Data augmentation is used to increase the size of the training dataset and improve the generalizability and accuracy of the model by helping the model to learn more features and patterns in </span><span class="No-Break"><span class="koboSpan" id="kobo.63.1">the data.</span></span></p>
<h2 id="_idParaDest-125"><a id="_idTextAnchor130"/><span class="koboSpan" id="kobo.64.1">Image data augmentation</span></h2>
<p><span class="koboSpan" id="kobo.65.1">Image data augmentation is a </span><a id="_idIndexMarker394"/><span class="koboSpan" id="kobo.66.1">technique of augmenting the image dataset to improve the accuracy of the model. </span><span class="koboSpan" id="kobo.66.2">The following is a selection of the techniques that can be used for image </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">data augmentation.</span></span></p>
<h3><span class="koboSpan" id="kobo.68.1">Image rotation</span></h3>
<p><span class="koboSpan" id="kobo.69.1">Image rotation is a</span><a id="_idIndexMarker395"/><span class="koboSpan" id="kobo.70.1"> technique where an image is rotated by a certain angle. </span><span class="koboSpan" id="kobo.70.2">This technique is used to increase the size of the training dataset and improve the model’s ability to recognize </span><a id="_idIndexMarker396"/><span class="koboSpan" id="kobo.71.1">objects from different angles. </span><span class="koboSpan" id="kobo.71.2">The Python code for image rotation is </span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.73.1">
from PIL import Image
import numpy as np
def rotate_image(image_path, degrees):
    img = Image.open(image_path)
    rotated_image = img.rotate(degrees)
    return rotated_image
image_path = "path/to/image.jpg"
rotated_image = rotate_image(image_path, 45)
rotated_image.show()</span></pre> <p><span class="koboSpan" id="kobo.74.1">In the preceding code, we load</span><a id="_idIndexMarker397"/><span class="koboSpan" id="kobo.75.1"> the image from the image path and rotate it by a given number of degrees. </span><span class="koboSpan" id="kobo.75.2">This creates a new dataset for the same image from different angles and improves </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">model training.</span></span></p>
<h3><span class="koboSpan" id="kobo.77.1">Image translation</span></h3>
<p><span class="koboSpan" id="kobo.78.1">Image translation is </span><a id="_idIndexMarker398"/><span class="koboSpan" id="kobo.79.1">a technique where an image is shifted horizontally or vertically by a certain amount of pixels. </span><span class="koboSpan" id="kobo.79.2">This technique is used to increase the size of the training dataset and improve the model’s ability to recognize objects in different positions. </span><span class="koboSpan" id="kobo.79.3">The Python code for image translation is </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.81.1">
from PIL import Image
import numpy as np
def translate_image(image_path, x_offset, y_offset):
    img = Image.open(image_path)
    translated_image = img.transform(img.size, \
        Image.AFFINE, (1, 0, x_offset, 0, 1, y_offset))
    return translated_image
image_path = "path/to/image.jpg"
translated_image = translate_image(image_path, 50, 50)
translated_image.show()</span></pre> <p><span class="koboSpan" id="kobo.82.1">In the preceding code, we</span><a id="_idIndexMarker399"/><span class="koboSpan" id="kobo.83.1"> define a Python function that shifts the image by a certain amount </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">of pixels.</span></span></p>
<h3><span class="koboSpan" id="kobo.85.1">Image scaling</span></h3>
<p><span class="koboSpan" id="kobo.86.1">Image scaling </span><a id="_idIndexMarker400"/><span class="koboSpan" id="kobo.87.1">is an augmentation technique where an image is scaled up or down by a certain factor. </span><span class="koboSpan" id="kobo.87.2">This technique is used to increase the size of the training dataset and improve the model’s ability to recognize objects at different scales. </span><span class="koboSpan" id="kobo.87.3">The Python code for image scaling is </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.89.1">
from PIL import Image
import numpy as np
def scale_image(image_path, scale_factor):
    img = Image.open(image_path)
    scaled_image = img.resize((int(img.size[0]*scale_factor),\
        int(img.size[1]*scale_factor)))
    return scaled_image
image_path = "path/to/image.jpg"
scaled_image = scale_image(image_path, 0.5)
scaled_image.show()</span></pre> <p><span class="koboSpan" id="kobo.90.1">In the preceding code, we change the image size by multiplying the image by a scale factor in a Python function. </span><span class="koboSpan" id="kobo.90.2">Next, let’s see how to implement an SVM with data augmentation using the </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">CIFAR-10 dataset.</span></span></p>
<h1 id="_idParaDest-126"><a id="_idTextAnchor131"/><span class="koboSpan" id="kobo.92.1">Implementing an SVM with data augmentation in Python</span></h1>
<p><span class="koboSpan" id="kobo.93.1">In this section, we will </span><a id="_idIndexMarker401"/><span class="koboSpan" id="kobo.94.1">provide a step-by-step guide to implement an SVM with data augmentation in Python using</span><a id="_idIndexMarker402"/><span class="koboSpan" id="kobo.95.1"> the CIFAR-10 dataset. </span><span class="koboSpan" id="kobo.95.2">We will start by introducing the CIFAR-10 dataset and then move on to loading the dataset in Python. </span><span class="koboSpan" id="kobo.95.3">We will then preprocess the data for SVM training and implement an SVM with the default hyperparameters and dataset. </span><span class="koboSpan" id="kobo.95.4">Next, we train and evaluate the performance of the SVM with an augmented dataset, showing that the performance of the SVM improves on the </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">augmented dataset.</span></span></p>
<h2 id="_idParaDest-127"><a id="_idTextAnchor132"/><span class="koboSpan" id="kobo.97.1">Introducing the CIFAR-10 dataset</span></h2>
<p><span class="koboSpan" id="kobo.98.1">The CIFAR-10 dataset is a</span><a id="_idIndexMarker403"/><span class="koboSpan" id="kobo.99.1"> commonly used image classification dataset that consists of 60,000 32x32 color images in 10 classes. </span><span class="koboSpan" id="kobo.99.2">The classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. </span><span class="koboSpan" id="kobo.99.3">The dataset is divided into 50,000 training images and 10,000 testing images. </span><span class="koboSpan" id="kobo.99.4">The dataset is preprocessed in a way that the training set and test set have an equal number of images from </span><span class="No-Break"><span class="koboSpan" id="kobo.100.1">each class.</span></span></p>
<h2 id="_idParaDest-128"><a id="_idTextAnchor133"/><span class="koboSpan" id="kobo.101.1">Loading the CIFAR-10 dataset in Python</span></h2>
<p><span class="koboSpan" id="kobo.102.1">To load the </span><a id="_idIndexMarker404"/><span class="koboSpan" id="kobo.103.1">CIFAR-10 dataset in Python, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.104.1">cifar10</span></strong><span class="koboSpan" id="kobo.105.1"> module</span><a id="_idIndexMarker405"/><span class="koboSpan" id="kobo.106.1"> from the Keras library. </span><span class="koboSpan" id="kobo.106.2">If you don’t have Keras installed, you can install it using the </span><span class="No-Break"><span class="koboSpan" id="kobo.107.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.108.1">
pip install keras</span></pre> <p><span class="koboSpan" id="kobo.109.1">Once you have installed Keras, you can load the CIFAR-10 dataset using the </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">following code:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.111.1">
from keras.datasets import cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span></pre> <p><span class="koboSpan" id="kobo.112.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.113.1">cifar10.load_data()</span></strong><span class="koboSpan" id="kobo.114.1"> function</span><a id="_idIndexMarker406"/><span class="koboSpan" id="kobo.115.1"> returns two tuples: </span><strong class="source-inline"><span class="koboSpan" id="kobo.116.1">(x_train, y_train)</span></strong><span class="koboSpan" id="kobo.117.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.118.1">(x_test, y_test)</span></strong><span class="koboSpan" id="kobo.119.1">. </span><span class="koboSpan" id="kobo.119.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.120.1">x_train</span></strong><span class="koboSpan" id="kobo.121.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.122.1">x_test</span></strong><span class="koboSpan" id="kobo.123.1"> tuples contain the input images, while the </span><strong class="source-inline"><span class="koboSpan" id="kobo.124.1">y_train</span></strong><span class="koboSpan" id="kobo.125.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.126.1">y_test</span></strong><span class="koboSpan" id="kobo.127.1"> tuples contain the</span><a id="_idIndexMarker407"/><span class="koboSpan" id="kobo.128.1"> corresponding class labels for the </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">input images.</span></span></p>
<h2 id="_idParaDest-129"><a id="_idTextAnchor134"/><span class="koboSpan" id="kobo.130.1">Preprocessing the data for SVM training</span></h2>
<p><span class="koboSpan" id="kobo.131.1">In this section, we will</span><a id="_idIndexMarker408"/><span class="koboSpan" id="kobo.132.1"> first convert the input images from </span><a id="_idIndexMarker409"/><span class="koboSpan" id="kobo.133.1">3D matrices to 2D matrices. </span><span class="koboSpan" id="kobo.133.2">We will also normalize the pixel values of the input images to be between 0 and 1. </span><span class="koboSpan" id="kobo.133.3">Finally, we will reshape the input images and convert the class labels to one-hot </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">encoded vectors.</span></span></p>
<p><span class="koboSpan" id="kobo.135.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.136.1">reshape()</span></strong><span class="koboSpan" id="kobo.137.1"> function is used to reshape the input images from 3D matrices to 2D matrices. </span><span class="koboSpan" id="kobo.137.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.138.1">-1</span></strong><span class="koboSpan" id="kobo.139.1"> argument tells the function to infer the number of columns based on the number of rows and the size of </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">each row:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.141.1">
# Reshape the input images
x_train = x_train.reshape(x_train.shape[0], -1)
x_test = x_test.reshape(x_test.shape[0], -1)</span></pre> <p><span class="koboSpan" id="kobo.142.1">The pixel values of the input images are normalized to be between 0 and 1 by dividing them by 255, which is the maximum </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1">pixel value:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.144.1">
# Convert pixel values to between 0 and 1
x_train = x_train / 255
x_test = x_test / 255</span></pre> <p><span class="koboSpan" id="kobo.145.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.146.1">to_categorical()</span></strong><span class="koboSpan" id="kobo.147.1"> function is used to convert the class labels to one-hot encoded vectors. </span><span class="koboSpan" id="kobo.147.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.148.1">num_classes</span></strong><span class="koboSpan" id="kobo.149.1"> variable is set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.150.1">10</span></strong><span class="koboSpan" id="kobo.151.1">, which is the number of classes in the </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">CIFAR-10 dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.153.1">
# Convert class labels to one-hot encoded vectors
num_classes = 10
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)</span></pre> <h2 id="_idParaDest-130"><a id="_idTextAnchor135"/><span class="koboSpan" id="kobo.154.1">Implementing an SVM with the default hyperparameters</span></h2>
<p><span class="koboSpan" id="kobo.155.1">Hyperparameters in</span><a id="_idIndexMarker410"/><span class="koboSpan" id="kobo.156.1"> SVMs are</span><a id="_idIndexMarker411"/><span class="koboSpan" id="kobo.157.1"> parameters that are not learned from the data but are set prior to the training process. </span><span class="koboSpan" id="kobo.157.2">They control the behavior of the SVM model and can </span><a id="_idIndexMarker412"/><span class="koboSpan" id="kobo.158.1">significantly impact its performance. </span><span class="koboSpan" id="kobo.158.2">Here are some important hyperparameters </span><span class="No-Break"><span class="koboSpan" id="kobo.159.1">in SVM:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.160.1">Kernel</span></strong><span class="koboSpan" id="kobo.161.1">: The kernel function</span><a id="_idIndexMarker413"/><span class="koboSpan" id="kobo.162.1"> determines the type of decision boundary</span><a id="_idIndexMarker414"/><span class="koboSpan" id="kobo.163.1"> used by the SVM. </span><span class="koboSpan" id="kobo.163.2">Common kernel functions include the linear, polynomial, </span><strong class="bold"><span class="koboSpan" id="kobo.164.1">radial basis function</span></strong><span class="koboSpan" id="kobo.165.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.166.1">RBF</span></strong><span class="koboSpan" id="kobo.167.1">), and sigmoid function. </span><span class="koboSpan" id="kobo.167.2">The choice of kernel depends on the data and problem </span><span class="No-Break"><span class="koboSpan" id="kobo.168.1">at hand.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.169.1">Regularization parameter (C)</span></strong><span class="koboSpan" id="kobo.170.1">: Regularization </span><a id="_idIndexMarker415"/><span class="koboSpan" id="kobo.171.1">is a technique used to prevent overfitting or underfitting of the model. </span><span class="koboSpan" id="kobo.171.2">Regularization methods help to control the complexity of the model and improve its generalization on </span><span class="No-Break"><span class="koboSpan" id="kobo.172.1">unseen data.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.173.1">For a binary classification problem, the decision boundary is a hyperplane that separates data into two classes. </span><span class="koboSpan" id="kobo.173.2">The margin is the distance between this hyperplane and the nearest data point from either class. </span><span class="koboSpan" id="kobo.173.3">The “width” of the margin is the actual numerical value of the distance or gap between the decision boundary and the nearest </span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">data point.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.175.1">A wider margin implies a larger separation between classes, providing more room for potential misclassifications without affecting the decision boundary. </span><span class="koboSpan" id="kobo.175.2">The regularization parameter, often denoted as C, controls the trade-off between achieving a low training error rate and maintaining a wide margin. </span><span class="koboSpan" id="kobo.175.3">A smaller C value allows for more misclassifications but results in a larger margin, while a larger C value tries to minimize misclassifications at the cost of a </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">narrower margin.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.177.1">Gamma (for RBF kernels)</span></strong><span class="koboSpan" id="kobo.178.1">: The gamma parameter</span><a id="_idIndexMarker416"/><span class="koboSpan" id="kobo.179.1"> influences the shape of the decision boundary for SVMs with the RBF kernel. </span><span class="koboSpan" id="kobo.179.2">It determines the reach of each training sample and affects the smoothness of the decision boundary. </span><span class="koboSpan" id="kobo.179.3">Higher gamma values tend to result in more complex </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">decision boundaries.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.181.1">Degree (for polynomial kernels)</span></strong><span class="koboSpan" id="kobo.182.1">: The degree parameter</span><a id="_idIndexMarker417"/><span class="koboSpan" id="kobo.183.1"> specifies the degree of the polynomial kernel function. </span><span class="koboSpan" id="kobo.183.2">It determines the nonlinearity of the decision boundary. </span><span class="koboSpan" id="kobo.183.3">Higher degree values allow for more complex decision boundaries but may increase the risk </span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">of overfitting.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.185.1">These </span><a id="_idIndexMarker418"/><span class="koboSpan" id="kobo.186.1">hyperparameters need to be carefully tuned to achieve the best performance of the SVM model. </span><span class="koboSpan" id="kobo.186.2">Grid search, random search, or other optimization techniques can be employed to explore different combinations of hyperparameter values and select</span><a id="_idIndexMarker419"/><span class="koboSpan" id="kobo.187.1"> the </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1">optimal set.</span></span></p>
<p><span class="koboSpan" id="kobo.189.1">To implement an SVM with the default hyperparameters, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.190.1">svm.SVC</span></strong><span class="koboSpan" id="kobo.191.1"> class from the scikit-learn library. </span><span class="koboSpan" id="kobo.191.2">We will first create an instance of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.192.1">SVC</span></strong><span class="koboSpan" id="kobo.193.1"> class and then fit the training data to </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">the classifier.</span></span></p>
<p><span class="koboSpan" id="kobo.195.1">An instance of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.196.1">SVC</span></strong><span class="koboSpan" id="kobo.197.1"> class is created using </span><strong class="source-inline"><span class="koboSpan" id="kobo.198.1">svm.SVC()</span></strong><span class="koboSpan" id="kobo.199.1">. </span><span class="koboSpan" id="kobo.199.2">By not specifying any hyperparameters, it uses the default values for the kernel, regularization parameter (C), and other </span><span class="No-Break"><span class="koboSpan" id="kobo.200.1">relevant parameters:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.201.1">
from sklearn import svm
# Create an instance of the SVC class with default hyperparameters
clf = svm.SVC()</span></pre> <p><span class="koboSpan" id="kobo.202.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.203.1">fit()</span></strong><span class="koboSpan" id="kobo.204.1"> function is used to fit the training data to </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">the classifier:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.206.1">
# Fit the training data to the classifier
clf.fit(x_train, y_train)</span></pre> <h2 id="_idParaDest-131"><a id="_idTextAnchor136"/><span class="koboSpan" id="kobo.207.1">Evaluating SVM on the original dataset</span></h2>
<p><span class="koboSpan" id="kobo.208.1">We evaluate the performance of the original </span><a id="_idIndexMarker420"/><span class="koboSpan" id="kobo.209.1">dataset to compare the performance with the </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">augmented dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.211.1">To evaluate the performance of SVM on the original dataset, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.212.1">predict()</span></strong><span class="koboSpan" id="kobo.213.1"> function to predict the class labels of the test data and then use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.214.1">accuracy_score()</span></strong><span class="koboSpan" id="kobo.215.1"> function from the scikit-learn library to calculate the accuracy of </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">the classifier:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.217.1">
from sklearn.metrics import accuracy_score
# Predict the class labels of the test data
y_pred = clf.predict(x_test)
# Calculate the accuracy of the classifier
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))</span></pre> <p><span class="koboSpan" id="kobo.218.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.219.1">predict()</span></strong><span class="koboSpan" id="kobo.220.1"> function is used to predict the class labels of the test data. </span><span class="koboSpan" id="kobo.220.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.221.1">accuracy_score()</span></strong><span class="koboSpan" id="kobo.222.1"> function is used to calculate the accuracy of the classifier by comparing the predicted class labels to the actual </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">class labels.</span></span></p>
<p><span class="koboSpan" id="kobo.224.1">The accuracy of the SVM model on the test dataset is around </span><strong class="source-inline"><span class="koboSpan" id="kobo.225.1">47.97%</span></strong><span class="koboSpan" id="kobo.226.1">, which is not very good. </span><span class="koboSpan" id="kobo.226.2">This indicates that the SVM model is not able to learn all the important features and patterns in the </span><span class="No-Break"><span class="koboSpan" id="kobo.227.1">original dataset.</span></span></p>
<h2 id="_idParaDest-132"><a id="_idTextAnchor137"/><span class="koboSpan" id="kobo.228.1">Implementing an SVM with an augmented dataset</span></h2>
<p><span class="koboSpan" id="kobo.229.1">To</span><a id="_idIndexMarker421"/><span class="koboSpan" id="kobo.230.1"> implement</span><a id="_idIndexMarker422"/><span class="koboSpan" id="kobo.231.1"> SVM with data augmentation, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.232.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.233.1"> class from the Keras library to generate new training data. </span><span class="koboSpan" id="kobo.233.2">We will first create an instance of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.234.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.235.1"> class and then use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.236.1">flow()</span></strong><span class="koboSpan" id="kobo.237.1"> function to generate new batches of </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">training data:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.239.1">
from keras.preprocessing.image import ImageDataGenerator
# Create an instance of the ImageDataGenerator class
datagen = ImageDataGenerator(rotation_range=20, \
    width_shift_range=0.1, height_shift_range=0.1, \
    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
# Generate new batches of training data
gen_train = datagen.flow(x_train, y_train, batch_size=64)</span></pre> <p><span class="koboSpan" id="kobo.240.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.241.1">ImageDataGenerator()</span></strong><span class="koboSpan" id="kobo.242.1"> function creates an instance of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.243.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.244.1"> class. </span><span class="koboSpan" id="kobo.244.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.245.1">rotation_range</span></strong><span class="koboSpan" id="kobo.246.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.247.1">width_shift_range</span></strong><span class="koboSpan" id="kobo.248.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.249.1">height_shift_range</span></strong><span class="koboSpan" id="kobo.250.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.251.1">shear_range</span></strong><span class="koboSpan" id="kobo.252.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.253.1">zoom_range</span></strong><span class="koboSpan" id="kobo.254.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.255.1">horizontal_flip</span></strong><span class="koboSpan" id="kobo.256.1"> arguments are used to specify the types of data augmentation to be applied to the </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">training data.</span></span></p>
<p><span class="koboSpan" id="kobo.258.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.259.1">flow()</span></strong><span class="koboSpan" id="kobo.260.1"> function</span><a id="_idIndexMarker423"/><span class="koboSpan" id="kobo.261.1"> is used to </span><a id="_idIndexMarker424"/><span class="koboSpan" id="kobo.262.1">generate new batches of training data from the original training data and the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.263.1">ImageDataGenerator</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.264.1"> object.</span></span></p>
<h2 id="_idParaDest-133"><a id="_idTextAnchor138"/><span class="koboSpan" id="kobo.265.1">Training the SVM on augmented data</span></h2>
<p><span class="koboSpan" id="kobo.266.1">To train SVM on </span><a id="_idIndexMarker425"/><span class="koboSpan" id="kobo.267.1">augmented data, we</span><a id="_idIndexMarker426"/><span class="koboSpan" id="kobo.268.1"> will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.269.1">partial_fit()</span></strong><span class="koboSpan" id="kobo.270.1"> function of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.271.1">SVC</span></strong><span class="koboSpan" id="kobo.272.1"> class to train the classifier on each batch of training data generated by the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.273.1">ImageDataGenerator</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.274.1"> object:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.275.1">
# Train the classifier on each batch of training data
for i in range(100):
    x_batch, y_batch = gen_train.next()
    clf.partial_fit(x_batch, y_batch, classes=np.unique(y_train))</span></pre> <p><span class="koboSpan" id="kobo.276.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.277.1">classes</span></strong><span class="koboSpan" id="kobo.278.1"> argument is used to specify the unique classes in the </span><span class="No-Break"><span class="koboSpan" id="kobo.279.1">training data.</span></span></p>
<h2 id="_idParaDest-134"><a id="_idTextAnchor139"/><span class="koboSpan" id="kobo.280.1">Evaluating the SVM’s performance on the augmented dataset</span></h2>
<p><span class="koboSpan" id="kobo.281.1">To evaluate the </span><a id="_idIndexMarker427"/><span class="koboSpan" id="kobo.282.1">performance</span><a id="_idIndexMarker428"/><span class="koboSpan" id="kobo.283.1"> of the SVM on the augmented dataset, we will again use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.284.1">predict()</span></strong><span class="koboSpan" id="kobo.285.1"> function to predict the class labels of the test data and then use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.286.1">accuracy_score()</span></strong><span class="koboSpan" id="kobo.287.1"> function to calculate the accuracy of the classifier by comparing the predicted class labels to the actual </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">class labels:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.289.1">
# Predict the class labels of the test data
y_pred_aug = clf.predict(x_test)
# Calculate the accuracy of the classifier
accuracy_aug = accuracy_score(y_test, y_pred_aug)
print("Accuracy with Data Augmentation: %.2f%%" % (accuracy_aug * 100.0))</span></pre> <p><span class="koboSpan" id="kobo.290.1">The accuracy of the SVM model on the augmented test dataset is around </span><strong class="source-inline"><span class="koboSpan" id="kobo.291.1">54.75%</span></strong><span class="koboSpan" id="kobo.292.1">, which is better than the previous accuracy. </span><span class="koboSpan" id="kobo.292.2">This indicates that the SVM model is able to learn more important features and patterns in the augmented dataset, and is able to generalize better to </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">new data.</span></span></p>
<p><span class="koboSpan" id="kobo.294.1">To summarize, in this section, we have discussed the importance of data augmentation in training SVMs for image classification. </span><span class="koboSpan" id="kobo.294.2">We have used the CIFAR-10 dataset to illustrate the impact of data augmentation on the performance of the SVM model. </span><span class="koboSpan" id="kobo.294.3">We have also provided Python code examples for loading the CIFAR-10 dataset, training an SVM model on the original dataset, and training an SVM model on the </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">augmented dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.296.1">The results show that data augmentation can improve the performance of SVM models on image classification tasks. </span><span class="koboSpan" id="kobo.296.2">By applying random rotations, translations, and scaling, we can generate new images that the SVM model can use to learn more features and patterns. </span><span class="koboSpan" id="kobo.296.3">This enables the SVM model to generalize better to new data and achieve </span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">better accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.298.1">In the next section, we will see how to implement the SVM with data augmentation using the MNIST handwritten </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">digits dataset.</span></span></p>
<h1 id="_idParaDest-135"><a id="_idTextAnchor140"/><span class="koboSpan" id="kobo.300.1">Image classification using the SVM with data augmentation on the MNIST dataset</span></h1>
<p><span class="koboSpan" id="kobo.301.1">Let us see</span><a id="_idIndexMarker429"/><span class="koboSpan" id="kobo.302.1"> how we can apply data augmentation for image classification using an SVM with the MNIST dataset. </span><span class="koboSpan" id="kobo.302.2">All the steps are similar to the previous example with the CIFAR-10 dataset, except the </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">dataset itself:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.304.1">
import tensorflow as tf
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from keras.datasets import mnist
from keras.preprocessing.image import ImageDataGenerator
# load MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()
# normalize pixel values between 0 and 1
x_train = x_train / 255.0
x_test = x_test / 255.0
# convert labels to one-hot encoded vectors
y_train = tf.keras.utils.to_categorical(y_train)
y_test = tf.keras.utils.to_categorical(y_test)
# create image data generator for data augmentation
datagen = ImageDataGenerator(rotation_range=20, \
    width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2)
# fit image data generator on training dataset
datagen.fit(x_train.reshape(-1, 28, 28, 1))
# create SVM model
svm_model = SVC()
# define hyperparameters for grid search
param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', \
    'poly', 'rbf'], 'degree': [2, 3, 4]}
# perform grid search for optimal hyperparameters
svm_grid_search = GridSearchCV(svm_model, param_grid, cv=3)
svm_grid_search.fit(datagen.flow(
    x_train.reshape(-1, 28, 28, 1),y_train, batch_size=32), \
    steps_per_epoch=len(x_train) / 32)
# evaluate SVM model on test dataset
accuracy = svm_grid_search.score(x_test.reshape(-1, 28*28), y_test)
print("Accuracy with data augmentation: {:.2f}%".format(accuracy*100))</span></pre> <p><span class="koboSpan" id="kobo.305.1">As stated, this</span><a id="_idIndexMarker430"/><span class="koboSpan" id="kobo.306.1"> code is similar to the previous example, except that we are now using the MNIST dataset and the images are grayscale and of size 28x28. </span><span class="koboSpan" id="kobo.306.2">We have also modified the input shape of the SVM model and the image data generator to accommodate the new image size and </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">color channel.</span></span></p>
<p><span class="koboSpan" id="kobo.308.1">The results show that data augmentation can also improve the performance of SVM models on the MNIST dataset. </span><span class="koboSpan" id="kobo.308.2">By applying random rotations, translations, and scaling, we can generate new images that the SVM model can use to learn more features and patterns. </span><span class="koboSpan" id="kobo.308.3">This enables the SVM model to generalize better to new data and achieve </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">better accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.310.1">In addition, we have used grid search to find the optimal hyperparameters for the SVM model. </span><span class="koboSpan" id="kobo.310.2">This is important because the performance of SVM models is highly dependent on the choice of hyperparameters. </span><span class="koboSpan" id="kobo.310.3">By tuning the hyperparameters using grid search, we can improve the accuracy of the SVM model </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1">even further.</span></span></p>
<p><span class="koboSpan" id="kobo.312.1">Overall, this example code demonstrates the effectiveness of data augmentation in improving the performance of SVM models on image classification tasks. </span><span class="koboSpan" id="kobo.312.2">It also highlights the importance of hyperparameter tuning using grid search to achieve the best </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">possible accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.314.1">To summarize, data augmentation is a powerful technique for improving the performance of machine learning models on image classification tasks. </span><span class="koboSpan" id="kobo.314.2">By generating new images that the model can use to learn more features and patterns, we can improve the generalization ability of the model and achieve better accuracy. </span><span class="koboSpan" id="kobo.314.3">SVM models are particularly well suited for image classification tasks and can benefit greatly from data augmentation. </span><span class="koboSpan" id="kobo.314.4">With the help of Python libraries such as scikit-learn and TensorFlow, we can easily implement SVM models with data augmentation and achieve state-of-the-art performance on image </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">classification tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.316.1">Next, let us see how to implement convolutional neural networks with augmented </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">training data.</span></span></p>
<h1 id="_idParaDest-136"><a id="_idTextAnchor141"/><span class="koboSpan" id="kobo.318.1">Convolutional neural networks using augmented image data</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.319.1">Convolutional Neural Networks</span></strong><span class="koboSpan" id="kobo.320.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.321.1">CNNs</span></strong><span class="koboSpan" id="kobo.322.1">) have </span><a id="_idIndexMarker431"/><span class="koboSpan" id="kobo.323.1">revolutionized the field of computer vision by demonstrating exceptional performance in various image-related tasks such as object detection, image classification, and segmentation. </span><span class="koboSpan" id="kobo.323.2">However, the availability of large, annotated datasets for training CNNs is often a challenge. </span><span class="koboSpan" id="kobo.323.3">Fortunately, one effective approach to overcome</span><a id="_idIndexMarker432"/><span class="koboSpan" id="kobo.324.1"> this limitation is through the use of </span><strong class="bold"><span class="koboSpan" id="kobo.325.1">image data </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.326.1">augmentation</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.327.1"> techniques.</span></span></p>
<p><span class="koboSpan" id="kobo.328.1">Let’s start from scratch and explain what CNNs are and how they work. </span><span class="koboSpan" id="kobo.328.2">Imagine you have a picture, say a photo of a cat, and you want to teach a computer how to recognize that it’s a cat. </span><span class="koboSpan" id="kobo.328.3">CNNs are like a special type of computer program that helps computers understand and recognize things in images, just like how you recognize objects </span><span class="No-Break"><span class="koboSpan" id="kobo.329.1">in photos.</span></span></p>
<p><span class="koboSpan" id="kobo.330.1">An image is made up of tiny dots called pixels. </span><span class="koboSpan" id="kobo.330.2">Each pixel has a color, and when you put them all together, you get an image. </span><span class="koboSpan" id="kobo.330.3">The more pixels you have, the more detailed the image is. </span><span class="koboSpan" id="kobo.330.4">When you look at a picture, your brain doesn’t try to understand it all at once. </span><span class="koboSpan" id="kobo.330.5">Instead, it focuses on small parts, like the shape of an ear or the color of an eye. </span><span class="koboSpan" id="kobo.330.6">This is how we recognize things. </span><span class="koboSpan" id="kobo.330.7">We break the big picture into small pieces and understand them one </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">by one.</span></span></p>
<p><span class="koboSpan" id="kobo.332.1">CNNs work a</span><a id="_idIndexMarker433"/><span class="koboSpan" id="kobo.333.1"> bit like the human brain, breaking images down into small parts. </span><span class="koboSpan" id="kobo.333.2">These small parts are called “features” or “filters.” </span><span class="koboSpan" id="kobo.333.3">Imagine these filters as tiny windows that move across the picture. </span><span class="koboSpan" id="kobo.333.4">These windows look at a small part of the image at a time and learn what’s important </span><span class="No-Break"><span class="koboSpan" id="kobo.334.1">in it.</span></span></p>
<h2 id="_idParaDest-137"><a id="_idTextAnchor142"/><span class="koboSpan" id="kobo.335.1">How CNNs work</span></h2>
<p><span class="koboSpan" id="kobo.336.1">Let us understand how </span><a id="_idIndexMarker434"/><span class="koboSpan" id="kobo.337.1">CNNs work for the </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">desired output:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.339.1">Convolution</span></strong><span class="koboSpan" id="kobo.340.1">: This is the </span><a id="_idIndexMarker435"/><span class="koboSpan" id="kobo.341.1">first step. </span><span class="koboSpan" id="kobo.341.2">It’s like moving the small window (filter) over the picture. </span><span class="koboSpan" id="kobo.341.3">The filter checks the colors and shapes in the area it’s looking at and learns </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">what’s important.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.343.1">Pooling</span></strong><span class="koboSpan" id="kobo.344.1">: After the different parts of the image have been looked at, the CNN doesn’t need all the details. </span><span class="koboSpan" id="kobo.344.2">Pooling</span><a id="_idIndexMarker436"/><span class="koboSpan" id="kobo.345.1"> is like taking a summary of what it’s seen. </span><span class="koboSpan" id="kobo.345.2">It simplifies things, but we don’t lose the </span><span class="No-Break"><span class="koboSpan" id="kobo.346.1">important parts.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.347.1">Fully connected layers</span></strong><span class="koboSpan" id="kobo.348.1">: After</span><a id="_idIndexMarker437"/><span class="koboSpan" id="kobo.349.1"> looking at the many small parts and summarizing them, everything is connected together next. </span><span class="koboSpan" id="kobo.349.2">It’s like putting the pieces of a puzzle together to see the whole picture. </span><span class="koboSpan" id="kobo.349.3">This helps the CNN understand the entire image and make a final decision on what is depicted </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">in it.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.351.1">After the convolutional layers have processed the image by extracting various features and patterns, the fully connected layers play a crucial role in bringing all the information together to make a comprehensive decision about the content of the image. </span><span class="koboSpan" id="kobo.351.2">This process is akin to assembling the pieces of a puzzle, where each piece corresponds to a specific feature detected by the convolutional layers. </span><span class="koboSpan" id="kobo.351.3">By connecting these pieces, the network gains a holistic understanding of </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">the image.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.353.1">However, as powerful as fully connected layers are, there is a risk of overfitting, a situation where the model becomes too specialized in the training data and performs poorly on new, unseen data. </span><span class="koboSpan" id="kobo.353.2">To mitigate this, regularization techniques</span><a id="_idIndexMarker438"/><span class="koboSpan" id="kobo.354.1"> are </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">often employed.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.356.1">Regularization in fully connected layers</span></strong><span class="koboSpan" id="kobo.357.1">: Regularization</span><a id="_idIndexMarker439"/><span class="koboSpan" id="kobo.358.1"> is a set of techniques used to prevent overfitting and enhance the generalization capabilities of a model. </span><span class="koboSpan" id="kobo.358.2">In the context of fully connected layers, regularization methods are applied to control the complexity of the model and avoid relying too heavily on specific features present in the </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">training data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.360.1">Training a CNN</span></strong><span class="koboSpan" id="kobo.361.1">: To teach a CNN to recognize cats, you’d show it lots of cat pictures. </span><span class="koboSpan" id="kobo.361.2">It looks at them, learns the important features, and gets better over time at recognizing them. </span><span class="koboSpan" id="kobo.361.3">It also needs to see pictures of things that are not cats, so it can tell </span><span class="No-Break"><span class="koboSpan" id="kobo.362.1">the difference.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.363.1">Making predictions</span></strong><span class="koboSpan" id="kobo.364.1">: Once a CNN is trained, you can show it a new picture, and it will try to find the important features just like it learned. </span><span class="koboSpan" id="kobo.364.2">If it finds enough cat-like</span><a id="_idIndexMarker440"/><span class="koboSpan" id="kobo.365.1"> features, it will say, “Hey, that’s </span><span class="No-Break"><span class="koboSpan" id="kobo.366.1">a cat!”</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.367.1">So, in simple terms, a CNN is like a computer program that learns to recognize things in pictures by looking at small parts of the image, finding important features, and making decisions based on </span><span class="No-Break"><span class="koboSpan" id="kobo.368.1">those features.</span></span></p>
<p><span class="koboSpan" id="kobo.369.1">As we’ve seen, a CNN’s architecture constitutes convolution, pooling, and fully connected layers. </span><span class="koboSpan" id="kobo.369.2">The architecture specifies how the model is structured, including the number of layers, the size of filters, and the connections between neurons. </span><span class="koboSpan" id="kobo.369.3">The architecture guides how the learned weights and features are used to process images and </span><span class="No-Break"><span class="koboSpan" id="kobo.370.1">make</span></span><span class="No-Break"><a id="_idIndexMarker441"/></span><span class="No-Break"><span class="koboSpan" id="kobo.371.1"> predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.372.1">So, the final model is, in essence, a combination of the architecture, the learned weights, and the learned features. </span><span class="koboSpan" id="kobo.372.2">Let’s break down a couple of </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">these elements:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.374.1">Learned weights</span></strong><span class="koboSpan" id="kobo.375.1">: These </span><a id="_idIndexMarker442"/><span class="koboSpan" id="kobo.376.1">are the parameters that the CNN has learned during the training process. </span><span class="koboSpan" id="kobo.376.2">The model adjusts these weights to make accurate predictions. </span><span class="koboSpan" id="kobo.376.3">These weights are essentially the “knowledge” the model gains during training. </span><span class="koboSpan" id="kobo.376.4">They represent how important certain features are for </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">making decisions.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.378.1">Learned features</span></strong><span class="koboSpan" id="kobo.379.1">: Features, in </span><a id="_idIndexMarker443"/><span class="koboSpan" id="kobo.380.1">the context of a CNN, are visual patterns and characteristics of images. </span><span class="koboSpan" id="kobo.380.2">They are representations of important information within the image. </span><span class="koboSpan" id="kobo.380.3">These features are not directly visible to us but are learned by the network through the layers of convolution and pooling. </span><span class="koboSpan" id="kobo.380.4">Features are abstract representations of the image that help the model recognize patterns </span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">and objects.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.382.1">In practice, these learned weights and features are stored in the model’s parameters. </span><span class="koboSpan" id="kobo.382.2">When you save a trained CNN model, you are saving these parameters, which can be used to make predictions on new, unseen images. </span><span class="koboSpan" id="kobo.382.3">The model takes an image as input, processes it through its layers, and uses the learned weights and features to make predictions, such as classifying objects in the image or detecting </span><span class="No-Break"><span class="koboSpan" id="kobo.383.1">specific patterns.</span></span></p>
<p><span class="koboSpan" id="kobo.384.1">We will now delve into the powerful combination of CNNs and image data augmentation. </span><span class="koboSpan" id="kobo.384.2">By artificially augmenting the data, CNNs can be exposed to a broader range of variations during training to help them generalize better to </span><span class="No-Break"><span class="koboSpan" id="kobo.385.1">unseen images.</span></span></p>
<p><span class="koboSpan" id="kobo.386.1">Some of the benefits and considerations of using image data augmentation are reducing overfitting, enhancing model robustness, and improving generalization performance. </span><span class="koboSpan" id="kobo.386.2">Whether you are a beginner or an experienced practitioner, this section serves as a comprehensive guide to understanding and implementing image data augmentation in the context of CNNs, assisting you in taking your computer vision projects to </span><span class="No-Break"><span class="koboSpan" id="kobo.387.1">new heights.</span></span></p>
<h2 id="_idParaDest-138"><a id="_idTextAnchor143"/><span class="koboSpan" id="kobo.388.1">Practical example of a CNN using data augmentation</span></h2>
<p><span class="koboSpan" id="kobo.389.1">Let us see how to</span><a id="_idIndexMarker444"/><span class="koboSpan" id="kobo.390.1"> implement image data augmentation on a CNN. </span><span class="koboSpan" id="kobo.390.2">To do so, you can follow </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1">these steps:</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.392.1">Step 1</span></strong><span class="koboSpan" id="kobo.393.1">: Start by importing the necessary libraries, including Keras </span><span class="No-Break"><span class="koboSpan" id="kobo.394.1">and NumPy:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.395.1">
import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.preprocessing.image import ImageDataGenerator
import numpy as np</span></pre> <p><strong class="bold"><span class="koboSpan" id="kobo.396.1">Step 2</span></strong><span class="koboSpan" id="kobo.397.1">: Create</span><a id="_idIndexMarker445"/><span class="koboSpan" id="kobo.398.1"> an </span><strong class="source-inline"><span class="koboSpan" id="kobo.399.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.400.1"> object and specify the desired data </span><span class="No-Break"><span class="koboSpan" id="kobo.401.1">augmentation techniques:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.402.1">
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)</span></pre> <p><span class="koboSpan" id="kobo.403.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.404.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.405.1"> object will generate batches of augmented data using the specified data augmentation techniques. </span><span class="koboSpan" id="kobo.405.2">In this example, we are using rotation, width and height shifts, and </span><span class="No-Break"><span class="koboSpan" id="kobo.406.1">horizontal flipping.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.407.1">Step 3</span></strong><span class="koboSpan" id="kobo.408.1">: Load the original dataset and split it into training and </span><span class="No-Break"><span class="koboSpan" id="kobo.409.1">validation sets:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.410.1">
train_generator = datagen.flow_from_directory(
    '/path/to/dataset',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)
val_generator = datagen.flow_from_directory(
    '/path/to/dataset',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)</span></pre> <p><span class="koboSpan" id="kobo.411.1">Here, we </span><a id="_idIndexMarker446"/><span class="koboSpan" id="kobo.412.1">are using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.413.1">flow_from_directory()</span></strong><span class="koboSpan" id="kobo.414.1"> function to load the original dataset from the specified directory. </span><span class="koboSpan" id="kobo.414.2">We also specify the target size of the images, the batch size, and the class mode (categorical in this case). </span><span class="koboSpan" id="kobo.414.3">We split the data into training and validation sets using the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.415.1">subset</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.416.1"> parameter.</span></span></p>
<p><span class="koboSpan" id="kobo.417.1">In the provided code snippet, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.418.1">flow_from_directory</span></strong><span class="koboSpan" id="kobo.419.1"> function is used to generate a data generator to load images from a directory. </span><span class="koboSpan" id="kobo.419.2">Let’s break down </span><span class="No-Break"><span class="koboSpan" id="kobo.420.1">the parameters:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.421.1">'/path/to/dataset'</span></strong><span class="koboSpan" id="kobo.422.1">: This is the path to the directory containing the dataset. </span><span class="koboSpan" id="kobo.422.2">The function will look for subdirectories inside this directory, where each subdirectory represents a different class </span><span class="No-Break"><span class="koboSpan" id="kobo.423.1">or category.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.424.1">target_size=(224, 224)</span></strong><span class="koboSpan" id="kobo.425.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.426.1">target_size</span></strong><span class="koboSpan" id="kobo.427.1"> is the size to which all images will be resized during loading. </span><span class="koboSpan" id="kobo.427.2">In this case, each image will be resized as a square with dimensions of 224x224 pixels. </span><span class="koboSpan" id="kobo.427.3">Standardizing the image size is important for consistency and compatibility with neural network models, especially when using pre-trained models that expect a specific </span><span class="No-Break"><span class="koboSpan" id="kobo.428.1">input size.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.429.1">batch_size=32</span></strong><span class="koboSpan" id="kobo.430.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.431.1">batch_size</span></strong><span class="koboSpan" id="kobo.432.1"> determines the number of images loaded and processed in each iteration during training or validation. </span><span class="koboSpan" id="kobo.432.2">A larger batch size can lead to faster training but may require more memory. </span><span class="koboSpan" id="kobo.432.3">Smaller batch sizes are often used when memory is limited or for fine-tuning models. </span><span class="koboSpan" id="kobo.432.4">It also affects the gradient update during training, impacting the stability and convergence of the </span><span class="No-Break"><span class="koboSpan" id="kobo.433.1">training process.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.434.1">class_mode='categorical'</span></strong><span class="koboSpan" id="kobo.435.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.436.1">class_mode</span></strong><span class="koboSpan" id="kobo.437.1"> specifies how the target classes are represented. </span><span class="koboSpan" id="kobo.437.2">In this case, it is set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.438.1">categorical</span></strong><span class="koboSpan" id="kobo.439.1">, indicating that the labels are one-hot encoded (a binary matrix representation of class membership). </span><span class="koboSpan" id="kobo.439.2">Other possible values include </span><strong class="source-inline"><span class="koboSpan" id="kobo.440.1">binary</span></strong><span class="koboSpan" id="kobo.441.1"> for binary classification, </span><strong class="source-inline"><span class="koboSpan" id="kobo.442.1">sparse</span></strong><span class="koboSpan" id="kobo.443.1"> for integer-encoded class labels, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.444.1">None</span></strong><span class="koboSpan" id="kobo.445.1"> for no labels (used for </span><span class="No-Break"><span class="koboSpan" id="kobo.446.1">test datasets).</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.447.1">subset='validation'</span></strong><span class="koboSpan" id="kobo.448.1">: Subset is used to specify whether the generator is for the training set or the validation set. </span><span class="koboSpan" id="kobo.448.2">In this case, it is set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.449.1">validation</span></strong><span class="koboSpan" id="kobo.450.1">, indicating that the generator is for the validation set. </span><span class="koboSpan" id="kobo.450.2">When using subset, make sure the dataset directory contains subdirectories like </span><strong class="source-inline"><span class="koboSpan" id="kobo.451.1">train</span></strong><span class="koboSpan" id="kobo.452.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.453.1">validation</span></strong><span class="koboSpan" id="kobo.454.1"> to facilitate </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">the split.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.456.1">In summary, these </span><a id="_idIndexMarker447"/><span class="koboSpan" id="kobo.457.1">parameters help configure the data generator to load and preprocess images from a directory. </span><span class="koboSpan" id="kobo.457.2">The choices made for target size, batch size, and class mode are often determined by the requirements of the machine learning model being used, the available computing resources, and the characteristics of </span><span class="No-Break"><span class="koboSpan" id="kobo.458.1">the dataset.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.459.1">Step 4</span></strong><span class="koboSpan" id="kobo.460.1">: Create a </span><span class="No-Break"><span class="koboSpan" id="kobo.461.1">CNN model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.462.1">
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(256, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))
model.compile(loss='categorical_crossentropy', \
    optimizer='adam', metrics=['accuracy'])</span></pre> <p><span class="koboSpan" id="kobo.463.1">Here, we are </span><a id="_idIndexMarker448"/><span class="koboSpan" id="kobo.464.1">creating a simple CNN model with four convolutional layers and one fully connected layer. </span><span class="koboSpan" id="kobo.464.2">We are using ReLU activation for the convolutional layers and softmax activation for the output layer. </span><span class="koboSpan" id="kobo.464.3">We also compile the model with the categorical cross-entropy loss function, the Adam optimizer, and the </span><span class="No-Break"><span class="koboSpan" id="kobo.465.1">accuracy metric.</span></span></p>
<p><span class="koboSpan" id="kobo.466.1">In the preceding code snippet, a CNN model is being created using the Keras library. </span><span class="koboSpan" id="kobo.466.2">Let’s break down </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">the components:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.468.1">Rectified Linear Unit (ReLU) Activation</span></strong><span class="koboSpan" id="kobo.469.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.470.1">activation='relu'</span></strong><span class="koboSpan" id="kobo.471.1"> is used for the convolutional and dense </span><a id="_idIndexMarker449"/><span class="koboSpan" id="kobo.472.1">layers. </span><span class="koboSpan" id="kobo.472.2">ReLU is an activation function that introduces non-linearity to the model. </span><span class="koboSpan" id="kobo.472.3">It outputs the input directly if it is positive; otherwise, it outputs zero. </span><span class="koboSpan" id="kobo.472.4">ReLU is preferred for CNNs because it helps the model learn complex patterns and relationships in data. </span><span class="koboSpan" id="kobo.472.5">It is computationally efficient and mitigates the vanishing </span><span class="No-Break"><span class="koboSpan" id="kobo.473.1">gradient problem.</span></span><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.474.1">The effect of ReLU</span></strong><span class="koboSpan" id="kobo.475.1">: ReLU</span><a id="_idIndexMarker450"/><span class="koboSpan" id="kobo.476.1"> introduces non-linearity, enabling the model to learn complex features and relationships in the data. </span><span class="koboSpan" id="kobo.476.2">It helps address the vanishing gradient problem, promoting more efficient training by allowing the model to propagate gradients </span><span class="No-Break"><span class="koboSpan" id="kobo.477.1">during backpropagation.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.478.1">Softmax activation</span></strong><span class="koboSpan" id="kobo.479.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.480.1">activation='softmax'</span></strong><span class="koboSpan" id="kobo.481.1"> is used for the output layer. </span><span class="koboSpan" id="kobo.481.2">Softmax</span><a id="_idIndexMarker451"/><span class="koboSpan" id="kobo.482.1"> is a function that converts raw scores (logits) into probabilities. </span><span class="koboSpan" id="kobo.482.2">It is often used in the output layer of a multi-class classification model. </span><span class="koboSpan" id="kobo.482.3">In this binary classification case (two classes), the softmax activation function normalizes the output scores for each class, assigning a probability to each class. </span><span class="koboSpan" id="kobo.482.4">The class with the highest probability is considered the model’s prediction. </span><span class="koboSpan" id="kobo.482.5">Softmax is useful for producing probability distributions over multiple classes, making it suitable for </span><span class="No-Break"><span class="koboSpan" id="kobo.483.1">classification problems.</span></span><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.484.1">The effect of Softmax</span></strong><span class="koboSpan" id="kobo.485.1">: Softmax converts raw model outputs into probability distributions over classes. </span><span class="koboSpan" id="kobo.485.2">It ensures that the predicted probabilities sum to 1, facilitating a meaningful interpretation of the model’s confidence in each class. </span><span class="koboSpan" id="kobo.485.3">In binary classification, it is often used in conjunction with categorical </span><span class="No-Break"><span class="koboSpan" id="kobo.486.1">cross-entropy loss.</span></span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.487.1">Why should we use them? </span><span class="koboSpan" id="kobo.487.2">ReLU is</span><a id="_idIndexMarker452"/><span class="koboSpan" id="kobo.488.1"> chosen for its simplicity, computational efficiency, and effectiveness in training deep neural networks. </span><span class="koboSpan" id="kobo.488.2">Softmax is selected for the output layer to obtain class probabilities, which are valuable for interpreting and evaluating the </span><span class="No-Break"><span class="koboSpan" id="kobo.489.1">model’s predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.490.1">In summary, ReLU </span><a id="_idIndexMarker453"/><span class="koboSpan" id="kobo.491.1">and softmax activations contribute to the effectiveness of the CNN model by introducing non-linearity, promoting efficient training, and producing meaningful probability distributions for classification. </span><span class="koboSpan" id="kobo.491.2">They are widely used in CNNs for image </span><span class="No-Break"><span class="koboSpan" id="kobo.492.1">classification tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.493.1">In the provided code snippet, the model is compiled with three important components – categorical cross-entropy loss, the Adam optimizer, and the accuracy metric. </span><span class="koboSpan" id="kobo.493.2">Let’s delve into each </span><span class="No-Break"><span class="koboSpan" id="kobo.494.1">of them:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.495.1">Categorical cross-entropy </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.496.1">loss</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.497.1"> (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.498.1">loss='categorical_crossentropy'</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.499.1">):</span></span><ul><li><span class="koboSpan" id="kobo.500.1">Categorical cross-entropy </span><a id="_idIndexMarker454"/><span class="koboSpan" id="kobo.501.1">is a loss function commonly used for multi-class </span><span class="No-Break"><span class="koboSpan" id="kobo.502.1">classification problems.</span></span></li><li><span class="koboSpan" id="kobo.503.1">In this context, the model is designed for binary classification (two classes), but it uses categorical cross-entropy to handle a case where there are more than two classes. </span><span class="koboSpan" id="kobo.503.2">The target labels are expected to </span><span class="No-Break"><span class="koboSpan" id="kobo.504.1">be one-hot-encoded.</span></span></li><li><span class="koboSpan" id="kobo.505.1">The loss function measures the dissimilarity between the predicted probabilities (obtained from the softmax activation in the output layer) and the true </span><span class="No-Break"><span class="koboSpan" id="kobo.506.1">class labels.</span></span></li><li><span class="koboSpan" id="kobo.507.1">The goal during training is to minimize this loss, effectively improving the model’s ability to make accurate </span><span class="No-Break"><span class="koboSpan" id="kobo.508.1">class predictions.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.509.1">Adam </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.510.1">optimizer</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.511.1"> (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.512.1">optimizer='adam'</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.513.1">):</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.514.1">Adaptive Moment Estimation</span></strong><span class="koboSpan" id="kobo.515.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.516.1">Adam</span></strong><span class="koboSpan" id="kobo.517.1">) is an optimization algorithm widely used to </span><a id="_idIndexMarker455"/><span class="koboSpan" id="kobo.518.1">train </span><span class="No-Break"><span class="koboSpan" id="kobo.519.1">neural networks.</span></span></li><li><span class="koboSpan" id="kobo.520.1">It combines ideas from two other optimization algorithms – </span><strong class="bold"><span class="koboSpan" id="kobo.521.1">Root Mean Square Propagation</span></strong><span class="koboSpan" id="kobo.522.1"> (RMSprop) </span><span class="No-Break"><span class="koboSpan" id="kobo.523.1">and Momentum.</span></span></li><li><span class="koboSpan" id="kobo.524.1">Adam adapts the learning rates of each parameter individually, making it well-suited for a variety of </span><span class="No-Break"><span class="koboSpan" id="kobo.525.1">optimization problems.</span></span></li><li><span class="koboSpan" id="kobo.526.1">It is known for its efficiency and effectiveness in training deep neural networks</span><a id="_idIndexMarker456"/><span class="koboSpan" id="kobo.527.1"> and is often a default choice for </span><span class="No-Break"><span class="koboSpan" id="kobo.528.1">many applications.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.529.1">Accuracy </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.530.1">metric</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.531.1"> (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.532.1">metrics=['accuracy']</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.533.1">):</span></span><ul><li><span class="koboSpan" id="kobo.534.1">Accuracy is a metric </span><a id="_idIndexMarker457"/><span class="koboSpan" id="kobo.535.1">used to evaluate the performance of a </span><span class="No-Break"><span class="koboSpan" id="kobo.536.1">classification model.</span></span></li><li><span class="koboSpan" id="kobo.537.1">In the context of binary classification, accuracy measures the proportion of correctly classified instances (both true positives and true negatives) among </span><span class="No-Break"><span class="koboSpan" id="kobo.538.1">all instances.</span></span></li><li><span class="koboSpan" id="kobo.539.1">The accuracy metric is essential for assessing how well the model performs on the training and </span><span class="No-Break"><span class="koboSpan" id="kobo.540.1">validation datasets.</span></span></li><li><span class="koboSpan" id="kobo.541.1">While accuracy is a commonly used metric, it might not be sufficient for imbalanced datasets, where one class is much more prevalent than the other. </span><span class="koboSpan" id="kobo.541.2">In such </span><a id="_idIndexMarker458"/><span class="koboSpan" id="kobo.542.1">cases, additional metrics such as precision, recall, or F1 score may </span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">be considered.</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.544.1">In summary, the </span><a id="_idIndexMarker459"/><span class="koboSpan" id="kobo.545.1">choice of categorical cross-entropy loss, the Adam optimizer, and the accuracy metric during compilation reflects the best practices for training a binary classification model. </span><span class="koboSpan" id="kobo.545.2">These choices are based on their effectiveness in optimizing the model parameters, handling multi-class scenarios, and providing a straightforward evaluation of </span><span class="No-Break"><span class="koboSpan" id="kobo.546.1">classification accuracy.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.547.1">Step 5</span></strong><span class="koboSpan" id="kobo.548.1">: Train the model using the </span><span class="No-Break"><span class="koboSpan" id="kobo.549.1">augmented dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.550.1">
model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // 32,
    validation_data=val_generator,
    validation_steps=val_generator.samples // 32,
    epochs=10
)</span></pre> <p><span class="koboSpan" id="kobo.551.1">We use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.552.1">fit()</span></strong><span class="koboSpan" id="kobo.553.1"> function to train the model on the augmented dataset. </span><span class="koboSpan" id="kobo.553.2">We specify the training and validation generators, the number of steps per epoch, the validation steps, and the number </span><span class="No-Break"><span class="koboSpan" id="kobo.554.1">of epochs.</span></span></p>
<p><span class="koboSpan" id="kobo.555.1">In this code snippet, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.556.1">fit()</span></strong><span class="koboSpan" id="kobo.557.1"> function is used to train the model on an augmented dataset. </span><span class="koboSpan" id="kobo.557.2">Let’s break down the </span><span class="No-Break"><span class="koboSpan" id="kobo.558.1">key components:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.559.1">Training generator</span></strong><span class="koboSpan" id="kobo.560.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.561.1">train_generator</span></strong><span class="koboSpan" id="kobo.562.1">):The training generator is an instance of a data </span><a id="_idIndexMarker460"/><span class="koboSpan" id="kobo.563.1">generator that generates batches of training data with augmentation on the fly in </span><em class="italic"><span class="koboSpan" id="kobo.564.1">Step 3</span></em><span class="koboSpan" id="kobo.565.1">. </span><span class="koboSpan" id="kobo.565.2">A data generator is a way to efficiently load and preprocess data in chunks during training rather than loading the entire dataset into memory. </span><strong class="source-inline"><span class="koboSpan" id="kobo.566.1">train_generator</span></strong><span class="koboSpan" id="kobo.567.1"> is responsible for providing the model with batches of augmented </span><span class="No-Break"><span class="koboSpan" id="kobo.568.1">training data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.569.1">Validation generator</span></strong><span class="koboSpan" id="kobo.570.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.571.1">val_generator</span></strong><span class="koboSpan" id="kobo.572.1">): Similar to the training generator, the validation generator</span><a id="_idIndexMarker461"/><span class="koboSpan" id="kobo.573.1"> is an instance of a data generator that generates batches of validation data. </span><span class="koboSpan" id="kobo.573.2">The validation generator provides a separate set of data that the model has not seen during training. </span><span class="koboSpan" id="kobo.573.3">It helps assess the model’s generalization to unseen examples and </span><span class="No-Break"><span class="koboSpan" id="kobo.574.1">prevents overfitting.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.575.1">Number of steps per epoch</span></strong><span class="koboSpan" id="kobo.576.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.577.1">steps_per_epoch=train_generator.samples // 32</span></strong><span class="koboSpan" id="kobo.578.1">): </span><strong class="source-inline"><span class="koboSpan" id="kobo.579.1">steps_per_epoch</span></strong><span class="koboSpan" id="kobo.580.1"> specifies the number of batches of data to process in each epoch of training. </span><span class="koboSpan" id="kobo.580.2">It is calculated as the total number of samples in the training dataset divided by the batch size (</span><strong class="source-inline"><span class="koboSpan" id="kobo.581.1">32</span></strong><span class="koboSpan" id="kobo.582.1"> in this case). </span><span class="koboSpan" id="kobo.582.2">Each step involves a forward </span><a id="_idIndexMarker462"/><span class="koboSpan" id="kobo.583.1">pass (prediction) and a backward pass (gradient computation and parameter updates) on a batch of data. </span><span class="koboSpan" id="kobo.583.2">A smaller </span><strong class="source-inline"><span class="koboSpan" id="kobo.584.1">steps_per_epoch</span></strong><span class="koboSpan" id="kobo.585.1"> value means that the model will see fewer batches in each epoch, potentially leading to faster training but with less exposure to the </span><span class="No-Break"><span class="koboSpan" id="kobo.586.1">entire dataset.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.587.1">Validation steps</span></strong><span class="koboSpan" id="kobo.588.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.589.1">validation_steps=val_generator.samples // 32</span></strong><span class="koboSpan" id="kobo.590.1">): </span><strong class="source-inline"><span class="koboSpan" id="kobo.591.1">validation_steps</span></strong><span class="koboSpan" id="kobo.592.1"> is similar to </span><strong class="source-inline"><span class="koboSpan" id="kobo.593.1">steps_per_epoch</span></strong><span class="koboSpan" id="kobo.594.1"> but for the validation dataset. </span><span class="koboSpan" id="kobo.594.2">It determines the number of batches processed during each validation epoch. </span><span class="koboSpan" id="kobo.594.3">Like </span><strong class="source-inline"><span class="koboSpan" id="kobo.595.1">steps_per_epoch</span></strong><span class="koboSpan" id="kobo.596.1">, it is calculated based on the total number of samples in the validation dataset divided by the </span><span class="No-Break"><span class="koboSpan" id="kobo.597.1">batch size.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.598.1">Number of epochs</span></strong><span class="koboSpan" id="kobo.599.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.600.1">epochs=10</span></strong><span class="koboSpan" id="kobo.601.1">): Epoch specifies the number of times the entire dataset is processed during training. </span><span class="koboSpan" id="kobo.601.2">Training for more epochs allows the model to learn from the data over multiple passes, potentially improving performance. </span><span class="koboSpan" id="kobo.601.3">However, training for too many epochs may lead to overfitting, where the </span><a id="_idIndexMarker463"/><span class="koboSpan" id="kobo.602.1">model memorizes the training data but fails to generalize to </span><span class="No-Break"><span class="koboSpan" id="kobo.603.1">new data.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.604.1">Adjusting the batch size, steps per epoch, and validation steps can impact the training speed and memory requirements. </span><span class="koboSpan" id="kobo.604.2">A larger batch size and more steps per epoch may lead to slower training but can be more memory-efficient. </span><span class="koboSpan" id="kobo.604.3">The number of epochs should be chosen carefully to balance model training and </span><span class="No-Break"><span class="koboSpan" id="kobo.605.1">prevent overfitting.</span></span></p>
<p><span class="koboSpan" id="kobo.606.1">In summary, the settings provided to </span><strong class="source-inline"><span class="koboSpan" id="kobo.607.1">fit()</span></strong><span class="koboSpan" id="kobo.608.1"> control how the model is trained, the data it sees in each epoch, and the evaluation of the validation set. </span><span class="koboSpan" id="kobo.608.2">Properly tuning these settings is crucial to achieving good model performance and preventing issues such </span><span class="No-Break"><span class="koboSpan" id="kobo.609.1">as overfitting.</span></span></p>
<p><span class="koboSpan" id="kobo.610.1">By following these steps, you can implement supervised CNNs using image data augmentation in Keras. </span><span class="koboSpan" id="kobo.610.2">This can help improve the performance of your model and make it more robust to variations in the </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1">input data.</span></span></p>
<h2 id="_idParaDest-139"><a id="_idTextAnchor144"/><span class="koboSpan" id="kobo.612.1">CNN using image data augmentation with the CIFAR-10 dataset</span></h2>
<p><span class="koboSpan" id="kobo.613.1">Let us see some example </span><a id="_idIndexMarker464"/><span class="koboSpan" id="kobo.614.1">Python code for a supervised CNN using image data augmentation with the </span><span class="No-Break"><span class="koboSpan" id="kobo.615.1">CIFAR-10 dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.616.1">
import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
# Load the CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
# Normalize the input data
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
# Convert the labels to one-hot encoding
y_train = tf.keras.utils.to_categorical(y_train)
y_test = tf.keras.utils.to_categorical(y_test)
# Define the CNN architecture</span></pre> <p><span class="koboSpan" id="kobo.617.1">The preceding code defines the architecture of a CNN using the Keras library. </span><span class="koboSpan" id="kobo.617.2">Let’s go through each line to understand the purpose and functionality of </span><span class="No-Break"><span class="koboSpan" id="kobo.618.1">each component.</span></span></p>
<p><span class="koboSpan" id="kobo.619.1">The following line creates a sequential model, which allows us to stack layers on top of each </span><span class="No-Break"><span class="koboSpan" id="kobo.620.1">other sequentially:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.621.1">
model = Sequential()</span></pre> <p><span class="koboSpan" id="kobo.622.1">The following code snippet adds </span><a id="_idIndexMarker465"/><span class="koboSpan" id="kobo.623.1">a 2D convolutional layer to the model. </span><span class="koboSpan" id="kobo.623.2">It has 32 filters, a filter size of </span><strong class="source-inline"><span class="koboSpan" id="kobo.624.1">(3, 3)</span></strong><span class="koboSpan" id="kobo.625.1">, the ReLU activation function, and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.626.1">'same'</span></strong><span class="koboSpan" id="kobo.627.1"> padding. </span><span class="koboSpan" id="kobo.627.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.628.1">input_shape</span></strong><span class="koboSpan" id="kobo.629.1"> parameter is set to the shape of the input data (</span><strong class="source-inline"><span class="koboSpan" id="kobo.630.1">x_train</span></strong><span class="koboSpan" id="kobo.631.1">) without the </span><span class="No-Break"><span class="koboSpan" id="kobo.632.1">batch dimension:</span></span></p>
<p><span class="koboSpan" id="kobo.633.1">Let’s break down the following CNN code snippet to understand it more </span><span class="No-Break"><span class="koboSpan" id="kobo.634.1">in depth:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.635.1">
model.add(Conv2D(32, (3, 3), activation='relu', \
    padding='same', input_shape=x_train.shape[1:]))</span></pre> <p><strong class="bold"><span class="koboSpan" id="kobo.636.1">2D convolutional layer addition</span></strong><span class="koboSpan" id="kobo.637.1">: In deep</span><a id="_idIndexMarker466"/><span class="koboSpan" id="kobo.638.1"> learning for image processing, convolutional layers are crucial to learning hierarchical features from input images. </span><span class="koboSpan" id="kobo.638.2">Convolutional layers are used to detect local patterns in the input data. </span><span class="koboSpan" id="kobo.638.3">Each filter in the convolutional layer learns to recognize different features or patterns. </span><span class="koboSpan" id="kobo.638.4">The code adds a layer to the neural network model, and specifically, it’s a</span><a id="_idIndexMarker467"/><span class="koboSpan" id="kobo.639.1"> 2D </span><span class="No-Break"><span class="koboSpan" id="kobo.640.1">convolutional layer.</span></span></p>
<p><span class="koboSpan" id="kobo.641.1">The convolutional </span><a id="_idIndexMarker468"/><span class="koboSpan" id="kobo.642.1">layer has the </span><span class="No-Break"><span class="koboSpan" id="kobo.643.1">following configurations:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.644.1">Filters</span></strong><span class="koboSpan" id="kobo.645.1">: There are 32 filters. </span><span class="koboSpan" id="kobo.645.2">Filters </span><a id="_idIndexMarker469"/><span class="koboSpan" id="kobo.646.1">are small grids that slide over the input data to detect patterns </span><span class="No-Break"><span class="koboSpan" id="kobo.647.1">or features.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.648.1">Filter size</span></strong><span class="koboSpan" id="kobo.649.1">: Each filter has a size of (3, 3). </span><span class="koboSpan" id="kobo.649.2">This means it considers a 3x3 grid of pixels at some point during the convolution operation capturing </span><span class="No-Break"><span class="koboSpan" id="kobo.650.1">local information.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.651.1">Activation function</span></strong><span class="koboSpan" id="kobo.652.1">: The ReLU activation function</span><a id="_idIndexMarker470"/><span class="koboSpan" id="kobo.653.1"> is applied element-wise to the output of each convolutional operation. </span><span class="koboSpan" id="kobo.653.2">ReLU introduces non-linearity, allowing the model to learn </span><span class="No-Break"><span class="koboSpan" id="kobo.654.1">complex patterns.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.655.1">Padding</span></strong><span class="koboSpan" id="kobo.656.1">: The </span><strong class="source-inline"><span class="koboSpan" id="kobo.657.1">Same</span></strong><span class="koboSpan" id="kobo.658.1"> padding</span><a id="_idIndexMarker471"/><span class="koboSpan" id="kobo.659.1"> is used. </span><span class="koboSpan" id="kobo.659.2">Padding is a technique to preserve spatial dimensions after convolution preventing information loss at the edges of the image. </span><strong class="source-inline"><span class="koboSpan" id="kobo.660.1">Same</span></strong><span class="koboSpan" id="kobo.661.1"> padding pads the input so that the output has the same spatial dimensions as </span><span class="No-Break"><span class="koboSpan" id="kobo.662.1">the it.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.663.1">Input shape parameter</span></strong><span class="koboSpan" id="kobo.664.1">: The </span><strong class="source-inline"><span class="koboSpan" id="kobo.665.1">input_shape</span></strong><span class="koboSpan" id="kobo.666.1"> parameter</span><a id="_idIndexMarker472"/><span class="koboSpan" id="kobo.667.1"> is set to the shape of the input data (</span><strong class="source-inline"><span class="koboSpan" id="kobo.668.1">x_train</span></strong><span class="koboSpan" id="kobo.669.1">) without the batch dimension. </span><span class="koboSpan" id="kobo.669.2">The input shape determines the size of the input data that the layer will process. </span><span class="koboSpan" id="kobo.669.3">In this case, it is set to the shape of the training data </span><strong class="source-inline"><span class="koboSpan" id="kobo.670.1">x_train</span></strong><span class="koboSpan" id="kobo.671.1"> without considering the </span><span class="No-Break"><span class="koboSpan" id="kobo.672.1">batch dimension.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.673.1">In summary, this code snippet adds a convolutional layer to the neural network model, configuring it with specific parameters for filter size, number of filters, activation function, and padding. </span><span class="koboSpan" id="kobo.673.2">The convolutional layer plays a crucial role in learning hierarchical features from </span><span class="No-Break"><span class="koboSpan" id="kobo.674.1">input images.</span></span></p>
<p><span class="koboSpan" id="kobo.675.1">The following line adds another 2D convolutional layer with the same specifications as the previous one, but without specifying the input shape. </span><span class="koboSpan" id="kobo.675.2">The model will infer the input shape based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.676.1">previous layer:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.677.1">
model.add(Conv2D(32, (3, 3), activation='relu'))</span></pre> <p><span class="koboSpan" id="kobo.678.1">The following line adds a max-pooling layer with a pool size of (2, 2), which reduces the spatial dimensions of the input by taking the maximum value within </span><span class="No-Break"><span class="koboSpan" id="kobo.679.1">each pool:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.680.1">
model.add(MaxPooling2D(pool_size=(2, 2)))</span></pre> <p><span class="koboSpan" id="kobo.681.1">The following line adds a dropout layer with a rate of 0.25, which randomly sets 25% of the input units to 0 during training. </span><span class="koboSpan" id="kobo.681.2">Dropout helps prevent overfitting by introducing randomness and reducing the reliance on </span><span class="No-Break"><span class="koboSpan" id="kobo.682.1">specific features:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.683.1">
model.add(Dropout(0.25))</span></pre> <p><span class="koboSpan" id="kobo.684.1">The code continues adding more convolutional layers, max-pooling layers, and dropout layers, and finally ends with fully connected (</span><span class="No-Break"><span class="koboSpan" id="kobo.685.1">dense) layers:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.686.1">
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))</span></pre> <p><span class="koboSpan" id="kobo.687.1">The following line flattens the previous layer’s output to a 1D tensor, preparing it to be connected to a </span><span class="No-Break"><span class="koboSpan" id="kobo.688.1">dense layer:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.689.1">
model.add(Flatten())</span></pre> <p><span class="koboSpan" id="kobo.690.1">The following</span><a id="_idIndexMarker473"/><span class="koboSpan" id="kobo.691.1"> line adds a dense layer with 512 units and </span><span class="No-Break"><span class="koboSpan" id="kobo.692.1">ReLU activation:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.693.1">
model.add(Dense(512, activation='relu'))</span></pre> <p><span class="koboSpan" id="kobo.694.1">The following line adds a dropout layer with a rate </span><span class="No-Break"><span class="koboSpan" id="kobo.695.1">of 0.5:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.696.1">
model.add(Dropout(0.5))</span></pre> <p><span class="koboSpan" id="kobo.697.1">The following line adds a final dense layer with 10 units and softmax activation, which produces a probability distribution over the 10 classes </span><span class="No-Break"><span class="koboSpan" id="kobo.698.1">for classification:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.699.1">
model.add(Dense(10, activation='softmax'))</span></pre> <p><span class="koboSpan" id="kobo.700.1">The following code initializes an instance of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.701.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.702.1"> class from Keras, which is used for data augmentation in </span><span class="No-Break"><span class="koboSpan" id="kobo.703.1">image datasets:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.704.1">
# Define the data augmentation parameters
datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)
# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy',\
    metrics=['accuracy'])
# Train the model with data augmentation
history = model.fit(datagen.flow(x_train, y_train, \
    batch_size=64), epochs=100, \
    validation_data=(x_test, y_test))
# Evaluate the model on the test set
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])</span></pre> <p><span class="koboSpan" id="kobo.705.1">This code defines a </span><a id="_idIndexMarker474"/><span class="koboSpan" id="kobo.706.1">CNN with two convolutional layers, two max-pooling layers, and three fully connected layers. </span><span class="koboSpan" id="kobo.706.2">Data augmentation is performed using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.707.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.708.1"> class, which randomly applies various transformations to the training images to generate more training data. </span><span class="koboSpan" id="kobo.708.2">The model is trained for 100 epochs using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.709.1">fit</span></strong><span class="koboSpan" id="kobo.710.1"> method with the data generator as the input. </span><span class="koboSpan" id="kobo.710.2">Finally, the model is evaluated on the test set using the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.711.1">evaluate</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.712.1"> method.</span></span></p>
<h1 id="_idParaDest-140"><a id="_idTextAnchor145"/><span class="koboSpan" id="kobo.713.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.714.1">In this chapter, we covered a variety of image data augmentation techniques. </span><span class="koboSpan" id="kobo.714.2">We learned how to implement an SVM with data augmentation in Python using the scikit-learn and Keras libraries. </span><span class="koboSpan" id="kobo.714.3">We first implemented SVM with the default hyperparameters and evaluated the performance of the classifier on the original dataset. </span><span class="koboSpan" id="kobo.714.4">We then implemented an SVM with data augmentation and trained the classifier on each batch of training data generated by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.715.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.716.1"> object. </span><span class="koboSpan" id="kobo.716.2">Finally, we evaluated the performance of the classifier on the </span><span class="No-Break"><span class="koboSpan" id="kobo.717.1">augmented dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.718.1">We also saw how to implement a CNN using augmentation with the CIFAR-10 dataset. </span><span class="koboSpan" id="kobo.718.2">Using data augmentation, we were able to improve the accuracy of the classifier on the augmented dataset. </span><span class="koboSpan" id="kobo.718.3">This demonstrates the effectiveness of data augmentation in improving the performance of machine learning models, especially in cases where the available dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.719.1">is limited.</span></span></p>
<p><span class="koboSpan" id="kobo.720.1">Data augmentation can reduce the need for manual annotation by creating variations of existing labeled data. </span><span class="koboSpan" id="kobo.720.2">Instead of labeling each transformed image separately, augmentation techniques allow for the generation of additional labeled samples without the need for additional human </span><span class="No-Break"><span class="koboSpan" id="kobo.721.1">annotation efforts.</span></span></p>
<p><span class="koboSpan" id="kobo.722.1">In the next chapter, we will explore how to label text data using </span><span class="No-Break"><span class="koboSpan" id="kobo.723.1">generative models.</span></span></p>
</div>


<div class="Content" id="_idContainer085">
<h1 id="_idParaDest-141" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor146"/><span class="koboSpan" id="kobo.1.1">Part 3: Labeling Text, Audio, and Video Data</span></h1>
<p><span class="koboSpan" id="kobo.2.1">In this part of the book, you will explore how to read text, audio, and video data using Python, analyze the data, and extract features. </span><span class="koboSpan" id="kobo.2.2">The content delves into various methods for programmatically labeling text, video, and audio data in Python, leveraging OpenAI’s large language models, as well as semi-supervised and unsupervised techniques such as K-means clustering. </span><span class="koboSpan" id="kobo.2.3">Additionally, this section aids in understanding different open source data annotation tools such as Label Studio, CVAT, pyOpenAnnotate, and Azure Machine Learning for image, video, audio, and text data, providing a comprehensive comparison </span><span class="No-Break"><span class="koboSpan" id="kobo.3.1">between them.</span></span></p>
<p><span class="koboSpan" id="kobo.4.1">This part comprises the </span><span class="No-Break"><span class="koboSpan" id="kobo.5.1">following chapters:</span></span></p>
<ul>
<li><a href="B18944_07.xhtml#_idTextAnchor147"><em class="italic"><span class="koboSpan" id="kobo.6.1">Chapter 7</span></em></a><span class="koboSpan" id="kobo.7.1">, </span><em class="italic"><span class="koboSpan" id="kobo.8.1">Labeling Text Data</span></em></li>
<li><a href="B18944_08.xhtml#_idTextAnchor176"><em class="italic"><span class="koboSpan" id="kobo.9.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.10.1">, </span><em class="italic"><span class="koboSpan" id="kobo.11.1">Exploring Video Data</span></em></li>
<li><a href="B18944_09.xhtml#_idTextAnchor204"><em class="italic"><span class="koboSpan" id="kobo.12.1">Chapter 9</span></em></a><span class="koboSpan" id="kobo.13.1">, </span><em class="italic"><span class="koboSpan" id="kobo.14.1">Labeling Video Data</span></em></li>
<li><a href="B18944_10.xhtml#_idTextAnchor221"><em class="italic"><span class="koboSpan" id="kobo.15.1">Chapter 10</span></em></a><span class="koboSpan" id="kobo.16.1">, </span><em class="italic"><span class="koboSpan" id="kobo.17.1">Exploring Audio Data</span></em></li>
<li><a href="B18944_11.xhtml#_idTextAnchor248"><em class="italic"><span class="koboSpan" id="kobo.18.1">Chapter 11</span></em></a><span class="koboSpan" id="kobo.19.1">, </span><em class="italic"><span class="koboSpan" id="kobo.20.1">Labeling Audio Data</span></em></li>
<li><a href="B18944_12.xhtml#_idTextAnchor267"><em class="italic"><span class="koboSpan" id="kobo.21.1">Chapter 12</span></em></a><span class="koboSpan" id="kobo.22.1">, </span><em class="italic"><span class="koboSpan" id="kobo.23.1">Hands-On Exploring Data Labeling Tools</span></em></li>
</ul>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer086">
</div>
</div>
</body></html>