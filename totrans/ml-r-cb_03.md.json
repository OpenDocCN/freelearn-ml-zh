["```py\n    > sample(1:10)\n\n    ```", "```py\n    > sample(1:10, size = 5)\n\n    ```", "```py\n    > sample(c(0,1), 10, replace = TRUE)\n\n    ```", "```py\n    > sample.int(20, 12)\n\n    ```", "```py\n    > dnorm(0)\n    [1] 0.3989423\n\n    ```", "```py\n    > dnorm(0,mean=3,sd=5)\n    [1] 0.06664492\n\n    ```", "```py\n    > curve(dnorm,-3,3)\n\n    ```", "```py\n    > pnorm(1.5)\n    [1] 0.9331928\n\n    ```", "```py\n    > pnorm(1.5, lower.tail=FALSE)\n    [1] 0.0668072\n\n    ```", "```py\n    > curve(pnorm(x), -3,3)\n\n    ```", "```py\n    > qnorm(0.5)\n    [1] 0\n    > qnorm(pnorm(0))\n    [1] 0\n\n    ```", "```py\n    > set.seed(50)\n    > x = rnorm(100,mean=3,sd=5)\n    > hist(x)\n\n    ```", "```py\n    > set.seed(50)\n    > y = runif(100,0,5)\n    > hist(y)\n\n    ```", "```py\n    > shapiro.test(x)\n\n     Shapiro-Wilk normality test\n\n    data:  x \n    W = 0.9938, p-value = 0.9319\n    > shapiro.test(y)\n\n     Shapiro-Wilk normality test\n\n    data:  y \n    W = 0.9563, p-value = 0.002221\n\n    ```", "```py\n    > help(TDist)\n\n    ```", "```py\n    >help(Binomial)\n\n    ```", "```py\n    >help(Chisquare)\n\n    ```", "```py\n> help(distributions)\n\n```", "```py\n    > data(mtcars)\n\n    ```", "```py\n    > range(mtcars$mpg)\n    [1] 10.4 33.9\n\n    ```", "```py\n    > length(mtcars$mpg)\n    [1] 32\n\n    ```", "```py\n    > mean(mtcars$mpg)\n    [1] 20.09062\n\n    ```", "```py\n    > median(mtcars$mpg)\n    [1] 19.2\n\n    ```", "```py\n    > sd(mtcars$mpg)\n    [1] 6.026948\n\n    ```", "```py\n    > var(mtcars$mpg)\n    [1] 36.3241\n\n    ```", "```py\n    > sd(mtcars$mpg) ^ 2\n    [1] 36.3241\n\n    ```", "```py\n    > IQR(mtcars$mpg)\n    [1] 7.375\n\n    ```", "```py\n    > quantile(mtcars$mpg,0.67)\n     67% \n    21.4\n\n    ```", "```py\n    > max(mtcars$mpg)\n    [1] 33.9\n\n    ```", "```py\n    > min(mtcars$mpg)\n    [1] 10.4\n\n    ```", "```py\n    > cummax(mtcars$mpg)\n     [1] 21.0 21.0 22.8 22.8 22.8 22.8 22.8 24.4 24.4 24.4 24.4 24.4 24.4 24.4 24.4 24.4\n    [17] 24.4 32.4 32.4 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9\n\n    ```", "```py\n    > cummin(mtcars$mpg)\n     [1] 21.0 21.0 21.0 21.0 18.7 18.1 14.3 14.3 14.3 14.3 14.3 14.3 14.3 14.3 10.4 10.4\n    [17] 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4\n\n    ```", "```py\n    > summary(mtcars)\n\n    ```", "```py\n    > table(mtcars$cyl)\n\n     4  6  8\n    11  7 14\n\n    ```", "```py\n    > stem(mtcars$mpg)\n\n     The decimal point is at the |\n\n     10 | 44\n     12 | 3\n     14 | 3702258\n     16 | 438\n     18 | 17227\n     20 | 00445\n     22 | 88\n     24 | 4\n     26 | 03\n     28 | \n     30 | 44\n     32 | 49\n\n    ```", "```py\n    > library(ggplot2)\n    > qplot(mtcars$mpg, binwidth=2)\n\n    ```", "```py\n> mode = function(x) {\n+ temp = table(x)\n+ names(temp)[temp == max(temp)]\n+ }\n\n```", "```py\n> x = c(1,2,3,3,3,4,4,5,5,5,6)\n> mode(x)\n[1] \"3\" \"5\"\n\n```", "```py\n    > cov(mtcars[1:3])\n     mpg        cyl       disp\n    mpg    36.324103  -9.172379  -633.0972\n    cyl    -9.172379   3.189516   199.6603\n    disp -633.097208 199.660282 15360.7998\n\n    ```", "```py\n    > cor(mtcars[1:3])\n     mpg        cyl       disp\n    mpg   1.0000000 -0.8521620 -0.8475514\n    cyl  -0.8521620  1.0000000  0.9020329\n    disp -0.8475514  0.9020329  1.0000000\n\n    ```", "```py\n    > library(reshape2)\n    > qplot(x=Var1, y=Var2, data=melt(cor(mtcars[1:3])), fill=value, geom=\"tile\")\n\n    ```", "```py\n    > lmfit = lm(mtcars$mpg ~ mtcars$cyl)\n    > lmfit\n\n    Call:\n    lm(formula = mtcars$mpg ~ mtcars$cyl)\n\n    Coefficients:\n    (Intercept)   mtcars$cyl \n     37.885       -2.876 \n\n    ```", "```py\n    > summary(lmfit)\n\n    Call:\n    lm(formula = mtcars$mpg ~ mtcars$cyl)\n\n    Residuals:\n     Min      1Q  Median      3Q     Max \n    -4.9814 -2.1185  0.2217  1.0717  7.5186 \n\n    Coefficients:\n     Estimate Std. Error t value Pr(>|t|) \n    (Intercept)  37.8846     2.0738   18.27  < 2e-16 ***\n    mtcars$cyl   -2.8758     0.3224   -8.92 6.11e-10 ***\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    Residual standard error: 3.206 on 30 degrees of freedom\n    Multiple R-squared:  0.7262,  Adjusted R-squared:  0.7171 \n    F-statistic: 79.56 on 1 and 30 DF,  p-value: 6.113e-10\n\n    ```", "```py\n    > anova(lmfit)\n    Analysis of Variance Table\n\n    Response: mtcars$mpg\n     Df Sum Sq Mean Sq F value    Pr(>F) \n    mtcars$cyl  1 817.71  817.71  79.561 6.113e-10 ***\n    Residuals  30 308.33   10.28 \n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    ```", "```py\n    > lmfit = lm(mtcars$mpg ~ mtcars$cyl)\n    > plot(mtcars$cyl, mtcars$mpg)\n    > abline(lmfit)\n\n    ```", "```py\n    > binom.test(x=92, n=315, p=1/6)\n\n     Exact binomial test\n\n    data:  92 and 315\n    number of successes = 92, number of trials = 315, p-value = 3.458e-08\n    alternative hypothesis: true probability of success is not equal to 0.1666667\n    95 percent confidence interval:\n     0.2424273 0.3456598\n    sample estimates:\n    probability of success \n     0.2920635 \n\n    ```", "```py\n    > ?binom.test\n\n    ```", "```py\n    > boxplot(mtcars$mpg, mtcars$mpg[mtcars$am==0], ylab = \"mpg\", names=c(\"overall\",\"automobile\"))\n    > abline(h=mean(mtcars$mpg),lwd=2, col=\"red\")\n    > abline(h=mean(mtcars$mpg[mtcars$am==0]),lwd=2, col=\"blue\")\n\n    ```", "```py\n    > mpg.mu = mean(mtcars$mpg)\n    > mpg_am = mtcars$mpg[mtcars$am == 0]\n    > t.test(mpg_am,mu = mpg.mu)\n\n     One Sample t-test\n\n    data:  mpg_am\n    t = -3.3462, df = 18, p-value = 0.003595\n    alternative hypothesis: true mean is not equal to 20.09062\n    95 percent confidence interval:\n     15.29946 18.99528\n    sample estimates:\n    mean of x \n     17.14737 \n\n    ```", "```py\n    >boxplot(mtcars$mpg~mtcars$am,ylab='mpg',names=c('automatic','manual'))\n    > abline(h=mean(mtcars$mpg[mtcars$am==0]),lwd=2, col=\"blue\")\n    > abline(h=mean(mtcars$mpg[mtcars$am==1]),lwd=2, col=\"red\")\n\n    ```", "```py\n    > t.test(mtcars$mpg~mtcars$am)\n\n     Welch Two Sample t-test\n\n    data:  mtcars$mpg by mtcars$am\n    t = -3.7671, df = 18.332, p-value = 0.001374\n    alternative hypothesis: true difference in means is not equal to 0\n    95 percent confidence interval:\n     -11.280194  -3.209684\n    sample estimates:\n    mean in group 0 mean in group 1 \n     17.14737        24.39231 \n\n    ```", "```py\n    > ?t.test\n\n    ```", "```py\n    > x = rnorm(50)\n    > ks.test(x,\"pnorm\")\n\n     One-sample Kolmogorov-Smirnov test\n\n    data:  x\n    D = 0.1698, p-value = 0.0994\n    alternative hypothesis: two-sided\n\n    ```", "```py\n    > set.seed(3)\n    > x = runif(n=20, min=0, max=20)\n\n    > y = runif(n=20, min=0, max=20)\n\n    ```", "```py\n    > plot(ecdf(x), do.points = FALSE, verticals=T, xlim=c(0, 20))\n    > lines(ecdf(y), lty=3, do.points = FALSE, verticals=T)\n\n    ```", "```py\n    > ks.test(x,y)\n\n     Two-sample Kolmogorov-Smirnov test\n\n    data:  x and y\n    D = 0.3, p-value = 0.3356\n    alternative hypothesis: two-sided\n\n    ```", "```py\n    > ?ks.test\n\n    ```", "```py\n    > ?ecdf\n\n    ```", "```py\n    > boxplot(mtcars$mpg~mtcars$am,ylab='mpg',names=c('automatic','manual'))\n\n    ```", "```py\n    > wilcox.test(mpg ~ am, data=mtcars)\n\n     Wilcoxon rank sum test with continuity correction\n\n    data:  mpg by am\n    W = 42, p-value = 0.001871\n    alternative hypothesis: true location shift is not equal to 0\n\n    Warning message:\n    In wilcox.test.default(x = c(21.4, 18.7, 18.1, 14.3, 24.4, 22.8,  :\n     cannot compute exact p-value with ties\n\n    ```", "```py\n    > ? wilcox.test\n\n    ```", "```py\n    > ftable = table(mtcars$am, mtcars$gear)\n    > ftable\n\n     3  4  5\n     0 15  4  0\n     1  0  8  5\n\n    ```", "```py\n    > mosaicplot(ftable, main=\"Number of Forward Gears Within Automatic and Manual Cars\", color = TRUE)\n\n    ```", "```py\n    > chisq.test(ftable)\n\n     Pearson's Chi-squared test\n\n    data:  ftable\n    X-squared = 20.9447, df = 2, p-value = 2.831e-05\n\n    Warning message:\n    In chisq.test(ftable) : Chi-squared approximation may be incorrect\n\n    ```", "```py\n> ? chisq.test\n\n```", "```py\n    > boxplot(mtcars$mpg~factor(mtcars$gear),xlab='gear',ylab='mpg')\n\n    ```", "```py\n    > oneway.test(mtcars$mpg~factor(mtcars$gear))\n\n     One-way analysis of means (not assuming equal variances)\n\n    data:  mtcars$mpg and factor(mtcars$gear)\n    F = 11.2848, num df = 2.000, denom df = 9.508, p-value = 0.003085\n\n    ```", "```py\n    > mtcars.aov = aov(mtcars$mpg ~ as.factor(mtcars$gear))\n    > summary(mtcars.aov)\n     Df Sum Sq Mean Sq F value   Pr(>F) \n    as.factor(mtcars$gear)  2  483.2  241.62    10.9 0.000295 ***\n    Residuals              29  642.8   22.17 \n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    ```", "```py\n    > model.tables(mtcars.aov, \"means\")\n    Tables of means\n    Grand mean\n\n    20.09062 \n\n     as.factor(mtcars$gear) \n     3     4     5\n     16.11 24.53 21.38\n    rep 15.00 12.00  5.00\n\n    ```", "```py\n    > mtcars_posthoc =TukeyHSD(mtcars.aov)\n    > mtcars_posthoc\n     Tukey multiple comparisons of means\n     95% family-wise confidence level\n\n    Fit: aov(formula = mtcars$mpg ~ as.factor(mtcars$gear))\n\n    $`as.factor(mtcars$gear)`\n     diff        lwr       upr     p adj\n    4-3  8.426667  3.9234704 12.929863 0.0002088\n    5-3  5.273333 -0.7309284 11.277595 0.0937176\n    5-4 -3.153333 -9.3423846  3.035718 0.4295874\n\n    ```", "```py\n    > par(mfrow=c(1,2))\n    > boxplot(mtcars$mpg~mtcars$gear,subset=(mtcars$am==0),xlab='gear', ylab = \"mpg\",main='automatic')\n    > boxplot(mtcars$mpg~mtcars$gear,subset=(mtcars$am==1),xlab='gear', ylab = \"mpg\", main='manual')\n\n    ```", "```py\n    > boxplot(mtcars$mpg~factor(mtcars$gear)* factor(mtcars$am),xlab='gear * transmission', ylab = \"mpg\",main='Boxplot of mpg by gear * transmission')\n\n    ```", "```py\n    > interaction.plot(mtcars$gear, mtcars$am, mtcars$mpg, type=\"b\", col=c(1:3),leg.bty=\"o\", leg.bg=\"beige\", lwd=2, pch=c(18,24,22), xlab=\"Number of Gears\", ylab=\"Mean Miles Per Gallon\", main=\"Interaction Plot\")\n\n    ```", "```py\n    > mpg_anova2 = aov(mtcars$mpg~factor(mtcars$gear)*factor(mtcars$am))\n    > summary(mpg_anova2) \n     Df Sum Sq Mean Sq F value   Pr(>F) \n    factor(mtcars$gear)  2  483.2  241.62  11.869 0.000185 ***\n    factor(mtcars$am)    1   72.8   72.80   3.576 0.069001 . \n    Residuals           28  570.0   20.36 \n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    ```", "```py\n    > TukeyHSD(mpg_anova2)\n     Tukey multiple comparisons of means\n     95% family-wise confidence level\n\n    Fit: aov(formula = mtcars$mpg ~ factor(mtcars$gear) * factor(mtcars$am))\n\n    $`factor(mtcars$gear)`\n     diff        lwr       upr     p adj\n    4-3  8.426667  4.1028616 12.750472 0.0001301\n    5-3  5.273333 -0.4917401 11.038407 0.0779791\n    5-4 -3.153333 -9.0958350  2.789168 0.3999532\n\n    $`factor(mtcars$am)`\n     diff       lwr     upr     p adj\n    1-0 1.805128 -1.521483 5.13174 0.2757926\n\n    ```", "```py\n    > par(mfrow=c(1,2))\n    > plot(TukeyHSD(mpg_anova2))\n\n    ```", "```py\n    > ?MANOVA\n\n    ```"]