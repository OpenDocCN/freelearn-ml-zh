- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction to Data Privacy, Privacy Breaches, and Threat Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Privacy-preserving **machine learning** (**ML**) is becoming increasingly important
    in today’s digital age, where the use of personal data is ubiquitous in various
    industries, including healthcare, finance, and marketing. While ML can bring many
    benefits, such as improved accuracy and efficiency, it also raises significant
    concerns about privacy and security. Many individuals are increasingly concerned
    about the risks associated with the use of their personal data, including unauthorized
    access, misuse, and abuse. Furthermore, there are regulations such as the **General
    Data Protection Regulation** (**GDPR**) and the **California Consumer Privacy
    Act** (**CCPA**) that require organizations to comply with strict privacy guidelines
    while processing personal data.
  prefs: []
  type: TYPE_NORMAL
- en: This book provides a comprehensive understanding of the techniques and tools
    available to protect individuals’ privacy while enabling effective ML. This book
    will help researchers, ML engineers, software engineers, and practitioners to
    understand the importance of privacy and how to incorporate it into their ML algorithms
    and data processing pipelines. This book bridges the gap between the theoretical
    foundations of privacy and the practical implementation of privacy-preserving
    ML techniques, enabling data-driven decision-making without compromising individuals’
    privacy.
  prefs: []
  type: TYPE_NORMAL
- en: In this introductory chapter, we are going to learn about privacy, including
    data privacy; sensitive data versus personal sensitive data; data privacy regulations;
    **Privacy by Design** (**PbD**) concepts; and why data privacy is important. Once
    we have discussed these concepts, we will cover privacy threat modeling using
    the LINDDUN framework in detail and explain linkability and identifiability threats
    with an example. This chapter will help you to better understand privacy and why
    it is important. We will discuss key privacy regulations, such as the GDPR and
    CPRA, at a high level, as well as privacy threat modeling. At the end of this
    chapter, we will cover the need for privacy-preserving ML and a use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What do privacy and data privacy mean?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Privacy by Design and a case study
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Privacy breaches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Privacy threat modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The need for privacy-preserving ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What do privacy and data privacy mean?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alan Westin’s theory describes privacy as the control over how information about
    a person is handled and communicated to others. Irwin Altman added that privacy
    includes limiting social interaction and included regulating personal space and
    territory.
  prefs: []
  type: TYPE_NORMAL
- en: Personal data includes any information that by itself or in conjunction with
    other elements can be used to identify an individual, such as their name, age,
    gender, personal identification number, race, religion, address, email address,
    biometric data, device IDs, medical data, and genetics data, based on the regulations
    defined in the country where the orginated from.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy refers to an individual’s ability to keep their information, whether
    it is personal or non-personal data, to themselves and share data based on their
    consent. Privacy helps individuals maintain autonomy over their personal lives.
  prefs: []
  type: TYPE_NORMAL
- en: Data privacy focuses on the use and governance of personal data and policies
    to ensure that data is collected, processed, shared, and used/inferred in an appropriate
    way.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy regulations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As per the latest statistics of the **United Nations Conference on Trade and
    Development** (**UNCTAD**), 71% of countries have their own privacy laws, which
    shows the importance of privacy and data protection across the world.
  prefs: []
  type: TYPE_NORMAL
- en: Most privacy laws deal with the collection of sensitive personal data, data
    processing, sharing data with other parties, and data subject rights. 137 out
    of 194 countries in the world have legal legislation to protect data and individuals’
    data privacy.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1 – Privacy legislation worldwide as of December 2021](img/B16573_01_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 – Privacy legislation worldwide as of December 2021
  prefs: []
  type: TYPE_NORMAL
- en: 'Source: [https://unctad.org/page/data-protection-and-privacy-legislation-worldwide](https://unctad.org/page/data-protection-and-privacy-legislation-worldwide)'
  prefs: []
  type: TYPE_NORMAL
- en: Out of these privacy regulations across the world, the most popular and widely
    implemented ones are the **GDPR** in Europe and the **CCPA** in the US.
  prefs: []
  type: TYPE_NORMAL
- en: 'As per the GDPR, personal data is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The data subjects are identifiable if they can be directly or indirectly identified,
    especially by reference to an identifier such as a name, an identification number,
    location data, an online identifier or one of several special characteristics,
    which expresses the physical, physiological, genetic, mental, commercial, cultural
    or social identity of these natural persons. In practice, these also include all
    data which are or can be assigned to a person in any kind of way. For example,
    the telephone, credit card or personnel number of a person, account data, number
    plate, appearance, customer number or address are all personal data.
  prefs: []
  type: TYPE_NORMAL
- en: In this definition, the keywords are whether the person can be identified either
    *directly* or *indirectly* using an identifier mentioned as name. We will learn
    more about indirect identification, how individuals can be identified through
    indirect identifiers, and how their privacy is compromised in the *Privacy threat*
    *modeling* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The GDPR also defines sensitive personal data, which includes genetic, biometric,
    and health data, as well as personal data revealing racial and ethnic origin,
    political opinions, religious or ideological convictions, or trade union membership.
    Most regulations have articles/sections covering the following when working with
    personal data, non-personal data, and sensitive personal data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Purpose, scope, and definition of personal data**: The purpose of the privacy
    law, specifying its scope and outlining the types of data and entities covered
    by the law. It clarifies the legal framework’s intent and applicability and definitions
    of terms such as personal data and sensitive personal data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Privacy enforcement authority**: Regulations define the role of the data
    protection authority or supervisory body responsible for overseeing compliance
    with the law, providing guidance, and handling complaints.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fines and penalties**: Most laws have different fines/penalties based on
    the nature of privacy violations in that country. For example, the GDPR imposes
    a fine of 20 million euros, or up to 4% of the total global turnover of the preceding
    fiscal year of the company, whichever is higher for severe violations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rights**: Some countries define privacy as a fundamental right of people
    in that country. Each individual has rights to their data, that is, the right
    to know, remove, forget, and delete data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following table lists the data subject rights defined by popular privacy
    laws across the world:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Privacy Laws** | **Data** **Subject Rights** |'
  prefs: []
  type: TYPE_TB
- en: '| GDPR | Right to be informedRight to accessRight to rectificationRight to
    erasure/be forgottenRight to data portabilityRight to restrict data processingRight
    to withdraw consentRight to object processingRight to object automated decision-making
    |'
  prefs: []
  type: TYPE_TB
- en: '| CCPA | Right to knowRight to accessRight to deleteRight to opt-outRight to
    non-discriminationRight to correctRight to limit |'
  prefs: []
  type: TYPE_TB
- en: '| LGPD(This is Brazil’s General Personal Data Protection Law – **Lei Geral
    de Proteção de** **Dados** (**LGPD**)) | Right to be informedRight to accessRight
    to rectificationRight to erasureRight to data portabilityRight to object processingRight
    to object automated decision-making |'
  prefs: []
  type: TYPE_TB
- en: Table 1.1 – Data subject rights
  prefs: []
  type: TYPE_NORMAL
- en: We have gone through a high-level definition of privacy, privacy regulations
    in various countries, and data subject requests (rights of individuals).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now learn more about PbD, what it is, and how it helps to protect data
    privacy.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy by Design and a case study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The concept of PbD was created by Ann Cavoukian in the 1990s and presented
    in her 2009 presentation, “*Privacy by Design: The Definitive Workshop.*” As Cavoukian
    states, the concept of PbD encompasses more than just technology.'
  prefs: []
  type: TYPE_NORMAL
- en: PbD is a framework that promotes the integration of privacy and data protection
    principles into the design and development of systems, products, and services.
  prefs: []
  type: TYPE_NORMAL
- en: 'The PbD framework has seven foundational principles. The objective of these
    principles is to ensure that privacy is embedded in every stage of a system’s
    development and that data subjects’ privacy rights are protected:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Proactive not reactive measures**: PbD requires that privacy considerations
    be integrated into the design and development of a system from the outset, rather
    than being added as an afterthought.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Privacy as the default setting**: PbD requires that privacy settings be set
    to the highest level by default and that users must opt-in to more invasive settings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**End-to-end security**: PbD requires that privacy and security measures be
    integrated throughout the entire life cycle of a system, from design and development
    to deployment and decommissioning. I strongly suggest using a “begin with privacy”
    approach instead of shift-left privacy. In this way, privacy begins from the software
    requirements phase itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Full functionality**: PbD requires that privacy and data protection measures
    be integrated in a way that does not compromise the functionality of the system
    or product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visibility and transparency**: PbD requires that users are informed of the
    privacy risks associated with a system or product and that they have access to
    information about how their data is being collected, used, and shared.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Respect for user privacy**: PbD requires that users have control over their
    personal data and that their privacy preferences are respected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Holistic approach**: PbD requires that privacy and data protection considerations
    are integrated into all aspects of a system or product, including its technical
    design, operational procedures, and business practices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The PbD approach has become increasingly important in recent years, as privacy
    concerns have grown in response to the rapid expansion of data-driven technologies.
  prefs: []
  type: TYPE_NORMAL
- en: PbD is now widely recognized as a best practice for organizations that process
    personal data and is an important component of data protection regulations, such
    as the EU’s GDPR.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, PbD is a comprehensive framework that aims to ensure that privacy is
    an integral part of any system or product and that data protection is considered
    from the beginning of the development process, rather than as an afterthought.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through an example to understand PbD in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Example – Privacy by Design in a social media platform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PbD is a framework that advocates for embedding privacy considerations into
    the design and architecture of systems, products, and services from the very beginning.
    By incorporating privacy as a core component, organizations can proactively address
    privacy concerns and ensure the protection of user data. This example case study
    illustrates how a social media platform can implement PbD principles.
  prefs: []
  type: TYPE_NORMAL
- en: Case study description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s consider a hypothetical social media platform called “MyConnect,” which
    aims to prioritize user privacy and data protection by implementing PbD principles
    throughout its development and operation. We will explore its principles one by
    one.
  prefs: []
  type: TYPE_NORMAL
- en: '**Minimized data collection**: MyConnect follows a privacy-focused approach
    by collecting only necessary user data. It only requests information that is directly
    relevant to providing the platform’s core functionality. Unnecessary data points,
    such as excessive personal details or invasive tracking information, are deliberately
    avoided.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Privacy-oriented default settings**: MyConnect implements privacy-oriented
    settings to protect user privacy by default. For example, it sets user profiles
    to private, limiting the visibility of user information to only approved connections.
    Additionally, it enables opt-in consent for features such as location sharing,
    ensuring that users have to actively choose to share their location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Granular privacy controls**: MyConnect offers granular privacy controls,
    empowering users to manage their privacy preferences. Users have control over
    who can view their posts, access their profile information, and send connection
    requests. The platform provides easy-to-use privacy settings that allow users
    to customize their privacy levels according to their preferences.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secure data storage and encryption**: MyConnect prioritizes the security
    of user data by employing strong encryption mechanisms. User data, including personal
    information and communications, is stored securely and encrypted both at rest
    and during transmission. This ensures that even if a data breach occurs, the data
    remains unreadable and protected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regular security audits and updates**: MyConnect conducts regular security
    audits to identify potential vulnerabilities and address them promptly. It stays
    updated with the latest security measures and patches any identified security
    weaknesses to ensure the ongoing protection of user data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transparency and user education**: MyConnect maintains transparency with
    its users by providing clear and concise privacy policies and terms of service.
    It educates users about their rights, the data collected, and how it is used.
    The platform also offers user-friendly guides and resources to educate users about
    privacy best practices and how to protect their information. MyConnect also implements
    a new way of sharing the details of how it protects data privacy on its platform
    through “privacy data sheets.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following mapping shows how the PbD principle is implemented at the social
    media platform company:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Privacy By Design – Principle | MyConnect Implementation |'
  prefs: []
  type: TYPE_TB
- en: '| Proactive not reactive measures | Minimized data collection |'
  prefs: []
  type: TYPE_TB
- en: '| Privacy as the default setting | Privacy-oriented default settings |'
  prefs: []
  type: TYPE_TB
- en: '| Respect for user privacy | Granular privacy controls |'
  prefs: []
  type: TYPE_TB
- en: '| End-to-end security | Secure data storage and encryption |'
  prefs: []
  type: TYPE_TB
- en: '| Holistic approach | Regular security audits and updates |'
  prefs: []
  type: TYPE_TB
- en: '| Visibility and transparency | Transparency and user education |'
  prefs: []
  type: TYPE_TB
- en: Table 1.2 - MyConnect implementation
  prefs: []
  type: TYPE_NORMAL
- en: '**Benefits** **and outcomes**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implementing PbD principles in MyConnect yields several key benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enhanced user** **trust**: Users of MyConnect feel confident that their privacy
    is respected and their data is protected. The platform’s commitment to privacy
    empowers users to engage and share content without undue concerns about their
    personal information being misused.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance with privacy regulations**: By incorporating PbD principles, MyConnect
    ensures compliance with privacy regulations, such as the GDPR. This protects the
    platform from legal and reputational risks associated with privacy breaches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Positive reputation and differentiation**: MyConnect gains a competitive
    advantage by promoting itself as a privacy-conscious social media platform. Its
    PbD approach can attract privacy-conscious users who prioritize the protection
    of their personal information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduced privacy incidents and breaches**: PbD practices reduce the likelihood
    of privacy incidents and data breaches. By incorporating privacy considerations
    from the start of the project, MyConnect minimizes the potential vulnerabilities
    that could lead to unauthorized access or misuse of user data. We will go through
    privacy breaches in more detail in the next section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MyConnect’s implementation of PbD principles showcases the significance of considering
    privacy as a fundamental component in the design and operation of a social media
    platform by prioritizing minimized data collection, privacy-oriented defaults,
    granular privacy controls, secure data storage, regular audits, transparency,
    and user education.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy breaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is a privacy breach?
  prefs: []
  type: TYPE_NORMAL
- en: A privacy breach, also known as a data breach, refers to an incident where unauthorized
    individuals or entities gain access to confidential or sensitive information without
    proper authorization. This breach of privacy can occur in various forms, such
    as hacking, theft, accidental exposure, or improper handling of data. It typically
    involves the unauthorized access, acquisition, disclosure, or use of personal
    information, which may include personally identifiable information (PII) such
    as names, addresses, social security numbers, financial details, and login credentials.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy breaches can have serious consequences for individuals, organizations,
    and even society. They can lead to identity theft, financial fraud, reputational
    damage, loss of trust, legal implications, and emotional distress for those affected.
    Protecting personal data and maintaining privacy is essential to ensure the security
    and well-being of individuals and maintain trust in digital systems and services.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some examples of privacy breaches: one involves a company
    utilizing web technologies in their product, while the other concerns a company
    incorporating **artificial intelligence** (**AI**) and ML into their products
    and services.'
  prefs: []
  type: TYPE_NORMAL
- en: Equifax privacy breach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Equifax privacy breach refers to a massive data breach that occurred in
    2017, in which the personal information of approximately 147 million people was
    compromised. Equifax is one of the largest consumer credit reporting agencies
    in the United States, and the breach was one of the most significant data breaches
    in history.
  prefs: []
  type: TYPE_NORMAL
- en: The breach occurred when hackers exploited a vulnerability in Equifax’s website
    software, allowing them to gain access to sensitive information such as names,
    social security numbers, birth dates, addresses, and, in some cases, driver’s
    license numbers and credit card information.
  prefs: []
  type: TYPE_NORMAL
- en: The breach went undetected for several months, during which time the hackers
    were able to access and steal the information. The Equifax breach was a significant
    event, and it highlighted the importance of cybersecurity and the need for companies
    to take proactive measures to protect their customers’ data.
  prefs: []
  type: TYPE_NORMAL
- en: The breach also resulted in numerous investigations, lawsuits, and settlements
    against Equifax, with the company ultimately agreeing to pay over $700 million
    in damages and penalties. In addition to the financial impact, the breach had
    serious consequences for the affected individuals, who were at risk of identity
    theft and other fraudulent activities. The breach highlighted the need for individuals
    to be vigilant about monitoring their credit reports, protecting their personal
    information, and taking steps to protect themselves from identity theft.
  prefs: []
  type: TYPE_NORMAL
- en: The attackers used a combination of techniques, including SQL injection and
    **cross-site scripting** (**XSS**), to gain access to sensitive data stored in
    Equifax’s databases. SQL injection is a type of attack in which an attacker injects
    malicious code into a SQL statement, allowing them to execute unauthorized actions
    on a database. In this case, the attackers used SQL injection to bypass Equifax’s
    security controls and gain access to the personal information of millions of individuals.
  prefs: []
  type: TYPE_NORMAL
- en: The attackers also used XSS attacks, which involve injecting malicious code
    into a website to steal sensitive data from users. In this case, the attackers
    were able to inject malicious code into Equifax’s website. Once the attackers
    gained access to Equifax’s systems, they were able to extract large amounts of
    data over a period of several months without being detected. The data stolen included
    names, social security numbers, birth dates, addresses, driver’s license numbers,
    and credit card information.
  prefs: []
  type: TYPE_NORMAL
- en: The Equifax breach highlights the importance of cybersecurity and the need for
    companies to take proactive measures to protect their systems and data from attackers.
    It also underscores the importance of ongoing monitoring and detection to quickly
    identify and respond to potential security threats.
  prefs: []
  type: TYPE_NORMAL
- en: 'Source: [https://en.wikipedia.org/wiki/2017_Equifax_data_breach](https://en.wikipedia.org/wiki/2017_Equifax_data_breach)'
  prefs: []
  type: TYPE_NORMAL
- en: Clearview AI Privacy breach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Clearview AI is a technology company that developed a controversial facial recognition
    system. The company’s software was designed to match images of individuals with
    publicly available photos, scraping data from various sources on the internet,
    including social media platforms. The system gained widespread attention due to
    concerns over privacy and ethical implications.
  prefs: []
  type: TYPE_NORMAL
- en: In early 2020, Clearview AI found itself at the center of a major privacy breach.
    It was revealed that the company had amassed a massive database of billions of
    facial images without the knowledge or consent of the individuals involved. These
    images were collected from various online platforms, including Facebook, Instagram,
    and X (formerly Twitter).
  prefs: []
  type: TYPE_NORMAL
- en: The breach was brought to light by investigative reports and researchers who
    discovered that Clearview AI’s database was accessible to law enforcement agencies
    and other organizations. It raised significant concerns about the potential misuse
    of the technology, as it could be employed for mass surveillance, tracking individuals,
    or invading people’s privacy without their knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: One of the primary concerns regarding Clearview AI’s practices was the lack
    of transparency and consent. Individuals whose photos were included in the database
    had not given their permission or even been aware that their images were being
    used in this manner. Clearview AI’s scraping of publicly available data bypassed
    many social media platforms’ terms of service, further exacerbating the privacy
    issues.
  prefs: []
  type: TYPE_NORMAL
- en: The breach prompted legal and ethical debates about the use of facial recognition
    technology and the need for stronger regulations. Critics argued that Clearview
    AI’s practices were an invasion of privacy, as people’s faces were being used
    as biometric identifiers without their consent.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, there were concerns about the potential for racial bias and discrimination
    in the system, as facial recognition algorithms have shown to be less accurate
    for certain demographics. Following the revelation of the privacy breach, Clearview
    AI faced significant backlash from privacy advocates, technology experts, and
    the public. Several lawsuits were filed against the company, accusing it of violating
    privacy laws and regulations. As a result, Clearview AI was subject to investigations
    by various regulatory authorities.
  prefs: []
  type: TYPE_NORMAL
- en: In response to the backlash, Clearview AI made efforts to improve its practices
    and address privacy concerns. The company claimed to have implemented stricter
    policies regarding data access and established a verification system for potential
    clients. However, skepticism remains regarding the efficacy of these measures
    and the overall ethics of the company’s operations.
  prefs: []
  type: TYPE_NORMAL
- en: The Clearview AI privacy breach serves as a cautionary tale about the potential
    dangers of unchecked facial recognition technology and the importance of safeguarding
    personal privacy. It has fueled discussions surrounding privacy laws, regulation
    of emerging technologies, and the ethical implications of mass surveillance. As
    the debate continues, it remains crucial to strike a balance between technological
    advancement and protecting individuals’ rights and privacy.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy threat modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In an increasingly digital world, privacy has become a paramount concern for
    individuals, organizations, and societies at large. With the widespread collection
    and processing of personal data, it is essential to assess and mitigate privacy
    threats effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy threat modeling – definition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Privacy threat modeling is a proactive process that aims to identify and understand
    potential threats to privacy before they materialize. By examining the system’s
    architecture, data flows, and interactions, privacy threat modeling allows for
    the identification of vulnerabilities and risks that may compromise individuals’
    privacy. It helps organizations anticipate and address privacy concerns during
    the design and development stages, ensuring privacy protections are integrated
    into the system from the outset.
  prefs: []
  type: TYPE_NORMAL
- en: The importance of privacy threat modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Privacy threat modeling offers several key benefits, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Risk identification**: By systematically assessing potential privacy threats,
    organizations can identify and understand the risks they face. This knowledge
    enables them to prioritize privacy controls and allocate resources effectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PbD approach**: Privacy threat modeling encourages a privacy-centric approach
    to system design and development. By integrating privacy considerations early
    on, organizations can save time, effort, and costs that may otherwise be required
    for retrofitting privacy safeguards.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance and accountability**: Privacy regulations and standards, such
    as the GDPR, require organizations to implement privacy measures. Privacy threat
    modeling helps organizations fulfill these requirements by identifying and addressing
    potential compliance gaps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stakeholder trust**: Demonstrating a commitment to privacy protection enhances
    stakeholder trust. Privacy threat modeling provides a systematic way to showcase
    an organization’s dedication to safeguarding individuals’ privacy, leading to
    increased confidence among users (internal and external) and customers. It builds
    a culture of responsible development.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous privacy threat modeling helps clarify the requirements for privacy
    and allows organizations to move toward building standard privacy features and
    patterns. Focusing on proactive issue identification and fixing helps companies
    build a privacy-forward culture.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy threat modeling’s alignment to Privacy by Design principles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Privacy threat modeling involves identifying potential privacy risks and vulnerabilities
    within a system. While it doesn’t directly encompass all PbD principles, it is
    an essential step in implementing those principles effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how privacy threat modeling aligns with different PbD principles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data minimization**: Helps identify areas where data collection might be
    excessive or unnecessary, leading to potential privacy risks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose specification**: Identifies scenarios where collected data might
    be used for unintended purposes, helping to ensure that data use is appropriately
    specified'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consent mechanisms**: Highlights instances where data might be collected
    or used without proper user consent, assisting in designing effective consent
    processes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Access controls**: Identifies potential unauthorized access points, guiding
    the implementation of access controls to prevent unauthorized data exposure'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data encryption**: Reveals vulnerabilities in data storage or transmission
    that could lead to data breaches, informing the need for encryption'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User empowerment**: Helps identify areas where users might lack control over
    their data, prompting the implementation of tools for user data management'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security measures**: Identifies potential security weaknesses that could
    compromise user data, contributing to the implementation of robust security measures'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regular audits and assessments**: Supports ongoing assessments by identifying
    areas of potential vulnerability that require regular monitoring and evaluation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While privacy threat modeling is not a direct substitute for PbD principles,
    it plays a crucial role in shaping the design and development process by identifying
    potential risks and vulnerabilities. The insights gained from threat modeling
    enable organizations to effectively apply PbD principles to address those risks
    and enhance the overall privacy posture of their systems.
  prefs: []
  type: TYPE_NORMAL
- en: Steps in privacy threat modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Performing an effective privacy threat assessment involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Define the system**: Clearly define the scope of the system or application
    under assessment. Identify its components, data flows, and interfaces with other
    systems.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Identify data types**: Determine the types of personal data the system processes
    and stores. Categorize the data based on sensitivity and regulatory requirements.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Identify threat sources**: Enumerate potential threat sources, both internal
    and external, that may attempt to compromise the privacy of the system’s data
    or users.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analyze threat scenarios**: Develop realistic threat scenarios by combining
    threat sources and system components. Consider scenarios that may exploit vulnerabilities
    in data handling, storage, transmission, or user interactions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Assess impact and likelihood**: Evaluate the potential impact and likelihood
    of each threat scenario materializing. Consider the potential harm to individuals,
    regulatory penalties, reputation damage, and other relevant factors.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Identify controls**: Identify and implement appropriate privacy controls
    and safeguards to mitigate identified threats. Consider technical, organizational,
    and procedural measures to address vulnerabilities and protect privacy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Document and communicate**: Document the privacy threat assessment process,
    including identified threats, mitigations, and residual risks. Communicate the
    findings to stakeholders, such as system designers, developers, privacy officers,
    and management, to ensure collective awareness and buy-in.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Review and update**: Regularly review and update the privacy threat assessment
    as the system evolves or new threats emerge.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Privacy threat modeling is an iterative process that should be integrated into
    the organization’s ongoing privacy management practices
  prefs: []
  type: TYPE_NORMAL
- en: Privacy threat modeling frameworks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several privacy threat modeling frameworks available that provide
    structured methodologies and guidelines to assess and mitigate privacy risks effectively.
    Let’s explore some of the widely recognized privacy threat modeling frameworks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**STRIDE (Microsoft)**: The STRIDE framework, originally developed by Microsoft,
    focuses on identifying threats to the security and privacy of a system. It stands
    for the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spoofing identity**: Unauthorized actors masquerade as legitimate users'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tampering with data**: Unauthorized modification or destruction of data'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Repudiation**: Denial of actions or transactions by malicious actors'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Information disclosure**: Unauthorized access to sensitive information'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Denial of service**: Disruption or degradation of system availability'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Elevation of privileg**e: Unauthorized escalation of privileges'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The STRIDE framework helps identify potential privacy threats by considering
    how each threat category could impact the privacy of the system’s users and data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**LINDDUN**: This is a privacy threat modeling framework. It provides a comprehensive
    approach to identify and address privacy concerns. The components of the LINDDUN
    framework are as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Linkability**: Assessing the potential for linking various data points to
    identify individuals'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Identifiability**: Evaluating the extent to which individuals can be identified
    or re-identified from the data'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-repudiation**: Ensuring that actions and transactions cannot be denied'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Detectability**: Assessing the ability to detect privacy breaches or unauthorized
    access'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data disclosure**: Excessively collecting, storing, processing, or sharing
    personal data'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unawareness**: Evaluating the level of user awareness and control over data
    collection and usage'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-compliance**: Identifying risks of non-compliance with privacy regulations
    and standards'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: LINDDUN provides a holistic view of privacy threats and helps organizations
    analyze the impact of these threats on individuals’ privacy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**PLOT4AI**: The **Privacy Library of Threats for Artificial Intelligence**
    (**PLOT4AI**) is a comprehensive resource meticulously crafted to tackle the intricate
    web of privacy concerns entwined with AI technology. Presently, the library comprises
    an assemblage of 86 unique threats, meticulously categorized into eight distinct
    groupings:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Techniques and processes**: This category covers the potential downsides
    stemming from processes or technical maneuvers capable of detrimentally affecting
    individuals'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accessibility**: This aims to rectify the deficiency in the accessibility
    and user-friendliness of AI systems for a diverse range of individuals'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Identifiability and linkability**: This casts a spotlight on threats and
    linking individuals to specific attributes or other individuals, coupled with
    apprehensions surrounding identification'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: This zooms in on the potential perils arising from inadequately
    fortified AI systems and procedures against security vulnerabilities'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Safety**: This concentrates efforts on recognizing perils and shielding individuals
    from plausible harm or jeopardy'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unawareness**: This confronts the issue of neglecting to inform individuals
    and extends to them the chance to intervene'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ethics and human rights**: This illuminates conceivable adverse effects on
    individuals or the harm borne out of an absence of consideration for values and
    principles'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-compliance**: This directs attention toward threats emerging from the
    failure to adhere to data protection laws and other pertinent regulations'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This repository stands as a robust arsenal to empower the AI community and stakeholders
    in safeguarding the paramount importance of privacy as AI continues to unfold
    its potential.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The library introduces a simplified four-phase **development life cycle** (**DLC**)
    approach, aligning with various methodologies, such as SEMMA, CRISP-DM, ASUM-DM,
    TDSP, and MDM. This streamlined approach ensures accessibility for non-technical
    stakeholders while maintaining alignment with established methodologies.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Data flow diagrams** (**DFDs**) are employed as visual representations of
    systems under analysis. PLOT4AI emphasizes the importance of thorough threat modeling
    and suggests using both basic and detailed DFDs for different categories of threats.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Threats are presented in the form of cards, similar to LINDDUN GO, categorized
    by colors and icons representing the threat category and DLC phase. Some threats
    might have multiple category icons or DLC icons, reflecting their diverse impacts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To practically apply PLOT4AI, it can be used as a card game in both physical
    and digital formats. Sessions are timeboxed to maintain engagement and focus,
    involving diverse stakeholders and a facilitator. In the sessions, participants
    are guided through each threat card’s question, discussion, and potential recommendations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By utilizing PLOT4AI, organizations can enhance their privacy practices, mitigate
    risks, streamline processes, and foster collaboration among stakeholders. The
    library’s output can also contribute to data privacy impact assessments and facilitate
    compliance efforts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: While still in development, PLOT4AI offers benefits such as improved processes,
    reduced rework, clearer purpose, and alignment among stakeholders. The resource
    provides valuable insights into humanizing AI through the lens of privacy threat
    modeling.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The company provides an online assessment tool that, through responding to its
    queries, enables individuals to discern the threat model pertinent to the ML systems
    or products they are tasked with enhancing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here is a link to the assessment tool: [https://plot4.ai/assessments/](https://plot4.ai/assessments/).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s deep dive into one of the frameworks, LINDDUN, with a detailed example
    to understand more about privacy threat modeling.
  prefs: []
  type: TYPE_NORMAL
- en: The LINDDUN framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**LINDDUN** is a privacy threat modeling methodology that supports analysts
    in systematically eliciting and mitigating privacy threats in software architectures.
    This framework was developed by privacy experts at KU Leuven.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The LINDDUN framework consists of three main steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Model the system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Elicit threats.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mitigate threats.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 1.\uFEFF2 – LINDDUN framework steps](img/B16573_01_02.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 1.2 – LINDDUN framework steps
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – modeling the system
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this step, it is crucial to gain a comprehensive understanding of the system
    or product being developed, including detailed knowledge of data flows. This entails
    comprehending how data is collected, processed, utilized, retained, and shared,
    as well as identifying the system’s users and their access methods. Additionally,
    it is essential to understand how the system interacts with other systems. To
    facilitate the analysis of privacy threats, LINDDUN employs DFDs as a means of
    capturing system or product knowledge, in the same way that STRIDE (Microsoft’s
    security threat modeling method) is utilized for security threat modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – eliciting and documenting threats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'LINDDUN encompasses seven distinct threat categories that enable the identification
    of threats through the utilization of threat trees. The framework provides the
    following high-level descriptions of these seven threat categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Threat Category** | **Privacy** **Threat Details** |'
  prefs: []
  type: TYPE_TB
- en: '| Linkability | This category involves linking two or more publicly available
    data sets to derive insights. Often, data subjects are unaware that their data
    can be linked with other datasets from the web, leading to the exposure of personal
    information, for instance, linking individuals with similar diseases or linking
    people who visit a specific mall. |'
  prefs: []
  type: TYPE_TB
- en: '| Identifiability | Identifiability refers to the ability to identify specific
    personal information about an individual, such as their email, age, or gender,
    based on other available data through alternative means, for example, identifying
    a consumer based on their transaction data or identifying the readers of a particular
    website. |'
  prefs: []
  type: TYPE_TB
- en: '| Non-repudiation | Non-repudiation ensures that a data subject cannot deny
    their involvement in a particular action. This can apply to instances such as
    social media comments or posts that can be attributed to a specific individual.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Detectability | Detectability involves the ability to determine whether a
    particular item of interest relating to a data subject exists. New personal information
    can often be derived based on the available data, for instance, by analyzing the
    type of social media posts to identify the author and extract further insights.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Disclosure of information | This category pertains to the ability to learn
    the content of a specific item of interest about a data subject. It involves accessing
    and obtaining personal information about an individual. |'
  prefs: []
  type: TYPE_TB
- en: '| Unawareness | Unawareness refers to situations where data subjects are uninformed
    about the collection, processing, storage, or sharing of activities related to
    their personal data, including the corresponding purposes. Examples include collecting
    personal data without user consent, sharing it with third parties, or processing
    the data to generate insights, all without the knowledge of the data subjects.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Non-compliance | Non-compliance arises when systems collect and process personal
    data without adhering to privacy regulations. This can involve actions such as
    collecting data without consent, processing and sharing data without proper encryption,
    or retaining data for a longer period than necessary. These threat categories
    provide a framework for analyzing privacy threats within LINDDUN, enabling a comprehensive
    understanding of potential risks associated with personal data. |'
  prefs: []
  type: TYPE_TB
- en: Table 1.3 – LINDDUN categories at a high level
  prefs: []
  type: TYPE_NORMAL
- en: Step 2a – map DFD elements to threat categories
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Prepare a mapping table for each DFD item in the system and LINDDUN threats:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Data** **Flow Element** | **L** | **I** | **N** | **D** | **D** | **U**
    | **N** |'
  prefs: []
  type: TYPE_TB
- en: '| Entity | X |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Data store | X | X |  |  |  | X | X |'
  prefs: []
  type: TYPE_TB
- en: '| Data flow |  |  | X |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Process | X | X |  | X |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: Table 1.4 – Map between DFD and threat category
  prefs: []
  type: TYPE_NORMAL
- en: Put “X” marks where the DFD element has a potential privacy threat against the
    threat category.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2b – elicit and document threats
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Figure 1.3 – Threat documentation steps](img/B16573_01_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.3 – Threat documentation steps
  prefs: []
  type: TYPE_NORMAL
- en: Use the LINDDUN trees to elicit and document the threats for each DFD category.
    In the preceding example, the **Linkability** category tree consists of the possible
    privacy tree model for data store linkability.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – mitigating threats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this step, identified privacy threats are handled appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3a – prioritize the threats
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Prioritize the threats to privacy as either low, medium, or high risk.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3b – mitigation strategy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For each identified threat, plan for a mitigation strategy. The LINDDUN framework
    provides the following taxonomy of mitigation strategies for privacy threats.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4 – Mitigation strategy for privacy threats](img/B16573_01_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.4 – Mitigation strategy for privacy threats
  prefs: []
  type: TYPE_NORMAL
- en: 'Source: LINDDUN mitigation strategies taxonomy ([https://www.linddun.org/linddun](https://www.linddun.org/linddun))'
  prefs: []
  type: TYPE_NORMAL
- en: Step 3c – select a privacy-enhancing solution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The final step of the framework involves planning a privacy-enhanced solution
    for each threat mitigation strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider a practical example to explain the LINDDUN framework.
  prefs: []
  type: TYPE_NORMAL
- en: Example – social media platform (MyConnect) privacy threat modeling
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this example, we will use the LINDDUN framework to assess the privacy threats
    associated with the social media platform we looked at earlier in this chapter.
    The goal is to identify potential risks and vulnerabilities that may compromise
    user privacy:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linkability**: Linkability refers to the ability to link different data points
    to identify individuals. In the case of a social media platform, linkability threats
    may include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User profile linking**: Assess the extent to which user profiles can be linked
    across different social media platforms or services, potentially revealing more
    information about individuals than intended'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cross-device tracking**: Evaluate the risk of tracking users’ activities
    across multiple devices to create a comprehensive profile and track their online
    behavior'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Identifiability**: Identifiability focuses on the potential for individuals
    to be identified or re-identified from the data. Privacy threats related to identifiability
    may include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**De-anonymization**: Assess the risk of adversaries being able to de-anonymize
    users’ data by combining and analyzing various datasets'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Re-identification attacks**: Evaluate the likelihood of attackers being able
    to re-identify users by linking seemingly anonymous data with external datasets'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-repudiation**: Non-repudiation ensures that actions and transactions
    cannot be denied. In the context of a social media platform, non-repudiation threats
    may include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User content alteration**: Assess the risk of unauthorized modifications
    or the tampering of user-generated content, potentially leading to false attributions
    or denial of user actions'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Account hijacking**: Evaluate the likelihood of malicious actors gaining
    unauthorized access to user accounts and performing actions on behalf of legitimate
    users, leading to the denial of user involvement'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Detectability**: Detectability focuses on the ability to detect privacy breaches
    or unauthorized access. Potential threats in this category for a social media
    platform include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unauthorized access monitoring**: Assess the platform’s ability to detect
    and respond to unauthorized access attempts by malicious actors seeking to obtain
    user data'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data leakage monitoring**: Evaluate the platform’s capability to monitor
    and detect data leakage incidents, such as the unauthorized sharing of user data
    with third parties'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unawareness**: Unawareness refers to the level of user awareness and control
    over data collection and usage. Privacy threats related to unawareness may include
    the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data collection transparency**: Assess the platform’s transparency in informing
    users about the types of data collected, the purposes, and the third parties with
    whom the data is shared'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consent management**: Evaluate the effectiveness of the platform’s consent
    mechanisms in obtaining explicit user consent for data processing activities'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-compliance**: This involves identifying risks of non-compliance with
    privacy regulations and standards. For a social media platform, potential non-compliance
    threats may include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inadequate privacy policies**: Assess the platform’s privacy policies to
    ensure they comply with applicable privacy laws and provide clear information
    to users about data handling practices'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data transfer across jurisdictions**: Evaluate the risks associated with
    data transfers to jurisdictions with differing privacy regulations and assess
    compliance with cross-border data transfer requirements'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By applying the LINDDUN framework to the social media platform example, we can
    identify specific threats and vulnerabilities in each category. This allows the
    organization behind the platform to develop appropriate privacy controls and safeguards
    to mitigate the identified risks, enhancing user privacy protection and compliance
    with privacy regulations.
  prefs: []
  type: TYPE_NORMAL
- en: 'After exploring concepts such as data privacy, privacy threats, and threat
    modeling, it is time to delve into the central focus of this book: privacy-preserving
    ML. In this section, we will discover why it is necessary and explore the various
    technologies associated with privacy-preserving ML.'
  prefs: []
  type: TYPE_NORMAL
- en: The need for privacy-preserving ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Privacy-preserving ML has emerged as a response to the growing concerns about
    data privacy in AI and ML and the need to protect sensitive information while
    leveraging the power of ML algorithms. You will learn about ML and privacy-preserving
    ML techniques in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of the reasons why privacy-preserving ML is necessary:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Protection of sensitive data**: Privacy-preserving ML techniques enable organizations
    to utilize sensitive data without exposing it to potential breaches or unauthorized
    access. By implementing privacy safeguards, organizations can protect sensitive
    information such as PII, medical records, financial data, or proprietary business
    data. You will learn more in *Chapters 5* to *8* on how to protect sensitive data
    using different privacy-preserving technologies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance with privacy regulations**: Many jurisdictions have enacted strict
    privacy regulations and data protection laws, such as the European Union’s **GDPR**
    and the **CCPA**. Privacy-preserving ML techniques help organizations comply with
    these regulations by ensuring that user data is processed in a privacy-conscious
    manner.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preserving user trust**: Privacy breaches and data misuse incidents can severely
    damage user trust in organizations that handle personal data. By adopting privacy-preserving
    ML techniques, organizations demonstrate their commitment to protecting user privacy,
    thereby enhancing trust and fostering long-term relationships with customers or
    users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collaboration and data sharing**: Privacy-preserving ML techniques enable
    secure collaboration and data sharing among multiple organizations. These techniques
    allow organizations to combine their datasets without directly exposing sensitive
    information, facilitating joint research, and achieving collective insights while
    respecting data privacy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fairness and bias mitigation**: Privacy-preserving ML can also contribute
    to addressing issues related to fairness and bias in ML models. By applying privacy
    techniques, organizations can protect sensitive attributes and mitigate the risk
    of discrimination based on factors such as race, gender, or ethnicity, thus promoting
    fairness in ML applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Confidentiality in healthcare and research**: In domains such as healthcare
    and research, privacy-preserving ML techniques are crucial for maintaining the
    confidentiality of sensitive medical records and personal health information.
    These techniques allow healthcare providers and researchers to extract valuable
    insights from aggregated data while preserving patient privacy. You will learn
    more about aggregated datasets, privacy issues, and how to protect sensitivity
    and privacy of the individuals in *Chapters 3* and *4*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Protection against insider threats**: Privacy-preserving ML techniques can
    help safeguard against insider threats by reducing the risk of unauthorized access
    to sensitive data by individuals within the organization. These techniques enable
    organizations to limit access to sensitive information and ensure that the privacy
    of users or customers is maintained, even within their own workforce. You will
    learn more about insider threats in [*Chapter 9*](B16573_09.xhtml#_idTextAnchor204).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Privacy-preserving ML techniques are essential for organizations to strike a
    balance between utilizing data for valuable insights and preserving the privacy
    of individuals.
  prefs: []
  type: TYPE_NORMAL
- en: By adopting these techniques, organizations can comply with privacy regulations,
    maintain user trust, foster collaboration, and promote fairness in ML applications
    while protecting sensitive information from unauthorized access or misuse.
  prefs: []
  type: TYPE_NORMAL
- en: Case study – privacy-preserving ML in financial institutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Financial institutions handle large volumes of sensitive customer data, including
    personal and financial information. As ML techniques become more prevalent in
    the financial sector, the need to protect customer privacy while deriving insights
    from this data becomes critical. This case study examines a real-world scenario
    highlighting the necessity for privacy-preserving ML in financial institutions.
  prefs: []
  type: TYPE_NORMAL
- en: Case study description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'ARDHA Bank (a fictional bank for illustration purposes), a leading global bank,
    aims to leverage ML algorithms to improve its fraud detection capabilities. The
    bank possesses a vast amount of transaction data, including credit card transactions,
    account activities, and customer profiles. However, ensuring the privacy and confidentiality
    of customer data is a top priority for ARDHA Bank. To address this concern, ARDHA
    Bank is exploring the adoption of the following privacy-preserving ML techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Differential privacy**: ARDHA Bank adopts differential privacy techniques
    to protect customer privacy during the training of ML models. Differential privacy
    adds noise or perturbation to data to ensure that individual customer information
    remains obfuscated while still allowing accurate model training and analysis.
    You will learn more about differential privacy in *Chapters 3* to *5*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secure data aggregation**: To gather insights from customer data without
    exposing individual-level details, ARDHA Bank employs secure data aggregation
    techniques. This allows the bank to extract meaningful statistical information
    from the data while preserving customer privacy. Aggregated data can be used to
    train ML models without revealing sensitive information about specific customers.
    You will learn more about this in [*Chapter 4*](B16573_04.xhtml#_idTextAnchor079).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Federated learning**: ARDHA Bank implements federated learning, a privacy-preserving
    technique, to train ML models across multiple distributed data sources. Customer
    data remains decentralized and encrypted, allowing local models to be trained
    locally on each data source without sharing raw data. The trained models are then
    combined and aggregated to create a global model without exposing individual data.
    You will learn more about federated learning in *Chapters 6* and *7*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Encrypted inference**: When performing fraud detection or other ML tasks
    in real time, ARDHA Bank employs encrypted inference techniques. By using homomorphic
    encryption or secure multi-party computation, the bank can execute ML models on
    encrypted customer data without decrypting it. This ensures that sensitive information
    remains protected during the prediction phase. You will learn more about this
    in [*Chapter 8*](B16573_08.xhtml#_idTextAnchor158).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benefits and outcomes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ARDHA Bank has implemented privacy-preserving techniques to ensure the security
    of customer data. They use methods such as differential privacy, secure data aggregation,
    federated learning, and encrypted inference to protect individual customer information
    during the ML process. Despite this focus on privacy, the bank has developed effective
    fraud detection models by analyzing aggregated and anonymized data, enabling them
    to identify fraudulent patterns while respecting individual privacy. These efforts
    also ensure compliance with data protection regulations such as the GDPR and financial
    industry standards. By valuing customer privacy, ARDHA Bank builds trust, enhances
    its reputation, and strengthens customer relationships. The bank’s approach showcases
    the significance of safeguarding customer data while making use of advanced analytics
    in the financial sector.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy-preserving ML has equal significance in other domains as well, such
    as healthcare, education, and social networking.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To summarize, we have acquired a high-level understanding of privacy, data privacy,
    PbD concepts, and privacy threat modeling. Furthermore, we have explored the importance
    of privacy-preserved ML through a case study.
  prefs: []
  type: TYPE_NORMAL
- en: Moving forward, the next chapter will provide a brief overview of different
    types of ML (supervised and unsupervised) and the phases involved in ML (data
    extraction, data preparation, model development, model deployment, and inferencing).
    Additionally, we will examine the privacy threats and attacks associated with
    each phase.
  prefs: []
  type: TYPE_NORMAL
