- en: '*Chapter 1*: Introducing MLflow'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**MLflow** is an open source platform for the **machine learning** (**ML**)
    life cycle, with a focus on *reproducibility*, *training*, and *deployment*. It
    is based on an open interface design and is able to work with any language or
    platform, with clients in Python and Java, and is accessible through a REST API.
    Scalability is also an important benefit that an ML developer can leverage with
    MLflow.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter of the book, we will take a look at how MLflow works, with the
    help of examples and sample code. This will build the necessary foundation for
    the rest of the book in order to use the concept to engineer an end-to-end ML
    project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will look at the following sections in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What is MLflow?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started with MLflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring MLflow modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following prerequisites:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The latest version of Docker installed in your machine. In case you don''t
    have the latest version, please follow the instructions at the following URL:
    [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a bash terminal (Linux or Windows).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a browser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3.5+ installed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PIP installed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is MLflow?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implementing a product based on ML can be a laborious task. There is a general
    need to reduce the friction between different steps of the ML development life
    cycle, and between teams of data scientists and engineers that are involved in
    the process.
  prefs: []
  type: TYPE_NORMAL
- en: ML practitioners, such as data scientists and ML engineers, operate with different
    systems, standards, and tools. While data scientists spend most of their time
    developing models in tools such as Jupyter Notebooks, when running in production,
    the model is deployed in the context of a software application with an environment
    that is more demanding in terms of scale and reliability.
  prefs: []
  type: TYPE_NORMAL
- en: 'A common occurrence in ML projects is to have the models reimplemented by an
    engineering team, creating a custom-made system to serve the specific model. A
    set of challenges are common with teams that follow bespoke approaches regarding
    model development:'
  prefs: []
  type: TYPE_NORMAL
- en: ML projects that run over budget due to the need to create bespoke software
    infrastructure to develop and serve models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translation errors when reimplementing the models produced by data scientists
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability issues when serving predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Friction in terms of reproducing training processes between data scientists
    due to a lack of standard environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Companies leveraging ML tend to create their own (often extremely laborious)
    internal systems in order to ensure a smooth and structured process of ML development.
    Widely documented ML platforms include systems such as Michelangelo and FBLearner,
    from Uber and Facebook, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: It is in the context of the increasing adoption of ML that MLflow was initially
    created at Databricks and open sourced as a platform, to aid in the implementation
    of ML systems.
  prefs: []
  type: TYPE_NORMAL
- en: MLflow enables an everyday practitioner in one platform to manage the ML life
    cycle, from iteration on model development up to deployment in a reliable and
    scalable environment that is compatible with modern software system requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we will install MLflow on your machine and prepare it for use in this
    chapter. You will have two options when it comes to installing MLflow. The first
    option is through a Docker container-based recipe provided in the repository of
    the book: [https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Mlflow.git](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Mlflow.git).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To install it, follow these instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following commands to install the software:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The Docker image is very simple at this stage: it simply contains MLflow and
    sklearn, the main tools to be used in this chapter of the book. For illustrative
    purposes, you can look at the content of the `Dockerfile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To build the image, you should now run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Right after building the image, you can run the `./run.sh` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It is important to ensure that you have the latest version of Docker installed
    on your machine.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Open your browser to [http://localhost:888](http://localhost:888) and you should
    be able to navigate to the `Chapter01` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following section, we will be developing our first model with MLflow
    in the Jupyter environment created in the previous set of steps.
  prefs: []
  type: TYPE_NORMAL
- en: Developing your first model with MLflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the point of view of simplicity, in this section, we will use the built-in
    sample datasets in sklearn, the ML library that we will use initially to explore
    MLflow features. For this section, we will choose the famous `Iris` dataset to
    train a multi-class classifier using MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Iris dataset (one of sklearn''s built-in datasets available from [https://scikit-learn.org/stable/datasets/toy_dataset.html](https://scikit-learn.org/stable/datasets/toy_dataset.html))
    contains the following elements as features: sepal length, sepal width, petal
    length, and petal width. The target variable is the class of the iris: Iris Setosa,
    Iris Versocoulor, or Iris Virginica:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the sample dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, let's train your model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Training a simple machine model with a framework such as scikit-learn involves
    instantiating an estimator such as `LogisticRegression` and calling the `fit`
    command to execute training over the `Iris` dataset built in scikit-learn:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding lines of code are just a small portion of the ML **Engineering**
    process. As will be demonstrated, a non-trivial amount of code needs to be created
    in order to productionize and make sure that the preceding training code is usable
    and reliable. One of the main objectives of MLflow is to aid in the process of
    setting up ML systems and projects. In the following sections, we will demonstrate
    how MLflow can be used to make your solutions robust and reliable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Then, we will add MLflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With a few more lines of code, you should be able to start your first MLflow
    interaction. In the following code listing, we start by importing the `mlflow`
    module, followed by the `LogisticRegression` class in scikit-learn. You can use
    the accompanying Jupyter notebook to run the next section:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `mlflow.sklearn.autolog()` instruction enables you to automatically log
    the experiment in the local directory. It captures the metrics produced by the
    underlying ML library in use. **MLflow Tracking** is the module responsible for
    handling metrics and logs. By default, the metadata of an MLflow run is stored
    in the local filesystem.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If you run the following excerpt on the accompanying notebook''s root document,
    you should now have the following files in your home directory as a result of
    running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `mlruns` folder is generated alongside your notebook folder and contains
    all the experiments executed by your code in the current context.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `mlruns` folder will contain a folder with a sequential number identifying
    your experiment. The outline of the folder will appear as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So, with very little effort, we have a lot of traceability available to us,
    and a good foundation to improve upon.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Your experiment is identified as `UUID` on the preceding sample by `46dc6db17fb5471a9a23d45407da680f`.
    At the root of the directory, you have a `yaml` file named `meta.yaml`, which
    contains the content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the basic metadata of your experiment, with information including start
    time, end time, identification of the run (`run_id` and `run_uuid`), an assumption
    of the life cycle stage, and the user who executed the experiment. The settings
    are basically based on a default run, but provide valuable and readable information
    regarding your experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `model.pkl` file contains a serialized version of the model. For a scikit-learn
    model, there is a binary version of the Python code of the model. Upon autologging,
    the metrics are leveraged from the underlying machine library in use. The default
    packaging strategy was based on a `conda.yaml` file, with the right dependencies
    to be able to serialize the model.
  prefs: []
  type: TYPE_NORMAL
- en: The `MLmodel` file is the main definition of the project from an MLflow project
    with information related to how to run inference on the current model.
  prefs: []
  type: TYPE_NORMAL
- en: The `metrics` folder contains the training score value of this particular run
    of the training process, which can be used to benchmark the model with further
    model improvements down the line.
  prefs: []
  type: TYPE_NORMAL
- en: The `params` folder on the first listing of folders contains the default parameters
    of the logistic regression model, with the different default possibilities listed
    transparently and stored automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring MLflow modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MLflow modules are software components that deliver the core features that aid
    in the different phases of the ML life cycle. MLflow features are delivered through
    modules, extensible components that organize related features in the platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the built-in modules in MLflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '**MLflow Tracking**: Provides a mechanism and UI to handle metrics and artifacts
    generated by ML executions (training and inference)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mlflow Projects**: A package format to standardize ML projects'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mlflow Models**: A mechanism that deploys to different types of environments,
    both on-premises and in the cloud'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mlflow Model Registry**: A module that handles the management of models in
    MLflow and its life cycle, including state'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In order to explore the different modules, we will install MLflow in your local
    environment using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It is crucial that the technical requirements are correctly installed on your
    local machine to allow you to follow along. You can also use the `pip` command
    with the required permissions.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring MLflow projects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An MLflow project represents the basic unit of organization of ML projects.
    There are three different environments supported by MLflow projects: the Conda
    environment, Docker, and the local system.'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Model details of the different parameters available on an MLProject file can
    be consulted in the official documentation available at [https://www.mlflow.org/docs/latest/projects.html#running-projects](https://www.mlflow.org/docs/latest/projects.html#running-projects).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of an `MLproject` file of a `conda` environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In the `conda` option, the assumption is that there is a `conda.yaml` file with
    the required dependencies. MLflow, when asked to run the project, will start the
    environment with the specified dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'The system-based environment will look like the following; it''s actually quite
    simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The preceding system variant will basically rely on the local environment dependencies,
    assuming that the underlying operating system contains all the dependencies. This
    approach is particularly prone to library conflicts with the underlying operating
    system; it might be valuable in contexts where there is already an existing operating
    system environment that fits the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a Docker environment-based `MLproject` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Once you have your environment, the main file that defines how your project
    should look is the `MLProject` file. This file is used by MLflow to understand
    how it should run your project.
  prefs: []
  type: TYPE_NORMAL
- en: Developing your first end-to-end pipeline in MLflow
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will prototype a simple stock prediction project in this section with MLflow
    and will document the different files and phases of the solution. You will develop
    it in your local system using the MLflow and Docker installed locally.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we are assuming that MLflow and Docker are installed locally,
    as the steps in this section will be executed in your local environment.
  prefs: []
  type: TYPE_NORMAL
- en: The task in this illustrative project is to create a basic MLflow project and
    produce a working baseline ML model to predict, based on market signals over a
    certain number of days, whether the stock market will go up or down.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will use a Yahoo Finance dataset available for quoting the
    BTC-USD pair in [https://finance.yahoo.com/quote/BTC-USD/](https://finance.yahoo.com/quote/BTC-USD/)
    over a period of 3 months. We will train a model to predict whether the quote
    will be going up or not on a given day. A REST API will be made available for
    predictions through MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will illustrate, step by step, the creation of an MLflow project to train
    a classifier on stock data, using the Yahoo API for financial information retrieved
    using the package''s pandas data reader:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add your `MLProject` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding `MLProject` file specifies that dependencies will be managed in
    Docker with a specific image name. MLflow will try to pull the image using the
    version of Docker installed on your system. If it doesn't find it, it will try
    to retrieve it from Docker Hub. For the goals of this chapter, it is completely
    fine to have MLflow running on your local machine.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The second configuration that we add to our project is the main entry point
    command. The command to be executed will invoke in the Docker environment the
    `train.py` Python file, which contains the code of our project.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Add a Docker file to the project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Additionally, you can specify the Docker registry URL of your image. The advantage
    of running Docker is that your project is not bound to the Python language, as
    we will see in the advanced section of this book. The MLflow API is available
    in a Rest interface alongside the official clients: Python, Java, and R:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding Docker image file is based on the open source package Miniconda,
    a free minimal installer with a minimal set of packages for data science that
    allow us to control the details of the packages that we need in our environment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We will specify the version of MLflow (our ML platform), `numpy`, and `scipy`
    for numerical calculations. `Cloudpickle` allows us to easily serialize objects.
    We will use `pandas` to manage data frames, and `pandas_datareader` to allow us
    to easily retrieve the data from public sources.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Import the packages required for the project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the following listing, we explicitly import all the libraries that we will
    use during the execution of the training script: the library to read the data,
    and the different `sklearn` modules related to the chosen initial ML model:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We explicitly chose for the stock market movement detection problem a `RandomForestClassifier`,
    due to the fact that it's an extremely versatile and widely accepted baseline
    model for classification problems.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Acquire your training data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The component of the code that acquires the Yahoo Finance stock dataset is intentionally
    small, so we choose a specific interval of 3 months to train our classifier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `acquire_training_data` method returns a `pandas` data frame with the relevant
    dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The format of the data acquired is the classic format for financial securities
    in exchange APIs. For every day of the period, we retrieve the following data:
    the highest value of the stock, the lowest, opening, and close values of the stock,
    as well as the volume. The final column represents the adjusted close value, the
    value after dividends, and splits:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.1 – Excerpt from the acquired data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/image001.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.1 – Excerpt from the acquired data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Figure 1.2* is illustrative of the target variable that we would like to achieve
    by means of the current data preparation process:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.2 – Excerpt from the acquired data with the prediction column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/image002.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.2 – Excerpt from the acquired data with the prediction column
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make the data usable by scikit-learn.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The data acquired in the preceding step is clearly not directly usable by `RandomForestAlgorithm`,
    which thrives on categorical features. In order to facilitate the execution of
    this, we will transform the raw data into a feature vector using the rolling window
    technique.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Basically, the feature vector for each day becomes the deltas between the current
    and previous window days. In this case, we use the previous day''s market movement
    (1 for a stock going up, 0 otherwise):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following example is illustrative of the data frame output produced with
    the binarized ups and downs of the previous days:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.3 – Feature vector with binarized market ups and downs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/image003.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.3 – Feature vector with binarized market ups and downs
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Train and store your model in MLflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This portion of the following code listing calls the data preparation methods
    declared previously and executes the prediction process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The main execution also explicitly logs the ML model trained in the current
    execution in the MLflow environment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `mlflow.sklearn.log_model(clf, "model_random_forest")` method takes care
    of persisting the model upon training. In contrast to the previous example, we
    are explicitly asking MLflow to log the model and the metrics that we find relevant.
    This flexibility in the items to log allows one program to log multiple models
    into MLflow.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the end, your project layout should look like the following, based on the
    files created previously:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Build your project's Docker image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In order to build your Docker image, you should run the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '---> 268cb080fed2'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Successfully built 268cb080fed2
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Successfully tagged stockpred:latest
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run your project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In order to run your project, you can now run the MLflow project:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look similar to the excerpt presented here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This contains a printout of your model, the ID of your experiment, and the metrics
    captured during the current run.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: At this stage, you have a simple, reproducible baseline of a stock predictor
    pipeline using MLflow that you can improve on and easily share with others.
  prefs: []
  type: TYPE_NORMAL
- en: Re-running experiments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another extremely useful feature of MLflow is the ability to re-run a specific
    experiment with the same parameters as it was run with originally.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, you should be able to run your previous project by specifying
    the GitHub URL of the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Basically, what happens with the previous command is that MLflow clones the
    repository to a temporary directory and executes it, according to the recipe on
    MLProject.
  prefs: []
  type: TYPE_NORMAL
- en: The ID of the experiment (or the name) allows you to run the project with the
    original parameters, thereby enabling complete reproducibility of the project.
  prefs: []
  type: TYPE_NORMAL
- en: The MLflow projects feature allows your project to run in advanced cloud environments
    such as Kubernetes and Databricks. Scaling your ML job seamlessly is one of the
    main selling points of a platform such as MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: As you have seen from the current section, the **MLflow project** module allows
    the execution of a reproducible ML job that is treated as a self-contained project.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring MLflow tracking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **MLflow tracking** component is responsible for observability. The main
    features of this module are the logging of metrics, artifacts, and parameters
    of an MLflow execution. It provides vizualisations and artifact management features.
  prefs: []
  type: TYPE_NORMAL
- en: In a production setting, it is used as a centralized tracking server implemented
    in Python that can be shared by a group of ML practitioners in an organization.
    This enables improvements in ML models to be shared within the organization.
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 1.4*, you can see an interface that logs all the runs of your model
    and allows you to log your experiment's observables (metrics, files, models and
    artifacts). For each run, you can look and compare the different metrics and parameters
    of your module.
  prefs: []
  type: TYPE_NORMAL
- en: It addresses common pain points when model developers are comparing different
    iterations of their models on different parameters and settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot presents the different metrics for our last run of
    the previous model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4 – Sample of the MLFlow interface/UI'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image004.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.4 – Sample of the MLFlow interface/UI
  prefs: []
  type: TYPE_NORMAL
- en: 'MLflow allows the inspection of arbitrary artifacts associated with each model
    and its associated metadata, allowing metrics of different runs to be compared.
    You can see the RUN IDs and the Git hash of the code that generated the specific
    run of your experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.5 – Inspecting logged model artifacts'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image005.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.5 – Inspecting logged model artifacts
  prefs: []
  type: TYPE_NORMAL
- en: 'In your current directory of `stockpred`, you can run the following command
    to have access to the results of your runs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the MLflow UI locally will make it available at the following URL:
    [http://127.0.0.1:5000/](http://127.0.0.1:5000/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the particular case of the runs shown in the following screenshot, we have
    a named experiment where the parameter of the size of the window in the previous
    example was tweaked. Clear differences can be seen between the performance of
    the algorithms in terms of F1 score:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6 – Listing of MLflow runs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image006.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.6 – Listing of MLflow runs
  prefs: []
  type: TYPE_NORMAL
- en: 'Another very useful feature of MLFlow tracking is the ability to compare between
    different runs of jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.7 – Comparison of F1 metrics of job runs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image007.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.7 – Comparison of F1 metrics of job runs
  prefs: []
  type: TYPE_NORMAL
- en: This preceding visualization allows a practitioner to make a decision as to
    which model to use in production or whether to iterate further.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring MLflow Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**MLflow Models** is the core component that handles the different model flavors
    that are supported in MLflow and intermediates the deployment into different execution
    environments.'
  prefs: []
  type: TYPE_NORMAL
- en: We will now delve into the different models supported in the latest version
    of MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the *Getting started with MLflow* section, MLflow models have a
    specific serialization approach for when the model is persisted in its internal
    format. For example, the serialized folder of the model implemented on the `stockpred`
    project would look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Internally, MLflow sklearn models are persisted with the `conda` files with
    their dependencies at the moment of being run and a pickled model as logged by
    the source code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: MLflow, by default, supports serving models in two flavors, namely, as a `python_function`
    or in `s``klearn` format. The flavors are basically a format to be used by tools
    or environments serving models.
  prefs: []
  type: TYPE_NORMAL
- en: 'A good example of using the preceding is being able to serve your model without
    any extra code by executing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'You have access to a very simple web server that can run your model. Your model
    prediction interface can be executed by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The response to the API call to our model was `1`; as defined in our predicted
    variable, this means that in the next reading, the stock will move up.
  prefs: []
  type: TYPE_NORMAL
- en: The final few steps outline how powerful MLflow is as an end-to-end tool for
    model development, including for the prototyping of REST-based APIs for ML services.
  prefs: []
  type: TYPE_NORMAL
- en: The MLflow Models component allows the creation of custom-made Python modules
    that will have the same benefits as the built-in models, as long as a prediction
    interface is followed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the notable model types supported will be explored in upcoming chapters,
    including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost model format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: R functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: H2O model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyTorch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sklearn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spark MLib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fastai
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for the most prevalent ML types of models, combined with its built-in
    capability for on-premises and cloud deployment, is one of the strongest features
    of MLflow Models. We will explore this in more detail in the deployment-related
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring MLflow Model Registry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The model registry component in MLflow gives the ML developer an abstraction
    for model life cycle management. It is a centralized store for an organization
    or function that allows models in the organization to be shared, created, and
    archived collaboratively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The management of the model can be made with the different APIs of MLflow and
    with the UI. *Figure 1.7* demonstrates the Artifacts UI in the tracking server
    that can be used to register a model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.8 – Registering a model as an artifact'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image008.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.8 – Registering a model as an artifact
  prefs: []
  type: TYPE_NORMAL
- en: 'Upon registering the model, you can annotate the registered model with the
    relevant metadata and manage its life cycle. One example is to have models in
    a staging pre-production environment and manage the life cycle by sending the
    model to production:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.9 – Managing different model versions and stages'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image009.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.9 – Managing different model versions and stages
  prefs: []
  type: TYPE_NORMAL
- en: The model registry module will be explored further in the book, with details
    on how to set up a centralized server and manage ML model life cycles, from conception
    through to phasing out a model.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced MLflow, and explored some of the motivation behind
    adopting a ML platform to reduce the time from model development to production
    in ML development. With the knowledge and experience acquired in this chapter,
    you can start improving and making your ML development workflow reproducible and
    trackable.
  prefs: []
  type: TYPE_NORMAL
- en: 'We delved into each of the important modules of the platform: projects, models,
    trackers, and model registry. A particular emphasis was given to practical examples
    to illustrate each of the core capabilities, allowing you to have a hands-on approach
    to the platform. MLflow offers multiple out-of-the-box features that will reduce
    friction in the ML development life cycle with minimum code and configuration.
    Out-of-the-box metrics management, model management, and reproducibility are provided
    by MLflow.'
  prefs: []
  type: TYPE_NORMAL
- en: We will build on this introductory knowledge and expand our skills and knowledge
    in terms of building practical ML platforms in the rest of the chapters.
  prefs: []
  type: TYPE_NORMAL
- en: We briefly introduced in this chapter the use case of stock market prediction,
    which will be used in the rest of the book. In the next chapter, we will focus
    on defining rigorously the ML problem of stock market prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to enhance your knowledge, you can consult the documentation available
    at the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Reference information for MLflow is available here: [https://www.mlflow.org/docs/latest/](https://www.mlflow.org/docs/latest/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Review notes on ML platforms: [https://medium.com/nlauchande/review-notes-of-ml-platforms-uber-michelangelo-e133eb6031da](https://medium.com/nlauchande/review-notes-of-ml-platforms-uber-michelangelo-e133eb6031da)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MLflow technical paper: [https://www-cs.stanford.edu/people/matei/papers/2018/ieee_mlflow.pdf](https://www-cs.stanford.edu/people/matei/papers/2018/ieee_mlflow.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
