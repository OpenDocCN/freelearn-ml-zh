["```py\nfrom collections import Counter\nfrom sklearn.datasets import make_classification\nX, y = make_classification(n_samples=10000, n_features=2,\\\n    n_redundant=0, n_classes=2, flip_y=0, n_clusters_per_class=2,\\\n    class_sep=0.79, weights=[0.99], random_state=81)\n```", "```py\nfrom imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(sampling_strategy=1.0, random_state=42)\nX_res, y_res = ros.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))\n```", "```py\nResampled dataset shape Counter({0: 9900, 1: 9900})\n```", "```py\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=0)\nX_res, y_res = sm.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))\n```", "```py\nResampled dataset shape Counter({0: 9900, 1: 9900})\n```", "```py\nprint(\"Before: \", sorted(Counter(y).items()))\nfrom imblearn.over_sampling import BorderlineSMOTE\nX_resampled, y_resampled = BorderlineSMOTE().fit_resample(X, y)\nprint(\"After: \", sorted(Counter(y_resampled).items()))\n```", "```py\nBefore: [(0, 9900), (1, 100)]\nAfter:  [(0, 9900), (1, 9900)]\n```", "```py\nfrom imblearn.over_sampling import ADASYN\nX_resampled, y_resampled = ADASYN().fit_resample(X, y)\nprint(sorted(Counter(y_resampled).items()))\n```", "```py\n[(0, 9900), (1, 9900)]\n```", "```py\n    from imblearn.over_sampling import RandomOverSampler\n    X_cat_mix = np.array([[\"abc\", 1], [\"def\", 2],\\\n        [\"ghi\", 3]], dtype=object)\n    y_cat_mix = np.array([0, 0, 1])\n    print('X_cat_mix:', X_cat_mix, '\\n y_cat_mix: ', y_cat_mix)\n    X_resampled, y_resampled = RandomOverSampler().fit_resample(\\\n        X_cat_mix, y_cat_mix)\n    print('X_resampled:', X_resampled, '\\n y_resampled: ',\\\n        y_resampled)\n    ```", "```py\n    X_cat_mix: [['abc' 1]\n     ['def' 2]\n     ['ghi' 3]]\n     y_cat_mix:  [0 0 1]\n    X_resampled: [['abc' 1]\n     ['def' 2]\n     ['ghi' 3]\n     ['ghi' 3]]\n     y_resampled:  [0 0 1 1]\n    ```", "```py\n    from imblearn.over_sampling import SMOTENC\n    X_cat_mix = np.array([[\"small\", 1],\\\n        [\"medium\", 2],\\\n        [\"large\", 3],\\\n        [\"large\", 4],\\\n        [\"large\", 5]], dtype=object)\n    y_cat_mix = np.array([0, 0, 1, 0, 1])\n    print('X_cat_mix:', X_cat_mix, '\\n y_cat_mix: ', y_cat_mix)\n    X_resampled, y_resampled = SMOTENC(\n        categorical_features=[0], k_neighbors=1, random_state=1\n    ).fit_resample(X_cat_mix, y_cat_mix)\n    print('X_resampled:', X_resampled, '\\ny_resampled: ', \\\n        y_resampled)\n    ```", "```py\n    X_cat_mix: [['small' 1]\n               ['medium' 2]\n               ['large' 3]\n               ['large' 4]\n               ['large' 5]]\n    y_cat_mix: [0 0 1 0 1]\n    X_resampled: [['small' 1.0]\n                 ['medium' 2.0]\n                 ['large' 3.0]\n                 ['large' 4.0]\n                 ['large' 5.0]\n                 ['large' 3.005630378122263]]\n    y_resampled:  [0 0 1 0 1 1]\n    ```", "```py\n    from imblearn.over_sampling import SMOTEN\n    X_original = np.array([[\"abc\"], \\\n                           [\"def\"], \\\n                           [\"ghi\"], \\\n                           [\"ghi\"], \\\n                           [\"ghi\"]], dtype=object)\n    y_original = np.array([0, 0, 1, 1, 1])\n    print('X_original:', X_original, '\\ny_original: ', y_original)\n    X_resampled, y_resampled = \\\n        SMOTEN(k_neighbors=1).fit_resample(X_original, y_original)\n    print('X_resampled:', X_resampled, '\\ny_resampled:', \\\n        y_resampled)\n    ```", "```py\n    X_original: [['abc']\n                 ['def']\n                 ['ghi']\n                 ['ghi']\n                 ['ghi']]\n    y_original:  [0 0 1 1 1]\n    X_resampled: [['abc']\n                  ['def']\n                  ['ghi']\n                  ['ghi']\n                  ['ghi']\n                  ['abc']]\n    y_resampled:  [0 0 1 1 1 0]\n    ```", "```py\nX, y = make_classification(n_classes=3, class_sep=2, \\\n    weights=[0.1, 0.4, 0.5], n_clusters_per_class=1, \\\n    n_samples=100, random_state=10)\nprint('Original dataset shape %s' % Counter(y))\n```", "```py\nOriginal dataset shape Counter({2: 50, 1: 40, 0: 10})\n```", "```py\nover_sampler = SMOTE(sampling_strategy='minority')\nX_res, y_res = over_sampler.fit_resample(X, y)\nprint('Resampled dataset shape using minority strategy: %s'% \\\n    Counter(y_res))\n```", "```py\nResampled dataset shape using minority strategy: Counter({0: 50, 2: 50, 1: 40})\n```", "```py\nprint('Original dataset shape %s' % Counter(y))\nover_sampler = SMOTE(sampling_strategy={\n                             0 : 40,\n                             1 : 40,\n                             2 : 50})\nX_res, y_res = over_sampler.fit_resample(X, y)\nprint('Resampled dataset shape using dict strategy: %s\\n'% \\\n    Counter(y_res))\n```", "```py\nOriginal dataset shape Counter({2: 50, 1: 40, 0: 10})\nResampled dataset shape using dict strategy:\n         Counter({2: 50, 0: 40, 1: 40})\n```"]