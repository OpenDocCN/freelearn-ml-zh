<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Image Classification and Detection with SageMaker</h1>
                </header>
            
            <article>
                
<p class="mce-root">We have studied a type of deep learning algorithm called a <strong>Convolutional Neural Network</strong> (<strong>CNN</strong>), which is capable of classifying images. However, implementing such an algorithm in practice is extremely complex and requires a lot of expertise. <span>Amazon </span>SageMaker offers features that allow you to train machine learning models such as image classification algorithms using deep learning capabilities. </p>
<p>We'll cover the following topics in this chapter:</p>
<ul>
<li>Introducing Amazon SageMaker for image classification</li>
<li>Training a deep learning model using Amazon SageMaker  </li>
<li>Classifying images using Amazon SageMaker</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing Amazon SageMaker for image classification</h1>
                </header>
            
            <article>
                
<p>The<span> field of data science has been revolutionized because of services such as Tensorflow and SageMaker. C</span><span>omplex algorithms, such as Deep learning, were only accessible to large corporations and research labs in the past. However, thanks to services such as SageMaker, anyone who can write code to call these services can train and use sophisticated machine learning algorithms. This has enabled teenagers, with a working knowledge of machine learning, to create applications that can perform complex machine learning tasks. You will have the power to perform machine learning tasks at the same level as the world's top scientists by accessing state-of-the-art machine learning models in SageMaker marketplac</span><span>e. </span></p>
<p class="mce-root"/>
<p>Amazon SageMaker offers a large number of algorithms that data scientists can use to train their machine learning models, and it also offers tools to generate predictions on a batch of test data or create an endpoint to use the model as a service. When we work on smaller test datasets, we can use Python machine learning libraries, such as <kbd>scikit-learn</kbd>. However, when we are working on a larger dataset, we have to rely on frameworks, such as Apache Spark, and use the libraries, such as <kbd>MLLib</kbd>.</p>
<p>Amazon offers a suite of machine learning libraries in SageMaker where we can use pre-tuned models from various vendors to train our machine learning models. Hence, when you are working on a problem, you can search the Amazon SageMaker marketplace to find algorithms that are already available. If there are multiple algorithms and models available from different vendors, you can choose between algorithms based on their pricing models and accuracy.  </p>
<p>The SageMaker marketplace can be used to select models offered by vendors other than Amazon. Hence, if you need a specialized algorithm that is tuned to functions in the field of genetic engineering or a specialized version of an image classification algorithm, such as <strong>Construction-worker Detector</strong>, you can select one of the pre-trained models and directly get predictions. </p>
<p>Amazon SageMaker also offers jobs to tune parameters of the algorithms that are available in the marketplace so that they can be adapted to your cluster size and applications. Such jobs are called <strong>Hyperparameter-tuning Jobs</strong>. You can provide various values of parameters to check an algorithm. Amazon SageMaker can then automatically train to select what tuning parameters would work best for your application. You can also set the values of these parameters manually.</p>
<p>In this chapter, we'll present how to use Amazon SageMaker using an example of an image classifier. This algorithm learns from a labeled set of images and then detects objects in the testing dataset by assigning a probability of the existence of each object in the test image. For this test, we use a publicly available dataset called <kbd>Caltech265</kbd> (<a href="http://www.vision.caltech.edu/Image_Datasets/Caltech256/">http://www.vision.caltech.edu/Image_Datasets/Caltech256/</a>). This dataset contains 30,608 images. The dataset is labeled with 256 objects. </p>
<div class="packt_infobox">Please download the following dataset files to your AWS S3 bucket: <a href="http://data.mxnet.io/data/caltech-256/caltech-256-60-train.rec">http://data.mxnet.io/data/caltech-256/caltech-256-60-train.rec</a>  and   <a href="http://data.mxnet.io/data/caltech-256/caltech-256-60-val.rec">http://data.mxnet.io/data/caltech-256/caltech-256-60-val.rec</a></div>
<p>For the purpose of our experiment, we'll store the training data files in the AWS bucket under the <kbd>image-classification-full-training/train</kbd> folder. This file contains <span class="s2">15,420 </span>image files that are resized to 224 x 224 pixels. </p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training a deep learning model using Amazon SageMaker</h1>
                </header>
            
            <article>
                
<p><span>In this section, we will show how to train image classification models using this dataset. Similarly, download the </span><kbd>validation</kbd><span> file to the AWS bucket under the </span><span><kbd>image-classification-full-training/validation</kbd> folder.</span></p>
<p>In <a href="c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml">Chapter 7</a>, <em>Implementing Deep Learning Algorithms</em>, we studied an algorithm called a CNN, which uses deep neural networks to build an object detection model. This model trains on labeled images and learns how to identify objects in an image using various layers of deep neural networks. Building this deep learning model from scratch is difficult. Amazon SageMaker offers an easy way to train image classification algorithms using your own dataset and then deploys that model to detect objects in images. We'll provide a code example of training a model using the <kbd>caltech256</kbd> dataset and then we'll test it on image files in the next section, <span><em><span>Classifying images using Amazon SageMaker</span></em></span>. </p>
<p>Similar to <a href="a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml"/><a href="a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml"/>Chapter 8, <em><span class="cdp-organizer-chapter-title"><span class="cdp-organize-title-label">Implementing Deep Learning with TensorFlow on AWS</span></span></em>, you will have to start a new SageMaker instance and use Jupyter Notebooks to start the test. Amazon SageMaker already offers a large amount of example code for you to get started. To access these examples, please refer to the <span class="packt_screen">SageMaker Examples</span> tab:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-772 image-border" src="assets/fd2105b1-8f7c-445e-b19e-766c8774aadb.png" style="width:42.58em;height:8.33em;"/></p>
<p>The code that we use in this chapter is also a modification of the image classification example provided by SageMaker. You can create a new notebook with the kernel of <kbd><span>conda_python3</span></kbd>:</p>
<div class="packt_infobox">In chapters such as Chapter 5, <em>Customer Segmentation Using Clustering Algorithms</em>, and Chapter 6, <em>Analyzing Visitor Patterns to Make Recommendations</em>, we used the high-level <kbd>sagemaker</kbd> Python library provided by Amazon. Here, we have chosen to show how to use the SageMaker generic client from the <kbd>boto3</kbd> library. This library provides a declarative interface that more closely resembles the API behind SageMaker. Hopefully, you the reader can grasp the lower-level calls made to the API through the examples in this chapter.</div>
<p>We provide a code example here on how to use the boto3 client to create an image classification model using Amazon Sagemaker.</p>
<ol>
<li>Initialize the role and the image-classification image that we want to use in SageMaker, then specify the name of our bucket:</li>
</ol>
<pre style="padding-left: 60px"><span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">sagemaker</span> <span class="k">import</span> <span class="n">get_execution_role</span>
<span class="kn">from</span> <span class="nn">sagemaker.amazon.amazon_estimator</span> <span class="k">import</span> <span class="n">get_image_uri</span>

<span class="n">role</span> <span class="o">=</span> <span class="n">get_execution_role</span><span class="p">()</span>

<span class="n">bucket</span><span class="o">=</span><span class="s1">'mastering-ml-aws'</span>

<span class="n">training_image</span> <span class="o">=</span> <span class="n">get_image_uri</span><span class="p">(</span><span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span><span class="o">.</span><span class="n">region_name</span><span class="p">,</span> <span class="s1">'image-classification'</span><span class="p">)</span></pre>
<p style="padding-left: 60px">The training image <span><span>called </span></span><strong>image-classification</strong> is a Docker image of the image-classification algorithm. Amazon SageMaker provides a large variety of such images, which you can use to train your classifiers. Each image has its own tuning parameters, which you can also provide when training that algorithm.</p>
<ol start="2">
<li>We will declare these tuning parameters, in the <span><span>following </span></span>code block:</li>
</ol>
<pre style="padding-left: 60px"><span class="c1"># Define Parameters</span>

<span class="n">num_layers</span> <span class="o">=</span> <span class="s2">"18"</span> 
<span class="n">image_shape</span> <span class="o">=</span> <span class="s2">"3,224,224"</span>
<span class="n">num_training_samples</span> <span class="o">=</span> <span class="s2">"15420"</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="s2">"257"</span>
<span class="n">mini_batch_size</span> <span class="o">=</span>  <span class="s2">"64"</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="s2">"2"</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="s2">"0.01"</span></pre>
<p style="padding-left: 60px">An image classification algorithm uses deep neural networks; these parameters will be familiar to you as we studied them in <a href="c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml">Chapter 7</a><span>, </span><em>Implementing Deep Learning Algorithms</em>.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">We define the number of hidden layers that will be used by the deep learning algorithm. We also have to specify the number of channels and the size of each image. We define the number of training images and the number of classes (object types). The number of epochs defines the number of times we will iterate over the training dataset. The accuracy of the deep learning classifier increases with the number of iterations we have over the dataset. The learning rate defines the number of changes the deep learning algorithm is allowed to make to the weights.</p>
<p style="padding-left: 60px">We would recommend that you run this algorithm with different parameters to observe the effects on evaluation and training time. </p>
<ol start="3">
<li>Once we define the parameters, we initialize the boto3 client for S3, where we have stored our training and validation files. </li>
</ol>
<pre style="padding-left: 60px"><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="k">import</span> <span class="n">gmtime</span><span class="p">,</span> <span class="n">strftime</span>


<span class="c1"># caltech-256</span>
<span class="n">s3_train_key</span> <span class="o">=</span> <span class="s2">"image-classification-full-training/train"</span>
<span class="n">s3_validation_key</span> <span class="o">=</span> <span class="s2">"image-classification-full-training/validation"</span>
<span class="n">s3_train</span> <span class="o">=</span> <span class="s1">'s3://</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">/'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">s3_train_key</span><span class="p">)</span>
<span class="n">s3_validation</span> <span class="o">=</span> <span class="s1">'s3://</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">/'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">s3_validation_key</span><span class="p">)</span>

<span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">'s3'</span><span class="p">)</span></pre>
<ol start="4">
<li>We construct a JSON with all the parameters required to train our image classifier:</li>
</ol>
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3">
<pre style="padding-left: 60px"><span class="c1"># create unique job name </span>
<span class="n">job_name_prefix</span> <span class="o">=</span> <span class="s1">'example-imageclassification'</span>
<span class="n">timestamp</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">'-%Y-%m-</span><span class="si">%d</span><span class="s1">-%H-%M-%S'</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">())</span>
<span class="n">job_name</span> <span class="o">=</span> <span class="n">job_name_prefix</span> <span class="o">+</span> <span class="n">timestamp</span>
<span class="n">training_params</span> <span class="o">=</span> \
<span class="p">{</span>
    <span class="c1"># specify the training docker image</span>
    <span class="s2">"AlgorithmSpecification"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"TrainingImage"</span><span class="p">:</span> <span class="n">training_image</span><span class="p">,</span>
        <span class="s2">"TrainingInputMode"</span><span class="p">:</span> <span class="s2">"File"</span>
    <span class="p">},</span>
    <span class="s2">"RoleArn"</span><span class="p">:</span> <span class="n">role</span><span class="p">,</span>
    <span class="s2">"OutputDataConfig"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"S3OutputPath"</span><span class="p">:</span> <span class="s1">'s3://</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">/output'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">job_name_prefix</span><span class="p">)</span>
    <span class="p">},</span>
    <span class="s2">"ResourceConfig"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"InstanceCount"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">"InstanceType"</span><span class="p">:</span> <span class="s2">"ml.p2.xlarge"</span><span class="p">,</span>
        <span class="s2">"VolumeSizeInGB"</span><span class="p">:</span> <span class="mi">50</span>
    <span class="p">},</span>
    <span class="s2">"TrainingJobName"</span><span class="p">:</span> <span class="n">job_name</span><span class="p">,</span>
    <span class="s2">"HyperParameters"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"image_shape"</span><span class="p">:</span> <span class="n">image_shape</span><span class="p">,</span>
        <span class="s2">"num_layers"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_layers</span><span class="p">),</span>
        <span class="s2">"num_training_samples"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_training_samples</span><span class="p">),</span>
        <span class="s2">"num_classes"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_classes</span><span class="p">),</span>
        <span class="s2">"mini_batch_size"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">mini_batch_size</span><span class="p">),</span>
        <span class="s2">"epochs"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span>
        <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="p">},</span>
    <span class="s2">"StoppingCondition"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"MaxRuntimeInSeconds"</span><span class="p">:</span> <span class="mi">360000</span>
    <span class="p">},</span>
    <span class="s2">"InputDataConfig"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">"ChannelName"</span><span class="p">:</span> <span class="s2">"train"</span><span class="p">,</span>
            <span class="s2">"DataSource"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">"S3DataSource"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">"S3DataType"</span><span class="p">:</span> <span class="s2">"S3Prefix"</span><span class="p">,</span>
                    <span class="s2">"S3Uri"</span><span class="p">:</span> <span class="n">s3_train</span><span class="p">,</span>
                    <span class="s2">"S3DataDistributionType"</span><span class="p">:</span> <span class="s2">"FullyReplicated"</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">"ContentType"</span><span class="p">:</span> <span class="s2">"application/x-recordio"</span><span class="p">,</span>
            <span class="s2">"CompressionType"</span><span class="p">:</span> <span class="s2">"None"</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">"ChannelName"</span><span class="p">:</span> <span class="s2">"validation"</span><span class="p">,</span>
            <span class="s2">"DataSource"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">"S3DataSource"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">"S3DataType"</span><span class="p">:</span> <span class="s2">"S3Prefix"</span><span class="p">,</span>
                    <span class="s2">"S3Uri"</span><span class="p">:</span> <span class="n">s3_validation</span><span class="p">,</span>
                    <span class="s2">"S3DataDistributionType"</span><span class="p">:</span> <span class="s2">"FullyReplicated"</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">"ContentType"</span><span class="p">:</span> <span class="s2">"application/x-recordio"</span><span class="p">,</span>
            <span class="s2">"CompressionType"</span><span class="p">:</span> <span class="s2">"None"</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span></pre></div>
</div>
</div>
</div>
<p>There are a lot of things to learn in this JSON. We define the algorithm that we want to use for training in the <span class="s2"><kbd>AlgorithmSpecification</kbd> section. </span><span class="s2"><kbd>OutputDataConfig</kbd> defines where the model will be stored. </span><span class="s2"><kbd>ResourceConfig</kbd> defines the instance type to be used for a training job. Note that tasks such as image classification run faster on GPU-based instances on AWS. All the parameters for the algorithm are defined in the </span><span class="s2"><kbd>HyperParameters</kbd> section. We set the training dataset and the validation dataset under the </span><span class="s2"><kbd>InputDataConfig</kbd> section of JSON. This JSON configuration will be used in the next code block to set parameters for the training job. </span></p>
<p class="prompt input_prompt">The following code block starts a <kbd>sagemaker</kbd> training job:</p>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3">
<pre><span class="c1"># create the Amazon SageMaker training job</span>

<span class="n">sagemaker</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="n">service_name</span><span class="o">=</span><span class="s1">'sagemaker'</span><span class="p">)</span>
<span class="n">sagemaker</span><span class="o">.</span><span class="n">create_training_job</span><span class="p">(</span><span class="o">**</span><span class="n">training_params</span><span class="p">)</span></pre></div>
</div>
</div>
<p>After you start the training job, you can observe its progress of the training job on your Amazon SageMaker dashboard:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/229b3113-8c8b-41d0-8177-b633091ff6d0.png"/></p>
<p>This dashboard also shows you statistics for your model, including the CPU and GPU usage, and the memory utilization. You can also observe the training and validation accuracy of the model we're training on this dashboard.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Since we are only using two epochs, the training accuracy of this model is low:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/02b8ba3c-aeca-420c-a9b0-34140709c671.png"/></p>
<p>You have successfully trained an image classification model using SageMaker. SageMaker is very easy to use, as you just have to select the algorithm image, select the training dataset, and set the parameters for the algorithm. SageMaker automatically trains the model based on this information and also stores the model on your S3 bucket. </p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Classifying images using Amazon SageMaker</h1>
                </header>
            
            <article>
                
<p>The SageMaker models that you have trained are now available to be used to predict objects in images. As we discussed at the beginning of the chapter, SageMaker offers a marketplace where you can use many models directly to perform your tasks.</p>
<ol>
<li>Since we trained our own machine learning model, we will have to create a SageMaker model that can be used for prediction. The following code shows how to generate a usable model in Amazon Sagemaker</li>
</ol>
<pre style="padding-left: 60px"><span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="k">import</span> <span class="n">gmtime</span><span class="p">,</span> <span class="n">strftime</span>

<span class="n">sage</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="n">service_name</span><span class="o">=</span><span class="s1">'sagemaker'</span><span class="p">)</span> 

<span class="n">model_name</span><span class="o">=</span><span class="s2">"example-full-image-classification-model"</span>

<span class="n">info</span> <span class="o">=</span> <span class="n">sage</span><span class="o">.</span><span class="n">describe_training_job</span><span class="p">(</span><span class="n">TrainingJobName</span><span class="o">=</span><span class="n">job_name</span><span class="p">)</span>
<span class="n">model_data</span> <span class="o">=</span> <span class="n">info</span><span class="p">[</span><span class="s1">'ModelArtifacts'</span><span class="p">][</span><span class="s1">'S3ModelArtifacts'</span><span class="p">]</span>

<span class="n">hosting_image</span> <span class="o">=</span> <span class="n">get_image_uri</span><span class="p">(</span><span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span><span class="o">.</span><span class="n">region_name</span><span class="p">,</span> <span class="s1">'image-classification'</span><span class="p">)</span>

<span class="n">primary_container</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'Image'</span><span class="p">:</span> <span class="n">hosting_image</span><span class="p">,</span>
    <span class="s1">'ModelDataUrl'</span><span class="p">:</span> <span class="n">model_data</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">create_model_response</span> <span class="o">=</span> <span class="n">sage</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span>
    <span class="n">ModelName</span> <span class="o">=</span> <span class="n">model_name</span><span class="p">,</span>
    <span class="n">ExecutionRoleArn</span> <span class="o">=</span> <span class="n">role</span><span class="p">,</span>
    <span class="n">PrimaryContainer</span> <span class="o">=</span> <span class="n">primary_container</span><span class="p">)</span></pre>
<p>To create a model in SageMaker, we have to specify the model name that was generated in the previous steps. In our example, the model name was set to <span class="s2"><kbd>example-full-image-classification-model</kbd>. We also have to specify the container in which the model will be stored. Since we used the image-classification Docker image to generate this model, we have to specify it as a parameter. This image will help SageMaker read the trained model and define how it can be used for prediction. </span></p>
<p>The <kbd>create_model</kbd> function will create the model and return an <span><strong>Amazon Resource Name</strong> </span>(<strong><span>ARN </span></strong>) for the model. This can be used to call the model to generate predictions. </p>
<p class="mce-root"/>
<p>For testing, we will download the raw images from the <kbd>Caltech256</kbd> dataset and store them in an <kbd>S3</kbd> bucket. We will use these images to generate predictions:</p>
<pre><span class="err">!</span><span class="n">wget</span> <span class="o">-</span><span class="n">r</span> <span class="o">-</span><span class="n">np</span> <span class="o">-</span><span class="n">nH</span> <span class="o">--</span><span class="n">cut</span><span class="o">-</span><span class="n">dirs</span><span class="o">=</span><span class="mi">2</span> <span class="o">-</span><span class="n">P</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span> <span class="o">-</span><span class="n">R</span> <span class="s2">"index.html*"</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">vision</span><span class="o">.</span><span class="n">caltech</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">Image_Datasets</span><span class="o">/</span><span class="n">Caltech256</span><span class="o">/</span><span class="n">images</span><span class="o">/</span><span class="mf">008.</span><span class="n">bathtub</span><span class="o">/<br/><br/></span><span class="n">batch_input</span> <span class="o">=</span> <span class="s1">'s3://</span><span class="si">{}</span><span class="s1">/image-classification-full-training/test/'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bucket</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="s1">'/tmp/images/008.bathtub'</span>

<span class="err">!</span><span class="n">aws</span> <span class="n">s3</span> <span class="n">cp</span> <span class="err">$</span><span class="n">test_images</span> <span class="err">$</span><span class="n">batch_input</span> <span class="o">--</span><span class="n">recursive</span> <span class="o">--</span><span class="n">quiet</span></pre>
<p>Once we have downloaded all the images and stored them in an S3 bucket, we specify the parameters for running a batch prediction job. This job will predict the probability of each of the 256 objects being present in an image:</p>
<pre><span class="n">timestamp</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">'-%Y-%m-</span><span class="si">%d</span><span class="s1">-%H-%M-%S'</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">())</span>
<span class="n">batch_job_name</span> <span class="o">=</span> <span class="s2">"image-classification-model"</span> <span class="o">+</span> <span class="n">timestamp</span>
<span class="n">request</span> <span class="o">=</span> \
<span class="p">{</span>
    <span class="s2">"TransformJobName"</span><span class="p">:</span> <span class="n">batch_job_name</span><span class="p">,</span>
    <span class="s2">"ModelName"</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>
    <span class="s2">"MaxConcurrentTransforms"</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
    <span class="s2">"MaxPayloadInMB"</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
    <span class="s2">"BatchStrategy"</span><span class="p">:</span> <span class="s2">"SingleRecord"</span><span class="p">,</span>
    <span class="s2">"TransformOutput"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"S3OutputPath"</span><span class="p">:</span> <span class="s1">'s3://</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">/output'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">batch_job_name</span><span class="p">)</span>
    <span class="p">},</span>
    <span class="s2">"TransformInput"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"DataSource"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"S3DataSource"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">"S3DataType"</span><span class="p">:</span> <span class="s2">"S3Prefix"</span><span class="p">,</span>
                <span class="s2">"S3Uri"</span><span class="p">:</span> <span class="n">batch_input</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="s2">"ContentType"</span><span class="p">:</span> <span class="s2">"application/x-image"</span><span class="p">,</span>
        <span class="s2">"SplitType"</span><span class="p">:</span> <span class="s2">"None"</span><span class="p">,</span>
        <span class="s2">"CompressionType"</span><span class="p">:</span> <span class="s2">"None"</span>
    <span class="p">},</span>
    <span class="s2">"TransformResources"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"InstanceType"</span><span class="p">:</span> <span class="s2">"ml.p2.xlarge"</span><span class="p">,</span>
            <span class="s2">"InstanceCount"</span><span class="p">:</span> <span class="mi">1</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Transform job name: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">batch_job_name</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Input Data Location: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">s3_validation</span><span class="p">))</span></pre>
<p class="mce-root"/>
<p>As you might have guessed, we have to specify the model name in the <kbd>ModelName</kbd> parameter and the input folder in the <kbd>TransformInput</kbd> parameter. We also have to specify the <kbd>output</kbd> folder where the predictions are stored. We have to specify the instance type that we are using in the <kbd>TransformResources</kbd> parameter and the max number of files to process in the <kbd>MaxConcurrentTransforms</kbd> parameter. </p>
<p>The following code uses the parameters and starts the <kbd>create_transform_job</kbd>:</p>
<pre><span class="n">sagemaker</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">'sagemaker'</span><span class="p">)</span>
<span class="n">sagemaker</span><span class="o">.</span><span class="n">create_transform_job</span><span class="p">(</span><span class="o">**</span><span class="n">request</span><span class="p">)</span></pre>
<p>You can monitor your transforms job on the SageMaker dashboard under <span class="packt_screen">Inference</span> | <span class="packt_screen">Batch Transforms Jobs</span> section. Once the task is finished, you can access the predictions in the S3 bucket you specified as the <kbd>output</kbd> folder.</p>
<p>The predictions can be seen in the following format:</p>
<pre>{<br/>  "prediction": [<br/>    0.0002778972266241908,<br/>    0.05520012229681015,<br/>...<br/>    ]<br/>}</pre>
<p>Since our model had 256 object categories, the output specifies the probability of each object being present in the image. You can run the model on various datasets to check whether your model can predict the objects in the dataset correctly. </p>
<p>SageMaker offers a very easy-to-use service to not only train deep learning models but also to use them in applications to generate predictions. Although the service is very intuitive, SageMaker is expensive when you use the pre-built models on a large dataset to generate predictions. Based on the application being developed, data scientists should always consider the overall cost they would incur when using such services compared to building the same models on their own clusters in Apache Spark. </p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we studied how Amazon SageMaker offers various ready-to-use machine learning models to generate predictions, as well as algorithm images that can be used to train your models. Amazon SageMaker generates a layer of abstraction between you and the messy details of setting up your own clusters to train and create your own machine learning model. Amazon SageMaker dashboards also offer a place to store your trained models and monitor your batch-processing jobs for predictions. </p>
<p>You can also train your own machine learning models using your own datasets in SageMaker. We presented an example of training a machine learning model that is capable of performing object detection in images. We demonstrated how this model can then be deployed on SageMaker and used for running batch-prediction jobs. You will be able to use this as a template to work on other algorithms in Amazon SageMaker.</p>
<p>In this book, our aim is to provide you with an understanding of how machine learning algorithms work and how you can utilize powerful tools such as Apache Spark, Tensorflow, and SageMaker to deploy large-scale training and prediction jobs using machine learning. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exercises</h1>
                </header>
            
            <article>
                
<ol>
<li>For each of the examples provide in previous chapters, find an algorithm in Amazon SageMaker Marketplace that would be applicable to solve that problem.</li>
<li>Amazon SageMaker also provides a service to create endpoints to generate predictions. For the preceding example, create an endpoint for the model that we trained and generate predictions for one image. </li>
</ol>


            </article>

            
        </section>
    </body></html>