["```py\n$ pip install --upgrade --user awscli\n\n```", "```py\n$ export PATH=~/.local/bin:$PATH\n\n```", "```py\n$ source ~/.bash_profile\n\n```", "```py\n$ aws --version\n\n```", "```py\n$ aws-cli/1.11.47 Python/3.5.2 Darwin/15.6.0 botocore/1.5.10\n\n```", "```py\n$ aws configure\n\n```", "```py\n$ aws configure\n AWS Access Key ID [None]: ABCDEF_THISISANEXAMPLE\nAWS Secret Access Key [None]: abcdefghijk_THISISANEXAMPLE\nDefault region name [None]: us-west-2\nDefault output format [None]: json\n\n```", "```py\n$ aws configure --profile user2\n\n```", "```py\n~/.aws/config\n\n[default]\noutput = json\nregion = us-east-1\n\n[profile user2]\noutput = text\nregion = us-west-2\n\n```", "```py\n~/.aws/credentials\n\n[default]\naws_secret_access_key = ABCDEF_THISISANEXAMPLE\naws_access_key_id = abcdefghijk_THISISANEXAMPLE\n\n[user2]\naws_access_key_id = ABCDEF_ANOTHERKEY\naws_secret_access_key = abcdefghijk_ANOTHERKEY\n\n```", "```py\n$ aws <service> [options] <command> <subcommand> [parameters]\n\n```", "```py\n$ aws s3 ls aml.packt\n\n```", "```py\n$ aws <service> help\n\n```", "```py\n$ aws s3 <command> sourceURI destinationURI  [parameters]\n\n```", "```py\n$ aws s3 cp /tmp/foo/ s3://The_Bucket/ --recursive --exclude \"*\" --include \"*.jpg\"\n\n```", "```py\n$ aws machinelearning create-ml-model --generate-cli-skeleton\n\n```", "```py\n{\n   \"MLModelId\": \"\",\n   \"MLModelName\": \"\",\n   \"MLModelType\": \"\",\n   \"Parameters\": {\n       \"KeyName\": \"\"\n   },\n   \"TrainingDataSourceId\": \"\",\n   \"Recipe\": \"\",\n   \"RecipeUri\": \"\"\n}\n\n```", "```py\n$ aws machinelearning create-ml-model --generate-cli-skeleton > filename.json\n\n```", "```py\n$ aws machinelearning create-ml-model file://filename.json\n\n```", "```py\n $ head -n 1 ames_housing.csv > ames_housing_header.csv\n\n```", "```py\n $ tail -n +2 ames_housing.csv > ames_housing_nohead.csv\n\n```", "```py\n $ gshuf ames_housing_nohead.csv -o ames_housing_nohead.csv\n\n```", "```py\n $ head -n 2050 ames_housing_nohead.csv > ames_housing_training.csv\n $ tail -n 880 ames_housing_nohead.csv > ames_housing_validate.csv\n\n```", "```py\n $ cat ames_housing_header.csv ames_housing_training.csv > tmp.csv \n        $ mv tmp.csv ames_housing_training.csv\n\n $ cat ames_housing_header.csv ames_housing_validate.csv > tmp.csv\n        $ mv tmp.csv ames_housing_validate.csv\n\n```", "```py\n$ aws s3 cp ./ames_housing_training.csv s3://aml.packt/data/ch8/\nupload: ./ames_housing_training.csv to s3://aml.packt/data/ch8/ames_housing_training.csv\n\n$ aws s3 cp ./ames_housing_validate.csv s3://aml.packt/data/ch8/\nupload: ./ames_housing_validate.csv to s3://aml.packt/data/ch8/ames_housing_validate.csv\n\n```", "```py\n$ aws machinelearning create-data-source-from-s3 --generate-cli-skeleton\n\n```", "```py\n{\n   \"DataSourceId\": \"\",\n   \"DataSourceName\": \"\",\n   \"DataSpec\": {\n       \"DataLocationS3\": \"\",\n       \"DataRearrangement\": \"\",\n       \"DataSchema\": \"\",\n       \"DataSchemaLocationS3\": \"\"\n   },\n   \"ComputeStatistics\": true\n}\n\n```", "```py\n{\n   \"DataSourceId\": \"ch8_ames_housing_001\",\n   \"DataSourceName\": \"[DS] Ames Housing 001\",\n   \"DataSpec\": {\n       \"DataLocationS3\": \n         \"s3://aml.packt/data/ch8/ames_housing_training.csv\",\n       \"DataSchemaLocationS3\": \n         \"s3://aml.packt/data/ch8/ames_housing.csv.schema\"        \n   },\n   \"ComputeStatistics\": true\n}\n\n```", "```py\n{\n   \"DataSourceId\": \"ch8_ames_housing_002\",\n   \"DataSourceName\": \"[DS] Ames Housing 002\",\n   \"DataSpec\": {\n       \"DataLocationS3\": \n         \"s3://aml.packt/data/ch8/ames_housing_validate.csv\",\n       \"DataSchemaLocationS3\": \n         \"s3://aml.packt/data/ch8/ames_housing.csv.schema\"        \n   },\n   \"ComputeStatistics\": true\n}\n\n```", "```py\n{\n   \"DataSourceId\": \"ch8_ames_housing_003\",\n   \"DataSourceName\": \"[DS] Ames Housing training 003\",\n   \"DataSpec\": {\n       \"DataLocationS3\": \n         \"s3://aml.packt/data/ch8/ames_housing_shuffled.csv\",\n       \"DataRearrangement\": \n         \"{\"splitting\":{\"percentBegin\":0,\"percentEnd\":70}}\",\n       \"DataSchemaLocationS3\":\n         \"s3://aml.packt/data/ch8/ames_housing.csv.schema\"        \n   },\n   \"ComputeStatistics\": true\n}\n\n```", "```py\n{\n   \"DataSourceId\": \"ch8_ames_housing_004\",\n   \"DataSourceName\": \"[DS] Ames Housing validation 004\",\n   \"DataSpec\": {\n       \"DataLocationS3\":\n         \"s3://aml.packt/data/ch8/ames_housing_shuffled.csv\",\n       \"DataRearrangement\": \n         \"{\"splitting\":{\"percentBegin\":70,\"percentEnd\":100}}\",\n   },\n   \"ComputeStatistics\": true\n}\n\n```", "```py\n$ gshuf ames_housing_nohead.csv -o ames_housing_nohead.csv\n$ cat ames_housing_header.csv ames_housing_nohead.csv > tmp.csv\n$ mv tmp.csv ames_housing_shuffled.csv\n$ aws s3 cp ./ames_housing_shuffled.csv s3://aml.packt/data/ch8/\n\n```", "```py\n$ aws machinelearning create-data-source-from-s3 --cli-input-json file://dsrc_ames_housing_001.json\n\n```", "```py\n{\n   \"DataSourceId\": \"ch8_ames_housing_001\"\n}\n\n```", "```py\n$ aws machinelearning  get-data-source --data-source-id ch8_ames_housing_001\n\n```", "```py\n{\n   \"Status\": \"COMPLETED\",\n   \"NumberOfFiles\": 1,\n   \"CreatedByIamUser\": \"arn:aws:iam::178277xxxxxxx:user/alexperrier\",\n   \"LastUpdatedAt\": 1486834110.483,\n   \"DataLocationS3\": \"s3://aml.packt/data/ch8/ames_housing_training.csv\",\n   \"ComputeStatistics\": true,\n   \"StartedAt\": 1486833867.707,\n   \"LogUri\": \"https://eml-prod-emr.s3.amazonaws.com/178277513911-ds-ch8_ames_housing_001/.....\",\n   \"DataSourceId\": \"ch8_ames_housing_001\",\n   \"CreatedAt\": 1486030865.965,\n   \"ComputeTime\": 880000,\n   \"DataSizeInBytes\": 648150,\n   \"FinishedAt\": 1486834110.483,\n   \"Name\": \"[DS] Ames Housing 001\"\n}\n\n```", "```py\n        $ aws machinelearning create-ml-model --generate-cli-skeleton > \n        mdl_ames_housing_001.json\n\n```", "```py\n        {\n            \"MLModelId\": \"ch8_ames_housing_001\",\n            \"MLModelName\": \"[MDL] Ames Housing 001\",\n            \"MLModelType\": \"REGRESSION\",\n            \"Parameters\": {\n                \"sgd.shuffleType\": \"auto\",\n                \"sgd.l2RegularizationAmount\": \"1.0E-06\",\n                \"sgd.maxPasses\": \"100\"\n            },\n            \"TrainingDataSourceId\": \"ch8_ames_housing_001\",\n            \"RecipeUri\": \"s3://aml.packt/data/ch8\n              /recipe_ames_housing_001.json\"\n        }\n\n```", "```py\n        $ aws machinelearning create-ml-model --cli-input-json \n        file://mdl_ames_housing_001.json\n\n```", "```py\n        {\n            \"MLModelId\": \"ch8_ames_housing_001\"\n        }\n\n```", "```py\n        $ aws machinelearning get-ml-model --ml-model-id \n        ch8_ames_housing_001\n\n```", "```py\n        $ watch -n 10 aws machinelearning get-ml-model --ml-model-id \n        ch8_ames_housing_001\n\n```", "```py\n        $ aws machinelearning create-evaluation --generate-cli-skeleton >  \n        eval_ames_housing_001.json\n\n```", "```py\n        {\n            \"EvaluationId\": \"ch8_ames_housing_001\",\n            \"EvaluationName\": \"[EVL] Ames Housing 001\",\n            \"MLModelId\": \"ch8_ames_housing_001\",\n            \"EvaluationDataSourceId\": \"ch8_ames_housing_002\"\n        }\n\n```", "```py\n        $ aws machinelearning create-evaluation --cli-input-json \n        file://eval_ames_housing_001.json\n\n```", "```py\n        $ aws machinelearning get-evaluation --evaluation-id \n        ch8_ames_housing_001\n\n```", "```py\n        \"PerformanceMetrics\": {\n            \"Properties\": {\n                 \"RegressionRMSE\": \"29853.250469108018\"\n            }\n        }\n\n```", "```py\n#!/bin/bash\nfor k in 1 2 3 4 5 \ndo\n    filename=\"data/ames_housing_shuffled_$k.csv\"\n    gshuf data/ames_housing_nohead.csv -o data/ames_housing_nohead.csv\n    cat data/ames_housing_header.csv data/ames_housing_nohead.csv > tmp.csv;\n    mv tmp.csv $filename\n    aws s3 cp ./$filename s3://aml.packt/data/ch8/\ndone\n\n```", "```py\n{\n   \"DataSourceId\": \"CH8_AH_training_00{k}\",\n   \"DataSourceName\": \"[DS AH] training 00{k}\",\n   \"DataSpec\": {\n       \"DataLocationS3\": \"s3://aml.packt/data/ch8/shuffled_{k}.csv\",\n       \"DataSchemaLocationS3\":\"s3://aml.packt/data/ch8\n        /ames_housing.csv.schema\",\n       \"DataRearrangement\": \"{\"splitting\":\n       {\"percentBegin\":0,\"percentEnd\":70}}\"\n   },\n   \"ComputeStatistics\": true\n}\n\n```", "```py\n{\n   \"DataSourceId\": \"CH8_AH_evaluate_00{k}\",\n   \"DataSourceName\": \"[DS AH] evaluate 00{k}\",\n   \"DataSpec\": {\n       \"DataLocationS3\": \"s3://aml.packt/data/ch8/shuffled_{k}.csv\",\n       \"DataSchemaLocationS3\":\"s3://aml.packt/data/ch8\n       /ames_housing.csv.schema\",\n       \"DataRearrangement\": \"{\"splitting\":\n       {\"percentBegin\":70,\"percentEnd\":100}}\"\n   },\n   \"ComputeStatistics\": true\n}\n\n```", "```py\n{\n   \"MLModelId\": \"CH8_AH_L2_00{k}\",\n   \"MLModelName\": \"[MDL AH L2] 00{k}\",\n   \"MLModelType\": \"REGRESSION\",\n   \"Parameters\": {\n       \"sgd.shuffleType\": \"auto\",\n       \"sgd.l1RegularizationAmount\": \"0.0\",\n       \"sgd.l2RegularizationAmount\": \"1.0E-06\",\n       \"sgd.maxPasses\": \"100\"\n   },\n   \"TrainingDataSourceId\": \"CH8_AH_training_00{k}\",\n   \"RecipeUri\": \"s3://aml.packt/data/ch8/recipe_ames_housing_001.json\"\n}\n\n```", "```py\n{\n   \"MLModelId\": \"CH8_AH_L1_00{k}\",\n   \"MLModelName\": \"[MDL AH L1] 00{k}\",\n   \"MLModelType\": \"REGRESSION\",\n   \"Parameters\": {\n       \"sgd.shuffleType\": \"auto\",\n       \"sgd.l1RegularizationAmount\": \"1.0E-04\",\n       \"sgd.l2RegularizationAmount\": \"0.0\",\n       \"sgd.maxPasses\": \"100\"\n   },\n   \"TrainingDataSourceId\": \"CH8_AH_training_00{k}\",\n   \"RecipeUri\": \"s3://aml.packt/data/ch8/recipe_ames_housing_001.json\"\n}\n\n```", "```py\n{\n   \"EvaluationId\": \"CH8_AH_L2_00{k}\",\n   \"EvaluationName\": \"[EVL AH L2] 00{k}\",\n   \"MLModelId\": \"CH8_AH_L2_00{k}\",\n   \"EvaluationDataSourceId\": \"CH8_AH_evaluate_00{k}\"\n}\n\n```", "```py\n{\n   \"EvaluationId\": \"CH8_AH_L1_00{k}\",\n   \"EvaluationName\": \"[EVL AH L1] 00{k}\",\n   \"MLModelId\": \"CH8_AH_L1_00{k}\",\n   \"EvaluationDataSourceId\": \"CH8_AH_evaluate_00{k}\"\n}\n\n```", "```py\n.\n├── data\n│   └── cfg\n│   └── templates\n├── images\n├── py\n└── shell\n\n#!/bin/bash\n\nfor k in 1 2 3 4 5 \ndo\n    # training datasource\n    sed 's/{k}/1/g' data/templates/dsrc_training_template.json > data/cfg\n    /dsrc_training_00$k.json\n\n    # evaluation datasource\n    sed 's/{k}/1/g' data/templates/dsrc_validate_template.json > data/cfg\n    /dsrc_validate_00$k.json\n\n    # L2 model\n    sed 's/{k}/1/g' data/templates/mdl_l2_template.json > data/cfg\n    /mdl_l2_00$k.json\n\n    # L2 evaluation\n    sed 's/{k}/1/g' data/templates/eval_l2_template.json > data/cfg\n    /eval_l2_00$k.json\n\n    # L1 model\n    sed 's/{k}/1/g' data/templates/mdl_l1_template.json > data/cfg\n    /mdl_l1_00$k.json\n\n    # L1 evaluation\n    sed 's/{k}/1/g' data/templates/eval_l1_template.json > data/cfg\n    /eval_l1_00$k.json\n\ndone\n\n```", "```py\n#!/bin/bash\nfor k in 1 2 3 4 5 \ndo\n    aws machinelearning create-data-source-from-s3 --cli-input-json \n    file://data/cfg/dsrc_kfold_training_00$k.json\n    aws machinelearning create-data-source-from-s3 --cli-input-json \n    file://data/cfg/dsrc_kfold_validate_00$k.json\ndone\n\n```", "```py\n#!/bin/bash\nfor k in 1 2 3 4 5 \n    aws machinelearning create-ml-model --cli-input-json file://data\n    /cfg/mdl_l2_00$k.json\n    aws machinelearning create-ml-model --cli-input-json file://data\n    /cfg/mdl_l1_00$k.json\ndone\n\n```", "```py\n#!/bin/bash\nfor k in 1 2 3 4 5 \n    aws machinelearning create-evaluation --cli-input-json file://cfg\n    /eval_l2_00$k.json\n    aws machinelearning create-evaluation --cli-input-json file://cfg\n    /eval_l1_00$k.json\ndone\n\n```", "```py\n#!/bin/bash\nfor k in 1 2 3 4 5 \n    aws machinelearning get-evaluation --evaluation-id CH8_AH_L2_00$k | \n    grep RegressionRMSE >> l2_model_rmse.log\n    aws machinelearning get-evaluation --evaluation-id CH8_AH_L1_00$k |\n    grep RegressionRMSE >> l1_model_rmse.log\ndone\n\n```", "```py\nl1 | 26570.0 | 28880.4 | 27287.8 | 29815.7 | 27822.0]\n\nL2 | 36670.9 | 25804.3 | 28127.2 | 30539.0 | 24740.4\n\n```", "```py\npip install boto3\n\n```", "```py\nimport boto3\n# Initialize the S3 client\ns3 = boto3.resource('s3')\n# List all the buckets in out account\nfor bucket in s3.buckets.all():\n    print(bucket.name)\n\n```", "```py\n# load the file    \ndata = open('data/ames_housing_nohead.csv', 'rb')\ns3.Object('aml.packt', 'data/ames_housing_nohead.csv').put(Body=data)\n\n```", "```py\ndef name_id_generation(prefix, mode, trial):\n    Id = '_'.join([prefix, mode, \"%02d\"%int(trial)])\n    name = \"[%s] %s %02d\"% (prefix, mode, int(trial) )\n    return {'Name':name, 'Id':Id}\n\n```", "```py\n# The iteration number of our experiements\ntrial = 5\n# The S3 location of schemas and files\ndata_s3   = 's3://aml.packt/data/ch8/ames_housing_shuffled.csv'\nschema_s3 = 's3://aml.packt/data/ch8/ames_housing.csv.schema'\nrecipe_s3 = 's3://aml.packt/data/ch8/recipe_ames_housing_001.json'\n\n# And the parameters for the SGD algrithm\nsgd_params = {\n  \"sgd.shuffleType\": \"auto\",\n  \"sgd.l1RegularizationAmount\": \"1.0E-04\",\n  \"sgd.maxPasses\": \"100\"\n} \n\n```", "```py\nimport boto3\nimport time\nimport json\n\n```", "```py\nclient = boto3.client('machinelearning')\n\n```", "```py\n# Create datasource for training\nresource = name_id_generation('DS', 'training', trial)\nprint(\"Creating datasources for training (%s)\"% resource['Name'] )\nresponse = client.create_data_source_from_s3(\n  DataSourceId = resource['Id'] ,\n  DataSourceName = resource['Name'],\n  DataSpec = {\n    'DataLocationS3' : data_s3,\n    'DataSchemaLocationS3' : schema_s3,\n   'DataRearrangement':'{\"splitting\":{\"percentBegin\":0,\"percentEnd\":70}}'\n  },\n   ComputeStatistics = True\n)\n\n# Create datasource for validation\nresource = name_id_generation('DS', 'validation', trial)\nprint(\"Creating datasources for validation (%s)\"% resource['Name'] )\nresponse = client.create_data_source_from_s3(\n  DataSourceId = resource['Id'] ,\n  DataSourceName = resource['Name'],\n  DataSpec = {\n    'DataLocationS3': data_s3,\n    'DataSchemaLocationS3': schema_s3,\n    'DataRearrangement':'{\"splitting\":{\"percentBegin\":0,\"percentEnd\":70}}'\n  },\n  ComputeStatistics = True\n)\n\n```", "```py\n# Train model with existing recipe\nresource = name_id_generation('MDL', '', trial) \nprint(\"Training model (%s) with params:n%s\"% \n               (resource['Name'], json.dumps(sgd_params, indent=4)) )\nresponse = client.create_ml_model(\n  MLModelId = resource['Id'],\n  MLModelName = resource['Name'],\n  MLModelType = 'REGRESSION',\n  Parameters = sgd_params,\n  TrainingDataSourceId= name_id_generation('DS', 'training', trial)['Id'],\n  RecipeUri = recipe_s3\n)\n\n```", "```py\nresource = name_id_generation('EVAL', '', trial) \nprint(\"Launching evaluation (%s) \"% resource['Name'] )\nresponse = client.create_evaluation(\n  EvaluationId = resource['Id'],\n  EvaluationName = resource['Name'],\n  MLModelId = name_id_generation('MDL', '', trial)['Id'],\n  EvaluationDataSourceId = name_id_generation('DS', 'validation', trial)\n  ['Id']\n)\n\n```", "```py\nwaiter = client.get_waiter('evaluation_available')\n\n```", "```py\nwaiter.wait(FilterVariable='Name', EQ='the name of the evaluation')\n\n```", "```py\nwaiter.wait(FilterVariable='DataSourceId', EQ='the DatasourceId')\n\n```", "```py\nt0 = time.time()\n# declare the waiter and call the wait method on the evaluation\nwaiter = client.get_waiter('evaluation_available')\nprint(\"Waiting on evaluation to finish \")\nwaiter.wait(FilterVariable='Name', EQ=name_id_generation('EVAL', '', trial)['Name'])\nt = time.time() - t0\nprint(\"Evaluation has finished after %sm %ss\"% (int(t/60), t%60) )\n# get the evaluation results\nresponse = client.get_evaluation(\n  EvaluationId=name_id_generation('EVAL', '', trial)['Id']\n)\nRMSE =float(response['PerformanceMetrics']['Properties']['RegressionRMSE'])\nprint(\"[trial %0.2f] RMSE %0.2f\"% (trial, RMSE) )\n# and delete the resources\nprint(\"Deleting datasources and model\")\nresponse = client.delete_data_source(\n  DataSourceId=name_id_generation('DS', 'training', trial)['Id']\n)\nresponse = client.delete_data_source(\n  DataSourceId=name_id_generation('DS', 'validation', trial)['Id']\n)\nresponse = client.delete_ml_model(\n  MLModelId=name_id_generation('MDL', '', trial)['Id']\n)\n\n```", "```py\nCreating datasources for training ([DS] training 04)\nCreating datasources for validation ([DS] validation 04)\nTraining model ([MDL] 04) with params:\n{\n  \"sgd.shuffleType\": \"auto\",\n  \"sgd.l1RegularizationAmount\": \"1.0E-04\",\n  \"sgd.maxPasses\": \"100\"\n}\nLaunching evaluation ([EVAL] 04)\nWaiting on evaluation to finish\nEvaluation has finished after 11m 43.78s\n[trial 4] RMSE 22437.33\nDeleting datasources and model\n\n```", "```py\n\"groups\": {\n  \"NUMERIC_VARS_QB_50\":   \"group('LotFrontage','KitchenAbvGr','BsmtFinSF1','GarageCars','1stFlrSF','ScreenPorch','LowQualFinSF','LotArea','OverallCond','2ndFlrSF','GarageArea','EnclosedPorch','HalfBath')\",\n \"NUMERIC_VARS_QB_100\": \"group('BsmtFinSF2','WoodDeckSF','BsmtHalfBath','MiscVal','GrLivArea','Fireplaces')\",\n \"NUMERIC_VARS_QB_500\": \"group('OverallQual')\",\n \"NUMERIC_VARS_QB_20\": \"group('TotalBsmtSF')\",\n \"NUMERIC_VARS_QB_200\": \"group('MSSubClass','OpenPorchSF','YearRemod/Add','BsmtFullBath','MasVnrArea')\",\n \"NUMERIC_VARS_QB_10\": \"group('PoolArea','BedroomAbvGr','TotRmsAbvGrd','YearBuilt','MoSold','YrSold','GarageYrBlt','FullBath','BsmtUnfSF','3SsnPorch')\"\n }\n\n```", "```py\n{\n \"groups\" : {},\n \"assignments\" : { },\n \"outputs\" : [ \"ALL_INPUTS\" ]\n}\n\n```", "```py\nimport pandas as pd\nimport boto3\nimport json\n\n# Local schema with all the features\noriginal_schema_filename = 'data/ames_housing.csv.schema'\n# Initialize boto3 objects\ns3 = boto3.resource('s3')\nclient = boto3.client('machinelearning')\n\n# load dataset and feature_ names\ndf = pd.read_csv('data/ames_housing.csv')\noriginal_features = df.columns.difference(['SalePrice', 'Order'])\n\n# load original schema with all the features\nschema = json.load( open(original_schema_filename) )\n\n# SGD parameters: L1 heavy regularization\nsgd_parameters = {\n  \"sgd.shuffleType\": \"auto\",\n  \"sgd.l1RegularizationAmount\": \"1.0E-04\",\n  \"sgd.maxPasses\": \"100\"\n}\n\n# memorize all object Ids for future deletion\nbaseline_rmse = 61507.35\ndatasource_ids = []\nmodel_ids = []\nevaluation_ids = []\nfeatures_rmse = {}\n\ndef generate_trial(n):\n  n = \"X\" + str(n).zfill(3)\n  return {\n   'schema_filename': \"rfs_ames_housing_%s.schema\"% n, \n   'recipe_s3': 's3://aml.packt/RFS/recipe_ames_housing_default.json',\n   'data_s3': 's3://aml.packt/RFS/ames_housing_shuffled.csv',\n   'datasource_training_id': \"rfs_training_%s\"% n,\n   'datasource_training_name': \"[DS RFS] training %s\"% n,\n   'datasource_validation_id': \"rfs_validation_%s\"% n,\n   'datasource_validation_name': \"[DS RFS] validation %s\"% n,\n   'model_id': \"rfs_%s\"% n,\n   'model_name': \"[MDL RFS] %s\"% n,\n   'evaluation_id': \"rfs_%s\"% n,\n   'evaluation_name': \"[EVAL RFS] %s\"% n,\n  }\n\n```", "```py\nfor k in range(10):\n print(\"=\"* 10 + \" feature: %s\"% original_features[k])\n trial = generate_trial(k)\n\n # remove feature[k] from schema and upload to S3\n schema['excludedAttributeNames'] = [original_features[k]]\n with open(\"data/%s\"%trial['schema_filename'], 'w') as fp:\n json.dump(schema, fp, indent=4)\n s3.Object('aml.packt', \"RFS/%s\"% trial['schema_filename']).put(Body=open(\"data/%s\"%trial['schema_filename'], 'rb'))\n\n # create datasource\n print(\"Datasource %s\"% trial['datasource_training_name'])\n datasource_ids.append( trial['datasource_training_id'] )\n response = client.create_data_source_from_s3(\n   DataSourceId = trial['datasource_training_id'] ,\n   DataSourceName= trial['datasource_training_name'] ,\n   DataSpec={\n     'DataLocationS3': trial['data_s3'],\n     'DataRearrangement': '{\"splitting\":\n      {\"percentBegin\":0,\"percentEnd\":70}}',\n     'DataSchemaLocationS3': \"s3://aml.packt/RFS/%s\"% \n     trial['schema_filename']\n   },\n   ComputeStatistics=True\n )\n\n # Create datasource for validation\n print(\"Datasource %s\"% trial['datasource_validation_name'])\n datasource_ids.append( trial['datasource_validation_id'] )\n response = client.create_data_source_from_s3(\n DataSourceId = trial['datasource_validation_id'] ,\n DataSourceName= trial['datasource_validation_name'] ,\n DataSpec={\n 'DataLocationS3': trial['data_s3'],\n 'DataRearrangement': '{\"splitting\":{\"percentBegin\":70,\"percentEnd\":100}}',\n 'DataSchemaLocationS3': \"s3://aml.packt/RFS/%s\"% trial['schema_filename']\n },\n ComputeStatistics=True\n )\n\n # Train model with existing recipe\n print(\"Model %s\"% trial['model_name'])\n model_ids.append(trial['model_id'] )\n response = client.create_ml_model(\n MLModelId = trial['model_id'],\n MLModelName = trial['model_name'],\n MLModelType = 'REGRESSION',\n Parameters = sgd_parameters,\n TrainingDataSourceId = trial['datasource_training_id'] ,\n RecipeUri = trial['recipe_s3']\n )\n\n print(\"Evaluation %s\"% trial['evaluation_name'])\n evaluation_ids.append(trial['evaluation_id'])\n response = client.create_evaluation(\n EvaluationId = trial['evaluation_id'],\n EvaluationName = trial['evaluation_name'],\n MLModelId = trial['model_id'],\n EvaluationDataSourceId= trial['datasource_validation_id'] \n )\n\n```", "```py\nfor k in range(10):\n trial = generate_trial(k)\n waiter = client.get_waiter('evaluation_available')\n print(\"Waiting on evaluation %s to finish \"% trial['evaluation_name'])\n waiter.wait(FilterVariable='Name', EQ=trial['evaluation_name'])\n print(\"Evaluation has finished \")\n\n response = client.get_evaluation( EvaluationId=trial['evaluation_id'] )\n features_rmse[original_features[k]] = float(response['PerformanceMetrics']['Properties']['RegressionRMSE'])\n print(\"[%s] RMSE %0.2f\"% (original_features[k], float(response['PerformanceMetrics']['Properties']['RegressionRMSE'])) )\n # Now delete the resources\n print(\"Deleting datasources and model\")\n response = client.delete_data_source(\n DataSourceId = trial['datasource_training_id']\n )\n response = client.delete_data_source(\n DataSourceId = trial['datasource_validation_id']\n )\n response = client.delete_ml_model(\n MLModelId = trial['model_id']\n )\n\nprint(\"removing the feature increased the RMSE by \")\nfor k,v in features_rmse.items():\n print(\"%s t%0.2f %% \"% (k, (baseline_rmse - v)/ baseline_rmse *100.0 ) )\n\n```"]