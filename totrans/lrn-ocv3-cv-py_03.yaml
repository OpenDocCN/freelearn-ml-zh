- en: Chapter 3. Processing Images with OpenCV 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sooner or later, when working with images, you will find yourself in need of
    altering images: be it applying artistic filters, extrapolating certain sections,
    cutting, pasting, or whatever else your mind can conjure. This chapter presents
    some techniques to alter images, and by the end of it, you should be able to perform
    tasks, such as detecting skin tone in an image, sharpening an image, mark contours
    of subjects, and detecting crosswalks using a line segment detector.'
  prefs: []
  type: TYPE_NORMAL
- en: Converting between different color spaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are literally hundreds of methods in OpenCV that pertain to the conversion
    of color spaces. In general, three color spaces are prevalent in modern day computer
    vision: gray, BGR, and **Hue, Saturation, Value** (**HSV**).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Gray is a color space that effectively eliminates color information translating
    to shades of gray: this color space is extremely useful for intermediate processing,
    such as face detection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'BGR is the blue-green-red color space, in which each pixel is a three-element
    array, each value representing the blue, green, and red colors: web developers
    would be familiar with a similar definition of colors, except the order of colors
    is RGB.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In HSV, hue is a color tone, saturation is the intensity of a color, and value
    represents its darkness (or brightness at the opposite end of the spectrum).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A quick note on BGR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When I first started dealing with the BGR color space, something wasn''t adding
    up: the `[0 255 255]` value (no blue, full green, and full red) produces the yellow
    color. If you have an artistic background, you won''t even need to pick up paints
    and brushes to witness green and red mix into a muddy shade of brown. That is
    because the color model used in computing is called an **additive** and deals
    with lights. Lights behave differently from paints (which follow the **subtractive**
    color model), and—as software runs on computers whose medium is a monitor that
    emits light—the color model of reference is the additive one.'
  prefs: []
  type: TYPE_NORMAL
- en: The Fourier Transform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Much of the processing you apply to images and videos in OpenCV involves the
    concept of Fourier Transform in some capacity. Joseph Fourier was an 18th century
    French mathematician who discovered and popularized many mathematical concepts,
    and concentrated his work on studying the laws governing heat, and in mathematics,
    all things waveform. In particular, he observed that all waveforms are just the
    sum of simple sinusoids of different frequencies.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, the waveforms you observe all around you are the sum of other
    waveforms. This concept is incredibly useful when manipulating images, because
    it allows us to identify regions in images where a signal (such as image pixels)
    changes a lot, and regions where the change is less dramatic. We can then arbitrarily
    mark these regions as noise or regions of interests, background or foreground,
    and so on. These are the frequencies that make up the original image, and we have
    the power to separate them to make sense of the image and extrapolate interesting
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In an OpenCV context, there are a number of algorithms implemented that enable
    us to process images and make sense of the data contained in them, and these are
    also reimplemented in NumPy to make our life even easier. NumPy has a **Fast Fourier
    Transform** (**FFT**) package, which contains the `fft2()` method. This method
    allows us to compute **Discrete Fourier Transform** (**DFT**) of the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s examine the **magnitude spectrum** concept of an image using Fourier
    Transform. The magnitude spectrum of an image is another image, which gives a
    representation of the original image in terms of its changes: think of it as taking
    an image and dragging all the brightest pixels to the center. Then, you gradually
    work your way out to the border where all the darkest pixels have been pushed.
    Immediately, you will be able to see how many light and dark pixels are contained
    in your image and the percentage of their distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of Fourier Transform is the basis of many algorithms used for common
    image processing operations, such as edge detection or line and shape detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before examining these in detail, let''s take a look at two concepts that—in
    conjunction with the Fourier Transform—form the foundation of the aforementioned
    processing operations: high pass filters and low pass filters.'
  prefs: []
  type: TYPE_NORMAL
- en: High pass filter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **high pass filter** (**HPF**) is a filter that examines a region of an image
    and boosts the intensity of certain pixels based on the difference in the intensity
    with the surrounding pixels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take, for example, the following kernel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A **kernel** is a set of weights that are applied to a region in a source image
    to generate a single pixel in the destination image. For example, a `ksize` of
    `7` implies that `49 (7 x 7)` source pixels are considered in generating each
    destination pixel. We can think of a kernel as a piece of frosted glass moving
    over the source image and letting through a diffused blend of the source's light.
  prefs: []
  type: TYPE_NORMAL
- en: After calculating the sum of differences of the intensities of the central pixel
    compared to all the immediate neighbors, the intensity of the central pixel will
    be boosted (or not) if a high level of changes are found. In other words, if a
    pixel stands out from the surrounding pixels, it will get boosted.
  prefs: []
  type: TYPE_NORMAL
- en: This is particularly effective in edge detection, where a common form of HPF
    called high boost filter is used.
  prefs: []
  type: TYPE_NORMAL
- en: Both high pass and low pass filters use a property called `radius`, which extends
    the area of the neighbors involved in the filter calculation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go through an example of an HPF:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that both filters sum up to `0`, the reason for this is explained in detail
    in the *Edge detection* section.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: After the initial imports, we define a `3x3` kernel and a `5x5` kernel, and
    then we load the image in grayscale. Normally, the majority of image processing
    is done with NumPy; however, in this particular case, we want to "convolve" an
    image with a given kernel and NumPy happens to only accept one-dimensional arrays.
  prefs: []
  type: TYPE_NORMAL
- en: This does not mean that the convolution of deep arrays can't be achieved with
    NumPy, just that it would be a bit complex. Instead, `ndimage` (which is a part
    of SciPy, so you should have it installed as per the instructions in [Chapter
    1](part0014.xhtml#aid-DB7S2 "Chapter 1. Setting Up OpenCV"), *Setting Up OpenCV*),
    makes this trivial, through its `convolve()` function, which supports the classic
    NumPy arrays that the `cv2` modules use to store images.
  prefs: []
  type: TYPE_NORMAL
- en: We apply two HPFs with the two convolution kernels we defined. Lastly, we also
    implement a differential method of obtaining a HPF by applying a low pass filter
    and calculating the difference with the original image. You will notice that the
    third method actually yields the best result, so let's also elaborate on low pass
    filters.
  prefs: []
  type: TYPE_NORMAL
- en: Low pass filter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If an HPF boosts the intensity of a pixel, given its difference with its neighbors,
    a **low pass filter** (**LPF**) will smoothen the pixel if the difference with
    the surrounding pixels is lower than a certain threshold. This is used in denoising
    and blurring. For example, one of the most popular blurring/smoothening filters,
    the Gaussian blur, is a low pass filter that attenuates the intensity of high
    frequency signals.
  prefs: []
  type: TYPE_NORMAL
- en: Creating modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As in the case of our `CaptureManager` and `WindowManager` classes, our filters
    should be reusable outside Cameo. Thus, we should separate the filters into their
    own Python module or file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a file called `filters.py` in the same directory as `cameo.py`.
    We need the following `import` statements in `filters.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also create a file called `utils.py` in the same directory. It should
    contain the following `import` statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We will be adding filter functions and classes to `filters.py`, while more general-purpose
    math functions will go in `utils.py`.
  prefs: []
  type: TYPE_NORMAL
- en: Edge detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Edges play a major role in both human and computer vision. We, as humans, can
    easily recognize many object types and their pose just by seeing a backlit silhouette
    or a rough sketch. Indeed, when art emphasizes edges and poses, it often seems
    to convey the idea of an archetype, such as Rodin's *The Thinker* or Joe Shuster's
    *Superman*. Software, too, can reason about edges, poses, and archetypes. We will
    discuss these kinds of reasonings in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV provides many edge-finding filters, including `Laplacian()`, `Sobel()`,
    and `Scharr()`. These filters are supposed to turn non-edge regions to black while
    turning edge regions to white or saturated colors. However, they are prone to
    misidentifying noise as edges. This flaw can be mitigated by blurring an image
    before trying to find its edges. OpenCV also provides many blurring filters, including
    `blur()` (simple average), `medianBlur()`, and `GaussianBlur()`. The arguments
    for the edge-finding and blurring filters vary but always include `ksize`, an
    odd whole number that represents the width and height (in pixels) of a filter's
    kernel.
  prefs: []
  type: TYPE_NORMAL
- en: For blurring, let's use `medianBlur()`, which is effective in removing digital
    video noise, especially in color images. For edge-finding, let's use `Laplacian()`,
    which produces bold edge lines, especially in grayscale images. After applying
    `medianBlur()`, but before applying `Laplacian()`, we should convert the image
    from BGR to grayscale.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have the result of `Laplacian()`, we can invert it to get black edges
    on a white background. Then, we can normalize it (so that its values range from
    0 to 1) and multiply it with the source image to darken the edges. Let''s implement
    this approach in `filters.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note that we allow kernel sizes to be specified as arguments for `strokeEdges()`.
    The `blurKsize` argument is used as `ksize` for `medianBlur()`, while `edgeKsize`
    is used as `ksize` for `Laplacian()`. With my webcams, I find that a `blurKsize`
    value of `7` and an `edgeKsize` value of `5` looks best. Unfortunately, `medianBlur()`
    is expensive with a large `ksize`, such as `7`.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you encounter performance problems when running `strokeEdges()`, try decreasing
    the `blurKsize` value. To turn off blur, set it to a value less than `3`.
  prefs: []
  type: TYPE_NORMAL
- en: Custom kernels – getting convoluted
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have just seen, many of OpenCV's predefined filters use a kernel. Remember
    that a kernel is a set of weights, which determine how each output pixel is calculated
    from a neighborhood of input pixels. Another term for a kernel is a **convolution
    matrix**. It mixes up or convolves the pixels in a region. Similarly, a kernel-based
    filter may be called a convolution filter.
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenCV provides a very versatile `filter2D()` function, which applies any kernel
    or convolution matrix that we specify. To understand how to use this function,
    let''s first learn the format of a convolution matrix. It is a 2D array with an
    odd number of rows and columns. The central element corresponds to a pixel of
    interest and the other elements correspond to the neighbors of this pixel. Each
    element contains an integer or floating point value, which is a weight that gets
    applied to an input pixel''s value. Consider this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, the pixel of interest has a weight of `9` and its immediate neighbors
    each have a weight of `-1`. For the pixel of interest, the output color will be
    nine times its input color minus the input colors of all eight adjacent pixels.
    If the pixel of interest is already a bit different from its neighbors, this difference
    becomes intensified. The effect is that the image looks *sharper* as the contrast
    between the neighbors is increased.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing our example, we can apply this convolution matrix to a source and
    destination image, respectively, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The second argument specifies the per-channel depth of the destination image
    (such as `cv2.CV_8U` for 8 bits per channel). A negative value (as used here)
    means that the destination image has the same depth as the source image.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For color images, note that `filter2D()` applies the kernel equally to each
    channel. To use different kernels on different channels, we would also have to
    use the `split()` and `merge()` functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on this simple example, let''s add two classes to `filters.py`. One class,
    `VConvolutionFilter`, will represent a convolution filter in general. A subclass,
    `SharpenFilter`, will represent our sharpening filter specifically. Let''s edit
    `filters.py` to implement these two new classes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the weights sum up to `1`. This should be the case whenever we want
    to leave the image''s overall brightness unchanged. If we modify a sharpening
    kernel slightly so that its weights sum up to `0` instead, we have an edge detection
    kernel that turns edges white and non-edges black. For example, let''s add the
    following edge detection filter to `filters.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let''s make a blur filter. Generally, for a blur effect, the weights
    should sum up to `1` and should be positive throughout the neighborhood. For example,
    we can take a simple average of the neighborhood as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Our sharpening, edge detection, and blur filters use kernels that are highly
    symmetric. Sometimes, though, kernels with less symmetry produce an interesting
    effect. Let''s consider a kernel that blurs on one side (with positive weights)
    and sharpens on the other (with negative weights). It will produce a ridged or
    *embossed* effect. Here is an implementation that we can add to `filters.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This set of custom convolution filters is very basic. Indeed, it is more basic
    than OpenCV's ready-made set of filters. However, with a bit of experimentation,
    you should be able to write your own kernels that produce a unique look.
  prefs: []
  type: TYPE_NORMAL
- en: Modifying the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have high-level functions and classes for several filters, it is
    trivial to apply any of them to the captured frames in Cameo. Let''s edit `cameo.py`
    and add the lines that appear in bold face in the following excerpt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, I have chosen to apply two effects: stroking the edges and emulating
    Portra film colors. Feel free to modify the code to apply any filters you like.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a screenshot from Cameo with stroked edges and Portra-like colors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Modifying the application](img/image00194.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Edge detection with Canny
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'OpenCV also offers a very handy function called Canny (after the algorithm''s
    inventor, John F. Canny), which is very popular not only because of its effectiveness,
    but also the simplicity of its implementation in an OpenCV program, as it is a
    one-liner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is a very clear identification of the edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Edge detection with Canny](img/image00195.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The Canny edge detection algorithm is quite complex but also interesting: it''s
    a five-step process that denoises the image with a Gaussian filter, calculates
    gradients, applies **non maximum** **suppression** (**NMS**) on edges, a double
    threshold on all the detected edges to eliminate false positives, and, lastly,
    analyzes all the edges and their connection to each other to keep the real edges
    and discard the weak ones.'
  prefs: []
  type: TYPE_NORMAL
- en: Contour detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another vital task in computer vision is contour detection, not only because
    of the obvious aspect of detecting contours of subjects contained in an image
    or video frame, but because of the derivative operations connected with identifying
    contours.
  prefs: []
  type: TYPE_NORMAL
- en: These operations are, namely, computing bounding polygons, approximating shapes,
    and generally calculating regions of interest, which considerably simplify interaction
    with image data because a rectangular region with NumPy is easily defined with
    an array slice. We will be using this technique a lot when exploring the concept
    of object detection (including faces) and object tracking.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go in order and familiarize ourselves with the API first with an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Firstly, we create an empty black image that is 200x200 pixels in size. Then,
    we place a white square in the center of it utilizing ndarray's ability to assign
    values on a slice.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then threshold the image, and call the `findContours()` function. This function
    has three parameters: the input image, hierarchy type, and the contour approximation
    method. There are a number of aspects that are of particular interest in this
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: The function modifies the input image, so it would be advisable to use a copy
    of the original image (for example, by passing `img.copy()`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Secondly, the hierarchy tree returned by the function is quite important: `cv2.RETR_TREE`
    will retrieve the entire hierarchy of contours in the image, enabling you to establish
    "relationships" between contours. If you only want to retrieve the most external
    contours, use `cv2.RETR_EXTERNAL`. This is particularly useful when you want to
    eliminate contours that are entirely contained in other contours (for example,
    in a vast majority of cases, you won''t need to detect an object within another
    object of the same type).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `findContours` function returns three elements: the modified image, contours,
    and their hierarchy. We use the contours to draw on the color version of the image
    (so that we can draw contours in green) and eventually display it.'
  prefs: []
  type: TYPE_NORMAL
- en: The result is a white square with its contour drawn in green. Spartan, but effective
    in demonstrating the concept! Let's move on to more meaningful examples.
  prefs: []
  type: TYPE_NORMAL
- en: Contours – bounding box, minimum area rectangle, and minimum enclosing circle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finding the contours of a square is a simple task; irregular, skewed, and rotated
    shapes bring the best out of the `cv2.findContours` utility function of OpenCV.
    Let''s take a look at the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Contours – bounding box, minimum area rectangle, and minimum enclosing circle](img/image00196.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In a real-life application, we would be most interested in determining the
    bounding box of the subject, its minimum enclosing rectangle, and its circle.
    The `cv2.findContours` function in conjunction with a few other OpenCV utilities
    makes this very easy to accomplish:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: After the initial imports, we load the image, and then apply a binary threshold
    on a grayscale version of the original image. By doing this, we operate all find-contour
    calculations on a grayscale copy, but we draw on the original so that we can utilize
    color information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, let''s calculate a simple bounding box:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a pretty straightforward conversion of contour information to the `(x,
    y)` coordinates, plus the height and width of the rectangle. Drawing this rectangle
    is an easy task and can be done using this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Secondly, let''s calculate the minimum area enclosing the subject:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The mechanism used here is particularly interesting: OpenCV does not have a
    function to calculate the coordinates of the minimum rectangle vertexes directly
    from the contour information. Instead, we calculate the minimum rectangle area,
    and then calculate the vertexes of this rectangle. Note that the calculated vertexes
    are floats, but pixels are accessed with integers (you can''t access a "portion"
    of a pixel), so we need to operate this conversion. Next, we draw the box, which
    gives us the perfect opportunity to introduce the `cv2.drawContours` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Firstly, this function—like all drawing functions—modifies the original image.
    Secondly, it takes an array of contours in its second parameter, so you can draw
    a number of contours in a single operation. Therefore, if you have a single set
    of points representing a contour polygon, you need to wrap these points into an
    array, exactly like we did with our box in the preceding example. The third parameter
    of this function specifies the index of the contours array that we want to draw:
    a value of `-1` will draw all contours; otherwise, a contour at the specified
    index in the contours array (the second parameter) will be drawn.'
  prefs: []
  type: TYPE_NORMAL
- en: Most drawing functions take the color of the drawing and its thickness as the
    last two parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last bounding contour we''re going to examine is the minimum enclosing
    circle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The only peculiarity of the `cv2.minEnclosingCircle` function is that it returns
    a two-element tuple, of which the first element is a tuple itself, representing
    the coordinates of the circle's center, and the second element is the radius of
    this circle. After converting all these values to integers, drawing the circle
    is quite a trivial operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final result on the original image looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Contours – bounding box, minimum area rectangle, and minimum enclosing circle](img/image00197.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Contours – convex contours and the Douglas-Peucker algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the time, when working with contours, subjects will have the most diverse
    shapes, including convex ones. A convex shape is one where there are two points
    within this shape whose connecting line goes outside the perimeter of the shape
    itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first facility that OpenCV offers to calculate the approximate bounding
    polygon of a shape is `cv2.approxPolyDP`. This function takes three parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: A contour
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An epsilon value representing the maximum discrepancy between the original contour
    and the approximated polygon (the lower the value, the closer the approximated
    value will be to the original contour)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Boolean flag signifying that the polygon is closed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The epsilon value is of vital importance to obtain a useful contour, so let's
    understand what it represents. An epsilon is the maximum difference between the
    approximated polygon's perimeter and the original contour's perimeter. The lower
    this difference is, the more the approximated polygon will be similar to the original
    contour.
  prefs: []
  type: TYPE_NORMAL
- en: You may ask yourself why we need an approximate polygon when we have a contour
    that is already a precise representation. The answer to this is that a polygon
    is a set of straight lines, and the importance of being able to define polygons
    in a region for further manipulation and processing is paramount in many computer
    vision tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we know what an epsilon is, we need to obtain contour perimeter information
    as a reference value. This is obtained with the `cv2.arcLength` function of OpenCV:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Effectively, we're instructing OpenCV to calculate an approximated polygon whose
    perimeter can only differ from the original contour in an epsilon ratio.
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenCV also offers a `cv2.convexHull` function to obtain processed contour
    information for convex shapes and this is a straightforward one-line expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s combine the original contour, approximated polygon contour, and the
    convex hull in one image to observe the difference between them. To simplify things,
    I''ve applied the contours to a black image so that the original subject is not
    visible but its contours are:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Contours – convex contours and the Douglas-Peucker algorithm](img/image00198.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the convex hull surrounds the entire subject, the approximated
    polygon is the innermost polygon shape, and in between the two is the original
    contour, mainly composed of arcs.
  prefs: []
  type: TYPE_NORMAL
- en: Line and circle detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Detecting edges and contours are not only common and important tasks, they also
    constitute the basis for other complex operations. Lines and shape detection go
    hand in hand with edge and contour detection, so let's examine how OpenCV implements
    these.
  prefs: []
  type: TYPE_NORMAL
- en: The theory behind lines and shape detection has its foundation in a technique
    called the Hough transform, invented by Richard Duda and Peter Hart, who extended
    (generalized) the work done by Paul Hough in the early 1960s.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at OpenCV's API for the Hough transforms.
  prefs: []
  type: TYPE_NORMAL
- en: Line detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First of all, let's detect some lines, which is done with the `HoughLines` and
    `HoughLinesP` functions. The only difference between the two functions is that
    one uses the standard Hough transform, and the second uses the probabilistic Hough
    transform (hence `P` in the name).
  prefs: []
  type: TYPE_NORMAL
- en: The probabilistic version is so-called because it only analyzes a subset of
    points and estimates the probability of these points all belonging to the same
    line. This implementation is an optimized version of the standard Hough transform,
    and in this case, it's less computationally intensive and executes faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at a very simple example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The crucial point of this simple script—aside from the `HoughLines` function
    call—is the setting of minimum line length (shorter lines will be discarded) and
    the maximum line gap, which is the maximum size of a gap in a line before the
    two segments start being considered as separate lines.
  prefs: []
  type: TYPE_NORMAL
- en: Also note that the `HoughLines` function takes a single channel binary image,
    processed through the Canny edge detection filter. Canny is not a strict requirement,
    however; an image that's been denoised and only represents edges, is the ideal
    source for a Hough transform, so you will find this to be a common practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'The parameters of `HoughLinesP` are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The image we want to process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The geometrical representations of the lines, `rho` and `theta`, which are usually
    `1` and `np.pi/180`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The threshold, which represents the threshold below which a line is discarded.
    The Hough transform works with a system of bins and votes, with each bin representing
    a line, so any line with a minimum of the `<threshold>` votes is retained, the
    rest discarded.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MinLineLength` and `MaxLineGap`, which we mentioned previously.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circle detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'OpenCV also has a function for detecting circles, called `HoughCircles`. It
    works in a very similar fashion to `HoughLines`, but where `minLineLength` and
    `maxLineGap` were the parameters to discard or retain lines, `HoughCircles` has
    a minimum distance between circles'' centers, minimum, and maximum radius of the
    circles. Here''s the obligatory example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s a visual representation of the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Circle detection](img/image00199.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Detecting shapes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The detection of shapes with the Hough transform is limited to circles; however,
    we already implicitly explored detecting shapes of any kind, specifically when
    we talked about `approxPolyDP`. This function allows the approximation of polygons,
    so if your image contains polygons, they will be quite accurately detected, combining
    the usage of `cv2.findContours` and `cv2.approxPolyDP`.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, you should have gained a good understanding of color spaces,
    Fourier Transform, and the several kinds of filters made available by OpenCV to
    process images.
  prefs: []
  type: TYPE_NORMAL
- en: You should also be proficient in detecting edges, lines, circles, and shapes
    in general. Additionally, you should be able to find contours and exploit the
    information they provide about the subjects contained in an image. These concepts
    will serve as the ideal background to explore the topics in the next chapter.
  prefs: []
  type: TYPE_NORMAL
