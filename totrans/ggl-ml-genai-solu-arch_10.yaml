- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Hyperparameters and Optimization
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数和优化
- en: We introduced the concepts of hyperparameters and hyperparameter optimization
    (or tuning) in [*Chapter 2*](B18143_02.xhtml#_idTextAnchor035). In this chapter,
    we will dive into these concepts in more detail, and we will use Google Cloud
    products such as Vertex AI Vizier to define and run hyperparameter tuning jobs.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [*第 2 章*](B18143_02.xhtml#_idTextAnchor035) 中介绍了超参数和超参数优化（或调整）的概念。在本章中，我们将更详细地探讨这些概念，并使用
    Google Cloud 产品，如 Vertex AI Vizier，来定义和运行超参数调整作业。
- en: Following our established pattern, we will begin by covering some prerequisites
    that are required for the hands-on activities in this chapter. Then, we cover
    some important basic concepts that relate to the content covered in this chapter,
    and finally, we perform hands-on activities that teach you how to apply those
    concepts in real-world scenarios.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 按照我们建立的模式，我们将首先介绍本章实践活动中所需的先决条件。然后，我们将介绍与本章内容相关的一些重要基本概念，最后，我们将进行实践操作，教您如何在现实场景中应用这些概念。
- en: 'This chapter covers the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了以下主题：
- en: Prerequisites and basic concepts
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先决条件和基本概念
- en: What are hyperparameters?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是超参数？
- en: Hyperparameter optimization
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数优化
- en: 'Hands-on: performing hyperparameter tuning in Vertex AI'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实践：在 Vertex AI 中进行超参数调整
- en: Let’s begin by reviewing the prerequisites for this chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先回顾本章的先决条件。
- en: Prerequisites
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 先决条件
- en: The steps in this section need to be completed before we can perform the primary
    activities in this chapter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中执行主要活动之前，需要完成本节中的步骤。
- en: Enabling the Artifact Registry API
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启用 Artifact Registry API
- en: We’re going to create Docker images in order to run our custom code in conjunction
    with the Google Cloud Vertex AI Vizier service. The Google Cloud Artifact Registry
    is a fully managed artifact repository that we can use for storing our container
    images. It can be seen as the next generation of the **Google Cloud Container
    Registry** (**GCR**) that can be used to store artifacts such as Java JAR files,
    Node.js modules, Python wheels, Go modules, Maven artifacts, and npm packages
    (in addition to Docker images, which were already supported in GCR).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建 Docker 镜像，以便与 Google Cloud Vertex AI Vizier 服务一起运行我们的自定义代码。Google Cloud
    Artifact Registry 是一个完全管理的工件存储库，我们可以用它来存储我们的容器镜像。它可以被视为下一代 **Google Cloud Container
    Registry** (**GCR**)，可以用来存储诸如 Java JAR 文件、Node.js 模块、Python 轮子、Go 模块、Maven 工件和
    npm 包（除了已经支持在 GCR 中的 Docker 镜像）等工件。
- en: 'To enable the Artifact Registry API, perform the following steps:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用 Artifact Registry API，请执行以下步骤：
- en: In the Google Cloud console, navigate to **Google Cloud services menu** → **APIs
    & Services** → **Library**
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Google Cloud 控制台中，导航到 **Google Cloud 服务菜单** → **APIs & Services** → **Library**
- en: Search for `Artifact Registry` in the search box.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中搜索 `Artifact Registry`。
- en: Select the API in the list of results.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在结果列表中选择 API。
- en: On the page that displays information about the API, click **Enable**.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在显示 API 信息的页面上，点击 **启用**。
- en: Next, let’s set up the required permissions for the steps in this chapter.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们设置本章步骤所需的权限。
- en: Creating an AI/ML service account
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 AI/ML 服务账户
- en: In [*Chapter 6*](B18143_06.xhtml#_idTextAnchor187), we created a service account
    for using Google Cloud’s data processing services. In this chapter, we will create
    a service account that will be used in our hyperparameter tuning job for administering
    resources in Google Cloud Vertex AI.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 6 章*](B18143_06.xhtml#_idTextAnchor187) 中，我们创建了一个服务账户来使用 Google Cloud
    的数据处理服务。在本章中，我们将创建一个服务账户，该账户将用于在 Google Cloud Vertex AI 中管理资源时的超参数调整作业。
- en: 'Perform the following steps to create the required service account:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以创建所需的服务账户：
- en: In the Google Cloud console, navigate to **Google Cloud services menu** → **IAM
    & Admin** → **Service accounts**.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Google Cloud 控制台中，导航到 **Google Cloud 服务菜单** → **IAM & Admin** → **服务账户**。
- en: Select **Create** **service account**.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 **创建** **服务账户**。
- en: For the service account name, enter `ai-ml-sa`.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于服务账户名称，输入 `ai-ml-sa`。
- en: Click **Create** **and Continue**.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **创建** **并继续**。
- en: In the section titled **Grant this service account access to project**, add
    the roles shown in *Figure 8**.1*.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在标题为 **授予此服务账户访问项目** 的部分中，添加 *图 8**.1 中显示的角色。
- en: '![Figure 8.1: AI/ML service account permissions](img/B18143_08_1.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1：AI/ML 服务账户权限](img/B18143_08_1.jpg)'
- en: 'Figure 8.1: AI/ML service account permissions'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1：AI/ML 服务账户权限
- en: Select **Done**.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 **完成**。
- en: Our service account is now ready to be used later in this chapter.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的服务账户现在已准备好在本章的后续部分使用。
- en: Now that we’ve covered the prerequisites, let’s discuss some concepts that we
    need to understand before performing the hands-on activities in this chapter.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了先决条件，让我们讨论一些在执行本章中的动手活动之前我们需要理解的概念。
- en: Concepts
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念
- en: This section describes concepts that underpin the practical activities we will
    cover in this chapter.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了支撑我们在本章中将要讨论的实践活动的概念。
- en: Model evaluation metrics used in this chapter
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本章中使用的模型评估指标
- en: We’ve already discussed the topic of model evaluation metrics in previous chapters.
    We first introduced the concept in [*Chapter 1*](B18143_01.xhtml#_idTextAnchor015),
    where we briefly discussed metrics such as the **mean squared error** (**MSE**)
    for regression use cases and accuracy for classification use cases. In [*Chapter
    5*](B18143_05.xhtml#_idTextAnchor168), we used functions in scikit-learn to calculate
    some of these metrics for the models we created, and we suggested looking up additional
    metrics as a supplemental learning activity at the end of that chapter.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在之前的章节中讨论了模型评估指标的话题。我们首先在[*第一章*](B18143_01.xhtml#_idTextAnchor015)中介绍了这个概念，其中我们简要讨论了如回归用例的**均方误差**（**MSE**）和分类用例的准确率等指标。在[*第五章*](B18143_05.xhtml#_idTextAnchor168)中，我们使用了scikit-learn中的函数来计算我们创建的模型的一些这些指标，并在该章节的末尾建议将查找更多指标作为补充学习活动。
- en: In this chapter, we will train models for a classification use case, and we
    will introduce some additional metrics to evaluate our models. The main metric
    we will use is something called **AUC ROC**, which stands for **area under the
    receiver operating characteristic curve**. That sounds like a lot, but don’t worry,
    we will explain this metric in more detail in this section. In order to do so,
    we need to first introduce some concepts and simpler metrics that are used in
    calculating the AUC ROC.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将为分类用例训练模型，并介绍一些额外的指标来评估我们的模型。我们将使用的主要指标是称为**AUC ROC**的东西，它代表**接收者操作特征曲线下的面积**。听起来可能很多，但别担心，我们将在本节中更详细地解释这个指标。为了做到这一点，我们首先需要介绍一些概念和用于计算AUC
    ROC的更简单的指标。
- en: Note that in a binary classification use case, the model needs to predict one
    of two possible outcomes for each data point in the dataset, true or false, also
    referred to as **positive** or **negative**. They are usually represented by 1
    and 0.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在二元分类用例中，模型需要预测数据集中每个数据点的两种可能结果之一，即真或假，也称为**积极**或**消极**。它们通常用1和0表示。
- en: Models are rarely perfect, so they will sometimes make mistakes. Let’s take
    a look at the possible outcomes of a binary classification model’s predictions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 模型很少完美，所以它们有时会犯错误。让我们看看二元分类模型预测的可能结果。
- en: True positives, false positives, true negatives, and false negatives
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 真阳性、假阳性、真阴性和假阴性
- en: 'A binary classification model’s predictions generally have four possible outcomes:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 二元分类模型的预测通常有四种可能的结果：
- en: When our model predicts something to be true (or positive) and it really is
    true (or positive), we call this a **true** **positive** (**TP**)
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们的模型预测某事物为真（或积极）而实际上它是真（或积极）时，我们称之为**真阳性**（**TP**）
- en: When our model predicts something to be true (or positive) but really it is
    false (or negative), we call this a **false** **positive** (**FP**)
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们的模型预测某事物为真（或积极）但实际上它是假的（或消极）时，我们称之为**假阳性**（**FP**）
- en: When our model predicts something to be false (or negative) and it really is
    false (or negative), we call this a **true** **negative** (**TN**)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们的模型预测某事物为假（或消极）而实际上它是假（或消极）时，我们称之为**真阴性**（**TN**）
- en: When our model predicts something to be false (or negative) but it is really
    true (or positive), we call this a **false** **negative** (**FN**)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们的模型预测某事物为假（或消极）但实际上它是真的（或积极）时，我们称之为**假阴性**（**FN**）
- en: Let’s take a look at how these outcomes are related to each other in more detail.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这些结果是如何相互关联的。
- en: Confusion matrix
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: The preceding concepts can be represented visually in something called a confusion
    matrix, which is demonstrated in *Table 8.1*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 前述概念可以通过称为混淆矩阵的视觉方式来表示，这在*表8.1*中有演示。
- en: '|  | **Predicted negative** | **Predicted positive** |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | **预测为消极** | **预测为积极** |'
- en: '| Actual negative | TN | FP |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 实际消极 | TN | FP |'
- en: '| **Actual positive** | FN | TP |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| **实际积极** | FN | TP |'
- en: 'Table 8.1: Confusion matrix'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.1：混淆矩阵
- en: We can use the preceding concepts to calculate metrics that measure how well
    our models are performing when trying to accurately identify positive or negative
    data points in our dataset. We define these metrics next.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用前面的概念来计算衡量模型在尝试准确识别数据集中的正或负数据点时表现如何的指标。我们将在下面定义这些指标。
- en: True positive rate
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**真阳性率**'
- en: The **true positive rate** (**TPR**) represents a count of all of the data points
    in our dataset that our model correctly predicted as positive compared against
    all of the data points in the dataset that are positive, including any data points
    that our model erroneously predicted to be negative (i.e., our model said they
    were negative, even though they were positive, which means it was a false negative).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**真阳性率**（**TPR**）表示模型正确预测为正例的数据点总数与数据集中所有正例数据点的总数之比，包括模型错误地预测为负的数据点（即模型说它们是负的，尽管它们是正的，这意味着它是假阴性）。'
- en: The formula to calculate TPR is TPR = TP / (TP + FN)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 计算TPR的公式是TPR = TP / (TP + FN)
- en: TPR is also referred to as **recall** or **sensitivity**.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**TPR**也被称作**召回率**或**灵敏度**。'
- en: False positive rate
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**假阳性率**'
- en: The **false positive rate** (**FPR**) is the ratio of false positives (the number
    of negative instances incorrectly predicted as positive by our model) to the sum
    of false positives and true negatives (the number of negative instances correctly
    predicted by the model). In other words, it’s the proportion of actual negatives
    that are incorrectly identified as positive.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**假阳性率**（**FPR**）是假阳性（模型错误地将负例预测为正例的数量）与假阳性加上真负例（模型正确预测为负例的数量）之和的比率。换句话说，它是实际负例中被错误地识别为正例的比例。'
- en: The formula to calculate FPR is FPR = FP / (FP + TN)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 计算FPR的公式是FPR = FP / (FP + TN)
- en: TPR is also referred to as **fall out**.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**TPR**也被称作**漏报率**。'
- en: True negative rate
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**真阴性率**'
- en: The **true negative rate** (**TNR**) is described very similarly to how we described
    the TPR, just with positive and negative switched around. That is, the TNR represents
    a count of all of the data points in our dataset that our model correctly predicted
    as negative compared against all of the data points in the dataset that are negative,
    including any data points that our model erroneously predicted to be positive
    (i.e., our model said they were positive, even though they were negative, which
    means it was a false positive).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**真阴性率**（**TNR**）的描述方式与TPR类似，只是将正负进行了交换。也就是说，TNR表示模型正确预测为负的数据点总数与数据集中所有负例数据点的总数之比，包括模型错误地预测为正的数据点（即模型说它们是正的，尽管它们是负的，这意味着它是假阳性）。'
- en: The formula to calculate TNR is TNR = TN / (TN + FP)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 计算TNR的公式是TNR = TN / (TN + FP)
- en: TPR is also referred to as **specificity**.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**TPR**也被称作**特异性**。'
- en: False negative rate
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**假阴性率**'
- en: The **false negative rate** (**FNR**) is described very similarly to how we
    described the FPR, just with positive and negative switched around. It is the
    ratio of wrongly predicted negative observations to the actual positives. In other
    words, it’s the proportion of actual positives that are incorrectly identified
    as negative.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**假阴性率**（**FNR**）的描述方式与FPR类似，只是将正负进行了交换。它是错误预测的负观察值与实际正例的比率。换句话说，它是实际正例中被错误地识别为负例的比例。'
- en: The formula to calculate FNR is FNR = FN / (FN + TP)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 计算FNR的公式是FNR = FN / (FN + TP)
- en: Precision
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**精确度**'
- en: Precision is the ratio of correctly predicted positive observations to the total
    predicted positives. In other words, out of all the instances the model predicted
    as positive, how many were actually positive?
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度是正确预测的正观察值与总预测正例的比率。换句话说，在模型预测为正的所有实例中，有多少实际上是正的？
- en: The formula to calculate FNR is P = TP / (TP + FP)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 计算FNR的公式是P = TP / (TP + FP)
- en: When I first started learning all of this stuff, I wondered why there were so
    many different metrics for measuring slightly different aspects of binary classification
    model performance.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始学习所有这些内容时，我 wonder为什么有这么多不同的指标来衡量二元分类模型性能的略微不同的方面。
- en: 'There are at least a couple of reasons for this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 至少有以下几个原因：
- en: '**Statistical basis**: These metrics are natural outcomes from statistical
    analysis in binary classification use cases'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统计基础**：这些指标是二元分类用例中统计分析的自然结果'
- en: '**Trial and error**: Each metric may be more important than the others, based
    on the desired outcomes of the use case'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**试错法**：每个指标可能比其他指标更重要，这取决于用例的预期结果。'
- en: Consider the following example for the second point. If you’re trying to predict
    credit card fraud, you may want to maximize the sensitivity of your model, which
    would reduce the number of false negatives as much as possible, even if that ends
    up causing more false positives. In other words, it’s better to accidentally flag
    a transaction as fraudulent even if it’s not fraudulent than to accidentally allow
    a fraudulent transaction to occur.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下第二个点的例子。如果你试图预测信用卡欺诈，你可能希望最大化你模型的敏感性，这将尽可能减少错误否定数，即使这最终导致更多的错误肯定。换句话说，即使交易并非欺诈，错误地将交易标记为欺诈也比错误地允许欺诈交易发生要好。
- en: On the other hand, if you’re creating a spam filter, you would probably prefer
    allowing a few spam emails to accidentally reach your inbox (false negatives)
    than having valid emails flagged as spam (false positives).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果你正在创建垃圾邮件过滤器，你可能更愿意允许一些垃圾邮件意外地进入你的收件箱（错误否定），而不是将有效邮件标记为垃圾邮件（错误肯定）。
- en: The preceding metrics are often too simple to use independently, and you will
    therefore usually want to find a more complex combination of metrics that provides
    a more balanced outcome. Even in the credit card fraud use case, too many false
    positives would be disruptive and frustrating for credit card customers. The balance
    depends on the threshold you specify (between 0 and 1) for determining whether
    something is positive or negative. For example, a low threshold results in more
    positives, while a higher threshold results in more negatives. This brings us
    to more advanced metrics such as F1 score and AUC ROC, which we describe next.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 前述指标通常过于简单，无法独立使用，因此你通常会想要找到一个更复杂的指标组合，以提供更平衡的结果。即使在信用卡欺诈用例中，太多的错误肯定也会对信用卡客户造成干扰和挫败。这种平衡取决于你指定的阈值（介于0和1之间），以确定某物是正还是负。例如，低阈值会导致更多的正例，而高阈值会导致更多的负例。这使我们转向更高级的指标，如F1分数和AUC
    ROC，我们将在下面描述。
- en: F1 score
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F1分数
- en: 'F1 score is defined as the **harmonic mean** of precision and recall, which
    is calculated using the following formula:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数定义为精确率和召回率的**调和平均数**，其计算公式如下：
- en: F1 = 2 * (precision * recall) / (precision + recall)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: F1 = 2 * (精确率 * 召回率) / (精确率 + 召回率)
- en: The F1 score is particularly useful when you care more about the positive class
    and you want to balance precision and recall.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数特别有用，当你更关心正类，并且想要平衡精确率和召回率时。
- en: AUC ROC
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AUC ROC
- en: To understand AUC ROC, let’s first break down its name. The **receiver operating
    characteristic** (**ROC**) is a pretty fancy name for a curve that is generated
    by plotting the TPR against the FPR at various classification threshold settings,
    as depicted in *Figure 8**.2*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解AUC ROC，我们首先分解其名称。**接收者操作特征**（ROC）是一个相当复杂的名称，指的是通过在不同分类阈值设置下绘制TPR与FPR的曲线生成的曲线，如图*图8.2*所示。
- en: '![Figure 8.2: AUC ROC](img/B18143_08_2.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2：AUC ROC](img/B18143_08_2.jpg)'
- en: 'Figure 8.2: AUC ROC'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2：AUC ROC
- en: The **area under the curve** (**AUC**) is a measure of the entire two-dimensional
    area underneath the ROC curve from (0, 0) to (1, 1), as represented by the blue
    area in *Figure 8**.2*. The AUC provides an aggregate measure of performance across
    all possible classification thresholds, and the objective is to maximize the area
    under the curve, so in the best possible scenario, the curve would stretch up
    into the top-left corner, filling up the entire graph.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**曲线下的面积**（AUC）是ROC曲线下从（0, 0）到（1, 1）的整个二维面积，如图*图8.2*中的蓝色区域所示。AUC提供了对所有可能的分类阈值的性能的汇总度量，目标是最大化曲线下的面积，因此，在最佳情况下，曲线会延伸到左上角，填满整个图表。'
- en: 'Let’s take a look at how to interpret the AUC ROC score values in more detail:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看如何解释AUC ROC分数值：
- en: An AUC ROC score of 1.0 means that the model is able to perfectly distinguish
    between all the positive and the negative data points correctly, in which case
    it has no false negatives and no false positives (i.e., no mistakes).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AUC ROC分数为1.0表示模型能够完美地区分所有正负数据点，在这种情况下，它没有错误否定和错误肯定（即没有错误）。
- en: An AUC ROC score of 0.5 means that the model is not able to accurately distinguish
    between positive and negative data points and performs no better than random guessing.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An AUC ROC score of less than 0.5 means that the model is performing worse than
    random guessing, predicting negatives as positives and positives as negatives.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding these metrics is important because they are generally what our
    ML algorithms are trying to optimize. In the next section, we will discuss hyperparameters
    and hyperparameter tuning and we will see that these objective metrics form the
    fundamental goal of our tuning jobs.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: What are hyperparameters?
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed in [*Chapter 2*](B18143_02.xhtml#_idTextAnchor035), hyperparameters
    are parameters that define aspects of how our model training jobs run. They are
    not the parameters in the dataset from which our models learn but rather external
    configuration options related to how the model training process is executed. They
    influence how the resulting models perform and they represent higher-level properties
    of the model, such as its complexity or how quickly it should learn.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are examples of hyperparameters that we’ve already discussed
    in this book:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: In our [*Chapter 2*](B18143_02.xhtml#_idTextAnchor035) discussion of hyperparameters,
    we covered examples such as learning rate and the number of epochs
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In [*Chapter 5*](B18143_05.xhtml#_idTextAnchor168), we configured the number
    of clusters as a hyperparameter for our K-means algorithm and we configured hyperparameters
    for our tree-based models, such as the maximum depth of our trees
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We talked about regularization in [*Chapter 7*](B18143_07.xhtml#_idTextAnchor215),
    and regularization parameters are another example of hyperparameters.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many more types of hyperparameters for different kinds of algorithms,
    and we will encounter more as we progress through this book.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter optimization
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How do we know what kinds of hyperparameters to use and what their values should
    be? Hyperparameters can be chosen based on domain knowledge, experience, or trial
    and error, but to most efficiently choose the best hyperparameters, we can use
    a process called hyperparameter optimization, or hyperparameter tuning, which
    is a systematic process that can be implemented via different mechanisms that
    we will discuss next. Ultimately, the goal of hyperparameter optimization is to
    tune the hyperparameters of a model to achieve the best performance as measured
    by running it against a validation set, which is a subset of our source dataset.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Methods for optimizing hyperparameter values
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [*Chapter 2*](B18143_02.xhtml#_idTextAnchor035), we described hyperparameter
    tuning mechanisms such as grid search, random search, and Bayesian optimization,
    summarized here as a quick refresher:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '**Grid search**: This is an exhaustive search of the entire hyperparameter
    space (i.e., it tries out every possible combination of all hyperparameter values).
    This is usually impractical and unnecessarily computationally expensive.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网格搜索**：这是对整个超参数空间（即尝试所有可能的超参数值组合）的穷举搜索。这通常是不切实际的，并且计算上过于昂贵。'
- en: '**Random search**: The random search approach uses a subsampling technique
    in which hyperparameter values are selected at random for each training job experiment.
    This will not result in all possible values of every hyperparameter being tested,
    but it can often be quite an efficient method for finding an effective set of
    hyperparameter values.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机搜索**：随机搜索方法使用一种子采样技术，其中为每个训练作业实验随机选择超参数值。这不会导致测试每个超参数的所有可能值，但它通常是一种非常有效的方法来找到一组有效的超参数值。'
- en: '**Bayesian optimization**: This uses an optimization algorithm, and it is something
    that is provided as a managed service in Google Cloud Vertex AI.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯优化**：这使用一种优化算法，并且是Google Cloud Vertex AI提供的一项托管服务。'
- en: 'The following are some additional hyperparameter tuning mechanisms that exist
    in the industry:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些在行业中存在的额外超参数调整机制：
- en: '**Gradient-based optimization**: This method uses Gradient Descent, which we’ve
    already covered in depth earlier in this book. These methods are often used when
    training neural networks. We provide a separate section later in this book that
    describes how to train neural networks in detail.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于梯度的优化**：这种方法使用梯度下降，我们已经在本书的早期部分对其进行了深入探讨。这些方法通常用于训练神经网络。本书后面将提供单独的部分，详细描述如何训练神经网络。'
- en: '**Evolutionary algorithms**: These are **population-based** optimization algorithms
    loosely modeled on the process of evolutionary natural selection. The term “population-based”
    refers to the practice of building a pool (or population) of potential candidates.
    In this context, each candidate in the population represents a different set of
    hyperparameters, and candidates are evaluated based on their validation performance.
    The best-performing ones are then selected to produce “offspring” for the next
    generation. These algorithms are also more likely to be used for advanced use
    cases such as neural networks, where the hyperparameter search space can be large
    and complex, and it can be expensive to evaluate the performance of individual
    solutions.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进化算法**：这些是**基于种群**的优化算法，其模型松散地基于自然选择的过程。术语“基于种群”指的是构建一个潜在候选者池（或种群）的做法。在这种情况下，种群中的每个候选者代表一组不同的超参数，候选者根据其验证性能进行评估。表现最好的候选者随后被选中以产生下一代的“后代”。这些算法也更有可能被用于高级用例，如神经网络，其中超参数搜索空间可能很大且复杂，评估单个解决方案的性能可能很昂贵。'
- en: '**Automated machine learning** (**AutoML**) **systems**: We discussed the process
    of AutoML in previous chapters. It can be used to automate the entire ML lifecycle,
    including hyperparameter tuning.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化机器学习**（**AutoML**）**系统**：我们在前面的章节中讨论了AutoML的过程。它可以用于自动化整个机器学习生命周期，包括超参数调整。'
- en: 'In any case, the general tuning process works as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，一般的调整过程如下：
- en: 'Split your source dataset into three subsets:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将源数据集分为三个子集：
- en: '**Training dataset**: Used to train the model'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练数据集**：用于训练模型'
- en: '**Validation dataset**: Used to evaluate each combination of hyperparameters
    during the tuning process'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**验证数据集**：用于在调整过程中评估每个超参数组合'
- en: '**Test dataset**: Used to test the final model'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**测试数据集**：用于测试最终模型'
- en: Select which type of machine learning model we want to create (e.g., linear
    regression, decision tree, neural network). This determines which specific hyperparameters
    can be tuned.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择我们想要创建的机器学习模型类型（例如，线性回归，决策树，神经网络）。这决定了哪些特定的超参数可以被调整。
- en: Set an initial range or grid of hyperparameters and values. This can be based
    on domain knowledge or research or we could just start with a random broad range
    and refine it over time.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置初始的超参数范围或网格及其值。这可以基于领域知识或研究，或者我们可以从随机广泛的范围开始，并在一段时间内对其进行细化。
- en: Choose a method for searching through the model’s hyperparameter space (e.g.,
    random search, Bayesian optimization).
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一种搜索模型超参数空间的方法（例如，随机搜索，贝叶斯优化）。
- en: For each combination of hyperparameters, fit the model to the training data
    and evaluate its performance by testing it against the validation data and measuring
    the appropriate objective metrics for the chosen type of model (e.g., MSE for
    regression, AUC ROC for binary classification).
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个超参数组合，将模型拟合到训练数据，并通过测试它来评估其性能，与验证数据比较，并测量所选模型类型的适当目标指标（例如，回归的MSE，二分类的AUC
    ROC）。
- en: Once all combinations have been evaluated, choose the combination of hyperparameter
    values that resulted in the best model performance.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦评估了所有组合，选择导致最佳模型性能的超参数值组合。
- en: Train a final model using those hyperparameters and test the resulting model
    using the `test` dataset to confirm the model’s ability to generalize to unseen
    data.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这些超参数训练一个最终模型，并使用`test`数据集测试该模型，以确认模型对未见数据的泛化能力。
- en: Note that finding the best set of hyperparameters and values could require iterating
    through the outlined steps hundreds or even thousands of times, which would be
    extremely time-consuming or potentially impossible to perform manually. This is
    why hyperparameter tuning jobs, which automate the steps, are often required.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，找到最佳的超参数和值组合可能需要迭代数百次甚至数千次概述的步骤，这将非常耗时，或者可能无法手动执行。这就是为什么通常需要自动化步骤的超参数调优作业。
- en: Now that we’ve covered many of the important theoretical concepts related to
    hyperparameter tuning, it’s time for us to shift our focus to the practical implementation
    of these concepts.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了与超参数调优相关的许多重要理论概念，是时候将我们的重点转移到这些概念的实际应用上了。
- en: 'Hands-on: performing hyperparameter tuning in Vertex AI'
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动手实践：在Vertex AI中进行超参数调优
- en: Considering that Google Cloud Vertex AI provides tools that make it easy for
    us to implement every step in the data science project lifecycle, this gives us
    the perfect environment to put our knowledge into practice and start implementing
    hyperparameter tuning jobs. In fact, as we mentioned previously, Vertex AI provides
    a tool called Vizier that is specialized for the purpose of automating hyperparameter
    tuning jobs, which we will dive into in more detail next.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到Google Cloud Vertex AI提供了使我们能够轻松实现数据科学项目生命周期中每一步的工具，这为我们提供了一个完美的环境来将我们的知识付诸实践并开始实施超参数调优作业。实际上，正如我们之前提到的，Vertex
    AI提供了一个名为Vizier的工具，专门用于自动化超参数调优作业，我们将在下一部分更详细地探讨。
- en: Vertex AI Vizier
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Vertex AI Vizier
- en: Vertex AI Vizier is a service in Google Cloud that automates the hyperparameter
    tuning process that we outlined in the previous section of this chapter. In this
    section, we discuss some terminology used by the Vertex AI Vizier service and
    we describe some details on how it works. Then, we will actually use it in our
    hands-on activities to implement hyperparameter tuning jobs.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI Vizier是Google Cloud中的一项服务，它自动化了我们在本章前一部分概述的超参数调优过程。在本节中，我们将讨论Vertex
    AI Vizier服务使用的某些术语，并描述其工作的一些细节。然后，我们将在我们的动手活动中实际使用它来实施超参数调优作业。
- en: Vertex AI Vizier terminology
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Vertex AI Vizier术语
- en: Google Cloud uses some terminology that is specific to the Vertex AI Vizier
    service. We will briefly describe some important terms here and relate them back
    to the generic concepts we covered earlier in this chapter.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud使用一些特定于Vertex AI Vizier服务的术语。我们在此简要描述一些重要术语，并将它们与我们本章早期讨论的通用概念联系起来。
- en: Studies, study configurations, and trials
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 研究、研究配置和试验
- en: In Vertex AI Vizier, a **study** represents the overall objective we are trying
    to achieve and all of the steps and other details involved in working towards
    that objective. For example, if we look at the general tuning process steps we
    outlined in the *Methods for optimizing hyperparameter values* section of this
    chapter, a study encapsulates all of those steps. A **study configuration** is
    the actual configuration object that contains all of the details of our study,
    such as the objective metric that we want the study to optimize, what parameters
    to test, and what kind of parameter search method to use.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在Vertex AI Vizier中，一个**研究**代表我们试图实现的总体目标以及实现该目标所涉及的所有步骤和其他细节。例如，如果我们查看本章“优化超参数值的方法”部分概述的一般调优过程步骤，一个研究封装了所有这些步骤。一个**研究配置**是包含我们研究所有细节的实际配置对象，例如我们希望研究优化的目标指标、要测试的参数以及要使用的参数搜索方法。
- en: A **trial** is an individual experiment in our study, or a single iteration
    in the tuning process (i.e., a single training and evaluation job that uses a
    specific set of hyperparameter values). A study will run many trials when working
    toward our specified objective.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: After you create a study, Vertex AI Vizier will start running trials on its
    own. In each test, a different set of hyperparameters will be used. Vertex AI
    Vizier will keep track of the results of each run and use this knowledge to choose
    the best set of hyperparameters (it will automatically stop running trials when
    it has found the best set of hyperparameters). Vizier will also summarize all
    of the trials and rank them according to which ones performed best with regard
    to the objective metric. Then, we can train our ML model with the hyperparameters
    from the top-ranking trial.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve gotten the terminology covered, let’s dive into the hands-on
    activities!
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Use case and dataset
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will develop an XGBoost model to detect credit card fraud
    using the `Credit Card Fraud Detection` dataset available on Kaggle ([https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’re going to use Jupyter Notebook for the hands-on activities in this chapter,
    and we’re going to customize the contents of the notebook, so we will use a `user-managed`
    notebook instance. We can use the same Vertex AI Workbench user-managed notebook
    instance that we created in [*Chapter 7*](B18143_07.xhtml#_idTextAnchor215). Please
    open JupyterLab on that notebook instance. In the directory explorer on the left
    side of the screen, navigate to the `Chapter-08` directory and open the `vizier-hpo.ipynb`
    notebook. You can choose `Python (Local)` as the kernel. Again, you can run each
    cell in the notebook by selecting the cell and pressing *Shift* + *Enter* on your
    keyboard. In addition to the relevant code, the notebook contains markdown text
    that describes what the code is doing.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: How our hyperparameter tuning job works
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using Vertex AI Vizier for hyperparameter tuning involves several steps that
    we implement in the model. Let’s take a look at the salient steps in the process:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: First, we create a training application, which consists of a Python script that
    trains our model with the given hyperparameters. This script must also track and
    report the performance of the model when testing it on the validation set so that
    Vertex AI Vizier can use those performance metrics to determine the best hyperparameters.
    For this reason, we use the `cloudml-hypertune` Python library in our code to
    periodically report the hyperparameter tuning metric back to Vertex AI.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we create a configuration object for the hyperparameter tuning job, which
    specifies the hyperparameters to tune and the range of their possible values to
    try, as well as the objective metric we want to optimize (in our case, we’re using
    AUC ROC, referred to simply as `auc` in the code). One important thing to note
    at this point is that the more hyperparameters we include, the more combinations
    of trials will need to be run. This could result in additional time and computing
    resources (and therefore cost) being needed for our tuning job. For this reason,
    it is best to use domain knowledge wherever possible to determine which hyperparameters
    we want the tuning job to focus on. We can also use the `maxTrials` variable in
    the configuration for the hyperparameter tuning job to control the number of trials.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Understandably, it’s not always possible to use domain knowledge to narrow the
    parameter search space, and we often will need to find a trade-off between the
    quality of our hyperparameter tuning job outputs and the time and costs required
    to run them. For example, running the tuning job for a very long time may get
    us as close as possible to finding the perfect set of hyperparameter values, but
    running it for a shorter time may get us results that are just good enough, depending
    on the needs of our use case.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The final stage in our hyperparameter tuning implementation is to use the Vertex
    AI Vizier client library to submit the hyperparameter tuning job to Vertex AI,
    which then runs our training application with different sets of hyperparameter
    values and finds the best ones.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the results of our hyperparameter tuning job
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Of course, we’re not just running hyperparameter tuning jobs for fun (although
    it is also fun)! When our tuning job finds the best set of hyperparameters, we
    will want to access and review them, and usually, we will want to then use them
    to train the final version of our model.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the results via the Google Cloud console
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When we run the hyperparameter tuning job in the notebook, the output from
    our code will display a link that will enable us to view the status of the tuning
    job in the Google Cloud console. The most important thing to view at that link
    is the list of trials performed by our tuning job, which will look similar to
    *Figure 8**.3*:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3: Hyperparameter tuning trials](img/B18143_08_3.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.3: Hyperparameter tuning trials'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: In the list of our hyperparameter tuning trials in the Google Cloud console,
    we can see the AUC metric for each trial, as well as the related trial ID (depicted
    within the box on the left in *Figure 8**.3*), and we can also see the hyperparameter
    values that were used for each trial (depicted within the box on the right in
    *Figure 8**.3*). We can click the arrow symbol in the header of the `auc` column
    to sort that column by ascending or descending AUC score. In our case, we want
    to sort it in descending order because we want the maximum score to appear at
    the top. This then tells us which trial had the hyperparameters that resulted
    in the best-performing model. In *Figure 8**.3*, you may notice that at least
    the top five trials all have the same AUC score. This is common because there
    may be multiple different combinations of hyperparameter values that can result
    in the same metric score. You can use the arrow in the bottom-right of the screen
    to peruse through the pages of additional trials, and you will see other trials
    that resulted in lower AUC scores.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the results programmatically
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: While it’s useful and interesting to view the results of our hyperparameter
    tuning jobs in the Google Cloud console, we likely won’t want to have to manually
    copy and paste them into the final training job to create our resulting model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, we can access all of those details programmatically via the Vertex
    API, and we can use the Vertex client library to do that from our development
    environment. In our notebook, after the tuning job finishes, we can continue with
    the additional activities in that notebook, which will show you how to access
    and use the best set of hyperparameter values produced by our tuning job. We then
    use those hyperparameter values to train a new model in our notebook, and then
    we finally test that model against the test dataset and calculate and display
    the resulting final AUC score. Note that when I ran this, I got a ROC-AUC score
    of 0.9188, which is pretty good!
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Great job, you have now learned quite a lot about the topic of hyperparameter
    tuning and you should be ready to start applying what you’ve learned to other
    types of ML problems. Let’s summarize what we’ve learned in this chapter.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we dived deeper into the important concept of objective metrics
    in machine learning. We covered, in detail, many of the most popular metrics that
    are used for evaluating binary classification models, such as precision, recall,
    F1 score, and ROC AUC. We then moved on to discuss hyperparameter optimization,
    including some of the important theoretical information in this area, such as
    the different types of methods that can be used to search for the optimal set
    of hyperparameters and associated values. This also provided some insight into
    why it can be very difficult or even impossible to efficiently perform hyperparameter
    tuning manually due to the large number of trials that can be required.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Next, we dived into the Google Cloud Vertex AI Vizier service, which can be
    used to automate the hyperparameter tuning process for us. We then performed hands-on
    activities in Jupyter Notebook on Vertex AI, and we used Vizier to automatically
    find the best set of hyperparameters for training a credit card fraud detection
    model using XGBoost.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们深入了解了Google Cloud Vertex AI Vizier服务，该服务可以用来自动为我们进行超参数调优。我们在Vertex AI上的Jupyter
    Notebook中进行了实际操作，并使用Vizier自动找到用于训练信用卡欺诈检测模型的最佳超参数集。
- en: Next, we used the outputs of our hyperparameter tuning job to train a final
    version of our model, and we then evaluated that model against our test dataset.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用超参数调优作业的输出训练了我们模型的最终版本，然后我们用测试数据集评估了该模型。
- en: In the next chapter, begin exploring beyond the simpler machine-learning algorithms
    such as linear regression and decision trees, and delve into the realm of Artificial
    Neural Networks (ANNs). Let's move on and discover this fascinating category of
    concepts and technologies.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始探索比线性回归和决策树等更简单的机器学习算法更深入的内容，并深入到人工神经网络（ANNs）的领域。让我们继续前进，发现这个概念和技术类别中的迷人之处。
