- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Preparing for ML Development
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备机器学习开发
- en: In *Part 2* of the book, we will examine the ML process. We will start from
    the preparation work, which includes ML problem framing to define an ML problem;
    data preparation and feature engineering to get the data ready; followed by the
    ML model development phases, which include model training, model validation, model
    testing, and model deployment. We will end *Part 2* with neural networks and DL.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的*第2部分*中，我们将检查机器学习过程。我们将从准备工作开始，包括机器学习问题界定来定义机器学习问题；数据准备和特征工程来准备数据；然后是机器学习模型开发阶段，包括模型训练、模型验证、模型测试和模型部署。我们将以神经网络和深度学习结束*第2部分*。
- en: 'In this chapter, will discuss the two ML preparation tasks: ML problem framing
    and data preparation. We will address the following questions for the problem
    we are solving:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论两个机器学习准备任务：机器学习问题界定和数据准备。我们将针对我们正在解决的问题提出以下问题：
- en: What are the business requirements?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 业务需求是什么？
- en: Is ML the best way to solve the problem?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习是解决问题的最佳方式吗？
- en: What are the inputs and outputs for the problem?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题的输入和输出是什么？
- en: Where is my data?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我的数据在哪里？
- en: How do I measure the success of the ML solution?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我如何衡量机器学习解决方案的成功？
- en: Is the data ready?
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据准备好了吗？
- en: How do I collect my data?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我如何收集我的数据？
- en: How do I transform and construct my data?
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我如何转换和构建我的数据？
- en: How do I select features for the ML model?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我如何为机器学习模型选择特征？
- en: 'It is very important that we identify the business requirements, understand
    the problem and its inputs/outputs, establish the business success measurements,
    and collect, transform, and construct high-quality datasets before model training
    and deployment. Through this process, we will learn and develop the following
    skills:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 确定业务需求、理解问题及其输入/输出、建立业务成功指标、在模型训练和部署之前收集、转换和构建高质量数据集非常重要。通过这个过程，我们将学习和培养以下技能：
- en: Defining and understanding a business problem
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义和理解业务问题
- en: Translating it to an ML problem
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将其转化为机器学习问题
- en: Defining and measuring the success of the business problem
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义和衡量业务问题的成功
- en: Defining high-quality datasets
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义高质量数据集
- en: Collecting data
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集数据
- en: Transforming and constructing data
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换和构建数据
- en: Feature engineering
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程
- en: Let’s keep these questions and skills in mind as we go through this chapter.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们阅读本章时，让我们牢记这些问题和技能。
- en: Starting from business requirements
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从业务需求开始
- en: 'A typical ML process starts by defining business requirements. Follow the following
    steps to define the business requirements of the problem:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的机器学习过程首先从定义业务需求开始。按照以下步骤定义问题的业务需求：
- en: Clearly define the business outcome that your ML solution is supposed to achieve,
    among all the stakeholders. For example, for a prediction ML problem, we need
    to define a range of accuracy that is acceptable by the business and agreed upon
    by all the stakeholders.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在所有利益相关者中，明确定义您的机器学习解决方案旨在实现的业务成果。例如，对于预测机器学习问题，我们需要定义一个业务可以接受的准确度范围，并且所有利益相关者都同意。
- en: Clearly define the data source of the ML problem. All ML projects are based
    on loads of data. You need to clearly define what the reliable data sources are,
    including training data, evaluation data, testing data, and a feed of regularly
    updated data.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 明确定义机器学习问题的数据来源。所有机器学习项目都基于大量数据。您需要明确定义可靠的数据来源，包括训练数据、评估数据、测试数据和定期更新的数据流。
- en: Clearly define the frequency of ML model updating (since data distributions
    drift over time), and the strategies for maintaining production during the model
    updating times.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 明确定义机器学习模型更新的频率（因为数据分布会随时间漂移），以及维护生产在模型更新时间内的策略。
- en: Clearly define the financial indications of the ML product or project. Understand
    any limitations such as resource availability and budget planning, and so on.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 明确定义机器学习产品或项目的财务指标。了解任何限制，如资源可用性和预算规划等。
- en: Clearly define the rules, policies, and regulations for the problem.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 明确定义问题的规则、政策和法规。
- en: 'Let us look at an example of the problem and the business requirements:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个问题和业务需求的例子：
- en: '**Example 1**: A real estate company called Zeellow does great business buying
    and selling properties in the United States. Due to the nature of the business,
    accurately predicting house prices is critical for Zeellow. Over the past few
    years, they have accumulated a large amount of historical data for US houses.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例 1**：一家名为 Zeellow 的房地产公司在美国买卖房产业务做得很好。由于业务性质，准确预测房价对 Zeellow 来说至关重要。在过去几年中，他们积累了大量美国房屋的历史数据。'
- en: Here, the business outcome is accurately predicting house prices in the United
    States. It is agreed by business stakeholders that more than 2% prediction error
    is not acceptable. The data source is defined as the in-house historical property
    database. Due to database updates, the model needs to be updated every month.
    There are two data scientists and two data engineers working full-time on the
    project, and enough funding has been provided. There are no regulations about
    the house data and the ML problem.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，业务成果是准确预测美国房价。业务利益相关者一致认为，超过 2% 的预测误差是不可接受的。数据源定义为内部历史房产数据库。由于数据库更新，模型需要每月更新。有两个数据科学家和两个数据工程师全职从事该项目，并且已经提供了足够的资金。关于房屋数据和机器学习问题没有规定。
- en: Defining ML problems
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义机器学习问题
- en: 'After we have identified the business requirements, we need to define the problem
    by identifying the features and target of the problem. For *Example 1*, the house
    price is the target, and features are the house attributes that affect the house
    price, such as the location, the house size (total square footage), the age of
    the house, the number of bedrooms and bathrooms of the house, and so on. *Table
    3.1* shows a small sample dataset:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们确定了业务需求之后，我们需要通过识别问题的特征和目标来定义问题。对于**示例 1**，房价是目标，特征是影响房价的房屋属性，如位置、房屋大小（总面积）、房屋年龄、房屋的卧室和浴室数量等。*表
    3.1* 展示了一个小样本数据集：
- en: '![Table 3.1 – Example 1 dataset ](img/Table_3.1.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![表 3.1 – 示例 1 数据集](img/Table_3.1.jpg)'
- en: Table 3.1 – Example 1 dataset
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.1 – 示例 1 数据集
- en: The problem is then defined as building a model among the features and the target
    and discovering their relationships. During the problem definition process, we
    will understand the problem better, decide whether ML is the best solution for
    the problem, and to what category the problem belongs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然后定义问题为在特征和目标之间建立模型并发现它们之间的关系。在问题定义过程中，我们将更好地理解问题，决定机器学习是否是解决问题的最佳解决方案，以及问题属于哪个类别。
- en: Is ML the best solution?
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习是最好的解决方案吗？
- en: When facing a problem, the first thing we need to do is choose the best modeling/solution
    for the problem. For example, given the initial position and speed of a physical
    object, its mass, and the forces acting on it, how can we precisely predict its
    position at any time *t*? For this problem, a traditional mathematical model,
    based on Newton’s laws in the classic mechanical world, works much better than
    any ML models!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 面对问题时，我们首先需要做的是为问题选择最佳的建模/解决方案。例如，给定一个物理对象的初始位置和速度、其质量和作用在其上的力，我们如何精确预测其在任何时间
    *t* 的位置？对于这个问题，基于经典力学世界中牛顿定律的传统数学模型，比任何机器学习模型都要好得多！
- en: 'While scientific modeling provides the mathematical relationship between the
    prediction target and features, there are many problems that are very hard or
    even impossible to build a mathematical model for, and ML may be the best way
    to solve these problems. How do we know whether ML is the best way to solve a
    given problem? There are several conditions that need to be checked when judging
    whether ML is a potentially good solution for a problem:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然科学建模提供了预测目标和特征之间的数学关系，但有许多问题很难建立数学模型，甚至不可能建立，机器学习可能是解决这些问题的最佳方式。我们如何知道机器学习是否是解决给定问题的最佳方式？在判断机器学习是否是潜在的良好解决方案时，需要检查以下条件：
- en: There is a pattern among the features and the predicting target. For *Example
    1*, we know the house price will be related to house features such as location,
    the total square footage, age, and so on, and there are patterns between the house
    price and its features.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征和预测目标之间存在一种模式。对于**示例 1**，我们知道房价将与房屋特征（如位置、总面积、年龄等）相关，并且房价与其特征之间存在模式。
- en: The existing pattern or relationship cannot be modeled using mathematics or
    science. For *Example 1*, the relationships between the price of the house and
    the features cannot be mathematically formulated.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现有的模式或关系无法用数学或科学方法建模。对于**示例 1**，房价和特征之间的关系无法用数学公式表示。
- en: There is plenty of quality data available. For *Example 1*, Zeellow has accumulated
    a large amount of historical data for US houses, including prices and their features.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用的优质数据量很大。对于**示例 1**，Zeellow 为美国房屋积累了大量历史数据，包括价格和其特征。
- en: In *Example 1*, Zeellow needs to predict house prices. Apparently, there are
    relationships between the house price and the features of the house, but it is
    very difficult to build a mathematical model to describe the relationships. Since
    we have enough historical data, ML is potentially a good way to solve the problem.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**示例 1**中，Zeellow 需要预测房屋价格。显然，房价和房屋特征之间存在关系，但建立数学模型来描述这些关系非常困难。由于我们有足够的历史数据，机器学习可能是解决该问题的有效方法。
- en: 'Let’s look at more examples and see whether ML is the best solution for them:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看更多示例，看看机器学习是否是它们的最佳解决方案：
- en: '**Example 2**: Zeellow Mortgage is a subsidiary of Zeellow and is a mortgage
    business in the States. They have also accumulated a large amount of historical
    data on mortgage applicants and are trying to automate the decision process of
    approval or denial for new applications.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例 2**：Zeellow 抵押贷款是 Zeellow 的子公司，是一家美国的抵押贷款业务。他们还积累了大量关于抵押贷款申请人的历史数据，并试图自动化对新申请的批准或拒绝决策过程。'
- en: '**Example 3**: Zeellow Appraisal is a subsidiary of Zeellow and they evaluate
    the prices of existing houses when they are under contract. One good approximation
    for that is to see how similar properties are priced, and this leads to the grouping
    of properties.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例 3**：Zeellow 评估是 Zeellow 的子公司，他们在房屋签订合同时评估现有房屋的价格。一个很好的近似方法是查看类似房产的定价情况，这会导致房产的分组。'
- en: After we examine these two problems and check their conditions, we can decide
    whether ML is the way to solve the problems. Further, we will look at the categories
    of ML problems and what types our three examples belong to.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查这两个问题及其条件后，我们可以决定机器学习是否是解决问题的方法。进一步地，我们将查看机器学习问题的类别以及我们的三个示例属于哪种类型。
- en: ML problem categories
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习问题类别
- en: ML problems can be divided into several categories. For *Example 1*, Zeellow
    needs to predict house prices, which is a continuous value, compared to *Example
    2* where ML needs to predict an approval (yes) or denial (no) for a mortgage application.
    An ML problem that outputs a continuous value is called **Regression**, while
    a problem that outputs discrete values (two or more) is called **Classification**.
    If there are two outputs (yes and no), then it’s called **Binary classification**.
    If there are more than two outputs, then it’s called **Multiclass classification**.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习问题可以分为几个类别。对于**示例 1**，Zeellow 需要预测房价，这是一个连续值，与**示例 2**中机器学习需要预测抵押贷款申请的批准（是）或拒绝（否）相比。输出连续值的机器学习问题称为**回归**，而输出离散值（两个或更多）的问题称为**分类**。如果有两个输出（是和否），则称为**二元分类**。如果有超过两个输出，则称为**多类分类**。
- en: In both *Example 1* and *Example 2*, we let the machine learn from the existing
    dataset that is labeled with results. *Example 1*’s datasets are for houses that
    have been sold in the past few years and thus include house location, the number
    of bedrooms and bathrooms, the age of the house and the sale price. *Example 2*’s
    datasets include the mortgage applicant’s gender, age, income, marital status,
    and so on, and whether the application was approved or denied. Since the inputs
    for both examples are labeled, they are called **supervised learning**. Input
    data such as the house’s location, the number of bedrooms and bathrooms, and the
    age of the house in *Example 1*, and the applicant’s gender, age, income, and
    marital status in *Example 2*, are called **features** since they reflect the
    datasets attributes (features).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在**示例 1**和**示例 2**中，我们让机器从带有结果的现有数据集中学习。**示例 1**的数据集是过去几年已售出的房屋数据，包括房屋位置、卧室和浴室数量、房屋年龄和售价。**示例
    2**的数据集包括抵押贷款申请人的性别、年龄、收入、婚姻状况等，以及申请是否被批准或拒绝。由于这两个示例的输入都是标记的，因此它们被称为**监督学习**。在**示例
    1**中，房屋的位置、卧室和浴室数量以及房屋年龄等输入数据被称为**特征**，因为它们反映了数据集的属性（特征）。
- en: '**Unsupervised learning problems**, on the other hand, have inputs that are
    not labeled. For *Example 3*, Zeellow Appraisal needs to divide houses into different
    groups, and each group has similar features. The focus here is not on the house
    prices but to identify meaningful patterns in the data and split the houses into
    groups. Since we do not label the datasets, it is an unsupervised learning problem.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**无监督学习问题**，另一方面，输入没有标签。对于**示例 3**，Zeellow 评估需要将房屋分成不同的组，并且每个组都有相似的特征。这里的重点不是房价，而是要识别数据中的有意义模式并将房屋分成组。由于我们没有标记数据集，这是一个无监督学习问题。'
- en: Another type of machine learning problem is **reinforcement learning** (**RL**).
    In RL, you don’t collect examples with labels. You set up the model (agent) and
    a reward function to reward the agent when it performs a task. With reinforcement
    learning, the agent can learn very quickly how to outperform humans. More details
    can be found on the Wikipedia page ([https://en.wikipedia.org/wiki/Reinforcement_learning](https://en.wikipedia.org/wiki/Reinforcement_learning)).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种机器学习问题是**强化学习**（**RL**）。在强化学习中，你不需要收集带有标签的例子。你设置模型（代理）和奖励函数，当代理完成一个任务时奖励它。通过强化学习，代理可以快速学会如何超越人类。更多详情可以在维基百科页面找到（[https://en.wikipedia.org/wiki/Reinforcement_learning](https://en.wikipedia.org/wiki/Reinforcement_learning)）。
- en: ML model inputs and outputs
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习模型的输入和输出
- en: In an ML problem, the inputs are usually datasets, including all kinds of data
    formats/media such as numerical data, images, audio, and so on. Input datasets
    are extremely important and will decide how good the ML model will be.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习问题中，输入通常是数据集，包括各种数据格式/媒体，如数值数据、图像、音频等。输入数据集非常重要，将决定机器学习模型的好坏。
- en: For supervised learning, labeled data is used to train the model, which is a
    piece of software representing what a machine has learned from the training data.
    Inputs to supervised learning are marked datasets of features and targets, and
    the model learns by comparing the labeled target values with the model outputs
    to find errors. The erroris what we want to optimize. Note we refer to the optimization
    of the error, not the minimization of the error. In other words, minimizing the
    error to zero may not generate the best model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于监督学习，使用标记数据来训练模型，这是一个代表机器从训练数据中学到什么的软件。监督学习的输入是标记的特征和目标的数据集，模型通过比较标记的目标值与模型输出以找到错误来学习。错误是我们想要优化的。注意，我们指的是错误的优化，而不是错误的极小化。换句话说，将错误最小化到零可能不会生成最好的模型。
- en: Within supervised learning, the output for a regression model is a continuous
    numerical value, and for a classification model, the output is a discrete value
    indicating a category (yes/no for binary classifications).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，回归模型的输出是一个连续的数值，而分类模型的输出是一个离散的值，表示一个类别（二分类中的是/否）。
- en: For unsupervised learning, input data is not labeled, and usually, the objective
    is to find the input data patterns and group them into different categories, called
    **clustering** or **grouping**.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于无监督学习，输入数据没有标签，通常的目标是找到输入数据的模式并将它们分组到不同的类别中，称为**聚类**或**分组**。
- en: For reinforcement learning, the input is a state, and the output is the action
    performed by ML. Between input and output, we have a function that takes a state
    as input and returns an action as output.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于强化学习，输入是一个状态，输出是机器学习执行的动作。在输入和输出之间，有一个函数，它以状态作为输入并返回一个动作作为输出。
- en: Measuring ML solutions and data readiness
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量机器学习解决方案和数据准备情况
- en: After we define the problem and conclude that ML is a potentially good solution
    to the problem, we need to set up a way of measuring the problem solution and
    whether it’s ready for production deployment. For *Example 1*, we need to have
    a consensus as to what range is acceptable for the house prediction errors and
    we can use the ML model in production.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们定义问题并得出结论，认为机器学习可能是解决问题的潜在好方法之后，我们需要建立一个衡量问题解决方案和它是否准备好生产部署的方法。对于**示例 1**，我们需要就房屋预测误差的接受范围达成共识，并且可以使用机器学习模型在生产环境中使用。
- en: ML model performance measurement
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习模型性能测量
- en: 'To evaluate the performance of ML solutions, we use ML metrics. For regression
    models, there are three metrics: mean square error, mean absolute error, and r-square.
    For classification models, we use the confusion matrix. We will discuss that more
    in the following chapters.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估机器学习解决方案的性能，我们使用机器学习指标。对于回归模型，有三个指标：均方误差、平均绝对误差和r平方。对于分类模型，我们使用混淆矩阵。我们将在接下来的章节中更详细地讨论这一点。
- en: 'Is the ML solution ready to be deployed? We need to circle back to the model’s
    original business goals in the ML problem framing:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习解决方案是否已经准备好部署？我们需要回到机器学习问题框架中模型的原始业务目标：
- en: For Zeellow, is predicting a house price with 95% accuracy good enough?
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于Zeellow来说，预测房价以95%的准确性是否足够好？
- en: For Zeellow Mortgage, are we allowed to make a decision with 95% confidence?
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于Zeellow抵押贷款，我们是否允许以95%的置信度做出决策？
- en: For Zeellow Appraisal, can we categorize a house into the proper group with
    95% accuracy?
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于Zeellow评估，我们能否以95%的准确性将房屋分类到正确的组别？
- en: After we have evaluated the ML model with the testing datasets and confirmed
    that the model reaches the business requirements, we will be ready to deploy it
    into production.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们使用测试数据集评估了机器学习模型并确认模型达到了业务要求后，我们就可以准备将其部署到生产环境中。
- en: Data readiness
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备就绪
- en: 'Data plays such a significant role in the machine learning process that the
    quality of data has a huge impact on the model performance, the so-called *garbage
    in, garbage out*. An ML model’s accuracy relies on many factors, including the
    size and quality of the dataset. The perception that *The more data, the more
    model accuracy* is not always true. In real time, it is a big challenge to obtain
    a big amount of clean, high-quality data. Often in an ML project, we spend a big
    portion of time collecting and preparing the datasets. Depending on the ML problem
    we need to solve, there are several ways to collect data and sources to collect
    it from. For example, we can go with the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 数据在机器学习过程中扮演着如此重要的角色，以至于数据的质量对模型性能有着巨大的影响，这就是所谓的*垃圾输入，垃圾输出*。一个机器学习模型的准确性依赖于许多因素，包括数据集的大小和质量。认为*数据越多，模型准确性越高*的观点并不总是正确的。在实时情况下，获取大量干净、高质量的数据是一个巨大的挑战。通常在一个机器学习项目中，我们会花费大量时间来收集和准备数据集。根据我们需要解决的机器学习问题，有几种收集数据的方法和来源。例如，我们可以考虑以下几种：
- en: Historical data collected by companies, such as user data and media data
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公司收集的历史数据，如用户数据和媒体数据
- en: Publicly available data from research institutes and government agencies
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自研究机构和政府机构公开可用的数据
- en: How much data is enough for my ML model, and how do we measure the quality of
    our data? It depends on the type of machine learning problem you want to solve.
    As part of the problem framing process, we need to check and make sure we have
    enough high-quality data to go with building an ML solution. Next, we will discuss
    more details about data preparation and feature engineering.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要多少数据才足够用于我的机器学习模型，我们如何衡量我们数据的质量？这取决于你想要解决的机器学习问题的类型。作为问题框架过程的一部分，我们需要检查并确保我们有足够的高质量数据来构建机器学习解决方案。接下来，我们将更详细地讨论数据准备和特征工程。
- en: Collecting data
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据收集
- en: '**Data collection** is collecting the source data and storing it in a central
    safe location. In the data collection phase, we try to answer the following questions:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据收集**是指收集源数据并将其存储在中央安全位置。在数据收集阶段，我们试图回答以下问题：'
- en: What is the nature of the problem and do we have the right data for it?
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题的本质是什么，我们是否有适合它的正确数据？
- en: Where is the data and do we have access to the data?
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据在哪里，我们是否有权访问数据？
- en: What can we do to ingest all the data into one central repository?
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能做些什么来将所有数据整合到一个中央存储库中？
- en: How do we safeguard the central data repository?
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何保护中央数据存储库？
- en: These questions are crucial in any ML project because, in a real business, data
    is typically spread across many different heterogeneous source systems, and bringing
    all the source data together to form a dataset may involve huge challenges.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题在任何机器学习项目中都至关重要，因为在实际业务中，数据通常分布在许多不同的异构源系统中，将所有源数据汇集在一起形成一个数据集可能会涉及巨大的挑战。
- en: 'A common data collection and consolidation process called **Extract, Transform,
    and Load** (**ETL**) has the following steps:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的**提取、转换和加载**（**ETL**）数据收集和整合过程包括以下步骤：
- en: '**Extract**: Pull the data from the various sources to a single location.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提取**：从各种来源将数据拉到一个单一的位置。'
- en: '**Transform**: During data extraction and consolidation, we may need to change
    the data format, modify some data, remove duplicates, and so on.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**转换**：在数据提取和整合过程中，我们可能需要更改数据格式，修改一些数据，删除重复项等。'
- en: '**Load**: Data is loaded into a single repository, such as Google Cloud Storage
    or Google BigQuery.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**加载**：数据被加载到一个单一存储库中，例如Google Cloud Storage或Google BigQuery。'
- en: 'During this ETL process, we also need to address the data size, quality, and
    security:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个ETL过程中，我们还需要解决数据的大小、质量和安全问题：
- en: '**Data size**: How much data do we need to get useful ML results? While the
    answer is dependent on the ML problem, the rule of thumb is that the training
    datasets will be several times more than the model’s trainable parameters. For
    example, a typical regression problem may need ten times as many observations
    as features. A typical image classification problem may require tens of thousands
    of images to create a high-accuracy image classifier. Generally speaking, simple
    models trained with large datasets perform better than complex models with small
    datasets.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data quality**: This can include the following:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reliability**: Are the data sources reliable? Is the dataset labeled correctly?
    Is the dataset filtered properly? Are there duplicates or missing values?'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature representation**: Does the dataset represent the useful ML features?
    Are there any outliers?'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consistency between training and production data**: Are there any skews that
    exist between the datasets for training and for production?'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data security**: Is the data secure? Do we need to encrypt the data? Is there
    any **Personally Identifiable Information** (**PII**) in the dataset? Are there
    any laws or regulatory requirements for accessing the dataset?'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the data is collected and stored in a central safe repository, we need
    to construct and transform it into the right format so that it can be used for
    ML model training. We will discuss this in the next section.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Data engineering
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The objectives of data engineering are to make sure that the datasets represent
    the real ML problem and have the right format for ML model training. Often, we
    use statistical techniques to sample, balance, and scale datasets, and handle
    missing values and outliers in the datasets. This section covers the following:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Sampling data with sub-datasets
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Balancing dataset classes
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transforming data
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let us start with data sampling and balancing.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Data sampling and balancing
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data sampling is a statistical analysis technique used to select, manipulate,
    and analyze a representative subset in a larger dataset. Sampling data plays an
    important role in data construction. When sampling data, you need to be very careful
    not to introduce biased factors. For more details, please refer to [https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/sampling](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/sampling).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'A classification dataset has more than two dataset classes. We call the classes
    that make up a large proportion of the set **majority classes**, and those that
    make up a small proposition **minority classes**. When the dataset has skewed
    class proportions – meaning the proportion of the minority classes is significantly
    less than that of the majority classes, it is an imbalanced dataset, and we need
    to balance it using statistical techniques called **downsampling** and **upweighting**.
    Let’s consider a fraud detection dataset with 1 positive and 200 negatives. The
    model training process will not reflect the real problem since the positive proportion
    is so small. In this case, we will need to process the dataset in two steps:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一个分类数据集有超过两个数据集类别。我们称构成集合大部分的类别为**多数类别**，而构成小比例的类别为**少数类别**。当数据集有偏斜的类别比例——即少数类别的比例显著低于多数类别的比例时，它是一个不平衡的数据集，我们需要使用称为**下采样**和**增加权重**的统计技术来平衡它。让我们考虑一个欺诈检测数据集，其中1个是正例，200个是负例。由于正例的比例如此之小，模型训练过程将不会反映真实问题。在这种情况下，我们需要分两步处理数据集：
- en: '**Downsampling**: Extract data examples from the dominant class to balance
    the classes. With a factor of 50 downsampling, the proportion will be 40:1 after
    downsampling.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**下采样**：从主导类中提取数据示例以平衡类别。以50的下采样因子，下采样后的比例将是40:1。'
- en: '**Upweighting**: Increase the dominant class weight by the same factor of 50
    (the same as the downsampling factor) during ML model training.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增加权重**：在机器学习模型训练期间，将主导类权重增加相同的50倍（与下采样因子相同）。'
- en: Some ML libraries have provided built-in features to facilitate the process.
    For more details about the techniques and why we perform the previous steps, refer
    to [https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一些机器学习库已经提供了内置功能来简化这个过程。有关技术和为什么执行前面的步骤的更多详细信息，请参阅[https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data)。
- en: Numerical value transformation
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数值值转换
- en: 'For a dataset that has numeric features covering distinctly different ranges
    (for example, the age feature in a mortgage application approval ML model), it
    is strongly recommended to normalize the dataset since it will help algorithms
    such as gradient descent to converge. Common ways to normalize data are the following:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有覆盖不同范围（例如，抵押贷款申请批准机器学习模型中的年龄特征）的数值特征的数据集，强烈建议规范化数据集，因为它将帮助梯度下降等算法收敛。规范化数据的一些常见方法如下：
- en: Scaling to a range
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放到一个范围
- en: Clipping
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 裁剪
- en: Log scaling
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数刻度
- en: Bucketing/binning
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 桶划分/分箱
- en: Scaling to a range
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缩放到一个范围
- en: '**Scaling to a range** normalization is converting floating-point feature values
    from their natural range (for example, the age range of 0-90 ) into a standard
    range (for example, 0 to 1, or -1 to +1). When you know the approximate range
    (upper and lower bounds) of your data, and the data is approximately uniformly
    distributed across that range, then it is a good normalization practice. For example,
    most age values fall between 0 and 90, and every part of the range has a substantial
    number of people, thus normalizing age values is a common practice.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**缩放到一个范围**规范化是将浮点特征值从其自然范围（例如，0-90岁的年龄范围）转换为标准范围（例如，0到1，或-1到+1）。当你知道数据的近似范围（上限和下限）并且数据在该范围内近似均匀分布时，这是一个很好的规范化实践。例如，大多数年龄值都在0到90之间，范围内的每个部分都有大量的人，因此规范化年龄值是一种常见的做法。'
- en: Feature clipping
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征裁剪
- en: '**Feature clipping** caps all feature values above (or below) a certain value
    to a fixed value. If your dataset contains extreme outliers, feature clipping
    may be a good practice. For example, you could clip all temperature values above
    80 to be exactly 80\. Feature clipping can be applied before or after other normalizations.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征裁剪**将所有超过（或低于）一定值的特征值限制为固定值。如果你的数据集中包含极端异常值，特征裁剪可能是一个好的做法。例如，你可以将所有超过80的温度值裁剪为正好80。特征裁剪可以在其他规范化之前或之后应用。'
- en: Log scaling
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对数刻度
- en: '**Log scaling** computes the log of your feature values, thus compressing a
    wide data range to a narrow range. When a handful of the data values have many
    points and most of the other values have few points, *log scaling* becomes a good
    transformation method. For example, movie ratings are good business use cases
    for *log scaling*, since most movies have very few ratings, while a few movies
    have lots of ratings.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**对数缩放**计算特征值的对数，从而将广泛的数据范围压缩到狭窄的范围。当数据值中有许多点而其他值很少时，*对数缩放*成为一种好的转换方法。例如，电影评分是*对数缩放*的良好商业用例，因为大多数电影只有很少的评分，而少数电影有大量的评分。'
- en: Bucketing
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 桶化
- en: '**Bucketing** is also called binning. It transforms numeric features into categorical
    features, using a set of thresholds. A good example is transforming house prices
    into low, medium, and high categories, for better modeling.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**桶化**也称为分箱。它使用一组阈值将数值特征转换为类别特征。一个很好的例子是将房价转换为低、中、高类别，以更好地建模。'
- en: Categorical value transformation
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 类别值转换
- en: 'Categorical values are discrete values that aren’t in an ordered relationship,
    with each value marking a category. If categorical data doesn’t have any order
    to it, for example, a *color* feature that has values such as red, green, and
    blue, and there is no preference among the categories, if you assign values of
    *1*, *2*, and *3* to represent *red*, *green*, and *blue*, respectively, the model
    might interpret blue as more important than red, since it has a higher numeric
    value. We often encode non-ordinal data into multiple columns or features, called
    **one-hot encoding**. *Figure 3.2* shows the one-hot encoding transformation for
    the color feature – red is 100, blue is 010, and green is 001:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 类别值是离散值，它们之间没有有序关系，每个值代表一个类别。如果类别数据没有顺序，例如，一个*颜色*特征具有红色、绿色和蓝色等值，并且没有对类别有任何偏好，如果你将*1*、*2*和*3*分别分配给代表*红色*、*绿色*和*蓝色*，那么模型可能会将蓝色解释为比红色更重要，因为它具有更高的数值。我们通常将非序数数据编码到多个列或特征中，称为**独热编码**。*图3.2*显示了颜色特征的独热编码转换
    – 红色是100，蓝色是010，绿色是001：
- en: '![Figure 3.2 – One-hot encoding for the “color” feature ](img/Figure_3.2.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2 – “颜色”特征的独热编码](img/Figure_3.2.jpg)'
- en: Figure 3.2 – One-hot encoding for the “color” feature
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – “颜色”特征的独热编码
- en: One-hot encoding transforms the non-ordinal categorical values into numerical
    values without introducing any ordinal bias. It is used widely in ML data transformations.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 独热编码将非序数类别值转换为数值，而不引入任何序数偏差。它在机器学习数据转换中得到了广泛应用。
- en: Missing value handling
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失值处理
- en: When preparing the dataset, we often see missing data. For example, some columns
    in your dataset might be missing because of a data collection error, or data wasn’t
    collected on a particular feature. Missing data can make it difficult to accurately
    interpret the relationship between the feature and the target variable and dealing
    with missing data is an important step in data preparation.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备数据集时，我们经常看到缺失数据。例如，你的数据集中的一些列可能因为数据收集错误而缺失，或者没有收集到特定特征的某些数据。缺失数据可能会使准确解释特征与目标变量之间的关系变得困难，处理缺失数据是数据准备中的重要步骤。
- en: Based on what has caused the missing data, the total dataset size, and the proportion
    of missing values, we can either drop the whole feature or impute the missing
    values. For example, if a row or column has a large percentage of missing values,
    *dropping* the entire row or column may be a viable option. If the missing values
    are randomly spread throughout the dataset and it’s only a small portion of its
    rows or columns, then *imputation* may be a better option. For categorical variables,
    we can usually replace missing values with mean, median, or most frequent values.
    For numerical or continuous variables, we typically use the mean or median to
    impute. Sometimes, we also encounter nulls or zeros, but those should be approached
    with care as zero can be a value in a column while an ETL pipeline will replace
    all missing values with zero.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 根据缺失数据的原因、总数据集大小以及缺失值的比例，我们可以选择删除整个特征或填充缺失值。例如，如果某行或某列有大量缺失值，*删除*整个行或列可能是一个可行的选项。如果缺失值在数据集中随机分布，并且只占其行或列的一小部分，那么*填充*可能是一个更好的选择。对于类别变量，我们通常可以用平均值、中位数或最频繁出现的值来替换缺失值。对于数值或连续变量，我们通常使用平均值或中位数来填充。有时，我们也会遇到空值或零，但应该谨慎处理，因为零可以是列中的一个值，而ETL管道会将所有缺失值替换为零。
- en: Outlier processing
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异常值处理
- en: 'Often, we also see outliers – data points that lie at an abnormal distance
    from other values in the dataset. Outliers can make it harder for models to predict
    accurately because they skew values away from the other more normal values that
    are related to that feature. Depending on the causes of the outliers, you want
    to clean them up, or transform them to add richness to your dataset (some algorithms
    have built-in functions to handle outliers):'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们也会看到异常值——这些数据点在数据集的其他值中距离异常遥远。异常值可能会使模型更难准确预测，因为它们会将值偏离与该特征相关的其他更正常值。根据异常值的原因，你可能想要清理它们，或者将它们转换以丰富你的数据集（一些算法具有内置的函数来处理异常值）：
- en: '**Deleting the outlier or imputing the outlier**: If your outlier is based
    on an artificial error, such as incorrectly entered data'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**删除异常值或填充异常值**：如果你的异常值基于人工错误，例如输入数据错误'
- en: '**Transforming the outlier**: Taking the natural log of a value to reduce the
    outlier’s influence on the overall dataset'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转换异常值**：通过对值取自然对数来减少异常值对整体数据集的影响'
- en: 'Through the previously shown process of data construction and transformation,
    the dataset is ready. And now it’s time to go to the next step: checking and selecting
    the features (the variables that affect the model target) – the process called
    feature engineering.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 通过之前展示的数据构建和转换过程，数据集已准备好。现在，是时候进行下一步：检查和选择特征（影响模型目标的变量）——这个过程称为特征工程。
- en: Feature engineering
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程
- en: '**Feature engineering** is the process of selecting and transforming the most
    relevant features in ML modeling. It is one of the most important steps in the
    ML learning process. Feature engineering includes **feature selection** and **feature
    synthesis** (transformation).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征工程**是选择和转换ML建模中最相关特征的过程。它是ML学习过程中最重要的步骤之一。特征工程包括**特征选择**和**特征合成**（转换）。'
- en: Feature selection
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征选择
- en: 'For an ML problem that has a lot of features extracted during the initial phase,
    feature selection is used to reduce the number of those features (input variables),
    so that we can focus on the features that are most useful to a model to predict
    the target variable. After you extract features for the problem, you need to use
    feature selection methods to choose the most appropriate features for model training.
    Depending on whether ML training is needed, there are two main types of feature
    selection methods you can use – filter methods and wrapper methods:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在初始阶段提取了大量特征的ML问题，特征选择用于减少这些特征（输入变量）的数量，以便我们可以专注于对模型预测目标变量最有用的特征。在你为问题提取特征之后，你需要使用特征选择方法来选择最适合模型训练的特征。根据是否需要ML训练，你可以使用两种主要的特征选择方法——过滤方法和包装方法：
- en: '**Filter methods** use statistical techniques to evaluate and score the relationship
    between each input variable and the target variable. The scores are used to compare
    the features and decide the input variables that will be used in the model.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过滤方法**使用统计技术来评估和评分每个输入变量与目标变量之间的关系。这些评分用于比较特征并决定将用于模型中的输入变量。'
- en: '**Wrapper methods** create many models with different subsets of input features
    and perform model training and compare their performances. The feature subsets
    fitting the best-performing model according to a performance metric will be selected.
    Wrapper methods need ML training on different subsets.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**包装方法**创建具有不同输入特征子集的多个模型，并执行模型训练和比较它们的性能。根据性能指标，将选择最适合性能的模型的特征子集。包装方法需要在不同的子集上进行ML训练。'
- en: Feature synthesis
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征合成
- en: A synthetic feature is created algorithmically, usually with a combination of
    the real features using arithmetic operations such as addition, subtraction, multiplication,
    and division to train machine learning models. **Feature synthesis** provides
    great insights into data patterns and helps model training for some ML problems.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 合成特征是通过算法创建的，通常是通过使用加法、减法、乘法和除法等算术运算将真实特征组合起来来训练机器学习模型。**特征合成**为数据模式提供了深刻的见解，并有助于某些ML问题的模型训练。
- en: After data collection, construction and transformation, and feature engineering,
    our data is ready for the next stage – modeling development.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据收集、构建和转换以及特征工程之后，我们的数据已准备好进入下一阶段——模型开发。
- en: Summary
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed preparations for an ML process. Starting from
    business requirements, you need to understand the problem and see if ML is the
    best solution for it. You then define the ML problem, set up performance measurement,
    and identify the data to be used for ML modeling to make sure we have a high-quality
    dataset.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了机器学习过程的准备工作。从业务需求开始，你需要理解问题并判断机器学习是否是最佳解决方案。然后你定义机器学习问题，设置性能测量，并确定用于机器学习建模的数据，以确保我们有一个高质量的数据集。
- en: Data plays such an important role! We have also discussed data preparation and
    feature engineering in this chapter. From data collection and construction to
    data transformation, feature selection, and feature synthesis, data pipelines
    prepare the dataset for ML model training. Mastering these data preparation and
    feature engineering skills will provide us with insights into the data and help
    us in model development. In the next chapter, we will discuss the ML model development
    process, from model training and validation to model testing and deployment.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 数据扮演着如此重要的角色！我们也在本章中讨论了数据准备和特征工程。从数据收集和构建到数据转换、特征选择和特征合成，数据管道为机器学习模型训练准备数据集。掌握这些数据准备和特征工程技能将使我们深入了解数据，并有助于模型开发。在下一章中，我们将讨论机器学习模型开发过程，从模型训练和验证到模型测试和部署。
- en: Further reading
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For further insights into what you''ve learned in this chapter, you can refer
    to the following links:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了深入了解本章所学内容，你可以参考以下链接：
- en: '[https://developers.google.com/machine-learning/problem-framing](https://developers.google.com/machine-learning/problem-framing%20)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://developers.google.com/machine-learning/problem-framing](https://developers.google.com/machine-learning/problem-framing%20)'
- en: '[https://developers.google.com/machine-learning/data-prep](https://developers.google.com/machine-learning/data-prep)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://developers.google.com/machine-learning/data-prep](https://developers.google.com/machine-learning/data-prep)'
