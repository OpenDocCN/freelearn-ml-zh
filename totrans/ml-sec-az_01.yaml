- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Assessing the Vulnerability of Your Algorithms, Models, and AI Environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to your machine learning security journey with Azure! Together, we will
    explore all the methods and techniques to secure our AI projects and set a security
    baseline for our services. Let us start with a quick introduction to the **machine
    learning** (**ML**) life cycle and the **Azure Machine Learning** components and
    processes that go into working with ML in Azure. We will cover the essential knowledge
    you need to follow the concepts and implementations outlined in the rest of the
    book.
  prefs: []
  type: TYPE_NORMAL
- en: The next step will be to go through an example scenario, which we will reference
    throughout this book as the basis for applying the concepts of securing your data,
    models, workspace, and applications that use the deployed models from Azure Machine
    Learning. You can follow the instructions to re-create this scenario in your Azure
    Machine Learning environment to familiarize yourself with the Azure Machine Learning
    components.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the **Zero Trust** model to develop an implementation and assessment
    strategy. This model is a security strategy based on the principle of *Never trust,
    always verify*. This model applies to all levels of implementation, from identities,
    infrastructure, and networks, to apps, endpoints, and data. This strategy is the
    best approach when working with multiple services and environments because we
    can easily adapt it to the complexity of modern cloud and hybrid environments.
    Since developing a strategy heavily depends on the individual scenario and use
    case for each organization, in this book, we will explore multiple options and
    demonstrate implementations of several Zero Trust aspects. Specifically, we will
    learn about attacks in [*Chapter 2*](B21076_02.xhtml#_idTextAnchor040), data governance
    and protection in *Part 2* of the book, how to manage and secure access to the
    workspace and associated resources in *Part 3*, and in [*Chapter 10*](B21076_10.xhtml#_idTextAnchor203),
    we will gather all those best practices in an ML security baseline.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the Azure Machine Learning life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing an ML project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the Zero Trust model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assessing the vulnerability of ML assets and apps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be familiar with the basic principles and
    defense areas of the Zero Trust strategy. You can use this strategy to create
    a high-level vulnerability assessment of **artificial intelligence** (**AI**)/ML
    project components, applications, and related services hosted in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we will need a few things to apply the learnings and implementations.
    Each chapter will outline more details if needed, but the minimal resources we
    need are an **Azure subscription** and an Azure Machine Learning resource with
    its related services.
  prefs: []
  type: TYPE_NORMAL
- en: Azure subscription and resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout this book, we will reference the scenario presented in this section
    and other services and implementations in Azure. You will need an active Azure
    subscription and an Azure Machine Learning workspace to follow along or replicate
    the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you don’t have an Azure subscription, you can activate a free trial by following
    this link: https://azure.microsoft.com/en-us/pricing/offers/ms-azr-0044p/.'
  prefs: []
  type: TYPE_NORMAL
- en: If you run the project suggested in this chapter from end to end, it should
    not cost more than $150–$200 as long as you delete all associated resources afterward
    and use the lowest pricing tier of all services. However, this estimation can
    vary by the region that you choose, which features you choose to implement, the
    size of the dataset, and for how long you plan to keep the resources deployed.
    The trial will provide you with a sufficient balance to try it out; however, I
    strongly recommend using the Azure pricing calculator and working with the cost
    management in your subscriptions to ensure keeping the costs at a minimum and
    deleting or stopping resources when you no longer use or need them.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The Azure free trial provides you with credits to spend on Azure services. After
    they are used up, you can keep the account and use free Azure services. You need
    to add your credit card, but the service won’t charge your card unless you explicitly
    change your subscription type. Azure uses a pay-as-you-go pricing model. To make
    sure you don’t run out of credits faster than intended, visit the Azure pricing
    calculator at https://azure.microsoft.com/en-us/pricing/calculator/.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To use Azure Machine Learning, you need to create an Azure Machine Learning
    resource. The following screenshot shows the basic options for creating one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1 – Azure Machine Learning resource creation form](img/B21076_01_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 – Azure Machine Learning resource creation form
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the Azure Machine Learning life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: No matter what technology or framework we choose to work with to develop our
    ML project, there are four phases we go through. Each stage has one or more steps,
    depending on the individual scenario. The ML life cycle is significant because
    it clearly outlines every project step. Then, it is easy to break the project
    into tasks and assign them to the person responsible because, usually, more than
    one role is involved in an ML project.
  prefs: []
  type: TYPE_NORMAL
- en: Let us review all the stages before we connect them to the components of Azure
    Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: ML life cycle
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In ML, we identify four stages: business understanding, data operations, model
    training, and model deployment. As shown in the following figure, these stages
    are part of an iterative process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.2 – ML life cycle](img/B21076_01_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.2 – ML life cycle
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through each step of this iterative process and what it entails, starting
    with the business understanding stage and the gathering of the initial requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Business understanding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Every project starts with a problem that needs to be solved. Business understanding
    (or problem understanding) is the first step in creating a plan that outlines
    what needs to be done. Ideally, we would like to have the requirements clearly
    detailed for us, but this is rarely the case. The first thing is to understand
    the project’s goal and where it can bring real value to the business. Then, evaluate
    which processes can be automated using ML by narrowing down the problem to actionable
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let us examine the following scenario. Our client is a hospital
    administration looking to minimize costs by increasing doctor productivity and
    automating as much of their workload as possible. In an analysis of doctors’ daily
    tasks, they found that they spend a lot of time looking through patient histories
    and analyzing their blood tests. By decreasing that time by 5%, the doctor could
    see more patients without working overtime. We can solve this problem by using
    supervised learning techniques, where an ML model could be trained to suggest
    illnesses by combining the patient’s symptoms and blood test results. The doctor
    would still have to verify the results. However, shortening the analysis time
    would increase the doctor’s productivity.
  prefs: []
  type: TYPE_NORMAL
- en: After narrowing down the requirements and clarifying the problem, the next step
    is to examine the data.
  prefs: []
  type: TYPE_NORMAL
- en: Data operations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ML is based on data. During this stage, we work with everything that has to
    do with data operations, from data collection to data processing. **Data gathering**
    or **data collection** is the part where the goal is to collect relevant data
    to the problem at hand. This data could come from various sources such as files,
    databases, APIs, or sensors. It is one of the most critical steps in the project
    because we identify the different data sources and collect and integrate the data.
    The quality and quantity of the data we gather will determine the efficiency and
    accuracy of the model’s output.
  prefs: []
  type: TYPE_NORMAL
- en: Collected data can be messy and often not ready to be used by ML algorithms.
    Issues with the data include irrelevant data, noise, outliers, and missing data.
    This is where **data preparation** or **data wrangling** comes in. Any data irrelevant
    to our model should be filtered properly. When outliers are recognized, we usually
    eliminate them from the dataset. With missing data, the process is a little bit
    more complex. Once identified, the outliers should be evaluated and either removed
    or filled with default or calculated values. Finally, data might need to be encoded
    differently to be used by ML algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Model training and evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An appropriate ML algorithm is selected and trained on the prepared data at
    this stage. The model is developed by completing multiple training iterations
    and the result is evaluated at the end of each iteration until a satisfactory
    performance level is achieved. During this stage, there might be a need to go
    back and work with the data again to ensure that data are relevant and that no
    unintended correlation might affect the results.
  prefs: []
  type: TYPE_NORMAL
- en: Model deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the results are satisfactory, the final step is deploying the model so
    that software engineers can integrate it into their applications and make predictions.
    Although it might seem like the end, this is far from it. Deployed models need
    to be monitored to ensure proper performance. Models can degrade over time, which
    would impact the accuracy of their predictions. In this case, we can retrain the
    model with an updated dataset to ensure this does not happen and the cycle starts
    over again. Changing the requirements or introducing a new business need might
    also cause us to retrain our model.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good understanding of the ML process, we can move on to the
    Azure Machine Learning service components that are part of each stage of the ML
    life cycle. Everything we need to develop Azure Machine Learning projects is part
    of or in some way related to the **Azure Machine Learning Studio** or workspace.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure Machine Learning is a cloud service for accelerating the ML project life
    cycle. It leverages the Azure infrastructure to connect to data and train, deploy,
    and monitor models. The service includes everything from connecting data from
    multiple data sources to working on developing the code and training, evaluating,
    and publishing models ready to be used by web applications.
  prefs: []
  type: TYPE_NORMAL
- en: The service is a complete environment for developing end-to-end ML projects.
    It allows collaboration for multiple roles, from data scientists to developers,
    security engineers, or IT (information technology) administrators. In this section,
    we will review how each component maps to each part of the ML project life cycle
    and the service capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning Studio
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Azure Machine Learning service creates several related Azure services required
    to use the service properly. First, you need an active Azure subscription. When
    you create the Azure Machine Learning resource, the following services are created
    alongside it: an **Azure Storage** account, an **Application Insights** resource,
    and **Azure** **Container Registry**.'
  prefs: []
  type: TYPE_NORMAL
- en: An Azure Storage account serves as the filesystem. All imported files, notebooks,
    and so on are saved here. The Applications Insights resource can be used to monitor
    a deployed model and provide logs and insights when the deployed model does not
    work as expected. The Azure Container Registry is optional in creating the workspace,
    but you will probably need one if you plan to publish your models in the **Azure
    Container Instances** (**ACI**) service. The models can be published to different
    compute targets, including containers, and are created as **APIs** so any application
    can easily use the models and make predictions. Everything else is handled from
    the Azure Machine Learning Studio. Here, you can work with your data, create compute
    resources, train and deploy your models, manage user access, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the Azure Machine Learning Studio home page.
    On the left, you can find the Azure Machine Learning **Authoring**, **Assets**,
    **Compute**, and other resource management options:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3 – Azure Machine Learning Studio](img/B21076_01_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.3 – Azure Machine Learning Studio
  prefs: []
  type: TYPE_NORMAL
- en: Most of the work will happen in the workspace, whether that is data preparation
    and import, code development, or model training and inferencing. Let us see what
    features and assets we have available to work with.
  prefs: []
  type: TYPE_NORMAL
- en: Working with data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are a few ways of working with data in Azure Machine Learning Studio.
    The first is working with data stored elsewhere by creating a **datastore**. A
    datastore is a reference to existing storage on Azure. That could be **Azure Blob
    Storage** or **Azure Data Lake**. If your data is not in Azure, you can still
    work with it in Azure Machine Learning. You can always upload your files as data
    assets into the workspace or add a reference to an external database. Then, you
    can use them in your project, share them with your colleagues, and keep the versioning
    to track changes and updates.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, you can see some of the types of data assets you
    can import:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4 – Create data asset in Azure Machine Learning Studio](img/B21076_01_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.4 – Create data asset in Azure Machine Learning Studio
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning Designer
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You can use **Python** and **R** to develop your Azure Machine Learning project,
    but the service also provides a visual designer. You can use the designer for
    training and inference (production models that make predictions).
  prefs: []
  type: TYPE_NORMAL
- en: 'Refer to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.5 – Azure Machine Learning Designer](img/B21076_01_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.5 – Azure Machine Learning Designer
  prefs: []
  type: TYPE_NORMAL
- en: The designer has many out-of-the-box modules for multiple operations that you
    can drag and drop onto the canvas to create the training pipeline. That includes
    importing data, splitting datasets, SQL operations, algorithms, and model evaluation
    modules. If you need more, you can always use the custom script modules for Python
    or R and add your code as part of the pipeline. The benefit is that you can quickly
    go to an inference pipeline and convert it to a web service with just a few clicks.
  prefs: []
  type: TYPE_NORMAL
- en: Automated Machine Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The **Automated Machine Learning** (**Automated ML**) capability of Azure Machine
    Learning is a set of tools and techniques that automate the process of building
    ML models. It helps beginners or experienced data scientists by automatically
    selecting the best algorithm and hyperparameters for a given dataset and then
    training and validating the model. This process is done by applying various algorithms,
    such as decision trees, random forests, and deep neural networks, to the data
    and selecting the best-performing model. It also includes data features such as
    preprocessing, feature engineering, and model selection. It allows users to upload
    data into the Azure Machine Learning workspace and let the platform handle the
    rest of the ML process with minimal configuration. When the best model is selected
    from the list, it can be deployed to a **web service** ready to be consumed, as
    is the case with all models in the Azure Machine Learning workspace. Have a look
    at the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6 – Automated ML supported algorithms](img/B21076_01_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.6 – Automated ML supported algorithms
  prefs: []
  type: TYPE_NORMAL
- en: Working with compute
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When training or deploying models, computing power is required. Azure Machine
    Learning provides a scalable compute infrastructure for training and deployment
    based on Azure infrastructure. To train your experiments, you can use compute
    targets or compute clusters. A compute target is a dedicated virtual machine running
    your training jobs. If you need more power, you can create a cluster with multiple
    nodes to run workloads in parallel. You can also attach compute from virtual machines
    you are not using or from other ML services such as **Azure Databricks**. You
    can use ACI or **Azure Kubernetes Service** (**AKS**) clusters to deploy models.
  prefs: []
  type: TYPE_NORMAL
- en: Coding with Python or R
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Besides the visual and automation tools, Azure Machine Learning supports **Jupyter
    Notebooks** for code development and collaboration. You can use the embedded notebook
    editor, **Visual Studio Code** with the Azure Machine Learning extension, or the
    Jupyter Notebook editor that you can launch from the running compute target during
    training. Refer to the following screenshot for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.7 – Azure Machine Learning Studio notebook editor](img/B21076_01_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.7 – Azure Machine Learning Studio notebook editor
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see the most fundamental components of Azure Machine Learning.
    The workspace is complete with multiple features and tools that can facilitate
    all stages of the ML life cycle and take an ML project from start to finish. In
    the following section, we will see how to use the features and tools outlined
    here to develop a sample ML project from development to production.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing an ML project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you want to follow along with the implementation examples in this book, here
    is an example project to get you started. If you are already an expert in Azure
    Machine Learning, feel free to skip this introduction. This section will help
    beginners with the service or those in other roles to understand the ML life cycle
    in action. We will create a sample project that demonstrates how to import a dataset
    into Azure Machine Learning, how to use the Automated ML feature to train multiple
    models with multiple parameters, and deploy the resulting model as an endpoint
    to be used for predictions. The Automated ML feature was chosen as it does not
    require extensive data science expertise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to the **Azure portal** ([https://portal.azure.com/](https://portal.azure.com/))
    and look for **Azure Machine Learning resource**. From **Overview**, click on
    **Studio web URL** or the **Launch Studio** button to access your workspace, as
    seen in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.8 – Accessing your Azure Machine Learning workspace](img/B21076_01_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.8 – Accessing your Azure Machine Learning workspace
  prefs: []
  type: TYPE_NORMAL
- en: Now you will find yourself on the home page of the workspace. From here on,
    you will find all the options in the left-hand menu outlined in the following
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ML starts with data, so you will need to find a dataset to use to train a model
    to make predictions. There are a lot of open source datasets available for ML
    and you can download them for free – for example, from university repositories
    for learning or research purposes. Just make sure the source is reputable so that
    there is no malware or something similar with your download. For this example,
    we will use the regression task with Automated ML. If you want to follow along
    with the steps, you can use any dataset; just make sure you tailor the Automated
    ML options to match the dataset you choose. If you don’t have a lot of experience
    and you want something close to the dataset used here, when you are looking for
    a dataset, pay attention to the task and data. If it can be used for regression
    and it contains a column with numerical data that your model will be trained to
    predict, any dataset will do. Automated ML does not support all types of ML tasks
    yet, so this is a good way to get started.
  prefs: []
  type: TYPE_NORMAL
- en: I am using a sample dataset that contains patient symptoms and a class column
    that notes whether the patient was diagnosed as diabetic. It will help to train
    a new model that predicts the probability if the patient will become diabetic
    or not based on symptoms.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have your dataset ready, all we have to do is go to the **Data** menu
    under **Assets** and create a new data asset. Here are the steps for it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we provide details for **Name**, **Description**, and set **Data type**
    as **Tabular**, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.9 – Create data asset](img/B21076_01_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.9 – Create data asset
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next step in the wizard, choose the **From local** **files** option:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.10 – Choosing the data source](img/B21076_01_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.10 – Choosing the data source
  prefs: []
  type: TYPE_NORMAL
- en: 'Leave the default option in the **Storage type** screen and move on to upload
    the file in the **File or folder** **selection** screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.11 – Uploading the file](img/B21076_01_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.11 – Uploading the file
  prefs: []
  type: TYPE_NORMAL
- en: 'Under **Settings**, choose the options as illustrated until **Data preview**
    shows the correct columns and data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.12 – Applying the settings](img/B21076_01_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.12 – Applying the settings
  prefs: []
  type: TYPE_NORMAL
- en: 'Under **Schema**, make sure the **Path** column is excluded from the dataset.
    You can also exclude any columns that you feel are not relevant to the prediction
    or change the **Data type** if it has been identified incorrectly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.13 – Choosing the columns and data type](img/B21076_01_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.13 – Choosing the columns and data type
  prefs: []
  type: TYPE_NORMAL
- en: Move on to the **Review** screen and create the dataset. Now you have a dataset
    available to use for your ML project! The next step is to start training a model.
  prefs: []
  type: TYPE_NORMAL
- en: Training the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many ways to train our model. Here, we will use the Automated ML capability
    of Azure Machine Learning to run the model through multiple algorithms and parameters,
    let the service train, and suggest the best model based on performance. It is
    the fastest way to create all the components we need to demonstrate the security
    concepts we will talk about later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us begin:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, open the **Automated ML** menu under **Authoring**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.14 – Starting a new Automated ML job](img/B21076_01_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.14 – Starting a new Automated ML job
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the dataset you created previously and move on to the next screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.15 – Selecting the data asset](img/B21076_01_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.15 – Selecting the data asset
  prefs: []
  type: TYPE_NORMAL
- en: 'Give the job a name under **New experiment name** and fill in **Target column**
    to predict in your dataset. In this dataset, it is the **Y** column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.16 – Configure job settings](img/B21076_01_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.16 – Configure job settings
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the **Compute cluster** option for the training compute and click on
    the **New** link to create a new cluster without leaving the wizard:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.17 – Creating the cluster](img/B21076_01_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.17 – Creating the cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the `0` and `2` should be fine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.18 – Cluster options](img/B21076_01_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.18 – Cluster options
  prefs: []
  type: TYPE_NORMAL
- en: Leave all other options to default, create the cluster, and when you get back
    to the Automated ML wizard, move on to the **Select task and** **settings** screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Since we want to predict a numeric value, we choose the **Regression** category
    of algorithms, as shown here. The service engine will run multiple regression
    algorithms that it deems to fit the data profile to generate multiple models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.19 – Selecting the algorithm category and settings](img/B21076_01_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.19 – Selecting the algorithm category and settings
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `1` hour under **Exit criterion**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.20 – Setting additional configuration settings](img/B21076_01_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.20 – Setting additional configuration settings
  prefs: []
  type: TYPE_NORMAL
- en: Leave all other options to default in the wizard and start the Automated ML
    job. Now, all you can do is wait until a performant model is found and the training
    stops or the maximum training time has been reached and the best model up to that
    point is automatically chosen. You can monitor the progress of the model’s training
    under the new job created in the **Automated** **ML** menu.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the model trained, we can deploy it.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can find the best-performing model under the **Models** menu as soon as
    the job is completed. Choose the one from the list that performs the most accurately
    based on the metrics, and it will be ready for deployment to the ACI as a web
    service.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps to try this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Choose the model from the list with the best score. You will recognize the
    best score as in the **Explained** column, it will also contain the feature explanation.
    You can also compare the scoring metric and it could be higher or lower, depending
    on the metric type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.21 – List of trained models with different algorithms and parameters](img/B21076_01_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.21 – List of trained models with different algorithms and parameters
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the **Model** screen and click on the **Deploy** button. In the list,
    choose the **Web service** option, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.22 – Model deployment](img/B21076_01_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.22 – Model deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'For the deployment settings, add **Name**, choose **Azure Container Instance**
    as **Compute type**, and set the **Enable authentication** toggle button to true.
    This is depicted in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.23 – Deployment settings](img/B21076_01_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.23 – Deployment settings
  prefs: []
  type: TYPE_NORMAL
- en: Wait for the deployment to finish and go to the **Endpoints** menu to integrate
    your model with an application and make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Making predictions using the deployed model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To use the deployed model for predictions, go to the **Endpoints** menu and
    find the endpoint deployment. Make sure **Deployment state** is **Healthy** and
    **Operation state** is **Succeeded**. If **Deployment state** is anything other
    than **Healthy** or **Failed**, it might need some more time to deploy. Refer
    to the following screenshot for the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.24 – Azure Machine Learning model endpoint for predictions](img/B21076_01_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.24 – Azure Machine Learning model endpoint for predictions
  prefs: []
  type: TYPE_NORMAL
- en: You can do a quick test of the service using the **Test** tab. Use the **Consume**
    tab to find the endpoint and authentication key to integrate the web service into
    your application for predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have followed along with the previous steps, congratulations: you just
    trained and deployed a model using Azure Machine Learning. This is not over yet,
    though; we will use this sample project throughout this book to demonstrate the
    implementations to learn how to secure your own solution. But before we dive into
    the implementations, let us go through the strategies and techniques we are going
    to follow, starting with Zero Trust.'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the Zero Trust model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Zero Trust** model is a security strategy based on the principle of *Never
    trust, always verify*. So, instead of assuming that our resources that are deployed
    behind a firewall are safe, the Zero Trust model assumes breach and every request
    needs to be verified as though it originates from an open network. The Zero Trust
    model is applied in cloud, on-premises, and hybrid environments. Implementing
    a Zero Trust security model can help organizations to reduce their overall attack
    surface, minimize the risk of data breaches, and improve their security posture
    by shifting from a perimeter-based security approach to a more comprehensive and
    adaptive security strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Although Azure Machine Learning is a cloud service, the Zero Trust model still
    applies because a complete ML project spans across data, networks, infrastructure,
    and applications. We will go through an overview of the Zero Trust model. Then,
    we’ll use this knowledge to apply it to assess the vulnerabilities in our workloads
    and reduce our attack surface using Azure’s tools and services. We will start
    by familiarizing ourselves with the Zero Trust principles and defense areas.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the Zero Trust principles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Zero Trust strategy is based on three principles – verify explicitly, use
    least-privilege access, and assume breach.
  prefs: []
  type: TYPE_NORMAL
- en: Let us understand each of these in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Verify explicitly
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *Verify explicitly* principle requires that all users, devices, applications,
    and resources attempting to access the network must be thoroughly authenticated
    and authorized before being granted access.
  prefs: []
  type: TYPE_NORMAL
- en: In traditional security models, once a user or device is authenticated and granted
    access, they are generally trusted to some degree and allowed to move within the
    network without additional checks. However, in the Zero Trust model, every access
    request is treated as a potential threat. Access is only granted after a multi-level
    verification process.
  prefs: []
  type: TYPE_NORMAL
- en: This verification process includes multiple layers of authentication, such as
    verifying user credentials, device identity, and network location. User authentication
    might involve **multifactor authentication** (**MFA**) or other advanced authentication
    methods to confirm the user’s identity. The verification process is not a one-time
    event but is ongoing and continuous. It includes checking for anomalies or changes
    in user behavior, device health, or other factors that may indicate a potential
    threat. If any changes or anomalies are detected, the system can initiate additional
    verification checks or even revoke access if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Use least-privilege access
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *Use-least privilege access* principle is a critical Zero Trust security
    model component. It states that users, devices, and applications should only be
    granted access to the minimum level of resources necessary to perform their job
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: Users are often given broad access privileges to network resources and data,
    assuming they only access the resources required to perform their job duties.
    However, this approach increases the risk of data breaches and unauthorized access
    by allowing users to access resources they don’t need, which attackers can exploit.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, the Zero Trust model takes a more granular approach to access control
    by limiting access based on the principle of least privilege. For example, a user
    in the marketing department may only need access to marketing-related files and
    not require access to the finance department’s data or systems. Similarly, a contractor
    may need access to specific files or applications but not to the entire network.
  prefs: []
  type: TYPE_NORMAL
- en: Assume breach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *Assume breach* principle assumes that a network has already been compromised
    and that attackers are present, or will be present, inside the network. This principle
    emphasizes the importance of early detection and response to mitigate the damage
    caused by a potential breach. We need to identify an attack as soon as it reaches
    our system by analyzing anomalies as soon as possible in every level of access.
  prefs: []
  type: TYPE_NORMAL
- en: Organizations typically focus on securing their network perimeters and preventing
    attackers from gaining access. However, with the increasing sophistication of
    cyberattacks, perimeter-based security is no longer sufficient to protect against
    modern threats. The Zero Trust model recognizes this and assumes that attackers
    will eventually penetrate the network through phishing attacks, malware, or other
    means.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming a breach means that organizations must implement additional security
    controls to limit the damage caused by an attack, such as micro-segmentation,
    encryption, and network isolation. These controls help to prevent attackers from
    moving laterally across the network and accessing critical resources, even if
    they have gained access to one part of the network.
  prefs: []
  type: TYPE_NORMAL
- en: Explaining Zero Trust defense areas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Zero Trust security model focuses on protecting network resources and data
    by implementing security controls across several defense areas or domains, such
    as the ones depicted in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.25 – Zero Trust defense areas](img/B21076_01_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.25 – Zero Trust defense areas
  prefs: []
  type: TYPE_NORMAL
- en: Let us understand each of these areas in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Identities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the vital defense areas is **identities**, which involves securing user
    identities and ensuring that only authorized users can access network resources.
    Identity verification, least-privileged access, risk-based adaptive access, and
    continuous monitoring are all part of identity management and security. Identity
    verification involves verifying user identities before granting access to network
    resources. It includes multifactor authentication, passwordless authentication,
    and conditional access policies to ensure that only authorized users can access
    sensitive resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us explore some best practices:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Least privileged access** involves granting users the minimum access necessary
    to perform their job functions. It includes role-based access controls, dynamic
    access control, and privileged access management to limit user access to only
    what they need.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Risk-based adaptive access** involves using risk assessment tools to evaluate
    user behavior and determine the level of access they should have to network resources.
    It includes continuous authentication, real-time risk assessments, and contextual
    access policies to ensure that user access is appropriate and secure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous monitoring** involves monitoring user activity and detecting anomalies
    or suspicious behavior. It includes real-time alerts, behavioral analytics, and
    ML to identify potential security threats and take proactive measures to prevent
    them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Endpoints
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another critical defense area is **endpoints**, which involves securing endpoints
    such as laptops, desktops, mobile devices, and servers. Microsoft’s approach to
    securing endpoints in the Zero Trust model involves ensuring that endpoints are
    healthy and compliant with security policies before granting access to network
    resources. It includes device management tools, compliance policies, and device
    health checks to ensure that devices and endpoints are secure and up to date.
  prefs: []
  type: TYPE_NORMAL
- en: Apps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another significant area is **applications**, which involves securing applications
    and ensuring that only authorized users and devices can access them. Applications
    must have a unique identity and should include authentication before granting
    access to network resources. This includes using certificates, tokens, and secure
    communication protocols to establish trust between applications and network resources.
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Data** is a crucial component in ML and involves securing data and ensuring
    that only authorized users and devices can access it. Multiple methods of securing
    data include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data classification** and **labeling** involve classifying and labeling data
    according to its sensitivity level and implementing access controls based on the
    classification. Labeling can be automated or user-defined and should include monitoring
    the data usage to protect sensitive data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data protection** involves protecting data both in transit and at rest. This
    includes encryption, access controls, and monitoring data usage to prevent unauthorized
    access or leakage of sensitive data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Governance**, **compliance**, and **regulatory requirements** mean ensuring
    that data is handled under appropriate governance, compliance, and regulatory
    requirements. This includes data retention policies, data breach notification
    policies, and compliance audits to ensure data is handled appropriately.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Infrastructure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Infrastructure** is vital in securing compute that connects devices, host
    applications, and data. Infrastructure includes any physical or virtual devices.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Device security** is about securing network devices such as switches, routers,
    and firewalls to prevent unauthorized access and ensure they are configured securely.
    It includes implementing device management tools, firmware, and software updates,
    and monitoring device activity to detect potential security threats.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Virtualization** security involves securing virtualized environments such
    as virtual machines and containers to prevent unauthorized access and ensure they
    are configured securely. It includes implementing virtualization management tools,
    patching and updates, and monitoring virtualization activity to detect potential
    security threats.'
  prefs: []
  type: TYPE_NORMAL
- en: The kind of cloud environment should also be considered, such as **infrastructure
    as a service** (**IaaS**), **platform as a service** (**PaaS**), and **software
    as a** **service** (**SaaS**).
  prefs: []
  type: TYPE_NORMAL
- en: Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, **network** is a defense area that includes securing the network connections
    between devices, applications, and data. The methods to achieve this are network
    micro-segmentation and access control. We can implement this by dividing the network
    into smaller segments and restricting access between them. We can expand the safety
    of the network by implementing firewalls and monitoring network activity to detect
    potential security threats. This includes managing network traffic and log analysis
    to detect potential security threats and take proactive measures to prevent them.
  prefs: []
  type: TYPE_NORMAL
- en: Let us move on to see how we can apply the Zero Trust strategy to assess the
    security status of our ML workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Assessing the vulnerability of ML assets and apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Part of assessing the vulnerabilities of Azure Machine Learning assets involves
    identifying potential security risks and then implementing appropriate measures
    to mitigate them.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will go through Azure Machine Learning components and their possible
    vulnerabilities. The implementation of security measures will be explained in
    greater detail in the rest of the book. The assessment is based on the Zero Trust
    defense areas.
  prefs: []
  type: TYPE_NORMAL
- en: The first step is identifying all the assets associated with Azure Machine Learning,
    such as data, models, and algorithms. That does not mean the Azure Machine Learning
    Studio only. Several services associated with Azure Machine Learning need to be
    checked. Once you have identified the assets, you should assess their potential
    risks, including unauthorized access, data breaches, and misuse.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to remember that everything in Azure operates on top of cloud
    infrastructure, so it is helpful to get familiar with any services that work with
    Azure Machine Learning and secure them. We will see in the next chapter how adversaries
    can leverage other systems to compromise ML projects. You might not need to use
    all of those systems, but if you are already using some of them it will help you
    assess what you need to secure.
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through the Zero Trust model areas and identify each service used
    in each area that relates to Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: Identity management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure uses **Microsoft Entra ID** (previously **Azure Active Directory**) for
    user authentication, authorization, and **role-based access control** (**RBAC**)
    to manage permissions for Azure resources. The Microsoft Entra ID service is an
    identity management solution that provides all controls to manage and safeguard
    access, including capabilities such as conditional access policies, identity protection,
    and privileged identity management.
  prefs: []
  type: TYPE_NORMAL
- en: First, identify each user or group and what access they need to use the services.
    Azure Machine Learning supports multiple roles such as data scientists, developers,
    IT administrators, and security engineers. Note what is the least access required
    for each user or group. Then, we can investigate what Microsoft Entra ID features
    you need to enable to mitigate access risks…
  prefs: []
  type: TYPE_NORMAL
- en: Data and data sources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data is the biggest component of any ML project. In Azure Machine Learning,
    you can add data from many sources. Identify all those sources and enable their
    security capabilities. Suppose you are importing data into the Azure Machine Learning
    workspace. In that case, it is stored in the Azure Storage account connected to
    your workspace. You must limit access to the workspace and secure the Storage
    account as well. If you are using a data source in Azure such as Azure SQL Server
    or CosmosDB, these services have multiple safeguards to limit access and protect
    from data breaches and data loss. Ensure that all data is also encrypted at rest
    and in transit. Azure provides several encryption options, such as **Azure Key
    Vault** and **Azure Storage Service Encryption**. **Azure SQL Database** also
    supports encryption on multiple levels. Another aspect to consider is backup.
    Ensure you have multiple options to recover your data in case of a security incident.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure Machine Learning works on top of Azure Infrastructure. There are four
    types of compute in Azure Machine Learning for training or inference, compute
    targets, compute clusters, AKS, and attached compute. For the deployment of models,
    you can use Azure Container Registry and Azure Containers. For attached compute,
    you can leverage virtual machines, the Azure Databricks service, and more. All
    those services have their own security features. Make sure you have all services
    or infrastructure up to date with the latest updates. Azure also provides several
    services for the automation of updates and monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Network and endpoints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Virtual networks are part of the Azure infrastructure services. Every service
    in Azure is deployed in the Microsoft network, or as it is sometimes called, the
    **Azure Backbone** network. Suppose your solution does not necessarily need to
    be available from the public internet, but only from your company office to and
    from Azure services, for example. In that case, multiple ways exist to keep traffic
    over the Azure Backbone network by encrypting and routing the network traffic
    between your virtual network and your on-premises infrastructure security. Identify
    the necessary endpoints and restrict network access to your workspace if possible.
    You can use anything from virtual networks, private links, and VPNs such as the
    Azure VPN Gateway, to even a private connection using ExpressRoute. If you already
    have firewalls, such as the Azure Firewall, or any networking, you can leverage
    those services to protect your ML projects. That could also apply to other services
    working with Azure Machine Learning, such as databases.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and maintenance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Part of the assessment is also setting a plan for monitoring and maintenance
    in place. Now that you have identified all the services you have and the features
    you need to enable, you need to answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Who is responsible for each security issue that arises?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What notifications should be enabled and for which services?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who is responsible for responding to each notification?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure has multiple views and support tools for monitoring and alerting.
  prefs: []
  type: TYPE_NORMAL
- en: AI/ML applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are two types of applications that you can leverage to work with Azure
    Machine Learning. These AI applications use the Azure Machine Learning endpoints
    for predictions or are applications that trigger Azure Machine Learning pipelines
    for model training or batch predictions.
  prefs: []
  type: TYPE_NORMAL
- en: For both types of applications, using secure coding practices will ensure that
    the application is not vulnerable to outside attacks. Techniques include input
    validation, error handling, and authentication mechanisms. Use secure protocols
    such as HTTPS or SSL/TLS to encrypt data in transit. To assess the vulnerability
    of an application, you can use security testing tools and techniques, such as
    penetration testing and vulnerability scanning, to identify and remediate potential
    security weaknesses. The application should also not expose or hardcode sensitive
    information such as connection strings or endpoint access keys. You can mitigate
    this using another Azure service, the Azure Key Vault. Applications that trigger
    pipelines that also need access data should be continuously assessed and monitored
    as changes in the dataset can affect the model’s accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: As you might have already realized, security is not clear-cut, but rather an
    iterative process. We need to assess, implement, monitor, and repeat to make sure
    our workloads are secure in Azure. We might need to leverage multiple security
    features and recommendations and tailor the Zero Trust strategy to our needs.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the basics of the ML life cycle and how it applies
    to Azure Machine Learning components. This knowledge is essential not only for
    data scientists and developers, but also for IT administrators and security engineers
    who are required to know the basics of ML development to ensure they can secure
    and monitor all associated services. For anyone wanting to get more familiar with
    Azure Machine Learning, you can always come back and recreate the scenario presented
    at the beginning as a base to follow along with the implementations and methods
    presented in the rest of the book’s chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Together, we learned what the Zero Trust strategy is and how it can be applied
    to Azure Machine Learning components and their associated services to assess what
    needs to be secured. We will need Zero Trust, as the principles and the defense
    areas outlined in this strategy are the same ones we will use in our security
    implementations in the following chapters. Now that you know how to create an
    initial assessment of the services you need to protect, in the next chapter, we
    will learn more about the methods and techniques that adversaries use to compromise
    our system. By learning those methods, you will be better equipped to protect
    your ML workloads and associated systems.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Introduction to Azure Machine* *Learning*: https://learn.microsoft.com/en-us/training/modules/intro-to-azure-ml'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Introduction to the Azure Machine Learning* *SDK*: [https://learn.microsoft.com/en-us/training/modules/intro-to-azure-machine-learning-service/](https://learn.microsoft.com/en-us/training/modules/intro-to-azure-machine-learning-service/
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Train an ML model with Azure Machine* *Learning*: https://learn.microsoft.com/en-us/training/modules/train-local-model-with-azure-mls/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Introduction to Zero Trust and best practice* *frameworks*: [https://learn.microsoft.com/en-us/training/modules/introduction-zero-trust-best-practice-frameworks/](https://learn.microsoft.com/en-us/training/modules/introduction-zero-trust-best-practice-frameworks/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
