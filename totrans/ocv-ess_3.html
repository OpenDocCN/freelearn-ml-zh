<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;3.&#xA0;First Things First &#x2013; Image Processing"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03" class="calibre1"/>Chapter 3. First Things First – Image Processing</h1></div></div></div><p class="calibre7">Image processing<a id="id191" class="calibre1"/> refers to digital processing of any two-dimensional data (a picture) by a computer by applying signal processing methods. Image processing has a broad spectrum of applications, such as image representation, image enhancement or sharpening, image restoration by means of filtering, and geometrical correction. These applications are usually the first stage and input to the following stages in a computer vision system. In OpenCV, there is a specific module, <code class="email">imgproc</code>, for image processing. In this chapter, we will cover the most important and frequently used methods available in the library, that is, pixel-level access, histogram manipulation, image equalization, brightness and contracts modeling, color spaces, filtering, and arithmetic and geometrical transforms.</p></div>

<div class="book" title="Chapter&#xA0;3.&#xA0;First Things First &#x2013; Image Processing">
<div class="book" title="Pixel-level access and common operations"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch03lvl1sec19" class="calibre1"/>Pixel-level access and common operations</h1></div></div></div><p class="calibre7">One <a id="id192" class="calibre1"/>of the most fundamental operations in image processing<a id="id193" class="calibre1"/> is pixel-level access. Since an image is contained in the <code class="email">Mat</code> matrix type, there is a generic access form that uses the <code class="email">at&lt;&gt;</code> template function. In order to use it, we have to specify the type of matrix cells, for example:</p><div class="informalexample"><pre class="programlisting">Mat src1 = imread("stuff.jpg", CV_LOAD_IMAGE_GRAYSCALE);
uchar pixel1=src1.at&lt;uchar&gt;(0,0);
cout &lt;&lt; "First pixel: " &lt;&lt; (unsigned int)pixel1 &lt;&lt; endl;
Mat src2 = imread("stuff.jpg", CV_LOAD_IMAGE_COLOR);
Vec3b pixel2 = src2.at&lt;Vec3b&gt;(0,0);
cout &lt;&lt; "First pixel (B):" &lt;&lt; (unsigned int)pixel2[0] &lt;&lt; endl;
cout &lt;&lt; "First pixel (G):" &lt;&lt; (unsigned int)pixel2[1] &lt;&lt; endl;
cout &lt;&lt; "First pixel (R):" &lt;&lt; (unsigned int)pixel2[2] &lt;&lt; endl;</pre></div><p class="calibre7">Note that color images use the <code class="email">Vec3b</code> type, which is an array of three unsigned chars. Images with a fourth alpha (transparency) channel would be accessed using the type <code class="email">Vec4b</code>. The <code class="email">Scalar</code> type represents a 1 to 4-element vector and can also be used in all these cases. Note that <code class="email">at&lt;&gt;</code> can be also used to change pixel values (that is, on the left-hand side of an assignment).</p><p class="calibre7">Apart from pixel access, there are a number of <a id="id194" class="calibre1"/>common operations<a id="id195" class="calibre1"/> for which we should know the corresponding snippets. The following table shows these common operations:</p><div class="informalexample"><table border="1" class="calibre17"><colgroup class="calibre18"><col class="calibre19"/><col class="calibre19"/></colgroup><thead class="calibre20"><tr class="calibre21"><th valign="bottom" class="calibre22">
<p class="calibre23">Operation</p>
</th><th valign="bottom" class="calibre22">
<p class="calibre23">Code example</p>
</th></tr></thead><tbody class="calibre24"><tr class="calibre21"><td valign="top" class="calibre25">
<p class="calibre23">Obtain size of matrix</p>
</td><td valign="top" class="calibre25">
<p class="calibre23">
</p><div class="informalexample1"><pre class="programlisting1">Size siz=src.size();
cout &lt;&lt; "width: " &lt;&lt; siz.width &lt;&lt; endl;
cout &lt;&lt; "height: " &lt;&lt; siz.height &lt;&lt; endl;</pre></div><p class="calibre23">
</p>
</td></tr><tr class="calibre21"><td valign="top" class="calibre25">
<p class="calibre23">Obtain number of channels</p>
</td><td valign="top" class="calibre25">
<p class="calibre23">
</p><div class="informalexample1"><pre class="programlisting1">int nc=src.channels();</pre></div><p class="calibre23">
</p>
</td></tr><tr class="calibre21"><td valign="top" class="calibre25">
<p class="calibre23">Obtain pixel data type</p>
</td><td valign="top" class="calibre25">
<p class="calibre23">
</p><div class="informalexample1"><pre class="programlisting1">int d=src.depth();</pre></div><p class="calibre23">
</p>
</td></tr><tr class="calibre21"><td valign="top" class="calibre25">
<p class="calibre23">Set matrix values </p>
</td><td valign="top" class="calibre25">
<p class="calibre23">
</p><div class="informalexample1"><pre class="programlisting1">src.setTo(0); //for one-channel src</pre></div><p class="calibre23">
</p>
 
<p class="calibre23">Or</p>
<p class="calibre23">

</p><div class="informalexample1"><pre class="programlisting1">src.setTo(Scalar(b,g,r)); // for three-channel src</pre></div><p class="calibre23">
   </p>
</td></tr><tr class="calibre21"><td valign="top" class="calibre25">
<p class="calibre23">Create a copy of the matrix</p>
</td><td valign="top" class="calibre25">
<p class="calibre23">
</p><div class="informalexample1"><pre class="programlisting1">Mat dst=src.clone();</pre></div><p class="calibre23">
</p>
</td></tr><tr class="calibre21"><td valign="top" class="calibre25">
<p class="calibre23">Create a copy of the matrix (with optional mask)</p>
</td><td valign="top" class="calibre25">
<p class="calibre23">
</p><div class="informalexample1"><pre class="programlisting1">src.copy(dst, mask);</pre></div><p class="calibre23">
</p>
</td></tr><tr class="calibre21"><td valign="top" class="calibre25">
<p class="calibre23">Reference a submatrix</p>
</td><td valign="top" class="calibre25">
<p class="calibre23">
</p><div class="informalexample1"><pre class="programlisting1">Mat dst=src(Range(r1,r2),Range(c1,c2));</pre></div><p class="calibre23">
</p>
</td></tr><tr class="calibre21"><td valign="top" class="calibre25">
<p class="calibre23">Create a new matrix from a submatrix (that is, image crop)</p>
</td><td valign="top" class="calibre25">
<p class="calibre23">
</p><div class="informalexample1"><pre class="programlisting1">Rect roi(r1,c2, width, height);
Mat dst=src(roi).clone();</pre></div><p class="calibre23">
</p>
</td></tr></tbody></table></div><p class="calibre7">Note the difference in the last two rows: in the last row, a new matrix is created. The case of the penultimate row only creates a reference to a submatrix within <code class="email">src</code>, but data is not actually copied.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="tip04" class="calibre1"/>Tip</h3><p class="calibre7">The most <a id="id196" class="calibre1"/>common operations, including additional iterator-based pixel access methods, are summarized in the <span class="strong"><em class="calibre12">OpenCV 2.4 Cheat Sheet</em></span>, which can be downloaded from <a class="calibre1" href="http://docs.opencv.org/trunk/opencv_cheatsheet.pdf">http://docs.opencv.org/trunk/opencv_cheatsheet.pdf</a>.</p></div></div></div>
<div class="book" title="Image histogram"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec20" class="calibre1"/>Image histogram</h1></div></div></div><p class="calibre7">An image histogram<a id="id197" class="calibre1"/> represents the frequency of the occurrence of the various gray levels or colors in the image, in case of 2D and 3D histograms respectively. Therefore, the histogram is similar to the probability density function of the different pixel values, that is, the gray levels, present in the image. In OpenCV, the image histogram may be calculated with the function <code class="email">void calcHist(const Mat* images, int nimages, const int* channels, InputArray mask, OutputArray hist, int dims, const int* histSize, const float** ranges, bool uniform=true, bool accumulate=false)</code>. The first parameter is a pointer to the input image. It is possible to calculate the histogram of more than one input image. This allows you to compare image histograms and calculate the joint histogram of several images. The second parameter is the number of source images. The third input parameter is the list of the channels used to compute the histogram. It is possible to calculate the histogram of more than one channel of the same color image. Thus, in this case, the <code class="email">nimages</code> value will be 1 and the<a id="id198" class="calibre1"/> <code class="email">const int* channels</code> parameter will be an array with the list of channel numbers. </p><p class="calibre7">The number of channels goes from zero to two. The parameter<a id="id199" class="calibre1"/> <code class="email">InputArray mask</code> is an optional mask to indicate the array elements (image pixels) counted in the histogram. The fifth parameter is the output histogram. The parameter <a id="id200" class="calibre1"/>
<code class="email">int dims</code> is the histogram dimensionality that must be positive and not greater than 32 (<code class="email">CV_MAX_DIMS</code>). A histogram can be <span class="strong"><em class="calibre12">n</em></span>-dimensional according to the number of bins used to quantize the pixel values of the image. The parameter <code class="email">const int* histSize</code> is the array of histogram sizes in each dimension. It allows us to compute histograms with non-uniform binning (or quantification). The <code class="email">const float** ranges</code> parameter is the array of the <code class="email">dims</code> arrays of the histogram bin boundaries in each dimension. The last two parameters have Boolean values and by default are <code class="email">true</code> and <code class="email">false</code> respectively. They indicate that the histogram is uniform and non-accumulative.</p><p class="calibre7">The following <code class="email">ImgHisto</code> example<a id="id201" class="calibre1"/> shows how to calculate and display the one-dimensional histogram of a 2D image:</p><div class="informalexample"><pre class="programlisting">#include "opencv2/imgproc/imgproc.hpp" // a dedicated include file
#include "opencv2/highgui/highgui.hpp"
#include &lt;iostream&gt;

using namespace cv;
using namespace std;

int main( int argc, char *argv[])
{
    int histSize = 255;

    long int dim;
    Mat hist, image;

    //Read original image
    Mat src = imread( "fruits.jpg");

    //Convert color image to gray level image
    cvtColor(src, image, CV_RGB2GRAY);

    //Create three windows
    namedWindow("Source", 0);
    namedWindow("Gray Level Image", 0);
    namedWindow("Histogram", WINDOW_AUTOSIZE);

    imshow("Source", src);
    imshow("Gray Level Image", image);

<span class="strong"><strong class="calibre8">    calcHist(&amp;image, 1, 0, Mat(), hist, 1, &amp;histSize, 0);</strong></span>

    dim=image.rows *image.cols;
    Mat histImage = Mat::ones(255, 255, CV_8U)*255;

    normalize(hist, hist, 0, histImage.rows, CV_MINMAX, CV_32F);

    histImage = Scalar::all(255);
    int binW = cvRound((double)histImage.cols/histSize);

    for( int i = 0; i &lt; histSize; i++ )
    rectangle( histImage, Point(i*binW, histImage.rows), Point((i+1)*binW, histImage.rows – cvRound(hist.at&lt;float&gt;(i))), Scalar::all(0), -1, 8, 0 );
    imshow("Histogram", histImage);

    cout &lt;&lt; "Press any key to exit...\n";
    waitKey(); // Wait for key press
    return 0;
}</pre></div><p class="calibre7">The code explanation is given here: the example creates three windows with the source image, the grayscale image, and the result of the 1D histogram. The 1D histogram is shown as a bar <a id="id202" class="calibre1"/>diagram for the 255 gray values. Thus, first the color pixels are converted into gray values using the <code class="email">cvtColor</code> function. The gray values are then normalized using the <code class="email">normalize</code> function between 0 and the maximum gray level value. Then the 1D histogram is calculated by discretizing the colors in the image into a number of bins and counting the number of image pixels in each bin. The following screenshot shows the output of the example. Note that a new include file, <code class="email">imgproc.hpp</code>, dedicated to image processing is needed.</p><div class="mediaobject"><img src="../images/00013.jpeg" alt="Image histogram" class="calibre9"/><div class="caption"><p class="calibre13">Output of the histogram example</p></div></div><p class="calibre10"> </p></div>
<div class="book" title="Histogram equalization"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec21" class="calibre1"/>Histogram equalization</h1></div></div></div><p class="calibre7">Once <a id="id203" class="calibre1"/>the image histogram is calculated, it can be <a id="id204" class="calibre1"/>modelled so that the image is modified and the histogram has a different shape. This is useful to change the low-contrast levels of images with narrow histograms, since this will spread out the gray levels and thus enhance the contrast. Histogram modeling, also known as histogram transfer, is a powerful technique for image enhancement. In histogram equalization, the goal is to obtain a uniform histogram for the output image. That is, a flat histogram where each pixel value has the same probability. In OpenCV, histogram equalization is performed with the function <code class="email">void equalizeHist(InputArray src, OutputArray dst)</code>. The first parameter is the input image and the second one is the output image with the histogram equalized.</p><p class="calibre7">The following <code class="email">EqualizeHist_Demo</code> example shows how to calculate and display the histogram <a id="id205" class="calibre1"/>equalized <a id="id206" class="calibre1"/>and the effect on the two-dimensional image:</p><div class="informalexample"><pre class="programlisting">#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include &lt;iostream&gt;
#include &lt;stdio.h&gt;

using namespace cv;
using namespace std;

int main( int, char *argv[] )
{
  Mat src, image, hist;
  int histSize = 255;
  long int dim;

  //Read original image
  src = imread( "fruits.jpg");

  //Convert to grayscale
  cvtColor( src, src, COLOR_BGR2GRAY );

  //Apply Histogram Equalization
<span class="strong"><strong class="calibre8">  equalizeHist( src, image );</strong></span>

  //Display results
  namedWindow("Source image", 0 );
  namedWindow("Equalized Image", 0 );

  imshow( "Source image", src );
  imshow( "Equalized Image", image );

  //Calculate Histogram of the Equalized Image and display
  calcHist(&amp;image, 1, 0, Mat(), hist, 1, &amp;histSize, 0);
  dim=image.rows *image.cols;
  Mat histImage = Mat::ones(255, 255, CV_8U)*255;
  normalize(hist, hist, 0, histImage.rows, CV_MINMAX, CV_32F);
  histImage = Scalar::all(255);
  int binW = cvRound((double)histImage.cols/histSize);

  for( int i = 0; i &lt; histSize; i++ )
  rectangle( histImage, Point(i*binW, histImage.rows), Point((i+1)*binW, histImage.rows – cvRound(hist.at&lt;float&gt;(i))), Scalar::all(0), -1, 8, 0 );

  namedWindow("Histogram Equalized Image", WINDOW_AUTOSIZE);
  imshow("Histogram Equalized Image", histImage);
 
  waitKey();// Exits the program
  return 0;
}</pre></div><p class="calibre7">The code <a id="id207" class="calibre1"/>explanation is given as follows. The example first reads the original image and converts it to grayscale. Then, histogram equalization<a id="id208" class="calibre1"/> is performed using the <code class="email">equalizeHist</code> function. Finally, the histogram of the equalized image is shown together with the two previous images. The following screenshot shows the output of the example, where three windows are created with the grayscale image, the equalized image, and its histogram:</p><div class="mediaobject"><img src="../images/00014.jpeg" alt="Histogram equalization" class="calibre9"/><div class="caption"><p class="calibre13">Output of the histogram equalization example</p></div></div><p class="calibre10"> </p></div>
<div class="book" title="Brightness and contrast modeling"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec22" class="calibre1"/>Brightness and contrast modeling</h1></div></div></div><p class="calibre7">The<a id="id209" class="calibre1"/> brightness<a id="id210" class="calibre1"/> of an object is the perceived luminance or intensity and depends on the luminance of the environment. Two objects in different environments could have the same luminance but different brightness. The reason is that the human visual perception is sensitive to luminance contrast rather than absolute luminance. Contrast <a id="id211" class="calibre1"/>is the<a id="id212" class="calibre1"/> difference in luminance and/or color that makes an object distinguishable compared to other objects within the same field of view. The maximum contrast of an image is known as the contrast ratio or dynamic range.</p><p class="calibre7">It is possible to modify the brightness and contrast of an image by means of point-wise operations. Point operations map a given gray pixel value into a different gray level according to a transform previously defined. In OpenCV, point operations may be performed with the function <code class="email">void Mat::convertTo(OutputArray m, int rtype, double alpha=1, double beta=0)</code>. The <code class="email">convertTo</code> function converts an image array to another data type with optional scaling. The first parameter is the output image and the second parameter is the output matrix type, that is, the depth, since the number of channels is the same as the input image. Thus, the source pixel values <code class="email">I(x,y)</code> are converted to the target data type with the new value <code class="email">(I(x,y) * alpha + beta)</code>.</p><p class="calibre7">The following <code class="email">BrightnessContrast</code> example<a id="id213" class="calibre1"/> shows how to perform an image pixel (point) operation to modify brightness and contrast:</p><div class="informalexample"><pre class="programlisting">#include "opencv2/imgproc/imgproc.hpp"
#include "opencv2/highgui/highgui.hpp"

#include &lt;iostream&gt;

using namespace cv;
using namespace std;

int init_brightness  = 100;
int init_contrast = 100;

Mat image;

/* brightness and contrast function to highlight the image*/
<span class="strong"><strong class="calibre8">void updateBrightnessContrast(int, void* )</strong></span>
{
    int histSize = 255;
    int var_brightness = init_brightness  - 100;
    int var_contrast = init_contrast - 100;

    double a, b;
    if( var_contrast &gt; 0 )
    {
        double delta = 127.*var_contrast/100;
        a = 255./(255. - delta*2);
        b = a*(var_brightness - delta);
    }
    else
    {
        double delta = -128.*var_contrast/100;
        a = (256.-delta*2)/255.;
        b = a*var_brightness + delta;
    }

    Mat dst, hist;

    <span class="strong"><strong class="calibre8">image.convertTo(dst, CV_8U, a, b);</strong></span>

    imshow("image", dst);

    calcHist(&amp;dst, 1, 0, Mat(), hist, 1, &amp;histSize, 0);
    Mat histImage = Mat::ones(200, 320, CV_8U)*255;

    normalize(hist, hist, 0, histImage.rows, CV_MINMAX, CV_32F);

    histImage = Scalar::all(255);
    int binW = cvRound((double)histImage.cols/histSize);

    for( int i = 0; i &lt; histSize; i++ )
        rectangle( histImage, Point(i*binW, histImage.rows), Point((i+1)*binW, histImage.rows – cvRound(hist.at&lt;float&gt;(i))), Scalar::all(0), -1, 8, 0 );
       imshow("histogram", histImage);
   }

const char* keys = {
    "{1| |fruits.jpg|input image file}"
};

int main( int argc, const char** argv )
    {
        CommandLineParser parser(argc, argv, keys);
        string inputImage = parser.get&lt;string&gt;("1");

        //Read the input image.
        image = imread( inputImage, 0 );
        namedWindow("image", 0);
        namedWindow("histogram", 0);

        createTrackbar("brightness", "image", &amp;init_brightness , 200, <span class="strong"><strong class="calibre8">updateBrightnessContrast);</strong></span>
        createTrackbar("contrast", "image", &amp;init_contrast, 200, <span class="strong"><strong class="calibre8">updateBrightnessContrast);</strong></span>

        <span class="strong"><strong class="calibre8">updateBrightnessContrast(0, 0);</strong></span>

    waitKey();
    return 0;
}</pre></div><p class="calibre7">The code explanation is given here: the example creates two windows with the grayscale image and its histogram. The<a id="id214" class="calibre1"/> new values for the brightness and contrast are selected by the user using the function <code class="email">createTrackbar</code>. This function attaches two sliders or range controls to the image for brightness and contrast. The following screenshot shows the output of the <code class="email">BrightnessContrast</code> example for a value of 148 for brightness and 81 for contrast:</p><div class="mediaobject"><img src="../images/00015.jpeg" alt="Brightness and contrast modeling" class="calibre9"/><div class="caption"><p class="calibre13">Output of the brightness and contrast image modification</p></div></div><p class="calibre10"> </p></div>
<div class="book" title="Histogram matching and LUT"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec23" class="calibre1"/>Histogram matching and LUT</h1></div></div></div><p class="calibre7">The <a id="id215" class="calibre1"/>histogram may also be used to modify the color of an image. Histogram matching<a id="id216" class="calibre1"/> is a method of color adjustment between two color images. Given a reference image and a target image, the result (destination image) will be equal to the target image except that its (three) histograms will look like those of the reference image. This effect is known as <a id="id217" class="calibre1"/>
<span class="strong"><strong class="calibre8">color mapping</strong></span> or <a id="id218" class="calibre1"/>
<span class="strong"><strong class="calibre8">color transfer</strong></span>.</p><p class="calibre7">The histogram matching algorithm<a id="id219" class="calibre1"/> is run over each of the three color histograms independently. For each channel, the <span class="strong"><strong class="calibre8">cumulative distribution function</strong></span> (<span class="strong"><strong class="calibre8">cdf</strong></span>)<a id="id220" class="calibre1"/> has to be calculated. For a given channel, let <code class="email">Fr</code> be the cdf of the reference image and <code class="email">Ft</code> be the cdf of the target image. Then, for each pixel <code class="email">v</code> in the reference image, we find the gray level <code class="email">w</code>, for which <code class="email">Fr(v)=Ft(w)</code>. The pixel with value <code class="email">v</code> is thus changed to <code class="email">w</code>.</p><p class="calibre7">Next, we provide another example of histograms in which we use a technique called histogram matching. The example also uses <a id="id221" class="calibre1"/>
<span class="strong"><strong class="calibre8">look-up tables</strong></span> (<span class="strong"><strong class="calibre8">LUT</strong></span>). A look-up table transformation assigns a new pixel value to each pixel in the input image (there is a good explanation and example<a id="id222" class="calibre1"/> of an LUT at <a class="calibre1" href="http://docs.opencv.org/doc/tutorials/core/how_to_scan_images/how_to_scan_images.html">http://docs.opencv.org/doc/tutorials/core/how_to_scan_images/how_to_scan_images.html</a>). The new values are given by a table. Thus, the first entry in this table gives the new value for pixel value 0, the second the new value for pixel value 1, and so on. Assuming we use a source and destination image, the transform is then given by <code class="email">Dst(x,y)=LUT(Src(x,y))</code>.</p><p class="calibre7">The OpenCV function for performing a look-up table transformation is <code class="email">LUT(InputArray src, InputArray lut, OutputArray dst, int interpolation=0)</code>. The parameter <code class="email">src</code> is an 8-bit image. The table is given in the parameter <code class="email">lut</code>, which has 256 elements. The table has either one channel or the same number of channels as the source image.</p><p class="calibre7">The following is the <a id="id223" class="calibre1"/>
<code class="email">histMatching</code> example:</p><div class="informalexample"><pre class="programlisting">#include "opencv2/opencv.hpp"
#include &lt;iostream&gt;

using namespace std;
using namespace cv;

void histMatch(const Mat &amp;reference, const Mat &amp;target, Mat &amp;result){
    float const HISTMATCH = 0.000001;
    double min, max;

    vector&lt;Mat&gt; ref_channels;
    split(reference, ref_channels);
    vector&lt;Mat&gt; tgt_channels;
    split(target, tgt_channels);

    int histSize = 256;
    float range[] = {0, 256};
    const float* histRange = { range };
    bool uniform = true;

    //For every channel (B, G, R)
    for ( int i=0 ; i&lt;3 ; i++ )
    {
         Mat ref_hist, tgt_hist;
         Mat ref_hist_accum, tgt_hist_accum;

        //Calculate histograms
<span class="strong"><strong class="calibre8">        calcHist(&amp;ref_channels[i], 1, 0, Mat(), ref_hist, 1, &amp;histSize, &amp;histRange, uniform, false);</strong></span>
<span class="strong"><strong class="calibre8">        calcHist(&amp;tgt_channels[i], 1, 0, Mat(), tgt_hist, 1, &amp;histSize, &amp;histRange, uniform, false);</strong></span>

        //Normalize histograms
        minMaxLoc(ref_hist, &amp;min, &amp;max);
        if (max==0) continue;
        ref_hist = ref_hist / max;
        minMaxLoc(tgt_hist, &amp;min, &amp;max);
        if (max==0) continue;
        tgt_hist = tgt_hist / max;

        //Calculate accumulated histograms
        ref_hist.copyTo(ref_hist_accum);
        tgt_hist.copyTo(tgt_hist_accum);

        float * src_cdf_data = ref_hist_accum.ptr&lt;float&gt;();
        float * dst_cdf_data = tgt_hist_accum.ptr&lt;float&gt;();

        for ( int j=1 ; j &lt; 256 ; j++ )
        {
            src_cdf_data[j] = src_cdf_data[j] + src_cdf_data[j-1];
            dst_cdf_data[j] = dst_cdf_data[j] + dst_cdf_data[j-1];
        }
        //Normalize accumulated
        minMaxLoc(ref_hist_accum, &amp;min, &amp;max);
        ref_hist_accum = ref_hist_accum / max;
        minMaxLoc(tgt_hist_accum, &amp;min, &amp;max);
        tgt_hist_accum = tgt_hist_accum / max;

        //Result max
        Mat Mv(1, 256, CV_8UC1);
        uchar * M = Mv.ptr&lt;uchar&gt;();
        uchar last = 0;
        for ( int j=0 ; j &lt; tgt_hist_accum.rows ; j++ )
        {
            float F1 = dst_cdf_data[j];

            for ( uchar k=last ; k &lt; ref_hist_accum.rows ; k++ )
            {
                float F2 = src_cdf_data[k];
                if ( std::abs(F2 - F1) &lt; HISTMATCH ||  F2 &gt; F1 )
                {
                    M[j] = k;
                    last = k;
                    break;
                }
            }
        }
        Mat lut(1, 256, CV_8UC1, M);
        <span class="strong"><strong class="calibre8">LUT(tgt_channels[i], lut, tgt_channels[i]);</strong></span>
    }

    //Merge the three channels into the result image
    merge(tgt_channels, result);
}

int main(int argc, char *argv[])
{
    //Read original image and clone it to contain results
    Mat ref = imread("baboon.jpg", CV_LOAD_IMAGE_COLOR );
    Mat tgt = imread("lena.jpg", CV_LOAD_IMAGE_COLOR );
    Mat dst = tgt.clone();

    //Create three windows
    namedWindow("Reference", WINDOW_AUTOSIZE);
    namedWindow("Target", WINDOW_AUTOSIZE);
    namedWindow("Result", WINDOW_AUTOSIZE);
    imshow("Reference", ref);
    imshow("Target", tgt);

    <span class="strong"><strong class="calibre8">histMatch</strong></span>(ref, tgt, dst);
    imshow("Result", dst);

    // Position windows on screen
    moveWindow("Reference", 0,0);
    moveWindow("Target", ref.cols,0);
    moveWindow("Result", ref.cols+tgt.cols,0);

    waitKey(); // Wait for key press
    return 0;
}</pre></div><p class="calibre7">The code <a id="id224" class="calibre1"/>explanation is given here: the example first reads the reference and target images. The output image is also allocated. The main function is <code class="email">histMatch</code>. In it, the reference and target images are first split into the three color channels. Then, for every channel, we obtain the normalized histograms of reference and target images, followed by the respective cdfs. Next, the histogram matching transformation is performed. </p><p class="calibre7">Finally, we apply the new pixel values using the look-up table. Note that the transformation could also be applied by iterating over every pixel in the result image. The look-up table option is, however, much faster. The following screenshot shows the output of the sample. The color palette of the reference image (the <code class="email">baboon.jpg</code> image) is transferred to the target image.</p><div class="mediaobject"><img src="../images/00016.jpeg" alt="Histogram matching and LUT" class="calibre9"/><div class="caption"><p class="calibre13">Output of the histMatching example</p></div></div><p class="calibre10"> </p></div>
<div class="book" title="Conversion from RGB to other color spaces"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec24" class="calibre1"/>Conversion from RGB to other color spaces</h1></div></div></div><p class="calibre7">The color of an<a id="id225" class="calibre1"/> image may also be modified by changing the color space. In OpenCV, six color models are available and it is possible to convert from one to another by using the <code class="email">cvtColor</code> function.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note10" class="calibre1"/>Note</h3><p class="calibre7">The default color format in OpenCV is often referred to as RGB but it is actually BGR (the channels are reversed).</p></div><p class="calibre7">The function<a id="id226" class="calibre1"/> <code class="email">void cvtColor(InputArray src, OutputArray dst, int code, int dstCn=0)</code> has the input and output images as the first and second parameters. The third parameter is the color space conversion code and the last parameter is the number of channels in the output image; if this parameter is 0, the number of channels is obtained automatically from the input image.</p><p class="calibre7">The following <code class="email">color_channels</code> example<a id="id227" class="calibre1"/> shows how to convert from RGB to HSV, Luv, Lab, YCrCb, and XYZ color spaces:</p><div class="informalexample"><pre class="programlisting">#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"

using namespace cv;
using namespace std;

int main( ){
    Mat image, HSV, Luv, Lab, YCrCb, XYZ;

    //Read image
    image = imread("HappyFish.jpg", CV_LOAD_IMAGE_COLOR);

    //Convert RGB image to different color spaces
<span class="strong"><strong class="calibre8">    cvtColor(image, HSV, CV_RGB2HSV);</strong></span>
<span class="strong"><strong class="calibre8">    cvtColor(image, Luv, CV_RGB2Luv);</strong></span>
<span class="strong"><strong class="calibre8">    cvtColor(image, Lab, CV_RGB2Lab);</strong></span>
<span class="strong"><strong class="calibre8">    cvtColor(image, YCrCb, CV_RGB2YCrCb);</strong></span>
<span class="strong"><strong class="calibre8">    cvtColor(image, XYZ, CV_RGB2XYZ);</strong></span>

    //Create windows and display results
    namedWindow( "Source Image", 0 );
    namedWindow( "Result HSV Image", 0 );
    namedWindow( "Result Luv Image", 0 );
    namedWindow( "Result Lab Image", 0 );
    namedWindow( "Result YCrCb Image", 0 );
    namedWindow( "Result XYZ Image", 0 );

    imshow( "Source Image", image );
    imshow( "Result HSV Image",  HSV );
    imshow( "Result Luv Image", Luv );
    imshow( "Result Lab Image", Lab);
    imshow( "Result YCrCb Image", YCrCb );
    imshow( "Result XYZ Image", XYZ );

    waitKey(); //Wait for key press
    return 0;  //End the program
}</pre></div><p class="calibre7">The<a id="id228" class="calibre1"/> code <a id="id229" class="calibre1"/>explanation is given here: the first example reads the original image and makes the conversion into five different color models. The original image in RGB and the results are then displayed. The following screenshot shows the output of the sample:</p><div class="mediaobject"><img src="../images/00017.jpeg" alt="Conversion from RGB to other color spaces" class="calibre9"/><div class="caption"><p class="calibre13">Output of the different color spaces</p></div></div><p class="calibre10"> </p></div>
<div class="book" title="Filtering with the retina model"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec25" class="calibre1"/>Filtering with the retina model</h1></div></div></div><p class="calibre7">Image restoration<a id="id230" class="calibre1"/> is concerned with <a id="id231" class="calibre1"/>filtering the digital image to minimize the effect of degradations. Degradation is produced by the <a id="id232" class="calibre1"/>sensing environment during image acquisition by optical or electronic devices. The effectiveness of image filtering depends on the extent and the accuracy of the knowledge of the degradation process as well as on the filter design.</p><p class="calibre7">In OpenCV, there are <a id="id233" class="calibre1"/>several isotropic and <a id="id234" class="calibre1"/>anisotropic filters available operating on both spatial and frequency domains. One of the most recent filters is the retina filter, which is based on a model of the human visual system. There is a class named <code class="email">Retina</code> to perform spatio-temporal filtering modeling the two main retina information channels, which are <span class="strong"><strong class="calibre8">parvocellular</strong></span> (<code class="email">parvo</code>) <a id="id235" class="calibre1"/>due to foveal vision and <span class="strong"><strong class="calibre8">magnocellular</strong></span> (<code class="email">magno</code>) due to <a id="id236" class="calibre1"/>peripheral vision. The <code class="email">parvo</code> channel is related to detail extraction while the <code class="email">magno</code> channel is dedicated to motion analysis.</p><p class="calibre7">The <code class="email">Retina</code> class<a id="id237" class="calibre1"/> may be applied on still images, images sequences, and video sequences to perform motion analysis. Here we present a simplified version of the <code class="email">retinademo</code> algorithm<a id="id238" class="calibre1"/> provided in OpenCV. The algorithm <code class="email">Filter_Retina.cpp</code> presented here demonstrates the use of the retina model images, which can be used to perform texture analysis with enhanced signal-to-noise ratio and enhanced details that are robust against input image luminance ranges. The main properties <a id="id239" class="calibre1"/>of the human retina model are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Spectral whitening (mid-frequency detail enhancement)</li><li class="listitem">High-frequency spatio-temporal noise reduction (temporal noise and high-frequency spatial noise are minimized)</li><li class="listitem">Low-frequency luminance reduction (luminance range compression): High-luminance regions do not hide details in darker regions anymore</li><li class="listitem">Local logarithmic luminance compression allows details to be enhanced even in low-light conditions</li></ul></div><div class="informalexample" title="Note"><h3 class="title2"><a id="note11" class="calibre1"/>Note</h3><p class="calibre7">For more information, refer to <span class="strong"><em class="calibre12">Using Human Visual System Modeling for bio-inspired low level image processing, Benoit A., Caplier A., Durette B., Herault J.,</em></span> Elsevier, Computer Vision and Image Understanding 114 (2010), pp. 758-773. DOI at <a class="calibre1" href="http://dx.doi.org/10.1016/j.cviu.2010.01.011">http://dx.doi.org/10.1016/j.cviu.2010.01.011</a>.</p></div><p class="calibre7">The <a id="id240" class="calibre1"/>following <a id="id241" class="calibre1"/>is the <a id="id242" class="calibre1"/>code for the example:</p><div class="informalexample"><pre class="programlisting">#include "opencv2/opencv.hpp"
using namespace cv;
using namespace std;
int main(int argc, char* argv[])
{
    //Declare input image and retina output buffers
    Mat src, retinaOutput_parvo, retinaOutput_magno;

    src =  imread("starry_night.jpg", 1); // load image in RGB

    //Create a retina instance with default parameters setup
    Ptr&lt; Retina&gt; myRetina;

    //Allocate "classical" retina :
<span class="strong"><strong class="calibre8">    myRetina = new  Retina(src.size());</strong></span>

    //Save default retina parameters file
    myRetina-&gt;write("RetinaDefaultParameters.xml");

    //The retina parameters may be reload using method "setup"
    //Uncomment to load parameters if file exists
    //myRetina-&gt;setup("RetinaSpecificParameters.xml");
    myRetina-&gt;clearBuffers();

    //Several iteration of the filter may be done
    for( int iter = 1; iter &lt; 6; iter++ ){
        // run retina filter
<span class="strong"><strong class="calibre8">        myRetina-&gt;run(src);</strong></span>

        // Retrieve and display retina output
<span class="strong"><strong class="calibre8">        myRetina-&gt;getParvo(retinaOutput_parvo);</strong></span>
<span class="strong"><strong class="calibre8">        myRetina-&gt;getMagno(retinaOutput_magno);</strong></span>

        //Create windows and display results
        namedWindow("Source Image", 0 );
        namedWindow("Retina Parvo", 0 );
        namedWindow("Retina Magno", 0 );

        imshow("Source Image", src);
        imshow("Retina Parvo", retinaOutput_parvo);
        imshow("Retina Magno", retinaOutput_magno);
    }
    cout&lt;&lt;"Retina demo end"&lt;&lt; endl;   // Program end message
    waitKey();
    return 0;
}</pre></div><p class="calibre7">The code <a id="id243" class="calibre1"/>explanation is given here: the example first reads the input image and obtains the retina model of the image using classical parameters for <a id="id244" class="calibre1"/>the model. The retina can be <a id="id245" class="calibre1"/>settled up with various parameters; by default, the retina cancels mean luminance and enforces all details of the visual scene. The filter is then run five times and the <code class="email">parvo</code> and <code class="email">magno</code> images and its details are shown. The following screenshot shows the output of the retina model filter after the five iterations:</p><div class="mediaobject"><img src="../images/00018.jpeg" alt="Filtering with the retina model" class="calibre9"/><div class="caption"><p class="calibre13">Output of the retina filter after five iterations</p></div></div><p class="calibre10"> </p></div>

<div id="page" style="height:0pt"/><div class="book" title="Arithmetic and geometrical transforms"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec26" class="calibre1"/>Arithmetic and geometrical transforms</h1></div></div></div><p class="calibre7">An arithmetic transform<a id="id246" class="calibre1"/> changes the value of an image pixel and it is applied point to point, whereas a geometrical transform<a id="id247" class="calibre1"/> changes the position of the image pixels. Thus, points in an image get a new position in the output image without changing their intensity values. Examples of arithmetic transforms may be addition, subtraction, and division between images. Examples of geometrical transforms are scaling, translation, and rotation of images. More complex transformations are to solve the barrel and cushion deformations of an image produced by an optical lens.</p><p class="calibre7">In OpenCV, there are several functions to perform arithmetic and geometrical transforms. Here we show two examples for image addition and perspective transformation by means of the functions <code class="email">addWeighted</code> and <code class="email">warpPerspective</code> respectively.</p></div>

<div class="book" title="Arithmetic and geometrical transforms">
<div class="book" title="Arithmetic transform"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch03lvl2sec15" class="calibre1"/>Arithmetic transform</h2></div></div></div><p class="calibre7">The<a id="id248" class="calibre1"/> function <code class="email">addWeighted</code><a id="id249" class="calibre1"/> performs a linear combination of two images, that is, addition of two weighted images to carry out a linear blending. The function <code class="email">void addWeighted(InputArray src1, double alpha, InputArray src2, double beta, double gamma, OutputArray dst, int dtype=-1)</code> has two input images as the first and third parameters with their weights (second and fourth parameter). Then, the output image is the sixth parameter. The fifth parameter, <code class="email">gamma</code>, is a scalar added to each sum. The last parameter <code class="email">dtype</code> is optional and refers to the depth of the output image; when both input images have the same depth, it can be set to <code class="email">-1</code>.</p><p class="calibre7">The following <code class="email">LinearBlend</code> example<a id="id250" class="calibre1"/> shows how to perform a linear blending between two images:</p><div class="informalexample"><pre class="programlisting">#include "opencv2/highgui/highgui.hpp"

using namespace cv;
using namespace std;

int main()
{
    double alpha = 0.5, beta, input;
    Mat src1, src2, dst;

    //Read images (same size and type )
    src1 = imread("baboon.jpg");
    src2 = imread("lena.jpg");
     //Create windows
    namedWindow("Final Linear Blend", CV_WINDOW_AUTOSIZE );

    //Perform a loop with 101 iteration for linear blending
    for(int k = 0; k &lt;= 100; ++k ){
        alpha = (double)k/100;
        beta  = 1 - alpha;

<span class="strong"><strong class="calibre8">        addWeighted( src2, alpha, src1, beta, 0.0, dst );</strong></span>

        imshow( "Final Linear Blend", dst );
        cvWaitKey(50);
    }
    namedWindow("Original Image 1", CV_WINDOW_AUTOSIZE );
    namedWindow("Original Image 2", CV_WINDOW_AUTOSIZE );
    imshow( "Original Image 1", src1 );
    imshow( "Original Image 2", src2 );

    cvWaitKey(); // Wait for key press
    return 0;   // End
}</pre></div><p class="calibre7">The code explanation<a id="id251" class="calibre1"/> is given here: the example first reads two images, <code class="email">src1= baboon.jpg</code> and <code class="email">src2= lena.jpg</code>, and then performs a total of 101 linear combinations with different values of the weights <code class="email">alpha</code> and <code class="email">beta</code>. The first linear combination or blend is with <code class="email">alpha</code> equal to zero, and therefore it is the <code class="email">src1</code> image. The value of <code class="email">alpha</code> increases in the loop while the value of <code class="email">beta</code> decreases. Therefore, the <code class="email">src2</code> image is combined and superimposed onto the <code class="email">src1</code> image. This produces a morphing effect and the <code class="email">baboon.jpg</code> image gradually changes into a different image, that is, into <code class="email">lena.jpg</code>. The following screenshot shows the output of several linear blending steps at iterations <code class="email">1</code>, <code class="email">10</code>, <code class="email">20</code>, <code class="email">30</code>, <code class="email">40</code>, <code class="email">50</code>, <code class="email">70</code>, <code class="email">85</code>, and <code class="email">100</code>:</p><div class="mediaobject"><img src="../images/00019.jpeg" alt="Arithmetic transform" class="calibre9"/><div class="caption"><p class="calibre13">Output of different lineal blending between two images</p></div></div><p class="calibre10"> </p></div></div>

<div class="book" title="Arithmetic and geometrical transforms">
<div class="book" title="Geometrical transforms"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch03lvl2sec16" class="calibre1"/>Geometrical transforms</h2></div></div></div><p class="calibre7">The <a id="id252" class="calibre1"/>function <code class="email">warpPerspective, void ocl::warpPerspective(const oclMat&amp; src, oclMat&amp; dst, const Mat&amp; M, Size dsize, int flags=INTER_LINEAR)</code> performs<a id="id253" class="calibre1"/> a perspective transformation on an image. It has the input or source image <code class="email">src</code> as the first parameter and <a id="id254" class="calibre1"/>the output or destination image <code class="email">dst</code> as the second parameter. Then, the third parameter is a 2 x 3 transformation matrix obtained <a id="id255" class="calibre1"/>from the <code class="email">getPerspectiveTransform</code> function, which calculates a perspective transform from the positions of four points in the two images in four pairs of corresponding points. The fourth parameter of <code class="email">warpPerspective</code> is the size of the output image and the last parameter is the interpolation method. By default, the interpolation method is linear, <code class="email">INTER_LINEAR</code>; other <a id="id256" class="calibre1"/>methods supported are nearest neighbor <a id="id257" class="calibre1"/>
<code class="email">INTER_NEAREST</code> and<a id="id258" class="calibre1"/> cubic <code class="email">INTER_CUBIC</code>.</p><p class="calibre7">The following<a id="id259" class="calibre1"/> <code class="email">Geometrical_Transform</code> example performs a perspective transformation to the input image <code class="email">img.jpg</code>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note12" class="calibre1"/>Note</h3><p class="calibre7">For full details of the example, refer to <span class="strong"><em class="calibre12">N. Amin</em></span>, <span class="strong"><em class="calibre12">Automatic perspective correction for quadrilateral objects</em></span>, at <a class="calibre1" href="https://opencv-code.com/tutorials/automatic-perspective-correction-for-quadrilateral-objects/">https://opencv-code.com/tutorials/automatic-perspective-correction-for-quadrilateral-objects/</a>.</p></div><div class="informalexample"><pre class="programlisting">#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include &lt;iostream&gt;
#include &lt;stdio.h&gt;

using namespace cv;
using namespace std;

Point2f centerpoint(0,0);

Point2f computeIntersect(Vec4i a,Vec4i b){
    int x1 = a[0], y1 = a[1], x2 = a[2], y2 = a[3], x3 = b[0], y3 = b[1], x4 = b[2], y4 = b[3];

    if (float d = ((float)(x1 - x2) * (y3 - y4)) - ((y1 - y2) * (x3 - x4)))
    {
        Point2f pnt;
        pnt.x = ((x1 * y2 - y1 * x2) * (x3 - x4) - (x1 - x2) * (x3 * y4 - y3 * x4)) / d;
        pnt.y = ((x1 * y2 - y1 * x2) * (y3 - y4) - (y1 - y2) * (x3 * y4 - y3 * x4)) / d;
        return pnt;
    }
    else
    return Point2f(-1, -1);
}

void sortCorners(vector&lt;Point2f&gt;&amp; corner_points, Point2f centerpoint)
{
    vector&lt;Point2f&gt; top, bot;

    for (int i = 0; i &lt; corner_points.size(); i++)
    {
        if (corner_points[i].y &lt; centerpoint.y)
        top.push_back(corner_points[i]);
        else
        bot.push_back(corner_points[i]);
    }

    Point2f tl = top[0].x &gt; top[1].x ? top[1] : top[0];
    Point2f tr = top[0].x &gt; top[1].x ? top[0] : top[1];
    Point2f bl = bot[0].x &gt; bot[1].x ? bot[1] : bot[0];
    Point2f br = bot[0].x &gt; bot[1].x ? bot[0] : bot[1];

    corner_points.clear();
    corner_points.push_back(tl);
    corner_points.push_back(tr);
    corner_points.push_back(br);
    corner_points.push_back(bl);
}

int main(){
    Mat src = imread("img.jpg");
    if (src.empty())
    return -1;

    Mat dst = src.clone();

    Mat bw;
    cvtColor(src, bw, CV_BGR2GRAY);

    Canny(bw, bw, 100, 100, 3);
    vector&lt;Vec4i&gt; lines;
    HoughLinesP(bw, lines, 1, CV_PI/180, 70, 30, 10);

    vector&lt;Point2f&gt; corner_points;
    for (int i = 0; i &lt; lines.size(); i++)
    {
        for (int j = i+1; j &lt; lines.size(); j++)
        {
            Point2f pnt = computeIntersect(lines[i], lines[j]);
            if (pnt.x &gt;= 0 &amp;&amp; pnt.y &gt;= 0)
            corner_points.push_back(pnt);
        }
    }

    vector&lt;Point2f&gt; approx;
    approxPolyDP(Mat(corner_points), approx, arcLength(Mat(corner_points), true) * 0.02, true);

    if (approx.size() != 4)
    {
        cout &lt;&lt; "The object is not quadrilateral!" &lt;&lt; endl;
        return -1;
    }

    //Get center point
    for (int i = 0; i &lt; corner_points.size(); i++)
    centerpoint += corner_points[i];
    centerpoint *= (1. / corner_points.size());

    sortCorners(corner_points, centerpoint);

    //Draw lines
    for (int i = 0; i &lt; lines.size(); i++)
    {
        Vec4i v = lines[i];
        line(dst, Point(v[0], v[1]), Point(v[2], v[3]), CV_RGB(0,255,0));
    }

    //Draw corner points
    circle(dst, corner_points[0], 3, CV_RGB(255,0,0), 2);
    circle(dst, corner_points[1], 3, CV_RGB(0,255,0), 2);
    circle(dst, corner_points[2], 3, CV_RGB(0,0,255), 2);
    circle(dst, corner_points[3], 3, CV_RGB(255,255,255), 2);

    //Draw mass center points
    circle(dst, centerpoint, 3, CV_RGB(255,255,0), 2);

    //Calculate corresponding points for corner points
    Mat quad = Mat::zeros(src.rows, src.cols/2, CV_8UC3);

    vector&lt;Point2f&gt; quad_pnts;
    quad_pnts.push_back(Point2f(0, 0));
    quad_pnts.push_back(Point2f(quad.cols, 0));
    quad_pnts.push_back(Point2f(quad.cols, quad.rows));
    quad_pnts.push_back(Point2f(0, quad.rows));

    // Draw corresponding points
    circle(dst, quad_pnts[0], 3, CV_RGB(255,0,0), 2);
    circle(dst, quad_pnts[1], 3, CV_RGB(0,255,0), 2);
    circle(dst, quad_pnts[2], 3, CV_RGB(0,0,255), 2);
    circle(dst, quad_pnts[3], 3, CV_RGB(255,255,255), 2);

<span class="strong"><strong class="calibre8">    Mat transmtx = getPerspectiveTransform(corner_points, quad_pnts);</strong></span>
<span class="strong"><strong class="calibre8">    warpPerspective(src, quad, transmtx, quad.size());</strong></span>

    //Create windows and display results
    namedWindow("Original Image", CV_WINDOW_AUTOSIZE );
    namedWindow("Selected Points", CV_WINDOW_AUTOSIZE );
    namedWindow("Corrected Perspertive", CV_WINDOW_AUTOSIZE );

    imshow("Original Image", src);
    imshow("Selected Points", dst);
    imshow("Corrected Perspertive", quad);

    waitKey(); //Wait for key press
    return 0;  //End
}</pre></div><p class="calibre7">The code <a id="id260" class="calibre1"/>explanation is given here: the example first reads the input image (<code class="email">img.jpg</code>) and calculates the key points of the region of interest or object to perform the perspective transformation. The key points are the corner points of the object. The algorithm only works for quadrilateral objects. The methods to calculate corners (Canny operator and Hough transforms) are explained in <a class="calibre1" title="Chapter 4. What's in the Image? Segmentation" href="part0035_split_000.html#page">Chapter 4</a>, <span class="strong"><em class="calibre12">What's in the Image, Segmentation</em></span>. The points corresponding to the object corners are the corners of the output image. These points are shown with circles on the original image. The dimension of the output image is set to the same height and half the width of the input image. Finally, the image with the corrected object is visualized. The perspective correction uses a linear transform, <code class="email">INTER_LINEAR</code>. The following screenshot shows the output <a id="id261" class="calibre1"/>of the algorithm:</p><div class="mediaobject"><img src="../images/00020.jpeg" alt="Geometrical transforms" class="calibre9"/><div class="caption"><p class="calibre13">Output of the geometrical transform performed to correct the perspective</p></div></div><p class="calibre10"> </p></div></div>
<div class="book" title="Summary"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec27" class="calibre1"/>Summary</h1></div></div></div><p class="calibre7">This chapter has covered the most common image processing methods used in computer vision. Image processing is often the step performed just before further computer vision applications. It has many methods and is usually applied for image corrections and enhancement such as image histograms, image equalization, brightness and contrast modeling, image color conversion by means of histogram matching and color space transformations, filtering using the model of the human retina, and arithmetic and geometrical transforms.</p><p class="calibre7">The next chapter will cover the next stage in a computer vision system, that is, the segmentation process. We will see how to extract regions of interest within an image.</p></div>
<div class="book" title="What else?"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec28" class="calibre1"/>What else?</h1></div></div></div><p class="calibre7">Other important functions in OpenCV for image processing are related to filtering. These functions have been omitted in the chapter since they are straightforward. OpenCV includes an example that shows how to use the main filters <code class="email">([opencv_source_code]/samples/cpp/filter2D_demo.cpp</code>). The main filter functions are:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">GaussianBlur</code> for a Gaussian filter</li><li class="listitem"><code class="email">medianBlur</code> for a median filter</li><li class="listitem"><code class="email">bilateralFilter</code> for anisotropic filtering</li><li class="listitem"><code class="email">blur</code> for a homogeneous blur</li></ul></div></div></body></html>