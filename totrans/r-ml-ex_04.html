<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;3.&#xA0;Predicting Customer Shopping Trends with Market Basket Analysis" id="OPEK1-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03" class="calibre1"/>Chapter 3. Predicting Customer Shopping Trends with Market Basket Analysis</h1></div></div></div><p class="calibre8">After the previous <a class="calibre1" title="Chapter 2. Let's Help Machines Learn" href="part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8">Chapter 2</a>, <span class="strong"><em class="calibre10">Let's Help Machine Learn</em></span>, you now know how to make machines learn from observations and data points so that they can find out interesting patterns, trends, and make predictions. In this chapter, we will be dealing with one of the complex problems faced by retailers, stores, and e-commerce marketplaces today. With the advent of modern technology and innovations, shopping has become a relatively pleasant and enjoyable experience which we can enjoy from the comfort of our home, without even venturing to an actual store, using the web or dedicated apps which provide shopping facilities. With a humongous number of retailers, stores, marketplaces, and sellers, competition is pretty stiff, and to attract customers, they have to use all the data they can gather from consumers about their personal traits and shopping patterns, and use machine learning techniques to try and make shopping experiences as personalized as possible based on each customer.</p><p class="calibre8">You might be wondering how machine learning can help in making shopping experiences personalized for each user! The answer lies in two things: data and algorithms. Using a combination of both of these, retailers are able to figure out what are the most trending items that the consumers buy, the likes and dislikes of the customers, the peak times when the sales go up and come down, the trending combination of products which people tend to buy, and the product reviews and prices which are being offered by other retailers for the same products. Retailers have their own data science teams which aggregate this data and apply various machine learning algorithms which are used to analyze the trending products and build recommender engines which predict what the customers are most likely to buy, and give recommendations to the customers based on their interests and shopping history.</p><p class="calibre8">In this chapter, we will be focusing on product based recommendations where the algorithms focus on customer shopping transactional data, where we observe common patterns of product combinations bought by the customers, to detect and predict what products customers are most likely to buy and what they have bought in the past. The main techniques we will be focusing on in this chapter are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Product contingency matrix evaluation</li><li class="listitem">Frequent itemsets generation</li><li class="listitem">Association rule mining</li></ul></div><p class="calibre8">Trend analysis using association rules and pattern mining however have their own limitations. They do not provide a more personalized shopping experience for each customer based on attributes like their interests, products they have bought and rated. We will be looking at that in the subsequent chapter where we focus on algorithms such as user-based collaborative filtering, which takes into account both product based and user based features when building recommender engines.</p><p class="calibre8">What is most interesting is that all the retailers and e-commerce marketplaces, such as Staples, Macy's, Target, Amazon, Flipkart, Alibaba, Rakuten, Lazada, and many many others, have their own data science teams, which solve a wide variety of problems including the one we discussed earlier. They make use of all the data generated from customer shopping transactions, product stocks, deliveries, SLAs, reviews, advertisements, click-through rates, bounce rates, pricing data, and many other sources. They process this data and feed it into their machine learning algorithm based engines to generate data driven insights to increase sales and profits for the business. Now this is definitely one domain which is hot in the market right now. Let's now look further into some of the machine learning techniques and algorithms which help them in making such great data driven decisions!</p></div>

<div class="book" title="Chapter&#xA0;3.&#xA0;Predicting Customer Shopping Trends with Market Basket Analysis" id="OPEK1-973e731d75c2419489ee73e3a0cf4be8">
<div class="book" title="Detecting and predicting trends"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch03lvl1sec20" class="calibre1"/>Detecting and predicting trends</h1></div></div></div><p class="calibre8">In this section, we will <a id="id147" class="calibre1"/>talk about what exactly we mean by trends and how the retailers <a id="id148" class="calibre1"/>detect and predict these trends. Basically, a trend in the retail context can be defined as a specific pattern or behavior which occurs over a period of time. This may involve a product or a combination of products being sold out in a very short period of time or even the reverse. A simple example would be a best-selling smartphone being prebooked and out of stock before even hitting the shelves on any e-commerce marketplace, or a combination of products like the classic beer and diapers combination which is frequently found in shopping baskets or carts of customers!</p><p class="calibre8">How can we even start analyzing shopping carts or start to detect and predict shopping trends. Like I mentioned earlier, we can achieve this with a combination of the right data and algorithms. Let's assume that we are heading a large retail chain. First we will have to keep track of each and every transaction which is taking place from our stores and website. We will need to gather data points relevant to the items being purchased, stockouts, combinations of items purchased together, and customer transactions to begin with.</p><p class="calibre8">Once we have this data, we can start processing, normalizing, and aggregating this data to machine readable formats, which can be easily operated on and fed to machine learning algorithms for product recommendations based on the shopping trends. We can achieve this by using the right data structures and constructs which we learned back in <a class="calibre1" title="Chapter 1. Getting Started with R and Machine Learning" href="part0014_split_000.html#DB7S2-973e731d75c2419489ee73e3a0cf4be8">Chapter 1</a>, <span class="strong"><em class="calibre10">Getting Started with R and Machine Learning</em></span>. There are several machine learning algorithms which help us in analyzing the shopping transactional data and recommending products based on the shopping trends. The main paradigm under which these algorithms fall is popularly known as <a id="id149" class="calibre1"/>
<span class="strong"><strong class="calibre9">market basket analysis</strong></span>. Interestingly, these algorithms use statistical and machine learning concepts such as probability, support, confidence, lift, pattern detection, and many more to determine what are the items being bought together frequently, which helps us in analyzing shopping transactions and detecting and predicting trends. This ultimately helps us in making product recommendations for the customers and also making business decisions wisely, if we were running a retail chain! Do note that the only data we will be using in both these algorithms is pure shopping transactions based data.</p><p class="calibre8">Before we start diving into building algorithms to analyze the <a id="id150" class="calibre1"/>shopping carts and transactions, let us first see what market <a id="id151" class="calibre1"/>basket analysis actually means and the concepts associated with it. This will come in handy later on, when we implement machine learning algorithms using some of these concepts to solve real world problems.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Market basket analysis"><div class="book" id="PNV62-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec21" class="calibre1"/>Market basket analysis</h1></div></div></div><p class="calibre8">Market basket <a id="id152" class="calibre1"/>analysis consists of some modeling techniques which are typically used by retailers and e-commerce marketplaces to analyze shopping carts and transactions to find out what customers buy the most, what kind of items they buy, what the peak season is for specific items to be sold the most, and so on. We will be focusing on item based transactional patterns in this chapter for detecting and predicting what items people are buying and are most likely to buy. Let us first look at the formal definition of market basket analysis and then we will look at core concepts, metrics, and techniques tied to it. Finally, we will conclude with how to actually use these results to make data driven decisions.</p></div>

<div class="book" title="Market basket analysis">
<div class="book" title="What does market basket analysis actually mean?"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch03lvl2sec32" class="calibre1"/>What does market basket analysis actually mean?</h2></div></div></div><p class="calibre8">Market basket analysis <a id="id153" class="calibre1"/>typically encompasses several modeling techniques based upon the simple principle that while shopping if you buy a certain group of items (also known as an itemset in machine learning lingo), you are likely to buy an other specific item or items along with that itemset. We analyze human shopping patterns and apply statistical techniques to generate frequent itemsets. These itemsets contain combination of items that people are most likely to buy together, based on past shopping history.</p><p class="calibre8">A simple example of an itemset would be people buying beer and diapers frequently at the market. The itemset can be depicted as <code class="email">{ beer, diapers }</code>. A frequent itemset is indicated by an itemset which occurs more frequently than usual and is specified by a metric known as support, which we will be talking about later on. Hence, from the preceding example you can <a id="id154" class="calibre1"/>say that if I buy beer, I am also most likely to buy <code class="email">diapers</code>, and recommend that product to me. We can also build item association rules on top of these itemsets by analyzing shopping purchases. An example association rule can be denoted by using itemsets using the notation, <code class="email">{ beer, diapers } -&gt; { milk }</code> which would indicate that if I am buying beer and diapers together, I am most likely to also purchase milk along with that!</p></div></div>

<div class="book" title="Market basket analysis">
<div class="book" title="Core concepts and definitions"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch03lvl2sec33" class="calibre1"/>Core concepts and definitions</h2></div></div></div><p class="calibre8">Now that you know what <a id="id155" class="calibre1"/>market basket analysis actually does, let us look at some definitions and concepts which are widely used in the algorithms and techniques.</p><p class="calibre8"><span class="strong"><strong class="calibre9">Transactional datasets</strong></span> indicate databases or datasets where the customer's shopping transactions are recorded daily/weekly and consist of various items bought together by the customers. We will take an example transactional dataset which we will also be using later on in the chapter for our algorithms. Consider the following dataset, which you can also get from the <code class="email">shopping_transaction_log.csv</code> file for this chapter. The data is represented in the following figure:</p><div class="mediaobject"><img src="../images/00078.jpeg" alt="Core concepts and definitions" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Each cell in the preceding dataset is also defined as an item. Items are also denoted by the symbol In where <code class="email">n</code> denotes the <code class="email">n-th</code> item number, and examples are enclosed in curly braces in formal definitions and when building algorithm pseudocode or doing some computations by hand. For example, cell combination <code class="email">(1, A)</code> indicates item <code class="email">I1</code> whose value is depicted as <code class="email">{ beer }</code>.</p><p class="calibre8"><span class="strong"><strong class="calibre9">Itemsets</strong></span> are defined as sets or groups of items which were bought together in any shopping transaction. Hence, these items are said to co-occur based on the transactions. We will denote itemsets as <code class="email">ISn</code> where <span class="strong"><em class="calibre10">n</em></span> denotes the <code class="email">n-th</code> itemset number. The itemset values will will be enclosed in curly braces. Each row in the preceding dataset denotes a particular transaction and the combination of items form the itemsets. The itemset <code class="email">IS1</code> is depicted by <code class="email">{ beer, diapers, bread }</code>.</p><p class="calibre8"><span class="strong"><strong class="calibre9">Association </strong></span><a id="id156" class="calibre1"/>
<span class="strong"><strong class="calibre9">rules</strong></span> or just rules are statements which have a <span class="strong"><strong class="calibre9">left-hand side</strong></span> (<span class="strong"><strong class="calibre9">LHS</strong></span>) and <a id="id157" class="calibre1"/>a <span class="strong"><strong class="calibre9">right-hand side</strong></span> (<span class="strong"><strong class="calibre9">RHS</strong></span>), and indicate that if we have the items on the LHS for purchase, we are likely to be interested in purchasing the <a id="id158" class="calibre1"/>RHS items too. This signifies that the itemsets are associated with each other. They are denoted as <code class="email">ISx  →  ISy</code>, which means that if I have itemset <code class="email">x</code> in my shopping cart, I will also be interested in purchasing itemset <code class="email">y</code> along with it. An example rule can be <code class="email">{ beer } → { diapers }</code> which indicates that if I have beer in my cart, there is a chance I will buy diapers too! We will now see some metrics which determine how to measure frequent itemsets and the strength of the association rules.</p><p class="calibre8">The <span class="strong"><strong class="calibre9">frequency</strong></span> of an itemset is basically the number of times a particular itemset occurs in the list of all transactions. Do note that the itemset can be a subset of a larger itemset in the transactions and still be counted because the subset denotes that the itemset containing the specific set of items was bought along with some other products. We can denote it as <code class="email">f(ISn)</code>, where <code class="email">ISn</code> is a particular itemset and function <code class="email">f( )</code> gives us the frequency of that itemset in the whole transactional based dataset. Taking our previous dataset, <code class="email">f(IS{beer, diapers})</code> is six, which indicates <code class="email">IS{beer, diapers}</code> has been purchased six times in total out of all the transactional data in our dataset.</p><p class="calibre8">The <span class="strong"><strong class="calibre9">support</strong></span> of an itemset is defined as the fraction of transactions in our transactional dataset which consists of that particular itemset. Basically, it means the number of times that itemset was purchased divided by the total number of transactions in the dataset. It can be denoted as <span class="strong"><img src="../images/00079.jpeg" alt="Core concepts and definitions" class="calibre16"/></span>, where <code class="email">S( )</code> denotes the support of the itemset <code class="email">ISn</code>. Taking our preceding example, <code class="email">S(IS{beer, diapers})</code> is <span class="strong"><img src="../images/00080.jpeg" alt="Core concepts and definitions" class="calibre16"/></span> which gives us <code class="email">66.67%</code>. The support for an association rule is similar and can be depicted as <span class="strong"><img src="../images/00081.jpeg" alt="Core concepts and definitions" class="calibre16"/></span>, where we use the intersection operator to see the frequency of both the itemsets occurring together in the transactional dataset. The support for the rule we defined earlier, <code class="email">S(IS{beer} → IS{diapers})</code>, is once again <span class="strong"><img src="../images/00080.jpeg" alt="Core concepts and definitions" class="calibre16"/></span> or <code class="email">66.67%</code> because the itemset combining beer and diapers occurs six times in total, as we saw earlier. When evaluating results from association rules or frequent itemsets, the higher the support, the better it is. Support is more about measuring the quality of rules detecting what has already happened from the past transactions.</p><p class="calibre8">The <span class="strong"><strong class="calibre9">confidence</strong></span> of an association rule is defined as the probability or likelihood that, for a new transaction containing itemset in the LHS of the rule, the transaction also contains the itemset on the RHS of the rule. The confidence for a rule can be depicted as <span class="strong"><img src="../images/00082.jpeg" alt="Core concepts and definitions" class="calibre16"/></span>, where <code class="email">C( )</code> denotes the confidence of the rule. Do note that since calculation of support involves dividing itemset frequency by the total number of transactions in the denominator, the RHS of the preceding equation ultimately reduces to getting the frequency of the itemsets for both the numerator and denominator. Thus we get <span class="strong"><img src="../images/00083.jpeg" alt="Core concepts and definitions" class="calibre16"/></span> as the reduced formula for getting confidence. The confidence for our earlier rule <code class="email">C(IS{beer} → IS{diapers})</code> is <span class="strong"><img src="../images/00084.jpeg" alt="Core concepts and definitions" class="calibre16"/></span> or <code class="email">100%</code>, which means the probability of buying diapers, if I have beer in my shopping basket, is a hundred percent! That is pretty high and if you go back to the dataset, you can see that it is true because for every transaction involving beer, we can see diapers associated with it. Thus, you can see that making predictions and recommendations is not rocket science but just simple applied math and statistical methods on top of data. Remember that confidence is more about detecting the quality of rules predicting what can happen in the future based on the past transactional data.</p><p class="calibre8">The <span class="strong"><strong class="calibre9">lift</strong></span> of an association rule is defined as the ratio of the support of the combination of two itemsets on the LHS and RHS together divided by the product of the support of each of the itemsets. The lift for a rule can be depicted as <span class="strong"><img src="../images/00085.jpeg" alt="Core concepts and definitions" class="calibre16"/></span>, where <code class="email">L( )</code> denotes the lift of the rule. For our example rule, <code class="email">L(IS{beer} → IS{diapers})</code> is, <span class="strong"><img src="../images/00086.jpeg" alt="Core concepts and definitions" class="calibre16"/></span> which evaluates to <span class="strong"><img src="../images/00087.jpeg" alt="Core concepts and definitions" class="calibre16"/></span> giving us the value of <code class="email">1.125</code> which is pretty decent! The lift of a rule in general is another metric to evaluate the quality of the rule. If the lift is <code class="email">&gt; 1</code> then it indicates that the presence of the itemset in the LHS is responsible for the increase in probability that the customer is also going to buy the itemset on the RHS. This is another very important way to determine itemset associations and which <a id="id159" class="calibre1"/>items influence people to buy other items, because if the lift has a value <code class="email">= 1</code>, it means that the itemsets on the LHS and RHS are independent and buying one itemset will not affect the customer to buy the other itemset. If the lift is <code class="email">&lt; 1</code>, it indicates that if the customer has an itemset on the LHS then the probability of buying the itemset on the RHS is relatively low.</p></div></div>

<div class="book" title="Market basket analysis">
<div class="book" title="Techniques used for analysis"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch03lvl2sec34" class="calibre1"/>Techniques used for analysis</h2></div></div></div><p class="calibre8">If you have been <a id="id160" class="calibre1"/>overwhelmed by all the mathematical information in the previous section, just relax and take a deep breath! You do not need to remember everything because most of the time, the algorithms will compute everything for you! The thing where you need to be good at is using these techniques and algorithms in the right way and interpreting the results to filter out what is necessary and useful. The earlier mentioned concepts will help you when you start implementing and applying the techniques later on, which we will briefly describe in this section. We will mainly be talking about three techniques which we will be exploring in this chapter.</p><p class="calibre8">Evaluation of a product contingency matrix is the simplest approach to start with, which is more of a global trend capturing mechanism and shows the top most products that are being bought together in a <a id="id161" class="calibre1"/>contingency matrix. The R package <code class="email">arules</code>, which we will be using later on, has a nice function called <span class="strong"><strong class="calibre9">crossTable</strong></span> which helps in cross-tabulating the joint occurrences across pairs of items into a contingency matrix. We will use this matrix to predict which products the customers would most likely buy with some other product from the matrix.</p><p class="calibre8">Frequent itemset generation takes off from where product contingency matrix stops, because it has a severe limitation of not being able to deal with pairs of products at any point in time. Hence, to get into itemsets which can have any number of products and detect patterns from there, we will be building our own frequent itemset generator using machine learning! Using this, we will be able to get frequent itemsets with specific support values indicating the sets of items likely to be purchased together, and hence forming the basis of recommending products to the customers.</p><p class="calibre8">Finally, we will be implementing association rule mining using the wonderful Apriori algorithm which uses frequent <a id="id162" class="calibre1"/>itemsets as a part of its rule generation process. You have already seen a demo of this in the <a class="calibre1" title="Chapter 2. Let's Help Machines Learn" href="part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8">Chapter 2</a>, <span class="strong"><em class="calibre10">Let's Help Machines Learn</em></span>. However, this time we will be using its full-fledged capabilities to view the association rules between product itemsets, evaluating the quality of the rules using the metrics we discussed earlier, and also using these rules to make trend predictions and recommendations for products in shopping transactions.</p></div></div>

<div class="book" title="Market basket analysis">
<div class="book" title="Making data driven decisions"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch03lvl2sec35" class="calibre1"/>Making data driven decisions</h2></div></div></div><p class="calibre8">You now know <a id="id163" class="calibre1"/>what market basket analysis is, what techniques are used for it, and what results they give us. Remember that the output of market basket analysis is a set of items or products which co-occur frequently in transactions. Now this can happen because of strong support, confidence, and lift which boost its association and the customers tend to buy them, or it could also be because the retailer has placed the items together or side by side in the store or website. However, do remember that strong associations do not always happen just by chance and that is what the retailers are always trying to find out using the techniques we talked about earlier to boost sales.</p><p class="calibre8">The following are some crucial data driven decisions which the retailers usually tend to take based on the results obtained from market basket analysis:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Frequent itemsets containing pairs of products such as diapers and beer should be typically placed side by side in the store, which would give customers easy access and they would tend to buy them more.</li><li class="listitem">Frequent itemsets which have a large number of distinct items or product counts should be placed in a specific category or theme for the itemset, such as special grocery combos or baby products. Discounts offered on the whole itemset attracts more customers.</li><li class="listitem">Association rules having a long list of items in the itemset or products obtained from frequent itemsets or contingency matrices can be shown as product suggestions and recommendations to the customers, in specific product pages associated with the itemsets, when they browse the shopping or e-commerce website. Care should be taken that the lift of these rules be greater than 1 at least, like we discussed earlier.</li><li class="listitem">Recommendation systems, targeted advertising, and marketing everything can be built upon the results obtained from market basket analysis.</li></ul></div><p class="calibre8">These decisions if made at the right place and right time can help the retailers immensely in boosting their sales and making good profits.</p><p class="calibre8">Now that we have a solid grasp of what market basket analysis actually does and how it works, we will start by building a simple algorithm for our first technique, where we make product recommendations using a product contingency matrix based on top trending products purchased in a supermarket, and then move on to building more sophisticated <a id="id164" class="calibre1"/>analyzers and recommenders using powerful machine learning capabilities of the R language.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Evaluating a product contingency matrix"><div class="book" id="QMFO2-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec22" class="calibre1"/>Evaluating a product contingency matrix</h1></div></div></div><p class="calibre8">We will be doing a <a id="id165" class="calibre1"/>couple of things here. First, we will analyze a small toy dataset belonging to a supermarket, by using a product contingency matrix of product pair purchases based on their frequency. Then we will move on to contingency matrices based on other metrics such as support, lift, and so on by using another dataset.</p><p class="calibre8">The data for our first matrix consists of the six most popular products sold at the supermarket and also the number of times each product was sold by itself and in combination with the other products. We have the data in the form of a data table captured in a <code class="email">csv</code> file, as you can see in the following figure:</p><div class="mediaobject"><img src="../images/00088.jpeg" alt="Evaluating a product contingency matrix" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">To analyze this data, we first need to understand what it depicts. Basically, each cell value denotes the number of times that product combination was sold. Thus, the cell combination <code class="email">(1, A)</code> denotes the product combination <code class="email">(milk, milk)</code>, which is basically the number of times milk was bought. Another example is the cell combination <code class="email">(4, C)</code> which is analogous to cell combination <code class="email">(3, D)</code> which indicates the number of times bread was bought along with butter. This is also often known as a contingency matrix and in our case it is a product contingency matrix since it deals with product data. Let us follow our standard machine learning pipeline of getting the data, analyzing it, running it on our algorithm, and <a id="id166" class="calibre1"/>getting the intended results.</p></div>

<div class="book" title="Evaluating a product contingency matrix">
<div class="book" title="Getting the data"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch03lvl2sec36" class="calibre1"/>Getting the data</h2></div></div></div><p class="calibre8">Here, we will first <a id="id167" class="calibre1"/>load the dataset into memory from the disk using the following code snippet. Remember to have the <code class="email">top_supermarket_transactions.csv</code> file in the same directory from which you run the following code snippet, which is also available in the file named <code class="email">ch3_product</code> contingency <code class="email">matrix.R</code> along with this book.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # reading in the dataset</strong></span>
<span class="strong"><strong class="calibre9">&gt; data &lt;- read.csv("supermarket_transactions.csv")</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; # assigning row names to be same as column names</strong></span>
<span class="strong"><strong class="calibre9">&gt; # to build the contingency matrix</strong></span>
<span class="strong"><strong class="calibre9">&gt; row.names(data) &lt;- data[[1]]</strong></span>
<span class="strong"><strong class="calibre9">&gt; data &lt;- subset(data, select = c(-1))</strong></span>
<span class="strong"><strong class="calibre9">&gt;</strong></span>
<span class="strong"><strong class="calibre9">&gt; ## viewing the contingency matrix</strong></span>
<span class="strong"><strong class="calibre9">&gt; cat("Products Transactions Contingency Matrix")</strong></span>
<span class="strong"><strong class="calibre9">Products Transactions Contingency Matrix</strong></span>
<span class="strong"><strong class="calibre9">&gt; data</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output:</strong></span></p><p class="calibre8"><span class="strong"><img src="../images/00089.jpeg" alt="Getting the data" class="calibre16"/></span></p></div></div>

<div class="book" title="Evaluating a product contingency matrix">
<div class="book" title="Analyzing and visualizing the data"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch03lvl2sec37" class="calibre1"/>Analyzing and visualizing the data</h2></div></div></div><p class="calibre8">Here, we will <a id="id168" class="calibre1"/>do some exploratory analysis of the <a id="id169" class="calibre1"/>dataset to see what kind of story the data tells us. For that, we will first look at the transactions related to buying milk and bread in the following code snippet:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; ## Analyzing and visualizing the data</strong></span>
<span class="strong"><strong class="calibre9">&gt; # Frequency of products bought with milk</strong></span>
<span class="strong"><strong class="calibre9">&gt; data['milk', ]</strong></span>
<span class="strong"><strong class="calibre9">      milk bread butter beer wine diapers</strong></span>
<span class="strong"><strong class="calibre9">milk 10000  8758   5241  300  215     753</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; # Sorting to get top products bought with milk</strong></span>
<span class="strong"><strong class="calibre9">&gt; sort(data['milk', ], decreasing = TRUE)</strong></span>
<span class="strong"><strong class="calibre9">      milk bread butter diapers beer wine</strong></span>
<span class="strong"><strong class="calibre9">milk 10000  8758   5241     753  300  215</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; # Frequency of products bought with bread</strong></span>
<span class="strong"><strong class="calibre9">&gt; data['bread', ]</strong></span>
<span class="strong"><strong class="calibre9">      milk bread butter beer wine diapers</strong></span>
<span class="strong"><strong class="calibre9">bread 8758  9562   8865  427  322     353</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; # Sorting to get top products bought with bread</strong></span>
<span class="strong"><strong class="calibre9">&gt; sort(data['bread', ], decreasing = TRUE)</strong></span>
<span class="strong"><strong class="calibre9">      bread butter milk beer diapers wine</strong></span>
<span class="strong"><strong class="calibre9">bread  9562   8865 8758  427     353  322</strong></span>
</pre></div><p class="calibre8">Thus, you can see that just by sorting the data columns we are able to see the top products which were bought in combination with bread or with milk. When recommending top products to buy from the matrix, we will remove the product from the recommendation list if that product is in the shopping cart already, because, if I buy bread, it makes no sense to recommend bread to me. Now, we will visualize the complete dataset using a mosaic plot. Do note that the product combinations which were bought very frequently will have high frequency values and will be indicated by a significant area in the mosaic plot.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # Visualizing the data</strong></span>
<span class="strong"><strong class="calibre9">&gt; mosaicplot(as.matrix(data), </strong></span>
<span class="strong"><strong class="calibre9">+            color=TRUE, </strong></span>
<span class="strong"><strong class="calibre9">+            title(main="Products Contingency Mosaic Plot"),</strong></span>
<span class="strong"><strong class="calibre9">+            las=2</strong></span>
<span class="strong"><strong class="calibre9">+            )</strong></span>
</pre></div><p class="calibre8">The code generates the following mosaic plot where we apply a gradient using the color parameter and specify that axis labels be at right angles to the axis using the <code class="email">las</code> parameter to make a cleaner plot.</p><div class="mediaobject"><img src="../images/00090.jpeg" alt="Analyzing and visualizing the data" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">From the preceding plot you can note that it is now very easy to see which products were bought a large number of times in combination with another product. Ignoring the same product row and column <a id="id170" class="calibre1"/>values, we can easily deduce <a id="id171" class="calibre1"/>that product combinations such as beer and diapers were bought very frequently!</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note09" class="calibre1"/>Note</h3><p class="calibre8">The background story about our beer – diapers combination was actually discovered by Walmart sometime back when they analyzed customer transactional data to find that, on Fridays, young American dads tend to buy beer and diapers together. They would celebrate the weekend with their friends but, having fathered an offspring, they also carried out essential duties of taking care of their children's needs. In fact, Walmart placed beer and diapers side by side in stores and their sales went up significantly! This is the power of analytics and machine learning which enables us to find out unknown and unexpected patterns.</p></div></div></div>

<div class="book" title="Evaluating a product contingency matrix">
<div class="book" title="Global recommendations"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch03lvl2sec38" class="calibre1"/>Global recommendations</h2></div></div></div><p class="calibre8">Now we will <a id="id172" class="calibre1"/>recommend products based on the product chosen by a customer in his shopping cart. Do note that we mention this as global recommendations because these product recommendations are neither based on association rules or frequent itemsets that we will be exploring after this. They are purely based on the global product contingency matrix of product pair purchase counts. The following code snippet enables us to recommend the top two suggested products for each item from the matrix:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">## Global Recommendations</strong></span>
<span class="strong"><strong class="calibre9">cat("Recommendations based on global products contingency matrix")</strong></span>
<span class="strong"><strong class="calibre9">items &lt;- names(data)</strong></span>
<span class="strong"><strong class="calibre9">for (item in items){</strong></span>
<span class="strong"><strong class="calibre9">  cat(paste("Top 2 recommended items to buy with", item, "are: "))</strong></span>
<span class="strong"><strong class="calibre9">  item.data &lt;- subset(data[item,], select=names(data)[!names(data) %in% item])</strong></span>
<span class="strong"><strong class="calibre9">  cat(names(item.data[order(item.data, decreasing = TRUE)][c(1,2)]))</strong></span>
<span class="strong"><strong class="calibre9">  cat("\n")</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">This gives us the following output:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">Top 2 recommended items to buy with milk are: bread butter</strong></span>
<span class="strong"><strong class="calibre9">Top 2 recommended items to buy with bread are: butter milk</strong></span>
<span class="strong"><strong class="calibre9">Top 2 recommended items to buy with butter are: bread milk</strong></span>
<span class="strong"><strong class="calibre9">Top 2 recommended items to buy with beer are: wine diapers</strong></span>
<span class="strong"><strong class="calibre9">Top 2 recommended items to buy with wine are: beer butter</strong></span>
<span class="strong"><strong class="calibre9">Top 2 recommended items to buy with diapers are: beer milk</strong></span>
</pre></div><p class="calibre8">Thus you can see that, based on the product pair purchases from the contingency matrix, we get the top two products which people would tend to buy, based on the global trends captured in that matrix. Now we will look at some more ways to generate more advanced contingency matrices based on some other metrics.</p></div></div>

<div class="book" title="Evaluating a product contingency matrix">
<div class="book" title="Advanced contingency matrices"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch03lvl2sec39" class="calibre1"/>Advanced contingency matrices</h2></div></div></div><p class="calibre8">Until now we have just <a id="id173" class="calibre1"/>used product contingency matrices based on product purchase frequencies. We will now look at creating some more contingency matrices using metrics such as support and lift, which we talked about earlier, since they are better indicators for items which have a probability of being purchased together by customers when shopping. For this we will be using the package <code class="email">arules</code> <a id="id174" class="calibre1"/>available in the <span class="strong"><strong class="calibre9">Comprehensive R Archive Network</strong></span> (<span class="strong"><strong class="calibre9">CRAN</strong></span>) repositories. You can download it if not present using the <code class="email">install.packages('arules')</code> command. Once it is installed, we will look at a standard grocery based transactional log database and build the contingency matrices using the standard machine learning methodology that we used in the previous chapters to work on any dataset or problem.</p><p class="calibre8">First, we will start by loading the required package and the data into our workspace and looking at what the transactional data looks like:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # loading the required package</strong></span>
<span class="strong"><strong class="calibre9">&gt; library(arules)</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; # getting and loading the data</strong></span>
<span class="strong"><strong class="calibre9">&gt; data(Groceries)</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; # inspecting the first 3 transactions </strong></span>
<span class="strong"><strong class="calibre9">&gt; inspect(Groceries[1:3])</strong></span>
<span class="strong"><strong class="calibre9">  items                                                   </strong></span>
<span class="strong"><strong class="calibre9">1 {citrus fruit,semi-finished bread,margarine,ready soups}</strong></span>
<span class="strong"><strong class="calibre9">2 {tropical fruit,yogurt,coffee}                          </strong></span>
<span class="strong"><strong class="calibre9">3 {whole milk}</strong></span>
</pre></div><p class="calibre8">Each preceding transaction is a set of products which were purchased together, just as we had discussed in the previous sections. We will now build several contingency matrices on different matrices and view the top five product pairs which customers would be interested in buying together. The following code snippet shows us a count based product contingency matrix:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # count based product contingency matrix </strong></span>
<span class="strong"><strong class="calibre9">&gt; ct &lt;- crossTable(Groceries, measure="count", sort=TRUE)</strong></span>
<span class="strong"><strong class="calibre9">&gt; ct[1:5, 1:5]</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output:</strong></span></p><p class="calibre8"><span class="strong"><img src="../images/00091.jpeg" alt="Advanced contingency matrices" class="calibre16"/></span></p><p class="calibre8">Here we see a similar matrix to what we had worked with earlier. Now we will create a support based product contingency matrix:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # support based product contingency matrix </strong></span>
<span class="strong"><strong class="calibre9">&gt; ct &lt;- crossTable(Groceries, measure="support", sort=TRUE)</strong></span>
<span class="strong"><strong class="calibre9">&gt; ct[1:5, 1:5]</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output:</strong></span></p><p class="calibre8"><span class="strong"><img src="../images/00092.jpeg" alt="Advanced contingency matrices" class="calibre16"/></span></p><p class="calibre8">Finally, we look at <a id="id175" class="calibre1"/>another matrix based on the metric lift which we discussed earlier. If you remember, the higher the value of lift, if greater than 1, the stronger the chance of both products being bought together by customers.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # lift based product contingency matrix </strong></span>
<span class="strong"><strong class="calibre9">&gt; ct &lt;- crossTable(Groceries, measure="lift", sort=TRUE)</strong></span>
<span class="strong"><strong class="calibre9">&gt; ct[1:5, 1:5]</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output:</strong></span></p><p class="calibre8"><span class="strong"><img src="../images/00093.jpeg" alt="Advanced contingency matrices" class="calibre16"/></span></p><p class="calibre8">From the preceding matrix, you can get such insights as that people tend to buy yoghurt and whole milk together, or that soda and whole milk do not really go together since it has a lift value less than <code class="email">1</code>. These kinds of insights help in planning product placement in stores and shopping websites for better sales and recommendations.</p><p class="calibre8">However, some of the main issues with this model are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">High number of products leads to a huge matrix which is difficult to work with since it needs more time and space to process.</li><li class="listitem">Can detect pairs of <a id="id176" class="calibre1"/>items in frequent itemsets only for recommendations. It is possible to find out combinations of more than two items from this model but that needs additional logic related to set theory.</li><li class="listitem">Faces the cold <a id="id177" class="calibre1"/>start problem, typically known in recommender engines, which happens when a new product is launched and we cannot predict recommendations or how it will sell in the market since our historical data does not have any information associated with it.</li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Frequent itemset generation"><div class="book" id="RL0A2-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec23" class="calibre1"/>Frequent itemset generation</h1></div></div></div><p class="calibre8">We will now look at a <a id="id178" class="calibre1"/>better technique to find patterns and detect frequently bought products. For this, we will be using the frequent itemset generation technique. We will be implementing this algorithm from scratch because, even though when we solve any machine learning or optimization problem we usually use readymade machine learning algorithms out of the box which are optimized and available in various R packages, one of the main objectives of this book is to make sure we understand what exactly goes on behind the scenes of a machine learning algorithm. Thus, we will see how we can build some of these algorithms ourselves using the principles of mathematics, statistics, and logic.</p></div>

<div class="book" title="Frequent itemset generation">
<div class="book" title="Getting started"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch03lvl2sec40" class="calibre1"/>Getting started</h2></div></div></div><p class="calibre8">The data we will be using for this is the <code class="email">shopping_transaction_log.csv</code> dataset which we used to explain the concepts of market basket analysis at the beginning of the chapter. The code we will be using for this section is available in the <code class="email">ch3_frequent</code> itemset <code class="email">generation.R</code> file. We will first go through all the functions and then define the main function which utilizes all the helper functions to define a workflow for frequent itemset generation.</p><p class="calibre8">We will start by loading <a id="id179" class="calibre1"/>some library dependencies and utility functions:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">## load library dependencies </strong></span>
<span class="strong"><strong class="calibre9">library(dplyr)  # manipulating data frames</strong></span>
<span class="strong"><strong class="calibre9">library(gridExtra)  # output clean formatted tables</strong></span>

<span class="strong"><strong class="calibre9">## Utility function: Appends vectors to a list</strong></span>
<span class="strong"><strong class="calibre9">list.append &lt;- function (mylist, ...){</strong></span>
<span class="strong"><strong class="calibre9">  mylist &lt;- c(mylist, list(...))</strong></span>
<span class="strong"><strong class="calibre9">  return(mylist)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div></div></div>

<div class="book" title="Frequent itemset generation">
<div class="book" title="Data retrieval and transformation"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch03lvl2sec41" class="calibre1"/>Data retrieval and transformation</h2></div></div></div><p class="calibre8">Next, we will <a id="id180" class="calibre1"/>define the functions for getting the data and transforming it into the required format of a data frame consisting of products and purchase frequency. We also have a function to prune this data frame if we want to remove products below a certain purchase frequency threshold.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">## Step 1: Function to read the dataset into memory from file</strong></span>
<span class="strong"><strong class="calibre9">get_transaction_dataset &lt;- function(filename){</strong></span>
<span class="strong"><strong class="calibre9">  df &lt;- read.csv(filename, header = FALSE)</strong></span>
<span class="strong"><strong class="calibre9">  dataset &lt;- list()</strong></span>
<span class="strong"><strong class="calibre9">  for (index in seq(nrow(df))){</strong></span>
<span class="strong"><strong class="calibre9">    transaction.set &lt;- as.vector(unlist(df[index,]))</strong></span>
<span class="strong"><strong class="calibre9">    transaction.set &lt;- transaction.set[transaction.set != ""]</strong></span>
<span class="strong"><strong class="calibre9">    dataset &lt;- list.append(dataset, transaction.set)</strong></span>
<span class="strong"><strong class="calibre9">  }</strong></span>
<span class="strong"><strong class="calibre9">  return(dataset)</strong></span>
<span class="strong"><strong class="calibre9">}  </strong></span>

<span class="strong"><strong class="calibre9">## Step 2: Function to convert dataset into a data frame</strong></span>
<span class="strong"><strong class="calibre9">get_item_freq_table &lt;- function(dataset){</strong></span>
<span class="strong"><strong class="calibre9">  item.freq.table &lt;- unlist(dataset) %&gt;% table %&gt;% data.frame</strong></span>
<span class="strong"><strong class="calibre9">  return (item.freq.table)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>

<span class="strong"><strong class="calibre9">## Step 3: Function to prune items based on minimum frequency</strong></span>
<span class="strong"><strong class="calibre9">##         as specified by the user.</strong></span>
<span class="strong"><strong class="calibre9">##         Here min freq &lt;- item.min.freq</strong></span>
<span class="strong"><strong class="calibre9">prune_item_freq_table &lt;- function(item.freq.table, item.min.freq){</strong></span>
<span class="strong"><strong class="calibre9">  pruned.item.table &lt;- item.freq.table[item.freq.table$Freq &gt;= </strong></span>
<span class="strong"><strong class="calibre9">                                       item.min.freq,]</strong></span>
<span class="strong"><strong class="calibre9">  return (pruned.item.table)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div></div></div>

<div class="book" title="Frequent itemset generation">
<div class="book" title="Building an itemset association matrix"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch03lvl2sec42" class="calibre1"/>Building an itemset association matrix</h2></div></div></div><p class="calibre8">Now, we <a id="id181" class="calibre1"/>will implement three functions to help us build the itemset association matrix. We start with building the first function, which returns us different unique itemset combinations from the list of items in our transactional dataset based on the number of items in each itemset passed as a parameter. This helps us in getting itemsets of a particular count.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">## Step 4: Function to get possible itemset combinations where </strong></span>
<span class="strong"><strong class="calibre9">##         each itemset has n number of items where n is specified ##         by the user. Here n &lt;- num.items </strong></span>
<span class="strong"><strong class="calibre9">get_associated_itemset_combinations &lt;- function(pruned.item.table, </strong></span>
<span class="strong"><strong class="calibre9">                                                num.items){</strong></span>
<span class="strong"><strong class="calibre9">  itemset.associations &lt;- c()</strong></span>
<span class="strong"><strong class="calibre9">  itemset.association.matrix &lt;- combn(pruned.item.table$., </strong></span>
<span class="strong"><strong class="calibre9">                                      num.items)</strong></span>
<span class="strong"><strong class="calibre9">  for (index in seq(ncol(itemset.association.matrix))){</strong></span>
<span class="strong"><strong class="calibre9">    itemset.associations &lt;- c(itemset.associations,</strong></span>
<span class="strong"><strong class="calibre9">                        paste(itemset.association.matrix[,index],</strong></span>
<span class="strong"><strong class="calibre9">                                    collapse = ", ")</strong></span>
<span class="strong"><strong class="calibre9">                            )</strong></span>
<span class="strong"><strong class="calibre9">  }</strong></span>
<span class="strong"><strong class="calibre9">  itemset.associations &lt;- unique(itemset.associations)</strong></span>
<span class="strong"><strong class="calibre9">  return (itemset.associations)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">The following function builds a frequency contingency table showing the occurrence of each itemset in each transaction from the dataset. This forms the basis of getting the data for building our frequent itemsets. The itemset association matrix shows on a high level the occurrence of the different unique itemsets generated in the previous function per transaction in our dataset.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">## Step 5: Function to build an itemset association matrix where ##         we see a contingency table showing itemset association </strong></span>
<span class="strong"><strong class="calibre9">##         occurrence in each transaction of the dataset</strong></span>
<span class="strong"><strong class="calibre9">build_itemset_association_matrix &lt;- function(dataset,   </strong></span>
<span class="strong"><strong class="calibre9">                                      itemset.association.labels,</strong></span>
<span class="strong"><strong class="calibre9">                                      itemset.combination.nums){  </strong></span>
<span class="strong"><strong class="calibre9">  itemset.transaction.labels &lt;- sapply(dataset, paste, </strong></span>
<span class="strong"><strong class="calibre9">                                       collapse=", ")</strong></span>
<span class="strong"><strong class="calibre9">  itemset.associations &lt;- lapply(itemset.association.labels, </strong></span>
<span class="strong"><strong class="calibre9">                              function(itemset){</strong></span>
<span class="strong"><strong class="calibre9">                                unlist(strsplit(itemset, ", ", </strong></span>
<span class="strong"><strong class="calibre9">                                                fixed = TRUE)</strong></span>
<span class="strong"><strong class="calibre9">                                       )</strong></span>
<span class="strong"><strong class="calibre9">                              }</strong></span>
<span class="strong"><strong class="calibre9">                          )</strong></span>
<span class="strong"><strong class="calibre9">  # building the itemset association matrix</strong></span>
<span class="strong"><strong class="calibre9">  association.vector &lt;- c()</strong></span>
<span class="strong"><strong class="calibre9">  for (itemset.association in itemset.associations){</strong></span>
<span class="strong"><strong class="calibre9">    association.vector &lt;- c(association.vector,</strong></span>
<span class="strong"><strong class="calibre9">           unlist(</strong></span>
<span class="strong"><strong class="calibre9">             lapply(dataset, </strong></span>
<span class="strong"><strong class="calibre9">                    function(dataitem,  </strong></span>
<span class="strong"><strong class="calibre9">                             num.items=itemset.combination.nums){ </strong></span>
<span class="strong"><strong class="calibre9">                      m &lt;- match(dataitem, itemset.association)</strong></span>
<span class="strong"><strong class="calibre9">                      m &lt;- length(m[!is.na(m)])</strong></span>
<span class="strong"><strong class="calibre9">                      if (m == num.items){</strong></span>
<span class="strong"><strong class="calibre9">                        1</strong></span>
<span class="strong"><strong class="calibre9">                      }else{</strong></span>
<span class="strong"><strong class="calibre9">                        NA</strong></span>
<span class="strong"><strong class="calibre9">                      }</strong></span>
<span class="strong"><strong class="calibre9">                    }</strong></span>
<span class="strong"><strong class="calibre9">             )</strong></span>
<span class="strong"><strong class="calibre9">           )</strong></span>
<span class="strong"><strong class="calibre9">    )</strong></span>
<span class="strong"><strong class="calibre9">  }</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  itemset.association.matrix &lt;- matrix(association.vector, </strong></span>
<span class="strong"><strong class="calibre9">                                       nrow = length(dataset))</strong></span>
<span class="strong"><strong class="calibre9">  itemset.association.labels &lt;- sapply(itemset.association.labels, </strong></span>
<span class="strong"><strong class="calibre9">                                       function(item) {</strong></span>
<span class="strong"><strong class="calibre9">                                         paste0('{', paste(item, </strong></span>
<span class="strong"><strong class="calibre9">                                           collapse = ', '), '}')</strong></span>
<span class="strong"><strong class="calibre9">                                       }</strong></span>
<span class="strong"><strong class="calibre9">                                )  </strong></span>

<span class="strong"><strong class="calibre9">  itemset.transaction.labels &lt;- sapply(dataset, </strong></span>
<span class="strong"><strong class="calibre9">                                    function(itemset){</strong></span>
<span class="strong"><strong class="calibre9">                                      paste0('{', paste(itemset, </strong></span>
<span class="strong"><strong class="calibre9">                                          collapse = ', '), '}')</strong></span>
<span class="strong"><strong class="calibre9">                                    }</strong></span>
<span class="strong"><strong class="calibre9">                                )</strong></span>
<span class="strong"><strong class="calibre9">  colnames(itemset.association.matrix) &lt;- itemset.association.labels</strong></span>
<span class="strong"><strong class="calibre9">  rownames(itemset.association.matrix) &lt;- itemset.transaction.labels</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  return (itemset.association.matrix)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">Once we have the itemset association matrix, we use it in the following function, to sum up these <a id="id182" class="calibre1"/>individual itemset occurrences to get the total occurrence of each itemset in the whole dataset:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">## Step 6: Function to generate total occurrences of each itemset </strong></span>
<span class="strong"><strong class="calibre9">##         in the transactional dataset based on data from the </strong></span>
<span class="strong"><strong class="calibre9">##         association matrix</strong></span>
<span class="strong"><strong class="calibre9">get_frequent_itemset_details &lt;- function(itemset.association.matrix){</strong></span>
<span class="strong"><strong class="calibre9">  frequent.itemsets.table &lt;- apply(itemset.association.matrix, </strong></span>
<span class="strong"><strong class="calibre9">                                   2, sum, na.rm=TRUE)</strong></span>
<span class="strong"><strong class="calibre9">  return (frequent.itemsets.table)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div></div></div>

<div class="book" title="Frequent itemset generation">
<div class="book" title="Creating a frequent itemsets generation workflow"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch03lvl2sec43" class="calibre1"/>Creating a frequent itemsets generation workflow</h2></div></div></div><p class="calibre8">Finally, we will <a id="id183" class="calibre1"/>define the function which will utilize all the previous functions to create a workflow for generating the frequent itemsets. The main parameters we will be taking here include <code class="email">data.file.path</code> which contains the location of the dataset, <code class="email">itemset.combination.nums</code> which denotes the number of items which should be in each itemset, <code class="email">item.min.freq</code> which denotes the minimum purchase count threshold of each item, and <code class="email">minsup</code> which tells us the minimum support for the generated frequent itemsets.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">## Step 7: Function containing entire workflow to generate </strong></span>
<span class="strong"><strong class="calibre9">##         frequent itemsets</strong></span>
<span class="strong"><strong class="calibre9">frequent.itemsets.generator &lt;- function(data.file.path, </strong></span>
<span class="strong"><strong class="calibre9">                                     itemset.combination.nums=2, </strong></span>
<span class="strong"><strong class="calibre9">                                     item.min.freq=2, minsup=0.2){</strong></span>
<span class="strong"><strong class="calibre9">  # get the dataset</strong></span>
<span class="strong"><strong class="calibre9">  dataset &lt;- get_transaction_dataset(data.file.path)</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  # convert data into item frequency table</strong></span>
<span class="strong"><strong class="calibre9">  item.freq.table &lt;- get_item_freq_table(dataset)</strong></span>
<span class="strong"><strong class="calibre9">  pruned.item.table &lt;- prune_item_freq_table(item.freq.table, </strong></span>
<span class="strong"><strong class="calibre9">                                             item.min.freq)</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  # get itemset associations</strong></span>
<span class="strong"><strong class="calibre9">  itemset.association.labels &lt;- get_associated_itemset_combinations(pruned.item.table,</strong></span>
<span class="strong"><strong class="calibre9">                                   itemset.combination.nums)</strong></span>
<span class="strong"><strong class="calibre9">  itemset.association.matrix &lt;- build_itemset_association_matrix(dataset, </strong></span>
<span class="strong"><strong class="calibre9">                                itemset.association.labels, </strong></span>
<span class="strong"><strong class="calibre9">                                itemset.combination.nums)</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  # generate frequent itemsets</strong></span>
<span class="strong"><strong class="calibre9">  frequent.itemsets.table &lt;- get_frequent_itemset_details(itemset.association.matrix)</strong></span>
<span class="strong"><strong class="calibre9">  frequent.itemsets.table &lt;- sort(frequent.itemsets.table[frequent.itemsets.table &gt; 0], </strong></span>
<span class="strong"><strong class="calibre9">                                  decreasing = TRUE)</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  frequent.itemsets.names &lt;- names(frequent.itemsets.table)</strong></span>
<span class="strong"><strong class="calibre9">  frequent.itemsets.frequencies &lt;- as.vector(frequent.itemsets.table)</strong></span>
<span class="strong"><strong class="calibre9">  frequent.itemsets.support &lt;- round((frequent.itemsets.frequencies * 100) / length(dataset), </strong></span>
<span class="strong"><strong class="calibre9">                                     digits=2)</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  frequent.itemsets &lt;- data.frame(Itemset=frequent.itemsets.names,</strong></span>
<span class="strong"><strong class="calibre9">                          Frequency=frequent.itemsets.frequencies,</strong></span>
<span class="strong"><strong class="calibre9">                          Support=frequent.itemsets.support)</strong></span>
<span class="strong"><strong class="calibre9">  # apply minimum support cutoff to get frequent itemsets</strong></span>
<span class="strong"><strong class="calibre9">  minsup.percentage &lt;- minsup * 100</strong></span>
<span class="strong"><strong class="calibre9">  frequent.itemsets &lt;- subset(frequent.itemsets,    </strong></span>
<span class="strong"><strong class="calibre9">  frequent.itemsets['Support'] &gt;= minsup.percentage)</strong></span>
<span class="strong"><strong class="calibre9">  frequent.itemsets.support &lt;- sapply(frequent.itemsets.support,</strong></span>
<span class="strong"><strong class="calibre9">                                      function(value){</strong></span>
<span class="strong"><strong class="calibre9">                                        paste0(value,'%')</strong></span>
<span class="strong"><strong class="calibre9">                                      }</strong></span>
<span class="strong"><strong class="calibre9">                               )</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  # printing to console</strong></span>
<span class="strong"><strong class="calibre9">  cat("\nItem Association Matrix\n")</strong></span>
<span class="strong"><strong class="calibre9">  print(itemset.association.matrix)</strong></span>
<span class="strong"><strong class="calibre9">  cat("\n\n")</strong></span>
<span class="strong"><strong class="calibre9">  cat("\nValid Frequent Itemsets with Frequency and Support\n")</strong></span>
<span class="strong"><strong class="calibre9">  print(frequent.itemsets)</strong></span>
<span class="strong"><strong class="calibre9">  </strong></span>
<span class="strong"><strong class="calibre9">  # displaying frequent itemsets as a pretty table</strong></span>
<span class="strong"><strong class="calibre9">  if (names(dev.cur()) != "null device"){</strong></span>
<span class="strong"><strong class="calibre9">    dev.off()</strong></span>
<span class="strong"><strong class="calibre9">  }</strong></span>
<span class="strong"><strong class="calibre9">  grid.table(frequent.itemsets)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div></div></div>

<div class="book" title="Frequent itemset generation">
<div class="book" title="Detecting shopping trends"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_5"><a id="ch03lvl2sec44" class="calibre1"/>Detecting shopping trends</h2></div></div></div><p class="calibre8">Now it's <a id="id184" class="calibre1"/>time to test our algorithm! We will first generate all the frequent itemsets that have two items where each item has been purchased at least three times in the overall dataset and have a minimum support of at least 20%. To do this, you will have to fire up the following function in the R console. Do remember to load all the previous functions in memory first.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; frequent.itemsets.generator(</strong></span>
<span class="strong"><strong class="calibre9">         data.file.path='shopping_transaction_log.csv',    </strong></span>
<span class="strong"><strong class="calibre9">         itemset.combination.nums=2, item.min.freq=3, minsup=0.2)</strong></span>
</pre></div><p class="calibre8">We get the following itemset contingency matrix, which is used to generate the frequent itemsets. The left side rows indicate the transactions and each column represents an itemset.</p><div class="mediaobject"><img src="../images/00094.jpeg" alt="Detecting shopping trends" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">The final frequent itemsets will be shown both in the console and in the plot section in the form of a pretty table, as follows:</p><div class="mediaobject"><img src="../images/00095.jpeg" alt="Detecting shopping trends" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Thus, you can clearly see that the itemset <code class="email">{beer, diapers}</code> is our most frequent itemset with a support of approximately <code class="email">67%</code>, which has occurred six times in total in our dataset, and the association matrix shows you the exact transactions where it has occurred. Thus, this function detects a trend of people buying beer and diapers or diapers and milk more frequently, and thus we can recommend people the same when they are shopping. We will also take a look at the frequent itemsets containing three items next:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; frequent.itemsets.generator(</strong></span>
<span class="strong"><strong class="calibre9">         data.file.path='shopping_transaction_log.csv',</strong></span>
<span class="strong"><strong class="calibre9">         itemset.combination.nums=3, item.min.freq=1, minsup=0.2)</strong></span>
</pre></div><p class="calibre8">This gives us the following table showing the frequent itemsets with their necessary statistics:</p><div class="mediaobject"><img src="../images/00096.jpeg" alt="Detecting shopping trends" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">Thus we see that we get two frequent itemsets with support greater than 20%. Of course remember that this is a small dataset and the bigger the dataset you have containing purchase transactions, the more patterns you will get with stronger support.</p><p class="calibre8">We have successfully built an algorithm for generating frequent itemsets! You can use this same algorithm on new datasets to generate more and more frequent itemsets and then we can start recommending products for people to purchase as soon as we see them buying one or more items from any of the frequent itemsets. A simple example would be if we see people buying beer, we can recommend diapers and milk to them since that shopping <a id="id185" class="calibre1"/>trend was detected by our algorithm in the frequent itemsets earlier.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Association rule mining"><div class="book" id="SJGS2-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec24" class="calibre1"/>Association rule mining</h1></div></div></div><p class="calibre8">We will now be implementing the final technique in market basket analysis for finding out association rules between itemsets to detect and predict product purchase patterns which can be used for product recommendations and suggestions. We will be notably using the Apriori algorithm from the <code class="email">arules</code> package which uses an implementation for generating frequent <a id="id186" class="calibre1"/>itemsets first, which we discussed earlier. Once it has the frequent itemsets, the algorithm generates necessary rules based on parameters such as support, confidence, and lift. We will also show how you can visualize and <a id="id187" class="calibre1"/>interact with these rules using the <code class="email">arulesViz</code> package. The code for this implementation is in the <code class="email">ch3_association</code> rule <code class="email">mining.R</code> file which you can directly load and follow the book.</p></div>

<div class="book" title="Association rule mining">
<div class="book" title="Loading dependencies and data"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch03lvl2sec45" class="calibre1"/>Loading dependencies and data</h2></div></div></div><p class="calibre8">We will first load the <a id="id188" class="calibre1"/>necessary package and data dependencies. Do note that we will be using the <code class="email">Groceries</code> dataset which we discussed earlier in the section dealing with advanced contingency matrices.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; ## loading package dependencies</strong></span>
<span class="strong"><strong class="calibre9">&gt; library(arules) # apriori algorithm</strong></span>
<span class="strong"><strong class="calibre9">&gt; library(arulesViz)  # visualize association rules</strong></span>
<span class="strong"><strong class="calibre9">&gt; </strong></span>
<span class="strong"><strong class="calibre9">&gt; ## loading dataset</strong></span>
<span class="strong"><strong class="calibre9">&gt; data(Groceries)</strong></span>
</pre></div></div></div>

<div class="book" title="Association rule mining">
<div class="book" title="Exploratory analysis"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch03lvl2sec46" class="calibre1"/>Exploratory analysis</h2></div></div></div><p class="calibre8">We will do some <a id="id189" class="calibre1"/>basic exploratory analysis on our dataset here, to see what kind of data we are dealing with and what products are the most popular among the customers.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; ## exploring the data</strong></span>
<span class="strong"><strong class="calibre9">&gt; inspect(Groceries[1:3])</strong></span>
<span class="strong"><strong class="calibre9">  items                                                   </strong></span>
<span class="strong"><strong class="calibre9">1 {citrus fruit,semi-finished bread,margarine,ready soups}</strong></span>
<span class="strong"><strong class="calibre9">2 {tropical fruit,yogurt,coffee}                          </strong></span>
<span class="strong"><strong class="calibre9">3 {whole milk}        </strong></span>
<span class="strong"><strong class="calibre9">&gt; # viewing the top ten purchased products                                    </strong></span>
<span class="strong"><strong class="calibre9">&gt; sort(itemFrequency(Groceries, type="absolute"), </strong></span>
<span class="strong"><strong class="calibre9">+                    decreasing = TRUE)[1:10]</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output:</strong></span></p><p class="calibre8"><span class="strong"><img src="../images/00097.jpeg" alt="Exploratory analysis" class="calibre16"/></span></p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # visualizing the top ten purchased products</strong></span>
<span class="strong"><strong class="calibre9">&gt; itemFrequencyPlot(Groceries,topN=10,type="absolute")</strong></span>
</pre></div><p class="calibre8">The preceding code snippet renders the following bar plot, which tells us the top ten most purchased products, which gives us a preliminary idea of what the customers buy the most when they purchase grocery items. It looks like people usually buy essential items such as milk and <a id="id190" class="calibre1"/>vegetables the most!</p><div class="mediaobject"><img src="../images/00098.jpeg" alt="Exploratory analysis" class="calibre11"/></div><p class="calibre12"> </p></div></div>

<div class="book" title="Association rule mining">
<div class="book" title="Detecting and predicting shopping trends"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch03lvl2sec47" class="calibre1"/>Detecting and predicting shopping trends</h2></div></div></div><p class="calibre8">We will be <a id="id191" class="calibre1"/>generating association rules <a id="id192" class="calibre1"/>now using the Apriori algorithm, which we talked about earlier, to detect shopping trends so that we can predict what customers might buy in the future and even recommend it to them. We will start off with a normal workflow for generating association rules:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # normal workflow</strong></span>
<span class="strong"><strong class="calibre9">&gt; metric.params &lt;- list(supp=0.001, conf=0.5)</strong></span>
<span class="strong"><strong class="calibre9">&gt; rules &lt;- apriori(Groceries, parameter = metric.params)</strong></span>
<span class="strong"><strong class="calibre9">&gt; inspect(rules[1:5])</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output:</strong></span></p><p class="calibre8"><span class="strong"><img src="../images/00099.jpeg" alt="Detecting and predicting shopping trends" class="calibre16"/></span></p><p class="calibre8">The way to interpret these rules is that you observe the items on the LHS and the items on the RHS, and conclude that if a customer has the item(s) from the LHS in his shopping cart, there is a chance of him also buying the item(s) on the RHS. This chance can be quantified using the metrics which are present in the remaining columns. We have discussed the significance of these metrics in the concepts of market basket analysis. From the previous rules, we can say that there is a 73.3% confidence that if a customer buys honey, he will also buy whole milk. From the previous rules, we see a trend that items such as honey, cocoa, pudding, and cooking chocolate all need milk as an essential ingredient, which might explain why people tend to buy that together with these products and we can recommend that to the customers. Feel free to tune the parameters for lift, support, and confidence to extract more rules from the dataset to get more and more patterns!</p><p class="calibre8">Often the rules <a id="id193" class="calibre1"/>generated by the Apriori algorithm have duplicate association rules which need to be removed before we examine the set of rules. You can do the same using the following utility function on the generated rules:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># pruning duplicate rules</strong></span>
<span class="strong"><strong class="calibre9">prune.dup.rules &lt;- function(rules){</strong></span>
<span class="strong"><strong class="calibre9">  rule.subset.matrix &lt;- is.subset(rules, rules)</strong></span>
<span class="strong"><strong class="calibre9">  rule.subset.matrix[lower.tri(rule.subset.matrix, diag=T)] &lt;- NA</strong></span>
<span class="strong"><strong class="calibre9">  dup.rules &lt;- colSums(rule.subset.matrix, na.rm=T) &gt;= 1</strong></span>
<span class="strong"><strong class="calibre9">  pruned.rules &lt;- rules[!dup.rules]</strong></span>
<span class="strong"><strong class="calibre9">  return(pruned.rules)</strong></span>
<span class="strong"><strong class="calibre9">}</strong></span>
</pre></div><p class="calibre8">There are also ways to sort rules by specific metrics to see the rules with the best quality. We will look at the best rules using the previous metric parameter values sorted by the best confidence values.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># sorting rules based on metrics</strong></span>
<span class="strong"><strong class="calibre9">rules &lt;- sort(rules, by="confidence", decreasing=TRUE)</strong></span>
<span class="strong"><strong class="calibre9">rules &lt;- prune.dup.rules(rules)</strong></span>
<span class="strong"><strong class="calibre9">inspect(rules[1:5])</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output:</strong></span></p><p class="calibre8"><span class="strong"><img src="../images/00100.jpeg" alt="Detecting and predicting shopping trends" class="calibre16"/></span></p><p class="calibre8">We see itemsets in the previous rules like <code class="email">{ rice, sugar }</code>, which have a strong tendency to be purchased along with <code class="email">{ whole milk }</code>. The confidence values are pretty high (and they should be since we sorted them!) of 100% and the lift is also greater than 1, indicating a positive association between the itemsets. Do note that in large datasets, the support values may not be very high and that is perfectly normal because we are searching some specific patterns in the whole transaction dataset which may not even cover 1% of the total transactions present due to the varied type of transactions. However, it is extremely <a id="id194" class="calibre1"/>important for us to detect these <a id="id195" class="calibre1"/>patterns to make informed decisions about predicting what products might get sold together and recommending them to the customers. We will next look at another example of showing the best quality rules sorted by lift:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; rules&lt;-sort(rules, by="lift", decreasing=TRUE)</strong></span>
<span class="strong"><strong class="calibre9">&gt; rules &lt;- prune.dup.rules(rules)</strong></span>
<span class="strong"><strong class="calibre9">&gt; inspect(rules[1:5])</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output:</strong></span></p><p class="calibre8"><span class="strong"><img src="../images/00101.jpeg" alt="Detecting and predicting shopping trends" class="calibre16"/></span></p><p class="calibre8">We see that these rules have really high lift and good confidence too making them items which customers would tend to buy together the most!</p><p class="calibre8">We will now look at detecting specific shopping patterns which we discussed earlier. One way to do this is to target specific items and generate association rules containing those items explicitly. The first way is to predict what items the customers might have in their shopping cart if they have bought an item on the RHS of association rules. We do this by specifying the item explicitly as shown next and analyze the transactional dataset:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; # finding itemsets which lead to buying of an item on RHS</strong></span>
<span class="strong"><strong class="calibre9">&gt; metric.params &lt;- list(supp=0.001,conf=0.5, minlen=2)</strong></span>
<span class="strong"><strong class="calibre9">&gt; rules&lt;-apriori(data=Groceries, parameter=metric.params, </strong></span>
<span class="strong"><strong class="calibre9">+                appearance = list(default="lhs",rhs="soda"),</strong></span>
<span class="strong"><strong class="calibre9">+                control = list(verbose=F))</strong></span>
<span class="strong"><strong class="calibre9">&gt; rules &lt;- prune.dup.rules(rules)</strong></span>
<span class="strong"><strong class="calibre9">&gt; rules&lt;-sort(rules, decreasing=TRUE, by="confidence")</strong></span>
<span class="strong"><strong class="calibre9">&gt; inspect(rules[1:5])</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output:</strong></span></p><p class="calibre8"><span class="strong"><img src="../images/00102.jpeg" alt="Detecting and predicting shopping trends" class="calibre16"/></span></p><p class="calibre8">It is interesting to note that people tend to buy beverages together, such as coffee, water, beer, and other miscellaneous beverages along with soda from the previous rules. Thus you can see that it is quite easy to predict when the users might buy soda using these rules and take action accordingly.</p><p class="calibre8">We can also predict what items the users are going to buy if they have already put some specific items in their shopping cart, by explicitly setting specific itemset values on the LHS of the association <a id="id196" class="calibre1"/>rules using the following <a id="id197" class="calibre1"/>technique:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9"># finding items which are bought when we have an itemset on LHS</strong></span>
<span class="strong"><strong class="calibre9">metric.params &lt;- list(supp=0.001, conf = 0.3, minlen=2)</strong></span>
<span class="strong"><strong class="calibre9">rules&lt;-apriori(data=Groceries, parameter=metric.params, </strong></span>
<span class="strong"><strong class="calibre9">               appearance = list(default="rhs",</strong></span>
<span class="strong"><strong class="calibre9">                                 lhs=c("yogurt", "sugar")),</strong></span>
<span class="strong"><strong class="calibre9">               control=list(verbose=F))</strong></span>
<span class="strong"><strong class="calibre9">#rules &lt;- prune.dup.rules(rules)</strong></span>
<span class="strong"><strong class="calibre9">rules&lt;-sort(rules, decreasing=TRUE,by="confidence")</strong></span>
<span class="strong"><strong class="calibre9">inspect(rules[1:5])</strong></span>
</pre></div><p class="calibre8"><span class="strong"><strong class="calibre9">Output:</strong></span></p><p class="calibre8"><span class="strong"><img src="../images/00103.jpeg" alt="Detecting and predicting shopping trends" class="calibre16"/></span></p><p class="calibre8">You can clearly see from the previous rules that people tend to buy milk if they have yogurt and sugar in their shopping cart together or individually. Thus, by targeting specific itemsets, you can offer specific product based recommendations to the customers.</p></div></div>

<div class="book" title="Association rule mining">
<div class="book" title="Visualizing association rules"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch03lvl2sec48" class="calibre1"/>Visualizing association rules</h2></div></div></div><p class="calibre8">There is an <a id="id198" class="calibre1"/>excellent package, <code class="email">arulesViz</code> which provides an interactive way to visualize the association rules and interact with them. Following is a sample visualization for the preceding association rules:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre9">&gt; ## visualizing rules</strong></span>
<span class="strong"><strong class="calibre9">&gt; plot(rules, method="graph", interactive=TRUE, shading=TRUE)</strong></span>
</pre></div><p class="calibre8">The preceding code snippet generates the following visualization which aids us in understanding the association rules even better. We have kept the itemsets on the LHS on the left-side of the visualization indicated by the vertices yogurt and sugar. We can see items on the RHS which have a probability to be bought if we buy any of the items on the LHS or both together. For example, people tend to buy whole milk if they have yogurt as well as sugar in their shopping cart, or either one of them.</p><div class="mediaobject"><img src="../images/00104.jpeg" alt="Visualizing association rules" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre8">This visualization generated by <code class="email">arulesViz</code> is completely interactive and you can play around with the vertices and edges, and place the itemsets according to your desire to find more and more trends and patterns from various rules.</p><p class="calibre8">This concludes our discussion on the main techniques which are being used in market basket analysis to <a id="id199" class="calibre1"/>detect and predict trends from shopping transaction logs and take actions accordingly from the derived insights.</p></div></div>
<div class="book" title="Summary" id="TI1E1-973e731d75c2419489ee73e3a0cf4be8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec25" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">In this chapter, we covered a lot of ground! We started with a discussion about how trends are detected and predicted in the retail vertical. Then we dived into what market basket analysis really means and the core concepts, mathematical formulae underlying the algorithms, and the critical metrics which are used to evaluate the results obtained from the algorithms, notably, support, confidence, and lift. We also discussed the most popular techniques used for analysis, including contingency matrix evaluation, frequent itemset generation, and association rule mining. Next, we talked about how to make data driven decisions using market basket analysis. Finally, we implemented our own algorithms and also used some of the popular libraries in R, such as <code class="email">arules</code>, to apply these techniques to some real world transactional data for detecting, predicting, and visualizing trends. Do note that these machine learning techniques only talk about product based recommendations purely based on purchase and transactional logs. The human element is missing here since we don't take into account the likes and dislikes based on user purchase or ratings.</p><p class="calibre8">In the next chapter, we will be tackling some of these very problems and building robust recommendation engines for recommending products taking into account products as well as user interests.</p></div></body></html>