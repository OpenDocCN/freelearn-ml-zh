- en: Training a Smart Alarm to Recognize the Villain and His Cat
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练智能警报器识别恶棍和他的猫
- en: '"The naming of cats is a difficult matter."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “给猫取名是一件困难的事情。”
- en: – T. S. Eliot, Old Possum's Book of Practical Cats (1939)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ——T. S. 艾略特，《老猫的实用猫书》（1939年）
- en: '"Blofeld: I''ve taught you to love chickens, to love their flesh, their voice."'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: “布洛菲尔德：我教过你爱鸡，爱它们的肉，爱它们的叫声。”
- en: – On Her Majesty's Secret Service (1969)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ——《皇家密探》（1969年）
- en: Imagine that the date is January 1, 2015\. The balance of world power is shifting
    again. Lithuania is joining the eurozone. Russia, Belarus, Armenia, Kazakhstan,
    and Kyrgyzstan are forming the Eurasian Economic Union. The first edition of *OpenCV
    for Secret Agents* is going to the printers. On this day, if you saw Ernst Stavro
    Blofeld, would you recognize him?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，日期是2015年1月1日。世界力量的平衡再次发生转移。立陶宛加入欧元区。俄罗斯、白俄罗斯、亚美尼亚、哈萨克斯坦和吉尔吉斯斯坦正在组建欧亚经济联盟。《OpenCV
    for Secret Agents》的第一版即将付印。在这一天，如果你看到了恩斯特·斯塔罗·布洛菲尔德，你会认出他吗？
- en: Let me remind you that Blofeld, as the number one man in the **Special Executive
    for Counterintelligence, Terrorism, Revenge, and Extortion** (**SPECTRE**), is
    a super-villain who eludes James Bond countless times before being written out
    of the movies due to an intellectual property dispute. Blofeld last appears as
    an anonymous character in the intro sequence of *For Your Eyes Only* (1981), where
    we see him fall from a helicopter and down a factory's smokestack as he shouts,
    *Mr. Boooooooooond!*
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我提醒你，布洛菲尔德作为**特别情报、恐怖主义、复仇和勒索执行处**（**SPECTRE**）的一把手，是一个超级恶棍，在多次逃脱詹姆斯·邦德的追捕后，由于知识产权纠纷而被写出了电影。布洛菲尔德最后一次出现在1981年电影《只为你的眼睛》的预告片中，我们看到他从直升机上坠落，沿着工厂的烟囱滚下，同时他喊道：“先生，波～哦～恩德！”
- en: Despite this dramatic exit, the evidence of Blofeld's death is unclear. After
    all, Blofeld is a notoriously difficult man to recognize. His face is seldom caught
    on camera. As early as the 1960s, he was using plastic surgery to change his identity
    and to turn his henchmen into lookalikes of himself. Half a century later, we
    must ask, is Blofeld a dead man or is he just made-over, perhaps as a beautiful
    actress in a Colombian telenovela?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个戏剧性的结局，布洛菲尔德死亡的证据并不明确。毕竟，布洛菲尔德是一个众所周知难以识别的人。他的脸很少出现在镜头中。早在20世纪60年代，他就使用整形手术来改变身份，并将他的手下变成他的替身。半个世纪后，我们不得不问，布洛菲尔德是已经死去的人，还是只是经过改造，可能成为哥伦比亚肥皂剧中的美丽女演员？
- en: One thing is certain. If Blofeld is alive, he is accompanied by a blue-eyed,
    white Angora cat (preserved by a veterinary miracle or taxidermy). Patting this
    cat is Blofeld's telltale habit in every movie. His face may be different but
    his lap cat is the same. We last see the cat jumping out of Blofeld's lap just
    before the fateful helicopter ride.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一件事是肯定的。如果布洛菲尔德还活着，他会伴随着一只蓝眼睛的白色安哥拉猫（由兽医奇迹或标本保存）。抚摸这只猫是布洛菲尔德在每部电影中的标志性习惯。他的脸可能不同，但他的宠物猫是相同的。我们最后一次看到这只猫从布洛菲尔德的腿上跳出来，就在那场致命的直升机飞行之前。
- en: Some commentators have noted a resemblance between Blofeld and Dr. Evil, the
    nemesis of Austin Powers. However, by comparing the respective lap cats, we can
    prove that these two villains are not the same.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一些评论员指出，布洛菲尔德和奥斯汀·鲍尔斯的宿敌德维尔博士有相似之处。然而，通过比较各自的宠物猫，我们可以证明这两个恶棍并非同一人。
- en: The moral is that two approaches to recognition are better than one. Though
    we cannot see the man's face, we should not lose sight of his cat.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 道理是，两种识别方法比一种更好。尽管我们看不到这个人的脸，但我们不应该忽视他的猫。
- en: Of course, the suspense ended on October 26, 2015, when Blofeld made his comeback
    in *Spectre*. He and the cat looked remarkably unchanged after 34 years.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，悬念在2015年10月26日结束，布洛菲尔德在《Spectre》中复出。他和猫在34年后看起来几乎没有变化。
- en: To automate the search for villains and their cats, we are going to develop
    a desktop or Raspberry Pi application called `Angora Blue` (an innocent-sounding
    code name that alludes to the blue eyes of Blofeld's cat). `Angora Blue` will
    send us an email alert when it recognizes a specified villain or a specified cat
    with a certain level of confidence. We will also develop a GUI app called `Interactive
    Recognizer`, which will train Angora Blue's recognition model based on camera
    images and names that we provide interactively. To distinguish faces from the
    background, `Interactive Recognizer` depends on a human face detection model that
    comes with OpenCV and a cat face detection model that we are going to train using
    an original script and third-party image databases.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了自动化搜索恶棍及其猫，我们将开发一个名为“Angora Blue”的桌面或Raspberry Pi应用程序（一个听起来无辜的代号，指的是邦德反派角色布洛菲尔德的猫的蓝眼睛）。当它以一定程度的置信度识别到指定的恶棍或指定的猫时，“Angora
    Blue”会向我们发送电子邮件警报。我们还将开发一个名为“Interactive Recognizer”的GUI应用程序，该程序将根据我们提供的相机图像和名称训练Angora
    Blue的识别模型。为了从背景中区分面部，Interactive Recognizer依赖于OpenCV附带的人类面部检测模型以及我们将使用原始脚本和第三方图像数据库训练的猫脸检测模型。
- en: Perhaps you have heard that OpenCV comes with a set of pretrained cat face detectors.
    This is true! I originally developed them for this book's first edition; I contributed
    them to OpenCV, and I have maintained them with improvements. This chapter covers
    the process that I used to train the latest version of these official OpenCV cat-face
    detectors.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 也许你听说过OpenCV附带了一套预训练的猫脸检测器。这是真的！我最初是为这本书的第一版开发它们的；我将它们贡献给了OpenCV，并且我一直在对它们进行改进。本章涵盖了训练这些官方OpenCV猫脸检测器最新版本所使用的过程。
- en: This is a big chapter, but it is rewarding because you will learn a process
    that applies to detecting and recognizing any kind of animal face, and even any
    object!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个大章节，但它是有回报的，因为你将学习一个适用于检测和识别任何动物面部，甚至任何物体的过程！
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter''s project has the following software dependencies:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的项目有以下软件依赖项：
- en: '**A Python environment with the following modules**: OpenCV (including opencv_contrib),
    NumPy, SciPy, Requests, wxPython, and optionally PyInstaller'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**以下模块的Python环境**：OpenCV（包括opencv_contrib）、NumPy、SciPy、Requests、wxPython，以及可选的PyInstaller'
- en: Setup instructions are covered in [Chapter 1](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml),
    *Preparing for the Mission*. Refer to the setup instructions for any version requirements.
    Basic instructions for running Python code are covered in [Appendix C](c44b1aaa-fe12-4054-85fb-37d584f15d3b.xhtml),
    *Running with Snakes (or, First Steps with Python)*.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 设置说明在[第1章](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml)“准备任务”中介绍。请参考设置说明以了解任何版本要求。运行Python代码的基本说明在[附录C](c44b1aaa-fe12-4054-85fb-37d584f15d3b.xhtml)“使用Snakes运行（或，Python的第一步）”中介绍。
- en: The completed project for this chapter can be found in this book's GitHub repository,
    [https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition),
    in the `Chapter003` folder.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的完成项目可以在本书的GitHub仓库中找到，[https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition)，在`Chapter003`文件夹中。
- en: Understanding machine learning in general
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解机器学习的一般概念
- en: Our work throughout this chapter builds on the techniques of machine learning,
    meaning that the software makes predictions or decisions based on statistical
    models. Particularly, our approach is one of supervised learning, meaning that
    we (programmers and users) provide the software with examples of data and correct
    responses. The software creates the statistical model to extrapolate from these
    examples. The human provided examples are referred to as reference data or training
    data (or reference images or training images in the context of computer vision).
    Conversely, the software's extrapolations pertain to test data (or test images
    or scenes in the context of computer vision).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的工作建立在机器学习技术的基础上，这意味着软件基于统计模型进行预测或决策。特别是，我们的方法是一种监督学习，这意味着我们（程序员和用户）向软件提供数据示例和正确响应。软件创建统计模型以从这些示例中进行外推。人类提供的示例被称为参考数据或训练数据（或在计算机视觉的上下文中称为参考图像或训练图像）。相反，软件的外推涉及测试数据（或在计算机视觉的上下文中称为测试图像或场景）。
- en: Supervised learning is much like the flashcard pedagogy used in early childhood
    education. The teacher shows the child a series of pictures (training images)
    and says,
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习与早期儿童教育中使用的闪卡教学法非常相似。老师向孩子展示一系列图片（训练图像）并说，
- en: '"This is a cow. Moo! This is a horse. Neigh!"'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '"这是一头牛。哞！这是一匹马。哞哞！"'
- en: Then, on a field trip to a farm (a scene), the child can hopefully distinguish
    between a horse and a cow. However, I must confess that I once mistook a horse
    for a cow, and I was teased about this misclassification for many years thereafter.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在一次农场（场景）的实地考察中，孩子可以希望区分马和牛。然而，我必须承认，我曾经把一匹马误认为是牛，并且在此之后多年里，我因为这种误分类而被人取笑。
- en: Apart from supervised learning, which is widely used in problems of vision and
    semantics, there are two other broad approaches to machine learning—unsupervised
    learning and reinforcement learning. **Unsupervised learning** requires the software
    to find some structure, such as clusters, in data where no meaning or correct
    examples are assigned by a human. Analyzing biological structures, such as genomes,
    is a common problem for unsupervised learning. On the other hand, **reinforcement
    learning** requires the software to experimentally optimize a solution to some
    sequence of problems, where a human assigns the final goal but the software must
    set intermediate goals. Piloting a vehicle and playing a game are common problems
    for reinforcement learning.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在视觉和语义问题中广泛使用的监督学习之外，还有两种其他广泛的机器学习方法——无监督学习和强化学习。**无监督学习**要求软件在数据中找到某种结构，例如聚类，而人类没有分配任何意义或正确示例。分析生物结构，如基因组，是无监督学习的常见问题。另一方面，**强化学习**要求软件通过实验优化一系列问题的解决方案，其中人类分配最终目标，但软件必须设定中间目标。驾驶车辆和玩游戏是强化学习的常见问题。
- en: Besides being a computer vision library, OpenCV offers a general purpose machine
    learning module that can process any kind of data, not necessarily images. For
    more information on this module and the underlying machine learning concepts,
    see the *Machine Learning* section of the official OpenCV-Python tutorials at
    [https://docs.opencv.org/4.0.0-beta/d6/de2/tutorial_py_table_of_contents_ml.html](https://docs.opencv.org/4.0.0-beta/d6/de2/tutorial_py_table_of_contents_ml.html).
    Meanwhile, our chapter proceeds with more specialized machine learning functionality
    and concepts that OpenCV users often apply to face detection and recognition.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 除了是一个计算机视觉库之外，OpenCV还提供了一个通用的机器学习模块，可以处理任何类型的数据，而不仅仅是图像。有关此模块和底层机器学习概念的更多信息，请参阅官方OpenCV-Python教程中的*机器学习*部分，链接为[https://docs.opencv.org/4.0.0-beta/d6/de2/tutorial_py_table_of_contents_ml.html](https://docs.opencv.org/4.0.0-beta/d6/de2/tutorial_py_table_of_contents_ml.html)。同时，我们的章节将继续介绍更专业的机器学习功能和概念，这些功能和概念是OpenCV用户经常应用于人脸检测和识别的。
- en: Planning the Interactive Recognizer app
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规划交互式识别器应用
- en: 'Let''s begin this project with the middle layer, the `Interactive Recognizer`
    app, in order to see how all layers connect. Like Luxocator from the [Chapter
    2](4ec4e82a-b63d-4fc1-bf3b-47c653c25a79.xhtml), *Searching for Luxury Accommodations
    Worldwide,* project, `Interactive Recognizer` is a GUI app built with wxPython.
    Refer to the following screenshot, featuring one of my colleagues, Chief Science
    Officer Sanibel San Delphinium Andromeda, high priestess of the Numm:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从这个项目的中间层开始，即`交互式识别器`应用，以便了解所有层是如何连接的。就像第2章中提到的Luxocator项目一样，*全球寻找豪华住宿*，`交互式识别器`是一个使用wxPython构建的GUI应用。参考以下截图，展示了我的同事，首席科学官Sanibel
    San Delphinium Andromeda，Numm的祭司：
- en: '![](img/c3363886-0e67-42c2-bdcd-a2a3289e91ed.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c3363886-0e67-42c2-bdcd-a2a3289e91ed.png)'
- en: 'The app uses a face detection model, which is loaded from disk, and it maintains
    a face recognition model, which is saved to disk and later loaded back from disk.
    The user may specify the identity of any detected face, and this input is added
    to the face recognition model. A detection result is shown by outlining the face
    in the video feed, while a recognition result is shown by displaying the name
    of the face in the text below. To elaborate, we may say that the app has the following
    flow of execution:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用使用一个从磁盘加载的人脸检测模型，并维护一个保存到磁盘的人脸识别模型，稍后从磁盘重新加载。用户可以指定任何检测到的人脸的身份，并将此输入添加到人脸识别模型中。检测结果通过在视频流中勾勒人脸轮廓来显示，而识别结果则通过在下面的文本中显示人脸名称来显示。为了详细说明，我们可以说该应用具有以下执行流程：
- en: Load a face detection model from file. The role of the detection model is to
    distinguish faces from the background.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load a face recognition model from file if any such model was saved during a
    previous run of `Interactive Recognizer`. Otherwise, if there is no such model
    to load, create a new one. The role of the recognition model is to distinguish
    faces of different individuals from each other.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Capture and display a live video from a camera.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each frame of video, detect the largest face, if any. If a face is detected:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw a rectangle around the face.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Permit the user to enter the face's identity as a short string (up to four characters),
    such as `Joe` or `Puss`. When the user hits the Add to Model button, train the
    model to recognize the face as whomever the user specified (`Joe`, `Puss`, or
    another identity).
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the recognition model is trained for at least one face, display the recognizer's
    prediction for the current face—that is, display the most probable identity of
    the current face, according to the recognizer. Also, display a measure of distance
    (non-confidence) for this prediction.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the recognition model is trained for at least one face, permit the user to
    hit the Clear Model button to delete the model (including any version saved to
    file) and create a new one.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On exit, if the recognition model is trained for at least one face, save the
    model to file so that it can be loaded in subsequent runs of `Interactive Recognizer`
    and `Angora Blue`.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We could generalize by using the term object instead of face. Depending on the
    models that it loads, `Interactive Recognizer` could detect and recognize any
    kind of object, not necessarily faces.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: We use a type of detection model called a **Haar cascade** and a type of recognition
    model called **Local Binary Patterns** (**LBP**) or **Local Binary Pattern Histograms**
    (**LBPH**). Alternatively, we may use LBPH for both detection and recognition.
    As detection models, LBP cascades are faster but generally less reliable, compared
    to Haar cascades. OpenCV comes with some Haar cascade and LBP cascade files, including
    several face detection models. Command-line tools for generating such files are
    also included with OpenCV. The APIs offer high-level classes for loading and using
    Haar or LBP cascades and for loading, saving, training, and using LBPH recognition
    models. Let's look at the basic concepts of these models.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Haar cascades and LBPH
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"Cookie Monster: Hey, you know what? A round cookie with one bite out of it
    looks like a C. A round donut with one bite out of it also looks like a C! But
    it is not as good as a cookie. Oh, and the moon sometimes looks like a C! But
    you can''t eat that."'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: – "C is for Cookie," Sesame Street
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Think about cloud-watching. If you lie on the ground and look up at the clouds,
    maybe you imagine that one cloud is shaped like a mound of mashed potatoes on
    a plate. If you board an airplane and fly to this cloud, you will still see some
    resemblance between the cloud's surface and the fluffy, lumpy texture of hearty
    mashed potatoes. However, if you could slice off a piece of cloud and examine
    it under a microscope, you might see ice crystals that do not resemble the microscopic
    structure of mashed potatoes at all.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下云彩观察。如果你躺在地上，抬头看云彩，也许你会想象其中一朵云彩像盘子上的土豆泥堆。如果你乘坐飞机飞到这朵云彩上，你仍然会看到云彩表面与松软、多孔的土豆泥纹理之间的一些相似之处。然而，如果你能切下一块云彩并在显微镜下观察，你可能会看到与土豆泥的微观结构完全不相似的冰晶。
- en: 'Similarly, in an image made up of pixels, a person or a computer vision algorithm
    can see many distinctive shapes or patterns, partly depending on the level of
    magnification. During the creation of a Haar cascade, various parts of the image
    are cropped and/or scaled so that we consider only a few pixels at a time (though
    these pixels may represent any level of magnification). This sample of the image
    is called a **window**. We subtract some of the grayscale pixel values from others
    in order to measure the window''s similarity to certain common shapes where a
    dark region meets a light region. Examples include an edge, a corner, or a thin
    line, as shown in the following diagram. If a window has a high similarity to
    one of these archetypes, it may be selected as a **feature**. We expect to find
    similar features at similar positions and magnifications relative to each other,
    across all images of the same subject:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在由像素组成的图像中，人或计算机视觉算法可以看到许多独特的形状或模式，这部分取决于放大倍数。在创建Haar级联的过程中，图像的各个部分会被裁剪和/或缩放，以便我们一次只考虑几个像素（尽管这些像素可能代表任何放大倍数）。这个图像样本被称为**窗口**。我们通过从其他像素中减去一些灰度像素值来测量窗口与某些常见形状的相似度，其中暗区域与亮区域相交。例如，包括边缘、角或细线，如下面的图所示。如果一个窗口与这些原型之一有很高的相似度，它可能被选为**特征**。我们期望在所有相同主题的图像中，相似特征在相对位置和放大倍数上都是相似的：
- en: '![](img/7751bc20-2862-456c-a467-0e2a24720d46.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7751bc20-2862-456c-a467-0e2a24720d46.png)'
- en: Not all features are equally significant. Across a set of images, we can see
    whether a feature is truly typical of images that include our subject (the **positive
    training set**) and atypical of images that exclude our subject (the **negative
    training set**). We give features a different rank or **stage** depending on how
    well they distinguish subjects from non-subjects. Together, a set of stages form
    a **cascade** or a series of comparison criteria. Every stage must be passed in
    order to reach a positive detection result. Conversely, a negative detection result
    can be reached in fewer stages, perhaps only a single stage (an important optimization).
    Like the training images, scenes are examined through various windows, and we
    may end up detecting multiple subjects in one scene.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有特征都具有同等的重要性。在一系列图像中，我们可以看到某个特征是否真正是包含我们的主题（**正训练集**）的图像的典型特征，以及是否是不包含我们的主题（**负训练集**）的图像的不典型特征。我们根据特征区分主题和非主题的能力给予它们不同的排名或**阶段**。一组阶段共同构成一个**级联**或一系列比较标准。每个阶段都必须通过才能达到阳性检测结果。相反，可以通过更少的阶段达到阴性检测结果，可能只有一个阶段（一个重要的优化）。像训练图像一样，场景通过各种窗口进行检查，我们最终可能在单个场景中检测到多个主题。
- en: For more information about Haar cascades in OpenCV, see the official documentation
    at [https://docs.opencv.org/4.0.0-beta/d7/d8b/tutorial_py_face_detection.html](https://docs.opencv.org/4.0.0-beta/d7/d8b/tutorial_py_face_detection.html).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 关于OpenCV中的Haar级联，请参阅官方文档[https://docs.opencv.org/4.0.0-beta/d7/d8b/tutorial_py_face_detection.html](https://docs.opencv.org/4.0.0-beta/d7/d8b/tutorial_py_face_detection.html)获取更多信息。
- en: 'An LBPH model, as the name suggests, is based on a kind of histogram. For each
    pixel in a window, we note whether each neighboring pixel in a certain radius
    is brighter or darker. Our histogram counts the darker pixels in each neighboring
    position. For example, suppose a window contains the following two neighborhoods
    of a one-pixel radius:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，LBPH模型基于一种直方图。对于窗口中的每个像素，我们记录在特定半径内的每个相邻像素是更亮还是更暗。我们的直方图计算每个相邻位置中的暗像素数量。例如，假设一个窗口包含以下两个半径为1像素的邻域：
- en: '![](img/30c8be1f-f92e-4085-9727-4b9f9c797077.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/30c8be1f-f92e-4085-9727-4b9f9c797077.png)'
- en: 'Counting these two neighborhoods (and not yet counting other neighborhoods
    in the window), our histogram can be visualized like this:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 计算这两个邻域（尚未计算窗口中的其他邻域），我们的直方图可以可视化如下：
- en: '![](img/cefbc6c1-db29-43dd-ad5f-cea6c565ee37.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/cefbc6c1-db29-43dd-ad5f-cea6c565ee37.png)'
- en: If we compute the LBPH of multiple sets of reference images for multiple subjects,
    we can determine which set of LBPH references is least distant from the LBPH of
    a piece of a scene, such as a detected face. Based on the least distant set of
    references, we can predict the identity of the face (or other object) in the scene.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们为多个主题计算多组参考图像的LBPH，我们可以确定哪一组LBPH参考与场景中某一部分（如检测到的人脸）的LBPH最接近。基于最接近的参考集，我们可以预测场景中人脸（或其他对象）的身份。
- en: An LBPH model is good at capturing fine texture detail in any subject, not just
    faces. Moreover, it is good for applications where the model needs to be updated,
    such as `Interactive Recognizer`. The histograms for any two images are computed
    independently, so a new reference image can be added without recomputing the rest
    of the model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: LBPH模型擅长捕捉任何主题的精细纹理细节，而不仅仅是人脸。此外，它适用于模型需要更新的应用，例如`交互式识别器`。任何两张图像的直方图都是独立计算的，因此可以添加新的参考图像而无需重新计算模型的其他部分。
- en: OpenCV also implements other models that are popular for face recognition, namely,
    Eigenfaces and Fisherfaces. We use LBPH because it supports updates in real time,
    whereas Eigenfaces and Fisherfaces do not. For more information on these three
    recognition models, see the official documentation at [https://docs.opencv.org/4.0.0-beta/da/d60/tutorial_face_main.html](https://docs.opencv.org/4.0.0-beta/da/d60/tutorial_face_main.html).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV还实现了其他在人脸识别中流行的模型，即Eigenfaces和Fisherfaces。我们使用LBPH是因为它支持实时更新，而Eigenfaces和Fisherfaces则不支持。有关这三个识别模型的更多信息，请参阅官方文档[https://docs.opencv.org/4.0.0-beta/da/d60/tutorial_face_main.html](https://docs.opencv.org/4.0.0-beta/da/d60/tutorial_face_main.html)。
- en: Alternatively, for detection rather than recognition, we can organize LBPH models
    into a cascade of multiple tests, much like a Haar cascade. Unlike an LBPH recognition
    model, an LBP cascade cannot be updated in real time.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，对于检测而不是识别，我们可以将LBPH模型组织成多个测试的级联，就像Haar级联一样。与LBPH识别模型不同，LBP级联不能实时更新。
- en: Haar cascades, LBP cascades, and LBPH recognition models are not robust with
    respect to rotation or flipping. For example, if we look at a face upside down,
    it will not be detected by a Haar cascade that was trained only with upright faces.
    Similarly, if we had an LBPH recognition model trained for a cat whose face is
    black on the cat's left-hand side and orange on the cat's right-hand side, the
    model might not recognize the same cat in a mirror. The exception is that we could
    include mirror images in the training set, but then we might get a false positive
    recognition for a different cat whose face is orange on the cat's left-hand side
    and black on the cat's right-hand side.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Haar级联、LBP级联和LBPH识别模型对旋转或翻转不稳健。例如，如果我们倒置地看一个脸，那么仅用直立脸训练的Haar级联将无法检测到它。同样，如果我们有一个为一只脸的左侧是黑色、右侧是橙色的猫训练的LBPH识别模型，那么在镜子中，模型可能无法识别出同一只猫。例外的情况是，我们可以将镜像图像包含在训练集中，但这样可能会对另一只脸的左侧是橙色、右侧是黑色的猫产生误报识别。
- en: Unless otherwise noted, we may assume that a Haar cascade or LBPH model is trained
    for an *upright* subject. That is, the subject is not tilted or upside down in
    the image's coordinate space. If a man is standing on his head, we can take an
    upright photo of his face by turning the camera upside down or, equivalently,
    by applying a 180-degree rotation in software.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，否则我们可以假设Haar级联或LBPH模型是为一个**直立**的主题训练的。也就是说，主题在图像坐标空间中没有被倾斜或倒置。如果一个人头朝下站立，我们可以通过将相机倒置或，等价地，在软件中应用180度旋转来拍摄他的直立人脸照片。
- en: Some other directional terms are worth noting. A *frontal*, *rear*, or *profile*
    subject has its front, rear, or profile visible in the image. Most computer vision
    people, including the authors of OpenCV, express *left* and *right* in the image's
    coordinate space. For example, if we say *left eye*, for an upright, frontal,
    non-mirrored face, we mean the subject's right-hand eye, since left and right
    in image space are opposite from an upright, frontal, non-mirrored subject's left-hand
    and right-hand directions.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一些其他方向术语也值得注意。一个*正面*、*背面*或*侧面*主题在图像中可见其正面、背面或侧面。包括OpenCV的作者在内的大多数计算机视觉人员，在图像坐标空间中表达*左*和*右*。例如，如果我们说*左眼*，对于一个直立、正面、非镜像的面孔，我们指的是主体的右手眼，因为在图像空间中，左右与直立、正面、非镜像主体的左手和右手方向相反。
- en: 'The following screenshot shows how we would label the *left eye* and *right
    eye* in a non-mirrored image (left) and mirrored image (right):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了我们在非镜像图像（左）和镜像图像（右）中如何标记*左眼*和*右眼*：
- en: '![](img/851a49a3-9db4-4a43-b274-929ce15bacb8.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/851a49a3-9db4-4a43-b274-929ce15bacb8.png)'
- en: Our human and feline detectors deal with upright, frontal faces.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的人类和猫检测器处理直立、正面的面孔。
- en: Of course, in a real-world photo, we cannot expect a face to be perfectly upright.
    The person's head or the camera might have been slightly tilted. Moreover, we
    cannot expect boundary regions, where a face meets a background, to be similar
    across images. We must take great care to preprocess the training images so that
    the face is rotated to a nearly perfect upright pose and boundary regions are
    cropped off. When cropping, we should place the major features of the face, such
    as eyes, in a consistent position. These considerations are addressed further
    in the *Planning the cat-detection model* section, later in this chapter.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在现实世界的照片中，我们无法期望人脸完全直立。人的头部或相机可能略有倾斜。此外，我们无法期望边界区域，即人脸与背景相交的区域，在图像中相似。我们必须非常小心地预处理训练图像，以便人脸旋转到几乎完美的直立姿态，并裁剪掉边界区域。在裁剪时，我们应该将人脸的主要特征，如眼睛，放置在一致的位置。这些考虑在*规划猫检测模型*部分中进一步讨论，这部分在本章的后面。
- en: If we must detect faces in various rotations, one option is to rotate the scene
    before sending it to the detector. For example, we can try to detect faces in
    the original scene, then in a version of the scene that has been rotated 15 degrees,
    then a version rotated—15 degrees (345 degrees), then a version rotated 30 degrees,
    and so on. Similarly, we can send mirrored versions of the scene to the detector.
    Depending on how many variations of the scene are tested, such an approach may
    be too slow for real-time use, and thus we do not use it in this chapter.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们必须检测各种旋转的人脸，一个选项是在将场景发送到检测器之前旋转场景。例如，我们可以尝试在原始场景中检测人脸，然后在旋转了15度的场景版本中检测，然后是旋转了15度（345度）的场景版本，然后是旋转了30度的场景版本，依此类推。同样，我们可以将场景的镜像版本发送到检测器。根据测试场景变体的数量，这种方法可能对于实时使用来说太慢，因此我们在这章中没有使用它。
- en: Implementing the Interactive Recognizer app
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现交互式识别器应用程序
- en: 'Let''s create a new folder, where we will store this chapter''s project, including
    the following subfolders and files that are relevant to `Interactive Recognizer`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个新的文件夹，我们将在这个文件夹中存储本章的项目，包括以下与`Interactive Recognizer`相关的子文件夹和文件：
- en: '`cascades/haarcascade_frontalface_alt.xml`: A detection model for a frontal
    human face. It should be included with OpenCV at a path such as `<opencv_unzip_destination>/data/haarcascades/haarcascade_frontalface_alt.xml`
    or for a MacPorts installation at `/opt/local/share/OpenCV/haarcascades/haarcascade_frontalface_alt.xml`.
    Copy or link to that version. (Alternatively, get it from this book''s GitHub
    repository).'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascades/haarcascade_frontalface_alt.xml`: 这是一个用于检测正面人脸的检测模型。它应该与OpenCV一起包含在路径中，例如
    `<opencv_unzip_destination>/data/haarcascades/haarcascade_frontalface_alt.xml`，或者对于MacPorts安装，在
    `/opt/local/share/OpenCV/haarcascades/haarcascade_frontalface_alt.xml`。复制或链接到该版本。（或者，可以从本书的GitHub仓库中获取它）。'
- en: '`cascades/lbpcascade_frontalface.xml`: An alternative (faster but less reliable)
    detection model for a frontal human face. It should be included with OpenCV at
    a path such as `<opencv_unzip_destination>/data/lbpcascades/lbpcascade_frontalface.xml`
    or for a MacPorts installation at `/opt/local/share/OpenCV/lbpcascades/lbpcascade_frontalface.xml`.
    Copy or link to that version. Alternatively, get it from this book''s GitHub repository.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascades/lbpcascade_frontalface.xml`: 用于检测正面人脸的另一种（更快但可靠性较低）的检测模型。它应包含在OpenCV中，路径如`<opencv_unzip_destination>/data/lbpcascades/lbpcascade_frontalface.xml`，或者对于MacPorts安装，在`/opt/local/share/OpenCV/lbpcascades/lbpcascade_frontalface.xml`。复制或链接到该版本。或者，您也可以从本书的GitHub仓库中获取。'
- en: '`cascades/haarcascade_frontalcatface.xml`: A detection model for a frontal,
    feline face. We will build it later in this chapter. Alternatively, you may get
    a prebuilt version from this book''s GitHub repository.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascades/haarcascade_frontalcatface.xml`: 用于检测正面猫科面部模型的检测模型。我们将在本章后面构建它。或者，您也可以从本书的GitHub仓库中获取预构建版本。'
- en: '`cascades/haarcascade_frontalcatface_extended.xml`: An alternative detection
    model for a frontal feline face. This version is sensitive to diagonal patterns,
    potentially including whiskers and ears. We will build it later in this chapter.
    (Alternatively, you may get a prebuilt version from this book''s GitHub repository.)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascades/haarcascade_frontalcatface_extended.xml`: 用于检测正面猫科面部面的另一种检测模型。此版本对对角线图案敏感，可能包括胡须和耳朵。我们将在本章后面构建它。（或者，您也可以从本书的GitHub仓库中获取预构建版本。）'
- en: '`cascades/lbpcascade_frontalcatface.xml`: Another alternative (faster but less
    reliable) detection model for a frontal feline face. We will build it later in
    this chapter. (Alternatively, you may get a prebuilt version from this book''s
    GitHub repository.)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascades/lbpcascade_frontalcatface.xml`: 用于检测正面猫科面部面的另一种（更快但可靠性较低）的检测模型。我们将在本章后面构建它。（或者，您也可以从本书的GitHub仓库中获取预构建版本。）'
- en: '`recognizers/lbph_human_faces.xml`: A recognition model for the faces of certain
    human individuals. It is generated by `InteractiveHumanFaceRecognizer.py`, as
    follows later.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognizers/lbph_human_faces.xml`: 某些人类个体面部识别模型。它由`InteractiveHumanFaceRecognizer.py`生成，如下所述。'
- en: '`recognizers/lbph_cat_faces.xml`: A recognition model for the faces of certain
    feline individuals. It is generated by `InteractiveCatFaceRecognizer.py`, as follows
    later.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognizers/lbph_cat_faces.xml`: 某些猫科个体面部识别模型。它由`InteractiveCatFaceRecognizer.py`生成，如下所述。'
- en: '`ResizeUtils.py`: Utility functions for resizing images. It copies or links
    to the previous chapter''s version of `ResizeUtils.py`. We will add a function
    to resize the camera capture dimensions.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ResizeUtils.py`: 用于调整图像大小的实用函数。它复制或链接到上一章的`ResizeUtils.py`版本。我们将在本节中添加一个调整摄像头捕获尺寸的函数。'
- en: '`WxUtils.py`: Utility functions for wxPython GUI applications. It copies or
    links to the [Chapter 2](4ec4e82a-b63d-4fc1-bf3b-47c653c25a79.xhtml), *Searching
    for Luxury Accommodations Worldwide*, version of `WxUtils.py`.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WxUtils.py`: 用于wxPython GUI应用程序的实用函数。它复制或链接到[第2章](4ec4e82a-b63d-4fc1-bf3b-47c653c25a79.xhtml)，*全球寻找豪华住宿*版本的`WxUtils.py`。'
- en: '`BinasciiUtils.py`: Utility functions for converting human-readable identifiers
    into numbers and back.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BinasciiUtils.py`: 用于将可读标识符转换为数字及其反向转换的实用函数。'
- en: '`InteractiveRecognizer.py`: A class that encapsulates the `Interactive Recognizer`
    app and exposes certain variables for configuration. We will implement it in this
    section.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`InteractiveRecognizer.py`: 封装`Interactive Recognizer`应用程序的类，并公开某些配置变量。我们将在本节中实现它。'
- en: '`InteractiveHumanFaceRecognizer.py`: A script to launch a version of Interactive
    Recognizer that is configured for frontal human faces. We will implement it in
    this section.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`InteractiveHumanFaceRecognizer.py`: 启动配置为检测正面人脸的Interactive Recognizer版本的脚本。我们将在本节中实现它。'
- en: '`InteractiveCatFaceRecognizer.py`: A script to launch a version of `Interactive
    Recognizer` that is configured for frontal feline faces. We will implement it
    in this section.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`InteractiveCatFaceRecognizer.py`: 启动配置为检测正面猫科面部面的Interactive Recognizer版本的脚本。我们将在本节中实现它。'
- en: 'Let''s start with an addition to our existing `ResizeUtils` module. We want
    to be able to specify the resolution at which a camera captures images. Camera
    input is represented by an OpenCV class called `VideoCapture`, with the `get`
    and `set` methods that pertain to various camera parameters, including resolution.
    (Incidentally, `VideoCapture` can also represent a video file.) There is no guarantee
    that a given capture resolution is supported by a given camera. We need to check
    the success or failure of any attempt to set the capture resolution. Accordingly,
    let''s add the following utility function to `ResizeUtils.py` to attempt to set
    a capture resolution and to return the actual capture resolution:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从向现有的 `ResizeUtils` 模块添加功能开始。我们希望能够指定相机捕获图像的分辨率。相机输入由一个名为 `VideoCapture`
    的 OpenCV 类表示，该类具有与各种相机参数相关的 `get` 和 `set` 方法，包括分辨率。（顺便提一下，`VideoCapture` 也可以表示视频文件。）不能保证给定的捕获分辨率被给定的相机支持。我们需要检查尝试设置捕获分辨率时的成功或失败。因此，让我们向
    `ResizeUtils.py` 添加以下实用函数，以尝试设置捕获分辨率并返回实际的捕获分辨率：
- en: '[PRE0]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, let''s consider the requirements for our new `BinasciiUtils` module. OpenCV''s
    recognizers use 32-bit integers as identifiers. For a GUI, asking the user to
    give a face a number, instead of a name, is not very friendly. We could keep a
    dictionary that maps numbers to names, and we could save this dictionary to disk,
    alongside the recognition model, but here is my lazier solution. Four or fewer
    ASCII characters can be cast to a 32-bit integer (and vice versa). For example,
    consider the name *Puss*, in which the letter ASCII codes are *80*, *117*, *115*,
    and *115*, respectively. Remembering that each letter is one byte or 8 bits, we
    can apply bitshift operations to the ASCII codes to get the following value:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑我们新的 `BinasciiUtils` 模块的要求。OpenCV 的识别器使用 32 位整数作为标识符。对于 GUI，要求用户给一个脸一个数字，而不是一个名字，并不是很友好。我们可以保留一个将数字映射到名字的字典，并且我们可以将这个字典与识别模型一起保存到磁盘上，但这是我的更懒惰的解决方案。四个或更少的
    ASCII 字符可以转换为 32 位整数（反之亦然）。例如，考虑名字 *Puss*，其中字母的 ASCII 码分别是 *80*，*117*，*115* 和
    *115*。记住每个字母是一个字节或 8 位，我们可以应用位移操作来获取以下值：
- en: '![](img/057dc3ba-57dd-475e-b121-7f32de7ac5eb.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/057dc3ba-57dd-475e-b121-7f32de7ac5eb.png)'
- en: 'We will let the user enter names of up to four characters, and, behind the
    scenes, we will convert to and from the 32-bit integers that the model stores.
    Let''s create `BinasciiUtils.py`, and put the following imports and conversion
    functions in it:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将允许用户输入最多四个字符的名字，而在幕后，我们将将其转换为模型存储的 32 位整数。让我们创建 `BinasciiUtils.py`，并将以下导入和转换函数放入其中：
- en: '[PRE1]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let''s proceed to write `InteractiveRecognizer.py`. It should start with
    the following `import` statements:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始编写 `InteractiveRecognizer.py`。它应该以以下 `import` 语句开始：
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Our `InteractiveRecognizer` application class accepts several arguments that
    allow us to create different variants of the app with different titles, highlight
    colors, recognition models, detection models, and tweaks to the detection behavior.
    Let''s look at the initializer''s declaration:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `InteractiveRecognizer` 应用程序类接受几个参数，允许我们创建具有不同标题、高亮颜色、识别模型、检测模型和检测行为调整的不同变体的应用程序。让我们看看初始化器的声明：
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The initializer''s arguments are defined as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化器的参数定义如下：
- en: '`recognizerPath`: This is the file containing the recognition model. This file
    does not need to exist when the app starts. Rather, the recognition model (if
    any) is saved here when the app exits.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognizerPath`：这是包含识别模型的文件。当应用程序启动时，此文件不需要存在。相反，当应用程序退出时，识别模型（如果有的话）将保存在这里。'
- en: '`cascadePath`: This is the file containing the detection model. This file does
    need to exist when the app starts.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascadePath`：这是包含检测模型的文件。当应用程序启动时，此文件必须存在。'
- en: '`scaleFactor`: The detector searches for faces at several different scales.
    This argument specifies the ratio of each scale to the next smaller scale. A bigger
    ratio implies a faster search but fewer detections.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scaleFactor`：检测器在几个不同的尺度上搜索人脸。此参数指定每个尺度与下一个较小尺度之间的比率。较大的比率意味着搜索更快，但检测更少。'
- en: '`minNeighbors`: If the detector encounters two overlapping regions that both
    might pass detection as faces, they are called neighbors. The `minNeighbors` argument
    specifies the minimum number of neighbors that a face must have in order to pass
    detection. Where `minNeighbors>0`, the rationale is that a true face could be
    cropped in several alternative places and still look like a face. A greater number
    of required neighbors implies fewer detections and a lower proportion of false
    positives.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minNeighbors`: 如果检测器遇到两个可能都被识别为面部且重叠的区域，它们被称为邻居。`minNeighbors`参数指定面部必须具有的最小邻居数才能通过检测。当`minNeighbors>0`时，其理由是真正的面部可以在几个不同的位置裁剪并仍然看起来像面部。所需邻居数量越多，检测越少，误报比例越低。'
- en: '`minSizeProportional`: A face''s minimum width and height are expressed as
    a proportion of the camera''s vertical resolution or horizontal resolution, whichever
    is less. For example, if the camera resolution is *640 x 480* and `minSizeProportional=(0.25,
    0.25)`, the face must measure at least *120 x 120* (in pixels) in order to pass
    detection. A bigger minimum size implies a faster search but fewer detections.
    The `(0.25, 0.25)` default value is appropriate for a face that is close to a
    webcam.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minSizeProportional`: 面部的最小宽度和高度以相机垂直分辨率或水平分辨率（取较小者）的比例表示。例如，如果相机分辨率为*640
    x 480*，且`minSizeProportional=(0.25, 0.25)`，则面部必须至少测量*120 x 120*（以像素为单位）才能通过检测。更大的最小尺寸意味着搜索更快，但检测更少。`(0.25,
    0.25)`默认值适用于接近网络摄像头的面部。'
- en: '`rectColor`: This is for the color of the rectangle outlining a detected face.
    Like most color tuples in OpenCV, it is specified in **blue, green, and red**
    (**BGR**) order (not RGB).'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rectColor`: 这是用于描绘检测到的面部的矩形的颜色。像OpenCV中的大多数颜色元组一样，它以**蓝色、绿色和红色**（**BGR**）的顺序指定（不是RGB）。'
- en: '`cameraDeviceID`: The is the device ID of the camera that should be used for
    input. Typically, webcams are numbered starting from `0`, with any connected external
    webcams coming before any internal webcams. Some camera drivers reserve fixed
    device IDs. For example, OpenNI reserves `900` for Kinect and `910` for Asus Xtion.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cameraDeviceID`: 这是用于输入的相机的设备ID。通常，网络摄像头从`0`开始编号，任何连接的外部网络摄像头都排在任何内部网络摄像头之前。一些相机驱动程序保留固定的设备ID。例如，OpenNI为Kinect保留`900`，为Asus
    Xtion保留`910`。'
- en: '`imageSize`: The preferred resolution for captured images. If the camera does
    not support this resolution, another resolution is used.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imageSize`: 这是捕获图像的首选分辨率。如果相机不支持此分辨率，将使用另一个分辨率。'
- en: '`title`: The app title, as seen in the window title bar.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`title`: 应用程序标题，如窗口标题栏所示。'
- en: 'We also provide a public Boolean variable to configure whether or not the camera
    feed is mirrored. By default, it is mirrored because users find a mirrored image
    of themselves to be more intuitive:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一个公共布尔变量来配置是否镜像相机流。默认情况下，它是镜像的，因为用户发现镜像中的自己图像更直观：
- en: '[PRE4]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Another Boolean tracks whether the app should still be running or whether it
    is closing. This information is relevant to cleaning up a background thread:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个布尔值跟踪应用程序是否仍在运行或是否正在关闭。此信息与清理后台线程相关：
- en: '[PRE5]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Using an OpenCV class called `cv2.VideoCapture`, we open a camera feed and
    get its resolution, as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 使用名为`cv2.VideoCapture`的OpenCV类，我们打开相机流并获取其分辨率，如下所示：
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We define variables to store the images that we will capture, process, and
    display. Initially, these are `None`. In order to capture and process images on
    one thread, and then draw them to the screen on another thread, we will use a
    pattern known as **double buffering**. While one frame (the **back buffer**) is
    being prepared on one thread, another frame (the **front buffer**) will be being
    drawn on a second thread. When both threads have done a round of work, we will
    swap the buffers so that the old back buffer becomes the new front buffer and
    vice versa (by simply changing references, without copying data). To accomplish
    this in a thread-safe manner, we need to declare a **mutual exclusion lock** (also
    called a **mutex**), which represents a permission or resource (in this case,
    access to the front buffer) that only one thread can acquire at a time. We will
    see the lock in use later in this section, in the `_onVideoPanelPaint` and `_runCaptureLoop` methods.
    For now, here are the initial declarations of the images and lock:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义变量来存储我们将要捕获、处理和显示的图像。最初，这些变量为`None`。为了在一个线程中捕获和处理图像，然后在另一个线程中将它们绘制到屏幕上，我们将使用一种称为**双缓冲**的模式。当在一个线程上准备一个帧（**后缓冲区**）时，另一个帧（**前缓冲区**）将在第二个线程上绘制。当两个线程都完成了一轮工作后，我们将交换缓冲区，使旧的后缓冲区成为新的前缓冲区，反之亦然（通过简单地更改引用，而不复制数据）。为了以线程安全的方式完成此操作，我们需要声明一个**互斥锁**（也称为**mutex**），它代表一个权限或资源（在这种情况下，访问前缓冲区），一次只能由一个线程获取。我们将在本节的后续内容中看到锁的使用，在`_onVideoPanelPaint`和`_runCaptureLoop`方法中。现在，以下是图像和锁的初始声明：
- en: '[PRE7]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we set up variables related to detection and recognition. Many of these
    variables just store initialization arguments for later use. Also, we keep a reference
    to the currently detected face, which is initially `None`. We initialize an LBPH
    recognizer and load any recognition model that we may have saved on a previous
    run on the app. Likewise, we initialize a detector by loading a Haar cascade or
    LBP cascade from file. Here is the relevant code:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们设置与检测和识别相关的变量。其中许多变量仅用于存储后续使用的初始化参数。此外，我们保留对当前检测到的脸的引用，初始值为`None`。我们初始化一个LBPH识别器，并加载在之前的运行中可能保存的任何识别模型。同样，我们通过从文件加载Haar级联或LBP级联来初始化一个检测器。以下是相关代码：
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Having set up the variables that are relevant to computer vision, we proceed
    to the GUI implementation, which is mostly boilerplate code. First, in the following
    snippet, we set up the window with a certain style, size, title, and background
    color, and we bind a handler for its close event:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置了与计算机视觉相关的变量之后，我们继续进行GUI实现，这主要是样板代码。首先，在以下代码片段中，我们设置了具有特定样式、大小、标题和背景色的窗口，并为其关闭事件绑定了一个处理程序：
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we set a callback for the *Escape* key. Since a key is not a GUI widget,
    there is no `Bind` method directly associated with a key, and we need to set up
    the callback a bit differently than we have previously seen with wxWidgets. We
    bind a new menu event and callback to the `InteractiveRecognizer` instance, and
    we map a keyboard shortcut to the menu event using a class called `wx.AcceleratorTable`.
    (Note, however, that our app actually has no menu, nor is an actual menu item
    required for the keyboard shortcut to work.) Here is the code:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们为*Escape*键设置一个回调。由于键不是一个GUI小部件，没有直接与键关联的`Bind`方法，我们需要以与我们之前使用wxWidgets看到的不同方式设置回调。我们将一个新的菜单事件和回调绑定到`InteractiveRecognizer`实例上，并使用名为`wx.AcceleratorTable`的类将键盘快捷键映射到菜单事件。（然而，请注意，我们的应用程序实际上没有菜单，也不需要实际的菜单项来使键盘快捷键工作。）以下是代码：
- en: '[PRE10]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following code initializes the GUI widgets (including a video panel, text
    field, buttons, and label) and sets their event callbacks:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码初始化了GUI小部件（包括视频面板、文本框、按钮和标签）并设置了它们的事件回调：
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Similar to Luxocator (the [Chapter 2](4ec4e82a-b63d-4fc1-bf3b-47c653c25a79.xhtml), *Searching
    for Luxury Accommodations Worldwide,* project), `Interactive Recognizer` lays
    out the image on top and a row of controls on the bottom. Here is the layout code:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 与Luxocator（第2章，*全球寻找豪华住宿*，项目）类似，`Interactive Recognizer`将图像放置在顶部，并在底部放置一行控件。以下是布局代码：
- en: '[PRE12]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, the initializer starts a background thread that performs image capture
    and image processing, including detection and recognition. It is important to
    perform the intensive computer vision work on a background thread so that it doesn''t
    stall the handling of GUI events. Here is the code that starts the thread:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，初始化器启动一个后台线程，执行图像捕获和图像处理，包括检测和识别。在后台线程上执行密集的计算机视觉工作很重要，这样就不会阻碍 GUI 事件的处理。以下是启动线程的代码：
- en: '[PRE13]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: With a variety of input events and background work, `InteractiveRecognizer`
    has many methods that run in an indeterminate order. We will look at input event
    handlers first, before proceeding to the image pipeline (capture, processing,
    and display), which partly runs on the background thread.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 由于有各种输入事件和后台工作，`InteractiveRecognizer` 有许多方法以不确定的顺序运行。我们首先查看输入事件处理器，然后再继续到图像处理管道（捕获、处理和显示），这部分工作在后台线程上运行。
- en: 'When the window is closed, we ensure that the background thread stops. Then,
    if the recognition model is trained, we save it to file. Here is the implementation
    of the relevant callback:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 当窗口关闭时，我们确保后台线程停止。然后，如果识别模型已训练，我们将其保存到文件。以下是相关回调的实现：
- en: '[PRE14]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Besides closing the window when its standard *X* button is clicked, we also
    close it in the `_onQuitCommand` callback, which we linked to the *Esc* button.
    The callback''s implementation is shown in the following code:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 除了点击窗口的标准 *X* 按钮关闭窗口外，我们还在 `_onQuitCommand` 回调中关闭它，该回调与 *Esc* 按钮相关联。回调的实现如下所示：
- en: '[PRE15]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We handle the video panel''s erase event by doing nothing because we simply
    want to draw over the old video frame instead of erasing it. We handle the video
    panel''s draw event by acquiring the lock that gives us thread-safe access to
    the front image buffer, converting the image into a wxPython bitmap, and then
    drawing the bitmap to the panel. Here are the implementations of the two relevant
    callbacks in the following code:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过什么都不做来处理视频面板的擦除事件，因为我们只想在旧的视频帧上绘制，而不是擦除它。我们通过获取锁来处理视频面板的绘制事件，该锁为我们提供了对前图像缓冲区的线程安全访问，将图像转换为
    wxPython 位图，然后将位图绘制到面板上。以下是以下代码中两个相关回调的实现：
- en: '[PRE16]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'When the user adds or deletes text in the text field, our `_onReferenceTextCtrlKeyUp`
    callback (as follows) calls a helper method to check whether the Add to Model
    button should be enabled or disabled:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户在文本字段中添加或删除文本时，我们的 `_onReferenceTextCtrlKeyUp` 回调（如下所示）调用一个辅助方法来检查是否应该启用或禁用“添加到模型”按钮：
- en: '[PRE17]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'When the Add to Model button is clicked, its callback provides new training
    data to the recognition model. If the LBPH model has no prior training data, we
    must use the recognizer''s `train` method; otherwise, we must use its `update`
    method. Both methods accept two arguments—a list of images (the faces) and a NumPy
    array of integers (the face identifiers). We train or update the model with just
    one image at a time so that the user can interactively test the effect of each
    incremental change to the model. The image is the most recently detected face,
    and the identifier is converted from the text in the text field using our `BinasciiUtils.fourCharsToInt`
    function. Here is the implementation of the Add to Model button''s callback:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 当点击“添加到模型”按钮时，其回调为识别模型提供新的训练数据。如果 LBPH 模型没有先前的训练数据，我们必须使用识别器的 `train` 方法；否则，我们必须使用其
    `update` 方法。两种方法都接受两个参数——一个图像列表（人脸）和一个整数 NumPy 数组（人脸标识符）。我们一次只使用一张图像来训练或更新模型，以便用户可以交互式地测试模型每次增量更改的效果。图像是最近检测到的人脸，标识符是通过我们的
    `BinasciiUtils.fourCharsToInt` 函数从文本字段中的文本转换而来的。以下是“添加到模型”按钮回调的实现：
- en: '[PRE18]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'When the Clear Model button is clicked, its callback deletes the recognition
    model (including any version that has been saved to disk) and creates a new one.
    Also, we record that the model is untrained and we disable the Clear Model button
    until the model is retrained. Here is the implementation in the following code:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当点击“清除模型”按钮时，其回调删除识别模型（包括任何已保存到磁盘的版本）并创建一个新的模型。此外，我们记录模型未训练，并禁用“清除模型”按钮，直到模型重新训练。以下是以下代码中的实现：
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Our background thread runs a loop. On each iteration, we capture an image using
    the `VideoCapture` object''s `read` method. Along with the image, the `read` method
    returns a `success` flag, which we do not need because instead we just check whether
    the image is `None`. If the image is not `None`, we call a helper method named
    `_detectAndRecognize`, and then we may mirror the image for display. We also acquire
    the lock to perform a thread-safe swap of the front and back image buffers. After
    the swap, we tell the video panel to refresh itself by drawing the bitmap from
    the new front buffer. Here is the implementation of the loop in the following
    code:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的背景线程运行一个循环。在每次迭代中，我们使用 `VideoCapture` 对象的 `read` 方法捕获一个图像。与图像一起，`read` 方法返回一个
    `success` 标志，我们不需要它，因为我们只是检查图像是否为 `None`。如果图像不是 `None`，我们调用一个名为 `_detectAndRecognize`
    的辅助方法，然后我们可能镜像图像以进行显示。我们还获取锁以执行线程安全的交换前后图像缓冲区。交换后，我们告诉视频面板通过绘制新前缓冲区中的位图来刷新自己。以下是以下代码中循环的实现：
- en: '[PRE20]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: By calling `self._capture.read(self._image)`, we are telling OpenCV to reuse
    the image buffer in `self._image` (if `self.image` is not `None` and is the right
    size) so that new memory doesn't have to be allocated every time we capture a
    new frame. Alternatively, it would be valid, but less efficient, to call `self._capture.read()`
    without arguments; in this case, new memory would be allocated every time we captured
    a new frame.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用 `self._capture.read(self._image)`，我们告诉 OpenCV 重新使用 `self._image` 中的图像缓冲区（如果
    `self.image` 不是 `None` 且大小正确），这样每次捕获新帧时就不需要分配新内存。或者，也可以调用 `self._capture.read()`
    而不带参数；在这种情况下，每次捕获新帧时都会分配新内存。
- en: Recall that the loop ends after our `_onCloseWindow` callback sets `_running`
    to `False`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，我们的循环在 `_onCloseWindow` 回调将 `_running` 设置为 `False` 后结束。
- en: 'The `_detectAndRecognize` helper method is also running on the background thread.
    It begins by creating an equalized grayscale version of the image. An **equalized**
    image has an approximately uniform histogram; that is to say, for some bin size,
    the number of pixels in each bin of gray values is approximately equal. It is
    a kind of contrast adjustment that makes a subject''s appearance more predictable,
    despite different lighting conditions and exposure settings in different images;
    thus, it aids detection or recognition. We pass the equalized image to the classifier''s
    `detectMultiScale` method, also using the `scaleFactor`, `minNeighbors`, and `minSize` arguments
    that were specified during initialization of `InteractiveRecognizer`. As the return
    value from `detectMultiScale`, we get a list of rectangle measurements, describing
    the bounds of the detected faces. For display, we draw green outlines around these
    faces. If at least one face is detected, we store an equalized grayscale version
    of the first face in the `_currDetectedObject` member variable. Here is the implementation
    of this first portion of the `_detectAndRecognize` method:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`_detectAndRecognize` 辅助方法也在后台线程上运行。它首先创建图像的均衡灰度版本。均衡的图像具有大约均匀的直方图；也就是说，对于某个箱子大小，每个灰度值箱子中的像素数量大约相等。这是一种对比度调整，使得主题的外观在不同光照条件和不同图像的曝光设置下更加可预测；因此，它有助于检测或识别。我们将均衡的图像传递给分类器的
    `detectMultiScale` 方法，同时使用在 `InteractiveRecognizer` 初始化期间指定的 `scaleFactor`、`minNeighbors`
    和 `minSize` 参数。作为 `detectMultiScale` 的返回值，我们得到一系列矩形测量值，描述了检测到的面部边界。为了显示，我们在这些面部周围绘制绿色轮廓。如果至少检测到一个面部，我们将第一个面部的均衡灰度版本存储在
    `_currDetectedObject` 成员变量中。以下是 `_detectAndRecognize` 方法第一部分的实现：'
- en: '[PRE21]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that we perform equalization separately on the detected face region after
    we crop it. This enables us to get an equalization result that is better adapted
    to the local contrast of the face, instead of the global contrast of the whole
    image.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在裁剪检测到的面部区域后单独对其进行均衡。这使得我们能够得到一个更好地适应面部局部对比度的均衡结果，而不是整个图像的全局对比度。
- en: 'If a face is currently detected and the recognition model is trained for at
    least one individual, we can proceed to predict the identity of the face. We pass
    the equalized face to the `predict` method of the recognizer and get two return
    values—an integer identifier and a measure of distance (non-confidence). Using
    our `BinasciiUtils.intToFourChars` function, we convert the integer into a string
    (of at most four characters), which will be one of the face names that the user
    previously entered. We show the name and distance. If an error occurs (for example,
    if an invalid model was loaded from file), we delete and recreate the model. If
    the model is not yet trained, we show instructions about training the model. Here
    is the implementation of this middle portion of the `_detectAndRecognize` method:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果当前检测到人脸且识别模型至少为一个人训练过，我们可以继续预测人脸的身份。我们将均衡化的人脸传递给识别器的`predict`方法，并得到两个返回值——一个整数标识符和距离（非置信度）的度量。使用我们的`BinasciiUtils.intToFourChars`函数，我们将整数转换为字符串（最多四个字符），这将是用户之前输入的其中一个人脸名称。我们显示名称和距离。如果发生错误（例如，如果从文件加载了无效的模型），我们删除并重新创建模型。如果模型尚未训练，我们显示有关训练模型的说明。以下是`_detectAndRecognize`方法此中间部分的实现：
- en: '[PRE22]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If no face was detected, we set `_currDetectedObject` to `None` and show either
    the instructions (if the model hasn''t been trained yet) or no descriptive text,
    otherwise. Under all conditions, we end the `_detectAndRecognize` method by ensuring
    that the Add to Model button is enabled or disabled, as appropriate. Here is this
    final portion of the method''s implementation:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有检测到人脸，我们将`_currDetectedObject`设置为`None`，并显示说明（如果模型尚未训练）或没有描述性文本。在所有情况下，我们通过确保添加到模型按钮按适当的方式启用或禁用来结束`_detectAndRecognize`方法。以下是该方法实现的最后部分：
- en: '[PRE23]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The Add to Model button should be enabled only when a face is detected and
    the text field is not empty. We can implement this logic in the following manner:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当检测到人脸且文本字段不为空时，才应启用添加到模型按钮。我们可以以下述方式实现此逻辑：
- en: '[PRE24]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Since we set the label''s text under several different conditions, we use the
    following helper functions to reduce repetition of code, as shown in the following
    code:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在几种不同的条件下设置了标签的文本，我们使用以下辅助函数来减少代码的重复，如下面的代码所示：
- en: '[PRE25]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note the use of the `wx.CallAfter` function to ensure that the label is updated
    on the main thread.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 注意使用`wx.CallAfter`函数以确保标签在主线程上更新。
- en: 'That is all the functionality of `Interactive Recognizer`. Now, we just need
    to write the `main` functions for the two variants of the app, starting with the
    `Interactive Human Face Recognizer`. As arguments to the initializer of `InteractiveRecognizer`,
    we provide the app''s title and PyInstaller-compatible paths to the relevant detection
    model and recognition model. We run the app. Here is the implementation, which
    we may put in `InteractiveHumanFaceRecognizer.py`:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是`交互式识别器`的所有功能。现在，我们只需要编写两个应用变体的`main`函数，从`交互式人脸识别器`开始。作为`InteractiveRecognizer`初始化器的参数，我们提供应用的标题以及相关检测模型和识别模型的PyInstaller兼容路径。我们运行应用。以下是实现，我们可能将其放在`InteractiveHumanFaceRecognizer.py`中：
- en: '[PRE26]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Remember that `cascades/haarcascade_frontalface_alt.xml` or `cascades/lpbcascade_frontalface.xml`
    needs to be obtained from the OpenCV samples or from this book's GitHub repository.
    Feel free to test `Interactive Human Face Recognizer` now!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 记住`cascades/haarcascade_frontalface_alt.xml`或`cascades/lpbcascade_frontalface.xml`需要从OpenCV样本或本书的GitHub仓库中获取。现在可以自由测试`交互式人脸识别器`了！
- en: 'Our second variant of the app, `Interactive Cat Face Recognizer`, uses very
    similar code. We change the app''s title and the paths of the detection and recognition
    models. Also, we lower the `scaleFactor` value to `1.2`, the `minNeighbors` value
    to `1`, and the `minSizeProportional` value to (`0.125`, `0.125`) to make the
    detector a little more sensitive. (A cat face is smaller than a human face, and
    our cat face detection model turns out to be less prone to false positives than
    our human face detection model, so these adjustments are appropriate.) Here is
    the implementation, which we may put in `InteractiveCatFaceRecognizer.py`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用的第二个变体，`交互式猫脸识别器`，使用非常相似的代码。我们更改了应用标题和检测和识别模型的路径。此外，我们将`scaleFactor`值降低到`1.2`，将`minNeighbors`值降低到`1`，将`minSizeProportional`值设置为(`0.125`,
    `0.125`)，使检测器略微更敏感。（猫脸比人脸小，我们的猫脸检测模型最终证明比我们的人脸检测模型更不容易出现误报，因此这些调整是合适的。）以下是实现，我们可能将其放在`InteractiveCatFaceRecognizer.py`中：
- en: '[PRE27]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: At this stage, `Interactive Cat Face Recognizer` will not run properly because
    `cascades/haarcascade_frontalcatface.xml`, `cascades/haarcascade_frontalcatface_extended.xml`,
    or `cascades/lpbcascade_frontalcatface.xml` does not exist (unless you copied
    the prebuilt version from this book's GitHub repository). Soon, we will create
    it!
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，`交互式猫脸识别器`无法正常运行，因为`cascades/haarcascade_frontalcatface.xml`、`cascades/haarcascade_frontalcatface_extended.xml`或`cascades/lpbcascade_frontalcatface.xml`文件不存在（除非您已从本书的GitHub仓库中复制了预构建版本）。很快，我们将创建它！
- en: Planning the cat-detection model
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计划猫检测模型
- en: When I said *soon*, I meant in a day or two. Training a Haar cascade takes a
    lot of processing time. Training an LBP cascade is relatively quick. However,
    in either case, we need to download some big collections of images before we even
    start. Settle down with a reliable internet connection, a power outlet, at least
    4 GB of free disk space, and the fastest CPU and biggest RAM you can find. Do
    not attempt this segment of the project on a Raspberry Pi. Keep the computer away
    from external heat sources or things that might block its fans. My processing
    time for Haar cascade training was 24 hours (or more for the whisker-friendly
    version that is sensitive to diagonal patterns), with 100% usage on four cores,
    on a MacBook Pro with a 2.6 GHz Intel Core i7 CPU and 16 GB RAM.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说“很快”时，我的意思是几天之内。训练Haar级联需要大量的处理时间。训练LBP级联相对较快。然而，在两种情况下，我们都需要在开始之前下载一些大型的图像集合。请确保有一个可靠的互联网连接、电源插座、至少4GB的空闲磁盘空间，以及你能找到的最快CPU和最大RAM。不要在树莓派上尝试这个项目部分。请将计算机远离外部热源或可能阻挡其风扇的东西。我训练Haar级联的处理时间是24小时（或者更多，对于对对角线图案敏感的、对胡须友好的版本），在MacBook
    Pro上使用四个核心，CPU主频为2.6 GHz，RAM为16 GB。
- en: 'We use the following sets of images, which are freely available for research
    purposes:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下几组图像，这些图像可以免费用于研究目的：
- en: The PASCAL **Visual Object Classes Challenge 2007** (**VOC2007**) dataset. VOC2007
    contains 10,000 images of diverse subjects against diverse backgrounds, under
    diverse lighting conditions, so it is suitable as the basis of our negative training
    set. The images come with annotation data, including a count of cats for each
    image (most often 0). Thus, in building our negative training set, we can easily
    omit images that contain cats.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PASCAL视觉对象类别挑战2007**（**VOC2007**）数据集。VOC2007包含了10,000张在不同背景、不同光照条件下的不同主题图像，因此它适合作为我们负样本训练集的基础。这些图像附带注释数据，包括每张图像中猫的数量（通常是0）。因此，在构建我们的负样本训练集时，我们可以轻松地排除包含猫的图像。'
- en: The frontal face dataset from the **California Institute of Technology** (**Caltech**)
    Faces 1999\. This set contains 450 images of frontal human faces under diverse
    lighting conditions and against diverse backgrounds. These images make a useful
    addition to our negative training set because our frontal cat face detector may
    be deployed in places where frontal human faces are also likely to be present.
    None of the images contain cats.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自**加州理工学院**（**Caltech**）的正面人脸数据集。这个集合包含了450张在不同光照条件和不同背景下的正面人脸图像。这些图像对我们负样本训练集是一个有用的补充，因为我们的正面猫脸检测器可能会部署在正面人脸也可能存在的场所。这些图像中没有任何一张包含猫。
- en: The Urtho negative training set, which was originally part of a face- and eye-detection
    project called **Urtho**. This set contains 3,000 images of diverse backgrounds.
    None of the images contain cats.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Urtho负样本训练集，最初是名为**Urtho**的一个人脸和眼脸检测项目的一部分。这个集合包含了3,000张不同背景的图像。这些图像中没有任何一张包含猫。
- en: 'The cat head dataset from Microsoft Research (*Microsoft Cat Dataset 2008*)
    has 10,000 images of cats against diverse backgrounds and under diverse lighting
    conditions. The rotation of the cat''s head varies, but in all cases the nose,
    mouth, both eyes, and both ears are clearly visible. Thus, we may say that all
    the images include frontal faces and are suitable for use as our positive training
    set. Each image comes with annotation data, indicating coordinates of the center
    of the mouth, center of the eyes, and corners of the hollow of the ear (three
    corners per ear). Based on the annotation data, we can straighten and crop the
    cat''s face in order to make the positive training images more similar to each
    other, as shown in the following screenshot:'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软研究院的猫头数据集（*微软猫数据集2008*）包含10,000张猫在不同背景和光照条件下的图像。猫头的旋转各不相同，但在所有情况下，鼻子、嘴巴、两只眼睛和两只耳朵都清晰可见。因此，我们可以这样说，所有图像都包含正面人脸，适合用作我们的正训练集。每张图像都附带注释数据，指示嘴巴中心、眼睛中心和耳窝（每只耳朵三个角）的坐标。基于注释数据，我们可以将猫的脸部拉直并裁剪，以便使正训练图像更加相似，如下面的截图所示：
- en: '![](img/4ea6b541-c4f7-4b19-b7ed-f2887149e46e.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4ea6b541-c4f7-4b19-b7ed-f2887149e46e.png)'
- en: 'The author of the Urtho negative training set is unknown. The other annotated
    datasets are generously provided by the following authors, as part of the following
    publications:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Urtho负训练集的作者不详。其他注释数据集由以下作者慷慨提供，作为以下出版物的一部分：
- en: Everingham, M. and Van Gool, L. and Williams, C. K. I. and Winn, J., and Zisserman,
    A. *The PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results*.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 永宁，M. 和范古尔，L. 和威廉姆斯，C. K. I. 和温，J.，以及齐瑟曼，A. *PASCAL视觉对象类别挑战2007（VOC2007）结果*。
- en: Weber, Markus. *Frontal face dataset*. California Institute of Technology, 1999.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 韦伯，马克斯。*正面人脸数据集*。加州理工学院，1999年。
- en: Weiwei Zhang, Jian Sun, and Xiaoou Tang. *Cat Head Detection - How to Effectively
    Exploit Shape and Texture Features*, *Proc. of European Conf. Computer Vision*,
    vol. 4, pp. 802-816, 2008.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张伟伟，孙剑，唐晓鸥。*猫头检测 - 如何有效利用形状和纹理特征*，《欧洲计算机视觉会议论文集》，第4卷，第802-816页，2008年。
- en: We will preprocess the images and generate files describing the positive and
    negative training sets. After preprocessing, all the training images are in equalized
    grayscale format, and the positive training images are upright and cropped. The
    description files conform to certain formats expected by the OpenCV training tools.
    With the training sets prepared, we will run the OpenCV training tools with the
    appropriate parameters. The output will be a Haar cascade file for detecting upright
    frontal cat faces.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将预处理图像并生成描述正负训练集的文件。预处理后，所有训练图像都转换为均等灰度格式，正训练图像都是竖直裁剪的。描述文件符合OpenCV训练工具期望的某些格式。准备好训练集后，我们将使用适当的参数运行OpenCV训练工具。输出将是一个用于检测竖直正面猫脸的Haar级联文件。
- en: Implementing the training script for the cat-detection model
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现猫检测模型的训练脚本
- en: '"Praline: I''ve never seen so many aerials in me life. The man told me, their
    equipment could pinpoint a purr at 400 yards and Eric, being such a happy cat,
    was a piece of cake."'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: “普朗尼：我一生中从未见过这么多空中动作。那个人告诉我，他们的设备可以在400码外精确地定位到一声呼噜，而埃里克，作为一个如此快乐的猫，简直是小菜一碟。”
- en: – Fish License sketch, Monty Python's Flying Circus, Episode 23 (1970)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: – 鱼牌草图，蒙提·派森飞行马戏团，第23集（1970年）
- en: 'This segment of the project uses tens of thousands of files, including images,
    annotation files, scripts, and intermediate and final outputs of the training
    process. Let''s organize all of this new material by giving our project a subfolder,
    `cascade_training`, which will ultimately have the following contents:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目这一部分使用了成千上万的文件，包括图像、注释文件、脚本以及训练过程的中间和最终输出。让我们通过为我们的项目创建一个子文件夹，命名为`cascade_training`，来组织所有这些新材料，该文件夹最终将包含以下内容：
- en: '`cascade_training/CAT_DATASET_01`: This is the first half of the Microsoft
    Cat Dataset 2008.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/CAT_DATASET_01`：这是微软猫数据集2008年的前半部分。'
- en: '`cascade_training/CAT_DATASET_02`: This is the second half of the Microsoft
    Cat Dataset 2008.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/CAT_DATASET_02`：这是微软猫数据集2008年的后半部分。'
- en: '`cascade_training/faces`: This is the Caltech Faces 1999 dataset.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/faces`：这是Caltech Faces 1999数据集。'
- en: '`cascade_training/urtho_negatives`: This is the Urtho negatives dataset.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/urtho_negatives`：这是Urtho负数据集。'
- en: '`cascade_training/VOC2007`: This is the VOC2007 dataset.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/VOC2007`：这是VOC2007数据集。'
- en: '`cascade_training/describe.py`: A script to preprocess and describe the positive
    and negative training sets. As outputs, it creates new images in the previous
    dataset directories and in the following text description files.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/describe.py`: 这是一个用于预处理和描述正负训练集的脚本。作为输出，它在之前的数据集目录中创建新的图像，并在以下文本描述文件中。'
- en: '`cascade_training/negative_description.txt`: This is a generated text file
    describing the negative training set.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/negative_description.txt`: 这是一个描述负训练集的生成文本文件。'
- en: '`cascade_training/positive_description.txt`: This is a generated text file
    describing the positive training set.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/positive_description.txt`: 这是一个描述正训练集的生成文本文件。'
- en: '`cascade_training/train.bat` (Windows) or `cascade_training/train.sh` (Mac
    or Linux): This is a script to run the OpenCV cascade training tools with appropriate
    parameters. As input, it uses the previous text description files. As output,
    it generates a not-yet mentioned binary description file and cascade files.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/train.bat`（Windows）或`cascade_training/train.sh`（Mac或Linux）：这是一个用于运行OpenCV级联训练工具的脚本，带有适当的参数。作为输入，它使用之前的文本描述文件。作为输出，它生成一个尚未提到的二进制描述文件和级联文件。'
- en: '`cascade_training/binary_description`: This is a generated binary file describing
    the positive training set.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/binary_description`: 这是一个描述正训练集的生成二进制文件。'
- en: '`cascade_training/lbpcascade_frontalcatface/*.xml`: This gives the intermediate
    and final results of the LBP cascade training.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/lbpcascade_frontalcatface/*.xml`: 这提供了LBP级联训练的中间和最终结果。'
- en: '`cascades/lbpcascade_frontalcatface.xml`: This is a copy of the final result
    of the LBP cascade training, in a location where our apps expect it.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascades/lbpcascade_frontalcatface.xml`: 这是LBP级联训练最终结果的副本，位于我们的应用程序期望的位置。'
- en: '`cascade_training/haarcascade_frontalcatface/*.xml`: This shows the intermediate
    and final results of the Haar cascade training.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascade_training/haarcascade_frontalcatface/*.xml`: 这显示了Haar级联训练的中间和最终结果。'
- en: '`cascades/haarcascade_frontalcatface.xml`: This is a copy of the final result
    of the Haar cascade training, in a location where our apps expect it.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascades/haarcascade_frontalcatface.xml`: 这是Haar级联训练最终结果的副本，位于我们的应用程序期望的位置。'
- en: For up-to-date instructions on obtaining and extracting the Microsoft Cat Dataset
    2008, the Caltech Faces 1999 dataset, the Urtho negatives dataset, and the VOC2007
    dataset, refer to the README on this book's GitHub web page at [https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition/](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition/).
    Over time, some of the datasets' original websites and mirrors have gone down
    permanently, yet other mirrors continue to come online.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 关于获取和提取Microsoft Cat Dataset 2008、Caltech Faces 1999数据集、Urtho负样本数据集和VOC2007数据集的最新说明，请参阅本书GitHub网页上的README文件[https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition/](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition/)。随着时间的推移，一些数据集的原始网站和镜像已经永久关闭，但其他镜像仍在上线。
- en: 'Once the datasets are downloaded and decompressed to the proper locations,
    let''s write `describe.py`. It needs to start with the following shebang line
    and imports:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据集下载并解压缩到正确的位置，让我们编写`describe.py`。它需要以下shebang行和导入：
- en: '[PRE28]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'All our source images need some preprocessing to optimize them as training
    images. We need to save the preprocessed versions, so let''s globally define an
    extension that we will use for these files:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的所有源图像都需要一些预处理以优化它们作为训练图像。我们需要保存预处理版本，因此让我们全局定义一个我们将用于这些文件的扩展名：
- en: '[PRE29]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To give our training images a more predictable appearance despite differences
    in lighting conditions and exposure settings, we need to create equalized grayscale
    images at several points in this script. Let''s write the following helper function
    for this purpose:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使我们的训练图像在光照条件和曝光设置不同的情况下具有更可预测的外观，我们需要在脚本中的几个地方创建均衡的灰度图像。让我们编写以下辅助函数来完成此目的：
- en: '[PRE30]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Similarly, we need to append to the negative description file at more than
    one point in the script. Each line in the negative description is just an image
    path. Let''s add the following helper method, which accepts an image path and
    a file object for the negative description, loads the image and saves an equalized
    version, and appends the equalized version''s path to the description file:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们需要在脚本中的多个地方追加到负描述文件。负描述中的每一行只是一个图像路径。让我们添加以下辅助方法，它接受一个图像路径和一个负描述的文件对象，加载图像并保存均衡版本，并将均衡版本的路经追加到描述文件：
- en: '[PRE31]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, let''s write the `describeNegative` function that calls `describeNegativeHelper`.
    It begins by opening a file in write mode so that we can write the negative description.
    Then, we iterate over all the image paths in the Caltech Faces 1999 set, which
    contains no cats. We skip any paths to output images that were written on a previous
    call of this function. We pass the remaining image paths, along with the newly
    opened negative description file, to `describeNegativeHelper`, as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编写调用`describeNegativeHelper`的`describeNegative`函数。它首先以写入模式打开一个文件，以便我们可以写入负描述。然后，我们遍历Caltech
    Faces 1999集中的所有图像路径，该集中不包含猫。我们跳过任何在之前调用此函数时已写入的输出图像路径。我们将剩余的图像路径，以及新打开的负描述文件，按照以下方式传递给`describeNegativeHelper`：
- en: '[PRE32]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'For every image in the Urtho negative training set, we pass the file path to `describeNegativeHelper`,
    as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Urtho负训练集中的每一张图像，我们按照以下方式传递文件路径到`describeNegativeHelper`：
- en: '[PRE33]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The remainder of the `describeNegative` function is responsible for passing
    relevant file paths from the VOC2007 image set to `describeNegativeHelper`. Some
    images in VOC2007 do contain cats. An annotation file, `VOC2007/ImageSets/Main/cat_test.txt`,
    lists image IDs and a flag indicating whether any cats are present in the image.
    The flag may be—`1` (no cats), `0` (one or more cats as background or secondary
    subjects of the image), or `1` (one or more cats as foreground or foreground subjects
    of the image). We parse this annotation data and, if an image contains no cats,
    we pass its path and the description file to `describeNegativeHelper`, as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`describeNegative`函数的其余部分负责将VOC2007图像集中的相关文件路径传递到`describeNegativeHelper`。VOC2007中的某些图像确实包含猫。一个注释文件`VOC2007/ImageSets/Main/cat_test.txt`列出了图像ID和一个标志，表示图像中是否包含猫。标志可能是`1`（没有猫），`0`（一个或多个猫作为图像的背景或次要主题），或`1`（一个或多个猫作为图像的前景或前景主题）。我们解析这些注释数据，如果图像不包含猫，我们按照以下方式传递其路径和描述文件到`describeNegativeHelper`：'
- en: '[PRE34]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, let''s move on to helper functions for generating the positive description.
    When rotating a face to straighten it, we also need to rotate a list of coordinate
    pairs representing features of the face. The following helper function accepts
    such a list, along with a center of rotation and angle of rotation, and returns
    a new list of the rotated coordinate pairs:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续编写生成正描述的辅助函数。当将人脸旋转以使其直立时，我们还需要旋转表示人脸特征的坐标对列表。以下辅助函数接受这样的列表，以及旋转中心和旋转角度，并返回一个新的旋转坐标对列表：
- en: '[PRE35]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next, let''s write a long helper function to preprocess a single positive training
    image. This function accepts two arguments—a list of coordinate pairs (which is
    named `coords`) and an OpenCV image. Refer to the diagram of feature points on
    a cat face. The numbering of the points signifies their order in a line of annotation
    data and in `coords`. To begin the function, we get the coordinates for the eyes
    and mouth. If the face is upside down (not an uncommon pose in playful or sleepy
    cats), we swap our definitions of left and right eyes to be consistent with an
    upright pose. (In determining whether the face is upside down, we rely in part
    on the position of the mouth relative to the eyes.) Then, we find the angle between
    the eyes and we rotate the image so that the face becomes upright. An OpenCV function
    called `cv2.getRotationMatrix2D` is used to define the rotation, and another function
    called `cv2.warpAffine` is used to apply it. As a result of rotating border regions,
    some blank regions are introduced into the image. We may specify a fill color
    for these regions as an argument to `cv2.warpAffine`. We use 50% gray, since it
    has the least tendency to bias the equalization of the image. Here is the implementation
    of this first part of the `preprocessCatFace` function:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们编写一个长辅助函数来预处理单个正训练图像。这个函数接受两个参数——一个坐标对列表（命名为`coords`）和一个OpenCV图像。参考猫脸上的特征点图。点的编号表示它们在注释数据行和`coords`中的顺序。为了开始这个函数，我们获取眼睛和嘴巴的坐标。如果人脸是倒置的（在玩耍或困倦的猫中并不罕见），我们将左右眼睛的定义进行交换，以保持直立姿势的一致性。（在确定人脸是否倒置时，我们部分依赖于嘴巴相对于眼睛的位置。）然后，我们找到眼睛之间的角度，并将图像旋转，使人脸直立。使用名为`cv2.getRotationMatrix2D`的OpenCV函数来定义旋转，并使用名为`cv2.warpAffine`的另一个函数来应用它。由于旋转边界区域，图像中引入了一些空白区域。我们可以将这些区域的填充颜色作为`cv2.warpAffine`的参数指定。我们使用50%灰色，因为它最不容易偏移图像的均衡。以下是`preprocessCatFace`函数这个第一部分的实现：
- en: '[PRE36]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'As well as straightening the image, we call `rotateCoords` to make feature
    coordinates that match the straightened image. Here is the code for this function
    call:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'At this stage, the image and feature coordinates are transformed so that the
    cat''s eyes are level and upright. Next, let''s crop the image to eliminate most
    of the background and to standardize the eyes'' position relative to the bounds.
    Arbitrarily, we define the cropped face to be a square region, as wide as the
    distance between the outer base points of the cat''s ears. This square is positioned
    so that half its area lies to the left of the midpoint between the cat''s eyes,
    half lies to the right, 40% lies above, and 60% lies below. For an ideal frontal
    cat face, this crop excludes all background regions, but includes the eyes, chin,
    and several fleshy regions—the nose, mouth, and part of the inside of the ears.
    We equalize and return the cropped image. Accordingly, the implementation of `preprocessCatFace`
    proceeds as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: During cropping, we usually eliminate the blank border region that was introduced
    during rotation. However, if the cat face was close to the border of the original
    image, some of the rotated gray border region may remain.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'The following pair of screenshots is an example of input and output for the
    `processCatFace` function. First, there''s the input:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f23403bc-aabd-42a5-82d9-1dcd5a023e9b.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
- en: 'The output is displayed in the following screenshot:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/943b2738-7ab0-45be-b71c-419354f919b5.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
- en: 'To generate the positive description file, we iterate over all the images in
    the Microsoft Cat Dataset 2008\. For each image, we parse the cat feature coordinates
    from the corresponding `.cat` file and we generate the straightened, cropped,
    and equalized image by passing the coordinates and original image to our `processCatFace`
    function. We append each processed image path and measurements to the positive
    description file. Here is the implementation:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Here, let''s take note of the format of a positive description file. Each line
    contains a path to a training image, followed by a series of numbers indicating
    the count of positive objects in the image and the measurements (x, y, width,
    and height) of rectangles containing those objects. In our case, there is always
    one cat face filling the entire cropped image, so we get lines such as the following,
    which is for a *64 x 64* image:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Hypothetically, if the image had two *8 x 8* pixel cat faces in opposite corners,
    its line in the description file would look like this:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The main function of `describe.py` simply calls our `describeNegative` and
    `describePositive` functions, as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Run `describe.py` and then feel free to have a look at the generated files,
    including `negative_description.txt`, `positive_description.txt`, and the cropped
    cat faces whose filenames follow the `CAT_DATASET_*/CAT_*/*.out.jpg` pattern.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will use two of OpenCV's command-line tools. We will refer to them
    as `<opencv_createsamples>` and `<opencv_traincascade>`. They are responsible
    for converting the positive description to a binary format and generating the
    Haar cascade in an XML format, respectively. On Windows, these executables are
    named `opencv_createsamples.exe` and `opencv_traincascade.exe`. On Mac or Linux,
    the executables are named `opencv_createsamples` and `opencv_traincascade`.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用OpenCV的两个命令行工具。我们将它们称为 `<opencv_createsamples>` 和 `<opencv_traincascade>`。它们分别负责将正描述转换为二进制格式并生成XML格式的Haar级联。在Windows上，这些可执行文件命名为`opencv_createsamples.exe`和`opencv_traincascade.exe`。在Mac或Linux上，可执行文件命名为`opencv_createsamples`和`opencv_traincascade`。
- en: For up-to-date instructions on obtaining `<opencv_createsamples>` and `<opencv_traincascade>`,
    refer to the README on this book's GitHub web page at [https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition/](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition/).
    At the time of writing, there is not yet an OpenCV 4.x version of these two command-line
    tools, but the OpenCV 3.4 version of them is forward-compatible, and work on a
    4.x version has been proposed for summer 2019.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 关于获取 `<opencv_createsamples>` 和 `<opencv_traincascade>` 的最新说明，请参考本书GitHub网页上的README文件，网址为
    [https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition/](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition/)。在撰写本文时，这两个命令行工具还没有OpenCV
    4.x版本，但它们的OpenCV 3.4版本是向前兼容的，并且已经提出在2019年夏季开发4.x版本。
- en: 'Many flags can be used to provide arguments to `<opencv_createsamples>` and
    `<opencv_traincascade>`, as described in the official documentation at [https://docs.opencv.org/master/dc/d88/tutorial_traincascade.html](https://docs.opencv.org/master/dc/d88/tutorial_traincascade.html).
    We use the following flags and values:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用许多标志来为 `<opencv_createsamples>` 和 `<opencv_traincascade>` 提供参数，具体请参阅官方文档中的描述，文档地址为
    [https://docs.opencv.org/master/dc/d88/tutorial_traincascade.html](https://docs.opencv.org/master/dc/d88/tutorial_traincascade.html)。我们使用的标志和值如下：
- en: '`vec`: This is the path to a binary description of the positive training images.
    This file is generated by `<opencv_createsamples>`.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vec`：这是正训练图像二进制描述的路径。此文件由`opencv_createsamples`生成。'
- en: '`info`: This is the path to a text description of the positive training images.
    We generated this file using `describe.py`.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`info`：这是正训练图像文本描述的路径。我们使用`describe.py`生成了此文件。'
- en: '`bg`: The path to a text description of the negative training images. We generated
    this file using `describe.py`.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bg`：负训练图像文本描述的路径。我们使用`describe.py`生成了此文件。'
- en: '`num`: The number of positive training images in `info`.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num`：`info`中正训练图像的数量。'
- en: '`numStages`: The number of stages in the cascade. As we discussed earlier in
    *Conceptualizing Haar cascades and LBPH*, each stage is a test that is applied
    to an image region. If the region passes all tests, it is classified as a frontal
    cat face (or whatever class of object the positive training set represents). We
    use `20`.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numStages`：级联中的阶段数量。正如我们之前在 *概念化Haar级联和LBPH* 中讨论的那样，每个阶段是对图像区域应用的一个测试。如果该区域通过所有测试，则被分类为正面猫脸（或正训练集代表的任何对象类别）。我们使用`20`。'
- en: '`numPos`: The number of positive training images used in each stage. It should
    be significantly smaller than `num`. (Otherwise, the trainer will fail, complaining
    that it has run out of new images to use in new stages.) We use 90% of `num`.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numPos`：每个阶段使用的正训练图像数量。它应该远小于`num`。（否则，训练器将失败，并抱怨它已经没有新图像可用于新阶段。）我们使用`num`的90%。'
- en: '`numNeg`: The number of negative training images used in each stage. We use
    90% of the number of negative training images in `bg`.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numNeg`：每个阶段使用的负训练图像数量。我们使用`bg`中负训练图像数量的90%。'
- en: '`minHitRate`: The **hit rate** is also called the **sensitivity**, **recall**,
    or **true positive rate**. In our case, it is the proportion of cat faces that
    are correctly classified as such. The `minHitRate` parameter specifies the minimum
    hit rate that *each* stage must achieve. A higher proportion implies a longer
    training time but a better fit between the model and the training data. (A better
    fit is normally a good thing, though it is possible to **overfit** so that the
    model does not make correct extrapolations beyond the training data.) We use `0.995`. With
    20 stages, this implies an overall hit rate of *0.995 ^ 20* or approximately 99%.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minHitRate`: **命中率**也称为**灵敏度**、**召回率**或**真阳性率**。在我们的情况下，它是正确分类为猫脸的猫脸比例。`minHitRate`参数指定了每个阶段必须达到的最小命中率。更高的比例意味着更长的训练时间，但模型与训练数据之间的拟合度更好。（更好的拟合通常是好事，尽管有可能**过拟合**，导致模型无法对训练数据之外的进行正确的外推。）我们使用`0.995`。如果有20个阶段，这意味着总的命中率为*0.995^20*，大约是99%。'
- en: '`maxFalseAlarmRate`: The **false alarm rate** is also called the **miss rate**
    or **false positive rate**. In our case, it is the proportion of backgrounds or
    non-cat faces that are misclassified as cat faces. The `maxFalseAlarmRate` parameter
    specifies the maximum false alarm rate for *each* stage. We use `0.5`. With 20
    stages, this implies an overall false alarm rate of *0.5 ^ 20* or approximately
    one in a million.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxFalseAlarmRate`: **误报率**也称为**漏报率**或**假阳性率**。在我们的情况下，它是将背景或非猫脸错误分类为猫脸的比例。`maxFalseAlarmRate`参数指定了每个阶段的最大误报率。我们使用`0.5`。如果有20个阶段，这意味着总的误报率为*0.5^20*，大约是百万分之一。'
- en: '`featureType`: The type of features used, either `HAAR` (the default) or `LBP`.
    As we discussed previously, Haar cascades tend to be more reliable but are much
    slower to train and somewhat slower at runtime.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`featureType`: 使用的特征类型，可以是`HAAR`（默认值）或`LBP`。正如我们之前讨论的，Haar级联通常更可靠，但训练和运行速度要慢得多。'
- en: '`mode`: This is the subset of Haar features used. (For LBP, this flag has no
    effect.) The valid options are `BASIC` (the default), `CORE`, and `ALL`. The `CORE`
    option makes the model slower to train and run, but the benefit is to make the
    model sensitive to little dots and thick lines. The `ALL` option goes further,
    making the model even slower to train and run but adding sensitivity to diagonal
    patterns (whereas `BASIC` and `CORE` are only sensitive to horizontal and vertical
    patterns). The `ALL` option has nothing to do with detecting non-upright subjects.
    Rather, it relates to detecting subjects that contain diagonal patterns. For example,
    a cat''s whiskers and ears might qualify as diagonal patterns.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mode`: 这是使用的Haar特征的子集。（对于LBP，此标志没有效果。）有效的选项是`BASIC`（默认值）、`CORE`和`ALL`。`CORE`选项会使模型训练和运行速度变慢，但好处是使模型对小点和粗线敏感。`ALL`选项更进一步，使模型训练和运行速度更慢，但增加了对对角线图案的敏感性（而`BASIC`和`CORE`只对水平和垂直图案敏感）。`ALL`选项与检测非直立物体无关。相反，它关系到检测包含对角线图案的物体。例如，猫的胡须和耳朵可能符合对角线图案的标准。'
- en: 'Let''s write a shell script to run `<opencv_createsamples>` and `<opencv_traincascade>`
    with the appropriate flags and to copy the resulting Haar cascade to the path
    where `Interactive Cat Face Recognizer` expects it. On Windows, let''s call our
    script `train.bat` and implement it as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个shell脚本来运行`<opencv_createsamples>`和`<opencv_traincascade>`，并使用适当的标志，然后将生成的Haar级联复制到`Interactive
    Cat Face Recognizer`期望的路径。在Windows上，让我们将我们的脚本命名为`train.bat`，并实现如下：
- en: '[PRE43]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'On Mac or Linux, let''s instead call our script `train.sh` and implement it
    as follows:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在Mac或Linux上，我们可以将我们的脚本命名为`train.sh`，并实现如下：
- en: '[PRE44]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The preceding versions of the training script are configured to use basic Haar
    features and will take a long, long time to run, perhaps more than a day. By commenting
    out the variables related to a basic Haar configuration and uncommenting the variables
    related to an LBP configuration, we can cut the training time down to several
    minutes. As a third alternative, variables for an extended Haar configuration
    (sensitive to diagonal patterns) are also present but currently commented out.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的训练脚本版本配置为使用基本的Haar特征，运行时间会很长，可能超过一天。通过注释掉与基本Haar配置相关的变量，并取消注释与LBP配置相关的变量，我们可以将训练时间缩短到几分钟。作为第三种选择，也存在用于扩展Haar配置（对对角线图案敏感）的变量，但当前已被注释掉。
- en: 'When the training is done, feel free to have a look at the generated files,
    including the following:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，您可以随意查看生成的文件，包括以下内容：
- en: For basic Haar features, `cascades/haarcascade_frontalcatface.xml` and `cascade_training/haarcascade_frontalcatface/*`
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于基本的 Haar 特征，`cascades/haarcascade_frontalcatface.xml` 和 `cascade_training/haarcascade_frontalcatface/*`
- en: For extended Haar features, `cascades/haarcascade_frontalcatface_extended.xml`
    and `cascade_training/haarcascade_frontalcatface_extended/*`
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于扩展的 Haar 特征，`cascades/haarcascade_frontalcatface_extended.xml` 和 `cascade_training/haarcascade_frontalcatface_extended/*`
- en: For LBP, `cascades/lbpcascade_frontalcatface.xml` and `cascade_training/lbpcascade_frontalcatface/*`
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于LBP，`cascades/lbpcascade_frontalcatface.xml` 和 `cascade_training/lbpcascade_frontalcatface/*`
- en: Finally, let's run `InteractiveCatFaceRecognizer.py` to test our cascade!
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们运行 `InteractiveCatFaceRecognizer.py` 来测试我们的级联！
- en: Remember that our detector is designed for frontal upright cat faces. The cat
    should be facing the camera and might need some incentive to hold that pose. For
    example, you could ask the cat to settle on a blanket or in your lap, and you
    could pat or comb the cat. See the following screenshot of my colleague, Chancellor
    Josephine (*Little Jo*) Antoinette Puddingcat, GRL (Grand Rock of Lambda), sitting
    for a test.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们的检测器是为正面直立猫脸设计的。猫应该面对摄像头，可能需要一些激励来保持这个姿势。例如，你可以要求猫在毯子上或你的腿上坐下，你可以轻拍或梳理猫。请看以下我同事，Chancellor
    Josephine（*Little Jo*）Antoinette Puddingcat，GRL（Grand Rock of Lambda）为测试而坐的截图。
- en: 'If you do not have a cat (or even a human) who is willing to participate, then
    you can simply print a few images of a given cat (or human) from the web. Use
    heavy, matte paper and hold the print so that it faces the camera. Use prints
    of some images for training the recognizer and prints of other images for testing
    it:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有猫（甚至人）愿意参与，那么你可以简单地从网上打印一些给定猫（或人）的图片。使用重而哑光的纸张，并将打印品面对摄像头。使用一些图片的打印品来训练识别器，其他图片的打印品来测试它：
- en: '![](img/1496173d-fee5-46a8-ae44-f33cdfda9fe4.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1496173d-fee5-46a8-ae44-f33cdfda9fe4.png)'
- en: Our detector is pretty good at finding frontal cat faces. However, I encourage
    you to experiment further, make it better, and share your results! The current
    version sometimes mistakes the center of a frontal human face for a frontal cat
    face. Perhaps we should have used more databases of human faces as negative training
    images. Alternatively, if we had used faces of several mammal species as positive
    training images, could we have created a more general mammal face detector? Let
    me know what you discover!
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的检测器在寻找正面猫脸方面相当出色。然而，我鼓励你进一步实验，使其变得更好，并分享你的结果！当前版本有时会将正面人脸的中心误认为是正面猫脸。也许我们应该使用更多的人脸数据库作为负训练图像。或者，如果我们使用了多种哺乳动物物种的人脸作为正训练图像，我们能否创建一个更通用的哺乳动物人脸检测器？告诉我你发现了什么！
- en: Planning the Angora Blue app
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规划 Angora Blue 应用
- en: '`Angora Blue` reuses the same detection and recognition models that we created
    earlier. It is a relatively linear and simple app because it has no GUI and does
    not modify any models. It just loads the detection and recognition models from
    file and then silently runs a camera until a face is recognized with a certain
    level of confidence. After recognizing a face, the app sends an email alert and
    exits. To elaborate, we may say the app has the following flow of execution:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '`Angora Blue` 重新使用了我们之前创建的相同的检测和识别模型。因为它没有图形用户界面，也不修改任何模型，所以它是一个相对线性且简单的应用。它只是从文件中加载检测和识别模型，然后默默地运行摄像头，直到以一定程度的置信度识别出人脸。在识别到人脸后，应用会发送电子邮件警报并退出。为了详细说明，我们可以说应用具有以下执行流程：'
- en: Load face detection and face recognition models from file for both human and
    feline subjects.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文件中加载人类和猫科动物的正面人脸检测和识别模型。
- en: 'Capture a live video from a camera. For each frame of video, it can do the
    following:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从摄像头捕获实时视频。对于视频的每一帧，它可以执行以下操作：
- en: Detect all human faces in the frame. Perform recognition on each human face.
    If a face is recognized with a certain level of confidence, it sends an email
    alert and exits the app.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在帧中检测所有人类人脸。对每个检测到的人脸进行识别。如果人脸以一定程度的置信度被识别，它会发送电子邮件警报并退出应用。
- en: Detect all cat faces in the frame. Discard any cat faces that intersect with
    human faces. (We assume that such cat faces are false positives, since our cat
    detector sometimes mistakes human faces for cat faces.) For each remaining cat
    face, it performs recognition. If a face is recognized with a certain level of
    confidence, it sends an email alert and exits the app.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在帧中检测所有猫脸。丢弃与人类人脸相交的任何猫脸。（我们假设这样的猫脸是假阳性，因为我们的猫检测器有时会将人脸误认为是猫脸。）对于每个剩余的猫脸，它执行识别。如果人脸以一定程度的置信度被识别，它会发送电子邮件警报并退出应用。
- en: '`Angora Blue` is capable of running on a Raspberry Pi. The Pi''s small size
    makes it a nice platform for a hidden alarm system! Make sure that the Pi or other
    machine is connected to the internet in order to send email messages.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '`Angora Blue`能够在Raspberry Pi上运行。Pi的小尺寸使其成为隐藏警报系统的理想平台！确保Pi或其他机器连接到互联网，以便发送电子邮件消息。'
- en: Implementing the Angora Blue app
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现 Angora Blue 应用
- en: 'The `Angora Blue` app uses three new files—`GeomUtils.py`, `MailUtils.py`,
    and `AngoraBlue.py`, which should all be in our project''s top folder. Given the
    app''s dependencies on our previous work, the following files are relevant to
    `Angora Blue`:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '`Angora Blue`应用使用三个新文件—`GeomUtils.py`、`MailUtils.py`和`AngoraBlue.py`，这些文件都应该在我们的项目顶层文件夹中。鉴于应用对我们先前工作的依赖，以下文件与`Angora
    Blue`相关：'
- en: '`cascades/haarcascade_frontalface_alt.xml`'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascades/haarcascade_frontalface_alt.xml`'
- en: '`cascades/haarcascade_frontalcatface.xml`'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cascades/haarcascade_frontalcatface.xml`'
- en: '`recognizers/lbph_human_faces.xml`'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognizers/lbph_human_faces.xml`'
- en: '`recognizers/lbph_cat_faces.xml`'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recognizers/lbph_cat_faces.xml`'
- en: '`ResizeUtils.py`: A utility function for resizing images, including camera
    capture dimensions'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ResizeUtils.py`：用于调整图像大小的实用函数，包括相机捕获尺寸'
- en: '`GeomUtils.py`: A utility function for geometric operations'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GeomUtils.py`：用于几何操作的实用函数'
- en: '`MailUtils.py`: A utility function for sending emails'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MailUtils.py`：用于发送电子邮件的实用函数'
- en: '`AngoraBlue.py`: The application that sends an email alert when a person or
    cat is recognized'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AngoraBlue.py`：当识别到人或猫时发送电子邮件警报的应用程序'
- en: 'First, let''s create `GeomUtils.py`. It doesn''t need any import statements.
    Let''s add the following `intersects` function, which accepts two rectangles as
    arguments and returns either `True` (if they intersect) or `False` (otherwise),
    as shown in the following code:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建`GeomUtils.py`。它不需要任何导入语句。让我们添加以下`intersects`函数，该函数接受两个矩形作为参数，并返回`True`（如果它们相交）或`False`（否则），如下所示：
- en: '[PRE45]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Using the `intersects` function, let''s write the following `difference` function,
    which accepts two lists of rectangles, `rects0` and `rects1`, and returns a new
    list containing the rectangles in `rects0` that don''t intersect with any rectangle
    in `rects1`:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`intersects`函数，让我们编写以下`difference`函数，该函数接受两个矩形列表`rects0`和`rects1`，并返回一个新列表，其中包含`rects0`中不与`rects1`中的任何矩形相交的矩形：
- en: '[PRE46]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Later, we will use the `difference` function to filter out cat faces that intersect
    with human faces.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将使用`difference`函数来过滤掉与人类面部相交的猫面部。
- en: 'Now, let''s create `MailUtils.py`. It needs the following `import` statement:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建`MailUtils.py`。它需要以下`import`语句：
- en: '[PRE47]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'For the task of sending an email, let''s copy the following function from Rosetta
    Code, a free wiki that offers utility functions in many programming languages,
    as shown in the following code:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 对于发送电子邮件的任务，让我们从Rosetta Code复制以下函数，这是一个提供多种编程语言实用函数的免费维基百科，如下所示：
- en: '[PRE48]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: By default, the `sendEmail` function uses Gmail. By specifying the optional
    `smtpServer` argument, we can use a different service.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`sendEmail`函数使用Gmail。通过指定可选的`smtpServer`参数，我们可以使用不同的服务。
- en: Since July 2014, the default security settings on Google accounts require apps
    to use not only SMTP authentication but also OAuth authentication in order to
    send an email through Gmail. Our `sendEmail` function uses a secure TLS connection
    but handles SMTP authentication only (as this is sufficient for most email services
    other than Gmail). To reconfigure your Google account for compatibility with our
    function, log in to your account, go to [https://www.google.com/settings/security/lesssecureapps](https://www.google.com/settings/security/lesssecureapps),
    select the Enable option, and click Done. For best security, you might wish to
    create a dummy Google account for this project and apply the custom security setting
    to this dummy account only. Alternatively, most email services besides Gmail should
    not require special configuration.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 自2014年7月起，谷歌账户的默认安全设置要求应用在通过Gmail发送电子邮件时不仅要使用SMTP身份验证，还要使用OAuth身份验证。我们的`sendEmail`函数使用安全的TLS连接，但仅处理SMTP身份验证（因为这对于除Gmail之外的大多数电子邮件服务来说已经足够了）。为了使您的谷歌账户与我们的函数兼容，请登录您的账户，转到[https://www.google.com/settings/security/lesssecureapps](https://www.google.com/settings/security/lesssecureapps)，选择启用选项，然后点击完成。为了最佳安全性，您可能希望为此项目创建一个虚拟谷歌账户，并将自定义安全设置仅应用于此虚拟账户。或者，除了Gmail之外的大多数电子邮件服务通常不需要特殊配置。
- en: 'Now, we are ready to implement `AngoraBlue.py`. It starts with the following
    shebang line and imports:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备实现`AngoraBlue.py`。它以以下shebang行开始并导入：
- en: '[PRE49]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '`Angora Blue` simply uses a `main` function and one helper function, `recognizeAndReport`.
    This helper function begins as follows, by iterating over a given list of face
    rectangles and using a given recognizer (be it a human recognizer or a cat recognizer)
    to get a label and distance (non-confidence) for each face, as shown in the following
    code:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '`Angora Blue` 仅使用一个 `main` 函数和一个辅助函数 `recognizeAndReport`。这个辅助函数从以下方式开始，通过遍历给定的面矩形列表，并使用给定的识别器（无论是人类识别器还是猫识别器）为每个面获取标签和距离（非置信度），如下面的代码所示：'
- en: '[PRE50]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'For testing, it is useful to log the recognition results here. However, we
    comment out the logging in the final version, as follows:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 对于测试，在这里记录识别结果是有用的。然而，我们在最终版本中注释掉了日志记录，如下所示：
- en: '[PRE51]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'If any of the faces is recognized with a certain level of confidence (based
    on a `maxDistance` argument), we attempt to send an email alert. If the alert
    is sent successfully, the function returns `True`, meaning it did recognize and
    report a face. Otherwise, it returns `False`. Here is the remainder of the implementation:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任何面部以一定程度的置信度被识别（基于 `maxDistance` 参数），我们尝试发送电子邮件警报。如果警报成功发送，函数返回 `True`，表示它确实识别并报告了一个面部。否则，它返回
    `False`。以下是实现剩余部分的代码：
- en: '[PRE52]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The `main` function starts by defining paths to the detection and recognition
    models. If either recognition model does not exist (because it has not been trained),
    we print an error and exit, as follows:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '`main` 函数首先定义检测和识别模型的路径。如果任一识别模型不存在（因为它尚未训练），我们打印错误并退出，如下所示：'
- en: '[PRE53]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We prompt the user to enter email credentials and recipients, and we store
    the user responses in local variables, as shown in the following code:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提示用户输入电子邮件凭据和收件人，并将用户响应存储在局部变量中，如下面的代码所示：
- en: '[PRE54]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'As in `Interactive Recognizer`, we start capturing video from a camera and
    we store the video''s resolution in order to calculate the relative, minimum size
    of a face. Here is the relevant code:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `Interactive Recognizer` 类似，我们从摄像头开始捕获视频，并存储视频的分辨率以计算面部的相对、最小尺寸。以下是相关代码：
- en: '[PRE55]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We load detectors and recognizers from file and set a minimum face size for
    detection and maximum distance (non-confidence) for recognition. We specify the
    values separately for human and feline subjects. You may need to tweak the values
    based on your particular camera setup and models. The code proceeds as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从文件中加载检测器和识别器，并为检测设置最小面部尺寸，为识别设置最大距离（非置信度）。我们分别为人类和猫类主体指定值。您可能需要根据您的特定摄像头设置和模型调整这些值。代码继续如下：
- en: '[PRE56]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We read frames from the camera continuously until an email alert is sent as
    a result of face recognition. Each frame is converted into grayscale and equalized.
    Next, we detect and recognize human faces and possibly send an alert, as follows:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从摄像头连续读取帧，直到由于面部识别而发送电子邮件警报。每个帧被转换为灰度并均衡。接下来，我们检测和识别人类面部，并可能发送警报，如下所示：
- en: '[PRE57]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'If no alert has been sent, we continue to cat-detection and recognition. For
    cat-detection, we make extra efforts to eliminate false positives by specifying
    a higher `minNeighbors` value and by filtering out any cat faces that intersect
    human faces. Here is this final part of Angora Blue''s implementation:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 如果尚未发送警报，我们继续进行猫的检测和识别。对于猫检测，我们通过指定更高的 `minNeighbors` 值并过滤掉任何与人类面部相交的猫面部来额外努力消除误报。以下是
    Angora Blue 实现的这部分最终代码：
- en: '[PRE58]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Before testing `Angora Blue`, ensure that the two recognition models are trained
    using `Interactive Human Face Recognizer` and `Interactive Cat Face Recognizer`.
    Preferably, each model should contain two or more individuals. Then, set up a
    computer and webcam in a place where frontal human faces and frontal cat faces
    will be encountered. Try to get your friends and pets to participate in the following
    test cases:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试 `Angora Blue` 之前，确保使用 `Interactive Human Face Recognizer` 和 `Interactive
    Cat Face Recognizer` 训练了两个识别模型。最好每个模型包含两个或更多个体。然后，在将正面人类面部和正面猫面部遇到的地方设置一台计算机和摄像头。尝试让您的朋友和宠物参与以下测试案例：
- en: A human, who is unknown to the model, looks into the camera. Nothing should
    happen. If you get an email alert, increase `humanMaxDistance` and try again.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一位对模型未知的人类看向摄像头。不应该发生任何事情。如果您收到电子邮件警报，请增加 `humanMaxDistance` 并再次尝试。
- en: A cat, who is unknown to the model, looks into the camera. Nothing should happen.
    If you get an email alert, increase `catMaxDistance` and try again.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一只对模型未知的猫看向摄像头。不应该发生任何事情。如果您收到电子邮件警报，请增加 `catMaxDistance` 并再次尝试。
- en: A human, who is known to the model, looks into the camera. You should get an
    email alert. If not, decrease `humanMaxDistance` or rerun `Interactive Human Face
    Recognizer` to add more samples of the given human face. Try `Angora Blue` again.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型已知的人类看向摄像头。你应该会收到电子邮件警报。如果没有，请降低`humanMaxDistance`或重新运行`Interactive Human
    Face Recognizer`以添加更多给定人类面部样本。再次尝试`Angora Blue`。
- en: A cat, who is known to the model, looks into the camera. You should get an email
    alert. If not, decrease `catMaxDistance` or rerun `Interactive Cat Face Recognizer`
    to add more samples of the given cat face. Try `Angora Blue` again.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型已知的猫看向摄像头。你应该会收到电子邮件警报。如果没有，请降低`catMaxDistance`或重新运行`Interactive Cat Face
    Recognizer`以添加更多给定猫面部样本。再次尝试`Angora Blue`。
- en: Again, if you don't have enough human or feline volunteers, just get some heavy,
    matte paper and print faces from the web. Hold a print so that it is visible (and
    upright) from the camera's perspective, but ensure that you stay out of view so
    that the recognizer runs only on the print, not on you.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，如果你没有足够的人类或猫志愿者，只需准备一些重而哑光的纸张，从网上打印人脸。将打印品拿在手中，使其从摄像头的视角可见（并且直立），但确保你自己不在视野中，这样识别器只会在打印品上运行，不会在你身上运行。
- en: Once the recognition model and `Angora Blue` are tweaked, we are ready to deploy
    our alarm system to a vast network of webcam-enabled computers! Let the search
    for the blue-eyed Angora begin!
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦调整好识别模型和`Angora Blue`，我们就可以将我们的警报系统部署到大量配备网络摄像头的计算机上！让我们开始寻找蓝眼睛安哥拉兔吧！
- en: Building Angora Blue for distribution
  id: totrans-307
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为分发构建Angora Blue
- en: We can use PyInstaller to bundle `Angora Blue`, along with detection and recognition
    models, for distribution. Since the build scripts should be quite similar to the
    ones we used for Luxocator (the [Chapter 2](4ec4e82a-b63d-4fc1-bf3b-47c653c25a79.xhtml), *Searching
    for Luxury Accommodations Worldwide,* project), we will not discuss their implementation
    here. However, they are included in this book's GitHub repository.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用PyInstaller将`Angora Blue`以及检测和识别模型捆绑在一起进行分发。由于构建脚本应该与我们用于Luxocator（第2章，*全球寻找豪华住宿*）项目中的脚本相当相似，我们在这里不讨论它们的实现。然而，它们包含在本书的GitHub仓库中。
- en: Further fun with finding felines
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找猫的更多乐趣
- en: '**Kittydar** (short for **kitty radar**), by Heather Arthur, is an open source,
    JavaScript library for detecting upright frontal cat faces. You can find its demo
    application at [http://harthur.github.io/kittydar/](http://harthur.github.io/kittydar/)
    and its source code at [https://github.com/harthur/kittydar](https://github.com/harthur/kittydar).'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kittydar**（意为**猫雷达**），由Heather Arthur编写，是一个用于检测直立正面猫脸的开源JavaScript库。你可以在[http://harthur.github.io/kittydar/](http://harthur.github.io/kittydar/)找到其演示应用程序，在[https://github.com/harthur/kittydar](https://github.com/harthur/kittydar)找到其源代码。'
- en: 'Another detector for upright frontal cat faces was developed by Microsoft Research
    using the Microsoft Cat Dataset 2008\. The detector is described in the following
    research paper, but no demo application or source code has been released:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 微软研究院使用微软猫数据集2008开发了一个用于直立正面猫脸的检测器。该检测器在以下研究论文中描述，但没有发布演示应用程序或源代码：
- en: Weiwei Zhang, Jian Sun, and Xiaoou Tang. Cat Head Detection - How to Effectively
    Exploit Shape and Texture Features, *Proc. of European Conf. Computer Vision*,
    vol. 4, pp. 802-816, 2008.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 张伟伟，孙剑，唐晓鸥。猫头检测 - 如何有效地利用形状和纹理特征，*欧洲计算机视觉会议论文集*，第4卷，第802-816页，2008年。
- en: If you know of other work on cat detectors, recognizers, or datasets, please
    write to tell me about it!
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你知道有关猫检测器、识别器或数据集的其他工作，请写信告诉我！
- en: Summary
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Like the previous chapter, this chapter has dealt with classification tasks,
    as well as interfaces among OpenCV, a source of images, and a GUI. This time,
    our classification labels have more objective meanings (a species or an individual's
    identity), so the classifier's success or failure is more obvious. To meet the
    challenge, we used much bigger sets of training images, we preprocessed the training
    images for greater consistency, and we applied two tried-and-true classification
    techniques in sequence (either Haar cascades or LBP cascades for detection and
    then LBPH for recognition).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 像上一章一样，本章处理了分类任务，以及OpenCV（图像来源）、GUI之间的接口。这次，我们的分类标签具有更客观的含义（一个物种或个体的身份），因此分类器的成功或失败更为明显。为了应对这一挑战，我们使用了更大的训练图像集，我们对训练图像进行了预处理以增强一致性，并且依次应用了两种经过验证的分类技术（使用Haar级联或LBP级联进行检测，然后使用LBPH进行识别）。
- en: The methodology presented in this chapter, as well as the entire `Interactive
    Recognizer` app and some of the other code, generalizes well to other original
    work in detection and recognition. With the right training images, you could detect
    and recognize many more animals in many poses. You could even detect an object
    such as a car and recognize the Batmobile!
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中提出的这种方法，以及整个`Interactive Recognizer`应用程序和部分其他代码，在检测和识别的其他原创工作中具有很好的泛化能力。有了合适的训练图像，你可以在许多姿势中检测和识别出更多的动物。你甚至可以检测到像汽车这样的物体，并识别出蝙蝠车！
- en: For our next project, we turn our attention to a moving target, literally. We
    will try to detect a person who is in motion and then recognize particular gestures.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的下一个项目，我们将注意力转向一个移动的目标，字面上的移动目标。我们将尝试检测一个正在运动的人，然后识别特定的手势。
