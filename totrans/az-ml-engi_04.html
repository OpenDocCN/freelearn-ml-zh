<html><head></head><body>
<div id="_idContainer172">
<h1 class="chapter-number" id="_idParaDest-57"><a id="_idTextAnchor061"/><span class="koboSpan" id="kobo.1.1">4</span></h1>
<h1 id="_idParaDest-58"><a id="_idTextAnchor062"/><span class="koboSpan" id="kobo.2.1">Tuning Your Models with AMLS</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.3.1">Tuning your models</span></strong><span class="koboSpan" id="kobo.4.1"> is an </span><a id="_idIndexMarker295"/><span class="koboSpan" id="kobo.5.1">important step in your data science journey. </span><span class="koboSpan" id="kobo.5.2">The objective of a data science workload is to provide the best model on unseen data in the shortest duration of time. </span><span class="koboSpan" id="kobo.5.3">In order to provide a reliable model, not only are you required to tune the features that are the inputs to your model but you also need to tune the parameters of your model itself. </span><span class="koboSpan" id="kobo.5.4">Model parameters, also </span><a id="_idIndexMarker296"/><span class="koboSpan" id="kobo.6.1">known as </span><strong class="bold"><span class="koboSpan" id="kobo.7.1">hyperparameters</span></strong><span class="koboSpan" id="kobo.8.1">, can</span><a id="_idIndexMarker297"/><span class="koboSpan" id="kobo.9.1"> have a significant impact on the performance of your trained model. </span><span class="koboSpan" id="kobo.9.2">Tuning a model can take a lot of effort and involves trial and error. </span><span class="koboSpan" id="kobo.9.3">Several frameworks can be leveraged to automate this task. </span><span class="koboSpan" id="kobo.9.4">AMLS provides this functionality, which we will explore in this chapter. </span><span class="koboSpan" id="kobo.9.5">AMLS allows you to define model parameters that should be tuned to find the best model through the use of a special type of job referred to as a </span><strong class="bold"><span class="koboSpan" id="kobo.10.1">sweep job</span></strong><span class="koboSpan" id="kobo.11.1">. </span><span class="koboSpan" id="kobo.11.2">These </span><a id="_idIndexMarker298"/><span class="koboSpan" id="kobo.12.1">hyperparameters will be defined for a given AMLS job, and AMLS will run many trials and determine the best model for the hyperparameters within the range of possible </span><span class="No-Break"><span class="koboSpan" id="kobo.13.1">defined values.</span></span></p>
<p><span class="koboSpan" id="kobo.14.1">In this chapter, we will explore how AMLS enables hyperparameter tuning through a </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">sweep job.</span></span></p>
<p><span class="koboSpan" id="kobo.16.1">In this chapter, we will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.18.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">model parameters</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.20.1">Sampling hyperparameters</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">sweep jobs</span></span></li>
<li><span class="koboSpan" id="kobo.23.1">Setting up a sweep job with </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">grid sampling</span></span></li>
<li><span class="koboSpan" id="kobo.25.1">Setting up a sweep job with </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">random sampling</span></span></li>
<li><span class="koboSpan" id="kobo.27.1">Setting up a sweep job with </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">Bayesian sampling</span></span></li>
<li><span class="koboSpan" id="kobo.29.1">Reviewing the results of a </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">sweep job</span></span></li>
</ul>
<h1 id="_idParaDest-59"><a id="_idTextAnchor063"/><span class="koboSpan" id="kobo.31.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.32.1">In order to access your workspace, recall the steps from the </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">previous chapter:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.34.1">Go </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">to </span></span><a href="https://ml.azure.com"><span class="No-Break"><span class="koboSpan" id="kobo.36.1">https://ml.azure.com</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.37.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.38.1">Select your </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">workspace name.</span></span></li>
<li><span class="koboSpan" id="kobo.40.1">In the workspace </span><strong class="bold"><span class="koboSpan" id="kobo.41.1">user interface</span></strong><span class="koboSpan" id="kobo.42.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.43.1">UI</span></strong><span class="koboSpan" id="kobo.44.1">), on the left-hand side, click </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">on </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.46.1">Compute</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.48.1">On the </span><strong class="bold"><span class="koboSpan" id="kobo.49.1">Compute</span></strong><span class="koboSpan" id="kobo.50.1"> screen, select your compute instance and </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">select </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.52.1">Start</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer138">
<span class="koboSpan" id="kobo.54.1"><img alt="Figure 4.1 – Start compute" src="image/B18003_04_001.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.55.1">Figure 4.1 – Start compute</span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.56.1">Your compute instance will change from a </span><strong class="bold"><span class="koboSpan" id="kobo.57.1">Stopped</span></strong><span class="koboSpan" id="kobo.58.1"> status to a </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.59.1">Starting</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.60.1"> status.</span></span></li>
<li><span class="koboSpan" id="kobo.61.1">In the previous chapter, we cloned the Git repository – if you have not already done so, continue to follow the steps provided here. </span><span class="koboSpan" id="kobo.61.2">If you have already cloned the repository, skip to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.62.1">step 7</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.63.1">.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.64.1">Open the terminal on your compute instance. </span><span class="koboSpan" id="kobo.64.2">Note that the path will include your user in the directory. </span><span class="koboSpan" id="kobo.64.3">Type the following into the terminal to clone the sample notebooks into your </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">working directory:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.66.1">
git clone https://github.com/PacktPublishing/Azure-Machine-Learning-Engineering.git</span></pre>
<ol>
<li value="7"><span class="koboSpan" id="kobo.67.1">Clicking on the refresh icon shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.68.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.69.1">.2</span></em><span class="koboSpan" id="kobo.70.1"> will update and refresh the notebooks displayed on </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">your screen:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer139">
<span class="koboSpan" id="kobo.72.1"><img alt="Figure 4.2 – The refresh icon" src="image/B18003_04_002.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.73.1">Figure 4.2 – The refresh icon</span></p>
<ol>
<li value="8"><span class="koboSpan" id="kobo.74.1">Review the notebooks in your </span><strong class="source-inline"><span class="koboSpan" id="kobo.75.1">Azure-Machine-Learning-Engineering</span></strong><span class="koboSpan" id="kobo.76.1"> directory. </span><span class="koboSpan" id="kobo.76.2">This will display the files cloned into your working directory as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.77.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.78.1">.3</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.79.1">:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer140">
<span class="koboSpan" id="kobo.80.1"><img alt="Figure 4.3 – Azure-Machine-Learning-Engineering" src="image/B18003_04_003.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.81.1">Figure 4.3 – Azure-Machine-Learning-Engineering</span></p>
<h1 id="_idParaDest-60"><a id="_idTextAnchor064"/><span class="koboSpan" id="kobo.82.1">Understanding model parameters</span></h1>
<p><span class="koboSpan" id="kobo.83.1">In your data </span><a id="_idIndexMarker299"/><span class="koboSpan" id="kobo.84.1">science workload, as you define your features, you determine which parameters should be leveraged by your model. </span><span class="koboSpan" id="kobo.84.2">However, depending on the algorithm selected, you can control the training behavior by altering the parameters of the model itself – this is known </span><a id="_idIndexMarker300"/><span class="koboSpan" id="kobo.85.1">as </span><strong class="bold"><span class="koboSpan" id="kobo.86.1">hyperparameter tuning</span></strong><span class="koboSpan" id="kobo.87.1">. </span><span class="koboSpan" id="kobo.87.2">Using hyperparameter tuning, we can explore a variety of model parameters to identify the best model parameters to establish the best model result. </span><span class="koboSpan" id="kobo.87.3">To evaluate the model results, a </span><strong class="bold"><span class="koboSpan" id="kobo.88.1">primary metric</span></strong><span class="koboSpan" id="kobo.89.1"> is selected. </span><span class="koboSpan" id="kobo.89.2">A primary metric</span><a id="_idIndexMarker301"/><span class="koboSpan" id="kobo.90.1"> is defined as the key metric for evaluating the model. </span><span class="koboSpan" id="kobo.90.2">Every time a hyperparameter is changed, the primary metric will either go up or down in value and based on the primary metric, that will yield a better or </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">worse model.</span></span></p>
<p><span class="koboSpan" id="kobo.92.1">In this chapter, we will create a logistic regression model by leveraging </span><strong class="source-inline"><span class="koboSpan" id="kobo.93.1">sklearn</span></strong><span class="koboSpan" id="kobo.94.1">’s implementation of logistic regression with an </span><strong class="source-inline"><span class="koboSpan" id="kobo.95.1">sklearn</span></strong><span class="koboSpan" id="kobo.96.1"> pipeline. </span><span class="koboSpan" id="kobo.96.2">For a logistic regression model, there are several model parameters that we can tune to improve the performance of our model. </span><span class="koboSpan" id="kobo.96.3">For a logistic regression model, one parameter is the penalty term. </span><span class="koboSpan" id="kobo.96.4">Defining the penalty term as </span><strong class="source-inline"><span class="koboSpan" id="kobo.97.1">l2</span></strong><span class="koboSpan" id="kobo.98.1">, referred to as ridge regression, is used by the logistic regression estimator to apply a penalty to a model when the model is overly complex. </span><span class="koboSpan" id="kobo.98.2">This uses the </span><strong class="source-inline"><span class="koboSpan" id="kobo.99.1">l2</span></strong><span class="koboSpan" id="kobo.100.1"> normalization on the coefficients of your model as the penalty. </span><span class="koboSpan" id="kobo.100.2">Typically, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.101.1">l2</span></strong><span class="koboSpan" id="kobo.102.1"> normalization prevents the model from being overfitted by penalizing complex models. </span><span class="koboSpan" id="kobo.102.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.103.1">l2</span></strong><span class="koboSpan" id="kobo.104.1"> norm squares the model coefficients, sums them, and takes the square root of the value. </span><span class="koboSpan" id="kobo.104.2">When creating the model, we can select the </span><strong class="source-inline"><span class="koboSpan" id="kobo.105.1">l1</span></strong><span class="koboSpan" id="kobo.106.1"> norm, referred to as lasso regression, which would be the sum of the absolute value of the coefficients as penalty terms. </span><span class="koboSpan" id="kobo.106.2">Changing the code from leveraging a </span><strong class="source-inline"><span class="koboSpan" id="kobo.107.1">l2</span></strong><span class="koboSpan" id="kobo.108.1"> normalization penalty to a </span><strong class="source-inline"><span class="koboSpan" id="kobo.109.1">l1</span></strong><span class="koboSpan" id="kobo.110.1"> normalization penalty would leverage the technique of hyperparameter tuning or tuning our model parameters. </span><span class="koboSpan" id="kobo.110.2">If we were not going to rely on hyperparameter tuning to select the penalty term, we </span><a id="_idIndexMarker302"/><span class="koboSpan" id="kobo.111.1">would say that lasso regression generally performs better than ridge regression when few predictor variables are significant, and ridge regression generally performs better when there are many significant </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">predictor variables.</span></span></p>
<p><span class="koboSpan" id="kobo.113.1">In addition to the penalty term, we can also specify the value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.114.1">C</span></strong><span class="koboSpan" id="kobo.115.1">, which is the inverse of the regularization strength, as a hyperparameter to tune for </span><span class="No-Break"><span class="koboSpan" id="kobo.116.1">our model.</span></span></p>
<p><span class="koboSpan" id="kobo.117.1">The last hyperparameter we will tune is </span><strong class="source-inline"><span class="koboSpan" id="kobo.118.1">max_iter</span></strong><span class="koboSpan" id="kobo.119.1">, which is the maximum iterations that the solver can take before converging. </span><span class="koboSpan" id="kobo.119.2">As you consider the model parameters you would like to explore when building your model, you are defining the search space. </span><span class="koboSpan" id="kobo.119.3">The </span><strong class="bold"><span class="koboSpan" id="kobo.120.1">search space</span></strong><span class="koboSpan" id="kobo.121.1"> is a</span><a id="_idIndexMarker303"/><span class="koboSpan" id="kobo.122.1"> concept that defines the parameters and the range of values possible during </span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">hyperparameter tuning.</span></span></p>
<p><span class="koboSpan" id="kobo.124.1">Now that we have an understanding of hyperparameter tuning, and defining a search space, we will explore the method for selecting the combinations of model hyperparameters to leverage </span><a id="_idIndexMarker304"/><span class="koboSpan" id="kobo.125.1">within an AMLS job designed to tune these parameters, known as a </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.126.1">sweep job</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">.</span></span></p>
<h1 id="_idParaDest-61"><a id="_idTextAnchor065"/><span class="koboSpan" id="kobo.128.1">Sampling hyperparameters</span></h1>
<p><span class="koboSpan" id="kobo.129.1">Inside the search space, hyperparameters </span><a id="_idIndexMarker305"/><span class="koboSpan" id="kobo.130.1">are either continuous or discrete values. </span><span class="koboSpan" id="kobo.130.2">Continuous hyperparameters can be in a continuous range of values, while discrete hyperparameters are only able to use certain values. </span><span class="koboSpan" id="kobo.130.3">For logistic regression, the penalty term can have one of two discrete values: </span><strong class="source-inline"><span class="koboSpan" id="kobo.131.1">l1</span></strong><span class="koboSpan" id="kobo.132.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.133.1">l2</span></strong><span class="koboSpan" id="kobo.134.1">. </span><span class="koboSpan" id="kobo.134.2">AMLS can use either a list or a range for setting hyperparameters, as we will see when we dig into </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1">the code.</span></span></p>
<p><span class="koboSpan" id="kobo.136.1">For the hyperparameter of </span><strong class="source-inline"><span class="koboSpan" id="kobo.137.1">C</span></strong><span class="koboSpan" id="kobo.138.1">, we could define it as a discrete value, or we could define C to be a value in a continuous range with a </span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">specified distribution.</span></span></p>
<p><span class="koboSpan" id="kobo.140.1">For the </span><strong class="source-inline"><span class="koboSpan" id="kobo.141.1">max_iter</span></strong><span class="koboSpan" id="kobo.142.1"> hyperparameter, the default value for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.143.1">sklearn</span></strong><span class="koboSpan" id="kobo.144.1"> logistic regression model is </span><strong class="source-inline"><span class="koboSpan" id="kobo.145.1">100</span></strong><span class="koboSpan" id="kobo.146.1">. </span><span class="koboSpan" id="kobo.146.2">We could set this to a discrete value such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.147.1">penality_term</span></strong><span class="koboSpan" id="kobo.148.1">, or a uniform value such </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">as </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.150.1">C</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.152.1">The following code shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.153.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.154.1">.4</span></em><span class="koboSpan" id="kobo.155.1"> defines the search space for the penalty term, the inverse regularization strength of the model, and the maximum iterations as choices, which are discrete values for a defined </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">job command:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer141">
<span class="koboSpan" id="kobo.157.1"><img alt="Figure 4.4 – Defining the search space" src="image/B18003_04_004.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.158.1">Figure 4.4 – Defining the search space</span></p>
<p><span class="koboSpan" id="kobo.159.1">Once the search space has been defined, we can select what type of sampling we would like our sweep job to run. </span><span class="koboSpan" id="kobo.159.2">For each parameter defined in the search space, trials are created based on the sampled model hyperparameters. </span><span class="koboSpan" id="kobo.159.3">There are three types of sampling available with sweep jobs in AMLS: </span><strong class="bold"><span class="koboSpan" id="kobo.160.1">random</span></strong><span class="koboSpan" id="kobo.161.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.162.1">grid</span></strong><span class="koboSpan" id="kobo.163.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">and </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.165.1">Bayesian</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.166.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.167.1">Grid sampling</span><a id="_idIndexMarker306"/><span class="koboSpan" id="kobo.168.1"> will create a trial per hyperparameter combination. </span><span class="koboSpan" id="kobo.168.2">As an example, if we had specified our search space to check for </span><strong class="source-inline"><span class="koboSpan" id="kobo.169.1">l1</span></strong><span class="koboSpan" id="kobo.170.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.171.1">l2</span></strong><span class="koboSpan" id="kobo.172.1">, and we selected </span><strong class="source-inline"><span class="koboSpan" id="kobo.173.1">C</span></strong><span class="koboSpan" id="kobo.174.1"> to be discrete values of </span><strong class="source-inline"><span class="koboSpan" id="kobo.175.1">0.01</span></strong><span class="koboSpan" id="kobo.176.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.177.1">.1</span></strong><span class="koboSpan" id="kobo.178.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.179.1">1</span></strong><span class="koboSpan" id="kobo.180.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.181.1">10</span></strong><span class="koboSpan" id="kobo.182.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.183.1">max_iter</span></strong><span class="koboSpan" id="kobo.184.1"> to be </span><strong class="source-inline"><span class="koboSpan" id="kobo.185.1">10</span></strong><span class="koboSpan" id="kobo.186.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.187.1">100</span></strong><span class="koboSpan" id="kobo.188.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.189.1">150</span></strong><span class="koboSpan" id="kobo.190.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.191.1">200</span></strong><span class="koboSpan" id="kobo.192.1">, then there would be </span><strong class="source-inline"><span class="koboSpan" id="kobo.193.1">2x4x4=32</span></strong><span class="koboSpan" id="kobo.194.1"> trials created. </span><span class="koboSpan" id="kobo.194.2">Given grid sampling will create a trial per hyperparameter combination, grid sampling only supports </span><span class="No-Break"><span class="koboSpan" id="kobo.195.1">discrete hyperparameters.</span></span></p>
<p><span class="koboSpan" id="kobo.196.1">When leveraging random sampling, the </span><a id="_idIndexMarker307"/><span class="koboSpan" id="kobo.197.1">hyperparameter values are randomly selected during </span><span class="No-Break"><span class="koboSpan" id="kobo.198.1">the trials.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.199.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.200.1">.5</span></em><span class="koboSpan" id="kobo.201.1"> shows the hyperparameters defined in the search space here for both discrete and continuous values. </span><span class="koboSpan" id="kobo.201.2">In this code, the value for </span><strong class="source-inline"><span class="koboSpan" id="kobo.202.1">C</span></strong><span class="koboSpan" id="kobo.203.1"> follows a uniform distribution between values of </span><strong class="source-inline"><span class="koboSpan" id="kobo.204.1">0.01</span></strong><span class="koboSpan" id="kobo.205.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.206.1">10</span></strong><span class="koboSpan" id="kobo.207.1"> for a defined job command, which shows how we can define </span><strong class="source-inline"><span class="koboSpan" id="kobo.208.1">C</span></strong><span class="koboSpan" id="kobo.209.1"> as a continuous value, as opposed to with the grid job, when </span><strong class="source-inline"><span class="koboSpan" id="kobo.210.1">C</span></strong><span class="koboSpan" id="kobo.211.1"> was defined as a value from a list as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.212.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.213.1">.5</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer142">
<span class="koboSpan" id="kobo.215.1"><img alt="Figure 4.5 – Discrete and continuous hyperparameters" src="image/B18003_04_005.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.216.1">Figure 4.5 – Discrete and continuous hyperparameters</span></p>
<p><span class="koboSpan" id="kobo.217.1">In the preceding example, since </span><strong class="source-inline"><span class="koboSpan" id="kobo.218.1">C</span></strong><span class="koboSpan" id="kobo.219.1"> is a continuous hyperparameter, we are not able to leverage grid sampling, but we can leverage either random or </span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">Bayesian sampling.</span></span></p>
<p><span class="koboSpan" id="kobo.221.1">Bayesian sampling</span><a id="_idIndexMarker308"/><span class="koboSpan" id="kobo.222.1"> leverages the output on the primary metric of the previous trial to determine the next set of hyperparameters </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">to run.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.224.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.225.1">Grid space sampling does not support continuous hyperparameters – it will only support choice hyperparameters containing </span><span class="No-Break"><span class="koboSpan" id="kobo.226.1">discrete values.</span></span></p>
<p><span class="koboSpan" id="kobo.227.1">Given that hyperparameters</span><a id="_idIndexMarker309"/><span class="koboSpan" id="kobo.228.1"> can be discrete or continuous, we will define how exhaustive the search on the grid space should be and, importantly, how to end a job that is searching across a search space to provide the best primary metric for a given model. </span><span class="koboSpan" id="kobo.228.2">In the next section, we will explore how to set up our job to effectively and efficiently search for the </span><span class="No-Break"><span class="koboSpan" id="kobo.229.1">best hyperparameters.</span></span></p>
<h1 id="_idParaDest-62"><a id="_idTextAnchor066"/><span class="koboSpan" id="kobo.230.1">Understanding sweep jobs</span></h1>
<p><span class="koboSpan" id="kobo.231.1">Sweep jobs </span><a id="_idIndexMarker310"/><span class="koboSpan" id="kobo.232.1">in AMLS enable a data scientist to define the hyperparameters to explore in a single job. </span><span class="koboSpan" id="kobo.232.2">During the job, this will automate the task of searching for the hyperparameters that will provide a model with the best results for the primary metric-creating trials. </span><span class="koboSpan" id="kobo.232.3">In a run of a job, multiple trials are created and evaluated for the hyperparameters that are defined within the search space based on the sampling method selected. </span><span class="koboSpan" id="kobo.232.4">By defining the search space, we can create a single run of a job for testing multiple hypotheses at a single time rather than re-writing code and re-running jobs, reducing the time spent exploring the </span><span class="No-Break"><span class="koboSpan" id="kobo.233.1">search space.</span></span></p>
<p><span class="koboSpan" id="kobo.234.1">To leverage the hyperparameters in your job, your code needs to be updated to leverage these new parameters by passing them into your code through the Python </span><strong class="source-inline"><span class="koboSpan" id="kobo.235.1">ArgumentParser</span></strong><span class="koboSpan" id="kobo.236.1"> shown </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer143">
<span class="koboSpan" id="kobo.238.1"><img alt="Figure 4.6 – Passing a parameter list into the job" src="image/B18003_04_006.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.239.1">Figure 4.6 – Passing a parameter list into the job</span></p>
<p><span class="koboSpan" id="kobo.240.1">Now that the arguments have been passed into the main function, they can be leveraged in the model training script by passing them into the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.241.1">model_train</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.242.1"> function.</span></span></p>
<p><span class="koboSpan" id="kobo.243.1">Here’s the code for passing parameters into the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.244.1">model_train</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.245.1"> function:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer144">
<span class="koboSpan" id="kobo.246.1"><img alt="Figure 4.7 – Passing parameters for model training" src="image/B18003_04_007.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.247.1">Figure 4.7 – Passing parameters for model training</span></p>
<p><span class="koboSpan" id="kobo.248.1">In the </span><strong class="source-inline"><span class="koboSpan" id="kobo.249.1">model_train</span></strong><span class="koboSpan" id="kobo.250.1"> function, you can leverage the hyperparameters as you build the logistic </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">regression model.</span></span></p>
<p><span class="koboSpan" id="kobo.252.1">Here’s the code for </span><a id="_idIndexMarker311"/><span class="koboSpan" id="kobo.253.1">passing parameters into the logistic </span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">regression model:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer145">
<span class="koboSpan" id="kobo.255.1"><img alt="Figure 4.8 – Leveraging hyperparameters" src="image/B18003_04_008.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.256.1">Figure 4.8 – Leveraging hyperparameters</span></p>
<p><span class="koboSpan" id="kobo.257.1">As with all AML SDK v2 jobs, a sweep job is defined initially as a </span><strong class="source-inline"><span class="koboSpan" id="kobo.258.1">job</span></strong><span class="koboSpan" id="kobo.259.1"> command. </span><span class="koboSpan" id="kobo.259.2">In the job command, you specify the code, the location of the file, the command with its parameters, inputs, the environment, the compute, and a display name, but for the sweep job, we also specify the hyperparameters as we saw in </span><em class="italic"><span class="koboSpan" id="kobo.260.1">Figures 4.4 </span></em><span class="No-Break"><span class="koboSpan" id="kobo.261.1">and</span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.262.1"> 4.5</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.263.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.264.1">Once the job command is updated to include the hyperparameters, you can specify the sweep parameters for the command. </span><span class="koboSpan" id="kobo.264.2">In the sweep method, you specify the compute that you are going to leverage, the sampling algorithm, the primary metric, and the goal. </span><span class="koboSpan" id="kobo.264.3">The sampling algorithm can be set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.265.1">random</span></strong><span class="koboSpan" id="kobo.266.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.267.1">bayesian</span></strong><span class="koboSpan" id="kobo.268.1">, or </span><strong class="source-inline"><span class="koboSpan" id="kobo.269.1">grid</span></strong><span class="koboSpan" id="kobo.270.1"> as discussed earlier. </span><span class="koboSpan" id="kobo.270.2">The primary metric is the metric that is required to be logged in the job that you would like to evaluate the trials against. </span><span class="koboSpan" id="kobo.270.3">The goal specifies how you would like the primary metric to be evaluated. </span><span class="koboSpan" id="kobo.270.4">The goal can be to minimize or maximize the primary metric, which is used to judge your </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">model’s performance.</span></span></p>
<p><span class="koboSpan" id="kobo.272.1">The code for the </span><a id="_idIndexMarker312"/><span class="koboSpan" id="kobo.273.1">sweep of the job command is </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">shown here:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer146">
<span class="koboSpan" id="kobo.275.1"><img alt="Figure 4.9 – Setting the sweep parameters" src="image/B18003_04_009.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.276.1">Figure 4.9 – Setting the sweep parameters</span></p>
<p><span class="koboSpan" id="kobo.277.1">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.278.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.279.1">.9</span></em><span class="koboSpan" id="kobo.280.1"> here, you can see the values for sweep parameters being set. </span><span class="koboSpan" id="kobo.280.2">In this case, we will evaluate the </span><strong class="source-inline"><span class="koboSpan" id="kobo.281.1">test_AUC</span></strong><span class="koboSpan" id="kobo.282.1"> primary metric to be maximized by leveraging a grid sampling algorithm on the compute cluster </span><span class="No-Break"><span class="koboSpan" id="kobo.283.1">named </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.284.1">cpu-cluster</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.286.1">To set the limits for a sweep job, we specify the maximum total trials – </span><strong class="source-inline"><span class="koboSpan" id="kobo.287.1">max_total_trials</span></strong><span class="koboSpan" id="kobo.288.1"> – which defaults to </span><strong class="source-inline"><span class="koboSpan" id="kobo.289.1">1000</span></strong><span class="koboSpan" id="kobo.290.1">. </span><span class="koboSpan" id="kobo.290.2">The maximum concurrent trials – </span><strong class="source-inline"><span class="koboSpan" id="kobo.291.1">max_concurrent_trials</span></strong><span class="koboSpan" id="kobo.292.1"> – which defaults to the number specified by </span><strong class="source-inline"><span class="koboSpan" id="kobo.293.1">max_total_trials</span></strong><span class="koboSpan" id="kobo.294.1"> if not set, will specify how many concurrent trials should be run at any given time. </span><span class="koboSpan" id="kobo.294.2">An additional parameter to set is the timeout: </span><strong class="source-inline"><span class="koboSpan" id="kobo.295.1">timeout</span></strong><span class="koboSpan" id="kobo.296.1">. </span><span class="koboSpan" id="kobo.296.2">The timeout is in seconds. </span><span class="koboSpan" id="kobo.296.3">The timeout is for the entire sweep job, which defaults to a value </span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">of </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.298.1">100800</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer147">
<span class="koboSpan" id="kobo.300.1"><img alt="Figure 4.10 – Setting job limits for grid sampling" src="image/B18003_04_010.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.301.1">Figure 4.10 – Setting job limits for grid sampling</span></p>
<p><span class="koboSpan" id="kobo.302.1">Note that in the grid sampling experiment explored in this chapter, the maximum number of total runs is actually 32, but if we added additional choices as hyperparameters, setting the trial limits will ensure the job does not exceed a total number of 60 trials in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.303.1">Figure </span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.304.1">4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.305.1">.10</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.306.1"> here.</span></span></p>
<p><span class="koboSpan" id="kobo.307.1">With random sampling, hyperparameters are selected at random, so the job limit here will be very important to set. </span><span class="koboSpan" id="kobo.307.2">As stated, </span><strong class="source-inline"><span class="koboSpan" id="kobo.308.1">max_total_trials</span></strong><span class="koboSpan" id="kobo.309.1"> defaults to </span><strong class="source-inline"><span class="koboSpan" id="kobo.310.1">1000</span></strong><span class="koboSpan" id="kobo.311.1">, so we can see that running a job with </span><strong class="source-inline"><span class="koboSpan" id="kobo.312.1">max_total_trials</span></strong><span class="koboSpan" id="kobo.313.1"> equal to </span><strong class="source-inline"><span class="koboSpan" id="kobo.314.1">120</span></strong><span class="koboSpan" id="kobo.315.1"> will result in only </span><strong class="source-inline"><span class="koboSpan" id="kobo.316.1">120</span></strong><span class="koboSpan" id="kobo.317.1"> trials being created for a given </span><span class="No-Break"><span class="koboSpan" id="kobo.318.1">job run.</span></span></p>
<p><span class="koboSpan" id="kobo.319.1">Setting the </span><a id="_idIndexMarker313"/><span class="koboSpan" id="kobo.320.1">maximum limits of the sweep job is shown </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer148">
<span class="koboSpan" id="kobo.322.1"><img alt="Figure 4.11 – Setting job limits for random sampling" src="image/B18003_04_011.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.323.1">Figure 4.11 – Setting job limits for random sampling</span></p>
<p><span class="koboSpan" id="kobo.324.1">When leveraging Bayesian sampling, previous trial information is leveraged to determine the next parameters for which to search in the search space. </span><span class="koboSpan" id="kobo.324.2">With grid and random sampling, each trial is independent of other trials. </span><span class="koboSpan" id="kobo.324.3">Given each trial for grid sampling and random sampling is independent, once the primary metric has been determined in a given trial, if it will not yield the best model, there is no need for the code to continue running. </span><span class="koboSpan" id="kobo.324.4">These trials can be terminated early, so compute resources can be used for the next trial primary metric </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">evaluation instead.</span></span></p>
<p><span class="koboSpan" id="kobo.326.1">To enable early termination, AMLS sweep jobs incorporate the concept of an </span><strong class="bold"><span class="koboSpan" id="kobo.327.1">early termination policy</span></strong><span class="koboSpan" id="kobo.328.1">. </span><span class="koboSpan" id="kobo.328.2">An early termination policy will prematurely end a given trial after the primary metric is logged if the defined criteria are not met. </span><span class="koboSpan" id="kobo.328.3">For early termination, there are several policies that AMLS supports, including </span><strong class="bold"><span class="koboSpan" id="kobo.329.1">none</span></strong><span class="koboSpan" id="kobo.330.1">, a </span><strong class="bold"><span class="koboSpan" id="kobo.331.1">truncation</span></strong><span class="koboSpan" id="kobo.332.1"> selection policy, a </span><strong class="bold"><span class="koboSpan" id="kobo.333.1">median</span></strong><span class="koboSpan" id="kobo.334.1"> stopping policy, and a </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.335.1">bandit</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.336.1"> policy.</span></span></p>
<p><span class="koboSpan" id="kobo.337.1">If no early termination policy </span><a id="_idIndexMarker314"/><span class="koboSpan" id="kobo.338.1">is selected, the trial run will execute until completion – as explained earlier, this is required for Bayesian sampling. </span><span class="koboSpan" id="kobo.338.2">However, when grid or random sampling is leveraged, if a truncation policy is selected, AMLS will terminate trials based on the selected early </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">termination policy.</span></span></p>
<h2 id="_idParaDest-63"><a id="_idTextAnchor067"/><span class="koboSpan" id="kobo.340.1">Truncation policies</span></h2>
<p><span class="koboSpan" id="kobo.341.1">If a truncation policy is </span><a id="_idIndexMarker315"/><span class="koboSpan" id="kobo.342.1">selected, AMLS will cancel a percentage of the lowest-performing runs based on the value </span><span class="No-Break"><span class="koboSpan" id="kobo.343.1">in </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.344.1">truncation_percentage</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.345.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.346.1">The following is the sample code for an early termination policy that starts evaluations at an interval of </span><strong class="source-inline"><span class="koboSpan" id="kobo.347.1">1</span></strong><span class="koboSpan" id="kobo.348.1">, and terminates the lowest </span><strong class="source-inline"><span class="koboSpan" id="kobo.349.1">75</span></strong><span class="koboSpan" id="kobo.350.1">% of all trials using a </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">truncation policy:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer149">
<span class="koboSpan" id="kobo.352.1"><img alt="Figure 4.12 – Truncation early termination policy" src="image/B18003_04_012.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.353.1">Figure 4.12 – Truncation early termination policy</span></p>
<p><span class="koboSpan" id="kobo.354.1">When executing a sweep job with a truncation early termination policy, in the </span><strong class="bold"><span class="koboSpan" id="kobo.355.1">Overview</span></strong><span class="koboSpan" id="kobo.356.1"> tab in AMLS, you can review the policy on the </span><strong class="bold"><span class="koboSpan" id="kobo.357.1">Job Overview</span></strong><span class="koboSpan" id="kobo.358.1"> screen. </span><span class="koboSpan" id="kobo.358.2">Regardless of the early termination policy selected, it can be viewed on the </span><strong class="bold"><span class="koboSpan" id="kobo.359.1">Job</span></strong> <span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.360.1">Overview</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.361.1"> screen.</span></span></p>
<p><span class="koboSpan" id="kobo.362.1">An early termination policy is shown as follows in </span><span class="No-Break"><span class="koboSpan" id="kobo.363.1">the workspace:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer150">
<span class="koboSpan" id="kobo.364.1"><img alt="Figure 4.13 – Early termination policy for a sweep job" src="image/B18003_04_013.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.365.1">Figure 4.13 – Early termination policy for a sweep job</span></p>
<p><span class="koboSpan" id="kobo.366.1">In addition to a truncation policy, we can also set a median policy, which we will look </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">at next.</span></span></p>
<h2 id="_idParaDest-64"><a id="_idTextAnchor068"/><span class="koboSpan" id="kobo.368.1">Median policies</span></h2>
<p><span class="koboSpan" id="kobo.369.1">Another type of early termination</span><a id="_idIndexMarker316"/><span class="koboSpan" id="kobo.370.1"> policy is the median stopping policy. </span><span class="koboSpan" id="kobo.370.2">This policy will prematurely end trials based on the median value across all the training trials. </span><span class="koboSpan" id="kobo.370.3">If a given trial is worse than the median average, it will </span><span class="No-Break"><span class="koboSpan" id="kobo.371.1">be terminated.</span></span></p>
<p><span class="koboSpan" id="kobo.372.1">Here is the sample code for an early termination policy that starts evaluation at an interval of 2, and terminates any trial that is below the median of </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">all trials:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer151">
<span class="koboSpan" id="kobo.374.1"><img alt="Figure 4.14 – Median early termination policy" src="image/B18003_04_014.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.375.1">Figure 4.14 – Median early termination policy</span></p>
<h2 id="_idParaDest-65"><a id="_idTextAnchor069"/><span class="koboSpan" id="kobo.376.1">Bandit policies</span></h2>
<p><span class="koboSpan" id="kobo.377.1">An early termination policy known as the </span><a id="_idIndexMarker317"/><span class="koboSpan" id="kobo.378.1">bandit policy will end runs prematurely when the primary metric is not within a certain range of the current most successful trial. </span><span class="koboSpan" id="kobo.378.2">This range is defined by </span><strong class="source-inline"><span class="koboSpan" id="kobo.379.1">slack_factor</span></strong><span class="koboSpan" id="kobo.380.1">. </span><span class="koboSpan" id="kobo.380.2">At the time of evaluation, the best primary metric value is divided by (1+ </span><strong class="source-inline"><span class="koboSpan" id="kobo.381.1">slack_factor</span></strong><span class="koboSpan" id="kobo.382.1">), and if a trial does not have a primary metric that is better than that value, it will be terminated early. </span><span class="koboSpan" id="kobo.382.2">If a data scientist would prefer to set a value rather than setting a ratio with </span><strong class="source-inline"><span class="koboSpan" id="kobo.383.1">slack_factor</span></strong><span class="koboSpan" id="kobo.384.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.385.1">slack_amount</span></strong><span class="koboSpan" id="kobo.386.1"> can be </span><span class="No-Break"><span class="koboSpan" id="kobo.387.1">used instead:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer152">
<span class="koboSpan" id="kobo.388.1"><img alt="Figure 4.15 – Bandit early termination policy" src="image/B18003_04_015.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.389.1">Figure 4.15 – Bandit early termination policy</span></p>
<p><span class="koboSpan" id="kobo.390.1">To provide some context to the bandit policy, let us assume that the primary metric at the interval of </span><strong class="source-inline"><span class="koboSpan" id="kobo.391.1">2</span></strong><span class="koboSpan" id="kobo.392.1"> so far has the best metric of </span><strong class="source-inline"><span class="koboSpan" id="kobo.393.1">.85</span></strong><span class="koboSpan" id="kobo.394.1"> for our </span><strong class="source-inline"><span class="koboSpan" id="kobo.395.1">test_AUC</span></strong><span class="koboSpan" id="kobo.396.1">. </span><span class="koboSpan" id="kobo.396.2">In the example here, if the metric is below </span><strong class="source-inline"><span class="koboSpan" id="kobo.397.1">.85</span></strong><span class="koboSpan" id="kobo.398.1">/</span><strong class="source-inline"><span class="koboSpan" id="kobo.399.1">1.1</span></strong><span class="koboSpan" id="kobo.400.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.401.1">.773</span></strong><span class="koboSpan" id="kobo.402.1">, then it will </span><span class="No-Break"><span class="koboSpan" id="kobo.403.1">be terminated.</span></span></p>
<p><span class="koboSpan" id="kobo.404.1">As the training becomes increasingly complex, establishing the ability to terminate trials prematurely ensures that compute resources are not consumed when the desired result will ultimately not </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">be achieved.</span></span></p>
<p><span class="koboSpan" id="kobo.406.1">In the next section, we will explore setting up a sweep job that leverages grid sampling to determine the best </span><span class="No-Break"><span class="koboSpan" id="kobo.407.1">model hyperparameters.</span></span></p>
<h1 id="_idParaDest-66"><a id="_idTextAnchor070"/><span class="koboSpan" id="kobo.408.1">Setting up a sweep job with grid sampling</span></h1>
<p><span class="koboSpan" id="kobo.409.1">Earlier in the chapter, we </span><a id="_idIndexMarker318"/><span class="koboSpan" id="kobo.410.1">cloned our sample notebook to leverage </span><a id="_idIndexMarker319"/><span class="koboSpan" id="kobo.411.1">this material. </span><span class="koboSpan" id="kobo.411.2">The notebook for this chapter, </span><strong class="source-inline"><span class="koboSpan" id="kobo.412.1">'</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.413.1">Chapter 4</span></strong></span><strong class="source-inline"><span class="koboSpan" id="kobo.414.1"> - Hyperparameter Tuning'</span></strong><span class="koboSpan" id="kobo.415.1">, provides a review on creating a job command to create a logistic regression model by leveraging an </span><strong class="source-inline"><span class="koboSpan" id="kobo.416.1">sklearn</span></strong><span class="koboSpan" id="kobo.417.1"> pipeline and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.418.1">mlflow</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.419.1"> capabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.420.1">The code is then updated and placed into a new directory – the </span><strong class="source-inline"><span class="koboSpan" id="kobo.421.1">hyperparametertune</span></strong><span class="koboSpan" id="kobo.422.1"> folder. </span><span class="koboSpan" id="kobo.422.2">The code leverages python’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.423.1">argparse</span></strong><span class="koboSpan" id="kobo.424.1"> module, which enables you to pass parameters into scripts. </span><span class="koboSpan" id="kobo.424.2">To run the script that has been generated by this notebook, we will create a job command and update the job command to include the hyperparameters as shown in the following </span><span class="No-Break"><span class="koboSpan" id="kobo.425.1">code snippet:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer153">
<span class="koboSpan" id="kobo.426.1"><img alt="Figure 4.16 – Job sweep command with hyperparameters for grid sampling" src="image/B18003_04_016.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.427.1">Figure 4.16 – Job sweep command with hyperparameters for grid sampling</span></p>
<p><span class="koboSpan" id="kobo.428.1">Note that the hyperparameters have been included as inputs to the command, but their values are added to the command in line 22 in the preceding figure. </span><span class="koboSpan" id="kobo.428.2">This could have been done as a single command, but for illustrative purposes, it is provided separately as an update </span><span class="No-Break"><span class="koboSpan" id="kobo.429.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.430.1">grid_sampling_job_command</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.431.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.432.1">Once the </span><a id="_idIndexMarker320"/><span class="koboSpan" id="kobo.433.1">command is prepared, we call the sweep </span><a id="_idIndexMarker321"/><span class="koboSpan" id="kobo.434.1">method providing the compute, the sampling algorithm, the primary metric, and the goal. </span><span class="koboSpan" id="kobo.434.2">Recall that here we will expect to see 32 runs, so setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.435.1">max_total_trials</span></strong><span class="koboSpan" id="kobo.436.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.437.1">60</span></strong><span class="koboSpan" id="kobo.438.1"> will not be a hit, but if we were to update the hyperparameters to include more choices, we could </span><span class="No-Break"><span class="koboSpan" id="kobo.439.1">hit </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.440.1">max_total_trials</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.441.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer154">
<span class="koboSpan" id="kobo.442.1"><img alt="Figure 4.17 – Calling the sweep method during grid sampling" src="image/B18003_04_017.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.443.1">Figure 4.17 – Calling the sweep method during grid sampling</span></p>
<p><span class="koboSpan" id="kobo.444.1">Later in the</span><a id="_idIndexMarker322"/><span class="koboSpan" id="kobo.445.1"> notebook when we look at random </span><a id="_idIndexMarker323"/><span class="koboSpan" id="kobo.446.1">sampling and Bayesian sampling, we will define the value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.447.1">C</span></strong><span class="koboSpan" id="kobo.448.1"> as a continuous value – however, to leverage grid sampling, we have defined it to be a choice, which is a list of </span><span class="No-Break"><span class="koboSpan" id="kobo.449.1">discrete values.</span></span></p>
<p><span class="koboSpan" id="kobo.450.1">To submit </span><strong class="source-inline"><span class="koboSpan" id="kobo.451.1">grid_sweep_job</span></strong><span class="koboSpan" id="kobo.452.1">, we pass the command to </span><strong class="source-inline"><span class="koboSpan" id="kobo.453.1">ml_client</span></strong><span class="koboSpan" id="kobo.454.1">, which was created to manage the connection </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">to AMLS:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer155">
<span class="koboSpan" id="kobo.456.1"><img alt="Figure 4.18 – Running the sweep job" src="image/B18003_04_018.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.457.1">Figure 4.18 – Running the sweep job</span></p>
<p><span class="koboSpan" id="kobo.458.1">As the sweep job is executing, it can be helpful to get the status of the running job. </span><span class="koboSpan" id="kobo.458.2">Given we are leveraging </span><strong class="source-inline"><span class="koboSpan" id="kobo.459.1">mlflow</span></strong><span class="koboSpan" id="kobo.460.1"> to log the metrics of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.461.1">sklearn</span></strong><span class="koboSpan" id="kobo.462.1"> model, we can request all trials for a given parent </span><strong class="source-inline"><span class="koboSpan" id="kobo.463.1">run_id</span></strong><span class="koboSpan" id="kobo.464.1"> value, which is the run </span><span class="No-Break"><span class="koboSpan" id="kobo.465.1">for </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.466.1">grid_sweep_job</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.468.1">In the following code snippet, we pass in our </span><strong class="source-inline"><span class="koboSpan" id="kobo.469.1">experiment_</span><a id="_idTextAnchor071"/><span class="koboSpan" id="kobo.470.1">id</span></strong><span class="koboSpan" id="kobo.471.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.472.1">run_id</span></strong><span class="koboSpan" id="kobo.473.1"> values and get back the </span><span class="No-Break"><span class="koboSpan" id="kobo.474.1">job status:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer156">
<span class="koboSpan" id="kobo.475.1"><img alt="Figure 4.19 – Getting the status of the sweep job" src="image/B18003_04_019.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.476.1">Figure 4.19 – Getting the status of the sweep job</span></p>
<p><span class="koboSpan" id="kobo.477.1">We search across the run for a given </span><strong class="source-inline"><span class="koboSpan" id="kobo.478.1">experiment_id</span></strong><span class="koboSpan" id="kobo.479.1"> value. </span><span class="koboSpan" id="kobo.479.2">Our </span><strong class="source-inline"><span class="koboSpan" id="kobo.480.1">experiment_id</span></strong><span class="koboSpan" id="kobo.481.1"> value will be </span><strong class="source-inline"><span class="koboSpan" id="kobo.482.1">'chapter4'</span></strong><span class="koboSpan" id="kobo.483.1">, so we request all runs that have been made for </span><strong class="source-inline"><span class="koboSpan" id="kobo.484.1">'chapter4'</span></strong><span class="koboSpan" id="kobo.485.1"> and further refine that list based on </span><strong class="source-inline"><span class="koboSpan" id="kobo.486.1">tags.mlflow.parentRunId</span></strong><span class="koboSpan" id="kobo.487.1">, which is the </span><strong class="source-inline"><span class="koboSpan" id="kobo.488.1">run_id</span></strong><span class="koboSpan" id="kobo.489.1"> value associated with the grid sampling run. </span><span class="koboSpan" id="kobo.489.2">In line 3 of </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.490.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.491.1">.19</span></em><span class="koboSpan" id="kobo.492.1">, we request runs that have a </span><strong class="source-inline"><span class="koboSpan" id="kobo.493.1">run_id</span></strong><span class="koboSpan" id="kobo.494.1"> value associated with the run of the grid sweep job. </span><span class="koboSpan" id="kobo.494.2">If we get back a value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.495.1">0</span></strong><span class="koboSpan" id="kobo.496.1">, then we know that we have to wait for the run to be established in AMLS. </span><span class="koboSpan" id="kobo.496.2">Once there are runs provided, we move on to the next </span><strong class="source-inline"><span class="koboSpan" id="kobo.497.1">while</span></strong><span class="koboSpan" id="kobo.498.1"> loop, where we are checking whether all the runs have been completed. </span><span class="koboSpan" id="kobo.498.2">Once all the runs are completed</span><a id="_idIndexMarker324"/><span class="koboSpan" id="kobo.499.1"> for the grid sweep job, the message on line</span><a id="_idIndexMarker325"/><span class="koboSpan" id="kobo.500.1"> 24 will </span><span class="No-Break"><span class="koboSpan" id="kobo.501.1">be printed.</span></span></p>
<p><span class="koboSpan" id="kobo.502.1">Congratulations on leveraging a sweep job with grid sampling! </span><span class="koboSpan" id="kobo.502.2">Grid sampling works well when you have a search space that contains discrete values for your hyperparameters. </span><span class="koboSpan" id="kobo.502.3">Next, we will explore leveraging a sweep job with random sampling to enable use to explore continuous values for </span><span class="No-Break"><span class="koboSpan" id="kobo.503.1">our hyperparameters.</span></span></p>
<h1 id="_idParaDest-67"><a id="_idTextAnchor072"/><span class="koboSpan" id="kobo.504.1">Setting up a sweep job for random sampling</span></h1>
<p><span class="koboSpan" id="kobo.505.1">As we</span><a id="_idIndexMarker326"/><span class="koboSpan" id="kobo.506.1"> saw with setting up a command for </span><a id="_idIndexMarker327"/><span class="koboSpan" id="kobo.507.1">grid sampling, a command for random sampling is simply a job command with the hyperparameters included in the command. </span><span class="koboSpan" id="kobo.507.2">One difference between the </span><strong class="source-inline"><span class="koboSpan" id="kobo.508.1">grid</span></strong><span class="koboSpan" id="kobo.509.1"> command and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.510.1">random</span></strong><span class="koboSpan" id="kobo.511.1"> command is that the hyperparameters can be continuous in a random sampling </span><span class="No-Break"><span class="koboSpan" id="kobo.512.1">sweep job.</span></span></p>
<p><span class="koboSpan" id="kobo.513.1">Here’s the code for the job command for </span><span class="No-Break"><span class="koboSpan" id="kobo.514.1">random sampling:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer157">
<span class="koboSpan" id="kobo.515.1"><img alt="Figure 4.20 – Sweep job command with hyperparameters for random sampling" src="image/B18003_04_020.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.516.1">Figure 4.20 – Sweep job command with hyperparameters for random sampling</span></p>
<p><span class="koboSpan" id="kobo.517.1">As shown</span><a id="_idIndexMarker328"/><span class="koboSpan" id="kobo.518.1"> in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.519.1">Figure 4</span></em></span><em class="italic"><span class="koboSpan" id="kobo.520.1">.20</span></em><span class="koboSpan" id="kobo.521.1"> in line 25, the value </span><a id="_idIndexMarker329"/><span class="koboSpan" id="kobo.522.1">of </span><strong class="source-inline"><span class="koboSpan" id="kobo.523.1">C</span></strong><span class="koboSpan" id="kobo.524.1"> is defined to follow a uniform distribution from </span><strong class="source-inline"><span class="koboSpan" id="kobo.525.1">0.01</span></strong><span class="koboSpan" id="kobo.526.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.527.1">10.0</span></strong><span class="koboSpan" id="kobo.528.1">, making this a continuous hyperparameter across the </span><span class="No-Break"><span class="koboSpan" id="kobo.529.1">search space.</span></span></p>
<p><span class="koboSpan" id="kobo.530.1">Just as with the grid sampling sweep job, we set parameters for our sweep but specify them using a random sampling algorithm as </span><span class="No-Break"><span class="koboSpan" id="kobo.531.1">shown here:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer158">
<span class="koboSpan" id="kobo.532.1"><img alt="Figure 4.21 – Calling the sweep method during random sampling" src="image/B18003_04_021.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.533.1">Figure 4.21 – Calling the sweep method during random sampling</span></p>
<p><span class="koboSpan" id="kobo.534.1">Given the </span><a id="_idIndexMarker330"/><span class="koboSpan" id="kobo.535.1">parameters for the sweep job and the </span><a id="_idIndexMarker331"/><span class="koboSpan" id="kobo.536.1">limits have been set, we are ready to execute the sweep job. </span><span class="koboSpan" id="kobo.536.2">In order to execute the code, again we leverage an </span><strong class="source-inline"><span class="koboSpan" id="kobo.537.1">ml_client</span></strong><span class="koboSpan" id="kobo.538.1"> method to create or update a job as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.539.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.540.1">.18</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.541.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.542.1">Now you have gone through grid and random sampling, there is an additional type of hyperparameter sampling that can be applied, which we will look </span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">at next.</span></span></p>
<h1 id="_idParaDest-68"><a id="_idTextAnchor073"/><span class="koboSpan" id="kobo.544.1">Setting up a sweep job for Bayesian sampling</span></h1>
<p><span class="koboSpan" id="kobo.545.1">Earlier in</span><a id="_idIndexMarker332"/><span class="koboSpan" id="kobo.546.1"> the chapter, we cloned our sample </span><a id="_idIndexMarker333"/><span class="koboSpan" id="kobo.547.1">notebook to leverage this material. </span><span class="koboSpan" id="kobo.547.2">The notebook for this chapter, </span><strong class="source-inline"><span class="koboSpan" id="kobo.548.1">'</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.549.1">Chapter 4</span></strong></span><strong class="source-inline"><span class="koboSpan" id="kobo.550.1"> - Hyperparameter Tuning'</span></strong><span class="koboSpan" id="kobo.551.1">, provides a review on creating a job command to create a </span><strong class="bold"><span class="koboSpan" id="kobo.552.1">logistic regression model</span></strong><span class="koboSpan" id="kobo.553.1"> by </span><a id="_idIndexMarker334"/><span class="koboSpan" id="kobo.554.1">leveraging an </span><strong class="source-inline"><span class="koboSpan" id="kobo.555.1">sklearn</span></strong><span class="koboSpan" id="kobo.556.1"> pipeline and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.557.1">mlflow</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.558.1"> capabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.559.1">The code is then updated and placed into a new directory – the </span><strong class="source-inline"><span class="koboSpan" id="kobo.560.1">hyperparametertune</span></strong><span class="koboSpan" id="kobo.561.1"> folder, which leverages Python’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.562.1">argparse</span></strong><span class="koboSpan" id="kobo.563.1"> module and enables you to pass parameters into scripts. </span><span class="koboSpan" id="kobo.563.2">To run the script that has been generated by this notebook, we will create a job command and update the job command to include the hyperparameters as shown in the code snippet here. </span><span class="koboSpan" id="kobo.563.3">Conveniently, the job command is the same as was found for the random sampling displayed in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.564.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.565.1">.16</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.566.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.567.1">The only difference here is that the sampling algorithm is defined as </span><strong class="source-inline"><span class="koboSpan" id="kobo.568.1">bayesian</span></strong><span class="koboSpan" id="kobo.569.1">, as shown in </span><span class="No-Break"><span class="koboSpan" id="kobo.570.1">the figure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer159">
<span class="koboSpan" id="kobo.571.1"><img alt="Figure 4.22 – Calling a sweep method using Bayesian sampling" src="image/B18003_04_022.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.572.1">Figure 4.22 – Calling a sweep method using Bayesian sampling</span></p>
<p><span class="koboSpan" id="kobo.573.1">In order to execute</span><a id="_idIndexMarker335"/><span class="koboSpan" id="kobo.574.1"> the code, again, we leverage the </span><strong class="source-inline"><span class="koboSpan" id="kobo.575.1">ml_client</span></strong><span class="koboSpan" id="kobo.576.1">’s method to create or update a job and continue by leveraging the </span><strong class="source-inline"><span class="koboSpan" id="kobo.577.1">get_job_status</span></strong><span class="koboSpan" id="kobo.578.1"> method as shown </span><a id="_idIndexMarker336"/><span class="koboSpan" id="kobo.579.1">in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.580.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.581.1">.19</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.582.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.583.1">You have now made it through grid, random, and Bayesian hyperparameter tuning job commands in AMLS. </span><span class="koboSpan" id="kobo.583.2">We will continue reviewing the results of the job </span><span class="No-Break"><span class="koboSpan" id="kobo.584.1">within AMLS.</span></span></p>
<h1 id="_idParaDest-69"><a id="_idTextAnchor074"/><span class="koboSpan" id="kobo.585.1">Reviewing results of a sweep job</span></h1>
<p><span class="koboSpan" id="kobo.586.1">Recall that for a </span><a id="_idIndexMarker337"/><span class="koboSpan" id="kobo.587.1">single trial of a sweep job, several trials will be created to determine the model that will provide the best primary metric. </span><span class="koboSpan" id="kobo.587.2">Clicking on </span><strong class="bold"><span class="koboSpan" id="kobo.588.1">jobs</span></strong><span class="koboSpan" id="kobo.589.1"> in the left-hand menu pane of your AMLS workspace will display a list of your jobs for review. </span><span class="koboSpan" id="kobo.589.2">By now, you have run the sample notebook provided for this chapter – let’s review </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">your results.</span></span></p>
<p><span class="koboSpan" id="kobo.591.1">Clicking on the </span><strong class="bold"><span class="koboSpan" id="kobo.592.1">chapter4</span></strong><span class="koboSpan" id="kobo.593.1"> job brings you to the jobs that you have performed as part of this chapter. </span><span class="koboSpan" id="kobo.593.2">Selecting the display name will drill into a given job’s details. </span><span class="koboSpan" id="kobo.593.3">Let us start by reviewing the results of the jobs that we have run as </span><span class="No-Break"><span class="koboSpan" id="kobo.594.1">shown here:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer160">
<span class="koboSpan" id="kobo.595.1"><img alt="Figure 4.23 – Job results" src="image/B18003_04_023.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.596.1">Figure 4.23 – Job results</span></p>
<p><span class="koboSpan" id="kobo.597.1">To review the results of the job, follow the </span><span class="No-Break"><span class="koboSpan" id="kobo.598.1">next steps:</span></span></p>
<ol>
<li value="1"><span class="koboSpan" id="kobo.599.1">Clicking on the </span><strong class="bold"><span class="koboSpan" id="kobo.600.1">Experiment</span></strong><span class="koboSpan" id="kobo.601.1"> name, </span><strong class="bold"><span class="koboSpan" id="kobo.602.1">Chapter04</span></strong><span class="koboSpan" id="kobo.603.1">, will bring us to the different job sweeps that have been performed as part of </span><span class="No-Break"><span class="koboSpan" id="kobo.604.1">this chapter.</span></span></li>
<li><span class="koboSpan" id="kobo.605.1">Clicking on a given run of your experiment will provide the details for a given job run as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.606.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.607.1">.24</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.608.1">:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer161">
<span class="koboSpan" id="kobo.609.1"><img alt="Figure 4.24 – Job sweep details" src="image/B18003_04_024.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.610.1">Figure 4.24 – Job sweep details</span></p>
<p><span class="koboSpan" id="kobo.611.1">Key information </span><a id="_idIndexMarker338"/><span class="koboSpan" id="kobo.612.1">was captured as metadata, providing traceability for a given job run. </span><span class="koboSpan" id="kobo.612.2">This information includes </span><span class="No-Break"><span class="koboSpan" id="kobo.613.1">the following:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.614.1">The </span><span class="No-Break"><span class="koboSpan" id="kobo.615.1">sampling policy</span></span></li>
<li><span class="koboSpan" id="kobo.616.1">The </span><span class="No-Break"><span class="koboSpan" id="kobo.617.1">parameter space</span></span></li>
<li><span class="koboSpan" id="kobo.618.1">The </span><span class="No-Break"><span class="koboSpan" id="kobo.619.1">primary metric</span></span></li>
<li><span class="koboSpan" id="kobo.620.1">The </span><span class="No-Break"><span class="koboSpan" id="kobo.621.1">best trial</span></span></li>
<li><span class="koboSpan" id="kobo.622.1">The number of </span><span class="No-Break"><span class="koboSpan" id="kobo.623.1">runs completed</span></span></li>
</ol>
<ol>
<li value="3"><span class="koboSpan" id="kobo.624.1">Clicking on the trial hyperlink from the run details brings up the trial with the best results for the selected </span><span class="No-Break"><span class="koboSpan" id="kobo.625.1">primary metric:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer162">
<span class="koboSpan" id="kobo.626.1"><img alt="Figure 4.25 – Best trial run" src="image/B18003_04_025.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.627.1">Figure 4.25 – Best trial run</span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.628.1">Clicking on </span><a id="_idIndexMarker339"/><span class="koboSpan" id="kobo.629.1">the </span><strong class="bold"><span class="koboSpan" id="kobo.630.1">Metrics</span></strong><span class="koboSpan" id="kobo.631.1"> tab for the best trial run provides the metrics for the evaluation of a </span><span class="No-Break"><span class="koboSpan" id="kobo.632.1">given trial:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer163">
<span class="koboSpan" id="kobo.633.1"><img alt="Figure 4.26 – Metrics for the best trial run of the sweep job" src="image/B18003_04_026.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.634.1">Figure 4.26 – Metrics for the best trial run of the sweep job</span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.635.1">To review all the trials created for a job run holistically, you can click on the job run and head over to the </span><strong class="bold"><span class="koboSpan" id="kobo.636.1">Trials</span></strong><span class="koboSpan" id="kobo.637.1"> tab as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.638.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.639.1">.27</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.640.1">:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer164">
<span class="koboSpan" id="kobo.641.1"><img alt="Figure 4.27 – Trial runs for a grid sampling sweep job" src="image/B18003_04_027.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.642.1">Figure 4.27 – Trial runs for a grid sampling sweep job</span></p>
<p><span class="koboSpan" id="kobo.643.1">Not only are you able to</span><a id="_idIndexMarker340"/><span class="koboSpan" id="kobo.644.1"> review each metric individually through the AMLS workspace UI for a given run of a job but you can also view a parallel coordinates chart, displaying how the different hyperparameters selected impacted the </span><span class="No-Break"><span class="koboSpan" id="kobo.645.1">primary metric.</span></span></p>
<p><span class="koboSpan" id="kobo.646.1">To review the search space and its impact on the primary metric, review the parallel coordinates chart in the </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.647.1">Trials</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.648.1"> tab:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer165">
<span class="koboSpan" id="kobo.649.1"><img alt="Figure 4.28 – Grid search space parallel coordinates chart" src="image/B18003_04_028.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.650.1">Figure 4.28 – Grid search space parallel coordinates chart</span></p>
<p><span class="koboSpan" id="kobo.651.1">In addition to the </span><a id="_idIndexMarker341"/><span class="koboSpan" id="kobo.652.1">parallel coordinates chart, AMLS provides a 2D scatter chart and a 3D scatter chart for evaluating </span><span class="No-Break"><span class="koboSpan" id="kobo.653.1">hyperparameter tuning.</span></span></p>
<p><span class="koboSpan" id="kobo.654.1">The 3D scatter chart for hyperparameter tuning is </span><span class="No-Break"><span class="koboSpan" id="kobo.655.1">shown here:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer166">
<span class="koboSpan" id="kobo.656.1"><img alt="Figure 4.29 – 3D scatter chart" src="image/B18003_04_029.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.657.1">Figure 4.29 – 3D scatter chart</span></p>
<p><span class="koboSpan" id="kobo.658.1">We have seen how to graphically view and compare models through charts in the AML Studio, but we are not limited to accessing this valuable information through </span><span class="No-Break"><span class="koboSpan" id="kobo.659.1">the UI.</span></span></p>
<p><span class="koboSpan" id="kobo.660.1">Not only are we able to retrieve the best trial of the sweep job through the AMLS Studio by reviewing results in the experiment tab but we are also able to access this information by leveraging the AMLS Python </span><span class="No-Break"><span class="koboSpan" id="kobo.661.1">SDK v2.</span></span></p>
<p><span class="koboSpan" id="kobo.662.1">Putting the results from the job run into a pandas DataFrame is shown </span><span class="No-Break"><span class="koboSpan" id="kobo.663.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer167">
<span class="koboSpan" id="kobo.664.1"><img alt="Figure 4.30 – Getting the job results into a pandas DataFrame" src="image/B18003_04_030.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.665.1">Figure 4.30 – Getting the job results into a pandas DataFrame</span></p>
<p><span class="koboSpan" id="kobo.666.1">At the end of the </span><a id="_idIndexMarker342"/><span class="koboSpan" id="kobo.667.1">notebook, we have included the code for returning a pandas DataFrame for the completed </span><span class="No-Break"><span class="koboSpan" id="kobo.668.1">job run:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer168">
<span class="koboSpan" id="kobo.669.1"><img alt="Figure 4.31 – Sorting the job trials to get the highest test_AUC for trials" src="image/B18003_04_031.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.670.1">Figure 4.31 – Sorting the job trials to get the highest test_AUC for trials</span></p>
<p><span class="koboSpan" id="kobo.671.1">Given we have the pandas DataFrame properly sorted by the primary metric, we can easily pull out the </span><strong class="source-inline"><span class="koboSpan" id="kobo.672.1">run_id</span></strong><span class="koboSpan" id="kobo.673.1"> value for the best trial run as </span><span class="No-Break"><span class="koboSpan" id="kobo.674.1">shown here:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer169">
<span class="koboSpan" id="kobo.675.1"><img alt="Figure 4.32 – Getting the best run_id value from the sorted pandas DataFrame" src="image/B18003_04_032.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.676.1">Figure 4.32 – Getting the best run_id value from the sorted pandas DataFrame</span></p>
<p><span class="koboSpan" id="kobo.677.1">Now that we have the best run retrieved into the </span><strong class="source-inline"><span class="koboSpan" id="kobo.678.1">best_run_id</span></strong><span class="koboSpan" id="kobo.679.1"> variable as shown here, we can leverage the best model from the </span><span class="No-Break"><span class="koboSpan" id="kobo.680.1">sweep job.</span></span></p>
<p><span class="koboSpan" id="kobo.681.1">Loading the model from the best sweep job trial is shown </span><span class="No-Break"><span class="koboSpan" id="kobo.682.1">as follows:</span></span></p>
<p class="IMG---Figure"><span class="koboSpan" id="kobo.683.1"><img alt="Figure 4.33 – Loading the best model" src="image/B18003_04_033.png"/></span></p>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.684.1">Figure 4.33 – Loading the best model</span></p>
<p><span class="koboSpan" id="kobo.685.1">Once the model has been loaded and given we are using the virtual environment that was used to create the model, we can carry out inference using the loaded model as </span><span class="No-Break"><span class="koboSpan" id="kobo.686.1">shown here:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer171">
<span class="koboSpan" id="kobo.687.1"><img alt="Figure 4.34 – Inference using the best model from the sweep job" src="image/B18003_04_034.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.688.1">Figure 4.34 – Inference using the best model from the sweep job</span></p>
<p><span class="koboSpan" id="kobo.689.1">Congratulations – you </span><a id="_idIndexMarker343"/><span class="koboSpan" id="kobo.690.1">have retrieved the best trial run for a given sweep job from the SDK v2! </span><span class="koboSpan" id="kobo.690.2">This run information can be viewed in the UI as well </span><span class="No-Break"><span class="koboSpan" id="kobo.691.1">as programmatically.</span></span></p>
<h1 id="_idParaDest-70"><a id="_idTextAnchor075"/><span class="koboSpan" id="kobo.692.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.693.1">In this chapter, we have explored what model parameters are and how a sweep job can be leveraged to tune hyperparameters that are defined for a given model. </span><span class="koboSpan" id="kobo.693.2">We have also explored options for setting up sweep jobs based on the search space and sampling methodology selected. </span><span class="koboSpan" id="kobo.693.3">AMLS provides the ability to sweep across the search space to tune a model, automating the process of hyperparameter tuning on a compute cluster, which will shut itself down in the idle period after the trials are completed, consuming compute </span><span class="No-Break"><span class="koboSpan" id="kobo.694.1">resources wisely.</span></span></p>
<p><span class="koboSpan" id="kobo.695.1">In addition to setting up a sweep job, you have been able to review your results in the Studio as well as in the code – providing intuitive insight into the best-performing model for your use case. </span><span class="koboSpan" id="kobo.695.2">Now that you have completed the chapter, be sure to turn off your compute resources to </span><span class="No-Break"><span class="koboSpan" id="kobo.696.1">save cost.</span></span></p>
<p><span class="koboSpan" id="kobo.697.1">In the next chapter, we will show you how to leverage AMLS to take over the time-consuming task of model development. </span><span class="koboSpan" id="kobo.697.2">This functionality is not only available through the SDK and the CLI, but in the AMLS Studio itself </span><span class="No-Break"><span class="koboSpan" id="kobo.698.1">as well.</span></span></p>
</div>
</body></html>