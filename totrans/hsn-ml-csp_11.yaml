- en: Microbenchmarking and Activation Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter we are going to learn the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What microbenchmarking is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to apply it to your code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What activation functions are
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to plot and benchmark activation functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every developer needs to have a good benchmarking tool at their disposal. Qualitative
    benchmarks are everywhere; you hear everyday, *We decreased this by 10% and increased
    that by 25%*. Remember the old adage, *When you hear a number thrown out, 98.4
    percent of the time that number is false*? By the way, I just made up that number
    as well. When you hear a quote like that, ask that person to prove it and what
    do you get? Task manager perhaps? As data scientists, we don't need qualitative
    results; we need quantitative results that can be proven and consistently replicated.
    Reproducible results are incredibly important, not only for consistency but also
    for credibility and accuracy. And that's where microbenchmarking comes in to play.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to use the irreplaceable `BenchmarkDotNet` library, which you
    can find here: [https://github.com/dotnet/BenchmarkDotNet](https://github.com/dotnet/BenchmarkDotNet).'
  prefs: []
  type: TYPE_NORMAL
- en: If you are not already using this library, you need to drop what you are doing
    right now and install it. I consider it one of the most irreplaceable frameworks
    you can use, and I consider it in terms of importance, right up there with unit
    and integration testing.
  prefs: []
  type: TYPE_NORMAL
- en: To show you just how valuable this tool is, we are going to plot several activation
    functions and compare their runtimes. As part of this, we will consider **warmup**,
    **legacy** and **RyuJIT**, **cold starting**, and more aspects of a program execution.
    In the end, we will have a quantitative set of results that prove the exact measurements
    of our functions. If, say in release 2.0, we see that something is running slower,
    we can rerun the benchmarks and compare.
  prefs: []
  type: TYPE_NORMAL
- en: I would strongly recommend that this be integrated into your continuous integration/continuous
    build process so that at each release, you have benchmark numbers to compare.
    And that's not just our code. I have created massive CI/CD systems that encompassed
    a huge number of programs, microservices, environments, and build and deploy steps.
    We would also regularly benchmark certain .NET library functions that we use all
    the time to verify; in between .NET framework releases, nothing has changed.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to have two samples. The first is an activation
    function viewer; it will plot each activation function so that you can see how
    it looks. You can find this as part of what I consider one of the most valuable
    open source programs, **SharpNEAT**, by Mr. Colin Green. This package is absolutely
    incredible, and there's not a day that goes by when I don't use it. I have created
    new UIs on top of it as well as advanced versions to work with my requirements,
    and it's as flexible a tool as you can find. I work daily with researching the
    integration of mirror and canonical neurons into extendable substrates, and tools
    such as SharpNEAT are incredible. A future advanced book will be highlighting
    SharpNEAT much more, so get familiar with it now! This first sample application
    is available with the latest SharpNEAT package, which can be found at [https://github.com/colgreen/sharpneat](https://github.com/colgreen/sharpneat).
  prefs: []
  type: TYPE_NORMAL
- en: Visual activation function plotting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here is a plot of local and global minimum being plotted from a custom version
    of SharpNEAT. It is absolutely amazing what you can do with this product in the
    realm of neural networks and advanced machine learning!
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5e1b0cd5-63fd-4651-8f0e-96b9b2fb805a.png)'
  prefs: []
  type: TYPE_IMG
- en: As I mentioned, we are going to plot and then benchmark several activation functions.
    We hear this term **activation functions** everywhere, but do we really know what
    it means? Let's start by giving a quick explanation just in case you are not familiar.
  prefs: []
  type: TYPE_NORMAL
- en: An activation function is used to decide whether a neuron has been activated
    or not. Some people like to replace the word **activated** with **fired**. Whatever
    flips your pickle! Either way, it's what finally determines whether something
    is on or off, fired or not, activated or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by showing you what a plot of a single activation function looks
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/25824019-1323-4dd5-bc88-242fec67a72d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is what the **Logistic Steep** approximation and **Swish activation**
    function look like when they are plotted individually, as there are many types
    of activation functions, here''s what all of our activation functions are going
    to look like when they are plotted together:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c96dcb6-1fe0-4351-a348-8c4f8696d16a.png)'
  prefs: []
  type: TYPE_IMG
- en: At this point you may be wondering, *Why do we even care what the plots look
    like?* Great question. We care because you are going to use these quite a bit
    once you progress into neural networks and beyond. It's very handy to be able
    to know whether your activation function will place the value of your neuron in
    on or off state, and what range it will keep or need the values in. You will no
    doubt encounter and/or use activation functions in your career as a machine learning
    developer, and knowing the difference between a `TanH` and a `LeakyReLU` activation
    function is very important.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting all functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The plotting of all the activation functions is done within a single function,
    remarkably titled `PlotAllFunctions`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The main Plot function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Behind the scenes, the `Plot` function is what is responsible for executing
    and plotting each function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The main point of interest within this code is highlighted in yellow. This is
    where the activation function that we passed in is executed and its value used
    for the *y* axis plot value. The famous **ZedGraph** open source plotting package
    is used for all graph plotting. Once each function is executed, the respective
    plot will be made.
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`BenchmarkDotNet` produces several reports, one of which is an HTML report
    similar to what you see here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ec9f37e5-485d-4bd9-8ef2-4038279fb496.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Excel report provides the details of every parameter that was used in running
    the program and is your most extensive source of information. In many cases, most
    of these parameters will use the default values and be more than you need, but
    at least you will have the choice to remove what you will:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c10d791-352d-4762-b01a-5a1cb00b301f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We''ll describe some of these parameters in our next section when we review
    the source code for creating what you see before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Let's dissect this code a bit more.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin with, we''ll create a manual configuration object that will hold our
    configuration parameters used for benchmarking:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll set up an exporter to hold the parameters we will use for exporting
    our results. We will export our results to a `.csv` file using a timing of microseconds
    and size in kilobytes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll create a benchmark job that will handle the measurements of the
    `LegacyJitX64` on the x64 architecture. You can feel free to change this and any
    other parameter to experiment with or include whatever results you need or want
    for your test scenario. In our case, we will be using the x64 platform; a `LaunchCount`,
    `WarmupCount`, and `TargetCount` of `1`; and `RunStrategy` of `Throughput`. We
    will also do the same for RyuJIT but we won''t show the code here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will run `BenchmarkRunner` to perform our tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '`BenchmarkDotNet` will run as a DOS command-line application, and the following
    is an example of the preceding code executing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28a6f0cd-5d8e-4b78-8b07-7dc8ce300724.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a look at one example of an activation function being plotted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You will notice the `[Benchmark]` attribute being used. This indicates to `BenchmarkDotNet`
    that this will be a test that needs to be benchmarked. Internally, it calls the
    following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1adf0073-45d7-40cc-b866-71f13c747239.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For the `LogisticFunctionSteep` function, the implementation, like most activation
    functions, is simple (assuming you know the formula). In this case we are not
    plotting the activation function but rather benchmarking it. You will notice that
    the function takes and returns `double`. We have also benchmarked the identical
    function by using and returning `float` variables, so we are benchmarking the
    difference between the function using `double` and `float`. Hence, people can
    see that sometimes the performance impact is more than they may think:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c3dca76d-77f9-493f-b81c-2306673f2fd8.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we learned about applying microbenchmarking to your code. We
    also saw how to plot and benchmark activation functions as well as use microbenchmarking
    with that as well. You now have one of the most powerful benchmarking libraries
    which you can add to all your code. In the next chapter, we are going to dive
    into Intuitive Deep Learning and show you one of the most powerful frameworks
    for machine learning testing available to a C# developer.
  prefs: []
  type: TYPE_NORMAL
