- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Exploring Data-Centric Machine Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据为中心的机器学习
- en: This chapter provides a foundational understanding of what data-centric **machine
    learning** (**ML**) is. We will also contrast data centricity with model centricity
    and compare the performance of the two approaches, using practical examples to
    illustrate key points. Through these practical examples, you will gain a strong
    appreciation for the potential of data centricity.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了对数据为中心的**机器学习**（ML）的基础理解。我们还将对比数据中心性与模型中心性，并比较两种方法的性能，使用实际例子来说明关键点。通过这些实际例子，你将深刻理解数据中心性的潜力。
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Understanding data-centric ML
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据为中心的机器学习
- en: Data-centric versus model-centric ML
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以数据为中心与以模型为中心的机器学习
- en: The importance of quality data in ML
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 质量数据在机器学习中的重要性
- en: Understanding data-centric ML
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解数据为中心的机器学习
- en: '**Data-centric ML** is the discipline of systematically engineering the data
    used to build ML and **artificial intelligence** (**AI**) systems1.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**以数据为中心的机器学习**是系统地构建机器学习和**人工智能**（AI）系统所使用数据的学科。'
- en: The data-centric AI and ML movement is grounded in the philosophy that data
    quality is more important than data volume when it comes to building highly informative
    models. Put another way, it is possible to achieve more with a small but high-quality
    dataset than with a large but noisy dataset. For most ML use cases, it is not
    feasible to build models based on very large datasets, say millions of observations,
    simply because the volume of data doesn’t exist. In other words, the potential
    use of ML as a tool to solve certain problems is often ignored on the basis that
    the available dataset is too small.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据为中心的AI和ML运动基于这样的哲学：在构建高度信息模型时，数据质量比数据量更重要。换句话说，使用一个小但高质量的数据集比使用一个大但嘈杂的数据集能取得更多成果。对于大多数机器学习用例，基于非常大的数据集（比如数百万个观察值）构建模型是不切实际的，因为数据量根本不存在。换句话说，基于可用数据集太小而忽略机器学习作为解决某些问题的工具的潜在用途是很常见的。
- en: But what if we can use ML to solve problems based on much smaller datasets,
    even down to less than 100 observations? This is one challenge the data-centric
    movement is attempting to solve through systematic data collection and engineering.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们能够使用机器学习来解决基于更小数据集的问题，甚至小于100个观察值呢？这是数据中心运动试图通过系统性的数据收集和工程来解决的一个挑战。
- en: For most ML use cases, the algorithm you need already exists. The quality of
    your input data (*x*) and your dependent variable labels (*y*) is what makes the
    difference. The traditional response to dealing with noise in a dataset is to
    get as much data as possible to average out anomalies. Data centricity tries to
    improve the signal in the data such that more data is not needed.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数机器学习用例，你需要的算法已经存在。你输入数据（x）和依赖变量标签（y）的质量才是决定因素。传统上处理数据集中噪声的响应是尽可能获取更多数据以平均异常值。以数据为中心试图提高数据中的信号，这样就不需要更多的数据。
- en: It’s important to note that data centricity marks the next frontier for larger
    data solutions too. No matter how big or small your dataset is, it is the foundational
    ingredient in your ML solution. Let’s take a closer look at the different aspects
    of data-centric ML.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，数据中心性也为更大的数据解决方案标记了下一个前沿。无论你的数据集有多大或多小，它都是你机器学习解决方案的基础成分。让我们更深入地看看数据为中心的机器学习的不同方面。
- en: The origins of data centricity
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据中心性的起源
- en: The push toward a more data-centric approach to ML development has been spearheaded
    by famous data science pioneer, Dr. Andrew Ng.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 推动向更以数据为中心的机器学习开发方法迈进的是著名的数据科学先驱，安德鲁·吴博士。
- en: Dr. Ng is the co-founder of the massive open online course platform Coursera
    and an adjunct professor in computer science at Stanford University. He is also
    the founder and CEO of DeepLearning.AI, an education company, and Landing AI2,
    an AI-driven visual inspection platform for manufacturing. He previously worked
    as chief scientist at Baidu and was the founding lead of the Google Brain team.
    His Coursera courses on various ML topics have been completed by millions of students
    worldwide.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 吴博士是大型开放在线课程平台Coursera的联合创始人，同时也是斯坦福大学计算机科学系的兼职教授。他还是教育公司DeepLearning.AI和制造AI驱动的视觉检测平台Landing
    AI的创始人兼首席执行官。他之前在百度担任首席科学家，并曾是谷歌大脑团队的创始负责人。他在Coursera上关于各种机器学习主题的课程已被全球数百万学生完成。
- en: 'Dr. Ng and his team at Landing AI build complex ML solutions, such as computer
    vision systems used to inspect manufacturing quality. Through this work, they
    observed that the following characteristics are typical of most ML opportunities3:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尼古拉斯·吴博士和他的Landing AI团队构建了复杂的机器学习解决方案，例如用于检查制造质量的计算机视觉系统。通过这项工作，他们观察到以下特征是大多数机器学习机会的典型特征3：
- en: The majority of potential ML use cases rely on datasets smaller than 10,000
    observations. It is often very difficult or impossible to add more data to reduce
    the effects of noise, so improving data quality is essential to these use cases.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数潜在的机器学习用例依赖于小于10,000个观察值的数据集。通常很难或不可能添加更多数据以减少噪声的影响，因此提高数据质量对于这些用例至关重要。
- en: Even in very large datasets, subsets of the data will exhibit the behavior of
    a small dataset. As an example, Google’s search engine generates billions of searches
    every day, but 95% of the searches are based on keyword combinations that occur
    fewer than 10 times per month (in the US). 15% of daily keyword combinations have
    never been searched before4.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使在非常大的数据集中，数据子集也会表现出小型数据集的行为。例如，谷歌的搜索引擎每天生成数十亿次的搜索，但其中95%的搜索是基于每月出现次数少于10次的关键词组合（在美国）。15%的每日关键词组合之前从未被搜索过4。
- en: When the dataset is small, it is typically faster and easier to identify and
    remove noise in the data than it is to collect more data. For example, if a dataset
    of 500 observations has 10% mislabeled observations, it is usually easier to improve
    the data quality on this existing data than it is to collect a new set of observations.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当数据集较小时，通常比收集更多数据更快、更容易识别和去除数据中的噪声。例如，如果一个包含500个观察值的数据集有10%的误标记观察值，通常比收集一组新的观察值更容易提高现有数据的数据质量。
- en: ML solutions are commonly built on pretrained models and packages, with minimal
    tweaking or modification required. Improving model performance by enhancing data
    quality frequently yields better results than changing model parameters or adding
    more data.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习解决方案通常建立在预训练模型和包的基础上，需要的调整或修改很少。通过提高数据质量来提高模型性能，通常比更改模型参数或添加更多数据产生更好的结果。
- en: Dr. Ng published a comparison of Landing AI’s outcomes that illustrates the
    last point that we just discussed.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尼古拉斯·吴博士发布了一篇关于Landing AI成果的比较，阐述了我们刚才讨论的最后一点。
- en: 'As shown in *Figure 1**.1*, Landing AI produced three defect detection solutions
    for their clients. In all three cases, the teams created a baseline model and
    then tried to improve upon this model using model-centric and data-centric approaches,
    respectively:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图1**.1*所示，Landing AI为他们的客户提供了三个缺陷检测解决方案。在所有三个案例中，团队创建了一个基线模型，然后分别尝试使用以模型为中心和以数据为中心的方法来改进这个模型：
- en: '![Figure 1.1 – Applying data-centric ML – Landing AI’s results (Source: A Chat
    with Andrew on MLOps: From Model-Centric to Data-Centric AI)](img/B19297_01_1.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1 – 应用以数据为中心的机器学习 – Landing AI的结果（来源：与Andrew关于MLOps的对话：从以模型为中心到以数据为中心的AI）](img/B19297_01_1.jpg)'
- en: 'Figure 1.1 – Applying data-centric ML – Landing AI’s results (Source: A Chat
    with Andrew on MLOps: From Model-Centric to Data-Centric AI)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 应用以数据为中心的机器学习 – Landing AI的结果（来源：与Andrew关于MLOps的对话：从以模型为中心到以数据为中心的AI）
- en: In all three examples, the Landing AI teams were able to achieve the best results
    by following a data-centric approach over a model-centric approach. In one of
    three examples, model-centric techniques achieved a tiny 0.04% uplift on the baseline
    model performance, and in the other two examples, no improvement was achieved.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有三个例子中，Landing AI团队通过采用以数据为中心的方法而不是以模型为中心的方法，能够实现最佳结果。在三个例子中的一个中，以模型为中心的技术在基线模型性能上实现了微小的0.04%的提升，而在另外两个例子中，没有实现任何改进。
- en: In contrast, improving data quality consistently led to an improvement in the
    baseline model, and in two out of three cases quite substantially. The Landing
    AI teams spent about 2 weeks iteratively improving the training datasets to achieve
    these results.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，提高数据质量始终会导致基线模型得到改善，在三个案例中的两个案例中，改善相当显著。Landing AI团队花费大约两周时间迭代改进训练数据集，以实现这些结果。
- en: 'Dr. Ng’s recommendation is clear: if you want to build relevant and impactful
    ML models regardless of the size of your dataset, you must put a lot of effort
    into systematically engineering your input data.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尼古拉斯·吴博士的建议很明确：无论你的数据集大小如何，如果你想构建相关且具有影响力的机器学习模型，你必须投入大量精力系统地设计你的输入数据。
- en: Logically, it makes sense that better data leads to better models and Landing
    AI’s results provide some empirical evidence for the same. Now, let’s have a look
    at why data centricity is the future of ML development.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从逻辑上讲，更好的数据导致更好的模型是有道理的，Landing AI 的结果也为这一点提供了实证证据。现在，让我们来看看为什么数据中心性是机器学习发展的未来。
- en: The components of ML systems
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习系统的组件
- en: 'ML systems are comprised of three main parts:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统由三个主要部分组成：
- en: 'The data-centric approach considers systematic data engineering the key to
    the next ML breakthroughs for two reasons:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以数据为中心的方法认为，系统性的数据工程是下一个机器学习突破的关键，原因有以下两点：
- en: Firstly, a model’s training data typically carries the most potential for improvement
    because it is the foundational ingredient in any model.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，一个模型的训练数据通常具有最大的改进潜力，因为它是任何模型的基础成分。
- en: Secondly, the code and infrastructure components of ML systems are much further
    advanced than our methods and processes for consistently capturing quality data.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其次，机器学习系统的代码和基础设施组件比我们持续捕获高质量数据的方法和过程更先进。
- en: Over the last few decades, we have experienced a huge evolution in ML algorithms,
    data science tools, and compute and storage capacity, and our approach to operationalizing
    data science solutions has matured through practices such as **ML** **operations**
    (**MLOps**).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几十年里，我们在机器学习算法、数据科学工具、计算和存储能力方面经历了巨大的演变，我们的数据科学解决方案的实施方法也通过诸如 **机器学习** **操作**（**MLOps**）等实践而成熟。
- en: Open source tools such as Python and R make it relatively cheap and accessible
    for almost anyone with a computer to learn how to produce, tune, and validate
    ML models. The popularity of these tools is underpinned by the availability of
    a large number of prebuilt packages that can be installed for free from public
    libraries. These packages allow users to use common ML algorithms with just a
    few lines of code.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 开源工具如 Python 和 R 使得几乎任何有电脑的人都能相对便宜且容易地学习如何生成、调整和验证机器学习模型。这些工具的流行得益于大量可免费从公共库中安装的预构建包。这些包允许用户仅用几行代码就使用常见的机器学习算法。
- en: At the other end of the tooling spectrum, low-code and no-code **automated ML**
    (**AutoML**) tools allow non-experts with limited or no coding experience to use
    ML techniques with a few mouse clicks.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在工具谱的另一端，低代码和无代码的 **自动化机器学习**（**AutoML**）工具允许那些具有有限或没有编码经验的非专家通过几次鼠标点击来使用机器学习技术。
- en: The evolution in cloud computing has provided us with elastic compute and storage
    capacity that can be scaled up or down relatively easily when demand calls for
    it (beware of the variable costs!).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算的发展为我们提供了弹性计算和存储能力，当需求增加时可以相对容易地进行扩展或缩减（注意可变成本！）。
- en: In other words, we have solved a lot of the technical constraints surrounding
    ML models. The biggest opportunity for further upside now lies in improving the
    availability, accuracy, consistency, completeness, validity, and uniqueness of
    input data.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们已经解决了围绕机器学习模型的技术约束中的许多问题。现在最大的机会在于提高输入数据的可用性、准确性、一致性、完整性、有效性和唯一性。
- en: Let’s take a closer look at why.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地看看原因。
- en: Data is the foundational ingredient
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据是基础成分
- en: Think of the analogous example of a chef wanting to create a world-renowned
    Michelin Star restaurant. The chef has spent a long time learning how to combine
    flavors and textures into wonderful recipes that will leave patrons delighted.
    After many years of practicing and honing their craft, they are ready to open
    their restaurant. They know what it takes to make their restaurant a success.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，一个厨师想要创建一家世界知名的米其林星级餐厅。这位厨师花费了很长时间学习如何将风味和质地结合成令人愉悦的食谱，让顾客满意。经过多年的实践和磨练技艺，他们准备开设自己的餐厅。他们知道如何让餐厅成功。
- en: At the front of the restaurant, they must have a nicely laid out dining room
    with comfortable furniture, set up in a way that lets their guests enjoy each
    other’s company. To serve the guests, they need great waiters who will attend
    to customers’ every need, making sure orders are taken, glasses are filled, and
    tables are kept clean and tidy.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在餐厅的前端，他们必须有一个布置得体的餐厅，舒适的家具，以让客人享受彼此的陪伴。为了服务客人，他们需要优秀的服务员，他们会关注顾客的每一个需求，确保订单被接收，酒杯被填满，餐桌保持干净整洁。
- en: But that’s not all. A successful restaurant must also have a fully equipped
    commercial kitchen capable of producing many meals quickly and consistently, no
    matter how many orders are put through at the same time. And then, of course,
    there is the food. The chef has created a wonderful menu full of carefully crafted
    recipes that will provide their guests with unique and delightful flavor sensations.
    They are all set to open their soon-to-be award-winning restaurant.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 但不仅如此。一家成功的餐厅还必须拥有一个配备齐全的商业厨房，能够快速且一致地制作出许多菜肴，无论同时处理多少订单。当然，还有食物。厨师创造了一份充满精心制作的食谱的菜单，将为他们的客人提供独特而令人愉悦的风味体验。他们一切准备就绪，即将开设即将获奖的餐厅。
- en: 'However, on opening night, there is a problem. Mold has gone through some of
    the vegetables in the pantry and they must be thrown away. Some herbs and spices
    are out of stock and hard to come by easily. Lastly, the most popular dish on
    the menu contains red cabbage, but only green cabbage was delivered by the supplier.
    As a result, the meals are not delightful flavor sensations, but rather bland
    and average. The chef has built a perfect operation and a wonderful menu but paid
    too little attention to the most important and hardest-to-control element: the
    ingredients.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在首演之夜，出现了一个问题。一些蔬菜在储藏室里长出了霉斑，它们必须被扔掉。一些香草和香料已经缺货，难以轻易获得。最后，菜单上最受欢迎的菜肴含有红卷心菜，但供应商只送来了绿卷心菜。因此，这些菜肴并不是令人愉悦的风味感觉，而是平淡无奇。厨师已经建立了一个完美的运营和一份精彩的菜单，但过于忽略了最重要的、最难控制的元素：食材。
- en: The ingredients are produced outside the restaurant and delivered by several
    different suppliers. If one or more parts of the supply chain are not delivering,
    then the final output will suffer, no matter how talented the chef is.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 食材是在餐厅外生产的，由几个不同的供应商运送。如果供应链的某个或某些部分未能交付，那么最终输出将受到影响，无论厨师多么有才华。
- en: The story of the restaurant illustrates why a more systematic approach to engineering
    high-quality datasets is the key to better models.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这家餐厅的故事说明了为什么采用更系统的方法来构建高质量数据集是构建更好模型的关键。
- en: Like the superstar chef needing the best ingredients to make their meals exceptional,
    data scientists often fall short of building highly impactful models because the
    input data isn’t as good or accessible as it should be. Instead of rotten vegetables,
    we have mislabeled observations. Instead of out-of-stock ingredients, we have
    missing values. Instead of the wrong kind of cabbage, we have generic or high-level
    labels with limited predictive power. Instead of a network of food suppliers,
    we have a plethora of data sources and technical platforms that are rarely purpose-built
    for ML.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 就像超级明星厨师需要最好的食材来制作出卓越的菜肴一样，数据科学家往往因为输入数据不够好或不够容易获取而无法构建高度有影响力的模型。我们不是有腐烂的蔬菜，而是有误标记的观察结果。我们不是缺货的食材，而是缺失的值。我们不是错误的卷心菜种类，而是具有有限预测能力的通用或高级标签。我们不是食品供应商的网络，而是大量数据源和技术平台，这些平台很少专门为机器学习而构建。
- en: Part of the reason for this lack of maturity in data collection has to do with
    the maturity of ML as a capability relative to other disciplines in the computer
    science sphere. It is common for people with only a superficial understanding
    of ML to view ML systems the same way they understand traditional software applications.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数据收集不成熟的部分原因与机器学习作为计算机科学领域其他学科相对能力的成熟度有关。对于只有表面了解机器学习的人来说，他们通常会将机器学习系统视为与传统软件应用相同的方式。
- en: However, unlike traditional software, ML systems produce variable outputs that
    depend on a combinatory set of ever-changing data inputs. In ML, the data is part
    of the code. This is important because the data holds the most potential for varying
    the final model output. The breadth, depth, and accuracy of input features and
    observations are foundational to building impactful and reliable models. If the
    dataset is unrepresentative of the real-world population or scenarios you are
    trying to predict, then the model is unlikely to be useful.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与传统的软件不同，机器学习系统产生的是可变输出，这些输出取决于一组不断变化的数据输入。在机器学习中，数据是代码的一部分。这很重要，因为数据是影响最终模型输出的最大潜在因素。输入特征和观察的广度、深度和准确性是构建有影响力和可靠模型的基础。如果数据集不能代表你试图预测的现实世界人口或场景，那么该模型可能没有用。
- en: At the same time, the dataset will determine most of the potential biases of
    the model; that is, whether the model is more likely to produce results that incorrectly
    favor one group over another. In short, the input data is the source of the most
    variability in an ML model and we want to use this variability to our advantage
    rather than it being a risk or a hindrance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，数据集将决定模型的大部分潜在偏差；也就是说，模型更有可能产生结果，错误地偏向某一群体而不是另一群体。简而言之，输入数据是ML模型中变化最大的来源，我们希望利用这种变化来发挥优势，而不是让它成为风险或障碍。
- en: As we move from data to algorithms and on to system infrastructure, we want
    the ML system to become increasingly standardized and unvarying. Following a data-centric
    approach, we want to have lots of the right kind of variability in the data (not
    noise!) while keeping our ML algorithms and overall operational infrastructure
    robust and stable. That way, we can iteratively improve model accuracy by improving
    data quality, while keeping everything else stable.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们从数据转向算法，再到系统基础设施，我们希望ML系统越来越标准化和统一。采用以数据为中心的方法，我们希望在数据中保持大量的正确类型的可变性（而非噪声！）同时保持我们的ML算法和整体运营基础设施的稳健和稳定。这样，我们可以通过提高数据质量来迭代提高模型精度，同时保持其他一切稳定。
- en: '*Figure 1**.2* provides an overview of the facets associated with each of the
    three components of ML systems – data, code, and infrastructure:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.2* 提供了与ML系统三个组成部分（数据、代码和基础设施）相关的各个方面的概述：'
- en: '![Figure 1.2 – The components of ML systems](img/B19297_01_2.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图1.2 – ML系统的组成部分](img/B19297_01_2.jpg)'
- en: Figure 1.2 – The components of ML systems
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – ML系统的组成部分
- en: Under a data-centric approach, high-quality data is the foundation for robust
    ML systems. The biggest opportunities to improve an ML model are typically found
    in the input data rather than the code.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在以数据为中心的方法下，高质量的数据是稳健ML系统的基石。提高ML模型的最大机会通常在于输入数据，而不是代码。
- en: While it makes a lot of sense to focus on data quality over changes to model
    parameters, data scientists tend to focus on the latter because it is a lot easier
    to implement in the short term. Multiple models and hyperparameters can typically
    be tested within a very short timeframe following a traditional model-centric
    approach, but increasing the signal and reducing the noise in your modeling dataset
    seems like a complex and time-consuming exercise.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在模型参数的更改上关注数据质量很有道理，但数据科学家往往更关注后者，因为这更容易在短期内实施。在采用传统的以模型为中心的方法后，通常可以在非常短的时间内测试多个模型和超参数，但增加建模数据集中的信号并减少噪声似乎是一项复杂且耗时的练习。
- en: In part, this is because systematically improved data collection typically involves
    upstream process changes and the participation of various stakeholders in the
    organization. That is rarely something data scientists can do alone, and it requires
    the overall organization to appreciate the value and potential of data science
    to commit the appropriate time and resources to better data collection. Unfortunately,
    most organizations waste more resources building and implementing suboptimal models
    based on poor data than the resources it would take to collect better data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在一定程度上，这是因为系统性地改进数据收集通常涉及上游流程的改变以及组织中各种利益相关者的参与。这通常是数据科学家无法单独完成的，需要整个组织认识到数据科学的价值和潜力，投入适当的时间和资源以改善数据收集。不幸的是，大多数组织在基于不良数据构建和实施次优模型上浪费的资源比收集更好数据的资源要多。
- en: As we will learn in the following sections, a well-designed data-centric approach
    can overcome this challenge and usually unlocks many new ML opportunities in an
    organization. This is because data-centric ML requires everyone involved in the
    data pipeline to think more holistically about the structure and purpose of an
    organization’s data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将了解到，精心设计的数据中心方法可以克服这一挑战，并且通常在组织内部解锁许多新的ML机会。这是因为数据中心ML要求所有参与数据管道的人都更全面地思考组织数据的结构和目的。
- en: To further understand and appreciate the potential of a data-centric approach
    to model development, let’s compare data centricity with the more dominant model-centric
    approach.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步理解和欣赏以数据为中心的方法在模型开发中的潜力，让我们将数据中心性与更占主导地位的模式中心方法进行比较。
- en: Data-centric versus model-centric ML
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据中心与模式中心ML
- en: So far, we have established that data centricity is about systematically engineering
    the data used to build ML models. The conventional and more prevalent model-centric
    approach to ML suggests that optimizing the model itself is the key to better
    performance.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经确定数据中心化是关于系统地构建机器学习模型所使用的数据。传统的、更普遍的以模型为中心的机器学习方法认为，优化模型本身是提高性能的关键。
- en: 'As illustrated in *Figure 1**.3*, the central objective of a model-centric
    approach is improving the code underlying the model. Under a data-centric approach,
    the goal is to find a much larger upside in improved data quality:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 1**.3* 所示，以模型为中心的方法的核心目标是改进模型背后的代码。在以数据为中心的方法下，目标是找到在改进数据质量方面的更大提升空间：
- en: '![Figure 1.3 – Building ML solutions via model-centric and data-centric workflows](img/B19297_01_3.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.3 – 通过以模型为中心和以数据为中心的工作流程构建机器学习解决方案](img/B19297_01_3.jpg)'
- en: Figure 1.3 – Building ML solutions via model-centric and data-centric workflows
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3 – 通过以模型为中心和以数据为中心的工作流程构建机器学习解决方案
- en: ML model development has traditionally focused on improving model performance
    mainly by optimizing the code. Under a data-centric approach, the focus shifts
    to achieving even larger performance enhancements, mainly by iteratively improving
    data quality. It is important to note that the data-centric approach sits on top
    of the principles and techniques that underpin model-centric ML, rather than replacing
    them. Both approaches consider the model and the data critical components of ML
    solutions. A solution will fail if either of the two is misconfigured, buggy,
    biased, or applied incorrectly.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型开发传统上主要关注通过优化代码来提高模型性能。在以数据为中心的方法下，重点转向通过迭代改进数据质量来实现更大的性能提升。需要注意的是，以数据为中心的方法建立在支撑以模型为中心的机器学习原则和技术之上，而不是取代它们。两种方法都将模型和数据视为机器学习解决方案的关键组成部分。如果其中任何一个配置不当、存在错误、有偏见或应用不当，解决方案就会失败。
- en: Model configuration is an important step under a data-centric approach and in
    the very short term, it is certainly quicker to seek incremental gains in model
    performance by optimizing the code. However, as we’ve discussed, there is limited
    upside in changing the recipe if you don’t have the right ingredients. In other
    words, the difference between the two approaches lies in where we put our focus
    and efforts into iteratively improving model performance.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在以数据为中心的方法下，模型配置是一个重要步骤，而在短期内，通过优化代码来寻求模型性能的增量提升无疑是更快的。然而，正如我们讨论的那样，如果你没有合适的原料，改变配方所能带来的提升是有限的。换句话说，两种方法之间的区别在于我们在迭代改进模型性能时，将重点放在哪里和投入多少努力。
- en: As illustrated in *Figure 1**.4*, a model-centric approach treats the data as
    fixed input and focuses on model selection, parameter tuning, feature engineering,
    and adding more data as the main ways to improve model performance. A data-centric
    approach considers the model somewhat static and focuses on improving performance
    mainly through data quality.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 1**.4* 所示，以模型为中心的方法将数据视为固定的输入，并专注于模型选择、参数调整、特征工程以及添加更多数据作为提高模型性能的主要方式。以数据为中心的方法认为模型相对静态，并主要关注通过提高数据质量来改善性能。
- en: Following a model-centric approach, we attempt to collect as much data as possible
    to crowd out any outliers in the data and reduce bias – the bigger the dataset,
    the better. Then, we engineer our model(s) to be as predictive as possible without
    overfitting.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 采用以模型为中心的方法，我们试图收集尽可能多的数据，以消除数据中的任何异常值并减少偏差——数据集越大越好。然后，我们设计我们的模型（们）尽可能具有预测性，同时避免过拟合。
- en: 'This is in contrast to a data-centric approach, which has better data collection
    and labeling at source, on top of model selection and tuning. Data quality is
    improved even further through outlier detection, programmatic labeling, more systematic
    feature engineering, and synthetic data creation (these techniques are explained
    in depth in subsequent chapters):'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这与以数据为中心的方法形成对比，后者在模型选择和调整的基础上，在数据收集和标注方面做得更好。通过异常值检测、程序化标注、更系统的特征工程和合成数据创建（这些技术将在后续章节中深入解释），数据质量得到进一步改善：
- en: '![Figure 1.4 – Comparing model-centric and data-centric ML approaches](img/B19297_01_4.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.4 – 比较以模型为中心和以数据为中心的机器学习方法](img/B19297_01_4.jpg)'
- en: Figure 1.4 – Comparing model-centric and data-centric ML approaches
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 – 比较以模型为中心和以数据为中心的机器学习方法
- en: 'ML model improvement comes from two areas: improving the code and improving
    the data. While data collection and engineering processes might sound like a data
    engineer’s job, they really should be a key part of the data scientist’s toolbox.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型改进来自两个方面：改进代码和改进数据。虽然数据收集和工程过程听起来像是数据工程师的工作，但它们实际上应该是数据科学家工具箱的关键部分。
- en: Let’s take a look at what’s required of data scientists, data engineers, and
    other stakeholders under a data-centric approach.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看在数据中心化方法下，数据科学家、数据工程师和其他利益相关者需要做什么。
- en: Data centricity is a team sport
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据中心化是一项团队运动
- en: While it makes a lot of sense to focus on data quality over changes to model
    parameters, data scientists tend to focus on the latter because it is a lot easier
    to implement in the short term. Multiple models and hyperparameters can typically
    be tested within a very short timeframe following a traditional model-centric
    approach, but increasing the signal and reducing the noise in your modeling dataset
    seems like a complex and time-consuming exercise that can’t easily be dealt with
    by a small team. Data-centric ML takes a lot more effort across the organization,
    whereas a model-centric approach largely relies on the data scientist’s skills
    and tools to increase model performance.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然关注数据质量而不是模型参数的变化很有意义，但数据科学家往往更关注后者，因为这在短期内更容易实施。在传统的以模型为中心的方法之后，通常可以在非常短的时间内测试多个模型和超参数，但增加建模数据集中的信号并减少噪声似乎是一项复杂且耗时的工作，难以由小团队轻松处理。数据中心化的机器学习需要整个组织投入更多的努力，而以模型为中心的方法在很大程度上依赖于数据科学家的技能和工具来提高模型性能。
- en: Data centricity is a team sport. Data centricity requires data scientists and
    others involved in ML development to acquire a new set of data quality-specific
    skills. The most important of these new data-centric skills and techniques is
    what we will teach you in this book.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心化是一项团队运动。数据中心化要求数据科学家和参与机器学习开发的其他人员掌握一套新的数据质量特定技能。这些新数据中心化技能和技术中最重要的，就是我们将在本书中向您传授的。
- en: Data capture and labeling processes must be designed with data science in mind
    and performed by professionals with at least a foundational understanding of ML
    development. Data engineering processes and ETL layers must be structured to identify
    data quality issues and allow for iterative improvement of ML input data. All
    of this requires continuous collaboration between data scientists, data collectors,
    subject matter experts, data engineers, business leaders, and others involved
    in turning data into insights.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 数据捕获和标注过程必须以数据科学为出发点，并由至少对机器学习开发有基础理解的专业人士执行。数据工程过程和ETL层必须结构化，以识别数据质量问题，并允许迭代改进机器学习输入数据。所有这些都需要数据科学家、数据收集者、领域专家、数据工程师、商业领袖以及将数据转化为洞察力的人员之间的持续协作。
- en: To illustrate this point, *Figure 1**.5* compares the data-to-model process
    for both approaches. Depending on the size and purpose of your organization, there
    may be a wide range of roles involved in delivering ML solutions, such as data
    architects, ML engineers, data labelers, analysts, model validators, decision
    makers, project managers, and product owners.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，*图1**.5*比较了两种方法的数据到模型过程。根据您组织的规模和目的，可能涉及多种角色来交付机器学习解决方案，例如数据架构师、机器学习工程师、数据标注员、分析师、模型验证员、决策者、项目经理和产品所有者。
- en: 'However, in our simplified diagram in *Figure 1**.5*, three types of roles
    are involved in the process – a data scientist, a data engineer, and a subject
    matter expert:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们的简化图*图1**.5*中，涉及三种类型的角色——数据科学家、数据工程师和领域专家：
- en: '![Figure 1.5 – Data-centric versus model-centric roles and responsibilities](img/B19297_01_5.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5 – 数据中心化与模型中心化的角色和责任](img/B19297_01_5.jpg)'
- en: Figure 1.5 – Data-centric versus model-centric roles and responsibilities
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 – 数据中心化与模型中心化的角色和责任
- en: Stakeholders at the top of the data pipeline must be active participants in
    the process for an organization to be good at data collection and engineering
    for ML purposes. In short, data centricity requires a lot of teamwork.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 数据管道顶部的利益相关者必须积极参与过程，以便组织在机器学习目的的数据收集和工程方面做得好。简而言之，数据中心化需要大量的团队合作。
- en: Under a conventional model-centric approach, data creation typically starts
    with a data collection process, which may be automated, manual, or a mix of both.
    Examples include a customer entering details into a web page, a radiographer performing
    a CT scan, or a call center operator taking a recorded call. At this point, data
    has been captured for its primary operational purpose, but through the work of
    the data engineer, this information can also be transformed into an analytical
    dataset. The typical process requires a data engineer to extract, transform, and
    normalize the data in a database, data lake, data warehouse, or equivalent.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的以模型为中心的方法下，数据创建通常从数据收集过程开始，这可能包括自动化、手动或两者的混合。例如，客户在网页上输入详细信息，放射科医生进行CT扫描，或呼叫中心操作员接听录音电话。在这个阶段，数据已经为了其主要运营目的而被捕获，但通过数据工程师的工作，这些信息也可以被转换成分析数据集。典型的过程需要数据工程师从数据库、数据湖、数据仓库或等效系统中提取、转换和标准化数据。
- en: Once a data scientist gets a hold of the data, it typically goes through several
    steps to ensure accuracy, consistency, validity, and integrity are maintained.
    In other words, the data should be ready for use; however, any data scientist
    knows that this is rarely the case.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据科学家掌握了数据，它通常会经过几个步骤以确保准确性、一致性、有效性和完整性得到保持。换句话说，数据应该准备好使用；然而，任何数据科学家都知道这很少是情况。
- en: A common heuristic in data science is that 80% of the time it takes to build
    a new ML model is spent on finding, cleaning, and preparing the modeling data
    for use, while only 20% is spent on analysis and model building. Traditionally,
    this has been seen as a problem because data scientists are paid to work with
    the data to build models and perform analyses, and not spend most of their time
    preparing it.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学中的一个常见经验法则是，构建一个新的机器学习模型所需的时间的80%用于寻找、清理和准备用于建模的数据，而只有20%用于分析和模型构建。传统上，这被视为一个问题，因为数据科学家被支付工资来处理数据以构建模型和执行分析，而不是花大部分时间准备数据。
- en: Following a data-centric approach, data preparation becomes the most important
    part of the model-building process. Instead of asking "*how might we minimize
    the time spent on data prep?",* we instead ask "*how might we systematically optimize
    data collection and preparation?"* The problem is not that data scientists are
    spending a lot of time learning and enhancing their datasets. The problem is a
    lack of connectivity between ML development and other upstream data activities
    that allow data scientists, engineers, and subject matter experts to co-create
    faster and more accurate results.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 采用以数据为中心的方法，数据准备成为模型构建过程中的最重要部分。我们不是问“我们如何最小化数据准备所花费的时间？”，而是问“我们如何系统地优化数据收集和准备？”问题不在于数据科学家在学习和增强他们的数据集上花费了大量的时间。问题在于机器学习开发与其他上游数据活动之间的连接不足，这允许数据科学家、工程师和领域专家更快、更准确地共同创造结果。
- en: In essence, data centricity is about establishing the processes, tools, and
    techniques to do this systematically. Subject matter experts are actively involved
    in key parts of the ML development process, including identifying outliers, validating
    data labels and model predictions, and developing new features and attributes
    that should be captured in the data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，数据中心性是关于建立系统化执行这些工作的流程、工具和技术。领域专家积极参与机器学习开发的关键部分，包括识别异常值、验证数据标签和模型预测，以及开发应在数据中捕获的新特征和属性。
- en: Data engineers and data scientists also gain additional responsibilities under
    a data-centric approach. The data engineer’s responsibilities must expand from
    building and maintaining data pipelines to being more directly involved in developing
    and maintaining high-quality features and labels for specific ML solutions. In
    turn, this requires data engineers and data scientists to understand each other’s
    roles and collaborate towards common goals.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在以数据为中心的方法下，数据工程师和数据科学家也承担了额外的责任。数据工程师的责任必须从构建和维护数据管道扩展到更直接地参与开发和维护特定机器学习解决方案的高质量特征和标签。反过来，这要求数据工程师和数据科学家理解彼此的角色，并朝着共同的目标进行合作。
- en: In the next section, we will illustrate, through applied examples, the impact
    a data-centric approach can have on ML opportunities.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将通过应用实例来说明，以数据为中心的方法可以对机器学习机会产生的影响。
- en: The importance of quality data in ML
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 质量数据在机器学习中的重要性
- en: So far, we have defined what data-centric ML is and how it compares to the conventional
    model-centric approach. In this section, we will examine what good data looks
    like in practice.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: 'From a data-centric perspective, good data is as follows5:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '**Captured consistently**: Independent (*x*) and dependent variables (*y*)
    are labeled unambiguously'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Full of signal and free of noise**: Input data covers a wide range of important
    observations and events in the smallest number of observations possible'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Designed for the business problem**: Data is designed and collected specifically
    for solving a business problem with ML, rather than the problem being solved with
    whatever data is already available'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timely and relevant**: Independent and dependent variables provide an accurate
    representation of current trends (no data or concept drift)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At first glance, this sort of systematic data collection seems both expensive
    and time-consuming. However, in our experience, highly deliberate data collection
    is often a foundational requirement for getting the desired results with ML.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: To appreciate the importance and potential of data centricity, let’s look at
    some applied examples of how data quality and systematic engineering of features
    make all the difference.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Identifying high-value legal cases with natural language processing
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our first example of the pivotal importance of data quality comes from an ML
    solution built by Jonas and Manmohan at a large Australian legal services firm.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: ML is a nascent discipline in legal services relative to comparable service
    industries such as banking, insurance, utilities, and telecommunications. This
    is due to the nature and complexity of the data available in legal services, as
    well as the risks and ethics associated with using ML in a legal setting.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Although the legal services industry is incredibly data-rich, data is often
    collected manually, stored in a textual format, and highly contextual to the particulars
    of the legal case. This textual data may come in a variety of formats, such as
    letters from medical professionals, legal contracts, counterparty communications,
    emails between lawyer and client, case notes, and audio recordings.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: On top of that, the legal services industry is a high-stakes environment where
    a mistake or omission made by one party can win or lose the case altogether. Because
    of this, legal professionals tend to spend a lot of time and effort reviewing
    detailed documents and keeping track of key dates and steps in the legal process.
    The devil is in the detail!
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: The legal services firm is a no-win-no-fee plaintiff law firm representing people
    who have been injured or wronged physically or financially. The company fights
    on behalf of individuals or groups against the more powerful counterparties, such
    as insurance firms, negligent hospitals or doctors, and misbehaving corporations.
    The client only pays a fee if they win – otherwise, the firm bears the loss.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: In 2022, the business identified an opportunity to use data science to find
    rare but high-value cases that could then be fast-tracked by specialist lawyers.
    The earlier in the process that these high-value cases could be identified, the
    better. So, the goal was to recognize them in the very first interview with prospective
    clients.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: The initial project design followed a conventional model-centric approach. The
    data science team collected 2 years’ worth of case notes from prospective client
    interviews and created a flag for cases that had later turned out to be high-value
    (the dependent variable, *y*). The team also used topic modeling to engineer new
    features to be included in the final input dataset. **Topic modeling** is an unsupervised
    ML technique that’s used to detect patterns across various documents or text snippets
    that can be grouped into *topics*. These topics were then used as direct input
    into the initial model and also as a tool to explain model predictions.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'The initial model proved reasonably predictive, but the team faced several
    challenges that could only be solved by taking a data-centric approach:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Less than a thousand high-value cases were opened on an annual basis, so this
    was a *small data* problem, even after oversampling.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main predictors were captured from case notes, which were in a semi-structured
    or unstructured format, and often free text. Although case notes followed some
    standards, each note taker had used their distinct vocabulary, shortenings, and
    formatting, making it difficult to create a standardized modeling dataset.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because the input data was largely in free-text format, some very important
    facts were too vague for the model to pick up. For instance, it was important
    whether the legal case involved more than one injured person as this could change
    the case strategy altogether. Sometimes, each injured party would be called out
    explicitly and other times just referred to as *they*.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some details were left out of the case notes because they were either assumed
    knowledge by legal professionals or they would be obvious to a human reading the
    document as a whole. Unfortunately, this was not helpful to a learning algorithm.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The team decided to take a data-centric approach and formed a cross-functional
    project team comprising a highly skilled lawyer, a data scientist, a data engineer,
    an operations manager, and a call center expert. Everyone on the team was an expert
    in one part of the overall process and together they provided lots of depth and
    breadth across client experience, legal, data, and operational processes.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'Rather than improving model accuracy through feature engineering, the team
    altered the data capture altogether by designing a set of client questions that
    were highly predictive of whether a case was high value. The criteria for new
    questions were as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: It must provide very specific details on whether a case was high value or not
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The format must be easily interpretable by humans and algorithms alike
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It must be easy for the prospective client to answer new questions and the call
    center operator to capture the information
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It must be easy to create a triaging process around the captured data such that
    the call center operator can take the right action immediately
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The previously mentioned criteria highlight why it is important to involve a
    wide group of subject matter experts in developing ML solutions. Everyone in the
    cross-functional team had specific knowledge that contributed to the finer details
    of the overall solution.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'The team identified a handful of key questions that would be highly predictive
    of whether a case was high-value. These questions needed to be so specific that
    they could only be answered with a yes, no, or a quantity. For example, rather
    than looking for the word *they* in a free text field, the call center operator
    could simply ask *how many people were involved in the incident?* and record only
    a numeric answer:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6 – Hypothetical case notes before and after data-centric improvements](img/B19297_01_6.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
- en: Figure 1.6 – Hypothetical case notes before and after data-centric improvements
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: With these questions answered, every prospective case could be grouped into
    high, medium, and low probability of being a high-value case. The team then built
    a simple process that allowed call center operators to direct high-probability
    cases straight into a fast-track process handled by specialized lawyers. Other
    cases would continue to be monitored using an ML model to detect new facts that
    may push them into high-value territory.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: The final solution was a success because it helped identify high-value cases
    faster and more accurately, but the benefits of taking a data-centric approach
    were much broader than that. The focus on improved data collection didn’t just
    create better data for ML purposes. It created a different kind of collaboration
    between people from across the business, ultimately leading to better-defined
    processes and a stronger focus on optimizing key moments in the client journey.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Predicting cardiac arrests in emergency calls
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another example comes from an experimental study conducted at the **Emergency
    Medical Dispatch Center** (**EMDC**) in Copenhagen, Denmark6.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: A team led by medical researcher *Stig Blomberg* worked to examine whether an
    ML solution could be used to identify out-of-hospital cardiac arrest by listening
    to the calls made to the EMDC.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: The team trained and tested an ML model using audio recordings of emergency
    calls generated in 2014, with the primary goal of assisting medical dispatchers
    in the early detection of cardiac arrest calls.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'The study found the ML solution to be faster and more accurate at identifying
    cases of cardiac arrest as measured by the model’s sensitivity. However, the researchers
    also discovered the following limitations in following a model-centric approach:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: With no ability for structured feedback between ambulance paramedics and dispatchers,
    there was a lack of *learning* in the system. For instance, it would likely be
    possible to improve human and machine predictions of cardiac arrest by asking
    tailored and more structured questions of the caller, such as "*does he look pale?"*
    or "*can* *he move?".*
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language barriers of non-native speakers impacted model performance. The ML
    solution worked best with Danish-speaking callers and was worse at identifying
    cardiac arrests in foreign-accent calls than the human dispatchers who might speak
    several languages.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although the solution had a higher sensitivity (detection of true positives)
    than human dispatchers, less than one in five alerts were true positives. This
    created a high risk of alert fatigue among dispatchers, who ultimately bear the
    risk of acting on ML recommendations or not.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This case study is another prime example of an ML use case that requires a data-centric
    approach to achieve optimal results while managing risks and ethics appropriately.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, an ML solution classifying cardiac arrest calls will only ever be based
    on *small data* due to the nature and complexity of the underlying problem. In
    this case, it is not necessarily possible to just add more data to improve model
    performance.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: With about 1,000 true cardiac arrests being reported per year from a population
    of circa 1.8 million people in Greater Copenhagen, even years’ worth of call recordings
    would not add up to a large dataset. Once you consider the many subsets in the
    data, such as foreign language speakers and those with non-native accents, the
    data becomes even more fragmented.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: The risks and ethical concerns associated with producing wrong predictions (especially
    false negatives) for life-and-death situations mean that data labels must be carefully
    curated until any biases are reduced to an acceptable minimum. This requires an
    iterative process of reviewing data quality and enhancing model features.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Classifying cardiac arrest cases based on a short phone conversation is a complex
    exercise. It requires subject matter expertise, as well as training and experience
    from dispatchers and paramedics alike. Building a quality natural language dataset
    for ML purposes is largely about reducing ambiguity in the interpretation of the
    signal you’re looking for. This, in turn, requires the organization to define
    what matters in the process that is being modeled by involving subject matter
    experts in the design. You will learn how this is done in [*Chapter 4*](B19297_04.xhtml#_idTextAnchor056),
    *Data Labeling is a* *Collaborative Process*.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Being specific in how questions are asked and answered creates clarity for human
    agents (in this case, the dispatchers), as well as ML models. This example highlights
    how data centricity is not just about collecting better data for ML models. It
    is a golden opportunity to be more deliberate in defining and improving how people
    work and collaborate across the organization.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: The two case studies you have just read through highlight the importance of
    carefully collecting and curating datasets to be high quality in terms of accuracy,
    validity, and contextual relevance. In some situations, data quality can be a
    matter of life and death!
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: As you will learn in [*Chapter 2*](B19297_02.xhtml#_idTextAnchor028)*, From
    Model-Centric to Data-Centric – ML’s Evolution*, there is huge potential for ML
    to be a fantastic tool in high-stakes domains such as legal services and healthcare,
    so long as we can manage the risks associated with data quality.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve discussed the different aspects of data-centric ML, let’s summarize
    what we’ve learned in this chapter.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the fundamentals of data-centric ML and its origins.
    We also learned how data centricity differs from model centricity, including the
    roles and responsibilities of key stakeholders in a typical organization using
    ML. At this point, you should have a solid understanding of data-centric ML and
    its additional potential compared to a more traditional model-centric approach.
    Hopefully, this will encourage you to use data-centric ML for your next project.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discover why ML development has been mostly model-centric
    until now and explore further why data centricity is the key to the next phase
    of the evolution of AI.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://datacentricai.org/](https://datacentricai.org/), viewed 10 July 2022'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://www.andrewng.org/](https://www.andrewng.org/) and [https://www.coursera.org/instructor/andrewng](https://www.coursera.org/instructor/andrewng),
    viewed 6 July 2022'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://www.youtube.com/watch?v=06-AZXmwHjo](https://www.youtube.com/watch?v=06-AZXmwHjo),
    viewed 2 August 2022'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://ahrefs.com/blog/long-tail-keywords/](https://ahrefs.com/blog/long-tail-keywords/),
    viewed 2 August 2022'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Derived from *A Chat with Andrew on MLOps – From Model-centric to Data-Centric
    AI*: [https://www.youtube.com/watch?v=06-AZXmwHjo](https://www.youtube.com/watch?v=06-AZXmwHjo),
    viewed 2 August 2022'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Zicari et al.: *On assessing trustworthy AI in healthcare: Best practice for
    machine learning as a supportive tool to recognize cardiac arrest in emergency
    calls*. Frontiers in Human Dynamics (2021)'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
