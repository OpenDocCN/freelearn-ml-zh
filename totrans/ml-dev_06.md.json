["```py\nimport matplotlib.pyplot as plt\nimport imageio\nimport numpy as np\n```", "```py\narr = imageio.imread(\"b.bmp\") [:,:,0].astype(np.float)\nplt.imshow(arr, cmap=plt.get_cmap('binary_r'))\nplt.show()\n```", "```py\nclass ConvolutionalOperation:\n    def apply3x3kernel(self, image, kernel):  # Simple 3x3 kernel operation\n        newimage=np.array(image)\n        for m in range(1,image.shape[0]-2):\n            for n in range(1,image.shape[1]-2):\n                newelement = 0\n                for i in range(0, 3):\n                    for j in range(0, 3):\n                        newelement = newelement + image[m - 1 + i][n - 1+ \n                        j]*kernel[i][j]\n                newimage[m][n] = newelement\n        return (newimage)\n```", "```py\nkernels = {\"Blur\":[[1./16., 1./8., 1./16.], [1./8., 1./4., 1./8.], [1./16., 1./8., 1./16.]]\n           ,\"Identity\":[[0, 0, 0], [0., 1., 0.], [0., 0., 0.]]\n           ,\"Laplacian\":[[1., 2., 1.], [0., 0., 0.], [-1., -2., -1.]]\n           ,\"Left Sobel\":[[1., 0., -1.], [2., 0., -2.], [1., 0., -1.]]\n           ,\"Upper Sobel\":[[1., 2., 1.], [0., 0., 0.], [-1., -2., -1.]]}\n```", "```py\nconv = ConvolutionalOperation()\nplt.figure(figsize=(30,30))\nfig, axs = plt.subplots(figsize=(30,30))\nj=1\nfor key,value in kernels.items():\n    axs = fig.add_subplot(3,2,j)\n    out = conv.apply3x3kernel(arr, value)\n    plt.imshow(out, cmap=plt.get_cmap('binary_r'))\n    j=j+1\nplt.show()\n\n<matplotlib.figure.Figure at 0x7fd6a710a208>\n```", "```py\nclass PoolingOperation:\n    def apply2x2pooling(self, image, stride):  # Simple 2x2 kernel operation\n        newimage=np.zeros((int(image.shape[0]/2),int(image.shape[1]/2)),np.float32)\n        for m in range(1,image.shape[0]-2,2):\n            for n in range(1,image.shape[1]-2,2):\n                newimage[int(m/2),int(n/2)] = np.max(image[m:m+2,n:n+2])\n        return (newimage)\n```", "```py\nplt.figure(figsize=(30,30))\npool=PoolingOperation()\nfig, axs = plt.subplots(figsize=(20,10))\naxs = fig.add_subplot(1,2,1)\nplt.imshow(arr, cmap=plt.get_cmap('binary_r'))\nout=pool.apply2x2pooling(arr,1)\naxs = fig.add_subplot(1,2,2)\nplt.imshow(out, cmap=plt.get_cmap('binary_r'))\nplt.show()\n```", "```py\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.optimizers import SGD\nfrom keras.applications.inception_v3 import InceptionV3, decode_predictions, preprocess_input\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\n\nUsing TensorFlow backend.\n```", "```py\nmodel=InceptionV3()\nmodel.compile(optimizer=SGD(), loss='categorical_crossentropy')\n```", "```py\n# resize into VGG16 trained images' format\nim = cv2.resize(cv2.imread('blue_jay.jpg'), (299, 299))\nim = np.expand_dims(im, axis=0)\nim = im /255.\nim = im - 0.5\nim =  im * 2\nplt.figure (figsize=(10,10))\nplt.imshow(im[0], cmap=plt.get_cmap('binary_r'))\nplt.show()\n```", "```py\nout = model.predict(im)\nprint('Predicted:', decode_predictions(out, top=3)[0])\nprint (np.argmax(out))\n\nPredicted: [('n01530575', 'brambling', 0.18225007), ('n01824575', 'coucal', 0.13728797), ('n01560419', 'bulbul', 0.048493069)]\n10\n```", "```py\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.optimizers import SGD\nfrom keras.applications.vgg16 import VGG16\nimport keras.applications as apps\n\nmodel=apps.vgg16.VGG16()\n\nfrom quiver_engine.server import launch\nlaunch(model,input_folder=\".\") \n```", "```py\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential, Model \nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras import backend as k \nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\nfrom keras.models import load_model\nfrom keras.applications.vgg16 import VGG16, decode_predictions,preprocess_input\nimport cv2\nimport numpy as np\n\nUsing TensorFlow backend.\n```", "```py\nimg_width, img_height = 224, 224\ntrain_data_dir = \"train\"\nvalidation_data_dir = \"validation\"\nnb_train_samples = 300\nnb_validation_samples = 100 \nbatch_size = 16\nepochs = 50\n```", "```py\nmodel = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n\n# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\nfor layer in model.layers[:5]:\n    layer.trainable = False\n\n#Adding custom Layers \nx = model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation=\"relu\")(x)\npredictions = Dense(2, activation=\"softmax\")(x)\n\n# creating the final model \nmodel_final = Model(input = model.input, output = predictions)\n```", "```py\n# compile the model \nmodel_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n\n# Initiate the train and test generators with data Augumentation \ntrain_datagen = ImageDataGenerator(\nrescale = 1./255,\nhorizontal_flip = True,\nfill_mode = \"nearest\",\nzoom_range = 0.3,\nwidth_shift_range = 0.3,\nheight_shift_range=0.3,\nrotation_range=30)\n\ntest_datagen = ImageDataGenerator(\nrescale = 1./255,\nhorizontal_flip = True,\nfill_mode = \"nearest\",\nzoom_range = 0.3,\nwidth_shift_range = 0.3,\nheight_shift_range=0.3,\nrotation_range=30)\n```", "```py\ntrain_generator = train_datagen.flow_from_directory(\ntrain_data_dir,\ntarget_size = (img_height, img_width),\nbatch_size = batch_size, \nclass_mode = \"categorical\")\n\nvalidation_generator = test_datagen.flow_from_directory(\nvalidation_data_dir,\ntarget_size = (img_height, img_width),\nclass_mode = \"categorical\")\n\n# Save the model according to the conditions  \ncheckpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n\nFound 120 images belonging to 2 classes.\nFound 40 images belonging to 2 classes.\n```", "```py\nmodel_final.fit_generator(\ntrain_generator,\nsamples_per_epoch = nb_train_samples,\nnb_epoch = epochs,\nvalidation_data = validation_generator,\nnb_val_samples = nb_validation_samples,\ncallbacks = [checkpoint, early])\n\nEpoch 1/50\n288/300 [===========================>..] - ETA: 2s - loss: 0.7809 - acc: 0.5000\n\n/usr/local/lib/python3.5/dist-packages/Keras-1.2.2-py3.5.egg/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n  warnings.warn('Epoch comprised more than '\n\nEpoch 00000: val_acc improved from -inf to 0.63393, saving model to vgg16_1.h5\n304/300 [==============================] - 59s - loss: 0.7802 - acc: 0.4934 - val_loss: 0.6314 - val_acc: 0.6339\nEpoch 2/50\n296/300 [============================>.] - ETA: 0s - loss: 0.6133 - acc: 0.6385Epoch 00001: val_acc improved from 0.63393 to 0.80833, saving model to vgg16_1.h5\n312/300 [===============================] - 45s - loss: 0.6114 - acc: 0.6378 - val_loss: 0.5351 - val_acc: 0.8083\nEpoch 3/50\n288/300 [===========================>..] - ETA: 0s - loss: 0.4862 - acc: 0.7986Epoch 00002: val_acc improved from 0.80833 to 0.85833, saving model to vgg16_1.h5\n304/300 [==============================] - 50s - loss: 0.4825 - acc: 0.8059 - val_loss: 0.4359 - val_acc: 0.8583\nEpoch 4/50\n296/300 [============================>.] - ETA: 0s - loss: 0.3524 - acc: 0.8581Epoch 00003: val_acc improved from 0.85833 to 0.86667, saving model to vgg16_1.h5\n312/300 [===============================] - 48s - loss: 0.3523 - acc: 0.8590 - val_loss: 0.3194 - val_acc: 0.8667\nEpoch 5/50\n288/300 [===========================>..] - ETA: 0s - loss: 0.2056 - acc: 0.9549Epoch 00004: val_acc improved from 0.86667 to 0.89167, saving model to vgg16_1.h5\n304/300 [==============================] - 45s - loss: 0.2014 - acc: 0.9539 - val_loss: 0.2488 - val_acc: 0.8917\nEpoch 6/50\n296/300 [============================>.] - ETA: 0s - loss: 0.1832 - acc: 0.9561Epoch 00005: val_acc did not improve\n312/300 [===============================] - 17s - loss: 0.1821 - acc: 0.9551 - val_loss: 0.2537 - val_acc: 0.8917\nEpoch 7/50\n288/300 [===========================>..] - ETA: 0s - loss: 0.0853 - acc: 0.9792Epoch 00006: val_acc improved from 0.89167 to 0.94167, saving model to vgg16_1.h5\n304/300 [==============================] - 48s - loss: 0.0840 - acc: 0.9803 - val_loss: 0.1537 - val_acc: 0.9417\nEpoch 8/50\n296/300 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9764Epoch 00007: val_acc did not improve\n312/300 [===============================] - 17s - loss: 0.0770 - acc: 0.9776 - val_loss: 0.1354 - val_acc: 0.9417\nEpoch 9/50\n296/300 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9865Epoch 00008: val_acc did not improve\n312/300 [===============================] - 17s - loss: 0.0719 - acc: 0.9872 - val_loss: 0.1565 - val_acc: 0.9250\nEpoch 10/50\n288/300 [===========================>..] - ETA: 0s - loss: 0.0465 - acc: 0.9931Epoch 00009: val_acc did not improve\n304/300 [==============================] - 16s - loss: 0.0484 - acc: 0.9901 - val_loss: 0.2148 - val_acc: 0.9167\nEpoch 11/50\n296/300 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9764Epoch 00010: val_acc did not improve\n312/300 [===============================] - 17s - loss: 0.0634 - acc: 0.9744 - val_loss: 0.1759 - val_acc: 0.9333\nEpoch 12/50\n288/300 [===========================>..] - ETA: 0s - loss: 0.0305 - acc: 0.9931\n```", "```py\nim = cv2.resize(cv2.imread('test/gaff2.jpg'), (img_width, img_height))\nim = np.expand_dims(im, axis=0).astype(np.float32)\nim=preprocess_input(im)\n\nout = model_final.predict(im)\n\nprint (out)\nprint (np.argmax(out))\n\n[[  1.00000000e+00   1.35796010e-13]]\n0\n```"]