["```py\n pip install feature-engine\n```", "```py\n conda install -c conda-forge feature_engine\n```", "```py\n pip install category_encoders\n```", "```py\n     import pandas as pd\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n     data = pd.read_csv(\"credit_approval_uci.csv\")\n    ```", "```py\n     X_train, X_test, y_train, y_test = train_test_split(\n        data.drop(labels=[\"target\"], axis=1),\n        data[\"target\"],\n        test_size=0.3,\n        random_state=0,\n    )\n    ```", "```py\n     X_train[\"A4\"].unique()\n    ```", "```py\n    <st c=\"5923\">A4</st> into *<st c=\"5930\">k-1</st>* binary variables using <st c=\"5958\">pandas</st> and then inspect the first five rows of the resulting DataFrame:\n\n    ```", "```py\n\n    ```", "```py\n <st c=\"6444\">Missing        l        u        y</st>\n<st c=\"6458\">596     False</st> <st c=\"6468\">False   True  False</st>\n<st c=\"6485\">303     False  False   True  False</st>\n<st c=\"6512\">204     False  False</st> <st c=\"6529\">False   True</st>\n<st c=\"6539\">351     False  False  False   True</st>\n<st c=\"6566\">118     False  False   True  False</st>\n```", "```py\n     X_train_enc = pd.get_dummies(X_train, drop_first=True)\n    X_test_enc = pd.get_dummies(X_test, drop_first=True)\n    ```", "```py\n     X_train_enc.head()\n    ```", "```py\n     from sklearn.preprocessing import OneHotEncoder\n    from sklearn.compose import ColumnTransformer\n    ```", "```py\n     cat_vars = X_train.select_dtypes(\n        include=\"O\").columns.to_list()\n    ```", "```py\n     encoder = OneHotEncoder(drop=\"first\",\n        sparse_output=False)\n    ```", "```py\n     ct = ColumnTransformer(\n        [(\"encoder\", encoder, cat_vars)],\n        remainder=\"passthrough\",\n        force_int_remainder_cols=False,\n    ).set_output(transform=\"pandas\")\n    ```", "```py\n     ct.fit(X_train)\n    ```", "```py\n     ct.named_transformers_[\"encoder\"].categories_\n    ```", "```py\n     X_train_enc = ct.transform(X_train)\n    X_test_enc = ct.transform(X_test)\n    ```", "```py\n     ct.get_feature_names_out()\n    ```", "```py\n     from feature_engine.encoding import OneHotEncoder\n    ```", "```py\n     ohe_enc = OneHotEncoder(drop_last=True)\n    ```", "```py\n     ohe_enc.fit(X_train)\n    ```", "```py\n     ohe_enc.variables_\n    ```", "```py\n    ['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13']\n    ```", "```py\n     ohe_enc.encoder_dict_\n    ```", "```py\n     <st c=\"13269\">{'A1': ['a', 'b'],</st>\n     <st c=\"13288\">'A4': ['u', 'y', 'Missing'],</st>\n     <st c=\"13317\">'A5': ['g', 'p', 'Missing'],</st>\n     <st c=\"13346\">'A6': ['c', 'q', 'w', 'ff', 'm', 'i', 'e', 'cc', 'x', 'd', 'k', 'j', 'Missing', 'aa'],</st>\n     <st c=\"13433\">'A7': ['v', 'ff', 'h', 'dd', 'z', 'bb', 'j', 'Missing', 'n'],</st>\n     <st c=\"13495\">'A9': ['t'],</st>\n     <st c=\"13508\">'A10': ['t'],</st>\n     <st c=\"13522\">'A12': ['t'],</st>\n     <st c=\"13536\">'A13': ['g', 's']}</st>\n    ```", "```py\n     X_train_enc = ohe_enc.transform(X_train)\n    X_test_enc = ohe_enc.transform(X_test)\n    ```", "```py\n     import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n     data = pd.read_csv(\"credit_approval_uci.csv\")\n    X_train, X_test, y_train, y_test = train_test_split(\n        data.drop(labels=[\"target\"], axis=1),\n        data[\"target\"],\n        test_size=0.3,\n        random_state=0,\n    )\n    ```", "```py\n     X_train[\"A6\"].unique()\n    ```", "```py\n    <st c=\"18343\">A6</st>, sort them in decreasing order, and then display the five most frequent categories:\n\n    ```", "```py\n\n    <st c=\"18496\">We can</st> <st c=\"18503\">see the five most frequent categories and the number of observations per category in the</st> <st c=\"18593\">following output:</st>\n\n    ```", "```py\n     top_5 = [x for x in X_train[ <st c=\"18816\">\" A6\"].value_counts().sort_values(</st> **<st c=\"18851\">ascending=False).head(5).index\n    ]</st>**\n    ```", "```py\n\n    ```", "```py\n     X_train_enc = X_train.copy()\n    X_test_enc = X_test.copy()\n    for label in top_5:\n        X_train_enc[f\"A6_{label}\"] = np.where(\n            X_train[\"A6\"] == label, 1, 0)\n        X_test_enc[f\"A6_{label}\"] = np.where(\n            X_test[\"A6\"] == label, 1, 0)\n    ```", "```py\n     X_train_enc[[\"A6\"] + [f\"A6_{\n        label}\" for label in top_5]].head(10)\n    ```", "```py\n     <st c=\"19422\">A6  A6_c  A6_q</st> <st c=\"19436\">A6_w  A6_i  A6_ff</st>\n    <st c=\"19451\">596   c      1      0      0      0        0</st>\n    <st c=\"19467\">303   q</st> <st c=\"19474\">0      1      0      0        0</st>\n    <st c=\"19483\">204   w      0      0      1      0</st> <st c=\"19498\">0</st>\n    <st c=\"19499\">351  ff      0      0      0      0        1</st>\n    <st c=\"19515\">118   m      0</st> <st c=\"19524\">0      0      0        0</st>\n    <st c=\"19531\">247   q      0      1      0      0        0</st>\n    <st c=\"19547\">652</st> <st c=\"19551\">i      0      0      0      1        0</st>\n    <st c=\"19563\">513   e      0      0</st> <st c=\"19574\">0      0        0</st>\n    <st c=\"19579\">230  cc      0      0      0      0        0</st>\n    <st c=\"19677\">scikit-learn</st>.\n    ```", "```py\n     from sklearn.preprocessing import OneHotEncoder\n    ```", "```py\n     encoder = OneHotEncoder(\n        min_frequency=39,\n        max_categories=5,\n        sparse_output=False,\n    ).set_output(transform=\"pandas\")\n    ```", "```py\n     X_train_enc = encoder.fit_transform(X_train[\n        ['A6', 'A7']])\n    X_test_enc = encoder.transform(X_test[['A6', 'A7']])\n    ```", "```py\n     From feature_engine.encoding import OneHotEncoder\n    ohe_enc = OneHotEncoder(\n        top_categories=5,\n        variables=[\"A6\", \"A7\"]\n    )\n    ```", "```py\n     ohe_enc.fit(X_train)\n    ```", "```py\n     X_train_enc = ohe_enc.transform(X_train)\n    X_test_enc = ohe_enc.transform(X_test)\n    ```", "```py\n     import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from feature_engine.encoding import CountFrequencyEncoder\n    ```", "```py\n     data = pd.read_csv(\"credit_approval_uci.csv\")\n    X_train, X_test, y_train, y_test = train_test_split(\n        data.drop(labels=[\"target\"], axis=1),\n        data[\"target\"],\n        test_size=0.3,\n        random_state=0,\n    )\n    ```", "```py\n     counts = X_train[\"A7\"].value_counts().to_dict()\n    ```", "```py\n<st c=\"25308\">{'v': 277, 'h': 101, 'ff': 41, 'bb': 39, 'z': 7, 'dd': 5, 'j': 5, 'Missing': 4, 'n': 3, 'o': 1}</st>\n```", "```py\n     X_train_enc = X_train.copy()\n    X_test_enc = X_test.copy()\n    X_train_enc[\"A7\"] = X_train_enc[\"A7\"].map(counts)\n    X_test_enc[\"A7\"] = X_test_enc[\"A7\"].map(counts)\n    ```", "```py\n     count_enc = CountFrequencyEncoder(\n        encoding_method=\"count\", variables=None,\n    )\n    ```", "```py\n     count_enc.fit(X_train)\n    ```", "```py\n     count_enc.variables_\n    ```", "```py\n    <st c=\"26625\">['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13']</st>\n    ```", "```py\n    <st c=\"26748\">count_enc.encoder_dict_</st>\n    ```", "```py\n     X_train_enc = count_enc.transform(X_train)\n    X_test_enc = count_enc.transform(X_test)\n    ```", "```py\n     import pandas as pd\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n     data = pd.read_csv(\"credit_approval_uci.csv\")\n    X_train, X_test, y_train, y_test = train_test_split(\n        data.drop(labels=[\"target\"], axis=1),\n        data[\"target\"],\n        test_size=0.3,\n        random_state=0,\n    )\n    ```", "```py\n     ordinal_mapping = {k: i for i, k in enumerate(\n        X_train[\"A7\"].unique(), 0)\n    }\n    ```", "```py\n    <st c=\"31083\">{'v': 0, 'ff': 1, 'h': 2, 'dd': 3, 'z': 4, 'bb': 5, 'j': 6, 'Missing': 7, 'n': 8, 'o': 9}</st>\n    ```", "```py\n     X_train_enc = X_train.copy()\n    X_test_enc = X_test.copy()\n    X_train_enc[\"A7\"] = X_train_enc[\"A7\"].map(ordinal_mapping)\n    X_test_enc[\"A7\"] = X_test_enc[\"A7\"].map(ordinal_mapping)\n    ```", "```py\n     from sklearn.preprocessing import OrdinalEncoder\n    from sklearn.compose import ColumnTransformer\n    ```", "```py\n     enc = OrdinalEncoder()\n    ```", "```py\n     cat_vars = X_train.select_dtypes(include=\"O\").columns.to_list()\n    ```", "```py\n     ct = ColumnTransformer(\n        [(\"encoder\", enc, cat_vars)],\n        remainder=\"passthrough\",\n        force_int_remainder_cols=False,\n    ).set_output(transform=\"pandas\")\n    ```", "```py\n     ct.fit(X_train)\n    ```", "```py\n     X_train_enc = ct.transform(X_train)\n    X_test_enc = ct.transform(X_test)\n    ```", "```py\n     from feature_engine.encoding import OrdinalEncoder\n    ```", "```py\n     enc = OrdinalEncoder(\n        encoding_method=\"arbitrary\",\n        variables=cat_vars,\n    )\n    ```", "```py\n     enc.fit(X_train)\n    ```", "```py\n     X_train_enc = enc.transform(X_train)\n    X_test_enc = enc.transform(X_test)\n    ```", "```py\n     import pandas as pd\n    import matplotlib.pyplot as plt\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n     data = pd.read_csv(\"credit_approval_uci.csv\")\n    X_train, X_test, y_train, y_test = train_test_split(\n        data.drop(labels=[\"target\"], axis=1),\n        data[\"target\"],\n        test_size=0.3,\n        random_state=0,\n    )\n    ```", "```py\n     y_train.groupby(X_train[\"A7\"]).mean().sort_values()\n    ```", "```py\n    <st c=\"37914\">A7</st>\n    <st c=\"37917\">o          0.000000</st>\n    <st c=\"37928\">ff         0.146341</st>\n    <st c=\"37940\">j          0.200000</st>\n    <st c=\"37951\">dd         0.400000</st>\n    <st c=\"37963\">v          0.418773</st>\n    <st c=\"37974\">bb         0.512821</st>\n    <st c=\"37986\">h          0.603960</st>\n    <st c=\"37997\">n          0.666667</st>\n    <st c=\"38008\">z          0.714286</st>\n    <st c=\"38019\">Missing    1.000000</st>\n    <st c=\"38036\">Name: target, dtype: float64</st>\n    ```", "```py\n     ordered_labels = y_train.groupby(\n        X_train[\"A7\"]).mean().sort_values().index\n    ```", "```py\n     ordinal_mapping = {\n        k: i for i, k in enumerate(ordered_labels, 0)\n    }\n    ```", "```py\n    <st c=\"38847\">A7</st> in a copy of the datasets:\n\n    ```", "```py\n\n    ```", "```py\n     y_train.groupby(X_train[\"A7\"]).mean().plot()\n    plt.title(\"Relationship between A7 and the target\")\n    plt.ylabel(\"Mean of target\")\n    plt.show()\n    ```", "```py\n     y_train.groupby(X_train_enc[\"A7\"]).mean().plot()\n    plt.title(\"Relationship between A7 and the target\")\n    plt.ylabel(\"Mean of target\")\n    plt.show()\n    ```", "```py\n     from feature_engine.encoding import OrdinalEncoder\n    ```", "```py\n     ordinal_enc = OrdinalEncoder(\n        encoding_method=\"ordered\",\n        variables=None)\n    ```", "```py\n     ordinal_enc.fit(X_train, y_train)\n    ```", "```py\n     X_train_enc = ordinal_enc.transform(X_train)\n    X_test_enc = ordinal_enc.transform(X_test)\n    ```", "```py\n     import pandas as pd\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n     data = pd.read_csv(\"credit_approval_uci.csv\")\n    X_train, X_test, y_train, y_test = train_test_split(\n        data.drop(labels=[\"target\"], axis=1),\n        data[\"target\"],\n        test_size=0.3,\n        random_state=0,\n    )\n    ```", "```py\n     from sklearn.preprocessing import TargetEncoder\n    from sklearn.compose import ColumnTransformer\n    ```", "```py\n     cat_vars = X_train.select_dtypes(\n        include=\"O\").columns.to_list()\n    ```", "```py\n     enc = TargetEncoder(smooth=\"auto\", random_state=9)\n    ```", "```py\n     ct = ColumnTransformer(\n        [(\"encoder\", enc, cat_vars)],\n        remainder=\"passthrough\",\n    ).set_output(transform=\"pandas\")\n    ```", "```py\n     X_train_enc = ct.fit_transform(X_train, y_train)\n    X_test_enc = ct.transform(X_test)\n    ```", "```py\n     from feature_engine.encoding import MeanEncoder\n    ```", "```py\n     mean_enc = MeanEncoder(smoothing=\"auto\",\n        variables=None)\n    ```", "```py\n     mean_enc.fit(X_train, y_train)\n    ```", "```py\n     X_train_enc = mean_enc.transform(X_train)\n    X_test_enc = mean_enc.transform(X_test)\n    ```", "```py\n     import numpy as np\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n     data = pd.read_csv(\"credit_approval_uci.csv\")\n    X_train, X_test, y_train, y_test = train_test_split(\n        data.drop(labels=[\"target\"], axis=1),\n        data[\"target\"],\n        test_size=0.3,\n        random_state=0,\n    )\n    ```", "```py\n     neg_y_train = pd.Series(\n        np.where(y_train == 1, 0, 1),\n        index=y_train.index\n    )\n    ```", "```py\n     total_pos = y_train.sum()\n    total_neg = neg_y_train.sum()\n    ```", "```py\n     pos = y_train.groupby(\n        X_train[\"A1\"]).sum() / total_pos\n    neg = neg_y_train.groupby(\n        X_train[\"A1\"]).sum() / total_neg\n    ```", "```py\n     woe = np.log(pos/neg)\n    ```", "```py\n    <st c=\"56276\">A1</st>\n    <st c=\"56278\">Missing    0.203599</st>\n    <st c=\"56295\">a          0.092373</st>\n    <st c=\"56306\">b         -0.042410</st>\n    <st c=\"56375\">A1</st> with the WoE in a copy of the datasets:\n\n    ```", "```py\n\n    <st c=\"56565\">You can inspect the e</st><st c=\"56587\">ncoded variable by</st> <st c=\"56607\">executing</st> `<st c=\"56617\">X_train_enc[\"A1\"].head()</st>`<st c=\"56641\">.</st><st c=\"56642\">Now, let’s perform WoE encoding</st> <st c=\"56675\">using</st> `<st c=\"56681\">feature-engine</st>`<st c=\"56695\">.</st>\n    ```", "```py\n    <st c=\"56722\">from feature_engine.encoding import WoEEncoder</st>\n    ```", "```py\n     woe_enc = WoEEncoder(variables = [\"A1\", \"A9\", \"A12\"])\n    ```", "```py\n     woe_enc.fit(X_train, y_train)\n    ```", "```py\n     X_train_enc = woe_enc.transform(X_train)\n    X_test_enc = woe_enc.transform(X_test)\n    ```", "```py\n     import numpy as np\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from feature_engine.encoding import RareLabelEncoder\n    ```", "```py\n     data = pd.read_csv(\"credit_approval_uci.csv\")\n    X_train, X_test, y_train, y_test = train_test_split(\n        data.drop(labels=[\"target\"], axis=1),\n        data[\"target\"],\n        test_size=0.3,\n        random_state=0,\n    )\n    ```", "```py\n     freqs = X_train[\"A7\"].value_counts(normalize=True)\n    ```", "```py\n    <st c=\"60003\">v 0.573499</st>\n    <st c=\"60013\">h 0.209110</st>\n    <st c=\"60024\">ff 0.084886</st>\n    <st c=\"60036\">bb 0.080745</st>\n    <st c=\"60048\">z 0.014493</st>\n    <st c=\"60059\">dd 0.010352</st>\n    <st c=\"60071\">j 0.010352</st>\n    <st c=\"60082\">Missing 0.008282</st>\n    <st c=\"60099\">n 0.006211</st>\n    <st c=\"60110\">o 0.002070</st>\n    <st c=\"60234\">z</st>, <st c=\"60237\">dd</st>, <st c=\"60241\">j</st>, <st c=\"60244\">Missing</st>, <st c=\"60253\">n</st>, and <st c=\"60260\">o</st> are rare categories.\n    ```", "```py\n     frequent_cat = [\n        x for x in freqs.loc[freqs > 0.05].index.values]\n    ```", "```py\n    <st c=\"60646\">Rare</st> string in a copy of the datasets:\n\n    ```", "```py\n\n    ```", "```py\n     X_train[\"A7\"].value_counts(normalize=True)\n    ```", "```py\n    <st c=\"61113\">v       0.573499</st>\n    <st c=\"61124\">h       0.209110</st>\n    <st c=\"61135\">ff      0.084886</st>\n    <st c=\"61147\">bb      0.080745</st>\n    <st c=\"61159\">Rare    0.051760</st>\n    <st c=\"61236\">feature-engine</st>.\n    ```", "```py\n     rare_encoder = RareLabelEncoder(tol=0.05,\n        n_categories=4)\n    ```", "```py\n     rare_encoder.fit(X_train)\n    ```", "```py\n     X_train_enc = rare_encoder.transform(X_train)\n    X_test_enc = rare_encoder.transform(X_test)\n    ```", "```py\n     import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from category_encoders.binary import BinaryEncoder\n    ```", "```py\n     data = pd.read_csv(\"credit_approval_uci.csv\")\n    X_train, X_test, y_train, y_test = train_test_split(\n        data.drop(labels=[\"target\"], axis=1), data[\"target\"],\n        test_size=0.3,\n        random_state=0,\n    )\n    ```", "```py\n     X_train[\"A7\"].unique()\n    ```", "```py\n    <st c=\"66315\">A7</st>:\n\n    ```", "```py\n\n    ```", "```py\n     encoder.fit(X_train)\n    ```", "```py\n     X_train_enc = encoder.transform(X_train)\n    X_test_enc = encoder.transform(X_test)\n    ```"]