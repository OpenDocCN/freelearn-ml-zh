- en: RevoScaleR Package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `RevoScaleR` package comes with Microsoft Machine Learning R Server and
    R Services. It is also available with R Client, but with some limitations discussed
    in [Chapter 2](part0025.html#NQU20-e3f81285367248f4bbc6431bcd4f926d), *Overview
    of Microsoft Machine Learning Server and SQL Server*. Given the rapid development
    and constant upgrades, this chapter will cover version 8.X and version 9.X-the
    latter is also available with SQL Server 2017\. Changes and upgrades in version
    9.X are not to be overlooked and will be covered as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics are covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of R challenged
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalable and distributive computational environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions for data preparation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions for descriptive statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions for statistical tests and sampling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions for predictive modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Primarily, this R package is designed to be handled in ecosystems where clients
    would be connecting to Microsoft R Server in order to have R code executed against
    a much more powerful server, which would presumably hold whole datasets, not just
    a smaller portion, on which people working on client machines would be dealing
    with.
  prefs: []
  type: TYPE_NORMAL
- en: Overcomming R language limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prior to SQL Server 2016 (and 2017) BI and data scientists had the OLAP cubes,
    DMX language, and all super awesome and cool Microsoft algorithms available within
    **SQL Server Analysis Services **(**SSAS**). But, with rapid changes and bigger
    market demands, the need for integration of an open-source product (whether R,
    Python, Perl,or any other) was practically already there. And the next logical
    step was to integrate it with one. Microsoft sought a solution and ended up acquiring
    Revolution Analytics, which has put them on track again. Revolution R has addressed
    major issues concerning the R language.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft addressed R's limitations. Many of these limitations were aimed at
    faster data exploration and parallel programming techniques in R. In addition
    to this, also MKL computations have been enhanced, therefore making matrix-wise
    calculations even faster, along with scalar calculation and also calculation resulting
    in cartesian-products.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following limitations were addressed and also solved:'
  prefs: []
  type: TYPE_NORMAL
- en: Communication overhead is particularly an issue with fine-grained parallelism
    consisting of a very large number of relatively small tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load balance is where computing resources aren't contributing equally to the
    problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Impacts from the use of RAM and virtual memory, such as cache misses and page
    faults
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network effects, such as latency and bandwidth, that impact performance and
    communication overhead
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interprocess conflicts and thread scheduling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data access and other I/O considerations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalable and distributive computational environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `RevoScaleR` package has the following functions available, which will be
    covered in detail throughout the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a list of all the `ScaleR` functions, the following T-SQL can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You get a table in SSMS with all the relevant `rx` functions that can be used
    with the `RevoScaleR` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the list of these functions, a simpler and better overview of the
    functions can be prepared:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00070.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: List of RevoScaleR functions (source: Microsoft)'
  prefs: []
  type: TYPE_NORMAL
- en: Functions for data preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Importing data is the first of the many processes in data preparation. Importing
    data is a process of bringing data into your system from any external system using
    an external file or by establishing a connection to a live data source. In the
    following part, we will look at importing data that is stored as SPSS or SAS files
    and using an ODBC connection string to connect directly to an external live database
    system.
  prefs: []
  type: TYPE_NORMAL
- en: Data import from SAS, SPSS, and ODBC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Importing data into R or SQL Server tables is not the main focus of `RevoScaleR`
    library, but since this is on the list, let's briefly look into it. In this manner,
    based on your data source, the `RevoScaleR` package gives many abilities to connect
    to different data sources. Among these are also SAS and SPSS - two very broad
    and common statistical programs for data analysis and predictive analytics. We
    will simply focus on SAS software ([https://www.sas.com/](https://www.sas.com/)),
    SPSS Statistics, acquired by IBM in 2009 ([https://www.ibm.com/products/spss-statistics](https://www.ibm.com/products/spss-statistics)),
    or SPSS Modeler ([https://www.ibm.com/products/spss-modeler](https://www.ibm.com/products/spss-modeler)).
  prefs: []
  type: TYPE_NORMAL
- en: Importing SAS data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SAS is among the popular programs for data analysis if not the most popular
    for statistical analysis, data mining, and machine learning. Therefore, let's
    create a simple SAS file and read it using the `ScaleR` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the following SAS code (the code is available along with the book), you
    can very easily create a sample dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00071.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Outlook of SAS code'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's assume that our SAS data is stored in the file `sas_data.sas7bdat`
    as the code suggests in the `PROC DATA` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the following R code, we can extract and import this dataset into the
    R `data.frame`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure that your `sampleDataDir` holds the data sample. Also, you could
    specify some other path such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'However, you need to make sure that you have granted access to this working
    folder. In both ways, you should get results presented as a table, read from the
    SAS file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00072.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Outlook of SAS code result'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way of importing the SAS file is by using `RxSasData` directly (in
    this case, from R):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You can easily generate a histogram from the SAS data file.
  prefs: []
  type: TYPE_NORMAL
- en: Importing SPSS data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With SPSS, the procedure is similar. The following SPSS syntax (the syntax
    is included with this chapter) generates the sample dataset, which is stored on
    your local machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00073.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Outlook of SPSS syntax'
  prefs: []
  type: TYPE_NORMAL
- en: 'This involves getting data into R Services using the SPSS save file that is
    generated from the preceding SPSS syntax, which is relatively the same as with
    the SAS file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to this, the `RevoScaleR` package has a special function to directly
    read the SPSS file called `RxSpssData`. The following R code can accomplish the
    same result as the preceding T-SQL code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'And the `RevoScaleR` histogram can be used directly with the SPSS datasource,
    generating a simple histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00074.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Importing data using ODBC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the ODBC driver extends accessibility to almost any kind of database whose
    driver you can obtain and that has  a common RDBM model.
  prefs: []
  type: TYPE_NORMAL
- en: The `RevoScaleR` package extends the list of ODBS drivers also to support systems
    on Linux and other systems. Using ODBC, you can connect to MySQL, Oracle, PostgreSQL,
    SQL Server on Linux, Cloudera, and Teradata (which in this case is much better
    to use than the `RxTeradata` function).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example will use the ODBC driver to get data from another SQL
    server instance, both using the `RxOdbcData` and `RxSqlServerData` function, since
    they are interchangeable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This would be the same as running the following on the same server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In the case of using the `RxOdbcData` function, you should check the credentials
    and you might also want to check which user you are using to run the script. You
    can also create a new login and user and use it to check and execute the script:
    the `Adventureworks` database is available to download from Microsoft''s GitHub
    website ([https://github.com/Microsoft/sql-server-samples/tree/master/samples/databases/adventure-works](https://github.com/Microsoft/sql-server-samples/tree/master/samples/databases/adventure-works)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Variable creation and data transformation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Variable creation and data transformation are two processes when defining data
    munging and data wrangling tasks. These tasks are important for proper data preparation
    and make it easier to analyze data for future tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The functions that we will be exploring are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Variable creation and recoding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data transformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling missing values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sorting, merging, and splitting datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregate by category (which means sums), which is similar to T-SQL aggregations
    and Windows functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This part will cover some of the following functions, mainly focusing on data
    transformation, handling missing values, and splitting datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '`RxDataSource`, `rxDataStep`, `rxDataStepXdf`, `RxFileSystem`, `rxFindFileInPath`,
    `rxFindPackage`, `rxFisherTest`, `RxForeachDoPar`, `rxGetInfo`, `rxGetInfoXdf`,
    `rxGetJobInfo`, `rxGetJobInfo`, `rxGetOption`, `rxGetVarInfo`, `rxGetVarNames`,
    `rxImport`, `rxImportToXdf`, `rxIsOpen`, `rxOdbcData`, `rxOptions`, `rxOpen`,
    `rxQuantile`, `rxReadXdf`, `rxResultsDF`, `rxSetFileSystem`, `rxSetInfo`, `rxSetInfoXdf`,
    `rxSort`, `rxSetVarInfoXdf`, `rxSetVarInfo`, `rxMarginals`, `rxMerge`, `rxMergeXdf`'
  prefs: []
  type: TYPE_NORMAL
- en: When using In-database R Service (or the in-database machine learning service,
    also counting Python for SQL Server 2017), you should keep in mind where and how
    to do any kind of data transformation, data wrangling, as well as sorting and/or
    merging. After running many performance and speed tests, it became very clear
    that many of the munging and wrangling tasks should be done in-database, before
    sending the dataset to be executed by `sp_execute_external_script`. This set of
    functions is the only set where the computation context should be considered as
    a very important one. All the other functions for statistical tests, descriptive
    statistics, and predictive statistics can easily be used with external procedure,
    without compromising on performance or time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting with the `rxDataStep` function, it gives us many opportunities to
    extract and generate XDF files, using in-database R:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the `df_sql4.xdf` file on your sample data directory. If
    you are interested in where this folder is pointing to, you can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'It will be something similar to what is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00075.gif)'
  prefs: []
  type: TYPE_IMG
- en: And make sure that you have granted access for the user, executing the `rxDataStep`
    code, because the code will be creating a physical XDF file on the destination
    location.
  prefs: []
  type: TYPE_NORMAL
- en: Variable creation and recoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using `rxGetVarInfo` will expose the information about the `data.frame` to
    the `sp_execute_external_script` output. It is obvious that some of these functions
    were never designed for presenting the output to `data.frame`, but were designed
    only for exploring the dataset. Some of these functions-for example, `rxGetVarInfo`-will
    give a nice output in the R environment, but will be hard to manipulate in data
    frames for outputting in the SQL Server database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we are using the `unlist` function that unlists the set of lists
    in a single vector. Just to compare the output, we can run the same script in
    the R environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, running the `rxGetVarInfo(df_sql)` will give you a slightly different
    export:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'And after unlisting with the `unlist()` function, we get the same information,
    written in a slightly different manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This indicates that some of these functions for variable creation and recoding
    were meant more for R data engineers than for T-SQL data engineers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `rxGetInfo()` function will get you the size of your dataset and the number
    of observations/variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The same logic applies: if you run this R environment, you will get a neater
    display of information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding some additional parameters to this function also yields a richer output,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'A with `rxGetVarInfo`, `rxGetInfo` will create a list of elements. `rxGetVarInfo`
    will generate a list of lists, where the number of tuples equals the number of
    variables, and `rxGetInfo` will generate a list of six elements, where each list
    will hold information about the object:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00076.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Knowing this, the preceding T-SQL executions can be slightly altered so that
    the relevant information is displayed in a more readable format, by presenting
    elements (tuples) to the result set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The results returned in SQL Server Management Studio:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00077.gif)'
  prefs: []
  type: TYPE_IMG
- en: This looks very neat and spending some extra effort will for sure give much
    better formatted results that will be easier to read as well as much more informative.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, you have also seen how to create a new variable. This especially
    comes in handy when cleaning data or recoding/bucketing data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s suppose that you want to recode the values of existing variables in
    the dataset and create a new one. It can be done using standard R code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can do this using the `rxDataStep()` function and the `transformFunc`
    parameter with an additional function for creating a new variable by transforming
    old values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '`rxDataStep()X` is a very powerful function mainly for data selection, subsetting,
    data transformation, and the creation of new variables for the desired dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset subsetting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Subsetting the data is also relatively straightforward using the `rxDataStep()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind that subsetting operations using R code might bring unnecessary
    memory and I/O costs, especially when pumping whole datasets into R, instead of
    subsetting the data beforehand. In the preceding example, using the `rowSelection`
    parameter in `rxDataStep` can easily be replaced with the `WHERE` clause in the
    `@input_data_1` argument. So bear this in mind and always avoid unnecessary traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset merging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `rxMerge()` function merges two datasets into one. The datasets must be
    a dataframe (or XDF format) and operate similarly to the `JOIN` clause in T-SQL
    (the `rxMerge()` function should not be confused with T-SQL''s `MERGE` statement).
    Two datasets are merged based on one or more variables using the `matchVars` argument.
    In addition, when using the local compute context (which we are using in the next
    sample), the sorting of the data needs to be defined as well, since `data.frames`-as
    a collection of vectors-in R are not presorted or do not hold any sorts whatsoever.
    So, if no presorting is done, the `autoSort` argument must be set to true (`autosort
    = TRUE`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This T-SQL code creates a left join on both the datasets. Dataframe 2 (called `someExtraData`)
    is created on the fly, but it can be any other dataframe read from an XDF file
    or any manually inserted dataset, and will be joined at R runtime. Also, pay attention
    to which is the first and which is the second data frame in combination to which
    type of join you are using. The preceding example specifies the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'However, the order of the data frames could be changed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Then, the output would be presented differently (the sorting of the columns
    in the data frame would be changed).
  prefs: []
  type: TYPE_NORMAL
- en: Functions for descriptive statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Descriptive statistics give insights into understanding data. These are summary
    statistics that describe a given dataset by summarizing features and measures,
    such as central tendency and measure of spread (or variability). Central tendency
    includes calculation of the mean, median, mode, whereas measures of variability
    include range, quartiles, minimum and maximum value, variance and standard deviation,
    as well as skewness and kurtosis.
  prefs: []
  type: TYPE_NORMAL
- en: 'These statistics are covered by`rx-` functions in `RevoScaleR` package, which
    means that you can use all the computational advantages of the package by calling:
    `rxSummary`, `rxCrossTabs`, `rxMarginals`, `rxQuantile`, `rxCube`, and `rxHistogram`,
    without worrying about the performance, out of memory exceptions, or which R package
    holds the right function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be using the`[Sales].[vPersonDemographics]` view in the `AdventureWorks`
    database to neatly show the usability of these functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: With one line of R code, you can get some summary statistics. I prefer using
    the `summaryStats` argument to list the statistics, but note that the order of
    the statistics does not mean that the order of the output will be the same. In
    addition, using the element `summary$sDataFrame` dataframe as a result from `rxSummary` will
    automatically generate the data frame that will contain all the summaries for
    numeric variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of the T-SQL query is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00078.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'The `rxSummary()` function also holds a formula, whereby you can specify which
    variables the function will take into account while calculating descriptive statistics.
    In our case, we have used only the `TotalChildren` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'But let''s assume, we want to get descriptives for all the variables; we simply
    write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give us statistics for all the variables as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00079.gif)'
  prefs: []
  type: TYPE_IMG
- en: Note that only the integer (continuous) type of variables will be taken into
    consideration, whereas variables such as `MaritalStatus`, `Education`, and `Occupation`,
    will be presented as `NULL`, since these variables are treated as categorical
    variables in R.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, firstly, we will need to specify the factor variable, and based on
    that we will be able to run the statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This function will give simple counts for the `MaritalStatus` factor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The same logic can be applied to all other categorical variables. The formula
    in the `rxSummary()` function also gives users the ability to combine different
    variables. For example, instead of using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This will calculate the observed statistics for both the variables together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This can also be calculated for categorical variables. These variables need
    to be recoded into factors first and later the same summary statistics can be
    calculated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'And the complete R and T-SQL code using `sp_execute_external_script` is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are the results for each factor level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Quantiles and deciles are also very useful to view the data distribution and
    the `RevoScaleR` packages provides the `rxQuantile` function. Using T-SQL, the
    result set can be returned as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also modify and calculate deciles with a slight change to the `rxQuantile()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculating crosstabulations-the relationship between two (or more) variables-we
    will use two functions: `rxCrossTabs` and `rxMargins`. Crosstabulations are usually
    expressed in a contingency table or any other *[n]*[m] *table format; this really
    depends on the number of levels each variable will have.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use our two variables `NumberCarsOwned` and `TotalChildren` to explore
    the `rxCrossTabs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculating crosstabulations using `rxCrossTabs` can give you two types of
    statistics: the count of observations and the mean of observations, given the
    category of intersect. This is manipulated using the means `= TRUE` or means `=
    FALSE` argument. The function operates in a way that will need the dependent variable(s)
    and independent variables(s) and in our example, the information can be retrieved
    from the results as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: In order to have the crosstabulation successfully calculated, independent variables
    must be presented as factors. In this case, the `TotalChildren` variable has a
    `F()` function wrapped, denoting a factor conversion in the runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be visualized using a standard barplot in the base package or R:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00080.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the following code to plot the histogram using `barplot` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Using variables that are categorical, there is no need for explicit conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Also, the transform argument can be used to recode, recalculate, or somehow
    transform any of the variables. Marginal statistics from the contingency tables
    deriving from `rxCrossTabs` can be called using the `rxMarginals` functions, which
    is simply wrapped around the `rxCrossTabs`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Marginal statistics will give you the sum, counts, or mean for each of the
    totals per row or per column for the desired variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Exploring the data can also be done using the graphs and the `RevoScaleR` package
    comes with a Line and bar plot, both designed to tackle large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a simplistic preview of one of the variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00081.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the following line of R code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'This has already been converted to marital status factor as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00082.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Also, variables can be combined as follows (the marital status with the number
    of cars owned):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'And we get the following plot, showing marital status (**M** - married; **S**
    - single) and the total number of cars owned as a categorical variable (**0**
    - no car, **1** - 1 car owned, **2** - two cars owned, **3** - three cars owned,
    and **4** - four cars owned):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00083.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Instead of a bar plot, we can also use a Line plot, but this time with different
    variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'For the time period of little over half a year (between January 01 and July
    17^(th) 2001), the plot is showing a logarithmic variable for the total amount
    of purchases in this time period. In this case, we need to factorize the date
    variable and we are also using the `log()` function to level the purchases. And
    instead of using `rxHistogram`, we are using `rxLinePlot`, another `RevoScaleR`
    function, to plot graphs for large datasets. `rxLinePlot` represents a line chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00084.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'So, in the end, we can combine all three graphs using the `par()` function,
    arranging two columns, each having one or two graphs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Using graphs is good for storytelling, customer journey, or simply by great
    and fast understanding of the data, when combining the most informative variables.
    Another good way is to use markdown documentation and include multiple graphs
    in one block. An addition when using the `par()` function in combination with
    `rxHistogram` or `rxLinePlot` is that it might not always display graphs as expected.
    This is due to some compatibility issues with the `par()` function. Alternatively,
    using `print()` function and positioning each graph is another way to do it, without
    running into possible problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00085.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Functions for statistical tests and sampling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Statistical tests are important for determining the correlation between two
    (or more) variables and what is their direction of correlation (positive, neutral,
    or negative). Statistically speaking, the correlation is a measure of the strength
    of the association between two variables and their direction. The `RevoScaleR`
    package supports calculation of Chi-square, Fischer, and Kendall rank correlation.
    Based on the types of variable, you can distinguish between Kendall, Spearman,
    or Pearson correlation coefficient.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Chi-Square test, we will be using the `rxChiSquareTest()` function that
    uses the contingency table to see if two variables are related. A small chi-square
    test statistic means that the observed data fits your expected data very well,
    denoting there is a correlation, respectively. The formula for calculating chi-square
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00086.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Prior to calculating this statistical independence test, we must have data in
    the `xCrossTab` or xCube format. Therefore, the T-SQL query will need to generate
    the crosstabulations first in order to calculate the chi-square coefficient.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chi-square is generated on two categorical variables as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'With Kendall Tau you can calculate the correlation between the ranks and the
    result of the preceding correlation using R code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'This same principle can be used in a T-SQL query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Many other principles can be used to calculate correlations among variables.
    But this is beyond the scope of this book, and therefore we have focused only
    on the necessary ones.
  prefs: []
  type: TYPE_NORMAL
- en: Functions for predictive modeling will be covered in the next chapter - [Chapter
    6](part0096.html#2RHM00-e3f81285367248f4bbc6431bcd4f926d), *Predictive Modeling*.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has covered important functions (among many others) for data manipulation
    and data wrangling. These steps are absolutely and utterly important for understanding
    the structure of the dataset, the content of the dataset, and how the data is
    distributed. These are used to mainly understand frequencies, descriptive statistics,
    and also some statistical sampling, as well as statistical correlations.
  prefs: []
  type: TYPE_NORMAL
- en: 'These steps must be done (or should be done) prior to data cleaning and data
    merging in order to get a better understanding of the data. Cleaning the data
    is of the highest importance, as outliers might bring sensitive data (or any kind
    of data) to strange or false conclusions: it might also sway the results in some
    other direction. So, treating these steps as highly important by using the powerful
    `rx`- functions (or classes) should be the task of every data engineer, data wrangler,
    as well as data scientist. The next chapter will be focused on `RevoScaleR` functions
    for predictive modeling, mainly focusing on creating models and running the predictions
    against these models.'
  prefs: []
  type: TYPE_NORMAL
