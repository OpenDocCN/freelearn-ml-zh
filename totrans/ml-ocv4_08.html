<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Detecting Pedestrians with Support Vector Machines</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we talked about how to use decision trees for classification and regression. In this chapter, we want to direct our attention to another well-established supervised learner in the machine learning world:<span> </span><strong>support vector machines</strong><span> </span>(<strong>SVMs</strong>). Soon after their introduction in early 1990, SVMs quickly became popular in the machine learning community, largely because of their success in early handwritten digit classification. They remain relevant to this day, especially in application domains, such as computer vision.</p>
<p>The goal of this chapter is to apply SVMs to a popular problem in computer vision: pedestrian detection. In contrast to a recognition task (where we name the category of an object), the goal of a detection task is to say whether a particular object (or in our case, a pedestrian) is present in an image or not. You might already know that OpenCV can do this in two to three lines of code. But, we won't learn anything if we do it that way. So instead, we'll build the whole pipeline from scratch! We will obtain a real-world dataset, perform feature extraction using the<span> </span><strong>histogram of oriented gradients</strong><span> </span>(<strong>HOG</strong>), and apply an SVM to it.</p>
<p>In this chapter, we will implement SVMs in OpenCV with Python. We will learn to deal with <span>nonlinear decision boundaries and understand the kernel trick. By the end of the chapter, we will learn to detect pedestrians in the wild.</span></p>
<p>Along the way, we will cover the following topics:</p>
<ul>
<li>Implementing SVMs in OpenCV with Python</li>
<li>Dealing with nonlinear decision boundaries</li>
<li>Understanding the kernel trick</li>
<li>Detecting pedestrians in the wild</li>
</ul>
<p>Excited? Then let's go!</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Technical requirement</h1>
                </header>
            
            <article>
                
<p>You can refer to the codes for this chapter from the following link: <a href="https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter06">https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter06</a>.</p>
<p>Here is a short summary of the software and hardware requirements:</p>
<ul>
<li>OpenCV version 4.1.x (4.1.0 or 4.1.1 will both work just fine).</li>
<li>Python version 3.6 (any Python version 3.x will be fine).</li>
<li>Anaconda Python 3 for installing Python and the required modules.</li>
<li>You can use any operating system—macOS, Windows, and Linux-based OS—with this book. We recommend you to have at least 4 GB RAM in your system.</li>
<li>You don't need to have a GPU to run the code provided with the book.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Understanding linear SVMs</h1>
                </header>
            
            <article>
                
<p>In order to understand how SVMs work, we<span> </span>have<span> </span>to think about decision boundaries. When we used linear classifiers or decision trees in earlier chapters, our goal was always to minimize the classification error. We did this by assessing the accuracy using mean squared error. An SVM tries to achieve low classification errors too, but it does so only implicitly. An SVM's explicit objective is to maximize the margins between data points of</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Learning optimal decision boundaries</h1>
                </header>
            
            <article>
                
<p>Let's look at a simple example. Consider some<span> </span>training<span> </span>samples with only two features (<em>x</em><span> </span>and<span> </span><em>y</em><span> </span>values) and a corresponding target label (positive (+) or negative (-)). Since the labels are categorical, we know that this is a classification task. Moreover, because we<span> </span>only<span> </span>have two distinct classes (+ and -), it's a binary classification task.</p>
<p>In a binary classification task, a decision boundary is a line that partitions the training set into two subsets, one for each class. An<span> </span><strong>optimal</strong><span> </span><strong>decision</strong><span> </span><strong>boundary</strong><span> </span>partitions the data so that all data samples from one class (say, +) are to the left of the decision boundary, and all other data samples (say, -) are to the right of it.</p>

<p>An SVM updates its choice of a decision ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Implementing our first SVM</h1>
                </header>
            
            <article>
                
<p>But enough<span> </span>with<span> </span>the theory. Let's do some coding!</p>
<p>It might be a good idea to pace ourselves. For our very first SVM, we should probably focus on a simple dataset, perhaps a binary classification task.</p>
<p>A cool trick about scikit-learn's <kbd>datasets</kbd> module that I haven't told you about is that you can generate random datasets of controlled size and complexity. A few notable ones are as follows:</p>
<ul>
<li><kbd>datasets.make_classification([n_samples, ...])</kbd>: This function generates a random <em>n</em>-class classification problem, where we can specify the number of samples, the number of features, and the number of target labels</li>
<li><span><kbd>datasets.make_regression([n_samples, ...])</kbd>: This function generates a random regression problem</span></li>
<li><kbd>datasets.make_blobs([n_samples, n_features, ...])</kbd>: This function generates a number of Gaussian blobs we can use for clustering</li>
</ul>
<p><span>This means that we can use</span> <kbd>make_classification</kbd><span> </span><span>to build a custom dataset for a binary classification task.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Generating the dataset</h1>
                </header>
            
            <article>
                
<p>As we can now recite in our sleep, a<span> </span>binary<span> </span>classification problem has exactly two distinct target labels (<kbd>n_classes=2</kbd>). For the sake of simplicity, let's limit ourselves to only two feature values (<kbd>n_features=2</kbd>; for example, an<span> </span><em>x</em><span> </span>and a<span> </span><em>y</em><span> </span>value). Let's say we want to create 100 data samples:</p>
<pre>In [1]: from sklearn import datasets...     X, y = datasets.make_classification(n_samples=100, n_features=2,...                                         n_redundant=0, n_classes=2,...                                         random_state=7816)</pre>








<p>We expect<span> </span><kbd>X</kbd><span> </span>to have 100 rows (data samples) and 2 columns (features), whereas the<span> </span><kbd>y</kbd><span> vector </span>should have a single column that contains all the target labels:</p>
<pre>In [2]: X.shape, y.shapeOut[2]: ((100, 2), (100,))</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Visualizing the dataset</h1>
                </header>
            
            <article>
                
<p>We can plot these data points in a<span> </span>scatter<span> </span>plot using Matplotlib. Here, the idea is to plot the<span> </span><em>x</em><span> </span>values (found in the first column of<span> </span><kbd>X</kbd>,<span> </span><kbd>X[:, 0]</kbd>) against the<span> </span><em>y</em><span> </span>values (found in the second column of<span> </span><kbd>X</kbd>,<span> </span><kbd>X[:, 1]</kbd>). A neat trick is to pass the target labels as color values (<kbd>c=y</kbd>):</p>
<pre>In [3]: import matplotlib.pyplot as plt<br/>...     %matplotlib inline<br/>...     plt.scatter(X[:, 0], X[:, 1], c=y, s=100)<br/>...     plt.xlabel('x values')<br/>...     plt.ylabel('y values')<br/>Out[3]: &lt;matplotlib.text.Text at 0x24f7ffb00f0&gt;</pre>
<p>This will produce the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-912 image-border" src="Images/446f1f5d-ef34-4521-952f-09087174d16e.png" style="width:39.67em;height:24.92em;" width="862" height="541"/></p>
<p class="mce-root"/>
<p>The preceding output shows the r<span>andomly generated data for a binary classification problem. </span>You can see that, for the most part, data points of the two classes are clearly separated. However, there are a few regions (particularly near the left and bottom of the plot) where the data points of both classes intermingle. These will be hard to classify correctly, as we will see in just a second.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Preprocessing the dataset</h1>
                </header>
            
            <article>
                
<p>The next step is to split the<span> </span>data<span> </span>points into training and test sets, as we have done before. But, before we do that, we have to prepare the data for OpenCV as follows:</p>
<ul>
<li>All feature values in<span> </span><kbd>X</kbd><span> </span>must be 32-bit floating point numbers</li>
<li>Target labels must be either -1 or +1</li>
</ul>
<p>We can achieve this with the following code:</p>
<pre>In [4]: import numpy as np...     X = X.astype(np.float32)...     y = y * 2 - 1</pre>
<p>Now we can pass the data to scikit-learn's<span> </span><kbd>train_test_split</kbd><span> </span>function as we did in the earlier chapters:</p>
<pre>In [5]: from sklearn import model_selection as ms...     X_train, X_test, y_train, y_test = ms.train_test_split(...         X, y, test_size=0.2, random_state=42...     )</pre>
<p>Here, <span>I chose to reserve 20 percent of all data points for the test set, but ...</span></p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building the support vector machine</h1>
                </header>
            
            <article>
                
<p>In OpenCV, SVMs are built, trained, and scored the<span> </span>same<span> </span>exact way as every other learning algorithm we have encountered so far, using the following four steps:</p>
<ol>
<li>Call the<span> </span><kbd>create</kbd><span> </span>method to construct a new SVM:</li>
</ol>
<pre style="padding-left: 60px">In [6]: import cv2<br/>...     svm = cv2.ml.SVM_create()</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p style="padding-left: 60px"><span>As shown in the following command, there are different <em>modes</em> in which we can operate an SVM. For now, all we care about is the case we discussed in the previous example: an SVM that tries to partition the data with a straight line. This can be specified with the <kbd>setKernel</kbd> method:<br/></span></p>
<pre style="padding-left: 60px">In [7]: svm.setKernel(cv2.ml.SVM_LINEAR)</pre>
<ol start="2">
<li>Call the classifier's<span> </span><kbd>train</kbd><span> </span>method to find the optimal decision boundary:</li>
</ol>
<pre style="padding-left: 60px">In [8]: svm.train(X_train, cv2.ml.ROW_SAMPLE, y_train)<br/>      Out[8]: True</pre>
<ol start="3">
<li>Call the classifier's<span> </span><kbd>predict</kbd><span> </span>method to predict the target labels of all data samples in the test set:</li>
</ol>
<pre style="padding-left: 60px">In [9]: _, y_pred = svm.predict(X_test)</pre>
<ol start="4">
<li>Use scikit-learn's<span> </span><kbd>metrics</kbd><span> </span>module to score the classifier:</li>
</ol>
<pre style="padding-left: 60px">In [10]: from sklearn import metrics<br/>...      metrics.accuracy_score(y_test, y_pred)<br/>Out[10]: 0.80000000000000004</pre>
<p><span>Congratulations, we got 80 percent correctly classified test samples!</span></p>
<p>Of course, so far we have no idea what happened under the hood. For all we know, we might as well have got these commands off a web search and typed them into the Terminal, without really knowing what we're doing. But this is not who we want to be. Getting a system to work is one thing and understanding it is another.<span> </span><span>Let's get to that!</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Visualizing the decision boundary</h1>
                </header>
            
            <article>
                
<p>What was true in trying to<span> </span>understand<span> </span>our data is true for trying to understand our classifier: visualization is the first step in understanding a system. We know the SVM somehow came up with a decision boundary that allowed us to correctly classify 80 percent of the test samples. But how can we find out what that decision boundary actually looks like?</p>
<p>For this, we will borrow a trick from the guys behind scikit-learn. The idea is to generate a fine grid of<span> </span><em>x</em><span> </span>and<span> </span><em>y</em><span> </span>coordinates and run that through the SVM's<span> </span><kbd>predict</kbd><span> </span>method. This will allow us to know, for every<span> </span><em>(x, y)</em><span> </span>point, what target label the classifier would have predicted.</p>

<p>We will do this in a dedicated function, which we call<span> </span><kbd>plot_decision_boundary ...</kbd></p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Dealing with nonlinear decision boundaries</h1>
                </header>
            
            <article>
                
<p>What if the data cannot be optimally<span> </span>partitioned<span> </span>using a linear decision boundary? In such a case, we say the data is not linearly separable<em>.</em></p>
<p>The basic idea to deal with data that is not linearly separable is to create nonlinear combinations of the original features. This is the same as saying we want to project our data to a higher-dimensional space (for example, from 2D to 3D), in which the data suddenly becomes linearly separable.</p>
<p>This concept is illustrated in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-914 image-border" src="Images/61a436e0-d761-4823-bdb7-339eac903fe7.png" style="width:26.00em;height:12.50em;" width="1593" height="765"/></p>
<p>The preceding diagram shows how to find linear hyperplanes in higher-dimensional spaces. If data in its original input space (left) cannot be linearly separated, we can apply a mapping function<span> </span><em>ϕ(.)</em><span> </span>that projects the data from 2D into a 3D (or a high-dimensional) space. In this higher-dimensional space, we may<span> </span>find<span> </span>that there is now a<span> </span>linear<span> </span>decision boundary (which, in 3D, is a plane) that can<span> </span>separate<span> </span>the data.</p>
<div class="packt_infobox">A linear decision boundary in an <em>n</em>-dimensional space is called a<span> </span><strong>hyperplane</strong>. For example, a decision boundary in 6D feature space is a 5D hyperplane; in 3D feature space, it's a regular 2D plane; and in 2D space, it's a straight line.</div>
<p>However, one problem with this mapping approach is that it is impractical in large dimensions because it adds a lot of extra terms to do the mathematical projections between the dimensions. This is<span> </span>where<span> </span>the so-called<span> </span><strong>kernel trick</strong><span> </span>comes into play.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Understanding the kernel trick</h1>
                </header>
            
            <article>
                
<p>Granted, we won't have time to develop all the mathematics needed to truly understand the kernel trick. A more realistic section title would have been<span> </span><em>Acknowledging that something called the kernel trick exists and accepting that it works,</em><span> </span>but that would have been a bit wordy.</p>
<p>Here's the<span> </span>kernel<span> </span>trick in a nutshell.</p>
<p>In order to figure out the slope and orientation of the decision hyperplane in the high-dimensional space, we have to multiply all the feature values with appropriate weight values and sum them all up. The more dimensions our feature space has, the more work we have to do.</p>

<p>However, mathematicians smarter than us have long realized that an SVM has no need to explicitly work in the higher-dimensional ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Knowing our kernels</h1>
                </header>
            
            <article>
                
<p>OpenCV provides a whole range of SVM<span> </span>kernels to experiment with. Some of the most commonly used ones include the following:</p>
<ul>
<li><kbd>cv2.ml.SVM_LINEAR</kbd>: This is the kernel we used previously. It provides a linear decision boundary in the original feature space (the<span> </span><em>x</em><span> </span>and<span> </span><em>y</em><span> </span>values).</li>
<li><kbd>cv2.ml.SVM_POLY</kbd>: This kernel provides a decision boundary that is a polynomial function in the original feature space. In order to use this kernel, we also have to specify a coefficient via<span> </span><kbd>svm.setCoef0</kbd><span> </span>(usually set to <kbd>0</kbd>) and the degree of the polynomial via<span> </span><kbd>svm.setDegree</kbd>.</li>
<li><kbd>cv2.ml.SVM_RBF</kbd>: This kernel implements the kind of Gaussian function we discussed earlier.</li>
<li><kbd>cv2.ml.SVM_SIGMOID</kbd>: This kernel implements a sigmoid function, similar to the one we encountered when talking about logistic regression in<span> </span><a href="323dbb44-1e2b-4eaa-8cd1-2575e6766ffc.xhtml" target="_blank">Chapter 3</a>,<span> </span><em>First Steps in Supervised Learning</em>.</li>
<li><kbd>cv2.ml.SVM_INTER</kbd>:<span> </span><span>This kernel is a new addition to OpenCV 3. It separates classes based on the similarity of their histograms.</span></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Implementing nonlinear SVMs</h1>
                </header>
            
            <article>
                
<p>In order to test some of the<span> </span>SVM<span> </span>kernels we just talked about, we will return to our code sample mentioned earlier. We want to repeat the process of building and training the SVM on the dataset generated earlier, but this time, we want to use a whole range of different kernels:</p>
<pre>In [13]: kernels = [cv2.ml.SVM_LINEAR, cv2.ml.SVM_INTER,...                 cv2.ml.SVM_SIGMOID, cv2.ml.SVM_RBF]</pre>
<p>Do you remember what all of these stand for?</p>
<p>Setting a different SVM kernel is relatively simple. We take an entry from the<span> </span><kbd>kernels</kbd><span> </span>list and pass it to the<span> </span><kbd>setKernels</kbd><span> </span>method of the SVM class. That's all.</p>
<p>The laziest way to repeat things is to use a<span> </span><kbd>for</kbd><span> </span>loop as shown here:</p>
<pre>In [14]: for idx, kernel in enumerate(kernels):</pre>
<p>Then the steps are as follows: ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Detecting pedestrians in the wild</h1>
                </header>
            
            <article>
                
<p>We briefly talked about the difference<span> </span>between<span> </span>detection and recognition. While recognition is concerned with classifying objects (for example, as pedestrians, cars, bicycles, and so on), detection is basically answering the question: is there a pedestrian present in this image?</p>
<p>The core idea behind most detection algorithms is to split up an image into many small patches, and then classify each image patch as either containing a pedestrian or not. This is exactly what we are going to do in this section. In order to arrive at our own pedestrian detection algorithm, we need to perform the following steps:</p>
<ol>
<li>Build a database of images containing pedestrians. These will be our positive data samples.</li>
<li>Build a database of images not containing pedestrians. These will be our negative data samples.</li>
<li>Train an SVM on the dataset.</li>
<li>Apply the SVM to every possible patch of a test image in order to decide whether the overall image contains a pedestrian.</li>
</ol>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Obtaining the dataset</h1>
                </header>
            
            <article>
                
<p>For the purpose of this section, we will<span> </span>work<span> </span>with the MIT People dataset, which we are free to use for non-commercial purposes. So make sure not to use this in your groundbreaking autonomous start-up company before obtaining a corresponding software license.</p>
<div class="packt_infobox">However, if you followed our installation instructions from earlier and checked out the code on GitHub, you already have the dataset and are ready to go! The file can be found at<span> <a href="https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/blob/master/data/chapter6/pedestrians128x64.tar.gz" target="_blank">https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/blob/master/data/chapter6/pedestrians128x64.tar.gz</a></span>.</div>
<p><span>By referring to the following steps, you will</span> learn <span>to detect pedestrians in the wild:</span></p>
<ol>
<li>Since we are supposed to run this code from a Jupyter Notebook in the ...</li></ol></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Taking a glimpse at the histogram of oriented gradients (HOG)</h1>
                </header>
            
            <article>
                
<p>The HOG might just provide the<span> </span>help<span> </span>we're looking for in<span> </span>order<span> </span>to get this project done. The HOG is a feature descriptor for images, much like the ones we discussed in<span> </span><a href="142fec63-a847-4cde-9de9-c34805d2bb84.xhtml" target="_blank">Chapter 4</a>,<span> </span><em>Representing Data and Engineering Features</em>. It has been successfully applied to many different tasks in computer vision but seems to work especially well for classifying people.</p>
<p>The essential idea behind HOG features is that the local shapes and appearance of objects within an image can be described by the distribution of edge directions. The image is divided into small<span> </span>connected<span> </span>regions, within which a histogram of gradient directions (or edge directions) is compiled. Then, the descriptor is assembled by concatenating the different histograms. For improved performance, the local histograms can also be contrast-normalized, which results in better invariance to changes in illumination and shadowing.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The HOG descriptor is fairly accessible in OpenCV by means of<span> </span><kbd>cv2.HOGDescriptor</kbd>, which takes a bunch of input arguments, such as the detection window size (minimum size of the object to be detected, 48 x 96), the block size (how large each box is, 16 x 16), the cell size (8 x 8), and the cell stride (how many pixels to move from one cell to the next, 8 x 8). For each of these cells, the HOG descriptor then calculates a histogram of oriented gradients using nine bins:</p>
<pre>In [7]: win_size = (48, 96)<br/>...     block_size = (16, 16)<br/>...     block_stride = (8, 8)<br/>...     cell_size = (8, 8)<br/>...     num_bins = 9<br/>...     hog = cv2.HOGDescriptor(win_size, block_size, block_stride,<br/>...                             cell_size, num_bins)</pre>
<p>Although this function call looks fairly complicated, these are actually the only values for which the HOG descriptor is implemented. The argument that matters the most is the window size (<kbd>win_size</kbd>).</p>
<p>All that's left to do is call<span> </span><kbd>hog.compute</kbd><span> </span>on our data samples. For this, we build a dataset of positive samples (<kbd>X_pos</kbd>) by randomly picking pedestrian images from our data directory. In the following code snippet, we randomly select 400 pictures from the over 900 available, and apply the HOG descriptor to them:</p>
<pre>In [8]: import numpy as np<br/>...     import random<br/>...     random.seed(42)<br/>...     X_pos = []<br/>...     for i in random.sample(range(900), 400):<br/>...         filename = "%s/per%05d.ppm" % (extractdir, i)<br/>...         img = cv2.imread(filename)<br/>...         if img is None:<br/>...             print('Could not find image %s' % filename)<br/>...             continue<br/>...         X_pos.append(hog.compute(img, (64, 64)))</pre>
<p>We should also<span> </span>remember<span> </span>that OpenCV wants the feature matrix to contain 32-bit floating point numbers, and the target labels to be 32-bit integers. We don't mind, since converting to NumPy arrays will allow us to easily investigate the sizes of the matrices we created:</p>
<pre>In [9]: X_pos = np.array(X_pos, dtype=np.float32)<br/>...     y_pos = np.ones(X_pos.shape[0], dtype=np.int32)<br/>...     X_pos.shape, y_pos.shape<br/>Out[9]: ((399, 1980, 1), (399,))</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>It looks like we picked a total of 399 training samples, each of which has 1,980 feature values (which are the HOG feature values).</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Generating negatives</h1>
                </header>
            
            <article>
                
<p>The real challenge, however, is to<span> </span>come<span> </span>up with the perfect example of a non-pedestrian. After all, it's easy to think of example images of pedestrians. But what is the opposite of a pedestrian?</p>
<p>This is actually a common problem when trying to solve new machine learning problems. Both research labs and companies spend a lot of time creating and annotating new datasets that fit their specific purpose.</p>
<p>If you're stumped, let me give you a hint on how to approach this. A good first approximation to finding the opposite of a pedestrian is to assemble a dataset of images that look like the images of the positive class but do not contain pedestrians. These images could contain anything like cars, bicycles, streets, houses, ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Implementing the SVM</h1>
                </header>
            
            <article>
                
<p>We already know how to<span> </span>build<span> </span>an SVM in OpenCV, so there's nothing much to see here. Planning ahead, we wrap the training procedure into a function, so that it's easier to repeat the procedure in the future:</p>
<pre>In [15]: def train_svm(X_train, y_train):<br/>...          svm = cv2.ml.SVM_create()<br/>...          svm.train(X_train, cv2.ml.ROW_SAMPLE, y_train)<br/>...          return svm</pre>
<p>The same can be done for the scoring function. Here we pass a feature matrix,<span> </span><kbd>X</kbd><span> </span>and a label vector,<span> </span><kbd>y</kbd>, but we do not specify whether we're talking about the training or the test set. In fact, from the viewpoint of the function, it doesn't matter what set the data samples belong to, as long as they have the right format:</p>
<pre>In [16]: def score_svm(svm, X, y):<br/>...          from sklearn import metrics<br/>...          _, y_pred = svm.predict(X)<br/>...          return metrics.accuracy_score(y, y_pred)</pre>
<p>Then we can train and score the SVM with two short function calls:</p>
<pre>In [17]: svm = train_svm(X_train, y_train)<br/>In [18]: score_svm(svm, X_train, y_train)<br/>Out[18]: 1.0<br/>In [19]: score_svm(svm, X_test, y_test)<br/>Out[19]: 0.64615384615384619</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Thanks to the HOG feature descriptor, we make no mistake on the training set. However, our generalization performance is quite abysmal (64.6 percent), as it is much less than the training performance (100 percent). This is an indication that the model is overfitting the data. The fact that it is performing way better on the training set than the test set means that the model has resorted to memorizing the training samples, rather than trying to abstract it into a meaningful decision rule. What can we do to improve the model performance?</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Bootstrapping the model</h1>
                </header>
            
            <article>
                
<p>An interesting way to improve the performance of our model is to use bootstrapping. This idea was actually applied in one of the first papers on using SVMs in combination with HOG features for pedestrian detection. So let's pay a little tribute to the pioneers and try to understand what they did.</p>
<p>Their idea was quite simple. After training the SVM on the training set, they scored the model and found that the model produced some false positives. Remember that false positive means that the model predicted a positive (+) for a sample that was really a negative (-). In our context, this would mean the SVM falsely believed an image to contain a pedestrian. If this happens for a particular image in the dataset, this example ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Detecting pedestrians in a larger image</h1>
                </header>
            
            <article>
                
<p>What's left to do is to<span> </span>connect<span> </span>the SVM classification procedure with the process of detection. The way to do this is to repeat our classification for every possible patch in the image. This is similar to what we did earlier when we visualized decision boundaries; we created a fine grid and classified every point on that grid. The same idea applies here. We divide the image into patches and classify every patch as either containing a pedestrian or not.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>By following these steps, you will be able to detect a pedestrian in an image:</p>
<ol>
<li><span>We first</span> have to loop over all possible patches in an image as follows, each time shifting our region of interest by a small number of<span> </span><kbd>stride</kbd><span> </span>pixels:</li>
</ol>
<pre style="padding-left: 60px">In [23]: stride = 16<br/>...      found = []<br/>...      for ystart in np.arange(0, img_test.shape[0], stride):<br/>...          for xstart in np.arange(0, img_test.shape[1], stride):</pre>
<ol start="2">
<li>We want to make sure that we do not go beyond the image boundaries:</li>
</ol>
<pre style="padding-left: 60px">...              if ystart + hroi &gt; img_test.shape[0]:<br/>...                  continue<br/>...              if xstart + wroi &gt; img_test.shape[1]:<br/>...                  continue</pre>
<ol start="3">
<li>Then we cut out the ROI, preprocess it, and classify it:</li>
</ol>
<pre style="padding-left: 60px">...              roi = img_test[ystart:ystart + hroi,<br/>...                             xstart:xstart + wroi, :]<br/>...              feat = np.array([hog.compute(roi, (64, 64))])<br/>...              _, ypred = svm.predict(feat)</pre>
<ol start="4">
<li>If that particular patch happens to be classified as a pedestrian, we add it to the list of successes:</li>
</ol>
<pre style="padding-left: 60px">...              if np.allclose(ypred, 1):<br/>...                  found.append((ystart, xstart, hroi, wroi))</pre>
<ol start="5">
<li>Because pedestrians could appear not just at various locations but also in various sizes, we would have to rescale the image and repeat the whole process. Thankfully, OpenCV has a convenience function for this multi-scale detection task in the form of the<span> </span><kbd>detectMultiScale</kbd><span> </span>function. This is a bit of a hack, but we can pass all SVM parameters to the<span> </span><kbd>hog</kbd><span> </span>object:</li>
</ol>
<pre style="padding-left: 60px">In [24]: rho, _, _ = svm.getDecisionFunction(0)<br/>...      sv = svm.getSupportVectors()<br/>...      hog.setSVMDetector(np.append(sv.ravel(), rho))</pre>
<ol start="6">
<li>Then it's possible to call the detection function:</li>
</ol>
<pre style="padding-left: 60px">In [25]: found = hog.detectMultiScale(img_test)</pre>
<p style="padding-left: 60px">The function will return a list of bounding boxes that contain detected pedestrians.</p>
<p class="mce-root"/>
<div class="packt_tip">This seems to work only for linear SVM classifiers. The OpenCV documentation is terribly inconsistent across versions in this regard, so I'm not sure at which version this started or stopped working. Be careful!</div>
<ol start="7">
<li>In practice, when people are faced with a standard task such as pedestrian detection, they often rely on pre-scanned SVM classifiers that are built into OpenCV. This is the method that I hinted at in the very beginning of this chapter. By loading either<span> </span><kbd>cv2.HOGDescriptor_getDaimlerPeopleDetector()</kbd><span> </span>or<span> </span><kbd>cv2.HOGDescriptor_getDefaultPeopleDetector()</kbd>, we can get started with only a few lines of code:</li>
</ol>
<pre style="padding-left: 60px">In [26]: hogdef = cv2.HOGDescriptor()<br/>...      pdetect = cv2.HOGDescriptor_getDefaultPeopleDetector()<br/>In [27]: hogdef.setSVMDetector(pdetect)<br/>In [28]: found, _ = hogdef.detectMultiScale(img_test)</pre>
<ol start="8">
<li>It's easy to plot the test image with matplotlib as shown here:</li>
</ol>
<pre style="padding-left: 60px">In [29]: from matplotlib import patches<br/>...      fig = plt.figure()<br/>...      ax = fig.add_subplot(111)<br/>...      ax.imshow(cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB))</pre>
<ol start="9">
<li>Then we can mark the detected pedestrians in the image by looping over the bounding boxes in <kbd>found</kbd>:</li>
</ol>
<pre style="padding-left: 60px">...      for f in found:<br/>...          ax.add_patch(patches.Rectangle((f[0], f[1]), f[2], f[3],<br/>...                                         color='y', linewidth=3,<br/>...                                         fill=False))</pre>
<p style="padding-left: 60px">The result looks like this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-924 image-border" src="Images/7d871221-d88e-4ca8-9913-5c9e6c669582.png" style="width:23.08em;height:22.92em;" width="532" height="527"/></p>
<p>The preceding screenshot shows detected pedestrians in a test image.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Further improving the model</h1>
                </header>
            
            <article>
                
<p>Although the RBF kernel makes for a good default kernel, it is not always the one that works best for our problem. The only real way to know which kernel works best on our data is to try them all and compare the classification performance across models. There are strategic ways to<span> </span>perform<span> </span>this so-called<span> </span><strong>hyperparameter tuning</strong>, which we'll talk about in detail in<span> </span><a href="904bc419-cb0e-44cd-ae3f-8ce97e15baa2.xhtml" target="_blank">Chapter 11</a>,<span> </span><em>Selecting the Right Model with Hyperparameter Tuning.</em></p>
<p>What if we don't know how to do hyperparameter tuning properly yet?</p>
<p>Well, I'm sure you remember the first step in data understanding,<span> </span><em>visualize the data</em>. Visualizing the data could help us understand if a linear SVM was powerful enough to classify the data, in which case there would be no ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Multiclass classification using SVMs</h1>
                </header>
            
            <article>
                
<div>
<p>SVMs are inherently two-class classifiers. In particular, the most prevalent method of multi-class classification in practice has been to create <em>|C|</em> one-versus-rest classifiers (commonly referred to as <strong>one-versus-all</strong> (<strong>OVA</strong>) classification) where <em>|C|</em> is the number of classes<em><strong> </strong></em>and to choose the class that classifies the test datum with the highest margin. Another approach is to develop a set of one-versus-one classifiers and to select the class that is chosen by the most classifiers. While this involves building <em>|C|(|C| - 1)/2</em> classifiers, the time for training classifiers may decrease, since the training data set for each classifier is much smaller.</p>
</div>
<p>Now let's quickly jump onto how you can apply multi-class classification using SVMs with the help of a real-life dataset.</p>
<p>For the purpose of this section, we will<span> </span>work<span> </span>with the UCI Human Activity Recognition using smartphones dataset, which we are free to use for non-commercial purposes. So make sure not to use this in your groundbreaking autonomous start-up company before obtaining a corresponding software license.</p>
<p>The dataset can be obtained from the Kaggle website,<span> </span><a href="https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones" target="_blank">https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones</a>. There you should find a<span> </span><span class="packt_screen">Download</span><span> </span>button that leads you to a file called<span> </span><a href="https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones/downloads/human-activity-recognition-with-smartphones.zip/1" target="_blank">https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones/downloads/human-activity-recognition-with-smartphones.zip/1</a>.</p>
<div class="packt_infobox">However, if you followed our installation instructions from earlier and checked out the code on GitHub, you already have the dataset and are ready to go! The file can be found at<span> </span><kbd>notebooks/data/multiclass</kbd>.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">About the data</h1>
                </header>
            
            <article>
                
<p class="mce-root">A group of 30 volunteers were chosen within an age group of 19-48 years and the experiments were carried out on them. Six activities were performed by each person, namely <kbd>Walking</kbd>, <kbd>Walking_Upstairs</kbd>, <kbd>Walking_Downstairs</kbd>, <kbd>Sitting</kbd>, <kbd>Standing</kbd>, and <kbd>Laying</kbd> with the help of a smartphone fastened around the waist. Mainly three-axial linear acceleration and three-axial angular velocity at a constant rate of 50 Hz were captured using embedded accelerometer and gyroscope. To label the data, the experiments have been video-recorded. The dataset has been randomly split into two sets, where 70% of the volunteers were selected for generating the training data and 30% the test data.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Attribute information</h1>
                </header>
            
            <article>
                
<p>For each entry in the dataset, the following is provided:</p>
<ul>
<li class="mce-root">Triaxial acceleration from the accelerometer and the approximate acceleration of the body</li>
<li class="mce-root">Triaxial angular velocity from the gyroscope</li>
<li class="mce-root">Time and frequency domain variables with 561-feature vector</li>
<li class="mce-root">Various labels of activity</li>
<li class="mce-root">An identifier of the subject who was observed</li>
</ul>
<p class="mce-root">By referring to the following steps, you will learn how to build a multi-class classification using SVMs:</p>
<ol>
<li> Let's quickly import all the necessary libraries that you will need in order to implement an SVM with multi-class classification:</li>
</ol>
<pre style="padding-left: 60px">In [1]: import numpy as np<br/>...     import pandas as pd<br/>...     import matplotlib.pyplot as plt <br/>...     %matplotlib inline<br/>...     from sklearn.utils import shuffle<br/>...     from sklearn.svm import SVC<br/>...     from sklearn.model_selection import cross_val_score, GridSearchCV</pre>
<div>
<ol start="2">
<li>Next, you will be loading the dataset. Since we are supposed to run this code from a Jupyter Notebook in the<span> </span><kbd>notebooks/</kbd><span> </span>directory, the relative path to the data directory is simply<span> </span><kbd>data/</kbd>:</li>
</ol>
</div>
<div>
<pre style="padding-left: 60px">In [2]: datadir = "data"<br/>...     dataset = "multiclass"<br/>...     train = shuffle(pd.read_csv("data/dataset/train.csv"))<br/>...     test = shuffle(pd.read_csv("data/dataset/test.csv"))</pre></div>
<ol start="3">
<li>Let's check whether there are any missing values in the training and testing dataset; if there are any, then we will simply drop them from the dataset:</li>
</ol>
<pre style="padding-left: 60px">In [3]: train.isnull().values.any()<br/>Out[3]: False<br/>In [4]: test.isnull().values.any()<br/>Out[4]: False </pre>
<ol start="4">
<li>Next, we will find the frequency distribution of the classes in the data, which means that we will check how many samples belong to each of the six classes:</li>
</ol>
<pre style="padding-left: 60px">In [5]: train_outcome = pd.crosstab(index=train["Activity"], # Make a crosstab<br/> columns="count") # Name the count column<br/>... train_outcome</pre>
<p style="padding-left: 60px">From the following screenshot, you can observe that the <kbd>LAYING</kbd> class has the most samples, but overall, the data is approximately equally distributed and there are no major signs of class imbalance:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-926 image-border" src="Images/5196c8be-e10f-4176-ad2a-e2fb5e211252.png" style="width:12.00em;height:13.00em;" width="416" height="451"/></p>
<ol start="5">
<li><span>Next, we will separate out the predictors (input values) and outcome values (class labels) from the train and test datasets:</span></li>
</ol>
<pre style="padding-left: 60px">In [6]: X_train = pd.DataFrame(train.drop(['Activity','subject'],axis=1))<br/>...     Y_train_label = train.Activity.values.astype(object)<br/>...     X_test = pd.DataFrame(test.drop(['Activity','subject'],axis=1)) <br/>...     Y_test_label = test.Activity.values.astype(object)</pre>
<ol start="6">
<li>Since the SVM expects numerical input and labels, you will now transform the non-numerical labels into numerical labels. But first, we will have to import a  <kbd><span><span>preprocessing</span></span></kbd> module from the <kbd>sklearn</kbd> library:</li>
</ol>
<pre style="padding-left: 60px">In [7]: from sklearn import preprocessing<br/>... encoder = preprocessing.LabelEncoder()</pre>
<ol start="7">
<li>Now, we will encode the train and test labels into numerical values:</li>
</ol>
<pre style="padding-left: 60px">In [8]: encoder.fit(Y_train_label)<br/>...     Y_train = encoder.transform(Y_train_label)<br/>...     encoder.fit(Y_test_label)<br/>...     Y_test = encoder.transform(Y_test_label) </pre>
<ol start="8">
<li>Next, we will scale (normalise) the train and test feature set and for this, you will import <kbd><span><span>StandardScaler</span></span></kbd> from <kbd>sklearn</kbd>:</li>
</ol>
<pre style="padding-left: 60px">In [9]: from sklearn.preprocessing import StandardScaler<br/>...     scaler = StandardScaler()<br/>...     X_train_scaled = scaler.fit_transform(X_train)<br/>...     X_test_scaled = scaler.transform(X_test)</pre>
<ol start="9">
<li>Once the data is scaled and the labels are in a correct format, now is the time when we will fit the data. But before that, we will define a dictionary with the different parameter settings that the SVM will use while training itself, and this technique is called <kbd>GridSearchCV</kbd>. The parameter grid will be based on the results of a random search:</li>
</ol>
<pre style="padding-left: 60px">In [10]: params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],<br/>                     'C': [1, 10, 100, 1000]},<br/>                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]</pre>
<ol start="10">
<li>Finally, we will call <kbd>GridSearchCV</kbd> on the data using the preceding parameters for the best SVM fit:</li>
</ol>
<pre style="padding-left: 60px">In [11]: svm_model = GridSearchCV(SVC(), params_grid, cv=5)<br/>...      svm_model.fit(X_train_scaled, Y_train)</pre>
<ol start="11">
<li>It's time to check how well the SVM model was trained on the data; in short, we will find the accuracy. Not only that, but we will also check what the parameter settings were for which SVM performed the best:</li>
</ol>
<pre style="padding-left: 60px">In [12]: print('Best score for training data:', svm_model.best_score_,"\n") <br/>...      print('Best C:',svm_model.best_estimator_.C,"\n") <br/>...      print('Best Kernel:',svm_model.best_estimator_.kernel,"\n")<br/>...      print('Best Gamma:',svm_model.best_estimator_.gamma,"\n")<br/>Out[12]: Best score for training data: 0.986<br/>...      Best C: 100<br/>...      Best Kerne: rbf<br/>...      Best Gamma: 0.001</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>Voila! As we can see, the SVM achieved 98.6% accuracy on the training data on a multi-class classification problem. But hold down your horses until we find the accuracy on the test data. So, let's quickly check that:</p>
<pre>In [13]: final_model = svm_model.best_estimator_<br/>... print("Training set score for SVM: %f" % final_model.score(X_train_scaled , Y_train))<br/>... print("Testing set score for SVM: %f" % final_model.score(X_test_scaled , Y_test ))<br/>Out[13]: Training set score for SVM: 1.00<br/>... Testing set score for SVM: 0.9586</pre>
<p>Wow! Isn't that amazing? We were able to achieve 95.86% accuracy on the testing set; that's the power of SVMs.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we learned about SVMs in all their forms and flavors. We now know how to draw decision boundaries in 2D and hyperplanes in high-dimensional spaces. We learned about different SVM kernels and look at how to implement them in OpenCV.</p>
<p>In addition, we also applied our newly gained knowledge to the practical example of pedestrian detection. For this, we had to learn about the HOG feature descriptor, and how to collect suitable data for the task. We used bootstrapping to improve the performance of our classifier and combined the classifier with OpenCV's multi-scale detection mechanism.</p>
<p>Not only was that a lot to digest in a single chapter, but you have also made it through half of the book. Congrats!</p>
<p>In the next chapter, ...</p></article></section></div>



  </body></html>