["```py\nInstall-Package Stanford.NLP.CoreNLP\n```", "```py\njar xf stanford-corenlp-<version-number>-models.jar \n```", "```py\nusing System;\nusing System.IO;\nusing java.util;\nusing java.io;\nusing edu.stanford.nlp.pipeline;\nusing Console = System.Console;\n\nnamespace Tokenizer\n{\n    class Program\n    {\n        static void Main()\n        {\n            // Path to the folder with models extracted from Step #3\n            var jarRoot = @\"<path-to-your-model-files-dir>\";\n\n            // Text for processing\n            var text = \"We're going to test our CoreNLP installation!!\";\n\n            // Annotation pipeline configuration\n            var props = new Properties();\n            props.setProperty(\"annotators\", \"tokenize, ssplit, pos, lemma\");\n            props.setProperty(\"ner.useSUTime\", \"0\");\n\n            // We should change current directory, so StanfordCoreNLP could find all the model files automatically\n            var curDir = Environment.CurrentDirectory;\n            Directory.SetCurrentDirectory(jarRoot);\n            var pipeline = new StanfordCoreNLP(props);\n            Directory.SetCurrentDirectory(curDir);\n\n            // Annotation\n            var annotation = new Annotation(text);\n            pipeline.annotate(annotation);\n\n            // Result - Pretty Print\n            using (var stream = new ByteArrayOutputStream())\n            {\n                pipeline.prettyPrint(annotation, new PrintWriter(stream));\n                Console.WriteLine(stream.toString());\n                stream.close();\n            }\n\n            Console.ReadKey();\n        }\n    }\n}\n```", "```py\n// 1\\. Remove URL's\nstring urlPattern = @\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\";\nRegex rgx = new Regex(urlPattern);\ntweet = rgx.Replace(tweet, \"\");\n\n// 2\\. Remove Twitter ID's\nstring userIDPattern = @\"@\\w+\";\nrgx = new Regex(userIDPattern);\ntweet = rgx.Replace(tweet, \"\");\n\n// 3\\. Remove Numbers\nstring numberPattern = @\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\";\ntweet = Regex.Replace(tweet, numberPattern, \"\");\n\n// 4\\. Replace Hashtag\nstring hashtagPattern = @\"#\";\ntweet = Regex.Replace(tweet, hashtagPattern, \"\");\n```", "```py\n// 1\\. Replace Smiley Faces\nstring smileyFacePattern = String.Format(@\"{0}{1}[)dD]+|[)dD]+{1}{0}\", eyesPattern, nosePattern);\ntweet = Regex.Replace(tweet, smileyFacePattern, \" emo_smiley \");\n\n// 2\\. Replace LOL Faces\nstring lolFacePattern = String.Format(@\"{0}{1}[pP]+\", eyesPattern, nosePattern);\ntweet = Regex.Replace(tweet, lolFacePattern, \" emo_lol \");\n\n// 3\\. Replace Sad Faces\nstring sadFacePattern = String.Format(@\"{0}{1}\\(+|\\)+{1}{0}\", eyesPattern, nosePattern);\ntweet = Regex.Replace(tweet, sadFacePattern, \" emo_sad \");\n\n// 4\\. Replace Neutral Faces\nstring neutralFacePattern = String.Format(@\"{0}{1}[\\/|l*]\", eyesPattern, nosePattern);\ntweet = Regex.Replace(tweet, neutralFacePattern, \" emo_neutral \");\n\n// 5\\. Replace Heart\nstring heartPattern = \"<3\";\ntweet = Regex.Replace(tweet, heartPattern, \" emo_heart \");\n```", "```py\n// 1\\. Replace Punctuation Repeat\nstring repeatedPunctuationPattern = @\"([!?.]){2,}\";\ntweet = Regex.Replace(tweet, repeatedPunctuationPattern, \" $1_repeat \");\n\n// 2\\. Replace Elongated Words (i.e. wayyyy -> way_emphasized)\nstring elongatedWordsPattern = @\"\\b(\\S*?)(.)\\2{2,}\\b\";\ntweet = Regex.Replace(tweet, elongatedWordsPattern, \" $1$2_emphasized \");\n```", "```py\nprivate static string[] FormatTweets(Series<int, string> rows)\n{\n    var cleanTweets = rows.GetAllValues().Select((x, i) =>\n    {\n        string tweet = x.Value;\n        return CleanTweet(tweet);\n    });\n\n    return cleanTweets.ToArray();\n}\n```", "```py\nprivate static string CleanTweet(string rawTweet)\n{\n      string eyesPattern = @\"[8:=;]\";\n      string nosePattern = @\"['`\\-]?\";\n\n      string tweet = rawTweet;\n      // 1\\. Remove URL's\n      string urlPattern = @\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\";\n      Regex rgx = new Regex(urlPattern);\n      tweet = rgx.Replace(tweet, \"\");\n      // 2\\. Remove Twitter ID's\n      string userIDPattern = @\"@\\w+\";\n      rgx = new Regex(userIDPattern);\n      tweet = rgx.Replace(tweet, \"\");\n      // 3\\. Replace Smiley Faces\n      string smileyFacePattern = String.Format(@\"{0}{1}[)dD]+|[)dD]+{1}{0}\", eyesPattern, nosePattern);\n      tweet = Regex.Replace(tweet, smileyFacePattern, \" emo_smiley \");\n      // 4\\. Replace LOL Faces\n      string lolFacePattern = String.Format(@\"{0}{1}[pP]+\", eyesPattern, nosePattern);\n      tweet = Regex.Replace(tweet, lolFacePattern, \" emo_lol \");\n      // 5\\. Replace Sad Faces\n      string sadFacePattern = String.Format(@\"{0}{1}\\(+|\\)+{1}{0}\", eyesPattern, nosePattern);\n      tweet = Regex.Replace(tweet, sadFacePattern, \" emo_sad \");\n      // 6\\. Replace Neutral Faces\n      string neutralFacePattern = String.Format(@\"{0}{1}[\\/|l*]\", eyesPattern, nosePattern);\n      tweet = Regex.Replace(tweet, neutralFacePattern, \" emo_neutral \");\n      // 7\\. Replace Heart\n      string heartPattern = \"<3\";\n      tweet = Regex.Replace(tweet, heartPattern, \" emo_heart \");\n      // 8\\. Replace Punctuation Repeat\n      string repeatedPunctuationPattern = @\"([!?.]){2,}\";\n      tweet = Regex.Replace(tweet, repeatedPunctuationPattern, \" $1_repeat \");\n      // 9\\. Replace Elongated Words (i.e. wayyyy -> way_emphasized)\n      string elongatedWordsPattern = @\"\\b(\\S*?)(.)\\2{2,}\\b\";\n      tweet = Regex.Replace(tweet, elongatedWordsPattern, \" $1$2_emphasized \");\n      // 10\\. Replace Numbers\n      string numberPattern = @\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\";\n      tweet = Regex.Replace(tweet, numberPattern, \"\");\n      // 11\\. Replace Hashtag\n      string hashtagPattern = @\"#\";\n      tweet = Regex.Replace(tweet, hashtagPattern, \"\");\n\n      return tweet;\n}\n```", "```py\nrawDF.AddColumn(\"tweet\", processedTweets);\n```", "```py\nrawDF.SaveCsv(Path.Combine(dataDirPath, \"processed-training.csv\"));\n```", "```py\nprivate static Frame<int, string> CreateWordVec(Series<int, string> rows, ISet<string> stopWords, bool useLemma=false)\n        {\n            // Path to the folder with models extracted from `stanford-corenlp-<version>-models.jar`\n            var jarRoot = @\"<path-to-model-files-dir>\";\n\n            // Annotation pipeline configuration\n            var props = new Properties();\n            props.setProperty(\"annotators\", \"tokenize, ssplit, pos, lemma\");\n            props.setProperty(\"ner.useSUTime\", \"0\");\n\n            // We should change current directory, so StanfordCoreNLP could find all the model files automatically\n            var curDir = Environment.CurrentDirectory;\n            Directory.SetCurrentDirectory(jarRoot);\n            var pipeline = new StanfordCoreNLP(props);\n            Directory.SetCurrentDirectory(curDir);\n\n            var wordsByRows = rows.GetAllValues().Select((x, i) =>\n            {\n                var sb = new SeriesBuilder<string, int>();\n\n                // Annotation\n                var annotation = new Annotation(x.Value);\n                pipeline.annotate(annotation);\n\n                var tokens = annotation.get(typeof(CoreAnnotations.TokensAnnotation));\n                ISet<string> terms = new HashSet<string>();\n\n                foreach (CoreLabel token in tokens as ArrayList)\n                {\n                    string lemma = token.lemma().ToLower();\n                    string word = token.word().ToLower();\n                    string tag = token.tag();\n                    //Console.WriteLine(\"lemma: {0}, word: {1}, tag: {2}\", lemma, word, tag);\n\n                    // Filter out stop words and single-character words\n                    if (!stopWords.Contains(lemma) && word.Length > 1)\n                    {\n                        if (!useLemma)\n                        {\n                            terms.Add(word);\n                        }\n                        else\n                        {\n                            terms.Add(lemma);\n                        }\n                    }\n                }\n\n                foreach (string term in terms)\n                {\n                    sb.Add(term, 1);\n                }\n\n                return KeyValue.Create(i, sb.Series);\n            });\n\n            // Create a data frame from the rows we just created\n            // And encode missing values with 0\n            var wordVecDF = Frame.FromRows(wordsByRows).FillMissing(0);\n\n            return wordVecDF;\n        }\n```", "```py\n// Look at the sentiment distributions in our sample set\nvar sampleSetDistribution = rawDF.GetColumn<string>(\n    \"airline_sentiment\"\n).GroupBy<string>(x => x.Value).Select(x => x.Value.KeyCount);\nsampleSetDistribution.Print();\n```", "```py\ntweetLemmaVecDF.AddColumn(\n    \"tweet_polarity\", \n    rawDF.GetColumn<string>(\"airline_sentiment\").Select(\n        x => x.Value == \"neutral\" ? 0 : x.Value == \"positive\" ? 1 : 2\n    )\n);\ntweet_polarity, to the term matrix data frame. We are taking the values of theÂ airline_sentiment column and encoding 0 for neutral, 1 for positive, and 2 for negative. We are going to use this newly added column in our future model building steps.\n```", "```py\nvar neutralTermFrequencies = ColumnWiseSum(\n    tweetLemmaDF.Where(\n        x => x.Value.GetAs<int>(\"tweet_polarity\") == 0\n    ),\n    \"tweet_polarity\"\n).Sort().Reversed;\n\nvar positiveTermFrequencies = ColumnWiseSum(\n    tweetLemmaDF.Where(\n        x => x.Value.GetAs<int>(\"tweet_polarity\") == 1\n    ),\n    \"tweet_polarity\"\n).Sort().Reversed;\n\nvar negativeTermFrequencies = ColumnWiseSum(\n    tweetLemmaDF.Where(\n        x => x.Value.GetAs<int>(\"tweet_polarity\") == 2\n    ),\n    \"tweet_polarity\"\n).Sort().Reversed;\n```", "```py\nprivate static Series<string, double> ColumnWiseSum(Frame<int, string> frame, string exclude)\n{\n    var sb = new SeriesBuilder<string, double>();\n    foreach(string colname in frame.ColumnKeys)\n    {\n        double frequency = frame[colname].Sum();\n        if (!colname.Equals(exclude))\n        {\n            sb.Add(colname, frequency);\n        }\n    }\n\n    return sb.ToSeries();\n}\n```", "```py\nvar nbSplitSet = new SplitSetValidation<NaiveBayes<BernoulliDistribution>, double[]>()\n{\n    Learner = (s) => new NaiveBayesLearning<BernoulliDistribution>(),\n\n    Loss = (expected, actual, p) => new ZeroOneLoss(expected).Loss(actual),\n\n    Stratify = false,\n\n    TrainingSetProportion = 0.8,\n\n    ValidationSetProportion = 0.2\n};\nvar nbResult = nbSplitSet.Learn(input, output);\nSplitSetValidationÂ objectâTrainingSetProportionandÂ ValidationSetProportion. As the name suggests, you can define what percentage of your sample set is should be used for training with theÂ TrainingSetProportionparameter andÂ what percentage of your sample set to be used for validation with theÂ ValidationSetProportionÂ parameter. Here in our code snippet, we are telling our program to use 80% of our sample for training and 20% for validation. In the last line of the code snippet, we fit a Naive Bayes classification model to the train set that was split from the sample set. Also, note here that we used BernoulliDistribution for our Naive Bayes classifier, as we used one-hot encoding to encode our features and all of our features have binary values, similar to what we did in the previous chapter.\n```", "```py\nvar rfSplitSet = new SplitSetValidation<RandomForest, double[]>()\n{\n    Learner = (s) => new RandomForestLearning()\n    {\n        NumberOfTrees = 100, // Change this hyperparameter for further tuning\n\n        CoverageRatio = 0.5, // the proportion of variables that can be used at maximum by each tree\n\n        SampleRatio = 0.7 // the proportion of samples used to train each of the trees\n\n    },\n\n    Loss = (expected, actual, p) => new ZeroOneLoss(expected).Loss(actual),\n\n    Stratify = false,\n\n    TrainingSetProportion = 0.7,\n\n    ValidationSetProportion = 0.3\n};\nvar rfResult = rfSplitSet.Learn(input, output);\n```", "```py\n// Get in-sample & out-sample prediction results for NaiveBayes Classifier\nvar nbTrainedModel = nbResult.Model;\n\nint[] nbTrainSetIDX = nbSplitSet.IndicesTrainingSet;\nint[] nbTestSetIDX = nbSplitSet.IndicesValidationSet;\n\nConsole.WriteLine(\"* Train Set Size: {0}, Test Set Size: {1}\", nbTrainSetIDX.Length, nbTestSetIDX.Length);\n\nint[] nbTrainPreds = new int[nbTrainSetIDX.Length];\nint[] nbTrainActual = new int[nbTrainSetIDX.Length];\nfor (int i = 0; i < nbTrainPreds.Length; i++)\n{\n   nbTrainActual[i] = output[nbTrainSetIDX[i]];\n   nbTrainPreds[i] = nbTrainedModel.Decide(input[nbTrainSetIDX[i]]);\n}\n\nint[] nbTestPreds = new int[nbTestSetIDX.Length];\nint[] nbTestActual = new int[nbTestSetIDX.Length];\nfor (int i = 0; i < nbTestPreds.Length; i++)\n{\n   nbTestActual[i] = output[nbTestSetIDX[i]];\n   nbTestPreds[i] = nbTrainedModel.Decide(input[nbTestSetIDX[i]]);\n}\n```", "```py\n// Get in-sample & out-sample prediction results for RandomForest Classifier\nvar rfTrainedModel = rfResult.Model;\n\nint[] rfTrainSetIDX = rfSplitSet.IndicesTrainingSet;\nint[] rfTestSetIDX = rfSplitSet.IndicesValidationSet;\n\nConsole.WriteLine(\"* Train Set Size: {0}, Test Set Size: {1}\", rfTrainSetIDX.Length, rfTestSetIDX.Length);\n\nint[] rfTrainPreds = new int[rfTrainSetIDX.Length];\nint[] rfTrainActual = new int[rfTrainSetIDX.Length];\nfor (int i = 0; i < rfTrainPreds.Length; i++)\n{\n    rfTrainActual[i] = output[rfTrainSetIDX[i]];\n    rfTrainPreds[i] = rfTrainedModel.Decide(input[rfTrainSetIDX[i]]);\n}\n\nint[] rfTestPreds = new int[rfTestSetIDX.Length];\nint[] rfTestActual = new int[rfTestSetIDX.Length];\nfor (int i = 0; i < rfTestPreds.Length; i++)\n{\n    rfTestActual[i] = output[rfTestSetIDX[i]];\n    rfTestPreds[i] = rfTrainedModel.Decide(input[rfTestSetIDX[i]]);\n}\n```"]