- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Segmenting Customers with Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the rising availability of data on customer characteristics and behaviors,
    it has become more accessible to approach customers with more informed insights.
    From analyzing the drivers behind customer engagements that we discussed in *Chapter
    3* to understanding which specific products that individual customers may like,
    which we touched on in *Chapter 7*, the assumptions behind these approaches were
    based on the fact that there are certain groups of similar customers that behave
    in similar fashions.
  prefs: []
  type: TYPE_NORMAL
- en: Targeted marketing approaches are proven to work significantly better than mass
    marketing, due to which **customer segmentation** has been a frequently discussed
    topic in this domain. Also, with the upcoming cookieless world, first-party data
    is expected to play an even more critical role. Consequently, targeted strategies
    based on customer segments, such as geographic segments, demographic segments,
    or interest topic segments that will still be available without browser cookies,
    are going to be critical for success.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: One-time versus repeat customers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer segmentation with K-means clustering and purchase behaviors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer segmentation with **large language models** (**LLMs**) and product
    interests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One-time versus repeat customers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: According to *BIA Advisory Services*, which provides some very clear metrics,
    repeat customers spend 67% more than new customers on average. Also, a survey
    conducted by *BIA Advisory Services* says that over half of the surveyed businesses’
    revenue comes from repeat customers rather than new customers. This signifies
    the fact that retaining existing customers is as important as growing the customer
    base. However, businesses often sacrifice customer service to gain new customers.
  prefs: []
  type: TYPE_NORMAL
- en: '**BIA Advisory Services report**'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.bia.com/small-business-owners-shift-investment-from-customer-acquisition-to-customer-engagement-new-report-by-manta-and-biakelsey/](https://www.bia.com/small-business-owners-shift-investment-from-customer-acquisition-to-customer-engagement-new-report-by-manta-and-biakelsey/)'
  prefs: []
  type: TYPE_NORMAL
- en: The need to retain customers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several benefits that indicate why retaining customers is so important
    to businesses:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Less investment**: The first obvious reason is that new customers cost more.
    If you recall a typical customer life cycle from *Chapter 2*, you need to spend
    capital and marketing resources to promote brand awareness among potential new
    customers, engage prospects with your business, and then finally convert them
    into paying customers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B30999_08_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.1: The customer life cycle'
  prefs: []
  type: TYPE_NORMAL
- en: For existing customers, you can skip these steps and focus your efforts on retaining
    them as repeat customers by providing great customer service and introducing products
    that interest them enough. Obtaining new customers often costs multiple times
    more than keeping existing customers.
  prefs: []
  type: TYPE_NORMAL
- en: '**Greater reliability**: Repeat customers bring more reliable and recurring
    revenue to your business. As previously mentioned, repeat customers often contribute
    more than half of the revenue for businesses and spend more than new customers.
    As you provide products or services that existing customers like and as you provide
    better customer services, your customers may become loyal to your brand and continue
    to purchase products.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, if you are selling pet products, such as pet food or pet toys,
    and they like your products, they may come back next month to purchase more or
    even subscribe to get monthly pet foods delivered to them. This results in a reliable
    and recurring revenue stream that is going to strengthen the cash flow of your
    business, which you can use to invest more into your products, which will bring
    in more revenue. This starts the positive cycle for your business.
  prefs: []
  type: TYPE_NORMAL
- en: '**Building brand loyalty**: Repeat customers who are loyal to your business
    bring in more new customers. As you may recall from *Chapter 2*, loyal customers
    act as your brand ambassadors and marketing agents, where they spread the word
    about your business and bring in new customers. Without having to spend more marketing
    dollars, these loyal customers promote your business and attract new customers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many more subtle benefits to having a strong repeat customer base,
    but these are the three most obvious benefits of having repeat customers, and
    demonstrate how they help businesses significantly.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the impact of retaining customers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s take a look at a practical example of the kinds of impacts these repeat
    customers have on the business compared to new customers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Source code and data**: [https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.8](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.8
    )'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data source**: [https://archive.ics.uci.edu/dataset/352/online+retail](https://archive.ics.uci.edu/dataset/352/online+retail)'
  prefs: []
  type: TYPE_NORMAL
- en: 'As always, we will start by importing the data into a `pandas` DataFrame. Take
    a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here, we load the data into a `pandas` DataFrame, `df`. As we are only interested
    in comparing new versus repeat customers, we are going to drop the rows with `NaN`
    values using the `dropna` function and only take the customers who have purchased
    at least one or more items by filtering with `df["Quantity"] > 0`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we are going to create the following additional variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Sales amount**: By simply multiplying the quantity that the customers have
    purchased by the individual price of the items, we can get the total sales amount
    for each order. In the following code, we create a new column named `Sales`, which
    has the total sales amount for each order:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '**Month variable**: In order to decide whether a given customer is a new customer
    or not, we need to consider the time horizon of the data. If a given customer
    has not purchased any items previously, then this customer will be considered
    new. On the other hand, if a given customer has purchased an item previously,
    then we will consider this customer a repeat customer. For this exercise, we are
    going to look at month-over-month data, which will require us to create a variable
    for what month the invoice was created. In the following code, we convert the
    column, `InvoiceDate`, into the `datetime` type and cast `InvoiceDate` into each
    month. For example, the date `2011-02-23` will be cast to `2011-02-01`:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'With these two variables, we can now start dissecting whether the sales are
    from the new or repeat customers. Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s take a closer look at this code. We first iterate through each month
    in the `month` variable. For each iteration, we find the unique customers in the
    given month and store them as a set into a variable, named `curr_customers`. We
    do the same for the past customers by getting the unique customers up to the given
    month and storing them as a set in a variable named `prev_customers`. Based on
    these two variables, we can identify the new customers from the repeat customers
    by using some set operations:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we find the intersection between `curr_customers` and `prev_customers`,
    which represent the repeat customers as we have seen these customers in our sales
    data already.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we subtract the `prev_customers` set from the `curr_customers` set, which
    gives us the new customers as these are the customers that we have not seen before.
    From these operations, we have successfully identified new versus repeat customers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on these `prev_customers` and `curr_customers` sets, we can find the revenue
    from the new and repeat customers. Using the `isin` function, we select the `CustomerIDs`
    that match the IDs in the set of `new_customers` and compute the total sales from
    the new customers by summing all the sales amounts from these customers and the
    average sales amount for the new customers by taking a mean of all the sales amounts
    from these customers. Similarly, using the `isin` function, we select the `CustomerIDs`
    that match the IDs in the set of `repeat_customers` and compute the total sales
    from the repeat customers. We do this by summing all the sales amounts from these
    customers and the average sales amount for the repeat customers by taking a mean
    of all the sales amounts from these customers. We save this data into a variable,
    `monthly_data`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We do one last set of computations as in the following and will be ready to
    look at the differences between the new and repeat customers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code simply converts the data into a `pandas` DataFrame and computes what
    percentage of customers are actually repeat customers and what percentage of sales
    are from the repeat customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’re done, let’s take a look at the monthly customer counts and the
    breakdowns between the new and repeat customers using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce the following chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.2: The number of new versus repeat customers'
  prefs: []
  type: TYPE_NORMAL
- en: The bars on the left for each time period represent the number of new customers
    for each month and the bars on the right represent the number of repeat customers.
    As you can see, the composition of the repeat customers grows over time and there
    is some cycle in terms of the influx of the new customers. We see more new customers
    at the beginning and end of the year and dips during the summertime from June
    to August.
  prefs: []
  type: TYPE_NORMAL
- en: The line chart shows what percentage of the customers in each month were repeat
    customers and as this chart suggests, it grew from around 40% in January 2011
    to around 80% in November 2011.
  prefs: []
  type: TYPE_NORMAL
- en: This indicates a very healthy business. It shows continuous demand and purchases
    from the customers who have made previous purchases from this business. The number
    of repeat customers continuously grows, which suggests that the products and services
    this business provides continuously attract customers who have once interacted
    with this business. For a business that lacks attractive products and/or good
    customer service, the number of repeat customers will typically decrease. One
    thing to note here though is that the rate of new customer influx is relatively
    steady and not growing. This, of course, is better than a decreasing new customer
    count over time, but this shows that there is a growth potential to capture more
    new customers. Given that there is a healthy repeat and recurring customer base,
    the marketers can focus on new customer acquisition more for this business.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, let’s take a look at the sales amount from the new and repeat customers.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This code produces the following chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.3: Sales from new versus repeat customers'
  prefs: []
  type: TYPE_NORMAL
- en: Similar to before, the bars on the left represent the sales amount from new
    customers and the bars on the right represent the sales amount from repeat customers.
    As was the case with a number of customer comparisons before, the sales amount
    from repeat customers outweighs the sales amount from new customers. This suggests
    that there is a strong continuous recurring revenue from repeat customers. The
    percentage of sales from the repeat customers reached above 80% in November 2011\.
    This is somewhat expected as we have discussed previously how repeat customers
    often take up more than half of the revenue for the businesses. Another point
    discussed previously and reported by *BIA Advisory Services* was that repeat customers
    typically spend 67% more than new customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s see what our data says about this business by comparing average monthly
    sales from new customers against repeat customers. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This code should produce a chart like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_04.png)Figure 8.4: Average sales from new versus repeat customers'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the bars on the left are the average sales from the new customers
    and the bars on the right are the average sales from the repeat customers for
    each month. The line plot shows the ratios between the average sales of the new
    customers versus those of the repeat customers. For example, if the ratio is `1.5`,
    it means that the repeat customers spent `1.5` times more than the new customers
    on average during that month. Based on this example dataset, we see that, on average,
    repeat customers spent more than the average customers for all months reported.
    In November 2011, the ratio was `1:1.58`, which suggests that the repeat customers
    spent about 60% more than the new customers on average. This aligns with the *BIA
    Advisory Services* report that repeat customers spend significantly more than
    new customers on average.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this exercise, we have dissected the customer base into two simple segments:
    new versus repeat. As you may have noticed, this is a simple analytical exercise
    to conduct, but this produces powerful insights into the dynamics and health of
    the business and also tells the marketers which group of customers to focus on.'
  prefs: []
  type: TYPE_NORMAL
- en: If there is a strong recurring customer base with continuous recurring revenue,
    but it shows steadiness or a decreasing new customer base, it suggests that marketers
    should focus more on new customer acquisition.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if there is a decline in repeat customers, it suggests that
    the products and services may not be attractive for customers to come back or
    that the customer service does not meet the customer expectations. In this case,
    the marketers should focus on improving the product marketing strategies, customer
    satisfaction strategies, or other marketing strategies to attract customers to
    come back for repeated purchases.
  prefs: []
  type: TYPE_NORMAL
- en: Customer segmentation with purchase behaviors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Segmenting customers based on new versus repeat customers is one of the basic
    and critical analyses to conduct. However, oftentimes, we would like to segment
    customers based on multiple factors, which can be demographic factors, such as
    age, geolocation, and occupation, or purchase history, such as how much they spent
    in the past year, how many items they have purchased, and how many returns they
    have requested. You can also segment based on customer web activities, such as
    number of logins in the past X number of days, how long they stay on your webpage,
    and what pages they look at.
  prefs: []
  type: TYPE_NORMAL
- en: There are still challenges to segmenting customers based on these factors, as
    there are an infinite number of ways and values you can segment the customers
    by. For example, if you are segmenting your customers by age, some of the questions
    that may arise are “`how many buckets should I create?`" or “`what age cutoff
    thresholds should I choose?`". Similarly, if you want to segment your customers
    by past sales volume, you will still have to choose what thresholds to use to
    break down the customer base and how many segments you want to create.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, when you combine these segments across multiple factors, the number
    of segments grows exponentially. For example, if you have 2 segments based on
    the sales volume and combine it with the other 2 segments from purchase quantity,
    you will end up with 4 segments. If you had 3 segments for both factors, then
    you would end up with 9 segments in total. In summary, there are mainly three
    key questions to be answered in conducting customer segmentation:'
  prefs: []
  type: TYPE_NORMAL
- en: What factor(s) should be used for customer segmentation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How many segments should be created?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What thresholds should be used to break down into segments?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are going to use the online retail dataset that we have used previously as
    an example and discuss how to answer these key questions with the K-means clustering
    algorithm and silhouette score for measuring the effectiveness of clusters.
  prefs: []
  type: TYPE_NORMAL
- en: K-means clustering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: K-means clustering is one of the most frequently used machine learning algorithms
    for clustering and segmentation. It is a method to partition the data into *k*
    clusters. In short, the algorithm iteratively finds the centroids and groups the
    data points to the nearest centroids until the data points are closer to their
    centroids than to their neighboring centroids. As you can imagine, the data points
    in our case will be the factors of interest, such as sales amount, quantity, and
    refund, and the “*k*” in K-means clustering is how many clusters or customer segments
    we would like to create.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to create customer segments based on the total sales amount, order
    quantity, and refunds, we need to do some prep work. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we first get the net sales and quantity for each customer. This will
    subtract any refunds and returned items as there are some records with negative
    `Sales` and `Quantity` values. Next, we get the information about the refunds.
    We assume any quantity that is negative is a refund. Thus, we get the total refund
    amount by summing all the sales with the negative quantity values and the total
    refund quantity by summing all the order quantities with the negative quantity
    values. Lastly, we merge these two DataFrames by the index, which is the customer
    ID. The resulting DataFrame should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.5: The resulting net sales, net quantity, refund amount, and refund
    quantity'
  prefs: []
  type: TYPE_NORMAL
- en: 'One thing to note here is that the data is highly skewed. Take a look at the
    following code, which we will be using to generate histograms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.6: Data distribution'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see from these histograms, the data is highly skewed to the right.
    This occurs often, especially when the data has monetary or quantity values. Skewness
    in data causes disproportionate clusters with suboptimal segmentation of data.
    One simple approach to overcome this skewness is to log transform the data, using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can generate the log-transformed data’s histograms using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are the histograms that are generated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.7: Log-transformed data distribution'
  prefs: []
  type: TYPE_NORMAL
- en: As expected, the log-transformed data is more centered around the mean and closer
    to a bell curve. We are going to examine clustering both with and without log
    transformation and see how it affects the clustering results.
  prefs: []
  type: TYPE_NORMAL
- en: Without log transformation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Training a K-means clustering algorithm in Python is straightforward. Take
    a look at the following code, where we import the `KMeans` module in the `scikit-learn`
    package to build a K-means clustering algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we are building customer segments based on the three columns,
    `NetSales`, `NetQuantity`, and `TotalRefundQuantity`. Then, we are building four
    clusters by using the parameter `n_clusters`. The `labels_` attribute of the trained
    `KMeans` model has the assigned labels (0 through 3) for each row or customer
    and the `cluster_centers_` attribute shows the centroids of each cluster.
  prefs: []
  type: TYPE_NORMAL
- en: '**Randomness in K-means clustering**'
  prefs: []
  type: TYPE_NORMAL
- en: As K-means clustering is an algorithm with iterative approaches to updating
    centroids from the original randomly selected centroids, there is a randomness
    in K-means clustering that results in slightly different results each time it
    is run. If you would like to get the same results each time, you would want to
    set the `random_state` variable.
  prefs: []
  type: TYPE_NORMAL
- en: The examples in this chapter do not use the `random_state` variable, so your
    results may look slightly different from the charts you see here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s visualize the clusters so that we can visually inspect how the K-means
    clustering algorithm has segmented the customer base using the three factors we
    are interested in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we first define a function, `plot_clusters`, to 2D plot each cluster,
    where it takes the DataFrame as an input with the two columns for x- and y-axes.
    Then, we create three plots: one to visualize the clusters based on `NetSales`
    and `NetQuantity`, another for `NetSales` and `TotalRefundQuantity`, and a third
    for `NetQuantity` and `TotalRefundQuantity`. The three resulting plots should
    look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.8: Clusters based on NetSales versus NetQuantity'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.9: Clusters based on NetSales versus TotalRefundQuantity'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.10: Clusters based on NetQuantity versus TotalRefundQuantity'
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figures 8.8*, *8**.9*, and *8.10*, we can easily see how clusters are formed
    based on the pairs. For instance, cluster `0` seems to be the customers who have
    low net sales, low net quantity, and low refunds, and cluster `1` seems to be
    the customers who have low-mid net sales, low-mid net quantity, and low refunds.
    However, there are two things that stand out in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: Some clusters have a wide range of points. Cluster `0`, as an example, has a
    wide range of refund quantity that ranges from `0` to `80,000` if you look at
    *Figure 8.10*. This makes it difficult to describe what cluster `0` actually signifies
    and how it is different from other clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another thing to note here is that most of the data points are in cluster `0`
    and very few are in other clusters. Cluster `3` seems to contain only two data
    points. These large imbalances in cluster sizes make generalizations from these
    clusters less reliable as insights based on a few data points are not so trustable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can take a look at the number of data points in each cluster using the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the details of each cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.11: The number of data points in each cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Data skewness often causes these problems as it makes the K-means clustering
    algorithm difficult to find or effectively cluster the data points. This is the
    reason why we need to normalize the data before applying clustering algorithms
    when there is a skewness in the data.
  prefs: []
  type: TYPE_NORMAL
- en: With log transformation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s see how log transformation may help customer segmentation using K-means
    clustering. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we use the previously defined variable, `log_customer_df`, which is the
    log-transformed data, using the `np.log` function. We then fit a K-means clustering
    model with four clusters. We can see what the cluster sizes look like now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.12: The number of data points in each cluster after log transformation'
  prefs: []
  type: TYPE_NORMAL
- en: 'Compared to earlier in the chapter, when we fit the clustering model without
    the log transformation, the clusters are more balanced, with each cluster having
    a significant number of customers. This is going to give better insights into
    how customers are segmented based on the three factors of our interest: net sales,
    net quantity, and total refunds. Let’s visualize the clusters with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This code should create three charts similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.13: Clusters on NetSales versus NetQuantity after transformation'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.14: Clusters on NetSales versus TotalRefundQuantityafter transformation'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.15: Clusters on NetQuantity versus TotalRefundQuantity after transformation'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive deeper into these cluster visualizations. There is no clear separation
    between clusters based on the net sales and net quantity if you look at *Figure
    8.13*. Cluster `3` seems more centered around the mean, while cluster `1` tends
    more toward higher net sales and higher net quantity, and the clusters `0` and
    `2` more toward lower net sales and lower net quantity. Despite these subtle differences,
    all clusters seem to cluster around the means of net sales and net quantity.
  prefs: []
  type: TYPE_NORMAL
- en: 'The distinctions between clusters are more clear in *Figures 8.14* and *8**.15*.
    Cluster `1` seems to be the customer segment with high total refunds, with the
    cutoff threshold around `4` in the log scale. You can convert this log-transformed
    value by reverting the transformation we have applied previously or by using the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The `X` in this code is the value in the log scale and `COLUMN` in this code
    is the factor of interest. Let’s take a closer look at these clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cluster 0**: This cluster seems to be the cluster with low total refunds
    and low net quantity. The thresholds for `TotalRefundQuantity` in the log scale
    are around `2` and `6.7` for `NetQuantity`. These numbers equate to `6.4` in total
    refunds and `811.4` in net quantity, using the preceding equation. This suggests
    that the customers in this cluster have less than `6.4` total refunds and have
    a net quantity less than `811.4`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster 1**: This cluster seems to be the group of customers who have got
    refunds the most frequently. The cutoff threshold for cluster `1` seems to be
    around `4` in the log scale of `TotalRefundQuantity` and using the code above,
    this equates to `54 (np.exp(4) + customer_df.min()["TotalRefundQuantity"] - 1)`.
    Thus, cluster `1` is the segment of customers with above 54 total refunds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster 2**: This cluster seems to be the customer segment with mid-total
    refunds with a threshold of around `2` in the log scale of `TotalRefundQuantity`,
    which equates to about `6` in actual total refunds. Thus, cluster `2` is the segment
    of customers with total refunds between `6` and `54`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster 3**: The customers in cluster `3` seem to be the ones with low total
    refunds but high net quantity. This customer segment may be the sweet spot for
    the business as it suggests that they buy frequently from the business but do
    not get as many refunds as other customers in different segments. Given that their
    cutoff thresholds for total refunds in the log scale are around `2` and `6.7`
    for net quantity, this group of customers are the ones with less than 6 in total
    refunds and more than `811` in net quantity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see in this exercise, the K-means clustering algorithm is helpful
    in segmenting the customers in an ML way without having to define the thresholds
    for each customer segment manually for yourselves. This programmatic approach
    helps you define customer segments more dynamically and in a more data-driven
    way. This way, you can better understand how different customer segments are grouped
    and what the separating factors are, which then can be used to strategize and
    prioritize for your future marketing efforts.
  prefs: []
  type: TYPE_NORMAL
- en: Silhouette score
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have seen how to build customer segments with the K-means clustering algorithm.
    One of the key arguments to build the clusters was the number of clusters. However,
    you may wonder how to decide or how you would know the right number of clusters
    before you build such clusters. In a practical setting, you would want to build
    multiple clusters with different numbers of clusters and decide which one works
    the best. This is where the **silhouette score** comes in. Simply put, the silhouette
    score is a metric that quantifies how well a given data point fits into its cluster
    and how distinguishable it is from other clusters. The formula for the silhouette
    score looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_001.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *a*[i] is the average distance of the *i*^(th) data point to all other
    points in the same cluster and *b*[i] is the minimum average distance of the *i*^(th)
    data point to all other points in the other clusters.
  prefs: []
  type: TYPE_NORMAL
- en: In order to get the silhouette scores for a clustering algorithm, you need to
    get the average of all individual silhouette scores for each data point. Silhouette
    scores range between `-1` and `1`. The closer the score is to `1`, the better
    the data points are clustered together and the more distinct they are from adjacent
    clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Silhouette scores can easily be computed in Python. The `scikit-learn` package
    in Python has a function, `silhouette_score`, which computes the average silhouette
    score for the clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'As a higher silhouette score value suggests better clusters, we can utilize
    this to decide what the ideal number of clusters is. Take a look at the following
    code, where we are experimenting with clusters of sizes from `4` to `8`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'For each cluster, we compute the silhouette scores and check what percentage
    of data points are in each cluster. Ideally, the best cluster is the one with
    the highest silhouette score and the highest number of data points evenly distributed
    among each cluster. This code should generate the output that follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.16: The cluster size experimentation results'
  prefs: []
  type: TYPE_NORMAL
- en: 'This chart shows a couple of important decision factors when you are figuring
    out what the best cluster size should be:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Silhouette scores**: First, we can see the silhouette scores for each cluster
    size, where it is `0.4986` for the cluster of size `4`, `0.5391` for the cluster
    of size `5`, and so forth. Here, the silhouette score for the cluster of size
    `5` seems to be the highest with `0.5391`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster sizes and compositions**: We should also evaluate if the data points
    in each cluster are somewhat evenly distributed, as large imbalances among the
    clusters may not be reliable enough to generate the best insights. The horizontal
    bar charts in *Figure 8.16* show the cluster compositions for each cluster size.
    The dotted vertical line shows where the bars should be if the composition is
    completely evenly distributed. As can be seen in these charts, clusters with high
    silhouette scores do not necessarily mean the best clusters. Cluster `5`, for
    example, has the highest overall silhouette score, but has a large imbalance where
    the *0*^(th) cluster has close to 70% of data points and the rest shares a small
    portion of the data. This is not an ideal cluster as too much of the data is in
    one cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this example, a cluster of size `4` may be the best choice as the data points
    are more evenly distributed across the clusters compared to others, even though
    the silhouette score is not the highest.
  prefs: []
  type: TYPE_NORMAL
- en: Customer segmentation with product interests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have discussed how we can build customer segments based on their purchase
    history in the previous section and how this can inform marketers on which segment
    to prioritize and strategize for the next marketing effort. Not only can we segment
    customers based on their purchase history, or more specifically with numerical
    values, but we can also find customer segments based on their product interests.
  prefs: []
  type: TYPE_NORMAL
- en: The items that customers purchase have hidden insights into what types of items
    each customer is interested in and what they are likely to purchase more of. There
    are multiple approaches to segmenting customers based on the products that they
    have purchased in the past, such as simply grouping by the product categories
    that they have purchased from. However, in this exercise, we are going to expand
    on the topic of the embedding vectors that we touched on in *Chapter 5*.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have not already, you may need to install Hugging Face’s `transformers`
    using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As previously discussed in *Chapter 5*, modern LLMs like **BERT** and **GPT**
    introduced contextual embeddings, where the words and sentences are transformed
    into numerical values or vectors that represent the contextual meanings. We will
    be using the pre-trained LLM `all-MiniLM-L6-v2` from Hugging Face to encode past
    product purchases for each customer in our example dataset and build customer
    segments using these embedding vectors. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here, we first get all the product descriptions of products that the customers
    have bought and then create a comma-separated list for each of the customers,
    which gets stored in the variable `customer_item_df`. Then, we load the pre-trained
    LLM, `sentence-transformers/all-MiniLM-L6-v2`, and encode the list of product
    descriptions for each customer into numerical vectors by using the `encode` function
    of the pre-trained LLM. This will result in a vector of 384 values for each customer.
    We then save this array into `tmp.npy` for future usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'In high-dimensional space, the distances between data points become less meaningful
    as the volume increases due to larger dimensions making data too sparse. As the
    K-means clustering algorithm uses distance metrics to cluster data points together,
    this becomes an issue. In order to overcome this, we need to apply some dimensionality
    reduction techniques. In this exercise, we will simply apply **principal component
    analysis** (**PCA**) to reduce the dimensions of the embedding vectors while retrieving
    most of the variance within the data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we import the `PCA` module in the `scikit-learn` package. We import the
    previously built embedding vectors from the temporary location, `tmp.npy`, and
    fit and transform the vector by using the `fit_transform` function. We have defined
    it to return 5 components, as you can see from the `n_components` parameter. The
    resulting vector, `transforemd_encoded`, should have a size of 5 vectors for each
    customer.
  prefs: []
  type: TYPE_NORMAL
- en: '**Other dimensionality reduction approaches**'
  prefs: []
  type: TYPE_NORMAL
- en: There are numerous dimensionality reduction techniques other than PCA. In our
    exercise, we used PCA for its simplicity, but T-SNE and UMAP are two others that
    are frequently used when dealing with high-dimensional data. Be sure to check
    them out and see if they may be a better fit for this exercise!
  prefs: []
  type: TYPE_NORMAL
- en: '**T-SNE**: [https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '**UMAP**: [https://umap-learn.readthedocs.io/en/latest/](https://umap-learn.readthedocs.io/en/latest/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it’s finally the time to build customer segments or clusters based on these
    embedding vectors, which have contextual understandings of the products that each
    customer has bought. Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This code should look familiar, as this is almost the exact same code as before
    when we built clusters using purchase history with the K-means clustering algorithm.
    The main difference here is instead of the sales metrics, we use the embedding
    vectors as the input to `KMeans` to build clusters. The output of this code should
    look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.17: The silhouette scores for different cluster sizes'
  prefs: []
  type: TYPE_NORMAL
- en: The actual values may differ as there is some randomness in fitting a K-means
    clustering algorithm, but the trend should be similar.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on this, we are going to build 7 clusters based on the embedding vectors,
    as in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this code, we build 7 clusters. Then, for each cluster, we get the top 5
    most common items that customers in each cluster have purchased by using the `collections`
    library in Python. We then store these top 5 most commonly bought items for each
    cluster in a DataFrame named `common_items_df`. This DataFrame should give us
    insights into what types of products interest each customer segment the most.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a closer look at this DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_08_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.18: The top 5 common items for each cluster'
  prefs: []
  type: TYPE_NORMAL
- en: 'This gives us the following insights:'
  prefs: []
  type: TYPE_NORMAL
- en: The customers in the first cluster or the cluster indexed at 0 seem to have
    the most interest in some decoration items, such as ornaments and wooden frames.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The customers in the second cluster or the cluster indexed at 1 seem to show
    interest in party-related items, such as baking sets, party bunting, and cards.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The customers in the third cluster or the cluster indexed at 2 seem to be into
    teas or tea ceremonies, as they bought teacups and saucers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fourth cluster’s customers seem to like purchasing bags.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fifth cluster’s customers seem to like water bottles, and so forth.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, these customer clusters show what they are mostly interested
    in and how different customers can be grouped together by their product interests.
    These are going to be powerful insights as you build your next marketing strategies
    and campaigns. You may not want to promote tea sets to those who are interested
    in purchasing water bottles and vice versa. This misaligned targeting will result
    in wasteful marketing campaigns with low success rates in engagements and conversions.
    You would want to take these findings about different customer segments based
    on their product interests and build more targeted marketing campaigns for each
    segment with the product categories they are most interested in.
  prefs: []
  type: TYPE_NORMAL
- en: This way, you are more likely to have successful marketing campaigns with more
    success in drawing customer engagements and conversions.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed different ways to segment the customer base. We
    first looked at how new versus repeat customers contribute to revenue, as well
    as how monthly progressions of new and repeat customer numbers can tell us which
    segment or group of customers to focus on during the next marketing campaigns.
    Then, we discussed how the K-means clustering algorithm can be used to programmatically
    build and identify different customer segments. Using the sales amount, order
    quantity, and refunds, we experimented with how these factors can be used to build
    different customer segments. In lieu of doing it, we touched on silhouette scores
    as a criterion for finding the best number of clusters and how log transformation
    can be beneficial when dealing with highly skewed datasets. Lastly, we used word
    and sentence embedding vectors to convert the product descriptions into numerical
    vectors with contextual understanding and further built customer segments based
    on their product interests.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapters, we are going to explore LLMs even further. From creating
    compelling content using pre-trained zero-shot models to more advanced few-shot
    and RAG approaches, we will touch more on LLMs and generative AI in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/genai](https://packt.link/genai)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code12856128601808671.png)'
  prefs: []
  type: TYPE_IMG
