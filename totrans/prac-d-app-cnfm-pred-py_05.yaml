- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Types of Conformal Predictors
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正规预测器的类型
- en: This chapter describes different families of conformal predictors, exploring
    various approaches to quantifying uncertainty. Through practical examples, we
    provide an intermediate-level understanding of these techniques and how they can
    be applied to real-world situations.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了不同类型的正规预测器家族，探讨了量化不确定性的各种方法。通过实际例子，我们提供了对这些技术及其如何应用于现实世界情况的中间水平理解。
- en: Here are examples of how companies are using conformal prediction.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是公司如何使用正规预测的例子。
- en: At a high-profile AI developer conference called GTC 2023 ([https://www.nvidia.com/gtc/](https://www.nvidia.com/gtc/)),
    Bill Dally, NVIDIA’s chief scientist and SVP of research, offered insights into
    one of NVIDIA’s R&D primary focuses, which is in conformal prediction ([https://www.hpcwire.com/2023/03/28/whats-stirring-in-nvidias-rd-lab-chief-scientist-bill-dally-provides-a-peek/](https://www.hpcwire.com/2023/03/28/whats-stirring-in-nvidias-rd-lab-chief-scientist-bill-dally-provides-a-peek/)).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在一场名为GTC 2023的知名AI开发者大会上（[https://www.nvidia.com/gtc/](https://www.nvidia.com/gtc/))，NVIDIA的首席科学家兼研究高级副总裁比尔·达利（Bill
    Dally）分享了对NVIDIA研发主要关注点之一的见解，即正规预测（[https://www.hpcwire.com/2023/03/28/whats-stirring-in-nvidias-rd-lab-chief-scientist-bill-dally-provides-a-peek/](https://www.hpcwire.com/2023/03/28/whats-stirring-in-nvidias-rd-lab-chief-scientist-bill-dally-provides-a-peek/))。
- en: Traditional machine learning models for autonomous vehicles output a single
    classification (e.g., pedestrian or no pedestrian on the road) and position estimate
    for detected objects. However, NVIDIA wants to produce a set of potential outputs
    with probabilities; for example, an object could be a pedestrian (80% probability)
    or cyclist (20% probability) at a position of 20 +/- 1 meters.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 传统自动驾驶车辆机器学习模型输出单个分类（例如，道路上是否有行人）和检测到的对象的定位估计。然而，NVIDIA希望产生一组带有概率的潜在输出；例如，一个物体可能是行人（80%概率）或骑自行车者（20%概率），位于20
    +/- 1米的某个位置。
- en: This allows the vehicle’s planner to guarantee safe actions accounting for multiple
    possible outcomes. Rather than just the most likely label and position, conformal
    prediction provides a range of plausible options, such as “pedestrian at 19–21
    meters” with 80% confidence.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得车辆的规划者能够保证考虑到多种可能结果的安全行动。正规预测不仅提供最可能标签和位置，还提供一系列可能的选项，例如“80%置信度的行人位于19-21米处”。
- en: NVIDIA uses a nonconformity function to calculate probabilities that measure
    how strange or different each potential label and position is compared to the
    training data. This generates a multi-modal predictive distribution reflecting
    uncertainty.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA使用非一致性函数来计算概率，这些概率衡量每个潜在标签和位置相对于训练数据的奇异或不同程度。这生成一个多模态预测分布，反映了不确定性。
- en: Conformal prediction gives NVIDIA’s vehicles a reliable way to quantify uncertainty
    and consider multiple interpretations of the environment. By planning for the
    entire set of plausible outcomes rather than just the single most likely one,
    conformal prediction improves robustness and safety.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正规预测为NVIDIA的车辆提供了一种可靠的方式来量化不确定性，并考虑环境的多重解释。通过规划所有可能的结局，而不仅仅是单一的最可能结局，正规预测提高了鲁棒性和安全性。
- en: In the realm of machine learning, quantifying uncertainty and providing reliable
    predictions is of significant importance. Conformal prediction is an innovative
    technique that allows us to construct prediction sets (in classification) and
    prediction intervals (in regression), offering a measure of confidence in our
    predictions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的领域，量化不确定性和提供可靠的预测具有重要意义。正规预测是一种创新技术，它允许我们构建预测集（在分类中）和预测区间（在回归中），为我们预测提供信心度量的指标。
- en: This chapter aims to provide a deeper understanding of the different types of
    conformal predictors and their respective approaches to quantifying uncertainty.
    Through practical examples, we will illustrate how these techniques can be applied
    to various machine learning tasks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在提供对不同类型正规预测器和它们量化不确定性的各自方法的更深入理解。通过实际例子，我们将展示这些技术如何应用于各种机器学习任务。
- en: 'In this chapter, we will explore the following topics:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨以下主题：
- en: Foundations of classical and inductive conformal predictors
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经典和归纳正规预测器的基础
- en: Examining algorithmic descriptions of conformal predictors
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查正规预测器的算法描述
- en: Mathematical formulations and practical examples
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数学公式和实际例子
- en: Advantages and limitations of conformal predictors
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正规预测器的优缺点
- en: Guidelines for choosing the most suitable conformal predictor for specific problem
    domains
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择最适合特定问题域的最合适一致预测器的指南
- en: Let’s start with the classical conformal predictors.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从经典一致预测开始。
- en: Understanding classical predictors
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解经典预测器
- en: Before we deep dive into the intricacies of conformal predictors, let’s briefly
    recap the key concepts from the previous chapters. Conformal prediction is a framework
    that enables creating confidence regions for our predictions while controlling
    the error rate.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨一致预测的复杂性之前，让我们简要回顾一下前几章的关键概念。一致预测是一个框架，它允许我们在控制错误率的同时为我们的预测创建置信区域。
- en: 'This approach is especially beneficial in situations where a measure of uncertainty
    is essential, such as in medical diagnosis, self-driving cars, or financial risk
    management. The framework encompasses two main types of conformal predictors:
    **classical** and **inductive**.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法在需要不确定性度量的情况下特别有益，例如在医学诊断、自动驾驶汽车或金融风险管理中。该框架包括两种主要类型的一致预测器：**经典**和**归纳**。
- en: '**Classical transductive conformal prediction** (**TCP**) is the original form
    of conformal prediction developed by the inventors of Conformal prediction. It
    forms the basis for understanding the general principles of conformal predictors.
    Classical Conformal prediction was developed to construct prediction regions that
    conform to a specified confidence level. The critical aspect of classical Conformal
    prediction is its distribution-free nature, meaning it makes no assumptions about
    the data distribution. Thus, it can be applied to any machine learning algorithm,
    making it algorithm-agnostic.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**经典传输归纳一致预测**（**TCP**）是一致预测的原始形式，由一致预测的发明者开发。它构成了理解一致预测一般原则的基础。经典一致预测是为了构建符合指定置信水平的预测区域而开发的。经典一致预测的关键方面是其无分布性质，这意味着它不对数据分布做出任何假设。因此，它可以应用于任何机器学习算法，使其具有算法无关性。'
- en: In contrast to the widely used inductive conformal prediction, classical TCP
    does not require a separate calibration set, enabling a more efficient utilization
    of the entire dataset.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 与广泛使用的归纳一致预测相比，经典TCP不需要单独的校准集，从而更有效地利用整个数据集。
- en: As a result, for smaller datasets, it can generate more accurate predictions.
    This approach allows statistical, machine learning, and deep learning models to
    fully capitalize on all available data, potentially leading to more efficient
    (narrower) prediction sets and intervals.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于较小的数据集，它可以生成更准确的预测。这种方法允许统计、机器学习和深度学习模型充分利用所有可用数据，可能导致更有效（更窄）的预测集和区间。
- en: Let’s discuss how classical TCP can be used in classification problems.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下经典TCP如何在分类问题中使用。
- en: Applying TCP for classification problems
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将TCP应用于分类问题
- en: In classification tasks, not only do we seek to assign labels, but we aim to
    do so confidently and accurately. This is where classical TCP shines. As we delve
    into its use in classification, we will cover its unique approach and advantages
    over traditional techniques. Ready to explore? Let’s dive into the nuances of
    TCP for classification!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类任务中，我们不仅寻求分配标签，而且希望这样做既自信又准确。这正是经典TCP（传输归纳一致预测）的亮点所在。当我们深入研究其在分类中的应用时，我们将介绍其独特的方法和相对于传统技术的优势。准备好探索了吗？让我们深入了解分类中TCP的微妙之处！
- en: In the previous chapters, we discussed the core concept of the conformal prediction
    framework, which involves assigning a nonconformity measure (or strangeness) to
    each object in the dataset. This measure is utilized to rank the objects within
    the dataset. Subsequently, when predicting a new object, a prediction region is
    created that encompasses values linked to a specific proportion of the dataset
    objects, determined by their strangeness scores. This proportion corresponds to
    the desired confidence level for the predictions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们讨论了一致预测框架的核心概念，即对数据集中的每个对象分配一个非一致性度量（或奇异度）。这个度量被用来对数据集中的对象进行排序。随后，在预测一个新对象时，创建一个包含与数据集中对象特定比例值相关的预测区域，这个比例由它们的奇异度得分确定。这个比例对应于预测所需的置信水平。
- en: In contrast to the more popular inductive conformal prediction method, which
    relies on a calibration set to rank objects based on their nonconformity scores,
    classical TCP employs the entire dataset in conjunction with the features of the
    new object to establish the prediction region.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 与更受欢迎的归纳一致性预测方法相比，后者依赖于校准集根据对象的非一致性分数对对象进行排序，经典TCP则结合使用整个数据集和新对象的特征来建立预测区域。
- en: While this approach can be computationally expensive, it allows you to fully
    leverage the whole dataset to capture changes in the data distribution, providing
    more accurate prediction regions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种方法在计算上可能很昂贵，但它允许你充分利用整个数据集来捕捉数据分布的变化，从而提供更准确的预测区域。
- en: However, classical conformal prediction has some limitations, too. For instance,
    it may not be feasible for large datasets or real-time applications because it
    requires retraining the underlying point prediction model for each new prediction.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，经典一致性预测也有一些局限性。例如，对于大型数据集或实时应用来说，它可能不可行，因为它需要为每个新的预测重新训练底层点预测模型。
- en: 'Classical conformal prediction is a process that involves several key steps.
    Here, we outline these steps to provide a clear understanding of the procedure:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 经典一致性预测是一个涉及多个关键步骤的过程。在此，我们概述这些步骤，以提供对程序的清晰理解：
- en: '**Dataset preparation**: Divide the dataset into training and test sets. The
    training set is used to train the machine learning model, while the test set is
    used to evaluate the performance of the conformal predictor.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据集准备**：将数据集划分为训练集和测试集。训练集用于训练机器学习模型，而测试集用于评估一致性预测器的性能。'
- en: '**Model training**: Train the underlying machine learning model using the training
    dataset. This point prediction model will generate point predictions for new objects.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型训练**：使用训练数据集训练底层机器学习模型。这个点预测模型将为新对象生成点预测。'
- en: '**Nonconformity measure calculation**: Define a nonconformity (strangeness)
    measure that quantifies how different an object is from the other objects in the
    dataset. For each object in the training dataset, calculate its nonconformity
    score using the trained model.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**非一致性度量计算**：定义一个非一致性（奇异度）度量，该度量量化了对象与数据集中其他对象的不同程度。对于训练数据集中的每个对象，使用训练好的模型计算其非一致性分数。'
- en: '**New object nonconformity score**: When a new object (without its label) is
    introduced, calculate its nonconformity score using the same nonconformity measure
    and the trained point prediction model.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**新对象非一致性分数**：当引入一个新对象（没有其标签）时，使用相同的非一致性度量以及训练好的点预测模型来计算其非一致性分数。'
- en: '**Ranking**: Based on calculated nonconformity scores, rank all objects, including
    the objects in the training dataset and the new object.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**排序**：根据计算出的非一致性分数，对所有对象进行排序，包括训练数据集中的对象和新对象。'
- en: '**Prediction region**: Determine the desired confidence level for the prediction.
    Identify the proportion of objects in the ranked set corresponding to this confidence
    level. Form a prediction set that includes the values associated with these objects.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测区域**：确定预测所需的置信水平。识别与该置信水平相对应的排序集中对象的占比。形成一个包含这些对象相关值的预测集。'
- en: Let’s clarify these concepts using a practical example with the hinge loss nonconformity
    measure, which we discussed in the previous chapters. As a reminder, hinge loss
    (also known as inverse probability or LAC loss) is a nonconformity measure calculated
    as *1-P(y|x)*, where *P(y|x)* represents the class score produced by the underlying
    model for the actual class.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个实际例子来阐明这些概念，这个例子使用了我们在前几章讨论的拉格朗日损失非一致性度量。提醒一下，拉格朗日损失（也称为逆概率或LAC损失）是一种非一致性度量，计算为*1-P(y|x)*，其中*P(y|x)*代表底层模型为实际类别产生的类别分数。
- en: The hinge loss nonconformity measure intuitively measures the difference between
    the probability score generated by an ideal classifier for the correct class (which
    should ideally be 1) and the classification score produced by the classifier model.
    It quantifies how far the model’s prediction is from the perfect classification,
    with larger nonconformity scores indicating a more significant discrepancy between
    the ideal and actual predictions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 拉格朗日损失非一致性度量直观地衡量了理想分类器为正确类别（理想情况下应为1）生成的概率分数与分类器模型产生的分类分数之间的差异。它量化了模型的预测与完美分类之间的距离，非一致性分数越大，理想预测与实际预测之间的差异就越显著。
- en: 'To compute the inverse probability (hinge) nonconformity score, consider an
    example where your classifier generates two scores: *class_0 = 0.6* and *class_1
    = 0.4,* with the actual label *y=1*. To determine the nonconformity score, subtract
    the probability of the true class (in this case, 0.4 from 1).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算逆概率（铰链）非一致性得分，考虑一个例子，其中你的分类器生成两个得分：*class_0 = 0.6* 和 *class_1 = 0.4*，实际标签
    *y=1*。为了确定非一致性得分，从真实类别的概率（在这种情况下，1减去0.4）中减去。
- en: The resulting inverse probability (hinge) nonconformity score is 0.6.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的逆概率（铰链）非一致性得分为0.6。
- en: The hinge (inverse probability) score is lower when the underlying machine learning
    classification model performs better. This performance is influenced by a range
    of factors, such as the size and complexity of the dataset, the type of machine
    learning model employed, and the quality of the model’s construction. In other
    words, a well-built model using an appropriate machine learning technique for
    the given dataset will generally yield lower hinge scores, indicating better predictions.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当底层机器学习分类模型表现更好时，铰链（逆概率）得分更低。这种性能受多种因素的影响，例如数据集的大小和复杂性、所采用的机器学习模型类型以及模型构建的质量。换句话说，使用适合给定数据集的适当机器学习技术构建的良好模型通常会生成较低的铰链得分，表明更好的预测。
- en: The training process is the critical difference between TCP and **inductive
    conformal prediction** (**ICP**). In ICP, the underlying classifier is trained
    only once on the training set and the calibration of the conformal prediction
    model happens on the calibration dataset.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程是TCP与**归纳一致性预测**（**ICP**）之间的关键区别。在ICP中，底层分类器仅在训练集上训练一次，一致性预测模型的校准发生在校准数据集上。
- en: In contrast, with TCP, the classifier is trained by appending each test point
    to the training set twice, each time assigning potential labels 0 and 1\. This
    procedure is repeated for every point in the test set. As a result, the underlying
    classifier model is trained *2 x m* times, where m is the number of points in
    your test set. This may become computationally expensive for large datasets, and
    for such datasets, using ICP might be a more suitable choice.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，在TCP中，通过将每个测试点添加到训练集中两次来训练分类器，每次分配潜在的标签0和1。对于测试集中的每个点，重复此过程。因此，底层分类器模型被训练了*2
    x m*次，其中m是测试集中的点数。对于大型数据集，这可能会变得计算成本高昂，对于此类数据集，使用ICP可能是一个更合适的选择。
- en: However, the computational cost is typically manageable for medium and small
    datasets. To obtain potentially better point predictions and narrower probability
    intervals, you might consider TCP, which achieves better prediction intervals
    by training the classifier model *2 x m* times. Many algorithms, such as logistic
    regression, are fast and well suited for this approach.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于中等和较小的数据集，计算成本通常是可管理的。为了获得潜在的更好点预测和更窄的概率区间，您可以考虑TCP，通过训练分类器模型*2 x m*次来实现更好的预测区间。许多算法，如逻辑回归，都快速且适合这种方法。
- en: 'The overall methodology for training TCP remains fundamentally unchanged. The
    TCP algorithm process is as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 训练TCP的整体方法保持基本不变。TCP算法过程如下：
- en: Train the underlying classifier on the entire training set.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在整个训练集上训练底层分类器。
- en: Append each test point to the training set with each possible class label one
    class label at a time.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个测试点及其所有可能的类别标签逐个添加到训练集中。
- en: For each appended test point with a postulated label, retrain the classifier
    and compute the nonconformity score for the test point given the postulated label.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个添加的带有假设标签的测试点，重新训练分类器，并根据假设标签计算测试点的非一致性得分。
- en: Calculate the p-values for each postulated label, comparing the test point’s
    nonconformity score to the scores of the points in the training set.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个假设标签的p值，比较测试点的非一致性得分与训练集中点的得分。
- en: For each test point and each postulated label, include the postulated label
    in the prediction set if its p-value is greater than or equal to the chosen significance
    level.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个测试点和每个假设的标签，如果其p值大于或等于所选显著性水平，则将假设的标签包含在预测集中。
- en: We will illustrate the TCP approach with a practical classification task example
    using the German credit dataset ([https://www.openml.org/d/31](https://www.openml.org/d/31)),
    a classical dataset describing good and bad credit risk based on features such
    as loan duration, credit history, employment, property, age, housing, and so on.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用德国信贷数据集（[https://www.openml.org/d/31](https://www.openml.org/d/31)）来举例说明TCP方法，这是一个经典的描述良好和不良信用风险的数据库，基于贷款期限、信用历史、就业、财产、年龄、住房等特征。
- en: In the GitHub repo for the book, you will find a notebook ([https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_05_TCP.ipynb](https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_05_TCP.ipynb))
    describing how TCP works that you can work through to understand the key concepts
    of TCP in practice.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的GitHub仓库中，你可以找到一个描述TCP如何工作的笔记本（[https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_05_TCP.ipynb](https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_05_TCP.ipynb)），你可以通过它来理解TCP在实践中的关键概念。
- en: '![Figure 5.1 – German credit dataset](img/B19925_05_1.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1 – 德国信贷数据集](img/B19925_05_1.jpg)'
- en: Figure 5.1 – German credit dataset
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – 德国信贷数据集
- en: For clarity, let’s examine the first test point with the original index `30`,
    which has now been appended to the end of the training set. We will use this extended
    training set we created to train the classical transductive conformal predictor.
    This new dataset created using the code in the notebook incorporates all points
    from the original training set and the single test point.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，让我们检查第一个测试点，其原始索引为`30`，现在已被添加到训练集的末尾。我们将使用我们创建的这个扩展训练集来训练经典的归纳一致性预测器。这个新数据集是通过笔记本中的代码创建的，它包含了原始训练集中的所有点和单个测试点。
- en: 'We now have a feature set to train two classification models: one with an assumed
    label of the test point of 0 and another with an assumed label of 1\. We train
    two models using any classifier (in this case, *Logistic Regression* from scikit-learn)
    and calculate nonconformity scores using the described procedure.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个特征集来训练两个分类模型：一个假设测试点的标签为0，另一个假设标签为1。我们使用任何分类器（在这种情况下，来自scikit-learn的*逻辑回归*）训练两个模型，并使用描述的流程计算非一致性分数。
- en: '![Figure 5.2 – Distribution of nonconformity scores](img/B19925_05_2.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图5.2 – 非一致性分数分布](img/B19925_05_2.jpg)'
- en: Figure 5.2 – Distribution of nonconformity scores
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – 非一致性分数分布
- en: From the distribution of nonconformity scores, we observe that the nonconformity
    score for *label 0* (represented by the green vertical line) is relatively typical
    (more conforming) to the training set. In contrast, the nonconformity score for
    the potential *label 1* (represented by the red vertical line) is in a low-density
    probability area.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从非一致性分数的分布中，我们可以观察到对于*标签0*（由绿色垂直线表示）的非一致性分数相对典型（更符合训练集）。相比之下，潜在*标签1*（由红色垂直线表示）的非一致性分数位于低密度概率区域。
- en: This suggests that the test object is likelier to be assigned a label of 0,
    while label 1 is less probable. However, conformal prediction is a robust mathematical
    machine learning framework, so we must quantify and statistically test this decision.
    This is where p-values come into play.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明测试对象更有可能被分配标签0，而标签1则不太可能。然而，一致性预测是一个健壮的数学机器学习框架，因此我们必须对这个决策进行量化和统计检验。这就是p值发挥作用的地方。
- en: Let’s take a moment to revisit the conventional process of calculating p-values,
    which we previously explored in [*Chapter 3*](B19925_03.xhtml#_idTextAnchor033),
    using the formula from Vovk’s book *Algorithmic Learning in a* *Random World*.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花点时间回顾一下我们之前在[*第3章*](B19925_03.xhtml#_idTextAnchor033)中探讨的传统计算p值的过程，使用Vovk的书籍《*随机世界中的算法学习*》中的公式。
- en: 'p-values can be computed as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: p值可以按照以下方式计算：
- en: 'p = (|z i : α i ≥ : α T| + 1) / (n + 1)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 'p = (|z i : α i ≥ : α T| + 1) / (n + 1)'
- en: Here, the nonconformity score of a new test point is compared with the nonconformity
    scores of points in the training set. Essentially, the nonconformity score quantifies
    the *strangeness* or novelty of the new test object compared to the previously
    encountered objects in the training dataset.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，新测试点的非一致性分数与训练集中的点的非一致性分数进行比较。本质上，非一致性分数量化了新测试对象与训练数据集中先前遇到的物体相比的“奇特”或新颖程度。
- en: According to the formula, what we need to do is to check (for each test point
    and each potential value of label 0 and 1) how many objects in the set of training
    data appended with the test point using the postulated label have nonconformity
    values that are larger or equal to the nonconformity score of the test point.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 根据公式，我们需要做的是检查（对于每个测试点和标签0和1的每个潜在值）在添加测试点后的训练数据集中有多少对象的非一致性值大于或等于测试点的非一致性得分。
- en: 'We then divide it by the number of training points *(n+1)* (+1 accounts for
    the test point that we appended to the training set). As a result, we obtain two
    p-values for each test point: one for class 0 and one for class 1.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将它除以训练点的数量*(n+1)*（+1是为了我们添加到训练集中的测试点）。结果，我们为每个测试点获得两个p值：一个用于类别0，一个用于类别1。
- en: The central concept of conformal prediction revolves around utilizing nonconformity
    values for each test point to evaluate how well it aligns with the training set.
    By computing p-values based on this evaluation, we can conduct robust statistical
    tests to determine if each potential label value should be included in the prediction
    set.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性预测的核心概念是利用每个测试点的非一致性值来评估其与训练集的匹配程度。通过基于这种评估计算p值，我们可以进行稳健的统计测试，以确定每个潜在标签值是否应该包含在预测集中。
- en: Let’s say we have a postulated label (either 0 or 1). If there are sufficient
    instances in the training set with nonconformity values equal to or greater than
    the test point’s nonconformity value, then we infer that this postulated label
    aligns well with the observed data. As a result, we incorporate this label into
    our prediction set. Conversely, if the postulated label does not correspond well
    with the observed data, we refrain from including it in the prediction set.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个假设的标签（要么是0要么是1）。如果训练集中有足够的实例，其非一致性值等于或大于测试点的非一致性值，那么我们推断这个假设的标签与观察到的数据匹配得很好。因此，我们将这个标签纳入我们的预测集。相反，如果假设的标签与观察到的数据不匹配，我们则不将其纳入预测集。
- en: In essence, this procedure echoes the principles of statistical hypothesis testing.
    For each hypothesized label value, we establish a null hypothesis, asserting that
    the label could be part of the prediction set if its associated p-value exceeds
    a pre-defined significance level. If the p-value falls short of this threshold,
    we discard the null hypothesis. This implies that the proposed label doesn’t adequately
    match the pattern found in the training data, leading us to exclude it from our
    prediction set.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，这个程序反映了统计假设检验的原则。对于每个假设的标签值，我们建立了一个零假设，即如果其关联的p值超过预先定义的显著性水平，则标签可以是预测集的一部分。如果p值低于这个阈值，我们则拒绝零假设。这意味着提出的标签不足以匹配训练数据中发现的模式，导致我们将其排除在我们的预测集之外。
- en: 'For example, let’s say we have calculated two p-values for the first test object:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们为第一个测试对象计算了两个p值：
- en: Assume for label 0 that the p-value is 0.55\. Since the p-value is larger than
    the significance level (0.05), we include the hypothesized label (0 in this case)
    in the prediction set for this test point.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设对于标签0，p值是0.55。由于p值大于显著性水平（0.05），我们将假设的标签（在这种情况下是0）纳入这个测试点的预测集中。
- en: Now assume for label 1 that the p-value is 0.002\. Since the p-value is smaller
    than the significance level (0.05), we cannot include the hypothesized label (1
    in this case) in the prediction set for this test point.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在假设对于标签1，p值是0.002。由于p值小于显著性水平（0.05），我们不能将假设的标签（在这种情况下是1）纳入这个测试点的预测集中。
- en: Thus, the final prediction set for this point is 0.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，这个点的最终预测集是0。
- en: In the context of TCP, the key distinction between binary and multiclass classification
    lies in the number of potential labels taken into account for each test point.
    In a binary classification scenario, only two labels exist (0 and 1). In contrast,
    multiclass classification involves a greater number of classes (for instance,
    C1, C2, C3, ...).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在TCP的背景下，二分类和多分类之间的关键区别在于每个测试点考虑的潜在标签数量。在二分类场景中，只有两个标签存在（0和1）。相比之下，多分类涉及更多的类别（例如，C1、C2、C3、...）。
- en: The main difference from the binary classification is that we will have to repeat
    the process for each possible class label, increasing computational complexity
    as you need to retrain the classifier for each test point and each potential label.
    However, the overall method for obtaining the prediction set remains the same.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 与二进制分类的主要区别在于，我们将不得不为每个可能的类标签重复此过程，随着需要为每个测试点和每个潜在标签重新训练分类器，计算复杂性会增加。然而，获取预测集的整体方法保持不变。
- en: After delving into the nuances of TCP for classification, let’s pivot our focus.
    Next up, we’ll explore the intricacies of employing TCP in regression contexts.
    This approach offers unique challenges and benefits, so let’s dive in!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究分类中TCP的细微差别之后，让我们转换我们的焦点。接下来，我们将探讨在回归环境中应用TCP的复杂性。这种方法提供了独特的挑战和好处，让我们深入探讨！
- en: Applying TCP for regression problems
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将TCP应用于回归问题
- en: 'TCP can also be applied to regression problems. The process for TCP in regression
    is similar to the one used for classification, with some differences in computing
    nonconformity scores and prediction intervals. Here is an algorithmic description
    of the TCP for regression problems:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: TCP也可以应用于回归问题。回归中TCP的过程与用于分类的过程类似，但在计算非一致性得分和预测区间方面有一些差异。以下是回归问题中TCP的算法描述：
- en: Train the underlying regression model on the entire training set.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在整个训练集上训练基础回归模型。
- en: For each test point, create a grid of potential target values. The granularity
    of this grid depends on the desired precision and the problem’s nature.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个测试点，创建一个潜在目标值的网格。该网格的粒度取决于所需的精度和问题的性质。
- en: For each test point and each potential target value on the grid, append the
    test point to the training set with the associated target value.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于网格上的每个测试点和每个潜在的目标值，将测试点及其相关目标值附加到训练集中。
- en: For each appended test point with a postulated target value, retrain the regression
    model and compute the nonconformity score for the given postulated target value.
    The nonconformity score can be computed as the absolute difference between the
    predicted value and the true value of the appended point, or you can calculate
    it by using other error metrics such as **mean squared** **error** (**MSE**).
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个附加的测试点及其假设的目标值，重新训练回归模型并计算给定假设目标值的非一致性得分。非一致性得分可以计算为预测值与附加点的真实值之间的绝对差异，或者您可以使用其他误差度量，如**均方误差**（**MSE**）来计算它。
- en: Calculate the p-values for each postulated target value by comparing the test
    point’s nonconformity score for each value on the grid of potential target values
    to the scores of the points in the training set.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过比较测试点在每个潜在目标值网格上的非一致性得分与训练集中点的得分，为每个假设的目标值计算p值。
- en: For each test point, include the postulated target value in the prediction interval
    if its p-value is greater than or equal to the chosen significance level.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个测试点，如果其p值大于或等于所选的显著性水平，则将其假设的目标值包含在预测区间中。
- en: The prediction set for a regression problem will be an interval rather than
    a set of discrete labels, as in classification. The main difference from the classification
    is that you will have to repeat the process for each potential target value in
    the grid, which could increase computational complexity. However, the overall
    method for obtaining the prediction interval remains the same.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 回归问题的预测集将是一个区间，而不是分类中的离散标签集合。与分类的主要区别在于，您将不得不对网格中的每个潜在目标值重复此过程，这可能会增加计算复杂性。然而，获取预测区间的整体方法保持不变。
- en: We conclude the section about TCP by summarizing the advantages and limitations
    of TCP.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过总结TCP的优点和局限性来结束关于TCP的部分。
- en: Advantages
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优点
- en: 'TCP has several advantages over alternative methods of uncertainty quantification:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: TCP相对于其他不确定性量化方法具有几个优点：
- en: '**Distribution-free**: Transductive conformal predictors do not make any assumptions
    about the distribution of the data, making them suitable for various types of
    data'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无分布假设**：归纳一致性预测器不对数据的分布做出任何假设，这使得它们适用于各种类型的数据'
- en: '**Validity**: They provide prediction intervals with a guaranteed coverage
    probability, allowing for a reliable measure of uncertainty'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有效性**：它们提供具有保证覆盖概率的预测区间，从而允许对不确定性进行可靠的度量'
- en: '**Adaptability**: Conformal predictors can be applied to various machine learning
    models, making them versatile and easily adaptable to different settings'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适应性**：符合预测器可以应用于各种机器学习模型，使它们具有多功能性和易于适应不同环境'
- en: '**Better prediction intervals**: Transductive conformal predictors generally
    produce more precise prediction intervals compared to inductive conformal predictors
    since they fully utilize the dataset for training the underlying point prediction
    model'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更好的预测区间**：与归纳一致预测器相比，传递一致预测器通常产生更精确的预测区间，因为它们充分利用数据集来训练底层点预测模型'
- en: 'But there are a few limitations as well:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 但也有一些局限性：
- en: '**Computational expense**: TCP requires retraining the model for each test
    point and for each potential class label (in classification) or each potential
    target value on the grid regression, making it computationally expensive, particularly
    for large datasets'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算成本**：TCP需要对每个测试点和每个潜在类别标签（在分类中）或网格回归中的每个潜在目标值重新训练模型，这使得它计算成本高昂，尤其是在大数据集中'
- en: '**Not ideal for online learning**: Due to the computational expense, transductive
    conformal predictors are not well suited for online learning scenarios where models
    must be continuously updated'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不适用于在线学习**：由于计算成本，传递一致预测器不适合在线学习场景，在这些场景中，模型必须持续更新'
- en: '**Complexity**: Implementing transductive conformal predictors can be more
    complicated than traditional machine learning models, potentially posing a barrier
    to widespread adoption'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂性**：实现传递一致预测器可能比传统机器学习模型更复杂，这可能会成为广泛采用的一个障碍'
- en: Transductive conformal predictors offer several advantages in providing reliable,
    distribution-free prediction intervals. However, their computational expense and
    scalability limitations should be considered, particularly for large-scale or
    online learning applications.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 传递一致预测器在提供可靠、无分布预测区间方面具有几个优点。然而，它们的计算成本和可扩展性限制应予以考虑，尤其是在大规模或在线学习应用中。
- en: 'Building upon our exploration of TCP, it’s time to turn our attention to another
    intriguing variant: inductive conformal predictors. Differing from its classical
    counterpart in key ways, this approach brings a new set of strategies and benefits
    to the table. Ready to delve into the mechanics and merits of inductive conformal
    predictors? Let’s embark on this enlightening journey!'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探索TCP的基础上，现在是时候将我们的注意力转向另一个有趣的变体：归纳一致预测器。与它的经典对应物在关键方面有所不同，这种方法带来了一套全新的策略和好处。准备好深入了解归纳一致预测器的机制和优点了吗？让我们开始这段启发性的旅程！
- en: Understanding inductive conformal predictors
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解归纳一致预测器
- en: ICP is a variant of conformal prediction that provides valid predictive regions
    under the same assumptions as classical conformal prediction and has the added
    benefit of improved computational efficiency, which is particularly useful when
    dealing with large datasets.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ICP是一种符合预测的变体，它在经典符合预测的相同假设下提供有效的预测区域，并且具有计算效率提高的额外好处，这在处理大数据集时特别有用。
- en: ICPs present a highly efficient and effective solution within the realm of machine
    learning. They provide a form of conformal prediction that caters to larger datasets,
    making it highly suitable for real-world applications that involve extensive data
    volumes. ICPs divide the dataset into training and calibration sets during the
    model-building process. The training set is used to develop the model, while the
    calibration set helps calculate the nonconformity scores. This two-step process
    optimizes computation and delivers precise prediction regions.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ICPs在机器学习领域提供了一个高效且有效的解决方案。它们提供了一种符合预测的形式，适用于更大的数据集，非常适合涉及大量数据量的现实世界应用。在模型构建过程中，ICPs将数据集分为训练集和校准集。训练集用于开发模型，而校准集有助于计算非一致性分数。这个两步过程优化了计算并提供了精确的预测区域。
- en: '![Figure 5.3 – Inductive conformal prediction](img/B19925_05_3.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图5.3 – 归纳一致预测](img/B19925_05_3.jpg)'
- en: Figure 5.3 – Inductive conformal prediction
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – 归纳一致预测
- en: A predictive model, such as a neural network or a decision tree, is first trained
    on the proper training set. Then, the nonconformity of each example in the calibration
    set is computed using the trained model. The nonconformity measure is a real-valued
    function that describes how much an example contradicts the rest of the data.
    The nonconformity scores of the calibration set are then used to determine the
    size of the prediction region for new examples.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 预测模型，如神经网络或决策树，首先在合适的训练集上训练。然后，使用训练好的模型计算校准集中每个示例的非一致性。非一致性度量是一个实值函数，描述了一个示例与数据集其他部分相矛盾的程度。然后，使用校准集的非一致性分数来确定新示例预测区域的大小。
- en: The inductive approach offers a significant computational advantage, particularly
    for large datasets. By creating the predictive model only once, ICP reduces the
    algorithm’s time complexity, unlike TCP, which requires retraining the model for
    each new prediction. However, it’s important to note that ICP assumes the data
    are exchangeable, meaning the data’s order doesn’t carry any information.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 归纳方法在计算上提供了显著的优势，尤其是在处理大数据集时。通过仅创建一次预测模型，ICP 减少了算法的时间复杂度，与需要为每个新的预测重新训练模型的 TCP
    不同。然而，需要注意的是，ICP 假设数据是可交换的，这意味着数据的顺序不携带任何信息。
- en: In terms of applications, inductive conformal predictors can be used for both
    classification (binary and multiclass) and regression tasks. The method offers
    a flexible and efficient way of providing a measure of uncertainty associated
    with predictions, a valuable feature in many practical applications.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用方面，归纳一致性预测器可以用于分类（二分类和多分类）和回归任务。该方法提供了一种灵活且高效的方式来提供与预测相关的不确定性的度量，这在许多实际应用中是一个有价值的特性。
- en: 'ICP involves several steps, most of which center around the calculation of
    nonconformity scores. Here’s a rough outline of the algorithm along with the associated
    mathematical formulation:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ICP 包含几个步骤，其中大部分集中在非一致性分数的计算上。以下是算法的粗略概述以及相关的数学公式：
- en: '**Data partitioning**: Split the initial dataset *D* into a proper training
    set *D_train*, and a calibration set *D_cal*.'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据分区**：将初始数据集 *D* 划分为合适的训练集 *D_train* 和校准集 *D_cal*。'
- en: '**Model training**: Train a predictive model *M* on *D_train*. This model is
    used to generate predictions on new instances. The type of model (e.g., SVM, decision
    tree, linear regression, etc.) depends on the problem at hand.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型训练**：在 *D_train* 上训练预测模型 *M*。该模型用于对新实例进行预测。模型类型（例如，SVM、决策树、线性回归等）取决于具体问题。'
- en: '**Nonconformity measure calculation**: Use the trained model *M* to predict
    outcomes for instances in the calibration set *D_cal*. For each instance of, *(x_i,
    y_i)* in *D_cal*, compute a nonconformity score *α_i*, representing the *strangeness*
    or *abnormality* of the instance. The nonconformity measure *α* is generally problem-specific.
    For instance, classification tasks could be hinge loss *1 - p_yi,* where *p_yi*
    is the predicted probability of the correct class *y_i* according to the model
    *M*. For regression, it could be the absolute error *|y_i - y_hat_i|*, where *y_hat_i*
    is the model’s prediction for *x_i*.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**非一致性度量计算**：使用训练好的模型 *M* 对校准集 *D_cal* 中的实例进行预测。对于 *D_cal* 中的每个实例 *(x_i, y_i)*，计算一个非一致性分数
    *α_i*，表示实例的*奇特性*或*异常性*。非一致性度量 *α* 通常与问题相关。例如，分类任务可能是铰链损失 *1 - p_yi*，其中 *p_yi*
    是根据模型 *M* 预测的正确类别 *y_i* 的概率。对于回归，它可能是绝对误差 *|y_i - y_hat_i|*，其中 *y_hat_i* 是模型对
    *x_i* 的预测。'
- en: '`|{i: α_i ≥ α_x}|` denotes the number of instances in the calibration set with
    nonconformity scores greater than or equal to *α_x*. This p-value represents how
    often we expect to observe a nonconformity score at least as large as *α_x* by
    chance.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`|{i: α_i ≥ α_x}|` 表示校准集中非一致性分数大于或等于 *α_x* 的实例数量。这个 p 值表示我们期望通过偶然观察到至少与 *α_x*
    一样大的非一致性分数的频率。'
- en: '**Prediction output**: Using the calculated p-value, create a prediction set
    *Γ(x)* for the new test point *x*. For classification, the prediction set contains
    all classes *y* for which the p-value is at least the chosen significance level
    *ε*: Γ(x) = {y: p_y ≥ ε}. For regression, an interval prediction (*y_lower,* *y_upper*)
    is typically outputted, where *y_lower* and *y_upper* are the lowest and highest
    values, respectively, for which the p-value is at least as large as the chosen
    significant level.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测输出**：使用计算出的p值，为新测试点x创建一个预测集Γ(x)。对于分类，预测集包含所有p值至少为所选显著性水平ε的类别y：Γ(x) = {y:
    p_y ≥ ε}。对于回归，通常输出一个区间预测（y_lower, y_upper），其中y_lower和y_upper分别是p值至少与所选显著性水平一样大的最低和最高值。'
- en: Please note that this is a high-level description of the algorithm and mathematical
    formulation. The exact details may vary based on the specific form of ICP used
    and the type of problem (classification, regression, etc.) being addressed.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这是一个对算法和数学公式的概述性描述。具体细节可能根据使用的具体形式ICP和要解决的问题的类型（分类、回归等）而有所不同。
- en: As we’ve unpacked the complexities and capabilities of both classical and inductive
    approaches, it’s now essential to discern how to choose the optimal method for
    a given situation. Let’s navigate the factors and guidelines that will guide you
    in selecting the best-fit conformal predictor for your specific needs in the upcoming
    section, *Choosing the right* *conformal predictor*.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们解开了传统和归纳方法复杂性和功能，现在至关重要的是要辨别如何为特定情况选择最佳方法。让我们在接下来的部分，*选择合适的保形预测器*中，探讨将指导你选择最适合你特定需求的保形预测器的因素和指南。
- en: Choosing the right conformal predictor
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择合适的保形预测器
- en: Both classical and inductive conformal predictors offer valuable approaches
    to building reliable machine learning models. However, they each come with unique
    strengths and weaknesses.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是传统的还是归纳的保形预测器，都为构建可靠的机器学习模型提供了有价值的途径。然而，它们各自都有独特的优势和劣势。
- en: Classical transductive conformal predictors are highly adaptable and do not
    make any assumptions about data distribution. However, they tend to be computationally
    expensive, requiring the model’s retraining for each new prediction.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的保形预测器高度适应性强，不对数据分布做任何假设。然而，它们通常计算成本较高，需要为每个新的预测重新训练模型。
- en: Inductive conformal predictors, conversely, are computationally more efficient,
    as they only require the model to be trained once.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，归纳保形预测器在计算上更高效，因为它们只需要对模型进行一次训练。
- en: 'Choosing the right conformal predictor largely depends on the specific requirements
    of the problem at hand. Some considerations might include the following:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的保形预测器在很大程度上取决于手头问题的具体要求。以下是一些可能需要考虑的因素：
- en: '**Computation resources**: If computation resources or time are a concern,
    inductive conformal predictors might be more suitable due to their reduced computational
    cost'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算资源**：如果计算资源或时间是一个问题，由于它们的计算成本较低，归纳保形预测器可能更适合。'
- en: '**Data size**: For smaller datasets, classical conformal predictors might be
    more suitable, while for larger datasets, inductive conformal predictors are usually
    the preferred choice due to computational efficiency'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据量**：对于较小的数据集，传统的保形预测器可能更合适，而对于较大的数据集，由于计算效率高，归纳保形预测器通常是首选。'
- en: '**Data quality**: If data quality is high, inductive conformal predictors can
    be a good choice'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据质量**：如果数据质量高，归纳保形预测器可能是一个不错的选择。'
- en: '**Real-time requirements**: If the model needs to make real-time predictions,
    inductive conformal predictors might be more suitable due to their one-time training
    process'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时需求**：如果模型需要做出实时预测，由于它们的单次训练过程，归纳保形预测器可能更适合。'
- en: Here are real-life scenarios illustrating when one might opt for transductive
    or inductive conformal predictors.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些现实生活中的场景，说明了何时可能会选择传统的或归纳的保形预测器。
- en: Transductive conformal predictors
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传统的保形预测器
- en: 'medical diagnostics with limited data:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据有限的情况下进行医疗诊断：
- en: '**Scenario**: A hospital uses machine learning to diagnose a rare disease but
    only has a limited dataset of past patients.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**场景**：一家医院使用机器学习来诊断罕见疾病，但只有有限的过往患者数据集。'
- en: '**Reasoning**: Given the smaller dataset and the critical nature of accurate
    predictions, classical TCP is favored. Its adaptability and distribution-free
    nature might lead to more accurate predictions, even if it requires more computational
    power per prediction.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理**：鉴于数据集较小且准确预测至关重要，经典TCP（传输控制协议）更受欢迎。其适应性和无分布特性可能导致更准确的预测，尽管这可能需要每个预测更多的计算能力。'
- en: Inductive conformal predictors
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 归纳符合预测
- en: 'e-commerce recommendation systems:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 电子商务推荐系统：
- en: '**Scenario**: A large e-commerce platform wants to provide real-time product
    recommendations to millions of its users based on their browsing habits.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**场景**：一个大型电子商务平台希望根据用户的浏览习惯向数百万用户提供实时产品推荐。'
- en: '**Reasoning**: Due to the massive scale, the system can’t afford to retrain
    models for every recommendation. ICP’s one-time training process, combined with
    its computational efficiency for larger datasets, makes it a suitable choice.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理**：由于规模巨大，系统无法为每个推荐重新训练模型。ICP（集成符合预测）的一次性训练过程，结合其在大型数据集上的计算效率，使其成为合适的选择。'
- en: To effectively choose the appropriate type of conformal predictor, it’s essential
    to gain a deep understanding of both classical and inductive conformal predictors,
    their working principles, and their strengths and weaknesses. Furthermore, understanding
    the nature and requirements of the problem domain, such as the specific characteristics
    of the data, the computational resources available, the need for real-time predictions,
    and the importance of model interpretability, can significantly aid in making
    an informed choice. Always remember that the best conformal predictor is the one
    that best meets the needs of your specific problem domain.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地选择合适的符合预测类型，深入了解经典和归纳符合预测、它们的工作原理以及它们的优缺点至关重要。此外，了解问题域的性质和需求，如数据的特定特征、可用的计算资源、对实时预测的需求以及模型可解释性的重要性，可以显著帮助做出明智的选择。始终记住，最好的符合预测是能满足您特定问题域需求的那一个。
- en: Summary
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter explored the fascinating world of conformal predictors, their types,
    and their distinctive features. The key concepts and skills we touched upon include
    covering the foundational principles of conformal prediction and its application
    in machine learning. It also highlighted the differences between classical transductive
    and inductive conformal predictors. We also covered how to effectively choose
    the appropriate type of conformal predictor based on the specific requirements
    of the problem. Finally, the practical applications of conformal predictors in
    binary classification, multiclass classification, and regression were also included.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了符合预测的迷人世界，包括其类型和独特特征。我们触及的关键概念和技能包括覆盖符合预测的基础原理及其在机器学习中的应用。它还突出了经典转导符合预测和归纳符合预测之间的差异。我们还介绍了如何根据问题的具体要求有效地选择合适的符合预测类型。最后，还包括了符合预测在二分类、多分类和回归中的实际应用。
- en: The chapter also provided a detailed algorithmic description and mathematical
    formulation of classical and inductive conformal predictors, adding to our theoretical
    understanding. To deepen our learning, we also took a hands-on approach, looking
    at practical examples in Python.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还提供了经典和归纳符合预测的详细算法描述和数学公式，增加了我们的理论理解。为了深化我们的学习，我们还采取了动手方法，查看 Python 中的实际示例。
- en: For those interested in further exploring conformal predictors, several avenues
    exist for you to consider. A more detailed study of the mathematical underpinnings
    of conformal prediction could be pursued, along with implementing conformal predictors
    in more complex machine learning models.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些想进一步探索符合预测的人来说，存在几个可以考虑的途径。可以追求对符合预测数学基础的更深入研究，以及将符合预测实现到更复杂的机器学习模型中。
- en: Exploring the advanced versions of conformal predictors, such as Mondrian conformal
    predictors, or understanding how conformal prediction can be integrated with other
    machine learning techniques, such as neural networks and ensemble learning, are
    also exciting areas for further research.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 探索符合预测的高级版本，如 Mondrian 符合预测，或了解如何将符合预测与其他机器学习技术（如神经网络和集成学习）集成，也是进一步研究的令人兴奋的领域。
- en: In closing, we hope this chapter has given a solid grounding in the principles
    and applications of conformal prediction. Moving into the next chapter, we’ll
    delve deeper into conformal prediction for classification problems. As always,
    keep exploring, keep learning, and enjoy the journey!
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束之前，我们希望这一章已经为正则预测的原则和应用提供了坚实的基础。进入下一章，我们将更深入地探讨正则预测在分类问题中的应用。一如既往，继续探索，继续学习，并享受这段旅程！
- en: 'Part 3: Applications of Conformal Prediction'
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分：正则预测的应用
- en: In this part, we will provide more details about conformal prediction for classification
    problems. It will introduce the calibration concept and illustrate how conformal
    prediction compares with other calibration methods, explaining how it can quantify
    uncertainty in regression to produce well-calibrated prediction intervals. This
    part will also explain how conformal prediction can produce prediction intervals
    for point forecasting models, illustrate applications using open source libraries,
    and detail recent innovations in conformal prediction for NLP. Finally, this part
    will explain how conformal prediction can be applied to produce state-of-the-art
    uncertainty quantification for NLP and illustrate applications using open source
    libraries.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这部分，我们将提供更多关于正则预测在分类问题中的详细信息。它将介绍校准概念，并说明正则预测与其他校准方法相比的优势，解释它如何量化回归中的不确定性以产生良好的校准预测区间。这部分还将解释正则预测如何为点预测模型产生预测区间，通过使用开源库展示应用，并详细说明正则预测在自然语言处理中的最新创新。最后，这部分将解释如何将正则预测应用于产生自然语言处理中最先进的确定性量化，并通过使用开源库展示应用。
- en: 'This section has the following chapters:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包含以下章节：
- en: '[*Chapter 6*](B19925_06.xhtml#_idTextAnchor058), *Conformal Prediction for
    Classification*'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B19925_06.xhtml#_idTextAnchor058)，*正则预测在分类中的应用*'
- en: '[*Chapter 7*](B19925_07.xhtml#_idTextAnchor073), *Conformal Prediction for
    Regression*'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B19925_07.xhtml#_idTextAnchor073)，*正则预测在回归中的应用*'
- en: '[*Chapter 8*](B19925_08.xhtml#_idTextAnchor090), *Conformal Prediction for
    Time Series and Forecasting*'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B19925_08.xhtml#_idTextAnchor090)，*正则预测在时间序列和预测中的应用*'
- en: '[*Chapter 9*](B19925_09.xhtml#_idTextAnchor111), *Conformal Prediction for
    Computer Vision*'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B19925_09.xhtml#_idTextAnchor111)，*正则预测在计算机视觉中的应用*'
- en: '[*Chapter 10*](B19925_10.xhtml#_idTextAnchor130), *Conformal Prediction for
    Natural Language Processing*'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B19925_10.xhtml#_idTextAnchor130)，*正则预测在自然语言处理中的应用*'
