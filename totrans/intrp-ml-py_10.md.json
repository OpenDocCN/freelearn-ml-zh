["```py\nimport math\nimport os\nimport mldatasets\nimport pandas as pd\nimport numpy as np\nimport timeit\nfrom tqdm.notebook import tqdm\nfrom sklearn.feature_selection import VarianceThreshold,\\\n                                    mutual_info_classif, SelectKBest\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression,\\\n                                    LassoCV, LassoLarsCV, LassoLarsIC\nfrom mlxtend.feature_selection import SequentialFeatureSelector\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.decomposition import PCA import shap\nfrom sklearn-genetic-opt import GAFeatureSelectionCV\nfrom scipy.stats import rankdata\nfrom sklearn.discriminant_analysis import\nLinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n```", "```py\nX_train, X_test, y_train, y_test = mldatasets.load(\n    \"nonprofit-mailer\",\n    prepare=True\n)\ny_train = y_train.squeeze()\ny_test = y_test.squeeze() \n```", "```py\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape) \n```", "```py\n(95485, 435)\n(95485,)\n(96017, 435)\n(96017,) \n```", "```py\nvar_cost = 0.68\ny_test_donors = y_test[y_test > 0]\ntest_donors = len(y_test_donors)\ntest_donations = sum(y_test_donors)\ntest_min_profit = test_donations - (len(y_test)*var_cost)\ntest_max_profit = test_donations - (test_donors*var_cost)\nprint(\n    '%s test donors totaling $%.0f (min profit: $%.0f,\\\n    max profit: $%.0f)'\n    %(test_donors, test_donations, test_min_profit,\\\n       test_max_profit))\ny_train_donors = y_train[y_train > 0]\ntrain_donors = len(y_train_donors)\ntrain_donations = sum(y_train_donors)\ntrain_min_profit = train_donations – (len(y_train)*var_cost)\ntrain_max_profit = train_donations – (train_donors*var_cost)\nprint(\n    '%s train donors totaling $%.0f (min profit: $%.0f,\\\n    max profit: $%.0f)'\n    %(train_donors, train_donations, train_min_profit,\\\n    train_max_profit)) \n```", "```py\n4894 test donors totaling $76464 (min profit: $11173, max profit: $73136)\n4812 train donors totaling $75113 (min profit: $10183, max profit: $71841) \n```", "```py\nrand = 9\nos.environ['PYTHONHASHSEED']=str(rand)\nnp.random.seed(rand) \n```", "```py\nstime = timeit.default_timer()\nreg_mdl = xgb.XGBRFRegressor(max_depth=4, n_estimators=200, seed=rand)\nfitted_mdl = reg_mdl.fit(X_train, y_train)\netime = timeit.default_timer()\nbaseline_time = etime-stime \n```", "```py\nreg_mdls = {}\nreg_mdls['rf_4_all'] = mldatasets.evaluate_reg_mdl(\n    fitted_mdl,\n    X_train,\n    X_test,\n    y_train,\n    y_test,\n    plot_regplot=True,\n    ret_eval_dict=True\n) \n```", "```py\nthreshs = np.hstack(\n    [\n      np.linspace(0.40,1,61),\n      np.linspace(1.1,3,20),\n      np.linspace(4,25,22)\n    ]\n) \n```", "```py\ny_formatter = plt.FuncFormatter(\n    lambda x, loc: \"${:,}K\".format(x/1000)\n)\nprofits_test = mldatasets.profits_by_thresh(\n    y_test,\n    reg_mdls['rf_4_all']['preds_test'],\n    threshs,\n    var_costs=var_cost,\n    min_profit=test_min_profit\n)\nprofits_train = mldatasets.profits_by_thresh(\n    y_train,\n    reg_mdls['rf_4_all']['preds_train'],\n    threshs,\n    var_costs=var_cost,\n    min_profit=train_min_profit\n)\nreg_mdls['rf_4_all']['max_profit_train'] =profits_train.profit.max()\nreg_mdls['rf_4_all']['max_profit_test'] = profits_test.profit.max()\nreg_mdls['rf_4_all']['max_roi'] = profits_test.roi.max()\nreg_mdls['rf_4_all']['min_costs'] = profits_test.costs.min()\nreg_mdls['rf_4_all']['profits_train'] = profits_train\nreg_mdls['rf_4_all']['profits_test'] = profits_test\nmldatasets.compare_df_plots(\n    profits_test[['costs', 'profit', 'roi']],\n    profits_train[['costs', 'profit', 'roi']],\n    'Test',\n    'Train',\n    y_formatter=y_formatter,\n    x_label='Threshold',\\\n    plot_args={'secondary_y':'roi'}\n) \nFigure 10.2. You can tell that Test and Train are almost identical. Costs decrease steadily at a high rate and profit at a lower rate, while ROI increases steadily. However, some differences exist, such as ROI, which becomes a bit higher eventually, and although viable thresholds start at the same point, Train does end at a different threshold. It turns out the model can turn a profit, so despite the appearance of the plot in *Figure 10.1*, the model is far from useless:\n```", "```py\nreg_mdls['rf_4_all']['total_feat'] =\\\n    reg_mdls['rf_4_all']['fitted'].feature_importances_.shape[0] reg_mdls['rf_4_all']['num_feat'] = sum(\n    reg_mdls['rf_4_all']['fitted'].feature_importances_ > 0\n)\nprint(reg_mdls['rf_4_all']['num_feat']) \n```", "```py\nfor depth in tqdm(range(5, 13)):\nmdlname = 'rf_'+str(depth)+'_all'\nstime = timeit.default_timer()\nreg_mdl = xgb.XGBRFRegressor(\n    max_depth=depth,\n    n_estimators=200,\n    seed=rand\n)\nfitted_mdl = reg_mdl.fit(X_train, y_train)\netime = timeit.default_timer()\nreg_mdls[mdlname] = mldatasets.evaluate_reg_mdl(\n    fitted_mdl,\n    X_train,\n    X_test,\n    y_train,\n    y_test,\n    plot_regplot=False,\n    show_summary=False,\n    ret_eval_dict=True\n)\nreg_mdls[mdlname]['speed'] = (etime - stime)/baseline_time\nreg_mdls[mdlname]['depth'] = depth\nreg_mdls[mdlname]['fs'] = 'all'\nprofits_test = mldatasets.profits_by_thresh(\n    y_test,\n    reg_mdls[mdlname]['preds_test'],\n    threshs,\n    var_costs=var_cost,\n    min_profit=test_min_profit\n)\nprofits_train = mldatasets.profits_by_thresh(\n    y_train,\n    reg_mdls[mdlname]['preds_train'],\n    threshs,\n    var_costs=var_cost,\n    min_profit=train_min_profit\n)\nreg_mdls[mdlname]['max_profit_train'] = profits_train.profit.max()\nreg_mdls[mdlname]['max_profit_test'] = profits_test.profit.max()\nreg_mdls[mdlname]['max_roi'] = profits_test.roi.max()\nreg_mdls[mdlname]['min_costs'] = profits_test.costs.min()\nreg_mdls[mdlname]['profits_train'] = profits_train\nreg_mdls[mdlname]['profits_test'] = profits_test\nreg_mdls[mdlname]['total_feat'] =\\\nreg_mdls[mdlname]['fitted'].feature_importances_.shape[0]\nreg_mdls[mdlname]['num_feat'] = sum(\n    reg_mdls[mdlname]['fitted'].feature_importances_ > 0) \n```", "```py\ndef display_mdl_metrics(reg_mdls, sort_by='depth', max_depth=None):\n    reg_metrics_df = pd.DataFrame.from_dict( reg_mdls, 'index')\\\n                        [['depth', 'fs', 'rmse_train', 'rmse_test',\\\n                          'max_profit_train',\\\n                          'max_profit_test', 'max_roi',\\\n                          'min_costs', 'speed', 'num_feat']]\n    pd.set_option('precision', 2) \n    html = reg_metrics_df.sort_values(\n        by=sort_by, ascending=False).style.\\\n        format({'max_profit_train':'${0:,.0f}',\\\n        'max_profit_test':'${0:,.0f}', 'min_costs':'${0:,.0f}'}).\\\n        background_gradient(cmap='plasma', low=0.3, high=1,\n                            subset=['rmse_train', 'rmse_test']).\\\n        background_gradient(cmap='viridis', low=1, high=0.3,\n                            subset=[\n                                'max_profit_train', 'max_profit_test'\n                                ]\n                            )\n    return html\ndisplay_mdl_metrics(reg_mdls) \ndisplay_mdl_metrics function to output the DataFrame shown in *Figure 10.4*. Something that should be immediately visible is how RMSE train and RMSE test are inverses. One decreases dramatically, and another increases slightly as the depth increases. The same can be said for profit. ROI tends to increase with depth and training speed and the number of features used as well:\n```", "```py\nnum_cols_l = X_train.select_dtypes([np.number]).columns\ncat_cols_l = X_train.select_dtypes([np.bool, np.object]).columns\nnum_const = VarianceThreshold(threshold=0)\nnum_const.fit(X_train[num_cols_l])\nnum_const_cols = list(\n    set(X_train[num_cols_l].columns) -\n    set(num_cols_l[num_const.get_support()])\n) \nnunique() function on categorical features. It will return a pandas series, and then a lambda function can filter out only those with one unique value. Then, .index.tolist() returns the name of the features as a list. Now, we just join both lists of constant features, and voilà! We have all constants (all_const_cols). We can print them; there should be three:\n```", "```py\ncat_const_cols = X_train[cat_cols_l].nunique()[lambda x:\\\n                                               x<2].index.tolist()\nall_const_cols = num_const_cols + cat_const_cols\nprint(all_const_cols) \n```", "```py\nthresh = 0.999\nquasi_const_cols = []\nnum_rows = X_train.shape[0]\nfor col in tqdm(X_train.columns):\n    top_val = (\n        X_train[col].value_counts() / num_rows\n        ).sort_values(ascending=False).values[0]\n    if top_val >= thresh:\n        quasi_const_cols.append(col)\nprint(quasi_const_cols) \n```", "```py\nX_train_transposed = X_train.T\ndup_cols = X_train_transposed[\n    X_train_transposed.duplicated()].index.tolist()\nprint(dup_cols) \n```", "```py\nX_train_orig = X_train.copy()\nX_test_orig = X_test.copy()\ndrop_cols = quasi_const_cols + dup_cols\nX_train.drop(labels=drop_cols, axis=1, inplace=True)\nX_test.drop(labels=drop_cols, axis=1, inplace=True) \n```", "```py\ncorrs = X_train.corr(method='spearman')\nprint(corrs.shape) \n```", "```py\nextcorr_cols = (abs(corrs) > 0.99).sum(axis=1)[lambda x: x>1]\\\n.index.tolist()\nprint(extcorr_cols)\nuncorr_cols = (abs(corrs) > 0.15).sum(axis=1)[lambda x: x==1]\\\n.index.tolist()\nprint(uncorr_cols) \n```", "```py\n['MAJOR', 'HHAGE1', 'HHAGE3', 'HHN3', 'HHP1', 'HV1', 'HV2', 'MDMAUD_R', 'MDMAUD_F', 'MDMAUD_A']\n['TCODE', 'MAILCODE', 'NOEXCH', 'CHILD03', 'CHILD07', 'CHILD12', 'CHILD18', 'HC15', 'MAXADATE'] \n```", "```py\ncorr_cols = X_train.columns[\n    ~X_train.columns.isin(uncorr_cols)\n].tolist()\nprint(len(corr_cols)) \n```", "```py\nmdlname = 'rf_11_f-corr'\nstime = timeit.default_timer()\nreg_mdl = xgb.XGBRFRegressor(\n    max_depth=11,\n    n_estimators=200,\n    seed=rand\n)\nfitted_mdl = reg_mdl.fit(X_train[corr_cols], y_train)\nreg_mdls[mdlname]['num_feat'] = sum(\n    reg_mdls[mdlname]['fitted'].feature_importances_ > 0\n) \n```", "```py\ny_train_class = np.where(y_train > 0.68, 1, 0) \n```", "```py\nmic_selection = SelectKBest(\n    mutual_info_classif, k=160).fit(X_train, y_train_class)\nmic_cols = X_train.columns[mic_selection.get_support()].tolist()\nprint(len(mic_cols)) \n```", "```py\nmdlname = 'rf_5_f-mic'\nstime = timeit.default_timer()\nreg_mdl = xgb.XGBRFRegressor(max_depth=5, n_estimators=200, seed=rand)\nfitted_mdl = reg_mdl.fit(X_train[mic_cols], y_train)\nreg_mdls[mdlname]['num_feat'] = sum(\n    reg_mdls[mdlname]['fitted'].feature_importances_ > 0\n) \n```", "```py\ndisplay_mdl_metrics(reg_mdls, 'max_profit_test') \nFigure 10.6. It is evident that the filter MIC model is the least overfitted of all. It ranked higher than more complex models with more features and took less time to train than any model. Its speed is an advantage for hyperparameter tuning. What if we wanted to find the best classification target thresholds or MIC *k*? We won’t do this now, but we would likely get a better model if we ran every combination, but it would take time to do and even more with more features:\n```", "```py\n    sum(reg_mdls[mdlname]['fitted'].feature_importances_ > 0) \n    ```", "```py\nlasso_selection = SelectFromModel(\n    LassoCV(n_jobs=-1, random_state=rand)\n)\nlasso_selection.fit(X_train, y_train)\nlasso_cols = X_train.columns[lasso_selection.get_support()].tolist()\nprint(len(lasso_cols))\nprint(lasso_cols) \n```", "```py\n7\n['ODATEDW', 'TCODE', 'POP901', 'POP902', 'HV2', 'RAMNTALL', 'MAXRDATE'] \n```", "```py\nllars_selection = SelectFromModel(LassoLarsCV(n_jobs=-1))\nllars_selection.fit(X_train, y_train)\nllars_cols = X_train.columns[llars_selection.get_support()].tolist()\nprint(len(llars_cols))\nprint(llars_cols) \n```", "```py\n8\n['RECPGVG', 'MDMAUD', 'HVP3', 'RAMNTALL', 'LASTGIFT', 'AVGGIFT', 'MDMAUD_A', 'DOMAIN_SOCIALCLS'] \n```", "```py\nllarsic_selection = SelectFromModel(LassoLarsIC(criterion='aic'))\nllarsic_selection.fit(X_train, y_train)\nllarsic_cols = X_train.columns[\n    llarsic_selection.get_support()\n].tolist()\nprint(len(llarsic_cols))\nprint(llarsic_cols) \n```", "```py\n111\n['TCODE', 'STATE', 'MAILCODE', 'RECINHSE', 'RECP3', 'RECPGVG', 'RECSWEEP',..., 'DOMAIN_URBANICITY', 'DOMAIN_SOCIALCLS', 'ZIP_LON'] \n```", "```py\nlog_selection = SelectFromModel(\n    LogisticRegression(\n        C=0.0001,\n        solver='sag',\n        penalty='l2',\n        n_jobs=-1,\n        random_state=rand\n    )\n)\nlog_selection.fit(X_train, y_train_class)\nlog_cols = X_train.columns[log_selection.get_support()].tolist()\nprint(len(log_cols))\nprint(log_cols) \n```", "```py\n87\n['ODATEDW', 'TCODE', 'STATE', 'POP901', 'POP902', 'POP903', 'ETH1', 'ETH2', 'ETH5', 'CHIL1', 'HHN2',..., 'AMT_7', 'ZIP_LON'] \n```", "```py\nfsnames = ['e-lasso', 'e-llars', 'e-llarsic', 'e-logl2']\nfscols = [lasso_cols, llars_cols, llarsic_cols, log_cols] \n```", "```py\ndef train_mdls_with_fs(reg_mdls, fsnames, fscols, depths):\n    for i, fsname in tqdm(enumerate(fsnames), total=len(fsnames)):\n       depth = depths[i]\n       cols = fscols[i]\n       mdlname = 'rf_'+str(depth)+'_'+fsname\n       stime = timeit.default_timer()\n       reg_mdl = xgb.XGBRFRegressor(\n           max_depth=depth, n_estimators=200, seed=rand\n       )\n       fitted_mdl = reg_mdl.fit(X_train[cols], y_train)\n       reg_mdls[mdlname]['num_feat'] = sum(\n           reg_mdls[mdlname]['fitted'].feature_importances_ > 0\n       )\ntrain_mdls_with_fs(reg_mdls, fsnames, fscols, [3, 4, 5, 6]) \n```", "```py\n    top_cols = list(set(mic_cols).union(set(llarsic_cols)\\\n    ).union(set(log_cols)))\n    len(top_cols) \n    ```", "```py\n    sample_size = 0.1\n    sample_train_idx = np.random.choice(\n        X_train.shape[0],\n        math.ceil(X_train.shape[0]*sample_size),\n        replace=False\n    )\n    sample_test_idx = np.random.choice(\n        X_test.shape[0],\n        math.ceil(X_test.shape[0]*sample_size),\n        replace=False\n    ) \n    ```", "```py\nsfs_lda = SequentialFeatureSelector(\n    LinearDiscriminantAnalysis(n_components=1),\n    forward=True,\n    floating=False,\n    k_features=100,\n    cv=3,\n    scoring='f1',\n    verbose=2,\n    n_jobs=-1\n)\nsfs_lda = sfs_lda.fit(X_train.iloc[sample_train_idx][top_cols],\\\n                      y_train_class[sample_train_idx])\nsfs_lda_cols = X_train.columns[list(sfs_lda.k_feature_idx_)].tolist() \n```", "```py\nrfe_lda = RFECV(\n    LinearDiscriminantAnalysis(n_components=1),\n    step=2, cv=3, scoring='f1', verbose=2, n_jobs=-1\n)\nrfe_lda.fit(\n    X_train.iloc[sample_train_idx][top_cols],\n    y_train_class[sample_train_idx]\n)\nrfe_lda_cols = np.array(top_cols)[rfe_lda.support_].tolist() \n```", "```py\nfitted_rf_mdl = reg_mdls['rf_11_all']['fitted']\nshap_rf_explainer = shap.TreeExplainer(fitted_rf_mdl)\nshap_rf_values = shap_rf_explainer.shap_values(\n    X_test_orig.iloc[sample_test_idx]\n)\nshap_imps = pd.DataFrame(\n    {'col':X_train_orig.columns, 'imp':np.abs(shap_rf_values).mean(0)}\n).sort_values(by='imp',ascending=False)\nshap_cols = shap_imps.head(120).col.tolist() \n```", "```py\nga_rf = GAFeatureSelectionCV(\n    RandomForestRegressor(random_state=rand, max_depth=3),\n    cv=3,\n    scoring='neg_root_mean_squared_error',\n    crossover_probability=0.8,\n    mutation_probability=0.1,\n    generations=5, n_jobs=-1\n)\nga_rf = ga_rf.fit(\n    X_train.iloc[sample_train_idx][top_cols].values,\n    y_train[sample_train_idx]\n)\nga_rf_cols = np.array(top_cols)[ga_rf.best_features_].tolist() \n```", "```py\nfsnames = ['w-sfs-lda', 'h-rfe-lda', 'a-shap', 'a-ga-rf']\nfscols = [sfs_lda_cols, rfe_lda_cols, shap_cols, ga_rf_cols]\ndepths = [5, 6, 5, 6] \n```", "```py\ntrain_mdls_with_fs(reg_mdls, fsnames, fscols, depths) \ndisplay_mdl_metrics(reg_mdls, 'max_profit_test', max_depth=7) \nFigure 10.8:\n```", "```py\nwinning_mdl = 'rf_5_e-llarsic'\nfitted_rf_mdl = reg_mdls[winning_mdl]['fitted']\nshap_rf_explainer = shap.TreeExplainer(fitted_rf_mdl)\nshap_rf_interact_values = \\\n    shap_rf_explainer.shap_interaction_values(\n        X_test.iloc[sample_test_idx][llarsic_cols]\n    )\nshap.summary_plot(\n    shap_rf_interact_values,\n    X_test.iloc[sample_test_idx][llarsic_cols],\n    plot_type=\"compact_dot\",\n    sort=True\n) \nFigure 10.9:\n```", "```py\nshap_rf_interact_avgs = np.abs(shap_rf_interact_values).mean(0)\nshap_rf_interact_avgs_nodiag = shap_rf_interact_avgs.copy()\nnp.fill_diagonal(shap_rf_interact_avgs_nodiag, 0)\nshap_rf_interact_df = pd.DataFrame(shap_rf_interact_avgs_nodiag)\nshap_rf_interact_df.columns = X_test[llarsic_cols].columns\nshap_rf_interact_df.index = X_test[llarsic_cols].columns\nshap_rf_interact_ranks = 112 -rankdata(np.sum(\n     shap_rf_interact_avgs_nodiag, axis=0)\n)\nmost_interact_cols = shap_rf_interact_df.columns[\n    shap_rf_interact_ranks < 13\n]\nshap_rf_interact_df = shap_rf_interact_df.loc[\nmost_interact_cols,most_interact_cols\n]\nsns.heatmap(\n    shap_rf_interact_df,\n    cmap='Blues',\n    annot=True,\n    annot_kws={'size':10},\n    fmt='.3f',\n    linewidths=.5\n) \nFigure 10.10. It depicts the most salient feature interactions according to SHAP interaction absolute mean values. Note that these are averages, so given how right-skewed most of these features are, it is likely much higher for many observations. However, it’s still a good indication of relative impact:\n```", "```py\nshap_rf_values = shap_rf_explainer.shap_values(\n    X_test.iloc[sample_test_idx] [llarsic_cols]\n)\nmaxramt_shap = shap_rf_values[:,llarsic_cols.index(\"MAXRAMNT\")]\nshap.dependence_plot(\n    \"MAXRAMNT\",\n    shap_rf_values,\n    X_test.iloc[sample_test_idx][llarsic_cols],\n    interaction_index=\"AVGGIFT\",\n    show=False, alpha=0.1\n)\nplt.xlim(xmin=np.percentile(X_test.MAXRAMNT, 1),\\\n         xmax=np.percentile(X_test.MAXRAMNT, 99))\nplt.ylim(ymin=np.percentile(maxramt_shap, 1),\\\n         ymax=np.percentile(maxramt_shap, 99))\nplt.xscale('log') \n```", "```py\nprofits_test = reg_mdls['rf_5_e-llarsic']['profits_test']\nprofits_train = reg_mdls['rf_5_e-llarsic']['profits_train']\nmldatasets.compare_df_plots(\n    profits_test[['costs', 'profit', 'roi']],\n    profits_train[['costs', 'profit', 'roi']],\n    'Test',\n    'Train',\n    x_label='Threshold',\n    y_formatter=y_formatter,\n    plot_args={'secondary_y':'roi'}\n) \n```"]