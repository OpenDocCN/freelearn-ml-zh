- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Model Calibration
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型校准
- en: So far, we have explored various ways to handle the data imbalance. In this
    chapter, we will see the need to do some post-processing of the prediction scores
    that we get from the trained models. This can be helpful either during the real-time
    prediction from the model or during the offline training time evaluation of the
    model. We will also understand some ways of measuring how calibrated the model
    is and how imbalanced datasets make the model calibration inevitable.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探讨了处理数据不平衡的各种方法。在本章中，我们将看到需要对从训练模型获得的预测分数进行一些后处理的需求。这可以在从模型进行实时预测或在对模型进行离线训练时间评估时有所帮助。我们还将了解一些衡量模型校准程度的方法以及不平衡数据集如何使模型校准变得不可避免。
- en: 'The following topics will be covered in the chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introduction to model calibration
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型校准简介
- en: The influence of data balancing techniques on model calibration
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据平衡技术对模型校准的影响
- en: Plotting calibration curves for a model trained on a real-world dataset
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为在真实世界数据集上训练的模型绘制校准曲线
- en: Model calibration techniques
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型校准技术
- en: The impact of calibration on a model’s performance
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 校准对模型性能的影响
- en: By the end of this chapter, you will have a clear understanding of what model
    calibration means, how to measure it, and when and how to apply it.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将清楚地了解模型校准的含义、如何衡量它以及何时以及如何应用它。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Similar to prior chapters, we will continue to utilize common libraries such
    as `matplotlib`, `numpy`, `scikit-learn`, `xgboost`, and `imbalanced-learn`. The
    code and notebooks for this chapter are available on GitHub at [https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/master/chapter10](https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/master/chapter10).
    You can open the GitHub notebook using Google Colab by clicking on the **Open
    in Colab** icon on the top of the chapter’s notebook or by launching it from [https://colab.research.google.com](https://colab.research.google.com)
    using the GitHub URL of the notebook.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与前几章类似，我们将继续使用常见的库，如`matplotlib`、`numpy`、`scikit-learn`、`xgboost`和`imbalanced-learn`。本章的代码和笔记本可在GitHub上找到，网址为[https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/master/chapter10](https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/master/chapter10)。您可以通过点击章节笔记本顶部的**在Colab中打开**图标或通过使用笔记本的GitHub
    URL从[https://colab.research.google.com](https://colab.research.google.com)启动它来打开GitHub笔记本。
- en: Introduction to model calibration
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型校准简介
- en: What is the difference between stating “*The model predicted the transaction
    as fraudulent*” and “*The* *model estimated a 60% probability of the transaction
    being fraudulent*”? When would one statement be more useful than the other?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: “*模型预测交易为欺诈*”和“*模型估计交易欺诈的可能性为60%*”之间的区别是什么？何时一个陈述比另一个更有用？
- en: The difference between the two is that the second statement represents likelihood.
    This likelihood can be useful in understanding the model’s confidence, which is
    needed in many applications, such as in medical diagnosis. For example, the prediction
    that a patient is 80% likely or 80% probable to have cancer is more useful to
    the doctor than just predicting whether the patient has cancer or not.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 两者之间的区别在于第二个陈述代表似然性。这种似然性在理解模型的置信度时可能很有用，这在许多应用中都是必需的，例如在医学诊断中。例如，预测一个患者有80%的可能性或80%的可能性患有癌症，对医生来说比仅仅预测患者是否患有癌症更有用。
- en: A model is considered calibrated if there is a match between the number of positive
    classes and predicted probability. Let’s try to understand this further. Let’s
    say we have 10 observations, and for each of them, the model predicts a probability
    of 0.7 to be of the positive class. If the model is calibrated, then we expect
    7 out of those 10 observations to belong to the positive class.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果正类别的数量与预测概率相匹配，则认为模型是校准的。让我们进一步理解这一点。假设我们有10个观察值，并且对于每一个，模型预测正类别的概率为0.7。如果模型是校准的，那么我们预计这10个观察值中有7个属于正类别。
- en: However, surprisingly, most machine learning models are not calibrated, and
    their prediction values tend to be overconfident or underconfident. What does
    that mean? An overconfident model would predict the probability to be 0.9 (for
    example), while the actual probability might have been only 0.6\. Similarly, an
    underconfident model would predict the probability to be 0.6 (for example) while
    the actual probability might have been 0.9.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，令人惊讶的是，大多数机器学习模型都没有校准，它们的预测值往往过于自信或缺乏自信。这意味着什么？一个过于自信的模型可能会预测概率为0.9（例如），而实际概率可能只有0.6。同样，一个缺乏自信的模型可能会预测概率为0.6（例如），而实际概率可能是0.9。
- en: '*Do we always need to calibrate* *model probabilities?*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们是否总是需要校准* *模型概率*？'
- en: Actually, it depends upon the problem at hand. If the problem inherently involves
    the ordering of certain items, say in search ranking, then all we need is relative
    scores and real probabilities don’t matter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这取决于具体问题。如果问题本质上涉及某些项目的排序，比如在搜索排名中，那么我们只需要相对分数，实际的概率并不重要。
- en: 'Here is an example of an overconfident model where we can see that most of
    the time, the predicted probabilities from the model are much higher than the
    fraction of actual positive examples:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个过度自信模型的例子，我们可以看到，大多数时候，模型预测的概率远高于实际正例的分数：
- en: '![](img/B17259_10_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_01.jpg)'
- en: Figure 10.1 – The calibration curve of an overconfident model for which predicted
    probabilities are overestimated
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 对预测概率高估的过度自信模型的校准曲线
- en: Why bother with model calibration
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要在乎模型校准
- en: 'As we’ve discussed, model calibration may not be necessary if the primary goal
    is to obtain a relative ranking of items. However, there are several other scenarios
    where model calibration becomes crucial:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论的那样，如果主要目标是获得项目的相对排名，则模型校准可能不是必要的。然而，还有其他几种场景下，模型校准变得至关重要：
- en: '**Interpreting model predictions as confidence**: Calibrated models allow the
    scores to be interpreted as the model’s confidence in its predictions. For example,
    in a spam detection system, a calibrated score of 0.9 could mean the model is
    90% confident that an email is spam.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将模型预测解释为置信度**：校准模型允许将分数解释为模型对其预测的置信度。例如，在垃圾邮件检测系统中，校准得分为0.9可能意味着模型有90%的置信度认为一封电子邮件是垃圾邮件。'
- en: '**Interpreting model predictions as probabilities**: These scores can also
    be viewed as probabilities, making them directly interpretable. In a weather prediction
    model, a calibrated score of 0.8 could be interpreted as an 80% chance of rain.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将模型预测解释为概率**：这些分数也可以被视为概率，使它们直接可解释。在一个天气预报模型中，校准得分为0.8可以解释为有80%的降雨可能性。'
- en: '**High-stake applications**: Such calibrated probabilities are particularly
    useful in high-stake applications such as healthcare for disease prediction or
    in fraud detection. For instance, in predicting the likelihood of a patient having
    a certain disease, a calibrated score of 0.7 could mean there’s a 70% chance the
    patient has the disease, guiding further medical tests or treatments.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高风险应用**：这种校准概率在医疗保健等高风险应用中特别有用，例如疾病预测或欺诈检测。例如，在预测患者患有某种疾病的可能性时，校准得分为0.7可能意味着患者有70%的可能性患有该疾病，从而指导进一步的医学检查或治疗。'
- en: '**Enhancing human interpretability and trust**: Human interpretability and
    trust in model predictions are enhanced when the model is calibrated. For example,
    in a loan approval system, a calibrated score could help loan officers understand
    the risk associated with a loan application, thereby aiding in the decision-making
    process.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强人类可解释性和信任**：当模型校准时，人类对模型预测的可解释性和信任度得到增强。例如，在贷款审批系统中，校准得分可以帮助贷款官员了解贷款申请的风险，从而有助于决策过程。'
- en: 'It is particularly important to be aware of model calibration when working
    with deep learning models, as several common neural network hyperparameters can
    affect model calibration:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当与深度学习模型一起工作时，尤其重要的是要意识到模型校准，因为几个常见的神经网络超参数会影响模型校准：
- en: '**Model capacity**: More layers (depth) and more neurons (width) usually reduce
    the classification error but have been found to lower the calibration of the model
    [1].'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型容量**：更多的层（深度）和更多的神经元（宽度）通常可以减少分类错误，但发现这会降低模型的校准度 [1]。'
- en: '**Batch norm**: Although batch norm typically improves training time, has a
    mild regularizing effect, and might even improve the accuracy of the model, it
    can also make the model more miscalibrated [1].'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批归一化**：尽管批归一化通常可以提高训练时间，具有轻微的正则化效果，甚至可能提高模型的准确性，但它也可能使模型出现更多的校准错误[1]。'
- en: '**Weight decay**: Weight decay is a regularization technique, and more weight
    decay typically helps calibrate the model. So, instead, if we have less weight
    decay, then we would expect the model to be more miscalibrated [1].'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**权重衰减**：权重衰减是一种正则化技术，通常更多的权重衰减有助于校准模型。因此，如果我们有较少的权重衰减，那么我们预期模型会更多地出现校准错误[1]。'
- en: Let’s see what kind of model scores typically need to be calibrated.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看通常需要校准的模型得分类型。
- en: Models with and without well-calibrated probabilities
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 具有和没有良好校准概率的模型
- en: The logistic regression model is often assumed to output calibrated probabilities,
    particularly when it is an appropriate fit for the data [2]. This assumption is
    based on the model’s optimization of the cross-entropy loss or log loss function.
    However, it’s worth noting that logistic regression can produce overconfident
    predictions, and regularization techniques such as L1/L2 can help the model be
    more conservative and thus improve calibration.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型通常假设输出校准概率，尤其是在它适合数据时[2]。这个假设基于模型对交叉熵损失或对数损失函数的优化。然而，值得注意的是，逻辑回归可能会产生过于自信的预测，而L1/L2等正则化技术可以帮助模型更加保守，从而提高校准。
- en: Naïve Bayes models often push probabilities close to zero or one due to their
    assumption about feature independence, which can result in poor calibration [2].
    On the other hand, bagging models (such as random forests) and boosting models
    generally produce probabilities that are away from the extremes of zero and one.
    This is due to the score-averaging nature of the individual decision trees or
    stumps they use, which often leads to better calibration.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于对特征独立性的假设，朴素贝叶斯模型通常将概率推向零或一，这可能导致校准不良[2]。另一方面，袋装模型（如随机森林）和提升模型通常产生远离零和一的概率。这是由于它们使用的单个决策树或树桩的得分平均性质，这通常会导致更好的校准。
- en: For neural networks, some research studies show that simple networks tend to
    give calibrated scores [2]. Still, since neural network models are getting more
    complex day by day, modern neural networks tend to be fairly uncalibrated [1]
    [3]. As *Figure 10**.2* shows, a five-layer LeNet is well calibrated since its
    confidence levels closely mirror the expected accuracy, evident by the bars roughly
    aligning along the diagonal. In contrast, while a 110-layer ResNet boasts higher
    accuracy (lower error), its confidence scores don’t align as closely with this
    accuracy [1].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于神经网络，一些研究显示，简单的网络往往给出校准得分[2]。然而，由于神经网络模型每天都在变得更加复杂，现代神经网络往往校准不足[1] [3]。如图*10**.2*所示，五层LeNet校准良好，因为其置信水平与预期的准确性紧密匹配，这从条形图大致沿对角线对齐中可以看出。相比之下，虽然110层ResNet具有更高的准确性（更低的错误率），但其置信分数与这种准确性并不紧密匹配[1]。
- en: '![](img/B17259_10_02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17259_10_02.jpg)'
- en: Figure 10.2 – Reliability diagrams for a five-layer LeNet (left) and a 110-layer
    ResNet (right) on CIFAR-100 (adapted from Guo et al. [1])
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 – 在CIFAR-100上对五层LeNet（左）和110层ResNet（右）的可靠性图（改编自Guo等人[1]）
- en: Next, we will learn how to measure whether a model is calibrated or not.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习如何衡量模型是否校准。
- en: Calibration curves or reliability plot
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校准曲线或可靠性图
- en: Let’s see how we can understand if the model’s scores are calibrated or not.
    Let’s assume we have a model that predicts if an image is of a cat or not.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何理解模型的得分是否校准。假设我们有一个预测图像是否为猫的模型。
- en: A **calibration curve** is basically obtained by plotting the fraction of actual
    positive values (*y* axis) against predicted probability scores (*x* axis).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**校准曲线**基本上是通过将实际正值的比例（*y*轴）与预测概率得分（*x*轴）进行绘图来获得的。'
- en: 'Let’s see how to plot the calibration curve, also known as a **reliability
    plot**:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何绘制校准曲线，也称为**可靠性图**：
- en: 'Create a dataset with two columns: one with actual labels and another with
    predicted probability.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含两列的数据集：一列是实际标签，另一列是预测概率。
- en: Sort the data into ascending order using predicted probability.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用预测概率对数据进行升序排序。
- en: Divide the predicted probability dataset into fixed-size bins ranging from 0
    to 1\. For example, if we create 10 bins, we get 0.1, 0.2, 0.3, …, 0.9, 1.0\.
    If there are too many examples in the dataset, we can use smaller-size bins and
    vice versa.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测概率数据集划分为从 0 到 1 的固定大小区间。例如，如果我们创建 10 个区间，我们得到 0.1、0.2、0.3、……、0.9、1.0。如果数据集中有太多示例，我们可以使用更小的区间，反之亦然。
- en: Now compute the fraction of actual positives in each bin. These fraction values
    will be our *y* axis values. On the *x* axis, we plot the fixed bin value, i.e.,
    0.1, 0.2, 0.3, etc.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在计算每个区间中实际正例的比例。这些比例值将是我们的 *y* 轴值。在 *x* 轴上，我们绘制固定区间值，即 0.1、0.2、0.3、等等。
- en: 'We get a plot like the one in the following diagram:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得到如下图中类似的图表：
- en: '![](img/B17259_10_03.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17259_10_03.jpg)'
- en: Figure 10.3 – Plotting the probability predictions of an XGBoost classifier
    against the fraction of positives
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – 将 XGBoost 分类器的概率预测与正例比例绘制成图
- en: 'We need to be careful with the number of bins chosen because of the following
    reasons:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要小心选择区间的数量，以下是一些原因：
- en: If we choose too few bins, the plot may look linear and well-fitted, giving
    the impression that the model is calibrated. More importantly, the real danger
    of using too few bins is that the curve won’t have enough detail; it will essentially
    be just a few points connected together.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们选择的区间太少，图表可能看起来是线性的并且拟合得很好，给人一种模型已经校准的印象。更重要的是，使用太少区间的真正危险是曲线将没有足够的细节；它本质上只是几个点连接在一起。
- en: Similarly, if we choose too many bins, then the plot may look noisy, and we
    may wrongly conclude the model to be uncalibrated.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同样，如果我们选择的区间太多，那么图表可能看起来很嘈杂，我们可能会错误地得出模型未校准的结论。
- en: It might become particularly difficult to identify whether a model is calibrated
    or not if we are dealing with imbalanced datasets. If our dataset is not balanced
    and has a much smaller number of examples of positive classes to plot, then the
    calibration plot may look noisy or show that the model is underconfident or overconfident.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们处理的是不平衡数据集，那么确定模型是否校准可能特别困难。如果我们的数据集不平衡，并且正例的示例数量很少，那么校准图可能看起来很嘈杂或显示模型不够自信或过于自信。
- en: 'However, it’s worth noting that many models are not perfectly calibrated and
    their calibration curves may deviate from the perfect calibration line:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，值得注意的是，许多模型并不是完全校准的，它们的校准曲线可能会偏离完美的校准线：
- en: '![](img/B17259_10_04.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17259_10_04.jpg)'
- en: Figure 10.4 – A calibration curve plot when fitted via an XGBoost model; on
    the left is an overconfident model and on the right is an underconfident model
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 – 通过 XGBoost 模型拟合的校准曲线图；左侧是一个过于自信的模型，右侧是一个不够自信的模型
- en: '`scikit-learn` provides a function called `calibration_curve` to easily plot
    this curve:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn` 提供了一个名为 `calibration_curve` 的函数，可以轻松绘制此曲线：'
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: However, visually judging and comparing various calibration plots can be error-prone,
    and we might want to use a metric that can make some kind of numerical comparison
    of the calibrations of two different models.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，视觉判断和比较各种校准图可能会出错，我们可能希望使用一个可以比较两个不同模型校准的某种数值比较指标。
- en: Brier score
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Brier 分数
- en: 'There is a commonly used measure called the **Brier score**, which is basically
    the mean squared error of the predicted probability obtained from the model as
    follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个常用的度量标准称为 **Brier 分数**，基本上是从模型获得的预测概率的均方误差，如下所示：
- en: Brier score =  1 _ N  ∑ (predicted _ probability − actual _ label) 2
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Brier 分数 = 1/N ∑ (预测概率 - 实际标签)²
- en: where N is the number of examples.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 N 是示例数量。
- en: 'This score varies between 0 (best possible score) and 1 (worst possible score).
    This metric is very similar to the `scikit-learn` makes our job a bit easier:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分数介于 0（最佳可能分数）和 1（最差可能分数）之间。这个指标与 `scikit-learn` 非常相似，它使我们的工作变得容易一些：
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This outputs the following Brier score loss value:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出以下 Brier 分数损失值：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The paper *Class Probability Estimates are Unreliable for Imbalanced Data (and
    How to Fix Them)* by Wallace and Dahabreh [4] argues that a lower Brier score
    for an imbalanced dataset might just mean that the calibration is good overall
    but not necessarily for minority or rare classes. In order to track the calibration
    of individual classes, they proposed a stratified Brier score:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Wallace 和 Dahabreh 的论文《不平衡数据中的类别概率估计不可靠（以及如何修复它们）》（[4]）认为，对于不平衡数据集，较低的 Brier
    分数可能仅仅意味着校准总体上是好的，但并不一定适用于少数或稀有类别。为了跟踪单个类别的校准，他们提出了分层 Brier 分数：
- en: '![](img/B17259_10_05.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17259_10_05.jpg)'
- en: Figure 10.5 – Stratified Brier scores for positive and negative classes [4]
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 – 正负类的分层Brier分数 [4]
- en: where N pos denotes the number of positive class examples, N neg denotes the
    number of negative class examples, y i is the label, and  ˆ P  is the model prediction
    score.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 其中N pos表示正类示例的数量，N neg表示负类示例的数量，y i是标签，ˆ P是模型预测分数。
- en: Let’s look at an alternative metric to measure calibration that is more popular
    among deep learning models.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个更受欢迎的替代指标来衡量校准，这在深度学习模型中更为常见。
- en: Expected Calibration Error
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预期校准误差
- en: '**Expected Calibration Error** (**ECE**) [5] is another metric for measuring
    how calibrated a model is. Predicted probabilities from the model are grouped
    into M bins of equal size. Let’s assume B m is the set of examples whose prediction
    scores fall into the *m*th bin.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**预期校准误差**（**ECE**）[5]是衡量模型校准程度的另一个指标。模型的预测概率被分组到M个大小相等的区间中。假设B m是预测分数落在第*m*个区间的示例集合。'
- en: Then for each bin (B m), we calculate the difference between the average predicted
    probability (that is, conf(B m)) and accuracy (that is, the proportion of examples
    correctly classified). This difference is | acc(B m) − conf(B m)|.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于每个区间（B m），我们计算平均预测概率（即conf(B m)）和准确率（即正确分类的示例比例）之间的差异。这个差异是| acc(B m) −
    conf(B m)|。
- en: 'We also weigh these differences by the number of examples in each bin and finally
    sum them up to get the overall ECE value. This is equivalent to multiplying the
    difference by B m/n, where n is the total number of examples. Finally, we sum
    this over all the bins to get the final formula:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还根据每个区间的示例数量权衡这些差异，最后将它们加起来得到总的ECE值。这相当于将差异乘以B m/n，其中n是示例总数。最后，我们将这个值对所有区间求和，得到最终的公式：
- en: ECE = ∑ m=1 M |B m| /n *|acc(B m) − conf(B m)|
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ECE = ∑ m=1 M |B m| /n *|acc(B m) − conf(B m)|
- en: 'Accuracy and confidence can be defined as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率和置信度可以定义为以下：
- en: 'Accuracy acc(B m) is the proportion of examples in bin B m correctly classified
    by the model:'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率acc(B m)是模型正确分类到B m区间的示例比例：
- en: acc(B m) = (1 / |B m|)* ∑ i=1 |B m| I(y i = ŷ i)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: acc(B m) = (1 / |B m|)* ∑ i=1 |B m| I(y i = ŷ i)
- en: 'Confidence is the average predicted probability of the examples in bin B m:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 置信度是B m区间中示例的平均预测概率：
- en: conf(B m) = (1 / |B m|)* ∑ i=1 |B m| p i
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: conf(B m) = (1 / |B m|)* ∑ i=1 |B m| p i
- en: 'There is an extension of the previous metric called **Maximum Calibration Error**
    (**MCE**) that measures the largest difference between the accuracy and confidence
    *across all* *the bins*:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个之前指标的扩展，称为**最大校准误差**（**MCE**），它衡量了所有区间中准确率和置信度之间的最大差异：
- en: MCE = ma x m=1 M |acc(B m) − conf(B m)|
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: MCE = ma x m=1 M |acc(B m) − conf(B m)|
- en: This can be useful in applications where it is important that the model be well
    calibrated in all bins, and MCE can then be minimized.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这在模型需要在所有区间内都很好地校准的应用中非常有用，并且可以最小化MCE。
- en: '*Figure 10**.6* shows a reliability diagram with the ECE and MCE values on
    the MNIST dataset:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10**.6*显示了MNIST数据集上的可靠性图，其中包含ECE和MCE值：'
- en: '![](img/B17259_10_06.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_06.jpg)'
- en: Figure 10.6 – Reliability diagram with ECE and MCE values for the MNIST dataset
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 – MNIST数据集的可靠性图，包含ECE和MCE值
- en: 🚀 Model calibration in production at Netflix
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 🚀 Netflix在生产中的模型校准
- en: '**🎯** **Problem** **being solved:**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**🎯** **解决的问题：**'
- en: Netflix aimed to provide recommendations [6] that were closely aligned with
    a user’s varied interests rather than focusing solely on their main preferences.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Netflix旨在提供与用户多样化的兴趣紧密相关的推荐[6]，而不是仅仅关注他们的主要偏好。
- en: '**⚖️****Data imbalance:**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**⚖️** **数据不平衡：**'
- en: Traditional recommendation systems can amplify a user’s primary interests, thereby
    overshadowing their secondary or tertiary preferences. This can be considered
    a form of interest imbalance.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的推荐系统可能会放大用户的主要兴趣，从而掩盖他们的次要或第三级偏好。这可以被认为是一种兴趣不平衡。
- en: '**🎨** **Model** **calibration strategy:**'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**🎨** **模型校准策略：**'
- en: Netflix employed a greedy re-ranking approach to calibration. The initial model
    ranked movies based on the predicted likelihood of a user watching them. This
    ranking is then adjusted using a greedy algorithm to ensure that the top 10 recommended
    movies match the genre distribution in the user’s watch history.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Netflix采用了贪婪重排序方法进行校准。初始模型根据用户观看电影的预测概率对电影进行排序。然后使用贪婪算法调整排序，以确保前10个推荐电影与用户观看历史中的类型分布相匹配。
- en: '**Example**: If a user’s watch history comprises 50% action, 30% comedy, and
    20% drama, the re-ranking algorithm reshuffles the top recommendations to reflect
    this distribution.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：如果一个用户的观看历史包括50%的动作片，30%的喜剧片和20%的剧情片，重新排序算法会重新排列顶级推荐以反映这种分布。'
- en: '**📊****Additional points:**'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**📊** **附加点**：'
- en: The greedy re-ranking algorithm was straightforward to implement. It was empirically
    shown to improve recommendation performance across various datasets.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 贪婪重新排序算法易于实现。经验上证明，它在各种数据集上提高了推荐性能。
- en: This approach ensured that Netflix’s recommendations cater to the full spectrum
    of a user’s interests, preventing any single interest from dominating the suggestions.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法确保了Netflix的推荐能够满足用户兴趣的全谱系，防止任何单一兴趣主导建议。
- en: In the next section, let’s try to understand how data balancing techniques can
    affect the calibration of models.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，让我们尝试了解数据平衡技术如何影响模型的校准。
- en: The influence of data balancing techniques on model calibration
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据平衡技术对模型校准的影响
- en: The usual impact of applying data-level techniques, such as oversampling and
    undersampling, is that they change the distribution of the training data for the
    model. This means that the model sees an almost equal number of all the classes,
    which doesn’t reflect the actual data distribution. Because of this, the model
    becomes less calibrated against the true imbalanced distribution of data. Similarly,
    algorithm-level cost-sensitive techniques that use `class_weight` to account for
    the data imbalance have a similar degraded impact on degrading the calibration
    of the model against the true data distribution. *Figure 10**.7* (log scale) from
    a recent study [7] shows the degrading calibration of a CNN-based model for pneumonia
    detection task, as `class_weight` increases from 0.5 to 0.9 to 0.99\. The model
    becomes over-confident and hence less calibrated with the increase in `class_weight`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 应用数据级技术，如过采样和欠采样，的通常影响是它们改变了模型训练数据的分布。这意味着模型看到所有类别的数量几乎相等，这并不反映实际的数据分布。因此，模型对真实不平衡数据分布的校准程度降低。同样，使用`class_weight`来处理数据不平衡的算法级成本敏感技术对模型对真实数据分布的校准也有类似的负面影响。*图10.7*（对数尺度）来自最近的研究[7]，展示了基于CNN的肺炎检测任务的模型校准的退化，随着`class_weight`从0.5增加到0.9到0.99。随着`class_weight`的增加，模型变得过于自信，因此与真实数据分布的校准程度降低。
- en: '![](img/B17259_10_07.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_07.jpg)'
- en: Figure 10.7 – Degrading calibration of a CNN model as class_weight changes from
    0.5 to 0.9 to 0.99 (log scale) (image adapted from Caplin, et al. [7])
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 – 随着class_weight从0.5变化到0.9到0.99（对数尺度）的CNN模型校准退化（图像改编自Caplin等人[7]）
- en: Similarly, in *Figure 10**.8*, we show the calibration curve for the logistic
    regression model on the `thyroid_sick` UCI dataset. The corresponding notebook
    can be found in the GitHub repo of this book.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在*图10.8*中，我们展示了在`thyroid_sick` UCI数据集上逻辑回归模型的校准曲线。相应的笔记本可以在本书的GitHub仓库中找到。
- en: '![](img/B17259_10_08.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_08.jpg)'
- en: Figure 10.8 – A calibration curve using logistic regression with no sampling
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8 – 使用无采样的逻辑回归校准曲线
- en: '*Figure 10**.9* and *Figure 10**.10* demonstrate how oversampling techniques
    can worsen a model’s calibration:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10.9*和*图10.10*展示了过采样技术如何恶化模型的校准：'
- en: '![](img/B17259_10_09.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_09.jpg)'
- en: Figure 10.9 – A calibration curve using logistic regression with random oversampling
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9 – 使用随机过采样的逻辑回归校准曲线
- en: '![](img/B17259_10_10.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_10.jpg)'
- en: Figure 10.10 – A calibration curve using logistic regression with SMOTE
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 – 使用SMOTE的逻辑回归校准曲线
- en: 'Similarly, *Figure 10**.11* shows a similar effect for undersampling techniques:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，*图10.11*展示了欠采样技术产生的类似效果：
- en: '![](img/B17259_10_11.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_11.jpg)'
- en: Figure 10.11 – A calibration curve using logistic regression with random undersampling
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11 – 使用随机欠采样的逻辑回归校准曲线
- en: '*Figure 10**.12* shows how class weighting can negatively affect the model
    calibration:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10.12*展示了类权重如何对模型校准产生负面影响：'
- en: '![](img/B17259_10_12.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_12.jpg)'
- en: Figure 10.12 – A calibration curve with no sampling technique (left) and class
    weighting (right) using logistic regression
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12 – 无采样技术（左）和类权重（右）使用逻辑回归的校准曲线
- en: In the plots that we just saw, both undersampling and oversampling made the
    model over-confident. Undersampling can make the model optimistic about its ability
    to classify the minority class while oversampling can lead the model to overestimate
    the likelihood of encountering minority instances. This overconfidence arises
    because the model assumes the altered training data represents the real-world
    distribution. To elaborate, when we undersample or oversample, we’re essentially
    telling the model that the minority class is more common (or less rare) than it
    actually is. The model can then generalize this skewed view to new, unseen data.
    As a result, it can become overconfident in its predictions for the minority class,
    thinking these outcomes are more likely than they actually are. This overconfidence
    doesn’t extend to the majority class because the model still sees plenty of those
    examples during training. Therefore, the model ends up being miscalibrated and
    tends to be overly sure of its predictions for the minority class.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们刚刚看到的图表中，无论是欠采样还是过采样都使模型过于自信。欠采样可能会使模型对其分类少数类的能力过于乐观，而过采样可能会导致模型高估遇到少数实例的可能性。这种过自信是由于模型假设修改后的训练数据代表了真实世界的分布。为了详细说明，当我们进行欠采样或过采样时，我们实际上是在告诉模型少数类的出现频率比实际情况更高（或更不常见）。然后，模型可以将这种扭曲的观点推广到新的、未见过的数据。因此，它可能会对其对少数类的预测过于自信，认为这些结果比实际情况更有可能。这种过自信并不适用于多数类，因为模型在训练过程中仍然看到了大量的这些例子。因此，模型最终会校准不当，并且倾向于对其对少数类的预测过于自信。
- en: In the following section, we will utilize a real-world dataset, train a model
    using this dataset, and then determine the calibration of the model by plotting
    calibration curves.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将使用一个真实世界的数据集，使用这个数据集训练一个模型，然后通过绘制校准曲线来确定模型的校准情况。
- en: Plotting calibration curves for a model trained on a real-world dataset
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制基于真实世界数据集训练的模型的校准曲线
- en: Model calibration should ideally be done on a dataset that is separate from
    the training and test set. Why? It’s to avoid overfitting because the model can
    become too tailored to the training/test set’s unique characteristics.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 模型校准理想情况下应该在独立于训练集和测试集的数据集上进行。为什么？这是为了避免过拟合，因为模型可能会变得过于适应训练/测试集的独特特征。
- en: We can have a hold-out dataset that has been specifically set aside for model
    calibration. In some cases, we may have too little data to justify splitting it
    further into a separate hold-out dataset for calibration. In such cases, a practical
    compromise might be to use the test set for calibration, assuming that the test
    set has the same distribution as the dataset on which the model will be used to
    make final predictions. However, we should keep in mind that after calibrating
    on the test set, we no longer have an unbiased estimate of the final performance
    of the model, and we need to be cautious about interpreting the model’s performance
    metrics.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以保留一个专门用于模型校准的保留数据集。在某些情况下，我们可能数据太少，无法证明将其进一步分割为单独的保留数据集进行校准的合理性。在这种情况下，一个实用的折衷方案可能是使用测试集进行校准，假设测试集与模型将用于最终预测的数据集具有相同的分布。然而，我们应该记住，在测试集上进行校准后，我们不再有模型最终性能的无偏估计，我们需要谨慎地解释模型性能指标。
- en: We use the `HR Data for Analytics` dataset from Kaggle ([https://www.kaggle.com/datasets/jacksonchou/hr-data-for-analytics](https://www.kaggle.com/datasets/jacksonchou/hr-data-for-analytics)).
    This dataset contains employee profiles of a large company, where each record
    is an employee.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 Kaggle 上的 `HR Data for Analytics` 数据集（[https://www.kaggle.com/datasets/jacksonchou/hr-data-for-analytics](https://www.kaggle.com/datasets/jacksonchou/hr-data-for-analytics)）。这个数据集包含了一家大型公司的员工档案，其中每条记录代表一名员工。
- en: 'The downloaded dataset `HR_comma_sep.csv` has been added to the GitHub repo
    of the book. Let’s load the dataset into a `pandas` DataFrame:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 下载的数据集 `HR_comma_sep.csv` 已添加到本书的 GitHub 仓库中。让我们将数据集加载到一个 `pandas` DataFrame
    中：
- en: '[PRE3]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This shows some sample rows from the dataset:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了数据集的一些样本行：
- en: '|  | `last_evaluation` | `left` | ... | `sales` | `salary` |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|  | `last_evaluation` | `left` | ... | `sales` | `salary` |'
- en: '| `0` | 0.53 | 1 | ... | sales | low |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| `0` | 0.53 | 1 | ... | 销售额 | 低 |'
- en: '| `1` | 0.86 | 1 | ... | sales | medium |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| `1` | 0.86 | 1 | ... | 销售额 | 中等 |'
- en: '| `2` | 0.88 | 1 | ... | sales | medium |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| `2` | 0.88 | 1 | ... | 销售额 | 中等 |'
- en: '| `3` | 0.87 | 1 | ... | sales | low |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| `3` | 0.87 | 1 | ... | 销售额 | 低 |'
- en: '| `4` | 0.52 | 1 | ... | sales | low |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| `4` | 0.52 | 1 | ... | 销售额 | 低 |'
- en: '| `...` | ... | ... | ... | ... | ... |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| `...` | ... | ... | ... | ... | ... |'
- en: '| `14994` | 0.57 | 1 | ... | support | low |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| `14994` | 0.57 | 1 | ... | 支持度 | 低 |'
- en: '| `14995` | 0.48 | 1 | ... | support | low |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| `14995` | 0.48 | 1 | ... | 支持度 | 低 |'
- en: '| `14996` | 0.53 | 1 | ... | support | low |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| `14996` | 0.53 | 1 | ... | 支持度 | 低 |'
- en: '| `14997` | 0.96 | 1 | ... | support | low |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| `14997` | 0.96 | 1 | ... | 支持度 | 低 |'
- en: '| `14998` | 0.52 | 1 | ... | support | low |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| `14998` | 0.52 | 1 | ... | 支持度 | 低 |'
- en: Table 10.1 – Sample rows from the HR Data for Analytics dataset from Kaggle
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.1 – Kaggle的HR Data for Analytics数据集的样本行
- en: 'It’s clear that some of the columns, such as `sales` and `salary`, are categorical.
    The `left` column is our labels column. Let’s get the imbalance in the dataset:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，一些列，如`sales`和`salary`，是分类的。`left`列是我们的标签列。让我们获取数据集的不平衡情况：
- en: '[PRE4]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This gives us the count of the labels:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了标签的数量：
- en: '[PRE5]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We need to convert the categorical columns into ID labels using `LabelEncoder`
    and then standardize these columns using `StandardScaler` from `sklearn`. After
    preprocessing, we split the dataset into three subsets: 80% for the training set
    and 10% each for the validation and test sets. We’ll skip the code for these steps
    and jump straight into training the model. For the complete code, please refer
    to the accompanying GitHub notebook.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要使用`LabelEncoder`将分类列转换为ID标签，然后使用`sklearn`中的`StandardScaler`对这些列进行标准化。预处理完成后，我们将数据集分为三个子集：80%用于训练集，10%分别用于验证集和测试集。我们将跳过这些步骤的代码，直接进入模型训练。完整的代码请参阅附带的GitHub笔记本。
- en: As usual, we will train a random forest model on the training set and use the
    test set for evaluating the model. We will use a validation set for calibrating
    the model.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，我们将在训练集上训练随机森林模型，并使用测试集来评估模型。我们将使用验证集来校准模型。
- en: '[PRE6]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let’s figure out how calibrated the model is. We print the Brier’s score and
    plot the calibration curve:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来了解一下模型的校准程度。我们打印Brier分数并绘制校准曲线：
- en: '[PRE7]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This gives the following output:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下输出：
- en: '[PRE8]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s plot the calibration curve:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制校准曲线：
- en: '[PRE9]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](img/B17259_10_13_New.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17259_10_13_New.jpg)'
- en: Figure 10.13 – A calibration curve of an uncalibrated random forest model
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13 – 未校准的随机森林模型的校准曲线
- en: '*Figure 10**.13* shows that the model is overconfident in the initial range
    of predictions (0 to ~0.4) and is then underconfident afterward.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10.13* 显示，模型在预测范围的初始阶段（0到约0.4）过于自信，随后则不够自信。'
- en: In the next section, we will look at some techniques to improve the calibration
    of the models.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨一些提高模型校准的技术。
- en: Model calibration techniques
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型校准技术
- en: 'There are several ways to calibrate a model. There are two broad categorizations
    of the calibration techniques based on the nature of the method used to adjust
    the predicted probabilities to better align with the true probabilities: parametric
    and non-parametric:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以校准模型。根据调整预测概率以更好地与真实概率对齐所使用的方法的性质，校准技术可以分为两大类：参数化和非参数化：
- en: '**Parametric methods**: These methods assume a specific functional form for
    the relationship between the predicted probabilities and the true probabilities.
    They have a set number of parameters that need to be estimated from the data.
    Once these parameters are estimated, the calibration function is fully specified.
    Examples include Platt scaling, which assumes a logistic function, and beta calibration,
    which assumes a beta distribution. We will also discuss temperature scaling and
    label smoothing.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参数化方法**：这些方法假设预测概率与真实概率之间的关系具有特定的函数形式。它们具有一组需要从数据中估计的参数。一旦这些参数被估计，校准函数就完全确定了。例如，Platt缩放法假设对数函数，beta校准假设beta分布。我们还将讨论温度缩放和标签平滑。'
- en: '**Non-parametric methods**: These methods do not assume a specific functional
    form for the calibration function. They are more flexible and can adapt to more
    complex relationships between the predicted and true probabilities. However, they
    often require more data to produce a reliable calibration. Examples include isotonic
    regression, which fits a piece-wise constant function, and spline calibration,
    which uses spline (piecewise-defined polynomial) functions to fit the predicted
    probabilities.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非参数化方法**：这些方法不假设校准函数具有特定的函数形式。它们更灵活，可以适应预测概率与真实概率之间更复杂的关系。然而，它们通常需要更多的数据来产生可靠的校准。例如，等距回归法拟合分段常数函数，样条校准法使用样条（分段定义的多项式）函数来拟合预测概率。'
- en: First, we will explore a theoretical, formula-based method for calibrating scores
    for models trained on sampled data, specifically in the context of imbalanced
    data. Next, we’ll examine popular methods such as Platt’s scaling and isotonic
    regression, which are commonly used with classical machine learning models. Finally,
    we’ll introduce supporting techniques such as temperature scaling and label smoothing,
    which are more prevalent among deep learning models.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将探讨一种基于理论、公式的方法，用于校准在采样数据上训练的模型分数，特别是在数据不平衡的背景下。接下来，我们将检查流行的方法，如Platt的缩放和等调回归，这些方法通常与经典机器学习模型一起使用。最后，我们将介绍支持技术，如温度缩放和标签平滑，这些技术在深度学习模型中更为常见。
- en: The calibration of model scores to account for sampling
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对模型分数进行校准以考虑采样
- en: If we used oversampling or undersampling to balance a dataset, we can derive
    a theoretical calibration formula. As we saw in [*Chapter 2*](B17259_02.xhtml#_idTextAnchor042),
    *Oversampling Methods*, [*Chapter 3*](B17259_03.xhtml#_idTextAnchor079), *Undersampling
    Methods* (both based on sampling), and [*Chapter 7*](B17259_07.xhtml#_idTextAnchor205),
    *Data-Level Deep Learning Methods*, we can apply some (over/under) sampling techniques
    or data augmentation techniques to bump up the relative number of samples of the
    minority classes(s) in order to account for a data imbalance. As a result, we
    change the distribution of training data. Although downsampling enhances the model’s
    ability to distinguish between classes, it also leads to an overestimation of
    the predicted probabilities. Because of this, the model scores during inference
    (real-world prediction) time are still in the downsampled space, and we should
    bring the scores back to the real distribution.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用过采样或欠采样来平衡数据集，我们可以推导出一个理论校准公式。正如我们在[*第2章*](B17259_02.xhtml#_idTextAnchor042)、“过采样方法”，[*第3章*](B17259_03.xhtml#_idTextAnchor079)、“欠采样方法”（两者均基于采样），以及[*第7章*](B17259_07.xhtml#_idTextAnchor205)，“数据级深度学习方法”中看到的，我们可以应用一些（过/欠）采样技术或数据增强技术，以提高少数类（s）样本的相对数量，以解决数据不平衡问题。因此，我们改变了训练数据的分布。尽管下采样增强了模型区分类别的能力，但它也导致了预测概率的高估。因此，在推理（现实世界预测）时间内的模型分数仍然处于下采样空间中，我们应该将这些分数带回真实分布。
- en: Typically, the goal of downsampling is to balance the dataset in terms of the
    number of instances of positive and negative classes.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，下采样的目标是平衡数据集中正类和负类实例的数量。
- en: As an example, if there are 100 positive class instances and 200 negative class
    instances after downsampling, the ratio is w = 100/200 = 0.5.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果经过下采样后，有100个正类实例和200个负类实例，那么比例w = 100/200 = 0.5。
- en: 'Assuming the number of negative class examples is more than the number of positive
    class examples, we define w as the ratio:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 假设负类样本的数量多于正类样本的数量，我们定义w为该比例：
- en: w =  Number of positive class instances in downsampled dataset    ________________________________________    Number
    of negative class instances in downsampled dataset
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: w =  下采样数据集中正类实例的数量    ________________________________________    下采样数据集中负类实例的数量
- en: Now, let’s assume p is the probability of selecting a positive class example
    from the original dataset (without any kind of downsampling used).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设p是原始数据集中选择正类样本的概率（没有使用任何下采样）。
- en: 'If p is the probability of selecting a positive class in the original dataset,
    then the probability p d of selecting a positive class from the downsampled dataset
    can be computed using the following formula [8]:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果p是原始数据集中选择正类的概率，那么从下采样数据集中选择正类的概率p d可以使用以下公式[8]计算：
- en: p d =  p _ p+ w (1 − p)
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: p d =  p _ p+ w (1 − p)
- en: Note that if w=1, that is, when no downsampling is done, p d = p. You can refer
    to the paper by Moscatelli et al. [9] for a proof of this relationship between
    the original and downsampled dataset probabilities.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果w=1，即没有进行下采样时，p d = p。您可以参考Moscatelli等人[9]的论文，以证明原始和下采样数据集概率之间的关系。
- en: Explaining the denominator
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解释分母
- en: 'The following are the various terms in the denominator of the previous formula:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为前一个公式分母中的各种术语：
- en: p is the probability of selecting a positive class instance in the original
    dataset
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: p是原始数据集中选择正类实例的概率
- en: (1 − p) is the probability of selecting a negative class instance in the original
    dataset
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1 − p)是原始数据集中选择负类实例的概率
- en: w (1 − p) is the probability of selecting a negative class instance when downsampling
    is used
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: w(1 - p) 是使用下采样时选择负类实例的概率
- en: The summation p+ w (1 − p) is the total sum of probabilities for both the positive
    and downsampled negative classes in the dataset after downsampling the negative
    class by a factor of w
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 求和 p + w(1 - p) 是在负类以w倍数下采样后，数据集中正类和下采样负类的概率总和
- en: 'Now that we understand the previous formula, we can flip it to find out the
    probability p of selecting a positive class in the original dataset [10]:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经理解了之前的公式，我们可以将其反转来找出原始数据集中选择正类的概率 p [10]：
- en: p =  p d _ p d + 1 − p d _ w
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: p = p_d / (p_d + 1 - p_d * w)
- en: 'where:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: w is the ratio of positive class to negative class (called the negative downsampling
    ratio)
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: w 是正类与负类的比例（称为负类下采样率）
- en: p d is the probability of selecting a positive class from the downsampled dataset
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: p_d 是从下采样数据集中选择正类的概率
- en: 'Let’s understand this with some numbers:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一些数字来理解这一点：
- en: We have a total of 100,000 examples with 10,000 from the positive class and
    90,000 from the negative class.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们总共有100,000个示例，其中10,000个来自正类，90,000个来自负类。
- en: Let’s say we use a downsampling rate w = 0.5, which means that after downsampling,
    we have 10,000 positives and 20,000 negatives. This also implies that during downsampling,
    for every positive class example, we selected only two negative class examples.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设我们使用下采样率 w = 0.5，这意味着下采样后，我们有10,000个正类和20,000个负类。这也意味着在下采样过程中，对于每个正类示例，我们只选择了两个负类示例。
- en: Let’s assume our prediction score from a model when trained on the downsampled
    dataset, p d, is 0.9.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设我们在对下采样数据集进行训练时的模型预测分数为 p_d，为0.9。
- en: Let’s compute the prediction score in the original dataset. From the previous
    defined formula, p =  p d _ p d + 1 − p d _ w  =  0.9 _ 0.9 + 1 − 0.9 _ 0.5  =
     0.9 _ 0.9 + 0.2 = 0.82.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让我们计算原始数据集中的预测分数。根据之前定义的公式，p = p_d / (p_d + 1 - p_d * w) = 0.9 / (0.9 + 0.2)
    = 0.9 / 1.1 = 0.82。
- en: So, a model prediction score of 0.9 in downsampled example changed to 0.82 in
    the original dataset. Notice how the probability got lowered.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，下采样示例中的模型预测分数0.9在原始数据集中变为0.82。注意概率是如何降低的。
- en: 'A more generic and simpler formula [11] is the relationship between odds before
    and after sampling:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更通用且简单的公式 [11] 是采样前后概率之比的关系：
- en: odds _ after = odds _ before *  proportion _ of _ 1 _ before _ sampling * (1
    − proportion _ of _ 1 _ after _ sampling)     _____________________________________________________     (1
    − proportion _ of _ 1 _ before _ sampling) * (proportion _ of _ 1 _ after _ sampling)
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 欠采样后的概率 = 欠采样前的概率 * 欠采样前1的比例 * (1 - 欠采样后1的比例) / (1 - 欠采样前1的比例) * 欠采样后1的比例
- en: 'where *odds* are a way to express the probability of an event as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *odds* 是以以下方式表达事件概率的一种方式：
- en: odds =  probability ___________ 1 − probability
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 概率 = 1 - 概率
- en: '*Figure 10**.14* and *Figure 10**.15* show the model calibration plots before
    and after applying the previous calibration formula, respectively, when using
    random undersampling on the `thyroid_sick` UCI dataset available from the `imblearn.datasets`
    package. You can find the complete notebook on GitHub.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10.14* 和 *图10.15* 分别显示了在应用之前的校准公式之前和之后，使用随机欠采样对来自 `imblearn.datasets` 包的
    `thyroid_sick` UCI 数据集进行校准时模型校准图。您可以在GitHub上找到完整的笔记本。'
- en: '![](img/B17259_10_14.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_14.jpg)'
- en: Figure 10.14 – A model calibration plot before calibration when using undersampling
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14 – 使用欠采样进行校准前的模型校准图
- en: '![](img/B17259_10_15.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_15.jpg)'
- en: Figure 10.15 – A model calibration plots after calibration when using undersampling
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.15 – 使用欠采样进行校准后的模型校准图
- en: 🚀 Model calibration in production at Meta
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 🚀 Meta在生产中的模型校准
- en: '**🎯** **Problem** **being solved:**'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**🎯** **解决的问题：**'
- en: Meta aimed to accurately predict **Click-Through Rates** (**CTR**) for ads to
    optimize online bidding and auctions in Meta’s advertising system [10]. Accurate
    click prediction is crucial for optimizing online bidding and auctions.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Meta旨在准确预测广告的点击通过率（**CTR**）以优化Meta广告系统中的在线竞价和拍卖 [10]。准确的点击预测对于优化在线竞价和拍卖至关重要。
- en: '**⚖️** **Data** **imbalance issue:**'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**⚖️** **数据不平衡问题：**'
- en: Meta dealt with massive volumes of data, which inherently contained imbalances.
    A full day of Facebook ad impression data contained a huge number of instances.
    Meta used negative downsampling to speed up training and improve model performance.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Meta处理了大量的数据，这些数据本身存在不平衡。一天内Facebook广告曝光数据包含大量的实例。Meta使用负下采样来加速训练并提高模型性能。
- en: '**🎨** **Model** **calibration strategy:**'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**🎨** **模型** **校准策略：**'
- en: Since Meta used downsampling, they used the formula from the previous section,
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Meta使用了下采样，他们使用了上一节中的公式，
- en: p =  p d _ p d + 1 − p d _ w  , to re-calibrate the model prediction score.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: p =  p d _ p d + 1 − p d _ w  ，以重新校准模型预测分数。
- en: '**📊** **Additional** **important points:**'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**📊** **额外** **重要点：**'
- en: They explored the impact of data freshness and online learning on prediction
    accuracy. The efficiency of an ads auction depended on the accuracy and calibration
    of click prediction. They also used normalized cross-entropy loss and calibration
    as their major evaluation metrics.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 他们研究了数据新鲜度和在线学习对预测准确性的影响。广告拍卖的效率取决于点击预测的准确性和校准。他们还使用了归一化交叉熵损失和校准作为他们主要的评估指标。
- en: Platt’s scaling
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Platt缩放
- en: 'With this technique, we try to map the classifier’s probabilities to the perfect
    calibration line. More precisely, we just fit a logistic regression model, with
    the input being the original model’s probability scores and the labels being the
    actual labels. The `CalibratedClassifierCV` API in `sklearn` already facilitates
    the implementation of this technique:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种技术，我们试图将分类器的概率映射到完美的校准线上。更精确地说，我们只是拟合一个逻辑回归模型，输入是原始模型的概率分数，标签是实际标签。`sklearn`中的`CalibratedClassifierCV`
    API已经简化了这种技术的实现：
- en: '[PRE10]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here is the Brier score output:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是Brier分数的输出结果：
- en: '[PRE11]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The Brier score for Platt’s scaled model is smaller than that of the uncalibrated
    model, which was 0.0447, meaning that the Platt’s scaled model is calibrated better.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Platt缩放模型的Brier分数小于未校准模型的Brier分数，后者为0.0447，这意味着Platt缩放模型的校准更好。
- en: Isotonic regression
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 等调回归
- en: Isotonic regression is particularly useful when we expect a monotonic relationship
    between the input variables and the output. In this context, a monotonic function
    is one that is either entirely non-decreasing or entirely non-increasing. The
    monotonicity here refers to the relationship between the model’s raw output and
    the true probabilities, not the arrangement of the data points.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们期望输入变量和输出之间存在单调关系时，等调回归特别有用。在这种情况下，单调函数是指要么完全非递减，要么完全非递增的函数。这里的单调性指的是模型的原始输出和真实概率之间的关系，而不是数据点的排列。
- en: If the model’s output does not follow this expected monotonic behavior, isotonic
    regression can be applied to enforce it. Isotonic regression can be used in cases
    such as credit scoring or medical diagnosis, where a higher score should consistently
    indicate a higher likelihood of a particular outcome.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型的输出不遵循这种预期的单调行为，可以使用等调回归来强制执行。等调回归可用于信用评分或医疗诊断等场景，在这些场景中，更高的分数应始终表示更高的特定结果的可能性。
- en: '[PRE12]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is the output:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出结果：
- en: '[PRE13]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This Brier score value is a further improvement over Platt’s scaling method.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这个Brier分数值是在Platt缩放方法之上的进一步改进。
- en: 'Let’s plot the calibration curves for both the techniques:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制这两种技术的校准曲线：
- en: '[PRE14]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](img/B17259_10_16.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_16.jpg)'
- en: Figure 10.16 – Calibration curves for a random forest model
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.16 – 随机森林模型的校准曲线
- en: As *Figure 10**.16* shows, the isotonic regression is the closest to the perfectly
    calibrated curve; hence, it performed the best for our model and data. Platt’s
    scaling did pretty well at calibrating the model, too.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图10.16*所示，等调回归最接近完美的校准曲线；因此，它在我们的模型和数据上表现最佳。Platt缩放在校准模型方面也做得相当不错。
- en: Choosing between Platt’s scaling and Isotonic regression
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Platt缩放和等调回归之间进行选择
- en: Platt’s scaling is considered more apt for problems where the model predictions
    follow the sigmoid curve. This makes sense because logistic regression (which
    is used by Platt’s scaling) uses a sigmoid to fit the data points. Isotonic regression
    has a much broader coverage of distortions that it can cover for the predicted
    probabilities. However, some research studies [2] show that isotonic regression
    is more prone to overfitting the predicted probabilities. Hence, its performance
    can be worse than Platt’s scaling when we only have a limited dataset since it
    doesn’t generalize well with the limited dataset.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Platt缩放被认为更适合模型预测遵循sigmoid曲线的问题。这是有道理的，因为逻辑回归（Platt缩放使用的）使用sigmoid来拟合数据点。等距回归可以覆盖更广泛的预测概率的扭曲。然而，一些研究[2]表明，等距回归更容易过度拟合预测概率。因此，当只有有限的数据集时，它的性能可能比Platt缩放更差，因为它与有限数据集的泛化能力不佳。
- en: A general rule to follow
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循的一般规则
- en: When the dataset at hand is very small or limited, choose Platt’s scaling. However,
    when data is sufficient enough not to have an overfitted model, isotonic regression
    usually does better than Platt’s scaling.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 当手头的数据集非常小或有限时，选择Platt缩放。然而，当数据足够多，不会导致过度拟合模型时，等距回归通常比Platt缩放表现更好。
- en: For the calibration of a multi-class classifier, we can use the **one-vs-rest**
    approach with individual calibration plots per class. We can apply techniques
    such as Platt’s scaling or Isotonic regression for enhanced predictability, just
    like binary classification.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多类分类器的校准，我们可以使用**一对余**方法，并为每个类别使用单独的校准图。我们可以应用像Platt缩放或等距回归这样的技术来提高可预测性，就像二元分类一样。
- en: Temperature scaling
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 温度缩放
- en: Temperature scaling is a post-processing technique used to improve the calibration
    of neural networks. It works by scaling the logits (the output of the final layer
    of the network before applying the softmax function) using a temperature parameter.
    This has the effect of sharpening or softening the probabilities assigned to each
    class depending on the temperature value. By adjusting the temperature parameter,
    it is possible to achieve better calibration of the model’s confidence estimates,
    which can be useful in applications such as classification or ranking.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 温度缩放是一种后处理技术，用于提高神经网络的校准。它通过使用温度参数缩放logits（在应用softmax函数之前网络的最终层输出）来实现。这会根据温度值调整分配给每个类别的概率，使其变尖锐或变柔和。通过调整温度参数，可以实现对模型置信度估计的更好校准，这在分类或排名等应用中可能很有用。
- en: Temperature scaling can be considered a multi-class extension of Platt’s scaling
    with only one hyper-parameter of temperature *T* > 0 for all classes.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 温度缩放可以被视为Platt缩放的多类扩展，它只有一个温度超参数 *T* > 0，适用于所有类别。
- en: Label smoothing
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标签平滑
- en: Label smoothing [12] is a regularization technique that’s known to improve model
    calibration. It modifies the training data that is used to train the model and
    is usually handled as a part of the model training. It is not a post-processing
    technique like temperature scaling and previous techniques.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 标签平滑[12]是一种已知的可以改善模型校准的正则化技术。它修改用于训练模型的训练数据，通常作为模型训练的一部分来处理。它不像温度缩放和之前的技术那样是一种后处理技术。
- en: When neural networks are trained, they often develop excessive confidence in
    their predictions, which can hinder their ability to generalize and perform well
    on new, unseen data. Therefore, it is beneficial to introduce a form of **regularization**
    that reduces the network’s level of certainty and improves its performance on
    new data.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 当神经网络进行训练时，它们往往对自己的预测过于自信，这可能会阻碍它们泛化能力和在新、未见过的数据上的表现。因此，引入一种**正则化**形式以降低网络的不确定性水平并提高其在新数据上的性能是有益的。
- en: Let’s say we have a binary classification problem where the true labels can
    be either 0 or 1\. Without label smoothing, the training labels would be one-hot
    encoded, meaning the true label would be 1 for positive examples and 0 for negative
    examples.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个二元分类问题，其中真实标签可以是0或1。在没有标签平滑的情况下，训练标签将被进行one-hot编码，这意味着对于正例，真实标签为1，对于负例，真实标签为0。
- en: With label smoothing, we add a small amount of **noise** to the true labels.
    For example, we can set a smoothing factor of 0.1.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 使用标签平滑，我们在真实标签上添加一小部分**噪声**。例如，我们可以设置一个平滑因子为0.1。
- en: 'Here is an example of the original and smoothed labels for a positive example
    in binary classification:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个二元分类中正例原始标签和平滑标签的例子：
- en: '[PRE15]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: By adding this noise to the labels, the model is encouraged to be less confident
    in its predictions and to be more robust to small changes in the input data. This
    can lead to improved performance on unseen data.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向标签添加这种噪声，模型被鼓励对其预测不那么自信，并对输入数据的小变化更加鲁棒。这可能导致在未见过的数据上性能提升。
- en: In large datasets, mislabeled data can be a concern. Neural networks should
    be designed to approach the correct answer cautiously to mitigate the impact of
    incorrect labels. Label smoothing helps in this regard by slightly adjusting the
    target labels, making the model less confident about its predictions. This can
    prevent the model from overfitting to noisy or incorrect labels.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型数据集中，错误标记的数据可能是一个问题。神经网络应该被设计成谨慎地接近正确答案，以减轻错误标签的影响。标签平滑在这方面有所帮助，通过稍微调整目标标签，使模型对其预测不那么自信。这可以防止模型过度拟合噪声或错误标签。
- en: According to the paper by Müller [13], label smoothing can improve model calibration
    by automatically adjusting the network’s output probabilities. This eliminates
    the need for manual temperature scaling.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Müller的论文[13]，标签平滑可以通过自动调整网络的输出概率来提高模型校准。这消除了手动温度缩放的需要。
- en: Label smoothing can help improve accuracy in various domains, such as image
    classification, text, and speech recognition problems. Most of the modern machine
    learning frameworks, including TensorFlow, PyTorch, and Transformers (from Hugging
    Face), provide built-in implementations for label smoothing in some form in their
    APIs.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 标签平滑可以帮助提高各个领域的准确性，例如图像分类、文本和语音识别问题。大多数现代机器学习框架，包括TensorFlow、PyTorch和来自Hugging
    Face的Transformers，在其API中以某种形式提供了标签平滑的内置实现。
- en: 'In PyTorch, it’s implemented in the cross-entropy loss function:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch中，它在交叉熵损失函数中实现：
- en: '[PRE16]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here we can specify the amount of smoothing (as a floating-point value between
    0 and 1) when computing the loss and where a value of 0.0 (default) means no smoothing.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算损失时，我们可以指定平滑量（介于0和1之间的浮点值），其中默认值为0.0（0.0表示无平滑）。
- en: In general, it can be helpful to add label smoothing to the loss functions if
    you are looking to add some regularization to your network.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，如果你想在网络中添加一些正则化，那么将标签平滑添加到损失函数中可能会有所帮助。
- en: Arguments against label smoothing
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标签平滑的反对意见
- en: There are some arguments against label smoothing. It’s just another hyperparameter
    to tune, and when there are few better regularization techniques such as weight
    decay and L1 regularization, it may be overkill to make your network more complex
    and implicitly modify the labels of your training data. Another point to consider
    is that since it adds random noise to the labels, it’s possible that the network
    might underfit in certain cases.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标签平滑有一些反对意见。它只是另一个需要调整的超参数，当有更好的正则化技术，如权重衰减和L1正则化时，可能过度复杂化你的网络并隐式修改训练数据的标签。另一个需要考虑的问题是，由于它向标签添加随机噪声，网络可能在某些情况下可能欠拟合。
- en: There are some further improved variants of label smoothing, such as **label-aware
    smoothing**, as mentioned in Zhong et al.’s *Improving Calibration for Long-Tailed*
    *Recognition* [14].
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 标签平滑还有一些改进的变体，例如文中提到的**标签感知平滑**，见Zhong等人关于*改进长尾识别校准*的[14]。
- en: 'The following table shows a comparison of the four techniques we just discussed
    for model calibration:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了我们对模型校准所讨论的四种技术的比较：
- en: '| **Theme** | **Temperature scaling** | **Label smoothing** | **Platt’s scaling**
    | **Isotonic Regression** |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| **主题** | **温度缩放** | **标签平滑** | **Platt的缩放** | **等调回归** |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Change in label values | No change in label values of training data | Change
    in label values of training data | No change in the label values of the training
    data | No change in the label values of the training data |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 标签值的变化 | 训练数据的标签值没有变化 | 训练数据的标签值发生变化 | 训练数据的标签值没有变化 | 训练数据的标签值没有变化 |'
- en: '| Timing | After training has been completed, the value of the hyperparameter
    T is computed on a validation dataset | Done during the actual training of the
    model | Applied after training | Applied after training |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 时间 | 训练完成后，在验证数据集上计算超参数T的值 | 在模型实际训练期间完成 | 训练后应用 | 训练后应用 |'
- en: '| Prediction value adjustment | Prediction values from the model are manually
    adjusted | Predicted values are changed by applying label smoothing | Prediction
    values from the model are manually adjusted | Prediction values from the model
    are manually adjusted |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 预测值调整 | 模型的预测值被手动调整 | 通过应用标签平滑改变预测值 | 模型的预测值被手动调整 | 模型的预测值被手动调整 |'
- en: '| Role | Acts as a regularizer | Acts as a regularizer | Acts as a model calibrator
    or prediction score transformer | Acts as a model calibrator or prediction score
    transformer |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 角色 | 作为正则化器 | 作为正则化器 | 作为模型校准器或预测分数转换器 | 作为模型校准器或预测分数转换器 |'
- en: Table 10.2 – Comparing temperature scaling, label smoothing, Platt’s scaling,
    and isotonic regression
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.2 – 比较温度缩放、标签平滑、Platt缩放和等调回归
- en: There are other model calibration techniques that we didn’t get a chance to
    explore. For instance, **spline calibration** [15][16] is a non-parametric method
    that employs a spline function, a piece-wise polynomial function that is smooth
    and continuous. This technique is somewhat similar to isotonic regression in its
    non-parametric nature.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他模型校准技术我们没有机会探索。例如，**样条校准** [15][16] 是一种非参数方法，它使用样条函数，这是一种平滑且连续的分段多项式函数。这种技术在非参数性质上与等调回归有些相似。
- en: On the other hand, **beta calibration** [17] is a parametric method that fits
    a beta distribution to the model’s predictions. This technique is conceptually
    similar to Platt’s scaling, as both are parametric methods. Beta calibration is
    particularly useful for modeling probabilities, such as click-through rates or
    customer conversion rates.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**beta校准** [17] 是一种参数方法，它将beta分布拟合到模型的预测中。这种技术与Platt缩放在概念上相似，因为两者都是参数方法。Beta校准特别适用于建模概率，例如点击率或客户转化率。
- en: '**Focal loss**, discussed in [*Chapter 8*](B17259_08.xhtml#_idTextAnchor235),
    *Algorithm-Level Deep Learning Techniques*, is another method commonly used in
    deep learning models. As demonstrated in the paper by Mukhoti et al. [3], focal
    loss produces well-calibrated models and is often combined with temperature scaling
    for optimal results. Given that neural networks with multiple layers tend to be
    overconfident in their predictions, focal loss serves as a regularizing effect.
    It forces the model to focus on harder examples, thereby reducing overconfidence
    and improving calibration [3].'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '**焦点损失**，在第[*第8章*](B17259_08.xhtml#_idTextAnchor235)中讨论，*算法级深度学习技术*，是深度学习模型中常用的一种方法。正如Mukhoti等人
    [3] 的论文所示，焦点损失产生校准良好的模型，并且通常与温度缩放结合以获得最佳结果。鉴于多层神经网络往往对其预测过于自信，焦点损失起到正则化作用。它迫使模型关注更难的问题示例，从而减少过度自信并提高校准
    [3]。'
- en: 🚀 Model calibration with focal loss at Amazon
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 🚀 在亚马逊使用焦点损失进行模型校准
- en: '**🎯** **Problem** **being solved:**'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '**🎯** **问题解决：**'
- en: When Amazon deployed conversational bots [18] to handle customer requests, the
    calibration of the underlying ML models proved to be of importance. In one instance,
    Amazon’s chatbot was tasked with automatically classifying return reason codes.
    These return reason codes exhibited class imbalance. When a customer wanted to
    return an item, determining the appropriate reason became pivotal for efficient
    return processing. For instance, if a customer expressed dissatisfaction with
    an item’s size or color, it was classified under “Customer Preference.” In such
    cases, Amazon understood that offering a replacement wasn’t the optimal solution;
    rather, a refund was more appropriate.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 当亚马逊部署会话机器人 [18] 来处理客户请求时，底层机器学习模型的校准证明非常重要。在一次实例中，亚马逊的聊天机器人被要求自动分类退货原因代码。这些退货原因代码表现出类别不平衡。当客户想要退货时，确定适当的理由对于高效的退货处理变得至关重要。例如，如果客户对商品的大小或颜色表示不满，它会被归类为“客户偏好”。在这种情况下，亚马逊理解提供替代品不是最佳解决方案；相反，退款更为合适。
- en: '**🎨** **Model** **calibration strategy:**'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '**🎨** **模型校准策略：**'
- en: Through rigorous testing, they uncovered the robustness of focal loss in addressing
    model miscalibration in such real-world tasks. Focal loss was used as a calibration
    method. Moreover, it wasn’t merely about adopting focal loss; the value of *γ*
    within the loss function played a crucial role in enhancing model calibration.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 通过严格的测试，他们揭示了在处理此类现实任务中的模型误校准问题时，焦点损失的鲁棒性。焦点损失被用作校准方法。此外，这不仅仅关于采用焦点损失；损失函数中*γ*的值在增强模型校准方面发挥了关键作用。
- en: '**📊****Additional points:**'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '**📊** **其他要点：**'
- en: Focal loss outperformed traditional cross-entropy loss in achieving better-calibrated
    models. The technique was tested in an internal A/B experiment at Amazon. The
    results showed improvements in automation rate and customer experience, meaning
    the bot could resolve more queries without human intervention and receive more
    positive responses from customers.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: Focal loss在实现更好校准的模型方面优于传统的交叉熵损失。这项技术已在亚马逊内部进行的A/B测试中得到验证。结果显示，自动化率和客户体验得到了提升，这意味着机器人可以在没有人工干预的情况下解决更多查询，并从客户那里获得更多积极的反馈。
- en: Next, let’s see in what ways calibration might impact the performance of a model.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看校准可能会以何种方式影响模型的性能。
- en: The impact of calibration on a model’s performance
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 校准对模型性能的影响
- en: Accuracy, log-loss, and Brier scores usually improve because of calibration.
    However, since the model calibration still involves approximately fitting a model
    to the calibration curve plotted on the held-out calibration dataset, it may sometimes
    worsen the accuracy or other performance metrics by small amounts. Nevertheless,
    the benefits of having calibrated probabilities in terms of giving us actual interpretable
    probability values that represent likelihood far outweigh the slight performance
    impact.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率、对数损失和Brier分数通常会因为校准而提高。然而，由于模型校准仍然涉及将模型拟合到在保留的校准数据集上绘制的校准曲线，它有时可能会略微降低准确率或其他性能指标。尽管如此，拥有校准概率的好处——即给我们提供实际可解释的概率值，这些值代表可能性——远远超过了轻微的性能影响。
- en: As discussed in [*Chapter 1*](B17259_01.xhtml#_idTextAnchor015), *Introduction
    to Data Imbalance in Machine Learning*, ROC-AUC is a rank-based metric, meaning
    it evaluates the model’s ability to distinguish between classes based on the ranking
    of predicted scores rather than their absolute values. ROC-AUC doesn’t make any
    claim about accurate probability estimates. Strictly monotonic calibration functions,
    which continuously increase or decrease without any flat regions, preserve this
    ranking; they adjust the scale of the probabilities without altering their relative
    order. For instance, if one score is higher than another before calibration, it
    remains higher afterward. Because ROC-AUC is concerned with the ranking of predictions
    rather than the actual probability values, it remains unaffected by such monotonic
    calibration functions.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*第一章*](B17259_01.xhtml#_idTextAnchor015)《机器学习中数据不平衡的介绍》中所述，ROC-AUC是一个基于排名的指标，这意味着它评估模型区分不同类别的能力是基于预测分数的排名，而不是它们的绝对值。ROC-AUC对准确的概率估计不做任何声明。严格单调的校准函数，即连续增加或减少而没有任何平坦区域，保留这种排名；它们调整概率的尺度，而不改变它们的相对顺序。例如，如果一个分数在校准之前比另一个分数高，那么它在之后仍然更高。因为ROC-AUC关注的是预测的排名而不是实际的概率值，所以它不受这种单调校准函数的影响。
- en: However, in rare cases, closely ranked predictions might become tied due to
    calibration, especially if the calibration function is loosely monotonic and has
    flat stretches. This could slightly affect the ROC-AUC.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在罕见的情况下，由于校准，紧密排序的预测可能会因为校准而变得相同，特别是如果校准函数是松散单调的并且有平坦部分。这可能会略微影响ROC-AUC。
- en: Summary
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we went through the basic concepts of model calibration, why
    we should care about it, how to measure whether a model is calibrated, how data
    imbalance affects the model calibration, and, finally, how to calibrate an uncalibrated
    model. Some of the calibration techniques we talked about include Platt’s scaling,
    isotonic regression, temperature scaling, and label smoothing.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了模型校准的基本概念、为什么我们应该关注它、如何衡量模型是否校准、数据不平衡如何影响模型校准，以及最后如何校准未校准的模型。我们讨论的一些校准技术包括Platt缩放、等调回归、温度缩放和标签平滑。
- en: With this, we come to the end of this book. Thank you for dedicating your time
    to reading the book. We trust that it has broadened your knowledge of handling
    imbalanced datasets and their practical applications in machine learning. As we
    draw this book to a close, we’d like to offer some concluding advice on how to
    effectively utilize the techniques discussed.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们这本书就结束了。感谢您抽出时间阅读这本书。我们相信，它已经拓宽了您对处理不平衡数据集及其在机器学习中的实际应用的知识。随着我们这本书的结束，我们想提供一些关于如何有效利用所讨论技术的结论性建议。
- en: Like other machine learning techniques, the methods discussed in this book can
    be highly useful under the right conditions, but they also come with their own
    set of challenges. Recognizing when and where to apply these techniques is essential,
    as overly complex solutions can lead to less-than-optimal performance.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他机器学习技术一样，本书中讨论的方法在适当的条件下非常有用，但它们也带来了一组自己的挑战。认识到何时何地应用这些技术是至关重要的，因为过于复杂的解决方案可能导致性能不佳。
- en: Establishing a sound baseline solution is crucial. Implementing various methods,
    such as those in cost-sensitive learning and algorithm-level deep learning techniques,
    can offer insights into handling imbalanced datasets effectively. Each method
    has its pros and cons.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 建立一个可靠的基线解决方案至关重要。实施各种方法，如成本敏感学习中的方法以及算法级别的深度学习技术，可以提供有效处理不平衡数据集的见解。每种方法都有其优缺点。
- en: For specialized problems, the book provides targeted solutions. For small datasets,
    the oversampling methods can help manage computational resources. For large datasets,
    the chapter on undersampling methods offers suitable techniques.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特定问题，本书提供了针对性的解决方案。对于小数据集，过采样方法可以帮助管理计算资源。对于大数据集，关于欠采样方法的章节提供了合适的技巧。
- en: Occasionally, more modern approaches such as graph machine learning algorithms
    can be applied to the problem at hand. The model calibration and threshold tuning
    techniques are useful for decision-making based on model predictions.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，可以应用更现代的方法，如图机器学习算法来解决手头的问题。模型校准和阈值调整技术对于基于模型预测的决策非常有用。
- en: Sometimes, data imbalance may not be a problem at all, and we highly encourage
    you to establish the baseline performance with the imbalanced data without applying
    any of the techniques discussed in this book. A lot of the real-world data also
    tends to be tabular, where tree-based models such as XGBoost can be robust to
    certain kinds of data imbalance.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，数据不平衡可能根本不是问题，我们强烈建议你在不应用本书中讨论的任何技术的情况下，使用不平衡数据建立基线性能。许多现实世界的数据也倾向于是表格形式，其中基于树的模型如XGBoost可以对某些类型的数据不平衡具有鲁棒性。
- en: We encourage you to apply this knowledge, experiment with new approaches, and
    continue to expand your expertise as you progress in this field. The landscape
    of machine learning is constantly changing, and your skills will only increase
    in value as you keep up with its evolution. We hope that the knowledge you’ve
    gained will empower you to pick up any research paper that you feel interested
    in and be able to reproduce its results. We appreciate your commitment to reading
    this book, and we wish you success in all your future endeavors.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们鼓励你应用这些知识，尝试新的方法，并在你在这个领域进步的过程中继续扩展你的专业知识。机器学习的领域不断变化，随着你跟上其发展，你的技能将只会增加价值。我们希望你所获得的知识能够赋予你选择任何你感兴趣的研究论文并能够重现其结果的能力。我们感谢你阅读这本书的承诺，并祝愿你在未来的所有事业中取得成功。
- en: Questions
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Can a well-calibrated model have low accuracy? What about the reverse: can
    a model with high accuracy be poorly calibrated?'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个校准良好的模型是否可能具有较低的准确率？反之，一个具有高准确率的模型是否可能校准不良？
- en: Take a limited classification dataset with, say, only 100 data points. Train
    a decision tree model using this dataset and then assess its calibration.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以一个有限的分类数据集为例，比如只有100个数据点。使用这个数据集训练一个决策树模型，然后评估其校准情况。
- en: Calibrate the model using Platt’s scaling. Measure the Brier score after calibration.
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Platt的缩放方法校准模型。校准后测量Brier分数。
- en: Calibrate the model using isotonic regression. Measure the Brier score after
    calibration
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用等调回归校准模型。校准后测量Brier分数
- en: How do the Brier scores differ in (A) and (B)?
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在(A)和(B)中，Brier分数有何不同？
- en: Measure the AUC, accuracy, precision, recall, and F1 score of the model before
    and after calibration.
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在校准前后测量模型的AUC、准确率、精确率、召回率和F1分数。
- en: Take a balanced dataset, say with 10,000 points. Train a decision tree model
    using it. Then check how calibrated it is.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用一个平衡的数据集，比如有10,000个数据点。使用它来训练一个决策树模型。然后检查其校准情况。
- en: Calibrate the model using Platt’s scaling. Measure the Brier score after calibration.
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Platt的缩放方法校准模型。校准后测量Brier分数。
- en: Calibrate the model using isotonic regression. Measure the Brier score after
    calibration.
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用等调回归校准模型。校准后测量Brier分数。
- en: How do the Brier scores differ in (a) and (b)?
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在(a)和(b)中，Brier分数有何不同？
- en: Measure the AUC, accuracy, precision, recall, and F1 score of the model before
    and after calibration and compare their values.
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在校准前后测量模型的AUC、准确率、精确率、召回率和F1分数，并比较它们的值。
- en: 'Given a classification dataset, compare how calibrated the following models
    are by default without applying any calibration techniques by comparing their
    Brier scores:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于一个分类数据集，通过比较它们的Brier分数来比较以下模型默认情况下未经校准技术校准的校准程度：
- en: Logistic regression
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Decision tree
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树
- en: XGBoost
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: XGBoost
- en: Random forest
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机森林
- en: AdaBoost
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: AdaBoost
- en: Neural network
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络
- en: 'Take an imbalanced dataset and train three models with logistic regression,
    a random forest model, and an XGBoost model, respectively. Measure the calibration
    of these models using the calibration curve and Brier scores. Finally, apply these
    techniques to handle data imbalance and measure the calibration again:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对一个不平衡的数据集进行训练，分别使用逻辑回归、随机森林模型和XGBoost模型。使用校准曲线和Brier分数来衡量这些模型的校准情况。最后，应用这些技术来处理数据不平衡并再次测量校准：
- en: Undersampling
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下采样
- en: Oversampling
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过采样
- en: 'Cost-sensitive learning: increase the `class_weight` by doubling the previous
    value. Did the model get less calibrated because of doubling the `class_weight`?'
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 成本敏感学习：将`class_weight`增加一倍。由于将`class_weight`加倍，模型是否变得校准度更低？
- en: References
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger, “*On Calibration of Modern
    Neural Networks*.” arXiv, Aug. 03, 2017\. Accessed: Nov. 21, 2022, [http://arxiv.org/abs/1706.04599](http://arxiv.org/abs/1706.04599)'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: C. Guo, G. Pleiss, Y. Sun, 和 K. Q. Weinberger，"关于现代神经网络的校准"。arXiv，2017年8月3日。访问日期：2022年11月21日，[http://arxiv.org/abs/1706.04599](http://arxiv.org/abs/1706.04599)。
- en: 'A. Niculescu-Mizil and R. Caruana, “*Predicting good probabilities with supervised
    learning*,” in Proceedings of the 22nd International Conference on Machine Learning
    - ICML ‘05, Bonn, Germany, 2005, pp. 625–632\. doi: 10.1145/1102351.1102430.'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A. Niculescu-Mizil 和 R. Caruana，"使用监督学习预测良好的概率"，载于第22届国际机器学习会议 - ICML ‘05，德国波恩，2005年，第625-632页。doi:
    10.1145/1102351.1102430。'
- en: J. Mukhoti, V. Kulharia, A. Sanyal, S. Golodetz, P. H. S. Torr, and P. K. Dokania,
    “*Calibrating Deep Neural Networks using Focal Loss*”. Feb 2020, [https://doi.org/10.48550/arXiv.2002.09437](https://doi.org/10.48550/arXiv.2002.09437)
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: J. Mukhoti, V. Kulharia, A. Sanyal, S. Golodetz, P. H. S. Torr, 和 P. K. Dokania，"使用焦点损失校准深度神经网络"。2020年2月，[https://doi.org/10.48550/arXiv.2002.09437](https://doi.org/10.48550/arXiv.2002.09437)。
- en: 'B. C. Wallace and I. J. Dahabreh, “*Class Probability Estimates are Unreliable
    for Imbalanced Data (and How to Fix Them)*,” in 2012 IEEE 12th International Conference
    on Data Mining, Brussels, Belgium, Dec. 2012, pp. 695–704\. doi: 10.1109/ICDM.2012.115.'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B. C. Wallace 和 I. J. Dahabreh，"对于不平衡数据，类别概率估计是不可靠的（以及如何修复它们）"，载于2012年IEEE第12届数据挖掘国际会议，比利时布鲁塞尔，2012年12月，第695-704页。doi:
    10.1109/ICDM.2012.115。'
- en: 'M. Pakdaman Naeini, G. Cooper, and M. Hauskrecht, “*Obtaining Well Calibrated
    Probabilities Using Bayesian Binning*,” AAAI, vol. 29, no. 1, Feb. 2015, doi:
    10.1609/aaai.v29i1.9602.'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'M. Pakdaman Naeini, G. Cooper, 和 M. Hauskrecht，"使用贝叶斯分箱获得良好校准的概率"，AAAИ，第29卷，第1期，2015年2月，doi:
    10.1609/aaai.v29i1.9602。'
- en: 'H. Steck, “*Calibrated recommendations*,” in Proceedings of the 12th ACM Conference
    on Recommender Systems, Vancouver British Columbia Canada: ACM, Sep. 2018, pp.
    154–162\. doi: 10.1145/3240323.3240372.'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'H. Steck，"校准推荐"，载于第12届ACM推荐系统会议论文集，加拿大不列颠哥伦比亚省温哥华：ACM，2018年9月，第154-162页。doi:
    10.1145/3240323.3240372。'
- en: 'A. Caplin, D. Martin, and P. Marx, “*Calibrating for Class Weights by Modeling
    Machine Learning*.” arXiv, Jul. 31, 2022\. Accessed: Dec. 09, 2022\. [Online].
    Available at [http://arxiv.org/abs/2205.04613](http://arxiv.org/abs/2205.04613)'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A. Caplin, D. Martin, 和 P. Marx，"通过建模机器学习校准类别权重"。arXiv，2022年7月31日。访问日期：2022年12月9日。[在线]。可在[http://arxiv.org/abs/2205.04613](http://arxiv.org/abs/2205.04613)获取。
- en: 'A. D. Pozzolo, O. Caelen, R. A. Johnson, and G. Bontempi, “*Calibrating Probability
    with Undersampling for Unbalanced Classification*,” in 2015 IEEE Symposium Series
    on Computational Intelligence, Cape Town, South Africa, Dec. 2015, pp. 159–166\.
    doi: 10.1109/SSCI.2015.33, [https://dalpozz.github.io/static/pdf/SSCI_calib_final_noCC.pdf](https://dalpozz.github.io/static/pdf/SSCI_calib_final_noCC.pdf)'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A. D. Pozzolo, O. Caelen, R. A. Johnson, 和 G. Bontempi，"使用下采样校准不平衡分类的概率"，载于2015年IEEE计算智能系列研讨会，南非开普敦，2015年12月，第159-166页。doi:
    10.1109/SSCI.2015.33，[https://dalpozz.github.io/static/pdf/SSCI_calib_final_noCC.pdf](https://dalpozz.github.io/static/pdf/SSCI_calib_final_noCC.pdf)'
- en: 'M. Moscatelli, S. Narizzano, F. Parlapiano, and G. Viggiano, *Corporate default
    forecasting with machine learning*. IT: Banca d’Italia, 2019\. Accessed: Oct.
    14, 2023\. [Online]. Available at [https://doi.org/10.32057/0.TD.2019.1256](https://doi.org/10.32057/0.TD.2019.1256)'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: M. Moscatelli, S. Narizzano, F. Parlapiano 和 G. Viggiano，*使用机器学习进行公司违约预测*。IT：意大利银行，2019年。访问日期：2023年10月14日。[在线]。可在[https://doi.org/10.32057/0.TD.2019.1256](https://doi.org/10.32057/0.TD.2019.1256)获取。
- en: 'X. He et al., “*Practical Lessons from Predicting Clicks on Ads at Facebook*,”
    in Proceedings of the Eighth International Workshop on Data Mining for Online
    Advertising, New York NY USA, Aug. 2014, pp. 1–9\. doi: 10.1145/2648584.2648589.'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'X. He 等人，"从预测Facebook广告点击中汲取的实际经验"，载于第八届国际在线广告数据挖掘研讨会论文集，纽约 NY 美国，2014年8月，第1-9页。doi:
    10.1145/2648584.2648589。'
- en: G. King and L. Zeng, “*Logistic Regression in Rare Events* *Data*,” 2001.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: G. King 和 L. Zeng，"稀事件数据中的逻辑回归"，2001年。
- en: 'Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, “*Rethinking the
    Inception Architecture for Computer Vision*.” arXiv, Dec. 11, 2015\. Accessed:
    Dec. 17, 2022\. [Online]. Available at [http://arxiv.org/abs/1512.00567](http://arxiv.org/abs/1512.00567)'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens 和 Z. Wojna，"重新思考计算机视觉中的Inception架构。"
    arXiv，2015年12月11日。访问日期：2022年12月17日。[在线]。可在[http://arxiv.org/abs/1512.00567](http://arxiv.org/abs/1512.00567)获取。
- en: 'R. Müller, S. Kornblith, and G. Hinton, “*When Does Label Smoothing Help?*”
    arXiv, Jun. 10, 2020\. Accessed: Dec. 11, 2022\. [Online]. Available at [http://arxiv.org/abs/1906.02629](http://arxiv.org/abs/1906.02629)'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: R. Müller, S. Kornblith 和 G. Hinton，"何时标签平滑有助于？" arXiv，2020年6月10日。访问日期：2022年12月11日。[在线]。可在[http://arxiv.org/abs/1906.02629](http://arxiv.org/abs/1906.02629)获取。
- en: Zhong et al., Improving Calibration for Long-Tailed Recognition. CVPR 2021\.
    [https://arxiv.org/abs/2104.00466](https://arxiv.org/abs/2104.00466)
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zhong 等人，改进长尾识别的校准。CVPR 2021。[https://arxiv.org/abs/2104.00466](https://arxiv.org/abs/2104.00466)
- en: 'B. Lucena, “*Spline-Based Probability Calibration*.” arXiv, Sep. 20, 2018\.
    Accessed: Jul. 22, 2023\. [Online]. Available at [http://arxiv.org/abs/1809.07751](http://arxiv.org/abs/1809.07751)'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: B. Lucena，"基于样条的概率校准。" arXiv，2018年9月20日。访问日期：2023年7月22日。[在线]。可在[http://arxiv.org/abs/1809.07751](http://arxiv.org/abs/1809.07751)获取。
- en: 'K. Gupta, A. Rahimi, T. Ajanthan, T. Mensink, C. Sminchisescu, and R. Hartley,
    “*Calibration of Neural Networks using Splines*.” arXiv, Dec. 29, 2021\. Accessed:
    Jul. 22, 2023\. [Online]. Available at [http://arxiv.org/abs/2006.12800](http://arxiv.org/abs/2006.12800)'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: K. Gupta, A. Rahimi, T. Ajanthan, T. Mensink, C. Sminchisescu 和 R. Hartley，"使用样条进行神经网络校准。"
    arXiv，2021年12月29日。访问日期：2023年7月22日。[在线]。可在[http://arxiv.org/abs/2006.12800](http://arxiv.org/abs/2006.12800)获取。
- en: 'M. Kull and P. Flach, “*Beta calibration: a well-founded and easily implemented
    improvement on logistic calibration for binary classiﬁers*,” in Proceedings of
    the twentieth International Conference on Artificial Intelligence and Statistics
    (pp. 623–631).'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: M. Kull 和 P. Flach，"Beta校准：对二元分类器的逻辑校准的合理且易于实现的改进"，载于第二十届国际人工智能与统计会议论文集（第623-631页）。
- en: 'C. Wang, J. Balazs, G. Szarvas, P. Ernst, L. Poddar, and P. Danchenko, “Calibrating
    Imbalanced Classifiers with Focal Loss: An Empirical Study,” in Proceedings of
    the 2022 Conference on Empirical Methods in Natural Language Processing: Industry
    Track, Abu Dhabi, UAE: Association for Computational Linguistics, 2022, pp. 145–153\.
    doi: 10.18653/v1/2022.emnlp-industry.14.'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C. Wang, J. Balazs, G. Szarvas, P. Ernst, L. Poddar 和 P. Danchenko，"使用焦点损失校准不平衡分类器：一项实证研究"，载于2022年自然语言处理实证方法会议：工业轨迹论文集，阿布扎比，阿联酋：计算语言学协会，2022年，第145-153页。doi:
    10.18653/v1/2022.emnlp-industry.14。'
- en: Appendix
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录
- en: Machine Learning Pipeline in Production
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习流水线在生产中的应用
- en: In this appendix, we will look at when and at which step we incorporate the
    data imbalance-handling techniques within a production machine learning pipeline.
    This mainly applies to supervised classification problems.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在本附录中，我们将探讨在生产的机器学习流水线中何时以及在哪一步引入数据不平衡处理技术。这主要适用于监督分类问题。
- en: Machine learning training pipeline
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习训练流水线
- en: A machine learning pipeline is the end-to-end process of training one or more
    machine learning models and then deploying them to a live environment. It may
    involve stages such as data collection, model training, validation, deployment,
    monitoring, and iterative improvement, with a focus on scalability, efficiency,
    and robustness.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习流水线是指训练一个或多个机器学习模型并将其部署到实际环境中的端到端过程。它可能包括数据收集、模型训练、验证、部署、监控和迭代改进等阶段，重点关注可扩展性、效率和鲁棒性。
- en: Various steps during the offline training are shown in *Figure A.1*. Please
    note that some of the steps may not be necessary depending on the problem at hand.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 离线训练过程中的各种步骤在*图A.1*中展示。请注意，根据具体问题，某些步骤可能不是必需的。
- en: '![](img/B17259_App_01.jpg)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17259_App_01.jpg)'
- en: Figure A.1 – High-level steps in a machine learning training pipeline
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 图A.1 – 机器学习训练流程的高级步骤
- en: 'The following is the sequence of steps involved in building a model that can
    handle data imbalance:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 构建能够处理数据不平衡的模型所涉及的步骤如下：
- en: '**Gather data**: The first step involves gathering the necessary data for training
    the machine learning model. This data can be sourced from various places such
    as databases, files, APIs, or through web scraping. Immediately after gathering,
    it’s often beneficial to perform **data validation**. During this phase, the data
    schema and data range can be verified, along with any custom data validation checks.
    Subsequently, the data is partitioned into a training set, a validation set, and
    a test set. Many production systems often do not prioritize producing validation
    sets. The primary function of producing these validation sets is to aid in model-tuning
    activities, such as hyperparameter adjustment, early stopping, model calibration,
    threshold tuning, and so on. Such tuning often takes place during the model development
    phase, outside of the main production pipeline. **It’s crucial to split the data
    prior to executing any data transformations or imbalance handling techniques**.
    This precaution ensures data leakage is avoided, which could otherwise lead to
    a biased model performance.'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集数据**：第一步涉及收集训练机器学习模型所需的数据。这些数据可以来自数据库、文件、API或通过网络爬虫。收集数据后，立即进行**数据验证**通常是有益的。在这个阶段，可以验证数据模式和数据范围，以及任何自定义的数据验证检查。随后，数据被划分为训练集、验证集和测试集。许多生产系统通常不优先考虑生成验证集。生成这些验证集的主要功能是帮助进行模型调优活动，如超参数调整、早期停止、模型校准、阈值调整等。这种调整通常在模型开发阶段进行，而不是在主生产流程之外。**在执行任何数据转换或不平衡处理技术之前，对数据进行拆分至关重要**。这种预防措施确保避免了数据泄露，否则可能会导致模型性能偏差。'
- en: '**Data transformation**: The next step is to transform the data into a format
    that can be easily fed into the machine learning model. This may involve tasks
    such as data cleaning, feature selection, normalization, and scaling. These transformation
    steps may need to be stored in order to apply them during model prediction time.
    It can be helpful to store these transformations somewhere (for example, a file
    or database) so that they can be retrieved later during inferencing.'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据转换**：下一步是将数据转换成可以轻松输入机器学习模型的格式。这可能涉及数据清洗、特征选择、归一化和缩放等任务。这些转换步骤可能需要存储起来，以便在模型预测时应用。将转换存储在某个地方（例如，文件或数据库）可能会有所帮助，这样可以在后续的推理过程中检索它们。'
- en: '**Handle data imbalance (if needed)**: The machine learning model might underperform
    on a minority class(es) due to a bias toward the majority class. Throughout this
    book, we’ve delved into both data-level and algorithm-level techniques. To summarize,
    data-level techniques focus on resampling the dataset to achieve balanced samples
    across each class, whereas algorithm-level techniques modify the learning algorithm
    to address imbalanced data. For a deeper understanding, please refer to the relevant
    chapters in the book.'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**处理数据不平衡（如果需要）**：由于对多数类的偏差，机器学习模型可能在少数类（或多个少数类）上表现不佳。在这本书中，我们深入探讨了数据级和算法级的技术。总结来说，数据级技术侧重于重采样数据集，以实现每个类别的样本平衡，而算法级技术则修改学习算法以处理不平衡数据。为了更深入的理解，请参考书中的相关章节。'
- en: '**Train model**: After the data has been preprocessed, it’s time to train the
    machine learning model. This step involves the following:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练模型**：数据预处理完成后，就是训练机器学习模型的时候了。这一步骤包括以下内容：'
- en: Selecting an appropriate algorithm
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择合适的算法
- en: Setting its hyperparameters
  id: totrans-342
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置其超参数
- en: Feeding the preprocessed data into the algorithm
  id: totrans-343
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预处理数据输入到算法中
- en: The training process may require several iterations to fine-tune the model until
    it produces satisfactory results. The trained model binary should be versioned
    and stored for future use, including deploying to a production environment for
    online inferencing.
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练过程可能需要多次迭代以微调模型，直到产生令人满意的结果。训练好的模型二进制文件应该进行版本控制并存储起来，以供将来使用，包括部署到生产环境进行在线推理。
- en: If any data imbalance handling technique was applied, it could miscalibrate
    the model. If calibrated prediction scores are expected from the model, it’s crucial
    to recalibrate the prediction scores. For more information on various model calibration
    techniques, please refer to [*Chapter 10*](B17259_10.xhtml#_idTextAnchor279),
    *Model Calibration*.
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果应用了任何数据不平衡处理技术，可能会使模型失准。如果期望模型提供校准后的预测分数，那么重新校准预测分数至关重要。有关各种模型校准技术的更多信息，请参阅[*第10章*](B17259_10.xhtml#_idTextAnchor279)，*模型校准*。
- en: '**Evaluate model**: This step involves assessing the performance of the trained
    model on the test set produced in *step 1*. For classification problems, metrics
    such as accuracy, precision, and recall are typically used, while for other types
    of problems, appropriate metrics should be chosen. If the model’s performance
    doesn’t meet the desired benchmarks, you may need to not only revisit the data
    transformations (as outlined in *step 2*) but also consider adjusting the model’s
    architecture, hyperparameters, or even the problem formulation. For binary classification
    models specifically, you’ll want to determine an appropriate threshold for classifying
    predictions. For more in-depth information on threshold tuning techniques, please
    refer to [*Chapter 5*](B17259_05.xhtml#_idTextAnchor151), *Cost-Sensitive Learning.*'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估模型**：这一步骤涉及评估训练好的模型在*步骤1*中产生的测试集上的性能。对于分类问题，通常使用准确率、精确率和召回率等指标，而对于其他类型的问题，应选择适当的指标。如果模型的性能未达到预期的基准，您可能不仅需要回顾数据转换（如*步骤2*中概述的），还需要考虑调整模型的架构、超参数，甚至问题表述。对于二元分类模型，您需要确定一个合适的阈值来对预测进行分类。有关阈值调整技术的更深入信息，请参阅[*第5章*](B17259_05.xhtml#_idTextAnchor151)，*成本敏感学习*。'
- en: After successfully evaluating the model, its fitness for deployment as a service
    is assessed, enabling it to handle live traffic or make batch predictions. We
    will delve deeper into inferencing in the following section.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功评估模型后，评估其作为服务的适用性，使其能够处理实时流量或进行批量预测。我们将在下一节更深入地探讨推理。
- en: Inferencing (online or batch)
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推理（在线或批量）
- en: Inferencing is a process of using a trained machine learning model to make predictions
    on new unseen data. **Online inferencing** refers to making predictions in real
    time on live data as it arrives. Latency is of utmost importance during online
    inferencing in order to prevent any lags to the end user.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 推理是一个使用训练好的机器学习模型对新未见数据进行预测的过程。**在线推理**指的是在实时数据到来时进行预测。在线推理期间，延迟是最重要的，以防止对最终用户造成任何延迟。
- en: There is another type called **batch inferencing**, where predictions are made
    on a large set of already collected data in an offline fashion.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 另有一种类型称为**批量推理**，在这种推理中，对已收集的大量数据进行离线预测。
- en: '![](img/B17259_App_02.jpg)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17259_App_02.jpg)'
- en: Figure A.2 – Process flow when live data comes to the model for scoring (inferencing)
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 图A.2 – 当实时数据到来模型进行评分（推理）时的流程图
- en: 'Inferencing is a process of using a trained machine learning model to make
    predictions on new input (unseen) data in real time. The following are the steps
    involved in the inferencing process:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 推理是一个使用训练好的机器学习模型对新输入（未见）数据进行实时预测的过程。推理过程中涉及以下步骤：
- en: '**Input data**: The first step is to receive new input data that needs to be
    classified or predicted. This data could be in the form of text, images, audio,
    or any other data format.'
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**输入数据**：第一步是接收需要分类或预测的新输入数据。这些数据可以是文本、图像、音频或其他任何数据格式。'
- en: '**Transform data**: Before predicting, the input data needs to undergo transformations
    (such as normalization and scaling) to make it compatible with the trained model.
    It’s crucial to apply the same transformations that were used during training.'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**转换数据**：在预测之前，输入数据需要经过转换（如归一化和缩放），以便与训练好的模型兼容。应用在训练期间使用的相同转换至关重要。'
- en: '**Model prediction**: Once the input data has been transformed, it is fed into
    the trained model to generate a predicted score. The predicted score represents
    the likelihood of the input belonging to a particular class or category.'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型预测**：一旦输入数据被转换，它就会被输入到训练好的模型中，以生成一个预测分数。预测分数表示输入属于特定类别或类别的可能性。'
- en: '**Calibrate score (if needed)**: Model calibration can be essential when model
    predictions are not reliable. Notably, when any data imbalance handling techniques
    are used, the risk of model miscalibration increases. For a comprehensive understanding
    of this topic, please refer to [*Chapter 10*](B17259_10.xhtml#_idTextAnchor279),
    *Model Calibration*.'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**校准分数（如有必要）**：当模型预测不可靠时，模型校准可能至关重要。值得注意的是，当使用任何数据不平衡处理技术时，模型误校准的风险增加。为了全面了解这一主题，请参阅[*第10章*](B17259_10.xhtml#_idTextAnchor279)，*模型校准*。'
- en: '**Final prediction using threshold**: The calibrated score is then used to
    make the final prediction using an appropriate threshold and take any action—for
    example, notification to the customer, human reviews, and so on.'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用阈值进行最终预测**：然后使用校准后的分数，通过适当的阈值进行最终预测，并采取任何行动——例如，通知客户、人工审查等。'
- en: 🌟 Monitoring data as well as model in production
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 🌟 监控生产中的数据和模型
- en: Monitoring data and its distribution is crucial as it can change over time,
    potentially impacting the effectiveness of any initially applied imbalance-handling
    techniques. Such shifts can affect model performance and evaluation metrics, necessitating
    a re-evaluation and potential recalibration of strategies. Beyond just data imbalance,
    phenomena such as model drift and data drift—where there is a change in the model’s
    performance or the nature of incoming data—pose significant concerns. Implementing
    automated mechanisms to track these variations is essential for ensuring optimal
    model performance and consistent predictions.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 监控数据和其分布至关重要，因为它们可能会随时间变化，可能影响最初应用的任何不平衡处理技术的有效性。这种变化可能会影响模型性能和评估指标，需要重新评估和可能重新校准策略。除了数据不平衡之外，模型漂移和数据漂移等现象——即模型性能或传入数据的性质发生变化——也引起重大关注。实施自动机制以跟踪这些变化对于确保最佳模型性能和一致的预测至关重要。
- en: In conclusion, inferencing entails transforming new input data, producing a
    predicted score using a trained machine learning model, calibrating that score,
    and determining a final prediction using a threshold. This procedure is reiterated
    for every incoming data point requiring a prediction.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，推理涉及将新的输入数据转换为训练好的机器学习模型的预测分数，校准该分数，并使用阈值确定最终预测。此过程对每个需要预测的输入数据点都会重复进行。
- en: Assessments
  id: totrans-362
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估
- en: "Chapter 1 – Introduction to Data Imbalance in \LMachine Learning"
  id: totrans-363
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 - 机器学习中的数据不平衡简介
- en: The choice of loss function when training a model can greatly affect the performance
    of the model on imbalanced datasets. Some loss functions may be more sensitive
    to class imbalance than others. For instance, a model trained with a loss function
    such as cross-entropy might be heavily influenced by the majority class and perform
    poorly on the minority class.
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型时选择损失函数可以极大地影响模型在不平衡数据集上的性能。一些损失函数可能对类别不平衡更敏感。例如，使用交叉熵损失函数训练的模型可能会受到多数类的影响很大，在少数类上的表现可能不佳。
- en: The PR curve is more informative than the ROC curve when dealing with highly
    skewed datasets because it focuses on the performance of the classifier on the
    positive (minority) class, which is often the class of interest in imbalanced
    datasets. The ROC curve, on the other hand, considers both the TPR and the FPR
    and thus might give an overly optimistic view of the model’s performance when
    the negative class dominates the dataset.
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当处理高度倾斜的数据集时，PR曲线比ROC曲线更有信息量，因为它关注分类器在正类（少数类）上的性能，这在不平衡数据集中通常是感兴趣的类别。另一方面，ROC曲线同时考虑了TPR和FPR，因此在负类主导数据集时，可能会对模型性能给出过于乐观的看法。
- en: Accuracy can be a misleading metric for model performance on imbalanced datasets
    because it does not take into account the distribution of classes. A model that
    always predicts the majority class will have high accuracy, but it is not useful
    if our goal is to correctly classify instances of the minority class.
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准确率可能是一个误导性的模型性能指标，因为它没有考虑到类别的分布。始终预测多数类的模型将具有高准确率，但如果我们目标是正确分类少数类实例，则这并不有用。
- en: 'In the context of imbalanced datasets, feature engineering poses a unique challenge
    due to the limited number of instances in the minority class. With so few examples,
    it becomes difficult even for human experts to identify features that are truly
    indicative of the minority class. Poorly chosen features can worsen the problem:
    if the features capture noise rather than the underlying pattern, the model is
    likely to overfit. Conversely, if the features are too generic and fail to capture
    the nuances of the minority class, the model may underfit, leading to poor performance
    on new, unseen data.'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在不平衡数据集的背景下，特征工程由于少数类别的实例数量有限而提出独特的挑战。由于示例如此之少，即使是人类专家也很难识别出真正指示少数类别的特征。选择不当的特征可能会加剧问题：如果特征捕捉到的是噪声而不是潜在模式，模型很可能会过拟合。相反，如果特征过于通用且未能捕捉到少数类别的细微差别，模型可能会欠拟合，导致在新未见数据上的表现不佳。
- en: The choice of “k” in k-fold cross-validation can impact the model’s performance
    on imbalanced datasets. With imbalanced datasets, some folds may contain very
    few or even no examples from the minority classes, potentially leading to misleading
    evaluations of the model. A solution to this issue is to use stratified k-fold
    cross-validation, available through the `sklearn.model_selection.StratifiedKFold`
    API, which ensures that each fold maintains a similar distribution of the various
    classes.
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在k折交叉验证中“k”的选择可能会影响模型在不平衡数据集上的性能。在不平衡数据集中，某些折可能包含非常少的甚至没有来自少数类别的示例，这可能导致对模型评估的误导。解决这个问题的一个方法是使用分层k折交叉验证，通过`sklearn.model_selection.StratifiedKFold`
    API提供，这确保了每个折保持各种类别的相似分布。
- en: Usually, the greater the imbalance in the test set, the more negatively the
    PR curve is affected. In contrast, the ROC curve is not affected by the class
    distribution in the test set.
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通常，测试集中的不平衡程度越大，PR曲线受到的负面影响就越大。相比之下，ROC曲线不受测试集中类别分布的影响。
- en: 'In *Figures 1.13* and *1.14*, we presented three test sets with imbalance ratios
    of 1:9, 1:3, and 1:1\. The ROC-AUC for all these cases is 0.96, as shown in *Figure
    1**.13*. On the other hand, the average precision value is inversely proportional
    to the level of imbalance in the test set, as illustrated in *Figure 1**.14* (that
    is, greater imbalance results in lower average precision):'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在*图1.13*和*图1.14*中，我们展示了三个不平衡比率为1:9、1:3和1:1的测试集。所有这些情况的ROC-AUC都是0.96，如图*图1.13*所示。另一方面，平均精度值与测试集中不平衡的程度成反比，如图*图1.14*所示（即，更大的不平衡导致平均精度更低）：
- en: '![](img/B17259_01_13.jpg)'
  id: totrans-371
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_01_13.jpg)'
- en: Figure B.1 – ROC curves remain the same when the imbalance ratio changes in
    the test set
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.1 – 当测试集中的不平衡比率变化时，ROC曲线保持不变
- en: '![](img/B17259_01_14.jpg)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_01_14.jpg)'
- en: Figure B.2 – The PR curve changes considerably when the imbalance ratio changes
    in the test set
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.2 – 当测试集中的不平衡比率变化时，PR曲线会显著变化
- en: Having a high AUC-ROC but a low AUC-PR in the context of an imbalanced dataset
    could indicate that the model is performing well in distinguishing between the
    classes overall (as indicated by the high AUC-ROC), but it is not doing a good
    job at identifying the positive (minority) class (as indicated by the low AUC-PR).
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在不平衡数据集的背景下，具有高AUC-ROC但低AUC-PR可能表明模型在总体上区分类别表现良好（如高AUC-ROC所示），但在识别正类（少数类）方面做得不好（如低AUC-PR所示）。
- en: Sampling bias can contribute to the challenge of imbalanced datasets in machine
    learning because it can lead to an overrepresentation of one class and an underrepresentation
    of another. This can skew the model’s learning and result in poor performance
    in the underrepresented class.
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 样本偏差可能导致机器学习中不平衡数据集的挑战，因为它可能导致某一类别的过度代表和另一类别的不足代表。这可能会扭曲模型的训练并导致在代表性不足的类别上表现不佳。
- en: Labeling errors can contribute to the challenge of imbalanced datasets in machine
    learning because they can lead to an incorrect representation of the classes in
    the data. If instances of the minority class are mistakenly labeled as the majority
    class, the model might learn incorrect patterns and perform poorly on the minority
    class.
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标记错误可能导致机器学习中不平衡数据集的挑战，因为它们可能导致数据集中类别的错误表示。如果少数类别的实例被错误地标记为多数类，模型可能会学习到错误的模式并在少数类上表现不佳。
- en: There are many real-world scenarios where dealing with imbalanced datasets is
    inherently part of the problem. Some examples include fraud detection (where fraudulent
    transactions are rare compared to legitimate ones), medical diagnosis (where diseases
    are often rare compared to healthy cases), and spam detection (where spam emails
    are typically fewer than non-spam emails). Can you think of any others?
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在许多现实世界场景中，处理不平衡数据集本质上就是问题的一部分。一些例子包括欺诈检测（欺诈交易与合法交易相比很少见）、医疗诊断（疾病与健康病例相比通常很少见）和垃圾邮件检测（垃圾邮件通常比非垃圾邮件少）。你能想到其他的例子吗？
- en: 'Here are the answers:'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里是答案：
- en: Its value ranges from -1 (worst value) to +1 (best value).
  id: totrans-380
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其值范围从 -1（最差值）到 +1（最佳值）。
- en: 'The dummy model always predicts class 1, so here are our various confusion
    matrix values:'
  id: totrans-381
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 空白模型总是预测类别 1，因此这里列出了我们各种混淆矩阵的值：
- en: TP = 90, TN = 0, FP=10, FN = 0
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: TP = 90，TN = 0，FP=10，FN = 0
- en: MCC =  TP · TN − FP · FN    __________________________________    √ ______________________________________    (TP
    + FP) · (TP + FN) · (TN + FP) · (TN + FN)
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MCC =  TP · TN − FP · FN    __________________________________    √ ______________________________________    (TP
    + FP) · (TP + FN) · (TN + FP) · (TN + FN)
- en: 'The confusion matrix values are as follows:'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 混淆矩阵的值如下：
- en: TP = 90
  id: totrans-385
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: TP = 90
- en: TN = 0
  id: totrans-386
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: TN = 0
- en: FP = 10
  id: totrans-387
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FP = 10
- en: FN = 0
  id: totrans-388
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: FN = 0
- en: 'By plugging these values into the formula, we get the following:'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将这些值代入公式，我们得到以下结果：
- en: MCC =  (90 × 0) − (10 × 0)  _____________________________   √ _________________________________   (90
    + 10) × (90 + 0) × (0 + 10) × (0 + 0)
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MCC =  (90 × 0) − (10 × 0)  _____________________________   √ _________________________________   (90
    + 10) × (90 + 0) × (0 + 10) × (0 + 0)
- en: =  0 − 0 ______________  √ _______________  100 × 90 × 10 × 0
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: =  0 − 0 ______________  √ _______________  100 × 90 × 10 × 0
- en: Since the denominator becomes zero (because of the term (TN + FN = 0 + 0)),
    the MCC is undefined.
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于分母变为零（因为 (TN + FN = 0 + 0) 这一项），MCC 是未定义的。
- en: 'We can compute the other metrics as follows:'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以按照以下方式计算其他指标：
- en: Accuracy = TP+TN/ (TP+TN+FP+FN) = 0.90
  id: totrans-394
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Accuracy = TP+TN/ (TP+TN+FP+FN) = 0.90
- en: Precision = TP/(TP+FP) = 90/(90+10) = 0.90
  id: totrans-395
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Precision = TP/(TP+FP) = 90/(90+10) = 0.90
- en: Recall = TP/(TP+FN) = 90/(90+0) = 1
  id: totrans-396
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Recall = TP/(TP+FN) = 90/(90+0) = 1
- en: F1 score = 2*Precision*Recall/(Precision+Recall) = 2*0.90*1/(0.90+1) = 0.95
  id: totrans-397
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: F1 分数 = 2*Precision*Recall/(Precision+Recall) = 2*0.90*1/(0.90+1) = 0.95
- en: Let’s compute MCC for the previous values. It’s undefined (0/0), which would
    mean something is wrong with the model, and we should go back and fix any issues
    with the data or the model.
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们计算前述值的 MCC。它是未定义的（0/0），这意味着模型可能存在问题，我们应该回去检查数据或模型中的任何问题。
- en: In summary, MCC is a metric that generates a high score only if the model does
    well on both positive and negative class examples from the test set. Also, MCC
    can help inform the user about ongoing prediction issues.
  id: totrans-399
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总结来说，MCC 是一个指标，只有当模型在测试集的正负类示例上都表现良好时，才会产生高分。此外，MCC 还可以帮助用户了解持续的预测问题。
- en: This is left as an exercise for you.
  id: totrans-400
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这留给你作为练习。
- en: Chapter 2 – Oversampling Methods
  id: totrans-401
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 – 过采样方法
- en: This is left as an exercise for you.
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这留给你作为练习。
- en: One approach is to oversample the minority class by 20x to balance both classes.
    It’s important to note that achieving the perfect balance between the classes
    is not always necessary; a slight imbalance may be acceptable, depending on the
    specific requirements and constraints. This technique is not applied at test time
    as the test data should remain representative of what we would encounter in the
    real world.
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种方法是通过将少数类过采样 20 倍来平衡两类。需要注意的是，在类之间实现完美的平衡并不总是必要的；轻微的不平衡可能是可接受的，具体取决于特定的需求和限制。这种技术不在测试时间应用，因为测试数据应该代表我们在现实世界中会遇到的情况。
- en: The primary concern with oversampling before splitting the data into training,
    test, and validation sets is data leakage. This occurs when duplicate samples
    end up in both the training and test/validation sets, leading to overly optimistic
    performance metrics. The model may perform well during evaluation because it has
    already seen the same examples during training, but this can result in poor generalization
    to new, unseen data. To mitigate this risk, it’s crucial to first split the data
    into training, test, and validation sets and then apply balancing techniques such
    as oversampling exclusively to the training set.
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在将数据分割成训练、测试和验证集之前，对数据进行过采样的主要问题是数据泄露。这发生在重复样本同时出现在训练和测试/验证集中，导致过度乐观的性能指标。模型在评估期间可能表现良好，因为它已经在训练期间看到了相同的示例，但这可能导致对新、未见数据的泛化能力差。为了减轻这种风险，首先将数据分割成训练、测试和验证集，然后仅将平衡技术（如过采样）应用于训练集。
- en: Data normalization can help indirectly in dealing with data imbalance by ensuring
    that all features have the same scale, which can lead to better model performance.
    However, normalization may not directly address the imbalance between the classes
    in the dataset. To tackle data imbalance, other techniques can be employed, such
    as various sampling techniques, cost-sensitive approaches, or threshold adjustment
    techniques.
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据归一化可以通过确保所有特征具有相同的尺度来间接帮助处理数据不平衡，这可能导致更好的模型性能。然而，归一化可能不会直接解决数据集中类之间的不平衡。为了解决数据不平衡，可以采用其他技术，例如各种采样技术、成本敏感方法或阈值调整技术。
- en: This has been left as an exercise for you.
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习。
- en: Chapter 3 – Undersampling Methods
  id: totrans-407
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章 – 欠采样方法
- en: This has been left as an exercise for you.
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习。
- en: This has been left as an exercise for you.
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习。
- en: This has been left as an exercise for you.
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习。
- en: '`TomekLinksNCR` is a custom undersampling method that combines Tomek links
    and NCR. It removes Tomek links and then applies NCR to remove more noisy and
    borderline samples from the majority class. This aims to create a more balanced
    dataset while retaining the underlying structure of the data.'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`TomekLinksNCR` 是一种自定义的欠采样方法，它结合了 Tomek links 和 NCR。它首先移除 Tomek links，然后应用
    NCR 从多数类中移除更多噪声和边缘样本。这旨在创建一个更平衡的数据集，同时保留数据的底层结构。'
- en: Chapter 4 – Ensemble Methods
  id: totrans-412
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章 – 集合方法
- en: This has been left as an exercise for you.
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习。
- en: The main difference between `BalancedRandomForestClassifier` and `BalancedBaggingClassifier`
    is the base classifier and the ensemble learning method they employ. `BalancedRandomForestClassifier`
    uses decision trees as base classifiers and follows a random forest as the estimator,
    while `BalancedBaggingClassifier` can use any base classifier that supports sample
    weighting and follows a bagging approach.
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`BalancedRandomForestClassifier` 和 `BalancedBaggingClassifier` 之间的主要区别在于它们使用的基分类器和集成学习方法。`BalancedRandomForestClassifier`
    使用决策树作为基分类器，并遵循随机森林作为估计器，而 `BalancedBaggingClassifier` 可以使用任何支持样本加权的基分类器，并遵循 bagging
    方法。'
- en: Random forest can be considered an extension of bagging that incorporates an
    additional layer of randomness by also randomly selecting a subset of features
    at each split in the decision tree. This helps create more diverse trees and generally
    results in better performance of random forest models.
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随机森林可以被视为 bagging 的扩展，它通过在决策树的每个分裂点随机选择特征子集来引入额外的随机性。这有助于创建更多样化的树，并且通常会导致随机森林模型性能更好。
- en: Chapter 5 – Cost-Sensitive Learning
  id: totrans-416
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章 – 成本敏感学习
- en: This chapter’s questions have been left as exercises for you.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的问题已被留作你的练习。
- en: Chapter 6 – Data Imbalance in Deep Learning
  id: totrans-418
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第六章 – 深度学习中的数据不平衡
- en: The main challenge stems from the different types of data these models handle.
    Classical machine learning models typically work with structured, tabular data,
    while deep learning models handle unstructured data such as images, text, audio,
    and video.
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主要挑战源于这些模型处理的数据类型不同。经典的机器学习模型通常处理结构化、表格数据，而深度学习模型处理非结构化数据，如图像、文本、音频和视频。
- en: An imbalanced version of the MNIST dataset can be created by randomly selecting
    a certain percentage of examples for each class. This process involves choosing
    indices of the samples to remove and then actually removing these samples from
    the training set.
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以通过随机选择每个类的一定百分比的示例来创建 MNIST 数据集的不平衡版本。这个过程涉及选择要移除的样本的索引，然后实际上从训练集中移除这些样本。
- en: This has been left as an exercise for you.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习。
- en: Random oversampling is used to address imbalance in the dataset. It works by
    duplicating samples from the minority classes until each class has an equal number
    of samples. This technique is usually considered to perform better than no sampling.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机过采样用于解决数据集中的不平衡。它通过复制少数类的样本，直到每个类都有相同数量的样本来实现。这种技术通常被认为比不采样表现得更好。
- en: Data augmentation techniques can include rotating, scaling, cropping, blurring,
    adding noise to the image, and much more. However, ensuring these augmentations
    preserve the original labels and avoiding inadvertently removing important details
    from the data is crucial. Please refer to [*Chapter 7*](B17259_07.xhtml#_idTextAnchor205),
    *Data-Level Deep Learning Methods*, for a detailed discussion of the various data
    augmentation techniques.
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据增强技术可以包括旋转、缩放、裁剪、模糊、向图像添加噪声等。然而，确保这些增强保留原始标签，并避免无意中从数据中删除重要细节是至关重要的。请参阅[*第7章*](B17259_07.xhtml#_idTextAnchor205)，*数据级深度学习方法*，以详细了解各种数据增强技术。
- en: 'Undersampling reduces the instances of the majority class to balance the dataset.
    However, this method has a significant limitation: important information might
    be lost if instances from the majority class are randomly removed, especially
    when the majority class has a lot of variation.'
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下采样减少了多数类的实例以平衡数据集。然而，这种方法有一个显著的局限性：如果随机删除多数类的实例，可能会丢失重要信息，特别是当多数类有很多变化时。
- en: The data augmentation techniques must preserve the original labels because the
    model learns to associate the features of the data with these labels. If the labels
    change due to augmentation, the model might learn incorrect associations, which
    would degrade its performance when making predictions.
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据增强技术必须保留原始标签，因为模型学习将数据的特征与这些标签关联起来。如果标签由于增强而改变，模型可能会学习到错误的关联，这会降低其在进行预测时的性能。
- en: Chapter 7 – Data-Level Deep Learning Methods
  id: totrans-426
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 – 数据级深度学习方法
- en: This chapter’s questions have been left as exercises for you.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的问题已被留作你的练习题。
- en: Chapter 8 – Algorithm-Level Deep Learning Techniques
  id: totrans-428
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 – 算法级深度学习技术
- en: This has been left as an exercise for you.
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习题。
- en: This has been left as an exercise for you.
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习题。
- en: 'Tversky loss is based on the Tversky index, which is defined by the following
    formula:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Tversky损失基于Tversky指数，其定义如下公式：
- en: TverskyIndex =  TruePositive   _______________________________________    TruePositive+
    α * FalsePositive + (1 − α) * FalseNegative
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: TverskyIndex =  TruePositive   _______________________________________    TruePositive+
    α * FalsePositive + (1 − α) * FalseNegative
- en: 'A smoothing factor is added to both the numerator and denominator to avoid
    division by zero. `alpha` is a hyperparameter that can be tuned:'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在分子和分母中添加了一个平滑因子以避免除以零。`alpha`是一个可以调整的超参数：
- en: '[PRE17]'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This has been left as an exercise for you.
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习题。
- en: Chapter 9 – Hybrid Deep Learning Methods
  id: totrans-436
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章 – 混合深度学习方法
- en: We don’t provide a full answer here, but only some functions that will help
    you with the main task.
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在这里不提供完整的答案，而只提供一些将帮助你完成主要任务的函数。
- en: 'We could use `torch.nn.functional.triplet_margin_loss()`, or we could implement
    it from scratch:'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以使用`torch.nn.functional.triplet_margin_loss()`，或者我们可以从头实现它：
- en: '[PRE18]'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You would want to generate triplets for the imbalanced MNIST dataset. The following
    function generates a list of triplets (anchor, positive, and negative) for a batch
    of images. It generates one triplet per class present in the batch. We assume
    that there are at least two examples for each class in the batch:'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你会想要为不平衡的MNIST数据集生成三元组。以下函数为一批图像生成三元组列表（锚点、正例和负例）。它为批次中存在的每个类别生成一个三元组。我们假设批次中每个类别至少有两个示例：
- en: '[PRE19]'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This has been left as an exercise for you.
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习题。
- en: Chapter 10 – Model Calibration
  id: totrans-443
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章 – 模型校准
- en: 'Yes, a well-calibrated model can have low accuracy and vice-versa. Let’s take
    a dumb model that always outputs 0.1 probability for any input example. This model
    is perfectly calibrated, but its accuracy is only 90%, which is quite low for
    an imbalanced dataset with a 1:9 imbalance ratio. Here is the implementation of
    such a model:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是的，一个校准良好的模型可以具有较低的准确率，反之亦然。让我们考虑一个总是为任何输入示例输出0.1概率的愚蠢模型。这个模型校准得非常完美，但它的准确率只有90%，对于一个1:9不平衡比率的失衡数据集来说相当低。以下是此类模型的实现：
- en: '[PRE20]'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This produces the accuracy value and calibration plot:'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这会产生准确率值和校准图：
- en: '[PRE21]'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](img/B17259_10_17.jpg)'
  id: totrans-448
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17259_10_17.jpg)'
- en: Figure B.3 – A dummy model with perfect calibration but a low accuracy score
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.3 – 一个校准完美但准确率得分低的虚拟模型
- en: This has been left as an exercise for you.
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习题。
- en: This has been left as an exercise for you.
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习题。
- en: This has been left as an exercise for you.
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习题。
- en: This has been left as an exercise for you.
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已被留作你的练习题。
