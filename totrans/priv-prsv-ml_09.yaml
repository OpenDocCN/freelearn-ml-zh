- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Federated Learning and Implementing FL Using Open Source Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn about **Federated Learning** (**FL**) and how
    to implement it using open source frameworks. We will cover why it is needed and
    how to preserve data privacy. We will also look at the definition of FL, as well
    as its characteristics and the steps involved in it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: FL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FL algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The steps involved in implementing FL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open source frameworks for implementing FL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An end-to-end use case of implementing fraud detection using FL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FL with differential privacy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By exploring these topics, you will gain a comprehensive understanding of the
    need for FL and the open source frameworks for implementing FL.
  prefs: []
  type: TYPE_NORMAL
- en: Federated learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: FL has emerged as a solution to address the challenges of traditional centralized
    **Machine Learning** (**ML**) approaches in scenarios where data privacy and data
    locality are of paramount importance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key reasons that we need FL are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Preserving data privacy**: In many situations, data is sensitive and cannot
    be shared due to legal, ethical, or privacy concerns. FL enables you to train
    models directly on distributed data sources without sharing the raw data, ensuring
    privacy protection. By keeping data local and performing model updates locally,
    FL minimizes the risk of exposing sensitive information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data localization and regulatory compliance**: FL allows organizations to
    comply with data localization requirements and regulations. Instead of transferring
    data to a central server, data remains within the jurisdiction where it is generated
    or collected, addressing concerns related to cross-border data transfers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability and efficiency**: Centralized machine learning approaches often
    face challenges when dealing with large volumes of data, as aggregating and processing
    data from various sources can be time-consuming and resource-intensive. FL distributes
    the training process, allowing data to remain decentralized while benefiting from
    the collective intelligence of all participating devices or data sources. This
    decentralized approach improves scalability and computational efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Access to diverse data**: FL facilitates the pooling of data from multiple
    sources, enabling models to learn from diverse datasets without the need for direct
    data sharing. This is particularly beneficial in scenarios where data sources
    have distinct characteristics, such as different demographics, geographical regions,
    or user preferences. Access to a diverse range of data enhances the generalization
    and robustness of ML models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhanced security and resilience**: With FL, the data remains distributed
    across devices or edge nodes, reducing the risk of a single point of failure or
    vulnerability. This distributed nature enhances the security and resilience of
    the overall system, making it less susceptible to attacks or breaches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User empowerment and inclusion**: FL offers opportunities for user participation
    and control over their data. Instead of relinquishing data ownership and control
    to a centralized authority, users can actively contribute to the learning process
    while retaining control over their personal information. This empowers individuals
    and promotes a sense of inclusion and transparency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The need for FL arises from the critical requirements of preserving data privacy,
    complying with regulatory frameworks, achieving scalability and efficiency, accessing
    diverse data sources, ensuring security, and empowering users.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging FL, organizations can overcome the limitations of centralized
    approaches and unlock the potential of distributed data for training robust and
    privacy-preserving ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Preserving privacy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s consider the case of ARDHA Bank (a fictional bank for illustration purposes
    only). ARDHA Bank is a financial institution that has been operating in the United
    States for several years, adhering to country-specific regulations. The bank offers
    a range of services to its customers, including fraud prevention, loyalty programs,
    and digital payments. Initially, ARDHA Bank employed static rule-based systems
    to detect and prevent fraudulent activities. However, recognizing the need for
    more advanced approaches, they transitioned to utilizing ML algorithms for enhanced
    fraud detection and prevention.
  prefs: []
  type: TYPE_NORMAL
- en: With access to a comprehensive dataset comprising historical and current transaction
    data, ARDHA Bank developed ML and **Deep Learning** (**DL**) algorithms specifically
    tailored to their operations. These algorithms were trained on this extensive
    dataset, allowing the bank to effectively identify and prevent financial fraud
    with exceptional accuracy. By leveraging the power of ML and DL techniques, ARDHA
    Bank significantly improved its ability to detect and mitigate fraudulent digital
    transactions, thereby safeguarding its customers’ financial interests.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – A simple ML model in a financial bank](img/B16573_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – A simple ML model in a financial bank
  prefs: []
  type: TYPE_NORMAL
- en: ARDHA Bank, having experienced success in the **United States** (**US**), made
    the strategic decision to expand its business and establish branches in two additional
    countries – France (for Europe) and India. With the expansion, ARDHA Bank aimed
    to offer the same suite of services to its customers in both regions. To provide
    digital payment services in France and India, one option considered by ARDHA Bank
    was to transmit periodic transaction data from both countries to their US servers.
    The US servers would then serve as the central location to run the ML models.
    After training the ML models on the combined data from all regions, the trained
    models would be deployed to the regional servers in France and India. By adopting
    this approach, ARDHA Bank sought to leverage the infrastructure of its US servers
    to process and analyze the transaction data efficiently. The centralized training
    of ML models allowed for a unified approach to fraud detection and prevention,
    ensuring consistency and accuracy across different regions. This strategy enabled
    ARDHA Bank to provide reliable and effective digital payment services in Europe
    and India while maintaining data security and privacy. By utilizing regional servers
    and deploying the trained ML models locally, the bank ensured swift and localized
    decision-making, catering to the specific needs and regulatory requirements of
    each region.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – A simple ML model in a financial bank in three locations](img/B16573_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – A simple ML model in a financial bank in three locations
  prefs: []
  type: TYPE_NORMAL
- en: The proposed solution, which involves transferring data to a central server
    and running ML models on that data, faces challenges due to privacy regulations
    and data localization laws in Europe and India. These regulations, such as the
    **General Data Protection Regulation** (**GDPR**) in Europe and India’s data localization
    requirements, stipulate that data generated within these countries must be stored
    within local data centers. Data must remain within the borders of the country
    where it was created.
  prefs: []
  type: TYPE_NORMAL
- en: Given these privacy and localization constraints, an alternative approach is
    necessary. One possible alternative is to run ML models locally at each branch
    or location of the bank. This approach entails deploying client models that utilize
    the local data available at each location. The local models would process the
    data within the boundaries of the respective country, ensuring compliance with
    privacy regulations. To implement this alternative, only the model weights and
    parameters, not the transaction data used by customers, would be shared with a
    central server. The central server, hosted in any country, would be responsible
    for running a global model using the aggregated model weights and parameters from
    each location. The resulting global model could then be regularly distributed
    back to the local clients in each country. This approach enables the bank to leverage
    the benefits of ML models while adhering to privacy regulations and data localization
    laws. By conducting ML computations locally and sharing only model-related information,
    the bank ensures compliance, data security, and privacy. Additionally, this distributed
    approach allows for local adaptation and customization while still benefiting
    from the insights gained through the global model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Local model interactions with the global model](img/B16573_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – Local model interactions with the global model
  prefs: []
  type: TYPE_NORMAL
- en: This approach is known as **Federated Machine Learning**, or FL. In FL, the
    traditional paradigm of moving data to a central location is reversed. Instead,
    the model and computation are brought to the data.
  prefs: []
  type: TYPE_NORMAL
- en: In FL, the ML model is deployed and executed directly on the local data sources
    or devices where the data resides. This eliminates the need to transfer raw data
    to a central server, addressing privacy concerns and regulatory requirements.
    The model is trained locally using the data on each device, and only the model
    updates, such as gradients or weights, are securely transmitted to a central aggregator.
  prefs: []
  type: TYPE_NORMAL
- en: By keeping the data decentralized and performing computations locally, FL ensures
    data privacy and reduces the risks associated with data transfer. It allows organizations
    to leverage the collective knowledge and insights from distributed data sources
    without compromising individual data privacy. This approach is particularly beneficial
    in scenarios where data cannot be easily shared due to legal, regulatory, or privacy
    constraints.
  prefs: []
  type: TYPE_NORMAL
- en: FL represents a paradigm shift in ML, enabling collaborative and privacy-preserving
    model training. It promotes a distributed approach where data remains under the
    control of the data owners while contributing to a shared model. This decentralized
    and privacy-conscious framework opens up possibilities to harness the power of
    large-scale data without sacrificing privacy and security.
  prefs: []
  type: TYPE_NORMAL
- en: FL definition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following is the formal definition of FL proposed as per the *Advances
    and Open Problems in Federated Learning* paper published at arxiv/1912.04977:'
  prefs: []
  type: TYPE_NORMAL
- en: “Federated learning is a machine learning setting where multiple entities (clients)
    collaborate in solving a machine learning problem, under the coordination of a
    central server or service provider. Each client’s raw data is stored locally and
    not exchanged or transferred; instead, focused updates intended for immediate
    aggregation are used to achieve the learning objective”
  prefs: []
  type: TYPE_NORMAL
- en: 'As per this definition, these are the characteristics of FL:'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple clients (entities) collaborate to solve an ML problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A service provider or central server coordinates with these entities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raw data (data with samples) is stored locally at each client location and is
    not transferred to the servers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The learning objective (or loss function) is defined. To minimize the loss (predictions
    versus actual), focused updates (weights and biases) are sent to the server from
    clients, the aggregation of weights (either average or dynamic aggregation) is
    done at the server, and these updates are sent back to clients.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s delve further into each one of these in detail to understand them better.
  prefs: []
  type: TYPE_NORMAL
- en: Characteristics of FL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following subsections will cover the characteristics of FL in depth.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple clients (entities) collaborate to solve an ML problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In FL, the participation requirement typically involves a minimum of two clients,
    while the maximum number of clients can vary based on the specific use cases and
    client types.
  prefs: []
  type: TYPE_NORMAL
- en: 'Clients participating in FL can be broadly classified into two categories –
    cross-device and cross-silo:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cross-device** clients are individual devices, such as smartphones, laptops,
    or IoT devices, that contribute their local data for model training. These devices
    act as clients in the FL framework, allowing their data to be utilized while preserving
    privacy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cross-silo** clients, on the other hand, represent data sources that are
    distributed across different organizational silos or entities. These silos can
    be different departments within an organization, separate institutions, or even
    distinct geographical regions. Each silo acts as a client, contributing its local
    data for collaborative model training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 6.4 – A classification of FL clients](img/B16573_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – A classification of FL clients
  prefs: []
  type: TYPE_NORMAL
- en: The maximum number of clients in an FL setup depends on the specific use cases
    and the scale of the distributed data sources. For instance, in scenarios where
    multiple organizations collaborate to build a global model while maintaining data
    privacy, the number of participating clients can be substantial. On the other
    hand, in more focused or localized use cases, the number of clients may be limited
    to a smaller group.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-silo FL clients
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Cross-silo clients are entities such as financial banks, institutions, hospitals,
    and pharmacy companies. These clients can be further categorized into two groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Different clients within the same institution**: This includes different
    branches of the same bank, different branches within a hospital network, and similar
    setups where multiple branches or divisions of a single institution participate
    in FL.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Different clients across different institutions**: This involves different
    organizations, such as different banks or hospitals, collaborating and contributing
    their data to the FL process. These clients represent inter-institutional collaborations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum number of clients in the cross-silo category can vary based on the
    specific use case, but typically, it ranges from tens to hundreds. The number
    of participating clients is usually limited due to the nature of collaborations
    and the scale of the institutions involved.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-device FL clients
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Cross-device clients, on the other hand, encompass various devices that participate
    as clients or nodes in FL. These devices can be either homogenous or heterogenous,
    and examples include devices such as Apple iPhones, Google phones, and the Brave
    browser.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of cross-device FL clients, each device runs its own ML model based
    on the local data available on that specific device. Only the model weights and
    biases are transmitted to the server based on device conditions and other configuration
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, the maximum number of clients can reach thousands or even
    millions, as it encompasses a wide range of devices participating in FL across
    different locations and user bases.
  prefs: []
  type: TYPE_NORMAL
- en: By accommodating both cross-silo and cross-device clients, FL enables collaboration
    and knowledge sharing while respecting data privacy and ensuring scalable participation
    across institutions and devices.
  prefs: []
  type: TYPE_NORMAL
- en: A service provider or central server coordinates with these entities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The server in FL makes decisions based on the network topology of the participating
    clients and the total number of clients involved in the process. The server determines
    when to distribute the initial model or updated models to the clients, considering
    factors such as the network structure and the specific number of participating
    clients. It decides whether to send the model updates to all clients or only a
    subset of them, based on the requirements of the learning task.
  prefs: []
  type: TYPE_NORMAL
- en: After the clients receive the model, they compute and update the weights and
    biases based on their local data. The clients then send these updated weights
    and biases back to the server. The server aggregates the received data and performs
    computations using an objective function to minimize the loss or optimize the
    learning objective.
  prefs: []
  type: TYPE_NORMAL
- en: Based on the aggregated information, the server generates an updated model.
    It decides which clients need to be updated with the new model and which clients
    can continue running the existing model without any changes. This decision is
    based on factors such as the learning progress, the need for updates, or the compatibility
    of clients with the updated model.
  prefs: []
  type: TYPE_NORMAL
- en: By carefully orchestrating these steps, the server manages the distribution
    of models, collects client updates, aggregates data, and ultimately, sends back
    the updated model to the appropriate clients. This iterative process in FL ensures
    collaborative model improvement while accounting for the individual requirements
    and capabilities of the participating clients.
  prefs: []
  type: TYPE_NORMAL
- en: Raw data (data with samples) is stored locally at each client location and is
    not transferred to the servers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In FL, raw data is stored locally at each client location instead of being centralized
    in a single server. This decentralized approach ensures that the data remains
    under the control and ownership of the respective clients, preserving privacy
    and complying with data regulations.
  prefs: []
  type: TYPE_NORMAL
- en: The data at each client location exhibits a specific distribution, which can
    vary across different clients. The distribution of the data refers to the statistical
    characteristics and patterns present within the dataset. The data samples within
    a client’s dataset can be independent of each other, meaning that they are unrelated
    or do not rely on each other for their values or properties. Alternatively, the
    data samples can be dependent, indicating that there is some form of correlation
    or relationship between them.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the data distribution can be either identical or non-identical
    among the clients. Identical data distribution implies that the statistical properties
    of the datasets are the same across different clients. On the other hand, non-identical
    data distribution suggests that the datasets exhibit variations in their statistical
    characteristics, such as mean, variance, or other relevant parameters.
  prefs: []
  type: TYPE_NORMAL
- en: The presence of diverse data distributions, whether independent or dependent,
    identical or non-identical, introduces challenges and complexities in FL. Nevertheless,
    FL methods are designed to handle these variations and enable collaborative model
    training across decentralized data sources, leveraging the collective knowledge
    while respecting data privacy and distribution characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: Datasets with IID and non-IID data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Independent and identically distributed (IID) data refers to a dataset in which
    the data samples are independent of each other, and the distribution of the data
    is identical across all samples. In this case, the outcomes of each data sample
    are not dependent on previous samples, and the statistical properties of the data
    remain consistent.
  prefs: []
  type: TYPE_NORMAL
- en: For example, consider a dataset where a coin is tossed five times and the number
    of times it turns up heads is recorded. In this scenario, each coin toss is independent
    of the previous tosses, and the probability of getting heads is identical for
    each toss. This results in an IID dataset where the distribution of outcomes is
    the same for every coin toss.
  prefs: []
  type: TYPE_NORMAL
- en: In FL, the data across different clients may exhibit **non-IID** characteristics.
    This means that the data samples are not identically distributed, and they may
    also be dependent on each other. Various factors can contribute to non-IID data,
    such as variations in the amount of labeled data, differences in the features
    present in the samples, data drift, concept drift, or imbalanced data.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in the case of cross-silo entities within a company, each client
    may have the same kind of features and labels for classification. However, the
    number of data samples at each location may vary, resulting in imbalanced data.
    Additionally, each location may not have data for all classes or may exhibit different
    distributions of examples.
  prefs: []
  type: TYPE_NORMAL
- en: Raw data in cross-silo entities in FL
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When dealing with cross-silo entities in FL, the raw data exhibits certain
    characteristics. Specifically, in the case of intra-company scenarios, the following
    can be observed:'
  prefs: []
  type: TYPE_NORMAL
- en: Each client within the cross-silo entities will possess the same kind of features.
    This means that the types of data attributes or variables available for analysis
    will be consistent across all clients.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The labels or classes used for classification tasks will also be the same among
    the clients. This ensures that the target categories or outcomes for classification
    are consistent throughout the participating entities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of data samples at each client location may vary. This implies that
    the amount of available data may differ across different locations or branches
    within the same company. Some clients may have more extensive datasets, while
    others may have fewer samples.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not all classes or categories may be represented in each client’s data. This
    results in imbalanced data, where certain classes may be overrepresented or underrepresented
    compared to others. Such imbalances can pose challenges for model training and
    evaluation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The distribution of examples may not be the same across all clients. This means
    that the statistical characteristics, such as the mean, variance, or other properties,
    may vary between different client locations. Each client’s data may exhibit unique
    distributional patterns, which need to be accounted for during the FL process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Considering these characteristics, FL techniques must address the variability
    in data samples, imbalanced class distributions, and divergent data distributions
    across the cross-silo entities.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of the banking example we discussed, since it is the same bank
    operating in different countries, the features (such as customer ID, amount, transaction
    date, source account, destination account, and address) and labels (*fraud* or
    *non-fraud*) will be the same. However, the distribution of data samples and labels
    may vary at each location, based on factors such as the number of customers and
    the types of transactions. This introduces non-IID characteristics to the data,
    requiring careful handling in FL approaches.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – The ML model in a financial bank in three locations](img/B16573_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – The ML model in a financial bank in three locations
  prefs: []
  type: TYPE_NORMAL
- en: Data is distributed in the following way to each client. There is skewness in
    the label data but samples with all features exist in each location/client/entity.
  prefs: []
  type: TYPE_NORMAL
- en: '| Data at different clients | FeaturesX={ X1, X2, X3, …Xn} | Labely = { y1,
    y2…, ym} |'
  prefs: []
  type: TYPE_TB
- en: '| X1 | X2 | X3 | X4 | Fraud data label counts |'
  prefs: []
  type: TYPE_TB
- en: '| Europe(Client 1) | yes | yes | yes | yes | Fraud count = N, Non-fraud = 0
    |'
  prefs: []
  type: TYPE_TB
- en: '| US(Client 2 | yes | yes | yes | yes | Fraud count = 0, Non-fraud = N |'
  prefs: []
  type: TYPE_TB
- en: '| India(Client 3) | yes | yes | yes | yes | Fraud count = N/2, Non-fraud =
    N/4 |'
  prefs: []
  type: TYPE_TB
- en: Table 6.1 – Label data skewness
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of intra-institutions, where different institutions within the
    same industry participate in FL to offer similar ML services, the data may exhibit
    the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: Each client, representing a different institution, may or may not have the same
    kind of features. This means that the available data attributes or variables may
    differ between institutions, based on their specific contexts or data collection
    practices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of data samples at each client location may vary. This indicates
    that the amount of data available for analysis could differ between different
    institutions. Some institutions may have larger datasets, while others may have
    relatively smaller ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not all classes or categories may be present in each client’s data. This can
    result in imbalanced data, where certain classes may be underrepresented or missing
    altogether in some institutions’ datasets. Handling imbalanced data is an important
    consideration in the FL process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The distribution of examples may also differ among the participating institutions.
    Each institution’s data may have its own unique distributional patterns, including
    variations in mean, variance, or other statistical properties. These differences
    need to be taken into account during the collaborative model training process.![Figure
    6.6 – FL client and server communication (send and receive) model parameters](img/B16573_06_06.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 6.6 – FL client and server communication (send and receive) model parameters
  prefs: []
  type: TYPE_NORMAL
- en: Data is distributed in the following way to each client. In this scenario, there
    is skewness in features and label data.
  prefs: []
  type: TYPE_NORMAL
- en: '| Data at different clients | FeaturesX={ X1, X2, X3, …Xn} | Labely = { y1,
    y2…, yn} |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| X1 | X2 | X3 | X4 | Fraud data label counts |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Client 1 | yes |  | yes |  | No (Non-Fraud)= 70% |'
  prefs: []
  type: TYPE_TB
- en: '| Client 2 |  | yes |  | yes | Yes (Fraud)= 100% |'
  prefs: []
  type: TYPE_TB
- en: '| Client 3 | yes | yes | yes | yes | Yes (Fraud) = 50%, No (Non-Fraud)=50%
    |'
  prefs: []
  type: TYPE_TB
- en: Table 6.2 – Feature and label data skewness at different clients
  prefs: []
  type: TYPE_NORMAL
- en: Learning objective
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In FL, the central server takes on the responsibility of executing the learning
    objective and minimizing the loss function. It achieves this by leveraging the
    model weights (*Wt*) and biases received from the participating clients. The server
    determines the number of rounds of data it needs from the clients and the specific
    clients that need to participate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider an example where there are three clients involved in the FL
    process. Each client sends its respective model weights and biases to the central
    server. The server then performs the following objective or learning function
    to minimize the loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '*minimize loss (**Wt, biases)*'
  prefs: []
  type: TYPE_NORMAL
- en: The objective of the server is to optimize the model parameters, represented
    by the weights (*Wt*) and biases, to minimize the loss function. By utilizing
    the received weights and biases from the participating clients, the server performs
    iterative updates to refine the model and improve its performance.
  prefs: []
  type: TYPE_NORMAL
- en: The specific details of the learning objective and loss function depend on the
    specific ML algorithm and the task at hand. The central server orchestrates the
    aggregation of client updates, manages the training process, and sends back the
    updated model to the clients. This collaborative approach enables the clients
    to collectively contribute their local knowledge while benefiting from the improved
    global model provided by the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the objective function:'
  prefs: []
  type: TYPE_NORMAL
- en: Min f(w) = ∑ i=1 n   £i * Fi(w)
  prefs: []
  type: TYPE_NORMAL
- en: Here, *w* is the model parameters (weights, and so on), *f(w)* is the objective
    function, and *n* is the number of clients participating in FL.
  prefs: []
  type: TYPE_NORMAL
- en: A few more mathematical terms will be used in the next section including the
    following.
  prefs: []
  type: TYPE_NORMAL
- en: '*Wt*: Model weights in the communication round *t* (client to server)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Wt k*: Model weights in the communication round on client *k*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*C*: The number of clients participating in each round to update the model
    and compute the weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*B*: The local clients’ batch size of the data samples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Pk*: The set of data samples at client *k*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*nk*: The number of data points at client *k*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*fi (w)*: *loss L ( xi, yi, w)* – the loss function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the server side, various objective functions can be implemented, depending
    on the specific requirements and goals of the FL process.
  prefs: []
  type: TYPE_NORMAL
- en: FL algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: FL algorithms, such as FedSGD, FedAvg, and Adaptive Federated Optimization,
    play a crucial role in the distributed training of ML models while ensuring privacy
    and security. In this section, we will explore these algorithms and their key
    characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: FedSGD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Federated stochastic gradient descent** (**FedSGD**) is a fundamental algorithm
    used in FL. It extends the traditional SGD optimization method to the federated
    setting. In FedSGD, each client (entity) computes the gradients on its local data
    and sends them to the central server. The server aggregates the gradients and
    updates the global model parameters accordingly. FedSGD is efficient for large-scale
    distributed training but may suffer from issues related to non-IID data and communication
    efficiency.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – The FedSGD model weights exchange with the server](img/B16573_06_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – The FedSGD model weights exchange with the server
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the FedSGD algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Server-side algorithm** | **Client-side algorithm** |'
  prefs: []
  type: TYPE_TB
- en: '| Initialize weights (w0)for each round t = 1,2, …m = max (C, K, 1)st = random
    set of m clientsfor client k in st,wt+1 = client-side function (k, wt)wt+1 = average
    of weights | Client-side function (k, w):'
  prefs: []
  type: TYPE_NORMAL
- en: Split the data in *k* batches, with each batch based on the batch size *B* (complete
    local dataset)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For each batch:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: fi (w) = loss L (xi, yi, w)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: w = w – learning rate * loss
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.3 - FedSGD Algorithem
  prefs: []
  type: TYPE_NORMAL
- en: 'On the client side, each participating client performs the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data partitioning**: Clients have their own local datasets and partition
    them into smaller subsets to ensure privacy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Local model training**: Each client independently trains the shared model
    using its local data. This involves computing the gradients of the model parameters
    (weights and biases) on the local dataset using SGD or a variant.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model update**: After the local model training, the client sends the computed
    gradients to the server for aggregation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the server side, the central server performs the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Aggregation**: The server receives the gradients from all participating clients
    and aggregates them using various aggregation techniques, such as averaging or
    weighted averaging.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model update**: The aggregated gradients are used to update the global model’s
    parameters. The server applies the received gradients to the global model, adjusting
    its weights and biases to reflect the collective knowledge from all clients.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model distribution**: The updated global model is then sent back to the clients
    for the next round of training, ensuring that each client benefits from the collective
    knowledge while preserving data privacy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: FedSGD aims to minimize the communication overhead between the clients and the
    server by exchanging only the model gradients rather than the raw data. This allows
    for distributed model training while maintaining data privacy and security. However,
    it is important to address challenges such as data heterogeneity and non-IID data
    distribution, which can impact the convergence and performance of the FL process.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, FedSGD enables collaborative model training in a decentralized manner,
    leveraging the computational resources of multiple clients while preserving data
    privacy. It serves as a foundational algorithm for FL and has paved the way for
    more advanced techniques to improve the efficiency and effectiveness of distributed
    ML.
  prefs: []
  type: TYPE_NORMAL
- en: FedAvg
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Federated averaging** (**FedAvg**) is a widely adopted FL algorithm designed
    to address the challenges of non-IID data and communication efficiency. In FedAvg,
    similar to FedSGD, each client computes the gradients on its local data. However,
    instead of directly updating the global model with the individual gradients, FedAvg
    employs weighted averaging to combine the client models’ parameters. This approach
    allows for better handling of data heterogeneity and reduces the communication
    overhead between the clients and the server.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – The FedAvg model weights exchange with the server](img/B16573_06_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – The FedAvg model weights exchange with the server
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the FedAvg algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Server-side algorithm** | **Client-side algorithm** |'
  prefs: []
  type: TYPE_TB
- en: '| Initialize weights (w0)for each round t = 1,2, …m = max (C, K, 1)st = random
    set of m clientsfor client k in st,wt+1 = client-side function (k, wt)wt+1 = average
    of gradients | Client-side function (k, w):'
  prefs: []
  type: TYPE_NORMAL
- en: Split the data into *k* batches, with each batch based on the batch size *B*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each epoch in training E
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For each batch:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: fi (w) = loss L (xi, yi, w)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: w = w – learning rate * loss
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.4 – FedAVG Algorithm
  prefs: []
  type: TYPE_NORMAL
- en: FedAvg leverages the concept of averaging to combine the locally trained models
    of different clients, which helps mitigate the impact of data heterogeneity and
    non-IID data distribution. By averaging the model parameters, FedAvg effectively
    creates a global model that captures insights from all participating clients while
    preserving the privacy of individual data. The iterative nature of FedAvg allows
    the shared model to progressively improve with each round of training. As the
    process continues, the global model becomes more refined and represents the collective
    knowledge of all clients.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, FedAvg enables collaborative training of a shared model in a privacy-preserving
    manner. It addresses challenges associated with data privacy and distribution,
    allowing multiple clients to contribute to the model’s improvement without sharing
    their raw data. FedAvg has been instrumental in advancing the field of FL, enabling
    applications in various domains while maintaining data privacy and security.
  prefs: []
  type: TYPE_NORMAL
- en: Fed Adaptative Optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In cross-device FL, a multitude of clients communicate with a central server,
    and each client possesses a unique set of data.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in the context of next-word prediction on phones, different users’
    phones contain distinct word sets based on factors such as country, region, and
    language. However, traditional FL algorithms such as FedSGD and FedAvg may not
    perform optimally when confronted with heterogeneous data from diverse clients.
    The challenge arises from the inherent differences in data distribution and characteristics
    among the clients. Heterogeneous data introduces complexities that can impact
    the convergence and performance of FL algorithms. As a result, handling heterogeneous
    data poses a considerable obstacle compared to scenarios where the clients have
    homogeneous data.
  prefs: []
  type: TYPE_NORMAL
- en: Efforts are being made to address the challenges associated with heterogeneous
    data in cross-device FL.
  prefs: []
  type: TYPE_NORMAL
- en: In order to overcome this, researchers at Google (*Sashank J. Reddi et al.,
    2021*) proposed new adaptative optimizations in the research paper published at
    arxiv.org/abs/2003.00295.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the detailed algorithm (the image is sourced from the preceding URL):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – The Fed Adaptive Optimization algorithm proposed by Google researchers](img/B16573_06_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – The Fed Adaptive Optimization algorithm proposed by Google researchers
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the article for a detailed explanation of the Adaptive Optimization
    algorithm. In a nutshell, the idea is to optimize the communication cost like
    FEDAVG and work in cross-device settings.
  prefs: []
  type: TYPE_NORMAL
- en: The steps involved in implementing FL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the five steps that are typically followed to implement FL.
    There can be alternatives/changes to these steps, but initially, these are the
    steps that need to be followed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The server side – the initialization of the global model**: In this step,
    the server starts and accepts the client requests. Before actually starting the
    server, the model on the server side will be initiated with model parameters.
    Typically, model parameters will be initiated with zeros or from the previous
    checkpoint model.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The server sends model parameters to all or a subset of clients**: In this
    step, the server sends the initial model parameters to all clients (for cross-silo
    FL clients, they will be within the same institutions and may only be numbered
    in the tens) or a subset of clients (in the case of cross-device FL where devices
    are in the millions, the server decides to select only a subset from the total
    devices). Each client will make use of these initial model parameters for the
    local training of the model.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The clients train the model and send the model weights/parameters back to
    the server**: In this step, each client will train the model with their local
    data, making use of the entire local data in one shot, dividing the data into
    several batches, or splitting the data randomly and making use of the different
    splits for different rounds (a multiple rounds of exchanges of model parameters
    between the client and server). The clients will send the model parameters or
    weights only to the server.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The server executes one of the FL algorithms, updates the global model, and
    sends the updated weights to the client for the next round**: In this step, the
    server will run one of the FL algorithms and make use of the weights received
    by the clients to update the global model. In the case of FedAvg, it will calculate
    the weighted average of the weights received from clients and send the updated
    weights back to the client for the next round.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Repeat steps 2 to 4 based on the number of rounds configured**: Repeat *steps
    2* to *4* for each round. If five rounds are configured, then repeat *steps 2*
    to *4* five times, and after the last round, clients will make use of the weights
    received by the server for the final ML model. Clients can make use of these model
    weights either at the end of the last round or in each round and evaluate the
    model’s accuracy with the test data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following sequence diagram shows these steps in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – The steps in the FL sequence diagram](img/B16573_06_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 – The steps in the FL sequence diagram
  prefs: []
  type: TYPE_NORMAL
- en: The sequence diagram shows the detailed interactions between the server and
    the clients participating in the FL, performing four high-level steps as explained
    in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Open source frameworks to implement FL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a few open source frameworks to implement FL at scale. The following
    are some of the most popular.
  prefs: []
  type: TYPE_NORMAL
- en: '**PySyft** ([https://github.com/OpenMined/PySyft](https://github.com/OpenMined/PySyft)),
    developed by OpenMined, is an open source stack that offers secure and private
    data science capabilities in Python. It introduces a separation between private
    data and model training, enabling functionalities such as FL, differential privacy,
    and encrypted computation. Initially, PySyft utilized the Opacus framework to
    support differential privacy, as discussed in the Differential privacy chapter.
    However, the latest version of PySyft incorporates its own differential privacy
    component to provide enhanced functionality and efficiency in preserving privacy
    while performing data analysis tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Federated
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**TensorFlow Federated** (**TFF**) is a library developed by Google that facilitates
    the training of shared ML models across multiple clients using their local data
    ([https://www.tensorflow.org/federated](https://www.tensorflow.org/federated)).
    TFF consists of two layers – the Federated Core API and the Federated Learning
    API.'
  prefs: []
  type: TYPE_NORMAL
- en: The Federated Core API offers low-level interfaces for tasks such as data serialization,
    distribution communication between the server and clients, and implementation
    of FL algorithms. It provides the foundational components necessary to build FL
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, the Federated Learning API provides a higher-level interface that
    allows users to easily construct FL models or wrap existing models as FL models.
    It offers a set of APIs for training and evaluating models using federated computations
    and datasets. This higher-level interface abstracts away some of the complexities
    involved in building and training FL models, making it more accessible and convenient
    for developers.
  prefs: []
  type: TYPE_NORMAL
- en: By providing these two layers, TFF empowers researchers and developers to leverage
    the power of FL in their projects. It simplifies the process of building and training
    models on decentralized data while ensuring privacy and data security.
  prefs: []
  type: TYPE_NORMAL
- en: Flower
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Flower** ([https://flower.dev/](https://flower.dev/)) is an open source framework
    that aims to provide a user-friendly experience. It supports ML and DL models
    developed using various frameworks, such as scikit-learn, TensorFlow, PyTorch,
    PyTorch Lightning, MXNet, and JAX. Flower makes it easy to convert these models
    into FL models.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the key features of Flower is its communication implementation, which
    is built on top of bidirectional gRPC streams. This enables an efficient and seamless
    exchange of multiple messages between clients and the server without the need
    to establish a new connection for each message request.
  prefs: []
  type: TYPE_NORMAL
- en: Flower offers a range of strategies and implements several FL algorithms on
    the server side. These algorithms include FedAvg, FedSGD, Fault Tolerance FedAvg,
    FedProxy, and FedOptim (which consists of FedAdagrad, FedYogi, and FedAdam). These
    algorithms provide different approaches to model aggregation and training in FL
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.11 – The Flower framework architecture diagram (simplified)](img/B16573_06_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.11 – The Flower framework architecture diagram (simplified)
  prefs: []
  type: TYPE_NORMAL
- en: To validate its performance, Flower has been extensively benchmarked. The framework
    has demonstrated the ability to scale up to 15 million clients using only two
    GPU servers. These experiments were compared with FedScale, another FL engine
    and benchmark suite, to evaluate Flower’s performance and efficiency in large-scale
    FL settings.
  prefs: []
  type: TYPE_NORMAL
- en: An end-to-end use case of implementing fraud detection using FL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fraud detection is a critical task for many industries, including finance, e-commerce,
    and healthcare. Traditional fraud detection methods often rely on centralized
    data collection, where sensitive customer information is gathered and analyzed
    in a single location. However, this approach raises concerns about data privacy
    and security, as well as compliance with regulations such as the GDPR.
  prefs: []
  type: TYPE_NORMAL
- en: FL offers a promising solution to address these challenges. By leveraging the
    power of distributed computing and collaborative learning, FL enables fraud detection
    models to be trained directly on the devices or local servers of individual institutions,
    without the need for data sharing. This decentralized approach ensures that sensitive
    customer data remains private and secure, as it never leaves the local environment.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing fraud detection using FL involves several key steps. Firstly, a
    consortium of institutions or organizations, such as banks or e-commerce platforms,
    need to establish an FL framework that enables them to collaborate on model training
    while preserving data privacy. This may involve the adoption of FL libraries or
    platforms such as TFF or Flower.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the participating institutions define a common fraud detection objective
    and develop a shared model architecture. Each institution then trains its local
    model using its own private data, which may include transaction records, user
    behavior patterns, and other relevant features. The models are trained locally,
    ensuring that sensitive data remains under the control of the respective institutions.
  prefs: []
  type: TYPE_NORMAL
- en: To facilitate collaborative learning, the institutions periodically share model
    updates with a central server. These updates, which typically include model weights
    and parameters, are aggregated using federated averaging or other aggregation
    techniques to create a global model that captures insights from all participants,
    while preserving the privacy of individual data.
  prefs: []
  type: TYPE_NORMAL
- en: The central server, which oversees the aggregation process, ensures that the
    global model is refined based on the collective knowledge of the participating
    institutions. This process allows the model to learn from a diverse range of fraud
    patterns and adapt to evolving fraudulent activities while maintaining data privacy
    and compliance with regulations.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing fraud detection using FL offers several advantages. It allows institutions
    to leverage a larger and more diverse dataset, leading to improved fraud detection
    accuracy. It also reduces the risks associated with data breaches or unauthorized
    access, since sensitive data remains under the control of the respective institutions.
    Additionally, FL enables real-time updates and faster model deployment, allowing
    institutions to respond quickly to emerging fraud patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing fraud detection using FL offers a privacy-preserving and collaborative
    approach to combat fraud in various industries. By combining the power of distributed
    computing and shared learning, organizations can enhance fraud detection capabilities
    while safeguarding sensitive customer data.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s implement this use case using the Flower framework and the open source
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Developing an FL model for fraud detection using the Flower framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this example, we will leverage the Flower framework to develop an FL model
    for fraud detection. The implementation will involve both server-side and client-side
    components. To illustrate the process, we will set up one server and two clients.
  prefs: []
  type: TYPE_NORMAL
- en: The communication between the server and clients will occur over several rounds,
    with the exchange of weights and parameters. The exact number of rounds may vary
    depending on the specific scenario, but typically, the communication continues
    until the weights converge or a predetermined convergence criterion is met.
  prefs: []
  type: TYPE_NORMAL
- en: On the server side, we will implement the FedAvg algorithm to aggregate the
    weights received from the clients. FedAvg is a widely used algorithm in FL that
    combines the knowledge from multiple clients to create a global model.
  prefs: []
  type: TYPE_NORMAL
- en: For the fraud detection task, we will develop an actual linear regression model
    using the scikit-learn library. This model will be trained using the data available
    at each client, which consists of transaction records and relevant features. The
    goal is to classify whether a transaction is fraudulent or not.
  prefs: []
  type: TYPE_NORMAL
- en: The client-side implementation will involve training the local linear regression
    models using the respective client’s data. The clients will then communicate with
    the server, exchanging their model weights and parameters over the predefined
    rounds. This collaborative learning process allows the clients to contribute their
    local insights to the global model while preserving the privacy of their data.
  prefs: []
  type: TYPE_NORMAL
- en: The server will receive the model updates from the clients and perform the aggregation
    step using the FedAvg algorithm. This aggregation process ensures that the global
    model incorporates the knowledge learned from all the participating clients, resulting
    in an enhanced fraud detection capability.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the implementation, the Flower framework provides the necessary infrastructure
    for the communication between the server and clients. It abstracts the underlying
    complexities of distributed computing and handles the synchronization of model
    updates. By developing an FL model for fraud detection, we can leverage the distributed
    knowledge and data from multiple clients to improve the accuracy of fraud classification.
    The federated approach also addresses privacy concerns by keeping the sensitive
    transaction data local to each client.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, this project demonstrates the implementation of an FL model using
    the Flower framework. The server and clients collaborate to train a global model
    for fraud detection, exchanging model weights and parameters over multiple communication
    rounds. By aggregating the client models using FedAvg, we can leverage the collective
    intelligence of multiple participants while ensuring data privacy.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset used in the example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Lopez, Elmir, and Axelsson* developed a mobile money dataset for fraud detection,
    and it is featured on Kaggle as well (E. A. Lopez-Rojas, A. Elmir, and S. Axelsson,
    *PaySim: A financial mobile money simulator for fraud detection*, 28th European
    Modeling and Simulation Symposium-EMSS, Larnaca, Cyprus. 2016).'
  prefs: []
  type: TYPE_NORMAL
- en: We will make use of this dataset for the detection of fraud using FL, but the
    same can be extended to anti-money laundering use cases as well, with minor changes
    to the model. The dataset can be found at [https://github.com/EdgarLopezPhD/PaySim](https://github.com/EdgarLopezPhD/PaySim).
  prefs: []
  type: TYPE_NORMAL
- en: Download this dataset and keep the file in the [*Chapter 6*](B16573_06_split_000.xhtml#_idTextAnchor120)
    directory with the name `PS_20174392719_1491204439457_log.csv`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This dataset consists of 6.3 million records of transactions and has the following
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Field** | **Data type** | **Details** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `Step` | Numerical | The unit of time in the real world. One step is 1 hour.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `Type` | Object | `CASH-IN`, `CASH-OUT`, `DEBIT`, `PAYMENT`, and `TRANSFER`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `Amount` | Numerical | The amount of the transaction. |'
  prefs: []
  type: TYPE_TB
- en: '| `nameOrig` | Object | The customer who started the transaction. |'
  prefs: []
  type: TYPE_TB
- en: '| `nameDest` | Object | The recipient ID of the transaction. |'
  prefs: []
  type: TYPE_TB
- en: '| `oldbalanceOrg` | Numerical | The initial balance before the transaction.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `newbalanceOrig` | Numerical | The customer’s balance after the transaction.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `oldbalanceDest` | Numerical | The initial recipient’s balance before the
    transaction. |'
  prefs: []
  type: TYPE_TB
- en: '| `newbalanceDest` | Numerical | The recipient’s balance after the transaction.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `isFraud` | Boolean | Identifies fraudulent (`1`) and non-fraudulent (`0`)
    transactions. |'
  prefs: []
  type: TYPE_TB
- en: '| `isFlaggedFraud` | Boolean | Flags illegal attempts to transfer more than
    200,000 amount in a single transaction. |'
  prefs: []
  type: TYPE_TB
- en: Table 6.5 – The dataset features
  prefs: []
  type: TYPE_NORMAL
- en: The installation of Flower
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Install Flower using the `python -m pip install` `flwr` command.
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of a server
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The server-side implementation of the FL model for fraud detection involves
    several high-level steps. We will utilize the sample code provided by the Flower
    framework and extend it to fit our specific use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps outline the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Initialize the** **model parameters**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the initial model weights to **0** and initialize the intercept as **0**
    (since we are working with a regression model).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine the number of classes or labels for classification.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine the number of features used in the model.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine the number of participating clients.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Define the supporting functions**: Develop additional functions to load the
    data from clients, define the loss function, and evaluate the model’s performance.
    These functions will help facilitate data handling, calculate the loss during
    training, and assess the model’s accuracy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Choose the server-side strategy**: Select the FedAvg algorithm as the strategy
    to aggregate the weights received from the clients. FedAvg is a popular choice
    to combine model updates from multiple clients and generate an updated global
    model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Start** **the server**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initiate the server-side component, which will orchestrate the FL process.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The server will communicate with the participating clients, receive their model
    updates, and aggregate the weights using the FedAvg algorithm.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It will also handle the synchronization of the model updates between the clients
    and ensure the convergence of the global model.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: By following these steps, we can implement the server-side functionality of
    our FL model. The initialization of model parameters, definition of supporting
    functions, selection of the server-side strategy (FedAvg), and starting the server
    itself are crucial in facilitating the collaborative training process among the
    clients. Through this implementation, the server will act as the central coordinator,
    receiving and aggregating the model updates from the clients. It plays a crucial
    role in ensuring the model’s convergence and generating an updated global model
    that incorporates the knowledge from all participating clients.
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the following code as `FL_AML_Server.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Dataset information with few rows and columns](img/B16573_06_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.12 – Dataset information with few rows and columns
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of using all 6 million records, we will use only the first 25,000 records
    in this example implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s find the data types of each field in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Encode the object data type fields as labels using `LabelEncoder`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Open a terminal and run this program (`python3 FL_AML_Server.py`)
  prefs: []
  type: TYPE_NORMAL
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.13 – Server startup logs](img/B16573_06_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.13 – Server startup logs
  prefs: []
  type: TYPE_NORMAL
- en: Server will run and wait for data from clients to process.
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of clients
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The client-side implementation of the FL model for fraud detection involves
    the following steps. We will utilize the provided `NumPyClient` from the Flower
    samples. The steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load** **the data**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load the relevant data to train and test the fraud detection model.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure the data is properly formatted and available for processing.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Split** **the data**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Split the loaded data into training and testing sets. This division allows you
    to evaluate the model’s performance on unseen data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Shuffle/partition** **the data**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Shuffle or partition the training data into batches.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Randomly select a partition for each round of communication with the server.
    This ensures that different subsets of the training data are used in each round.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Create the linear** **regression model**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Develop a simple linear regression model using the chosen framework (for example,
    scikit-learn).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure the model with appropriate settings for the fraud detection task.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Establish a connection with** **the server**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Establish a connection with the server to send and receive model weights.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Utilize the provided communication protocol (for example, gRPC) to exchange
    information.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Train** **the model**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize the model with the initial weights received from the server.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model using the client’s local data and the weights updated by the
    server for each round.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply appropriate optimization techniques (for example, gradient descent) to
    update the model parameters.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Test** **the model**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the trained model using the testing data to assess its performance.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate relevant metrics such as accuracy, precision, recall, or F1 score.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine the model’s effectiveness in detecting fraudulent transactions.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: By following these steps, we can implement the client-side functionality of
    the FL model. The client will load and partition the data, create the linear regression
    model, establish a connection with the server, train the model using local data
    and updated weights, and evaluate its performance. The client’s role is crucial
    in contributing local knowledge while preserving data privacy. By training on
    their respective local data and participating in the FL process, clients collectively
    improve the global fraud detection model without sharing sensitive information.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a non-IID dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To transform the dataset into a non-IID setting, we can apply the following
    approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '**First client (****client 1)**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply the **Synthetic Minority Oversampling Technique** (**SMOTE**) to oversample
    the fraud transactions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This technique generates synthetic examples of the minority class (fraudulent
    transactions) to balance the dataset
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: As a result, client 1 will have a training dataset with 50,000 samples, consisting
    of 25,000 original transactions and 25,000 synthetic fraud examples created using
    SMOTE
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The distribution of fraud versus non-fraud transactions will be balanced at
    50% for each class
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Second client (****client 2)**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leave the transactions as they are without any oversampling or modification
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Client 2 will have a training dataset with the last 25,000 transactions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The class distribution will reflect the original distribution, with only 2%
    of the transactions classified as fraud
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By employing this approach, we introduce non-identical and imbalanced datasets
    across the two clients. Client 1 will have a balanced dataset with equal representation
    of fraud and non-fraud transactions, while client 2 will have a dataset that mirrors
    the original distribution.
  prefs: []
  type: TYPE_NORMAL
- en: This non-IID setup allows us to simulate real-world scenarios where different
    clients may have varying distributions of data. Through FL, both clients can contribute
    their local knowledge while training their models on distinct datasets, ultimately
    improving the overall fraud detection model.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Client 1 | Client 2 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Original transactions | 25,000 | 25,000 |'
  prefs: []
  type: TYPE_TB
- en: '| Transactions generated using SMOTE | 25,000 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Total transactions | 50,000 | 25,000 |'
  prefs: []
  type: TYPE_TB
- en: '| Fraud versus non-fraud | 50% and 50% | Fraud: 2.43%(608)Non-fraud: 97.57%
    (24,392) |'
  prefs: []
  type: TYPE_TB
- en: '| Train and test split | 70:30 | 70:30 |'
  prefs: []
  type: TYPE_TB
- en: '| Number of partitions after shuffling the train data with equal size in each
    partition | 10 | 10 |'
  prefs: []
  type: TYPE_TB
- en: Table 6.6 – Training data distribution on the client side as non-IID data
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code for client 1\. Save this code as `FL_AML_Client1.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In this dataset, fraudulent transactions account for 0.33% of the total data,
    indicating a highly imbalanced dataset. This imbalance is typical in real-world
    scenarios, where fraud transactions are much less frequent compared to genuine
    (non-fraud) transactions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Encode the object types as labels using sci-kit learn’s `LabelEncoder`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply SMOTE to generate synthetic data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Open a second terminal and run the client 1 code (`python3 FL_AML_Client1.py`)
  prefs: []
  type: TYPE_NORMAL
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14 – The execution of client 1 and the logs](img/B16573_06_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.14 – The execution of client 1 and the logs
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s look at the code for client 2\. Save this code as `FL_AML_Client2.py`.
    The client 2 code will be the same as client 1, but fraud transactions are not
    increased using the SMOTE method. For thoroughness, here is the complete code
    for the second client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Encode the object types as labels using sci-kit learn’s `LabelEncoder`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Open another terminal and run the client 2 code (`python3 FL_AML_Client2.py`):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15 – Running client 2 and the logs](img/B16573_06_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.15 – Running client 2 and the logs
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you run the client 2 code, pay close attention to the log statements on
    the server side. The server will initiate communication with both clients, enabling
    the exchange of the initial parameters and, subsequently, the updated weights
    for each round. Monitoring the server logs will provide insights into the progress
    of the FL process and the information shared between the clients and the server:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16 – The server-side logs](img/B16573_06_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.16 – The server-side logs
  prefs: []
  type: TYPE_NORMAL
- en: 'Observe the logs on both clients as well as the server side. These metrics
    provide an overview of the loss (indicating the model’s performance) and accuracy
    (representing the model’s correctness) for each client across multiple rounds
    of the FL process:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Server** | **Client 1** | **Client 2** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| INFO flwr 2023-03-14 17:46:49,202 &#124; app.py:139 &#124; Starting Flower
    server, config: ServerConfig(num_rounds=5, round_ timeout=None)INFO flwr 2023-03-14
    17:51:21,810 &#124; server.py:101 &#124; FL starting |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | DEBUG flwr 2023-03-14 17:51:21,778 &#124; connection.py:38 &#124; ChannelConnectivity.READY
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | ChannelConnectivity. DEBUG flwr 2023-03-14 17:53:46,338 &#124; connection.py:38
    &#124; ChannelConnectivity.READY |'
  prefs: []
  type: TYPE_TB
- en: '| DEBUG flwr 2023-03-14 17:53:46,338 &#124; server.py:215 &#124; fit_round
    1: strategy sampled 2 clients (out of 2)DEBUG flwr 2023-03-14 17:53:46,351 &#124;
    server.py:229 &#124; fit_round 1 received 2 results and 0 failuresWARNING flwr
    2023-03-14 17:53:46,354 &#124; fedavg.py:242 &#124; No fit_metrics_aggregation_fn
    providedINFO flwr 2023-03-14 17:53:46,362 &#124; server.py:116 &#124; fit progress:
    (1, 0.06756539217831908, {‘accuracy’: 0.9962666666666666}, 144.549737353)DEBUG
    flwr 2023-03-14 17:53:46,363 &#124; server.py:165 &#124; evaluate_round 1: strategy
    sampled 2 clients (out of 2)DEBUG flwr 2023-03-14 17:53:46,377 &#124; server.py:179
    &#124; evaluate_round 1 received 2 results and 0 failures |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| INFO flwr 2023-03-14 17:53:46,400 &#124; server.py:116 &#124; fit progress:
    (2, 0.40485776608772656, {‘accuracy’: 0.9633333333333334}, 144.58791799899996)
    |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| INFO flwr 2023-03-14 17:53:46,432 &#124; server.py:116 &#124; fit progress:
    (3, 0.11833075507570899, {‘accuracy’: 0.9962666666666666}, 144.61946266499996)
    |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| INFO flwr 2023-03-14 17:53:46,465 &#124; server.py:116 &#124; fit progress:
    (4, 0.1145626928425223, {‘accuracy’: 0.9962666666666666}, 144.65267561899998)
    |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| INFO flwr 2023-03-14 17:53:46,497 &#124; server.py:116 &#124; fit progress:
    (5, 0.27867744042157033, {‘accuracy’: 0.9861333333333333}, 144.68508043599996)
    |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| INFO flwr 2023-03-14 17:53:46,511 &#124; app.py:202 &#124; app_fit: losses_distributed
    [(1, 0.4398987330496311), (2, 0.4606742262840271), (3, 0.5105149038136005), (4,
    0.5070083439350128), (5, 0.5951354652643204)] |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Training finished for round 1:0.06756539217831908 0.9962666666666666Training
    finished for round 2:0.40485776608772656 0.9633333333333334Training finished for
    round 3:0.11833075507570899 0.9962666666666666Training finished for round 4:0.1145626928425223
    0.9962666666666666Training finished for round 5:0.27867744042157033 0.9861333333333333
    | Training finished for round 1:0.8122320748323023 0.9745333333333334Training
    finished for round 2:0.5164906830160562 0.9541333333333334Training finished for
    round 3:0.9026990471833415 0.9745333333333334Training finished for round 4:0.8994540131249842
    0.9745333333333334Training finished for round 5:0.9115935132282235 0.9736 |'
  prefs: []
  type: TYPE_TB
- en: '|  | DEBUG flwr 2023-03-14 17:53:46,521 &#124; connection.py:109 &#124; gRPC
    channel closedINFO flwr 2023-03-14 17:53:46,522 &#124; app.py:153 &#124; Disconnect
    and shut down | DEBUG flwr 2023-03-14 17:53:46,521 &#124; connection.py:109 &#124;
    gRPC channel closedINFO flwr 2023-03-14 17:53:46,522 &#124; app.py:153 &#124;
    Disconnect and shut down |'
  prefs: []
  type: TYPE_TB
- en: Table 6.8 – Log data at Server and Clients
  prefs: []
  type: TYPE_NORMAL
- en: As per the log, there are 5 rounds of communication between clients and the
    server, and in each round, accuracy results and loss change based on the weights.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Client 1** | **Loss** | **Accuracy** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Round 1 | 0.06756539217831908 | 0.9962666666666666 |'
  prefs: []
  type: TYPE_TB
- en: '| Round 2 | 0.40485776608772656 | 0.9633333333333334 |'
  prefs: []
  type: TYPE_TB
- en: '| Round 3 | 0.11833075507570899 | 0.9962666666666666 |'
  prefs: []
  type: TYPE_TB
- en: '| Round 4 | 0.1145626928425223 | 0.9962666666666666 |'
  prefs: []
  type: TYPE_TB
- en: '| Round 5 | 0.27867744042157033 | 0.9861333333333333 |'
  prefs: []
  type: TYPE_TB
- en: Table 6.9 – Accuracy and Loss metrics at Client 1
  prefs: []
  type: TYPE_NORMAL
- en: As per the debug logs, loss and accuracy vary on client 1\. Let’s observe the
    loss and accuracy results on Client 2 as well.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Client 2** | **Loss** | **Accuracy** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Round 1 | 0.8122320748323023 | 0.9745333333333334 |'
  prefs: []
  type: TYPE_TB
- en: '| Round 2 | 0.5164906830160562 | 0.9541333333333334 |'
  prefs: []
  type: TYPE_TB
- en: '| Round 3 | 0.9026990471833415 | 0.9745333333333334 |'
  prefs: []
  type: TYPE_TB
- en: '| Round 4 | 0.8994540131249842 | 0.9745333333333334 |'
  prefs: []
  type: TYPE_TB
- en: '| Round 5 | 0.9115935132282235 | 0.9736 |'
  prefs: []
  type: TYPE_TB
- en: Table 6.10 – Accuracy and Loss metrics at Client 2
  prefs: []
  type: TYPE_NORMAL
- en: We have implemented a sample fraud detection application using Federated Learning
    and made use of open-source frameworks like Flower. In the next section, let’s
    try to learn and implement federated learning using differential privacy.
  prefs: []
  type: TYPE_NORMAL
- en: FL with differential privacy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Federated Learning with Differential Privacy** (**FL-DP**) is an approach
    that combines the principles of FL and **Differential Privacy** (**DP**) to ensure
    privacy and security in distributed ML systems. FL-DP aims to protect sensitive
    data while enabling collaborative model training across multiple devices or entities.'
  prefs: []
  type: TYPE_NORMAL
- en: The goal of FL-DP is to achieve accurate model training without compromising
    the privacy of individual data contributors. It addresses the challenge of preventing
    data leakage during the aggregation of model updates from different participants.
    By incorporating DP techniques, FL-DP provides strong privacy guarantees by adding
    noise or perturbation to the model updates or gradients before aggregating them.
  prefs: []
  type: TYPE_NORMAL
- en: There are different approaches to implementing FL-DP. One common approach involves
    each client training a local ML model using their own data. The client applies
    techniques such as clipping and noise addition to the gradients or weights of
    the model. The client then sends the updated data to the server. On the server
    side, the updates are aggregated while preserving privacy using techniques such
    as secure aggregation or privacy-preserving FL algorithms. This ensures that individual
    client data remains private while enabling collaborative model training.
  prefs: []
  type: TYPE_NORMAL
- en: FL-DP algorithms may vary depending on the specific differential privacy mechanisms
    used, such as Gaussian noise addition, subsampling, or advanced techniques such
    as **Private Aggregation of Teacher Ensembles** (**PATE**). The choice of techniques
    depends on the level of privacy required and the characteristics of the distributed
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing FL-DP requires careful consideration of privacy, accuracy, and
    computational overhead. It involves striking a balance between preserving privacy
    and maintaining model utility. Various frameworks and libraries, such as Flower
    and TensorFlow Privacy, provide tools and techniques to facilitate the implementation
    of FL-DP.
  prefs: []
  type: TYPE_NORMAL
- en: FL-DP has the potential to unlock the benefits of collaborative ML in scenarios
    where data privacy and security are paramount. By preserving privacy, FL-DP enables
    organizations and individuals to collaborate on model training while safeguarding
    sensitive information.
  prefs: []
  type: TYPE_NORMAL
- en: FL-DP provides a way to implement privacy-preserving techniques in the FL process,
    ensuring that client-side data remains protected.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will explore two general approaches to implementing FL-DP,
    although specific frameworks and implementations may have slight variations.
  prefs: []
  type: TYPE_NORMAL
- en: Approach one
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This approach shares similarities with **Differentially Private Federated Averaging**
    (**DP-FedAvg**), which was introduced by the Google research team. By following
    these approaches, FL-DP allows you to train ML models on client data while preserving
    privacy through techniques such as clipping and noise addition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each client does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Trains an ML/DL model using its local data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Computes gradients/weights using a standard SGD algorithm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Applies clipping to the weights to limit their sensitivity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Adds noise to the weights to introduce randomness and privacy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sends the modified weights to the server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The server does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Computes the average of the weights received from each client.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Broadcasts back the updated weights to the clients.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alternatively to step 1, applies clipping and adds noise to the final weights
    before broadcasting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.17 – The DP-FedAvg model weights exchanged with the server](img/B16573_06_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.17 – The DP-FedAvg model weights exchanged with the server
  prefs: []
  type: TYPE_NORMAL
- en: In this approach, each client trains its model on local data and work on the
    updated average weights sent by the server.
  prefs: []
  type: TYPE_NORMAL
- en: Approach two
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this approach, each client trains its model on local data and applies privacy-preserving
    techniques to compute the gradients/weights. The server then incorporates these
    noisy weights and performs aggregation using the FD-SGD algorithm, ensuring privacy
    is maintained throughout the FL process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each client does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Trains an ML model using its local data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Computes the gradients/weights using either noisy SGD or DP-SGD (DP stochastic
    gradient) algorithms, which incorporate noise during gradient computation to preserve
    privacy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sends the weights to the server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The server does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Utilizes the noisy weights received from the clients.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Follows the **Federated Differential SGD** (**FD-SGD**) algorithm, which incorporates
    privacy-preserving techniques during the aggregation process on the server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.18 – The DP-FedSGD model weights exchanged with the server](img/B16573_06_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.18 – The DP-FedSGD model weights exchanged with the server
  prefs: []
  type: TYPE_NORMAL
- en: There are various variants of Differential Privacy Federated Learning (FL-DP)
    algorithms designed to address different scenarios, such as cross-device and cross-silo
    FL, with both homogeneous and heterogeneous data. In our implementation, we will
    apply FL-DP to the same example as before, ensuring privacy preservation throughout
    the FL process.
  prefs: []
  type: TYPE_NORMAL
- en: A sample application using FL-DP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the time of writing, the Flower framework (version 1.3) currently offers
    experimental support for FL-DP. It provides a strategy class (similar to FedAvg,
    FedYogi, and so on) specifically designed to support FL-DP. The class name designed
    to support this is `DPFedAvg`.
  prefs: []
  type: TYPE_NORMAL
- en: The `DPFedAvg` class in the Flower framework is a component specifically designed
    to support FL-DP. It extends the functionality of the FedAvg algorithm by incorporating
    differential privacy techniques to protect the privacy of individual client data
    during model aggregation.
  prefs: []
  type: TYPE_NORMAL
- en: '`DPFedAvg` implements a privacy-preserving mechanism that ensures the privacy
    of client updates while enabling collaborative model training. It achieves this
    by adding noise or perturbation to the model updates or gradients received from
    each client, before aggregating them on the server side.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The key features and functionalities of the `DPFedAvg` class include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**DP**: **DPFedAvg** integrates DP techniques into the FL process, ensuring
    that the privacy of individual client data is preserved during model training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Noise addition**: **DPFedAvg** applies noise to the gradients or model updates
    received from each client before aggregating them. The amount of noise added is
    determined based on privacy parameters and privacy budget allocation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Privacy budget management**: **DPFedAvg** incorporates mechanisms to manage
    and allocate the privacy budget effectively, ensuring that the desired privacy
    guarantees are maintained throughout the training process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Privacy parameters**: **DPFedAvg** allows users to customize the privacy
    parameters such as privacy budget, noise distribution, and sensitivity of the
    model updates. These parameters enable fine-grained control over the level of
    privacy and utility trade-off.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model aggregation**: **DPFedAvg** performs the aggregation of client updates
    using the DP averaging algorithm. This ensures that the privacy of individual
    updates is preserved while generating an updated global model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compatibility with the Flower framework**: **DPFedAvg** is designed to seamlessly
    integrate with the Flower framework, allowing users to incorporate DP into their
    FL pipelines using the existing Flower infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By using the `DPFedAvg` class in the Flower framework, developers and ML engineers
    can implement FL-DP straightforwardly and efficiently. It provides a powerful
    tool to ensure privacy in distributed ML scenarios while maintaining the collaborative
    benefits of FL.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through the Flower-provided class in detail.
  prefs: []
  type: TYPE_NORMAL
- en: The DPFedAvgFixed class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This class is a wrapper class and adds clipping and Gaussian noise to the weights.
    The constructor of this class supports parameters to set server-side noise, a
    clip norm value, and the noise multiplier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use this class on the server side. The server code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The source code of the Jupyter notebooks for the server and clients is located
    in the [*Chapter* *6*](B16573_06_split_000.xhtml#_idTextAnchor120) folder:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Server code: **Fed-DP-AML-Server.ipynb**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Client 1 code: **DP-FL-AML_Client1.ipynb**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Client 2 code: **DP-FL-AML-Client2.ipynb**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s look at the accuracy of the model for the clients and server:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Client 1** | **Client 2** | **Server** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0.99626666666666660.71626666666666670.98760.93720.7714666666666666 | 0.97453333333333340.59786666666666670.96933333333333340.94480.7708
    | 0.99626666666666660.71626666666666670.98760.93720.7714666666666666 |'
  prefs: []
  type: TYPE_TB
- en: Table 6.11 – Accracy results at Sever and Clients
  prefs: []
  type: TYPE_NORMAL
- en: Applying DP to FL introduces some overhead in terms of computational cost, communication
    overhead, and potentially reduced model performance. In our example case, by the
    fourth round, the accuracy was 93%, but in the fifth round, the accuracy suddenly
    dropped. This tells us that we need to monitor the accuracy during training to
    help us decide on the number of rounds each client needs to participate in and
    stop further rounds when the accuracy drops.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explained why FL is needed and looked at its definition
    and characteristics in detail. We covered the steps involved in implementing FL
    and discussed IID and non-IID datasets and FL algorithms. We implemented a sample
    application using an open source FL framework. Finally, we converted the same
    application using DP.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about FL benchmarks and look at key start-ups
    that are working on or already have FL products.
  prefs: []
  type: TYPE_NORMAL
