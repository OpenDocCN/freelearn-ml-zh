- en: '*Chapter 9*: Implementing a Batch Scoring Solution'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第9章*：实现批量评分解决方案'
- en: You have trained regression, classification, and forecasting models with AutoML
    in Azure, and now it's time you learn how to put them in production and use them.
    **Machine learning** (**ML**) models, after all, are ultimately used to make predictions
    on new data, either in real time or in batches. In order to score new data points
    in batches in Azure, you must first create an ML pipeline.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经在Azure中用AutoML训练了回归、分类和预测模型，现在是时候学习如何将它们投入生产并使用了。毕竟，**机器学习**（**ML**）模型最终是用来对新数据进行预测的，无论是在实时还是在批量中。为了在Azure中批量评分新数据点，你必须首先创建一个机器学习管道。
- en: An ML pipeline lets you run repeatable Python code in the **Azure Machine Learning
    services** (**AMLS**) that you can run on a schedule. While you can run any Python
    code using an ML pipeline, here you will learn how to build pipelines for scoring
    new data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道允许你在**Azure机器学习服务**（**AMLS**）中运行可重复的Python代码，你可以在计划中运行这些代码。虽然你可以使用机器学习管道运行任何Python代码，但在这里，你将学习如何构建用于评分新数据的管道。
- en: You will begin this chapter by writing a simple ML pipeline to score data using
    the multiclass classification model you trained on the Iris dataset in [*Chapter
    5*](B16595_05_ePub.xhtml#_idTextAnchor068), *Building an AutoML Classification
    Solution*. Using the same data, you will then learn how to score new data points
    in parallel, enabling you to quickly score models with millions to billions of
    data points simultaneously.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 你将从此章节开始，编写一个简单的机器学习管道，使用在[*第5章*](B16595_05_ePub.xhtml#_idTextAnchor068)“构建AutoML分类解决方案”中训练的Iris数据集的多分类模型来评分数据。使用相同的数据，你将学习如何并行评分新的数据点，从而让你能够快速同时评分包含数百万到数十亿数据点的模型。
- en: Once you have written these two pipelines, you will learn how to create an ML
    pipeline for retraining an AutoML model. Finally, you will learn how to retrigger
    ML pipelines both manually through the GUI and programmatically through the **Azure
    ML SDK**.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦编写了这两个管道，你将学习如何创建用于重新训练AutoML模型的机器学习管道。最后，你将学习如何通过GUI手动和通过**Azure ML SDK**编程方式重新触发机器学习管道。
- en: By the end of this chapter, you will be able to not only train AutoML models
    but also use them to score new data in a reproducible, automatable fashion. Furthermore,
    the code and techniques you learn here apply to all ML models, not just those
    that are AutoML-generated. Coding batch scoring solutions is a key skill for any
    ML engineer, and by working through the exercises in this chapter, you will be
    well on your way to mastering that skill.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你不仅能够训练AutoML模型，而且能够以可重复、可自动化的方式使用它们来评分新数据。此外，你在这里学到的代码和技术适用于所有机器学习模型，而不仅仅是AutoML生成的模型。编写批量评分解决方案是任何机器学习工程师的关键技能，通过完成本章的练习，你将朝着掌握这一技能迈出重要一步。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Creating an ML pipeline
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建机器学习管道
- en: Creating a parallel scoring pipeline
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建并行评分管道
- en: Creating an AutoML training pipeline
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建AutoML训练管道
- en: Triggering and scheduling your ML pipelines
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 触发和安排你的机器学习管道
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter will feature a lot of coding using Jupyter notebooks within AMLS.
    Thus, you will need a working internet connection, an **AMLS workspace**, and
    a **compute instance**. ML pipelines also require a **compute cluster**. You will
    also need to have trained and registered the Iris multiclass classification model
    in [*Chapter 5*](B16595_05_ePub.xhtml#_idTextAnchor068), *Building an AutoML Classification
    Solution*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将使用AMLS中的Jupyter笔记本进行大量编码。因此，你需要一个有效的互联网连接、一个**AMLS工作空间**和一个**计算实例**。机器学习管道还需要一个**计算集群**。你还需要在[*第5章*](B16595_05_ePub.xhtml#_idTextAnchor068)“构建AutoML分类解决方案”中训练并注册Iris多分类模型。
- en: 'The following are the prerequisites for the chapter:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的先决条件如下：
- en: Access to the internet.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问互联网。
- en: A web browser, preferably Google Chrome or Microsoft Edge Chromium.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个网络浏览器，最好是Google Chrome或Microsoft Edge Chromium。
- en: A Microsoft Azure account.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Microsoft Azure账户。
- en: Have created an AMLS workspace.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已创建一个AMLS工作空间。
- en: Have created the `compute-cluster` compute cluster in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service*.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[*第2章*](B16595_02_ePub.xhtml#_idTextAnchor023)，“Azure机器学习服务入门”中创建了`compute-cluster`计算集群。
- en: Understand how to navigate to the Jupyter environment from an Azure compute
    instance as demonstrated in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution*.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解如何从 Azure 计算实例导航到 Jupyter 环境的方法，如 [*第 4 章*](B16595_04_ePub.xhtml#_idTextAnchor056)，*构建
    AutoML 回归解决方案* 中所示。
- en: Have trained and registered the `Iris-Multi-Classification-AutoML` ML model
    in [*Chapter 5*](B16595_05_ePub.xhtml#_idTextAnchor068), *Building an AutoML Classification
    Solution*.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [*第 5 章*](B16595_05_ePub.xhtml#_idTextAnchor068)，*构建 AutoML 分类解决方案* 中训练并注册了
    `Iris-Multi-Classification-AutoML` 机器学习模型。
- en: 'The code for this chapter is available here: [https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter09](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter09).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码在此处可用：[https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter09](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter09)。
- en: Creating an ML pipeline
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个机器学习流程
- en: ML pipelines are Azure's solution for batch scoring ML models. You can use ML
    pipelines to score any model you train, including your own custom models as well
    as AutoML-generated models. They can only be created via code using the Azure
    ML Python SDK. In this section, you will code a simple pipeline to score diabetes
    data using the `Diabetes-AllData-Regression-AutoML` model you built in [*Chapter
    4*](B16595_04_ePub.xhtml#_idTextAnchor056), *Building an AutoML Regression Solution*.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习流程是 Azure 的批量评分机器学习模型的解决方案。你可以使用机器学习流程来评分你训练的任何模型，包括你自己的自定义模型以及 AutoML 生成的模型。它们只能通过使用
    Azure ML Python SDK 的代码来创建。在本节中，你将编写一个简单的流程来使用你在 [*第 4 章*](B16595_04_ePub.xhtml#_idTextAnchor056)，*构建
    AutoML 回归解决方案* 中构建的 `Diabetes-AllData-Regression-AutoML` 模型来评分糖尿病数据。
- en: As in other chapters, you will begin by opening your compute instance and navigating
    to your Jupyter notebook environment. You will then create and name a new notebook.
    Once your notebook is created, you will build, configure, and run an ML pipeline
    step by step. After confirming your pipeline has run successfully, you will then
    publish your ML pipeline to a pipeline endpoint. **Pipeline endpoints** are simply
    URLs, web addresses that call ML pipeline runs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如其他章节所述，你将首先打开你的计算实例并导航到你的 Jupyter 笔记本环境。然后创建并命名一个新的笔记本。一旦你的笔记本创建完成，你将逐步构建、配置和运行一个机器学习流程。确认你的流程成功运行后，你将然后发布你的机器学习流程到流程端点。**流程端点**只是
    URL，是调用机器学习流程运行的网页地址。
- en: The following steps deviate greatly from previous chapters. You will have to
    load in many more libraries and also write a custom Python file for scoring new
    data. You will also learn how to create **environments**, that is, artifacts that
    specify which Python packages, package versions, and software settings you are
    using.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤与之前的章节有很大不同。你将需要加载更多的库，并编写一个用于评分新数据的自定义 Python 文件。你还将学习如何创建 **环境**，即指定你使用的
    Python 包、包版本和软件设置的工件。
- en: 'In addition to creating an environment, you will need to containerize it. Finally,
    you will need to configure and run your ML pipeline, completing the process by
    publishing your pipeline to an endpoint. The entire process is shown in *Figure
    9.1*:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 除了创建环境之外，你还需要对其进行容器化。最后，你需要配置并运行你的机器学习流程，通过将流程发布到端点来完成整个过程。整个过程在 *图 9.1* 中展示：
- en: '![Figure 9.1 – Steps involved in creating your ML scoring pipeline ](img/Figure_9.1_B16595.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.1 – 创建你的机器学习评分流程所涉及的步骤](img/Figure_9.1_B16595.jpg)'
- en: Figure 9.1 – Steps involved in creating your ML scoring pipeline
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – 创建你的机器学习评分流程所涉及的步骤
- en: The `ML-Scoring-Pipeline.ipynb` file in the GitHub repository contains the code
    for all the steps.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub 仓库中的 `ML-Scoring-Pipeline.ipynb` 文件包含了所有步骤的代码。
- en: Coding the first three steps of your ML scoring pipeline
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写你的机器学习评分流程的前三个步骤
- en: 'First, load in your libraries, set up your AMLS resources, and create a dataset
    to score with the following steps:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，加载你的库，设置你的 AMLS 资源，并按照以下步骤创建一个用于评分的数据集：
- en: Open **Azure Machine Learning studio** (**AML studio**) by navigating to [https://ml.azure.com/](https://ml.azure.com/).
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过导航到 [https://ml.azure.com/](https://ml.azure.com/) 打开 **Azure 机器学习工作室**（**AML
    工作室**）。
- en: Click **Compute** and start up a compute instance. Any compute instance will
    work, as they all link to the same Jupyter notebook environment.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **计算** 并启动一个计算实例。任何计算实例都可以，因为它们都链接到相同的 Jupyter 笔记本环境。
- en: Create a new Jupyter notebook and name it `machine-learning-pipeline`. If you
    need a refresher on how to do this, please review [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution*.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的 Jupyter 笔记本，并将其命名为 `machine-learning-pipeline`。如果你需要复习如何做这件事，请查阅 [*第4章*](B16595_04_ePub.xhtml#_idTextAnchor056)，*构建AutoML回归解决方案*。
- en: 'Open your newly created notebook and begin by importing all of the standard
    Azure libraries you will need using the following code:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开你刚刚创建的笔记本，并开始使用以下代码导入你将需要的所有标准 Azure 库：
- en: '[PRE0]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056), *Building an AutoML Regression
    Solution*, explains `Workspace`, `Dataset`, `Datastore`, `Experiment`, and `ComputeTarget`.
    `Environment` lets you create an object that contains information on which Python
    packages your ML pipeline will need to install to run successfully. `Model` lets
    you retrieve your previously trained ML models.'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[*第4章*](B16595_04_ePub.xhtml#_idTextAnchor056)，*构建AutoML回归解决方案*，解释了 `Workspace`、`Dataset`、`Datastore`、`Experiment`
    和 `ComputeTarget`。`Environment` 允许你创建一个对象，其中包含有关你的 ML 管道需要安装哪些 Python 包以成功运行的信息。`Model`
    允许你检索之前训练的 ML 模型。'
- en: 'Continuing on, import all of the Azure ML pipeline libraries with the following
    code:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续导入所有 Azure ML 管道库，使用以下代码：
- en: '[PRE1]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`RunConfiguration` stores information that your ML pipeline will need to run,
    including the environment and base image. `CondaDependencies` lets you add Python
    packages to your environment. `Default_CPU_Image` is needed to specify which base
    image you will use in your run configuration. `PythonScriptStep` is a type of
    `Pipeline` is the core package to build ML pipelines. `PublishedPipeline` lets
    you publish ML pipelines to endpoints. `StepSequence` lets you set the order of
    your ML pipeline steps and `RunDetails` simply shows you the output of your ML
    pipeline as it runs.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`RunConfiguration` 存储了你的 ML 管道运行所需的信息，包括环境和基础镜像。`CondaDependencies` 允许你向环境中添加
    Python 包。`Default_CPU_Image` 用于指定你在运行配置中将要使用的基础镜像。`PythonScriptStep` 是 `Pipeline`
    类型，是构建 ML 管道的核心包。`PublishedPipeline` 允许你将 ML 管道发布到端点。`StepSequence` 允许你设置 ML 管道步骤的顺序，而
    `RunDetails` 则简单地显示你的 ML 管道在运行时的输出。'
- en: Important note
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'If you are having trouble loading any Azure libraries, update the Azure ML
    SDK by running the `Update AzureML SDK.ipynb` notebook found here: [https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb).'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你加载任何 Azure 库时遇到困难，请通过运行此处找到的 `Update AzureML SDK.ipynb` 笔记本来更新 Azure ML SDK：[https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb)。
- en: 'Import `pandas`, `numpy`, and `os`. `os` will let you create and manipulate
    files and folders from your Jupyter notebook. `random` will let you generate random
    numbers, which is useful for simulating new Iris data:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas`、`numpy` 和 `os`。`os` 允许你从 Jupyter 笔记本中创建和操作文件和文件夹。`random` 允许你生成随机数，这对于模拟新的鸢尾花数据很有用：
- en: '[PRE2]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Connect your Jupyter notebook to your AMLS workspace:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将你的 Jupyter 笔记本连接到你的 AMLS 工作区：
- en: '[PRE3]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you are prompted to log in, follow the instructions.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你被提示登录，请按照说明操作。
- en: 'Set your compute cluster to the one you created in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service*:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将你的计算集群设置为你在 [*第2章*](B16595_02_ePub.xhtml#_idTextAnchor023)，*Azure 机器学习服务入门*
    中创建的那个：
- en: '[PRE4]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Set your datastore:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置你的数据存储：
- en: '[PRE5]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, you will create simulated Iris data to score. Begin by creating four
    variables that contain a list of numbers based on the minimum and maximum values
    of the original Iris dataset with the following code. These variables contain
    all the possible values contained within the Iris dataset:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你将创建用于评分的模拟鸢尾花数据。首先，使用以下代码创建四个变量，这些变量包含基于原始鸢尾花数据集最小值和最大值的数字列表。这些变量包含鸢尾花数据集中所有可能的值：
- en: '[PRE6]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Continuing with the creation of simulated Iris data, create an empty `pandas`
    DataFrame called IrisDF, with the appropriate column names. Also, create an empty
    list called `IrisList`:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建模拟的鸢尾花数据集的过程中继续，创建一个名为 IrisDF 的空 `pandas` DataFrame，并包含适当的列名。同时，创建一个名为 `IrisList`
    的空列表：
- en: '[PRE7]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Continuing with the creation of simulated Iris data, use the `choice` function
    from the `random` package within a `for` loop to create 100 new data points, rounding
    each value to `1` decimal place.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建模拟的鸢尾花数据集的过程中继续，使用 `random` 包中的 `choice` 函数在 `for` 循环中创建 100 个新的数据点，并将每个值四舍五入到
    `1` 位小数。
- en: 'Combine each set of four data points with the column names in a Python dictionary
    within the `for` loop and append that dictionary to `IrisList` row by row:'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 `for` 循环中，将每组四个数据点与 Python 字典中的列名组合，并将该字典逐行追加到 `IrisList`：
- en: '[PRE8]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This code will leave you with a list of randomly generated values from the original
    Iris dataset that can be turned into a `pandas` DataFrame.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此代码将为您留下从原始 Iris 数据集中随机生成的值列表，这些值可以转换为 `pandas` DataFrame。
- en: 'Completing the creation of simulated Iris data, append `IrisList` to `IrisDF`:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成模拟 Iris 数据的创建，将 `IrisList` 追加到 `IrisDF`：
- en: '[PRE9]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Register your simulated Iris data with the following code:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码注册您的模拟 Iris 数据：
- en: '[PRE10]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This will save it to your datastore and create an Azure dataset named `Iris
    Scoring`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这将将其保存到您的数据存储中，并创建一个名为 `Iris Scoring` 的 Azure 数据集。
- en: Creating a Python script to score data in your ML pipeline
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个用于在您的机器学习管道中评分数据的 Python 脚本
- en: 'In this section, you will create a folder and write a Python script that your
    ML pipeline will execute to score data using the following steps:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将创建一个文件夹并编写一个 Python 脚本，您的机器学习管道将执行该脚本以评分数据，具体步骤如下：
- en: 'Make a folder to hold your scoring script using `os`:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `os` 创建一个用于存放评分脚本的文件夹：
- en: '[PRE11]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: For every ML pipeline step you make, you have to have an accompanying Python
    script.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于您做出的每个机器学习管道步骤，您都必须有一个相应的 Python 脚本。
- en: Write a Python script to score new data. This script is long and has to be one
    block of code. Begin by writing out a new Python script file called `Iris_Scoring.py`
    using the `%%writefile` magic command. `Run` lets your program access the AMLS
    workspace you used to create the ML pipeline while running remotely on a compute
    cluster.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个用于评分新数据的 Python 脚本。此脚本很长，必须是一段代码块。首先，使用 `%%writefile` 魔法命令编写一个新的 Python
    脚本文件，名为 `Iris_Scoring.py`。`Run` 允许您的程序在远程计算集群上运行时访问您用于创建机器学习管道的 AMLS 工作区。
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, import the other
    Python packages:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Scoring.py` 的同一单元格中继续，导入其他 Python 包：
- en: '[PRE12]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The only new package here is `joblib`, which will let you load saved ML models.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里唯一的新包是 `joblib`，它将允许您加载保存的机器学习模型。
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, set a variable called
    `run` using the `Run` function. You can use this variable to set your AMLS workspace:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Scoring.py` 的同一单元格中继续，使用 `Run` 函数设置一个名为 `run` 的变量。您可以使用此变量设置您的 AMLS
    工作区：
- en: '[PRE13]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Continuing in the same cell as part of `Iris_Scoring.py`, we are going to create
    a function called `main`. This function will run the main part of your scoring
    code.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Scoring.py` 的同一单元格中继续，我们将创建一个名为 `main` 的函数。此函数将运行您的评分代码的主要部分。
- en: 'First, connect to your AMLS workspace using the `run` variable you created.
    Next, set your datastore to the default option and your dataset to `Iris Scoring`.
    Convert the `Iris Scoring` dataset into a `pandas` DataFrame called `scoringDF`:'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，使用您创建的 `run` 变量连接到您的 AMLS 工作区。接下来，将数据存储设置为默认选项，并将数据集设置为 `Iris Scoring`。将
    `Iris Scoring` 数据集转换为名为 `scoringDF` 的 `pandas` DataFrame：
- en: '[PRE14]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, load your `Iris-Multi-Classification-AutoML`
    model with the Azure `Model` and `joblib` packages:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Scoring.py` 的同一单元格中继续，使用 Azure 的 `Model` 和 `joblib` 包加载您的 `Iris-Multi-Classification-AutoML`
    模型：
- en: '[PRE15]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, use your model to
    make predictions on `scoringDF`, save those predictions to a `pandas` `Series`,
    and add the predictions back to your `scoringDF` DataFrame in a new column called
    `Prediction`:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Scoring.py` 的同一单元格中继续，使用您的模型对 `scoringDF` 进行预测，将这些预测保存到 `pandas` 的 `Series`
    中，并将这些预测添加到您的 `scoringDF` DataFrame 的新列 `Prediction` 中：
- en: '[PRE16]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: When you add the new column, the predictions will be in the correct order and
    match the corresponding row.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当您添加新列时，预测将按正确顺序排列，并与相应的行匹配。
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, make a folder called
    `Output_Folder` using `os`:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Scoring.py` 的同一单元格中继续，使用 `os` 创建一个名为 `Output_Folder` 的文件夹：
- en: '[PRE17]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This will create a folder on your compute cluster to store your predictions
    temporarily so you can transfer them to your datastore.
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将在您的计算集群上创建一个文件夹，用于临时存储您的预测，以便您可以将其传输到您的数据存储。
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, specify a file called
    `Iris_Predictions.csv`. Then, use `os` to specify a path on the compute cluster
    where you will write that file out. Finally, use `to_csv` to write out `scoringDF`
    to your compute cluster:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Scoring.py` 的同一单元格中继续，指定一个名为 `Iris_Predictions.csv` 的文件。然后，使用 `os` 在计算集群上指定一个路径，您将在此路径上写入该文件。最后，使用
    `to_csv` 将 `scoringDF` 写入您的计算集群：
- en: '[PRE18]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This piece of code will write your output to your compute cluster. This is necessary
    to move it into your datastore.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码将您的输出写入您的计算集群。这是必要的，以便将其移动到您的数据存储中。
- en: Continuing in the same cell as part of `Iris_Scoring.py`, upload `Iris_Predictions.csv`
    to your datastore. This code will write it to a folder called `Output_Folder`,
    matching the directory structure on your compute cluster.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Scoring.py` 的同一单元格中继续，将 `Iris_Predictions.csv` 上传到您的数据存储。此代码将将其写入名为
    `Output_Folder` 的文件夹中，与您的计算集群上的目录结构相匹配。
- en: '[PRE19]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Completing `Iris_Scoring.py`, use `os` to remove the file and folder from your
    compute cluster. Finish the cell with boilerplate code that will automatically
    run your `main` function when the Python script is called within the ML pipeline:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成 `Iris_Scoring.py` 后，使用 `os` 从您的计算集群中删除文件和文件夹。使用模板代码完成单元格，当Python脚本在ML管道中调用时，将自动运行您的
    `main` 函数：
- en: '[PRE20]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This completes your Python script. Write the next piece of code in a new cell.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了您的Python脚本。在新的单元格中编写下一段代码。
- en: Creating and containerizing an environment
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建和容器化环境
- en: 'The difficult part is over and the rest is pure boilerplate, beginning with
    creating an environment. **Environments** are collections of Python packages that
    are required to run your code:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 困难的部分已经结束，剩下的都是纯模板代码，从创建环境开始。**环境**是运行您的代码所需的Python包的集合：
- en: 'In a new cell, create an environment. Also, set a variable using `CondaDependencies`:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新单元格中创建一个环境。同时，使用 `CondaDependencies` 设置一个变量：
- en: '[PRE21]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: All the packages and versions of packages that are required to run your Python
    script will be added to the `conda_dep` variable in the next step.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在下一步中，将运行您的Python脚本所需的全部包及其版本添加到 `conda_dep` 变量中。
- en: 'Attach Python packages to your `conda_dep` variable, beginning with the packages
    found in the `conda` package manager:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将Python包附加到您的 `conda_dep` 变量中，从 `conda` 包管理器中找到的包开始：
- en: '[PRE22]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: There are two package managers, `conda` and `pip`. `conda` automatically resolves
    dependencies for you. So, if a package requires another package, you don't have
    to worry about it. `pip` requires you to resolve those dependencies yourself.
    As a result, if a package is available in both `conda` and `pip`, always install
    it via `conda`.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有两个包管理器，`conda` 和 `pip`。`conda` 会自动为您解决依赖问题。因此，如果一个包需要另一个包，您无需担心。`pip` 则要求您自己解决这些依赖。结果，如果一个包在
    `conda` 和 `pip` 中都可用，请始终通过 `conda` 安装它。
- en: When installing packages, always specify the version. You can discover which
    version you are using by running the `!pip freeze` command in an empty cell. In
    addition to `numpy`, `joblib`, and `pandas`, AutoML-generated models also require
    `packaging` and `xgboost` to run.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在安装包时，始终指定版本。您可以通过在空单元格中运行 `!pip freeze` 命令来发现您正在使用哪个版本。除了 `numpy`、`joblib`
    和 `pandas` 之外，AutoML生成的模型还需要 `packaging` 和 `xgboost` 来运行。
- en: 'Attach Python packages to your `conda_dep` variable that are not available
    in `conda` using `pip` instead:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pip` 而不是 `conda` 将不可在 `conda` 中找到的Python包附加到您的 `conda_dep` 变量中：
- en: '[PRE23]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: There are three packages; `azureml-defaults` enables you to use standard Azure
    ML SDK functions, while `azureml-automl-core` and `azureml-automl-runtime` are
    required to score any AutoML-generated models.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有三个包；`azureml-defaults` 允许您使用标准的Azure ML SDK函数，而 `azureml-automl-core` 和 `azureml-automl-runtime`
    是评分任何AutoML生成的模型所必需的。
- en: 'Add the `conda_dep` variable to your environment and register the environment
    to your AMLS workspace by using the following code:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `conda_dep` 变量添加到您的环境中，并使用以下代码将环境注册到您的AMLS工作区：
- en: '[PRE24]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Now that your environment is registered, you can call it anywhere in AMLS.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在您的环境已注册，您可以在AMLS的任何地方调用它。
- en: 'Create a `RunConfiguration` object for containerizing your environment. Set
    your environment, enable Docker, and use `DEFAULT_CPU_IMAGE` as your base image:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的环境创建一个 `RunConfiguration` 对象以进行容器化。设置您的环境，启用Docker，并使用 `DEFAULT_CPU_IMAGE`
    作为基础镜像：
- en: '[PRE25]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This will create a **Docker container**, a portable package of code that can
    be run anywhere as it contains all your code's scripts and dependencies. Your
    environment can now be utilized by your ML pipeline, which you will configure
    in the last series of steps.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个 **Docker容器**，一个包含所有代码脚本和依赖项的可移植包，可以在任何地方运行。现在，您的环境可以通过您的ML管道使用，您将在最后一系列步骤中进行配置。
- en: Configuring and running your ML scoring pipeline
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置和运行您的ML评分管道
- en: 'With your environment built and containerized, your Python script written,
    and all your AMLS resources set, you''re ready to configure and run your ML pipeline
    by following these steps:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的环境构建并容器化，你的 Python 脚本编写完毕，以及所有你的 AMLS 资源设置完成后，你就可以按照以下步骤配置和运行你的机器学习流程：
- en: 'Configure your ML pipeline step with the following code. You need to give your
    step a name, `iris-scoring-step`, and specify your Python script name, Python
    script folder location, compute target, and run configuration. Always set `allow_reuse`
    to `False`:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码配置你的机器学习流程步骤。你需要给你的步骤起一个名字，`iris-scoring-step`，并指定你的 Python 脚本名称、Python
    脚本文件夹位置、计算目标和运行配置。始终将 `allow_reuse` 设置为 `False`：
- en: '[PRE26]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Setting `allow_reuse` to `True` is for debugging multi-step pipelines where
    you want to skip rerunning a successfully completed step.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将 `allow_reuse` 设置为 `True` 是为了调试多步骤流程，其中你希望跳过重新运行已成功完成的步骤。
- en: 'Set your **step sequence** and **pipeline object**:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置你的 **步骤序列** 和 **流程对象**：
- en: '[PRE27]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The step sequence is the order in which your ML pipeline steps will run.
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 步骤序列是你的机器学习流程步骤将运行的顺序。
- en: 'Give your pipeline experiment run a name, `Iris-Scoring-Pipeline-Run`, and
    submit it with the following code:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给你的流程实验运行起一个名字，`Iris-Scoring-Pipeline-Run`，并使用以下代码提交：
- en: '[PRE28]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Finally, this is what kicks your pipeline off!
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，这是启动你的流程的关键步骤！
- en: 'Use `RunDetails` to watch your pipeline get built and execute in real time:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `RunDetails` 来实时观察你的流程构建和执行：
- en: '[PRE29]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'As it runs, you will see a lot of logs. If your pipeline runs successfully,
    it will complete with the words **Finished**. You should see a graphic identical
    to the one in *Figure 9.2*:'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在运行过程中，你会看到很多日志。如果你的流程运行成功，它将以 **完成** 的字样结束。你应该看到一个与 *图 9.2* 中相同的图形：
- en: '![Figure 9.2 – Successful pipeline run graphic ](img/Figure_9.2_B16595.jpg)'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 9.2 – 成功的流程运行图形](img/Figure_9.2_B16595.jpg)'
- en: Figure 9.2 – Successful pipeline run graphic
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.2 – 成功的流程运行图形
- en: 'Publish your pipeline to an endpoint with the following code, specifying a
    name, description, and version number:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码将你的流程发布到端点，指定一个名称、描述和版本号：
- en: '[PRE30]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'All published pipelines require version numbers set by the creator. Running
    this code will give you a published pipeline ID as well as a link to the endpoint,
    as seen in *Figure 9.3*:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有已发布的流程都需要由创建者设置的版本号。运行此代码将给你一个已发布的流程 ID 以及一个访问端点的链接，如图 *图 9.3* 所示：
- en: '![Figure 9.3 – Successfully published pipeline ](img/Figure_9.3_B16595.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.3 – 成功发布的流程](img/Figure_9.3_B16595.jpg)'
- en: Figure 9.3 – Successfully published pipeline
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 – 成功发布的流程
- en: Now that you have executed and published your scoring pipeline, you can examine
    and download your scoring file. It was saved to a folder called `Output_Folder`
    in a file called `Iris_Predictions.csv`. Access the file directly by navigating
    to your storage account. You can do this either from the Azure portal ([https://portal.azure.com](https://portal.azure.com))
    or via **AML** **studio**.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经执行并发布了你的评分流程，你可以检查并下载你的评分文件。它被保存在一个名为 `Output_Folder` 的文件夹中，文件名为 `Iris_Predictions.csv`。通过导航到你的存储账户来直接访问该文件。你可以从
    Azure 门户（[https://portal.azure.com](https://portal.azure.com)）或通过 **AML** **工作室**
    来这样做。
- en: Accessing your scored predictions via AML studio
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过 AML 工作室访问你的评分预测
- en: To access `Iris_Predictions.csv` and download it to your desktop, you first
    have to locate your storage account. You can find your storage account through
    AML studio.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问 `Iris_Predictions.csv` 并将其下载到你的桌面，你首先必须定位你的存储账户。你可以通过 AML 工作室找到你的存储账户。
- en: 'The following steps will have you locate your datastore through the AML studio,
    access your storage account, navigate to the correct file, and download it to
    your local machine. This way, you can use the AI-generated predictions for any
    purpose you wish:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将指导你通过 AML 工作室定位你的数据存储，访问你的存储账户，导航到正确的文件，并将其下载到你的本地机器。这样，你可以使用 AI 生成的预测来完成任何你希望的目的：
- en: Navigate to AML studio at [https://ml.azure.com](https://ml.azure.com).
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 AML 工作室 [https://ml.azure.com](https://ml.azure.com)。
- en: Click **Datastores** on the left-hand panel.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击左侧面板上的 **Datastores**。
- en: Click the blue link to **workspaceblobstore** (default) in the center of the
    page.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击页面中央的蓝色链接到 **workspaceblobstore**（默认）。
- en: Click the blue link to your storage account under `automlexamplew` followed
    by a string of numbers. This will take you to your storage account resource in
    Azure.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击页面下方 `automlexamplew` 后跟一串数字的蓝色链接到你的存储账户。这将带你到 Azure 中的存储账户资源。
- en: Once in your storage account, click the blue link to **Containers** in the center-left
    of your screen. Clicking anywhere in the box will work.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦在你的存储账户中，点击屏幕中央左上角的蓝色链接到 **容器**。
- en: You will now see a list of folders. Click the folder that begins with `azureml-blobstore-`
    followed by a unique identifier ID.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你现在将看到一个文件夹列表。点击以 `azureml-blobstore-` 开头并跟有一个唯一标识符 ID 的文件夹。
- en: Click `azureml`, `managed-dataset`, and `UI`. These folders hold logs for your
    experiments, among other objects. *Figure 9.4* shows the folder structure you
    need to follow to reach your file:![Figure 9.4 – Path to your output files ](img/Figure_9.4_B16595.jpg)
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击屏幕中央左边的 `azureml`、`managed-dataset` 和 `UI`。这些文件夹包含你的实验日志以及其他对象。*图 9.4* 展示了你需要遵循的文件夹结构以到达你的文件：![图
    9.4 – 输出文件的路径](img/Figure_9.4_B16595.jpg)
- en: Figure 9.4 – Path to your output files
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.4 – 输出文件的路径
- en: Click **Iris_Predictions.csv**.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Iris_Predictions.csv**。
- en: Click the `Iris_Predictions.csv` to your local machine. It is a comma-separated
    file with headers.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `Iris_Predictions.csv` 添加到你的本地机器。它是一个带有标题的逗号分隔文件。
- en: Open up your file with Microsoft Excel or similar software to look at your data.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Microsoft Excel 或类似软件打开你的文件，查看你的数据。
- en: That was a lot of work, but now you have a working pipeline endpoint that can
    score new data points in batch. This is a huge accomplishment, as many organizations
    have trouble setting up such workflows. You can also easily reuse this code in
    multiple projects, as the vast majority is boilerplate. While you have to alter
    the Python script and add packages as appropriate, this template can also be used
    to score both AutoML and custom ML models.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一项繁重的工作，但现在你有一个可以批量评分新数据点的有效管道端点。这是一个巨大的成就，因为许多组织在设置此类工作流程时遇到困难。你还可以轻松地在多个项目中重用此代码，因为其中绝大多数是样板代码。虽然你必须修改
    Python 脚本并添加适当的包，但此模板也可以用于评分 AutoML 和自定义机器学习模型。
- en: Next, you will learn how to score 10,000,000 data points in no time at all using
    a parallel scoring pipeline.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将学习如何使用并行评分管道在极短的时间内评分 1000 万个数据点。
- en: Creating a parallel scoring pipeline
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建并行评分管道
- en: Standard ML pipelines work just fine for the majority of ML use cases, but when
    you need to score a large amount of data at once, you need a more powerful solution.
    That's where `ParallelRunStep` comes in. `ParallelRunStep` is Azure's answer to
    scoring big data in batch. When you use `ParallelRunStep`, you leverage all of
    the cores on your compute cluster simultaneously.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 标准机器学习管道对于大多数机器学习用例来说效果很好，但当你需要一次性评分大量数据时，你需要一个更强大的解决方案。这就是 `ParallelRunStep`
    的作用。`ParallelRunStep` 是 Azure 对批量评分大数据的回应。当你使用 `ParallelRunStep` 时，你可以同时利用计算集群上的所有核心。
- en: Say you have a compute cluster consisting of eight `Standard_DS3_v2` virtual
    machines. Each `Standard_DS3_v2` node has four cores, so you can perform 32 parallel
    scoring processes at once. This parallelization essentially lets you score data
    many times faster than if you used a single machine. Furthermore, it can easily
    scale vertically (increasing the size of each virtual machine in the cluster)
    and horizontally (increasing the node count).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个由八个 `Standard_DS3_v2` 虚拟机组成的计算集群。每个 `Standard_DS3_v2` 节点有四个核心，因此你可以一次性执行
    32 个并行评分过程。这种并行化实际上让你比使用单台机器快得多地评分数据。此外，它还可以轻松地进行垂直扩展（增加集群中每个虚拟机的大小）和水平扩展（增加节点数量）。
- en: This section will allow you to become a *big data* scientist who can score large
    batches of data. Here, you will again be using simulated Iris data, but instead
    of 100 rows, you will be scoring 10 million rows at once.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将帮助你成为一名能够评分大量数据的 *大数据* 科学家。在这里，你将再次使用模拟的 Iris 数据，但不是 100 行，而是一次性评分 1000 万行。
- en: Furthermore, this is an advanced solution that utilizes two pipeline steps,
    a step that scores data in parallel and a step that transfers data to an output
    folder. By working through this example, you'll understand how to create advanced
    multi-step pipeline runs to solve difficult problems.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这是一个利用两个管道步骤的高级解决方案，一个步骤是并行评分数据，另一个步骤是将数据传输到输出文件夹。通过完成这个示例，你会了解如何创建高级多步骤管道运行来解决复杂问题。
- en: Important note
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Parallel runs score data in batches, dividing your dataset into many small parts.
    If you have any data preprocessing that relies on calculations made with previous
    rows, this preprocessing should be done in a separate `PythonScriptStep` before
    being passed on to `ParallelRunStep`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 并行运行以批处理方式评分数据，将您的数据集分成许多小部分。如果您有任何依赖于之前行计算的数据预处理，则应在传递到 `ParallelRunStep` 之前在单独的
    `PythonScriptStep` 中完成此预处理。
- en: 'Much of this code is similar to the *Creating an ML pipeline* section. However,
    there are two pipeline steps to create instead of one. Furthermore, you will be
    introduced to new concepts such as `input` and `output` pipeline configuration
    options. At the end of this section, you will also publish your pipeline to an
    endpoint. *Figure 9.5* shows the entire process:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的大部分与 *创建机器学习管道* 部分类似。然而，您需要创建两个管道步骤而不是一个。此外，您将接触到新的概念，例如 `输入` 和 `输出` 管道配置选项。在本节的末尾，您还将发布您的管道到端点。*图
    9.5* 展示了整个流程：
- en: '![Figure 9.5 – Steps involved in creating a parallel scoring pipeline  ](img/Figure_9.5_B16595.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.5 – 创建并行评分管道涉及的步骤](img/Figure_9.5_B16595.jpg)'
- en: Figure 9.5 – Steps involved in creating a parallel scoring pipeline
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 – 创建并行评分管道涉及的步骤
- en: If you need a refresher on any of the steps, please refer to the *Creating an
    ML pipeline* section. You can find the code for all the steps in the `ML-Parallel-Pipeline.ipynb`
    file in the GitHub repository.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要任何步骤的复习，请参阅 *创建机器学习管道* 部分。您可以在 GitHub 仓库中找到所有步骤的代码，位于 `ML-Parallel-Pipeline.ipynb`
    文件。
- en: Coding the first three steps of your ML parallel scoring pipeline
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写您的机器学习并行评分管道的前三个步骤
- en: 'To create your parallel scoring pipeline, begin with the following steps:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建您的并行评分管道，请从以下步骤开始：
- en: Navigate to your Jupyter environment on your compute instance and create a new
    Jupyter notebook. Name it `ml-parallel-pipeline`.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到您的计算实例上的 Jupyter 环境，创建一个新的 Jupyter 笔记本。将其命名为 `ml-parallel-pipeline`。
- en: 'Open your newly created notebook and import your standard Azure libraries:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开您新创建的笔记本并导入您的标准 Azure 库：
- en: '[PRE31]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'From `azureml.core.compute`, import `ComputeTargetNext` and import all of the
    Azure ML pipeline libraries with the following code:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `azureml.core.compute` 导入 `ComputeTargetNext` 并使用以下代码导入所有 Azure ML 管道库：
- en: '[PRE32]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: There are three additional packages compared to the previous section. `ParallelRunStep`
    is an ML pipeline step that lets you run Python code in parallel. `ParallelRunConfig`
    lets you configure `ParallelRunStep`. `PipelineData` lets you pass intermediate
    data from one step to another.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与上一节相比，有三个额外的包。`ParallelRunStep` 是一个机器学习管道步骤，允许您并行运行 Python 代码。`ParallelRunConfig`
    允许您配置 `ParallelRunStep`。`PipelineData` 允许您将中间数据从一个步骤传递到另一个步骤。
- en: Important note
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'If you are having trouble loading any Azure libraries, update the Azure ML
    SDK by running the `Update AzureML SDK.ipynb` notebook found here: [https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb).'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您在加载任何 Azure 库时遇到问题，请运行此处找到的 `Update AzureML SDK.ipynb` 笔记本以更新 Azure ML SDK：[https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb)。
- en: 'Import `pandas`, `numpy`, `os`, and `random`:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas`、`numpy`、`os` 和 `random`：
- en: '[PRE33]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'As always, connect your Jupyter notebook to your AMLS workspace:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如往常一样，将您的 Jupyter 笔记本连接到您的 AMLS 工作区：
- en: '[PRE34]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: If you are prompted to log in, follow the instructions.
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您被提示登录，请按照说明操作。
- en: 'Set your compute cluster with the following code:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码设置您的计算集群：
- en: '[PRE35]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Set your datastore:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置您的数据存储：
- en: '[PRE36]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Use the following code to create simulated Iris data:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建模拟的 Iris 数据：
- en: '[PRE37]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Continuing with the creation of simulated Iris data, create an empty `pandas`
    DataFrame and list:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续创建模拟的 Iris 数据，创建一个空的 `pandas` DataFrame 和列表：
- en: '[PRE38]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Continuing with the creation of simulated Iris data, use the `choice` function
    from the `random` package within a `for` loop to create 10,000,000 new data points,
    rounding each value to `1` decimal place:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续创建模拟的 Iris 数据，使用 `random` 包中的 `choice` 函数在 `for` 循环中创建 10,000,000 个新的数据点，每个值四舍五入到
    `1` 位小数：
- en: '[PRE39]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This will take a while, so give it some time to run.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将需要一些时间，所以请给它一些运行的时间。
- en: 'Completing the creation of simulated Iris data, append `IrisList` to `IrisDF`:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成模拟 Iris 数据的创建，将 `IrisList` 添加到 `IrisDF`：
- en: '[PRE40]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Register your simulated Iris data with the following code:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码注册您的模拟 Iris 数据：
- en: '[PRE41]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This will save it to your datastore and create an Azure dataset named `Iris
    Parallel Scoring`. You're now ready to write your Python script.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把它保存到你的数据存储中，并创建一个名为`Iris Parallel Scoring`的Azure数据集。你现在可以编写你的Python脚本了。
- en: Creating Python scripts to score data in your ML parallel pipeline
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建用于在您的ML并行管道中评分数据的Python脚本
- en: 'Next, create a folder and write two Python scripts that your ML pipeline will
    execute to score data. You will need one step to make predictions and another
    step to transfer your output to a final destination on your datastore:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个文件夹并编写两个Python脚本，你的ML管道将执行这些脚本来评分数据。你需要一个步骤来做出预测，另一个步骤将你的输出传输到数据存储上的最终目的地：
- en: 'Make a folder to hold your scoring script using `os`:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`os`创建一个文件夹来保存你的评分脚本：
- en: '[PRE42]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This folder should already exist from the previous section, but this code will
    not error out since `exist_ok` is set to `True`. This folder will hold both the
    scripts you will write for your parallel pipeline run.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个文件夹应该已经在上一节中存在，但由于`exist_ok`被设置为`True`，这段代码不会出错。这个文件夹将包含你将为你的并行管道运行编写的脚本。
- en: 'Write a Python script to score new data in parallel:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个Python脚本来并行评分新数据：
- en: '[PRE43]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: This script is significantly different from the previous script, but also has
    to be in one cell. Begin by writing a new Python script file called `Iris_Parallel_Scoring.py`
    using the `%%writefile` magic command. Begin by loading in your Azure libraries.
    You should recognize all of them from the previous section.
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个脚本与之前的脚本有很大不同，但也要在一个单元格中完成。首先，使用`%%writefile`魔法命令编写一个新的Python脚本文件`Iris_Parallel_Scoring.py`。首先加载你的Azure库。你应该能从上一节中认出它们。
- en: 'Continuing in the same cell as part of `Iris_Parallel_Scoring.py`, import other
    Python packages, including the new `argparse` package:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Iris_Parallel_Scoring.py`的同一单元格中继续，导入其他Python包，包括新的`argparse`包：
- en: '[PRE44]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This package lets you pass arguments into your script. **Arguments** are flexible
    pieces of code that you can pass into your pipeline at runtime. For example, you
    can use arguments to pass in different datastores or datasets.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个包允许你在脚本中传递参数。**参数**是灵活的代码片段，你可以在运行时将其传递到你的管道中。例如，你可以使用参数传递不同的数据存储或数据集。
- en: 'Continuing in the same cell as part of `Iris_Parallel_Scoring.py`, set a variable
    called `run` using the `Run` function:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Iris_Parallel_Scoring.py`的同一单元格中继续，使用`Run`函数设置一个名为`run`的变量：
- en: '[PRE45]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Continuing in the same cell as part of `Iris_Parallel_Scoring.py`, create a
    function called `init`. This function will pass in your arguments and load your
    ML model, setting it to a global variable.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Iris_Parallel_Scoring.py`的同一单元格中继续，创建一个名为`init`的函数。这个函数将传递你的参数并加载你的ML模型，将其设置为全局变量。
- en: '`parser` to store your arguments and add the `model_name` argument to that
    variable. `ParallelRunStep` also passes hidden arguments behind the scenes, so
    you also need to set `unknown_args`. Once that is done, use `joblib` to load your
    model using the `model_name` argument, as shown in the following code:'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用`parser`来存储你的参数，并将`model_name`参数添加到该变量中。`ParallelRunStep`在幕后还传递了隐藏的参数，因此你还需要设置`unknown_args`。完成这些后，使用`joblib`通过`model_name`参数加载你的模型，如下面的代码所示：
- en: '[PRE46]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Continuing in the same cell as part of `Iris_Parallel_Scoring.py`, create a
    function called `main`. This function will score your data and return the result,
    which will be automatically stored in a file called `parallel_run_step.txt.model`
    with the Azure `Model` and `joblib` packages.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Iris_Parallel_Scoring.py`的同一单元格中继续，创建一个名为`main`的函数。这个函数将评分你的数据并返回结果，该结果将被自动存储在一个名为`parallel_run_step.txt.model`的文件中，使用Azure的`Model`和`joblib`包。
- en: First, you will use the `predict` function on your `model` variable to make
    predictions. Notice that the data is automatically passed into this function as
    a `pandas` DataFrame called `input_data`.
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，你将使用`model`变量的`predict`函数来做出预测。注意，数据会自动作为名为`input_data`的`pandas` DataFrame传递到这个函数中。
- en: 'You then convert these predictions into a series and add it back to `input_data`
    as a column called `Prediction`. Completing `Iris_Parallel_Scoring.py`, you return
    the finished `input_data` DataFrame to be automatically written to the text file:'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后将这些预测转换为序列，并将其添加回`input_data`作为名为`Prediction`的列。完成`Iris_Parallel_Scoring.py`后，你将返回完成的`input_data`
    DataFrame，它将被自动写入文本文件：
- en: '[PRE47]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Write a Python script to transfer your results to the output location of your
    choice. `ParallelRunStep` outputs a file called `parallel_run_step.txt`. This
    will be stored as pipeline data.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个Python脚本来将你的结果传输到你选择的输出位置。`ParallelRunStep`输出一个名为`parallel_run_step.txt`的文件。这将作为管道数据存储。
- en: Pipeline data is data that is saved in your datastore as an intermediate step
    to be passed on to another ML pipeline step. Furthermore, `parallel_run_step.txt`
    has no headers and you need to add them.
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 管道数据是在您的数据存储中保存的数据，作为传递给另一个机器学习管道步骤的中间步骤。此外，`parallel_run_step.txt` 没有标题，您需要添加它们。
- en: 'Begin by writing out a new Python script file called `Iris_Parallel_Output_Creation.py`
    using the `%%writefile` magic command. Start by loading in your Azure libraries
    as usual:'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先使用 `%%writefile` 魔法命令编写一个新的 Python 脚本文件，名为 `Iris_Parallel_Output_Creation.py`。首先像往常一样加载您的
    Azure 库：
- en: '[PRE48]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    load in all of the standard Python packages you need:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Parallel_Output_Creation.py` 的同一单元格中继续，作为该脚本的一部分，加载您需要的所有标准 Python 包：
- en: '[PRE49]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: You will once again need `argparse` to pass in arguments, namely the folder
    that holds `parallel_run_step.txt`.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您将再次需要 `argparse` 来传递参数，即包含 `parallel_run_step.txt` 的文件夹。
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    set a variable called `run` using the `Run` function:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Parallel_Output_Creation.py` 的同一单元格中继续，使用 `Run` 函数设置一个名为 `run` 的变量：
- en: '[PRE50]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    pass in your arguments to access the folder that holds `parallel_run_step.txt`:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Parallel_Output_Creation.py` 的同一单元格中继续，作为该脚本的一部分，传递您的参数以访问包含 `parallel_run_step.txt`
    的文件夹：
- en: '[PRE51]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Call the `input_data_folder` argument and pass it in as an argument when you
    configure this pipeline step.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调用 `input_data_folder` 参数，并在配置此管道步骤时将其作为参数传递：
- en: Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`, write
    a function called `main`. This function will transfer your predictions from an
    intermediate pipeline data location to its final destination.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Parallel_Output_Creation.py` 的同一单元格中继续，作为该脚本的一部分，编写一个名为 `main` 的函数。此函数将把您的预测从中间管道数据位置转移到最终目的地。
- en: 'Begin by using `os` and `input_data_folder` to find the path holding `parallel_run_step.txt`.
    Then, read it in as a space-delimited text file with no headers in a `pandas`
    DataFrame called `result` using the following code:'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先使用 `os` 和 `input_data_folder` 查找包含 `parallel_run_step.txt` 的路径。然后，使用以下代码将其作为没有标题的空格分隔文本文件读取到名为
    `result` 的 `pandas` DataFrame 中：
- en: '[PRE52]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    as part of your `main` function, add columns to your `result` DataFrame:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Parallel_Output_Creation.py` 的同一单元格中继续，作为 `main` 函数的一部分，向您的 `result`
    DataFrame 添加列：
- en: '[PRE53]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: It's important to remember that `parallel_run_step.txt` never has headers, so
    you need to enter the columns manually in the correct order as shown in the preceding
    code.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要的是要记住，`parallel_run_step.txt` 从来没有标题，因此您需要手动输入列，顺序应与前面代码中所示相同。
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    as part of your `main` function, connect to your AMLS workspace using the `run`
    variable and set a variable for your datastore:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Parallel_Output_Creation.py` 的同一单元格中继续，作为 `main` 函数的一部分，使用 `run` 变量连接到您的
    AMLS 工作区，并设置一个用于数据存储的变量：
- en: '[PRE54]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: This is the datastore that will hold your final output file.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是将保存您的最终输出文件的存储区。
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    as part of your `main` function, use `os` to create a folder called `Output_Folder`
    on your compute cluster, and write a CSV file called `Iris_Parallel_Predictions.csv`:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Parallel_Output_Creation.py` 的同一单元格中继续，作为 `main` 函数的一部分，使用 `os` 在您的计算集群上创建一个名为
    `Output_Folder` 的文件夹，并编写一个名为 `Iris_Parallel_Predictions.csv` 的 CSV 文件：
- en: '[PRE55]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Even though the original `parallel_run_step.txt` file was space-delimited, you
    can set the delimiter on your final output file to whatever you wish.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 即使原始的 `parallel_run_step.txt` 文件是空格分隔的，您也可以将最终输出文件的分隔符设置为所需的任何内容。
- en: Completing `Iris_Parallel_Output_Creation.py`, upload `Iris_Parallel_Predictions.csv`
    to your datastore in a folder called `Output_Folder`.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成 `Iris_Parallel_Output_Creation.py`，将 `Iris_Parallel_Predictions.csv` 上传到名为
    `Output_Folder` 的文件夹中，该文件夹位于您的数据存储中。
- en: 'Then, use `os` to remove both `Iris_Parallel_Predictions.csv` and `Output_Folder`
    from your compute cluster. Finally, trigger your `main` function as you did in
    the *Creating an ML pipeline* section:'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，使用 `os` 从您的计算集群中删除 `Iris_Parallel_Predictions.csv` 和 `Output_Folder`。最后，像在
    *创建机器学习管道* 部分中那样触发您的 `main` 函数：
- en: '[PRE56]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: With both steps written, the rest of the code is pure boilerplate to containerize
    your environment and to configure and run your pipeline.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写完这两个步骤后，其余的代码纯粹是为了容器化您的环境以及配置和运行您的管道。
- en: Configuring and running your ML parallel scoring pipeline
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置和运行您的机器学习并行评分管道
- en: 'Since you''ve already built your environment in the *Creating an ML pipeline*
    section, all that''s really left is configuring your ML pipeline steps. Use the
    following steps:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您已经在“创建ML管道”部分中构建了您的环境，所以剩下的只是配置您的ML管道步骤。使用以下步骤：
- en: 'In a new cell, retrieve the environment that you created in the *Creating an
    ML pipeline* section with the following code:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个新的单元中，使用以下代码检索您在“创建ML管道”部分中创建的环境：
- en: '[PRE57]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Next, define a variable that defines your pipeline data and assigns it to a
    datastore:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义一个变量来定义您的管道数据并将其分配给数据存储：
- en: '[PRE58]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: This is the location that will hold `parallel_run_step.txt` between your first
    and second steps. You must also give this pipeline data object a name.
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是将在您的第一步和第二步之间保存`parallel_run_step.txt`的位置。您还必须给这个管道数据对象起一个名称。
- en: 'Enable Docker on your environment and specify `DEFAULT_CPU_IMAGE` as your base
    image for your `ParallelRunStep`:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的环境中启用Docker，并将`DEFAULT_CPU_IMAGE`指定为您的`ParallelRunStep`的基础镜像：
- en: '[PRE59]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: You do not need to specify a `RunConfiguration` object for `ParallelRunStep`.
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您不需要为`ParallelRunStep`指定`RunConfiguration`对象。
- en: 'Create a `RunConfiguration` object for your output creation step:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的输出创建步骤创建一个`RunConfiguration`对象：
- en: '[PRE60]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Set your parallel run configurations with the following code:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码设置您的并行运行配置：
- en: '[PRE61]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: You need to input the name of your Python script as well as the source directory
    that holds it. You need to specify how much data will be scored in parallel with
    `mini_batch_size`. For all `error_threshold` is how many times the step can fail
    in parallel before the entire pipeline fails. Next, setting `output_action` to
    `append_row` will automatically generate `parallel_run_step.txt` for you. Other
    options for `output_action` are labor-intensive.
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您需要输入Python脚本的名称以及包含它的源目录。您需要指定将并行评分的数据量，使用`mini_batch_size`。对于所有`error_threshold`是指步骤在管道失败之前可以并行失败多少次。接下来，将`output_action`设置为`append_row`将自动为您生成`parallel_run_step.txt`。其他`output_action`选项较为繁琐。
- en: Set your compute target to the appropriate compute cluster and specify your
    environment. Leave `run_invocation_timeout` at 60 seconds so your run will fail
    if it idles for too long and set `node_count` equal to the number of nodes in
    your compute cluster to ensure maximum parallelization. Lastly, set `logging_level`
    to `DEBUG` for informative logs.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将您的计算目标设置为适当的计算集群并指定您的环境。将`run_invocation_timeout`设置为60秒，以便您的运行在空闲时间过长时将失败，并将`node_count`设置为您的计算集群中的节点数以确保最大并行化。最后，将`logging_level`设置为`DEBUG`以获取信息性日志。
- en: 'Set the two variables that you will need to create your parallel scoring step,
    your dataset, and your model name:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置您将需要创建并行评分步骤、数据集和模型名称的两个变量：
- en: '[PRE62]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Datasets need to be passed in with the `as_named_input` code and appear as the
    `input_data` variable in your Python script.
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集需要使用`as_named_input`代码传递，并在您的Python脚本中作为`input_data`变量出现。
- en: 'Create your parallel scoring step using the following code:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建您的并行评分步骤：
- en: '[PRE63]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: You need to give the step a name, `iris-parallel-scoring-step`. No spaces are
    allowed. Pass in your configurations using `parallel_run_config` and pass in your
    dataset using `inputs`. Set `output` to your pipeline data object and pass in
    your model name as an argument. As always, set `allow_reuse` equal to `False`.
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您需要给步骤起一个名称，`iris-parallel-scoring-step`。不允许有空格。使用`parallel_run_config`传递您的配置，并使用`inputs`传递您的数据集。将`output`设置为您的管道数据对象，并将模型名称作为参数传递。一如既往，将`allow_reuse`设置为`False`。
- en: 'Create your output creation step using the following code:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建您的输出创建步骤：
- en: '[PRE64]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Give this step the name `iris-output-step` and pass in your script name and
    source directory. For `arguments` and `input`, you need to pass in `parallel_run_output`.
    This lets your output creation step use `parallel_run_step.txt` generated by your
    parallel scoring step. Then, set your compute target, specify your run configuration,
    and set `allow_reuse` to `False`.
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 给这个步骤起一个名称`iris-output-step`，并传递您的脚本名称和源目录。对于`arguments`和`input`，您需要传递`parallel_run_output`。这允许您的输出创建步骤使用由并行评分步骤生成的`parallel_run_step.txt`。然后，设置您的计算目标，指定您的运行配置，并将`allow_reuse`设置为`False`。
- en: 'Set your step sequence and create a pipeline object:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置您的步骤序列并创建一个管道对象：
- en: '[PRE65]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: This time, you have two steps to set, `parallel_run_step` and `output_step`.
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这次，您需要设置两个步骤，`parallel_run_step`和`output_step`。
- en: 'Give your pipeline experiment run a name, `Iris-Parallel-Scoring-Pipeline-Run`,
    and submit it to your compute cluster:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给您的管道实验运行起一个名称，`Iris-Parallel-Scoring-Pipeline-Run`，并将其提交到您的计算集群：
- en: '[PRE66]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Use `RunDetails` to watch your pipeline execute in real time:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`RunDetails`实时查看你的管道执行：
- en: '[PRE67]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Notice how fast this scores your data. If your pipeline runs successfully,
    it will complete with the word **Finished**. You should see a graphic identical
    to the one in *Figure 9.6*:'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意它如何快速评分你的数据。如果你的管道运行成功，它将以单词**完成**结束。你应该看到一个与*图9.6*中相同的图形：
- en: '![Figure 9.6 – Successful parallel pipeline run graphic ](img/Figure_9.6_B16595.jpg)'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图9.6 – 成功的并行管道运行图形](img/Figure_9.6_B16595.jpg)'
- en: Figure 9.6 – Successful parallel pipeline run graphic
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.6 – 成功的并行管道运行图形
- en: 'Publish your pipeline to an endpoint as you did in the previous section, naming
    it `Iris-Parallel-Scoring-Pipeline` or whatever you wish:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照上一节的做法，将你的管道发布到端点，命名为`Iris-Parallel-Scoring-Pipeline`或你想要的任何名称：
- en: '[PRE68]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Running this code will give you your published pipeline ID as well as a link
    to the endpoint, as seen in *Figure 9.7*:'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行此代码将给你发布管道的ID以及一个到端点的链接，如图*图9.7*所示：
- en: '![Figure 9.7 – Successfully published parallel pipeline ](img/Figure_9.7_B16595.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![图9.7 – 成功发布的并行管道](img/Figure_9.7_B16595.jpg)'
- en: Figure 9.7 – Successfully published parallel pipeline
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7 – 成功发布的并行管道
- en: You can now examine and download your scoring file as you did in the previous
    section. Look inside `Output_Folder` in your datastore for a file called `Iris_Parallel_Predictions.csv`.
    It's quite a bit larger than your last file, at around 30 MB.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以像上一节那样检查和下载你的评分文件。在你的数据存储库中的`Output_Folder`内查找名为`Iris_Parallel_Predictions.csv`的文件。它比你的上一个文件大得多，大约30MB。
- en: With both a standard scoring pipeline and a parallel run pipeline built, you
    are now at the cutting edge of AMLS. Both of these pipelines can be used to score
    not only AutoML-generated ML models, but custom models as well.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建了标准评分管道和并行运行管道之后，你现在处于AMLS的前沿。这两个管道都可以用来评分不仅AutoML生成的ML模型，还可以自定义模型。
- en: Even experienced data scientists have a hard time building these batch scoring
    solutions. So, you have acquired a desirable, marketable skill that will enable
    you to work alongside seasoned experts.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 即使经验丰富的数据科学家也难以构建这些批量评分解决方案。因此，你已经掌握了一项有吸引力的、可销售的技能，这将使你能够与资深专家并肩工作。
- en: In the next section, you will learn how to build a pipeline for training AutoML
    models instead of scoring.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何构建用于训练AutoML模型的管道，而不是评分。
- en: Creating an AutoML training pipeline
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建AutoML训练管道
- en: Sometimes, it's necessary to retrain a model that you trained in AutoML. ML
    models can degrade over time if the relationship between your data and your target
    variable changes. This is true for all ML models, not just ones generated by AutoML.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，有必要重新训练你在AutoML中训练的模型。如果数据与目标变量之间的关系发生变化，ML模型会随着时间的推移而退化。这对所有ML模型都适用，而不仅仅是AutoML生成的模型。
- en: Imagine, for example, that you build an ML model to predict demand for frozen
    pizza at a supermarket, and then one day, a famous pizza chain sets up shop next
    door. It's very likely that consumer buying behavior will change, and you will
    need to retrain the model. This is true for all ML models.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，例如，你构建了一个ML模型来预测超市冷冻披萨的需求，然后有一天，一家著名的披萨连锁店在隔壁开店。消费者购买行为很可能发生变化，你需要重新训练模型。这对所有ML模型都适用。
- en: Luckily, AMLS has specialized ML pipeline steps built specifically for retraining
    models. In this section, we are going to use one of those steps, the AutoML step.
    The **AutoML step** lets you retrain models easily whenever you want, either with
    a push of a button or on a schedule.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，AMLS有专门为重新训练模型构建的ML管道步骤。在本节中，我们将使用其中之一，即AutoML步骤。**AutoML步骤**让你可以随时轻松地重新训练模型，无论是按按钮还是按计划。
- en: Here, you will build a two-step ML pipeline where you will first train a model
    with an AutoML step and register it with a typical Python script step. This will
    enable you to build complete end-to-end solutions with automated scoring and training,
    completing your skillset. Furthermore, this will familiarize you with the AutoML
    step and all of its caveats.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你将构建一个两步机器学习（ML）管道，首先使用AutoML步骤训练一个模型，然后使用典型的Python脚本步骤注册它。这将使你能够构建具有自动化评分和训练的完整端到端解决方案，完善你的技能集。此外，这将使你熟悉AutoML步骤及其所有注意事项。
- en: Important note
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Not all ML models require retraining, particularly those that predict physical
    phenomena, as the relationship between your data and the target variable is unlikely
    to change over time. However, most ML models will improve with additional data
    points, so it does make sense to retrain models as you collect and label more
    data.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有ML模型都需要重新训练，尤其是那些预测物理现象的模型，因为你的数据与目标变量之间的关系不太可能随时间改变。然而，大多数ML模型会随着额外的数据点的增加而改进，因此随着你收集和标记更多数据，重新训练模型是有意义的。
- en: By now, you should know what to expect in terms of creating ML pipelines. Most
    of the steps will be familiar to you, but you will have to work with specialized
    forms of pipeline data that pass data from your training step to your model registration
    step.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该知道在创建ML管道方面可以期待什么。大多数步骤对你来说都很熟悉，但你将不得不与专门形式的管道数据一起工作，这些数据将数据从你的训练步骤传递到你的模型注册步骤。
- en: 'The Python scripts involved in this pipeline are much simpler than those involved
    in scoring pipelines, and thus require less customization when you try it with
    your own data. At the end of this section, like others, you will also publish
    your AutoML training pipeline to an endpoint. *Figure 9.8* outlines the process:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 此管道中涉及的Python脚本比评分管道中的脚本简单得多，因此当你尝试用你自己的数据时，需要更少的定制。在本节结束时，就像其他部分一样，你也将你的AutoML训练管道发布到端点。*图9.8*概述了该过程：
- en: '![Figure 9.8 – Steps involved in setting up an AutoML retraining pipeline ](img/Figure_9.8_B16595.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![图9.8 – 设置AutoML重训练管道涉及的步骤](img/Figure_9.8_B16595.jpg)'
- en: Figure 9.8 – Steps involved in setting up an AutoML retraining pipeline
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.8 – 设置AutoML重训练管道涉及的步骤
- en: This process is a little bit different than the other pipelines, as you need
    to configure your AutoML settings early on. You can find the code for all the
    steps in the `ML-Retraining-Pipeline.ipynb` file in the GitHub repository.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程与其他管道略有不同，因为你需要尽早配置你的AutoML设置。你可以在GitHub仓库中的`ML-Retraining-Pipeline.ipynb`文件中找到所有步骤的代码。
- en: Coding the first two steps of your AutoML training pipeline
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写你的AutoML训练管道的前两个步骤
- en: 'To create your AutoML training pipeline, begin with the following steps:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建你的AutoML训练管道，请从以下步骤开始：
- en: Navigate to your Jupyter environment on your compute instance and create a new
    Jupyter notebook. Name it `automl-training-pipeline`.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到你的计算实例上的Jupyter环境，创建一个新的Jupyter笔记本。命名为`automl-training-pipeline`。
- en: 'Open your newly created notebook and import the usual set of Azure libraries
    along with `AutoMLConfig`:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开你新创建的笔记本，并导入通常的Azure库以及`AutoMLConfig`：
- en: '[PRE69]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '`AutoMLConfig` lets you configure AutoML training runs.'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`AutoMLConfig`允许你配置AutoML训练运行。'
- en: 'Continuing on, import the necessary Azure ML pipeline libraries with the following
    code:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续使用以下代码导入必要的Azure ML管道库：
- en: '[PRE70]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: There are two new packages. `AutoMLStep` is an ML pipeline step that lets you
    run AutoML training runs. `TrainingOutput` lets you access the output from your
    AutoML step to pass on to your model registration step.
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有两个新的包。`AutoMLStep`是一个ML管道步骤，允许你运行AutoML训练运行。`TrainingOutput`允许你访问AutoML步骤的输出，以便传递到你的模型注册步骤。
- en: 'Import `os`:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`os`：
- en: '[PRE71]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: This is the only non-Azure Python package you will need to make this pipeline,
    and it will be used to create a new folder.
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是构建此管道所需的唯一非Azure Python包，它将被用来创建一个新的文件夹。
- en: 'Connect your Jupyter notebook to your AMLS workspace:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将你的Jupyter笔记本连接到你的AMLS工作区：
- en: '[PRE72]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Log in if prompted by following the instructions.
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果需要，按照说明登录。
- en: 'Set your compute cluster:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置你的计算集群：
- en: '[PRE73]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Set your datastore:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置你的数据存储：
- en: '[PRE74]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Retrieve your `Iris Training` dataset with the following code. You will pass
    this dataset into your AutoML configuration settings:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码检索你的`Iris Training`数据集。你将此数据集传递到你的AutoML配置设置中：
- en: '[PRE75]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Retrieve the environment named `AutoML Environment` that you created in the
    *Creating an ML pipeline* section of this chapter:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取你在本章*创建ML管道*部分创建的名为`AutoML Environment`的环境：
- en: '[PRE76]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: This will be used only for your model registration step; your AutoML training
    step will use a standard, autogenerated environment.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这将仅用于你的模型注册步骤；你的AutoML训练步骤将使用标准、自动生成的环境。
- en: Configuring your AutoML model training settings and step
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置你的AutoML模型训练设置和步骤
- en: 'Next, you''ll configure everything related to your AutoML training step with
    the following code:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将使用以下代码配置与你的AutoML训练步骤相关的所有设置：
- en: 'Set variables to pass into your AutoML configuration settings:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置变量以传递到你的AutoML配置设置中：
- en: '[PRE77]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Explanations for these settings can be found in [*Chapter 5*](B16595_05_ePub.xhtml#_idTextAnchor068),
    *Building an AutoML Classification Solution*. One new setting is `iterations`.
    This will be used to determine how many AutoML models should be trained concurrently;
    this value should equal the number of nodes on your compute cluster to ensure
    maximum parallelization.
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些设置的说明可以在[*第 5 章*](B16595_05_ePub.xhtml#_idTextAnchor068)中找到，*构建 AutoML 分类解决方案*。一个新设置是
    `iterations`。这将用于确定应该并行训练多少个 AutoML 模型；此值应等于您的计算集群上的节点数，以确保最大并行化。
- en: 'Configure your AutoML training run:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置您的 AutoML 训练运行：
- en: '[PRE78]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: An explanation for these settings can be found in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution*. If you would like higher accuracy, adjust
    `experiment_timeout_minutes` to give AutoML more time to train. Note that you
    are passing in your dataset here.
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些设置的说明可以在[*第 4 章*](B16595_04_ePub.xhtml#_idTextAnchor056)中找到，*构建 AutoML 回归解决方案*。如果您希望获得更高的精度，请调整
    `experiment_timeout_minutes` 以给 AutoML 更多时间进行训练。请注意，您在这里传递了您的数据集。
- en: 'Set the output for AutoML metrics:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 AutoML 指标输出：
- en: '[PRE79]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: This code is standard boilerplate used in every AutoML step. It saves metrics
    from your AutoML run as intermediate pipeline data that you can use to pass on
    to other steps in your ML pipeline.
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此代码是每个 AutoML 步骤中使用的标准样板代码。它将您的 AutoML 运行中的指标保存为中间管道数据，您可以使用这些数据传递到您的 ML 管道中的其他步骤。
- en: 'Set the output for your best model:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置您最佳模型的输出：
- en: '[PRE80]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: This code is standard boilerplate used in every AutoML step. It saves information
    about the best model from your AutoML run as intermediate pipeline data to pass
    on to your model registration step.
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此代码是每个 AutoML 步骤中使用的标准样板代码。它将您的 AutoML 运行中关于最佳模型的信息保存为中间管道数据，以便传递到您的模型注册步骤。
- en: 'Configure your AutoML step:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置您的 AutoML 步骤：
- en: '[PRE81]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: All you need to do is give it a name, pass in your AutoML configuration settings,
    and specify `metrics_data` and `model_data` as output. As always, set `allow_reuse`
    to `False`.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要做的只是给它一个名称，传递您的 AutoML 配置设置，并指定 `metrics_data` 和 `model_data` 作为输出。始终将 `allow_reuse`
    设置为 `False`。
- en: Creating a Python script to register your model
  id: totrans-338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个 Python 脚本以注册您的模型
- en: 'With your AutoML training step configured, you now need to write another script
    to extract and register your model using the following steps:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置了 AutoML 训练步骤后，您现在需要编写另一个脚本，使用以下步骤提取和注册您的模型：
- en: 'Make a folder to hold your training script using `os`:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `os` 创建一个文件夹来保存您的训练脚本：
- en: '[PRE82]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Write a Python script to register your model. This script is very short compared
    to the others you wrote. Begin by writing out a new Python script file called
    `Iris_Model_Registration.py` using the `%%writefile` magic command and loading
    in your Azure libraries and `argparse`:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个 Python 脚本以注册您的模型。与您编写的其他脚本相比，此脚本非常简短。首先，使用 `%%writefile` 魔法命令编写一个新的 Python
    脚本文件，名为 `Iris_Model_Registration.py`，并加载您的 Azure 库和 `argparse`：
- en: '[PRE83]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Continuing in the same cell as part of `Iris_Model_Registration_Scoring.py`,
    set a variable called `run` using the `Run` function:'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Model_Registration_Scoring.py` 的同一单元格中继续，使用 `Run` 函数设置一个名为 `run` 的变量：
- en: '[PRE84]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Continuing in the same cell as part of `Iris_Model_Registration_Scoring.py`,
    pass in your arguments to access the best model as trained by AutoML as well as
    the dataset you used to train the model. For this, you will need three arguments,
    `model_name`, `model_path`, and `dataset_name`:'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Model_Registration_Scoring.py` 的同一单元格中继续，传递您的参数以访问由 AutoML 训练的最佳模型以及您用于训练模型的数据库。为此，您需要三个参数，`model_name`、`model_path`
    和 `dataset_name`：
- en: '[PRE85]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Continuing in the same cell as part of `Iris_Model_Registration_Scoring.py`,
    write a function called `main`. This function will register your best model. Begin
    by connecting to your AMLS workspace using the `run` variable:'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Model_Registration_Scoring.py` 的同一单元格中继续，编写一个名为 `main` 的函数。此函数将注册您的最佳模型。首先，使用
    `run` 变量连接到您的 AMLS 工作区：
- en: '[PRE86]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Continuing in the same cell as part of `Iris_Model_Registration_Scoring.py`,
    as part of your `main` function, retrieve your dataset through the `dataset_name`
    argument:'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Iris_Model_Registration_Scoring.py` 的同一单元格中继续，作为 `main` 函数的一部分，通过 `dataset_name`
    参数检索您的数据集：
- en: '[PRE87]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Use the `Dataset.Scenario.Training` line of code to specify the scenario in
    which it was used. This information will be saved when you register your model.
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用 `Dataset.Scenario.Training` 代码行指定它所使用的场景。当您注册模型时，将保存此信息。
- en: 'Continuing in the same cell as part of `Iris_Model_Registration_Scoring.py`,
    as part of your `main` function, register your model using the `model_path` and
    `model_name` arguments:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Iris_Model_Registration_Scoring.py`的同一单元格中，作为`main`函数的一部分，使用`model_path`和`model_name`参数注册您的模型：
- en: '[PRE88]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: While `model_name` is something you specify, `model_path` will be automatically
    generated from `model_data`. The dataset you used to train your model will also
    be saved using this code. Finally, complete `Iris_Model_Registration_Scoring.py`
    with the boilerplate code that triggers `main`.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`model_name`是您指定的，但`model_path`将自动从`model_data`生成。您用于训练模型的那个数据集也将使用此代码保存。最后，使用触发`main`的样板代码完成`Iris_Model_Registration_Scoring.py`。
- en: Configuring and running your AutoML training pipeline
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置和运行您的AutoML训练管道
- en: 'All that''s left is to containerize your environment, configure your model
    registration step, and run and publish your pipeline by following these steps:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的就是容器化您的环境，配置您的模型注册步骤，并按照以下步骤运行和发布您的管道：
- en: 'Create a `RunConfiguration` object for the model registration step:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为模型注册步骤创建一个`RunConfiguration`对象：
- en: '[PRE89]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Note that this uses `AutoML Environment`, but you can get away with using a
    simpler environment without `pandas` or NumPy if you so desire.
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，这使用的是`AutoML环境`，但如果您愿意，也可以使用没有`pandas`或NumPy的更简单环境。
- en: 'Set variables for your model name and dataset name:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置模型名称和数据集名称的变量：
- en: '[PRE90]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: Your model name will be used to register the best model that AutoML produces
    and is your choice. Your dataset name, on the other hand, should match the dataset
    you used to train your model.
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您的模型名称将用于注册AutoML生成的最佳模型，这是您的选择。另一方面，您的数据集名称应该与您用于训练模型的那个数据集相匹配。
- en: 'Configure your model registration step:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置您的模型注册步骤：
- en: '[PRE91]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Here, you must pass in three arguments, `model_name`, `model_data`, and `dataset_name`,
    and pass in `model_data` as input. This is because `model_data` is pipeline data
    generated by your AutoML training step, while `model_name` and `dataset_name`
    are simple string variables. As always, set `allow_reuse` to `False`.
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，您必须传递三个参数，`model_name`、`model_data`和`dataset_name`，并将`model_data`作为输入传递。这是因为`model_data`是您的AutoML训练步骤生成的管道数据，而`model_name`和`dataset_name`是简单的字符串变量。一如既往，将`allow_reuse`设置为`False`。
- en: 'Set your step sequence and create a pipeline object:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置您的步骤序列并创建一个管道对象：
- en: '[PRE92]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: This time, you have two steps to set, `automl_training step` and `model_registration_step`.
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这次，您需要设置两个步骤，`automl_training步骤`和`model_registration步骤`。
- en: 'Give your pipeline experiment run a name, `Iris-AutoML-Training-Pipeline-Run`,
    and submit it to your compute cluster:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给您的管道实验运行起一个名字，`Iris-AutoML-Training-Pipeline-Run`，并将其提交到您的计算集群：
- en: '[PRE93]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: This will take much longer than your other pipelines, perhaps around a half
    hour.
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将比您的其他管道花费更长的时间，可能大约半小时。
- en: 'Use `RunDetails` to watch your pipeline execute in real time:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`RunDetails`实时查看您的管道执行：
- en: '[PRE94]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'If your pipeline runs successfully, it will complete with the word **Finished**.
    You should see a graphic identical to the one in *Figure 9.9*:'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您的管道运行成功，它将以“完成”一词结束。您应该看到一个与图9.9中相同的图形：
- en: '![Figure 9.9 – Successful AutoML training pipeline](img/Figure_9.9_B16595.jpg)'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图9.9 – 成功的AutoML训练管道](img/Figure_9.9_B16595.jpg)'
- en: Figure 9.9 – Successful AutoML training pipeline
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.9 – 成功的AutoML训练管道
- en: 'Publish your pipeline to an endpoint as you did in the previous section, naming
    it `Iris-AutoML-Training-Pipeline` or whatever you wish:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照上一节中的方法将管道发布到端点，命名为`Iris-AutoML-Training-Pipeline`或您想要的任何名称：
- en: '[PRE95]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Running this code will give you your published pipeline ID as well as a link
    to your endpoint, as seen in *Figure 9.10*:'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行此代码将为您提供已发布的管道ID以及访问端点的链接，如图9.10所示：
- en: '![Figure 9.10 – Successfully published AutoML training pipeline](img/Figure_9.10_B16595.jpg)'
  id: totrans-381
  prefs: []
  type: TYPE_IMG
  zh: '![图9.10 – 成功发布的AutoML训练管道](img/Figure_9.10_B16595.jpg)'
- en: Figure 9.10 – Successfully published AutoML training pipeline
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.10 – 成功发布的AutoML训练管道
- en: Important note
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'Sometimes when you''re running an ML pipeline, your computer will crash. However,
    your pipeline run will continue to run and you will still be able to publish it
    upon completion. To retrieve a completed pipeline so you can publish it, use the
    following code:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 有时当您运行一个机器学习管道时，您的计算机可能会崩溃。然而，您的管道运行将继续进行，并且您仍然可以在完成后发布它。要检索一个已完成的管道以便发布，请使用以下代码：
- en: '[PRE96]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: You have now built three ML pipelines, a standard scoring pipeline, a parallel
    run pipeline, and an AutoML training pipeline. This was not a trivial effort,
    but all that hard work has paid off. You have mastered one of the most complex
    parts of AMLS.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经构建了三个机器学习管道，一个标准评分管道、一个并行运行管道和一个AutoML训练管道。这并非易事，但所有的辛勤工作都得到了回报。你已经掌握了AMLS中最复杂的一部分。
- en: While making these pipelines is quite an undertaking, once you have them, they
    are very easy to manually rerun or automatically schedule, as you will see in
    the next section.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然创建这些管道是一项相当艰巨的任务，但一旦拥有它们，它们就非常容易手动重新运行或自动调度，正如你将在下一节中看到的那样。
- en: Triggering and scheduling your ML pipelines
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 触发和调度你的机器学习管道
- en: One of the biggest problems data scientists face is creating easy, rerunnable,
    production-ready code and scheduling it in an automatic, reliable manner. You've
    already accomplished the first part by creating your three ML pipelines. Now,
    it's time to learn how to do the second part.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家面临的最大问题之一是创建易于重用、生产就绪的代码，并以自动、可靠的方式对其进行调度。你已经通过创建三个机器学习管道完成了第一部分。现在，是时候学习如何完成第二部分了。
- en: In this section, you will first learn how to manually trigger the pipelines
    you've created through the GUI. Then, you will learn how to trigger the pipelines
    via code, both manually and on an automated schedule. This will enable you to
    put your ML pipelines into production, generating results on an hourly, daily,
    weekly, or monthly basis.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将首先学习如何通过图形用户界面手动触发你创建的管道。然后，你将学习如何通过代码触发管道，包括手动和自动调度。这将使你能够将你的机器学习管道投入生产，每小时、每天、每周或每月生成结果。
- en: Triggering your published pipeline from the GUI
  id: totrans-391
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从GUI触发已发布的管道
- en: 'Triggering your published pipeline from the AML studio GUI is easy. However,
    you cannot set up an automated schedule for your ML pipelines at this time. As
    such, it is most useful for triggering training pipelines when you notice that
    your results seem off. Use the following steps to manually trigger your ML pipeline
    through the AML studio:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 从AML工作室GUI触发已发布的管道很容易。然而，目前你无法为你的机器学习管道设置自动调度。因此，它最有用的情况是在你注意到结果似乎不正确时触发训练管道。使用以下步骤通过AML工作室手动触发你的机器学习管道：
- en: Navigate to [https://ml.azure.com](https://ml.azure.com) to access AML studio.
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到[https://ml.azure.com](https://ml.azure.com)以访问AML工作室。
- en: Click **Pipelines** under **Assets** on the left-hand side.
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击左侧**资产**下的**管道**。
- en: Click **Pipeline endpoints** near the top of the page.
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击页面顶部附近的**管道端点**。
- en: Click the blue link to **Iris-AutoML-Training-Pipeline**.
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击蓝色链接**Iris-AutoML-Training-Pipeline**。
- en: Click **Submit**. This will open up a dialog box.
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**提交**。这将打开一个对话框。
- en: Select an experiment name from the drop-down box under `Iris-AutoML-Training-Pipeline-Run`.
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`Iris-AutoML-Training-Pipeline-Run`下的下拉框中选择一个实验名称。
- en: Click **Submit**.
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**提交**。
- en: 'Click **Pipelines** under **Assets** again and, on the top line, you should
    see a new run, as shown in *Figure 9.11*:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次点击**资产**下的**管道**，在顶部行，你应该看到一个新运行，如图*9.11*所示：
- en: '![Figure 9.11 – Pipeline run submitted through the GUI ](img/Figure_9.11_B16595.jpg)'
  id: totrans-401
  prefs: []
  type: TYPE_IMG
  zh: '![图9.11 – 通过GUI提交的管道运行](img/Figure_9.11_B16595.jpg)'
- en: Figure 9.11 – Pipeline run submitted through the GUI
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.11 – 通过GUI提交的管道运行
- en: Compared to making an ML pipeline, resubmitting it is very easy. Next, we will
    look at ways to trigger our pipeline through code and create an automatic schedule.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 与创建机器学习管道相比，重新提交它非常简单。接下来，我们将探讨通过代码触发我们的管道并创建自动调度的方法。
- en: Triggering and scheduling a published pipeline through code
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过代码触发和调度已发布的管道
- en: Triggering a published ML pipeline through code first requires you to obtain
    your pipeline ID. These were generated at the end of the previous sections whenever
    you published a pipeline. You can also find your pipeline ID by clicking on individual
    pipelines found under **Pipeline endpoints** through the AML studio. You will
    also need your pipeline IDs to set up schedules through code.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 通过代码首先触发已发布的机器学习管道需要你获取你的管道ID。这些在上一节的末尾生成，每次你发布一个管道时都会生成。你还可以通过点击AML工作室下**管道端点**中的单个管道来找到你的管道ID。你还需要你的管道ID来通过代码设置调度。
- en: 'All the code for this section can be found in the `ML-Pipeline-Scheduling.ipynb`
    file in the GitHub repository. Begin by opening a Jupyter notebook and following
    these steps:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中所有代码都可以在GitHub仓库中的`ML-Pipeline-Scheduling.ipynb`文件中找到。首先，打开一个Jupyter笔记本并按照以下步骤操作：
- en: Create a new Jupyter notebook as you have before. Name it `pipeline-scheduling`.
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如同之前一样创建一个新的Jupyter笔记本。将其命名为`pipeline-scheduling`。
- en: 'Open your notebook and import the required Azure libraries, three of which
    are new. `PublishedPipeline` lets you access any ML pipelines you have published.
    `Schedule` and `ScheduleRecurrence` let you schedule ML pipelines:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开你的笔记本并导入所需的Azure库，其中三个是新的。`PublishedPipeline`让你可以访问你发布的任何ML管道。`Schedule`和`ScheduleRecurrence`让你可以安排ML管道：
- en: '[PRE97]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'To manually trigger an ML pipeline, use the following code by replacing `your-published-pipeline-id`
    with the ID of your published AutoML training pipeline. That''s it:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要手动触发一个ML管道，使用以下代码，并用你发布的AutoML训练管道的ID替换`your-published-pipeline-id`。就是这样：
- en: '[PRE98]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'To create a schedule for running your ML pipeline, first determine an interval
    with the following code. The interval options are `Minute`, `Hour`, `Day`, `Week`,
    or `Month`. You can also specify `start_time` and `time_zone` as optional arguments.
    Another optional argument is `status`, which you can set to `Disabled` to turn
    off your schedule:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建运行你的ML管道的日程安排，首先使用以下代码确定一个间隔。间隔选项有`Minute`（分钟）、`Hour`（小时）、`Day`（天）、`Week`（周）或`Month`（月）。你也可以指定`start_time`（开始时间）和`time_zone`（时区）作为可选参数。另一个可选参数是`status`（状态），你可以将其设置为`Disabled`来关闭你的日程安排：
- en: '[PRE99]'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Create your schedule by giving it a name and passing in your `recurrence` settings,
    experiment name, published pipeline ID, and a description:'
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提供一个名称并传递你的`recurrence`设置、实验名称、发布的管道ID和描述来创建你的日程安排：
- en: '[PRE100]'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: You have now created a schedule that will automatically trigger your AutoML
    training pipeline once a day. This schedule will automatically spin up your compute
    cluster, train a model, and spin down. Many companies spend years trying to figure
    out how best to schedule ML training and scoring runs in a timely, reliable manner,
    and you've accomplished this task in a mere chapter!
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经创建了一个日程安排，该安排将每天自动触发你的AutoML训练管道。这个日程安排将自动启动你的计算集群，训练一个模型，然后关闭。许多公司花费数年时间试图找出如何及时、可靠地安排ML训练和评分运行的最佳方法，而你仅用了一章就完成了这个任务！
- en: Summary
  id: totrans-417
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: You have now implemented a fully automated ML batch scoring solution using an
    AutoML trained model. You've created pipelines that can score models, pipelines
    that can process big data in parallel, and pipelines that can retrain AutoML models.
    You can trigger them whenever you want and you can even set up an automated scoring
    schedule. This is no small feat, as many organizations have spent years trying
    to learn best practices for these tasks.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经实现了一个使用AutoML训练模型的全自动ML批量评分解决方案。你已经创建了可以评分模型的管道，可以并行处理大数据的管道，以及可以重新训练AutoML模型的管道。你可以随时触发它们，甚至可以设置自动评分日程。这可不是一件小事，因为许多组织花费了数年时间去学习这些任务的最佳实践。
- en: In [*Chapter 10*](B16595_10_ePub.xhtml#_idTextAnchor151), *Creating End-to-End
    AutoML Solutions*, you will cement your knowledge as you learn how to ingest data
    into Azure, score it with ML pipelines, and write your results to whatever location
    you want.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第10章*](B16595_10_ePub.xhtml#_idTextAnchor151)《创建端到端AutoML解决方案》中，你将在学习如何将数据导入Azure、使用ML管道进行评分以及将结果写入你想要的任何位置的过程中巩固你的知识。
