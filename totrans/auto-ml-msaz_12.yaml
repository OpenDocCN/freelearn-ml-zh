- en: '*Chapter 9*: Implementing a Batch Scoring Solution'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have trained regression, classification, and forecasting models with AutoML
    in Azure, and now it's time you learn how to put them in production and use them.
    **Machine learning** (**ML**) models, after all, are ultimately used to make predictions
    on new data, either in real time or in batches. In order to score new data points
    in batches in Azure, you must first create an ML pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: An ML pipeline lets you run repeatable Python code in the **Azure Machine Learning
    services** (**AMLS**) that you can run on a schedule. While you can run any Python
    code using an ML pipeline, here you will learn how to build pipelines for scoring
    new data.
  prefs: []
  type: TYPE_NORMAL
- en: You will begin this chapter by writing a simple ML pipeline to score data using
    the multiclass classification model you trained on the Iris dataset in [*Chapter
    5*](B16595_05_ePub.xhtml#_idTextAnchor068), *Building an AutoML Classification
    Solution*. Using the same data, you will then learn how to score new data points
    in parallel, enabling you to quickly score models with millions to billions of
    data points simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have written these two pipelines, you will learn how to create an ML
    pipeline for retraining an AutoML model. Finally, you will learn how to retrigger
    ML pipelines both manually through the GUI and programmatically through the **Azure
    ML SDK**.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to not only train AutoML models
    but also use them to score new data in a reproducible, automatable fashion. Furthermore,
    the code and techniques you learn here apply to all ML models, not just those
    that are AutoML-generated. Coding batch scoring solutions is a key skill for any
    ML engineer, and by working through the exercises in this chapter, you will be
    well on your way to mastering that skill.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating an ML pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a parallel scoring pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating an AutoML training pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Triggering and scheduling your ML pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will feature a lot of coding using Jupyter notebooks within AMLS.
    Thus, you will need a working internet connection, an **AMLS workspace**, and
    a **compute instance**. ML pipelines also require a **compute cluster**. You will
    also need to have trained and registered the Iris multiclass classification model
    in [*Chapter 5*](B16595_05_ePub.xhtml#_idTextAnchor068), *Building an AutoML Classification
    Solution*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the prerequisites for the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Access to the internet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A web browser, preferably Google Chrome or Microsoft Edge Chromium.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Microsoft Azure account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have created an AMLS workspace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have created the `compute-cluster` compute cluster in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand how to navigate to the Jupyter environment from an Azure compute
    instance as demonstrated in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have trained and registered the `Iris-Multi-Classification-AutoML` ML model
    in [*Chapter 5*](B16595_05_ePub.xhtml#_idTextAnchor068), *Building an AutoML Classification
    Solution*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code for this chapter is available here: [https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter09](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter09).'
  prefs: []
  type: TYPE_NORMAL
- en: Creating an ML pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML pipelines are Azure's solution for batch scoring ML models. You can use ML
    pipelines to score any model you train, including your own custom models as well
    as AutoML-generated models. They can only be created via code using the Azure
    ML Python SDK. In this section, you will code a simple pipeline to score diabetes
    data using the `Diabetes-AllData-Regression-AutoML` model you built in [*Chapter
    4*](B16595_04_ePub.xhtml#_idTextAnchor056), *Building an AutoML Regression Solution*.
  prefs: []
  type: TYPE_NORMAL
- en: As in other chapters, you will begin by opening your compute instance and navigating
    to your Jupyter notebook environment. You will then create and name a new notebook.
    Once your notebook is created, you will build, configure, and run an ML pipeline
    step by step. After confirming your pipeline has run successfully, you will then
    publish your ML pipeline to a pipeline endpoint. **Pipeline endpoints** are simply
    URLs, web addresses that call ML pipeline runs.
  prefs: []
  type: TYPE_NORMAL
- en: The following steps deviate greatly from previous chapters. You will have to
    load in many more libraries and also write a custom Python file for scoring new
    data. You will also learn how to create **environments**, that is, artifacts that
    specify which Python packages, package versions, and software settings you are
    using.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to creating an environment, you will need to containerize it. Finally,
    you will need to configure and run your ML pipeline, completing the process by
    publishing your pipeline to an endpoint. The entire process is shown in *Figure
    9.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Steps involved in creating your ML scoring pipeline ](img/Figure_9.1_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – Steps involved in creating your ML scoring pipeline
  prefs: []
  type: TYPE_NORMAL
- en: The `ML-Scoring-Pipeline.ipynb` file in the GitHub repository contains the code
    for all the steps.
  prefs: []
  type: TYPE_NORMAL
- en: Coding the first three steps of your ML scoring pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, load in your libraries, set up your AMLS resources, and create a dataset
    to score with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open **Azure Machine Learning studio** (**AML studio**) by navigating to [https://ml.azure.com/](https://ml.azure.com/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Compute** and start up a compute instance. Any compute instance will
    work, as they all link to the same Jupyter notebook environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new Jupyter notebook and name it `machine-learning-pipeline`. If you
    need a refresher on how to do this, please review [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open your newly created notebook and begin by importing all of the standard
    Azure libraries you will need using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056), *Building an AutoML Regression
    Solution*, explains `Workspace`, `Dataset`, `Datastore`, `Experiment`, and `ComputeTarget`.
    `Environment` lets you create an object that contains information on which Python
    packages your ML pipeline will need to install to run successfully. `Model` lets
    you retrieve your previously trained ML models.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing on, import all of the Azure ML pipeline libraries with the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`RunConfiguration` stores information that your ML pipeline will need to run,
    including the environment and base image. `CondaDependencies` lets you add Python
    packages to your environment. `Default_CPU_Image` is needed to specify which base
    image you will use in your run configuration. `PythonScriptStep` is a type of
    `Pipeline` is the core package to build ML pipelines. `PublishedPipeline` lets
    you publish ML pipelines to endpoints. `StepSequence` lets you set the order of
    your ML pipeline steps and `RunDetails` simply shows you the output of your ML
    pipeline as it runs.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If you are having trouble loading any Azure libraries, update the Azure ML
    SDK by running the `Update AzureML SDK.ipynb` notebook found here: [https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import `pandas`, `numpy`, and `os`. `os` will let you create and manipulate
    files and folders from your Jupyter notebook. `random` will let you generate random
    numbers, which is useful for simulating new Iris data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Connect your Jupyter notebook to your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you are prompted to log in, follow the instructions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your compute cluster to the one you created in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your datastore:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, you will create simulated Iris data to score. Begin by creating four
    variables that contain a list of numbers based on the minimum and maximum values
    of the original Iris dataset with the following code. These variables contain
    all the possible values contained within the Iris dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing with the creation of simulated Iris data, create an empty `pandas`
    DataFrame called IrisDF, with the appropriate column names. Also, create an empty
    list called `IrisList`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Continuing with the creation of simulated Iris data, use the `choice` function
    from the `random` package within a `for` loop to create 100 new data points, rounding
    each value to `1` decimal place.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Combine each set of four data points with the column names in a Python dictionary
    within the `for` loop and append that dictionary to `IrisList` row by row:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code will leave you with a list of randomly generated values from the original
    Iris dataset that can be turned into a `pandas` DataFrame.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Completing the creation of simulated Iris data, append `IrisList` to `IrisDF`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Register your simulated Iris data with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will save it to your datastore and create an Azure dataset named `Iris
    Scoring`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Python script to score data in your ML pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you will create a folder and write a Python script that your
    ML pipeline will execute to score data using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make a folder to hold your scoring script using `os`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For every ML pipeline step you make, you have to have an accompanying Python
    script.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Write a Python script to score new data. This script is long and has to be one
    block of code. Begin by writing out a new Python script file called `Iris_Scoring.py`
    using the `%%writefile` magic command. `Run` lets your program access the AMLS
    workspace you used to create the ML pipeline while running remotely on a compute
    cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, import the other
    Python packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The only new package here is `joblib`, which will let you load saved ML models.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, set a variable called
    `run` using the `Run` function. You can use this variable to set your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Continuing in the same cell as part of `Iris_Scoring.py`, we are going to create
    a function called `main`. This function will run the main part of your scoring
    code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, connect to your AMLS workspace using the `run` variable you created.
    Next, set your datastore to the default option and your dataset to `Iris Scoring`.
    Convert the `Iris Scoring` dataset into a `pandas` DataFrame called `scoringDF`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, load your `Iris-Multi-Classification-AutoML`
    model with the Azure `Model` and `joblib` packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, use your model to
    make predictions on `scoringDF`, save those predictions to a `pandas` `Series`,
    and add the predictions back to your `scoringDF` DataFrame in a new column called
    `Prediction`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: When you add the new column, the predictions will be in the correct order and
    match the corresponding row.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, make a folder called
    `Output_Folder` using `os`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will create a folder on your compute cluster to store your predictions
    temporarily so you can transfer them to your datastore.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing in the same cell as part of `Iris_Scoring.py`, specify a file called
    `Iris_Predictions.csv`. Then, use `os` to specify a path on the compute cluster
    where you will write that file out. Finally, use `to_csv` to write out `scoringDF`
    to your compute cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This piece of code will write your output to your compute cluster. This is necessary
    to move it into your datastore.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Continuing in the same cell as part of `Iris_Scoring.py`, upload `Iris_Predictions.csv`
    to your datastore. This code will write it to a folder called `Output_Folder`,
    matching the directory structure on your compute cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Completing `Iris_Scoring.py`, use `os` to remove the file and folder from your
    compute cluster. Finish the cell with boilerplate code that will automatically
    run your `main` function when the Python script is called within the ML pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This completes your Python script. Write the next piece of code in a new cell.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and containerizing an environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The difficult part is over and the rest is pure boilerplate, beginning with
    creating an environment. **Environments** are collections of Python packages that
    are required to run your code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a new cell, create an environment. Also, set a variable using `CondaDependencies`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: All the packages and versions of packages that are required to run your Python
    script will be added to the `conda_dep` variable in the next step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Attach Python packages to your `conda_dep` variable, beginning with the packages
    found in the `conda` package manager:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There are two package managers, `conda` and `pip`. `conda` automatically resolves
    dependencies for you. So, if a package requires another package, you don't have
    to worry about it. `pip` requires you to resolve those dependencies yourself.
    As a result, if a package is available in both `conda` and `pip`, always install
    it via `conda`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When installing packages, always specify the version. You can discover which
    version you are using by running the `!pip freeze` command in an empty cell. In
    addition to `numpy`, `joblib`, and `pandas`, AutoML-generated models also require
    `packaging` and `xgboost` to run.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Attach Python packages to your `conda_dep` variable that are not available
    in `conda` using `pip` instead:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There are three packages; `azureml-defaults` enables you to use standard Azure
    ML SDK functions, while `azureml-automl-core` and `azureml-automl-runtime` are
    required to score any AutoML-generated models.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Add the `conda_dep` variable to your environment and register the environment
    to your AMLS workspace by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that your environment is registered, you can call it anywhere in AMLS.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a `RunConfiguration` object for containerizing your environment. Set
    your environment, enable Docker, and use `DEFAULT_CPU_IMAGE` as your base image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will create a **Docker container**, a portable package of code that can
    be run anywhere as it contains all your code's scripts and dependencies. Your
    environment can now be utilized by your ML pipeline, which you will configure
    in the last series of steps.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring and running your ML scoring pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With your environment built and containerized, your Python script written,
    and all your AMLS resources set, you''re ready to configure and run your ML pipeline
    by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Configure your ML pipeline step with the following code. You need to give your
    step a name, `iris-scoring-step`, and specify your Python script name, Python
    script folder location, compute target, and run configuration. Always set `allow_reuse`
    to `False`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Setting `allow_reuse` to `True` is for debugging multi-step pipelines where
    you want to skip rerunning a successfully completed step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your **step sequence** and **pipeline object**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The step sequence is the order in which your ML pipeline steps will run.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Give your pipeline experiment run a name, `Iris-Scoring-Pipeline-Run`, and
    submit it with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, this is what kicks your pipeline off!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use `RunDetails` to watch your pipeline get built and execute in real time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As it runs, you will see a lot of logs. If your pipeline runs successfully,
    it will complete with the words **Finished**. You should see a graphic identical
    to the one in *Figure 9.2*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Successful pipeline run graphic ](img/Figure_9.2_B16595.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 9.2 – Successful pipeline run graphic
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Publish your pipeline to an endpoint with the following code, specifying a
    name, description, and version number:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'All published pipelines require version numbers set by the creator. Running
    this code will give you a published pipeline ID as well as a link to the endpoint,
    as seen in *Figure 9.3*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Successfully published pipeline ](img/Figure_9.3_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Successfully published pipeline
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have executed and published your scoring pipeline, you can examine
    and download your scoring file. It was saved to a folder called `Output_Folder`
    in a file called `Iris_Predictions.csv`. Access the file directly by navigating
    to your storage account. You can do this either from the Azure portal ([https://portal.azure.com](https://portal.azure.com))
    or via **AML** **studio**.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing your scored predictions via AML studio
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To access `Iris_Predictions.csv` and download it to your desktop, you first
    have to locate your storage account. You can find your storage account through
    AML studio.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will have you locate your datastore through the AML studio,
    access your storage account, navigate to the correct file, and download it to
    your local machine. This way, you can use the AI-generated predictions for any
    purpose you wish:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to AML studio at [https://ml.azure.com](https://ml.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Datastores** on the left-hand panel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the blue link to **workspaceblobstore** (default) in the center of the
    page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the blue link to your storage account under `automlexamplew` followed
    by a string of numbers. This will take you to your storage account resource in
    Azure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once in your storage account, click the blue link to **Containers** in the center-left
    of your screen. Clicking anywhere in the box will work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will now see a list of folders. Click the folder that begins with `azureml-blobstore-`
    followed by a unique identifier ID.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click `azureml`, `managed-dataset`, and `UI`. These folders hold logs for your
    experiments, among other objects. *Figure 9.4* shows the folder structure you
    need to follow to reach your file:![Figure 9.4 – Path to your output files ](img/Figure_9.4_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 9.4 – Path to your output files
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Iris_Predictions.csv**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the `Iris_Predictions.csv` to your local machine. It is a comma-separated
    file with headers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open up your file with Microsoft Excel or similar software to look at your data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That was a lot of work, but now you have a working pipeline endpoint that can
    score new data points in batch. This is a huge accomplishment, as many organizations
    have trouble setting up such workflows. You can also easily reuse this code in
    multiple projects, as the vast majority is boilerplate. While you have to alter
    the Python script and add packages as appropriate, this template can also be used
    to score both AutoML and custom ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you will learn how to score 10,000,000 data points in no time at all using
    a parallel scoring pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a parallel scoring pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Standard ML pipelines work just fine for the majority of ML use cases, but when
    you need to score a large amount of data at once, you need a more powerful solution.
    That's where `ParallelRunStep` comes in. `ParallelRunStep` is Azure's answer to
    scoring big data in batch. When you use `ParallelRunStep`, you leverage all of
    the cores on your compute cluster simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Say you have a compute cluster consisting of eight `Standard_DS3_v2` virtual
    machines. Each `Standard_DS3_v2` node has four cores, so you can perform 32 parallel
    scoring processes at once. This parallelization essentially lets you score data
    many times faster than if you used a single machine. Furthermore, it can easily
    scale vertically (increasing the size of each virtual machine in the cluster)
    and horizontally (increasing the node count).
  prefs: []
  type: TYPE_NORMAL
- en: This section will allow you to become a *big data* scientist who can score large
    batches of data. Here, you will again be using simulated Iris data, but instead
    of 100 rows, you will be scoring 10 million rows at once.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, this is an advanced solution that utilizes two pipeline steps,
    a step that scores data in parallel and a step that transfers data to an output
    folder. By working through this example, you'll understand how to create advanced
    multi-step pipeline runs to solve difficult problems.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Parallel runs score data in batches, dividing your dataset into many small parts.
    If you have any data preprocessing that relies on calculations made with previous
    rows, this preprocessing should be done in a separate `PythonScriptStep` before
    being passed on to `ParallelRunStep`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Much of this code is similar to the *Creating an ML pipeline* section. However,
    there are two pipeline steps to create instead of one. Furthermore, you will be
    introduced to new concepts such as `input` and `output` pipeline configuration
    options. At the end of this section, you will also publish your pipeline to an
    endpoint. *Figure 9.5* shows the entire process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Steps involved in creating a parallel scoring pipeline  ](img/Figure_9.5_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Steps involved in creating a parallel scoring pipeline
  prefs: []
  type: TYPE_NORMAL
- en: If you need a refresher on any of the steps, please refer to the *Creating an
    ML pipeline* section. You can find the code for all the steps in the `ML-Parallel-Pipeline.ipynb`
    file in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Coding the first three steps of your ML parallel scoring pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create your parallel scoring pipeline, begin with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to your Jupyter environment on your compute instance and create a new
    Jupyter notebook. Name it `ml-parallel-pipeline`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open your newly created notebook and import your standard Azure libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'From `azureml.core.compute`, import `ComputeTargetNext` and import all of the
    Azure ML pipeline libraries with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There are three additional packages compared to the previous section. `ParallelRunStep`
    is an ML pipeline step that lets you run Python code in parallel. `ParallelRunConfig`
    lets you configure `ParallelRunStep`. `PipelineData` lets you pass intermediate
    data from one step to another.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If you are having trouble loading any Azure libraries, update the Azure ML
    SDK by running the `Update AzureML SDK.ipynb` notebook found here: [https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import `pandas`, `numpy`, `os`, and `random`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As always, connect your Jupyter notebook to your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you are prompted to log in, follow the instructions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your compute cluster with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your datastore:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the following code to create simulated Iris data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing with the creation of simulated Iris data, create an empty `pandas`
    DataFrame and list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing with the creation of simulated Iris data, use the `choice` function
    from the `random` package within a `for` loop to create 10,000,000 new data points,
    rounding each value to `1` decimal place:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will take a while, so give it some time to run.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Completing the creation of simulated Iris data, append `IrisList` to `IrisDF`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Register your simulated Iris data with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will save it to your datastore and create an Azure dataset named `Iris
    Parallel Scoring`. You're now ready to write your Python script.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Python scripts to score data in your ML parallel pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, create a folder and write two Python scripts that your ML pipeline will
    execute to score data. You will need one step to make predictions and another
    step to transfer your output to a final destination on your datastore:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make a folder to hold your scoring script using `os`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This folder should already exist from the previous section, but this code will
    not error out since `exist_ok` is set to `True`. This folder will hold both the
    scripts you will write for your parallel pipeline run.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Write a Python script to score new data in parallel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This script is significantly different from the previous script, but also has
    to be in one cell. Begin by writing a new Python script file called `Iris_Parallel_Scoring.py`
    using the `%%writefile` magic command. Begin by loading in your Azure libraries.
    You should recognize all of them from the previous section.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing in the same cell as part of `Iris_Parallel_Scoring.py`, import other
    Python packages, including the new `argparse` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This package lets you pass arguments into your script. **Arguments** are flexible
    pieces of code that you can pass into your pipeline at runtime. For example, you
    can use arguments to pass in different datastores or datasets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing in the same cell as part of `Iris_Parallel_Scoring.py`, set a variable
    called `run` using the `Run` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Continuing in the same cell as part of `Iris_Parallel_Scoring.py`, create a
    function called `init`. This function will pass in your arguments and load your
    ML model, setting it to a global variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`parser` to store your arguments and add the `model_name` argument to that
    variable. `ParallelRunStep` also passes hidden arguments behind the scenes, so
    you also need to set `unknown_args`. Once that is done, use `joblib` to load your
    model using the `model_name` argument, as shown in the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Continuing in the same cell as part of `Iris_Parallel_Scoring.py`, create a
    function called `main`. This function will score your data and return the result,
    which will be automatically stored in a file called `parallel_run_step.txt.model`
    with the Azure `Model` and `joblib` packages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, you will use the `predict` function on your `model` variable to make
    predictions. Notice that the data is automatically passed into this function as
    a `pandas` DataFrame called `input_data`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You then convert these predictions into a series and add it back to `input_data`
    as a column called `Prediction`. Completing `Iris_Parallel_Scoring.py`, you return
    the finished `input_data` DataFrame to be automatically written to the text file:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Write a Python script to transfer your results to the output location of your
    choice. `ParallelRunStep` outputs a file called `parallel_run_step.txt`. This
    will be stored as pipeline data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pipeline data is data that is saved in your datastore as an intermediate step
    to be passed on to another ML pipeline step. Furthermore, `parallel_run_step.txt`
    has no headers and you need to add them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Begin by writing out a new Python script file called `Iris_Parallel_Output_Creation.py`
    using the `%%writefile` magic command. Start by loading in your Azure libraries
    as usual:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    load in all of the standard Python packages you need:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will once again need `argparse` to pass in arguments, namely the folder
    that holds `parallel_run_step.txt`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    set a variable called `run` using the `Run` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    pass in your arguments to access the folder that holds `parallel_run_step.txt`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Call the `input_data_folder` argument and pass it in as an argument when you
    configure this pipeline step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`, write
    a function called `main`. This function will transfer your predictions from an
    intermediate pipeline data location to its final destination.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Begin by using `os` and `input_data_folder` to find the path holding `parallel_run_step.txt`.
    Then, read it in as a space-delimited text file with no headers in a `pandas`
    DataFrame called `result` using the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    as part of your `main` function, add columns to your `result` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It's important to remember that `parallel_run_step.txt` never has headers, so
    you need to enter the columns manually in the correct order as shown in the preceding
    code.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    as part of your `main` function, connect to your AMLS workspace using the `run`
    variable and set a variable for your datastore:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the datastore that will hold your final output file.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing in the same cell as part of `Iris_Parallel_Output_Creation.py`,
    as part of your `main` function, use `os` to create a folder called `Output_Folder`
    on your compute cluster, and write a CSV file called `Iris_Parallel_Predictions.csv`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Even though the original `parallel_run_step.txt` file was space-delimited, you
    can set the delimiter on your final output file to whatever you wish.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Completing `Iris_Parallel_Output_Creation.py`, upload `Iris_Parallel_Predictions.csv`
    to your datastore in a folder called `Output_Folder`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, use `os` to remove both `Iris_Parallel_Predictions.csv` and `Output_Folder`
    from your compute cluster. Finally, trigger your `main` function as you did in
    the *Creating an ML pipeline* section:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With both steps written, the rest of the code is pure boilerplate to containerize
    your environment and to configure and run your pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring and running your ML parallel scoring pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since you''ve already built your environment in the *Creating an ML pipeline*
    section, all that''s really left is configuring your ML pipeline steps. Use the
    following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a new cell, retrieve the environment that you created in the *Creating an
    ML pipeline* section with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, define a variable that defines your pipeline data and assigns it to a
    datastore:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the location that will hold `parallel_run_step.txt` between your first
    and second steps. You must also give this pipeline data object a name.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Enable Docker on your environment and specify `DEFAULT_CPU_IMAGE` as your base
    image for your `ParallelRunStep`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You do not need to specify a `RunConfiguration` object for `ParallelRunStep`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a `RunConfiguration` object for your output creation step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your parallel run configurations with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You need to input the name of your Python script as well as the source directory
    that holds it. You need to specify how much data will be scored in parallel with
    `mini_batch_size`. For all `error_threshold` is how many times the step can fail
    in parallel before the entire pipeline fails. Next, setting `output_action` to
    `append_row` will automatically generate `parallel_run_step.txt` for you. Other
    options for `output_action` are labor-intensive.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Set your compute target to the appropriate compute cluster and specify your
    environment. Leave `run_invocation_timeout` at 60 seconds so your run will fail
    if it idles for too long and set `node_count` equal to the number of nodes in
    your compute cluster to ensure maximum parallelization. Lastly, set `logging_level`
    to `DEBUG` for informative logs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set the two variables that you will need to create your parallel scoring step,
    your dataset, and your model name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Datasets need to be passed in with the `as_named_input` code and appear as the
    `input_data` variable in your Python script.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create your parallel scoring step using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You need to give the step a name, `iris-parallel-scoring-step`. No spaces are
    allowed. Pass in your configurations using `parallel_run_config` and pass in your
    dataset using `inputs`. Set `output` to your pipeline data object and pass in
    your model name as an argument. As always, set `allow_reuse` equal to `False`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create your output creation step using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Give this step the name `iris-output-step` and pass in your script name and
    source directory. For `arguments` and `input`, you need to pass in `parallel_run_output`.
    This lets your output creation step use `parallel_run_step.txt` generated by your
    parallel scoring step. Then, set your compute target, specify your run configuration,
    and set `allow_reuse` to `False`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your step sequence and create a pipeline object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This time, you have two steps to set, `parallel_run_step` and `output_step`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Give your pipeline experiment run a name, `Iris-Parallel-Scoring-Pipeline-Run`,
    and submit it to your compute cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `RunDetails` to watch your pipeline execute in real time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Notice how fast this scores your data. If your pipeline runs successfully,
    it will complete with the word **Finished**. You should see a graphic identical
    to the one in *Figure 9.6*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.6 – Successful parallel pipeline run graphic ](img/Figure_9.6_B16595.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 9.6 – Successful parallel pipeline run graphic
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Publish your pipeline to an endpoint as you did in the previous section, naming
    it `Iris-Parallel-Scoring-Pipeline` or whatever you wish:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this code will give you your published pipeline ID as well as a link
    to the endpoint, as seen in *Figure 9.7*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.7 – Successfully published parallel pipeline ](img/Figure_9.7_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – Successfully published parallel pipeline
  prefs: []
  type: TYPE_NORMAL
- en: You can now examine and download your scoring file as you did in the previous
    section. Look inside `Output_Folder` in your datastore for a file called `Iris_Parallel_Predictions.csv`.
    It's quite a bit larger than your last file, at around 30 MB.
  prefs: []
  type: TYPE_NORMAL
- en: With both a standard scoring pipeline and a parallel run pipeline built, you
    are now at the cutting edge of AMLS. Both of these pipelines can be used to score
    not only AutoML-generated ML models, but custom models as well.
  prefs: []
  type: TYPE_NORMAL
- en: Even experienced data scientists have a hard time building these batch scoring
    solutions. So, you have acquired a desirable, marketable skill that will enable
    you to work alongside seasoned experts.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will learn how to build a pipeline for training AutoML
    models instead of scoring.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an AutoML training pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, it's necessary to retrain a model that you trained in AutoML. ML
    models can degrade over time if the relationship between your data and your target
    variable changes. This is true for all ML models, not just ones generated by AutoML.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine, for example, that you build an ML model to predict demand for frozen
    pizza at a supermarket, and then one day, a famous pizza chain sets up shop next
    door. It's very likely that consumer buying behavior will change, and you will
    need to retrain the model. This is true for all ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, AMLS has specialized ML pipeline steps built specifically for retraining
    models. In this section, we are going to use one of those steps, the AutoML step.
    The **AutoML step** lets you retrain models easily whenever you want, either with
    a push of a button or on a schedule.
  prefs: []
  type: TYPE_NORMAL
- en: Here, you will build a two-step ML pipeline where you will first train a model
    with an AutoML step and register it with a typical Python script step. This will
    enable you to build complete end-to-end solutions with automated scoring and training,
    completing your skillset. Furthermore, this will familiarize you with the AutoML
    step and all of its caveats.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Not all ML models require retraining, particularly those that predict physical
    phenomena, as the relationship between your data and the target variable is unlikely
    to change over time. However, most ML models will improve with additional data
    points, so it does make sense to retrain models as you collect and label more
    data.
  prefs: []
  type: TYPE_NORMAL
- en: By now, you should know what to expect in terms of creating ML pipelines. Most
    of the steps will be familiar to you, but you will have to work with specialized
    forms of pipeline data that pass data from your training step to your model registration
    step.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Python scripts involved in this pipeline are much simpler than those involved
    in scoring pipelines, and thus require less customization when you try it with
    your own data. At the end of this section, like others, you will also publish
    your AutoML training pipeline to an endpoint. *Figure 9.8* outlines the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.8 – Steps involved in setting up an AutoML retraining pipeline ](img/Figure_9.8_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 – Steps involved in setting up an AutoML retraining pipeline
  prefs: []
  type: TYPE_NORMAL
- en: This process is a little bit different than the other pipelines, as you need
    to configure your AutoML settings early on. You can find the code for all the
    steps in the `ML-Retraining-Pipeline.ipynb` file in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Coding the first two steps of your AutoML training pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create your AutoML training pipeline, begin with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to your Jupyter environment on your compute instance and create a new
    Jupyter notebook. Name it `automl-training-pipeline`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open your newly created notebook and import the usual set of Azure libraries
    along with `AutoMLConfig`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`AutoMLConfig` lets you configure AutoML training runs.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing on, import the necessary Azure ML pipeline libraries with the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There are two new packages. `AutoMLStep` is an ML pipeline step that lets you
    run AutoML training runs. `TrainingOutput` lets you access the output from your
    AutoML step to pass on to your model registration step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import `os`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the only non-Azure Python package you will need to make this pipeline,
    and it will be used to create a new folder.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Connect your Jupyter notebook to your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Log in if prompted by following the instructions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your compute cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your datastore:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Retrieve your `Iris Training` dataset with the following code. You will pass
    this dataset into your AutoML configuration settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Retrieve the environment named `AutoML Environment` that you created in the
    *Creating an ML pipeline* section of this chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will be used only for your model registration step; your AutoML training
    step will use a standard, autogenerated environment.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring your AutoML model training settings and step
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, you''ll configure everything related to your AutoML training step with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Set variables to pass into your AutoML configuration settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Explanations for these settings can be found in [*Chapter 5*](B16595_05_ePub.xhtml#_idTextAnchor068),
    *Building an AutoML Classification Solution*. One new setting is `iterations`.
    This will be used to determine how many AutoML models should be trained concurrently;
    this value should equal the number of nodes on your compute cluster to ensure
    maximum parallelization.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Configure your AutoML training run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: An explanation for these settings can be found in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution*. If you would like higher accuracy, adjust
    `experiment_timeout_minutes` to give AutoML more time to train. Note that you
    are passing in your dataset here.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set the output for AutoML metrics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code is standard boilerplate used in every AutoML step. It saves metrics
    from your AutoML run as intermediate pipeline data that you can use to pass on
    to other steps in your ML pipeline.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set the output for your best model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code is standard boilerplate used in every AutoML step. It saves information
    about the best model from your AutoML run as intermediate pipeline data to pass
    on to your model registration step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Configure your AutoML step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: All you need to do is give it a name, pass in your AutoML configuration settings,
    and specify `metrics_data` and `model_data` as output. As always, set `allow_reuse`
    to `False`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Python script to register your model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With your AutoML training step configured, you now need to write another script
    to extract and register your model using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make a folder to hold your training script using `os`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Write a Python script to register your model. This script is very short compared
    to the others you wrote. Begin by writing out a new Python script file called
    `Iris_Model_Registration.py` using the `%%writefile` magic command and loading
    in your Azure libraries and `argparse`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing in the same cell as part of `Iris_Model_Registration_Scoring.py`,
    set a variable called `run` using the `Run` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing in the same cell as part of `Iris_Model_Registration_Scoring.py`,
    pass in your arguments to access the best model as trained by AutoML as well as
    the dataset you used to train the model. For this, you will need three arguments,
    `model_name`, `model_path`, and `dataset_name`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing in the same cell as part of `Iris_Model_Registration_Scoring.py`,
    write a function called `main`. This function will register your best model. Begin
    by connecting to your AMLS workspace using the `run` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Continuing in the same cell as part of `Iris_Model_Registration_Scoring.py`,
    as part of your `main` function, retrieve your dataset through the `dataset_name`
    argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use the `Dataset.Scenario.Training` line of code to specify the scenario in
    which it was used. This information will be saved when you register your model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Continuing in the same cell as part of `Iris_Model_Registration_Scoring.py`,
    as part of your `main` function, register your model using the `model_path` and
    `model_name` arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: While `model_name` is something you specify, `model_path` will be automatically
    generated from `model_data`. The dataset you used to train your model will also
    be saved using this code. Finally, complete `Iris_Model_Registration_Scoring.py`
    with the boilerplate code that triggers `main`.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring and running your AutoML training pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All that''s left is to containerize your environment, configure your model
    registration step, and run and publish your pipeline by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `RunConfiguration` object for the model registration step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that this uses `AutoML Environment`, but you can get away with using a
    simpler environment without `pandas` or NumPy if you so desire.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set variables for your model name and dataset name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Your model name will be used to register the best model that AutoML produces
    and is your choice. Your dataset name, on the other hand, should match the dataset
    you used to train your model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Configure your model registration step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, you must pass in three arguments, `model_name`, `model_data`, and `dataset_name`,
    and pass in `model_data` as input. This is because `model_data` is pipeline data
    generated by your AutoML training step, while `model_name` and `dataset_name`
    are simple string variables. As always, set `allow_reuse` to `False`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your step sequence and create a pipeline object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This time, you have two steps to set, `automl_training step` and `model_registration_step`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Give your pipeline experiment run a name, `Iris-AutoML-Training-Pipeline-Run`,
    and submit it to your compute cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will take much longer than your other pipelines, perhaps around a half
    hour.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use `RunDetails` to watch your pipeline execute in real time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If your pipeline runs successfully, it will complete with the word **Finished**.
    You should see a graphic identical to the one in *Figure 9.9*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.9 – Successful AutoML training pipeline](img/Figure_9.9_B16595.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 9.9 – Successful AutoML training pipeline
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Publish your pipeline to an endpoint as you did in the previous section, naming
    it `Iris-AutoML-Training-Pipeline` or whatever you wish:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running this code will give you your published pipeline ID as well as a link
    to your endpoint, as seen in *Figure 9.10*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.10 – Successfully published AutoML training pipeline](img/Figure_9.10_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.10 – Successfully published AutoML training pipeline
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes when you''re running an ML pipeline, your computer will crash. However,
    your pipeline run will continue to run and you will still be able to publish it
    upon completion. To retrieve a completed pipeline so you can publish it, use the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: You have now built three ML pipelines, a standard scoring pipeline, a parallel
    run pipeline, and an AutoML training pipeline. This was not a trivial effort,
    but all that hard work has paid off. You have mastered one of the most complex
    parts of AMLS.
  prefs: []
  type: TYPE_NORMAL
- en: While making these pipelines is quite an undertaking, once you have them, they
    are very easy to manually rerun or automatically schedule, as you will see in
    the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Triggering and scheduling your ML pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the biggest problems data scientists face is creating easy, rerunnable,
    production-ready code and scheduling it in an automatic, reliable manner. You've
    already accomplished the first part by creating your three ML pipelines. Now,
    it's time to learn how to do the second part.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you will first learn how to manually trigger the pipelines
    you've created through the GUI. Then, you will learn how to trigger the pipelines
    via code, both manually and on an automated schedule. This will enable you to
    put your ML pipelines into production, generating results on an hourly, daily,
    weekly, or monthly basis.
  prefs: []
  type: TYPE_NORMAL
- en: Triggering your published pipeline from the GUI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Triggering your published pipeline from the AML studio GUI is easy. However,
    you cannot set up an automated schedule for your ML pipelines at this time. As
    such, it is most useful for triggering training pipelines when you notice that
    your results seem off. Use the following steps to manually trigger your ML pipeline
    through the AML studio:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to [https://ml.azure.com](https://ml.azure.com) to access AML studio.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Pipelines** under **Assets** on the left-hand side.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Pipeline endpoints** near the top of the page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the blue link to **Iris-AutoML-Training-Pipeline**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Submit**. This will open up a dialog box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select an experiment name from the drop-down box under `Iris-AutoML-Training-Pipeline-Run`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Submit**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click **Pipelines** under **Assets** again and, on the top line, you should
    see a new run, as shown in *Figure 9.11*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.11 – Pipeline run submitted through the GUI ](img/Figure_9.11_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.11 – Pipeline run submitted through the GUI
  prefs: []
  type: TYPE_NORMAL
- en: Compared to making an ML pipeline, resubmitting it is very easy. Next, we will
    look at ways to trigger our pipeline through code and create an automatic schedule.
  prefs: []
  type: TYPE_NORMAL
- en: Triggering and scheduling a published pipeline through code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Triggering a published ML pipeline through code first requires you to obtain
    your pipeline ID. These were generated at the end of the previous sections whenever
    you published a pipeline. You can also find your pipeline ID by clicking on individual
    pipelines found under **Pipeline endpoints** through the AML studio. You will
    also need your pipeline IDs to set up schedules through code.
  prefs: []
  type: TYPE_NORMAL
- en: 'All the code for this section can be found in the `ML-Pipeline-Scheduling.ipynb`
    file in the GitHub repository. Begin by opening a Jupyter notebook and following
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new Jupyter notebook as you have before. Name it `pipeline-scheduling`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open your notebook and import the required Azure libraries, three of which
    are new. `PublishedPipeline` lets you access any ML pipelines you have published.
    `Schedule` and `ScheduleRecurrence` let you schedule ML pipelines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To manually trigger an ML pipeline, use the following code by replacing `your-published-pipeline-id`
    with the ID of your published AutoML training pipeline. That''s it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To create a schedule for running your ML pipeline, first determine an interval
    with the following code. The interval options are `Minute`, `Hour`, `Day`, `Week`,
    or `Month`. You can also specify `start_time` and `time_zone` as optional arguments.
    Another optional argument is `status`, which you can set to `Disabled` to turn
    off your schedule:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create your schedule by giving it a name and passing in your `recurrence` settings,
    experiment name, published pipeline ID, and a description:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You have now created a schedule that will automatically trigger your AutoML
    training pipeline once a day. This schedule will automatically spin up your compute
    cluster, train a model, and spin down. Many companies spend years trying to figure
    out how best to schedule ML training and scoring runs in a timely, reliable manner,
    and you've accomplished this task in a mere chapter!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have now implemented a fully automated ML batch scoring solution using an
    AutoML trained model. You've created pipelines that can score models, pipelines
    that can process big data in parallel, and pipelines that can retrain AutoML models.
    You can trigger them whenever you want and you can even set up an automated scoring
    schedule. This is no small feat, as many organizations have spent years trying
    to learn best practices for these tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 10*](B16595_10_ePub.xhtml#_idTextAnchor151), *Creating End-to-End
    AutoML Solutions*, you will cement your knowledge as you learn how to ingest data
    into Azure, score it with ML pipelines, and write your results to whatever location
    you want.
  prefs: []
  type: TYPE_NORMAL
