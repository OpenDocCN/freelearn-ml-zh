- en: Chapter 2. Handling Files, Cameras, and GUIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Installing OpenCV and running samples is fun, but at this stage, we want to
    try it out ourselves. This chapter introduces OpenCV's I/O functionality. We also
    discuss the concept of a project and the beginnings of an object-oriented design
    for this project, which we will flesh out in subsequent chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'By starting with a look at the I/O capabilities and design patterns, we will
    build our project in the same way we would make a sandwich: from the outside in.
    Bread slices and spread, or endpoints and glue, come before fillings or algorithms.
    We choose this approach because computer vision is mostly extroverted—it contemplates
    the real world outside our computer—and we want to apply all our subsequent algorithmic
    work to the real world through a common interface.'
  prefs: []
  type: TYPE_NORMAL
- en: Basic I/O scripts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most CV applications need to get images as input. Most also produce images as
    output. An interactive CV application might require a camera as an input source
    and a window as an output destination. However, other possible sources and destinations
    include image files, video files, and raw bytes. For example, raw bytes might
    be transmitted via a network connection, or they might be generated by an algorithm
    if we incorporate procedural graphics into our application. Let's look at each
    of these possibilities.
  prefs: []
  type: TYPE_NORMAL
- en: Reading/writing an image file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OpenCV provides the `imread()` and `imwrite()` functions that support various
    file formats for still images. The supported formats vary by system but should
    always include the BMP format. Typically, PNG, JPEG, and TIFF should be among
    the supported formats too.
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore the anatomy of the representation of an image in Python and NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: 'No matter the format, each pixel has a value, but the difference is in how
    the pixel is represented. For example, we can create a black square image from
    scratch by simply creating a 2D NumPy array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If we print this image to a console, we obtain the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Each pixel is represented by a single 8-bit integer, which means that the values
    for each pixel are in the 0-255 range.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now convert this image into **Blue-green-red** (**BGR**) using `cv2.cvtColor`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s observe how the image has changed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, each pixel is now represented by a three-element array, with
    each integer representing the B, G, and R channels, respectively. Other color
    spaces, such as HSV, will be represented in the same way, albeit with different
    value ranges (for example, the hue value of the HSV color space has a range of
    0-180) and different numbers of channels.
  prefs: []
  type: TYPE_NORMAL
- en: You can check the structure of an image by inspecting the `shape` property,
    which returns rows, columns, and the number of channels (if there is more than
    one).
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will print `(3,3)`. If you then converted the image to BGR,
    the shape would be `(3,3,3)`, which indicates the presence of three channels per
    pixel.
  prefs: []
  type: TYPE_NORMAL
- en: 'Images can be loaded from one file format and saved to another. For example,
    let''s convert an image from PNG to JPEG:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most of the OpenCV functionalities that we use are in the `cv2` module. You
    might come across other OpenCV guides that instead rely on the `cv` or `cv2.cv`
    modules, which are legacy versions. The reason why the Python module is called
    `cv2` is not because it is a Python binding module for OpenCV 2.x.x, but because
    it has introduced a better API, which leverages object-oriented programming as
    opposed to the previous `cv` module, which adhered to a more procedural style
    of programming.
  prefs: []
  type: TYPE_NORMAL
- en: By default, `imread()` returns an image in the BGR color format even if the
    file uses a grayscale format. BGR represents the same color space as **red-green-blue**
    (**RGB**), but the byte order is reversed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, we may specify the mode of `imread()` to be one of the following
    enumerators:'
  prefs: []
  type: TYPE_NORMAL
- en: '`IMREAD_ANYCOLOR = 4`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IMREAD_ANYDEPTH = 2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IMREAD_COLOR = 1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IMREAD_GRAYSCALE = 0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IMREAD_LOAD_GDAL = 8`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IMREAD_UNCHANGED = -1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, let''s load a PNG file as a grayscale image (losing any color
    information in the process), and then, save it as a grayscale PNG image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: To avoid unnecessary headaches, use absolute paths to your images (for example,
    `C:\Users\Joe\Pictures\MyPic.png` on Windows or `/home/joe/pictures/MyPic.png`
    on Unix) at least while you're familiarizing yourself with OpenCV's API. The path
    of an image, unless absolute, is relative to the folder that contains the Python
    script, so in the preceding example, `MyPic.png` would have to be in the same
    folder as your Python script or the image won't be found.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the mode, `imread()` discards any alpha channel (transparency).
    The `imwrite()` function requires an image to be in the BGR or grayscale format
    with a certain number of bits per channel that the output format can support.
    For example, `bmp` requires 8 bits per channel, while PNG allows either 8 or 16
    bits per channel.
  prefs: []
  type: TYPE_NORMAL
- en: Converting between an image and raw bytes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Conceptually, a byte is an integer ranging from 0 to 255\. In all real-time
    graphic applications today, a pixel is typically represented by one byte per channel,
    though other representations are also possible.
  prefs: []
  type: TYPE_NORMAL
- en: An OpenCV image is a 2D or 3D array of the `.array` type. An 8-bit grayscale
    image is a 2D array containing byte values. A 24-bit BGR image is a 3D array,
    which also contains byte values. We may access these values by using an expression,
    such as `image[0, 0]` or `image[0, 0, 0]`. The first index is the pixel's *y*
    coordinate or row, `0` being the top. The second index is the pixel's *x* coordinate
    or column, `0` being the leftmost. The third index (if applicable) represents
    a color channel.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in an 8-bit grayscale image with a white pixel in the upper-left
    corner, `image[0, 0]` is `255`. For a 24-bit BGR image with a blue pixel in the
    upper-left corner, `image[0, 0]` is `[255, 0, 0]`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As an alternative to using an expression, such as `image[0, 0]` or `image[0,
    0] = 128`, we may use an expression, such as `image.item((0, 0))` or `image.setitem((0,
    0), 128)`. The latter expressions are more efficient for single-pixel operations.
    However, as we will see in subsequent chapters, we usually want to perform operations
    on large slices of an image rather than on single pixels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Provided that an image has 8 bits per channel, we can cast it to a standard
    Python `bytearray`, which is one-dimensional:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Conversely, provided that `bytearray` contains bytes in an appropriate order,
    we can cast and then reshape it to get a `numpy.array` type that is an image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As a more complete example, let''s convert `bytearray`, which contains random
    bytes to a grayscale image and a BGR image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: After running this script, we should have a pair of randomly generated images,
    `RandomGray.png` and `RandomColor.png`, in the script's directory.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here, we use Python's standard `os.urandom()` function to generate random raw
    bytes, which we will then convert to a NumPy array. Note that it is also possible
    to generate a random NumPy array directly (and more efficiently) using a statement,
    such as `numpy.random.randint(0, 256, 120000).reshape(300, 400)`. The only reason
    we use `os.urandom()` is to help demonstrate a conversion from raw bytes.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing image data with numpy.array
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you have a better understanding of how an image is formed, we can start
    performing basic operations on it. We know that the easiest (and most common)
    way to load an image in OpenCV is to use the `imread` function. We also know that
    this will return an image, which is really an array (either a 2D or 3D one, depending
    on the parameters you passed to `imread()`).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `y.array` structure is well optimized for array operations, and it allows
    certain kinds of bulk manipulations that are not available in a plain Python list.
    These kinds of `.array` type-specific operations come in handy for image manipulations
    in OpenCV. Let''s explore image manipulations from the start and step by step
    though, with a basic example: say you want to manipulate a pixel at the coordinates,
    (0, 0), of a BGR image and turn it into a white pixel.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: If you then showed the image with a standard `imshow()` call, you will see a
    white dot in the top-left corner of the image. Naturally, this isn't very useful,
    but it shows what can be accomplished. Let's now leverage the ability of `numpy.array`
    to operate transformations to an array much faster than a plain Python array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say that you want to change the blue value of a particular pixel, for
    example, the pixel at coordinates, (150, 120). The `numpy.array` type provides
    a very handy method, `item()`, which takes three parameters: the x (or left) position,
    y (or top), and the index within the array at (x, y) position (remember that in
    a BGR image, the data at a certain position is a three-element array containing
    the B, G, and R values in this order) and returns the value at the index position.
    Another `itemset()` method sets the value of a particular channel of a particular
    pixel to a specified value (`itemset()` takes two arguments: a three-element tuple
    (x, y, and index) and the new value).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we will change the value of blue at (150, 120) from its current
    value (127) to an arbitrary 255:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember that we do this with `numpy.array` for two reasons: `numpy.array`
    is an extremely optimized library for these kind of operations, and because we
    obtain more readable code through NumPy''s elegant methods rather than the raw
    index access of the first example.'
  prefs: []
  type: TYPE_NORMAL
- en: This particular code doesn't do much in itself, but it does open a world of
    possibilities. It is, however, advisable that you utilize built-in filters and
    methods to manipulate an entire image; the above approach is only suitable for
    small regions of interest.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at a very common operation, namely, manipulating channels.
    Sometimes, you'll want to zero-out all the values of a particular channel (B,
    G, or R).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using loops to manipulate the Python arrays is very costly in terms of runtime
    and should be avoided at all costs. Using array indexing allows for efficient
    manipulation of pixels. This is a costly and slow operation, especially if you
    manipulate videos, you''ll find yourself with a jittery output. Then a feature
    called indexing comes to the rescue. Setting all G (green) values of an image
    to `0` is as simple as using this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This is a fairly impressive piece of code and easy to understand. The relevant
    line is the last one, which basically instructs the program to take all pixels
    from all rows and columns and set the resulting value at index one of the three-element
    array, representing the color of the pixel to `0`. If you display this image,
    you will notice a complete absence of green.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a number of interesting things we can do by accessing raw pixels
    with NumPy''s array indexing; one of them is defining **regions of interests**
    (**ROI**). Once the region is defined, we can perform a number of operations,
    namely, binding this region to a variable, and then even defining a second region
    and assigning it the value of the first one (visually copying a portion of the
    image over to another position in the image):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: It's important to make sure that the two regions correspond in terms of size.
    If not, NumPy will (rightly) complain that the two shapes mismatch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, there are a few interesting details we can obtain from `numpy.array`,
    such as the image properties using this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'These three properties are in this order:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Shape**: NumPy returns a tuple containing the width, height, and—if the image
    is in color—the number of channels. This is useful to debug a type of image; if
    the image is monochromatic or grayscale, it will not contain a channel''s value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Size**: This property refers to the size of an image in pixels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Datatype**: This property refers to the datatype used for an image (normally
    a variation of an unsigned integer type and the bits supported by this type, that
    is, `uint8`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All in all, it is strongly advisable that you familiarize yourself with NumPy
    in general and `numpy.array` in particular when working with OpenCV, as it is
    the foundation of an image processing done with Python.
  prefs: []
  type: TYPE_NORMAL
- en: Reading/writing a video file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OpenCV provides the `VideoCapture` and `VideoWriter` classes that support various
    video file formats. The supported formats vary by system but should always include
    an AVI. Via its `read()` method, a `VideoCapture` class may be polled for new
    frames until it reaches the end of its video file. Each frame is an image in a
    BGR format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conversely, an image may be passed to the `write()` method of the `VideoWriter`
    class, which appends the image to a file in `VideoWriter`. Let''s look at an example
    that reads frames from one AVI file and writes them to another with a YUV encoding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The arguments to the `VideoWriter` class constructor deserve special attention.
    A video''s filename must be specified. Any preexisting file with this name is
    overwritten. A video codec must also be specified. The available codecs may vary
    from system to system. These are the options that are included:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cv2.VideoWriter_fourcc(''I'',''4'',''2'',''0'')`: This option is an uncompressed
    YUV encoding, 4:2:0 chroma subsampled. This encoding is widely compatible but
    produces large files. The file extension should be `.avi`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.VideoWriter_fourcc(''P'',''I'',''M'',''1'')`: This option is MPEG-1\.
    The file extension should be `.avi`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.VideoWriter_fourcc(''X'',''V'',''I'',''D'')`: This option is MPEG-4 and
    a preferred option if you want the resulting video size to be average. The file
    extension should be `.avi`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.VideoWriter_fourcc(''T'',''H'',''E'',''O'')`: This option is Ogg Vorbis.
    The file extension should be `.ogv`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.VideoWriter_fourcc(''F'',''L'',''V'',''1'')`: This option is a Flash video.
    The file extension should be `.flv`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A frame rate and frame size must be specified too. Since we are copying video
    frames from another video, these properties can be read from the `get()` method
    of the `VideoCapture` class.
  prefs: []
  type: TYPE_NORMAL
- en: Capturing camera frames
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A stream of camera frames is represented by the `VideoCapture` class too. However,
    for a camera, we construct a `VideoCapture` class by passing the camera''s device
    index instead of a video''s filename. Let''s consider an example that captures
    10 seconds of video from a camera and writes it to an AVI file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Unfortunately, the `get()` method of a `VideoCapture` class does not return
    an accurate value for the camera''s frame rate; it always returns `0`. The official
    documentation at [http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html](http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html)
    reads:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"When querying a property that is not supported by the backend used by the
    `VideoCapture` class, value `0` is returned."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This occurs most commonly on systems where the driver only supports basic functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: For the purpose of creating an appropriate `VideoWriter` class for the camera,
    we have to either make an assumption about the frame rate (as we did in the code
    previously) or measure it using a timer. The latter approach is better and we
    will cover it later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The number of cameras and their order is of course system-dependent. Unfortunately,
    OpenCV does not provide any means of querying the number of cameras or their properties.
    If an invalid index is used to construct a `VideoCapture` class, the `VideoCapture`
    class will not yield any frames; its `read()` method will return `(false, None)`.
    A good way to prevent it from trying to retrieve frames from `VideoCapture` that
    were not opened correctly is to use the `VideoCapture.isOpened` method, which
    returns a Boolean.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `read()` method is inappropriate when we need to synchronize a set of cameras
    or a multihead camera (such as a stereo camera or Kinect). Then, we use the `grab()`
    and `retrieve()` methods instead. For a set of cameras, we use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Displaying images in a window
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the most basic operations in OpenCV is displaying an image. This can
    be done with the `imshow()` function. If you come from any other GUI framework
    background, you would think it sufficient to call `imshow()` to display an image.
    This is only partially true: the image will be displayed, and will disappear immediately.
    This is by design, to enable the constant refreshing of a window frame when working
    with videos. Here''s a very simple example code to display an image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The `imshow()` function takes two parameters: the name of the frame in which
    we want to display the image, and the image itself. We''ll talk about `waitKey()`
    in more detail when we explore the displaying of frames in a window.'
  prefs: []
  type: TYPE_NORMAL
- en: The aptly named `destroyAllWindows()` function disposes of all the windows created
    by OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying camera frames in a window
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'OpenCV allows named windows to be created, redrawn, and destroyed using the
    `namedWindow()`, `imshow()`, and `destroyWindow()` functions. Also, any window
    may capture keyboard input via the `waitKey()` function and mouse input via the
    `setMouseCallback()` function. Let''s look at an example where we show the frames
    of a live camera input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The argument for `waitKey()` is a number of milliseconds to wait for keyboard
    input. The return value is either `-1` (meaning that no key has been pressed)
    or an ASCII keycode, such as `27` for *Esc*. For a list of ASCII keycodes, see
    [http://www.asciitable.com/](http://www.asciitable.com/). Also, note that Python
    provides a standard function, `ord()`, which can convert a character to its ASCII
    keycode. For example, `ord('a')` returns `97`.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'On some systems, `waitKey()` may return a value that encodes more than just
    the ASCII keycode. (A bug is known to occur on Linux when OpenCV uses GTK as its
    backend GUI library.) On all systems, we can ensure that we extract just the ASCII
    keycode by reading the last byte from the return value like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: OpenCV's window functions and `waitKey()` are interdependent. OpenCV windows
    are only updated when `waitKey()` is called, and `waitKey()` only captures input
    when an OpenCV window has focus.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mouse callback passed to `setMouseCallback()` should take five arguments,
    as seen in our code sample. The callback''s `param` argument is set as an optional
    third argument to `setMouseCallback()`. By default, it is `0`. The callback''s
    event argument is one of the following actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cv2.EVENT_MOUSEMOVE`: This event refers to mouse movement'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_LBUTTONDOWN`: This event refers to the left button down'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_RBUTTONDOWN`: This refers to the right button down'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_MBUTTONDOWN`: This refers to the middle button down'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_LBUTTONUP`: This refers to the left button up'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_RBUTTONUP`: This event refers to the right button up'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_MBUTTONUP`: This event refers to the middle button up'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_LBUTTONDBLCLK`: This event refers to the left button being double-clicked'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_RBUTTONDBLCLK`: This refers to the right button being double-clicked'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_MBUTTONDBLCLK`: This refers to the middle button being double-clicked'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The mouse callback''s flags argument may be some bitwise combination of the
    following events:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cv2.EVENT_FLAG_LBUTTON`: This event refers to the left button being pressed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_FLAG_RBUTTON`: This event refers to the right button being pressed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_FLAG_MBUTTON`: This event refers to the middle button being pressed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_FLAG_CTRLKEY`: This event refers to the *Ctrl* key being pressed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_FLAG_SHIFTKEY`: This event refers to the *Shift* key being pressed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.EVENT_FLAG_ALTKEY`: This event refers to the *Alt* key being pressed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unfortunately, OpenCV does not provide any means of handling window events.
    For example, we cannot stop our application when a window's close button is clicked.
    Due to OpenCV's limited event handling and GUI capabilities, many developers prefer
    to integrate it with other application frameworks. Later in this chapter, we will
    design an abstraction layer to help integrate OpenCV into any application framework.
  prefs: []
  type: TYPE_NORMAL
- en: Project Cameo (face tracking and image manipulation)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'OpenCV is often studied through a cookbook approach that covers a lot of algorithms
    but nothing about high-level application development. To an extent, this approach
    is understandable because OpenCV''s potential applications are so diverse. OpenCV
    is used in a wide variety of applications: photo/video editors, motion-controlled
    games, a robot''s AI, or psychology experiments where we log participants'' eye
    movements. Across such different use cases, can we truly study a useful set of
    abstractions?'
  prefs: []
  type: TYPE_NORMAL
- en: I believe we can and the sooner we start creating abstractions, the better.
    We will structure our study of OpenCV around a single application, but, at each
    step, we will design a component of this application to be extensible and reusable.
  prefs: []
  type: TYPE_NORMAL
- en: We will develop an interactive application that performs face tracking and image
    manipulations on camera input in real time. This type of application covers a
    broad range of OpenCV's functionality and challenges us to create an efficient,
    effective implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, our application will perform real-time facial merging. Given two
    streams of camera input (or, optionally, prerecorded video input), the application
    will superimpose faces from one stream onto faces in the other. Filters and distortions
    will be applied to give this blended scene a unified look and feel. Users should
    have the experience of being engaged in a live performance where they enter another
    environment and persona. This type of user experience is popular in amusement
    parks such as Disneyland.
  prefs: []
  type: TYPE_NORMAL
- en: In such an application, users would immediately notice flaws, such as a low
    frame rate or inaccurate tracking. To get the best results, we will try several
    approaches using conventional imaging and depth imaging.
  prefs: []
  type: TYPE_NORMAL
- en: We will call our application Cameo. A cameo is (in jewelry) a small portrait
    of a person or (in film) a very brief role played by a celebrity.
  prefs: []
  type: TYPE_NORMAL
- en: Cameo – an object-oriented design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python applications can be written in a purely procedural style. This is often
    done with small applications, such as our basic I/O scripts, discussed previously.
    However, from now on, we will use an object-oriented style because it promotes
    modularity and extensibility.
  prefs: []
  type: TYPE_NORMAL
- en: From our overview of OpenCV's I/O functionality, we know that all images are
    similar, regardless of their source or destination. No matter how we obtain a
    stream of images or where we send it as output, we can apply the same application-specific
    logic to each frame in this stream. Separation of I/O code and application code
    becomes especially convenient in an application, such as Cameo, which uses multiple
    I/O streams.
  prefs: []
  type: TYPE_NORMAL
- en: We will create classes called `CaptureManager` and `WindowManager` as high-level
    interfaces to I/O streams. Our application code may use `CaptureManager` to read
    new frames and, optionally, to dispatch each frame to one or more outputs, including
    a still image file, a video file, and a window (via a `WindowManager` class).
    A `WindowManager` class lets our application code handle a window and events in
    an object-oriented style.
  prefs: []
  type: TYPE_NORMAL
- en: Both `CaptureManager` and `WindowManager` are extensible. We could make implementations
    that do not rely on OpenCV for I/O. Indeed, *Appendix A*, *Integrating with Pygame*,
    *OpenCV Computer Vision with Python*, uses a `WindowManager` subclass.
  prefs: []
  type: TYPE_NORMAL
- en: Abstracting a video stream with managers.CaptureManager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we have seen, OpenCV can capture, show, and record a stream of images from
    either a video file or a camera, but there are some special considerations in
    each case. Our `CaptureManager` class abstracts some of the differences and provides
    a higher-level interface to dispatch images from the capture stream to one or
    more outputs—a still image file, video file, or a window.
  prefs: []
  type: TYPE_NORMAL
- en: A `CaptureManager` class is initialized with a `VideoCapture` class and has
    the `enterFrame()` and `exitFrame()` methods that should typically be called on
    every iteration of an application's main loop. Between a call to `enterFrame()`
    and `exitFrame()`, the application may (any number of times) set a `channel` property
    and get a `frame` property. The `channel` property is initially `0` and only multihead
    cameras use other values. The `frame` property is an image corresponding to the
    current channel's state when `enterFrame()` was called.
  prefs: []
  type: TYPE_NORMAL
- en: A `CaptureManager` class also has the `writeImage()`, `startWritingVideo()`,
    and `stopWritingVideo()` methods that may be called at any time. Actual file writing
    is postponed until `exitFrame()`. Also, during the `exitFrame()` method, the `frame`
    property may be shown in a window, depending on whether the application code provides
    a `WindowManager` class either as an argument to the constructor of `CaptureManager`
    or by setting a `previewWindowManager` property.
  prefs: []
  type: TYPE_NORMAL
- en: If the application code manipulates `frame`, the manipulations are reflected
    in recorded files and in the window. A `CaptureManager` class has a constructor
    argument and property called `shouldMirrorPreview`, which should be `True` if
    we want `frame` to be mirrored (horizontally flipped) in the window but not in
    recorded files. Typically, when facing a camera, users prefer live camera feed
    to be mirrored.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that a `VideoWriter` class needs a frame rate, but OpenCV does not provide
    any way to get an accurate frame rate for a camera. The `CaptureManager` class
    works around this limitation by using a frame counter and Python's standard `time.time()`
    function to estimate the frame rate if necessary. This approach is not foolproof.
    Depending on frame rate fluctuations and the system-dependent implementation of
    `time.time()`, the accuracy of the estimate might still be poor in some cases.
    However, if we deploy to unknown hardware, it is better than just assuming that
    the user's camera has a particular frame rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a file called `managers.py`, which will contain our implementation
    of `CaptureManager`. The implementation turns out to be quite long. So, we will
    look at it in several pieces. First, let''s add imports, a constructor, and properties,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that most of the `member` variables are non-public, as denoted by the
    underscore prefix in variable names, such as `self._enteredFrame`. These nonpublic
    variables relate to the state of the current frame and any file-writing operations.
    As discussed previously, the application code only needs to configure a few things,
    which are implemented as constructor arguments and settable public properties:
    the camera channel, window manager, and the option to mirror the camera preview.'
  prefs: []
  type: TYPE_NORMAL
- en: This book assumes a certain level of familiarity with Python; however, if you
    are getting confused by those `@` annotations (for example, `@property`), refer
    to the Python documentation about `decorators`, a built-in feature of the language
    that allows the wrapping of a function by another function, normally used to apply
    a user-defined behavior in several places of an application (refer to [https://docs.python.org/2/reference/compound_stmts.html#grammar-token-decorator](https://docs.python.org/2/reference/compound_stmts.html#grammar-token-decorator)).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Python does not have the concept of private member variables and the single/double
    underscore prefix (`_`) is only a convention.
  prefs: []
  type: TYPE_NORMAL
- en: By this convention, in Python, variables that are prefixed with a single underscore
    should be treated as protected (accessed only within the class and its subclasses),
    while variables that are prefixed with a double underscore should be treated as
    private (accessed only within the class).
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing with our implementation, let''s add the `enterFrame()` and `exitFrame()`
    methods to `managers.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Note that the implementation of `enterFrame()` only grabs (synchronizes) a frame,
    whereas actual retrieval from a channel is postponed to a subsequent reading of
    the `frame` variable. The implementation of `exitFrame()` takes the image from
    the current channel, estimates a frame rate, shows the image via the window manager
    (if any), and fulfills any pending requests to write the image to files.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several other methods also pertain to file writing. To finish our class implementation,
    let''s add the remaining file-writing methods to `managers.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The `writeImage()`, `startWritingVideo()`, and `stopWritingVideo()` public methods
    simply record the parameters for file-writing operations, whereas the actual writing
    operations are postponed to the next call of `exitFrame()`. The `_writeVideoFrame()`
    nonpublic method creates or appends a video file in a manner that should be familiar
    from our earlier scripts. (See the *Reading/writing a video file* section.) However,
    in situations where the frame rate is unknown, we skip some frames at the start
    of the capture session so that we have time to build up an estimate of the frame
    rate.
  prefs: []
  type: TYPE_NORMAL
- en: Although our current implementation of `CaptureManager` relies on `VideoCapture`,
    we could make other implementations that do not use OpenCV for input. For example,
    we could make a subclass that is instantiated with a socket connection, whose
    byte stream could be parsed as a stream of images. We could also make a subclass
    that uses a third-party camera library with different hardware support than what
    OpenCV provides. However, for Cameo, our current implementation is sufficient.
  prefs: []
  type: TYPE_NORMAL
- en: Abstracting a window and keyboard with managers.WindowManager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we have seen, OpenCV provides functions that cause a window to be created,
    destroyed, show an image, and process events. Rather than being methods of a window
    class, these functions require a window's name to pass as an argument. Since this
    interface is not object-oriented, it is inconsistent with OpenCV's general style.
    Also, it is unlikely to be compatible with other window or event handling interfaces
    that we might eventually want to use instead of OpenCV's.
  prefs: []
  type: TYPE_NORMAL
- en: For the sake of object orientation and adaptability, we abstract this functionality
    into a `WindowManager` class with the `createWindow()`, `destroyWindow()`, `show()`,
    and `processEvents()` methods. As a property, a `WindowManager` class has a function
    object called `keypressCallback`, which (if not `None`) is called from `processEvents()`
    in response to any key press. The `keypressCallback` object must take a single
    argument, such as an ASCII keycode.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s add the following implementation of `WindowManager` to `managers.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Our current implementation only supports keyboard events, which will be sufficient
    for Cameo. However, we could modify `WindowManager` to support mouse events too.
    For example, the class's interface could be expanded to include a `mouseCallback`
    property (and optional constructor argument), but could otherwise remain the same.
    With some event framework other than OpenCV's, we could support additional event
    types in the same way by adding callback properties.
  prefs: []
  type: TYPE_NORMAL
- en: '*Appendix A*, *Integrating with Pygame*, *OpenCV Computer Vision with Python*,
    shows a `WindowManager` subclass that is implemented with Pygame''s window handling
    and event framework instead of OpenCV''s. This implementation improves on the
    base `WindowManager` class by properly handling quit events—for example, when
    a user clicks on a window''s close button. Potentially, many other event types
    can be handled via Pygame too.'
  prefs: []
  type: TYPE_NORMAL
- en: Applying everything with cameo.Cameo
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our application is represented by a `Cameo` class with two methods: `run()`
    and `onKeypress()`. On initialization, a `Cameo` class creates a `WindowManager`
    class with `onKeypress()` as a callback, as well as a `CaptureManager` class using
    a camera and the `WindowManager` class. When `run()` is called, the application
    executes a main loop in which frames and events are processed. As a result of
    event processing, `onKeypress()` may be called. The spacebar causes a screenshot
    to be taken, *Tab* causes a screencast (a video recording) to start/stop, and
    *Esc* causes the application to quit.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same directory as `managers.py`, let''s create a file called `cameo.py`
    containing the following implementation of `Cameo`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: When running the application, note that the live camera feed is mirrored, while
    screenshots and screencasts are not. This is the intended behavior, as we pass
    `True` for `shouldMirrorPreview` when initializing the `CaptureManager` class.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we do not manipulate the frames in any way except to mirror them for
    preview. We will start to add more interesting effects in [Chapter 3](part0023.xhtml#aid-LTSU1
    "Chapter 3. Processing Images with OpenCV 3"), *Filtering Images*.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By now, we should have an application that displays a camera feed, listens for
    keyboard input, and (on command) records a screenshot or screencast. We are ready
    to extend the application by inserting some image-filtering code ([Chapter 3](part0023.xhtml#aid-LTSU1
    "Chapter 3. Processing Images with OpenCV 3"), *Filtering Images*) between the
    start and end of each frame. Optionally, we are also ready to integrate other
    camera drivers or application frameworks (*Appendix A*, *Integrating with Pygame*,
    *OpenCV Computer Vision with Python*) besides the ones supported by OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: We also now have the knowledge to process images and understand the principle
    of image manipulation through the NumPy arrays. This forms the perfect foundation
    to understand the next topic, filtering images.
  prefs: []
  type: TYPE_NORMAL
