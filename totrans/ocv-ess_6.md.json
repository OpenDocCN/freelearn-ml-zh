["```py\n#include \"opencv2/core/core.hpp\"\n#include \"opencv2/objdetect/objdetect.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include \"opencv2/imgproc/imgproc.hpp\"\n#include <iostream>\n\nusing namespace std;\nusing namespace cv;\n\nint main(int argc, char *argv[]){\n    CascadeClassifier cascade(argv[1]);\n    if (cascade.empty())\n        return -1;\n\n    VideoCapture vid(argv[2]);\n    if (!vid.isOpened()){\n        cout<<\"Error. The video cannot be opened.\"<<endl;\n        return -1;\n    }\n\n    namedWindow(\"Pedestrian Detection\");\n    Mat frame;\n    while(1) {\n        if (!vid.read(frame))\n            break;\n\n        Mat frame_gray;\n        if(frame.channels()>1){\n            cvtColor( frame, frame_gray, CV_BGR2GRAY );\n            equalizeHist( frame_gray, frame_gray );\n        }else{\n            frame_gray = frame;\n        }\n\n        vector<Rect> pedestrians;\n        cascade.detectMultiScale( frame_gray, pedestrians, 1.1, 2, 0, Size(30, 30), Size(150, 150) );\n\n        for( size_t i = 0; i < pedestrians.size(); i++ ) {\n            Point center( pedestrians[i].x + \n                          pedestrians[i].width*0.5, \n                          pedestrians[i].y + \n                          pedestrians[i].height*0.5 );\n            ellipse( frame, center, Size( pedestrians[i].width*0.5,\n                     pedestrians[i].height*0.5), 0, 0, 360, \n                     Scalar( 255, 0, 255 ), 4, 8, 0 );\n        }\n\n        imshow(\"Pedestrian Detection\", frame);\n        if(waitKey(100) >= 0)\n            break;\n    }\n    return 0;\n}\n```", "```py\n    Mat frame_gray;\n    if(frame.channels()>1){\n        cvtColor( frame, frame_gray, CV_BGR2GRAY );\n        equalizeHist( frame_gray, frame_gray );\n    }else{\n        frame_gray = frame;\n    }\n    ```", "```py\n    >cd C:\\chapter6\\images\n\n    ```", "```py\n    >for %i in (C:\\chapter6\\images\\train\\non-face\\*.pgm) do @echo %i >> train_non-face.txt\n\n    ```", "```py\n        >for %i in (C:\\chapter6\\images\\train\\face\\*.pgm) do @echo %i 1 0 0 19 19 >> train_face.dat\n\n        ```", "```py\n        >opencv_createsamples -info train_face.dat -vec train_face.vec -num 2429 -w 19 -h 19 -maxxangle 0 -maxyangle 0 -maxzangle 0\n\n        ```", "```py\n    >opencv_traincascade -data C:\\chapter6\\trainedCascade -vec train_face.vec -bg train_non-face.txt -numPos 242 -numNeg 454 -numStages 10 -w 19 -h 19\n\n    ```", "```py\n    PARAMETERS:\n    cascadeDirName: C:\\chapter6\\trainedCascade\n    vecFileName: train_face.vec\n    bgFileName: train_non-face.txt\n    numPos: 242\n    numNeg: 454\n    numStages: 10\n    precalcValBufSize[Mb] : 256\n    precalcIdxBufSize[Mb] : 256\n    stageType: BOOST\n    featureType: HAAR\n    sampleWidth: 19\n    sampleHeight: 19\n    boostType: GAB\n    minHitRate: 0.995\n    maxFalseAlarmRate: 0.5\n    weightTrimRate: 0.95\n    maxDepth: 1\n    maxWeakCount: 100\n    mode: BASIC\n    ===== TRAINING 0-stage =====\n    <BEGIN\n    POS count : consumed   242 : 242\n    NEG count : acceptanceRatio    454 : 1\n    Precalculation time: 4.524\n    +----+---------+---------+\n    |  N |    HR   |    FA   |\n    +----+---------+---------+\n    |   1|        1|        1|\n    +----+---------+---------+\n    |   2|        1|        1|\n    +----+---------+---------+\n    |   3| 0.995868| 0.314978|\n    +----+---------+---------+\n    END>\n    Training until now has taken 0 days 0 hours 0 minutes 9 seconds.\n    . . . Stages 1, 2, 3, and 4 . . .\n    ===== TRAINING 5-stage =====\n    <BEGIN\n    POS count : consumed   242 : 247\n    NEG count : acceptanceRatio    454 : 0.000220059\n    Required leaf false alarm rate achieved. Branch training terminated.\n\n    ```", "```py\n#include \"opencv2/core/core.hpp\"\n#include \"opencv2/objdetect/objdetect.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include <iostream>\n\nusing namespace std;\nusing namespace cv;\n\nint main(int argc, char* argv[]){\n    String model = argv[1];\n    vector<String> models;\n    models.push_back( model );\n    vector<String> names;\n    names.push_back( \"category\" );\n    LatentSvmDetector detector( models , names);\n    if( detector.empty() ) {\n        cout << \"Model cannot be loaded\" << endl;\n        return -1;\n    }\n\n    String img = argv[2];\n    Mat image = imread( img );\n    if( image.empty() ){\n        cout << \"Image cannot be loaded\" << endl;\n        return -1;\n    }\n\n    vector<LatentSvmDetector::ObjectDetection> detections;\n    detector.detect( image, detections, 0.1, 1);\n    for( size_t i = 0; i < detections.size(); i++ ) {\n        Point center( detections[i].rect.x + \n                      detections[i].rect.width*0.5, \n                      detections[i].rect.y + \n                      detections[i].rect.height*0.5 );\n        ellipse( image, center, Size( detections[i].rect.width*0.5, \n                 detections[i].rect.height*0.5), 0, 0, 360, \n                 Scalar( 255, 0, 255 ), 4, 8, 0 );\n    }\n    imshow( \"result\", image );\n    waitKey(0);\n    return 0;\n}\n```", "```py\n>latentDetection.exe xmlfile imagefile\n\n```", "```py\n#include \"opencv2/opencv.hpp\"\n#include \"opencv2/objdetect.hpp\"\n#include \"opencv2/highgui.hpp\"\n#include \"opencv2/imgproc.hpp\"\n\n#include <vector>\n#include <iostream>\n#include <iomanip>\n\nusing namespace std;\nusing namespace cv;\n\nint main(int argc, const char * argv[]){\n\n    Mat src = imread(argv[1]);\n\n    vector<Mat> channels;\n    computeNMChannels(src, channels);\n\n    //Negative images from RGB channels\n    channels.push_back(255-channels[0]);\n    channels.push_back(255-channels[1]); \n    channels.push_back(255-channels[2]);\n    channels.push_back(255-channels[3]);\n    for (int c = 0; c < channels.size(); c++){\n        stringstream ss;\n        ss << \"Channel: \" << c;\n        imshow(ss.str(),channels.at(c));\n    }\n\n    Ptr<ERFilter> er_filter1 = createERFilterNM1(\n                                   loadClassifierNM1(argv[2]),\n                                   16, 0.00015f, 0.13f, 0.2f,\ntrue, 0.1f );\n    Ptr<ERFilter> er_filter2 = createERFilterNM2(\n                                   loadClassifierNM2(argv[3]),  0.5 );\n\n    vector<vector<ERStat> > regions(channels.size());\n    // Apply filters to each channel\n    for (int c=0; c<(int)channels.size(); c++){\n        er_filter1->run(channels[c], regions[c]);\n        er_filter2->run(channels[c], regions[c]);\n    }\n    for (int c=0; c<(int)channels.size(); c++){\n        Mat dst = Mat::zeros( channels[0].rows + \n                              2, channels[0].cols + 2, CV_8UC1 );\n        // Show ERs\n        for (int r=0; r<(int)regions[c].size(); r++)\n        {\n            ERStat er = regions[c][r];\n            if (er.parent != NULL){\n                int newMaskVal = 255;\n                int flags = 4 + (newMaskVal << 8) + \n                                 FLOODFILL_FIXED_RANGE + \n                                 FLOODFILL_MASK_ONLY;\n                floodFill( channels[c], dst, Point(er.pixel % \n                           channels[c].cols,er.pixel / \n                           channels[c].cols), Scalar(255), 0, \n                           Scalar(er.level), Scalar(0), flags);\n            }\n        }\n        stringstream ss;\n        ss << \"Regions/Channel: \" << c;\n        imshow(ss.str(), dst);\n    }\n\n    vector<Rect> groups;\n    erGrouping( channels, regions, argv[4], 0.5, groups );\n    for (int i=(int)groups.size()-1; i>=0; i--)\n    {\n        if (src.type() == CV_8UC3)\n            rectangle( src,groups.at(i).tl(), groups.at(i).br(), \n                       Scalar( 0, 255, 255 ), 3, 8 );\n        else\n            rectangle( src,groups.at(i).tl(), groups.at(i).br(), \n                       Scalar( 255 ), 3, 8 );\n    }\n    imshow(\"grouping\",src);\n\n    waitKey(-1);\n    er_filter1.release();\n    er_filter2.release();\n    regions.clear();\n    groups.clear();\n}\n```"]