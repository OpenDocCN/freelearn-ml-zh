<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Scala for Tree-Based Ensemble Techniques</h1>
                </header>
            
            <article>
                
<p class="mce-root">In the previous chapter, we solved both classification and regression problems using linear models. We also used logistic regression, support vector machine, and Naive Bayes. However, in both cases, we haven't experienced good accuracy because our models showed low confidence.<br/></p>
<p class="mce-root">On the other hand, tree-based and tree ensemble classifiers are really useful, robust, and widely used for both classification and regression tasks. This chapter will provide a quick glimpse at developing these classifiers and regressors using tree-based and ensemble techniques, such as <strong>decision trees</strong> (<strong>DTs</strong>), <strong>random forests</strong> (<strong>RF</strong>), and <strong>gradient boosted trees</strong> (<strong>GBT</strong>), for both classification and regression. More specifically, we will revisit and solve both the regression (from <a href="f649db9f-aea9-4509-b9b8-e0b7d5fb726a.xhtml" target="_blank">Chapter 2</a>, <em>Scala for Regression Analysis</em>) and classification (from <a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml" target="_blank">Chapter 3</a>, <em>Scala for Learning Classification</em>) problems we discussed previously.</p>
<p class="mce-root">The following topics will be covered in this chapter:</p>
<ul>
<li>Decision trees and tree ensembles</li>
<li>Decision trees for supervised learning</li>
<li>Gradient boosted trees for supervised learning</li>
<li>Random forest for supervised learning</li>
<li>What's next?</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>Make sure Scala 2.11.x and Java 1.8.x are installed and configured on your machine.</p>
<p>The code files of this chapters can be found on GitHub:</p>
<p><a href="https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter04" target="_blank">https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter04</a></p>
<p>Check out the following playlist to see the Code in Action video for this chapter:<br/>
<a href="http://bit.ly/2WhQf2i" target="_blank">http://bit.ly/2WhQf2i</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Decision trees and tree ensembles</h1>
                </header>
            
            <article>
                
<p>DTs normally fall under supervised learning techniques, which are used to identify and solve problems related to classification and regression. As the name indicates, DTs have various branches—where each branch indicates a possible decision, appearance, or reaction in terms of statistical probability. In terms of features, DTs are split into two main types: the training set and the test set, which helps produce a good update on the predicted labels or classes.</p>
<p>Both binary and multiclass classification problems can be handled by DT algorithms, which is one of the reasons it is used across problems. For instance, for the admission example we introduced in <a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml" target="_blank">Chapter 3</a>, <em>Scala for Learning Classification</em>, DTs learn from the admission data to approximate a sine curve with a set of <kbd>if...else</kbd> decision rules, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-694 image-border" src="assets/b07f5aa1-744a-4782-8fc6-4ac4bdab1cc4.png" style="width:85.25em;height:44.25em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Generating decision rules using DTs based on university admission data</div>
<p>In general, the bigger the tree, the more complex the decision rules and the more fitted the model is. Another exciting power of DTs is that they can be used to solve both classification and regression problems. Now let's see some pros and cons of DTs. The two widely-used tree-based ensemble techniques are RF and GBT. The main difference between these two techniques is the way and order in which trees are trained:</p>
<ul>
<li>RFs train each tree independently but based on a random sample of the data. These random samples help to make the model more robust than a single DT, and hence it is less likely to have an overload on the training data.</li>
<li>GBTs train one tree at a time. The errors created by the trees trained previously will be rectified by every new tree that is trained. As more trees are added, the model becomes more expressive.</li>
</ul>
<p>RFs take a subset of observations and a subset of variables to build, which is an ensemble of DTs. These trees are actually trained on different parts of the same training set, but individual trees grow very deep tends to learn from highly unpredictable patterns.</p>
<div class="packt_infobox">Sometimes very deep trees are responsible for overfitting problems in DT models. In addition, these biases can make the classifier a low performer even if the quality of the features represented is good with respect to the dataset.</div>
<p class="mce-root"/>
<p>When DTs are built, RFs integrate them together to get a more accurate and stable prediction. RFs helps to average multiple DTs together, with the goal of reducing the variance to ensure consistency by computing proximities between pairs of cases. This is a direct consequence on RF too. By maximum voting from a panel of independent jurors, we get the final prediction that is better than the best jury. The following figure shows how the decisions from two forests are ensembled together to get the final prediction:<br/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-567 image-border" src="assets/debf3299-9124-459b-92b1-c5682ebce220.png" style="width:36.92em;height:23.83em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Tree-based ensemble and its assembling technique</div>
<p>In the end, both RF and GBT produce a weighted collection of DT, which is followed by predicting the combining results from the individual trees of each ensemble model. When using these approaches (as a classifier or regressor), the parameter settings are as follows:</p>
<ul>
<li>If the number of trees is 1, no bootstrapping is applied. If the number of trees is greater than 1, bootstrapping is applied, with <kbd>auto</kbd>, <kbd>all</kbd>, <kbd>sqrt</kbd>, <kbd>log2</kbd>, and one-third being the supported values.</li>
<li>The supported numerical values are [0.0-1.0] and [1-n]. If <kbd>numTrees</kbd> is <kbd>1</kbd>, <kbd>featureSubsetStrategy</kbd> is set to be <kbd>all</kbd>. If <kbd>numTrees &gt; 1</kbd> (for RF), <kbd>featureSubsetStrategy</kbd> is set to be <kbd>sqrt</kbd> for classification. If <kbd>featureSubsetStrategy</kbd> is chosen as <kbd>auto</kbd>, the algorithm infers the best feature subset strategy automatically.</li>
<li>The impurity criterion is used only for the information-gain calculation, with gini and variance as the supported values for classification and regression, respectively.</li>
<li><kbd>maxDepth</kbd> is the maximum depth of the tree (for example, depth 0 means 1 leaf node, depth 1 means 1 internal node and 2 leaf nodes, and so on).</li>
<li><kbd>maxBins</kbd> signifies the maximum number of bins used to split the features, where the suggested value is 100 to get better results.</li>
</ul>
<p>Now that we've already dealt with both regression analysis and classification problems, let's see how to use DT, RF, and GBT more comfortably to solve these problems. Let's get started with DT.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Decision trees for supervised learning</h1>
                </header>
            
            <article>
                
<p>In this section, we'll see how to use DTs to solve both regression and classification problems. In the previous two chapters, <a href="f649db9f-aea9-4509-b9b8-e0b7d5fb726a.xhtml" target="_blank">Chapter 2</a>, <em>Scala for Regression Analysis</em>, and <a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml" target="_blank">Chapter 3</a>, <em>Scala for Learning Classification</em>, we solved customer churn and insurance-severity claim problems. Those were classification and regression problems, respectively. In both approaches, we used other classic models. However, we'll see how we can solve them with tree-based and ensemble techniques. We'll use the DT implementation from the Apache Spark ML package in Scala.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Decision trees for classification</h1>
                </header>
            
            <article>
                
<p>First of all, we know the customer churn prediction problem in <a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml" target="_blank"/><a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml" target="_blank"/><a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml" target="_blank"/><a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml" target="_blank">Chapter 3</a>, <em>Scala for Learning Classification</em>, and we know the data as well. We also know the working principle of DTs. So we can directly move to the coding part using the Spark based implementation of DTs. First we create a <kbd>DecisionTreeClassifier</kbd> estimator by instantiating the <kbd>DecisionTreeClassifier</kbd> interface. Additionally, we need to specify the label and feature vector columns:</p>
<pre class="mce-root">val dTree = new DecisionTreeClassifier()<br/>        .setLabelCol("label")// Setting label column<br/>        .setFeaturesCol("features") // Setting feature vector column<br/>        .setSeed(1234567L)// for reproducibility</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>As discussed in the previous chapters, we have three transformers (<kbd>ipindexer</kbd>, <kbd>labelindexer</kbd>, and <kbd>assembler</kbd>) and an estimator (<kbd>dTree</kbd>). We can now chain them together in a single pipeline so that each of them will act as a stage:</p>
<pre class="mce-root">val pipeline = new Pipeline()<br/>          .setStages(Array(PipelineConstruction.ipindexer,<br/>                            PipelineConstruction.labelindexer,<br/>                                PipelineConstruction.assembler,dTree))</pre>
<p>Since we would like to perform hyperparameter tuning and cross-validation, we will have to create a <kbd>paramGrid</kbd> variable<span>,</span> which will be used for grid search over the hyperparameter space during the K-fold cross-validation:</p>
<pre class="mce-root">var paramGrid = new ParamGridBuilder()<br/>  .addGrid(dTree.impurity, "gini" :: "entropy" :: Nil)<br/>  .addGrid(dTree.maxBins, 2 :: 5 :: 10 :: 15 :: 20 :: 25 :: 30 :: Nil)<br/>  .addGrid(dTree.maxDepth, 5 :: 10 :: 15 :: 20 :: 25 :: 30 :: 30 :: Nil)<br/>  .build()</pre>
<p>More specifically, this will search for the DT's <kbd>impurity</kbd>, <kbd>maxBins</kbd>, and <kbd>maxDepth</kbd> for the best model. The maximum number of bins is used for separating continuous features and for choosing how to split on features at each node. Combined, the algorithm searches through the DT's <kbd>maxDepth</kbd> and <kbd>maxBins</kbd> parameters for the best model.</p>
<p>In the preceding code segment, we're creating a progressive <kbd>paramGrid</kbd> variable<span>,</span> where we specify the combination as a list of string or integer values. That means we are creating the grid space with different hyperparameter combinations. This will help us to provide the best model, consisting of optimal hyperparameters. However, for that, we need to have a <kbd>BinaryClassificationEvaluator</kbd> evaluator to evaluate each model and pick the best one during the cross-validation:</p>
<pre class="mce-root">val evaluator = new BinaryClassificationEvaluator()<br/>                  .setLabelCol("label")<br/>                  .setRawPredictionCol("prediction")</pre>
<p>We use <kbd>CrossValidator</kbd> to perform 10-fold cross validation to select the best model: </p>
<pre class="mce-root">println("Preparing for 10-fold cross-validation")<br/>val numFolds = 10<br/><br/>val crossval = new CrossValidator()<br/>     .setEstimator(pipeline)<br/>     .setEvaluator(evaluator)<br/>     .setEstimatorParamMaps(paramGrid)<br/>     .setNumFolds(numFolds)</pre>
<p class="mce-root"/>
<p>Let's now call the <kbd>fit</kbd> method so that the complete predefined pipeline, including all feature preprocessing and the DT classifier, is executed multiple times—each time with a different hyperparameter vector:</p>
<pre><strong>val</strong> cvModel = crossval.fit(Preprocessing.trainDF)</pre>
<p>Now it's time to evaluate the predictive power of the DT model on the test dataset:</p>
<pre><strong>val</strong> predictions = cvModel.transform(Preprocessing.testSet)<br/>prediction.show(10)</pre>
<p>This will lead us to the following DataFrame showing the predicted labels against the actual labels. Additionally, it shows the raw probabilities:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-568 image-border" src="assets/d2d26de4-9bd0-4238-a36d-ddf1cba4948d.png" style="width:24.50em;height:18.42em;"/></p>
<p>However, based on the preceding prediction DataFrame, it is really difficult to guess the classification's accuracy. But in the second step, the evaluation is done using <kbd>BinaryClassificationEvaluator</kbd> as follows:</p>
<pre><strong>val</strong> accuracy = evaluator.evaluate(predictions)<br/>println("Classification accuracy: " + accuracy)</pre>
<p>This will provide an output with an accuracy value:</p>
<pre><strong>Accuracy: 0.8441663599558337</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>So, we get about 84% classification accuracy from our binary classification model. Just like with SVM and LR, we will observe the area under the precision-recall curve and the area under the <strong>receiver operating characteristic</strong> (<strong>ROC</strong>) curve based on the following RDD, which contains the raw scores on the test set:</p>
<pre class="mce-root">val predictionAndLabels = predictions<br/>      .select("prediction", "label")<br/>      .rdd.map(x =&gt; (x(0).asInstanceOf[Double], x(1)<br/>        .asInstanceOf[Double]))</pre>
<p>The preceding RDD can be used for computing the previously mentioned two performance metrics:</p>
<pre><strong>val</strong> metrics = <strong>new</strong> BinaryClassificationMetrics(predictionAndLabels)<br/>println("Area under the precision-recall curve: " + metrics.areaUnderPR)<br/>println("Area under the receiver operating characteristic (ROC) curve: " + metrics.areaUnderROC)</pre>
<p>In this case, the evaluation returns 84% accuracy but only 67% precision, which is much better than that of SVM and LR: </p>
<pre><strong>Area under the precision-recall curve: 0.6665988000794282</strong><br/><strong>Area under the receiver operating characteristic (ROC) curve: 0.8441663599558337</strong></pre>
<p>Then, we calculate some more metrics, for example, false and true positive, and false and true negative, as these predictions are also useful to evaluate the model's performance:</p>
<pre><strong>val</strong> TC = predDF.count() //Total count<br/><br/><strong>val</strong> tp = tVSpDF.filter($"prediction" === 0.0).filter($"label" === $"prediction")<br/>                    .count() / TC.toDouble // True positive rate<br/><strong>val</strong> tn = tVSpDF.filter($"prediction" === 1.0).filter($"label" === $"prediction")<br/>                    .count() / TC.toDouble // True negative rate<br/><strong>val</strong> fp = tVSpDF.filter($"prediction" === 1.0).filter(not($"label" === $"prediction"))<br/>                    .count() / TC.toDouble // False positive rate<br/><strong>val</strong> fn = tVSpDF.filter($"prediction" === 0.0).filter(not($"label" === $"prediction"))<br/>                    .count() / TC.toDouble // False negative rate</pre>
<p class="mce-root">Additionally, we compute the Matthews correlation coefficient: <span class="packt_screen"><q><br/></q></span></p>
<pre><strong>val</strong> MCC = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (fp + tn) * (tn + fn)) </pre>
<p>Let's observe how high the model confidence is:</p>
<pre>println("True positive rate: " + tp *100 + "%")<br/>println("False positive rate: " + fp * 100 + "%")<br/>println("True negative rate: " + tn * 100 + "%")<br/>println("False negative rate: " + fn * 100 + "%")<br/>println("Matthews correlation coefficient: " + MCC)</pre>
<p>Fantastic! We achieved only 70% accuracy, which is probably why we had a low number of trees, but for what factors?</p>
<pre><strong>True positive rate: 70.76461769115441%</strong><br/><strong>False positive rate: 14.992503748125937%</strong><br/><strong>True negative rate: 12.293853073463268%</strong><br/><strong>False negative rate: 1.9490254872563717%</strong><br/><strong>Matthews correlation coefficient: 0.5400720075807806</strong></pre>
<p>Now let's see at what level we achieved the best model after the cross-validation:</p>
<pre><strong>val</strong> bestModel = cvModel.bestModel<br/>println("The Best Model and Parameters:\n--------------------")<br/>println(bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel].stages(3))</pre>
<p class="mce-root">According to the following output, we achieved the best tree model at <kbd>depth 5</kbd> with <kbd>53 nodes</kbd>:</p>
<pre class="mce-root"><strong>The Best Model and Parameters:</strong><br/><strong>DecisionTreeClassificationModel of depth 5 with 53 nodes</strong></pre>
<p>Let's extract those moves taken (that is, decisions) during tree construction by showing the tree. This tree helps us to find the most valuable features in our dataset:</p>
<pre class="mce-root">bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel]<br/>      .stages(3)<br/>      .extractParamMap<br/>val treeModel = bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel]<br/>      .stages(3)<br/>      .asInstanceOf[DecisionTreeClassificationModel]<br/>println("Learned classification tree model:\n" + treeModel.toDebugString)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In the following output, the <kbd>toDebugString()</kbd> method prints the tree's decision nodes and final the prediction outcomes at the end leaves: </p>
<pre><strong>Learned classification tree model:</strong><br/><strong>If (feature 3 &lt;= 245.2)</strong><br/><strong>    If (feature 11 &lt;= 3.0)</strong><br/><strong>     If (feature 1 in {1.0})</strong><br/><strong>      If (feature 10 &lt;= 2.0)</strong><br/><strong>       Predict: 1.0</strong><br/><strong>      Else (feature 10 &gt; 2.0)</strong><br/><strong>       If (feature 9 &lt;= 12.9)</strong><br/><strong>        Predict: 0.0</strong><br/><strong>       Else (feature 9 &gt; 12.9)</strong><br/><strong>        Predict: 1.0</strong><br/><strong>     …</strong><br/><strong> Else (feature 7 &gt; 198.0)</strong><br/><strong>      If (feature 2 &lt;= 28.0)</strong><br/><strong>       Predict: 1.0</strong><br/><strong>      Else (feature 2 &gt; 28.0)</strong><br/><strong>       If (feature 0 &lt;= 60.0)</strong><br/><strong>        Predict: 0.0</strong><br/><strong>       Else (feature 0 &gt; 60.0)</strong><br/><strong>        Predict: 1.0</strong></pre>
<p>We can also see that certain features (<kbd>3</kbd> and <kbd>11</kbd> in our case) are used for decision making—that is, the two most important reasons customers are likely to churn. But what are those two features? Let's see them:</p>
<pre>println("Feature 11:" + Preprocessing.trainDF.filter(PipelineConstruction.featureCols(11)))<br/>println("Feature 3:" + Preprocessing.trainDF.filter(PipelineConstruction.featureCols(3)))</pre>
<p>According to the following output, feature 3 and 11 were most important predictors:</p>
<pre><strong>Feature 11: [total_international_num_calls: double]</strong><br/><strong>Feature 3:  [total_day_mins: double]</strong></pre>
<p>The customer service calls and total day minutes are selected by DTs, since they provide an automated mechanism for determining the most important features.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Decision trees for regression</h1>
                </header>
            
            <article>
                
<p>In <a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml">Chapter 3</a>, <em>Scala for Learning Classification</em>, we learned how to predict the problem regarding slowness in traffic. We applied <strong>linear regression</strong> (<strong>LR</strong>) and generalized linear regression to solve this problem. Also, we knew the data very well.</p>
<p>As stated earlier, DT also can provide very powerful responses and performance in the case of a regression problem. Similar to <kbd>DecisionTreeClassifier</kbd>, a <kbd>DecisionTreeRegressor</kbd> estimator can be instantiated with the <kbd>DecisionTreeRegressor()</kbd> method. Additionally, we need to explicitly specify the label and feature columns:</p>
<pre>// Estimator algorithm<br/>val model = new DecisionTreeRegressor().setFeaturesCol("features").setLabelCol("label")</pre>
<p>We can set the max bins, number of trees, max depth, and impurity while instantiating the preceding estimator.</p>
<p>However, since we'll perform k-fold cross-validation, we can set those parameters while creating <kbd>paramGrid</kbd>:</p>
<pre>// Search through decision tree's parameter for the best model<br/>var paramGrid = new ParamGridBuilder()<br/>      .addGrid(rfModel.impurity, "variance" :: Nil)// variance for regression<br/>      .addGrid(rfModel.maxBins, 25 :: 30 :: 35 :: Nil)<br/>      .addGrid(rfModel.maxDepth, 5 :: 10 :: 15 :: Nil)<br/>      .addGrid(rfModel.numTrees, 3 :: 5 :: 10 :: 15 :: Nil)<br/>      .build()</pre>
<p class="mce-root">For a better and more stable performance, let's prepare the k-fold cross-validation and grid search as a part of model tuning. As you can guess, I am going to perform 10-fold cross-validation. Feel free to adjust number of folds based on your settings and dataset:</p>
<pre class="mce-root">println("Preparing K-fold Cross Validation and Grid Search: Model tuning")<br/>val numFolds = 10  // 10-fold cross-validation <br/>val cv = new CrossValidator()<br/>      .setEstimator(rfModel)<br/>      .setEvaluator(new RegressionEvaluator)<br/>      .setEstimatorParamMaps(paramGrid)<br/>      .setNumFolds(numFolds)</pre>
<p>Fantastic! We have created the cross-validation estimator. Now it's time to train DT regression model with cross-validation:</p>
<pre>println("Training model with decision tree algorithm")<br/>val cvModel = cv.fit(trainingData)</pre>
<p>Now that we have the fitted model, we can make predictions. So let's start evaluating the model on the train and validation set and calculate RMSE, MSE, MAE, R squared, and so on:</p>
<pre>println("Evaluating the model on the test set and calculating the regression metrics")<br/>val trainPredictionsAndLabels = cvModel.transform(testData).select("label", "prediction")<br/>                                            .map { case Row(label: Double, prediction: Double) <br/>                                            =&gt; (label, prediction) }.rdd<br/><br/>val testRegressionMetrics = new RegressionMetrics(trainPredictionsAndLabels)</pre>
<p>Once we have the best-fitted and cross-validated model, we can expect a good prediction accuracy. Let's observe the result on the train and the validation set:</p>
<pre><strong>val</strong> results = "\n=====================================================================\n" +<br/>      s"TrainingData count: ${trainingData.count}\n" +<br/>      s"TestData count: ${testData.count}\n" +<br/>      "=====================================================================\n" +<br/>      s"TestData MSE = ${testRegressionMetrics.meanSquaredError}\n" +<br/>      s"TestData RMSE = ${testRegressionMetrics.rootMeanSquaredError}\n" +<br/>      s"TestData R-squared = ${testRegressionMetrics.r2}\n" +<br/>      s"TestData MAE = ${testRegressionMetrics.meanAbsoluteError}\n" +<br/>      s"TestData explained variance = ${testRegressionMetrics.explainedVariance}\n" +<br/>      "=====================================================================\n"<br/>println(results)</pre>
<p class="mce-root">The following output shows the MSE, RMSE, R-squared, MAE and explained variance on the test set:</p>
<pre class="mce-root"><strong>=====================================================================</strong><br/><strong> TrainingData count: 80</strong><br/><strong> TestData count: 55</strong><br/><strong> =====================================================================</strong><br/><strong> TestData MSE = 7.871519100933004</strong><br/><strong> TestData RMSE = 2.8056227652578323</strong><br/><strong> TestData R-squared = 0.5363607928629964</strong><br/><strong> TestData MAE = 2.284866391184572</strong><br/><strong> TestData explained variance = 20.213067468774792</strong><br/><strong> =====================================================================</strong></pre>
<p>Great! We have managed to compute the raw prediction on the train set and the test set, and we can see the improvements compared to LR regression model. Let's hunt for the model that will help us to achieve better accuracy:</p>
<pre><strong>val </strong>bestModel = cvModel.bestModel.asInstanceOf[DecisionTreeRegressionModel]</pre>
<p>Additionally, we can see how the decisions were made by observing DTs in the forest:</p>
<pre>println("Decision tree from best cross-validated model: " + bestModel.toDebugString)</pre>
<p>The following is the output:</p>
<pre><strong>Decision tree from best cross-validated model at depth 5 with 39 nodes</strong><br/><strong>   If (feature 0 &lt;= 19.0)</strong><br/><strong>    If (feature 0 &lt;= 3.0)</strong><br/><strong>     If (feature 0 &lt;= 1.0)</strong><br/><strong>      If (feature 3 &lt;= 0.0)</strong><br/><strong>       If (feature 4 &lt;= 0.0)</strong><br/><strong>        Predict: 4.1</strong><br/><strong>       Else (feature 4 &gt; 0.0)</strong><br/><strong>        Predict: 3.4000000000000004</strong><br/><strong>      ....</strong><br/><strong>        Predict: 15.30909090909091</strong><br/><strong>       Else (feature 0 &gt; 25.0)</strong><br/><strong>        Predict: 12.800000000000002</strong><br/><strong>     Else (feature 11 &gt; 1.0)</strong><br/><strong>      Predict: 22.100000000000023</strong><br/><strong>    Else (feature 9 &gt; 1.0)</strong><br/><strong>     Predict: 23.399999999999977</strong></pre>
<p>With DTs, it is possible to measure the feature importance, so that in a later stage we can decide which features to use and which ones to drop from the DataFrame. Let's find the feature importance out of the best model we just created before for all the features that are arranged in an ascending order as follows:</p>
<pre>val featureImportances = bestModel.featureImportances.toArray<br/><br/>val FI_to_List_sorted = featureImportances.toList.sorted.toArray<br/>println("Feature importance generated by the best model: ")<br/>for(x &lt;- FI_to_List_sorted) println(x)<br/><br/></pre>
<p class="mce-root"/>
<p>Following is the feature importance generated by the model:</p>
<pre><strong>Feature importance generated by the best model:</strong><br/><strong> 0.0</strong><br/><strong> 0.0</strong><br/><strong> 0.0</strong><br/><strong> 0.0</strong><br/><strong> 0.0</strong><br/><strong> 0.0</strong><br/><strong> 0.0</strong><br/><strong> 0.0</strong><br/><strong> 7.109215735617604E-5</strong><br/><strong> 2.1327647206851872E-4</strong><br/><strong> 0.001134987328520092</strong><br/><strong> 0.00418143999334111</strong><br/><strong> 0.025448271970345014</strong><br/><strong> 0.03446268498009088</strong><br/><strong> 0.057588305610674816</strong><br/><strong> 0.07952108027588178</strong><br/><strong> 0.7973788612117217</strong><span class="packt_screen"><br/></span></pre>
<p>The last result is important to understand the feature importance. As you can see, RF has ranked some features to be more important. For example, the last few features are the most important ones, while eight of them are less important. We can drop those unimportant columns and train the DT model again to observe whether there is any greater reduction of MAE and increase in R-squared on the test set.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gradient boosted trees for supervised learning</h1>
                </header>
            
            <article>
                
<p>In this section, we'll see how to use GBT to solve both regression and classification problems. In the previous two chapters, <a href="f649db9f-aea9-4509-b9b8-e0b7d5fb726a.xhtml" target="_blank">Chapter 2</a><span>, </span><em>Scala for Regression Analysis</em>,<span> and </span><a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml" target="_blank">Chapter 3</a><span>, </span><em>Scala for Learning Classification</em>, we solved the customer churn and insurance severity claim problems, which were classification and regression problem, respectively. In both approaches, we used other classic models. However, we'll see how we can solve them with tree-based and ensemble techniques. We'll use the GBT implementation from the Spark ML package in Scala.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gradient boosted trees for classification</h1>
                </header>
            
            <article>
                
<p>We know the customer churn prediction problem from <a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml">Chapter 3</a>, <em>Scala for Learning Classification</em>, and we know the data well. We already know the working principles of RF, so let's start using the Spark-based implementation of RF:</p>
<ol>
<li>Instantiate a <kbd>GBTClassifier</kbd> estimator by invoking the <kbd>GBTClassifier()</kbd> interface:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">val gbt = new GBTClassifier()<br/>      .setLabelCol("label")<br/>      .setFeaturesCol("features")<br/>      .setSeed(1234567L)</pre>
<ol start="2">
<li>We have three transformers and an estimator ready. Chain in a single pipeline, that is, each of them acts a stage:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">// Chain indexers and tree in a Pipeline.<br/>val pipeline = new Pipeline()<br/>      .setStages(Array(ScalaClassification.PipelineConstruction.ipindexer,<br/>        ScalaClassification.PipelineConstruction.labelindexer,<br/>        ScalaClassification.PipelineConstruction.assembler,<br/>        gbt))</pre>
<ol start="3">
<li>Define the <kbd>paramGrid</kbd> variable to perform such a grid search over the hyperparameter space:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">// Search through decision tree's maxDepth parameter for best model<br/>val paramGrid = new ParamGridBuilder()<br/>      .addGrid(gbt.maxDepth, 3 :: 5 :: 10 :: Nil) // :: 15 :: 20 :: 25 :: 30 :: Nil)<br/>      .addGrid(gbt.impurity, "gini" :: "entropy" :: Nil)<br/>      .addGrid(gbt.maxBins, 5 :: 10 :: 20 :: Nil) //10 :: 15 :: 25 :: 35 :: 45 :: Nil)<br/>      .build()</pre>
<ol start="4">
<li>Define a <kbd>BinaryClassificationEvaluator</kbd> evaluator to evaluate the model:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">val evaluator = new BinaryClassificationEvaluator()<br/>                  .setLabelCol("label")<br/>                  .setRawPredictionCol("prediction")</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="5">
<li>We use a <kbd>CrossValidator</kbd> for performing 10-fold cross validation for best model selection: </li>
</ol>
<pre style="padding-left: 60px" class="mce-root">// Set up 10-fold cross validation<br/>val numFolds = 10<br/>val crossval = new CrossValidator()<br/>      .setEstimator(pipeline)<br/>      .setEvaluator(evaluator)<br/>      .setEstimatorParamMaps(paramGrid)<br/>      .setNumFolds(numFolds)</pre>
<ol start="6">
<li>Let's call now the <kbd>fit</kbd> method so that the complete predefined pipeline, including all feature preprocessing and DT classifier, is executed multiple times—each time with a different hyperparameter vector:</li>
</ol>
<pre style="padding-left: 60px"><strong>val</strong> cvModel = crossval.fit(Preprocessing.trainDF)</pre>
<p>Now it's time to evaluate the predictive power of DT model on the test dataset:</p>
<ol>
<li>Transform the test set with the model pipeline, which will update the features as per the same mechanism we described in the preceding feature engineering step:</li>
</ol>
<pre style="padding-left: 60px"><strong>val</strong> predictions = cvModel.transform(Preprocessing.testSet)<br/>prediction.show(10)</pre>
<p style="padding-left: 60px"><span>This will lead us to the following DataFrame showing the predicted labels against the actual labels. Additionally, it shows the raw probabilities:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-569 image-border" src="assets/5764c41b-e8ca-46e1-8139-1361a875ed98.png" style="width:25.58em;height:17.75em;"/></p>
<p class="mce-root"/>
<p style="padding-left: 60px">However, after seeing the preceding prediction DataFrame, it is really difficult to guess the classification accuracy.</p>
<ol start="2">
<li>But in the second step, in the evaluation is done using <kbd>BinaryClassificationEvaluator</kbd> as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>val</strong> accuracy = evaluator.evaluate(predictions)<br/>println("Classification accuracy: " + accuracy)</pre>
<p style="padding-left: 60px">This will give us the classification accuracy:</p>
<pre style="padding-left: 60px"><strong>Accuracy: 0.869460802355539</strong></pre>
<p>So we get about 87% classification accuracy from our binary classification model. Just like with SVM and LR, we will observe the area under the precision-recall curve and the area under the ROC curve based on the following RDD, which contains the raw scores on the test set:</p>
<pre class="mce-root"><strong>val</strong> predictionAndLabels = predictions<br/>      .select("prediction", "label")<br/>      .rdd.map(x =&gt; (x(0).asInstanceOf[Double], x(1)<br/>      .asInstanceOf[Double]))</pre>
<p>The preceding RDD can be used for computing the previously mentioned performance metrics:</p>
<pre><strong>val</strong> metrics = <strong>new</strong> BinaryClassificationMetrics(predictionAndLabels)<br/>println("Area under the precision-recall curve: " + metrics.areaUnderPR)<br/>println("Area under the receiver operating characteristic (ROC) curve: " + metrics.areaUnderROC)</pre>
<p class="mce-root"><span>This will share the value in terms of accuracy and prediction:</span></p>
<pre><strong>Area under the precision-recall curve: 0.7270259009251356</strong><br/><strong>Area under the receiver operating characteristic (ROC) curve: 0.869460802355539</strong></pre>
<p>In this case, the evaluation returns 87% accuracy but only 73% precision, which is much better than SVM and LR. Then we calculate some more false and true metrics. Positive and negative predictions can also be useful to evaluate the model's performance:</p>
<pre><strong>val</strong> TC = predDF.count() //Total count<br/><br/><strong>val</strong> tp = tVSpDF.filter($"prediction" === 0.0).filter($"label" === $"prediction")<br/>                    .count() / TC.toDouble // True positive rate<br/><strong>val</strong> tn = tVSpDF.filter($"prediction" === 1.0).filter($"label" === $"prediction")<br/>                    .count() / TC.toDouble // True negative rate<br/><strong>val</strong> fp = tVSpDF.filter($"prediction" === 1.0).filter(not($"label" === $"prediction"))<br/>                    .count() / TC.toDouble // False positive rate<br/><strong>val</strong> fn = tVSpDF.filter($"prediction" === 0.0).filter(not($"label" === $"prediction"))<br/>                    .count() / TC.toDouble // False negative rate</pre>
<p class="mce-root">Additionally, we compute the Matthews correlation coefficient: <span class="packt_screen"><q><br/></q></span></p>
<pre><strong>val</strong> MCC = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (fp + tn) * (tn + fn)) </pre>
<p>Let's observe how high the model confidence is:</p>
<pre>println("True positive rate: " + tp *100 + "%")<br/>println("False positive rate: " + fp * 100 + "%")<br/>println("True negative rate: " + tn * 100 + "%")<br/>println("False negative rate: " + fn * 100 + "%")<br/>println("Matthews correlation coefficient: " + MCC)</pre>
<p class="mce-root"><span>Now let's take a look at the true positive, false positive, true negative, and false negative rates. Additionally, we see the MCC:<br/></span></p>
<pre class="mce-root"><strong>True positive rate: 0.7781109445277361</strong><br/><strong>False positive rate: 0.07946026986506746</strong><br/><strong>True negative rate: 0.1184407796101949</strong><br/><strong>False negative rate: 0.0239880059970015</strong><br/><strong>Matthews correlation coefficient: 0.6481780577821629</strong></pre>
<p>These rates looks promising as we experienced positive MCC that shows mostly positive correlation indicating a robust classifier. Now, similar to DTs, RFs can be debugged during the classification. For the tree to be printed and to select the most important features, run the last few lines of code in the DT. Note that we still confine the hyperparameter space with <kbd>numTrees</kbd>, <kbd>maxBins</kbd>, and <kbd>maxDepth</kbd> by limiting them to <kbd>7</kbd>. Remember that bigger trees will most likely perform better. Therefore, feel free to play around with this code and add features, and also use a bigger hyperparameter space, for instance, bigger trees.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">GBTs for regression</h1>
                </header>
            
            <article>
                
<p>To reduce the size of a loss function, GBTs will train many DTs. For each instance, the algorithm will use the ensemble that is currently available to predict the label of each training.</p>
<p>Similar to decision trees, GBTs can do the following:</p>
<ul>
<li>Handle both categorical and numerical features</li>
<li>Be used for both binary classification and regression (multiclass classification is not yet supported)</li>
<li>Do not require feature scaling</li>
<li>Capture non-linearity and feature interactions from very high-dimensional datasets</li>
</ul>
<p>Suppose we have <em>N</em> data instances (being <em>x<sub>i</sub></em> = features of instance <em>i</em>) and <em>y</em> is the label (being <em>y<sub>i</sub></em> = label of instance <em>i</em>), then <em>f(x<sub>i</sub>)</em> is GBT model's predicted label for instance <em>i</em>, which tries to minimize any of the following losses:</p>
<p class="CDPAlignCenter CDPAlign"><span class="MathJax"><span class="math"><span><span class="mrow"><span class="mo"><img class="fm-editor-equation" src="assets/65f6f4b8-e90a-47da-a3c0-030f4ff1d493.png" style="width:25.17em;height:2.17em;"/></span></span></span></span></span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/880a15a7-d9c3-4c57-ac07-1527f8b1fb83.png" style="width:17.92em;height:2.17em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/a742e469-420d-40f4-aa94-c9bbef6a0223.png" style="width:17.42em;height:2.17em;"/></p>
<p>The first equation is called the <em>log</em> loss, which is twice the binomial negative <em>log</em> likelihood. The second one called squared error is commonly referred to as <em>L2</em> loss and the default loss for GBT-based regression task. Finally, the third, called absolute error, is commonly referred to as <em>L1</em> loss and is recommended if the data points have many outliers and robust than squared error.</p>
<p>Now that we know the minimum working principle of the GBT regression algorithm, we can get started. Let's instantiate a <kbd>GBTRegressor</kbd> estimator by invoking the <kbd>GBTRegressor()</kbd> interface:</p>
<pre><strong>val</strong> gbtModel = new GBTRegressor().setFeaturesCol("features").setLabelCol("label")</pre>
<p>We can set the max bins, number of trees, max depth, and impurity when instantiating the preceding estimator. However, since we'll perform k-fold cross-validation, we can set those parameters while creating the <kbd>paramGrid</kbd> variable too:</p>
<pre>// Search through GBT's parameter for the best model<br/><strong>var</strong> paramGrid = new ParamGridBuilder()<br/>      .addGrid(gbtModel.impurity, "variance" :: Nil)// variance for regression<br/>      .addGrid(gbtModel.maxBins, 25 :: 30 :: 35 :: Nil)<br/>      .addGrid(gbtModel.maxDepth, 5 :: 10 :: 15 :: Nil)<br/>      .addGrid(gbtModel.numTrees, 3 :: 5 :: 10 :: 15 :: Nil)<br/>      .build()</pre>
<div class="packt_infobox"><strong>Validation while training</strong>: Gradient boosting can overfit, especially when you train your model with more trees. In order to prevent this issue, it is useful to validate (for example, using cross-validation) while carrying out the training.</div>
<p class="mce-root">For a better and more stable performance, let's prepare the k-fold cross-validation and grid search as part of the model tuning. As you can guess, I am going to perform 10-fold cross-validation. Feel free to adjust the number of folds based on your settings and dataset:</p>
<pre class="mce-root">println("Preparing K-fold Cross Validation and Grid Search: Model tuning")<br/><strong>val</strong> numFolds = 10  // 10-fold cross-validation <br/><strong>val</strong> cv = new CrossValidator()<br/>      .setEstimator(gbtModel)<br/>      .setEvaluator(new RegressionEvaluator)<br/>      .setEstimatorParamMaps(paramGrid)<br/>      .setNumFolds(numFolds)</pre>
<p>Fantastic! We have created the cross-validation estimator. Now it's time to train the <kbd>RandomForestRegression</kbd> model with cross-validation:</p>
<pre>println("Training model with RandomForestRegressor algorithm")<br/><strong>val</strong> cvModel = cv.fit(trainingData)</pre>
<p>Now that we have the fitted model, we can make predictions. Let's start evaluating the model on the train and validation sets and calculate RMSE, MSE, MAE, and R squared error:</p>
<pre>println("Evaluating the model on the test set and calculating the regression metrics")<br/><strong>val</strong> trainPredictionsAndLabels = cvModel.transform(testData).select("label", "prediction")<br/>                                            .map { case Row(label: Double, prediction: Double) <br/>                                            =&gt; (label, prediction) }.rdd<br/><br/><strong>val</strong> testRegressionMetrics = new RegressionMetrics(trainPredictionsAndLabels)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Once we have the best-fitted and cross-validated model, we can expect a high prediction accuracy. Now let's observe the result on the train and the validation sets:</p>
<pre><strong>val</strong> results = "\n=====================================================================\n" +<br/>      s"TrainingData count: ${trainingData.count}\n" +<br/>      s"TestData count: ${testData.count}\n" +<br/>      "=====================================================================\n" +<br/>      s"TestData MSE = ${testRegressionMetrics.meanSquaredError}\n" +<br/>      s"TestData RMSE = ${testRegressionMetrics.rootMeanSquaredError}\n" +<br/>      s"TestData R-squared = ${testRegressionMetrics.r2}\n" +<br/>      s"TestData MAE = ${testRegressionMetrics.meanAbsoluteError}\n" +<br/>      s"TestData explained variance = ${testRegressionMetrics.explainedVariance}\n" +<br/>      "=====================================================================\n"<br/>println(results)</pre>
<p class="mce-root">The following output shows the MSE, RMSE, R-squared, MAE and explained variance on the test set:</p>
<pre class="mce-root"><strong>=====================================================================</strong><br/><strong> TrainingData count: 80</strong><br/><strong> TestData count: 55</strong><br/><strong> =====================================================================</strong><br/><strong> TestData MSE = 5.99847335425882</strong><br/><strong> TestData RMSE = 2.4491780977011084</strong><br/><strong> TestData R-squared = 0.4223425609926217</strong><br/><strong> TestData MAE = 2.0564380367107646</strong><br/><strong> TestData explained variance = 20.340666319995183</strong><br/><strong> =====================================================================</strong></pre>
<p>Great! We have managed to compute the raw prediction on the train and the test set, and we can see the improvements compared to the LR, DT, and GBT regression models. Let's hunt for the model that helps us to achieve better accuracy:</p>
<pre><strong>val </strong>bestModel = cvModel.bestModel.asInstanceOf[GBTRegressionModel]</pre>
<p>Additionally, we can see how the decisions were made by observing the DTs in the forest:</p>
<pre>println("Decision tree from best cross-validated model: " + bestModel.toDebugString)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In the following output, the toDebugString() method prints the tree's decision nodes and final prediction outcomes at the end leaves: </p>
<pre><strong>Decision tree from best cross-validated model with 10 trees</strong><br/><strong>   Tree 0 (weight 1.0):</strong><br/><strong>     If (feature 0 &lt;= 16.0)</strong><br/><strong>      If (feature 2 &lt;= 1.0)</strong><br/><strong>       If (feature 15 &lt;= 0.0)</strong><br/><strong>        If (feature 13 &lt;= 0.0)</strong><br/><strong>         If (feature 16 &lt;= 0.0)</strong><br/><strong>          If (feature 0 &lt;= 3.0)</strong><br/><strong>           If (feature 3 &lt;= 0.0)</strong><br/><strong>            Predict: 6.128571428571427</strong><br/><strong>           Else (feature 3 &gt; 0.0)</strong><br/><strong>            Predict: 3.3999999999999986</strong><br/><strong> ....</strong><br/><strong> Tree 9 (weight 1.0):</strong><br/><strong>     If (feature 0 &lt;= 22.0)</strong><br/><strong>      If (feature 2 &lt;= 1.0)</strong><br/><strong>       If (feature 1 &lt;= 1.0)</strong><br/><strong>        If (feature 0 &lt;= 1.0)</strong><br/><strong>         Predict: 3.4</strong><br/><strong> ...</strong></pre>
<p>With random forest, it is possible to measure the feature importance so that in a later stage, we can decide which features to use and which ones to drop from the DataFrame. Let's find the feature importance out of the best model we just created before for all the features that are arranged in an ascending order as follows:</p>
<pre><strong>val</strong> featureImportances = bestModel.featureImportances.toArray<br/><br/><strong>val</strong> FI_to_List_sorted = featureImportances.toList.sorted.toArray<br/>println("Feature importance generated by the best model: ")<br/>for(x &lt;- FI_to_List_sorted) println(x)<br/><br/></pre>
<p>Following is the feature importance generated by the model:</p>
<pre><strong>Feature importance generated by the best model:</strong><br/><strong> 0.0</strong><br/><strong> 0.0</strong><br/><strong> 5.767724652714395E-4</strong><br/><strong> 0.001616872851121874</strong><br/><strong> 0.006381209526062637</strong><br/><strong> 0.008867810069950395</strong><br/><strong> 0.009420668763121653</strong><br/><strong> 0.01802097742361489</strong><br/><strong> 0.026755738338777407</strong><br/><strong> 0.02761531441902482</strong><br/><strong> 0.031208534172407782</strong><br/><strong> 0.033620224027091</strong><br/><strong> 0.03801721834820778</strong><br/><strong> 0.05263475066123412</strong><br/><strong> 0.05562565266841311</strong><br/><strong> 0.13221209076999635</strong><br/><strong> 0.5574261654957049</strong></pre>
<p>The last result is important to understand the feature importance. As you can see, the RF has ranked some features that looks to be more important. For example, the last two features are the most important and the first two are less important. We can drop some unimportant columns and train the RF model to observe whether there is any reduction in the R-squared and MAE values on the test set.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random forest for supervised learning</h1>
                </header>
            
            <article>
                
<p>In this section, we'll see how to use RF to solve both regression and classification problems. We'll use DT implementation from the Spark ML package in Scala. Although both GBT and RF are ensembles of trees, the training processes are different. For instance, RF uses the bagging technique to perform the example, while GBT uses boosting. Nevertheless, there are several practical trade-offs between both the ensembles that can pose a dilemma about what to choose. However, RF would be the winner in most of the cases. Here are some justifications:</p>
<ul>
<li>GBTs train one tree at a time, but RF can train multiple trees in parallel. So the training time is lower with RF. However, in some special cases, training and using a smaller number of trees with GBTs is faster and more convenient.</li>
<li>RFs are less prone to overfitting. In other words, RFs reduces variance with more trees, but GBTs reduce bias with more trees.</li>
<li>RFs can be easier to tune since performance improves monotonically with the number of trees, but GBTs perform badly with an increased number of trees.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random forest for classification</h1>
                </header>
            
            <article>
                
<p>We're familiar with the customer churn prediction problem from <a href="51712107-c5bc-4d7d-a84a-3039aafc8c0a.xhtml" target="_blank">Chapter 3</a>, <em>Scala for Learning Classification</em>, and we also know the data well. We also know the working principle of RF. So, we can directly jump into coding using the Spark-based implementation of RFs.</p>
<p>We get started by instantiating a <kbd>RandomForestClassifier</kbd> estimator by invoking the <kbd>RandomForestClassifier()</kbd> interface:</p>
<pre class="mce-root"><strong>val</strong> rf = new RandomForestClassifier()<br/>                    .setLabelCol("label")<br/>                    .setFeaturesCol("features")<br/>                    .setSeed(1234567L)  // for reproducibility</pre>
<p>Now that we have three transformers and an estimator ready, the next task is to chain in a single pipeline, that is, each of them acts as a stage:</p>
<pre class="mce-root"><strong>val</strong> pipeline = new Pipeline()<br/>      .setStages(Array(PipelineConstruction.ipindexer,<br/>                   PipelineConstruction.labelindexer,<br/>                         PipelineConstruction.assembler,rf))</pre>
<p>Let's define <kbd>paramGrid</kbd> to perform a grid search over the hyperparameter space:</p>
<pre class="mce-root"><strong>val</strong> paramGrid = new ParamGridBuilder()<br/>       .addGrid(rf.maxDepth, 3 :: 5 :: 15 :: 20 :: 50 :: Nil)<br/>       .addGrid(rf.featureSubsetStrategy, "auto" :: "all" :: Nil)<br/>       .addGrid(rf.impurity, "gini" :: "entropy" :: Nil)<br/>       .addGrid(rf.maxBins, 2 :: 5 :: 10 :: Nil)<br/>       .addGrid(rf.numTrees, 10 :: 50 :: 100 :: Nil)<br/>       .build()</pre>
<p>Let's define a <kbd>BinaryClassificationEvaluator</kbd> evaluator to evaluate the model:</p>
<pre class="mce-root"><strong>val</strong> evaluator = new BinaryClassificationEvaluator()<br/>                  .setLabelCol("label")<br/>                  .setRawPredictionCol("prediction")</pre>
<p>We use a <kbd>CrossValidator</kbd> to perform 10-fold cross validation to select the best model:</p>
<pre class="mce-root"><strong>val</strong> crossval = new CrossValidator()<br/>      .setEstimator(pipeline)<br/>      .setEvaluator(evaluator)<br/>      .setEstimatorParamMaps(paramGrid)<br/>      .setNumFolds(numFolds)</pre>
<p>Let's call now the <kbd>fit</kbd> method so that the complete predefined pipeline, including all feature preprocessing and the DT classifier, is executed multiple times—each time with a different hyperparameter vector:</p>
<pre><strong>val</strong> cvModel = crossval.fit(Preprocessing.trainDF)</pre>
<p>Now it's time to evaluate the predictive power of the DT model on the test dataset.</p>
<p class="mce-root"/>
<p class="mceNonEditable"><span>As a first step, we need to transform the test set with the model pipeline, which will map the features according to the same mechanism we described in the feature engineering step:</span></p>
<pre><strong>val</strong> predictions = cvModel.transform(Preprocessing.testSet)<br/>prediction.show(10)</pre>
<p>This will lead us to the following DataFrame showing the predicted labels against the actual labels. Additionally, it shows the raw probabilities:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/779f9ae9-174a-49f5-a1af-6bc666d4286d.png" style="width:26.58em;height:20.17em;"/></p>
<p>However, based on the preceding prediction DataFrame, it is really difficult to guess the classification accuracy.</p>
<p>But in the second step, the evaluation is done using <kbd>BinaryClassificationEvaluator</kbd> as follows:</p>
<pre><strong>val</strong> accuracy = evaluator.evaluate(predictions)<br/>println("Classification accuracy: " + accuracy)</pre>
<p>The following is the output:</p>
<pre><strong>Accuracy: 0.8800055207949945</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>So we get about 87% classification accuracy from our binary classification model. Now, similar to SVM and LR, we will observe the area under the precision-recall curve and the area under the ROC curve based on the following RDD, which contains the raw scores on the test set:</p>
<pre class="mce-root"><strong>val</strong> predictionAndLabels = predictions<br/>      .select("prediction", "label")<br/>      .rdd.map(x =&gt; (x(0).asInstanceOf[Double], x(1)<br/>        .asInstanceOf[Double]))</pre>
<p>The preceding RDD can be used to compute the previously mentioned performance metrics:</p>
<pre><strong>val</strong> metrics = <strong>new</strong> BinaryClassificationMetrics(predictionAndLabels)<br/>println("Area under the precision-recall curve: " + metrics.areaUnderPR)<br/>println("Area under the receiver operating characteristic (ROC) curve: " + metrics.areaUnderROC)</pre>
<p>In this case, the evaluation returns 88% accuracy but only 73% precision, which is much better than SVM and LR: </p>
<pre><strong>Area under the precision-recall curve: 0.7321042166486744</strong><br/><strong>Area under the receiver operating characteristic (ROC) curve: 0.8800055207949945</strong></pre>
<p>Then we calculate some more metrics, for example, false and true positive and negative predictions, which will be useful to evaluate the model's performance:</p>
<pre><strong>val</strong> TC = predDF.count() //Total count<br/><br/><strong>val</strong> tp = tVSpDF.filter($"prediction" === 0.0).filter($"label" === $"prediction")<br/>                    .count() / TC.toDouble // True positive rate<br/><strong>val</strong> tn = tVSpDF.filter($"prediction" === 1.0).filter($"label" === $"prediction")<br/>                    .count() / TC.toDouble // True negative rate<br/><strong>val</strong> fp = tVSpDF.filter($"prediction" === 1.0).filter(not($"label" === $"prediction"))<br/>                    .count() / TC.toDouble // False positive rate<br/><strong>val</strong> fn = tVSpDF.filter($"prediction" === 0.0).filter(not($"label" === $"prediction"))<br/>                    .count() / TC.toDouble // False negative rate</pre>
<p class="mce-root">Additionally, we compute the Matthews correlation coefficient:<span class="packt_screen"><q><br/></q></span></p>
<pre><strong>val</strong> MCC = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (fp + tn) * (tn + fn))</pre>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Let's observe how high the model confidence is:</p>
<pre>println("True positive rate: " + tp *100 + "%")<br/>println("False positive rate: " + fp * 100 + "%")<br/>println("True negative rate: " + tn * 100 + "%")<br/>println("False negative rate: " + fn * 100 + "%")<br/>println("Matthews correlation coefficient: " + MCC)</pre>
<p><span>Now let's take a look at the true positive, false positive, true negative, and false negative rates. Additionally, we see the MCC:</span></p>
<pre><strong>True positive rate: 0.7691154422788605</strong><br/><strong>False positive rate: 0.08845577211394302</strong><br/><strong>True negative rate: 0.12293853073463268</strong><br/><strong>False negative rate: 0.019490254872563718</strong><br/><strong>Matthews correlation coefficient: 0.6505449208932913</strong></pre>
<p>Just like DT and GBT, RF not only shows robust performance but also a slightly improved performance. And like DT and GBT, RF can be debugged to get the DT that was constructed during the classification. For the tree to be printed and the most important features selected, try the last few lines of code in the DT, and you're done.</p>
<div class="packt_tip">Can you guess how many different models were trained? Well, we have 10-folds on cross-validation and 5-dimensional hyperparameter space cardinalities between 2 and 7. Now let's do some simple math: <em>10 * 7 * 5 * 2 * 3 * 6 = 12,600</em> models!</div>
<p>Now that we have seen how to use RF in a classification setting, let's see another example of regression analysis.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random forest for regression</h1>
                </header>
            
            <article>
                
<p>Since RF is fast and scalable enough for a large-scale dataset, Spark-based implementations of RF help you achieve massive scalability. Fortunately, we already know the working principles of RF.</p>
<div class="packt_infobox">If the proximities are calculated in RF, the storage requirements also grow exponentially.</div>
<p class="mce-root"/>
<p class="mce-root"/>
<p>We can jump directly into coding using the Spark-based implementation of RF for regression. We get started by instantiating a <kbd>RandomForestClassifier</kbd> estimator by invoking the <kbd>RandomForestClassifier()</kbd> interface:</p>
<pre><strong>val</strong> rfModel = new RandomForestRegressor()<br/>        .setFeaturesCol("features")<br/>        .setLabelCol("label")</pre>
<p>Now let's create a grid space by specifying some hyperparameters, such as the max number of bins, max depth of the trees, number of trees, and impurity types:</p>
<pre>// Search through decision tree's maxDepth parameter for best model<br/><strong>var</strong> paramGrid = new ParamGridBuilder()<br/>      .addGrid(rfModel.impurity, "variance" :: Nil)// variance for regression<br/>      .addGrid(rfModel.maxBins, 25 :: 30 :: 35 :: Nil)<br/>      .addGrid(rfModel.maxDepth, 5 :: 10 :: 15 :: Nil)<br/>      .addGrid(rfModel.numTrees, 3 :: 5 :: 10 :: 15 :: Nil)<br/>      .build()</pre>
<p class="mce-root">For a better and more stable performance, let's prepare the k-fold cross-validation and grid search as part of the model tuning. As you can guess, I am going to perform 10-fold cross-validation. Feel free to adjust the number of folds based on your settings and dataset:</p>
<pre class="mce-root">println("Preparing K-fold Cross Validation and Grid Search: Model tuning")<br/><strong>val</strong> numFolds = 10  // 10-fold cross-validation <br/><strong>val</strong> cv = new CrossValidator()<br/>      .setEstimator(rfModel)<br/>      .setEvaluator(new RegressionEvaluator)<br/>      .setEstimatorParamMaps(paramGrid)<br/>      .setNumFolds(numFolds)</pre>
<p>Fantastic! We have created the cross-validation estimator. Now it's time to train the random forest regression model with cross-validation:</p>
<pre>println("Training model with RandomForestRegressor algorithm")<br/><strong>val</strong> cvModel = cv.fit(trainingData)</pre>
<p>Now that we have the fitted model, we can make predictions. Let's start evaluating the model on the train and validation sets and calculate RMSE, MSE, MAE, and R squared:</p>
<pre>println("Evaluating the model on the test set and calculating the regression metrics")<br/><strong>val</strong> trainPredictionsAndLabels = cvModel.transform(testData).select("label", "prediction")<br/>                                            .map { case Row(label: Double, prediction: Double) <br/>                                            =&gt; (label, prediction) }.rdd<br/><br/><strong>val</strong> testRegressionMetrics = new RegressionMetrics(trainPredictionsAndLabels)</pre>
<p>Once we have the best-fitted and cross-validated model, we can expect a good prediction accuracy. Now let's observe the result on the train and validation sets:</p>
<pre><strong>val</strong> results = "\n=====================================================================\n" +<br/>      s"TrainingData count: ${trainingData.count}\n" +<br/>      s"TestData count: ${testData.count}\n" +<br/>      "=====================================================================\n" +<br/>      s"TestData MSE = ${testRegressionMetrics.meanSquaredError}\n" +<br/>      s"TestData RMSE = ${testRegressionMetrics.rootMeanSquaredError}\n" +<br/>      s"TestData R-squared = ${testRegressionMetrics.r2}\n" +<br/>      s"TestData MAE = ${testRegressionMetrics.meanAbsoluteError}\n" +<br/>      s"TestData explained variance = ${testRegressionMetrics.explainedVariance}\n" +<br/>      "=====================================================================\n"<br/>println(results)</pre>
<p class="mce-root">The following output shows the MSE, RMSE, R-squared, MAE and explained variance on the test set:</p>
<pre class="mce-root"><strong>=====================================================================</strong><br/><strong> TrainingData count: 80</strong><br/><strong> TestData count: 55</strong><br/><strong> =====================================================================</strong><br/><strong> TestData MSE = 5.99847335425882</strong><br/><strong> TestData RMSE = 2.4491780977011084</strong><br/><strong> TestData R-squared = 0.4223425609926217</strong><br/><strong> TestData MAE = 2.0564380367107646</strong><br/><strong> TestData explained variance = 20.340666319995183</strong><br/><strong> =====================================================================</strong></pre>
<p>Great! We have managed to compute the raw prediction on the train and the test sets, and we can see the improvements compared to the LR, DT, and GBT regression models. Let's hunt for the model that helps us to achieve better accuracy:</p>
<pre><strong>val </strong>bestModel = cvModel.bestModel.asInstanceOf[RandomForestRegressionModel]</pre>
<p>Additionally, we can see how the decisions were made by seeing DTs in the forest:</p>
<pre>println("Decision tree from best cross-validated model: " + bestModel.toDebugString)</pre>
<p class="mce-root"/>
<p>In the following output, the <kbd>toDebugString()</kbd> method prints the tree's decision nodes and final prediction outcomes at the end leaves:  </p>
<pre><strong>Decision tree from best cross-validated model with 10 trees</strong><br/><strong>   Tree 0 (weight 1.0):</strong><br/><strong>     If (feature 0 &lt;= 16.0)</strong><br/><strong>      If (feature 2 &lt;= 1.0)</strong><br/><strong>       If (feature 15 &lt;= 0.0)</strong><br/><strong>        If (feature 13 &lt;= 0.0)</strong><br/><strong>         If (feature 16 &lt;= 0.0)</strong><br/><strong>          If (feature 0 &lt;= 3.0)</strong><br/><strong>           If (feature 3 &lt;= 0.0)</strong><br/><strong>            Predict: 6.128571428571427</strong><br/><strong>           Else (feature 3 &gt; 0.0)</strong><br/><strong>            Predict: 3.3999999999999986</strong><br/><strong> ....</strong><br/><strong> Tree 9 (weight 1.0):</strong><br/><strong>     If (feature 0 &lt;= 22.0)</strong><br/><strong>      If (feature 2 &lt;= 1.0)</strong><br/><strong>       If (feature 1 &lt;= 1.0)</strong><br/><strong>        If (feature 0 &lt;= 1.0)</strong><br/><strong>         Predict: 3.4</strong><br/><strong> ...</strong></pre>
<p>With RF, it is possible to measure the feature importance so that at a later stage, we can decide which features to use and which ones to drop from the DataFrame. Let's find the feature importance out of the best model we just created before we arrange all the feature in an ascending order as follows:</p>
<pre><strong>val</strong> featureImportances = bestModel.featureImportances.toArray<br/><br/><strong>val</strong> FI_to_List_sorted = featureImportances.toList.sorted.toArray<br/>println("Feature importance generated by the best model: ")<br/>for(x &lt;- FI_to_List_sorted) println(x)<br/><br/></pre>
<p>Following is the feature importance generated by the model:</p>
<pre><strong>Feature importance generated by the best model:</strong><br/><strong> 0.0</strong><br/><strong> 0.0</strong><br/><strong> 5.767724652714395E-4</strong><br/><strong> 0.001616872851121874</strong><br/><strong> 0.006381209526062637</strong><br/><strong> 0.008867810069950395</strong><br/><strong> 0.009420668763121653</strong><br/><strong> 0.01802097742361489</strong><br/><strong> 0.026755738338777407</strong><br/><strong> 0.02761531441902482</strong><br/><strong> 0.031208534172407782</strong><br/><strong> 0.033620224027091</strong><br/><strong> 0.03801721834820778</strong><br/><strong> 0.05263475066123412</strong><br/><strong> 0.05562565266841311</strong><br/><strong> 0.13221209076999635</strong><br/><strong> 0.5574261654957049</strong></pre>
<p>The last result is important for understanding the feature importance. As seen, some features have higher weights than others. Even some of these have zero weights. Higher the weights the higher the importance of a feature. For example, the last two features are the most important, and the first two are less important. We can drop some unimportant columns and train the RF model to observe whether there is any reduction in the R-squared and MAE values on the test set.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What's next?</h1>
                </header>
            
            <article>
                
<p>So far, we have mostly covered classic and tree-based algorithms for both regression and classification. We saw that the ensemble technique showed the best performance compared to classic algorithms. However, there are other algorithms, such as one-vs-rest algorithm, which work for solving classification problems using other classifiers, such as logistic regression.</p>
<p>Apart from this, neural-network-based approaches, such as <strong>multilayer perceptron</strong> (<strong>MLP</strong>), <strong>convolutional neural network</strong> (<strong>CNN</strong>), and <strong>recurrent neural network</strong> (<strong>RNN</strong>), can also be used to solve supervised learning problems. However, as expected, these algorithms require a large number of training samples and a large computing infrastructure. The datasets we used so far throughout the examples had a few samples. Moreover, those were not so high dimensional. This doesn't mean that we cannot use them to solve these two problems; we can, but this results in huge overfitting due to a lack of training samples.</p>
<p>How do we fix this issue? Well, we can either search for other datasets or generate training data randomly. We'll discuss and show how we can train neural-network-based deep learning models to solve other problems.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we had a brief introduction to powerful tree-based algorithms, such as DTs, GBT, and RF, for solving both classification and regression tasks. We saw how to develop these classifiers and regressors using tree-based and ensemble techniques. Through two real-world classification and regression problems, we saw how tree ensemble techniques outperform DT-based classifiers or regressors.</p>
<p>We covered supervised learning for both classification and regression on structured and labeled data. However, with the rise of cloud computing, IoT, and social media, unstructured data is growing unprecedentedly, giving more than 80% data, most of which is unlabeled.</p>
<p>Unsupervised learning techniques, such as clustering analysis and dimensionality reduction, are key applications in data-driven research and industry settings to find hidden structures from unstructured datasets automatically. There are many clustering algorithms, such as k-means and bisecting k-means. However, these algorithms cannot perform well with high-dimensional input datasets and often suffer from the <em>curse of dimensionality</em>. Reducing the dimensionality using algorithms such as <strong>principal component analysis</strong> (<strong>PCA</strong>) and feeding the latent data is useful for clustering billions of data points.</p>
<p>In the next chapter, we will use one kind of genomic data to cluster a population according to their predominant ancestry, also called geographic ethnicity. We will also learn how to evaluate the clustering analysis result and about the dimensionality reduction technique to avoid the curse of dimensionality.</p>


            </article>

            
        </section>
    </body></html>