["```py\n     import matplotlib.pyplot as plt\n    import seaborn as sns\n    from sklearn.datasets import fetch_california_housing\n    ```", "```py\n     sns.set(style=\"darkgrid\")\n    ```", "```py\n     X, y = fetch_california_housing(\n        return_X_y=True, as_frame=True)\n    ```", "```py\n     plt.figure(figsize=(8, 3))\n    sns.boxplot(data=X[\"MedInc\"], orient=\"y\")\n    plt.title(\"Boxplot\")\n    plt.show()\n    ```", "```py\n     def plot_boxplot_and_hist(data, variable):\n        f, (ax_box, ax_hist) = plt.subplots(\n            2, sharex=True,\n            gridspec_kw={\"height_ratios\": (0.50, 0.85)})\n        sns.boxplot(x=data[variable], ax=ax_box)\n        sns.histplot(data=data, x=variable, ax=ax_hist)\n        plt.show()\n    ```", "```py\n     plot_boxplot_and_hist(X, \"MedInc\")\n    ```", "```py\n     def find_limits(df, variable, fold):\n        q1 = df[variable].quantile(0.25)\n        q3 = df[variable].quantile(0.75)\n        IQR = q3 - q1\n        lower_limit = q1 - (IQR * fold)\n        upper_limit = q3 + (IQR * fold)\n        return lower_limit, upper_limit\n    ```", "```py\n     lower_limit, upper_limit = find_limits(\n        X, \"MedInc\", 1.5)\n    ```", "```py\n     plot_boxplot_and_hist(X, \"HouseAge\")\n    ```", "```py\n     lower_limit, upper_limit = find_limits(\n        X, \"HouseAge\", 1.5)\n    ```", "```py\n     import numpy as np\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    from sklearn.datasets import load_breast_cancer\n    ```", "```py\n     X, y = load_breast_cancer(\n        return_X_y=True, as_frame=True)\n    ```", "```py\n     def plot_boxplot_and_hist(data, variable):\n        f, (ax_box, ax_hist) = plt.subplots(\n            2, sharex=True,\n            gridspec_kw={\"height_ratios\": (0.50, 0.85)})\n        sns.boxplot(x=data[variable], ax=ax_box)\n        sns.histplot(data=data, x=variable, ax=ax_hist)\n        plt.show()\n    ```", "```py\n     plot_boxplot_and_hist(X, \"mean smoothness\")\n    ```", "```py\n     def find_limits(df, variable, fold):\n        var_mean = df[variable].mean()\n        var_std = df[variable].std()\n        lower_limit = var_mean - fold * var_std\n        upper_limit = var_mean + fold * var_std\n        return lower_limit, upper_limit\n    ```", "```py\n     lower_limit, upper_limit = find_limits(\n        X, \"mean smoothness\", 3)\n    ```", "```py\n     outliers = np.where(\n        (X[«mean smoothness»] > upper_limit) |\n        (X[«mean smoothness»] < lower_limit),\n        True,\n        False\n    )\n    ```", "```py\n     def plot_boxplot_and_hist(data, variable):\n        f, (ax_box, ax_hist) = plt.subplots(\n            2, sharex=True,\n            gridspec_kw={\"height_ratios\": (0.50, 0.85)})\n        sns.boxplot(x=data[variable], ax=ax_box)\n        sns.histplot(data=data, x=variable, ax=ax_hist)\n        plt.vlines(\n            x=lower_limit, ymin=0, ymax=80, color='r')\n        plt.vlines(\n            x=upper_limit, ymin=0, ymax=80, color='r')\n         plt.show()\n    ```", "```py\n     plot_boxplot_and_hist(X, \"mean smoothness\")\n    ```", "```py\n     import numpy as np\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    from sklearn.datasets import load_breast_cancer\n    ```", "```py\n     X, y = load_breast_cancer(\n        return_X_y=True, as_frame=True)\n    ```", "```py\n     def find_limits(df, variable, fold):\n        median = df[variable].median()\n        center = df[variable] - median\n        MAD = center.abs().median() * 1.4826\n        lower_limit = median - fold * MAD\n        upper_limit = median + fold * MAD\n        return lower_limit, upper_limit\n    ```", "```py\n     lower_limit, upper_limit = find_limits(\n        X, \"mean smoothness\", 3)\n    ```", "```py\n     outliers = np.where(\n        (X[«mean smoothness»] > upper_limit) |\n        (X[«mean smoothness»] < lower_limit),\n        True,\n        False\n    )\n    ```", "```py\n     def plot_boxplot_and_hist(data, variable):\n        f, (ax_box, ax_hist) = plt.subplots(\n            2, sharex=True,\n            gridspec_kw={\"height_ratios\": (0.50, 0.85)})\n        sns.boxplot(x=data[variable], ax=ax_box)\n        sns.histplot(data=data, x=variable, ax=ax_hist)\n        plt.vlines(\n            x=lower_limit, ymin=0, ymax=80, color='r')\n        plt.vlines(\n            x=upper_limit, ymin=0, ymax=80, color='r')\n        plt.show()\n    ```", "```py\n     plot_boxplot_and_hist(X, \"mean smoothness\")\n    ```", "```py\n     import matplotlib.pyplot as plt\n    import seaborn as sns\n    from sklearn.datasets import fetch_california_housing\n    from sklearn.model_selection import train_test_split\n    from feature_engine.outliers import OutlierTrimmer\n    ```", "```py\n     X, y = fetch_california_housing(\n        return_X_y=True, as_frame=True)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=0)\n    ```", "```py\n     def find_limits(df, variable, fold):\n        q1 = df[variable].quantile(0.25)\n        q3 = df[variable].quantile(0.75)\n        IQR = q3 - q1\n        lower_limit = q1 - (IQR * fold)\n        upper_limit = q3 + (IQR * fold)\n        return lower_limit, upper_limit\n    ```", "```py\n     lower, upper = find_limits(X_train, \"MedInc\", 3)\n    ```", "```py\n     inliers = X_train[\"MedInc\"].ge(lower)\n    train_t = X_train.loc[inliers]\n    inliers = X_test[\"MedInc\"].ge(lower)\n    test_t = X_test.loc[inliers]\n    ```", "```py\n     inliers = X_train[\"MedInc\"].le(upper)\n    train_t = X_train.loc[inliers]\n    inliers = X_test[\"MedInc\"].le(upper)\n    test_t = X_test.loc[inliers]\n    ```", "```py\n     trimmer = OutlierTrimmer(\n        variables = [«MedInc\", \"HouseAge\", \"Population\"],\n        capping_method=\"iqr\",\n        tail=\"both\",\n        fold=1.5,\n    )\n    ```", "```py\n     trimmer.fit(X_train)\n    ```", "```py\n     X_train_t = trimmer.transform(X_train)\n    X_test_t = trimmer.transform(X_test)\n    ```", "```py\n     def plot_boxplot_and_hist(data, variable):\n        f, (ax_box, ax_hist) = plt.subplots(\n            2, sharex=True,\n            gridspec_kw={\"height_ratios\": (0.50, 0.85)}\n        )\n        sns.boxplot(x=data[variable], ax=ax_box)\n        sns.histplot(data=data, x=variable, ax=ax_hist)\n        plt.show()\n    ```", "```py\n     plot_boxplot_and_hist(X_train, \"MedInc\")\n    ```", "```py\n     plot_boxplot_and_hist(train_t, \"MedInc\")\n    ```", "```py\n     from sklearn.datasets import load_breast_cancer\n    from sklearn.model_selection import train_test_split\n    from feature_engine.outliers import Winsorizer\n    ```", "```py\n     X, y = load_breast_cancer(\n        return_X_y=True, as_frame=True)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=0)\n    ```", "```py\n     def find_limits(df, variable, fold):\n        var_mean = df[variable].mean()\n        var_std = df[variable].std()\n        lower_limit = var_mean - fold * var_std\n        upper_limit = var_mean + fold * var_std\n        return lower_limit, upper_limit\n    ```", "```py\n     var = \"worst smoothness\"\n    lower_limit, upper_limit = find_limits(\n        X_train, var, 3)\n    ```", "```py\n     train_t = X_train.copy()\n    test_t = X_test.copy()\n    ```", "```py\n     train_t[var] = train_t[var].clip(\n        lower=lower_limit, upper=upper_limit)\n    test_t[var] = test_t[var].clip(\n        lower=lower_limit, upper=upper_limit)\n    ```", "```py\n     capper = Winsorizer(\n        variables=[«worst smoothness», «worst texture»],\n        capping_method=\"gaussian\",\n        tail=\"both\",\n        fold=3,\n    )\n    ```", "```py\n     capper.fit(X_train)\n    ```", "```py\n     X_train = capper.transform(X_train)\n    X_test = capper.transform(X_test)\n    ```", "```py\n     worst smoothness  worst texture\n    min              0.071170        12.020000\n    max              0.201411        43.953738\n    ```", "```py\n     import matplotlib.pyplot as plt\n    import seaborn as sns\n    from sklearn.datasets import load_breast_cancer\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n     X, y = load_breast_cancer(\n        return_X_y=True, as_frame=True)\n    ```", "```py\n     X_train, X_test, y_train, y_test = train_test_split(\n        X,\n        y,\n        test_size=0.3,\n        random_state=0,\n    )\n    ```", "```py\n     q05 = X_train.quantile(0.05).to_dict()\n    q95 = X_train.quantile(0.95).to_dict()\n    ```", "```py\n     train_t = X_train.clip(lower=q05, upper=q95)\n    test_t = X_test.clip(lower=q05, upper=q95)\n    ```", "```py\n     var = 'worst smoothness'\n    X_train[var].agg([\"min\", \"max\", \"mean\"])\n    ```", "```py\n    <st c=\"37705\">min      0.071170</st>\n    <st c=\"37718\">max      0.222600</st>\n    <st c=\"37731\">mean     0.132529</st>\n    <st c=\"37745\">Name: worst smoothness, dtype: float64</st>\n    ```", "```py\n     train_t[var].agg([„min\", „max\"])\n    ```", "```py\n    <st c=\"38081\">min      0.096053</st>\n    <st c=\"38094\">max      0.173215</st>\n    <st c=\"38107\">mean     0.132063</st>\n    <st c=\"38121\">Name: worst smoothness, dtype: float64</st>\n    ```"]