["```py\nDeepBeliefNetwork = new DeepBeliefNetwork(28 * 29, 500, 500, 1000);\n```", "```py\nDeepBeliefNetworkTrainer trainer = new\n  DeepBeliefNetworkTrainer(DeepBeliefNetwork,\n  DeepBeliefNetwork?.LayerWeights?[layerId], inputs);\n```", "```py\nprivate void TrainNetwork(DeepBeliefNetworkTrainer trainer)\n         {\n             try\n             {\n                 Stopping = false;\n                 ClearBoxes();\n                 _unsavedChanges = true;\n                 int generation = 0;\n\n                 SetThreadExecutionState(EXECUTION_STATE.ES_CONTINUOUS\n                   | EXECUTION_STATE.ES_SYSTEM_REQUIRED);\n\n                 while (Stopping == false)\n                 {\n                     Stopwatch stopwatch = Stopwatch.StartNew();\n                     TrainingError error = trainer?.Train();\n                     label1.Text = string.Format(\n                         \"Gen {0} ({4:0.00} s): ReconstructionError=\n                           {1:0.00}, DetectorError={2:0.00},\n                           LearningRate={3:0.0000}\",\n                         generation, error.ReconstructionError,\n                         error.FeatureDetectorError,\n                         trainer.TrainingWeights.AdjustedLearningRate,\n                           stopwatch.ElapsedMilliseconds / 1000.0);\n\n                     Application.DoEvents();\n                     ShowReconstructed(trainer);\n                     ShowFeatureDetectors(trainer);\n                     Application.DoEvents();\n\n                     if (Stopping)\n                     {\n                         break;\n                     }\n                     generation++;\n                 }\n                 DocumentDeepBeliefNetwork();\n             }\n             finally\n             {\n                 SetThreadExecutionState(EXECUTION_STATE.ES_CONTINUOUS);\n             }\n         }\n```", "```py\n public TrainingError Train()\n         {\n             TrainingError trainingError = null;\n             if (_weights != null)\n             {\n                 ClearDetectorErrors(_weights.LowerLayerSize,\n                  _weights.UpperLayerSize);\n\n                 float reconstructionError = 0;\n\n                 ParallelFor(MultiThreaded, 0, _testCount,\n testCase =>\n {\n float errorPart = \n TrainOnSingleCase(_rawTestCases, \n _weights?.Weights, _detectorError,\n testCase, _weights.LowerLayerSize, \n _weights.UpperLayerSize, _testCount);\n\n lock (_locks?[testCase % \n _weights.LowerLayerSize])\n {\n reconstructionError += errorPart;\n }\n });\n\n                 float epsilon = \n                 _weights.GetAdjustedAndScaledTrainingRate(_testCount);\n                 UpdateWeights(_weights.Weights, \n                   _weights.LowerLayerSize, _weights.UpperLayerSize, \n                   _detectorError, epsilon);\n                 trainingError = new \n                   TrainingError(_detectorError.Sum(val => \n                   Math.Abs(val)), reconstructionError);\n                   _weights?.RegisterLastTrainingError(trainingError);\n                 return trainingError;\n             }\n             return trainingError;\n         }\n```", "```py\nprivate float TrainOnSingleCase(float[] rawTestCases, float[] weights, float[] detectorErrors, int testCase,\n             int lowerCount, int upperCount, int testCaseCount)\n         {\n             float[] model = new float[upperCount];\n             float[] reconstructed = new float[lowerCount];\n             float[] reconstructedModel = new float[upperCount];\n             int rawTestCaseOffset = testCase * lowerCount;\n\n             ActivateLowerToUpperBinary(rawTestCases, lowerCount, \n               rawTestCaseOffset, model, upperCount, weights); // Model\n             ActivateUpperToLower(reconstructed, lowerCount, model,\n               upperCount, weights); // Reconstruction\n             ActivateLowerToUpper(reconstructed, lowerCount, 0,\n             reconstructedModel, upperCount, weights); // \n             Reconstruction model\n             return AccumulateErrors(rawTestCases, lowerCount, \n             rawTestCaseOffset, model, upperCount, reconstructed,\n                 reconstructedModel, detectorErrors); // Accumulate \n                  detector errors\n         }\n```", "```py\nprivate float AccumulateErrors(float[] rawTestCases, int lowerCount, int rawTestCaseOffset, float[] model,\n             int upperCount, float[] reconstructed, float[] reconstructedModel, float[] detectorErrors)\n         {\n             float reconstructedError = 0;\n             float[] errorRow = new float[upperCount];\n\n             for (int lower = 0; lower < lowerCount; lower++)\n             {\n                 int errorOffset = upperCount * lower;\n                 for (int upper = 0; upper < upperCount; upper++)\n                 {\n                     errorRow[upper] = rawTestCases[rawTestCaseOffset + \n                       lower] * model[upper] + \n                       // What the model should believe in\n                         -reconstructed[lower] * \n                           reconstructedModel[upper]; \n                           // What the model actually believes in\n                 }\n\n                 lock (_locks[lower])\n                 {\n                     for (int upper = 0; upper < upperCount; upper++)\n                     {\n                         detectorErrors[errorOffset + upper] -= \n                           errorRow[upper];\n                     }\n                 }\n\n                 reconstructedError += \n                   Math.Abs(rawTestCases[rawTestCaseOffset + lower] - \n                   reconstructed[lower]);\n             }\n\n             return reconstructedError;\n         }\n```"]