- en: Chapter 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with Quadratic Unconstrained Binary Optimization Problems
  prefs: []
  type: TYPE_NORMAL
- en: '*The universe cannot be read until we have learned the language and* *become
    familiar with the characters in which it is written.*'
  prefs: []
  type: TYPE_NORMAL
- en: — Galileo Galilei
  prefs: []
  type: TYPE_NORMAL
- en: Starting with this chapter, we will be studying different algorithms that have
    been proposed to solve optimization problems with quantum computers. We will work
    both with **quantum annealers** and with computers that implement the **quantum
    circuit model**. We will use methods such as the **Quantum Approximate Optimization
    Algorithm** (**QAOA**), **Grover’s** **Adaptive Search** (**GAS**), and the **Variational
    Quantum Eigensolver** (**VQE**). We will also learn how to adapt these algorithms
    to different types of problems, and how to run them on simulators and actual quantum
    computers.
  prefs: []
  type: TYPE_NORMAL
- en: But before we can do all that, we need a language in which we can state problems
    in a manner that makes it possible for a quantum computer to solve them. In this
    regard, with the **Quadratic Unconstrained Binary** **Optimization** (**QUBO**)
    framework, we can formulate many different optimization problems in a way that
    maps directly into the quantum setting, allowing us to use a plethora of quantum
    algorithms to try to find solutions that are optimal or, at least, close to optimal.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will introduce all the tools that we need to work with QUBO formulations.
    We will start by studying the **maximum cut** (or **Max-Cut**) problem in graphs,
    probably the simplest problem that can be formulated in the QUBO framework, and
    we will work our way up from there.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The Max-Cut problem and the Ising model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Enter quantum: formulating optimization problems the quantum way'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving from Ising to QUBO and back
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combinatorial optimization problems with the QUBO model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After reading this chapter, you will be ready to write your own optimization
    problems in a format that will allow you to solve them using quantum computers.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 The Max-Cut problem and the Ising model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order for us to understand how to use quantum computers to solve optimization
    problems, we need to get used to some abstractions and techniques that we will
    develop throughout this chapter. To get started, we will consider the problem
    of finding what we call **maximum cuts** in a mathematical structure called a
    **graph**. This is possibly the simplest problem that can be written in the formalism
    that we will be using in the following chapters. It will help us in gaining intuition
    and it will provide a solid foundation for formulating more complicated problems
    later on.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Graphs and cuts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you are given a graph, you are essentially given some *elements*, which
    we will refer to as **vertices**, and some *connections* between pairs of these
    vertices, which we will call **edges**. See *Figure* *[*3.1*](#Figure3.1) for
    an example of a graph with five vertices and six edges.*
  prefs: []
  type: TYPE_NORMAL
- en: '*![Figure 3.1: Example of a graph](img/file303.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 3.1**: Example of a graph'
  prefs: []
  type: TYPE_NORMAL
- en: Given a graph, the **Max-Cut problem** consists in finding a **maximum cut**
    of it. That is, we want to divide the vertices of the graph into two sets — that’s
    what we call **cutting** the graph into two parts — such that the number of edges
    with extremes in different sets of the cut is the maximum possible. We call the
    number of such edges the **size of the cut**, and we say that these edges are
    **cut**. You can imagine that, for instance, the vertices represent workers of
    a company, edges have been added between people who don’t get along that well,
    and you need to form two teams trying to minimize the number of conflicts by putting
    potential enemies in different teams.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure* *[*3.2*](#Figure3.2) presents two different cuts for the graph in
    *Figure* *[*3.1*](#Figure3.1), using different colors for vertices that go in
    different sets and using dashed lines for edges that have extremes in different
    parts of the cut. As you can see, the cut in *Figure* *[*3.2a*](#Figure3.2a) has
    size ![5](img/file296.png "5"), while the cut in *Figure* * [*3.2b*](#Figure3.2b)
    is of size ![4](img/file143.png "4"). In fact, it is easy to check that no cut
    of this graph can have a size bigger than ![5](img/file296.png "5") since vertices
    ![0,1](img/file304.png "0,1"), and ![2](img/file302.png "2") can’t all go in different
    sets and, hence, at least one of the edges ![(0,1)](img/file305.png "(0,1)"),
    ![(0,2)](img/file306.png "(0,2)"), or ![(1,2)](img/file307.png "(1,2)") will not
    be cut. The cut in *Figure* * [*3.2a*](#Figure3.2a) is, then, a **maximum** or
    **optimal** cut.*****'
  prefs: []
  type: TYPE_NORMAL
- en: '**![(a)](img/file308.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: '**(a)**'
  prefs: []
  type: TYPE_NORMAL
- en: '![(b)](img/file309.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**(b)**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 3.2**: Two different cuts of the same graph'
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.1
  prefs: []
  type: TYPE_NORMAL
- en: The maximum cut in a graph doesn’t need to be unique. Find a maximum cut for
    the graph in *Figure* *[*3.1*](#Figure3.1) in which vertices ![0](img/file12.png
    "0") and ![1](img/file13.png "1") are in the same set.*
  prefs: []
  type: TYPE_NORMAL
- en: '*So now we know what the Max-Cut problem is about. But how do we formulate
    it mathematically? We will learn exactly that in the next subsection.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Formulating the problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Surprisingly enough, we can formulate the Max-Cut problem as a combinatorial
    optimization problem with no reference whatsoever to graphs, edges, or vertices.
    In order to do that, we associate a variable ![z_{i}](img/file310.png "z_{i}")
    to each vertex ![i = 0,\ldots,n - 1](img/file311.png "i = 0,\ldots,n - 1") of
    the graph. Variables ![z_{i}](img/file310.png "z_{i}") will take value ![1](img/file13.png
    "1") or ![- 1](img/file312.png "- 1"). Each assignment of values to the variables
    determines a cut: vertices whose variables take value ![1](img/file13.png "1")
    will be in one set and vertices whose variables take value ![- 1](img/file312.png
    "- 1") will be in the other one. For instance, for the cut of *Figure* * [*3.2a*](#Figure3.2a)
    we could have ![z_{0} = z_{2} = z_{3} = 1](img/file313.png "z_{0} = z_{2} = z_{3}
    = 1") and ![z_{1} = z_{4} = - 1](img/file314.png "z_{1} = z_{4} = - 1"). Notice
    that, for our purposes, we could also represent that cut with the assignment ![z_{0}
    = z_{2} = z_{3} = - 1](img/file315.png "z_{0} = z_{2} = z_{3} = - 1"), ![z_{1}
    = z_{4} = 1](img/file316.png "z_{1} = z_{4} = 1").*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The key observation to formulate Max-Cut as a combinatorial optimization problem
    is to notice that, if there is an edge between two vertices ![j](img/file258.png
    "j") and ![k](img/file317.png "k"), then that edge is cut if and only if ![z_{j}z_{k}
    = - 1](img/file318.png "z_{j}z_{k} = - 1"). This is because if the two vertices
    are in the same set, then either ![z_{j} = z_{k} = 1](img/file319.png "z_{j} =
    z_{k} = 1") or ![z_{j} = z_{k} = - 1](img/file320.png "z_{j} = z_{k} = - 1") and,
    consequently, ![z_{j}z_{k} = 1](img/file321.png "z_{j}z_{k} = 1"). However, if
    they are in different sets, then either ![z_{j} = 1](img/file322.png "z_{j} =
    1") and ![z_{k} = - 1](img/file323.png "z_{k} = - 1"), or ![z_{j} = - 1](img/file324.png
    "z_{j} = - 1") and ![z_{k} = 1](img/file325.png "z_{k} = 1"), yielding ![z_{j}z_{k}
    = - 1](img/file318.png "z_{j}z_{k} = - 1").'
  prefs: []
  type: TYPE_NORMAL
- en: Thus, our problem can be written as
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize~}\quad} & {\sum\limits_{(j,k) \in E}z_{j}z_{k}\qquad}
    & & \qquad \\ {\text{subject~to~}\quad} & {z_{j} \in \{ - 1,1\},\qquad j = 0,\ldots,n
    - 1\qquad} & & \qquad \\ \end{array}](img/file326.png "\begin{array}{rlrl} {\text{Minimize~}\quad}
    & {\sum\limits_{(j,k) \in E}z_{j}z_{k}\qquad} & & \qquad \\ {\text{subject~to~}\quad}
    & {z_{j} \in \{ - 1,1\},\qquad j = 0,\ldots,n - 1\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: where ![E](img/file327.png "E") is the set of edges in the graph and the vertices
    are ![\{ 0,\ldots,n - 1\}](img/file328.png "\{ 0,\ldots,n - 1\}"). For instance,
    for the graph in *Figure* * [*3.1*](#Figure3.1), we would have the following formulation:*
  prefs: []
  type: TYPE_NORMAL
- en: '*![\begin{array}{rlrl} {\text{Minimize~}\quad} & {z_{0}z_{1} + z_{0}z_{2} +
    z_{1}z_{2} + z_{1}z_{3} + z_{2}z_{4} + z_{3}z_{4}\qquad} & & \qquad \\ {\text{subject~to~}\quad}
    & {z_{j} \in \{ - 1,1\},\qquad j = 0,\ldots,4.\qquad} & & \qquad \\ \end{array}](img/file329.png
    "\begin{array}{rlrl} {\text{Minimize~}\quad} & {z_{0}z_{1} + z_{0}z_{2} + z_{1}z_{2}
    + z_{1}z_{3} + z_{2}z_{4} + z_{3}z_{4}\qquad} & & \qquad \\ {\text{subject~to~}\quad}
    & {z_{j} \in \{ - 1,1\},\qquad j = 0,\ldots,4.\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the cut ![z_{0} = z_{2} = z_{3} = 1](img/file313.png "z_{0} = z_{2}
    = z_{3} = 1"), ![z_{1} = z_{4} = - 1](img/file314.png "z_{1} = z_{4} = - 1") (which
    is the one in *Figure* * [*3.2a*](#Figure3.2a)), attains a value of ![- 4](img/file330.png
    "- 4") in the function to be minimized, which is the minimum possible value for
    this particular case — but notice that it does not coincide with the number of
    edges that are cut! The cut ![z_{0} = z_{3} = - 1](img/file331.png "z_{0} = z_{3}
    = - 1"), ![z_{1} = z_{2} = z_{4} = 1](img/file332.png "z_{1} = z_{2} = z_{4} =
    1"), on the other hand, achieves a value of ![- 2](img/file333.png "- 2"), showing
    once again that the cut on *Figure* * [*3.2b*](#Figure3.2b) is not optimal.**
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 3.2'
  prefs: []
  type: TYPE_NORMAL
- en: Write the Max-Cut problem for the graph in *Figure* *[*3.3*](#Figure3.3) as
    an optimization problem. What is the value of the function to be minimized when
    ![z_{0} = z_{1} = z_{2} = 1](img/file334.png "z_{0} = z_{1} = z_{2} = 1") and
    ![z_{3} = z_{4} = z_{5} = - 1](img/file335.png "z_{3} = z_{4} = z_{5} = - 1").
    Is it an optimal cut?*
  prefs: []
  type: TYPE_NORMAL
- en: '*![Figure 3.3: Another example of a graph](img/file336.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 3.3**: Another example of a graph'
  prefs: []
  type: TYPE_NORMAL
- en: At first sight, solving the Max-Cut problem might seem easy enough. However,
    it is an **NP-hard** problem (refer to *Appendix* *[*C*](ch026.xhtml#x1-233000C),
    *Computational* *Complexity*, for more details on this kind of problem). That
    means that if we were able to solve it efficiently with a classical algorithm,
    we would have ![P = NP](img/file337.png "P = NP"), something the scientific community
    strongly believes not to be true. This would be the case even if we could find
    a classical algorithm that approximates the optimal cut within a factor of ![\left.
    16\slash 17 \right.](img/file338.png "\left. 16\slash 17 \right."), as was proved
    by Håstad in a paper published in 2001 [[50](ch030.xhtml#Xhastad01optimal)]. So,
    even if we resort to looking for precise enough approximations, the problem is
    indeed hard!*
  prefs: []
  type: TYPE_NORMAL
- en: '*To learn more…'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to learn more about ![P](img/file1.png "P"), ![NP](img/file2.png
    "NP"), and ![NP](img/file2.png "NP")-hard problems, please check *Appendix* *
    [*C*](ch026.xhtml#x1-233000C), *Computational Complexity*. We will be discussing
    the **ratio of approximation** that quantum algorithms can achieve for the Max-Cut
    problem in *Chapter* * [*5*](ch013.xhtml#x1-940005), *QAOA: Quantum* *Approximate
    Optimization Algorithm*.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**We are now able to formulate Max-Cut as a minimization problem in which the
    variables take values ![1](img/file13.png "1") and ![- 1](img/file312.png "- 1").
    Is this just accidental or are there more problems that can be written in a similar
    way? Keep on reading and you will learn the answer in the next subsection.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3 The Ising model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Max-Cut problem, as formulated in the previous pages, can be seen as just
    a particular case of a seemingly unrelated problem in statistical physics: finding
    the state of minimum **energy** of an instance of the **Ising model**. For the
    physics geeks out there, this is a mathematical model for the ferromagnetic interaction
    of particles with **spin**, usually arranged in a lattice (see *Figure* *[*3.4*](#Figure3.4)
    and refer to the book by Gallavotti [[42](ch030.xhtml#Xgallavotti1999statistical)]
    for more details). The particle spins are represented by variables ![z_{j}](img/file339.png
    "z_{j}") that can take values ![1](img/file13.png "1") (spin up) or ![- 1](img/file312.png
    "- 1") (spin down) — sounds familiar, doesn’t it?*'
  prefs: []
  type: TYPE_NORMAL
- en: '*![Figure 3.4: Example of the Ising model](img/file340.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 3.4**: Example of the Ising model'
  prefs: []
  type: TYPE_NORMAL
- en: The total energy of the system is given by a quantity called the **Hamiltonian**
    function (more about this later in this chapter) defined by
  prefs: []
  type: TYPE_NORMAL
- en: '![- \sum\limits_{j,k}J_{jk}z_{j}z_{k} - \sum\limits_{j}h_{j}z_{j}](img/file341.png
    "- \sum\limits_{j,k}J_{jk}z_{j}z_{k} - \sum\limits_{j}h_{j}z_{j}")'
  prefs: []
  type: TYPE_IMG
- en: where the coefficients ![J_{jk}](img/file342.png "J_{jk}") represent the interaction
    between particles ![j](img/file258.png "j") and ![k](img/file317.png "k") (usually,
    only non-zero for adjacent particles) and the coefficients ![h_{j}](img/file343.png
    "h_{j}") represent the influence of an external magnetic field on particle ![j](img/file258.png
    "j").
  prefs: []
  type: TYPE_NORMAL
- en: Finding the state of minimum energy of the system consists in obtaining a spin
    configuration for which the Hamiltonian function attains its minimum value. As
    you can easily check yourself, when all the ![J_{jk}](img/file342.png "J_{jk}")
    coefficients are ![- 1](img/file312.png "- 1") and all the ![h_{j}](img/file343.png
    "h_{j}") coefficients are ![0](img/file12.png "0"), the problem is exactly the
    same as getting the maximum cut in a graph — although in a completely different
    context! Of course, this makes the problem of finding the state of minimum energy
    of a given Ising model an ![NP](img/file2.png "NP")-hard problem.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: The quantum annealers that we will be using in *Chapter* *[*4*](ch012.xhtml#x1-750004),
    *Quantum Adiabatic Computing and Quantum Annealing*, are quantum computers constructed
    with the specific purpose of sampling from states of low energy of systems whose
    behavior can be described with the Ising model. We will use this property to try
    to approximate solutions to Max-Cut and many other related problems.*
  prefs: []
  type: TYPE_NORMAL
- en: '*Let’s give an example of the problem of finding the minimum energy state of
    an Ising model. Imagine that we have particles arranged as in *Figure* *[*3.4*](#Figure3.4),
    where the numbers on the edges represent the coefficients ![J_{jk}](img/file342.png
    "J_{jk}") and we assume that the external magnetic field is homogeneous and that
    all coefficients ![h_{j}](img/file343.png "h_{j}") are equal to ![1](img/file13.png
    "1"). Then, the problem can be formulated as follows:*'
  prefs: []
  type: TYPE_NORMAL
- en: '*![\begin{array}{rlrl} {\text{Minimize~}\quad} & {z_{0}z_{1} - 2z_{1}z_{2}
    + z_{2}z_{3} - 3z_{0}z_{4} + z_{1}z_{5} + z_{2}z_{6} - 3z_{3}z_{7}\qquad} & &
    \qquad \\ & {+ z_{4}z_{5} - 2z_{5}z_{6} + z_{6}z_{7} - 3z_{4}z_{8} + z_{5}z_{9}
    + z_{6}z_{10} - 3z_{7}z_{11}\qquad} & & \qquad \\ & {+ z_{8}z_{9} - 2z_{9}z_{10}
    + z_{10}z_{11} - z_{0} - z_{1} - z_{2} - z_{3} - z_{4} - z_{5}\qquad} & & \qquad
    \\ & {- z_{6} - z_{7} - z_{8} - z_{9} - z_{10} - z_{11}\qquad} & & \qquad \\ {\text{subject~to~}\quad}
    & {z_{j} \in \{ - 1,1\},\qquad j = 0,\ldots,11.\qquad} & & \qquad \\ \end{array}](img/file344.png
    "\begin{array}{rlrl} {\text{Minimize~}\quad} & {z_{0}z_{1} - 2z_{1}z_{2} + z_{2}z_{3}
    - 3z_{0}z_{4} + z_{1}z_{5} + z_{2}z_{6} - 3z_{3}z_{7}\qquad} & & \qquad \\  &
    {+ z_{4}z_{5} - 2z_{5}z_{6} + z_{6}z_{7} - 3z_{4}z_{8} + z_{5}z_{9} + z_{6}z_{10}
    - 3z_{7}z_{11}\qquad} & & \qquad \\  & {+ z_{8}z_{9} - 2z_{9}z_{10} + z_{10}z_{11}
    - z_{0} - z_{1} - z_{2} - z_{3} - z_{4} - z_{5}\qquad} & & \qquad \\  & {- z_{6}
    - z_{7} - z_{8} - z_{9} - z_{10} - z_{11}\qquad} & & \qquad \\ {\text{subject~to~}\quad}
    & {z_{j} \in \{ - 1,1\},\qquad j = 0,\ldots,11.\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_NORMAL
- en: This seems a little more involved than the formulations of the Max-Cut problem
    that we have seen so far, but it clearly follows the same pattern. However, you
    could be wondering what all this has to with quantum computing, since all these
    formulas only involve classical variables. Fair point! It is now time to use our
    knowledge of qubits and quantum gates to try to see all these problems under a
    different, quantum light.
  prefs: []
  type: TYPE_NORMAL
- en: '3.2 Enter quantum: formulating optimization problems the quantum way'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will unveil how all the work that we have done so far in
    this chapter has followed a secret plan! Was the choice of ![z](img/file81.png
    "z") as the name for the variables in our problems completely arbitrary? Of course
    not! If it made you think of those lovely ![Z](img/file8.png "Z") quantum gates
    and matrices that we introduced back in *Chapter* * [*1*](ch008.xhtml#x1-180001),
    *Foundations* *of Quantum Computing*, you were on the right track. It will be
    the key to introducing the *quantum factor* into our problems, as we will begin
    to see in the next subsection.*
  prefs: []
  type: TYPE_NORMAL
- en: '*## 3.2.1 From classical variables to qubits'
  prefs: []
  type: TYPE_NORMAL
- en: So far, the formulations that we have considered for the Max-Cut problem and
    for the Ising model are purely classical. They do not mention quantum elements
    such as qubits, quantum gates, or measurements. But we are closer than you might
    think to being able to give a quantum formulation for these problems. We will
    start with a very simple instance of the Max-Cut problem and show how we can easily
    transform it into *quantum form*. Consider the graph in *Figure* *[*3.5*](#Figure3.5).
    We already know that the corresponding Max-Cut problem can be written as follows:*
  prefs: []
  type: TYPE_NORMAL
- en: '*![\begin{array}{rlrl} {\text{Minimize~}\quad} & {z_{0}z_{1} + z_{0}z_{2}\qquad}
    & & \qquad \\ {\text{subject~to~}\quad} & {z_{j} \in \{ - 1,1\},\qquad j = 0,1,2.\qquad}
    & & \qquad \\ \end{array}](img/file345.png "\begin{array}{rlrl} {\text{Minimize~}\quad}
    & {z_{0}z_{1} + z_{0}z_{2}\qquad} & & \qquad \\ {\text{subject~to~}\quad} & {z_{j}
    \in \{ - 1,1\},\qquad j = 0,1,2.\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5: A very simple Max-Cut problem](img/file346.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 3.5**: A very simple Max-Cut problem'
  prefs: []
  type: TYPE_NORMAL
- en: The crucial observation that we need to make in order to transform this formulation
    into a quantum one is that our beloved ![Z](img/file8.png "Z") matrix can be used
    to evaluate the different terms in the function that we need to minimize. Namely,
    it is easy to check that
  prefs: []
  type: TYPE_NORMAL
- en: '![\left\langle 0 \right|Z\left| 0 \right\rangle = \begin{pmatrix} 1 & 0 \\
    \end{pmatrix}\begin{pmatrix} 1 & 0 \\ 0 & {- 1} \\ \end{pmatrix}\begin{pmatrix}
    1 \\ 0 \\ \end{pmatrix} = 1,\qquad\left\langle 1 \right|Z\left| 1 \right\rangle
    = \begin{pmatrix} 0 & 1 \\ \end{pmatrix}\begin{pmatrix} 1 & 0 \\ 0 & {- 1} \\
    \end{pmatrix}\begin{pmatrix} 0 \\ 1 \\ \end{pmatrix} = - 1.](img/file347.png "\left\langle
    0 \right|Z\left| 0 \right\rangle = \begin{pmatrix} 1 & 0 \\ \end{pmatrix}\begin{pmatrix}
    1 & 0 \\ 0 & {- 1} \\ \end{pmatrix}\begin{pmatrix} 1 \\ 0 \\ \end{pmatrix} = 1,\qquad\left\langle
    1 \right|Z\left| 1 \right\rangle = \begin{pmatrix} 0 & 1 \\ \end{pmatrix}\begin{pmatrix}
    1 & 0 \\ 0 & {- 1} \\ \end{pmatrix}\begin{pmatrix} 0 \\ 1 \\ \end{pmatrix} = -
    1.")'
  prefs: []
  type: TYPE_IMG
- en: Now, consider the tensor product ![Z \otimes Z \otimes I](img/file348.png "Z
    \otimes Z \otimes I") and basis state ![\left| {010} \right\rangle](img/file251.png
    "\left| {010} \right\rangle"). We know from *Section* * [*1.5.1*](ch008.xhtml#x1-360001.5.1)
    that*
  prefs: []
  type: TYPE_NORMAL
- en: '*![\begin{array}{rlrl} {\left\langle {010} \right|Z \otimes Z \otimes I\left|
    {010} \right\rangle} & {= \left\langle {010} \right|\left( {Z\left| 0 \right\rangle
    \otimes Z\left| 1 \right\rangle \otimes I\left| 0 \right\rangle} \right)\qquad}
    & & \qquad \\ & {= \left\langle 0 \right|Z\left| 0 \right\rangle\left\langle 1
    \right|Z\left| 1 \right\rangle\left\langle 0 \right|I\left| 0 \right\rangle =
    1 \cdot ( - 1) \cdot 1 = - 1.\qquad} & & \qquad \\ \end{array}](img/file349.png
    "\begin{array}{rlrl} {\left\langle {010} \right|Z \otimes Z \otimes I\left| {010}
    \right\rangle} & {= \left\langle {010} \right|\left( {Z\left| 0 \right\rangle
    \otimes Z\left| 1 \right\rangle \otimes I\left| 0 \right\rangle} \right)\qquad}
    & & \qquad \\  & {= \left\langle 0 \right|Z\left| 0 \right\rangle\left\langle
    1 \right|Z\left| 1 \right\rangle\left\langle 0 \right|I\left| 0 \right\rangle
    = 1 \cdot ( - 1) \cdot 1 = - 1.\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_NORMAL
- en: We interpret ![\left| {010} \right\rangle](img/file251.png "\left| {010} \right\rangle")
    as representing a cut in which vertices ![0](img/file12.png "0") and ![2](img/file302.png
    "2") are assigned to one set (because the value of qubits ![0](img/file12.png
    "0") and ![2](img/file302.png "2") in ![\left| {010} \right\rangle](img/file251.png
    "\left| {010} \right\rangle") is ![0](img/file12.png "0")) and vertex ![1](img/file13.png
    "1") is assigned to the other (because qubit ![1](img/file13.png "1") has value
    ![1](img/file13.png "1") in ![\left| {010} \right\rangle](img/file251.png "\left|
    {010} \right\rangle")). Then, the fact that the product ![\left\langle {010} \right|Z
    \otimes Z \otimes I\left| {010} \right\rangle](img/file350.png "\left\langle {010}
    \right|Z \otimes Z \otimes I\left| {010} \right\rangle") evaluates to ![- 1](img/file312.png
    "- 1") means that edge ![(0,1)](img/file305.png "(0,1)") has extremes in different
    sets of the cut; that is because we have used ![Z \otimes Z \otimes I](img/file348.png
    "Z \otimes Z \otimes I"), having ![Z](img/file8.png "Z") operators acting on qubits
    ![0](img/file12.png "0") and ![1](img/file13.png "1"). This behavior is analogous
    to the one that we had with term ![z_{0}z_{1}](img/file351.png "z_{0}z_{1}") in
    the function to minimize our classical formulation of the problem.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, ![Z \otimes Z \otimes I](img/file348.png "Z \otimes Z \otimes I") is
    usually denoted by just ![Z_{0}Z_{1}](img/file352.png "Z_{0}Z_{1}") (the subindices
    indicate the positions of each ![Z](img/file8.png "Z") gate; the other positions
    are assumed to be the identity) and, following this convention, we would have,
    for instance,
  prefs: []
  type: TYPE_NORMAL
- en: '![\left\langle {010} \right|Z_{0}Z_{2}\left| {010} \right\rangle = \left\langle
    0 \right|Z\left| 0 \right\rangle\left\langle 1 \right|I\left| 1 \right\rangle\left\langle
    0 \right|Z\left| 0 \right\rangle = 1 \cdot 1 \cdot 1 = 1](img/file353.png "\left\langle
    {010} \right|Z_{0}Z_{2}\left| {010} \right\rangle = \left\langle 0 \right|Z\left|
    0 \right\rangle\left\langle 1 \right|I\left| 1 \right\rangle\left\langle 0 \right|Z\left|
    0 \right\rangle = 1 \cdot 1 \cdot 1 = 1")'
  prefs: []
  type: TYPE_IMG
- en: because the edge ![(0,2)](img/file306.png "(0,2)") is not cut with this particular
    assignment.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this is analogous for any basis state ![\left| x \right\rangle](img/file267.png
    "\left| x \right\rangle") with ![x \in \{ 000,001,\ldots,111\}](img/file354.png
    "x \in \{ 000,001,\ldots,111\}"), so ![\left\langle x \right|Z_{j}Z_{k}\left|
    x \right\rangle](img/file355.png "\left\langle x \right|Z_{j}Z_{k}\left| x \right\rangle")
    will be ![- 1](img/file312.png "- 1") if the edge ![(j,k)](img/file356.png "(j,k)")
    is cut under an assignment ![x](img/file269.png "x") and it will be ![1](img/file13.png
    "1") otherwise. We only need to notice that if ![j](img/file258.png "j") and ![k](img/file317.png
    "k") are in different parts of the cut, then their qubits will have different
    values and the product will be ![- 1](img/file312.png "- 1").
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, by linearity it holds that
  prefs: []
  type: TYPE_NORMAL
- en: '![\left\langle x \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x \right\rangle
    = \left\langle x \right|Z_{0}Z_{1}\left| x \right\rangle + \left\langle x \right|Z_{0}Z_{2}\left|
    x \right\rangle.](img/file357.png "\left\langle x \right|\left( {Z_{0}Z_{1} +
    Z_{0}Z_{2}} \right)\left| x \right\rangle = \left\langle x \right|Z_{0}Z_{1}\left|
    x \right\rangle + \left\langle x \right|Z_{0}Z_{2}\left| x \right\rangle.")'
  prefs: []
  type: TYPE_IMG
- en: Thus, we can rewrite our problem as finding a basis state ![\left| x \right\rangle](img/file267.png
    "\left| x \right\rangle") for which ![\left\langle x \right|\left( {Z_{0}Z_{1}
    + Z_{0}Z_{2}} \right)\left| x \right\rangle](img/file358.png "\left\langle x \right|\left(
    {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x \right\rangle") attains a minimum.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.3
  prefs: []
  type: TYPE_NORMAL
- en: Compute ![\left\langle {010} \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left|
    {010} \right\rangle](img/file359.png "\left\langle {010} \right|\left( {Z_{0}Z_{1}
    + Z_{0}Z_{2}} \right)\left| {010} \right\rangle") and ![\left\langle {100} \right|\left(
    {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| {100} \right\rangle](img/file360.png "\left\langle
    {100} \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| {100} \right\rangle").
    Does any of those states minimize ![\left\langle x \right|\left( {Z_{0}Z_{1} +
    Z_{0}Z_{2}} \right)\left| x \right\rangle](img/file358.png "\left\langle x \right|\left(
    {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x \right\rangle")?
  prefs: []
  type: TYPE_NORMAL
- en: But that is not the end of the story. For any basis state ![\left| x \right\rangle](img/file267.png
    "\left| x \right\rangle"), it holds that either ![Z_{j}Z_{k}\left| x \right\rangle
    = \left| x \right\rangle](img/file361.png "Z_{j}Z_{k}\left| x \right\rangle =
    \left| x \right\rangle") or ![Z_{j}Z_{k}\left| x \right\rangle = - \left| x \right\rangle](img/file362.png
    "Z_{j}Z_{k}\left| x \right\rangle = - \left| x \right\rangle"), as you can easily
    check. Notice that this proves that each ![\left| x \right\rangle](img/file267.png
    "\left| x \right\rangle") is an **eigenvector** of ![Z_{j}Z_{k}](img/file363.png
    "Z_{j}Z_{k}") with **eigenvalue** either ![1](img/file13.png "1") or ![- 1](img/file312.png
    "- 1") (refer to *Appendix* * [*B*](ch025.xhtml#x1-226000B), *Basic Linear Algebra*,
    for more information about eigenvectors and eigenvalues). Thus, for ![x \neq y](img/file364.png
    "x \neq y") we will have*
  prefs: []
  type: TYPE_NORMAL
- en: '*![\left\langle y \right|Z_{j}Z_{k}\left| x \right\rangle = \pm \left\langle
    y \middle| x \right\rangle = 0,](img/file365.png "\left\langle y \right|Z_{j}Z_{k}\left|
    x \right\rangle = \pm \left\langle y \middle| x \right\rangle = 0,")'
  prefs: []
  type: TYPE_NORMAL
- en: because ![\left\langle y \middle| x \right\rangle = 0](img/file366.png "\left\langle
    y \middle| x \right\rangle = 0") whenever ![x \neq y](img/file364.png "x \neq
    y"), as we proved in *Section* * [*1.5.1*](ch008.xhtml#x1-360001.5.1).*
  prefs: []
  type: TYPE_NORMAL
- en: '*Consequently, since a general state ![\left| \psi \right\rangle](img/file43.png
    "\left| \psi \right\rangle") can always be written as ![\left| \psi \right\rangle
    = {\sum}_{x}a_{x}\left| x \right\rangle](img/file367.png "\left| \psi \right\rangle
    = {\sum}_{x}a_{x}\left| x \right\rangle"), it follows by linearity that'
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\left\langle \psi \right|Z_{j}Z_{k}\left| \psi \right\rangle}
    & {= \left( {\sum\limits_{y}a_{y}^{\ast}\left\langle y \right|} \right)Z_{j}Z_{k}\left(
    {\sum\limits_{x}a_{x}\left| x \right\rangle} \right) = \sum\limits_{y}\sum\limits_{x}a_{y}^{\ast}a_{x}\left\langle
    y \right|Z_{j}Z_{k}\left| x \right\rangle\qquad} & & \qquad \\ & {= \sum\limits_{x}\left|
    a_{x} \right|^{2}\left\langle x \right|Z_{j}Z_{k}\left| x \right\rangle,\qquad}
    & & \qquad \\ \end{array}](img/file368.png "\begin{array}{rlrl} {\left\langle
    \psi \right|Z_{j}Z_{k}\left| \psi \right\rangle} & {= \left( {\sum\limits_{y}a_{y}^{\ast}\left\langle
    y \right|} \right)Z_{j}Z_{k}\left( {\sum\limits_{x}a_{x}\left| x \right\rangle}
    \right) = \sum\limits_{y}\sum\limits_{x}a_{y}^{\ast}a_{x}\left\langle y \right|Z_{j}Z_{k}\left|
    x \right\rangle\qquad} & & \qquad \\  & {= \sum\limits_{x}\left| a_{x} \right|^{2}\left\langle
    x \right|Z_{j}Z_{k}\left| x \right\rangle,\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: where we have used ![a_{x}^{\ast}a_{x} = \left| a_{x} \right|^{2}](img/file369.png
    "a_{x}^{\ast}a_{x} = \left| a_{x} \right|^{2}").
  prefs: []
  type: TYPE_NORMAL
- en: Hence, again by linearity, it is true that
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\left\langle \psi \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}}
    \right)\left| \psi \right\rangle} & {= \left\langle \psi \right|Z_{0}Z_{1}\left|
    \psi \right\rangle + \left\langle \psi \right|Z_{0}Z_{2}\left| \psi \right\rangle\qquad}
    & & \qquad \\ & {= \sum\limits_{x}\left| a_{x} \right|^{2}\left\langle x \right|Z_{0}Z_{1}\left|
    x \right\rangle + \sum\limits_{x}\left| a_{x} \right|^{2}\left\langle x \right|Z_{0}Z_{2}\left|
    x \right\rangle\qquad} & & \qquad \\ & {= \sum\limits_{x}\left| a_{x} \right|^{2}\left\langle
    x \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x \right\rangle.\qquad}
    & & \qquad \\ \end{array}](img/file370.png "\begin{array}{rlrl} {\left\langle
    \psi \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| \psi \right\rangle}
    & {= \left\langle \psi \right|Z_{0}Z_{1}\left| \psi \right\rangle + \left\langle
    \psi \right|Z_{0}Z_{2}\left| \psi \right\rangle\qquad} & & \qquad \\  & {= \sum\limits_{x}\left|
    a_{x} \right|^{2}\left\langle x \right|Z_{0}Z_{1}\left| x \right\rangle + \sum\limits_{x}\left|
    a_{x} \right|^{2}\left\langle x \right|Z_{0}Z_{2}\left| x \right\rangle\qquad}
    & & \qquad \\  & {= \sum\limits_{x}\left| a_{x} \right|^{2}\left\langle x \right|\left(
    {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x \right\rangle.\qquad} & & \qquad \\
    \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: We know that ![{\sum}_{x}\left| a_{x} \right|^{2} = 1](img/file371.png "{\sum}_{x}\left|
    a_{x} \right|^{2} = 1") and that every ![\left| a_{x} \right|^{2}](img/file372.png
    "\left| a_{x} \right|^{2}") is non-negative, so it holds that
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\sum\limits_{x}\left| a_{x} \right|^{2}\left\langle
    x \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x \right\rangle} & {\geq
    \sum\limits_{x}\left| a_{x} \right|^{2}\left\langle x_{\min} \right|\left( {Z_{0}Z_{1}
    + Z_{0}Z_{2}} \right)\left| x_{\min} \right\rangle\qquad} & & \qquad \\ & {= \left\langle
    x_{\min} \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x_{\min} \right\rangle\sum\limits_{x}\left|
    a_{x} \right|^{2}\qquad} & & \qquad \\ & {= \left\langle x_{\min} \right|\left(
    {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x_{\min} \right\rangle,\qquad} & & \qquad
    \\ \end{array}](img/file373.png "\begin{array}{rlrl} {\sum\limits_{x}\left| a_{x}
    \right|^{2}\left\langle x \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left|
    x \right\rangle} & {\geq \sum\limits_{x}\left| a_{x} \right|^{2}\left\langle x_{\min}
    \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x_{\min} \right\rangle\qquad}
    & & \qquad \\  & {= \left\langle x_{\min} \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}}
    \right)\left| x_{\min} \right\rangle\sum\limits_{x}\left| a_{x} \right|^{2}\qquad}
    & & \qquad \\  & {= \left\langle x_{\min} \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}}
    \right)\left| x_{\min} \right\rangle,\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: where ![\left| x_{\min} \right\rangle](img/file374.png "\left| x_{\min} \right\rangle")
    is a basis state (there could be more than one) for which ![\left\langle x \right|\left(
    {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x \right\rangle](img/file358.png "\left\langle
    x \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| x \right\rangle") is minimum
    and, hence, ![x_{\min}](img/file375.png "x_{\min}") represents a maximum cut.
  prefs: []
  type: TYPE_NORMAL
- en: This may all seem a little bit too abstract. But what we have proved is simply
    that the minimum over all possible quantum states is always reached on one of
    the basis states — which are the only ones that we can directly interpret as representing
    cuts. Then, we can rewrite the problem of finding a maximum cut for the graph
    of *Figure* *[*3.5*](#Figure3.5) as follows:*
  prefs: []
  type: TYPE_NORMAL
- en: '*![\begin{array}{rlrl} & {\text{Minimize~}\quad\left\langle \psi \right|\left(
    {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| \psi \right\rangle = \left\langle \psi
    \right|Z_{0}Z_{1}\left| \psi \right\rangle + \left\langle \psi \right|Z_{0}Z_{2}\left|
    \psi \right\rangle,\qquad} & & \qquad \\ & {{\text{where~}\left| \psi \right\rangle\text{~is~taken~from~the~set~of~quantum~states~on~}3\text{~qubits.}}\qquad}
    & & \qquad \\ \end{array}](img/file376.png "\begin{array}{rlrl}  & {\text{Minimize~}\quad\left\langle
    \psi \right|\left( {Z_{0}Z_{1} + Z_{0}Z_{2}} \right)\left| \psi \right\rangle
    = \left\langle \psi \right|Z_{0}Z_{1}\left| \psi \right\rangle + \left\langle
    \psi \right|Z_{0}Z_{2}\left| \psi \right\rangle,\qquad} & & \qquad \\  & {{\text{where~}\left|
    \psi \right\rangle\text{~is~taken~from~the~set~of~quantum~states~on~}3\text{~qubits.}}\qquad}
    & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_NORMAL
- en: Notice the change that we have introduced. In our previous formulation, we were
    only minimizing over basis states, but now that we know that the minimum over
    all possible states is reached on a basis state, we are minimizing over all possible
    quantum states. This will make our life easier in future chapters when we introduce
    quantum algorithms to solve this kind of problem, because we will be justified
    in using any quantum state instead of just constraining ourselves to those that
    come from the basis.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Although the minimum energy is always achieved on one basis state, it could
    also be the case that it is also achieved on a non-basis state. In fact, if two
    different basis states ![\left| x \right\rangle](img/file267.png "\left| x \right\rangle")
    and ![\left| y \right\rangle](img/file268.png "\left| y \right\rangle") achieve
    the minimum energy, then any superposition ![a\left| x \right\rangle + b\left|
    y \right\rangle](img/file377.png "a\left| x \right\rangle + b\left| y \right\rangle")
    is of minimum energy as well. That is the case, for example, for ![Z_{0}Z_{1}](img/file352.png
    "Z_{0}Z_{1}") for which both ![\left| {01} \right\rangle](img/file199.png "\left|
    {01} \right\rangle") and ![\left| {10} \right\rangle](img/file200.png "\left|
    {10} \right\rangle") have energy ![- 1](img/file312.png "- 1"). Then, any superposition
    ![a\left| {01} \right\rangle + b\left| {10} \right\rangle](img/file378.png "a\left|
    {01} \right\rangle + b\left| {10} \right\rangle") also achieves energy ![- 1](img/file312.png
    "- 1"), which is the minimum possible for ![Z_{0}Z_{1}](img/file352.png "Z_{0}Z_{1}").
  prefs: []
  type: TYPE_NORMAL
- en: 'It can be easily checked that our preceding argument holds for any number of
    qubits and any sum of tensor products ![Z_{j}Z_{k}](img/file363.png "Z_{j}Z_{k}"),
    so if we have a graph with set of vertices ![V](img/file379.png "V"), of size
    ![n](img/file244.png "n"), and set of edges ![E](img/file327.png "E"), we can
    rewrite the Max-Cut problem for the graph as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} & {\text{Minimize~}\quad\sum\limits_{(j,k) \in E}\left\langle
    \psi \right|Z_{j}Z_{k}\left| \psi \right\rangle,\qquad} & & \qquad \\ & {{\text{where~}\left|
    \psi \right\rangle\text{~is~taken~from~the~set~of~quantum~states~on~}n\text{~qubits.}}\qquad}
    & & \qquad \\ \end{array}](img/file380.png "\begin{array}{rlrl}  & {\text{Minimize~}\quad\sum\limits_{(j,k)
    \in E}\left\langle \psi \right|Z_{j}Z_{k}\left| \psi \right\rangle,\qquad} & &
    \qquad \\  & {{\text{where~}\left| \psi \right\rangle\text{~is~taken~from~the~set~of~quantum~states~on~}n\text{~qubits.}}\qquad}
    & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a step back and examine what we have proved. First, notice that matrices
    such as
  prefs: []
  type: TYPE_NORMAL
- en: '![\sum\limits_{(j,k) \in E}Z_{j}Z_{k}](img/file381.png "\sum\limits_{(j,k)
    \in E}Z_{j}Z_{k}")'
  prefs: []
  type: TYPE_IMG
- en: are **Hermitian** or **self-adjoint**. This means that they are equal to their
    conjugate transposes, as you can easily verify, and they have particular properties
    such as having real eigenvalues and being able to form an orthonormal basis with
    their eigenvectors (refer to *Appendix* *[*B*](ch025.xhtml#x1-226000B), *Basic
    Linear Algebra*, for more details). In our case, we have proved that the computational
    basis *is* such an orthonormal basis of eigenvectors. Furthermore, the quantity*
  prefs: []
  type: TYPE_NORMAL
- en: '*![\left\langle \psi \right|\left( {\sum\limits_{(j,k) \in E}Z_{j}Z_{k}} \right)\left|
    \psi \right\rangle = \sum\limits_{(j,k) \in E}\left\langle \psi \right|Z_{j}Z_{k}\left|
    \psi \right\rangle,](img/file382.png "\left\langle \psi \right|\left( {\sum\limits_{(j,k)
    \in E}Z_{j}Z_{k}} \right)\left| \psi \right\rangle = \sum\limits_{(j,k) \in E}\left\langle
    \psi \right|Z_{j}Z_{k}\left| \psi \right\rangle,")'
  prefs: []
  type: TYPE_NORMAL
- en: which is usually called the **expectation value** of ![{\sum}_{(j,k) \in E}Z_{j}Z_{k}](img/file383.png
    "{\sum}_{(j,k) \in E}Z_{j}Z_{k}"), attains its minimum value on one of those eigenvectors,
    called the **ground state**.
  prefs: []
  type: TYPE_NORMAL
- en: 'This result is known as the **variational principle**, and we will revisit
    it in a more general form in *Chapter* *[*7*](ch015.xhtml#x1-1190007), *VQE: Variational*
    *Quantum Eigensolver*.**  **For the Ising model, the situation is exactly the
    same. We can go through an analogous reasoning, only this time also involving
    terms of the form ![Z_{j}](img/file384.png "Z_{j}"). Each ![Z_{j}](img/file384.png
    "Z_{j}") is a tensor product with all the factors equal to the identity matrix
    except for the one in the ![j](img/file258.png "j")-th position, which is ![Z](img/file8.png
    "Z"). Then, finding the state of minimum energy of an Ising model with ![n](img/file244.png
    "n") particles and coefficients ![J_{jk}](img/file342.png "J_{jk}") and ![h_{j}](img/file343.png
    "h_{j}") is equivalent to the following problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} & {\text{Minimize~}\qquad - \sum\limits_{(j,k) \in E}J_{jk}\left\langle
    \psi \right|Z_{j}Z_{k}\left| \psi \right\rangle - \sum\limits_{j}h_{j}\left\langle
    \psi \right|Z_{j}\left| \psi \right\rangle,\qquad} & & \qquad \\ & {{\text{where~}\left|
    \psi \right\rangle\text{~is~taken~from~the~set~of~quantum~states~on~}n\text{~qubits.}}\qquad}
    & & \qquad \\ \end{array}](img/file385.png "\begin{array}{rlrl}  & {\text{Minimize~}\qquad
    - \sum\limits_{(j,k) \in E}J_{jk}\left\langle \psi \right|Z_{j}Z_{k}\left| \psi
    \right\rangle - \sum\limits_{j}h_{j}\left\langle \psi \right|Z_{j}\left| \psi
    \right\rangle,\qquad} & & \qquad \\  & {{\text{where~}\left| \psi \right\rangle\text{~is~taken~from~the~set~of~quantum~states~on~}n\text{~qubits.}}\qquad}
    & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: So, we have been able to cast several combinatorial optimization problems into
    a *quantum form*. More concretely, we have rewritten our problems as instances
    of finding the ground state of a self-adjoint matrix called the **Hamiltonian**
    of the system. Notice, however, that we do not really need to obtain the exact
    ground state. If we can prepare a state ![\left| \psi \right\rangle](img/file43.png
    "\left| \psi \right\rangle") such that the amplitude ![a_{x_{\min}} = \left\langle
    x_{\min} \middle| \psi \right\rangle](img/file386.png "a_{x_{\min}} = \left\langle
    x_{\min} \middle| \psi \right\rangle") is big in absolute value, then we will
    have a high probability of finding ![x_{\min}](img/file375.png "x_{\min}") when
    we measure ![\left| \psi \right\rangle](img/file43.png "\left| \psi \right\rangle").
    This approach will be behind the algorithms that we will introduce in *Chapters*
    * [*4*](ch012.xhtml#x1-750004) through * [*7*](ch015.xhtml#x1-1190007).**
  prefs: []
  type: TYPE_NORMAL
- en: '**In the following sections, we will see that the possibility of rewriting
    combinatorial optimization problems as instances of ground state problems is not
    just a happy coincidence, but rather the norm, and we will show how to write many
    other important problems in this form. But, before we turn to that, let us write
    some code to work with those tensor products of ![Z](img/file8.png "Z") matrices
    and to compute their expectation values.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 Computing expectation values with Qiskit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In *Chapter* *[*2*](ch009.xhtml#x1-400002), *The Tools of the Trade in Quantum
    Computing*, we introduced the main ways in which Qiskit can be used to work with
    quantum circuits and to execute them on simulators and real quantum computers.
    But Qiskit also allows us to work with quantum states and Hamiltonians, combining
    them with tensor products and computing their expectation values, something that
    can be useful when dealing with optimization problems, as we have just seen. Learning
    how to perform these computations will help make the concepts that we have introduced
    more concrete. Moreover, in *Chapter* *[*5*](ch013.xhtml#x1-940005), *QAOA: Quantum*
    *Approximate Optimization Algorithm*, we will be working extensively with Hamiltonians
    in Qiskit, so we will need to know how to initialize and manipulate them.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Let’s start by showing, for example, how to define in Qiskit a basis state
    of three qubits such as ![\left| {100} \right\rangle](img/file387.png "\left|
    {100} \right\rangle"). We can do this in several different ways. For instance,
    we can first define one-qubit states ![\left| 0 \right\rangle](img/file6.png "\left|
    0 \right\rangle") and ![\left| 1 \right\rangle](img/file14.png "\left| 1 \right\rangle")
    and compute their tensor products. There are several possible approaches to achieve
    this. The first one is to directly use the amplitudes to initialize a `Statevector`
    object. To do that, we need to import the class and then call its constructor
    with input `[1,0]` (the amplitudes of ![\left| 0 \right\rangle](img/file6.png
    "\left| 0 \right\rangle")) as shown in the following fragment of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The output that you will get if you run this code is
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: which shows that, indeed, we have created a quantum state and set it to ![\left|
    0 \right\rangle](img/file6.png "\left| 0 \right\rangle"). Of course, to initialize
    a quantum state to ![\left| 1 \right\rangle](img/file14.png "\left| 1 \right\rangle"),
    we can run
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'obtaining this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: An alternative, probably more convenient way of achieving the same result is
    to initialize the `Statevector` object from an integer such as `0` or `1`. We
    will use the `from_int` method and it is important to also use the `dims` parameter
    to indicate the size of the statevector. Otherwise, `0` could be interpreted to
    be ![\left| 0 \right\rangle](img/file6.png "\left| 0 \right\rangle") or ![\left|
    {00} \right\rangle](img/file198.png "\left| {00} \right\rangle") or ![\left| {000}
    \right\rangle](img/file388.png "\left| {000} \right\rangle") or... (as we mentioned
    in *Section* * [*1.4.1*](ch008.xhtml#x1-280001.4.1)). In our case, we set `dims`
    `=` `2`, but in general, we will have to set `dims` to ![2^{n}](img/file256.png
    "2^{n}"), where ![n](img/file244.png "n") is the number of qubits, because that
    is the number of amplitudes on an ![n](img/file244.png "n")-qubit system. Then,
    we can run*
  prefs: []
  type: TYPE_NORMAL
- en: '*[PRE4]'
  prefs: []
  type: TYPE_NORMAL
- en: 'which results in the following output, as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In either case, we can now construct states with a higher number of qubits
    by computing tensor products with the `tensor` method, as shown in the following
    lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'After running them, we will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the amplitude whose value is ![1](img/file13.png "1") is in the
    fifth position. It corresponds to ![\left| {100} \right\rangle](img/file387.png
    "\left| {100} \right\rangle"), because, in binary, ![100](img/file389.png "100")
    is ![4](img/file143.png "4") and we start counting on ![0](img/file12.png "0").
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can imagine, both the way in which we compute the tensor product and
    the representation as an amplitude vector can become difficult to parse when we
    are working with many qubits. The following lines show a more concise way of using
    tensor products and a much more beautiful way of presenting states, but they achieve
    exactly the same result as the code shown previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the output will be just ![\left| 100\rangle \right.](img/file390.png
    "\left| 100\rangle \right."). More readable, right?
  prefs: []
  type: TYPE_NORMAL
- en: A faster way of constructing the ![\left| 100\rangle \right.](img/file390.png
    "\left| 100\rangle \right.") state is using, again, the `from_int` method, as
    in
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: where we specify that we are working with three qubits by setting `dims` `=`
    `8` (because we need 8 amplitudes to define a three-qubit state).
  prefs: []
  type: TYPE_NORMAL
- en: So, we now know a bunch of ways of creating basis states. What about states
    that are in superposition? Well, it couldn’t be easier, because, in Qiskit, you
    can simply multiply basis states by amplitudes and then add them together. For
    instance, the instructions
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: create the state ![\left. 1\slash\sqrt{2}\left| {000} \right\rangle + 1\slash\sqrt{2}\left|
    {111} \right\rangle \right.](img/file391.png "\left. 1\slash\sqrt{2}\left| {000}
    \right\rangle + 1\slash\sqrt{2}\left| {111} \right\rangle \right.").
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It may seem that we have included some unnecessary parenthesis in the previous
    code. However, if you remove them, you will not get the expected result. Qiskit
    overloads the `^` operator to be used as the tensor product operation. But, in
    Python, `^` has a lower precedence than `+`, so we need the parenthesis for the
    operations to be performed in the desired order.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: An additional, indirect way of setting the values of a quantum state is creating
    a quantum circuit that prepares the state and running it to obtain the state vector
    with `get_stavector` as we learned to do in *Chapter* *[*2*](ch009.xhtml#x1-400002),
    *The Tools of the Trade in Quantum Computing*; or you can even just pass the quantum
    circuit to the `Statevector` constructor. For instance, to create basis states,
    you would only need a circuit with ![X](img/file9.png "X") gates on the qubits
    that you need to be set to ![1](img/file13.png "1"). If you use this method, however,
    you need to be careful to remember that qubit ![0](img/file12.png "0") in Qiskit
    circuits is represented as the rightmost one in kets. Thus, if you have a three-qubit
    `QuantumCircuit` called `qc` and you use `qc``.``x` `(0)`, you will obtain ![\left|
    {001} \right\rangle](img/file392.png "\left| {001} \right\rangle")!*
  prefs: []
  type: TYPE_NORMAL
- en: '*In order to compute expectation values, quantum states are not enough. We
    also need to create Hamiltonians. For now, we will learn how to work with tensor
    products of ![Z](img/file8.png "Z") gates, like the ones we used in the previous
    section, starting with simple ones that can be stored in Qiskit `Pauli` objects.
    Qiskit offers several ways to initialize them, like in the case of `Statevector`
    objects. The first one is to use a string to specify the positions of ![Z](img/file8.png
    "Z") and ![I](img/file53.png "I") matrices in the product. For instance, if we
    are working with three qubits and we want to create ![Z_{0}Z_{1}](img/file352.png
    "Z_{0}Z_{1}") (which is, as you surely remember, the tensor product ![Z \otimes
    Z \otimes I](img/file348.png "Z \otimes Z \otimes I")), we can use the following
    instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'They give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The matrix representing ![Z_{0}Z_{1}](img/file352.png "Z_{0}Z_{1}") is of size
    ![8 \times 8](img/file393.png "8 \times 8") and, as you can see, it can be hard
    to read. Fortunately, we can use the fact that tensor products of diagonal matrices
    are always diagonal, and print only the non-zero coefficients with the following
    instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'They will give us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: When constructing a `Pauli` object, we can also specify which positions of the
    tensor product are ![Z](img/file8.png "Z") matrices, passing them as a vector
    of ones (indicating the presence of ![Z](img/file8.png "Z")) and zeroes (indicating
    the absence of ![Z](img/file8.png "Z") or, equivalently, the presence of ![I](img/file53.png
    "I")). Since the construction method is more general and it can be used to create
    other tensor products, we would need to specify another vector with positions
    of ![X](img/file9.png "X") matrices, which we will set to all zeroes for the moment.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, you can run something like `Z0Z1` `=` `Pauli``(([0,1,1],[0,0,0]))`
    in order to obtain ![Z \otimes Z \otimes I](img/file348.png "Z \otimes Z \otimes
    I"). Notice that, because of the convention of qubit numbering in Qiskit, we need
    to use `[0,1,1]` for the vector of ![Z](img/file8.png "Z") positions instead of
    `[1,1,0]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main drawback of working with `Pauli` objects is that you cannot add them
    or multiply them by scalars. To get something like ![Z_{0}Z_{1} + Z_{1}Z_{2}](img/file394.png
    "Z_{0}Z_{1} + Z_{1}Z_{2}"), we need first to convert the `Pauli` objects to `PauliOp`,
    which we can then add together as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, in this case, is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Since the sum of diagonal matrices is diagonal, we have used the sparse representation
    to more compactly show the non-zero terms of `H_cut`. Notice that even some of
    the diagonal terms are zero, because some elements of ![Z_{0}Z_{1}](img/file352.png
    "Z_{0}Z_{1}") cancel with those of ![Z_{0}Z_{2}](img/file395.png "Z_{0}Z_{2}").
  prefs: []
  type: TYPE_NORMAL
- en: 'A more compact way of obtaining the same Hamiltonian is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This evaluates to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we have used `^` to compute tensor products and parenthesis to get
    the operation priorities right.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, more complicated Hamiltonians, even including coefficients, can be
    constructed.
  prefs: []
  type: TYPE_NORMAL
- en: For example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: defines the Hamiltonian ![\left. - 1\slash 2Z_{0}Z_{1} + 2Z_{0}Z_{2} - Z_{1}Z_{2}
    + Z_{1} - 5Z_{2} \right.](img/file396.png "\left. - 1\slash 2Z_{0}Z_{1} + 2Z_{0}Z_{2}
    - Z_{1}Z_{2} + Z_{1} - 5Z_{2} \right.").
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are ready to compute expectation values. Thanks to the code that we
    have written and executed so far, `psi` stores ![\left| {100} \right\rangle](img/file387.png
    "\left| {100} \right\rangle") and `H_cut` stores ![Z_{0}Z_{1} + Z_{1}Z_{2}](img/file394.png
    "Z_{0}Z_{1} + Z_{1}Z_{2}"). Then, computing ![\left\langle {100} \right|\left(
    {Z_{0}Z_{1} + Z_{1}Z_{2}} \right)\left| {100} \right\rangle](img/file397.png "\left\langle
    {100} \right|\left( {Z_{0}Z_{1} + Z_{1}Z_{2}} \right)\left| {100} \right\rangle")
    is as easy as running the following instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Since ![Z_{0}Z_{1} + Z_{0}Z_{2}](img/file398.png "Z_{0}Z_{1} + Z_{0}Z_{2}")
    is the Hamiltonian for the Max-Cut problem of the graph in *Figure* * [*3.5*](#Figure3.5),
    this indicates that the assignment represented by ![\left| {100} \right\rangle](img/file387.png
    "\left| {100} \right\rangle") (vertex ![0](img/file12.png "0") in one set and
    ![1](img/file13.png "1") and ![2](img/file302.png "2") in the other) cuts the
    two edges of the graph and is, therefore, an optimal solution. Notice how the
    output is represented as a complex number because inner products can, in general,
    have imaginary parts. However, these expectation values will always be real, and
    the coefficients that will go with the imaginary unit — represented in Python
    as `j` — will just be ![0](img/file12.png "0").*
  prefs: []
  type: TYPE_NORMAL
- en: '*Exercise 3.4'
  prefs: []
  type: TYPE_NORMAL
- en: Write code to compute the expectation value of all the possible cuts of the
    graph in *Figure* *[*3.5*](#Figure3.5). How many optimal solutions are there?*
  prefs: []
  type: TYPE_NORMAL
- en: '*If you want to evaluate expressions such as ![\left\langle \psi \right|H_{\text{cut}}\left|
    \psi \right\rangle](img/file399.png "\left\langle \psi \right|H_{\text{cut}}\left|
    \psi \right\rangle") step by step, you can also use Qiskit to first compute ![H_{\text{cut}}\left|
    \psi \right\rangle](img/file400.png "H_{\text{cut}}\left| \psi \right\rangle")
    and, then, the inner product of ![\left| \psi \right\rangle](img/file43.png "\left|
    \psi \right\rangle") with that. This can be achieved with the following instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here, the `evolve` method is used to compute the matrix-vector multiplication,
    and `inner` is, obviously, used for the inner product.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'We must stress that all these operations are numerical and not something that
    we can run on actual quantum computers. In fact, as you already know, on real
    devices we have no access to the full state vector: this is something that we
    can only do when we run circuits on simulators. In any case, we know that state
    vectors grow exponentially in size with the number of qubits, so simulations can
    easily become unfeasible in many scenarios. But don’t worry. In *Chapter* *[*5*](ch013.xhtml#x1-940005),
    *QAOA: Quantum Approximate* *Optimization Algorithm*, we will learn how to use
    quantum computers to estimate expectation values of tensor products of ![Z](img/file8.png
    "Z") matrices. In *Chapter* * [*7*](ch015.xhtml#x1-1190007), *VQE: Variational
    Quantum Eigensolver*, we will do the same with more general tensor products. In
    fact, the procedure that we will use will clarify why we call these quantities
    *expectation values*!**'
  prefs: []
  type: TYPE_NORMAL
- en: '**But enough of tensor products and expectation values for now. Instead, in
    the next section, we will introduce a new formalism that will allow us to formulate
    some optimization problems more naturally than with the Ising model.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Moving from Ising to QUBO and back
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Consider the following problem. Let’s say that you are given a set of integers
    ![S](img/file73.png "S") and a target integer value ![T](img/file74.png "T"),
    and you are asked whether there is any subset of ![S](img/file73.png "S") whose
    sum is ![T](img/file74.png "T"). For instance, if ![S = \{ 1,3,4,7, - 4\}](img/file401.png
    "S = \{ 1,3,4,7, - 4\}") and ![T = 6](img/file402.png "T = 6"), then the answer
    is affirmative, because ![3 + 7 - 4 = 6](img/file403.png "3 + 7 - 4 = 6"). However,
    if ![S = \{ 2, - 2,4,8, - 12\}](img/file404.png "S = \{ 2, - 2,4,8, - 12\}") and
    ![T = 1](img/file405.png "T = 1"), the answer is negative because all the numbers
    in the set are even and they cannot add up to an odd number.
  prefs: []
  type: TYPE_NORMAL
- en: This problem, called the **Subset Sum** problem, is known to be ![NP](img/file2.png
    "NP")**-complete** (see, for instance, *Section 7.5* in the book by Sipser [[90](ch030.xhtml#Xsipser2012introduction)]
    for a proof). It turns out that we can **reduce** the Subset Sum problem to finding
    a spin configuration of minimal energy for an Ising model, (which is an ![NP](img/file2.png
    "NP")-hard problem – see *Section* * [*3.1.3*](#x1-630003.1.3)). This means that
    we can rewrite any instance of Subset Sum as an Ising ground state problem (check
    *Appendix* * [*C*](ch026.xhtml#x1-233000C), *Computational* *Complexity*, for
    a refresher on **reductions**).**
  prefs: []
  type: TYPE_NORMAL
- en: '**However, it may not be directly evident how to do so.'
  prefs: []
  type: TYPE_NORMAL
- en: In fact, it is much simpler to pose the Subset Sum problem as a minimization
    problem by using binary variables instead of variables that take ![1](img/file13.png
    "1") or ![- 1](img/file312.png "- 1") values. Indeed, if we are given ![S = \{
    a_{0},\ldots,a_{m}\}](img/file406.png "S = \{ a_{0},\ldots,a_{m}\}") and an integer
    ![T](img/file74.png "T"), we can define binary variables ![x_{j}](img/file407.png
    "x_{j}"), ![j = 0,\ldots,m](img/file408.png "j = 0,\ldots,m"), and consider
  prefs: []
  type: TYPE_NORMAL
- en: '![c(x_{0},x_{1},\ldots,x_{m}) = \left( {a_{0}x_{0} + a_{1}x_{1} + \ldots +
    a_{m}x_{m} - T} \right)^{2}.](img/file409.png "c(x_{0},x_{1},\ldots,x_{m}) = \left(
    {a_{0}x_{0} + a_{1}x_{1} + \ldots + a_{m}x_{m} - T} \right)^{2}.")'
  prefs: []
  type: TYPE_IMG
- en: 'Clearly, the Subset Sum problem has a positive answer if and only if we can
    find binary values ![x_{j}](img/file407.png "x_{j}"), ![j = 0,\ldots,m](img/file408.png
    "j = 0,\ldots,m"), such that ![c(x_{0},x_{1},\ldots,x_{m}) = 0](img/file410.png
    "c(x_{0},x_{1},\ldots,x_{m}) = 0"). In that case, the variables ![x_{j}](img/file407.png
    "x_{j}") that are equal to ![1](img/file13.png "1") will indicate which numbers
    from the set are selected for the sum. But ![c(x_{0},x_{1},\ldots,x_{m})](img/file411.png
    "c(x_{0},x_{1},\ldots,x_{m})") is always non-negative, so we have reduced the
    Subset Sum problem to finding the minimum of ![c(x_{0},x_{1},\ldots,x_{m})](img/file411.png
    "c(x_{0},x_{1},\ldots,x_{m})"): if the minimum is ![0](img/file12.png "0"), the
    Subset Sum has a positive solution; otherwise, it doesn’t.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, for the case of ![S = \{ 1,4, - 2\}](img/file412.png "S = \{ 1,4,
    - 2\}") and ![T = 2](img/file413.png "T = 2") that we considered previously, the
    problem would be
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize~}\quad} & {x_{0}^{2} + 8x_{0}x_{1} -
    4x_{0}x_{2} - 4x_{0} + 16x_{1}^{2} - 16x_{1}x_{2} - 16x_{1} + 4x_{2}^{2} + 8x_{2}
    + 4\qquad} & & \qquad \\ {\text{subject~to~}\quad} & {x_{j} \in \{ 0,1\},\qquad
    j = 0,\ldots,m\qquad} & & \qquad \\ \end{array}](img/file414.png "\begin{array}{rlrl}
    {\text{Minimize~}\quad} & {x_{0}^{2} + 8x_{0}x_{1} - 4x_{0}x_{2} - 4x_{0} + 16x_{1}^{2}
    - 16x_{1}x_{2} - 16x_{1} + 4x_{2}^{2} + 8x_{2} + 4\qquad} & & \qquad \\ {\text{subject~to~}\quad}
    & {x_{j} \in \{ 0,1\},\qquad j = 0,\ldots,m\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: where we have expanded ![{(x_{0} + 4x_{1} - 2x_{2} - 2)}^{2}](img/file415.png
    "{(x_{0} + 4x_{1} - 2x_{2} - 2)}^{2}") to obtain the expression to be optimized.
    If you wish, you can simplify it a little by taking into account that ![x_{j}^{2}
    = x_{j}](img/file416.png "x_{j}^{2} = x_{j}") always holds for binary variables.
    In any case, ![x_{0} = 0,x_{1} = x_{2} = 1](img/file417.png "x_{0} = 0,x_{1} =
    x_{2} = 1") would be an optimal solution for this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that, in all of these cases, the function ![c(x_{0},x_{1},\ldots,x_{m})](img/file411.png
    "c(x_{0},x_{1},\ldots,x_{m})") that we need to minimize is a polynomial of degree
    ![2](img/file302.png "2") on the binary variables ![x_{j}](img/file407.png "x_{j}").
    We can thus generalize this setting and define **Quadratic Unconstrained** **Binary
    Optimization** (**QUBO**) problems, which are of the form
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize~}\quad} & {q(x_{0},\ldots,x_{m})\qquad}
    & & \qquad \\ {\text{subject~to~}\quad} & {x_{j} \in \{ 0,1\},\qquad j = 0,\ldots,m\qquad}
    & & \qquad \\ \end{array}](img/file418.png "\begin{array}{rlrl} {\text{Minimize~}\quad}
    & {q(x_{0},\ldots,x_{m})\qquad} & & \qquad \\ {\text{subject~to~}\quad} & {x_{j}
    \in \{ 0,1\},\qquad j = 0,\ldots,m\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: 'where ![q(x_{0},\ldots,x_{m})](img/file419.png "q(x_{0},\ldots,x_{m})") is
    a quadratic polynomial on the ![x_{j}](img/file407.png "x_{j}") variables. The
    reason why these problems are called QUBO should now be clear: we are minimizing
    quadratic expressions over binary variables with no restrictions (because every
    combination of zeroes and ones is acceptable).'
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding reduction of the Subset Sum problem, it follows that QUBO
    problems are ![NP](img/file2.png "NP")-hard. Indeed, the QUBO model is very flexible,
    and it enables us to formulate many optimization problems in a natural way. For
    example, it is quite easy to recast any Ising minimization problem as a QUBO instance.
    If you need to minimize
  prefs: []
  type: TYPE_NORMAL
- en: '![- \sum\limits_{j,k}J_{jk}z_{j}z_{k} - \sum\limits_{j}h_{j}z_{j}](img/file341.png
    "- \sum\limits_{j,k}J_{jk}z_{j}z_{k} - \sum\limits_{j}h_{j}z_{j}")'
  prefs: []
  type: TYPE_IMG
- en: with some variables ![z_{j}](img/file339.png "z_{j}"), ![j = 0,\ldots,m](img/file408.png
    "j = 0,\ldots,m"), taking values ![1](img/file13.png "1") or ![- 1](img/file312.png
    "- 1"), you can define new variables ![\left. x_{j} = (1 - z_{j})\slash 2 \right.](img/file420.png
    "\left. x_{j} = (1 - z_{j})\slash 2 \right."). Obviously, ![x_{j}](img/file407.png
    "x_{j}") will be ![0](img/file12.png "0") when ![z_{j}](img/file339.png "z_{j}")
    is ![1](img/file13.png "1"), and ![1](img/file13.png "1") when ![z_{j}](img/file339.png
    "z_{j}") is ![- 1](img/file312.png "- 1"). Furthermore, if you make the substitutions
    ![z_{j} = 1 - 2x_{j}](img/file421.png "z_{j} = 1 - 2x_{j}"), you obtain a quadratic
    polynomial in the binary variables ![x_{j}](img/file407.png "x_{j}") that takes
    exactly the same values as the energy function of the original Ising model. If
    you minimize the polynomial for the variables ![x_{j}](img/file407.png "x_{j}"),
    you can then recover the spin values ![z_{j}](img/file339.png "z_{j}") that achieve
    the minimal energy.
  prefs: []
  type: TYPE_NORMAL
- en: In case you were wondering, yes, you can also use the substitution ![z_{j} =
    2x_{j} - 1](img/file422.png "z_{j} = 2x_{j} - 1") to transform Ising problems
    into QUBO formalism. In that case, values of ![z_{j}](img/file339.png "z_{j}")
    equal to ![- 1](img/file312.png "- 1") would be taken to values of ![x_{j}](img/file407.png
    "x_{j}") equal to ![0](img/file12.png "0") and values of ![z_{j}](img/file339.png
    "z_{j}") equal to ![1](img/file13.png "1") would be taken to ![1](img/file13.png
    "1") in ![x_{j}](img/file407.png "x_{j}"). However, we will stick to the transformation
    ![z_{j} = 1 - 2x_{j}](img/file421.png "z_{j} = 1 - 2x_{j}") for the rest of the
    book.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, if the Ising energy is given by ![\left. ( - 1\slash 2)z_{0}z_{1}
    + z_{2} \right.](img/file423.png "\left. ( - 1\slash 2)z_{0}z_{1} + z_{2} \right."),
    then, under the transformation ![z_{j} = 1 - 2x_{j}](img/file421.png "z_{j} =
    1 - 2x_{j}"), the corresponding QUBO problem will be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize~}\quad} & {- 2x_{0}x_{1} + x_{0} + x_{1}
    - 2x_{2} + \frac{1}{2}\qquad} & & \qquad \\ {\text{subject~to~}\quad} & {x_{j}
    \in \{ 0,1\},\qquad j = 0,1,2.\qquad} & & \qquad \\ \end{array}](img/file424.png
    "\begin{array}{rlrl} {\text{Minimize~}\quad} & {- 2x_{0}x_{1} + x_{0} + x_{1}
    - 2x_{2} + \frac{1}{2}\qquad} & & \qquad \\ {\text{subject~to~}\quad} & {x_{j}
    \in \{ 0,1\},\qquad j = 0,1,2.\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: You can also go from a QUBO problem to an Ising model instance by using the
    ![\left. x_{j} = (1 - z_{j})\slash 2 \right.](img/file420.png "\left. x_{j} =
    (1 - z_{j})\slash 2 \right.") substitution. However, you will need to pay attention
    to a couple of details. Let’s illustrate them with an example. Suppose that your
    QUBO problem is asking to minimize ![x_{0}^{2} + 2x_{0}x_{1} - 3](img/file425.png
    "x_{0}^{2} + 2x_{0}x_{1} - 3"). Then, when you substitute the ![x_{j}](img/file407.png
    "x_{j}") variables, you obtain
  prefs: []
  type: TYPE_NORMAL
- en: '![\frac{z_{0}^{2}}{4} + \frac{z_{0}z_{1}}{2} - z_{0} - \frac{z_{1}}{2} - \frac{9}{4}.](img/file426.png
    "\frac{z_{0}^{2}}{4} + \frac{z_{0}z_{1}}{2} - z_{0} - \frac{z_{1}}{2} - \frac{9}{4}.")'
  prefs: []
  type: TYPE_IMG
- en: But the Ising model does not allow squared variables or independent terms! Fixing
    these problems is not difficult, though. Regarding the squared variables, we can
    simply notice that it always holds that ![z_{j}^{2} = 1](img/file427.png "z_{j}^{2}
    = 1"), because ![z_{j}](img/file339.png "z_{j}") is either ![1](img/file13.png
    "1") or ![- 1](img/file312.png "- 1"). Thus, we replace each squared variable
    with the constant value ![1](img/file13.png "1"). In our case, we would get
  prefs: []
  type: TYPE_NORMAL
- en: '![\frac{1}{4} + \frac{z_{0}z_{1}}{2} - z_{0} - \frac{z_{1}}{2} - \frac{9}{4}
    = \frac{z_{0}z_{1}}{2} - z_{0} - \frac{z_{1}}{2} - 2.](img/file428.png "\frac{1}{4}
    + \frac{z_{0}z_{1}}{2} - z_{0} - \frac{z_{1}}{2} - \frac{9}{4} = \frac{z_{0}z_{1}}{2}
    - z_{0} - \frac{z_{1}}{2} - 2.")'
  prefs: []
  type: TYPE_IMG
- en: 'Then, we can simply drop the independent term, because we are dealing with
    a minimization problem and it won’t influence the choice of optimal variables
    (however, you should add it back when you want to recover the original value of
    the function to minimize). In the preceding example, the equivalent Ising minimization
    problem would then be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize~}\quad} & {\frac{z_{0}z_{1}}{2} - z_{0}
    - \frac{z_{1}}{2}\qquad} & & \qquad \\ {\text{subject~to~}\quad} & {z_{j} \in
    \{ 1, - 1\},\qquad j = 0,1,2.\qquad} & & \qquad \\ \end{array}](img/file429.png
    "\begin{array}{rlrl} {\text{Minimize~}\quad} & {\frac{z_{0}z_{1}}{2} - z_{0} -
    \frac{z_{1}}{2}\qquad} & & \qquad \\ {\text{subject~to~}\quad} & {z_{j} \in \{
    1, - 1\},\qquad j = 0,1,2.\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: 'It is easy to check that this problem has two optimal solutions: ![z_{0} =
    z_{1} = 1](img/file430.png "z_{0} = z_{1} = 1") and ![z_{0} = 1,z_{1} = - 1](img/file431.png
    "z_{0} = 1,z_{1} = - 1"), both attaining the ![- 1](img/file312.png "- 1") value.
    If we add back the independent term of value ![- 2](img/file333.png "- 2") that
    we had dropped, we obtain an optimal cost of ![- 3](img/file432.png "- 3") in
    the QUBO problem. These solutions correspond to ![x_{0} = x_{1} = 0](img/file433.png
    "x_{0} = x_{1} = 0") and ![x_{0} = 0,x_{1} = 1](img/file434.png "x_{0} = 0,x_{1}
    = 1"), respectively, which indeed evaluate to ![- 3](img/file432.png "- 3") and
    are optimal for the original problem.'
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.5
  prefs: []
  type: TYPE_NORMAL
- en: Write the Subset Sum problem for ![S = \{ 1, - 2,3, - 4\}](img/file435.png "S
    = \{ 1, - 2,3, - 4\}") and ![T = 0](img/file436.png "T = 0") as a QUBO problem
    and transform it into an instance of the Ising model.
  prefs: []
  type: TYPE_NORMAL
- en: So now we know how to go from QUBO problems to Ising energy minimization problems
    and back, and we can use either formalism — whichever is more convenient at any
    given moment. In fact, as we will learn in *Chapters* *[*4*](ch012.xhtml#x1-750004)
    and *[*5*](ch013.xhtml#x1-940005), the Ising model is the preferred formulation
    when solving combinatorial optimization problems with quantum computers. Also,
    the software tools that we will be using (Qiskit and D-Wave’s Ocean) will help
    us in rewriting our QUBO problems in the Ising formalism by using transformations
    like the ones we have described in this section.**
  prefs: []
  type: TYPE_NORMAL
- en: '**We now have all the mathematical tools that we need in order to work with
    combinatorial optimization problems if we want to solve them with quantum computers.
    Let’s play with our new, shiny toys and use them to write some important problems
    in QUBO formalism.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Combinatorial optimization problems with the QUBO model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final section of the chapter, we are going to introduce some techniques
    that will allow us to write many important optimization problems as QUBO and Ising
    instances, so we can later solve them with different quantum algorithms. These
    examples will also help you understand how to formulate your own optimization
    problems under these models, which is the first step in order to be able to use
    quantum computers to solve them.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.1 Binary linear programming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Binary linear programming** problems involve optimizing a linear function
    on binary variables subject to linear constraints. Thus, the general form is'
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize}\quad} & {c_{0}x_{0} + c_{1}x_{1} + \ldots
    + c_{m}x_{m}\qquad} & & \qquad \\ {\text{subject~to}\quad} & {Ax \leq b,\qquad}
    & & \qquad \\ & {x_{j} \in \{ 0,1\},\qquad j = 0,\ldots,m,\qquad} & & \qquad \\
    \end{array}](img/file437.png "\begin{array}{rlrl} {\text{Minimize}\quad} & {c_{0}x_{0}
    + c_{1}x_{1} + \ldots + c_{m}x_{m}\qquad} & & \qquad \\ {\text{subject~to}\quad}
    & {Ax \leq b,\qquad} & & \qquad \\  & {x_{j} \in \{ 0,1\},\qquad j = 0,\ldots,m,\qquad}
    & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: where ![c_{j}](img/file438.png "c_{j}") are integer coefficients, ![A](img/file183.png
    "A") is an integer matrix, ![x](img/file269.png "x") is the transpose of ![(x_{0},\ldots,x_{m})](img/file439.png
    "(x_{0},\ldots,x_{m})"), and ![b](img/file17.png "b") is an integer column vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of this type of problem could be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize}\quad} & {- 5x_{0} + 3x_{1} - 2x_{2}\qquad}
    & & \qquad \\ {\text{subject~to}\quad} & {x_{0} + x_{2} \leq 1,\qquad} & & \qquad
    \\ & {3x_{0} - x_{1} + 3x_{2} \leq 4\qquad} & & \qquad \\ & {x_{j} \in \{ 0,1\},\qquad
    j = 0,1,2.\qquad} & & \qquad \\ \end{array}](img/file440.png "\begin{array}{rlrl}
    {\text{Minimize}\quad} & {- 5x_{0} + 3x_{1} - 2x_{2}\qquad} & & \qquad \\ {\text{subject~to}\quad}
    & {x_{0} + x_{2} \leq 1,\qquad} & & \qquad \\  & {3x_{0} - x_{1} + 3x_{2} \leq
    4\qquad} & & \qquad \\  & {x_{j} \in \{ 0,1\},\qquad j = 0,1,2.\qquad} & & \qquad
    \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: Binary linear programming (also known as **zero-one linear programming**) is
    ![NP](img/file2.png "NP")-hard. In fact, the decision version in which the goal
    is to determine if there is any assignment of zeroes and ones that satisfies the
    linear constraints (with no actual optimization performed) was one of Richard
    M. Karp’s original 21 ![NP](img/file2.png "NP")-complete problems published in
    his famous paper on reducibility [[56](ch030.xhtml#Xkarp1972reducibility)]. Assignments
    that satisfy the constraints are called **feasible**.
  prefs: []
  type: TYPE_NORMAL
- en: 'To write a binary linear program in QUBO formalism, we need to perform some
    transformations. The first one is to convert the inequality constraints into equality
    constraints by adding **slack variables**. This is better understood with an example.
    In the preceding problem, we have two constraints: ![x_{0} + x_{2} \leq 1](img/file441.png
    "x_{0} + x_{2} \leq 1") and ![3x_{0} - x_{1} + 3x_{2} \leq 4](img/file442.png
    "3x_{0} - x_{1} + 3x_{2} \leq 4"). In the first one, the minimum value of the
    left-hand side is ![0](img/file12.png "0"), attained when both ![x_{0}](img/file443.png
    "x_{0}") and ![x_{2}](img/file444.png "x_{2}") are 0\. Thus, if we add a new binary
    slack variable ![y_{0}](img/file445.png "y_{0}") to that left-hand side and substitute
    ![\leq](img/file446.png "\leq") with ![=](img/file447.png "="), we have'
  prefs: []
  type: TYPE_NORMAL
- en: '![x_{0} + x_{2} + y_{0} = 1,](img/file448.png "x_{0} + x_{2} + y_{0} = 1,")'
  prefs: []
  type: TYPE_IMG
- en: which can be satisfied if and only if ![x_{0} + x_{2} \leq 1](img/file441.png
    "x_{0} + x_{2} \leq 1") can be satisfied. Indeed, if ![x_{0} = x_{2} = 0](img/file449.png
    "x_{0} = x_{2} = 0"), then we can take ![y_{0} = 1](img/file450.png "y_{0} = 1");
    and, if ![x_{0} = 0](img/file451.png "x_{0} = 0") and ![x_{2} = 1](img/file452.png
    "x_{2} = 1"), or ![x_{0} = 1](img/file453.png "x_{0} = 1") and ![x_{2} = 0](img/file454.png
    "x_{2} = 0"), we can take ![y_{0} = 0](img/file455.png "y_{0} = 0"). If ![x_{0}
    = x_{2} = 1](img/file456.png "x_{0} = x_{2} = 1"), it is not possible to satisfy
    the constraint. That’s why we can replace ![x_{0} + x_{2} \leq 1](img/file441.png
    "x_{0} + x_{2} \leq 1") with ![x_{0} + x_{2} + y_{0} = 1](img/file457.png "x_{0}
    + x_{2} + y_{0} = 1") without changing the set of feasible solutions.
  prefs: []
  type: TYPE_NORMAL
- en: In the same way, the minimum value of ![3x_{0} - x_{1} + 3x_{2}](img/file458.png
    "3x_{0} - x_{1} + 3x_{2}") is ![- 1](img/file312.png "- 1"), and it is achieved
    when ![x_{0} = 0](img/file451.png "x_{0} = 0"), ![x_{1} = 1](img/file459.png "x_{1}
    = 1"), and ![x_{2} = 0](img/file454.png "x_{2} = 0").
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Notice how the general rule to minimize these linear expressions on binary variables
    within some constraints is to set the variables with positive coefficients to
    ![0](img/file12.png "0") and those with negative coefficients to ![1](img/file13.png
    "1").
  prefs: []
  type: TYPE_NORMAL
- en: Then, in order for ![3x_{0} - x_{1} + 3x_{2}](img/file458.png "3x_{0} - x_{1}
    + 3x_{2}") to reach up to ![4](img/file143.png "4"), which is the right-hand side
    of the constraint, we may need to add a number as big as ![5](img/file296.png
    "5"). But to write non-negative numbers up to ![5](img/file296.png "5") we need
    only three bits, so we can add three new binary variables, ![y_{1}](img/file460.png
    "y_{1}"), ![y_{2}](img/file461.png "y_{2}"), and ![y_{3}](img/file462.png "y_{3}"),
    and consider ![3x_{0} - x_{1} + 3x_{2} + y_{1} + 2y_{2} + 4y_{3} = 4,](img/file463.png
    "3x_{0} - x_{1} + 3x_{2} + y_{1} + 2y_{2} + 4y_{3} = 4,")
  prefs: []
  type: TYPE_NORMAL
- en: which can be satisfied if and only if ![3x_{0} - x_{1} + 3x_{2} \leq 4](img/file442.png
    "3x_{0} - x_{1} + 3x_{2} \leq 4") can be satisfied.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: In fact, notice that ![y_{1} + 2y_{2} + 4y_{3}](img/file464.png "y_{1} + 2y_{2}
    + 4y_{3}") may go up to ![7](img/file465.png "7"), but we only need to go up to
    ![5](img/file296.png "5"). Thus, we could also use
  prefs: []
  type: TYPE_NORMAL
- en: '![3x_{0} - x_{1} + 3x_{2} + y_{1} + 2y_{2} + 2y_{3} = 4](img/file466.png "3x_{0}
    - x_{1} + 3x_{2} + y_{1} + 2y_{2} + 2y_{3} = 4")'
  prefs: []
  type: TYPE_IMG
- en: as a replacement for ![3x_{0} - x_{1} + 3x_{2} \leq 4](img/file442.png "3x_{0}
    - x_{1} + 3x_{2} \leq 4").
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting it all together, our original problem is equivalent to the following
    one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize}\quad} & {- 5x_{0} + 3x_{1} - 2x_{2}\qquad}
    & & \qquad \\ {\text{subject~to}\quad} & {x_{0} + x_{2} + y_{0} = 1,\qquad} &
    & \qquad \\ & {3x_{0} - x_{1} + 3x_{2} + y_{1} + 2y_{2} + 2y_{3} = 4\qquad} &
    & \qquad \\ & {x_{j} \in \{ 0,1\},\qquad j = 0,1,2,\qquad} & & \qquad \\ & {y_{j}
    \in \{ 0,1\},\qquad j = 0,1,2,3.\qquad} & & \qquad \\ \end{array}](img/file467.png
    "\begin{array}{rlrl} {\text{Minimize}\quad} & {- 5x_{0} + 3x_{1} - 2x_{2}\qquad}
    & & \qquad \\ {\text{subject~to}\quad} & {x_{0} + x_{2} + y_{0} = 1,\qquad} &
    & \qquad \\  & {3x_{0} - x_{1} + 3x_{2} + y_{1} + 2y_{2} + 2y_{3} = 4\qquad} &
    & \qquad \\  & {x_{j} \in \{ 0,1\},\qquad j = 0,1,2,\qquad} & & \qquad \\  & {y_{j}
    \in \{ 0,1\},\qquad j = 0,1,2,3.\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: Now, we are ready to write the problem as a QUBO instance. The only thing that
    we need to do is to incorporate the constraints as **penalty terms** in the expression
    that we are trying to minimize. For that, we use an integer ![B](img/file184.png
    "B") (for which we will select a concrete value later on) and consider the problem
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize}\quad} & {- 5x_{0} + 3x_{1} - 2x_{2}
    + B{(x_{0} + x_{2} + y_{0} - 1)}^{2}\qquad} & & \qquad \\ & {+ B{(3x_{0} - x_{1}
    + 3x_{2} + y_{1} + 2y_{2} + 2y_{3} - 4)}^{2}\qquad} & & \qquad \\ {\text{subject~to}\quad}
    & {x_{j} \in \{ 0,1\},\qquad j = 0,1,2,\qquad} & & \qquad \\ & {y_{j}, \in \{
    0,1\},\qquad j = 0,1,2,3,\qquad} & & \qquad \\ \end{array}](img/file468.png "\begin{array}{rlrl}
    {\text{Minimize}\quad} & {- 5x_{0} + 3x_{1} - 2x_{2} + B{(x_{0} + x_{2} + y_{0}
    - 1)}^{2}\qquad} & & \qquad \\  & {+ B{(3x_{0} - x_{1} + 3x_{2} + y_{1} + 2y_{2}
    + 2y_{3} - 4)}^{2}\qquad} & & \qquad \\ {\text{subject~to}\quad} & {x_{j} \in
    \{ 0,1\},\qquad j = 0,1,2,\qquad} & & \qquad \\  & {y_{j}, \in \{ 0,1\},\qquad
    j = 0,1,2,3,\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: which is already in QUBO form.
  prefs: []
  type: TYPE_NORMAL
- en: Since the new problem is unconstrained, we need to set ![B](img/file184.png
    "B") big enough so that violating the constraints does not *pay off* . If one
    of the original constraints is violated, the terms that are multiplied by ![B](img/file184.png
    "B") will be greater than ![0](img/file12.png "0"). Moreover, the expression that
    we wanted to minimize in the original formulation of the problem was ![- 5x_{0}
    + 3x_{1} - 2x_{2}](img/file469.png "- 5x_{0} + 3x_{1} - 2x_{2}"), which can reach
    a minimum value of ![- 7](img/file470.png "- 7") (when ![x_{0} = x_{2} = 1](img/file456.png
    "x_{0} = x_{2} = 1") and ![x_{1} = 0](img/file471.png "x_{1} = 0")) and a maximum
    value of ![3](img/file472.png "3") (when ![x_{0} = x_{2} = 0](img/file449.png
    "x_{0} = x_{2} = 0") and ![x_{1} = 1](img/file459.png "x_{1} = 1")). Thus, if
    we choose, for instance, ![B = 11](img/file473.png "B = 11"), any assignment that
    violates the constraints will achieve a value greater than at least ![4](img/file143.png
    "4") and will never be selected as the optimal solution to the QUBO problem if
    there is at least one feasible solution (which is the case for this particular
    problem).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this way, a QUBO problem whose optimal solution is the same as the optimal
    solution of the original one is the following one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize}\quad} & {- 5x_{0} + 3x_{1} - 2x_{2}
    + 11{(x_{0} + x_{2} + y_{0} - 1)}^{2}\qquad} & & \qquad \\ & {+ 11{(3x_{0} - x_{1}
    + 3x_{2} + y_{1} + 2y_{2} + 2y_{3} - 4)}^{2}\qquad} & & \qquad \\ {\text{subject~to}\quad}
    & {x_{j} \in \{ 0,1\},\qquad j = 0,1,2,\qquad} & & \qquad \\ & {y_{j}, \in \{
    0,1\},\qquad j = 0,1,2,3.\qquad} & & \qquad \\ \end{array}](img/file474.png "\begin{array}{rlrl}
    {\text{Minimize}\quad} & {- 5x_{0} + 3x_{1} - 2x_{2} + 11{(x_{0} + x_{2} + y_{0}
    - 1)}^{2}\qquad} & & \qquad \\  & {+ 11{(3x_{0} - x_{1} + 3x_{2} + y_{1} + 2y_{2}
    + 2y_{3} - 4)}^{2}\qquad} & & \qquad \\ {\text{subject~to}\quad} & {x_{j} \in
    \{ 0,1\},\qquad j = 0,1,2,\qquad} & & \qquad \\  & {y_{j}, \in \{ 0,1\},\qquad
    j = 0,1,2,3.\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: If you expand the expression to minimize, you will obtain a quadratic polynomial
    in the ![x_{j}](img/file407.png "x_{j}") variables, exactly what we need in the
    QUBO formulation.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: '**Integer linear programming** is a generalization of binary linear programming
    in which non-negative integer variables are used instead of binary ones. In some
    instances of that kind of problem, the constraints allow us to deduce that the
    integer variables are bounded. For instance, if you have the constraint'
  prefs: []
  type: TYPE_NORMAL
- en: '![2a_{0} + 3a_{1} \leq 10](img/file475.png "2a_{0} + 3a_{1} \leq 10")'
  prefs: []
  type: TYPE_IMG
- en: then you can deduce that ![a_{0} \leq 5](img/file476.png "a_{0} \leq 5") and
    ![a_{1} \leq 3](img/file477.png "a_{1} \leq 3"). Since both ![a_{0}](img/file478.png
    "a_{0}") and ![a_{1}](img/file479.png "a_{1}") are non-negative, we can replace
    them with expressions in binary variables in the same way that we introduced slack
    variables for binary integer programs. In this case, for instance, we can replace
    ![a_{0}](img/file478.png "a_{0}") with ![x_{0} + 2x_{1} + 4x_{2}](img/file480.png
    "x_{0} + 2x_{1} + 4x_{2}") and ![a_{1}](img/file479.png "a_{1}") with ![x_{3}
    + 2x_{4}](img/file481.png "x_{3} + 2x_{4}"). In that manner, the integer linear
    program is transformed into an equivalent binary linear program that, in turn,
    can be written as a QUBO problem.
  prefs: []
  type: TYPE_NORMAL
- en: The procedure that we have studied in this section can be applied to transform
    any binary linear program into a QUBO problem. You only need to first introduce
    slack variables and then add penalty terms that substitute the original constraints.
    This is quite useful, since many important problems can be written directly as
    binary linear programs. In the next subsection, we will give a prominent example.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.2 The Knapsack problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the famous **Knapsack problem**, you are given a list of objects ![j = 0,\ldots,m](img/file408.png
    "j = 0,\ldots,m"), each of them with a weight ![w_{j}](img/file482.png "w_{j}")
    and a value ![c_{j}](img/file438.png "c_{j}"). You are also given a maximum weight
    ![W](img/file483.png "W") and the goal is to find a collection of objects that
    maximizes the total value without going over the maximum weight allowed. Think
    of it as if you were going on a journey and you want to pack as many valuable
    objects as possible without getting a knapsack that is too heavy to carry.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, you can have objects with values ![c_{0} = 5](img/file484.png
    "c_{0} = 5"), ![c_{1} = 3](img/file485.png "c_{1} = 3"), and ![c_{2} = 4](img/file486.png
    "c_{2} = 4") and weights ![w_{0} = 3](img/file487.png "w_{0} = 3"), ![w_{1} =
    1](img/file488.png "w_{1} = 1"), and ![w_{2} = 1](img/file489.png "w_{2} = 1").
    If the maximum weight is ![4](img/file143.png "4"), then the optimal solution
    would be to choose objects ![0](img/file12.png "0") and ![2](img/file302.png "2")
    for a total value of ![9](img/file490.png "9"). However, that solution is unfeasible
    if the maximum weight is ![3](img/file472.png "3"). In that case, we should choose
    objects ![1](img/file13.png "1") and ![2](img/file302.png "2") to obtain a total
    value of ![7](img/file465.png "7").
  prefs: []
  type: TYPE_NORMAL
- en: Although, at first sight, this problem may seem easy to solve, the fact is that
    (surprise, surprise!) it is ![NP](img/file2.png "NP")-hard. In fact, if we consider
    a decision version of the problem in which we are also given a value ![V](img/file379.png
    "V") and we are asked if there is a selection of objects with a value of at least
    ![V](img/file379.png "V") that also satisfies the weight constraint, then the
    problem is ![NP](img/file2.png "NP")-complete.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: Proving that the decision version of the Knapsack problem is ![NP](img/file2.png
    "NP")-complete is easy, because we already know that the Subset Sum problem is
    ![NP](img/file2.png "NP")-complete. Suppose, then, that you are given an instance
    of the Subset Sum problem with set ![S = \{ a_{0},\ldots,a_{m}\}](img/file406.png
    "S = \{ a_{0},\ldots,a_{m}\}") and target sum ![T](img/file74.png "T"). Then,
    you can recast this as an instance of the Knapsack problem by considering objects
    ![j = 0,\ldots,m](img/file408.png "j = 0,\ldots,m") with values ![c_{j} = a_{j}](img/file491.png
    "c_{j} = a_{j}") and weights ![w_{j} = a_{j}](img/file492.png "w_{j} = a_{j}"),
    maximum weight ![W = T](img/file493.png "W = T"), and minimum total value ![V
    = T](img/file494.png "V = T"). Then, a solution to the Knapsack decision problem
    will give you a selection of objects ![j_{0},\ldots,j_{k}](img/file495.png "j_{0},\ldots,j_{k}")
    such that ![a_{j_{0}} + \ldots + a_{j_{k}} \leq W = T](img/file496.png "a_{j_{0}}
    + \ldots + a_{j_{k}} \leq W = T") because of the weight constraint and such that
    ![a_{j_{0}} + \ldots + a_{j_{k}} \geq V = T](img/file497.png "a_{j_{0}} + \ldots
    + a_{j_{k}} \geq V = T") because of the minimum value condition. Obviously, that
    selection of objects would also be a solution to the Subset Sum problem.
  prefs: []
  type: TYPE_NORMAL
- en: It is straightforward to write the Knapsack problem as a binary linear program.
    We only need to define binary variables ![x_{j}](img/file407.png "x_{j}"), ![j
    = 0,\ldots,m](img/file408.png "j = 0,\ldots,m"), that indicate whether we choose
    object ![j](img/file258.png "j") (if ![x_{j} = 1](img/file498.png "x_{j} = 1"))
    or not (if ![x_{j} = 0](img/file499.png "x_{j} = 0")) and consider
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize}\quad} & {- c_{0}x_{0} - c_{1}x_{1} -
    \ldots - c_{m}x_{m}\qquad} & & \qquad \\ {\text{subject~to}\quad} & {w_{0}x_{0}
    + w_{1}x_{1} + \ldots + w_{m}x_{m} \leq W,\qquad} & & \qquad \\ & {x_{j} \in \{
    0,1\},\qquad j = 0,\ldots,m,\qquad} & & \qquad \\ \end{array}](img/file500.png
    "\begin{array}{rlrl} {\text{Minimize}\quad} & {- c_{0}x_{0} - c_{1}x_{1} - \ldots
    - c_{m}x_{m}\qquad} & & \qquad \\ {\text{subject~to}\quad} & {w_{0}x_{0} + w_{1}x_{1}
    + \ldots + w_{m}x_{m} \leq W,\qquad} & & \qquad \\  & {x_{j} \in \{ 0,1\},\qquad
    j = 0,\ldots,m,\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: where ![c_{j}](img/file438.png "c_{j}") are the object values, ![w_{j}](img/file482.png
    "w_{j}") are their weights, and ![W](img/file483.png "W") is the maximum weight
    of the knapsack. Notice that, since the original problem was asking to maximize
    the value, we are now minimizing the negative value, which is completely equivalent.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, in the example that we considered previously with object values
    ![5,3](img/file501.png "5,3"), and ![4](img/file143.png "4"), weights ![3,1](img/file502.png
    "3,1"), and ![1](img/file13.png "1"), and maximum weight ![3](img/file472.png
    "3"), the problem would be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize}\quad} & {- 5x_{0} - 3x_{1} - 4x_{2}\qquad}
    & & \qquad \\ {\text{subject~to}\quad} & {3x_{0} + x_{1} + x_{2} \leq 3,\qquad}
    & & \qquad \\ & {x_{j} \in \{ 0,1\},\qquad j = 0,1,2.\qquad} & & \qquad \\ \end{array}](img/file503.png
    "\begin{array}{rlrl} {\text{Minimize}\quad} & {- 5x_{0} - 3x_{1} - 4x_{2}\qquad}
    & & \qquad \\ {\text{subject~to}\quad} & {3x_{0} + x_{1} + x_{2} \leq 3,\qquad}
    & & \qquad \\  & {x_{j} \in \{ 0,1\},\qquad j = 0,1,2.\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: Of course, then we can add slack variables and introduce penalty terms, just
    as we did in the previous subsection, to rewrite the program as a QUBO problem.
    And that is exactly what we will need to do in order solve these problems with
    our quantum algorithms!
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.6
  prefs: []
  type: TYPE_NORMAL
- en: Consider objects with values ![3,1,7,7](img/file504.png "3,1,7,7") and weights
    ![2,1,5,4](img/file505.png "2,1,5,4"). Write the Knapsack problem for the case
    in which the maximum weight is ![8](img/file506.png "8") as a binary linear program.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: A variant of the Knapsack problem allows us to choose several copies of the
    same object to put into the knapsack. In that case, we should use integer variables
    instead of binary ones to represent the number of times that each object is chosen.
    However, notice that, once we know the maximum weight allowed, each integer variable
    is bounded. Thus, we can use the technique that we explained at the end of the
    previous subsection in order to replace the integer variables with binary variables.
    And, afterwards, of course, we can rewrite the problem using the QUBO formalism.
  prefs: []
  type: TYPE_NORMAL
- en: For our next examples of optimization problems, we shall go back to working
    with graphs. In fact, in the next subsection, we will deal with a very colorful
    problem!
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.3 Graph coloring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this subsection and the next, we will study some problems that are related
    to graphs but have many applications in different fields. The first one is graph
    coloring, in which we are given a graph and we are asked to assign a color to
    each vertex in such a way that vertices that are connected by an edge (also called
    **adjacent** vertices) receive different colors. Usually, we are asked to do this
    using the minimum possible number of colors or using no more than a given number
    of different colors. If we can color a graph with ![k](img/file317.png "k") colors,
    we say that it is ![k](img/file317.png "k")**-colorable**. The minimum number
    of colors needed to color a graph is called its **chromatic** **number**.
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure* *[*3.6*](#Figure3.6), we present three color assignments for the
    same graph. The one in *Figure* *[*3.6a*](#Figure3.6a) is not a valid coloring,
    because there are adjacent vertices that share the same color. The one in *Figure*
    *[*3.6b*](#Figure3.6b) is valid, but not optimal, because we do not need more
    than three colors for this graph, as *Figure* *[*3.6c*](#Figure3.6c) proves.****
  prefs: []
  type: TYPE_NORMAL
- en: '**![(a) Invalid coloring](img/file507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: '**(a)** Invalid coloring'
  prefs: []
  type: TYPE_NORMAL
- en: '![(b) Non-optimal coloring](img/file508.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**(b)** Non-optimal coloring'
  prefs: []
  type: TYPE_NORMAL
- en: '![(c) Optimal coloring](img/file509.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**(c)** Optimal coloring'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 3.6**: Different colorings of a graph'
  prefs: []
  type: TYPE_NORMAL
- en: The graph coloring problem may look like a children’s game. However, many very
    relevant practical problems can be written as instances of graph coloring. For
    example, imagine that your company has several projects and you need to assign
    supervisors to each of them, but some projects are incompatible because of time
    overlaps or other restrictions. You can create a graph in which the projects are
    the vertices and two projects are connected by an edge if and only if they are
    incompatible. Then, finding the chromatic number of the graph is equivalent to
    finding the minimum number of project leaders that you need to assign. Furthermore,
    finding a coloring will give you a way of assigning the supervisors while satisfying
    the constraints.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: 'The history of graph coloring dates back to the middle of the 19th century
    and it is full of surprising plot twists. It originated from a seemingly simple
    problem: finding the minimum number of colors needed in order to color a geographical
    map in such a way that any pair of neighboring countries receive different colors.
    But, in spite of its *humble* origins, it evolved to even become a philosophical
    debate about the validity of computer-assisted mathematical proofs!'
  prefs: []
  type: TYPE_NORMAL
- en: A very enjoyable popular recounting of this long and winding process can be
    found in *Four Colors Suffice*, by Robin Wilson [[98](ch030.xhtml#Xwilson2021four)].
  prefs: []
  type: TYPE_NORMAL
- en: Deciding whether a graph is ![2](img/file302.png "2")-colorable or not is relatively
    easy. Indeed, notice that the vertices of a ![2](img/file302.png "2")-colorable
    graph can be assigned to two disjoint sets depending on the color they receive
    and such that there are no edges among vertices of the same set — that’s why these
    graphs are said to be **bipartite graphs**. But it is a well-known fact (originally
    proved by König in 1936) that a graph is bipartite if and only if it has no **cycles**
    of odd length (refer to *Section 1.6* in the book by Diestel [[31](ch030.xhtml#Xdiestel2017graph)])
    and we can check for the presence of cycles by, for instance, computing the powers
    of the adjacency matrix of the graph (cf. *Section 10.4.7* in Rosen’s book on
    discrete mathematics [[81](ch030.xhtml#Xrosen2019discrete)]). However, checking
    if a graph is ![k](img/file317.png "k")-colorable is ![NP](img/file2.png "NP")-complete
    for any ![k \geq 3](img/file510.png "k \geq 3") (see the paper by Garey, Johnson,
    and Stockmeyer [[43](ch030.xhtml#Xgarey1976simplified)]) and, thus, computing
    the chromatic number of a graph is ![NP](img/file2.png "NP")-hard.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we have a graph with vertices ![0,\ldots,m](img/file511.png "0,\ldots,m").
    In order to write the problem of determining if a graph is ![k](img/file317.png
    "k")-colorable using the QUBO framework, we will define some binary variables
    ![x_{jl}](img/file512.png "x_{jl}") with ![j = 0,\ldots,m](img/file408.png "j
    = 0,\ldots,m") and ![l = 0,\ldots,k - 1](img/file513.png "l = 0,\ldots,k - 1").
    The variable ![x_{jl}](img/file512.png "x_{jl}") will get value ![1](img/file13.png
    "1") if the vertex ![j](img/file258.png "j") receives the ![l](img/file514.png
    "l")-th color (for simplicity, colors are usually identified with numbers) and
    ![0](img/file12.png "0") otherwise. Then, the condition that vertex ![j](img/file258.png
    "j") receives exactly one color can be algebraically written as
  prefs: []
  type: TYPE_NORMAL
- en: '![\sum\limits_{l = 0}^{k - 1}x_{jl} = 1.](img/file515.png "\sum\limits_{l =
    0}^{k - 1}x_{jl} = 1.")'
  prefs: []
  type: TYPE_IMG
- en: For this condition to hold, there must exist ![l](img/file514.png "l") such
    that ![x_{jl} = 1](img/file516.png "x_{jl} = 1") and such that ![x_{jh} = 0](img/file517.png
    "x_{jh} = 0") for any ![h \neq l](img/file518.png "h \neq l"), exactly as we need.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, we need to impose the constraint that adjacent vertices are
    not assigned the same color. Notice that in the case that two vertices ![j](img/file258.png
    "j") and ![h](img/file519.png "h") receive the same color ![l](img/file514.png
    "l"), then we would have ![x_{jl}x_{hl} = 1](img/file520.png "x_{jl}x_{hl} = 1").
    Thus, for adjacent vertices ![j](img/file258.png "j") and ![h](img/file519.png
    "h") we need to impose
  prefs: []
  type: TYPE_NORMAL
- en: '![\sum\limits_{l = 0}^{k - 1}x_{jl}x_{hl} = 0.](img/file521.png "\sum\limits_{l
    = 0}^{k - 1}x_{jl}x_{hl} = 0.")'
  prefs: []
  type: TYPE_IMG
- en: We can write these constraints as penalty terms in the expression to minimize
    in our QUBO problem to get
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize}\quad} & {\sum\limits_{j = 0}^{m}\left(
    {\sum\limits_{l = 0}^{k - 1}x_{jl} - 1} \right)^{2} + \sum\limits_{(j,h) \in E}\sum\limits_{l
    = 0}^{k - 1}x_{jl}x_{hl}\qquad} & & \qquad \\ {\text{subject~to}\quad} & {x_{jl}
    \in \{ 0,1\},\qquad j = 0,\ldots,m,l = 0,\ldots,k - 1,\qquad} & & \qquad \\ \end{array}](img/file522.png
    "\begin{array}{rlrl} {\text{Minimize}\quad} & {\sum\limits_{j = 0}^{m}\left( {\sum\limits_{l
    = 0}^{k - 1}x_{jl} - 1} \right)^{2} + \sum\limits_{(j,h) \in E}\sum\limits_{l
    = 0}^{k - 1}x_{jl}x_{hl}\qquad} & & \qquad \\ {\text{subject~to}\quad} & {x_{jl}
    \in \{ 0,1\},\qquad j = 0,\ldots,m,l = 0,\ldots,k - 1,\qquad} & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: where ![E](img/file327.png "E") is the set of edges of the graph. Notice that
    we do not need to square the terms ![{\sum}_{l = 0}^{k - 1}x_{jl}x_{hl}](img/file523.png
    "{\sum}_{l = 0}^{k - 1}x_{jl}x_{hl}") because they are always non-negative. If
    we find that the optimal solution of the problem is ![0](img/file12.png "0"),
    then the graph is ![k](img/file317.png "k")-colorable. Otherwise, it is not.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.7
  prefs: []
  type: TYPE_NORMAL
- en: Consider a graph with vertices ![0,1,2](img/file524.png "0,1,2"), and ![3](img/file472.png
    "3"), and edges ![(0,1)](img/file305.png "(0,1)"), ![(0,2)](img/file306.png "(0,2)"),
    ![(1,3)](img/file525.png "(1,3)"), and ![(2,3)](img/file526.png "(2,3)"). Write
    the QUBO version of the problem of checking whether the graph is ![2](img/file302.png
    "2")-colorable.
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will study another optimization problem on graphs.
    Do you like traveling? Then, prepare yourself to optimize your travel plans with
    the help of QUBO formalism.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.4 The Traveling Salesperson Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **Traveling Salesperson Problem** (or, simply, **TSP**) is one of the most
    famous problems in combinatorial optimization. The goal of the problem is very
    simple to state: you need to find a route that goes through each of the cities
    in a given set once and only once while minimizing some global quantity (distance
    traveled, time spent, total cost...).'
  prefs: []
  type: TYPE_NORMAL
- en: We can formulate the problem mathematically using graphs. In this formulation,
    we would be given a set of vertices ![j = 0,\ldots,m](img/file408.png "j = 0,\ldots,m")
    representing the cities, and, for each pair of vertices ![j](img/file258.png "j")
    and ![l](img/file514.png "l"), we would also be given the cost ![w_{jl}](img/file527.png
    "w_{jl}") of traveling from ![j](img/file258.png "j") to ![l](img/file514.png
    "l") (this cost does not need to be the same, in general, as ![w_{lj}](img/file528.png
    "w_{lj}")). We then need to find a **path** in the graph (that is, a set of edges
    such that the end of an edge is the beginning of the next one) that visits each
    vertex once and only once and that minimizes the sum of the costs of all the edges
    used.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: As you have probably guessed, the TSP is ![NP](img/file2.png "NP")-hard (refer
    to *Chapter 15* in the book on combinatorial optimization by Korte and Vygen [[61](ch030.xhtml#Xkorte2012combinatorial)]
    for more details). In fact, given a graph, a set of costs for the edges and a
    value ![C](img/file234.png "C"), it is ![NP](img/file2.png "NP")-complete to decide
    whether there is a path that visits all the cities and has a cost less than or
    equal to ![C](img/file234.png "C").
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in *Figure* *[*3.7*](#Figure3.7) we can see a TSP instance with
    four cities. The numbers that appear to label the edges are their costs. For simplicity,
    we have assumed that for every pair of vertices, the travel cost is, in this case,
    the same in both directions.*
  prefs: []
  type: TYPE_NORMAL
- en: '*![Figure 3.7: An example of the Traveling Salesperson Problem](img/file529.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 3.7**: An example of the Traveling Salesperson Problem'
  prefs: []
  type: TYPE_NORMAL
- en: To formulate the TSP in the QUBO framework, we will define binary variables
    ![x_{jl}](img/file512.png "x_{jl}") that will indicate the order of visiting the
    different vertices. More concretely, if vertex ![j](img/file258.png "j") is the
    ![l](img/file514.png "l")-th in the tour, then ![x_{jl}](img/file512.png "x_{jl}")
    will be ![1](img/file13.png "1") and ![x_{jh}](img/file530.png "x_{jh}") will
    be ![0](img/file12.png "0") for ![h \neq l](img/file518.png "h \neq l"). Thus,
    for every vertex ![j](img/file258.png "j"), we need to impose the constraint
  prefs: []
  type: TYPE_NORMAL
- en: '![\sum\limits_{l = 0}^{m}x_{jl} = 1,](img/file531.png "\sum\limits_{l = 0}^{m}x_{jl}
    = 1,")'
  prefs: []
  type: TYPE_IMG
- en: because every vertex needs to be visited exactly once. But we also need to impose
  prefs: []
  type: TYPE_NORMAL
- en: '![\sum\limits_{j = 0}^{m}x_{jl} = 1](img/file532.png "\sum\limits_{j = 0}^{m}x_{jl}
    = 1")'
  prefs: []
  type: TYPE_IMG
- en: for every position ![l](img/file514.png "l"), because we can only visit one
    city at a time.
  prefs: []
  type: TYPE_NORMAL
- en: If those two constraints are met, we will have a path that visits every vertex
    once and only once. However, that is not enough. We also want to minimize the
    total cost of the path, so we need an expression that gives us that cost in terms
    of the ![x_{jl}](img/file512.png "x_{jl}") variables. Notice that an edge ![(j,k)](img/file356.png
    "(j,k)") is used if and only if the vertices ![j](img/file258.png "j") and ![k](img/file317.png
    "k") are consecutive in the path. That is, if and only if there exists an ![l](img/file514.png
    "l") such that ![j](img/file258.png "j") is visited in position ![l](img/file514.png
    "l") and ![k](img/file317.png "k") is visited in position ![l + 1](img/file533.png
    "l + 1"). In that case, the cost of using the edge will be given by ![w_{jk}x_{jl}x_{kl
    + 1}](img/file534.png "w_{jk}x_{jl}x_{kl + 1}"), because ![x_{jl}x_{kl + 1} =
    1](img/file535.png "x_{jl}x_{kl + 1} = 1"). But if ![j](img/file258.png "j") and
    ![k](img/file317.png "k") are not consecutive in the path, then ![x_{jl}x_{kl
    + 1} = 0](img/file536.png "x_{jl}x_{kl + 1} = 0") for every ![l](img/file514.png
    "l"), which is also the cost of that path in our route — we are not using it,
    so we don’t pay for it!
  prefs: []
  type: TYPE_NORMAL
- en: Thus, the total cost of the tour is given by
  prefs: []
  type: TYPE_NORMAL
- en: '![\sum\limits_{l = 0}^{m - 1}\sum\limits_{j = 0}^{m}\sum\limits_{k = 0}^{m}w_{jk}x_{jl}x_{kl
    + 1},](img/file537.png "\sum\limits_{l = 0}^{m - 1}\sum\limits_{j = 0}^{m}\sum\limits_{k
    = 0}^{m}w_{jk}x_{jl}x_{kl + 1},")'
  prefs: []
  type: TYPE_IMG
- en: where we are assuming that ![w_{jj} = 0](img/file538.png "w_{jj} = 0") for ![j
    = 0,\ldots,m](img/file408.png "j = 0,\ldots,m") — staying in the same place costs
    nothing!
  prefs: []
  type: TYPE_NORMAL
- en: Then, we can incorporate the constraints as penalty terms in the function to
    minimize and write the TSP problem as
  prefs: []
  type: TYPE_NORMAL
- en: '![\begin{array}{rlrl} {\text{Minimize}\quad} & {\sum\limits_{l = 0}^{m - 1}\sum\limits_{j
    = 0}^{m}\sum\limits_{k = 0}^{m}w_{jk}x_{jl}x_{kl + 1} + B\left( {\sum\limits_{l
    = 0}^{m}x_{jl} - 1} \right)^{2} + B\left( {\sum\limits_{j = 0}^{m}x_{jl} - 1}
    \right)^{2}\qquad} & & \qquad \\ {\text{subject~to}\quad} & {x_{jl} \in \{ 0,1\},\qquad
    j,l = 0,\ldots,m,\qquad} & & \qquad \\ \end{array}](img/file539.png "\begin{array}{rlrl}
    {\text{Minimize}\quad} & {\sum\limits_{l = 0}^{m - 1}\sum\limits_{j = 0}^{m}\sum\limits_{k
    = 0}^{m}w_{jk}x_{jl}x_{kl + 1} + B\left( {\sum\limits_{l = 0}^{m}x_{jl} - 1} \right)^{2}
    + B\left( {\sum\limits_{j = 0}^{m}x_{jl} - 1} \right)^{2}\qquad} & & \qquad \\
    {\text{subject~to}\quad} & {x_{jl} \in \{ 0,1\},\qquad j,l = 0,\ldots,m,\qquad}
    & & \qquad \\ \end{array}")'
  prefs: []
  type: TYPE_IMG
- en: where ![B](img/file184.png "B") is chosen so that unfeasible solutions never
    achieve an optimal value. For instance, if we select
  prefs: []
  type: TYPE_NORMAL
- en: '![B = 1 + \sum\limits_{j,k = 0}^{m}w_{jk},](img/file540.png "B = 1 + \sum\limits_{j,k
    = 0}^{m}w_{jk},")'
  prefs: []
  type: TYPE_IMG
- en: then those solutions that violate the constraints will get a penalty that is
    bigger than the cost of any valid tour and will not be selected as optimal.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 3.8
  prefs: []
  type: TYPE_NORMAL
- en: Obtain the expression for the route cost in the TSP problem with the graph in
    *Figure* *[*3.7*](#Figure3.7).*
  prefs: []
  type: TYPE_NORMAL
- en: '*We have shown how to formulate several important problems in the QUBO formalism.
    But the ones that we have focused on are not, by any means, the only ones that
    these techniques can address. In the next subsection, we will give you a couple
    of hints of where to look for more.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.5 Other problems and other formulations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we have introduced the Ising and QUBO models and we have shown
    how to use them to formulate combinatorial optimization problems. In fact, in
    the last part of the chapter, we have studied several famous problems, including
    binary linear programming and the Traveling Salesperson Problem, and we have given
    QUBO formulations for them.
  prefs: []
  type: TYPE_NORMAL
- en: The possibility of using these frameworks to formulate optimization problems
    is not reduced to the examples that we have worked with. Other important problems
    that can be readily written as QUBO and Ising instances include finding cliques
    in graphs, determining whether a logic formula is satisfiable, and scheduling
    jobs under constraints. Using the techniques described in this chapter, you are
    now equipped to write your own formulations for these and other problems.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is useful to have some references to problems that have already
    been formulated as QUBO instances to be used out of the box or to serve as inspiration
    if your problem doesn’t exactly fit any of them. A good survey of such formulations
    is the one compiled by Lucas [[65](ch030.xhtml#Xlucas2014ising)], which includes
    all 21 of Karp’s ![NP](img/file2.png "NP")-complete problems and more.
  prefs: []
  type: TYPE_NORMAL
- en: An important thing that you should always keep in mind when using the QUBO framework
    is that, usually, there is more than just one way of formulating a problem. For
    example, sometimes it is straightforward to state a problem as a binary linear
    program and then use the transformations that we have studied to obtain a QUBO
    and, eventually, an Ising version of the problem. Nevertheless, it could be possible
    that with a different approach, you may find a more compact formulation that reduces,
    for instance, the number of variables or the length of the expression to minimize.
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, the comparison of alternative QUBO formulations of important
    combinatorial optimization problems has become a very active research area. It
    is good advice to keep an open mind (and an eye on the scientific literature)
    because, in many cases, choosing the right formulation can be a crucial factor
    to obtain better results when using quantum computers to solve optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  prefs: []
  type: TYPE_NORMAL
- en: A recent paper by Salehi, Glos, and Miszczak [[83](ch030.xhtml#Xsalehi2022unconstrained)]
    addresses the task of representing the TSP and some of its variants with QUBO
    formalism and studies how different formulations can affect the performance of
    quantum optimization algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Our next stop will be using actual quantum devices to solve the type of problem
    that we have been focusing on in this chapter. Get ready to learn how to use quantum
    annealers!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has been devoted to introducing two different mathematical frameworks,
    the Ising model and the QUBO formalism, which allow us to write combinatorial
    optimization problems in a way that we will later be able to use to find approximate
    solutions with the help of quantum computers. We started with some simple examples
    and worked our way up to some famous problems such as graph coloring and the Traveling
    Salesperson Problem.
  prefs: []
  type: TYPE_NORMAL
- en: In order to achieve that, we studied different techniques that find wider applications
    in the process of writing optimization problems for quantum computers. We saw,
    for example, how to use slack variables and how to replace constraints with penalty
    terms. We also learned how to transform integer variables into a series of binary
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: After all that we have covered in this chapter, you are now prepared to write
    your own problems in the languages required by optimization algorithms that can
    run on quantum computers. The rest of the chapters in this part of the book will
    be devoted to learning how to implement and run those quantum optimization algorithms.
    In fact, in the next chapter, we will explain how to use a type of quantum computer
    called a **quantum annealer** to solve QUBO and Ising problems.*****************************************
  prefs: []
  type: TYPE_NORMAL
