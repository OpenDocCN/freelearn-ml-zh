["```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.linear_model import LinearRegression\n    from sklearn.impute import SimpleImputer\n    from sklearn.pipeline import make_pipeline\n    from sklearn.compose import ColumnTransformer\n    from sklearn.compose import TransformedTargetRegressor\n    from sklearn.feature_selection import RFE\n    from sklearn.impute import KNNImputer\n    from sklearn.model_selection import cross_validate, KFold\n    import sklearn.metrics as skmet\n    import matplotlib.pyplot as plt\n    ```", "```py\nimport os\nimport sys\nsys.path.append(os.getcwd() + “/helperfunctions”)\nfrom preprocfunc import OutlierTrans\n```", "```py\nclass OutlierTrans(BaseEstimator,TransformerMixin):\n  def __init__(self,threshold=1.5):\n    self.threshold = threshold\n\n  def fit(self,X,y=None):\n    return self\n\n  def transform(self,X,y=None):\n    Xnew = X.copy()\n    for col in Xnew.columns:\n      thirdq, firstq = Xnew[col].quantile(0.75),\\\n        Xnew[col].quantile(0.25)\n      interquartilerange = self.threshold*(thirdq-firstq)\n      outlierhigh, outlierlow = interquartilerange+thirdq,\\\n        firstq-interquartilerange\n      Xnew.loc[(Xnew[col]>outlierhigh) | \\\n        (Xnew[col]<outlierlow),col] = np.nan\n    return Xnew.values\n```", "```py\n    fftaxrate14 = pd.read_csv(“data/fossilfueltaxrate14.csv”)\n    fftaxrate14.set_index(‘countrycode’, inplace=True)\n    fftaxrate14.info()\n    <class ‘pandas.core.frame.DataFrame’>\n    Index: 154 entries, AFG to ZWE\n    Data columns (total 19 columns):\n    #   Column                     Non-Null Count  Dtype\n                                   --------------  -----  \n    0   country                    154 non-null    object\n    1   region                     154 non-null    object\n    2   region_wb                  154 non-null    object\n    3   year                       154 non-null    int64\n    4   gas_tax_imp                154 non-null    float64\n    5   bmgap_diesel_spotprice_la  146 non-null    float64\n    6   fuel_income_dependence     152 non-null    float64\n    7   national_income_per_cap    152 non-null    float64\n    8   VAT_Rate                   151 non-null    float64\n    9   gov_debt_per_gdp           139 non-null    float64\n    10  polity                     151 non-null    float64\n    11  democracy_polity           151 non-null    float64\n    12  autocracy_polity           151 non-null    float64\n    13  goveffect                  154 non-null    float64\n    14  democracy_index            152 non-null    float64\n    15  democracy                  154 non-null    int64\n    16  nat_oil_comp               152 non-null    float64\n    17  nat_oil_comp_state         152 non-null    float64\n    18  motorization_rate          127 non-null    float64\n    dtypes: float64(14), int64(2), object(3)\n    memory usage: 24.1+ KB\n    ```", "```py\n    num_cols = [‘fuel_income_dependence’, \n      ’national_income_per_cap’, ‘VAT_Rate’,  \n      ‘gov_debt_per_gdp’, ’polity’, ’goveffect’,\n      ‘democracy_index’]\n    dummy_cols = ‘democracy_polity’,’autocracy_polity’,\n      ‘democracy’,’nat_oil_comp’,’nat_oil_comp_state’]\n    spec_cols = [‘motorization_rate’]\n    ```", "```py\n    fftaxrate14[[‘gas_tax_imp’] + num_cols + spec_cols].\\\n      agg([‘count’,’min’,’median’,’max’]).T\n                          count min    median   max\n    gas_tax_imp             154 -0.80  0.52     1.73\n    fuel_income_dependence  152 0.00   0.14     34.43\n    national_income_per_cap 152 260.00 6,050.00 104,540.00\n    VAT_Rate                151 0.00   16.50    27.00\n    gov_debt_per_gdp        139 0.55   39.30    194.76\n    polity                  151 -10.00 7.00     10.00\n    goveffect               154 -2.04  -0.15    2.18\n    democracy_index         152 0.03   0.57     0.93\n    motorization_rate       127 0.00   0.20     0.81\n    ```", "```py\n    fftaxrate14[dummy_cols].apply(pd.value_counts, normalize=True).T\n                                   0               1\n    democracy_polity               0.41            0.59\n    autocracy_polity               0.89            0.11\n    democracy                      0.42            0.58\n    nat_oil_comp                   0.54            0.46\n    nat_oil_comp_state             0.77            0.23\n    ```", "```py\n    target = fftaxrate14[[‘gas_tax_imp’]]\n    features = fftaxrate14[num_cols + dummy_cols + spec_cols]\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(features,\\\n      target, test_size=0.2, random_state=0)\n    ```", "```py\nstandtrans = make_pipeline(OutlierTrans(2), \n  SimpleImputer(strategy=”median”), StandardScaler())\ncattrans = make_pipeline(\n  SimpleImputer(strategy=”most_frequent”))\nspectrans = make_pipeline(OutlierTrans(2), \n  StandardScaler())\ncoltrans = ColumnTransformer(\n  transformers=[\n    (“stand”, standtrans, num_cols),\n    (“cat”, cattrans, dummy_cols),\n    (“spec”, spectrans, spec_cols)\n  ]\n)\n```", "```py\nlr = LinearRegression()\nrfe = RFE(estimator=lr, n_features_to_select=7)\npipe1 = make_pipeline(coltrans, \n  KNNImputer(n_neighbors=5), rfe, lr)\nttr=TransformedTargetRegressor(regressor=pipe1,\n  transformer=StandardScaler())\nttr.fit(X_train, y_train)\nselcols = X_train.columns[ttr.regressor_.named_steps[‘rfe’].support_]\ncoefs = ttr.regressor_.named_steps[‘linearregression’].coef_\nnp.column_stack((coefs.ravel(),selcols))\narray([[0.44753064726665703, ‘VAT_Rate’],\n       [0.12368913577287821, ‘gov_debt_per_gdp’],\n       [0.17926454403985687, ‘goveffect’],\n       [-0.22100930246392841, ‘autocracy_polity’],\n       [-0.15726572731003752, ‘nat_oil_comp’],\n       [-0.7013454686632653, ‘nat_oil_comp_state’],\n       [0.13855012574945422, ‘motorization_rate’]], dtype=object)\n```", "```py\n    pred = ttr.predict(X_test)\n    preddf = pd.DataFrame(pred, columns=[‘prediction’],\n      index=X_test.index).join(X_test).join(y_test)\n    preddf[‘resid’] = preddf.gas_tax_imp-preddf.prediction\n    preddf.resid.agg([‘mean’,’median’,’skew’,’kurtosis’])\n    mean                -0.09\n    median              -0.13\n    skew                 0.61\n    kurtosis             0.04\n    Name: resid, dtype: float64\n    ```", "```py\n    print(“Mean Absolute Error: %.2f, R-squared: %.2f” % \n      (skmet.mean_absolute_error(y_test, pred),\n      skmet.r2_score(y_test, pred)))\n    Mean Absolute Error: 0.23, R-squared: 0.75\n    ```", "```py\n    plt.hist(preddf.resid, color=”blue”, bins=np.arange(-0.5,1.0,0.25))\n    plt.axvline(preddf.resid.mean(), color=’red’, linestyle=’dashed’, linewidth=1)\n    plt.title(“Histogram of Residuals for Gax Tax Model”)\n    plt.xlabel(“Residuals”)\n    plt.ylabel(“Frequency”)\n    plt.xlim()\n    plt.show()\n    ```", "```py\n    plt.scatter(preddf.prediction, preddf.resid, color=”blue”)\n    plt.axhline(0, color=’red’, linestyle=’dashed’, linewidth=1)\n    plt.title(“Scatterplot of Predictions and Residuals”)\n    plt.xlabel(“Predicted Gax Tax”)\n    plt.ylabel(“Residuals”)\n    plt.show()\n    ```", "```py\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(features,\\\n      target, test_size=0.1, random_state=1)\n    ```", "```py\n    kf = KFold(n_splits=3, shuffle=True, random_state=0)\n    ```", "```py\n    scores = cross_validate(ttr, X=X_train, y=y_train,\n      cv=kf, scoring=(‘r2’, ‘neg_mean_absolute_error’), n_jobs=1)\n    print(“Mean Absolute Error: %.2f, R-squared: %.2f” % \n      (scores[‘test_neg_mean_absolute_error’].mean(),\n      scores[‘test_r2’].mean()))\n    Mean Absolute Error: -0.25, R-squared: 0.62\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.linear_model import Lasso\n    from sklearn.impute import SimpleImputer\n    from sklearn.pipeline import make_pipeline\n    from sklearn.compose import ColumnTransformer\n    from sklearn.compose import TransformedTargetRegressor\n    from sklearn.model_selection import cross_validate, KFold\n    import sklearn.metrics as skmet\n    import matplotlib.pyplot as plt\n    ```", "```py\n    import os\n    import sys\n    sys.path.append(os.getcwd() + “/helperfunctions”)\n    from preprocfunc import OutlierTrans\n    ```", "```py\n    fftaxrate14 = pd.read_csv(“data/fossilfueltaxrate14.csv”)\n    fftaxrate14.set_index(‘countrycode’, inplace=True)\n    num_cols = [‘fuel_income_dependence’,’national_income_per_cap’,\n      ‘VAT_Rate’,  ‘gov_debt_per_gdp’,’polity’,’goveffect’,\n      ‘democracy_index’]\n    dummy_cols = [‘democracy_polity’,’autocracy_polity’,\n    ‘democracy’,’nat_oil_comp’,’nat_oil_comp_state’]\n    spec_cols = [‘motorization_rate’]\n    target = fftaxrate14[[‘gas_tax_imp’]]\n    features = fftaxrate14[num_cols + dummy_cols + spec_cols]\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(features,\\\n      target, test_size=0.2, random_state=0)\n    ```", "```py\n    standtrans = make_pipeline(\n      OutlierTrans(2), SimpleImputer(strategy=”median”),\n      StandardScaler())\n    cattrans = make_pipeline(SimpleImputer(strategy=”most_frequent”))\n    spectrans = make_pipeline(OutlierTrans(2), StandardScaler())\n    coltrans = ColumnTransformer(\n      transformers=[\n        (“stand”, standtrans, num_cols),\n        (“cat”, cattrans, dummy_cols),\n        (“spec”, spectrans, spec_cols)\n      ]\n    )\n    ```", "```py\n    lasso = Lasso(alpha=0.1,fit_intercept=False)\n    pipe1 = make_pipeline(coltrans, KNNImputer(n_neighbors=5), lasso)\n    ttr=TransformedTargetRegressor(regressor=pipe1,transformer=StandardScaler())\n    ttr.fit(X_train, y_train)\n    ```", "```py\n    coefs = ttr.regressor_[‘lasso’].coef_\n    np.column_stack((coefs.ravel(), num_cols + dummy_cols + spec_cols))\n    array([[‘-0.0026505240129231175’, ‘fuel_income_dependence’],\n           [‘0.0’, ‘national_income_per_cap’],\n           [‘0.43472262042825915’, ‘VAT_Rate’],\n           [‘0.10927136643326674’, ‘gov_debt_per_gdp’],\n           [‘0.006825858127837494’, ‘polity’],\n           [‘0.15823493727828816’, ‘goveffect’],\n           [‘0.09622123660935211’, ‘democracy_index’],\n           [‘0.0’, ‘democracy_polity’],\n           [‘-0.0’, ‘autocracy_polity’],\n           [‘0.0’, ‘democracy’],\n           [‘-0.0’, ‘nat_oil_comp’],\n           [‘-0.2199638245781246’, ‘nat_oil_comp_state’],\n           [‘0.016680304258453165’, ‘motorization_rate’]], dtype=’<U32’)\n    ```", "```py\n    pred = ttr.predict(X_test)\n    preddf = pd.DataFrame(pred, columns=[‘prediction’],\n      index=X_test.index).join(X_test).join(y_test)\n    preddf[‘resid’] = preddf.gas_tax_imp-preddf.prediction\n    preddf.resid.agg([‘mean’,’median’,’skew’,’kurtosis’])\n    mean                 -0.06\n    median               -0.07\n    skew                  0.33\n    kurtosis              0.10\n    Name: resid, dtype: float64\n    ```", "```py\n    print(“Mean Absolute Error: %.2f, R-squared: %.2f” % \n      (skmet.mean_absolute_error(y_test, pred),\n      skmet.r2_score(y_test, pred)))\n    Mean Absolute Error: 0.24, R-squared: 0.68\n    ```", "```py\n    plt.hist(preddf.resid, color=”blue”, bins=np.arange(-0.5,1.0,0.25))\n    plt.axvline(preddf.resid.mean(), color=’red’, linestyle=’dashed’, linewidth=1)\n    plt.title(“Histogram of Residuals for Gax Tax Model”)\n    plt.xlabel(“Residuals”)\n    plt.ylabel(“Frequency”)\n    plt.show()\n    ```", "```py\n    plt.scatter(preddf.prediction, preddf.resid, color=”blue”)\n    plt.axhline(0, color=’red’, linestyle=’dashed’, linewidth=1)\n    plt.title(“Scatterplot of Predictions and Residuals”)\n    plt.xlabel(“Predicted Gax Tax”)\n    plt.ylabel(“Residuals”)\n    plt.show()\n    ```", "```py\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(features,\\\n      target, test_size=0.1, random_state=22)\n    kf = KFold(n_splits=4, shuffle=True, random_state=0)\n    scores = cross_validate(ttr, X=X_train, y=y_train,\n      cv=kf, scoring=(‘r2’, ‘neg_mean_absolute_error’), n_jobs=1)\n    print(“Mean Absolute Error: %.2f, R-squared: %.2f” % \n      (scores[‘test_neg_mean_absolute_error’].mean(),\n      scores[‘test_r2’].mean()))\n    Mean Absolute Error: -0.27, R-squared: 0.57\n    ```", "```py\n    lasso = Lasso()\n    lasso_params = {‘regressor__lasso__alpha’: np.arange(0.05, 1, 0.05)}\n    ```", "```py\n    gs = GridSearchCV(ttr,param_grid=lasso_params, cv=5)\n    gs.fit(X_train, y_train)\n    gs.best_params_\n    {‘regressor__lasso__alpha’: 0.05}\n    gs.best_score_\n    0.6028804486340877\n    ```", "```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n    from sklearn.linear_model import LinearRegression\n    from sklearn.pipeline import make_pipeline\n    from sklearn.model_selection import cross_validate\n    from sklearn.model_selection import KFold\n    from sklearn.impute import KNNImputer\n    import matplotlib.pyplot as plt\n    ```", "```py\n    import os\n    import sys\n    sys.path.append(os.getcwd() + “/helperfunctions”)\n    from preprocfunc import OutlierTrans\n    ```", "```py\n    landtemps = pd.read_csv(“data/landtempsb2019avgs.csv”)\n    landtemps.set_index(‘locationid’, inplace=True)\n    feature_cols = [‘latabs’,’elevation’]\n    landtemps[[‘avgtemp’] + feature_cols].\\\n      agg([‘count’,’min’,’median’,’max’]).T\n                 count      min      median    max\n    avgtemp      12,095    -60.82    10.45     33.93\n    latabs       12,095     0.02     40.67     90.00\n    elevation    12,088    -350.00   271.30    4,701.00\n    ```", "```py\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(landtemps[feature_cols],\\\n      landtemps[[‘avgtemp’]], test_size=0.1, random_state=0)\n    ```", "```py\n    lr = LinearRegression()\n    knnimp = KNNImputer(n_neighbors=45)\n    pipe1 = make_pipeline(OutlierTrans(3),knnimp,\n      StandardScaler(), lr)\n    ttr=TransformedTargetRegressor(regressor=pipe1,\n      transformer=StandardScaler())\n    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n    scores = cross_validate(ttr, X=X_train, y=y_train,\n      cv=kf, scoring=(‘r2’, ‘neg_mean_absolute_error’), n_jobs=1)\n    scores[‘test_r2’].mean(), scores[‘test_neg_mean_absolute_error’].mean()\n    (0.7933471824738406, -2.8047627785750913)\n    ```", "```py\n    ttr.fit(X_train, y_train)\n    pred = ttr.predict(X_test)\n    preddf = pd.DataFrame(pred, columns=[‘prediction’],\n      index=X_test.index).join(X_test).join(y_test)\n    preddf.resid.agg([‘mean’,’median’,’skew’,’kurtosis’])\n    mean                 0.00\n    median               0.50\n    skew                -1.13\n    kurtosis             3.48\n    Name: resid, dtype: float64\n    ```", "```py\n    plt.hist(preddf.resid, color=”blue”)\n    plt.axvline(preddf.resid.mean(), color=’red’, \n      linestyle=’dashed’, linewidth=1)\n    plt.title(“Histogram of Residuals for Linear Model of Temperature”)\n    plt.xlabel(“Residuals”)\n    plt.ylabel(“Frequency”)\n    plt.show()\n    ```", "```py\n    plt.scatter(preddf.prediction, preddf.resid, color=”blue”)\n    plt.axhline(0, color=’red’, linestyle=’dashed’, linewidth=1)\n    plt.title(“Scatterplot of Predictions and Residuals”)\n    plt.xlabel(“Predicted Temperature”)\n    plt.ylabel(“Residuals”)\n    plt.xlim(-20,40)\n    plt.ylim(-27,10)\n    plt.show()\n    ```", "```py\n    polytrans = PolynomialFeatures(degree=4, include_bias=False)\n    polytrans.fit(X_train.dropna())\n    featurenames = polytrans.get_feature_names(feature_cols)\n    featurenames\n    [‘latabs’,\n     ‘elevation’,\n     ‘latabs^2’,\n     ‘latabs elevation’,\n     ‘elevation^2’,\n     ‘latabs^3’,\n     ‘latabs^2 elevation’,\n     ‘latabs elevation^2’,\n     ‘elevation^3’,\n     ‘latabs^4’,\n     ‘latabs^3 elevation’,\n     ‘latabs^2 elevation^2’,\n     ‘latabs elevation^3’,\n     ‘elevation^4’]\n    ```", "```py\n    pipe2 = make_pipeline(OutlierTrans(3), knnimp,\n      polytrans, StandardScaler(), lr)\n    ttr2 = TransformedTargetRegressor(regressor=pipe2,\\\n      transformer=StandardScaler())\n    ```", "```py\n    ttr2.fit(X_train, y_train)\n    pred = ttr2.predict(X_test)\n    preddf = pd.DataFrame(pred, columns=[‘prediction’],\n      index=X_test.index).join(X_test).join(y_test)\n    preddf[‘resid’] = preddf.avgtemp-preddf.prediction\n    preddf.resid.agg([‘mean’,’median’,’skew’,’kurtosis’])\n    mean                 0.01\n    median               0.20\n    skew                -0.98\n    kurtosis             3.34\n    Name: resid, dtype: float64\n    ```", "```py\n    plt.hist(preddf.resid, color=”blue”)\n    plt.axvline(preddf.resid.mean(), color=’red’, linestyle=’dashed’, linewidth=1)\n    plt.title(“Histogram of Residuals for Temperature Model”)\n    plt.xlabel(“Residuals”)\n    plt.ylabel(“Frequency”)\n    plt.show()\n    ```", "```py\n    plt.scatter(preddf.prediction, preddf.resid, color=”blue”)\n    plt.axhline(0, color=’red’, linestyle=’dashed’, linewidth=1)\n    plt.title(“Scatterplot of Predictions and Residuals”)\n    plt.xlabel(“Predicted Temperature”)\n    plt.ylabel(“Residuals”)\n    plt.xlim(-20,40)\n    plt.ylim(-27,10)\n    plt.show()\n    ```", "```py\n    scores = cross_validate(ttr2, X=X_train, y=y_train,\n      cv=kf, scoring=(‘r2’, ‘neg_mean_absolute_error’),\n      n_jobs=1)\n    scores[‘test_r2’].mean(), scores[‘test_neg_mean_absolute_error’].mean()\n    (0.8323274036342788, -2.4035803290965507)\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.linear_model import SGDRegressor\n    from sklearn.compose import TransformedTargetRegressor\n    from sklearn.pipeline import make_pipeline\n    from sklearn.impute import KNNImputer\n    from sklearn.model_selection import GridSearchCV\n    import os\n    import sys\n    sys.path.append(os.getcwd() + “/helperfunctions”)\n    from preprocfunc import OutlierTrans\n    ```", "```py\n    landtemps = pd.read_csv(“data/landtempsb2019avgs.csv”)\n    landtemps.set_index(‘locationid’, inplace=True)\n    feature_cols = [‘latabs’,’elevation’]\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(landtemps[feature_cols],\\\n      landtemps[[‘avgtemp’]], test_size=0.1, random_state=0)\n    ```", "```py\n    knnimp = KNNImputer(n_neighbors=45)\n    sgdr = SGDRegressor()\n    pipe1 = make_pipeline(OutlierTrans(3),knnimp,StandardScaler(), sgdr)\n    ttr=TransformedTargetRegressor(regressor=pipe1,transformer=StandardScaler())\n    ```", "```py\nsgdr_params = {\n ‘regressor__sgdregressor__alpha’: 10.0 ** -np.arange(1, 7),\n ‘regressor__sgdregressor__loss’: [‘huber’,’epsilon_insensitive’],\n ‘regressor__sgdregressor__penalty’: [‘l2’, ‘l1’, ‘elasticnet’],\n ‘regressor__sgdregressor__epsilon’: np.arange(0.1, 1.6, 0.1)\n}\n```", "```py\n    gs = GridSearchCV(ttr,param_grid=sgdr_params, cv=5, scoring=”r2”)\n    gs.fit(X_train, y_train)\n    gs.best_params_\n    {‘regressor__sgdregressor__alpha’: 0.001,\n     ‘regressor__sgdregressor__epsilon’: 1.3000000000000003,\n     ‘regressor__sgdregressor__loss’: ‘huber’,\n     ‘regressor__sgdregressor__penalty’: ‘elasticnet’}\n    gs.best_score_\n    0.7941051735846133\n    ```", "```py\n    Results = \\\n      pd.DataFrame(gs.cv_results_[‘mean_test_score’], \\\n        columns=[‘meanscore’]).\\\n      join(pd.DataFrame(gs.cv_results_[‘params’])).\\\n      sort_values([‘meanscore’], ascending=False)\n    results.head(3).T\n                                             254      252      534\n    meanscore                           0.794105 0.794011 0.794009\n    regressor__sgdregressor__alpha      0.001000 0.001000 0.000001\n    regressor__sgdregressor__epsilon    1.300000 1.300000 1.500000\n    regressor__sgdregressor__loss          huber    huber    huber\n    regressor__sgdregressor__penalty  elasticnet       l2       l2\n    ```"]