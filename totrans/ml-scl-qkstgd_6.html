<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Scala for Recommender System</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we will learn about different approaches for developing recommender systems. Then we will learn how to develop a book recommendation system. Technically, it will be a model-based recommendation engine based on <strong>alternating least squares</strong> (<strong>ALS</strong>) and matrix factorization algorithms. We will use Spark MLlib-based implementation of these algorithms in Scala. In a nutshell, we will learn the following topics throughout this chapter:</p>
<ul>
<li>Overview of recommendation systems</li>
<li>Similarity-based recommender system</li>
<li>Content-based recommender system</li>
<li>Collaborative approaches</li>
<li>Hybrid recommendation systems</li>
<li>Developing a model-based book recommendation system</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>Make sure Scala 2.11.x and Java 1.8.x are installed and configured on your machine.</p>
<p class="mce-root"/>
<p>The code files of this chapters can be found on GitHub:</p>
<p><a href="https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter06" target="_blank">https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter06</a></p>
<p>Check out the following video to see the Code in Action:<br/>
<a href="http://bit.ly/2UQTFHs" target="_blank">http://bit.ly/2UQTFHs</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overview of recommendation systems</h1>
                </header>
            
            <article>
                
<p class="graf graf--p graf-after--h3">A recommender system is an information filtering approach, which predicts the rating given by a user to an item. Then the item for which the predicted rating is high will be recommended to the user. Recommender systems are now being used more or less everywhere for recommending movies, music, news, books, research articles, products, videos, books, news, Facebook friends, restaurants, routes, search queries, social tags, products, collaborators, jokes, restaurants, garments, financial services, Twitter pages, Android/iOS apps, hotels, life insurance, and even partners, in online dating sites.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Types of recommender systems</h1>
                </header>
            
            <article>
                
<p>There are a couple of ways to develop recommendation engines that typically produce a list of recommendations, such as similarity-based, content-based, collaborative, and hybrid recommendation systems as shown in the following figure:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-582 image-border" src="assets/93b9d48f-85a5-4b79-890a-02b006f94013.png" style="width:37.92em;height:16.33em;"/></p>
<p>We will discuss the similarity-based, content-based, collaborative, and hybrid recommendation systems. Then based on their pros and cons, we will see a hands-on example showing how to develop a book recommendation system.<br/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Similarity-based recommender systems</h1>
                </header>
            
            <article>
                
<p>There are two main types of similarity-based approaches: <strong>user-user similarity</strong> and <strong>user-item similarity</strong>. These can be used to build recommendation systems. To use a user-user item similarity approach, first construct a user-user similarity matrix. It will then pick items that are already liked by similar users and, finally, it recommends items for a specific user.</p>
<p>Suppose we want to develop a book recommender system: naturally, there will be many book users (readers) and a list of books. For the sake of brevity, let's pick the following machine learning-related books as the representative ones for the readers:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img class="alignnone size-full wp-image-695 image-border" src="assets/69c226c2-7250-47a8-8cb5-082aad603327.png" style="width:162.50em;height:45.00em;"/></div>
<p>Then a user-user similarity based recommender system will recommend books based on a similarity measure using some similarity measure techniques. For example, the cosine similarity is calculated as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c323a530-2bcd-4011-bda4-da9331fdb21b.png" style="width:14.42em;height:2.83em;"/></p>
<p class="CDPAlignLeft CDPAlign">In the preceding equation, <em>A</em> and <em>B</em> represent two users. If the similarity threshold is greater than or equal to a defined threshold, users <em>A</em> and <em>B</em> will most likely have similar preferences:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-696 image-border" src="assets/f1ba9bfb-4880-4978-b3ea-84d2ba8c7696.png" style="width:42.83em;height:31.00em;"/></p>
<p>However, user-user similarity based recommender systems are not robust. There are several reasons for that:</p>
<ul>
<li>User preferences and tastes usually change over time</li>
<li>They are computationally very expensive because of the similarity calculation for so many cases from very sparse matrix calculation</li>
</ul>
<p>Amazon and YouTube have millions of subscribed users, so any user-user utility matrix that you created would be a very sparse one. One workaround is using item-item similarity, which also computes an item-item utility matrix, finding similar items and, finally, recommending similar items, just like in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-697 image-border" src="assets/84c05ecb-de09-4eb0-9f9f-f0b3b82aaa71.png" style="width:36.17em;height:31.08em;"/></p>
<p class="CDPAlignLeft CDPAlign">This approach has one advantage over the user-user similarity approach, which is that usually the ratings on a given item do not change very significantly after an initial period. Let's take as an example the book <em>The Hundred Page Machine Learning Book</em>, which has already got a very good rating on Amazon even though it was released just a few months ago. So, even if over the next few months a few people give it lower ratings, its ratings would not change much after the initial period.</p>
<div class="packt_tip">Interestingly, this is also an assumption that the ratings will not change very significantly over time. However, this assumption works very well in cases where the number of users is much higher than the number of items.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Content-based filtering approaches</h1>
                </header>
            
            <article>
                
<p>Content-based filtering approaches are based on classical machine learning techniques such as classification or regression. This type of system learns how to represent an item (book) <em>I<sub>j</sub></em> and a user <em>U<sub>i</sub></em>. Then, a separate feature matrix for both <em>I<sub>j</sub></em> and <em>U<sub>i</sub></em> are created before combining them as a feature vector. Then the feature vector is fed into a classification or regression model for the training. This way, the ML model generates the label <em>L<sub>ij</sub></em>, which is interestingly the corresponding rating given by the user <em>U<sub>i</sub></em> on the item <em>I<sub>j</sub></em>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-700 image-border" src="assets/ba7ca2d2-16e1-40ec-8d6c-3256f282ac04.png" style="width:36.50em;height:29.00em;"/></p>
<p>A general warning is that the features should be created so they have direct impact on the rating (<strong>Labels</strong>). This means features should be as dependent as possible to avoid correlations.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Collaborative filtering approaches</h1>
                </header>
            
            <article>
                
<p class="graf graf--p graf-after--figure">The idea of collaborative filtering is that when we have many users who liked some items, then those items can be recommended to users who have not seen them yet. Suppose we have four readers and four books, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-701 image-border" src="assets/ee87495c-ed5a-4fae-89b7-875fdb402475.png" style="width:149.67em;height:107.58em;"/></p>
<p class="graf graf--p graf-after--figure">Also, imagine all of these users have bought item 1 (that is, <strong>Predictive Analytics with TensorFlow</strong>) and item 2 (that is, <strong>Deep Learning with TensorFlow</strong>). Now, suppose <strong>User 4</strong> has read items 1, 2, and 3 and say both <strong>User 1</strong> and <strong>User 2</strong> have bought item 3 (that is, <strong>Mastering Machine Learning Algorithms</strong>). However, since <strong>User 4</strong> has not seen item 4 (that is, <strong>Python Machine Learning</strong>) yet, <strong>User 3</strong> can recommend it to him.</p>
<p class="mce-root">So, the basic assumption is that users who have recommended an item previously tend to give recommendations in the future, too. If this assumption does not hold any longer, then a collaborative filtering recommender system cannot be build. This is probably the reason collaborative filtering approaches suffer from cold start, scalability, and sparsity problems.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<div class="mce-root packt_infobox"><strong>Cold start</strong>: Collaborative filtering approaches can get stuck and cannot make recommendation especially when a large amount of data about users is missing in the uer-item matrix.<strong><br/></strong></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The utility matrix</h1>
                </header>
            
            <article>
                
<p>Suppose we have a group of users who show a preference for a set of books. The higher a user's preference for a book, the higher the rating would be, between 1 and 10. Let's try to understand the problem using a matrix, with rows representing users and columns representing books:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-588 image-border" src="assets/f2f5a4e2-cda6-43ec-bd76-c2075b7c81b7.png" style="width:108.42em;height:57.83em;"/></p>
<p>Let's assume that ratings range from 1 to 10, with 10 being the highest level of preference. Then, in the preceding table, a user (row 1) gives a rating of <strong>7</strong> for the first book (column 1) and rates the second book as a <strong>6</strong>. Also, there are many empty cells that indicate users have not given any ratings for those books.</p>
<p>This matrix is often called a user-item or utility matrix, where each row represents a user and each column represents an item (book), while a cell represents the corresponding rating given by the user to that item.</p>
<p class="mce-root"/>
<div class="graf graf--p graf-after--p packt_infobox">In practice, the utility matrix is <em>very sparse</em> because a large number of cells are empty. The reason is that we have so many items and it is almost impossible for a single user to give ratings to all of the items. Even if a user rates 10% of the items, the other 90% of the cells of this matrix will still be empty. These empty cells often represented by NaN, which means not a number, although in our example utility matrix we used <strong>?</strong>. This sparsity often creates computational complexity. Let me give you an example.<br/>
<br/>
Suppose there are 1 million users (<em>n</em>) and only 10,000 items (movies, <em>m</em>), which is <em>10,000,000 * 10,000</em> or <em>10<sup>11</sup></em>, a very large number. Now, even if a user has rated 10 books, this means that the total number of given ratings will be <em>10 * 1 million = 10<sup>7</sup></em>. The sparsity of this matrix can be calculated as follows:<br/>
<br/>
<em>S<sub>m </sub>= Number of empty cells / Total number of cells = (10<sup>10 </sup>- 10<sup>7</sup>)/10<sup>10</sup> = 0.9999</em><br/>
<br/>
This means 99.99% of the cells will still be empty.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model-based book recommendation system</h1>
                </header>
            
            <article>
                
<p>In this section, we will show how to develop a model-based book recommendation system with the Spark MLlib library. Books and the corresponding ratings were downloaded from this link: <a href="http://www2.informatik.uni-freiburg.de/~cziegler/BX/">http://www2.informatik.uni-freiburg.de/~cziegler/BX/</a>. There are three CSV files:</p>
<ul>
<li>
<p class="normal-red"><kbd>BX-Users.csv</kbd>: Contains user's demographic data and each user is specified with user IDs (<kbd>User-ID</kbd>).</p>
</li>
<li>
<p class="normal-red"><kbd>BX-Books.csv</kbd>: Book related information such as <kbd>Book-Title</kbd>, <kbd>Book-Author</kbd>, <kbd>Year-Of-Publication</kbd>, and <kbd>Publisher</kbd> are there. Each book is identified by an ISBN. Also, <kbd>Image-URL-S</kbd>, <kbd>Image-URL-M</kbd>, and <kbd>Image-URL-L</kbd> are given.</p>
</li>
<li>
<p class="normal-red"><kbd>BX-Book-Ratings.csv</kbd>: Contains the rating specified by the <kbd>Book-Rating</kbd> <span>column.</span> Ratings are on a scale from <kbd>1</kbd> to <kbd>10</kbd> (higher values denoting higher appreciation), or implicit, expressed by <kbd>0</kbd>.</p>
</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Before we jump into the coding part, we need to know a bit more about the matrix factorization techniques such as <strong>singular value decomposition</strong> (<strong>SVD</strong>). SVD can be used to transform both the item and the user entries into the same potential space, which represents the interaction between users and items. The rationale behind matrix decomposition is that potential features represent how users score items. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Matrix factorization</h1>
                </header>
            
            <article>
                
<p>So, given the description of the users and the items, the task here is to predict how the user will rate those items that have not yet been rated. More formally, if a user <em>U<sub>i</sub></em> likes item <em>V<sub>1</sub></em>, <em>V<sub>5</sub></em>, and <em>V<sub>7</sub></em>,<em><sub> </sub></em>then the task is to recommend<span> item </span><em>V<sub>j</sub></em> to<em><sub> </sub></em>user <em>U<sub>i</sub></em> that they will most probably like too as shown in the following figure:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-702 image-border" src="assets/0b3f2bf8-844f-4507-84ab-348d3d4761b0.png" style="width:162.50em;height:45.92em;"/></p>
<p>Once we have such an application, the idea is that each time we receive new data, we update it to the training dataset and then update the model obtained by ALS training, where the collaborative filtering method is used. To handle the user-book utility matrix, a low-rank matrix factorization algorithm is used:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-703 image-border" src="assets/ac9c10e4-2d13-4adf-b0d3-b2ca554b7793.png" style="width:21.33em;height:9.17em;"/></p>
<p>Since not all the books are rated by all the users, not all of the entries in this matrix are known. The collaborative filtering approach discussed in a preceding section comes to this party as the savior. Well, using collaborative filtering, we can solve an optimization problem to approximate the ratings matrix by factorizing <strong>User factors (V)</strong> and <strong>Book factors (V)</strong>, which can be depicted as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-704 image-border" src="assets/0a51be14-29cc-47b8-9d99-df5b82413cda.png" style="width:16.42em;height:13.33em;"/></p>
<p>These two matrices are selected such that the error for the users-book pairs (in the case of known rating) gets minimized. The ALS algorithm first fills the user matrix with random values (between 1 and 10, in our case) and then optimizes those values such that the error is minimized. Then the ALS holds the book matrix as fixed and optimizes the value of the user's matrix using the following mathematical equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ac538922-4a7c-4f11-a300-a0753fda7574.png" style="width:27.00em;height:3.50em;"/></p>
<p>Spark MLlib supports a model-based collaborative filtering approach. In such an approach, users and items are described by a small set of latent factors for predicting missing entries of a user-item utility matrix. As described earlier, the ALS algorithms can learn those latent factors in an iterative way. The ALS algorithm accepts six parameters, namely <kbd>numBlocks</kbd>, <kbd>rank</kbd>, <kbd>iterations</kbd>, <kbd>lambda</kbd>, <kbd>implicitPrefs</kbd>, and <kbd>alpha</kbd>. <kbd>numBlocks</kbd> is number of blocks required to parallelize the computation. The <kbd>rank</kbd> parameter is the number of latent factors. The <kbd>iterations</kbd> parameter is the number of iterations by which ALS will get converged. The <kbd>lambda</kbd> parameter signifies the regularization parameter. The <kbd>implicitPrefs</kbd> parameter means that we want to use explicit feedback from the other users, and, finally, <kbd>alpha</kbd> is the baseline confidence in preference observations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploratory analysis</h1>
                </header>
            
            <article>
                
<p>In this subsection, we will perform some exploratory analysis about the ratings, books, and related statistics. This analysis will help us understand the data well:</p>
<pre><strong>val</strong> ratigsFile = "data/BX-Book-Ratings.csv"<br/><strong>var</strong> ratingDF = spark.read.format("com.databricks.spark.csv")<br/>      .option("delimiter", ";")<br/>      .option("header", true)<br/>      .load(ratigsFile)</pre>
<p>The following code segments show you the DataFrame of books from the <kbd>BX-Books.csv</kbd> file:</p>
<pre>/* Explore and query on books         */<br/><strong>val</strong> booksFile = "data/BX-Books.csv"<br/><strong>var</strong> bookDF = spark.read.format("com.databricks.spark.csv")<br/>            .option("header", "true")<br/>            .option("delimiter", ";")<br/>            .load(booksFile)    <br/>bookDF = bookDF.select(bookDF.col("ISBN"), <br/>                       bookDF.col("Book-Title"), <br/>                       bookDF.col("Book-Author"), <br/>                       bookDF.col("Year-Of-Publication"))<br/><br/>bookDF = bookDF.withColumnRenamed("Book-Title", "Title")<br/>                .withColumnRenamed("Book-Author", "Author")<br/>                .withColumnRenamed("Year-Of-Publication", "Year")<br/>    <br/>bookDF.show(10)</pre>
<p>The following is the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-592 image-border" src="assets/b53d3eed-f4cf-4aef-aae8-c735fa8a3887.png" style="width:32.67em;height:18.42em;"/></p>
<p>Let's see how many distinct books there are:</p>
<pre><strong>val</strong> numDistinctBook = bookDF.select(bookDF.col("ISBN")).distinct().count()<br/>println("Got " + numDistinctBook + " books") </pre>
<p>The following is the output:</p>
<pre><strong>Got 271,379 books</strong></pre>
<p>This information will be valuable for a later case, so that we can know how many books are missing ratings in the rating dataset. To register both datasets, we can use the following code:</p>
<pre>ratingsDF.createOrReplaceTempView("ratings")<br/>moviesDF.createOrReplaceTempView("books")</pre>
<p>This will help to make the in-memory querying faster by creating a temporary view as a in-memory table. Let's check the ratings-related statistics. Just use the following code lines:</p>
<pre>/* Explore and query ratings for books         */<br/><strong>val</strong> numRatings = ratingDF.count()<br/><strong>val</strong> numUsers = ratingDF.select(ratingDF.col("UserID")).distinct().count()<br/><strong>val</strong> numBooks = ratingDF.select(ratingDF.col("ISBN")).distinct().count()<br/>println("Got " + numRatings + " ratings from " + numUsers + " users on " + numBooks + " books")</pre>
<p>You should find <kbd>Got 1149780 ratings from 105283 users on 340556 books</kbd>. Now, let's get the maximum and minimum ratings along with the count of users who have rated a book:</p>
<pre>// Get the max, min ratings along with the count of users who have rated a book.    <br/>val statDF = spark.sql("select books.Title, bookrates.maxRating, bookrates.minRating, bookrates.readerID "<br/>      + "from(SELECT ratings.ISBN,max(ratings.Rating) as maxRating,"<br/>      + "min(ratings.Rating) as minRating,count(distinct UserID) as readerID "<br/>      + "FROM ratings group by ratings.ISBN) bookrates "<br/>      + "join books on bookrates.ISBN=books.ISBN " + "order by bookrates.readerID desc")<br/><br/>    statDF.show(10)</pre>
<p class="mce-root">The preceding code should generate the max and min ratings, along with the count of users who have rated a book:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-706 image-border" src="assets/6e045a60-3e6f-43a5-acb9-ba01529b0d7f.png" style="width:24.25em;height:16.00em;"/></p>
<p>Now, to get further insight we need to know more about the users and their ratings, which can be done by finding the top ten most active users and how many times they have rated a book:</p>
<pre>// Show the top 10 most-active users and how many times they rated a book<br/>val mostActiveReaders = spark.sql("SELECT ratings.UserID, count(*) as CT from ratings "<br/>      + "group by ratings.UserID order by CT desc limit 10")<br/>mostActiveReaders.show()</pre>
<p>The preceding lines of code should show the top ten most active users and how many times they have rated a book:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-594 image-border" src="assets/db26d027-5dc4-4dfa-bac8-2497f66622dd.png" style="width:8.33em;height:17.83em;"/></p>
<p>Now let's have a look at a particular user, and find the books that, say, user <kbd>130554</kbd> rated higher than <kbd>5</kbd>:</p>
<pre class="mce-root">// Find the movies that user 130554 rated higher than 5<br/><strong>val</strong> ratingBySpecificReader = spark.sql(<br/>      "<strong>SELECT</strong> ratings.UserID, ratings.ISBN,"<br/>        + "ratings.Rating, books.Title <strong>FROM</strong> ratings <strong>JOIN</strong> books "<br/>        + "<strong>ON</strong> books.ISBN=ratings.ISBN "<br/>        + "<strong>WHERE</strong> ratings.UserID=130554 and ratings.Rating &gt; 5")<br/><br/>ratingBySpecificReader.show(false)</pre>
<p>As described, the preceding line of code should show the name of all the movies rated by user 130554 giving more than 5 ratings:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-595 image-border" src="assets/e0775743-029d-4fe2-a3ee-0f1de8052f07.png" style="width:27.00em;height:31.58em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Prepare training and test rating data</h1>
                </header>
            
            <article>
                
<p>The following code splits ratings RDD into training data RDD (60%) and test data RDD (40%). The second parameter (that is <kbd>1357L</kbd>) is the <em>seed</em>, which is typically used for the purpose of reproducibility:</p>
<pre class="mce-root"><strong>val</strong> splits = ratingDF.randomSplit(Array(0.60, 0.40), 1357L)<br/><strong>val</strong> (trainingData, testData) = (splits(0), splits(1))<br/><br/>trainingData.cache<br/>testData.cache<br/><br/><strong>val</strong> numTrainingSample = trainingData.count()<br/><strong>val</strong> numTestSample = testData.count()<br/>println("Training: " + numTrainingSample + " test: " + numTestSample) </pre>
<p>You will see that there are 689,144 ratings in the training DataFrame and 345,774 ratings in the test DataFrame. The ALS algorithm requires an RDD of ratings for the <span>training</span>. The following code illustrates the way to build the recommendation model using APIs:</p>
<pre class="mce-root"><strong>val</strong> trainRatingsRDD = trainingData.rdd.map(row =&gt; {<br/>      val userID = row.getString(0)<br/>      val ISBN = row.getInt(1)<br/>      val ratings = row.getString(2)<br/>      Rating(userID.toInt, ISBN, ratings.toDouble)<br/>    })</pre>
<p><kbd>trainRatingsRDD</kbd> is an RDD of ratings that contains <kbd>UserID</kbd>, <kbd>ISBN</kbd>, and the corresponding ratings from the training dataset that we prepared in the preceding step. Similarly, we prepared another RDD from the test DataFrame:</p>
<pre class="mce-root"><strong>val</strong> testRatingsRDD = testData.rdd.map(row =&gt; {<br/>      val userID = row.getString(0)<br/>      val ISBN = row.getInt(1)<br/>      val ratings = row.getString(2)<br/>      Rating(userID.toInt, ISBN, ratings.toDouble)<br/>    })</pre>
<p>Based on the <kbd>trainRatingsRDD</kbd>, we build an ALS user model by adding the maximal iteration, a number of blocks, alpha, rank, lambda, seed, and implicit preferences. This method is generally used for analyzing and predicting missing ratings of specific users:</p>
<pre><strong>val</strong> model : MatrixFactorizationModel = new ALS()<br/>      .setIterations(10)<br/>      .setBlocks(-1)<br/>      .setAlpha(1.0)<br/>      .setLambda(0.01)<br/>      .setRank(25)<br/>      .setSeed(1234579L)<br/>      .setImplicitPrefs(false) // We want explicit feedback<br/>      .run(trainRatingsRDD)</pre>
<p>Finally, we iterated the model for learning <kbd>10</kbd> times. With this setting, we got good prediction accuracy. Readers are recommended to apply hyperparameter tuning to find the optimum values for these parameters. In order to evaluate the quality of the model, we compute the <strong>root mean squared error</strong> (<strong>RMSE</strong>). The following code calculates the RMSE value for the model that was developed with the help of the training set:</p>
<pre><strong>var</strong> rmseTest = computeRmse(model, testRatingsRDD, true)<br/>println("Test RMSE: = " + rmseTest) //Less is better</pre>
<p>For the preceding setting, we get the following output:</p>
<pre><strong>Test RMSE: = 1.6867585251053991 </strong></pre>
<p>The preceding method computes the RMSE to evaluate the model. The lower the RMSE, the better the model and its prediction capability is, which goes as follows:</p>
<pre>//Compute the RMSE to evaluate the model. Less the RMSE better the model and it's prediction capability. <br/><strong>def</strong> computeRmse(model: MatrixFactorizationModel, ratingRDD: RDD[Rating], implicitPrefs: Boolean): Double =         {<br/>    <strong>val</strong> predRatingRDD: RDD[Rating] = model.predict(ratingRDD.map(entry =&gt; (entry.user, entry.product)))<br/>    <strong>val</strong> predictionsAndRatings = predRatingRDD.map {entry =&gt; ((entry.user, entry.product), entry.rating)}<br/>                                .join(ratingRDD<br/>                                .map(entry =&gt; ((entry.user, entry.product), entry.rating)))<br/>                                .values    <br/>    math.sqrt(predictionsAndRatings.map(x =&gt; (x._1 - x._2) * (x._1 - x._2)).mean()) // return MSE<br/>          }</pre>
<p>Finally, let's do some movie recommendations for a specific user. Let's get the top ten book predictions for user <kbd>276747</kbd>:</p>
<pre>println("Recommendations: (ISBN, Rating)")<br/>println("----------------------------------")<br/><strong>val</strong> recommendationsUser = model.recommendProducts(276747, 10)<br/>recommendationsUser.map(rating =&gt; (rating.product, rating.rating)).foreach(println)<br/>println("----------------------------------")</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>We get the following output:</p>
<pre><strong>Recommendations: (ISBN =&gt; Rating)</strong><br/><strong>     (1051401851,15.127044702142243)</strong><br/><strong>     (2056910662,15.11531283195148)</strong><br/><strong>     (1013412890,14.75898119158678)</strong><br/><strong>     (603241602,14.53024153450836)</strong><br/><strong>     (1868529062,14.180262929540024)</strong><br/><strong>     (746990712,14.121654522195225)</strong><br/><strong>     (1630827789,13.741728003481194)</strong><br/><strong>     (1179316963,13.571754513473993)</strong><br/><strong>     (505970947,13.506755847456258)</strong><br/><strong>     (632523982,13.46591014905454)</strong><br/><strong>     ----------------------------------</strong></pre>
<p>We believe that the performance of the preceding model could be increased more. However, as far as we know, there is no model tuning facility available for the MLlib-based ALS algorithm.</p>
<div class="packt_infobox">Interested readers should refer to <a href="https://spark.apache.org/docs/preview/ml-collaborative-filtering.html" target="_blank">https://spark.apache.org/docs/preview/ml-collaborative-filtering.html</a> for more on tuning the ML-based ALS models.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding new user ratings and making new predictions</h1>
                </header>
            
            <article>
                
<p>We can create a sequence of a new user ID, the ISBN of the book, and the rating predicted in the previous step:</p>
<pre><strong>val</strong> new_user_ID = 300000 // new user ID randomly chosen<br/><br/>//The format of each line is (UserID, ISBN, Rating)<br/><strong>val</strong> new_user_ratings = Seq(<br/>      (new_user_ID, 817930596, 15.127044702142243),<br/>      (new_user_ID, 1149373895, 15.11531283195148),<br/>      (new_user_ID, 1885291767, 14.75898119158678),<br/>      (new_user_ID, 459716613, 14.53024153450836),<br/>      (new_user_ID, 3362860, 14.180262929540024),<br/>      (new_user_ID, 1178102612, 14.121654522195225),<br/>      (new_user_ID, 158895996, 13.741728003481194),<br/>      (new_user_ID, 1007741925, 13.571754513473993),<br/>      (new_user_ID, 1033268461, 13.506755847456258),<br/>      (new_user_ID, 651677816, 13.46591014905454))<br/><br/><strong>val</strong> new_user_ratings_RDD = spark.sparkContext.parallelize(new_user_ratings)<br/><strong>val</strong> new_user_ratings_DF = spark.createDataFrame(new_user_ratings_RDD).toDF("UserID", "ISBN", "Rating")<br/><br/><strong>val</strong> newRatingsRDD = new_user_ratings_DF.rdd.map(row =&gt; {<br/>      val userId = row.getInt(0)<br/>      val movieId = row.getInt(1)<br/>      val ratings = row.getDouble(2)<br/>      Rating(userId, movieId, ratings)<br/>    }) </pre>
<p>Now we add them to the data we will use to train our recommender model. We use Spark's <kbd>union()</kbd> transformation for this:</p>
<pre><strong>val</strong> complete_data_with_new_ratings_RDD = trainRatingsRDD.union(newRatingsRDD)</pre>
<p>Finally, we train the ALS model using all the parameters we selected before (when using the small dataset):</p>
<pre><strong>val</strong> newModel : MatrixFactorizationModel = new ALS()<br/>      .setIterations(10)<br/>      .setBlocks(-1)<br/>      .setAlpha(1.0)<br/>      .setLambda(0.01)<br/>      .setRank(25)<br/>      .setSeed(123457L)<br/>      .setImplicitPrefs(false)<br/>      .run(complete_data_with_new_ratings_RDD)</pre>
<p>We will need to repeat that every time a user adds new ratings. Ideally, we will do this in batches, and not for every single rating that comes into the system for every user. Then we can again make recommendations for other users such as <kbd>276724</kbd>, whose ratings about books were missing previously:</p>
<pre>// Making Predictions. Get the top 10 book predictions for user 276724<br/>//Book recommendation for a specific user. Get the top 10 book predictions for reader 276747<br/>println("Recommendations: (ISBN, Rating)")<br/>println("----------------------------------")<br/><strong>val</strong> newPredictions = newModel.recommendProducts(276747, 10)<br/>newPredictions.map(rating =&gt; (rating.product, rating.rating)).foreach(println)<br/>println("----------------------------------")</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>The following is the output:</p>
<pre><strong>Recommendations: (ISBN, Rating)</strong><br/><strong> ----------------------------------</strong><br/><strong> (1901261462,15.48152758068679)</strong><br/><strong> (1992983531,14.306018295431224)</strong><br/><strong> (1438448913,14.05457411015043)</strong><br/><strong> (2022242154,13.516608439192192)</strong><br/><strong> (817930596,13.487733919030019)</strong><br/><strong> (1079754533,12.991618591680165)</strong><br/><strong> (611897245,12.716161072778828)</strong><br/><strong> (11041460,12.44511878072316)</strong><br/><strong> (651596038,12.13345082904184)</strong><br/><strong> (1955775932,11.7254312955358)</strong><br/><strong> ----------------------------------</strong></pre>
<p>Finally, we compute the RMSE:</p>
<pre><strong>var</strong> newrmseTest = computeRmse(newModel, testRDD, true)<br/>println("Test RMSE: = " + newrmseTest) //Less is better</pre>
<p>The following is the output:</p>
<pre><strong>Test RMSE: = 4.892434600794704</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we have learned different approaches for recommender systems, such as similarity-based, content-based, collaborative filtering, and hybrid. Additionally, we discussed the downsides of these approaches. Then we implemented an end-to-end book recommendation system, which is a model-based recommendation with Spark. We have also seen how to interoperate between ALS and matrix factorization to efficiently handle a utility matrix.</p>
<p><span class="fontstyle0">In the next chapter, we will explain some basic concepts of</span> <strong>d</strong><span class="fontstyle2"><strong>eep learning</strong> (<strong>DL</strong>)</span><span class="fontstyle0">, which is one of the emerging branches of ML. We will briefly discuss some of the most well known and widely used neural network architectures. Then, we will look at various features of DL frameworks and libraries.</span></p>
<p><span class="fontstyle0">Then we will see how to prepare a programming environment, before moving on to coding with some open source DL libraries, such as</span> <span class="fontstyle2"><strong>Deeplearning4j</strong> (<strong>DL4J</strong>)</span><span class="fontstyle0">.</span> Finally,<span class="fontstyle0"> we will solve a real-life problem using two neural network architectures, called</span> <strong>m<span class="fontstyle2">ultilayer perceptron</span></strong> <span class="fontstyle0">(</span><strong><span class="fontstyle2">MLP</span></strong><span class="fontstyle0">)</span> <span class="fontstyle0">and <strong>long short-term memory</strong> (<strong>LSTM</strong>).</span></p>


            </article>

            
        </section>
    </body></html>