- en: '*Chapter 9*: Drift and Drift Detection'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout the previous chapters, you have discovered plenty of ways to build
    **machine learning** (**ML**) models that work in an online manner. They are able
    to update their learned decision rules from one single observation rather than
    having to retrain completely as is common in most ML models.
  prefs: []
  type: TYPE_NORMAL
- en: One reason that this is great is streaming, as these models will allow you to
    work and learn continuously. However, we could argue that a traditional ML model
    can also predict on a single observation. Even batch learning and offline models
    can predict a single new observation at a time. To get more insight into the added
    value of online ML, this chapter will go in depth into drift and drift detection.
  prefs: []
  type: TYPE_NORMAL
- en: To get to an improved understanding of those concepts, the chapter will start
    with an in-depth description of what drift is. You will then see different types
    of drift, including concept drift, data drift, and retraining strategy issues.
  prefs: []
  type: TYPE_NORMAL
- en: After that, you will be exposed to a number of methods to detect both data drift
    and concept drift. You will also see a number of methods to counteract drift and
    will be introduced to model explicability and retraining strategies.
  prefs: []
  type: TYPE_NORMAL
- en: For now, let's get started with the basics by having a deeper look at a definition
    of drift.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining drift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing model explicability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring drift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring drift in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Counteracting drift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can find all the code for this book on GitHub at the following link: [https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python](https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python).
    If you are not yet familiar with Git and GitHub, the easiest way to download the
    notebooks and code samples is by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to the link of the repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the green **Code** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Download zip**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you download the ZIP file, you unzip it in your local environment, and
    you will be able to access the code through your preferred Python editor.
  prefs: []
  type: TYPE_NORMAL
- en: Python environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To follow along with this book, you can download the code in the repository
    and execute it using your preferred Python editor.
  prefs: []
  type: TYPE_NORMAL
- en: If you are not yet familiar with Python environments, I would advise you to
    check out Anaconda ([https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)),
    which comes with Jupyter Notebook and JupyterLab, which are both great for executing
    notebooks. It also comes with Spyder and **Visual Studio Code** (**VS Code**)
    for editing scripts and programs.
  prefs: []
  type: TYPE_NORMAL
- en: If you have difficulty installing Python or the associated programs on your
    machine, you can check out **Google Colabatory** (**Google Colab**) ([https://colab.research.google.com/](https://colab.research.google.com/))
    or Kaggle Notebooks ([https://www.kaggle.com/code](https://www.kaggle.com/code)),
    which both allow you to run Python code in online notebooks for free, without
    any setup required.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The code in the book will generally use Colab and Kaggle Notebooks with Python
    version 3.7.13, and you can set up your own environment to mimic this.
  prefs: []
  type: TYPE_NORMAL
- en: Defining drift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is a well-known and commonly observed problem that models tend to start performing
    worse with time. Whether your metric is accuracy, R2 score, F1 score, or anything
    else, you will see a slow but steady decrease in performance over time if you
    put models into production and do not update them.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your use case, this decrease may become problematic quickly or
    slowly. Some use cases need to have continuous, near-perfect predictions. In some
    use cases— for example, for specialized ML in which the models have a direct impact
    on life—you would be strongly shocked if you observed a 1 percent decrease. In
    other use cases, ML is used more as automation than as prediction, and the business
    partners may not even notice a 5 percent decrease.
  prefs: []
  type: TYPE_NORMAL
- en: Whether it is going to impact you is not the question here. What is sure, is
    that in general, you will see your models decreasing. The goal for this chapter
    is to make sure to find out why model performance is decreasing, how you can measure
    it, and what can be done about it if you decide that it is too problematic for
    your use case.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will start by presenting three different types of drift
    that you may encounter in streaming use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Three types of drift
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two reasons for drift that are generally considered with streaming
    data: concept drift and data drift. In this part, you will first discover concept
    and data drift, but you will also see how retraining strategies can have an impact
    on your model drifting away from the data rather than the opposite.'
  prefs: []
  type: TYPE_NORMAL
- en: Concept drift
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In concept drift, we try to explain worsening model performance by a change
    in the concept that we are modeling. This means that the statistical properties
    of the target variable are changing, and therefore the model is no longer adequate
    for our use case.
  prefs: []
  type: TYPE_NORMAL
- en: A simplified example of concept change is a model that tries to forecast hot
    chocolate sales of a certain bar. Maybe the model was perfect for a certain while,
    but at some point, a competing bar got installed in the area. The underlying demand
    process has changed, and this was logically not included in the model, as the
    competition was not relevant when the model was built.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the concept changes, the model needs to be updated to take into account
    the most recent processes, as the model is no longer adequate for the use case.
    The following schematic diagram shows what goes wrong in the case of concept drift:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Concept drift'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_09_1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.1 – Concept drift
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have seen the theory behind concept drift, the next section will
    present data drift—a second important type of drift.
  prefs: []
  type: TYPE_NORMAL
- en: Data drift
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we talk about data drift, we talk about a change in the statistical properties
    of independent variables. This is mainly relevant when we have worked with a sample
    of data (maybe just based on what we had available), but then we start to realize
    that the sample is no longer representative of the data that we are receiving
    at the current moment.
  prefs: []
  type: TYPE_NORMAL
- en: Examples include changes in measurement machines, where a new measurement device
    may give slightly different measurements than the old material. Imagine we change
    the thermometer and our new thermometer measures about 0.5 degrees higher than
    the old one. You can understand that the model is not able to take this type of
    information into account and will make wrong predictions as the model takes the
    temperature higher than it should.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following schematic diagram shows what goes wrong in the case of data drift:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Data drift'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_09_2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.2 – Data drift
  prefs: []
  type: TYPE_NORMAL
- en: Having covered two important causes of drift, the next section will present
    model decay and misspecification—a third drift-related problem.
  prefs: []
  type: TYPE_NORMAL
- en: Model decay and misspecification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although not generally considered a problem of drift in the literature, I find
    it important to also mention problems with the model as one of the problems behind
    drifting and decaying performance. In real-life situations, humans are imperfect
    and make mistakes. Theoretically, we should expect models to be well specified
    and therefore not be the reasons for any problems.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, however, retraining of models may be wrongly automated, thereby
    introducing small problems that slowly, with time, add up to large problems, and
    this may be an important reason for model decay and lowering performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following schematic diagram shows what goes wrong in the case of model
    problems, due to any reason such as misspecification or retraining problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Model-induced problems'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_09_3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.3 – Model-induced problems
  prefs: []
  type: TYPE_NORMAL
- en: Having seen three potential reasons for drift in streaming models, the next
    section will explain how model explicability can be used as a solution against
    drift.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing model explicability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When models are learning in an online fashion, they are repeatedly relearning.
    This relearning process is happening automatically, and it is often impossible
    for a human user to keep an eye on the models continuously. In addition, this
    would go against the main goal of doing ML as the goal is to let machines—or models—take
    over, rather than having continuous human intervention.
  prefs: []
  type: TYPE_NORMAL
- en: When models learn or relearn, data scientists are generally faced with programmatic
    model-building interfaces. Imagine a random forest, in which hundreds of decision
    trees are acting at the same time to predict a target variable for a new observation.
    Even the task of printing out and looking at all those decisions would be a huge
    task.
  prefs: []
  type: TYPE_NORMAL
- en: Model explicability is a big topic in recent advances in ML. By throwing black-box
    models at data-science use cases, big mistakes are occurring. An example is that
    when self-driving cars were trained on a biased sample containing too many white
    people, the cars were measured to have more accidents with black people, just
    because of a data-science error. Understanding what happens in your model can
    have a life-saving impact.
  prefs: []
  type: TYPE_NORMAL
- en: When considering drift in models, it is also important to understand what happens
    in your model. The first model that you deploy is likely to be quite close to
    your expectation. After that, the model will relearn from every data point it
    encounters. If there are biases in the data, or if biases are occurring from over-
    or underfitting (and this happens when the model is running in autonomy), then
    at some point, you are likely to miss out on those trends.
  prefs: []
  type: TYPE_NORMAL
- en: You need to make sure to set up an initial method for model explicability as
    well as continue to investigate the topic. In the current chapter, we'll be focusing
    on data drift and concept drift, but keep in mind that model misspecification
    can also be a huge contributor to decreasing accuracy. This will be covered in
    more depth in [*Chapter 11*](B18335_11_ePub.xhtml#_idTextAnchor215).
  prefs: []
  type: TYPE_NORMAL
- en: For now, let's move on to some methods for measuring drift.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring drift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two important things to consider for drift. We should first be able
    to measure drift, as we cannot counteract something that we are not aware of.
    Secondly, once we become aware of drift, we should define the right strategies
    for counteracting it. Let's discuss measurements for drift first.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring data drift
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As described earlier, data drift means that the measurements are slowly changing
    over time, whereas the underlying concepts stay the same. To measure this, descriptive
    statistics can be very useful. As you have seen a lot of descriptive statistics
    in earlier chapters, we will not repeat the theory behind this.
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply descriptive statistics to measure data drift, we could simply set
    up a number of descriptive statistics and track them over time. For each variable,
    you could set up the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Measurements of centrality (mean, median, mode)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measurements of variation (standard deviation, variance, **interquartile range**,
    or **IQR**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Event correlation between the variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides this, it would be necessary to track drift on specific time scales.
    If you expect drift on very long periods, you could compute these descriptive
    statistics on a monthly or even yearly basis, but for quicker detection, it could
    be weekly, daily, or even hourly or more frequent.
  prefs: []
  type: TYPE_NORMAL
- en: The comparison of these metrics over time would allow you to detect a change
    in the data, which would be a common cause for drift in your model.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring concept drift
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When measuring concept drift, the best thing to do is to set up a thorough tracking
    of model performance over time. The performance metric that you use will depend
    on your use case and on the type of model you use but may include an R2 score
    for regression, accuracy, an F1 score for validation, or even more.
  prefs: []
  type: TYPE_NORMAL
- en: When measuring model performance over time, you are likely to see a decrease
    if no model updating is done. With online models that relearn on every data point,
    this should theoretically be less of an issue. When you do see your performance
    decrease, this indicates that something is off somewhere in your system.
  prefs: []
  type: TYPE_NORMAL
- en: If you are already measuring data drift, this would be a good first thing to
    look at, as data drift is likely to cause decreasing model performance. If data
    drift is not occurring, you are likely to have a concept drift in your system.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to keep in mind that measuring model drift and data drift are
    closely linked together in practice: it is hard to attribute decreasing performance
    to one specific root cause. The goal should be to keep your model performance
    high and find solutions for this if things are off. Measuring both performance
    and individual statistics and even more metrics together is what will make your
    strategy powerful against drift.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's now see some Python examples of how to detect drift in modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring drift in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When measuring drift, the first thing to do is to make sure that your model
    is writing out logs or results in some way. For the following example, you'll
    use a dataset in which each prediction was logged so that we have for each prediction
    the input variables, the prediction, the ground truth, and the absolute differences
    between prediction and ground truth as an indicator of error.
  prefs: []
  type: TYPE_NORMAL
- en: Logging your model's behavior is an absolute prerequisite if you want to work
    on drift detection. Let's start with some basic measurements that could help you
    to detect drift using Python.
  prefs: []
  type: TYPE_NORMAL
- en: A basic intuitive approach to measuring drift
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you will discover an intuitive approach to measuring drift.
    Here are the steps we''ll follow:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started measuring drift on our logged results data, we start by importing
    the data as a `pandas` DataFrame. This is done in the following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code block 9-1
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You will obtain a table that looks like the one shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – The data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_09_4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.4 – The data
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have the drift-detection data, let''s have a look at the development
    of the error over time by doing a `groupby` operation on the day and looking at
    the average error, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 9-2
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You will obtain the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – The result'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_09_5.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.5 – The result
  prefs: []
  type: TYPE_NORMAL
- en: You can clearly see that the error is strongly increasing over time, so we can
    be quite certain that we have a problem with model drift here. Now, of course,
    it is not yet defined whether this problem is caused by a problem in the data
    or a problem in the concept.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do an analysis with the target variable to see whether the target has
    experienced large changes over time. The following code does an average of the
    ground-truth value per day, to see whether there was a clear drift in the target
    variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code block 9-3
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6 – The result (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_09_6.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.6 – The result (continued)
  prefs: []
  type: TYPE_NORMAL
- en: We do see a quite important change on average over this period.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take our inspection further and also do this analysis for each of the
    independent variables. The following code does an average of the three independent
    variables per day to see if there is any obvious shift in there:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code block 9-4
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You will obtain the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7 – The groupby result'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_09_7.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.7 – The groupby result
  prefs: []
  type: TYPE_NORMAL
- en: We see a very clear change happening in the third explanatory variable, `X3`.
    It is highly probable that this is the cause of our model shift.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring drift with robust tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are working on small use cases and you do not want to integrate with
    large external platforms, the previous examples are really good. However, if you
    are working at a company where you are limited in resources, it may not be possible
    or not worth it to develop code for common use cases from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Drift detection is a use case that is getting quite some popularity at the moment,
    so more and more robust solutions are being presented to the public—be it paid
    programs, cloud programs, or open source solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Next, I will present a number of useful solutions that you could look at if
    you are interested in taking on external platforms for doing your model performance
    follow-ups and your drift-detection use cases. As those platforms are owned by
    companies and are sometimes paid, I do not want to go into much depth here, but
    it is good to give you some pointers in case this is of interest to you.
  prefs: []
  type: TYPE_NORMAL
- en: Soda SQL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One solution that is interesting to look at is Soda SQL. This is a tool that
    is specific for data quality, so it is not necessarily tuned for ML use cases.
    However, data quality issues will almost necessarily result in problematic models,
    so I find it valuable to discuss this solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find full information here: [https://docs.soda.io/](https://docs.soda.io/).
    Soda SQL is a tool that is really oriented toward data engineering, so I won''t
    go too much into detail here, but I do recommend keeping it in mind for your use
    cases.'
  prefs: []
  type: TYPE_NORMAL
- en: MLflow with whylogs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A tool that is much more oriented toward ML models in production is the `whylogs`
    open source Python library, which integrates with the WhyLabs app ([whylabsapp.com](http://whylabsapp.com)).
    If you sign up for an account with WhyLabs, you can use their **application programming
    interface** (**API**) and send your model logging directly to their databases,
    where it will be analyzed and made accessible to you.
  prefs: []
  type: TYPE_NORMAL
- en: Neptune
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A comparable tool is being delivered by Neptune ([neptune.ai](http://neptune.ai)).
    The goal of Neptune is also to present an **ML operations** (**MLOps**) platform
    to which you can send your logging data from basically any Python (or other) model
    environment. After that, you can access the performance on their web platform,
    and all the heavy lifting for drift detection is taken off your shoulders.
  prefs: []
  type: TYPE_NORMAL
- en: You have now seen some theoretical methods for measuring and detecting drift,
    and some start-up platforms that are proposing to do this type of work for you
    if you do not have the capacity to deliver it. Still, we have not talked about
    something equally important, which is counteracting drift.
  prefs: []
  type: TYPE_NORMAL
- en: Counteracting drift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in the introduction, model drift is bound to happen. Maybe it happens
    very slowly or maybe it occurs quickly, but it is something that cannot really
    be avoided if we don't try to actively counteract it.
  prefs: []
  type: TYPE_NORMAL
- en: What you will realize in the coming section is that online learning, which has
    been covered extensively in this book, is actually a very performant method against
    drift. Although we had not yet clearly defined drift, you will now come to understand
    that online learning has a strong added value here.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now recapitulate two approaches for counteracting drift, depending
    on the type of work you are doing, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Retraining for offline learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Online learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start with the most traditional case, which is offline learning with retraining
    strategies implemented against model decay.
  prefs: []
  type: TYPE_NORMAL
- en: Offline learning with retraining strategies against drift
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Offline learning is still the most commonly used method for ML. In offline
    learning, the model is trained once and then used only for prediction. The following
    schematic diagram depicts the offline learning process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.8 – Schematic diagram of offline learning'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_09_8.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.8 – Schematic diagram of offline learning
  prefs: []
  type: TYPE_NORMAL
- en: To update the model, it is generally necessary to retrain the full model and
    deploy a new version to your production environment. This is shown in *Figure
    9.9*.
  prefs: []
  type: TYPE_NORMAL
- en: The advantages of this approach are that the model builder has complete control
    over their model. There is no risk of the model learning new—wrong—processes.
    This comes at the cost of not updating when data or concept drift occurs. In this
    way, its advantages and disadvantages are the opposite of online learning.
  prefs: []
  type: TYPE_NORMAL
- en: Online learning against drift
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you have seen throughout this book, online learning is an alternative to
    offline learning and allows the model to update whenever a new data point arrives.
    The following diagram illustrates how a retraining strategy works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.9 – Schematic diagram of online learning'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_09_9.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.9 – Schematic diagram of online learning
  prefs: []
  type: TYPE_NORMAL
- en: 'Using online learning, the model has some autonomy in updating and will theoretically
    stay closer to the data: less drift should occur. However, this comes at a cost
    of the model builder not having full control over the theory model. Learning may
    go in the wrong direction, and unwanted decision rules are learned by the model.'
  prefs: []
  type: TYPE_NORMAL
- en: The advantages are the opposite of offline learning, and it will really depend
    on the business case whether to choose online or offline learning.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have first been introduced to the underlying foundations
    of model drift. You have seen that model drift and a decrease in model performance
    over time are to be expected in ML models in a real-life environment.
  prefs: []
  type: TYPE_NORMAL
- en: Decreasing performance can generally be attributed to drifting data, drifting
    concepts, or model-induced problems. Drifting data occurs when data measurements
    change over time, but the underlying theoretical concept behind the model stays
    the same. Concept drift captures problems of those theoretical underlying foundations
    of the learned processes.
  prefs: []
  type: TYPE_NORMAL
- en: Model- and model retraining-related problems are generally not considered standard
    reasons for drift, but they should still be monitored and taken seriously. Depending
    on your business case, relearning—especially if monitoring is lacking—can introduce
    large problems with ML systems.
  prefs: []
  type: TYPE_NORMAL
- en: Data drift can generally be measured well by using descriptive statistics. Concept
    drift is often harder to measure, but its presence can be deduced from an otherwise
    inexplicable decrease in model performance. In general, the importance here is
    not in attributing the decreasing performance to a specific cause, but rather
    in solving the problem using one of the provided solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Retraining strategies can often be used for offline models. They are a way to
    update models, without giving up control of learned decision rules. Online models,
    as thoroughly presented throughout the earlier chapters of this book, are a great
    alternative to retraining offline models. The great advantage of using online
    models is that online models are made specifically for retraining. These models
    allow for a larger degree of autonomy and will prove useful in many business cases,
    as long as monitoring of both data and models is implemented correctly.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will see how to adapt **feature transformation** (**FT**)
    and scaling to the online modeling case. FT and scaling are standard practice
    in many ML use cases, but due to drift in data—and bias in windowing—it poses
    some theoretical difficulties that need to be taken into account.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Model drift: [https://www.ibm.com/cloud/watson-studio/drift](https://www.ibm.com/cloud/watson-studio/drift)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data drift: [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-monitor-datasets?tabs=python](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-monitor-datasets?tabs=python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Concept drift: [https://www.iguazio.com/blog/concept-drift-deep-dive-how-to-build-a-drift-aware-ml-system/](https://www.iguazio.com/blog/concept-drift-deep-dive-how-to-build-a-drift-aware-ml-system/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dealing with concept drift: [https://neptune.ai/blog/concept-drift-best-practices](https://neptune.ai/blog/concept-drift-best-practices)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Retraining strategies: [https://www.kdnuggets.com/2019/12/ultimate-guide-model-retraining.html](https://www.kdnuggets.com/2019/12/ultimate-guide-model-retraining.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
