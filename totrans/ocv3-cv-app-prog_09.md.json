["```py\n    // Define feature detector \n    cv::Ptr<cv::FeatureDetector> ptrDetector;   // generic detector \n    ptrDetector= // we select the FAST detector \n                cv::FastFeatureDetector::create(80);    \n\n    // Keypoint detection \n    ptrDetector->detect(image1,keypoints1); \n    ptrDetector->detect(image2,keypoints2); \n\n```", "```py\n    // Define a square neighborhood \n    const int nsize(11);                       // size of the neighborhood \n    cv::Rect neighborhood(0, 0, nsize, nsize); // 11x11 \n    cv::Mat patch1; \n    cv::Mat patch2; \n\n```", "```py\n    // For all keypoints in first image \n    // find best match in second image \n    cv::Mat result; \n    std::vector<cv::DMatch> matches; \n\n    // for all keypoints in image 1 \n    for (int i=0; i<keypoints1.size(); i++) { \n\n      // define image patch \n      neighborhood.x = keypoints1[i].pt.x-nsize/2; \n      neighborhood.y = keypoints1[i].pt.y-nsize/2; \n\n      // if neighborhood of points outside image, \n      // then continue with next point \n      if (neighborhood.x<0 || neighborhood.y<0 ||   \n          neighborhood.x+nsize >= image1.cols || \n          neighborhood.y+nsize >= image1.rows) \n      continue; \n\n      // patch in image 1 \n      patch1 = image1(neighborhood); \n\n      // to contain best correlation value; \n      cv::DMatch bestMatch; \n\n      // for all keypoints in image 2 \n      for (int j=0; j<keypoints2.size(); j++) { \n\n        // define image patch \n        neighborhood.x = keypoints2[j].pt.x-nsize/2; \n        neighborhood.y = keypoints2[j].pt.y-nsize/2; \n\n        // if neighborhood of points outside image, \n        // then continue with next point \n        if (neighborhood.x<0 || neighborhood.y<0 ||   \n            neighborhood.x + nsize >= image2.cols ||   \n            neighborhood.y + nsize >= image2.rows) \n        continue; \n\n       // patch in image 2 \n       patch2 = image2(neighborhood); \n\n       // match the two patches \n       cv::matchTemplate(patch1,patch2,result, cv::TM_SQDIFF); \n\n       // check if it is a best match \n       if (result.at<float>(0,0) < bestMatch.distance) { \n\n         bestMatch.distance= result.at<float>(0,0); \n         bestMatch.queryIdx= i; \n         bestMatch.trainIdx= j; \n       } \n     } \n\n     // add the best match \n     matches.push_back(bestMatch); \n   } \n\n```", "```py\n    // extract the 25 best matches \n    std::nth_element(matches.begin(),   \n                     matches.begin() + 25,matches.end()); \n    matches.erase(matches.begin() + 25,matches.end()); \n\n```", "```py\n    //Draw the matching results \n    cv::Mat matchImage; \n    cv::drawMatches(image1,keypoints1,         // first image \n                    image2,keypoints2,         // second image \n                    matches,                   // vector of matches \n                    cv::Scalar(255,255,255),   // color of lines \n                    cv::Scalar(255,255,255));  // color of points \n\n```", "```py\n    // define search region \n    cv::Mat roi(image2, // here top half of the image \n    cv::Rect(0,0,image2.cols,image2.rows/2)); \n\n    // perform template matching \n    cv::matchTemplate(roi,            // search region \n                      target,         // template \n                      result,         // result \n                      cv::TM_SQDIFF); // similarity measure \n\n    // find most similar location \n    double minVal, maxVal; \n    cv::Point minPt, maxPt; \n    cv::minMaxLoc(result, &minVal, &maxVal, &minPt, &maxPt); \n\n    // draw rectangle at most similar location \n    // at minPt in this case \n    cv::rectangle(roi, cv::Rect(minPt.x, minPt.y,  \n                                target.cols, target.rows), 255); \n\n```", "```py\n    // Define keypoints vector \n    std::vector<cv::KeyPoint> keypoints1; \n    std::vector<cv::KeyPoint> keypoints2; \n\n    // Define feature detector \n    cv::Ptr<cv::Feature2D> ptrFeature2D =     \n                          cv::xfeatures2d::SURF::create(2000.0); \n\n    // Keypoint detection \n    ptrFeature2D->detect(image1,keypoints1); \n    ptrFeature2D->detect(image2,keypoints2); \n\n    // Extract the descriptor \n    cv::Mat descriptors1; \n    cv::Mat descriptors2; \n    ptrFeature2D->compute(image1,keypoints1,descriptors1); \n    ptrFeature2D->compute(image2,keypoints2,descriptors2); \n\n```", "```py\n    // Construction of the matcher  \n    cv::BFMatcher matcher(cv::NORM_L2); \n    // Match the two image descriptors \n    std::vector<cv::DMatch> matches; \n    matcher.match(descriptors1,descriptors2, matches); \n\n```", "```py\n    ptrFeature2D->detectAndCompute(image, cv::noArray(),  \n                                   keypoints, descriptors); \n\n```", "```py\n    cv::BFMatcher matcher2(cv::NORM_L2,    // distance measure \n                           true);          // cross-check flag \n\n```", "```py\n    // find the best two matches of each keypoint \n    std::vector<std::vector<cv::DMatch>> matches; \n    matcher.knnMatch(descriptors1,descriptors2,  \n                     matches, 2);  // find the k best matches \n\n```", "```py\n    //perform ratio test \n    double ratio= 0.85; \n    std::vector<std::vector<cv::DMatch>>::iterator it; \n    for (it= matches.begin(); it!= matches.end(); ++it) { \n\n      // first best match/second best match \n      if ((*it)[0].distance/(*it)[1].distance < ratio) { \n        // it is an acceptable match \n        newMatches.push_back((*it)[0]); \n      } \n    } \n    // newMatches is the updated match set \n\n```", "```py\n    // radius match \n    float maxDist= 0.4; \n    std::vector<std::vector<cv::DMatch>> matches2; \n    matcher.radiusMatch(descriptors1, descriptors2, matches2, maxDist); \n                       // maximum acceptable distance \n                       // between the 2 descriptors \n\n```", "```py\n    // Define keypoint vectors and descriptors \n    std::vector<cv::KeyPoint> keypoints1; \n    std::vector<cv::KeyPoint> keypoints2; \n    cv::Mat descriptors1; \n    cv::Mat descriptors2; \n\n    // Define feature detector/descriptor \n    // Construct the ORB feature object \n    cv::Ptr<cv::Feature2D> feature = cv::ORB::create(60); \n                           // approx. 60 feature points \n\n    // Keypoint detection and description \n    // Detect the ORB features \n    feature->detectAndCompute(image1, cv::noArray(),  \n                              keypoints1, descriptors1); \n    feature->detectAndCompute(image2, cv::noArray(),  \n                              keypoints2, descriptors2); \n\n    // Construction of the matcher  \n    cv::BFMatcher matcher(cv::NORM_HAMMING); // always use hamming norm \n    // for binary descriptors \n    // Match the two image descriptors \n    std::vector<cv::DMatch> matches; \n    matcher.match(descriptors1, descriptors2, matches); \n\n```", "```py\n    // to describe with FREAK  \n    feature = cv::xfeatures2d::FREAK::create(); \n\n```"]