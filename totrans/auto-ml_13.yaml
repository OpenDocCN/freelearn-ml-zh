- en: '*Chapter 10*: AutoML in the Enterprise'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"Harnessing machine learning can be transformational, but for it to be successful,
    enterprises need leadership from the top. This means understanding that when machine
    learning changes one part of the business — the product mix, for example — then
    other parts must also change. This can include everything from marketing and production
    to supply chain, and even hiring and incentive systems."'
  prefs: []
  type: TYPE_NORMAL
- en: – Erik Brynjolfsson, Director of the MIT Initiative on the Digital Economy
  prefs: []
  type: TYPE_NORMAL
- en: Automated **Machine Learning** (**ML**) is an enabler and an accelerator that
    unleashes the promise for organizations to expedite the analytics life cycle without
    having data scientists as a bottleneck. In earlier chapters, you learned how to
    perform automated ML using multiple hyperscalers, including open source tools,
    AWS, Azure, and GCP.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter, however, is quite different since here we will explore the enterprise
    use of automated ML. We will look into applying automated ML in real-world applications
    and discuss the pros and cons of such approaches. Model interpretability and transparency
    are areas of great interest in automated ML. We will explore models of trust in
    ML, providing a playbook for applying automated ML in an enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Does my organization need automated ML?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated ML – an accelerator for enterprise advanced analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated ML challenges and opportunities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establishing trust – model interpretability and transparency in automated ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing automated ML in an organization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Call to action – where do I go next?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does my organization need automated ML?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Technology decision-makers and stakeholders don''t like fads, and you probably
    shouldn''t either. Building and using technology for the sake of technology has
    limited business value in a vertical enterprise; the technology has to solve a
    business problem or provide an innovative differentiation to be relevant. Therefore,
    this inquiry becomes very significant: does an organization really need automated
    ML or is it just one of those steps in the AI and ML maturity cycle that we can
    live without? Would this investment result in **Return on Investment** (**ROI**),
    or would it become one of those unused platforms that sounded like a good idea
    at the time?'
  prefs: []
  type: TYPE_NORMAL
- en: Let's try to answer these questions by looking at the value proposition of automated
    ML and see whether it makes a good fit for your organization. As a technology
    stakeholder, envision yourself as someone trying to build an enterprise AI playbook
    and deciding whether to invest in and utilize or disregard the utility of automated
    ML.
  prefs: []
  type: TYPE_NORMAL
- en: Clash of the titans – automated ML versus data scientists
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In an organization, large or small, you would first need to communicate this
    idea to your own data science team. It could be a large group of people with a
    mix of PhDs, ML engineers, and data scientists, or it could be a close-knit group
    of startup bootstrappers, whose lead data science expert is an engineer with Jupyter
    notebooks installed on their machine. In either case, you would need convincing
    arguments to present a case for automated ML.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have said this before but will gladly repeat it: automated ML is not going
    to kill data scientist jobs any time soon. Having said that, you would be hard-pressed
    to find a data scientist who acknowledges the efficiency of using feature engineering,
    hyperparameter optimization, or neural architecture search using automated ML.
    As data scientists, we tend to think, sometimes rightfully so, that data science
    is an art form that cannot be brute-forced. There is a lot of subject matter expertise
    and knowledge that goes into model tuning, and therefore it is better left with
    humans who know what they are doing. The problem is that this model doesn''t scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Life of a data scientist'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.1_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.1 – Life of a data scientist
  prefs: []
  type: TYPE_NORMAL
- en: There is a perpetual shortage of qualified data scientists and other qualified
    individuals who can build, tune, monitor, and deploy models at scale. Our organizations
    are data-rich but starving for insights. We have seen several critical business
    intelligence, experimentation, and insight projects pushed down the priority stack
    for revenue-centric programs. Organizations need automated ML to let **subject
    matter experts** (**SMEs**) and citizen data scientists build data experiments
    and test their hypotheses without needing a PhD in ML. Would they get things wrong?
    I am sure. However, automated ML will enable and empower them to build advanced
    ML models and test their hypotheses.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we must support this democratization of AI. This is not to say that
    a mission-critical credit risk model trained by automated ML should be rolled
    out to production without proper due diligence and testing – that wouldn't be
    the case even with handcrafted models. An organization must make sure that performance,
    robustness, model decay, adversarial attacks, outlier parameters, and accuracy
    matrices and KPIs apply to all models equally.
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, ML progress in an enterprise is slow-paced. It is tough to scale
    and not very well automated. Collaboration among business teams and data scientists
    is difficult and actual operationalized models delivering business value are few
    and far between. Automated ML brings the promise of solving these problems and
    gives additional tools to data scientists to ease the manual drudgery of feature
    engineering, hyperparameter optimization, and neural architecture search.
  prefs: []
  type: TYPE_NORMAL
- en: Automated ML – an accelerator for enterprise advanced analytics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While building your AI playbook and reimagining the AI talent strategy for your
    organization, you should consider automated ML as an accelerator. The following
    are some of the reasons why you would want to consider using automated ML for
    your organization.
  prefs: []
  type: TYPE_NORMAL
- en: The democratization of AI with human-friendly insights
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Automated ML is rapidly becoming an inherent part of all major ML and deep learning
    platforms and will play an important part in democratizing advanced analytics.
    All major platforms tout these capabilities, but for it to be an accelerator for
    an enterprise, automated ML must play an important role in the democratization
    of AI. The toolset should enable a citizen data scientist to perform daunting
    ML tasks with ease and get human-friendly insights. Anything short of explainable,
    transparent, and repeatable AI and automated ML would not be the advanced analytics
    accelerator you had hoped for.
  prefs: []
  type: TYPE_NORMAL
- en: Augmented intelligence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Automated ML is becoming ingrained in most modern data science platforms, and
    therefore will be commoditized as part of the MLOps life cycle. For a data scientist,
    the biggest value proposition is the ease of feature engineering, data preprocessing,
    algorithmic selection, and hyperparameter tuning, that is, augmenting the data
    scientist's skillset. MLOps platforms with built-in automated ML also provide
    training and tuning, model monitoring and management, and head-to-head model comparison
    capabilities for A/B testing. This excellent suite of tools becomes extremely
    helpful to strengthen a data scientist's skills, hence automated ML proves to
    be an augmented intelligence platform for data scientists and domain SMEs alike.
  prefs: []
  type: TYPE_NORMAL
- en: Automated ML challenges and opportunities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have discussed the benefits of automated ML, but all these advantages are
    not without their fair share of challenges. Automated ML is not a silver bullet
    and there are several scenarios where it would not work. The following are some
    challenges and scenarios where automated ML may not be the best fit.
  prefs: []
  type: TYPE_NORMAL
- en: Not having enough data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The size of the dataset is a critical component for automated ML to work well.
    When feature engineering, hyperparameter optimization, and neural architectural
    search are used on small datasets, they do not yield good results. The dataset
    has to be significantly large for automated ML tools to do their job effectively.
    If this is not the case with your dataset, you might want to try the alternative
    approach of building models manually.
  prefs: []
  type: TYPE_NORMAL
- en: Model performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a small number of cases, the performance you get from out-of-the-box models
    may not work – you may have to hand-tune the model for performance or apply custom
    heuristics for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Domain expertise and special use cases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a case where your model requires significant subject matter expertise and
    rules built into it, the gains from automated ML models may not provide good returns.
  prefs: []
  type: TYPE_NORMAL
- en: Computational costs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Automated ML is inherently computationally expensive. If the datasets are extremely
    large, you might consider using local compute resources (which are arguably cheaper)
    to avoid the expensive costs associated with using cloud machines. In these cases,
    costs incurred in training the model may outweigh the optimization benefits –
    caveat emptor.
  prefs: []
  type: TYPE_NORMAL
- en: Embracing the learning curve
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Anything worth doing is never easy, such as exercise or ML. Automated ML takes
    the brunt of the work out of repetitive and tedious tasks, but there is still
    a learning curve. Most platforms dub their automated ML products as zero-code,
    low-code, or no-code approaches; however, you would still need to get yourself
    familiar with the tool. What happens when your results don't match your intuition
    or hypothesis based on years of subject matter expertise? How do you fine-tune
    the model based on identified important features? Which models perform well on
    training data but poorly on production datasets and why? These are practical considerations
    your citizen data scientists and stakeholders would need to go through as part
    of this learning curve. A lot of this learning and adaption would depend on the
    tool you select and how easy it makes life for you.
  prefs: []
  type: TYPE_NORMAL
- en: Stakeholder adaption
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every new technology faces the challenge of adaption – and automated ML would
    be dead on arrival due to its very nature. Your enterprise AI strategy should
    include training and incorporate the learning curve and potential disruption associated
    with the introduction of new technology such as automated ML. Building example
    templates and starter kits would help get stakeholders up to speed. We have seen
    in practice that getting junior data scientists and developers on board helps
    socialize new technology.
  prefs: []
  type: TYPE_NORMAL
- en: Let's proceed toward the next section, where we will discuss various techniques
    that can help in building trust in models trained by automated ML.
  prefs: []
  type: TYPE_NORMAL
- en: Establishing trust – model interpretability and transparency in automated ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Establishing trust in the model trained by automated ML can appear to be a challenging
    value proposition. Explaining to the business leaders, auditors, and stakeholders
    responsible for automated decision management that they can trust an algorithm
    to train and build a model that will be used for a potentially mission-critical
    system requires that you don't treat it any different from a "man-made" ML model.
    Model monitoring and observability requirements do not change based on the technique
    used to build the model. Reproducible model training and quality measurements,
    such as validating data, component integration, model quality, bias, and fairness,
    are also required as part of any ML development life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore some of the approaches and techniques we can use to build trust
    in automated ML models and ensure governance measures.
  prefs: []
  type: TYPE_NORMAL
- en: Feature importance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Feature importance, or how much a specific attribute contributes to the result
    of a prediction either positively or negatively, is a model inspection technique
    that is offered by most, if not all, automated ML frameworks. In earlier chapters,
    you have seen how AWS, GCP, and Azure all offer a view of feature importance scores
    for their trained models. This information can be used by domain SMEs and citizen
    data scientists to ensure the model is accurate.
  prefs: []
  type: TYPE_NORMAL
- en: Feature importance is not only helpful in validating the hypothesis but may
    also provide insights into data that was previously unknown. Data scientists,
    with the help of domain SMEs, can use feature importance to ensure that it does
    not exhibit bias against any protected class and see whether any of the preferences
    are against the law. For instance, if a loan decision algorithm has a bias toward
    a specific gender, ethnicity, or race, that would be illegal and unethical in
    most scenarios. On the contrary, if a breast cancer database shows a significant
    gender bias, that is due to a biological construct and hence is not a societal
    or implicit bias to be mitigated or addressed. Testing an automated ML model,
    or any model for that matter, for feature importance with perturbation makes a
    good sanity check for correctness, robustness, and bias.
  prefs: []
  type: TYPE_NORMAL
- en: Counterfactual analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In algorithmic explainability, counterfactual analysis belongs to the class
    of example-based explanations. In simple terms, it uses causal analysis to show
    what would have happened if an event has or has not occurred. For example, in
    a biased loan model, counterfactual analysis will reveal that while keeping all
    the other factors unchanged, modifying the ZIP code of a loan applicant has an
    impact on the outcome. This shows bias in the model against people in a specific
    geography, possibly a sign of latent racial bias manifested in the ZIP code as
    a proxy. Besides bias, counterfactual analysis can also reveal mistakes in model
    assumptions that can be quite beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: Data science measures for model accuracy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Standard ML approaches for performance estimation, model selection, and algorithm
    comparison should be applied to ensure the accuracy and robustness of the trained
    model. Some standard ways of validating a ML model are shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Standard measures for data science'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.2_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 – Standard measures for data science
  prefs: []
  type: TYPE_NORMAL
- en: For performance estimation in a large dataset, recommended approaches include
    checking for the confidence interval via normal approximation, as well as train/test
    splits. For smaller datasets, repeating k-fold cross-validation, leave-one-out
    cross-validation, and confidence interval testing helps to ensure good estimates
    for performance. For model selection with large datasets, three-way holdout methods
    of training validation, testing split, and repeated k-fold cross-validation with
    independent test sets work well. To compare the model and algorithms, applying
    multiple independent training and test sets for algorithm comparison, McNemar's
    test, and Cochran's test is prescribed, while for smaller datasets, nested cross-validations
    work quite effectively.
  prefs: []
  type: TYPE_NORMAL
- en: For automated ML-based models to be accurate and robust, we need to ensure that
    we perform explainability measures across the entire life cycle. Therefore, checks
    need to be performed pre-modeling – that is, characterizing the input data – during
    the modeling – that is, designing explainable model architectures and algorithms
    – and post-modeling – that is, extracting explanations from outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-modeling explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The pre-modeling explainability starts with exploratory data analysis and dataset
    statistical description and sanitization, that is, descriptions of the variables,
    metadata, provenance, statistics, between variables (pair plots and heatmaps),
    ground truth correlations, and probabilistic models generating synthetic data.
    This explainability extends to explainable feature engineering followed by interpretable
    prototype selections and identification of meaningful outliers.
  prefs: []
  type: TYPE_NORMAL
- en: During-modeling explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When using automated ML algorithms, choose to adopt a more explainable model
    family when given the option; linear models, decision trees, rule sets, decision
    sets, generalized additive models, and case-based reasoning methods are more explainable
    than complex black-box models.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid explainable models are also used to design explainable model architectures
    and algorithms such as **D****eep K-Nearest Neighbors** (**DKNN**), **Deep Weighted
    Averaging Classifier** (**DWAC**), **Self-Explaining Neural Network** (**SENN**),
    **Contextual Explanation Networks** (**CENs**), and **Bag-of-features Networks**
    (**BagNets**). The approach of joining prediction and explanation using models
    such as **Teaching Explanations for Decisions** (**TED**), multimodal explanations,
    and rationalizing neural predictions greatly helps explain the models. Visual
    explanations are, of course, quite effective since a picture is worth a thousand
    words, unless it's in a higher dimension because then it becomes quite confusing,
    such as postmodern art.
  prefs: []
  type: TYPE_NORMAL
- en: Explainability using architectural adjustments and regularizations as an artifact
    uses explainable **Convolutional Neural Networks** (**CNNs**), explainable deep
    architecture, and attention-based models, which are being used in natural language
    processing, time series analysis, and computer vision.
  prefs: []
  type: TYPE_NORMAL
- en: Post-modeling explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are various built-in tools for post-modeling explainability that are part
    of automated ML toolkits and hyperscalers. These tools include macro explanations
    and input-based explanations or perturbations to see how input manipulations can
    potentially impact the outputs. Macro explanation-based approaches, such as importance
    scores, decision rules, decision trees, dependency plots, verbal explanations,
    and counterfactual explanations, are great resources for domain SMEs to get their
    head around the outcomes of a trained model.
  prefs: []
  type: TYPE_NORMAL
- en: There are also explanation estimation methods that try to probe the proverbial
    black box, including perturbation-based training (LIME), backward propagation,
    proxy model, activation optimization, and SHAP.
  prefs: []
  type: TYPE_NORMAL
- en: As described in the preceding methods, there is no singular way of establishing
    trust in ML models, whether they are manually trained or built via automated ML
    toolkits. The only way to accomplish this is by following engineering best practices;
    validation, reproducibility, experimental audit trail, and explainability are
    the best-known methods to verify and ensure it works. You may not need all these
    approaches as part of your ML workflow but know that these and various other approaches
    to validate and monitor your model throughout the life cycle are critical to ensure
    the success of your enterprise ML operationalization.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing automated ML in an organization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have reviewed the automated ML platforms and the open source ecosystem
    and understand how it works under the hood, wouldn't you like to introduce automated
    ML in your organization? So, how do you do it? Here are some pointers to guide
    you through the process.
  prefs: []
  type: TYPE_NORMAL
- en: Brace for impact
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Andrew Ng is the founder and CEO of Landing AI, the former VP and chief scientist
    of Baidu, the co-chairman and co-founder of Coursera, the former founder and leader
    of Google Brain, and an adjunct professor at Stanford University. He has written
    extensively about AI and ML and his courses are seminal for anyone starting out
    with ML and deep learning. In his HBR article on AI in the enterprise, he poses
    five key questions to validate whether an AI project would be successful. We believe
    that this applies equally well to automated ML projects. The questions you should
    ask are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Does the project give you a quick win?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the project either too trivial or too unwieldy in size?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is your project specific to your industry?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are you accelerating your pilot project with credible partners?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is your project creating value?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These questions help not only to choose a meaningful project but also to seek
    business value and technical diligence. Building a small team and appointing a
    leader as an automated ML champion would help further the cause.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the right automated ML platform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Open source, AWS, GCP, Azure, or something else – what automated ML platform
    should you use?
  prefs: []
  type: TYPE_NORMAL
- en: There are few considerations you should keep in mind when choosing an automated
    ML platform. First of all, if you are cloud-native, that is, your data and compute
    reside in the cloud, it would make way more sense to use the automated ML offered
    by that specific cloud provider for all practical purposes. If you have a hybrid
    model, try to keep your automated ML compute close to the data you plan to use,
    wherever it resides. The feature parity might not make such a significant difference;
    however, not having access to the right data definitely would.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, cloud compute and storage resources for automated ML can
    get expensive quickly, providing you are working with large models and doing multiple
    simultaneous experiments. If you have compute resources and data available in
    an on-prem scenario, that is an ideal playground without increasing your hyperscaler's
    bill. However, this comes with the responsibility of setting up the infrastructure
    and doing the setup for an on-prem toolkit. So, if cost is not a major concern
    and you want to quickly explore what automated ML can do for you, cloud-based
    toolkits would make an ideal companion. Depending on your relationship with your
    cloud provider, you might also be able to get a discount.
  prefs: []
  type: TYPE_NORMAL
- en: The importance of data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the examples in previous chapters, it must have become painfully obvious
    that data, and a lot of it, is the single most important thing needed for a successful
    automated ML project. Smaller datasets do not provide good accuracy and do not
    make a good use case for automated ML. If you do not have large enough datasets
    to work with, or your use case does not lend itself well to automated ML, maybe
    it's not the right tool for the job.
  prefs: []
  type: TYPE_NORMAL
- en: The right messaging for your audience
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Automated ML promises to deliver immense value to both data scientists and SMEs;
    therefore, you should carefully craft your pitch.
  prefs: []
  type: TYPE_NORMAL
- en: For business leaders and stakeholders, it is a business enablement tool that
    will help citizen data scientists to expedite development; business users can
    test their hypotheses and execute experiments in a faster manner.
  prefs: []
  type: TYPE_NORMAL
- en: For your data science allies, you should introduce automated ML as a tool that
    helps augment their capabilities by taking away the repetitive and mundane tasks
    from their day-to-day job. Among many things, automated ML can help take away
    the drudgery of sifting through a dataset for important features and can help
    identify the right parameters and models through a large search space. It will
    expedite the training of new data scientists and will help other engineers who
    like to dabble in data science experiments gain a firm understanding of the fundamentals
    by doing it. If your fellow data scientists and ML engineers see value in this
    technology and do not feel threatened by it, they will be willing to adapt. This
    would not be the first time they have heard of this amazing technology and would
    love to use it, albeit with a healthy dose of skepticism.
  prefs: []
  type: TYPE_NORMAL
- en: Call to action – where do I go next?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All good things must end, and so does this book. Whew! We covered a lot of ground
    here. Automated ML is an active area of research and development, and in this
    book, we tried to give you a breadth-first overview of the fundamentals, key benefits,
    and platforms. We explained the underlying techniques of automated feature engineering,
    model and hyperparameter learning, and neural architecture search with examples
    from open source toolkits and cloud platforms. We covered a detailed walkthrough
    of three major cloud platforms, namely Microsoft Azure, AWS, and GCP. With the
    step-by-step walkthroughs, you saw the automated ML feature set offered in each
    platform by building ML models and trying them out.
  prefs: []
  type: TYPE_NORMAL
- en: The learning journey does not end here. There are several great references provided
    in the book where you can further do a deep dive to learn more about the topic.
    Automated ML platforms, especially cloud platforms, are always in flux, so by
    the time you read this, some of the screens and functionality might already have
    changed. The best way to keep up with these hyperscalers is to keep pace with
    the change, the only constant.
  prefs: []
  type: TYPE_NORMAL
- en: As a parting thought, we strongly believe what Sir Richard Branson said, that
    *"you don't learn to walk by following rules. You learn by doing, and by falling
    over."* The best way to learn something is by doing it – execution beats knowledge
    that doesn't get applied. Go ahead and try it out, and you will be glad to have
    the metaphorical coding battle scars.
  prefs: []
  type: TYPE_NORMAL
- en: Happy coding!
  prefs: []
  type: TYPE_NORMAL
- en: References and further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information on the topics covered in this chapter, you can refer to
    the given links:'
  prefs: []
  type: TYPE_NORMAL
- en: '*How to Choose Your First AI Project* by Andrew Ng: [https://hbr.org/2019/02/how-to-choose-your-first-ai-project](https://hbr.org/2019/02/how-to-choose-your-first-ai-project)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Explainable Artificial Intelligence for Neuroscience: Behavioral Neurostimulation*,
    December 2019, Frontiers in Neuroscience, 13:1346, DOI: 10.3389/fnins.2019.01346'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Interpretable ML – A Guide for Making Black Box Models Explainable* by Christoph
    Molnar: [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
