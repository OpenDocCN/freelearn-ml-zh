<html><head></head><body>
<div id="_idContainer049">
<h1 class="chapter-number" id="_idParaDest-40"><a id="_idTextAnchor040"/><span class="koboSpan" id="kobo.1.1">2</span></h1>
<h1 id="_idParaDest-41"><a id="_idTextAnchor041"/><span class="koboSpan" id="kobo.2.1">Understanding the Most Common Machine Learning Attacks</span></h1>
<p><span class="koboSpan" id="kobo.3.1">When getting started with securing your projects, there are many things you can use to learn security techniques quickly. </span><span class="koboSpan" id="kobo.3.2">The best is </span><a id="_idIndexMarker090"/><span class="koboSpan" id="kobo.4.1">the </span><strong class="bold"><span class="koboSpan" id="kobo.5.1">MITRE ATT&amp;CK framework</span></strong><span class="koboSpan" id="kobo.6.1">. </span><span class="koboSpan" id="kobo.6.2">As a globally recognized knowledge base, it contains valuable information about a range of attack techniques that an adversary can use to attack a system and their mitigations. </span><span class="koboSpan" id="kobo.6.3">In </span><a id="_idIndexMarker091"/><span class="koboSpan" id="kobo.7.1">this chapter, we are going to explore the </span><strong class="bold"><span class="koboSpan" id="kobo.8.1">MITRE ATLAS</span></strong><span class="koboSpan" id="kobo.9.1"> framework. </span><span class="koboSpan" id="kobo.9.2">It is adapted from the MITRE ATT&amp;CK framework</span><a id="_idIndexMarker092"/><span class="koboSpan" id="kobo.10.1"> for </span><strong class="bold"><span class="koboSpan" id="kobo.11.1">machine </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.12.1">learning</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.13.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.14.1">ML</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.16.1">The goal of this chapter is to familiarize ourselves with the different stages of an attack and possible attacks on our system. </span><span class="koboSpan" id="kobo.16.2">This is essential because, with that knowledge, we can understand how an adversary thinks and how to protect our system. </span><span class="koboSpan" id="kobo.16.3">As there are multiple stages of an attack, you will understand why applying the Zero Trust strategy (covered in the previous chapter) is the most effective way to protect the system. </span><span class="koboSpan" id="kobo.16.4">We must never forget that this is an ongoing process as new vulnerabilities and exploits are </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">released daily.</span></span></p>
<p><span class="koboSpan" id="kobo.18.1">We must always keep up to date with all new information, and the MITRE ATLAS framework will help us do exactly that. </span><span class="koboSpan" id="kobo.18.2">Finally, after exploring the MITRE ATLAS Matrix, we will cover the Azure services related to Azure Machine Learning and those most commonly affected </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">by attacks.</span></span></p>
<p><span class="koboSpan" id="kobo.20.1">In this chapter, we’re going to cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.22.1">Introducing the MITRE </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">ATLAS Matrix</span></span></li>
<li><span class="koboSpan" id="kobo.24.1">Understanding ML and </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">AI attacks</span></span></li>
<li><span class="koboSpan" id="kobo.26.1">Exploring Azure services involved in </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">ML attacks</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.28.1">By the end of this chapter, you will have a better understanding of ML attacks and their possible mitigations </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">for ML.</span></span></p>
<h1 id="_idParaDest-42"><a id="_idTextAnchor042"/><span class="koboSpan" id="kobo.30.1">Introducing the MITRE ATLAS Matrix</span></h1>
<p><span class="koboSpan" id="kobo.31.1">The MITRE ATT&amp;CK framework</span><a id="_idIndexMarker093"/><span class="koboSpan" id="kobo.32.1"> is a globally recognized </span><a id="_idIndexMarker094"/><span class="koboSpan" id="kobo.33.1">knowledge base and framework. </span><span class="koboSpan" id="kobo.33.2">Security professionals use it to understand and organize adversary behaviors in cyber threat environments. </span><strong class="bold"><span class="koboSpan" id="kobo.34.1">ATT&amp;CK</span></strong><span class="koboSpan" id="kobo.35.1">® (or ATTACK) stands for </span><strong class="bold"><span class="koboSpan" id="kobo.36.1">Adversarial Tactics, Techniques, and Common Knowledge</span></strong><span class="koboSpan" id="kobo.37.1">. </span><span class="koboSpan" id="kobo.37.2">It is</span><a id="_idIndexMarker095"/><span class="koboSpan" id="kobo.38.1"> essentially a catalog of </span><strong class="bold"><span class="koboSpan" id="kobo.39.1">tactics, techniques, and procedures</span></strong><span class="koboSpan" id="kobo.40.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.41.1">TTPs</span></strong><span class="koboSpan" id="kobo.42.1">) that adversaries</span><a id="_idIndexMarker096"/><span class="koboSpan" id="kobo.43.1"> use during different stages of a cyberattack. </span><span class="koboSpan" id="kobo.43.2">It covers many threat vectors, including initial access, execution, persistence, privilege escalation, defense evasion, credential access, discovery, lateral movement, collection, exfiltration, </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">and impact.</span></span></p>
<p><span class="koboSpan" id="kobo.45.1">The MITRE ATT&amp;CK framework organizes these techniques into a matrix that classifies them based on the various stages of an attack and the platforms on which they are applicable (for example, Windows, macOS, or Linux). </span><span class="koboSpan" id="kobo.45.2">Each technique in the matrix is described in detail in the MITRE knowledge base, including information on how adversaries typically employ it and the potential defensive measures we can take to detect and </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">prevent it.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.47.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.48.1">If this is the first time you are hearing about </span><a id="_idIndexMarker097"/><span class="koboSpan" id="kobo.49.1">the MITRE ATT&amp;CK® framework, you can explore the MITRE ATT&amp;CK® knowledge base </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">at </span></span><a href="https://attack.mitre.org/"><span class="No-Break"><span class="koboSpan" id="kobo.51.1">https://attack.mitre.org/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.52.1">.</span></span></p>
<p class="callout"><span class="koboSpan" id="kobo.53.1">(© 2023 The MITRE Corporation. </span><span class="koboSpan" id="kobo.53.2">This work is reproduced and distributed with the permission of The </span><span class="No-Break"><span class="koboSpan" id="kobo.54.1">MITRE Corporation.)</span></span></p>
<p><span class="koboSpan" id="kobo.55.1">The framework has become a widely adopted industry standard. </span><span class="koboSpan" id="kobo.55.2">It is used by security teams, security solutions vendors, and organizations to enhance their threat intelligence, develop more effective security controls, and improve incident response capabilities. </span><span class="koboSpan" id="kobo.55.3">It enables organizations to align their defenses with real-world adversary behaviors, helping them proactively detect, respond to, and mitigate </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">cyber threats.</span></span></p>
<p><span class="koboSpan" id="kobo.57.1">Although very comprehensive, the MITRE ATT&amp;CK framework might not cover all possible known attack methods, but it provides a great starting point. </span><span class="koboSpan" id="kobo.57.2">We are going to follow the MITRE ATLAS™ framework. </span><strong class="bold"><span class="koboSpan" id="kobo.58.1">ATLAS</span></strong><span class="koboSpan" id="kobo.59.1"> stands for </span><strong class="bold"><span class="koboSpan" id="kobo.60.1">Adversarial Threat Landscape for Artificial-Intelligence Systems</span></strong><span class="koboSpan" id="kobo.61.1">, and it is a knowledge base of adversary tactics based </span><a id="_idIndexMarker098"/><span class="koboSpan" id="kobo.62.1">on the MITRE ATT&amp;CK framework and contains</span><a id="_idIndexMarker099"/><span class="koboSpan" id="kobo.63.1"> techniques that apply to ML </span><a id="_idIndexMarker100"/><span class="koboSpan" id="kobo.64.1">and </span><strong class="bold"><span class="koboSpan" id="kobo.65.1">artificial intelligence</span></strong><span class="koboSpan" id="kobo.66.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.67.1">AI</span></strong><span class="koboSpan" id="kobo.68.1">) systems. </span><span class="koboSpan" id="kobo.68.2">The ATLAS Matrix shows the progression of an attack in stages and the techniques associated with each stage. </span><span class="koboSpan" id="kobo.68.3">The stages can be seen in the </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">following figure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer036">
<span class="koboSpan" id="kobo.70.1"><img alt="Figure 2.1 – The MITRE ATLAS stages" src="image/B21076_02_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.71.1">Figure 2.1 – The MITRE ATLAS stages</span></p>
<p><span class="koboSpan" id="kobo.72.1">While the stages appear in sequence and they usually start from reconnaissance and end with impact techniques, not all stages and techniques will be used in an attack. </span><span class="koboSpan" id="kobo.72.2">It depends on the adversary’s goal and the </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1">system architecture.</span></span></p>
<p><span class="koboSpan" id="kobo.74.1">Let us understand each stage in the </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">sections ahead.</span></span></p>
<h2 id="_idParaDest-43"><a id="_idTextAnchor043"/><span class="koboSpan" id="kobo.76.1">Reconnaissance</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.77.1">Reconnaissance</span></strong><span class="koboSpan" id="kobo.78.1"> refers to</span><a id="_idIndexMarker101"/><span class="koboSpan" id="kobo.79.1"> the initial phase of an attack where an adversary gathers information about the target ML system. </span><span class="koboSpan" id="kobo.79.2">The goal of reconnaissance is to gather intelligence that can be used to identify potential vulnerabilities, plan the attack, and increase the chances of success. </span><span class="koboSpan" id="kobo.79.3">Information can be anything from the ML technologies used or research information that can help the adversary obtain relevant ML artifacts and tailor attacks to the victim in the next stages of </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">the attack.</span></span></p>
<h2 id="_idParaDest-44"><a id="_idTextAnchor044"/><span class="koboSpan" id="kobo.81.1">Resource development</span></h2>
<p><span class="koboSpan" id="kobo.82.1">After the initial reconnaissance, the</span><a id="_idIndexMarker102"/><span class="koboSpan" id="kobo.83.1"> adversary is trying to discover resources they can use to support their endgame. </span><span class="koboSpan" id="kobo.83.2">This stage is called </span><strong class="bold"><span class="koboSpan" id="kobo.84.1">resource development</span></strong><span class="koboSpan" id="kobo.85.1"> and it is usually where the adversary purchases or steals resources to target ML artifacts, infrastructure, accounts, or capabilities that can be used later in </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1">the attack.</span></span></p>
<h2 id="_idParaDest-45"><a id="_idTextAnchor045"/><span class="koboSpan" id="kobo.87.1">Initial access</span></h2>
<p><span class="koboSpan" id="kobo.88.1">In the </span><strong class="bold"><span class="koboSpan" id="kobo.89.1">initial access</span></strong><span class="koboSpan" id="kobo.90.1"> stage, the adversary attempts to access the ML system. </span><span class="koboSpan" id="kobo.90.2">That can be anything from networks </span><a id="_idIndexMarker103"/><span class="koboSpan" id="kobo.91.1">to devices and platforms. </span><span class="koboSpan" id="kobo.91.2">If the adversary succeeds in this step, they can get an initial foothold in </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">the system.</span></span></p>
<h2 id="_idParaDest-46"><a id="_idTextAnchor046"/><span class="koboSpan" id="kobo.93.1">ML model access</span></h2>
<p><span class="koboSpan" id="kobo.94.1">After the adversary gains some form of</span><a id="_idIndexMarker104"/><span class="koboSpan" id="kobo.95.1"> access to the system, they will try to get further by gaining access to the ML model. </span><span class="koboSpan" id="kobo.95.2">The techniques used in the </span><strong class="bold"><span class="koboSpan" id="kobo.96.1">ML model access</span></strong><span class="koboSpan" id="kobo.97.1"> stage vary as the adversary can try to take advantage of many levels of access. </span><span class="koboSpan" id="kobo.97.2">They can target the database or technology that houses the data, or the endpoints used to train the ML model. </span><span class="koboSpan" id="kobo.97.3">The endpoint used for predictions or any other product or service that utilizes ML as part of its process is also vulnerable </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">to attack.</span></span></p>
<h2 id="_idParaDest-47"><a id="_idTextAnchor047"/><span class="koboSpan" id="kobo.99.1">Execution</span></h2>
<p><span class="koboSpan" id="kobo.100.1">In the </span><strong class="bold"><span class="koboSpan" id="kobo.101.1">execution</span></strong><span class="koboSpan" id="kobo.102.1"> stage, the adversary manages to run or embed malicious code or commands on a targeted </span><a id="_idIndexMarker105"/><span class="koboSpan" id="kobo.103.1">system to achieve their objective. </span><span class="koboSpan" id="kobo.103.2">This tactic focuses on the actions taken by an adversary to execute their payloads or explore the network to steal more data or gain access to more systems. </span><span class="koboSpan" id="kobo.103.3">Remote access tools can be run here to run scripts and discover unpatched </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">known vulnerabilities.</span></span></p>
<h2 id="_idParaDest-48"><a id="_idTextAnchor048"/><span class="koboSpan" id="kobo.105.1">Persistence</span></h2>
<p><span class="koboSpan" id="kobo.106.1">In the </span><strong class="bold"><span class="koboSpan" id="kobo.107.1">persistence</span></strong><span class="koboSpan" id="kobo.108.1"> stage, the adversary tries to maintain whatever access they have gained in the previous </span><a id="_idIndexMarker106"/><span class="koboSpan" id="kobo.109.1">steps. </span><span class="koboSpan" id="kobo.109.2">Techniques include but are not limited to elevating credentials, cutting off access to other users, and leaving behind modified data or models and backdoors so they can regain their access more easily if they </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">are discovered.</span></span></p>
<h2 id="_idParaDest-49"><a id="_idTextAnchor049"/><span class="koboSpan" id="kobo.111.1">Defense evasion</span></h2>
<p><span class="koboSpan" id="kobo.112.1">Of course, no adversary wants to be discovered before accomplishing their goals. </span><strong class="bold"><span class="koboSpan" id="kobo.113.1">Defense evasion</span></strong><span class="koboSpan" id="kobo.114.1"> techniques are </span><a id="_idIndexMarker107"/><span class="koboSpan" id="kobo.115.1">used by the adversary to avoid detection. </span><span class="koboSpan" id="kobo.115.2">Evading detection is something that an adversary can accomplish by turning off security features or software such as </span><span class="No-Break"><span class="koboSpan" id="kobo.116.1">malware detectors.</span></span></p>
<h2 id="_idParaDest-50"><a id="_idTextAnchor050"/><span class="koboSpan" id="kobo.117.1">Discovery</span></h2>
<p><span class="koboSpan" id="kobo.118.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.119.1">discovery</span></strong><span class="koboSpan" id="kobo.120.1"> stage is like reconnaissance but from the inside. </span><span class="koboSpan" id="kobo.120.2">The adversary is trying to work out your </span><a id="_idIndexMarker108"/><span class="koboSpan" id="kobo.121.1">ML environment. </span><span class="koboSpan" id="kobo.121.2">They are trying to gain knowledge about the system and internal network to broaden their goals or get as much information as possible before launching an attack. </span><span class="koboSpan" id="kobo.121.3">In this stage, the adversary will learn what they can or cannot control and what else they need to do based on their objective. </span><span class="koboSpan" id="kobo.121.4">Here, native operating system tools are often used to collect the </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">information needed.</span></span></p>
<h2 id="_idParaDest-51"><a id="_idTextAnchor051"/><span class="koboSpan" id="kobo.123.1">Collection</span></h2>
<p><span class="koboSpan" id="kobo.124.1">In the </span><strong class="bold"><span class="koboSpan" id="kobo.125.1">collection</span></strong><span class="koboSpan" id="kobo.126.1"> stage, all </span><a id="_idIndexMarker109"/><span class="koboSpan" id="kobo.127.1">investigation and information-gathering processes are finished. </span><span class="koboSpan" id="kobo.127.2">The adversary is trying to actively collect data or ML artifacts. </span><span class="koboSpan" id="kobo.127.3">Suppose their goal is simply to disrupt the service. </span><span class="koboSpan" id="kobo.127.4">In that case, the techniques in this stage will help them collect everything they need to extract from the system before making the service unusable. </span><span class="koboSpan" id="kobo.127.5">Extraction is part of the </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">exfiltration stage.</span></span></p>
<h2 id="_idParaDest-52"><a id="_idTextAnchor052"/><span class="koboSpan" id="kobo.129.1">ML attack staging</span></h2>
<p><span class="koboSpan" id="kobo.130.1">For ML, data extraction or</span><a id="_idIndexMarker110"/><span class="koboSpan" id="kobo.131.1"> service disruption might not be the only goal of the adversary. </span><span class="koboSpan" id="kobo.131.2">In AI projects, attacks targeting the ML model can be deployed. </span><strong class="bold"><span class="koboSpan" id="kobo.132.1">ML attack staging</span></strong><span class="koboSpan" id="kobo.133.1"> techniques include training proxy models, poisoning the target model, and crafting adversarial data to feed the target model. </span><span class="koboSpan" id="kobo.133.2">Some of them can even be performed offline, so it would be difficult to mitigate in </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">some cases.</span></span></p>
<h2 id="_idParaDest-53"><a id="_idTextAnchor053"/><span class="koboSpan" id="kobo.135.1">Exfiltration</span></h2>
<p><span class="koboSpan" id="kobo.136.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.137.1">exfiltration</span></strong><span class="koboSpan" id="kobo.138.1"> stage would be where data or artifacts will be extracted. </span><span class="koboSpan" id="kobo.138.2">The adversary is trying to</span><a id="_idIndexMarker111"/><span class="koboSpan" id="kobo.139.1"> steal (exfiltrate) the ML artifacts or use the information for future operations. </span><span class="koboSpan" id="kobo.139.2">In this case, the most targeted sources are software repositories, container registries, model repositories, and object stores. </span><span class="koboSpan" id="kobo.139.3">This is a challenging process, as data needs to leave the network, creating traffic that can </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">be detected.</span></span></p>
<h2 id="_idParaDest-54"><a id="_idTextAnchor054"/><span class="koboSpan" id="kobo.141.1">Impact</span></h2>
<p><span class="koboSpan" id="kobo.142.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.143.1">impact</span></strong><span class="koboSpan" id="kobo.144.1"> stage consists of techniques that disrupt or compromise the integrity of the system and possibly </span><a id="_idIndexMarker112"/><span class="koboSpan" id="kobo.145.1">manipulate business processes. </span><span class="koboSpan" id="kobo.145.2">The adversary can target data and corrupt or destroy it. </span><span class="koboSpan" id="kobo.145.3">Even worse, data might be slightly changed; not enough to trigger suspicion in the system, but just enough to disrupt the services in a way that helps the adversary with their endgame or provides cover for a </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">confidentiality breach.</span></span></p>
<p><span class="koboSpan" id="kobo.147.1">As you can see, these stages form a logical path an adversary might take to attack your system. </span><span class="koboSpan" id="kobo.147.2">In reality, that might not be the case as the flow heavily depends on their goal. </span><span class="koboSpan" id="kobo.147.3">Let us see the techniques used in each stage and examples of how they might affect </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">our systems.</span></span></p>
<h1 id="_idParaDest-55"><a id="_idTextAnchor055"/><span class="koboSpan" id="kobo.149.1">Understanding ML and AI attacks</span></h1>
<p><span class="koboSpan" id="kobo.150.1">All the stages </span><a id="_idIndexMarker113"/><span class="koboSpan" id="kobo.151.1">mentioned in the previous section use multiple techniques to achieve each goal. </span><span class="koboSpan" id="kobo.151.2">The adversary can use these techniques alone, sequentially, or combined. </span><span class="koboSpan" id="kobo.151.3">Some attacks can be repeated and used in various stages for different purposes. </span><span class="koboSpan" id="kobo.151.4">It all depends on the adversary’s goal, which is why by applying Zero Trust principles and always verifying all levels of the system, we have a better chance of protecting our services or at least detecting an incident before it has time to do any extensive damage to </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">the system.</span></span></p>
<p><span class="koboSpan" id="kobo.153.1">Here, we will describe the most common AI and ML attacks per stage. </span><span class="koboSpan" id="kobo.153.2">We will also talk about attacks from the MITRE ATT&amp;CK framework that, although not ML-specific, can be used to access systems that contain ML capabilities, among other things. </span><span class="koboSpan" id="kobo.153.3">Although we will outline the possible mitigations for each attack, we will go through the implementations in more detail in the </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">following chapters.</span></span></p>
<p><span class="koboSpan" id="kobo.155.1">Let us explore the attack techniques </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">per stage.</span></span></p>
<h2 id="_idParaDest-56"><a id="_idTextAnchor056"/><span class="koboSpan" id="kobo.157.1">Reconnaissance techniques</span></h2>
<p><span class="koboSpan" id="kobo.158.1">There are five </span><a id="_idIndexMarker114"/><span class="koboSpan" id="kobo.159.1">reconnaissance techniques that aim to</span><a id="_idIndexMarker115"/><span class="koboSpan" id="kobo.160.1"> gather information about the system, as seen in the </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1">following figure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer037">
<span class="koboSpan" id="kobo.162.1"><img alt="Figure 2.2 – Reconnaissance techniques" src="image/B21076_02_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.163.1">Figure 2.2 – Reconnaissance techniques</span></p>
<p><span class="koboSpan" id="kobo.164.1">Let us understand each of these techniques in the </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1">following sections.</span></span></p>
<h3><span class="koboSpan" id="kobo.166.1">Search for the victim’s publicly available information</span></h3>
<p><span class="koboSpan" id="kobo.167.1">Suppose the </span><a id="_idIndexMarker116"/><span class="koboSpan" id="kobo.168.1">organization uses open source model architectures that they have trained on additional proprietary data in production or that are in the research stage. </span><span class="koboSpan" id="kobo.168.2">In that case, they might publish system details with announcements or press releases. </span><span class="koboSpan" id="kobo.168.3">Although not technical, these might contain details about their model’s development and can help craft more realistic proxy models. </span><span class="koboSpan" id="kobo.168.4">To mitigate this, limit sharing information about the company’s systems, software stack, or frameworks used in developing systems when</span><a id="_idIndexMarker117"/><span class="koboSpan" id="kobo.169.1"> announcing deals </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">or partnerships.</span></span></p>
<h3><span class="koboSpan" id="kobo.171.1">Search victim-owned websites and application repositories</span></h3>
<p><span class="koboSpan" id="kobo.172.1">Company websites </span><a id="_idIndexMarker118"/><span class="koboSpan" id="kobo.173.1">may have a lot of information publicly available, including names of departments/divisions, physical locations, and data about key employees such as names, roles, and contact information. </span><span class="koboSpan" id="kobo.173.2">These sites may also have information that shows business operation details and relationships. </span><span class="koboSpan" id="kobo.173.3">The same goes for papers or technical blogs published by company employees. </span><span class="koboSpan" id="kobo.173.4">Employees are also vulnerable to social engineering attacks where the adversary poses as another employee to get company information. </span><span class="koboSpan" id="kobo.173.5">Ensure that you instruct employees not to share information about the projects they are working on—even with other employees if they are not working on the project—and anonymize the information they share on personal blogs or </span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">social media.</span></span></p>
<p><span class="koboSpan" id="kobo.175.1">Finally, ML-enabled applications might be available in mobile stores such as Google Play, the iOS App Store, the macOS App Store, and the Microsoft Store. </span><span class="koboSpan" id="kobo.175.2">The adversary might attempt to scan and analyze the app for ML-related components or endpoints. </span><span class="koboSpan" id="kobo.175.3">Try to obfuscate the application code where possible and ensure you secure endpoints if information </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">gets intercepted.</span></span></p>
<h3><span class="koboSpan" id="kobo.177.1">Search for publicly available adversarial vulnerability analysis</span></h3>
<p><span class="koboSpan" id="kobo.178.1">As soon as the technology </span><a id="_idIndexMarker119"/><span class="koboSpan" id="kobo.179.1">is identified, the adversary will research common system, model, or algorithm vulnerabilities to see whether they can use existing research to stage their attack. </span><span class="koboSpan" id="kobo.179.2">Identified vulnerabilities have implementations publicly available, making it easier for the adversary to gain initial access to the system and </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">plan effectively.</span></span></p>
<h3><span class="koboSpan" id="kobo.181.1">Active scanning</span></h3>
<p><span class="koboSpan" id="kobo.182.1">Active scanning</span><a id="_idIndexMarker120"/><span class="koboSpan" id="kobo.183.1"> is not a simple reconnaissance or information gathering. </span><span class="koboSpan" id="kobo.183.2">The adversary is actively probing the system to identify entry points or gather more actionable information. </span><span class="koboSpan" id="kobo.183.3">They can also be trying to determine</span><a id="_idIndexMarker121"/><span class="koboSpan" id="kobo.184.1"> whether the collected information </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">is valid.</span></span></p>
<h2 id="_idParaDest-57"><a id="_idTextAnchor057"/><span class="koboSpan" id="kobo.186.1">Resource development techniques</span></h2>
<p><span class="koboSpan" id="kobo.187.1">There are six techniques in this stage</span><a id="_idIndexMarker122"/><span class="koboSpan" id="kobo.188.1"> that usually</span><a id="_idIndexMarker123"/><span class="koboSpan" id="kobo.189.1"> exploit information gathered from the </span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">reconnaissance stage:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer038">
<span class="koboSpan" id="kobo.191.1"><img alt="Figure 2.3 – Resource development techniques" src="image/B21076_02_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.192.1">Figure 2.3 – Resource development techniques</span></p>
<h3><span class="koboSpan" id="kobo.193.1">Acquire public ML artifacts</span></h3>
<p><span class="koboSpan" id="kobo.194.1">As soon as the adversary has</span><a id="_idIndexMarker124"/><span class="koboSpan" id="kobo.195.1"> identified some of the details of the system, this can help them launch attacks such as creating a proxy ML model or directly crafting adversarial data, which are attack techniques that we will talk about later in this chapter. </span><span class="koboSpan" id="kobo.195.2">Artifacts include the software stack used to train the model, algorithms, model deployments, and training and testing datasets. </span><span class="koboSpan" id="kobo.195.3">The artifacts can also be in development or testing environments. </span><span class="koboSpan" id="kobo.195.4">Suppose they contain some logic, algorithms, or techniques that the production model uses. </span><span class="koboSpan" id="kobo.195.5">In that case, they can also compromise the production environment. </span><span class="koboSpan" id="kobo.195.6">Ensure you protect development environments as well as production environments. </span><span class="koboSpan" id="kobo.195.7">Access to those artifacts might require access keys or authenticated requests and you might think that this is enough, but it is not. </span><span class="koboSpan" id="kobo.195.8">You need to ensure that you differentiate access methods for different environments and rotate access keys so that the adversary cannot use the initial access stage techniques to</span><a id="_idIndexMarker125"/><span class="koboSpan" id="kobo.196.1"> acquire access to </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">multiple environments.</span></span></p>
<h3><span class="koboSpan" id="kobo.198.1">Obtain capabilities</span></h3>
<p><span class="koboSpan" id="kobo.199.1">Here, the </span><a id="_idIndexMarker126"/><span class="koboSpan" id="kobo.200.1">adversary may search for and get software tools to</span><a id="_idIndexMarker127"/><span class="koboSpan" id="kobo.201.1"> support their operations. </span><span class="koboSpan" id="kobo.201.2">Software tools can be either malicious or repurposed for malicious intent. </span><span class="koboSpan" id="kobo.201.3">Any software can be used here, and this tool or software doesn’t need to be ML-enabled. </span><span class="koboSpan" id="kobo.201.4">For example, the adversary can use a virtual camera to add realistic effects to a feed to intercept an actual camera feed going into a system and gain access using deep </span><span class="No-Break"><span class="koboSpan" id="kobo.202.1">fake technology.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.203.1">Deep fake technology</span></p>
<p class="callout"><span class="koboSpan" id="kobo.204.1">Deepfake technology is a </span><a id="_idIndexMarker128"/><span class="koboSpan" id="kobo.205.1">way to manipulate or generate videos, images, and audio of people using deep learning techniques. </span><span class="koboSpan" id="kobo.205.2">The technology uses existing audio, video, or images of a person to generate new content in the likeness of that person. </span><span class="koboSpan" id="kobo.205.3">The technology is so powerful that the generated content is indistinguishable from a real recorded video or audio and, as a result, can be used for various malicious purposes such as fake news, unauthorized access to systems that use biometrics, and </span><span class="No-Break"><span class="koboSpan" id="kobo.206.1">financial fraud.</span></span></p>
<h3><span class="koboSpan" id="kobo.207.1">Develop adversarial ML attack capabilities</span></h3>
<p><span class="koboSpan" id="kobo.208.1">As soon as the adversary has </span><a id="_idIndexMarker129"/><span class="koboSpan" id="kobo.209.1">access to the system, or at least information about it, they may choose to develop their own attacks or implement ideas described in public research. </span><span class="koboSpan" id="kobo.209.2">Public research papers with existing libraries as a starting point are usually well documented and explain which vulnerabilities they exploit. </span><span class="koboSpan" id="kobo.209.3">You can use this information to protect your system, so it’s imperative not to share information publicly so that the adversary has a limited ability to tailor the attack on </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">your system.</span></span></p>
<h3><span class="koboSpan" id="kobo.211.1">Acquire infrastructure</span></h3>
<p><span class="koboSpan" id="kobo.212.1">The adversary might buy or lease</span><a id="_idIndexMarker130"/><span class="koboSpan" id="kobo.213.1"> infrastructure they will use throughout their operation. </span><span class="koboSpan" id="kobo.213.2">This infrastructure can include physical or cloud servers’ domains, devices, or services. </span><span class="koboSpan" id="kobo.213.3">Depending on the implementation, the adversary will make it difficult for you to discover their traffic in your network and they will try to blend in. </span><span class="koboSpan" id="kobo.213.4">They will probably use infrastructure that can be very quickly provisioned and then shut down. </span><span class="koboSpan" id="kobo.213.5">That means that even if you discover a suspicious endpoint and block it, that doesn’t mean you are safe, as the adversary might provision new infrastructure and try again. </span><span class="koboSpan" id="kobo.213.6">This is why it’s essential to always follow the best industry practices about security to prepare for </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">any attack.</span></span></p>
<h3><span class="koboSpan" id="kobo.215.1">Publish poisoned datasets and poison training data</span></h3>
<p><span class="koboSpan" id="kobo.216.1">When it </span><a id="_idIndexMarker131"/><span class="koboSpan" id="kobo.217.1">comes to ML, everything is</span><a id="_idIndexMarker132"/><span class="koboSpan" id="kobo.218.1"> based on data. </span><span class="koboSpan" id="kobo.218.2">Poisoning the training data will change the results of the algorithm and the trained model. </span><span class="koboSpan" id="kobo.218.3">They can introduce vulnerabilities that cannot be easily detectable. </span><span class="koboSpan" id="kobo.218.4">The adversary may poison training data and publish it in a public location. </span><span class="koboSpan" id="kobo.218.5">It can be new data or a different version of an open source dataset. </span><span class="koboSpan" id="kobo.218.6">Always verify the source of any open source ML artifacts you use to train or update your model to protect against poisoned datasets. </span><span class="koboSpan" id="kobo.218.7">Staying away from public data is not the only thing you can do since data can be introduced into your system using the ML supply chain compromise attack, which we will highlight later in this chapter. </span><span class="koboSpan" id="kobo.218.8">Always validate that the data has not changed in the data sources; do not encrypt data or set the data sources as read-only or immutable </span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">if possible.</span></span></p>
<h3><span class="koboSpan" id="kobo.220.1">Establish accounts</span></h3>
<p><span class="koboSpan" id="kobo.221.1">The adversary may create </span><a id="_idIndexMarker133"/><span class="koboSpan" id="kobo.222.1">accounts with many services that they can use to target your system and gain access to the resources they need. </span><span class="koboSpan" id="kobo.222.2">They might also impersonate someone from your organization, such as an employee, and use this to gain access to your systems. </span><span class="koboSpan" id="kobo.222.3">Always verify whom you are talking to about a project and train your employees accordingly. </span><span class="koboSpan" id="kobo.222.4">For example, if you get a message on LinkedIn from a coworker asking you to share access or reset their password for them, always verify their identity. </span><span class="koboSpan" id="kobo.222.5">Even if they use a company email, if this is not the proper process for resetting credentials or requesting access, direct them to follow the appropriate process because their account might be compromised. </span><span class="koboSpan" id="kobo.222.6">You could unknowingly share access information about the ML </span><a id="_idIndexMarker134"/><span class="koboSpan" id="kobo.223.1">endpoint or training data with </span><a id="_idIndexMarker135"/><span class="koboSpan" id="kobo.224.1">a </span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">third party.</span></span></p>
<h2 id="_idParaDest-58"><a id="_idTextAnchor058"/><span class="koboSpan" id="kobo.226.1">Initial access techniques</span></h2>
<p><span class="koboSpan" id="kobo.227.1">The adversary can use the </span><a id="_idIndexMarker136"/><span class="koboSpan" id="kobo.228.1">following techniques to gain </span><a id="_idIndexMarker137"/><span class="koboSpan" id="kobo.229.1">access to </span><span class="No-Break"><span class="koboSpan" id="kobo.230.1">the system:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer039">
<span class="koboSpan" id="kobo.231.1"><img alt="Figure 2.4 – Initial access techniques" src="image/B21076_02_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.232.1">Figure 2.4 – Initial access techniques</span></p>
<p><span class="koboSpan" id="kobo.233.1">Let us understand each of these techniques in the </span><span class="No-Break"><span class="koboSpan" id="kobo.234.1">following sections.</span></span></p>
<h3><span class="koboSpan" id="kobo.235.1">ML supply chain compromise</span></h3>
<p><span class="koboSpan" id="kobo.236.1">With the ML supply chain</span><a id="_idIndexMarker138"/><span class="koboSpan" id="kobo.237.1"> compromise technique, the adversary is trying to gain access by compromising the unique parts of the ML supply chain. </span><span class="koboSpan" id="kobo.237.2">It usually includes hardware used to train the model, such as GPU hardware, data, parts of the software stack, or the model itself. </span><span class="koboSpan" id="kobo.237.3">When it comes to hardware, always verify that you have the latest updates and patches. </span><span class="koboSpan" id="kobo.237.4">When using open source libraries, always check the implementation of those algorithms. </span><span class="koboSpan" id="kobo.237.5">Any updates to the library should be checked for vulnerabilities or malicious code. </span><span class="koboSpan" id="kobo.237.6">Data can be poisoned, especially public data, and private datasets can be compromised during the labeling phase. </span><span class="koboSpan" id="kobo.237.7">If you are using a third-party service to label your data, make sure there are processes in place to protect against data poisoning. </span><span class="koboSpan" id="kobo.237.8">Also, keep versions of your datasets to compare any changes and identify issues if possible. </span><span class="koboSpan" id="kobo.237.9">If you’re using Azure Machine Learning, some capabilities can help you with that. </span><span class="koboSpan" id="kobo.237.10">Finally, if you are using open source models and fine-tuning them using your own private dataset, always verify the source of the model or the libraries, especially when updates are released. </span><span class="koboSpan" id="kobo.237.11">Every time you incorporate new models or execute unknown code, there is the possibility it is infected with </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">traditional malware.</span></span></p>
<h3><span class="koboSpan" id="kobo.239.1">Valid accounts</span></h3>
<p><span class="koboSpan" id="kobo.240.1">In this case, the adversary may obtain</span><a id="_idIndexMarker139"/><span class="koboSpan" id="kobo.241.1"> valid credentials from existing accounts or API access keys. </span><span class="koboSpan" id="kobo.241.2">Especially when using Azure Machine Learning, leaked or stolen credentials may provide access to artifacts and allow the adversary to compromise them. </span><span class="koboSpan" id="kobo.241.3">We should be worried about two levels of access. </span><span class="koboSpan" id="kobo.241.4">The first is the user credentials and user accounts with access to the trained model or pipelines, and the second is the API keys for the inference model </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">or pipeline.</span></span></p>
<h3><span class="koboSpan" id="kobo.243.1">Evade ML model</span></h3>
<p><span class="koboSpan" id="kobo.244.1">Not all attacks are targeted </span><a id="_idIndexMarker140"/><span class="koboSpan" id="kobo.245.1">at your ML project. </span><span class="koboSpan" id="kobo.245.2">An adversary can launch a craft adversarial data attack to prevent an ML model from correctly identifying data contents. </span><span class="koboSpan" id="kobo.245.3">This technique disrupts any task that relies on ML. </span><span class="koboSpan" id="kobo.245.4">Such tasks or processes can be, for example, ML-based malware detection software, network scanning software, or antivirus software that protects the system from traditional cyberattacks. </span><span class="koboSpan" id="kobo.245.5">Mitigations for this technique include model hardening to make ML models robust to specific inputs, behaviors, or atypical queries or using an ensemble of models for inference to increase robustness since an attack can be effective</span><a id="_idIndexMarker141"/><span class="koboSpan" id="kobo.246.1"> against one model type but </span><span class="No-Break"><span class="koboSpan" id="kobo.247.1">not another.</span></span></p>
<h3><span class="koboSpan" id="kobo.248.1">Exploit public-facing applications</span></h3>
<p><span class="koboSpan" id="kobo.249.1">While Azure </span><a id="_idIndexMarker142"/><span class="koboSpan" id="kobo.250.1">provides many security features and complies with several industry-standard protocols for its services, the responsibility for protecting anything from ML to databases, public-facing applications, and internet-accessible endpoints (such as web servers) falls on the customer. </span><span class="koboSpan" id="kobo.250.2">So, when protecting your ML assets, you must think of all the related services using your model. </span><span class="koboSpan" id="kobo.250.3">In this book, we will talk a lot about security practices that have nothing to do with ML just because they apply to related services that use the ML environment, such</span><a id="_idIndexMarker143"/><span class="koboSpan" id="kobo.251.1"> as networks </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">and applications.</span></span></p>
<h2 id="_idParaDest-59"><a id="_idTextAnchor059"/><span class="koboSpan" id="kobo.253.1">ML model access techniques</span></h2>
<p><span class="koboSpan" id="kobo.254.1">There are four techniques</span><a id="_idIndexMarker144"/><span class="koboSpan" id="kobo.255.1"> that can be leveraged</span><a id="_idIndexMarker145"/><span class="koboSpan" id="kobo.256.1"> to access your </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">ML model:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer040">
<span class="koboSpan" id="kobo.258.1"><img alt="Figure 2.5 – ML model access techniques" src="image/B21076_02_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.259.1">Figure 2.5 – ML model access techniques</span></p>
<p><span class="koboSpan" id="kobo.260.1">Let us review each of the ML model </span><span class="No-Break"><span class="koboSpan" id="kobo.261.1">access techniques.</span></span></p>
<h3><span class="koboSpan" id="kobo.262.1">ML model inference API access</span></h3>
<p><span class="koboSpan" id="kobo.263.1">The ML</span><a id="_idIndexMarker146"/><span class="koboSpan" id="kobo.264.1"> model inference API access technique refers to legitimate access to the inference API. </span><span class="koboSpan" id="kobo.264.2">The goal of creating models is to make predictions. </span><span class="koboSpan" id="kobo.264.3">More often than not, those predictions are leveraged from web applications. </span><span class="koboSpan" id="kobo.264.4">The way to accomplish this is to publish the model as a web API for use from the service. </span><span class="koboSpan" id="kobo.264.5">This API can provide an adversary with information about the model type or </span><span class="No-Break"><span class="koboSpan" id="kobo.265.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.266.1">Usually, models are retrained to learn based on input. </span><span class="koboSpan" id="kobo.266.2">That means if you are using the production environment to retrain and improve your model based on actual usage, ensure there is an approval process to check the data coming from public endpoints. </span><span class="koboSpan" id="kobo.266.3">Otherwise, an adversary can introduce false data to the system just by using the </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">inference API.</span></span></p>
<h3><span class="koboSpan" id="kobo.268.1">ML-enabled product or service</span></h3>
<p><span class="koboSpan" id="kobo.269.1">Even if your</span><a id="_idIndexMarker147"/><span class="koboSpan" id="kobo.270.1"> API is not public, the service using it still contains some information about the model and its data. </span><span class="koboSpan" id="kobo.270.2">An application that has access to an inference endpoint still has to send some data to it, which may reveal details of the ML model in logs or metadata. </span><span class="koboSpan" id="kobo.270.3">Hijacking the application opens up the ML service, making it vulnerable to </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">multiple attacks.</span></span></p>
<h3><span class="koboSpan" id="kobo.272.1">Physical environment access</span></h3>
<p><span class="koboSpan" id="kobo.273.1">Attacks </span><a id="_idIndexMarker148"/><span class="koboSpan" id="kobo.274.1">are not only digital. </span><span class="koboSpan" id="kobo.274.2">Suppose the model or the application interacting with the model uses real-world data somehow. </span><span class="koboSpan" id="kobo.274.3">In that case, the adversary can influence the model by accessing the environment where the data has been collected. </span><span class="koboSpan" id="kobo.274.4">For example, if you have an application that streams data from sensors or cameras by accessing the camera feed and poisoning it, the adversary can influence the model. </span><span class="koboSpan" id="kobo.274.5">Ensure that when you are using sensors, they are properly secured in their communication with any form of system and that there’s not a single point of failure in </span><span class="No-Break"><span class="koboSpan" id="kobo.275.1">the hardware.</span></span></p>
<h3><span class="koboSpan" id="kobo.276.1">Full ML model access</span></h3>
<p><span class="koboSpan" id="kobo.277.1">Sometimes, although</span><a id="_idIndexMarker149"/><span class="koboSpan" id="kobo.278.1"> it’s more secure to have the model in a centralized system and query it every time you need a prediction in real life, that’s not always sustainable or performant. </span><span class="koboSpan" id="kobo.278.2">You might be tempted to upload or repackage a mobile version of your model and add it to your edge device, such as your sensors or mobile device. </span><span class="koboSpan" id="kobo.278.3">While this might increase performance and provide faster predictions, this increases the attack surface area. </span><span class="koboSpan" id="kobo.278.4">If possible, consider uploading your model to the cloud with a single access point to reduce the attack </span><span class="No-Break"><span class="koboSpan" id="kobo.279.1">surface area.</span></span></p>
<h2 id="_idParaDest-60"><a id="_idTextAnchor060"/><span class="koboSpan" id="kobo.280.1">Execution techniques</span></h2>
<p><span class="koboSpan" id="kobo.281.1">There are two </span><a id="_idIndexMarker150"/><span class="koboSpan" id="kobo.282.1">execution techniques available, both of which</span><a id="_idIndexMarker151"/><span class="koboSpan" id="kobo.283.1"> rely on specific actions or scripts executed by a user or </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">a tool:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer041">
<span class="koboSpan" id="kobo.285.1"><img alt="Figure 2.6 – Execution techniques" src="image/B21076_02_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.286.1">Figure 2.6 – Execution techniques</span></p>
<p><span class="koboSpan" id="kobo.287.1">Let us explore each of these techniques in the </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">following sections.</span></span></p>
<h3><span class="koboSpan" id="kobo.289.1">User execution</span></h3>
<p><span class="koboSpan" id="kobo.290.1">The adversary will usually rely on</span><a id="_idIndexMarker152"/><span class="koboSpan" id="kobo.291.1"> specific actions made </span><a id="_idIndexMarker153"/><span class="koboSpan" id="kobo.292.1">by a legitimate user to gain execution. </span><span class="koboSpan" id="kobo.292.2">A system user may unknowingly execute unsafe code introduced by the ML supply chain compromise technique or social engineering. </span><span class="koboSpan" id="kobo.292.3">To mitigate this, train your users not to open suspicious or malicious links or documents from unknown sources. </span><span class="koboSpan" id="kobo.292.4">Part of the training should also be for checking the ML artifacts used throughout the ML process, as those can also be poisoned. </span><span class="koboSpan" id="kobo.292.5">Always check the checksum of the file or source and verify that it is secure </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">and unchanged.</span></span></p>
<h3><span class="koboSpan" id="kobo.294.1">Command and scripting interpreter</span></h3>
<p><span class="koboSpan" id="kobo.295.1">Adversaries may use command and script</span><a id="_idIndexMarker154"/><span class="koboSpan" id="kobo.296.1"> interpreters to execute commands in the target system. </span><span class="koboSpan" id="kobo.296.2">Those interfaces provide many ways of interacting with the system, and it’s a standard feature of different technologies. </span><span class="koboSpan" id="kobo.296.3">Depending on the operating system, there are tools included. </span><span class="koboSpan" id="kobo.296.4">For example, in Windows, the Windows Command Shell and PowerShell can be exploited. </span><span class="koboSpan" id="kobo.296.5">There are also interpreters for programming languages such as Python. </span><span class="koboSpan" id="kobo.296.6">Commands and scripts can be embedded in payloads delivered to the target system as documents or downloaded from poisoned sources. </span><span class="koboSpan" id="kobo.296.7">Remote services can also </span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">be used.</span></span></p>
<h2 id="_idParaDest-61"><a id="_idTextAnchor061"/><span class="koboSpan" id="kobo.298.1">Persistence techniques</span></h2>
<p><span class="koboSpan" id="kobo.299.1">Two persistent techniques are available, one</span><a id="_idIndexMarker155"/><span class="koboSpan" id="kobo.300.1"> of which we’ve already discussed in the </span><em class="italic"><span class="koboSpan" id="kobo.301.1">Resource development</span></em><span class="koboSpan" id="kobo.302.1"> section. </span><span class="koboSpan" id="kobo.302.2">The poison training data technique can be used to embed vulnerabilities or insert a backdoor trigger. </span><span class="koboSpan" id="kobo.302.3">Depending on the goal, this can be either a resource development or a </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">persistence technique:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer042">
<span class="koboSpan" id="kobo.304.1"><img alt="Figure 2.7 – Persistence techniques" src="image/B21076_02_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.305.1">Figure 2.7 – Persistence techniques</span></p>
<h3><span class="koboSpan" id="kobo.306.1">Backdoor ML model</span></h3>
<p><span class="koboSpan" id="kobo.307.1">The adversary can introduce a backdoor</span><a id="_idIndexMarker156"/><span class="koboSpan" id="kobo.308.1"> into the ML model based on other techniques, such as the poison training data technique. </span><span class="koboSpan" id="kobo.308.2">A model that includes a back door usually works as expected but will produce a different output when triggered by an input associated with a specific request from the adversary. </span><span class="koboSpan" id="kobo.308.3">This</span><a id="_idIndexMarker157"/><span class="koboSpan" id="kobo.309.1"> technique gives the adversary a persistent artifact on the system. </span><span class="koboSpan" id="kobo.309.2">The back door can be either a model response tailored to the input from the adversary or the invocation of an injected payload that bypasses the model and returns a different set </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">of results.</span></span></p>
<h2 id="_idParaDest-62"><a id="_idTextAnchor062"/><span class="koboSpan" id="kobo.311.1">Defense evasion techniques</span></h2>
<p><span class="koboSpan" id="kobo.312.1">There’s only one defense evasion</span><a id="_idIndexMarker158"/><span class="koboSpan" id="kobo.313.1"> technique we’ve</span><a id="_idIndexMarker159"/><span class="koboSpan" id="kobo.314.1"> already discussed: the evade ML technique. </span><span class="koboSpan" id="kobo.314.2">It can also be used as an initial access technique, and after initial access has been granted, the adversary is not detected by any other software that might be using ML by disrupting </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">its process.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer043">
<span class="koboSpan" id="kobo.316.1"><img alt="Figure 2.8 – Defense evasion techniques" src="image/B21076_02_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.317.1">Figure 2.8 – Defense evasion techniques</span></p>
<h2 id="_idParaDest-63"><a id="_idTextAnchor063"/><span class="koboSpan" id="kobo.318.1">Discovery techniques</span></h2>
<p><span class="koboSpan" id="kobo.319.1">There are</span><a id="_idIndexMarker160"/><span class="koboSpan" id="kobo.320.1"> three discovery techniques that all target getting more </span><a id="_idIndexMarker161"/><span class="koboSpan" id="kobo.321.1">information about the model, its ontology, its family, or </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">the artifacts:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer044">
<span class="koboSpan" id="kobo.323.1"><img alt="Figure 2.9 – Discovery techniques" src="image/B21076_02_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.324.1">Figure 2.9 – Discovery techniques</span></p>
<p><span class="koboSpan" id="kobo.325.1">Let us explain these techniques in the </span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">following sections.</span></span></p>
<h3><span class="koboSpan" id="kobo.327.1">Discover ML model ontology</span></h3>
<p><span class="koboSpan" id="kobo.328.1">To discover</span><a id="_idIndexMarker162"/><span class="koboSpan" id="kobo.329.1"> the ontology of the ML model output, the adversary can analyze the types of objects the model can take as input. </span><span class="koboSpan" id="kobo.329.2">The ontology of the model can also be found in either documentation or configuration files. </span><span class="koboSpan" id="kobo.329.3">To mitigate against this, you can try obfuscating the model’s output and restricting the number of requests the user can make to a model. </span><span class="koboSpan" id="kobo.329.4">Usually, the adversary would have to create a large number of requests for the model to </span><a id="_idIndexMarker163"/><span class="koboSpan" id="kobo.330.1">produce multiple outputs and get useful information from a range </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">of results.</span></span></p>
<h3><span class="koboSpan" id="kobo.332.1">Discover the ML model family</span></h3>
<p><span class="koboSpan" id="kobo.333.1">The adversary </span><a id="_idIndexMarker164"/><span class="koboSpan" id="kobo.334.1">may use examples from the responses and outputs to discover the general family of the model. </span><span class="koboSpan" id="kobo.334.2">Ensure that the family of the model is not public information and cannot be easily guessed by the inputs and outputs of the model. </span><span class="koboSpan" id="kobo.334.3">Passive ML output obfuscation can be used here to mitigate this and restrict the number of requests a user or application can make to the model in a specific amount of time. </span><span class="koboSpan" id="kobo.334.4">Anything you can do to limit knowledge about the model can make it more difficult for the adversary to tailor an attack to your individual technology or </span><span class="No-Break"><span class="koboSpan" id="kobo.335.1">model family.</span></span></p>
<h3><span class="koboSpan" id="kobo.336.1">Discover ML artifacts</span></h3>
<p><span class="koboSpan" id="kobo.337.1">At any point, the adversary</span><a id="_idIndexMarker165"/><span class="koboSpan" id="kobo.338.1"> will try to discover the private or public artifacts you are using in your model. </span><span class="koboSpan" id="kobo.338.2">This process usually starts in the resource development stage, but in this stage, we focus more on private ML artifacts. </span><span class="koboSpan" id="kobo.338.3">To mitigate this, collect and secure any artifacts, such as the software stack, testing and training data, data management systems, container registries, and software repositories. </span><span class="koboSpan" id="kobo.338.4">Encrypt sensitive information and systems where possible. </span><span class="koboSpan" id="kobo.338.5">Azure provides the management of encryption not only in data but also in whole services, such as </span><a id="_idIndexMarker166"/><span class="koboSpan" id="kobo.339.1">Azure </span><span class="No-Break"><span class="koboSpan" id="kobo.340.1">storage accounts.</span></span></p>
<h2 id="_idParaDest-64"><a id="_idTextAnchor064"/><span class="koboSpan" id="kobo.341.1">Collection techniques</span></h2>
<p><span class="koboSpan" id="kobo.342.1">In the </span><a id="_idIndexMarker167"/><span class="koboSpan" id="kobo.343.1">collection stage, we have three techniques that focus</span><a id="_idIndexMarker168"/><span class="koboSpan" id="kobo.344.1"> on </span><span class="No-Break"><span class="koboSpan" id="kobo.345.1">data collection:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer045">
<span class="koboSpan" id="kobo.346.1"><img alt="Figure 2.10 – Collection techniques" src="image/B21076_02_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.347.1">Figure 2.10 – Collection techniques</span></p>
<h3><span class="koboSpan" id="kobo.348.1">ML artifact collection</span></h3>
<p><span class="koboSpan" id="kobo.349.1">The adversary might collect any </span><a id="_idIndexMarker169"/><span class="koboSpan" id="kobo.350.1">useful data or company information for exfiltration as soon as the artifacts are identified. </span><span class="koboSpan" id="kobo.350.2">Suppose the adversary’s goal is not to disrupt the service but to gather information, such as proprietary data, by using your models and datasets. </span><span class="koboSpan" id="kobo.350.3">In that case, the adversary will be interested in getting as many ML artifacts as possible. </span><span class="koboSpan" id="kobo.350.4">Encryption of sensitive information at rest and in transit will help mitigate this to some extent because even if the adversary collects data, they won’t be able to read or </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">use it.</span></span></p>
<h3><span class="koboSpan" id="kobo.352.1">Data from information repositories</span></h3>
<p><span class="koboSpan" id="kobo.353.1">Data for ML is </span><a id="_idIndexMarker170"/><span class="koboSpan" id="kobo.354.1">not always stored in databases or used as datasets. </span><span class="koboSpan" id="kobo.354.2">Machine learning projects usually require collaboration and planning. </span><span class="koboSpan" id="kobo.354.3">Information can also be stored in several information repositories and can be mined to get valuable information. </span><span class="koboSpan" id="kobo.354.4">Information repositories include document-sharing services or project management systems such as SharePoint, Confluence, and Jira. </span><span class="koboSpan" id="kobo.354.5">To mitigate this technique, ensure that the users are trained and informed not to share model endpoints or information on the project management software. </span><span class="koboSpan" id="kobo.354.6">Documentation about the service should also be secured and shared only with people required to possess that information using </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">secure channels.</span></span></p>
<h3><span class="koboSpan" id="kobo.356.1">Data from the local system</span></h3>
<p><span class="koboSpan" id="kobo.357.1">Any data </span><a id="_idIndexMarker171"/><span class="koboSpan" id="kobo.358.1">stored in any local systems must be secured as well. </span><span class="koboSpan" id="kobo.358.2">After gaining access to the network, an adversary may search filesystems’ configuration files and local datasets to extract data, especially sensitive data such as </span><a id="_idIndexMarker172"/><span class="koboSpan" id="kobo.359.1">SSH keys, encryption keys, and </span><span class="No-Break"><span class="koboSpan" id="kobo.360.1">connection information.</span></span></p>
<h2 id="_idParaDest-65"><a id="_idTextAnchor065"/><span class="koboSpan" id="kobo.361.1">ML attack staging techniques</span></h2>
<p><span class="koboSpan" id="kobo.362.1">After data </span><a id="_idIndexMarker173"/><span class="koboSpan" id="kobo.363.1">collection, it makes sense that the adversary will move on to exfiltration to get that data out of the system. </span><span class="koboSpan" id="kobo.363.2">But for ML, there’s a </span><a id="_idIndexMarker174"/><span class="koboSpan" id="kobo.364.1">different stage. </span><span class="koboSpan" id="kobo.364.2">We also have to consider the ML attack staging. </span><span class="koboSpan" id="kobo.364.3">Depending on the adversary’s purpose, they might want to leverage their knowledge to disrupt the service by using several techniques that target the ML model before they try to extract ML data. </span><span class="koboSpan" id="kobo.364.4">Here, we can identify four techniques, one of which is the backdoor ML model technique that can also be used as a persistent technique. </span><span class="koboSpan" id="kobo.364.5">We’ve already discussed it in the </span><em class="italic"><span class="koboSpan" id="kobo.365.1">Backdoor ML model</span></em><span class="koboSpan" id="kobo.366.1"> section, so here, we will talk about </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">the rest:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer046">
<span class="koboSpan" id="kobo.368.1"><img alt="Figure 2.11 – ML attack staging techniques" src="image/B21076_02_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.369.1">Figure 2.11 – ML attack staging techniques</span></p>
<h3><span class="koboSpan" id="kobo.370.1">Create a proxy ML model</span></h3>
<p><span class="koboSpan" id="kobo.371.1">The adversary</span><a id="_idIndexMarker175"/><span class="koboSpan" id="kobo.372.1"> might create an ML model as a proxy for the target model. </span><span class="koboSpan" id="kobo.372.2">Proxy models can be used in a variety of ways. </span><span class="koboSpan" id="kobo.372.3">The adversary might train models from similar datasets, use available pre-trained models, or train a proxy model from ML artifacts they have gathered in previous stages. </span><span class="koboSpan" id="kobo.372.4">The proxy model then can serve to replicate the victim’s inference API or to replicate access to target another model within </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">the organization.</span></span></p>
<h3><span class="koboSpan" id="kobo.374.1">Verify attack</span></h3>
<p><span class="koboSpan" id="kobo.375.1">Before the launch of the</span><a id="_idIndexMarker176"/><span class="koboSpan" id="kobo.376.1"> attack, the adversary might need to verify that the strategy they have developed works. </span><span class="koboSpan" id="kobo.376.2">That means getting an offline or a replicated model and trying out the techniques they have planned. </span><span class="koboSpan" id="kobo.376.3">This gives them the confidence that the attack is effective. </span><span class="koboSpan" id="kobo.376.4">Then, they are free to deploy it in the physical environment or keep it and use it at a later time. </span><span class="koboSpan" id="kobo.376.5">When the adversary has gathered enough information and has the capability to verify the attack in a replicated system they have built that mirrors the victim organization system, it presents a new problem. </span><span class="koboSpan" id="kobo.376.6">The actual attack won’t trigger any significant traffic in the victim’s systems, making the use of this technique </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">potentially </span></span><span class="No-Break"><a id="_idIndexMarker177"/></span><span class="No-Break"><span class="koboSpan" id="kobo.378.1">undetectable.</span></span></p>
<h3><span class="koboSpan" id="kobo.379.1">Craft adversarial data</span></h3>
<p><span class="koboSpan" id="kobo.380.1">The craft adversarial data</span><a id="_idIndexMarker178"/><span class="koboSpan" id="kobo.381.1"> technique that was already mentioned in the </span><em class="italic"><span class="koboSpan" id="kobo.382.1">Evade ML model</span></em><span class="koboSpan" id="kobo.383.1"> section needs information and artifacts collected in multiple stages. </span><span class="koboSpan" id="kobo.383.2">Typically, the result is data poisoning. </span><span class="koboSpan" id="kobo.383.3">Depending on the adversary’s goal, the inputs have been modified, which causes effects such as missed predictions, misclassifications, or the maximizing of the system’s energy consumption. </span><span class="koboSpan" id="kobo.383.4">This attack depends greatly on the adversary’s knowledge of the system. </span><span class="koboSpan" id="kobo.383.5">You can use many different algorithms to develop the adversarial data</span><a id="_idIndexMarker179"/><span class="koboSpan" id="kobo.384.1"> attack, such as white-box optimization, black-box optimization, black-box transfer, or </span><span class="No-Break"><span class="koboSpan" id="kobo.385.1">manual modification.</span></span></p>
<h2 id="_idParaDest-66"><a id="_idTextAnchor066"/><span class="koboSpan" id="kobo.386.1">Exfiltration techniques</span></h2>
<p><span class="koboSpan" id="kobo.387.1">The data is usually extracted in the </span><a id="_idIndexMarker180"/><span class="koboSpan" id="kobo.388.1">exfiltration stage, which</span><a id="_idIndexMarker181"/><span class="koboSpan" id="kobo.389.1"> involves two techniques that apply </span><span class="No-Break"><span class="koboSpan" id="kobo.390.1">to ML:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer047">
<span class="koboSpan" id="kobo.391.1"><img alt="Figure 2.12 – Exfiltration techniques" src="image/B21076_02_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.392.1">Figure 2.12 – Exfiltration techniques</span></p>
<h3><span class="koboSpan" id="kobo.393.1">Exfiltration via ML inference API</span></h3>
<p><span class="koboSpan" id="kobo.394.1">The ML inference API, if </span><a id="_idIndexMarker182"/><span class="koboSpan" id="kobo.395.1">vulnerable, can lead to a leak of private information about the training, the model itself, or private intellectual property. </span><span class="koboSpan" id="kobo.395.2">If the model inference API needs to be public, ensure that you secure it as much as possible and limit the number of queries a user can do in production so that they cannot figure out different ways of getting </span><span class="No-Break"><span class="koboSpan" id="kobo.396.1">that information.</span></span></p>
<h3><span class="koboSpan" id="kobo.397.1">Exfiltration via cyber-means</span></h3>
<p><span class="koboSpan" id="kobo.398.1">Of course, the ML project is not the</span><a id="_idIndexMarker183"/><span class="koboSpan" id="kobo.399.1"> only thing that is vulnerable here. </span><span class="koboSpan" id="kobo.399.2">Depending on the overall security of the environment and the systems, an adversary might choose traditional exfiltration techniques to steal data from your network. </span><span class="koboSpan" id="kobo.399.3">Exfiltration can be accomplished by just transferring data over the network, transferring data over a physical medium such as a removable or cloud drive, or via the</span><a id="_idIndexMarker184"/><span class="koboSpan" id="kobo.400.1"> internet to a web service, a code repository, or directly to </span><span class="No-Break"><span class="koboSpan" id="kobo.401.1">cloud storage.</span></span></p>
<h2 id="_idParaDest-67"><a id="_idTextAnchor067"/><span class="koboSpan" id="kobo.402.1">Impact techniques</span></h2>
<p><span class="koboSpan" id="kobo.403.1">There are seven impact techniques</span><a id="_idIndexMarker185"/><span class="koboSpan" id="kobo.404.1"> available where the adversary </span><a id="_idIndexMarker186"/><span class="koboSpan" id="kobo.405.1">manipulates or interrupts the service for your ML systems or data. </span><span class="koboSpan" id="kobo.405.2">We have already covered the evade ML model technique. </span><span class="koboSpan" id="kobo.405.3">Let us look at the rest of the techniques of </span><span class="No-Break"><span class="koboSpan" id="kobo.406.1">this stage:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer048">
<span class="koboSpan" id="kobo.407.1"><img alt="Figure 2.13 – Impact techniques" src="image/B21076_02_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.408.1">Figure 2.13 – Impact techniques</span></p>
<h3><span class="koboSpan" id="kobo.409.1">Denial of ML service</span></h3>
<p><span class="koboSpan" id="kobo.410.1">Denial-of-service attacks</span><a id="_idIndexMarker187"/><span class="koboSpan" id="kobo.411.1"> target ML systems with multiple requests to disrupt the service. </span><span class="koboSpan" id="kobo.411.2">Since endpoints have finite resources, by using a denial-of-service attack, an adversary can create bottlenecks which can be expensive and disrupt the service so that it cannot serve other requests, rendering the service useless. </span><span class="koboSpan" id="kobo.411.3">There are a couple of things you can do to mitigate them that involve deploying third-party Azure services, but the first step would probably be to restrict the number of ML </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1">model requests.</span></span></p>
<h3><span class="koboSpan" id="kobo.413.1">Spam ML systems with chaff data</span></h3>
<p><span class="koboSpan" id="kobo.414.1">This technique requires the adversary to</span><a id="_idIndexMarker188"/><span class="koboSpan" id="kobo.415.1"> know that the system probably uses the data for predictions to retrain the service. </span><span class="koboSpan" id="kobo.415.2">Spamming the system with many requests and data that does not make sense will increase the number of predictions or false predictions. </span><span class="koboSpan" id="kobo.415.3">It will cause analysts or data scientists working on improving the system to waste much time reviewing and correcting those incorrect inferences. </span><span class="koboSpan" id="kobo.415.4">There are capabilities of Azure Machine Learning that we will talk about to mitigate this. </span><span class="koboSpan" id="kobo.415.5">However, the obvious choice here is to restrict the number of ML model queries or block traffic from suspicious endpoints that make multiple </span><span class="No-Break"><span class="koboSpan" id="kobo.416.1">unrelated requests.</span></span></p>
<h3><span class="koboSpan" id="kobo.417.1">Erode ML model integrity</span></h3>
<p><span class="koboSpan" id="kobo.418.1">This technique </span><a id="_idIndexMarker189"/><span class="koboSpan" id="kobo.419.1">combines spamming the system with data and using adversarial data to degrade the model’s performance. </span><span class="koboSpan" id="kobo.419.2">This doesn’t have to be a one-time event. </span><span class="koboSpan" id="kobo.419.3">The attack can be ongoing for quite some time, so the ML system is eroded and predictions are inaccurate. </span><span class="koboSpan" id="kobo.419.4">This attack might be more difficult to detect since it does not have the goal of disrupting the service; it wants to subtly make changes to the model that are not detectable over a long period </span><span class="No-Break"><span class="koboSpan" id="kobo.420.1">of time.</span></span></p>
<h3><span class="koboSpan" id="kobo.421.1">Harvest cost</span></h3>
<p><span class="koboSpan" id="kobo.422.1">Systems have finite </span><a id="_idIndexMarker190"/><span class="koboSpan" id="kobo.423.1">resources, and</span><a id="_idIndexMarker191"/><span class="koboSpan" id="kobo.424.1"> usually, when someone is launching multiple requests bombarding the system with so much data, it interrupts the service. </span><span class="koboSpan" id="kobo.424.2">With cloud computing, infrastructure doesn’t have to be a finite resource. </span><span class="koboSpan" id="kobo.424.3">Cloud systems can scale to accommodate increased traffic, but at the same time, auto-scaling affects the costs of those resources. </span><span class="koboSpan" id="kobo.424.4">Restricting the number of queries per application or detecting those kinds of attacks can mitigate this technique, which targets the operational costs of the </span><span class="No-Break"><span class="koboSpan" id="kobo.425.1">victim’s organization.</span></span></p>
<h3><span class="koboSpan" id="kobo.426.1">ML intellectual property theft</span></h3>
<p><span class="koboSpan" id="kobo.427.1">Sometimes </span><a id="_idIndexMarker192"/><span class="koboSpan" id="kobo.428.1">the target is the model itself. </span><span class="koboSpan" id="kobo.428.2">Let’s say you provide ML as a service. </span><span class="koboSpan" id="kobo.428.3">Someone who has managed to extract that model now has unlimited use of your service without paying. </span><span class="koboSpan" id="kobo.428.4">That can have a significant impact, as the intellectual property is unsafe and can cause economic harm to your organization. </span><span class="koboSpan" id="kobo.428.5">Mitigations for this technique include controlling access to your models and data at rest, securing your models and data in transit, and encrypting services and data </span><span class="No-Break"><span class="koboSpan" id="kobo.429.1">where possible.</span></span></p>
<h3><span class="koboSpan" id="kobo.430.1">System misuse for external effect</span></h3>
<p><span class="koboSpan" id="kobo.431.1">If the adversary cannot </span><a id="_idIndexMarker193"/><span class="koboSpan" id="kobo.432.1">extract the model, they might still attack the system and use it for their own purpose. </span><span class="koboSpan" id="kobo.432.2">Hijacking the system and using their own data to get results or predictions could be an example. </span><span class="koboSpan" id="kobo.432.3">By gaining access to a system that monitors and protects financial data, the adversary might be able to pass invoices that otherwise would be flagged as invalid. </span><span class="koboSpan" id="kobo.432.4">As a result, this prohibits the system from </span><span class="No-Break"><span class="koboSpan" id="kobo.433.1">preventing fraud.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.434.1">Case studies and examples</span></p>
<p class="callout"><span class="koboSpan" id="kobo.435.1">For more case studies, you can check the </span><em class="italic"><span class="koboSpan" id="kobo.436.1">Further reading </span></em><span class="koboSpan" id="kobo.437.1">section of this chapter or access the complete knowledge base </span><span class="No-Break"><span class="koboSpan" id="kobo.438.1">at </span></span><a href="https://atlas.mitre.org/"><span class="No-Break"><span class="koboSpan" id="kobo.439.1">https://atlas.mitre.org/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.440.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.441.1">After seeing the </span><a id="_idIndexMarker194"/><span class="koboSpan" id="kobo.442.1">types of generic techniques used in attacks, let us explore the actual services that can be affected in the case of </span><span class="No-Break"><span class="koboSpan" id="kobo.443.1">an attack.</span></span></p>
<h1 id="_idParaDest-68"><a id="_idTextAnchor068"/><span class="koboSpan" id="kobo.444.1">Exploring Azure services involved in ML attacks</span></h1>
<p><span class="koboSpan" id="kobo.445.1">As you can see, attacks </span><a id="_idIndexMarker195"/><span class="koboSpan" id="kobo.446.1">are multi-level and primarily based on the adversary’s goal. </span><span class="koboSpan" id="kobo.446.2">Since we do not know what that is, we can deploy multiple mitigation techniques to lessen the impact. </span><span class="koboSpan" id="kobo.446.3">As Azure Machine Learning is based on the Azure platform, we can deploy numerous tools to detect an incident, and by using automation, the platform will deploy mitigation steps before we are even aware that something has happened. </span><span class="koboSpan" id="kobo.446.4">Although we focused on ML attacks, attacks on related systems, virtual machines, and databases are still a concern. </span><span class="koboSpan" id="kobo.446.5">Let us look at associated </span><a id="_idIndexMarker196"/><span class="koboSpan" id="kobo.447.1">services that can be used together with </span><strong class="bold"><span class="koboSpan" id="kobo.448.1">Azure </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.449.1">Machine Learning</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.450.1">.</span></span></p>
<h2 id="_idParaDest-69"><a id="_idTextAnchor069"/><span class="koboSpan" id="kobo.451.1">Access</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.452.1">Microsoft Entra ID</span></strong><span class="koboSpan" id="kobo.453.1"> usually</span><a id="_idIndexMarker197"/><span class="koboSpan" id="kobo.454.1"> handles access in Azure. </span><span class="koboSpan" id="kobo.454.2">Microsoft Entra ID is </span><a id="_idIndexMarker198"/><span class="koboSpan" id="kobo.455.1">Microsoft’s cloud-based identity and access management service. </span><span class="koboSpan" id="kobo.455.2">It provides a range of features and capabilities to manage user identities and secure access to various resources in the Azure cloud and other Microsoft services. </span><span class="koboSpan" id="kobo.455.3">Besides identity and access management, it also</span><a id="_idIndexMarker199"/><span class="koboSpan" id="kobo.456.1"> provides </span><strong class="bold"><span class="koboSpan" id="kobo.457.1">Federation</span></strong><span class="koboSpan" id="kobo.458.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.459.1">single sign-on</span></strong><span class="koboSpan" id="kobo.460.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.461.1">SSO)</span></strong><span class="koboSpan" id="kobo.462.1">, a</span><a id="_idIndexMarker200"/><span class="koboSpan" id="kobo.463.1"> developer platform, and various features for security and governance. </span><span class="koboSpan" id="kobo.463.2">Different services might also offer different ways of authentication, such as via service credentials, access keys, and shared access signatures. </span><span class="koboSpan" id="kobo.463.3">We will focus on learning how to secure and mitigate all those services in the </span><span class="No-Break"><span class="koboSpan" id="kobo.464.1">following chapters.</span></span></p>
<h2 id="_idParaDest-70"><a id="_idTextAnchor070"/><span class="koboSpan" id="kobo.465.1">Data</span></h2>
<p><span class="koboSpan" id="kobo.466.1">ML is </span><a id="_idIndexMarker201"/><span class="koboSpan" id="kobo.467.1">based on </span><a id="_idIndexMarker202"/><span class="koboSpan" id="kobo.468.1">data. </span><span class="koboSpan" id="kobo.468.2">Azure </span><a id="_idIndexMarker203"/><span class="koboSpan" id="kobo.469.1">Machine Learning supports</span><a id="_idIndexMarker204"/><span class="koboSpan" id="kobo.470.1"> multiple data sources, specifically </span><strong class="bold"><span class="koboSpan" id="kobo.471.1">Azure Blob</span></strong><span class="koboSpan" id="kobo.472.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.473.1">File Storage</span></strong><span class="koboSpan" id="kobo.474.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.475.1">Azure Data Lake</span></strong><span class="koboSpan" id="kobo.476.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.477.1">Azure SQL Database</span></strong><span class="koboSpan" id="kobo.478.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.479.1">Azure PostgreSQL</span></strong><span class="koboSpan" id="kobo.480.1"> database, and </span><strong class="bold"><span class="koboSpan" id="kobo.481.1">Azure MySQL</span></strong><span class="koboSpan" id="kobo.482.1"> database, each </span><a id="_idIndexMarker205"/><span class="koboSpan" id="kobo.483.1">with individual security and monitoring</span><a id="_idIndexMarker206"/><span class="koboSpan" id="kobo.484.1"> features. </span><span class="koboSpan" id="kobo.484.2">We will be working with their security and</span><a id="_idIndexMarker207"/><span class="koboSpan" id="kobo.485.1"> monitoring features, including encryption at rest and encryption in transit, in the </span><span class="No-Break"><span class="koboSpan" id="kobo.486.1">upcoming chapters.</span></span></p>
<h2 id="_idParaDest-71"><a id="_idTextAnchor071"/><span class="koboSpan" id="kobo.487.1">Network</span></h2>
<p><span class="koboSpan" id="kobo.488.1">Although not directly related </span><a id="_idIndexMarker208"/><span class="koboSpan" id="kobo.489.1">to Azure Machine Learning, many attacks happen by infiltrating the on-premises or cloud network. </span><span class="koboSpan" id="kobo.489.2">In the following chapters, we will discuss securing the service using network services. </span><span class="koboSpan" id="kobo.489.3">These include virtual networks, network security </span><a id="_idIndexMarker209"/><span class="koboSpan" id="kobo.490.1">groups, </span><strong class="bold"><span class="koboSpan" id="kobo.491.1">Azure Firewall</span></strong><span class="koboSpan" id="kobo.492.1">, and</span><a id="_idIndexMarker210"/><span class="koboSpan" id="kobo.493.1"> hybrid solutions such as </span><strong class="bold"><span class="koboSpan" id="kobo.494.1">VPN gateways</span></strong><span class="koboSpan" id="kobo.495.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.496.1">ExpressRoute</span></strong><span class="koboSpan" id="kobo.497.1">. </span><span class="koboSpan" id="kobo.497.2">The </span><strong class="bold"><span class="koboSpan" id="kobo.498.1">Service Endpoints</span></strong><span class="koboSpan" id="kobo.499.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.500.1">Private Endpoints</span></strong><span class="koboSpan" id="kobo.501.1"> features can also be used for </span><a id="_idIndexMarker211"/><span class="koboSpan" id="kobo.502.1">better security </span><span class="No-Break"><span class="koboSpan" id="kobo.503.1">and isolation.</span></span></p>
<p><span class="koboSpan" id="kobo.504.1">An Azure </span><strong class="bold"><span class="koboSpan" id="kobo.505.1">virtual network</span></strong><span class="koboSpan" id="kobo.506.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.507.1">VNet</span></strong><span class="koboSpan" id="kobo.508.1">) is </span><a id="_idIndexMarker212"/><span class="koboSpan" id="kobo.509.1">a fundamental component of Microsoft Azure’s networking architecture. </span><span class="koboSpan" id="kobo.509.2">It is a logically isolated network environment that allows you to </span><a id="_idIndexMarker213"/><span class="koboSpan" id="kobo.510.1">securely connect and control Azure resources, including </span><strong class="bold"><span class="koboSpan" id="kobo.511.1">virtual machines</span></strong><span class="koboSpan" id="kobo.512.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.513.1">VMs</span></strong><span class="koboSpan" id="kobo.514.1">), </span><strong class="bold"><span class="koboSpan" id="kobo.515.1">Azure App Service</span></strong><span class="koboSpan" id="kobo.516.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.517.1">and</span></span><span class="No-Break"><a id="_idIndexMarker214"/></span><span class="No-Break"><span class="koboSpan" id="kobo.518.1"> databases.</span></span></p>
<p><span class="koboSpan" id="kobo.519.1">Azure VNets usually work together </span><a id="_idIndexMarker215"/><span class="koboSpan" id="kobo.520.1">with </span><strong class="bold"><span class="koboSpan" id="kobo.521.1">network security groups </span></strong><span class="koboSpan" id="kobo.522.1">(</span><strong class="bold"><span class="koboSpan" id="kobo.523.1">NSGs</span></strong><span class="koboSpan" id="kobo.524.1">), which provide granular network security and act as a basic firewall, allowing you to define inbound and outbound traffic rules to filter and control network traffic. </span><span class="koboSpan" id="kobo.524.2">NSGs do not maintain state but are the first step to securing the </span><span class="No-Break"><span class="koboSpan" id="kobo.525.1">network traffic.</span></span></p>
<p><span class="koboSpan" id="kobo.526.1">Azure Firewall is a</span><a id="_idIndexMarker216"/><span class="koboSpan" id="kobo.527.1"> cloud-based network security service offered by Microsoft Azure. </span><span class="koboSpan" id="kobo.527.2">It provides centralized, high-level network security and protection for VNets. </span><span class="koboSpan" id="kobo.527.3">Azure Firewall acts as a fully stateful network traffic filtering and routing solution, allowing you to control and monitor both inbound and outbound traffic to and from your </span><span class="No-Break"><span class="koboSpan" id="kobo.528.1">Azure resources.</span></span></p>
<p><span class="koboSpan" id="kobo.529.1">An Azure VPN gateway</span><a id="_idIndexMarker217"/><span class="koboSpan" id="kobo.530.1"> is a networking component that enables secure connectivity between on-premises networks and VNets. </span><span class="koboSpan" id="kobo.530.2">It provides a way to establish a </span><strong class="bold"><span class="koboSpan" id="kobo.531.1">virtual private network</span></strong><span class="koboSpan" id="kobo.532.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.533.1">VPN</span></strong><span class="koboSpan" id="kobo.534.1">) tunnel</span><a id="_idIndexMarker218"/><span class="koboSpan" id="kobo.535.1"> over the public internet, ensuring secure communication and extending your on-premises network into the </span><span class="No-Break"><span class="koboSpan" id="kobo.536.1">Azure cloud.</span></span></p>
<p><span class="koboSpan" id="kobo.537.1">If the VPN gateway is not enough, you can use </span><a id="_idIndexMarker219"/><span class="koboSpan" id="kobo.538.1">Azure ExpressRoute. </span><span class="koboSpan" id="kobo.538.2">This is a Microsoft Azure service that enables private and dedicated network connectivity between your on-premises network and Azure. </span><span class="koboSpan" id="kobo.538.3">It provides a reliable, high-throughput, low-latency connection, bypassing the </span><span class="No-Break"><span class="koboSpan" id="kobo.539.1">public internet.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.540.1">Service Endpoints</span></strong><span class="koboSpan" id="kobo.541.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.542.1">Private Endpoints</span></strong><span class="koboSpan" id="kobo.543.1"> are two</span><a id="_idIndexMarker220"/><span class="koboSpan" id="kobo.544.1"> features in Azure that provide secure and private </span><a id="_idIndexMarker221"/><span class="koboSpan" id="kobo.545.1">connectivity to Azure services. </span><span class="koboSpan" id="kobo.545.2">Service Endpoints allows you to extend your VNet to the Azure service’s backend, providing secure access to that service over the Azure backbone network. </span><span class="koboSpan" id="kobo.545.3">Private Endpoints allows you to</span><a id="_idIndexMarker222"/><span class="koboSpan" id="kobo.546.1"> access Azure services privately from your VNet using a private </span><span class="No-Break"><span class="koboSpan" id="kobo.547.1">IP address.</span></span></p>
<h2 id="_idParaDest-72"><a id="_idTextAnchor072"/><span class="koboSpan" id="kobo.548.1">Applications</span></h2>
<p><span class="koboSpan" id="kobo.549.1">Applications can </span><a id="_idIndexMarker223"/><span class="koboSpan" id="kobo.550.1">be hosted in multiple services inside and outside of Azure. </span><span class="koboSpan" id="kobo.550.2">Most ML services are intended to be used by an application, which is another component we need to consider when we are working on implementing security. </span><span class="koboSpan" id="kobo.550.3">In this book, we will learn how to secure services that host applications such as Azure App Service, VMs, or </span><strong class="bold"><span class="koboSpan" id="kobo.551.1">container</span></strong><span class="koboSpan" id="kobo.552.1"> services, but </span><a id="_idIndexMarker224"/><span class="koboSpan" id="kobo.553.1">we will also analyze some best practices for developing software applications. </span><span class="koboSpan" id="kobo.553.2">Of course, since the implementation of application security heavily depends on the programming language and libraries used, we will explain the high-level implementation of mitigation techniques</span><a id="_idIndexMarker225"/><span class="koboSpan" id="kobo.554.1"> such as SQL injection or </span><span class="No-Break"><span class="koboSpan" id="kobo.555.1">cross-site scripting.</span></span></p>
<h2 id="_idParaDest-73"><a id="_idTextAnchor073"/><span class="koboSpan" id="kobo.556.1">Compute</span></h2>
<p><span class="koboSpan" id="kobo.557.1">ML </span><a id="_idIndexMarker226"/><span class="koboSpan" id="kobo.558.1">relies</span><a id="_idIndexMarker227"/><span class="koboSpan" id="kobo.559.1"> heavily on computational resources. </span><span class="koboSpan" id="kobo.559.2">You can create multiple </span><a id="_idIndexMarker228"/><span class="koboSpan" id="kobo.560.1">compute targets for training or hosting inference </span><a id="_idIndexMarker229"/><span class="koboSpan" id="kobo.561.1">models </span><a id="_idIndexMarker230"/><span class="koboSpan" id="kobo.562.1">in the workspace. </span><span class="koboSpan" id="kobo.562.2">Targets can be local compute, </span><strong class="bold"><span class="koboSpan" id="kobo.563.1">Azure Machine Learning compute</span></strong><span class="koboSpan" id="kobo.564.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.565.1">Azure Databricks</span></strong><span class="koboSpan" id="kobo.566.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.567.1">HDInsight</span></strong><span class="koboSpan" id="kobo.568.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.569.1">Synapse Spark pools</span></strong><span class="koboSpan" id="kobo.570.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.571.1">Azure Kubernetes Service</span></strong><span class="koboSpan" id="kobo.572.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.573.1">AKS</span></strong><span class="koboSpan" id="kobo.574.1">), and Azure </span><a id="_idIndexMarker231"/><span class="koboSpan" id="kobo.575.1">VMs. </span><span class="koboSpan" id="kobo.575.2">These compute targets provide the necessary resources and infrastructure to run ML workloads at scale. </span><span class="koboSpan" id="kobo.575.3">They must be secured and monitored properly, as they are a critical part </span><span class="No-Break"><span class="koboSpan" id="kobo.576.1">of ML.</span></span></p>
<p><span class="koboSpan" id="kobo.577.1">Local compute</span><a id="_idIndexMarker232"/><span class="koboSpan" id="kobo.578.1"> allows you to use your local machine or on-premises infrastructure as the compute target. </span><span class="koboSpan" id="kobo.578.2">This is useful for development and experimentation when you don’t require </span><span class="No-Break"><span class="koboSpan" id="kobo.579.1">large-scale resources.</span></span></p>
<p><span class="koboSpan" id="kobo.580.1">Azure Machine Learning compute</span><a id="_idIndexMarker233"/><span class="koboSpan" id="kobo.581.1"> is a managed compute cluster provided by Azure Machine Learning. </span><span class="koboSpan" id="kobo.581.2">It dynamically provisions and scales compute resources based on your workload requirements. </span><span class="koboSpan" id="kobo.581.3">It supports both CPU and GPU instances and is optimized for running training jobs </span><span class="No-Break"><span class="koboSpan" id="kobo.582.1">at scale.</span></span></p>
<p><span class="koboSpan" id="kobo.583.1">Azure Databricks</span><a id="_idIndexMarker234"/><span class="koboSpan" id="kobo.584.1"> is an Apache Spark-based analytics platform that integrates with Azure Machine Learning. </span><span class="koboSpan" id="kobo.584.2">You can use Azure Databricks clusters as a compute target for training and deploying ML models, taking advantage of the distributed computing capabilities of Spark. </span><span class="koboSpan" id="kobo.584.3">If you still want to use Spark but are not using Databricks, you can use Azure Synapse </span><span class="No-Break"><span class="koboSpan" id="kobo.585.1">Spark pools.</span></span></p>
<p><span class="koboSpan" id="kobo.586.1">Azure HDInsight</span><a id="_idIndexMarker235"/><span class="koboSpan" id="kobo.587.1"> can also be set up as a compute target in Azure Machine Learning. </span><span class="koboSpan" id="kobo.587.2">Using its distributed processing capabilities allows you to execute ML tasks on </span><span class="No-Break"><span class="koboSpan" id="kobo.588.1">HDInsight clusters.</span></span></p>
<p><span class="koboSpan" id="kobo.589.1">AKS is a </span><a id="_idIndexMarker236"/><span class="koboSpan" id="kobo.590.1">managed Kubernetes service in Azure. </span><span class="koboSpan" id="kobo.590.2">You can deploy your ML workloads as containerized applications on AKS and use them as a compute target for training and serving models. </span><span class="koboSpan" id="kobo.590.3">AKS provides scalability and flexibility for running distributed training and </span><span class="No-Break"><span class="koboSpan" id="kobo.591.1">inference workloads.</span></span></p>
<p><span class="koboSpan" id="kobo.592.1">Azure VM instances</span><a id="_idIndexMarker237"/><span class="koboSpan" id="kobo.593.1"> can also </span><a id="_idIndexMarker238"/><span class="koboSpan" id="kobo.594.1">be a compute target. </span><span class="koboSpan" id="kobo.594.2">You can provision VMs with the required specifications and use them for training and deploying </span><span class="No-Break"><span class="koboSpan" id="kobo.595.1">ML models.</span></span></p>
<h2 id="_idParaDest-74"><a id="_idTextAnchor074"/><span class="koboSpan" id="kobo.596.1">Azure Machine Learning</span></h2>
<p><span class="koboSpan" id="kobo.597.1">All </span><a id="_idIndexMarker239"/><span class="koboSpan" id="kobo.598.1">previously mentioned services relate to</span><a id="_idIndexMarker240"/><span class="koboSpan" id="kobo.599.1"> or can be used with the </span><strong class="bold"><span class="koboSpan" id="kobo.600.1">Azure Machine Learning workspace</span></strong><span class="koboSpan" id="kobo.601.1">. </span><span class="koboSpan" id="kobo.601.2">The workspace</span><a id="_idIndexMarker241"/><span class="koboSpan" id="kobo.602.1"> is the main point of management</span><a id="_idIndexMarker242"/><span class="koboSpan" id="kobo.603.1"> for Azure Machine Learning; however, the workspace itself can be used for security or isolation, for example, if multiple workspaces might be needed for different scenarios. </span><span class="koboSpan" id="kobo.603.2">The workspace provides multiple features for monitoring and organizing assets such as model and dataset versioning and data drift. </span><span class="koboSpan" id="kobo.603.3">We will also explore security features in algorithms, data, and models, such as fairness, data anonymization, </span><span class="No-Break"><span class="koboSpan" id="kobo.604.1">and more.</span></span></p>
<p><span class="koboSpan" id="kobo.605.1">Now, we’ve learned about the services related to Azure Machine Learning that we need to protect. </span><span class="koboSpan" id="kobo.605.2">They might not be the only ones—it depends on your system architecture—but they are a great start to your </span><span class="No-Break"><span class="koboSpan" id="kobo.606.1">security journey.</span></span></p>
<h1 id="_idParaDest-75"><a id="_idTextAnchor075"/><span class="koboSpan" id="kobo.607.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.608.1">There are many attacks to be prepared for and vulnerabilities are discovered daily, so we must follow a framework that helps us keep up to date with current vulnerabilities and their mitigations where possible. </span><span class="koboSpan" id="kobo.608.2">The MITRE ATLAS framework is a great resource to get started as it is adapted to ML. </span><span class="koboSpan" id="kobo.608.3">We need to be aware of the 12 stages and multiple techniques per stage to protect our ML assets. </span><span class="koboSpan" id="kobo.608.4">However, as ML assets work with numerous other systems, the implementations we will see in the following chapters will include securing Azure Machine Learning and all its </span><span class="No-Break"><span class="koboSpan" id="kobo.609.1">related services.</span></span></p>
<p><span class="koboSpan" id="kobo.610.1">But before diving into those implementations, in the next chapter, we will learn about the security industry compliance standards we must adhere to and how to implement compliance controls together with responsible AI </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1">development practices.</span></span></p>
<h1 id="_idParaDest-76"><a id="_idTextAnchor076"/><span class="koboSpan" id="kobo.612.1">Further reading</span></h1>
<ul>
<li><span class="koboSpan" id="kobo.613.1">DeepPayload: Black-box Backdoor Attack on Deep Learning Models through Neural Payload </span><span class="No-Break"><span class="koboSpan" id="kobo.614.1">Injection: </span></span><a href="https://arxiv.org/abs/2101.06896"><span class="No-Break"><span class="koboSpan" id="kobo.615.1">https://arxiv.org/abs/2101.06896</span></span></a></li>
<li><span class="koboSpan" id="kobo.616.1">Imitation Attacks and Defenses for Black-box Machine Translation </span><span class="No-Break"><span class="koboSpan" id="kobo.617.1">Systems: </span></span><a href="https://arxiv.org/abs/2004.15015"><span class="No-Break"><span class="koboSpan" id="kobo.618.1">https://arxiv.org/abs/2004.15015</span></span></a></li>
<li><span class="koboSpan" id="kobo.619.1">Explaining and Harnessing Adversarial </span><span class="No-Break"><span class="koboSpan" id="kobo.620.1">Examples: </span></span><span class="No-Break"><span class="koboSpan" id="kobo.621.1">https://arxiv.org/abs/1412.6572</span></span></li>
</ul>
</div>
</body></html>