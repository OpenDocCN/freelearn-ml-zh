["```py\n    $ az login\n    ```", "```py\n    $ az account show --output table\n    ```", "```py\n$ az account set --subscription \"<yoursub>\"\n```", "```py\n    $ az extension list\n    ```", "```py\n    $ az extension remove -n azure-cli-ml\n    $ az extension remove -n ml\n    ```", "```py\n    $ az extension add -n ml\n    ```", "```py\n    $ az ml -h\n    ```", "```py\ncode: Manage Azure ML code assets.\ncompute: Manage Azure ML compute resources.\ndata: Manage Azure ML data assets.\ndatastore: Manage Azure ML datastores.\nendpoint: Manage Azure ML endpoints.\nenvironment: Manage Azure ML environments.\njob: Manage Azure ML jobs.\nmodel: Manage Azure ML models.\nworkspace: Manage Azure ML workspaces.\n```", "```py\n    $ az ml workspace create -h\n    ```", "```py\n    $ az account list-locations -o table\n    ```", "```py\n$ az group create -n mldemo -l westus2\n```", "```py\n    $ az ml workspace create -w mldemows -g mldemo -l westus2\n    ```", "```py\nAppInsights  Done (7s)\nStorageAccount ...  Done (31s)\nKeyVault  Done (23s)\nWorkspace ................  Done (1m 49s)\nTotal time : 2m 26s\n{\n\"application_insights\": \"/subscriptions/... \",\n\"description\": \"mldemows\",\n\"discovery_url\":\"https://westus2.api.azureml.ms/discovery\",\n\"friendly_name\": \"mldemows\",\n\"hbi_workspace\": false,\n\"key_vault\": \"/subscriptions/... \",\n\"location\": \"westus2\",\n\"mlflow_tracking_uri\": \"azureml://westus2.api.azureml.ms/mlflow/v1.0/subscriptions/... \",\n\"name\": \"mldemows\",\n\"storage_account\": \"/subscriptions/... \",\n\"tags\": {}\n}\n```", "```py\n    $ az ml workspace show -g mldemo -w mldemows\n    ```", "```py\n$schema: https://.../commandJob.schema.json\ncode:\n  local_path: <path-to-python-scripts>\ncommand: python <script-name> --data {inputs.trainingData1}\nenvironment:\n  docker:\n    image: docker.io/python\ncompute:\n  target: azureml:goazurego\ninputs:\n  trainingData1:\n    mode: mount\n    data:\n      local_path: <path-to-training-data>\n```", "```py\n    $ python --version\n    ```", "```py\n    $ sudo apt-get install python3.8\n    ```", "```py\n    $ python -m pip install azureml-sdk\n    ```", "```py\n    $ python -m pip install jupyterlab \n    $ python -m pip install notebook\n    ```", "```py\n$ jupyter-lab\n$ jupyter notebook\n```", "```py\n    $ python -m pip install -r .azureml/requirements.txt\n    ```", "```py\n    from azureml.core import Workspace\n    ws = Workspace.from_config()\n    ```", "```py\nimport tensorflow\nfrom tensorflow.keras.datasets import cifar10\n…\n```", "```py\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n…\ny_train = tensorflow.keras.utils.to_categorical\n                         (y_train, num_classes)\n…\n```", "```py\nmodel = Sequential()\n…\nmodel_name       = 'keras_cifar10_trained_model.h5'\nmodel_output_dir = os.path.join(os.getcwd(), 'outputs')\n```", "```py\nopt = RMSprop(learning_rate=0.0001, decay=1e-6)\n…\ncheckpoint_cb = ModelCheckpoint(model_path, \n                                monitor='val_loss',\n                                save_best_only=True)\n…\nmodel.compile(loss='categorical_crossentropy', \n              optimizer=opt, \n              metrics=['accuracy'])\n```", "```py\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(x_test, y_test),\n          shuffle=True,\n          callbacks=[azureml_cb, checkpoint_cb])\n```", "```py\nfrom azureml.core import Workspace, Experiment\nws  = Workspace.from_config()\nexp = Experiment(workspace=ws, name=\"cifar10_cnn_local\")\n```", "```py\n# Create and start an interactive run\nrun = exp.start_logging(snapshot_directory='.')\n```", "```py\nrun = exp.start_logging(snapshot_directory='.')\ntry:\n  # train your model here\n  run.complete()\nexcept:\n  run.cancel()\n  raise\n```", "```py\nwith exp.start_logging(snapshot_directory='.') as run:\n  # train your model here\n  pass\n```", "```py\nimport os\nfrom keras.calbacks import ModelCheckpoint\nmodel_output_dir = os.path.join(os.getcwd(), 'outputs')\nmodel_name       = 'keras_cifar10_trained_model.h5'\nmodel_path       = os.path.join(model_output_dir, model_name)\n# define a checkpoint callback\ncheckpoint_cb = ModelCheckpoint(model_path,\n                                monitor='val_loss',\n                                save_best_only=True)\n# train the model\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_split=0.2,\n          shuffle=True,\n          callbacks=[checkpoint_cb])\n```", "```py\n# Upload the best model\nrun.upload_file(model_name, model_path)\n# Register the best model\nrun.register_model(model_name, model_path=model_name, \n    model_framework='TfKeras')\n```", "```py\n# load the overall best model into the model object\nmodel = load_model(model_path)\n# evaluate the best model against the test dataset\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss of best model:', scores[0])\nrun.log('Test loss', scores[0])\nprint('Test accuracy of best model:', scores[1])\nrun.log('Test accuracy', scores[1])\n```", "```py\nfrom keras.callbacks import Callback\nimport numpy as np\nclass AzureMlKerasCallback(Callback):\n    def __init__(self, run):\n        super(AzureMlKerasCallback, self).__init__()\n        self.run = run\n    def on_epoch_end(self, epoch, logs=None):\n        # logs is filled by Keras at the end of an epoch\n        logs = logs or {}\n        for metric_name, metric_val in logs.items():\n          if isinstance(metric_val, (np.ndarray, np.generic)):\n           self.run.log_list(metric_name, metric_val.tolist())\n          else:\n           self.run.log(metric_name, metric_val)\n```", "```py\n# create an Azure Machine Learning monitor callback\nazureml_cb = AzureMlKerasCallback(run)\nmodel.fit(x_train, y_train,\n  batch_size=batch_size,\n  epochs=epochs,\n  validation_data=(x_test, y_test),\n  callbacks=[azureml_cb, checkpoint_cb])\n```", "```py\nfrom azureml.core import Run\ndef get_metrics_from_exp(exp, metric, status='Completed'):\n  for run in Run.list(exp, status=status):\n    yield run.get_metrics().get(metric)\n```", "```py\n# get the highest test accuracy\nbest_test_acc = max(get_metrics_from_exp(\n                    exp,'Test accuracy')\n                    default = 0)\n# upload the model\nrun.upload_file(model_name, model_path)\nif scores[1] > best_test_acc:\n  # register the best model as a new version\n  run.register_model(model_name, model_path=model_name)\n```", "```py\nfrom azureml.core.environment import Environment\nmyenv = Environment(name = \"user-managed-env\")\nmyenv.python.user_managed_dependencies = True\n```", "```py\nimport os\nscript = 'cifar10_cnn_remote.py'\nscript_folder = os.path.join(os.getcwd(), 'code')\n```", "```py\nfrom azureml.core import ScriptRunConfig\nrunconfig = ScriptRunConfig(source_directory=script_folder,\n                            script=script,\n                            environment = myenv)\nrun = exp.submit(runconfig)\nrun.wait_for_completion(show_output=True)\n```", "```py\nfrom azureml.widgets import RunDetails\nRunDetails(run).show()\n```", "```py\n# log output of the script \nlogging.basicConfig(filename='logs/debug.log', \n                    filemode='w',\n                    level=logging.DEBUG)\nlogger_cb = CSVLogger('logs/training.log')\n```", "```py\nfrom azureml.core import Run\n# load the current run\nrun = Run.get_context()\n```", "```py\n$schema: https://azuremlschemas.azureedge.net/latest/compute.schema.json\nname: mldemocompute\ntype: amlcompute\nsize: STANDARD_D2_V2\nlocation: westus2\nmin_instances: 0\nmax_instances: 2\nidle_time_before_scale_down: 900\n```", "```py\n    $ az ml compute create -f compute.yml -g mldemo -w mldemows\n    ```", "```py\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\ncluster_name = \"mldemocompute\"\nmin_nodes = 0\nmax_nodes = 2\nvm_size = \"STANDARD_D2_V2\"\ntry:   \n  aml_cluster = ComputeTarget\n                (workspace=ws, name=cluster_name)\nexcept ComputeTargetException:\n  print('Cluster not '%s' not found, creating one now.' \n         % cluster_name)\n  config = AmlCompute.provisioning_configuration\n           (vm_size=vm_size, \n            min_nodes=min_nodes, \n            max_nodes=max_nodes)\n  aml_cluster = ComputeTarget.create\n                (workspace=ws, \n                 name=cluster_name,\n                 provisioning_configuration=config)\naml_cluster.wait_for_completion(show_output=True)\n```", "```py\nmyenv = Environment.from_pip_requirements\n        (name = \"remote_env\", file_path = pipreq_path)\n```", "```py\n\"docker\": {\n\"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210714.v1\",\n\"platform\": {\n    \"architecture\": \"amd64\",\n    \"os\": \"Linux\"\n  }\n}\n```"]