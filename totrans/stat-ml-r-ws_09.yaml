- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Linear Algebra in R
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R中的线性代数
- en: 'The previous chapter introduced an efficient and effective reporting approach
    using R Markdown. *Part 1* of this book essentially covered the practical aspects
    of getting things done using R. *Part 2* of this book goes back to the fundamentals,
    covering two essential pillars of mathematics: linear algebra and calculus. Understanding
    these basics will better prepare us to appreciate and work with common mathematical
    operations to the point that these operations feel natural to us. *Part 2* aims
    to develop that level of literacy, starting with a fundamental review of linear
    algebra with R in this chapter.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章介绍了使用R Markdown的高效有效的报告方法。本书的*第一部分*主要涵盖了使用R完成实际工作的各个方面。本书的*第二部分*回归到基础，涵盖了数学的两个基本支柱：线性代数和微积分。理解这些基础知识将更好地为我们欣赏和操作常见的数学运算做好准备，使这些运算对我们来说变得自然。*第二部分*的目标是通过本章对线性代数的根本性回顾，开始培养这种水平的素养。
- en: By the end of this chapter, you will have learned about the basic concepts of
    linear algebra, including vectors, matrices, and the system of equations. You
    will also be able to interpret basic notations in linear algebra and work with
    common matrices using R.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将了解线性代数的基本概念，包括向量、矩阵和方程组系统。你还将能够解释线性代数中的基本符号，并使用R处理常见的矩阵。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introducing linear algebra
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍线性代数
- en: Common matrix operations and properties
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见矩阵运算和属性
- en: Solving system of linear equations
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解线性方程组
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the code and data for this chapter is available at [https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_7/working.R](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_7/working.R).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码和数据均可在[https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_7/working.R](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_7/working.R)找到。
- en: Introducing linear algebra
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍线性代数
- en: 'This chapter delves into one of the most important branches of mathematics:
    **linear algebra**. Linear algebra deals with linear operations of mathematical
    objects, including vectors, matrices, and tensors (high-dimensional matrices),
    the most common forms of data. For example, the typical table we use to store
    data in Excel consists of a series of columns. Each column is called a vector,
    which stores a specific number of elements and takes the form of a column instead
    of a row by default. A collection of these column vectors forms a matrix, a two-dimensional
    Excel table, or DataFrame, as we used to call it in the previous chapters. We
    can also view the same table as a collection of row vectors, where each vector
    lives in the form of a row.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章深入探讨了数学最重要的分支之一：**线性代数**。线性代数处理数学对象的线性运算，包括向量、矩阵和张量（高维矩阵），这些是最常见的数据形式。例如，我们通常在Excel中用来存储数据的典型表格由一系列列组成。每一列被称为一个向量，它存储一定数量的元素，默认情况下以列的形式存在而不是行。这些列向量的集合形成一个矩阵，一个二维的Excel表格或DataFrame，正如我们在前几章中所称呼的。我们也可以将同一表格视为行向量的集合，其中每个向量以行的形式存在。
- en: 'Let’s put these in context. The following code snippet loads the sleep dataset
    and prints out the first six rows and three columns. We use A to denote this 6x3
    matrix in the following exposition:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这些内容置于上下文中。以下代码片段加载了睡眠数据集，并打印出前六行和三列。我们在以下阐述中使用A表示这个6x3矩阵：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Let’s introduce some notation here. We use a bold lowercase letter, a, to denote
    a column vector, say the `extra` variable, which consists of six elements in the
    vector. In other words, a is a six-dimensional vector. The column vector, a, can
    be *transposed* into a row vector, denoting a T. Since a T is a row vector, we
    can write a T = [0.7, − 1.6, − 0.2, − 1.2, − 0.1, 3.4], which is also the typical
    way of writing row vectors (or transposed column vectors) in many books. Similarly,
    a row vector can be transposed into the (original) column vector, giving us (a T) T
    = a.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里引入一些符号。我们使用粗体小写字母a来表示一个列向量，例如`extra`变量，它由六个元素组成。换句话说，a是一个六维向量。列向量a可以*转置*成一个行向量，表示为a
    T。由于a T是一个行向量，我们可以写成a T = [0.7, − 1.6, − 0.2, − 1.2, − 0.1, 3.4]，这也是许多书中书写行向量（或转置的列向量）的典型方式。同样，一个行向量可以转置回（原始的）列向量，给我们(a
    T) T = a。
- en: 'A graphical illustration will help here. *Figure 7**.1* depicts the process
    of transposing the column vector, a, into a row vector, a T, then transposing
    it again into the original column vector, (a T) T = a. Therefore, we can view
    the matrix, A, as a collection of column vectors concatenated horizontally, or
    a collection of row vectors concatenated vertically:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个图形说明将有助于理解。*图7**.1*展示了将列向量a转换为行向量a T，然后再将其转换回原始列向量(a T) T = a的过程。因此，我们可以将矩阵A视为水平连接的列向量集合，或者垂直连接的行向量集合：
- en: '![Figure 7.1 – Transposing the column vector into a row vector, and then transposing
    it again into the original column vector](img/B18680_07_001.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图7.1 – 将列向量转换为行向量，然后再转换回原始列向量](img/B18680_07_001.jpg)'
- en: Figure 7.1 – Transposing the column vector into a row vector, and then transposing
    it again into the original column vector
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1 – 将列向量转换为行向量，然后再将其转换回原始列向量
- en: Note that the rows are also referred to as observations and that the columns
    are referred to as features or attributes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，行也被称为观测值，而列被称为特征或属性。
- en: We will start by working with vectors in the following section.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将从处理向量开始。
- en: Working with vectors
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理向量
- en: A vector in R chains together data elements of the same type. Multiple vectors
    join hands, often side by side, to form a matrix. Therefore, it is the building
    block in linear algebra, and we must start from there.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: R中的向量将相同类型的数据元素连接在一起。多个向量携手，通常是并排，形成一个矩阵。因此，它是线性代数的基石，我们必须从这里开始。
- en: There are multiple ways to create a vector. We will explore a few such options
    in the following exercise.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 创建向量的方法有多种。在接下来的练习中，我们将探索其中的一些选项。
- en: Exercise 7.1 – creating a vector
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习7.1 – 创建向量
- en: 'This exercise will introduce three common ways of creating a vector. Let’s
    get started:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习将介绍创建向量的三种常见方法。让我们开始吧：
- en: 'Create a vector of integers from 1 to 6 using the `c()` function, where `c`
    stands for concatenation:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`c()`函数从1到6创建一个整数向量，其中`c`代表连接：
- en: '[PRE1]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: One more function we can use to create a sequence of integers is the `seq()`
    function, which generates a sequence of numbers equally spaced based on the `by`
    argument.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还可以使用`seq()`函数来创建一个整数序列，该函数根据`by`参数生成等间距的数字序列。
- en: 'Create the same vector using `seq()`:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`seq()`创建相同的向量：
- en: '[PRE2]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: These three implementations create the same vector.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这三种实现方式创建的是相同的向量。
- en: 'In addition, we can use the `rep()` function to create a list of repeated numbers.
    The following code snippet produces a 6-element vector whose data is all ones:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，我们还可以使用`rep()`函数来创建重复数字的列表。以下代码片段生成一个包含所有元素都是1的6元素向量：
- en: '[PRE3]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: A vector in R is mutable, meaning we can change the value in the vector’s specific
    position(s). Let’s look at how to achieve this.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: R中的向量是可变的，这意味着我们可以更改向量中特定位置的数据。让我们看看如何实现这一点。
- en: Exercise 7.2 – modifying a vector
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习7.2 – 修改向量
- en: 'Modifying the contents of a vector is a common operation, especially in the
    context of processing a DataFrame using column-wise filtering conditions. The
    algebra of vectors follows mostly the same principle as scalars. To see this,
    we must first index the desired elements in the vector, followed by using an assignment
    operation to override the value of the specific element. Let’s take a look:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 修改向量的内容是一个常见的操作，尤其是在使用列过滤条件处理DataFrame的上下文中。向量的代数主要遵循与标量相同的原理。为了看到这一点，我们必须首先在向量中索引所需的元素，然后使用赋值操作来覆盖特定元素的值。让我们看看：
- en: 'Change the value of the second element in the vector, `x`, to `20`:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将向量`x`中第二个元素的值改为`20`：
- en: '[PRE4]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: So, we can access an element in a vector by wrapping the position in a squared
    bracket. We can also perform bulk operations that exert the same effect on all
    elements in a vector.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，我们可以通过将位置包裹在方括号中来访问向量中的元素。我们还可以执行对向量中所有元素产生相同效果的批量操作。
- en: 'Double all elements in the vector, `x`:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将向量`x`中的所有元素都乘以二：
- en: '[PRE5]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, the multiplier, `2`, is broadcast to each element in the vector to perform
    the respective multiplication. The same broadcasting mechanism applies to the
    addition operation and more.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，乘数`2`被广播到向量的每个元素上，以执行相应的乘法。相同的广播机制也适用于加法操作等。
- en: 'Increment all elements in `x` by one:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`x`中的所有元素增加一：
- en: '[PRE6]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Of course, we can obtain the same result by adding `x` to `y`, a vector of
    ones with the same length:'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当然，我们可以通过将`x`加到`y`上，一个长度相同的全一向量，来获得相同的结果：
- en: '[PRE7]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now that we’ve reviewed the basics of working with vectors, we can enter the
    realm of matrices.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经回顾了向量操作的基础，我们可以进入矩阵的领域。
- en: Working with matrices
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵操作
- en: A matrix is a stack of vectors superimposed together. An m x n matrix can be
    considered n m-dimensional column vectors stacked horizontally, or m n-dimensional
    row vectors stacked vertically. For each of the DataFrames that we have worked
    with, each row is an observation, and each column represents a feature.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵是一系列向量叠加而成的。一个m x n矩阵可以被认为是水平堆叠的n个m维列向量，或者垂直堆叠的m个n维行向量。对于我们所处理的每个DataFrame，每一行是一个观察值，每一列代表一个特征。
- en: Let’s look at how to create matrices by completing an exercise.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过完成一个练习来看看如何创建矩阵。
- en: Exercise 7.3 – creating a matrix
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习7.3 – 创建矩阵
- en: 'We can use the `matrix()` function to create a matrix. This function accepts
    three arguments: the data to be passed into the matrix via `data`, the number
    of rows via `nrow`, and the number of columns via `ncol`:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`matrix()`函数来创建矩阵。这个函数接受三个参数：通过`data`传递到矩阵中的数据，通过`nrow`传递的行数，以及通过`ncol`传递的列数：
- en: 'Create a 3x2 matrix, `X`, filled with the number `2`:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个填充数字`2`的3x2矩阵`X`：
- en: '[PRE8]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Note the use of the broadcasting mechanism here. As we only pass in a single
    number, it is replicated across all the cells in the matrix. Also, observe the
    indexing pattern in the result. The position on the left indexes each row before
    the comma and each column by the position on the right after the comma. We can
    verify this observation by indexing the element located in the second row and
    the first column:'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意这里使用了广播机制。因为我们只传递了一个数字，它被复制到矩阵的所有单元格中。同时，观察结果中的索引模式。逗号左侧的位置索引每个行，逗号右侧的位置索引每个列。我们可以通过索引第二行第一列的元素来验证这个观察：
- en: '[PRE9]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let’s verify the class of this object:'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们验证这个对象的类别：
- en: '[PRE10]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The result shows that `X` is both a matrix and (multi-dimensional) array.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示`X`既是矩阵也是（多维）数组。
- en: We can also create a matrix based on a vector.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们也可以基于向量创建矩阵。
- en: 'Create a 3x2 matrix using the `x` variable. Fill the matrix by rows:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用变量`x`创建一个3x2矩阵。按行填充矩阵：
- en: '[PRE11]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, filling by rows means sequentially placing each element in the original
    vector, `x`, row-wise, beginning from the first row from left to right and jumping
    to the next row when hitting the end of the current row. We can also design the
    filling by columns.
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，按行填充意味着按顺序将原始向量`x`中的每个元素按行放置，从左到右的第一行开始，当达到当前行的末尾时跳到下一行。我们也可以设计按列填充。
- en: 'Fill in the matrix by columns instead:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 改为按列填充矩阵：
- en: '[PRE12]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As with the vector, we can change a specific element in a matrix by first locating
    the element via indexing and assigning the new value, as shown here:'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与向量一样，我们可以通过索引定位矩阵中的特定元素，并分配新值来更改矩阵中的元素，如下所示：
- en: '[PRE13]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: A common operation in linear algebra is to multiply a matrix by a vector. Such
    an operation gives rise to many interesting and important interpretations regarding
    matrix manipulation. We’ll look at this operation in the following section.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数中的一种常见操作是将矩阵与向量相乘。这种操作产生了许多关于矩阵操作的有趣和重要的解释。我们将在下一节中查看这个操作。
- en: Matrix vector multiplication
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵向量乘法
- en: An overarching rule when multiplying a matrix by a vector is the equality of
    the inner dimension. In other words, the column dimension (meaning the number
    of columns) of the matrix, when multiplied by a vector on its right, has to be
    equal to the row dimension of the multiplying vector. For example, given an m
    x n matrix, it can only multiply a column vector of size n x 1, and such multiplication
    results in another vector of size m x 1.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当将矩阵与向量相乘时，一个总的规则是内维度的相等。换句话说，矩阵的列维度（即列数）乘以右侧的向量时，必须等于乘法向量的行维度。例如，给定一个m x n矩阵，它只能乘以一个大小为n
    x 1的列向量，这样的乘法结果将是一个大小为m x 1的向量。
- en: 'Let’s look at a concrete example here. Recall that X is a 3x2 matrix. Multiplying
    it by a 2x1 vector, y, should produce a 3x1 vector, z. The transition from the
    original vector, y, to the new vector, z, has an extra meaning here: y has changed
    space and now lives in a three-dimensional world instead of two! We can also say
    the old vector, y, is projected and stretched to the new vector, z, because of
    the projection matrix, X. Such a projection, or transformation, constitutes the
    majority of operations in modern neural networks. By projecting matrices (also
    called representations) across different layers, a neural network can *learn*
    different levels of abstraction.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，让我们看一个具体的例子。回想一下，X是一个3x2的矩阵。将其乘以一个2x1的向量y，应该产生一个3x1的向量z。从原始向量y到新向量z的转变在这里有额外的意义：y改变了空间，现在生活在一个三维世界中而不是二维！我们也可以说，旧的向量y由于投影矩阵X而被投影和拉伸到新的向量z。这种投影或变换构成了现代神经网络中大多数操作。通过在不同层之间投影矩阵（也称为表示），神经网络可以*学习*不同层次的概念抽象。
- en: 'Let’s assume y is a vector of ones. The rule of matrix-vector multiplication
    says that each entry in the resulting vector, z, is the inner product of the corresponding
    vectors. The inner product between two vectors, also called the dot product, is
    the sum of the products of the corresponding elements in each vector. For example,
    the first entry in z is 12\. Its positional index, which is [1,1], says that it
    requires the first row in X, which is [10, 2], and the first column in y, which
    is [1, 1], to enter the inner product operation. Multiplying the corresponding
    elements in each vector and summing the results gives us 10*1+2*1=12\. Similarly,
    the second entry is calculated as 2*1+2*1=4\. *Figure 7**.2* summarizes this matrix-vector
    multiplication:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 假设y是一个全为1的向量。矩阵-向量乘法的规则表明，结果向量z中的每个元素都是对应向量的内积。两个向量之间的内积，也称为点积，是每个向量中对应元素乘积的总和。例如，z中的第一个元素是12。它的位置索引[1,1]表示它需要X矩阵的第一行[10,
    2]和y矩阵的第一列[1, 1]来进行内积操作。将每个向量中对应元素相乘并求和，我们得到10*1+2*1=12。同样，第二个元素的计算为2*1+2*1=4。*图7.2*总结了这种矩阵-向量乘法：
- en: '![Figure 7.2 – Illustrating the matrix-vector multiplication process](img/B18680_07_002.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图7.2 – 矩阵-向量乘法过程示意图](img/B18680_07_002.jpg)'
- en: Figure 7.2 – Illustrating the matrix-vector multiplication process
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 – 矩阵-向量乘法过程示意图
- en: Now, let’s look at how to perform matrix-vector multiplication in R.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何在R中执行矩阵-向量乘法。
- en: Exercise 7.4 – applying matrix-vector multiplication
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习7.4 – 应用矩阵-向量乘法
- en: 'The matrix-vector multiplication operation comes via the `%*%` symbol in R.
    The `%*%` notation is very different from the `*` notation alone, which stands
    for element-wise multiplication. The following exercise illustrates such a difference:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，矩阵-向量乘法操作是通过`%*%`符号实现的。`%*%`符号与单独的`*`符号非常不同，后者代表逐元素乘法。以下练习说明了这种差异：
- en: 'Multiply the previous matrix, X, by a 2x1 vector of ones:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将之前的矩阵X乘以一个2x1的全为1的向量：
- en: '[PRE14]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The result shows that the generated vector is 3x1\. Note that the multiplication
    will not go through if the dimensions do not check:'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示生成的向量是3x1。请注意，如果维度不匹配，乘法将无法进行：
- en: '[PRE15]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The error says that the dimensions of the vector, `c(1,1,1)`, do not match those
    in the `X` matrix.
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 错误信息表明向量`c(1,1,1)`的维度与`X`矩阵中的维度不匹配。
- en: We can verify the calculation of each cell in the resulting vector.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以验证结果向量中每个单元格的计算。
- en: 'Calculate the first entry in the resulting vector separately:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分别计算结果向量中的第一个元素：
- en: '[PRE16]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The result shows that the first entry is the dot product of the first row, `X[1,]`,
    and the first (and only) column, `c(1,1)`. We can also re-express the dot product
    as explicit element-wise multiplication and summation.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示，第一个元素是第一行`X[1,]`和第一列（也是唯一的一列）`c(1,1)`的点积。我们也可以将点积重新表达为显式的逐元素乘法和求和。
- en: 'Re-express the previous dot product as explicit element-wise multiplication
    and summation:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将之前的点积重新表达为显式的逐元素乘法和求和：
- en: '[PRE17]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Note that both results return the same value but assume a different data structure:
    the dot product operation returns a matrix, while the re-expressed operation returns
    a vector.'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，两个结果返回相同的值，但假设不同的数据结构：点积操作返回一个矩阵，而重新表达的操作返回一个向量。
- en: 'Let’s verify the same calculation using the second entry in the resulting vector:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用结果向量的第二个元素来验证相同的计算：
- en: '[PRE18]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can also examine the behavior of multiplying a matrix with a scalar.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还可以检查矩阵与标量相乘的行为。
- en: 'Double each element in the matrix, X:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将矩阵X中的每个元素加倍：
- en: '[PRE19]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Note that when switching to the element-wise multiplication symbol, `*`, the
    dimension of the resulting matrix remains unchanged. In addition, the broadcasting
    mechanism is in play here, where a scalar of 2 is multiplied by each element in
    the matrix, X. The effect is as if we’re multiplying X by another matrix of the
    same dimensions:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，当切换到逐元素乘法符号`*`时，结果矩阵的维度保持不变。此外，这里还涉及广播机制，其中2这个标量乘以矩阵X中的每个元素。效果就像我们用另一个相同维度的矩阵乘以X一样：
- en: '[PRE20]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now, let’s cover matrix-matrix multiplication. We will refer to it as matrix
    multiplication for short.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来讨论矩阵-矩阵乘法。我们将简称为矩阵乘法。
- en: Matrix multiplication
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵乘法
- en: 'Matrix multiplication is the most widely used form of operation in many domains.
    Take the neural network model, for example. *Figure 7**.3* shows a simple network
    architecture called a fully connected neural network, where all neurons are fully
    connected. The input data, represented by the input layer with 10 rows and 3 columns,
    will enter a series of matrix multiplications (plus nonlinear transformations,
    which are ignored here) to learn useful representations (Z 1) and, therefore,
    accurate predictions (Z 2). There are two matrix multiplications here. The first
    matrix multiplication happens between the 10x3 input data, X, and the weight matrix
    W 1, which produces a 10x4 hidden representation, Z 1, in the hidden layer. The
    second matrix multiplication transforms Z 1 into the final 10x2 output, Z 2, using
    another 4x2 weight matrix, W 2\. We can also interpret a series of matrix multiplications
    as transforming/projecting the input data, X, to the hidden representation, Z 1,
    and then to the output, Z 2:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法在许多领域中被广泛使用。以神经网络模型为例。*图7.3*展示了简单网络架构，称为全连接神经网络，其中所有神经元都是完全连接的。表示为10行3列的输入数据将进入一系列矩阵乘法（加上这里忽略的非线性变换）来学习有用的表示（Z1）和，因此，准确的预测（Z2）。这里有两个矩阵乘法。第一个矩阵乘法发生在10x3的输入数据X和权重矩阵W1之间，在隐藏层中产生一个10x4的隐藏表示Z1。第二个矩阵乘法使用另一个4x2的权重矩阵W2将Z1转换为最终的10x2输出Z2。我们也可以将一系列矩阵乘法解释为将输入数据X转换/投影到隐藏表示Z1，然后到输出Z2：
- en: '![Figure 7.3 – Schematic of a simple two-layer fully connected neural network](img/B18680_07_003.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图7.3 – 简单两层全连接神经网络的示意图](img/B18680_07_003.jpg)'
- en: Figure 7.3 – Schematic of a simple two-layer fully connected neural network
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – 简单两层全连接神经网络的示意图
- en: As you can see from *Figure 7**.3*, the input data, represented by the input
    layer with 10 rows and 3 columns, will enter a series of matrix multiplications
    (plus nonlinear transformations, which are ignored here) to learn useful representations
    (Z 1) and, therefore, accurate predictions (Z 2). The first matrix multiplication
    happens between the 10x3 input data, X, and the weight matrix, W 1, resulting
    in a 10x4 hidden representation, Z 1\. The second matrix multiplication transforms
    Z 1 into the final 10x2 output, Z 2, using another 4x2 weight matrix, W 2.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图7.3*所示，输入数据，由10行3列的输入层表示，将进入一系列矩阵乘法（加上这里忽略的非线性变换）来学习有用的表示（Z1）和，因此，准确的预测（Z2）。第一个矩阵乘法发生在10x3的输入数据X和权重矩阵W1之间，产生一个10x4的隐藏表示Z1。第二个矩阵乘法使用另一个4x2的权重矩阵W2将Z1转换为最终的10x2输出Z2。
- en: There is more to these matrix multiplications. Let’s assume the input data has
    many features. By applying these matrix multiplications with the automatically
    learned weight matrices, these features can be weighed correspondingly to produce
    accurate predictions in the output layer. Automatic feature learning, including
    those nodes in the hidden layer, is a distinguishing characteristic of modern
    neural networks compared to traditional manual feature learning.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这些矩阵乘法不仅仅是这样。假设输入数据具有许多特征。通过应用这些矩阵乘法与自动学习的权重矩阵，这些特征可以相应地加权，以在输出层产生准确的预测。自动特征学习，包括隐藏层中的那些节点，是现代神经网络与传统手动特征学习相比的一个显著特点。
- en: 'Let’s look at a single matrix multiplication in more detail. *Figure 7**.4*
    illustrates the calculation process of multiplying a 2x2 matrix, [1 3 2 4], by
    another 2x2 matrix, [2 2 2 2]. We can also view each column in the resulting matrix
    as a result of matrix-vector multiplication, as covered earlier; these columns
    are then concatenated to form the new output matrix:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看单个矩阵乘法。*图7.4*说明了将2x2矩阵[1 3 2 4]与另一个2x2矩阵[2 2 2 2]相乘的计算过程。我们还可以将结果矩阵中的每一列视为前面提到的矩阵-向量乘法的结果；然后这些列被连接起来形成新的输出矩阵：
- en: '![Figure 7.4 – Breaking down the matrix multiplication process](img/B18680_07_004.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图7.4 – 矩阵乘法过程的分解](img/B18680_07_004.jpg)'
- en: Figure 7.4 – Breaking down the matrix multiplication process
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 – 矩阵乘法过程的分解
- en: Let’s go through an exercise to put the practical part of things into context.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个练习来将实际部分的内容置于上下文中。
- en: Exercise 7.5 – working with matrix multiplication
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习7.5 – 矩阵乘法操作
- en: 'Matrix multiplication still relies on the `%*%` sign in R. In this exercise,
    we will reproduce the example in *Figure 7**.4*, with a bit of stretch in terms
    of the order of multiplication:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，矩阵乘法仍然依赖于`%*%`符号。在这个练习中，我们将重新生成*图7.4*中的示例，在乘法顺序上略有扩展：
- en: 'Reproduce the previous matrix multiplication example:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新生成之前的矩阵乘法示例：
- en: '[PRE21]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Here, we use the `matrix()` function to create two matrices, the first generated
    by converting a vector and the second by duplicating a scalar value via broadcasting.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用`matrix()`函数创建了两个矩阵，第一个是通过转换向量生成的，第二个是通过广播重复标量值生成的。
- en: The order of multiplication is of key importance in matrix algebra; shuffling
    the order will produce a different result in most cases. Let me switch these two
    matrices.
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在矩阵代数中，乘法的顺序至关重要；改变顺序在大多数情况下会产生不同的结果。让我交换这两个矩阵。
- en: 'Switch the order of multiplication for these two matrices:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交换这两个矩阵的乘法顺序：
- en: '[PRE22]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Please verify the result of the matrix multiplication and appreciate the importance
    of order in multiplying two matrices: matrix multiplication is *not* commutative.'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请验证矩阵乘法的结果，并欣赏乘法顺序在两个矩阵乘法中的重要性：矩阵乘法*不是*交换的。
- en: Additionally, element-wise multiplication happens using the `*` operator.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，元素级联乘法是通过`*`运算符进行的。
- en: 'Double every element in the previous matrix on the left:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将左侧前一个矩阵中的每个元素都乘以2：
- en: '[PRE23]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Several special matrices are of particular interest. We’ll review them in the
    next section.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 几种特殊的矩阵特别引人关注。我们将在下一节中回顾它们。
- en: The identity matrix
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单位矩阵
- en: There are many special types of matrices. The first type of special matrix is
    the **identity matrix**, which assumes a value of 1 at the on-diagonal positions
    and 0 elsewhere. The biggest characteristic of an identity matrix is the identity
    preservation of the original multiplying matrix – that is, any matrix that can
    successfully multiply by an identity matrix obtains the same result as itself.
    This sounds like multiplying by one, and we are indeed doing so when the identity
    matrix is 1x1.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵有很多特殊类型。第一种特殊矩阵是**单位矩阵**，其对角线位置上的值为1，其他位置为0。单位矩阵的最大特点是保持原始乘法矩阵的恒等性——也就是说，任何能够成功与单位矩阵相乘的矩阵都会得到与自身相同的结果。这听起来像是乘以1，而当我们处理1x1的单位矩阵时，我们确实是这样做的。
- en: Exercise 7.6 – working with the identity matrix
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习7.6 – 单位矩阵操作
- en: 'Let’s go through an exercise to see how identity matrices work:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个练习来看看单位矩阵是如何工作的：
- en: 'Create a 2x2 identity matrix using the `diag()` function:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`diag()`函数创建一个2x2的单位矩阵：
- en: '[PRE24]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'To create an identity matrix, we simply need to pass the number of ones in
    the diagonal of the matrix. A diagonal matrix can also be created from a vector:'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要创建一个单位矩阵，我们只需要传递矩阵对角线上的1的数量。对角矩阵也可以从一个向量中创建：
- en: '[PRE25]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Here, the elements in the vector are used to fill in the diagonal positions
    of the diagonal matrix while leaving all the rest of the cells as 0.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，向量中的元素用于填充对角矩阵的对角线位置，而将所有其他单元格保留为0。
- en: Let’s multiply the 2x2 identity matrix by the previous running matrix.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们将2x2的单位矩阵与之前的运行矩阵相乘。
- en: 'Multiply this identity matrix by the previous 2x2 matrix numbered 1 to 4:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这个单位矩阵与之前编号为1到4的2x2矩阵相乘：
- en: '[PRE26]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can see that there is no change in the resulting matrix. Let’s verify this
    again:'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到结果矩阵没有发生变化。让我们再次验证这一点：
- en: '[PRE27]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Lastly, let’s verify that the result is still the same after switching the order
    of multiplication.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，让我们验证在交换乘法顺序后结果是否仍然相同。
- en: 'Move the multiplying identity matrix to the left and perform matrix multiplication:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将乘法单位矩阵移到左边并执行矩阵乘法：
- en: '[PRE28]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The result shows no change to the original matrix. If we use X to denote the
    original matrix and I to denote the identity matrix, we will get XI = IX = X.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示原始矩阵没有变化。如果我们用 X 表示原始矩阵，用 I 表示单位矩阵，我们将得到 XI = IX = X。
- en: Other operations can derive new matrices based on the original one, such as
    transposing or inversing a matrix.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 其他操作可以根据原始矩阵派生出新的矩阵，例如转置或求逆。
- en: Transposing a matrix
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转置一个矩阵
- en: We already have some experience transposing a vector, which is a special case
    of transposing a matrix. Transposing a matrix means flipping the original matrix,
    X, to generate a new one, X T, whose columns and rows are now switched. Transposing
    a transposed matrix, X T, gives back the original matrix, (X T) T = X.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有一些转置向量的经验，这是转置矩阵的特殊情况。转置矩阵意味着翻转原始矩阵 X，生成一个新的矩阵 Xᵀ，其列和行现在是交换的。转置一个转置矩阵 Xᵀ
    会返回原始矩阵，(Xᵀ)ᵀ = X。
- en: A special type of matrix is called the **symmetric matrix**, such that X T =
    X. A symmetric matrix is also a **square matrix**; otherwise, the transposed dimensions
    will not check.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 一种特殊的矩阵称为**对称矩阵**，即 Xᵀ = X。对称矩阵也是一个**方阵**；否则，转置的维度将不会匹配。
- en: Let’s see this in practice.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看实际操作。
- en: Exercise 7.7 – transposing a matrix
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 7.7 – 转置矩阵
- en: 'In this exercise, we will transpose a matrix using the `t()` function and transpose
    it again to see whether it matches the original matrix:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用 `t()` 函数转置一个矩阵，然后再转置一次，看看它是否与原始矩阵匹配：
- en: 'Create a square matrix, `X`, with elements one to four filled by column:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个元素从一到四按列填充的方阵 `X`：
- en: '[PRE29]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Transpose the matrix using `t()`:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `t()` 转置矩阵：
- en: '[PRE30]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Here, we can see that the transposed matrix has its rows and columns flipped
    from the original matrix. The diagonal elements stay the same, though.
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到转置矩阵的行和列与原始矩阵相反。尽管如此，对角元素保持不变。
- en: 'Transpose the transposed matrix again and verify whether it is equal to the
    original matrix:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次转置转置的矩阵并验证它是否等于原始矩阵：
- en: '[PRE31]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'A visual inspection shows that it is indeed the same original matrix. However,
    we can also use the built-in `all.equal()` function to perform a systematic check:'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 视觉检查显示它确实是同一个原始矩阵。然而，我们也可以使用内置的 `all.equal()` 函数进行系统检查：
- en: '[PRE32]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The result shows that these two matrices are equal to each other, thus being
    the same matrix.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示这两个矩阵彼此相等，因此是同一个矩阵。
- en: 'Let’s review the last type of operation: inversing a matrix.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾最后一种操作：逆一个矩阵。
- en: Inverting a matrix
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 求逆矩阵
- en: Inversing a scalar number is intuitive. For any number, x, its inverse (or reciprocal)
    is 1 _ x  if x ≠ 0\. This condition ensures that x is invertible. Similarly, not
    all matrices are invertible.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 逆一个标量数是直观的。对于任何数 x，其逆（或倒数）是 1/x，如果 x ≠ 0。这个条件确保 x 是可逆的。同样，并非所有矩阵都是可逆的。
- en: Formally, we say that a matrix, X, is invertible if it can, when multiplied
    by its inverse, X −1, produce an identity matrix, I. In other words, X X −1 =
    X −1 X = I.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，我们说一个矩阵 X 是可逆的，如果它可以乘以其逆矩阵 X⁻¹，从而产生一个单位矩阵 I。换句话说，XX⁻¹ = X⁻¹X = I。
- en: 'There are some interesting properties of an invertible matrix as well. For
    example, inverting an inverse matrix gives us the original matrix: (X −1) −1 =
    X. Also, since the product of an identity matrix with itself is an identity matrix,
    the inverse of an identity matrix is thus the identity matrix itself, a special
    case compared to others.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 可逆矩阵也有一些有趣的性质。例如，逆一个逆矩阵会给我们原始矩阵：(X⁻¹)⁻¹ = X。另外，由于单位矩阵与自身的乘积是一个单位矩阵，因此单位矩阵的逆就是单位矩阵本身，这是一个与其他情况不同的特殊情况。
- en: The inverse of a matrix can be obtained using the `solve()` function in R, which
    will give us an error if the matrix is not invertible. Let’s practice this via
    the following exercise.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵的逆可以使用 R 中的 `solve()` 函数获得，如果矩阵不可逆，它将给出错误。让我们通过以下练习来练习这个。
- en: Exercise 7.8 – inverting a matrix
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 7.8 – 求逆矩阵
- en: 'In this exercise, we will invert both an identity matrix and a standard square
    matrix using the `solve()` function:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用 `solve()` 函数逆一个单位矩阵和一个标准方阵：
- en: 'Invert a two-dimensional identity matrix:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 逆一个二维单位矩阵：
- en: '[PRE33]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The result shows that the inverse of an identity matrix is itself.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示单位矩阵的逆就是它自己。
- en: 'Invert the running matrix, X, from the previous example:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从上一个例子中逆矩阵 X：
- en: '[PRE34]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We can verify the validity of this inverse matrix by multiplying it by the original
    matrix and checking whether it gives us an identity matrix.
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过将这个逆矩阵乘以原始矩阵并检查它是否给出单位矩阵来验证这个逆矩阵的有效性。
- en: 'Multiply by the original matrix to verify it based on the definition of matrix
    inversion:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据矩阵逆的定义，通过乘以原始矩阵来验证它：
- en: '[PRE35]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The result shows that `Xinv` is indeed the inverse matrix of `X`.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果表明 `Xinv` 确实是 `X` 的逆矩阵。
- en: In the following section, we will look at matrix-vector multiplication from
    the perspective of solving a system of linear equations, which is an essential
    task in many machine learning algorithms.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将从解线性方程组的视角来探讨矩阵-向量乘法，这在许多机器学习算法中是一个基本任务。
- en: Solving a system of linear equations
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解线性方程组
- en: The matrix-vector multiplication operation gives rise to a system of equations.
    In a typical machine learning algorithm, data comes in the form of a matrix, X,
    and the target outcome is a vector, y. When the model that’s used is a straightforward
    linear model, we assume the input-output relationship as Xw = y, where w represents
    the vector of features/coefficients. An n x p matrix of input data multiplies
    a p x 1 vector, w, of features to produce, as expected, an n x 1 output vector,
    y. The essence of linear regress is thus to solve for the exact values in w such
    that the system of linear equations in Xw = y are satisfied.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵-向量乘法操作产生了一个方程组。在典型的机器学习算法中，数据以矩阵 X 的形式出现，目标结果是向量 y。当使用的模型是一个简单的线性模型时，我们假设输入-输出关系为
    Xw = y，其中 w 代表特征/系数向量。一个 n x p 的输入数据矩阵乘以一个 p x 1 的特征向量 w，将产生一个预期的 n x 1 输出向量 y。因此，线性回归的本质就是求解
    w 的确切值，使得 Xw = y 中的线性方程组得到满足。
- en: The equivalence between matrix-vector multiplication and the system of linear
    equations may take some time to become noticeable. Let’s pause and look at this
    equivalence.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵-向量乘法与线性方程组之间的等价性可能需要一段时间才能变得明显。让我们暂停一下，看看这种等价性。
- en: System of linear equations
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性方程组
- en: We are already familiar with the process of calculating a matrix-vector multiplication
    operation. A 2x2 matrix, X, when multiplying a 2x1 vector, w, will result in a
    2x1 vector, y. The first element in y, positioned as (1, 1), comes from the dot
    product (weighted sum) between the first row in X and the first column in y. Similarly,
    the second element in y, positioned as (2, 1), comes from the dot product between
    the second row in X and the first column in y. The positional index of each element
    in y determines the ingredients used in the respective dot product operation.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经熟悉了计算矩阵-向量乘法操作的过程。一个 2x2 的矩阵 X，当乘以一个 2x1 的向量 w 时，将得到一个 2x1 的向量 y。y 中的第一个元素，位于
    (1, 1) 位置，来自 X 的第一行与 y 的第一列之间的点积（加权求和）。同样，y 中的第二个元素，位于 (2, 1) 位置，来自 X 的第二行与 y
    的第一列之间的点积。y 中每个元素的位置索引决定了相应点积操作中使用的成分。
- en: Such an interpretation, however, is a raw and low-level one. A more advanced
    interpretation lies in the column space of X and the associated linear combination
    of the column vectors in X weighted by the weights in w in the same matrix-vector
    multiplication. A concrete example will help here.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种解释是原始和低级的。一个更高级的解释在于 X 的列空间以及 X 中列向量的相关线性组合，这些列向量在相同的矩阵-向量乘法中由 w 中的权重加权。一个具体的例子将有助于说明这一点。
- en: 'Suppose we have a simple matrix, X = [1 3 2 4], and a vector, w T = [1,1].
    The output vector is y = [1 * 1 + 3 * 1 2 * 1 + 4 * 1] = [4 6] based on the usual
    method of calculation. The column view gives another process of calculation: y
    = 1 *[1 2] + 1 *[3 4] = [1 2] + [3 4] = [4 6]. Here, the two columns, [1 2] and
    [3 4], are weighted by each element in w, respectively. In other words, these
    two columns are linearly combined to produce the output column vector, y. This
    forms the basis of the system of linear equations. *Figure 7**.5* summarizes these
    two different perspectives of matrix-vector multiplication for this example:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个简单的矩阵，X = [1 3 2 4]，以及一个向量，w T = [1,1]。根据通常的计算方法，输出向量 y = [1 * 1 + 3
    * 1 2 * 1 + 4 * 1] = [4 6]。从列的角度看，给出了另一种计算过程：y = 1 *[1 2] + 1 *[3 4] = [1 2] +
    [3 4] = [4 6]。在这里，这两个列，[1 2] 和 [3 4]，分别由 w 中的每个元素加权。换句话说，这两个列通过线性组合产生输出列向量 y。这构成了线性方程组的基础。*图
    7**.5* 总结了本例中矩阵-向量乘法的这两种不同视角：
- en: '![Figure 7.5 – Illustrating the two different ways of calculating matrix-vector
    multiplication](img/B18680_07_005.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.5 – 展示矩阵-向量乘法的两种不同计算方式](img/B18680_07_005.jpg)'
- en: Figure 7.5 – Illustrating the two different ways of calculating matrix-vector
    multiplication
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 – 阐述矩阵-向量乘法的两种不同计算方式
- en: Now, assume the weight vector, w, is unknown, with two unknown elements, w 1
    and w 2 – in other words, w T = [ w 1, w 2]. Also, assume that the input matrix,
    X, and the output vector, y, are known. This is a common situation where we are
    given the input-output data pairs and asked to estimate the coefficients of the
    linear model such that Xw = y. Now comes the system of linear equations. Plugging
    in the previous weighted combination of column vectors gives us
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设权重向量w是未知的，有两个未知元素，w1和w2——换句话说，wT = [w1, w2]。同时假设输入矩阵X和输出向量y是已知的。这是一个常见的情况，我们被给出输入-输出数据对，并要求估计线性模型的系数，使得Xw
    = y。现在出现了线性方程组。将之前的列向量加权组合插入其中，我们得到
- en: 'w 1 *[1 2] + w 2 *[3 4] = [ w 1 2 w 1] + [3 w 2 4 w 2] = [ w 1 + 3 w 2 2 w 1
    + 4 w 2] = [4 6]. We have a system of equations, as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: w1 * [1 2] + w2 * [3 4] = [w1 2 w1] + [3 w2 4 w2] = [w1 + 3 w2 2 w1 + 4 w2]
    = [4 6]。我们有一个方程组，如下所示：
- en: '{ w 1 + 3 w 2 = 4  2 w 1 + 4 w 2 = 6'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '{w1 + 3w2 = 4  2w1 + 4w2 = 6'
- en: Solving this system of linear equations gives us w 1 = w 2 = 1\. The equivalence
    of matrix-vector multiplication and the system of linear equations is manifested
    here.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 解这个线性方程组得到w1 = w2 = 1。矩阵-向量乘法和线性方程组的等价性在这里得到了体现。
- en: Let’s go through an exercise to appreciate the equivalence in terms of code.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个练习来欣赏代码中的等价性。
- en: Exercise 7.9 – understanding the system of linear equations
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习7.9 – 理解线性方程组
- en: 'In this exercise, we will first use the usual matrix-vector multiplication
    procedure to calculate the result, followed by providing a detailed and manual
    column-view implementation of the same operation. We will see that both give the
    same result:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将首先使用常规的矩阵-向量乘法过程来计算结果，然后提供一个详细的、手动的列视图实现相同的操作。我们将看到两者给出相同的结果：
- en: 'Create a 2x2 matrix, `X`, that consists of four numbers, 1 to 4, and is filled
    by column:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个由四个数字1到4组成的2x2矩阵`X`，按列填充：
- en: '[PRE36]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Create a vector, `w`, of length two, both filled with a value of 1:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个长度为2的向量`w`，两个元素都填充值为1：
- en: '[PRE37]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Note that a vector is a column vector by default. When the 2x2 matrix, `X`,
    multiplies the 2x1 vector, `w`, as shown in the following code, the vector, `w`,
    is expressed as a column vector before entering the multiplication operation.
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，默认情况下向量是列向量。当2x2矩阵`X`与2x1向量`w`相乘，如下面的代码所示时，向量`w`在乘法操作之前被表示为列向量。
- en: 'Multiply `X` and `w` and save the result in `y`:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`X`和`w`相乘并将结果保存在`y`中：
- en: '[PRE38]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Now, the `y` vector is displayed as an explicit column vector. Lastly, let’s
    verify the calculation using the column view.
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，`y`向量以显式的列向量形式显示。最后，让我们使用列视图验证计算。
- en: 'Perform the same matrix-vector multiplication using the column view, meaning
    a weighted sum of column vectors:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用列视图执行相同的矩阵-向量乘法，即列向量的加权求和：
- en: '[PRE39]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Here, we use `X[,1]` and `X[,2]` to access the first and second columns, respectively.
    The result agrees with the previous one, although following a different format
    as it is displayed as a row vector now.
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用`X[,1]`和`X[,2]`分别访问第一列和第二列。结果与之前的一致，尽管现在以行向量的格式显示，格式不同。
- en: Matrix-vector multiplication gives rise to a system of linear equations. However,
    this system of linear equations may or may not have a solution. Even if there
    is a solution, it may not be unique. In the following section, we will examine
    the potential solution to matrix-vector equations.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵-向量乘法产生一个线性方程组。然而，这个线性方程组可能有解也可能没有解。即使有解，也可能不是唯一的。在下一节中，我们将检查矩阵-向量方程的潜在解。
- en: The solution to matrix-vector equations
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵-向量方程的解
- en: 'Let’s continue with the example where a 2x2 matrix, X, multiplies a 2x1 weight
    vector, w, to produce a 2x1 output vector, y. We will discuss three cases here:
    without a solution, with a unique solution, and with infinitely many solutions.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续一个例子，其中2x2矩阵X与2x1权重向量w相乘，生成一个2x1输出向量y。在这里我们将讨论三种情况：无解、有唯一解和有无穷多解。
- en: We will start with the second case. Recall our previous values in X, w, and
    y. In [1 3 2 4] x [1 1] = [4 6], we multiplied the former two (X and w) to produce
    the third one (y) and showed how to derive the values of w given X and y by solving
    a system of linear equations in [1 3 2 4] x [w 1 w 2] = [4 6]. In other words,
    the solution is unique, and we can solve it analytically by writing out the explicit
    system of linear equations and solving the unknowns. It will be more involved
    when we have more unknowns to solve, but the process stays the same. In a typical
    linear regression setting, when the number of unknowns (the length of the weight
    vector, w) is the same as the number of equations (the number of rows in X), and
    provided that the input matrix, X, is a nice one (for example, if its columns
    are uncorrelated), we can find a unique solution to the system of linear equations.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从第二种情况开始。回想一下我们之前在X、w和y中的值。在[1 3 2 4] x [1 1] = [4 6]中，我们将前两个（X和w）相乘以产生第三个（y），并展示了如何通过在[1 3 2 4]
    x [w 1 w 2] = [4 6]中解线性方程组来得到w的值。换句话说，解是唯一的，我们可以通过写出显式的线性方程组并求解未知数来解析地解决它。当我们有更多的未知数要解决时，这个过程会更复杂，但过程是相同的。在一个典型的线性回归设置中，当未知数的数量（权重向量w的长度）与方程的数量（X的行数）相同时，并且输入矩阵X是一个好的矩阵（例如，如果其列是不相关的），我们可以找到线性方程组的唯一解。
- en: 'Now, let’s tweak the input matrix, X, so that no solution can be found. One
    way to do this is to set the second row vector of X to zero, giving us X = [1 3 0 0].
    Thus, we have the following:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们调整输入矩阵X，使得无法找到任何解。一种方法是将X的第二行向量设为零，得到X = [1 3 0 0]。因此，我们有以下情况：
- en: '[1 3 0 0]x[w 1 w 2] = [4 6]'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[1 3 0 0]x[w 1 w 2] = [4 6]'
- en: '{w 1 + 3 w 2 = 4 0 = 6'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '{w 1 + 3 w 2 = 4 0 = 6'
- en: It is obvious that the second equation fails, and therefore this system of linear
    equations cannot have a solution. This is called an *inconsistent* system since
    0 cannot be 6\. Note that in the first equation, there are infinitely many pairs
    of ( w 1, w 2) that satisfy the equation. This also leads to our third case.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，第二个方程失败了，因此这个线性方程组没有解。这被称为*不一致*系统，因为0不能等于6。请注意，在第一个方程中，有无数对( w 1, w 2)满足该方程。这也导致了我们的第三种情况。
- en: 'Now, suppose we change the output vector slightly and make the second entry
    of y zero, giving us y = [4 0]. Thus, we have the following:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们稍微改变输出向量，使y的第二个元素为零，得到y = [4 0]。因此，我们有以下情况：
- en: '[1 3 0 0]x[w 1 w 2] = [4 0]'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[1 3 0 0]x[w 1 w 2] = [4 0]'
- en: '{w 1 + 3 w 2 = 4 0 = 0'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '{w 1 + 3 w 2 = 4 0 = 0'
- en: Now, this system of linear equations has at least one solution and is *consistent*,
    but with infinitely many solutions. There is not much we can take away from solving
    this system of equations; since there are infinitely many solutions, we are unable
    to evaluate which one is the best to report. Real-world optimization problems
    are typically concerned with finding *the* single most optimal solution or the
    best sub-optimal solution that is closest to the empirically unattainable optimal
    solution.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这个线性方程组至少有一个解，并且是一致的，但有无穷多个解。从解这个方程组中我们无法得到太多信息；由于有无穷多个解，我们无法评估哪个是最好的报告。现实世界的优化问题通常关注于找到*唯一的*最优化解或最接近经验上无法达到的最优解的最佳次优解。
- en: '*Figure 7**.6* summarizes these three cases:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7**.6*总结了这三个情况：'
- en: '![Figure 7.6 – Three different cases when solving a system of linear equations](img/B18680_07_006.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![图7.6 – 解线性方程组的三个不同情况](img/B18680_07_006.jpg)'
- en: Figure 7.6 – Three different cases when solving a system of linear equations
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 – 解线性方程组的三个不同情况
- en: It turns out that we can also view the process of solving a system of linear
    equations from a geometric perspective. Let’s dive in.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们也可以从几何的角度来看解线性方程组的过程。让我们深入探讨。
- en: Geometric interpretation of solving a system of linear equations
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解线性方程组的几何解释
- en: 'Once again, let’s start with the case where we have a unique solution for the
    system of linear equations with two unknowns (w 1 and w 2) and two equations:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，让我们从具有两个未知数（w 1和w 2）和两个方程的线性方程组的唯一解的情况开始：
- en: '[1 3 2 4] x [w 1 w 2] = [4 6]'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[1 3 2 4] x [w 1 w 2] = [4 6]'
- en: '{ w 1 + 3 w 2 = 4  2 w 1 + 4 w 2 = 6'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '{ w 1 + 3 w 2 = 4  2 w 1 + 4 w 2 = 6'
- en: 'If we introduce a two-dimensional coordinate system and put w 1 and w 2 on
    the *x* axis and *y* axis, respectively, we will see two lines on the coordinate
    system, each representing a linear equation in the system. Now, we can re-express
    the previous system of equations as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们引入一个二维坐标系，并将w₁和w₂分别放在*x*轴和*y*轴上，我们将在坐标系上看到两条线，每条线代表系统中的一个线性方程。现在，我们可以将之前的方程组重新表达如下：
- en: '{w 2 = −  w 1 _ 3  +  4 _ 3   w 2 = −  w 1 _ 2  +  3 _ 2'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '{w₂ = −w₁ * 3 + 4 * 3   w₂ = −w₁ * 2 + 3 * 2'
- en: 'Therefore, solving the system of linear equations corresponds with finding
    the intersection point of these two lines, since it is only at the intersection
    point that both equations are satisfied. The following codes help us plot the
    two lines:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，解线性方程组相当于找到这两条线的交点，因为只有在这个交点处，两个方程都得到了满足。以下代码帮助我们绘制这两条线：
- en: '[PRE40]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Here, we use the `plot()` function to draw a two-dimensional coordinate system
    with a circle representing the point (1,1). We also add two lines using the `abline()`
    function, which accepts the intercept and slope of the line as input arguments.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`plot()`函数绘制一个二维坐标系，其中用圆表示点(1,1)。我们还使用`abline()`函数添加了两条线，该函数接受线的截距和斜率作为输入参数。
- en: Running this code generates *Figure 7**.7*. We can see that these two lines
    happen to meet at point (1,1), which is not a coincidence!
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码生成**图7.7**。我们可以看到这两条线恰好相交于点(1,1)，这并非巧合！
- en: '![Figure 7.7 – Plotting the system of linear equations as intersecting lines](img/B18680_07_007.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![图7.7 – 将线性方程组绘制为相交线](img/B18680_07_007.jpg)'
- en: Figure 7.7 – Plotting the system of linear equations as intersecting lines
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 – 将线性方程组绘制为相交线
- en: 'Now, we will look at the case with no solution for the system of equations.
    The previous example shows an inconsistent system of equations, where the second
    equation simply does not stand. With the geometric interpretation in the coordinate
    system, we can make another line parallel to the first one, such as by shifting
    the line up by one unit, to produce a case with no solution. Specifically, we
    can have the following system of equations:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将探讨方程组无解的情况。前面的例子显示了一个不一致的方程组，其中第二个方程根本不成立。在坐标系的几何解释中，我们可以画出一条与第一条线平行的线，例如通过将线向上移动一个单位，来产生一个无解的情况。具体来说，我们可以有以下方程组：
- en: '{ w 1 + 3 w 2 = 4  w 1 + 3 (w 2 − 1) = 4'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '{w₁ + 3w₂ = 4   w₁ + 3(w₂ − 1) = 4'
- en: 'Here, we minus 1 from w 2 to shift the line upward by one unit. Again, we can
    express these equations as a function of w 1:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们从w₂中减去1，将线向上移动一个单位。同样，我们可以将这些方程表达为w₁的函数：
- en: '{w 2 = −  w 1 _ 3  +  4 _ 3   w 2 = −  w 1 _ 3  +  7 _ 3'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '{w² = −w₁ * 3 + 4 * 3   w² = −w₁ * 3 + 7 * 3'
- en: 'Let’s plot these two lines on the coordinate system via the following code.
    The only change is the bigger intercept in the second line compared to the first
    one:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下代码在坐标系上绘制这两条线。唯一的变化是第二条线的截距比第一条线大：
- en: '[PRE41]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Running this code generates *Figure 7**.8*. Since these two lines are parallel,
    there will be no intersection between the two lines, so we’ll end up with no solution
    to the system of linear equations:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码生成**图7.8**。由于这两条线是平行的，它们之间不会有交点，因此线性方程组将没有解：
- en: '![Figure 7.8 – Plotting two parallel lines](img/B18680_07_008.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![图7.8 – 绘制两条平行线](img/B18680_07_008.jpg)'
- en: Figure 7.8 – Plotting two parallel lines
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 – 绘制两条平行线
- en: Now, let’s move on to the case with infinitely many solutions. As you may have
    guessed, we just need to make the second equation the same as the first one, thus
    creating two overlapping lines in the coordinate system. Any point on these two
    overlapping lines is a valid solution, and there is an infinite number of such
    points on the line(s).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续讨论有无穷多个解的情况。正如你可能猜到的，我们只需要将第二个方程与第一个方程相同，从而在坐标系中创建两条重叠的线。这两条重叠线上的任何点都是有效的解，并且在线上存在无限多个这样的点。
- en: Working with a system of linear equations may not guarantee a solution. Even
    if there are as many unknown variables as there are rows in the system, this isn’t
    guaranteed to give us a solution. In the following section, we’ll look at under
    what conditions we are guaranteed to get a unique solution.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性方程组一起工作并不保证有解。即使未知变量的数量与系统中的行数相同，这也并不能保证我们得到一个解。在下一节中，我们将探讨在什么条件下我们保证得到一个唯一解。
- en: Obtaining a unique solution to a system of linear equations
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取线性方程组的唯一解
- en: 'Recall our analytical framework: Xw = y, where we are given input-output pairs
    (X, y) and would like to solve the unknown vector, w. If things were simple and
    all these variables were scalars, we would simply divide both sides by X and obtain
    the solution, w = X −1 y, provided that X is invertible. Note that we would multiply
    both sides by X −1 on the left to perform the division. This brings us to the
    first condition: the matrix, X, needs to have a corresponding inverse matrix;
    that is, it is invertible.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾我们的分析框架：Xw = y，其中我们给出了输入输出对(X, y)，并希望求解未知向量w。如果事情很简单，并且所有这些变量都是标量，我们就会简单地两边除以X，得到解w
    = X⁻¹y，前提是X是可逆的。注意，我们会将两边都乘以X⁻¹的左边来进行除法。这使我们来到了第一个条件：矩阵X需要有一个相应的逆矩阵；也就是说，它是可逆的。
- en: '*Figure 7**.9* illustrates the correspondence between simple scalar calculations
    in regular algebra and matrix manipulations in matrix algebra. Note that by definition
    of matrix inverse, we have X −1 X = I. We used this result in the derivation.
    The identity matrix is special; any matrix multiplying an identity matrix will
    stay unchanged. Thus, we have Iw = w. Again, we assume the matrix, X, is invertible:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*图7.9*说明了常规代数中的简单标量计算与矩阵代数中的矩阵操作之间的对应关系。注意，根据矩阵逆的定义，我们有X⁻¹X = I。我们在推导中使用了这个结果。单位矩阵是特殊的；任何矩阵乘以单位矩阵都将保持不变。因此，我们有Iw
    = w。再次，我们假设矩阵X是可逆的：'
- en: '![Figure 7.9 – Comparing scalar and matrix manipulations when solving the system
    of linear equations](img/B18680_07_009.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图7.9 – 比较解线性方程组时标量和矩阵操作](img/B18680_07_009.jpg)'
- en: Figure 7.9 – Comparing scalar and matrix manipulations when solving the system
    of linear equations
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9 – 比较解线性方程组时标量和矩阵操作
- en: 'The second condition is that the *determinant* of the matrix, X, cannot be
    zero. The determinant is a summary measure of the size of the matrix; we will
    discuss this in more detail in the next chapter. The third condition is what we
    alluded to earlier: the rows and columns of the matrix, X, can form a *basis*
    for the corresponding row and column space. There should be no correlated rows
    or columns in the matrix. A basis of a vector space is a set of vectors that can
    uniquely generate all the other vectors in the same vector space via linear combinations.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个条件是矩阵X的**行列式**不能为零。行列式是矩阵大小的总结性度量；我们将在下一章中更详细地讨论这个问题。第三个条件是我们之前提到的：矩阵X的行和列可以形成对应行和列空间的**基**。矩阵中不应存在相关的行或列。向量空间的基是一组向量，可以通过线性组合唯一地生成同一向量空间中的所有其他向量。
- en: 'In addition, we would need a somewhat trivial condition: when Xw = 0, we have
    w = 0.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还需要一个相对简单的条件：当Xw = 0时，我们有w = 0。
- en: 'Computing the inverse and determinant of a matrix is straightforward in R.
    In the following code, we are calculating the inverse of the matrix, X, using
    the `solve()` function and its determinant using the `det()` function:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中计算矩阵的逆和行列式很简单。在下面的代码中，我们使用`solve()`函数计算矩阵X的逆，使用`det()`函数计算其行列式：
- en: '[PRE42]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The next chapter will touch on the matrix determinant, norm, trace, and other
    special properties in more detail.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将更详细地讨论矩阵行列式、范数、迹和其他特殊性质。
- en: Now that we can calculate the matrix inverse, let’s learn how to obtain the
    solution to the system of linear equations using the inverse of the input matrix,
    X, and output, vector y.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经能够计算矩阵的逆，让我们学习如何使用输入矩阵X和输出向量y的逆来获得线性方程组的解。
- en: Exercise 7.10 – obtaining the unique solution to a system of linear equations
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习7.10 – 获得线性方程组的唯一解
- en: 'In this exercise, we will make use of the matrix inverse to obtain the solution
    to a system of linear equations:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将利用矩阵逆来获得线性方程组的解：
- en: 'Construct the input matrix, `X`, and output vector, `y`, based on the previous
    example:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据前面的示例构建输入矩阵`X`和输出向量`y`：
- en: '[PRE43]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Note that the data we chose here is based on the previous running example, where
    the solution to the unknown variables is w = [1,1].
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，我们这里选择的数据是基于之前的运行示例，其中未知变量的解是w = [1,1]。
- en: 'Calculate the solution to the system of linear equations:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算线性方程组的解：
- en: '[PRE44]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: As we can see, the solution, which can be called the coefficient vector, matches
    the true result exactly. We can also multiply the input matrix by this solution
    to obtain an estimated output and check whether it is the same as the given output
    vector.
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如我们所见，解，可以称为系数向量，与真实结果完全匹配。我们还可以将输入矩阵乘以这个解，以获得一个估计的输出，并检查它是否与给定的输出向量相同。
- en: 'Calculate the output via matrix-vector multiplication between the input matrix
    and the estimated coefficient vector:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过输入矩阵和估计的系数向量之间的矩阵-向量乘法来计算输出：
- en: '[PRE45]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The result matches the given output vector.
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果与给定的输出向量匹配。
- en: Solving a system of linear equations with a square input matrix is a simple
    setting. When working with real data, the input matrix will likely be non-square,
    with more rows or columns. When there are more rows than columns, we have a limited
    number of unknown variables that need to satisfy more equations. This is an **overdetermined
    system**. On the other hand, when there are more unknown variables to satisfy
    fewer equations, we have an **underdetermined system**. We will discuss these
    two situations in the following section.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 使用平方输入矩阵求解线性方程组是一个简单的情况。当处理实际数据时，输入矩阵很可能是非方阵，拥有更多的行或列。当行数多于列数时，我们面临的是一个需要满足更多方程的有限未知变量，这种情况称为**超定系统**。另一方面，当需要满足的未知变量多于方程时，我们有一个**欠定系统**。我们将在下一节讨论这两种情况。
- en: Overdetermined and underdetermined systems of linear equations
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性方程组的超定和欠定系统
- en: The example we covered earlier, which consisted of two equations and two unknown
    variables to solve, gives a solution that passes through both lines on the coordinate
    system. This is called **interpolation**, where the solution perfectly satisfies
    both equations without any errors. In the language of machine learning, interpolation
    means the trained model can score 100% on the training dataset. This is not necessarily
    a good thing since the model will likely run into the risk of overfitting – that
    is, it will do pretty well on the training set but not so well on the test set.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论的例子，由两个方程和两个未知变量组成，给出了一个通过坐标系统上两条线的解。这被称为**插值**，其中解完美地满足两个方程，没有任何误差。在机器学习的语言中，插值意味着训练好的模型可以在训练数据集上获得100%的分数。这并不一定是一件好事，因为模型可能会遇到过拟合的风险——也就是说，它在训练集上表现得很好，但在测试集上表现不佳。
- en: Complex models such as neural networks and other nonlinear models tend to have
    very low or even zero training errors – that is, they are likely to interpolate
    the training data. The zero training cost occurs when the model becomes sufficiently
    complex to interpolate the training data. Perfect prediction in the training data
    is likely to happen when the number of coefficients, p, used by the model is equal
    to or larger than the number of observations, n, in the training input. In the
    case of linear regression, when p = n, we solve a system of linear equations where
    the number of free variables, whose optimal values we are solving for, is equal
    to the number of linear equations in the system.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂模型，如神经网络和其他非线性模型，往往具有非常低甚至为零的训练误差——这意味着它们很可能会插值训练数据。当模型变得足够复杂以至于可以插值训练数据时，就会发生零训练成本。当模型使用的系数数量，p，等于或大于训练输入中的观测数量，n，时，训练数据中的完美预测很可能会发生。在线性回归的情况下，当
    p = n 时，我们解决一个线性方程组，其中自由变量的数量，即我们正在求解其最优值的数量，等于系统中的线性方程数量。
- en: A simple example is a two-dimensional training set with two observation points
    on a coordinate system, as we saw earlier. When only one parameter is available,
    the model is reflected as a straight horizontal line in the coordinate system.
    This univariate model is too simple to fit these two points unless they happen
    to live along the fitted line. The resulting system of equations is said to be
    overdetermined and under-parameterized since we have more linear equations than
    the unknown variables in the system.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的例子是二维训练集，在坐标系统上有两个观测点，正如我们之前看到的。当只有一个参数可用时，模型在坐标系统中表现为一条水平的直线。这种单变量模型太简单，无法拟合这两个点，除非它们恰好位于拟合线上。由此产生的方程组被称为超定和欠参数化，因为我们有比系统中的未知变量更多的线性方程。
- en: 'When we have two parameters to fit the model, the problem can be solved with
    an exact solution: two linear equations and two unknowns, a straightforward exercise.
    We can fit a line anywhere in the coordinate system by adjusting its intercept
    and slope. So, the problem becomes fitting a line that passes through the two
    points. We can train a model that passes through the two points and produces zero
    training error, thus interpolating between these two points.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有两个参数来拟合模型时，问题可以用精确解来解决：两个线性方程和两个未知数，这是一个直接的练习。我们可以通过调整其截距和斜率在任何坐标系中拟合一条直线。因此，问题变成了拟合通过两个点的直线。我们可以训练一个通过这两个点并产生零训练误差的模型，从而在这两点之间进行插值。
- en: 'When there are more than two unknown variables – say we have three weights
    in the model – the problem becomes underdetermined and over-parameterized. The
    solution, when solvable, will be infinite. Having more than two parameters corresponds
    to fitting two points with a curved line. Any curve that passes through the two
    points produces zero training error, yet the curve can be arbitrarily wiggly and
    complex, depending on the number of parameters used. *Figure 7**.10* summarizes
    these three scenarios:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 当存在超过两个未知变量时——比如说模型中有三个权重——问题变为欠定和过参数化。当可解时，解将是无限的。超过两个参数对应于用曲线拟合两个点。任何通过这两个点的曲线都会产生零训练误差，但曲线可以任意扭曲和复杂，这取决于使用的参数数量。*图
    7.10* 总结了这三种情况：
- en: '![Figure 7.10 – Three scenarios of model complexity](img/B18680_07_010.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.10 – 模型复杂性的三种情况](img/B18680_07_010.jpg)'
- en: Figure 7.10 – Three scenarios of model complexity
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10 – 模型复杂性的三种情况
- en: '*Figure 7**.10* shows fitting two two-dimensional observations using different
    model complexities. The left plot contains a 0th degree polynomial model that
    contains only one parameter, thus being a horizontal line. The middle plot has
    an equal number of parameters to the number of observations, making the solution
    unique and exact. The right plot contains models with more than two parameters,
    where the solution is non-unique due to being an underdetermined system.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.10* 显示了使用不同的模型复杂度拟合两个二维观测值。左图包含一个0次多项式模型，它只包含一个参数，因此是一条水平线。中间的图具有与观测数量相等的参数数量，使得解是唯一和精确的。右图包含具有超过两个参数的模型，由于是欠定系统，解是非唯一的。'
- en: Perfect interpolation occurs when p = n – that is, the number of features is
    equal to the number of observations. The perfect interpolation continues with
    p > n when the system of equations becomes underdetermined and over-parameterized,
    leading to infinitely many solutions that correspond to models of an arbitrary
    shape. All these models pass through the observed data points and thus give zero
    training error.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 当 p = n 时，即特征数量等于观测数量时，发生完美插值。当方程组变为欠定和过参数化时，即 p > n，完美插值继续进行，导致无限多个解，这些解对应于任意形状的模型。所有这些模型都通过观测数据点，因此给出零训练误差。
- en: Summary
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced the basics of linear algebra, including working
    with vectors and matrices and performing matrix-vector multiplication. We highlighted
    a few special matrices, such as the identity matrix, and common operations, such
    as transposing and inverting a matrix.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了线性代数的基础知识，包括处理向量和矩阵以及执行矩阵-向量乘法。我们强调了几个特殊的矩阵，例如单位矩阵，以及一些常见的操作，例如矩阵的转置和求逆。
- en: Next, we used matrix-vector multiplication to solve a system of linear equations
    under different settings. We introduced the geometric interpretation that corresponds
    to the system of linear equations, along with how to obtain the solution using
    matrix inverse and multiplication operations.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用矩阵-向量乘法在不同的设置下解决线性方程组。我们介绍了与线性方程组相对应的几何解释，以及如何使用矩阵逆和乘法运算来获得解。
- en: Lastly, we touched upon common settings of the input matrix in the machine learning
    context, covering both underdetermined and overdetermined systems. Developing
    such an understanding will be crucial when we delve into statistical modeling
    and machine learning in the third part of this book.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们简要介绍了机器学习环境中输入矩阵的常见设置，包括欠定和过定系统。当我们深入到本书第三部分的统计建模和机器学习时，这种理解将至关重要。
- en: In the next chapter, we will discuss slightly more advanced concepts in matrix
    algebra and implementations in R.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论矩阵代数中的一些更高级的概念以及在 R 中的实现。
