- en: Predicting Sports Winners with Decision Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at predicting the winner of sports matches using
    a different type of classification algorithm to the ones we have seen so far:
    **decision trees**. These algorithms have a number of advantages over other algorithms.
    One of the main advantages is that they are readable by humans, allowing for their
    use in human-driven decision making. In this way, decision trees can be used to
    learn a procedure, which could then be given to a human to perform if needed.
    Another advantage is that they work with a variety of features, including categorical,
    which we will see in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the pandas library for loading and manipulating data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision trees for classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random forests to improve upon decision trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using real-world datasets in data mining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating new features and testing them in a robust framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will look at predicting the winner of games of the **National
    Basketball Association** (**NBA**). Matches in the NBA are often close and can
    be decided at the last minute, making predicting the winner quite difficult. Many
    sports share this characteristic, whereby the (generally) better team could be
    beaten by another team on the right day.
  prefs: []
  type: TYPE_NORMAL
- en: Various research into predicting the winner suggests that there may be an upper
    limit to sports outcome prediction accuracy which, depending on the sport, is
    between 70 percent and 80 percent. There is a significant amount of research being
    performed into sports prediction, often through data mining or statistics-based
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to have a look at an entry level basketball match
    prediction algorithm, using decision trees for determining whether a team will
    win a given match. Unfortunately, it doesn't quite make as much profit as the
    models that sports betting agencies use, which are often a bit more advanced,
    more complex, and ultimately, more accurate.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The data we will be using is the match history data for the NBA for the 2015-2016
    season. The website  [http://basketball-reference.com](http://basketball-reference.com/)
    contains a significant number of resources and statistics collected from the NBA
    and other leagues. To download the dataset, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to [http://www.basketball-reference.com/leagues/NBA_2016_games.html](http://www.basketball-reference.com/leagues/NBA_2016_games.html) 
    in your web browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click Share & more.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click Get table as CSV (for Excel).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the data, including the heading, into a text file named `basketball.csv`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat this process for the other months, except do not copy the heading.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This will give you a CSV file containing the results from each game of this
    season of the NBA. Your file should contain 1316 games and a total of 1317 lines
    in the file, including the header line.
  prefs: []
  type: TYPE_NORMAL
- en: CSV files are text files where each line contains a new row and each value is
    separated by a comma (hence the name). CSV files can be created manually by typing
    into a text editor and saving with a `.csv` extension. They can be opened in any
    program that can read text files but can also be opened in Excel as a spreadsheet.
    Excel (and other spreadsheet programs) can usually convert a spreadsheet to CSV
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: We will load the file with the `pandas` library, which is an incredibly useful
    library for manipulating data. Python also contains a built-in library called
    `csv` that supports reading and writing CSV files. However, we will use pandas,
    which provides more powerful functions that we will use later in the chapter for
    creating new features.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this chapter, you will need to install pandas. The easiest way to install
    it is to use Anaconda''s `conda` installer, as you did in [Chapter 1](lrn-dtmn-py-2e_ch03.html),
    *Getting Started with data mining to install scikit-learn*:'
  prefs: []
  type: TYPE_NORMAL
- en: '`$ conda install pandas` If you have difficulty in installing pandas, head
    to the project''s website at [http://pandas.pydata.org/getpandas.html](http://pandas.pydata.org/getpandas.html)
    and read the installation instructions for your system.'
  prefs: []
  type: TYPE_NORMAL
- en: Using pandas to load the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `pandas` library is a library for loading, managing, and manipulating data.
    It handles data structures behind-the-scenes and supports data analysis functions,
    such as computing the mean and grouping data by value.
  prefs: []
  type: TYPE_NORMAL
- en: When doing multiple data mining experiments, you will find that you write many
    of the same functions again and again, such as reading files and extracting features.
    Each time this reimplementation happens, you run the risk of introducing bugs.
    Using a high-quality library such as `pandas` significantly reduces the amount
    of work needed to do these functions, and also gives you more confidence in using
    well-tested code to underly your own programs.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, we will be using pandas a lot, introducing use cases as
    we go and new functions as needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can load the dataset using the `read_csv` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of this is a pandas **DataFrame**, and it has some useful functions
    that we will use later on. Looking at the resulting dataset, we can see some issues. Type
    the following and run the code to see the first five rows of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B06162OS_03_01.png)'
  prefs: []
  type: TYPE_IMG
- en: Just reading the data with no parameters resulted in quite a usable dataset,
    but it has some issues which we will address in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After looking at the output, we can see a number of problems:'
  prefs: []
  type: TYPE_NORMAL
- en: The date is just a string and not a date object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From visually inspecting the results, the headings aren't complete or correct
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These issues come from the data and we could fix this by altering the data itself.
    However, in doing this, we could forget the steps we took or misapply them; that
    is, we can't replicate our results. As with the previous section where we used
    pipelines to track the transformations we made to a dataset, we will use pandas
    to apply transformations to the raw data itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `pandas.read_csv` function has parameters to fix each of these issues,
    which we can specify when loading the file. We can also change the headings after
    loading the file, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The results have significantly improved, as we can see if we print out the
    resulting data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B06162OS_03_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Even in well-compiled data sources such as this one, you need to make some
    adjustments. Different systems have different nuances, resulting in data files
    that are not quite compatible with each other. When loading a dataset for the
    first time, always check the data loaded (even if it''s a known format) and also
    check the data types of the data. In pandas, this can be done with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have our dataset in a consistent format, we can compute a **baseline**,
    which is an easy way to get a good accuracy on a given problem. Any decent data
    mining solution should beat this baseline figure.
  prefs: []
  type: TYPE_NORMAL
- en: For a product recommendation system, a good baseline is to simply *recommend
    the most popular product*.
  prefs: []
  type: TYPE_NORMAL
- en: For a classification task, it can be to *always predict the most frequent task*,
    or alternatively applying a very simple classification algorithm like **OneR**.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our dataset, each match has two teams: a home team and a visitor team.
    An obvious baseline for this task is 50 percent, which is our expected accuracy
    if we simply guessed a winner at random. In other words, choosing the predicted
    winning team randomly will (over time) result in an accuracy of around 50 percent.
    With a little domain knowledge, however, we can use a better baseline for this
    task, which we will see in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Extracting new features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now extract some features from this dataset by combining and comparing
    the existing data. First, we need to specify our class value, which will give
    our classification algorithm something to compare against to see if its prediction
    is correct or not. This could be encoded in a number of ways; however, for this
    application, we will specify our class as 1 if the home team wins and 0 if the
    visitor team wins. In basketball, the team with the most points wins. So, while
    the data set doesn't specify who wins directly, we can easily compute it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can specify the data set by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We then copy those values into a NumPy array to use later for our scikit-learn
    classifiers. There is not currently a clean integration between pandas and scikit-learn,
    but they work nicely together through the use of NumPy arrays. While we will use
    pandas to extract features, we will need to extract the values to use them with
    scikit-learn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The preceding array now holds our class values in a format that scikit-learn
    can read.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the way, the better baseline figure for sports prediction is to predict
    the home team in every game. Home teams are shown to have an advantage in nearly
    all sports across the world. How big is this advantage? Let''s have a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The resulting value, around 0.59, indicates that the home team wins 59 percent
    of games on average. This is higher than 50 percent from random chance and is
    a simple rule that applies to most sports.
  prefs: []
  type: TYPE_NORMAL
- en: We can also start creating some features to use in our data mining for the input
    values (the `X` array). While sometimes we can just throw the raw data into our
    classifier, we often need to derive continuous numerical or categorical features
    from our data.
  prefs: []
  type: TYPE_NORMAL
- en: For our current dataset, we can't really use the features already present (in
    their current form) to do a prediction. We wouldn't know the scores of a game
    before we would need to predict the outcome of the game, so we can not use them
    as features. While this might sound obvious, it can be easy to miss.
  prefs: []
  type: TYPE_NORMAL
- en: The first two features we want to create to help us predict which team will
    win are whether either of those two teams won their previous game. This would
    roughly approximate which team is currently playing well.
  prefs: []
  type: TYPE_NORMAL
- en: We will compute this feature by iterating through the rows in order and recording
    which team won. When we get to a new row, we look up whether the team won the
    last time we saw them.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first create a (default) dictionary to store the team''s last result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We then create a new feature on our dataset to store the results of our new
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The key of this dictionary will be the team and the value will be whether they
    won their previous game. We can then iterate over all the rows and update the
    current row with the team''s last result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note that the preceding code relies on our dataset being in chronological order.
    Our dataset is in order; however, if you are using a dataset that is not in order,
    you will need to replace `dataset.iterrows()` with `dataset.sort("Date").iterrows()`.
  prefs: []
  type: TYPE_NORMAL
- en: Those last two lines in the loop update our dictionary with either a 1 or a
    0, depending on which team won the *current* game. This information is used for
    the next game each team plays.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the preceding code runs, we will have two new features: `HomeLastWin`
    and `VisitorLastWin`. Have a look at the dataset using `dataset.head(6)` to see
    an example of a home team and a visitor team that won their recent game. Have
    a look at other parts of the dataset using the panda''s indexer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Currently, this gives a false value to all teams (including the previous year's
    champion!) when they are first seen. We could improve this feature using the previous
    year's data, but we will not do that in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Decision trees are a class of supervised learning algorithms like a flow chart
    that consists of a sequence of nodes, where the values for a sample are used to
    make a decision on the next node to go to.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example gives a very good idea of how decision trees are a class
    of supervised learning algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B06162OS_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As with most classification algorithms, there are two stages to using them:'
  prefs: []
  type: TYPE_NORMAL
- en: The first stage is the **training** stage, where a tree is built using training
    data. While the nearest neighbor algorithm from the previous chapter did not have
    a training phase, it is needed for decision trees. In this way, the nearest neighbor
    algorithm is a lazy learner, only doing any work when it needs to make a prediction.
    In contrast, decision trees, like most classification methods, are eager learners,
    undertaking work at the training stage and therefore needing to do less in the
    predicting stage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second stage is the **predicting** stage, where the trained tree is used
    to predict the classification of new samples. Using the previous example tree,
    a data point of `["is raining", "very windy"]` would be classed as *bad weather*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many algorithms for creating decision trees. Many of these algorithms
    are iterative. They start at the base node and decide the best feature to use
    for the first decision, then go to each node and choose the next best feature,
    and so on. This process is stopped at a certain point when it is decided that
    nothing more can be gained from extending the tree further.
  prefs: []
  type: TYPE_NORMAL
- en: The `scikit-learn` package implements the **Classification and Regression Trees** (**CART**)
    algorithm as its default dDecision tree class, which can use both categorical
    and continuous features.
  prefs: []
  type: TYPE_NORMAL
- en: Parameters in decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most important parameters for a Decision Tree is the **stopping criterion**.
    When the tree building is nearly completed, the final few decisions can often
    be somewhat arbitrary and rely on only a small number of samples to make their
    decision. Using such specific nodes can result in trees that significantly overfit
    the training data. Instead, a stopping criterion can be used to ensure that the
    Decision Tree does not reach this exactness.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of using a stopping criterion, the tree could be created in full and
    then trimmed. This trimming process removes nodes that do not provide much information
    to the overall process. This is known as **pruning** and results in a model that
    generally does better on new datasets because it hasn't overfitted the training
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The decision tree implementation in scikit-learn provides a method to stop
    the building of a tree using the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: '`**min_samples_split**`: This specifies how many samples are needed in order
    to create a new node in the Decision Tree'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**min_samples_leaf**`: This specifies how many samples must be resulting from
    a node for it to stay'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first dictates whether a decision node will be created, while the second
    dictates whether a decision node will be kept.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another parameter for decision trees is the criterion for creating a decision.
    **Gini impurity** and** information gain** are two popular options for this parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Gini impurity**: This is a measure of how often a decision node would incorrectly
    predict a sample''s class'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Information gain**: This uses information-theory-based entropy to indicate
    how much extra information is gained by the decision node'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These parameter values do approximately the same thing--decide which rule and
    value to use to split a node into subnodes. The value itself is simply which metric
    to use to determine that split, however this can make a significant impact on
    the final models.
  prefs: []
  type: TYPE_NORMAL
- en: Using decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can import the `DecisionTreeClassifier` class and create a Decision Tree
    using scikit-learn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We used 14 for our `random_state` again and will do so for most of the book.
    Using the same random seed allows for replication of experiments. However, with
    your experiments, you should mix up the random state to ensure that the algorithm's
    performance is not tied to the specific value.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now need to extract the dataset from our pandas data frame in order to use
    it with our `scikit-learn` classifier. We do this by specifying the columns we
    wish to use and using the values parameter of a view of the data frame. The following
    code creates a dataset using our last win values for both the home team and the
    visitor team:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Decision trees are estimators, as introduced in [Chapter 2](lrn-dtmn-py-2e_ch03.html),
    *Classifying using **scikit-learn* *Estimators*, and therefore have `fit` and
    `predict` methods. We can also use the `cross_val_score` method to get the average
    score (as we did previously):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This scores 59.4 percent: we are better than choosing randomly! However, we
    aren''t beating our other baseline of just choosing the home team. In fact, we
    are pretty much exactly the same. We should be able to do better. **Feature engineering**
    is one of the most difficult tasks in data mining, and choosing *good* **features**
    is key to getting good outcomes—more so than choosing the right algorithm!'
  prefs: []
  type: TYPE_NORMAL
- en: Sports outcome prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We may be able to do better by trying other features. We have a method for testing
    how accurate our models are. The `cross_val_score` method allows us to try new
    features.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many possible features we could use, but we will try the following
    questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Which team is considered better generally?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which team won their last encounter?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will also try putting the raw teams into the algorithm, to check whether
    the algorithm can learn a model that checks how different teams play against each
    other.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the first feature, we will create a feature that tells us if the home team
    is generally better than the visitors. To do this, we will load the standings
    (also called a ladder in some sports) from the NBA in the previous season. A team
    will be considered better if it ranked higher in 2015 than the other team.
  prefs: []
  type: TYPE_NORMAL
- en: 'To obtain the standings data, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to [http://www.basketball-reference.com/leagues/NBA_2015_standings.html](http://www.basketball-reference.com/leagues/NBA_2015_standings.html)
    in your web browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select Expanded Standings to get a single list for the entire league.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the Export link.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the text and save it in a text/CSV file called `standings.csv` in your
    data folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Back in your Jupyter Notebook, enter the following lines into a new cell. You''ll
    need to ensure that the file was saved into the location pointed to by the data_folder
    variable. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: You can view the ladder by just typing standings into a new cell and running
  prefs: []
  type: TYPE_NORMAL
- en: 'the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B06162OS_03_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we create a new feature using a similar pattern to the previous feature.
    We iterate over the rows, looking up the standings for the home team and visitor
    team. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we use the `cross_val_score` function to test the result. First, we extract
    the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create a new `DecisionTreeClassifier` and run the evaluation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This now scores 60.9 percent  even better than our previous result, and now
    better than just choosing the home team every time. Can we do better?
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s test which of the two teams won their last match against each
    other. While rankings can give some hints on who won (the higher ranked team is
    more likely to win), sometimes teams play better against other teams. There are
    many reasons for this--for example, some teams may have strategies or players
    that work against specific teams really well. Following our previous pattern,
    we create a dictionary to store the winner of the past game and create a new feature
    in our data frame. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This feature works much like our previous rank-based feature. However, instead
    of looking up the ranks, this features creates a tuple called `teams`, and then
    stores the previous result in a dictionary. When those two teams play each other
    next, it recreates this tuple, and looks up the previous result. Our code doesn't
    differentiate between home games and visitor games, which might be a useful improvement
    to look at implementing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to evaluate. The process is pretty similar to before, except
    we add the new feature into the extracted values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This scores 62.2 percent. Our results are getting better and better.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will check what happens if we throw a lot of data at the Decision
    Tree, and see if it can learn an effective model anyway. We will enter the teams
    into the tree and check whether a Decision Tree can learn to incorporate that
    information.
  prefs: []
  type: TYPE_NORMAL
- en: 'While decision trees are capable of learning from categorical features, the
    implementation in `scikit-learn` requires those features to be encoded as numbers
    and features, instead of string values. We can use the `LabelEncoder` **transformer**
    to convert the string-based team names into assigned integer values. The code
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We should use the same transformer for encoding both the home team and visitor
    teams. This is so that the same team gets the same integer value as both a home
    team and visitor team. While this is not critical to the performance of this application,
    it is important and failing to do this may degrade the performance of future models.
  prefs: []
  type: TYPE_NORMAL
- en: These integers can be fed into the Decision Tree, but they will still be interpreted
    as continuous features by `DecisionTreeClassifier`. For example, teams may be
    allocated integers from 0 to 16\. The algorithm will see teams 1 and 2 as being
    similar, while teams 4 and 10 will be very different--but this makes no sense
    as all. All of the teams are different from each other--two teams are either the
    same or they are not!
  prefs: []
  type: TYPE_NORMAL
- en: 'To fix this inconsistency, we use the `OneHotEncoder` **transformer** to encode
    these integers into a number of binary features. Each binary feature will be a
    single value for the feature. For example, if the NBA team Chicago Bulls is allocated
    as integer 7 by the `LabelEncoder`, then the seventh feature returned by the `OneHotEncoder`
    will be a 1 if the team is Chicago Bulls and 0 for all other features/teams. This
    is done for every possible value, resulting in a much larger dataset. The code
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we run the Decision Tree as before on the new dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This scores an accuracy of 62.8 percent. The score is better still, even though
    the information given is just the teams playing. It is possible that the larger
    number of features were not handled properly by the decision trees. For this reason,
    we will try changing the algorithm and see if that helps. Data mining can be an
    iterative process of trying new algorithms and features.
  prefs: []
  type: TYPE_NORMAL
- en: Random forests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A single Decision Tree can learn quite complex functions. However, decision
    trees are prone to overfitting--learning rules that work only for the specific
    training set and don't generalize well to new data.
  prefs: []
  type: TYPE_NORMAL
- en: One of the ways that we can adjust for this is to limit the number of rules
    that it learns. For instance, we could limit the depth of the tree to just three
    layers. Such a tree will learn the best rules for splitting the dataset at a global
    level, but won't learn highly specific rules that separate the dataset into highly
    accurate groups. This trade-off results in trees that may have a good generalization,
    but an overall slightly poorer performance on the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: To compensate for this, we could create many of these *limited* decision trees
    and then ask each to predict the class value. We could take a majority vote and
    use that answer as our overall prediction. Random Forests is an algorithm developed
    from this insight.
  prefs: []
  type: TYPE_NORMAL
- en: There are two problems with the aforementioned procedure. The first problem
    is that building decision trees is largely deterministic—using the same input
    will result in the same output each time. We only have one training dataset, which
    means our input (and therefore the output) will be the same if we try to build
    multiple trees. We can address this by choosing a random subsample of our dataset,
    effectively creating new training sets. This process is called **bagging**  and it
    can be very effective in many situations in data mining.
  prefs: []
  type: TYPE_NORMAL
- en: The second problem we might run into with creating many decision trees from
    similar data is that the features that are used for the first few decision nodes
    in our tree will tend to be similar. Even if we choose random subsamples of our
    training data, it is still quite possible that the decision trees built will be
    largely the same. To compensate for this, we also choose a random subset of the
    features to perform our data splits on.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we have randomly built trees using randomly chosen samples, using (nearly)
    randomly chosen features. This is a random forest and, perhaps unintuitively,
    this algorithm is very effective for many datasets, with little need to tune many
    parameters of the model.
  prefs: []
  type: TYPE_NORMAL
- en: How do ensembles work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The randomness inherent in random forests may make it seem like we are leaving
    the results of the algorithm up to chance. However, we apply the benefits of averaging
    to nearly randomly built decision trees, resulting in an algorithm that reduces
    the variance of the result.
  prefs: []
  type: TYPE_NORMAL
- en: '**Variance** is the error introduced by variations in the training dataset
    on the algorithm. Algorithms with a high variance (such as decision trees) can
    be greatly affected by variations to the training dataset. This results in models
    that have the problem of overfitting. In contrast, **bias** is the error introduced
    by assumptions in the algorithm rather than anything to do with the dataset, that
    is, if we had an algorithm that presumed that all features would be normally distributed,
    then our algorithm may have a high error if the features were not.'
  prefs: []
  type: TYPE_NORMAL
- en: Negative impacts from bias can be reduced by analyzing the data to see if the
    classifier's data model matches that of the actual data.
  prefs: []
  type: TYPE_NORMAL
- en: To use an extreme example, a classifier that always predicts true, regardless
    of the input, has a very high bias. A classifier that always predicts randomly
    would have a very high variance. Each classifier has a high degree of error but
    of a different nature.
  prefs: []
  type: TYPE_NORMAL
- en: By averaging a large number of decision trees, this variance is greatly reduced.
    This results, at least normally, in a model with a higher overall accuracy and
    better predictive power. The trade-offs are an increase in time and an increase
    in the bias of the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In general, ensembles work on the assumption that errors in prediction are effectively
    random and that those errors are quite different from one classifier to another.
    By averaging the results across many models, these random errors are canceled
    out—leaving the true prediction. We will see many more ensembles in action throughout
    the rest of the book.
  prefs: []
  type: TYPE_NORMAL
- en: Setting parameters in Random Forests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Random Forest implementation in scikit-learn is called `RandomForestClassifier`,
    and it has a number of parameters. As Random Forests use many instances of `DecisionTreeClassifier`,
    they share many of the same parameters such as the `criterion` (Gini Impurity
    or Entropy/information gain), `max_features`, and `min_samples_split`.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some new parameters that are used in the ensemble process:'
  prefs: []
  type: TYPE_NORMAL
- en: '`n_estimators`: This dictates how many decision trees should be built. A higher
    value will take longer to run, but will (probably) result in a higher accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`oob_score`: If true, the method is tested using samples that aren''t in the
    random subsamples chosen for training the decision trees.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_jobs`: This specifies the number of cores to use when training the decision
    trees in parallel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `scikit-learn` package uses a library called **Joblib** for inbuilt parallelization.
    This parameter dictates how many cores to use. By default, only a single core
    is used--if you have more cores, you can increase this, or set it to -1 to use
    all cores.
  prefs: []
  type: TYPE_NORMAL
- en: Applying random forests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Random forests in scikit-learn use the **Estimator** interface, allowing us
    to use almost the exact same code as before to do cross-fold validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This results in an immediate benefit of 65.3 percent, up by 2.5 points by just
    swapping the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Random forests, using subsets of the features, should be able to learn more
    effectively with more features than normal decision trees. We can test this by
    throwing more features at the algorithm and seeing how it goes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This results in 63.3 percent—a drop in performance! One cause is the randomness
    inherent in random forests only chose some features to use rather than others.
    Further, there are many more features in  `X_teams` than in `X_lastwinner`, and
    having the extra features results in less relevant information being used. That
    said, don't get too excited by small changes in percentages, either up or down.
    Changing the random state value will have more of an impact on the accuracy than
    the slight difference between these feature sets that we just observed. Instead,
    you should run many tests with different random states, to get a good sense of
    the mean and spread of accuracy values.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also try some other parameters using the `GridSearchCV` class, as we
    introduced in [Chapter 2](lrn-dtmn-py-2e_ch02.html), *Classifying using **scikit-learn
    Estimators*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This has a much better accuracy of 67.4 percent!
  prefs: []
  type: TYPE_NORMAL
- en: 'If we wanted to see the parameters used, we can print out the best model that
    was found in the grid search. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The result shows the parameters that were used in the best scoring model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Engineering new features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous few examples, we saw that changing the features can have quite
    a large impact on the performance of the algorithm. Through our small amount of
    testing, we had more than 10 percent variance just from the features.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create features that come from a simple function in pandas by doing
    something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The feature_creator function must return a list of the feature''s value for
    each sample in the dataset. A common pattern is to use the dataset as a parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'You can create those features more directly by setting all the values to a
    single default value, like 0 in the next line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: You can then iterate over the dataset, computing the features as you go. We
    used
  prefs: []
  type: TYPE_NORMAL
- en: 'this format in this chapter to create many of our features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind that this pattern isn't very efficient. If you are going to do
    this, try all of your features at once.
  prefs: []
  type: TYPE_NORMAL
- en: A common *best practice* is to touch every sample as little as possible, preferably
    only once.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some example features that you could try and implement are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: How many days has it been since each team's previous match? Teams may be tired
    if they play too many games in a short time frame.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many games of the last five did each team win? This will give a more stable
    form of the `HomeLastWin` and `VisitorLastWin` features we extracted earlier (and
    can be extracted in a very similar way).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do teams have a good record when visiting certain other teams? For instance,
    one team may play well in a particular stadium, even if they are the visitors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are facing trouble extracting features of these types, check the pandasdocumentation
    at [http://pandas.pydata.org/pandas-docs/stable/](http://pandas.pydata.org/pandas-docs/stable/)
    for help. Alternatively, you can try an online forum such as Stack Overflow for
    assistance.
  prefs: []
  type: TYPE_NORMAL
- en: More extreme examples could use player data to estimate the strength of each
    team's sides to predict who won. These types of complex features are used every
    day by gamblers and sports betting agencies to try to turn a profit by predicting
    the outcome of sports matches.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we extended our use of scikit-learn's classifiers to perform
    classification and introduced the `pandas`library to manage our data. We analyzed
    real-world data on basketball results from the NBA, saw some of the problems that
    even well-curated data introduces, and created new features for our analysis.
  prefs: []
  type: TYPE_NORMAL
- en: We saw the effect that good features have on performance and used an ensemble
    algorithm, random forests, to further improve the accuracy. To take these concepts
    further, try to create your own features and test them out. Which features perform
    better? If you have trouble coming up with features, think about what other datasets
    can be included. For example, if key players are injured, this might affect the
    results of a specific match and cause a better team to lose.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will extend the affinity analysis that we performed
    in the first chapter to create a program to find similar books. We will see how
    to use algorithms for ranking and also use an approximation to improve the scalability
    of data mining.
  prefs: []
  type: TYPE_NORMAL
