- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Undersampling Methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, you have so much data that adding more data by oversampling only
    makes things worse. Don‚Äôt worry, as we have a strategy for those situations as
    well. It‚Äôs called undersampling, or downsampling. In this chapter, you will learn
    about the concept of undersampling, including when to use it and the various techniques
    to perform it. You will also see how to use these techniques via the `imbalanced-learn`
    library APIs and compare their performance with some classical machine learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing undersampling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When to avoid undersampling in the majority class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing examples uniformly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strategies for removing noisy observations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strategies for removing easy observations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you‚Äôll have mastered various undersampling techniques
    for imbalanced datasets and will be able to confidently apply them with the `imbalanced-learn`
    library to build better machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter will make use of common libraries such as `matplotlib`, `seaborn`,
    `pandas`, `numpy`, `scikit-learn`, and `imbalanced-learn`. The code and notebooks
    for this chapter can be found on GitHub at [https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/master/chapter03](https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/master/chapter03).
    To run the notebook, there are two options: you can click the **Open in Colab**
    icon at the top of the chapter‚Äôs notebook, or you can launch it directly from
    [https://colab.research.google.com](https://colab.research.google.com) using the
    GitHub URL of the notebook.'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing undersampling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Two households, both alike in dignity,
  prefs: []
  type: TYPE_NORMAL
- en: In fair Verona, where we lay our scene,
  prefs: []
  type: TYPE_NORMAL
- en: From ancient grudge break to new mutiny,
  prefs: []
  type: TYPE_NORMAL
- en: Where civil blood makes civil hands unclean.
  prefs: []
  type: TYPE_NORMAL
- en: ‚Äì Opening lines of *Romeo and Juliet*, by Shakespeare
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs look at a scenario inspired by Shakespeare‚Äôs play *Romeo and Juliet*.
    Imagine a town with two warring communities (viz., the Montagues and Capulets).
    They have been enemies for generations. The Montagues are in the minority and
    the Capulets are in the majority in the town. The Montagues are super rich and
    powerful. The Capulets are not that well off. This creates a complex situation
    in the town. There are regular riots in the town because of this rivalry. One
    day, the Montagues win the king‚Äôs favor and conspire to eliminate some Capulets
    to bring their numbers down. The idea is that if fewer Capulets are in the town,
    the Montagues will no longer be in the minority. The king agrees to the plan as
    he hopes for peace after its execution. We will use this story in this chapter
    to illustrate various undersampling algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, it is not sufficient to oversample the minority class. With oversampling,
    you can run into problems such as overfitting and longer training time. To solve
    these problems and to approach the issue of class imbalance differently, people
    have thought of the opposite of oversampling‚Äîthat is, **undersampling**. This
    is also often referred to in the literature as **downsampling** or **negative
    downsampling** to denote that the negative class (that is, the majority class)
    is being undersampled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Undersampling techniques reduce the number of samples in the majority class(es).
    This method has two obvious advantages over oversampling:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The data size remains in check**: Even if data imbalance is not a concern,
    dealing with massive datasets‚Äîranging from terabytes to petabytes‚Äîoften necessitates
    data reduction for practical training. The sheer volume can make training impractical
    both in terms of time and computational costs. Cloud providers such as Amazon
    Web Services, Microsoft Azure, and Google Cloud charge for compute units in addition
    to storage, making large-scale training expensive. Given that you‚Äôre likely to
    use only a fraction of the available training data anyway, it‚Äôs crucial to be
    strategic about which data to retain and which to discard. Undersampling becomes
    not just a method for balancing classes but also a cost-effective strategy for
    efficient training, potentially reducing training time from days to hours.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**There is a smaller chance of overfitting**: By using undersampling techniques,
    the number of majority class instances can be reduced, allowing the model to focus
    more on the minority class instances. This, in turn, improves the model‚Äôs ability
    to generalize across both classes. As a result, the model becomes less likely
    to overfit to the majority class and is better equipped to handle new, unseen
    data, thus reducing the likelihood of overfitting. We are going to discuss the
    various undersampling methods in this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 3**.1* shows the general idea behind undersampling graphically.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 ‚Äì General idea behind undersampling showing (a) imbalanced data with
    two classes and (b) data after undersampling
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 3**.1(a)*, we show the original data containing many data points
    from the circle class. In *Figure 3**.1(b)*, we show the resampled data after
    removing some data points from the circle class.
  prefs: []
  type: TYPE_NORMAL
- en: When to avoid undersampling the majority class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Undersampling is not a panacea and may not always work. It depends on the dataset
    and model under consideration:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Too little training data for all the classes**: If the dataset is already
    small, undersampling the majority class can lead to a significant loss of information.
    In such cases, it is advisable to try gathering more data or exploring other techniques,
    such as oversampling the minority class to balance the class distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Majority class equally important or more important than minority class**:
    In specific scenarios, such as the spam filtering example mentioned in [*Chapter
    1*](B17259_01.xhtml#_idTextAnchor015), *Introduction to Data Imbalance in Machine
    Learning*, it is crucial to maintain high accuracy in identifying the majority
    class instances. In such situations, undersampling the majority class might reduce
    the model‚Äôs ability to accurately classify majority class instances, leading to
    a higher false positive rate. Instead, alternative methods, such as cost-sensitive
    learning or adjusting the decision threshold (both of these are discussed in [*Chapter
    5*](B17259_05.xhtml#_idTextAnchor151), *Cost-Sensitive Learning*), can be considered.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**When undersampling harms model performance or causes overfitting of the model**:
    Undersampling the majority class might decrease overall model performance, as
    it discards potentially valuable information. Some of the undersampling methods
    discard the examples near the decision boundary, which can also alter the decision
    boundary. Also, by reducing the size of the majority class, undersampling can
    cause underfitting, where the model becomes too simple to capture the underlying
    trends in the limited training data and performs poorly on new, unseen data. There
    is some risk of overfitting as well when using undersampling techniques if the
    model memorizes the reduced dataset. In such cases, exploring other techniques
    such as ensemble methods ([*Chapter 4*](B17259_04.xhtml#_idTextAnchor120), *Ensemble
    Methods*), hybrid methods that combine oversampling and undersampling (discussed
    toward the end of this chapter), or using different algorithms less prone to overfitting
    might be better.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: üöÄ Undersampling techniques in production at Meta, Microsoft, and Uber
  prefs: []
  type: TYPE_NORMAL
- en: The main challenge in tasks such as ad click prediction is handling massive
    and imbalanced datasets. For instance, a single day of Facebook ads can contain
    hundreds of millions of instances, with an average **ClickThrough Rate** (**CTR**)
    of just 0.1%. To address this, Meta employs two specialized techniques, as detailed
    in the paper *Practical Lessons from Predicting Clicks on Ads at Facebook* [1].
    The first is uniform subsampling, which uniformly reduces the training data volume
    and has shown that using just 10% of the data results in only a 1% reduction in
    model performance. The second is negative downsampling, which specifically targets
    negative (‚Äúno-click‚Äù) examples and uses an optimal downsampling rate of 0.025.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, Microsoft and Uber have very similar approaches to tackling these
    challenges. To estimate the CTR of sponsored ads on Bing search [2], Microsoft
    uses a 50% negative downsampling rate for non-click cases, effectively halving
    the training time while maintaining similar performance metrics. Uber Eats also
    employs negative downsampling to reduce the training data in order to train models
    that predict whether to send push notifications to customers about new restaurants
    [3]. In addition, they remove the least important features when building the final
    version of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs look at one of the ways of classifying undersampling methods next.
  prefs: []
  type: TYPE_NORMAL
- en: Fixed versus cleaning undersampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Undersampling methods can be divided into two categories based on how data points
    get removed from the majority class. These categories are fixed methods and cleaning
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: In **fixed methods**, the number of examples in the majority class is reduced
    to a fixed number. Usually, we reduce the number of majority class samples to
    the size of the minority class. For example, if there are 100 million samples
    in the majority class and 10 million samples in the minority class, you will be
    left with only 10 million samples of both classes after applying the fixed method.
    Some such methods are random undersampling and instance hardness-based undersampling.
  prefs: []
  type: TYPE_NORMAL
- en: In **cleaning methods**, the number of samples of the majority class is reduced
    based on some pre-determined criteria, independent of the absolute number of examples.
    Once this criterion is met, the algorithm doesn‚Äôt care about the size of the majority
    or minority class.
  prefs: []
  type: TYPE_NORMAL
- en: '*Table 3.1* summarizes the key differences between the two methods in a tabular
    format:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Fixed** **undersampling methods** | **Cleaning** **undersampling methods**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Key idea | Selects a specific number of majority class instances to remove
    | Identifies and removes noisy, redundant, or misclassified majority class instances
    aiming to improve decision boundaries between classes |'
  prefs: []
  type: TYPE_TB
- en: '| Relationship between instances | Doesn‚Äôt consider relationships between instances
    | Evaluates relationships between instances |'
  prefs: []
  type: TYPE_TB
- en: '| Performance and ease of implementation | Faster and easier to implement |
    Sometimes, may have a better model performance and generalization than fixed undersampling
    methods |'
  prefs: []
  type: TYPE_TB
- en: '| Examples | Random undersamplingInstance hardness-based undersampling | Tomek
    linksNeighborhood cleaning rule |'
  prefs: []
  type: TYPE_TB
- en: Table 3.1 ‚Äì Fixed versus cleaning undersampling methods
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs create an imbalanced dataset using the `make_classification` API from
    `sklearn`. We will apply various undersampling techniques throughout this chapter
    to balance this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 3**.2* shows what the dataset looks like on a 2D plot. For the complete
    notebook code, please refer to the GitHub repository of this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 ‚Äì Plotting a dataset with an imbalance ratio of 1:99
  prefs: []
  type: TYPE_NORMAL
- en: Model calibration and threshold adjustment
  prefs: []
  type: TYPE_NORMAL
- en: After applying undersampling techniques, you may want to recalibrate the model‚Äôs
    probability scores. Why? As undersampling alters the original distribution of
    the classes, the model‚Äôs confidence estimates are biased [4] and may no longer
    accurately reflect the true likelihood of each class in the real-world scenario.
    Failing to recalibrate can lead to misleading or suboptimal decision-making when
    the model is deployed. Therefore, recalibrating the model‚Äôs probability scores
    ensures that the model not only classifies instances correctly but also estimates
    the probabilities in a manner that is consistent with the actual class distribution,
    enhancing its reliability. For a deeper understanding of this process, especially
    how to recalibrate model scores to account for the effects of downsampling, please
    refer to [*Chapter 10*](B17259_10.xhtml#_idTextAnchor279), *Model Calibration*.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of imbalanced datasets, threshold adjustment techniques can be
    a critical complement to undersampling methods. Whether or not we end up applying
    any sampling techniques, adjusting the threshold to determine the correct class
    label can be crucial for correctly interpreting the model‚Äôs performance. For a
    more in-depth understanding of various threshold adjustment techniques, you can
    refer to [*Chapter 5*](B17259_05.xhtml#_idTextAnchor151), *Cost-Sensitive Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: Undersampling approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let‚Äôs look at a second way to categorize undersampling algorithms. There are
    a few ways the king can eliminate some Capulets:'
  prefs: []
  type: TYPE_NORMAL
- en: He can eliminate the Capulets uniformly from the whole town, thereby removing
    a few Capulets from all areas of the town
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatively, the king can remove the Capulets who live near the houses of
    the Montagues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, he can remove the Capulets who live far away from the houses of the
    Montagues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These are the three major approaches used in undersampling techniques. We either
    remove the majority samples uniformly, remove the majority samples near the minority
    samples, or remove the majority samples far from the minority samples. We can
    also combine the last two approaches by removing some nearby and some far away
    samples. The following diagram gives the classification of these methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 ‚Äì Categorization of undersampling techniques
  prefs: []
  type: TYPE_NORMAL
- en: The following figure illustrates the difference between the two criteria. In
    *Figure 3**.4(a)*, we show the original dataset. In *Figure 3**.4(b)*, we show
    the same dataset after removing the examples close to the decision boundary. Notice
    how examples closer to the class boundary are removed.
  prefs: []
  type: TYPE_NORMAL
- en: Majority class examples far from the minority class may not effectively help
    models establish a decision boundary. Hence, such majority class examples away
    from the decision boundary can be removed. In *Figure 3**.4(c)*, we show the dataset
    after removing examples far away from the boundary. The examples far from the
    decision boundary can be considered easy-to-classify examples.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 ‚Äì Difference between two general approaches to undersampling
  prefs: []
  type: TYPE_NORMAL
- en: Having discussed various ways to classify the various undersampling techniques,
    let‚Äôs now look at them in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Removing examples uniformly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two major ways of removing the majority class examples uniformly from
    the data. The first way is to remove the examples randomly, and the other way
    involves using clustering techniques. Let‚Äôs discuss both of these methods in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Random UnderSampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first technique the king might think of is to pick Capulets randomly and
    remove them from the town. This is a na√Øve approach. It might work, and the king
    might be able to bring peace to the town. But the king might cause unforeseen
    damage by picking up some influential Capulets. However, it is an excellent place
    to start our discussion. This technique can be considered a close cousin of random
    oversampling. In **Random UnderSampling** (**RUS**), as the name suggests, we
    randomly extract observations from the majority class until the classes are balanced.
    This technique inevitably leads to data loss, might harm the underlying structure
    of the data, and thus performs poorly sometimes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 ‚Äì Comic explaining the main idea behind the RUS method
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the code sample for using RUS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `sampling_strategy` value can be used to specify the desired ratio of minority
    and majority classes, the default being that they will be made equal in number.
    *Figure 3**.6* shows the application of the `RandomUnderSampler` technique, where
    the right plot shows that most of the negative class samples got dropped:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 ‚Äì Plotting datasets before and after undersampling using RandomUnderSampler
  prefs: []
  type: TYPE_NORMAL
- en: Next, we transition to a smarter technique that forms groups among majority
    class examples.
  prefs: []
  type: TYPE_NORMAL
- en: ClusterCentroids
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second technique the king might follow to carry out uniform undersampling
    is to divide the Capulet population into groups based on location. Then, keep
    one Capulet from each group and remove other Capulets from the group. This method
    of undersampling is called the **ClusterCentroids** method. If there are *N* items
    in the minority class, we create *N* clusters from the points of the majority
    class. For example, this can be done using the K-means algorithm. K-means is a
    clustering algorithm that groups nearby points into different clusters and assigns
    centroids to each group.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 ‚Äì Comic illustrating the main idea behind the ClusterCentroids method
  prefs: []
  type: TYPE_NORMAL
- en: In the ClusterCentroids technique, we first apply the K-means algorithm to all
    of the majority class data. Then, for each cluster, we keep the centroid and remove
    all other examples within that cluster. It‚Äôs worth noting that the centroid might
    not even be a part of the original data, which is an important aspect of this
    method.
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 3**.8*, we show the working of ClusterCentroids. In *Figure 3**.8(a)*,
    we start with an imbalanced dataset. In *Figure 3**.8(b)*, we calculate the centroids
    for the three clusters. These centroids are shown as stars in the diagram. Finally,
    we remove all majority class samples except the centroids from the dataset in
    *Figure 3**.8(c)*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 ‚Äì Illustrating how the ClusterCentroids method works
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code for using ClusterCentroids:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 3**.9* shows the application of the ClusterCentroids technique, where
    the right plot shows that most of the negative class samples got dropped.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 ‚Äì Plotting datasets before and after undersampling using ClusterCentroids
  prefs: []
  type: TYPE_NORMAL
- en: One thing to note is that ClusterCentroids can be computationally expensive
    because it uses the K-means algorithm by default, which can be slow. We recommend
    exploring various parameters in the ClusterCentroids method, such as the estimator,
    which specifies the clustering method to be used. For example, K-means can be
    replaced with MiniBatchKMeans, a faster variant of the K-means clustering algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will attempt to eliminate the majority class examples
    in a more strategic manner.
  prefs: []
  type: TYPE_NORMAL
- en: Strategies for removing noisy observations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The king might decide to look at the friendships and locations of the citizens
    before removing anyone. The king might decide to remove the Capulets who are rich
    and live near the Montagues. This could bring peace to the city by separating
    the feuding clans. Let‚Äôs look at some strategies to do that with our data.
  prefs: []
  type: TYPE_NORMAL
- en: ENN, RENN, and AllKNN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The king can remove the Capulets based on their neighbors. For example, if one
    or more of the three closest neighbors of a Capulet is a Montague, the king can
    remove the Capulet. This technique is called `imbalanced-learn` library gives
    us options to decide which classes we would like to resample and what kind of
    class arrangement the neighbors of the sample should have.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two different criteria that we can follow for excluding the samples:'
  prefs: []
  type: TYPE_NORMAL
- en: We can choose to exclude samples whose one or more neighbors are not from the
    same class as themselves
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can decide to exclude samples whose majority of neighbors are not from the
    same class as themselves
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In *Figure 3**.10*, we show the working of the ENN algorithm. Here, we remove
    the majority samples that have one or more minority neighbors. In *Figure 3**.10(a)*,
    we show the original dataset. In *Figure 3**.10(b)*, we highlight the majority
    class samples that have one or more minority class nearest neighbors. The highlighted
    majority class samples are shown as solid boxes, and their neighbors are shown
    by creating curves around them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 ‚Äì Illustrating how the ENN method works
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code for using ENN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B17259_03_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 ‚Äì Plotting datasets before and after undersampling using ENN
  prefs: []
  type: TYPE_NORMAL
- en: Here, `n_neighbors` is the size of the neighborhood to consider to compute the
    nearest neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two variants of ENN that we won‚Äôt dive into, but you can explore
    them if you are interested: `imblearn.under_sampling.RepeatedEditedNearestNeighbours`)
    and `imblearn.under_sampling.AllKNN`). In RENN [6], we repeat the process followed
    in ENN until there are no more examples that can be removed or the maximum number
    of cycle counts has been reached. This algorithm also removes the noisy data.
    It is stronger in removing the boundary examples as the algorithm is repeated
    several times (*Figure 3**.12*).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 ‚Äì Plotting datasets before and after undersampling using RENN
  prefs: []
  type: TYPE_NORMAL
- en: In the **AllKNN** method [6], we repeat **ENN** but with the number of neighbors
    going from 1 to K.
  prefs: []
  type: TYPE_NORMAL
- en: Tomek links
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In 1976, Ivan Tomek proposed the idea of **Tomek links** [7]. Two examples are
    said to form Tomek links if they belong to two different classes, and there is
    no third point with a shorter distance to them than the distance between the two
    points. The intuition behind Tomek links is that ‚Äú*if two points are from different
    classes, they should not be nearest to each other.*‚Äù These points are part of
    the noise, and we can eliminate the majority member or both points to reduce noise.
    This is as if the king decides to remove the Capulets whose best friends are Montagues.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `TomekLinks` API as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B17259_03_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.13 ‚Äì Plotting datasets before and after undersampling using TomekLinks
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3**.14* shows the working of the Tomek links algorithm. In *Figure
    3**.14(a)*, we have the original dataset. In *Figure 3**.14(b),* we find and highlight
    the Tomek links. Notice that the points in these links are close to each other.
    In *Figure 3**.14(c)*, we show the dataset after removing the majority class samples
    (depicted as circles) that belong to the Tomek links. Notice the two circles present
    in part *(b)* but missing in part *(c)*. Similarly, we show the dataset after
    removing all the points in Tomek links in part *(d)* of the diagram.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.14 ‚Äì Illustrating how the TomekLinks algorithm works
  prefs: []
  type: TYPE_NORMAL
- en: Tomek links is a resource-intensive method due to its requirement of calculating
    pairwise distances between all examples. As stated in *A Study of the Behavior
    of Several Methods for Balancing Machine Learning Training Data* [8], performing
    this process on a reduced dataset would be more computationally efficient when
    dealing with large amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: In the next method, we will try to remove majority class examples from the perspective
    of minority class examples. Can we remove the nearest neighbors of the minority
    class that belong to the majority class?
  prefs: []
  type: TYPE_NORMAL
- en: Neighborhood Cleaning Rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Apart from removing the Capulets whose one or more nearest neighbors are Montagues,
    the king might decide to look at the nearest neighbors of Montagues and remove
    the Capulets who might come up as one of the nearest neighbors for a Montague.
    In the **Neighborhood Cleaning Rule** (**NCR**) [9], we apply an ENN algorithm,
    train a KNN on the remaining data, and then remove all the majority class samples
    that are the nearest neighbors of a minority sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code for using `NeighourhoodCleaningRule`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B17259_03_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.15 ‚Äì Plotting datasets before and after undersampling using NCR
  prefs: []
  type: TYPE_NORMAL
- en: Instance hardness threshold
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The king might ask a minister, ‚Äú*Which Capulets have mixed well with Montagues?*‚Äù
    The minister, based on their knowledge of the town, will give a list of those
    Capulets. Then, the king will remove the Capulets whose names are on the list.
    This method of using another model to identify noisy samples is known as the **instance
    hardness threshold**. In this method, we train a classification model on the data,
    such as a decision tree, random forest, or linear SVM.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to predicting the class of an instance, these classifiers can return
    their class probabilities. Class probabilities show the confidence the model has
    in classifying the instances. With the instance hardness threshold method [10],
    we remove the majority class samples that received low probability estimates (referred
    to as the ‚Äúhard instances‚Äù). These instances are considered ‚Äúhard to classify‚Äù
    due to class overlap, a principal contributor to instance hardness.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `imbalanced-learn` library provides an API for utilizing `InstanceHardnessThreshold`,
    where we can specify the estimator used to estimate the hardness of the examples.
    In this case, we use `LogisticRegression` as the estimator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B17259_03_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.16 ‚Äì Plotting datasets before and after undersampling using InstanceHardnessThreshold
  prefs: []
  type: TYPE_NORMAL
- en: Since classification models need to draw a decision boundary between the majority
    and minority classes, the majority class examples that are too far away from the
    minority class examples may not help the model decide this decision boundary.
    Considering this, we will look at methods in the next section that will remove
    such easy majority class examples.
  prefs: []
  type: TYPE_NORMAL
- en: Strategies for removing easy observations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The reverse of the strategy to remove the rich and famous Capulets is to remove
    the poor and weak Capulets. This section will discuss the techniques for **removing
    the majority samples far away from the minority samples**. Instead of removing
    the samples from the boundary between the two classes, we use them for training
    a model. This way, we can train a model to better discriminate between the classes.
    However, one downside is that these algorithms risk retaining noisy data points,
    which could then be used to train the model, potentially introducing noise into
    the predictive system.
  prefs: []
  type: TYPE_NORMAL
- en: Condensed Nearest Neighbors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Condensed Nearest Neighbors** (**CNNeighbors**) [11] is an algorithm that
    works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: We add all minority samples to a set and one randomly selected majority sample.
    Let‚Äôs call this set `C`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We train a KNN model with *k = 1* on set `C`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we repeat the following four steps for each of the remaining majority
    samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We consider one majority sample; let‚Äôs call it `e`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: We try to predict the class of `e` using KNN.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: If the predicted class matches the original class, we remove the sample. The
    intuition is that there is little to learn from `e` as even a *1-NN* classifier
    can learn it.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Otherwise, we add the sample to our set `C` and train the *1-NN* on `C` again.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: This method removes the easy-to-classify samples from the majority class.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code to use `CondensedNearestNeighbour` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B17259_03_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.17 ‚Äì Plotting datasets before and after undersampling using CNNeighbors
  prefs: []
  type: TYPE_NORMAL
- en: However, the CNNeighbors method can be computationally expensive, as it evaluates
    each majority class example using the KNN algorithm. This makes the CNNeighbors
    method unsuitable for big data applications.
  prefs: []
  type: TYPE_NORMAL
- en: One-sided selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The king might decide to remove some rich and many poor Capulets. This way,
    only the middle-class Capulets will stay in the town. In one-sided selection [12],
    we do just that. This method is a combination of CNNeighbors and Tomek links.
    We first resample using a CNNeighbors. Then, we remove the Tomek links from the
    resampled data. It reduces both noisy and easy-to-identify samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code for `OneSidedSelection`. When we don‚Äôt provide the `n_neighbors`
    parameter, the default value of `1` is taken:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B17259_03_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.18 ‚Äì Plotting datasets before and after undersampling using OneSidedSelection
  prefs: []
  type: TYPE_NORMAL
- en: Here, `n_seeds_S` is the number of minority class samples used as seeds in the
    method, and it can significantly impact the method‚Äôs performance. It is advisable
    to tune this parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Combining undersampling and oversampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You might wonder whether we can combine undersampling techniques with oversampling
    techniques to produce even better results. The answer is yes. Oversampling methods
    increase the number of samples of the minority class but also usually increase
    the noise in the data. Some undersampling techniques can help us remove the noise,
    for example, ENN, Tomek links, NCR, and instance hardness. We can combine these
    methods with SMOTE to produce good results. The combination of SMOTE with ENN
    [13] and Tomek links [14] has been well researched. Also, the `imbalanced-learn`
    library supports both of them: `SMOTEENN` and `SMOTETomek`.'
  prefs: []
  type: TYPE_NORMAL
- en: Model performance comparison
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let‚Äôs explore how some popular models perform using the various undersampling
    techniques we‚Äôve discussed. We use two datasets for this comparison: one synthetic
    dataset and one real-world dataset called `thyroid_sick` from the `imbalanced-learn`
    library. We‚Äôll evaluate the performance of 11 different undersampling techniques
    against a baseline of no sampling, using both logistic regression and random forest
    models. *Figures 3.19* to *3.22* show the average precision values for models
    trained using these various methods.'
  prefs: []
  type: TYPE_NORMAL
- en: You can find the notebook in the GitHub repository of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.19 ‚Äì Average precision when using various methods on the thyroid_sick
    dataset using random forest
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.20 ‚Äì Average precision when using various methods on synthetic data
    using random forest
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.21 ‚Äì Average precision when using various methods on the thyroid_sick
    dataset using logistic regression
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17259_03_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.22 ‚Äì Average precision when using various methods on synthetic data
    using logistic regression
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some more observations:'
  prefs: []
  type: TYPE_NORMAL
- en: The effectiveness of undersampling techniques can vary significantly depending
    on the dataset and its characteristics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No single technique dominates across all datasets, emphasizing the need for
    empirical testing to choose the best method for your specific problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, which method will work best for your data? There is no easy answer to this
    question. The key here is to develop an intuition about the inner workings of
    these methods and have a pipeline that can help you test different techniques.
  prefs: []
  type: TYPE_NORMAL
- en: However, certain techniques can be time-consuming. In our testing on a dataset
    with a million examples, methods such as `CondensedNearestNeighbor`, `ClusterCentroids`,
    and `ALLKNN` took longer than others. If you‚Äôre dealing with large amounts of
    data, planning to scale in the future, or are pressed for time, you may want to
    avoid these methods or tune their parameters. Techniques such as `RandomUnderSampler`
    and `InstanceHardnessThreshold` are more suitable for rapid iterative development.
  prefs: []
  type: TYPE_NORMAL
- en: That brings us to the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed undersampling, an approach to address the class
    imbalance in datasets by reducing the number of samples in the majority class.
    We reviewed the advantages of undersampling, such as keeping the data size in
    check and reducing the chances of overfitting. Undersampling methods can be categorized
    into fixed methods, which reduce the number of majority class samples to a fixed
    size, and cleaning methods, which reduce majority class samples based on predetermined
    criteria.
  prefs: []
  type: TYPE_NORMAL
- en: We went over various undersampling techniques, including random undersampling,
    instance hardness-based undersampling, ClusterCentroids, ENN, Tomek links, NCR,
    instance hardness, CNNeighbors, one-sided selection, and combinations of undersampling
    and oversampling techniques, such as `SMOTEENN` and `SMOTETomek`.
  prefs: []
  type: TYPE_NORMAL
- en: We concluded with a performance comparison of various undersampling techniques
    from the `imbalanced-learn` library on logistic regression and random forest models,
    using a few datasets, and benchmarked their performance and effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: Once you identify that your dataset is imbalanced and could potentially benefit
    from applying undersampling techniques, go ahead and experiment with the various
    methods discussed in this chapter. Evaluate their effectiveness using the appropriate
    metrics, such as PR-AUC, to find the most suitable approach for improving your
    model‚Äôs performance.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will go over various ensemble-based techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Explore the various undersampling APIs available from the `imbalanced-learn`
    library at [https://imbalanced-learn.org/stable/references/under_sampling.html](https://imbalanced-learn.org/stable/references/under_sampling.html).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explore the `NearMiss` undersampling technique, available through the `imblearn.under_sampling.NearMiss`
    API. Which class of methods does it belong to? Apply the `NearMiss` method to
    the dataset that we used in the chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try all the undersampling methods discussed in this chapter on the `us_crime`
    dataset from UCI. You can find this dataset in the `fetch_datasets` API of the
    `imbalanced-learn` library. Find the undersampling method with the highest `f1-score`
    metric for `LogisticRegression` and `XGBoost` models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Can you identify an undersampling method of your own? (Hint: think about combining
    the various approaches to undersampling in new ways.)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'X. He et al., ‚Äú*Practical Lessons from Predicting Clicks on Ads at Facebook*,‚Äù
    in Proceedings of the Eighth International Workshop on Data Mining for Online
    Advertising, New York NY USA: ACM, Aug. 2014, pp. 1‚Äì9\. doi: 10.1145/2648584.2648589.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'X. Ling, W. Deng, C. Gu, H. Zhou, C. Li, and F. Sun, ‚Äú*Model Ensemble for Click
    Prediction in Bing Search Ads*,‚Äù in Proceedings of the 26th International Conference
    on World Wide Web Companion - WWW ‚Äô17 Companion, Perth, Australia: ACM Press,
    2017, pp. 689‚Äì698\. doi: 10.1145/3041021.3054192.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*How Uber Optimizes the Timing of Push Notifications using ML and Linear* *Programming*:
    [https://www.uber.com/blog/how-uber-optimizes-push-notifications-using-ml/](https://www.uber.com/blog/how-uber-optimizes-push-notifications-using-ml/).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A. D. Pozzolo, O. Caelen, R. A. Johnson, and G. Bontempi, ‚Äú*Calibrating Probability
    with Undersampling for Unbalanced Classification*,‚Äù in 2015 IEEE Symposium Series
    on Computational Intelligence, Cape Town, South Africa: IEEE, Dec. 2015, pp. 159‚Äì166\.
    doi: 10.1109/SSCI.2015.33.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(Introducing the ENN method) D. L. Wilson, ‚Äú*Asymptotic Properties of Nearest
    Neighbor Rules Using Edited Data*,‚Äù IEEE Trans. Syst., Man, Cybern., vol. SMC-2,
    no. 3, pp. 408‚Äì421, Jul. 1972, doi: 10.1109/TSMC.1972.4309137.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(Introducing the RENN and AllKNN methods) ‚Äú*An Experiment with the Edited Nearest-Neighbor
    Rule*,‚Äù IEEE Trans. Syst., Man, Cybern., vol. SMC-6, no. 6, pp. 448‚Äì452, Jun.
    1976, doi: 10.1109/TSMC.1976.4309523.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'I. Tomek, ‚Äú*Two Modifications of CNN*,‚Äù IEEE Trans. Syst., Man, Cybern., vol.
    SMC-6, no. 11, pp. 769‚Äì772, Nov. 1976, doi: 10.1109/TSMC.1976.4309452.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'G. E. A. P. A. Batista, R. C. Prati, and M. C. Monard, ‚Äú*A study of the behavior
    of several methods for balancing machine learning training data*,‚Äù SIGKDD Explor.
    Newsl., vol. 6, no. 1, pp. 20‚Äì29, Jun. 2004, doi: 10.1145/1007730.1007735.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(Introducing the neighborhood cleaning rule method) J. Laurikkala, ‚Äú*Improving
    Identification of Difficult Small Classes by Balancing Class Distribution*,‚Äù in
    Artificial Intelligence in Medicine, S. Quaglini, P. Barahona, and S. Andreassen,
    Eds., in Lecture Notes in Computer Science, vol. 2101\. Berlin, Heidelberg: Springer
    Berlin Heidelberg, 2001, pp. 63‚Äì66\. doi: 10.1007/3-540-48229-6_9.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(Introducing the instance hardness threshold technique) M. R. Smith, T. Martinez,
    and C. Giraud-Carrier, ‚Äú*An instance level analysis of data complexity*,‚Äù Mach
    Learn, vol. 95, no. 2, pp. 225‚Äì256, May 2014, doi: 10.1007/s10994-013-5422-z.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'P. Hart, ‚Äú*The condensed nearest neighbor rule (corresp.)*,‚Äù IEEE transactions
    on information theory, vol. 14, no. 3, pp. 515‚Äì516, 1968, https://citeseerx.ist.psu.edu/document?‚Ä®    repid=rep1&type=pdf&doi=7c3771fd6829630cf450af853 df728ecd8da4ab2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Introducing the one-sided selection method) M. Kubat and S. Matwin, ‚Äú*Addressing
    The Curse Of Imbalanced Training Sets:* *One-sided Selection*‚Äù.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Application of `SMOTEENN` and `SMOTETomek` methods) Gustavo EAPA Batista, Ronaldo
    C Prati, and Maria Carolina Monard. *A study of the behavior of several methods
    for balancing machine learning training data*. ACM SIGKDD explorations newsletter,
    6(1):20‚Äì29, 2004.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '(Application of the `SMOTETomek` method) Gustavo EAPA Batista, Ana LC Bazzan,
    and Maria Carolina Monard. *Balancing training data for automated annotation of
    keywords: a case study*. In WOB, 10‚Äì18\. 2003.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
