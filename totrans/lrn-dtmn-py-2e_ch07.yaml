- en: Follow Recommendations Using Graph Mining
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用图挖掘进行关注推荐
- en: Graphs can be used to represent a wide range of phenomena. This is particularly
    true for online social networks, and the **Internet of Things** (**IoT**). Graph
    mining is big business, with websites such as Facebook running on data analysis
    experiments performed on graphs.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 图可以用来表示广泛的现象。这尤其适用于在线社交网络和物联网（IoT）。图挖掘是商业的大事，例如Facebook这样的网站就是基于在图上进行的数据分析实验。
- en: Social media websites are built upon engagement. Users without active news feeds,
    or interesting friends to follow, do not engage with sites. In contrast, users
    with more interesting friends and *followees* engage more, see more ads. This
    leads to larger revenue streams for the website.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 社交媒体网站建立在用户参与度之上。没有活跃新闻源或有趣的朋友关注，用户不会参与网站。相反，拥有更多有趣朋友和关注者的用户参与度更高，看到更多广告。这导致网站收入流增加。
- en: In this chapter, we look at how to define similarity on graphs, and how to use
    them within a data mining context. Again, this is based on a model of the phenomena. We
    look at some basic graph concepts, like sub-graphs and connected components. This
    leads to an investigation of cluster analysis, which we delve more deeply into
    in  [Chapter 10](lrn-dtmn-py-2e_ch10.html)<q>,</q> *Clustering News Articles.*
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何在图上定义相似性，以及如何在数据挖掘环境中使用它们。这同样基于现象模型。我们研究了一些基本的图概念，如子图和连通分量。这导致了对聚类分析的研究，我们将在第10章[lrn-dtmn-py-2e_ch10.html]《聚类新闻文章》中更深入地探讨。
- en: 'The topics covered in this chapter include:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖的主题包括：
- en: Clustering data to find patterns
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类数据以发现模式
- en: Loading datasets from previous experiments
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从之前的实验中加载数据集
- en: Getting follower information from Twitter
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从Twitter获取关注者信息
- en: Creating graphs and networks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建图和网络
- en: Finding subgraphs for cluster analysis
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找用于聚类分析的子图
- en: Loading the dataset
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据集
- en: In this chapter, our task is to recommend users on online social networks based
    on shared connections. Our logic is that if two users have the same friends, they
    are highly similar and worth recommending to each other. We want our recommendations
    to be of high value. We can only recommend so many people before it becomes tedious,
    therefore we need to find recommendations that engage users.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们的任务是推荐在线社交网络中的用户，基于共享连接。我们的逻辑是，如果两个用户有相同的关注者，他们非常相似，值得互相推荐。我们希望我们的推荐具有较高的价值。我们只能推荐这么多人，否则会变得乏味，因此我们需要找到能够吸引用户的推荐。
- en: To do this, we use the previous chapter's disambiguation model to find only
    users talking about *Python as a programming language*. In this chapter, we use
    the results from one data mining experiment as input into another data mining
    experiment. Once we have our Python programmers selected, we then use their friendships
    to find clusters of users that are highly similar to each other. The similarity
    between two users will be defined by how many friends they have in common. Our
    intuition will be that the more friends two people have in common, the more likely
    two people are to be friends (and therefore should be on our social media platform).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们使用上一章的消歧模型来找到只谈论*Python作为编程语言*的用户。在本章中，我们将一个数据挖掘实验的结果作为另一个数据挖掘实验的输入。一旦我们选定了Python程序员，我们就使用他们的友谊来找到高度相似的用户群。两个用户之间的相似度将由他们有多少共同朋友来定义。我们的直觉是，两个人共同的朋友越多，他们成为朋友的可能性就越大（因此应该在我们的社交媒体平台上）。
- en: We are going to create a small social graph from Twitter using the API we introduced
    in the previous chapter. The data we are looking for is a subset of users interested
    in a similar topic (again, the Python programming language) and a list of all
    of their friends (people they follow). With this data, we will check how similar
    two users are, based on how many friends they have in common.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用上一章介绍过的API从Twitter创建一个小型社交图谱。我们寻找的数据是感兴趣于类似话题（再次强调，是Python编程语言）的用户子集以及他们所有朋友的列表（他们关注的人）。有了这些数据，我们将检查两个用户之间的相似度，基于他们有多少共同朋友。
- en: There are many other online social networks apart from Twitter. The reason we
    have chosen Twitter for this experiment is that their API makes it quite easy
    to get this sort of information. The information is available from other sites,
    such as Facebook, LinkedIn, and Instagram, as well. However, getting this information
    is more difficult.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Twitter之外，还有许多其他的在线社交网络。我们选择Twitter进行这个实验的原因是他们的API使得获取这类信息变得相当容易。信息也来自其他网站，如Facebook、LinkedIn和Instagram等。然而，获取这些信息要困难得多。
- en: 'To start collecting data, set up a new Jupyter Notebook and an instance of
    the `twitter` connection, as we did in the previous chapter. You can reuse the
    app information from the previous chapter or create a new one:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始收集数据，设置一个新的Jupyter Notebook和一个`twitter`连接实例，就像我们在上一章中所做的那样。你可以重用上一章中的应用信息或创建一个新的：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Also, set up the filenames. You will want to use a different folder for this
    experiment from the one you used in  [Chapter 6](lrn-dtmn-py-2e_ch06.html), *Social
    Media Insight Using Naive Bayes*, ensuring you do not override your previous dataset!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，设置文件名。你将想要为这个实验使用一个与你在[第6章](lrn-dtmn-py-2e_ch06.html)，“使用朴素贝叶斯进行社交媒体洞察”中使用的不同的文件夹，确保你不会覆盖你之前的数据集！
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we will need a list of users. We will do a search for tweets, as we did
    in the previous chapter, and look for those mentioning the word `python`. First,
    create two lists for storing the tweet''s text and the corresponding users. We
    will need the user IDs later, so we create a dictionary mapping that now. The
    code is as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要一个用户列表。我们将像上一章中所做的那样进行推文搜索，寻找提到单词`python`的推文。首先，创建两个列表来存储推文文本和相应的用户。我们稍后需要用户ID，所以现在创建一个映射字典。代码如下：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will now perform a search for the word python, as we did in the previous
    chapter, and iterate over the search results and only saving Tweets with text (as
    per the last chapter''s requirements):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将执行对单词python的搜索，就像我们在上一章中所做的那样，遍历搜索结果，并只保存文本（按照上一章的要求）的推文：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Running this code will get about 100 tweets, maybe a little fewer in some cases.
    Not all of them will be related to the programming language, though. We will address
    that by using the model we trained in the previous chapter.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码将获取大约100条推文，在某些情况下可能稍微少一些。尽管如此，并非所有这些推文都与编程语言相关。我们将通过使用上一章中训练的模型来解决这个问题。
- en: Classifying with an existing model
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用现有模型进行分类
- en: As we learned in the previous chapter, not all tweets that mention the word
    python are going to be relating to the programming language. To do that, we will
    use the classifier we used in the previous chapter to get tweets based on the
    programming language. Our classifier wasn't perfect, but it will result in a better
    specialization than just doing the search alone.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一章中学到的，提到单词python的推文并不一定都与编程语言相关。为了做到这一点，我们将使用上一章中使用的分类器来获取基于编程语言的推文。我们的分类器并不完美，但它将比仅仅进行搜索的结果有更好的专业化。
- en: In this case, we are only interested in users who are tweeting about Python,
    the programming language. We will use our classifier from the last chapter to
    determine which tweets are related to the programming language. From there, we
    will select only those users who were tweeting about the programming language.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们只对那些在推文中提到Python编程语言的用户感兴趣。我们将使用上一章中的分类器来确定哪些推文与编程语言相关。从那里，我们只选择那些提到编程语言的用户。
- en: To do this part of our broader experiment, we first need to save the model from
    the previous chapter. Open the Jupyter Notebook we made in the last chapter, the
    one in which we built and trained the classifier.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行我们更广泛的实验的这一部分，我们首先需要保存上一章中的模型。打开我们在上一章中制作的Jupyter Notebook，即我们构建和训练分类器的那个。
- en: If you have closed it, then the Jupyter Notebook won't remember what you did,
    and you will need to run the cells again. To do this, click on the Cell menu on
    the Notebook and choose Run All.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经关闭了它，那么Jupyter Notebook将不会记住你所做的一切，你需要再次运行这些单元格。要做到这一点，点击笔记本上的单元格菜单并选择运行所有。
- en: After all of the cells have computed, choose the final blank cell. If your Notebook
    doesn't have a blank cell at the end, choose the last cell, select the Insert
    menu, and select the Insert Cell Below option.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有单元格都计算完毕后，选择最终的空白单元格。如果你的笔记本在末尾没有空白单元格，请选择最后一个单元格，选择插入菜单，然后选择插入单元格下方选项。
- en: We are going to use the `joblib` library to save our model and load it.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`joblib`库来保存我们的模型并加载它。
- en: '`joblib` is included with the `scikit-learn` package as a built-in external
    package. No extra installation step needed! This library has tools for saving
    and loading models, and also for simple parallel processing - which is used in
    `scikit-learn` quite a lot.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`joblib`是`scikit-learn`包内置的外部包之一。无需额外安装步骤！这个库提供了保存和加载模型以及简单并行处理（这在`scikit-learn`中相当常用）的工具。'
- en: 'First, import the library and create an output filename for our model (make
    sure the directories exist, or else they won''t be created). I''ve stored this
    model in my `Models` directory, but you could choose to store them somewhere else.
    The code is as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入库并为我们的模型创建一个输出文件名（确保目录存在，否则它们不会被创建）。我已经将这个模型存储在我的`Models`目录中，但您可以选择将它们存储在其他位置。代码如下：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, we use the `dump` function in `joblib`, which works much like the similarly
    named version in the `json` library. We pass the model itself and the output filename:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`joblib`库中的`dump`函数，它的工作方式与`json`库中同名版本类似。我们传递模型本身和输出文件名：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Running this code will save our model to the given filename. Next, go back to
    the new Jupyter Notebook you created in the last subsection and load this model.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码将把我们的模型保存到指定的文件名。接下来，回到您在上一个子节中创建的新Jupyter笔记本，并加载此模型。
- en: 'You will need to set the model''s filename again in this Notebook by copying
    the following code:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个笔记本中，您需要再次设置模型的文件名，方法是将以下代码复制过来：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Make sure the filename is the one you used just before to save the model. Next,
    we need to recreate our BagOfWords class, as it was a custom-built class and can''t
    be loaded directly by joblib. Simply copy the entire BagOfWords class from the
    previous chapter''s code, including its dependencies:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 确保文件名是您刚才保存模型时使用的那个。接下来，我们需要重新创建我们的BagOfWords类，因为它是一个自定义构建的类，不能直接由joblib加载。只需从上一章的代码中复制整个BagOfWords类及其依赖项：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In production, you would need to develop your custom transformers in separate,
    centralized files, and import them into the Notebook instead. This little hack
    simplifies the workflow, but feel free to experiment with centralizing important
    code by creating a library of common functionality.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中，您需要单独开发自己的自定义转换器，并将它们导入到笔记本中。这个小技巧简化了工作流程，但您可以自由地通过创建一个通用功能库来集中化重要代码进行实验。
- en: 'Loading the model now just requires a call to the  `load` function of `joblib`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在加载模型只需要调用`joblib`的`load`函数：
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Our context_classifier works exactly like the model object of the notebook
    we saw in [Chapter 6](lrn-dtmn-py-2e_ch06.html)<q>,</q> *Social Media Insight
    Using Naive Bayes*, It is an instance of a Pipeline, with the same three steps
    as before (`BagOfWords`, `DictVectorizer`, and a `BernoulliNB` classifier). Calling
    the predict function on this model gives us a prediction as to whether our tweets
    are relevant to the programming language. The code is as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的context_classifier与我们在[第6章](lrn-dtmn-py-2e_ch06.html)中看到的笔记本中的模型对象工作方式完全相同，即《使用朴素贝叶斯进行社交媒体洞察》。它是一个Pipeline的实例，与之前的三个步骤相同（`BagOfWords`、`DictVectorizer`和`BernoulliNB`分类器）。在这个模型上调用predict函数会给出我们的推文是否与编程语言相关的预测。代码如下：
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The *ith* item in `y_pred` will be 1 if the *ith* tweet is (predicted to be)
    related to the programming language, or else it will be 0\. From here, we can
    get just the tweets that are relevant and their relevant users:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`y_pred`中的第*i*个项如果是（预测为）与编程语言相关的推文，则为1，否则为0。从这里，我们可以获取相关推文及其相关用户：'
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Using my data, this comes up to 46 relevant users. A little lower than our 100
    tweets/users from before, but now we have a basis for building our social network.
    We can always add more data to get more users, but 40+ users will be sufficient
    to go through this chapter as a first pass. I recommend coming back, adding more
    data, and running the code again, to see what results you obtain.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我的数据，这对应着46个相关用户。比之前的100条推文/用户略低，但现在我们有了一个构建社交网络的基础。我们总是可以添加更多数据以获取更多用户，但40+个用户足以作为第一次遍历通过这一章节。我建议回来，添加更多数据，并再次运行代码，看看您获得什么结果。
- en: Getting follower information from Twitter
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Twitter获取关注者信息
- en: With our initial set of users, we now need to get the friends of each of these
    users. A friend is a person whom the user is following. The API for this is called
    friends/ids, and it has both good and bad points. The good news is that it returns
    up to 5,000 friend IDs in a single API call. The bad news is that you can only
    make 15 calls every 15 minutes, which means it will take you at least 1 minute
    per user to get all followers—more if they have more than 5,000 friends (which
    happens more often than you may think).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要获取我们初始用户集的每个用户的联系人。联系人是指用户正在关注的人。这个API叫做friends/ids，它既有优点也有缺点。好消息是它可以在单个API调用中返回多达5,000个朋友ID。坏消息是每15分钟你只能调用15次，这意味着你至少需要花1分钟每个用户来获取所有后继者——如果他们有超过5,000个朋友（这比你想的更常见）。
- en: The code is similar to the code from our previous API usage (obtaining tweets).
    We will package it as a function, as we will use this code in the next two sections.
    Our function takes a twitter user's ID value, and returns their friends. While
    it may be surprising to some, many Twitter users have more than 5,000 friends.
    Due to this we will need to use Twitter's pagination function, which lets Twitter
    return multiple pages of data through separate API calls. When you ask Twitter
    for information, it gives you your information along with a cursor, which is an
    integer that Twitter uses to track your request. If there is no more information,
    this cursor is 0; otherwise, you can use the supplied cursor to get the next page
    of results.  Passing this cursor lets twitter continue your query, returning the
    next set of data to you.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 代码与之前API使用（获取推文）的代码类似。我们将将其打包成一个函数，因为我们将在下一两个部分中使用这段代码。我们的函数接受一个Twitter用户的ID值，并返回他们的联系人。虽然对一些人来说可能很惊讶，但许多Twitter用户有超过5,000个朋友。因此，我们需要使用Twitter的分页功能，这允许Twitter通过单独的API调用返回多页数据。当你向Twitter请求信息时，它会给你你的信息以及一个光标，这是一个Twitter用来跟踪你的请求的整数。如果没有更多信息，这个光标是0；否则，你可以使用提供的光标来获取下一页的结果。传递这个光标让Twitter继续你的查询，返回下一组数据给你。
- en: 'In the function, we keep looping while this cursor is not equal to 0 (as, when
    it is, there is no more data to collect). We then perform a request for the user''s
    followers and add them to our list. We do this in a try block, as there are possible
    errors that can happen that we can handle. The follower''s IDs are stored in the
    ids key of the results dictionary. After obtaining that information, we update
    the cursor. It will be used in the next iteration of the loop. Finally, we check
    if we have more than 10,000 friends. If so, we break out of the loop. The code
    is as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数中，我们保持循环直到这个光标不等于0（因为，当它等于时，就没有更多数据可以收集了）。然后我们向用户的后继者发起请求并将他们添加到我们的列表中。我们这样做是在一个try块中，因为可能发生一些我们可以处理的错误。后继者的ID存储在结果字典的ids键中。在获取到这些信息后，我们更新光标。它将在循环的下一迭代中使用。最后，我们检查我们是否有超过10,000个朋友。如果是这样，我们就跳出循环。代码如下：
- en: '[PRE11]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: It is worth inserting a warning here. We are dealing with data from the Internet,
    which means weird things can and do happen regularly. A problem I ran into when
    developing this code was that some users have many, many, many thousands of friends.
    As a fix for this issue, we will put a failsafe here, exiting the function if
    we reach more than 10,000 users. If you want to collect the full dataset, you
    can remove these lines, but beware that it may get stuck on a particular user
    for a very long time.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里插入一个警告是值得的。我们正在处理来自互联网的数据，这意味着奇怪的事情会经常发生。我在开发这段代码时遇到的一个问题是，一些用户有很多很多很多的朋友。为了解决这个问题，我们在这里设置一个安全退出机制，当我们达到超过10,000个用户时退出函数。如果你想收集完整的数据集，你可以删除这些行，但请注意，它可能会在某个特定的用户上长时间卡住。
- en: Much of the above function is error handling, as quite a lot can go wrong when
    dealing with external APIs!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 上述函数的大部分是错误处理，因为在处理外部API时可能会出现很多问题！
- en: The most likely error that can happen is if we accidentally reach our API limit
    (while we have a sleep to stop that, it can occur if you stop and run your code
    before this sleep finishes). In this case, results is `None` and our code will
    fail with a `TypeError`. In this case, we wait for 5 minutes and try again, hoping
    that we have reached our next 15-minute window. There may be another `TypeError`
    that occurs at this time. If one of them does, we raise it and will need to handle
    it separately.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最可能发生的错误是我们意外达到API限制（虽然我们有一个睡眠来停止它，但在你停止并运行代码之前，它可能发生）。在这种情况下，结果为`None`，我们的代码将因`TypeError`而失败。在这种情况下，我们等待5分钟并再次尝试，希望我们已经到达下一个15分钟窗口。这时可能还会发生另一个`TypeError`。如果其中一个发生了，我们将抛出它，并需要单独处理。
- en: The second error that can happen occurs at Twitter's end, such as asking for
    a user that doesn't exist or some other data-based error, resulting in a `TwitterHTTPError` (which
    is a similar concept to a HTTP 404 error). In this case, don't try this user anymore,
    and just return any followers we did get (which, in this case, is likely to be
    0).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种可能发生的错误是在Twitter端发生的，比如请求一个不存在的用户或其他基于数据的错误，导致`TwitterHTTPError`（这与HTTP 404错误的概念类似）。在这种情况下，不要再尝试这个用户，只需返回我们确实获取到的任何关注者（在这种情况下，可能为0）。
- en: Finally, Twitter only lets us ask for follower information 15 times every 15
    minutes, so we will wait for 1 minute before continuing. We do this in a finally
    block so that it happens even if an error occurs.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Twitter只允许我们每15分钟请求15次关注者信息，因此我们将在继续之前等待1分钟。我们这样做是为了在发生错误的情况下也能执行。
- en: Building the network
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建网络
- en: Now we are going to build our network of users, where users are linked if the
    two users follow each other. The aim of building this network is to give us a
    data structure we can use to segment our list of users into groups. From these
    groups, we can then recommend people in the same group to each other. Starting
    with our original users, we will get the friends for each of them and store them
    in a dictionary. Using this concept we can grow the graph outwards from an initial
    set of users.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将构建我们的用户网络，其中如果两个用户相互关注，则用户之间有联系。构建这个网络的目标是给我们一个可以用来将用户列表分割成组的数据结构。从这些组中，我们然后可以向同一组的人推荐其他人。从我们的原始用户开始，我们将获取每个用户的联系人并存储在字典中。使用这个概念，我们可以从一组初始用户向外扩展图。
- en: 'Starting with our original users, we will get the friends for each of them
    and store them in a dictionary (after obtaining the user''s ID from our `*user_id*`
    dictionary):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的原始用户开始，我们将获取每个用户的联系人并将它们存储在字典中（在从我们的`*user_id*`字典中获取用户的ID之后）：
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, we are going to remove any user who doesn''t have any friends. For these
    users, we can''t really make a recommendation in this way. Instead, we might have
    to look at their content or people who follow them. We will leave that out of
    the scope of this chapter, though, so let''s just remove these users. The code
    is as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将删除任何没有联系人的用户。对于这些用户，我们实际上无法以这种方式做出推荐。相反，我们可能需要查看他们的内容或关注他们的人。不过，我们将把这一点排除在本章的范围之外，所以我们只需删除这些用户。代码如下：
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We now have between 30 and 50 users, depending on your initial search results.
    We are now going to increase that amount to 150\. The following code will take
    quite a long time to run—given the limits on the API, we can only get the friends
    for a user once every minute. Simple math will tell us that 150 users will take
    150 minutes, which is at least 2 hours and 30 minutes. Given the time we are going
    to be spending on getting this data, it pays to ensure we get only good users.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有30到50个用户，具体取决于你的初始搜索结果。我们现在将这个数量增加到150。以下代码将需要相当长的时间来运行——考虑到API的限制，我们每分钟只能获取一个用户的联系人。简单的数学告诉我们，150个用户将需要150分钟，这至少是2小时30分钟。考虑到我们将花费在获取这些数据上的时间，确保我们只获取好的用户是值得的。
- en: What makes a good user, though? Given that we will be looking to make recommendations
    based on shared connections, we will search for users based on shared connections.
    We will get the friends of our existing users, starting with those users who are
    better connected to our existing users. To do that, we maintain a count of all
    the times a user is in one of our friend's lists. It is worth considering the
    goals of the application when considering your sampling strategy. For this purpose,
    getting lots of similar users enables the recommendations to be more regularly
    applicable.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么样的用户才算好呢？鉴于我们将基于共享联系来做出推荐，我们将根据共享联系来搜索用户。我们将获取现有用户的联系人，从那些与现有用户联系更紧密的用户开始。为此，我们维护一个计数，记录用户出现在我们朋友的列表中的所有次数。在考虑你的采样策略时，考虑应用程序的目标是值得考虑的。为此目的，获取大量类似用户可以使推荐更加适用。
- en: To do this, we simply iterate over all the friend lists we have and then count
    each time a friend occurs.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们只需遍历我们所有的朋友列表，然后计算每个朋友出现的次数。
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Computing our current friend count, we can then get the most connected (that
    is, most friends from our existing list) person from our sample. The code is as
    follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 计算我们当前的朋友数量，然后我们可以从我们的样本中获取最连接的人（即现有列表中最多的朋友）。代码如下：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'From here, we set up a loop that continues until we have the friends of 150
    users. We then iterate over all of our best friends (which happens in order of
    the number of people who have them as friends) until we find a user we have not
    yet checked. We then get the friends of that user and update the `friends` counts.
    Finally, we work out who is the most connected user who we haven''t already got
    in our list:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们设置一个循环，直到我们有了150个用户的联系人。然后我们遍历我们最好的朋友（这是按照拥有他们作为朋友的人数顺序发生的）直到我们找到一个我们尚未检查的用户。然后我们获取该用户的联系人并更新`friends`计数。最后，我们找出我们列表中尚未出现的最连接的用户：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The codes will then loop and continue until we reach 150 users.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，代码将循环并继续，直到我们达到150个用户。
- en: You may want to set these values lower, such as 40 or 50 users (or even just
    skip this bit of code temporarily). Then, complete the chapter's code and get
    a feel for how the results work. After that, reset the number of users in this
    loop to 150, leave the code to run for a few hours, and then come back and rerun
    the later code.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想要将这些值设置得更低，比如40或50个用户（或者甚至暂时跳过这段代码）。然后，完成本章的代码，感受一下结果是如何工作的。之后，将此循环中的用户数量重置为150，让代码运行几小时，然后回来重新运行后面的代码。
- en: 'Given that collecting that data probably took nearly 3 hours, it would be a
    good idea to save it in case we have to turn our computer off. Using the `json`
    library, we can easily save our friends dictionary to a file:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 由于收集这些数据可能花费了近3个小时，因此将其保存下来是个好主意，以防我们不得不关闭电脑。使用`json`库，我们可以轻松地将我们的朋友字典保存到文件中：
- en: '[PRE17]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If you need to load the file, use the `json.load` function:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要加载文件，请使用`json.load`函数：
- en: '[PRE18]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Creating a graph
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个图
- en: At this point in our experiment, we have a list of users and their friends.
    This gives us a graph where some users are friends of other users (although not
    necessarily the other way around).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验的这个阶段，我们有一个用户及其联系人的列表。这给我们一个图，其中一些用户是其他用户的联系人（尽管不一定反过来）。
- en: 'A **graph** is a set of nodes and edges. Nodes are usually objects of interest
    - in this case, they are our users. The edges in this initial graph indicate that
    user A is a friend of user B. We call this a **directed graph**, as the order
    of the nodes matters. Just because user A is a friend of user B, that doesn''t
    imply that user B is a friend of user A. The example network below shows this,
    along with a user C who is friends of user B, and is friended in turn by user
    B as well:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**图**是一组节点和边。节点通常是感兴趣的物体——在这种情况下，它们是我们的用户。这个初始图中的边表示用户A是用户B的朋友。我们称之为**有向图**，因为节点的顺序很重要。仅仅因为用户A是用户B的朋友，并不意味着用户B也是用户A的朋友。下面的示例网络展示了这一点，以及一个与用户B是朋友并且反过来也被用户B添加为朋友的用户C：'
- en: '![](img/B06162_07_01.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B06162_07_01.png)'
- en: In python, one of the best libraries for working with graphs, including creating,
    visualising and computing, is called **NetworkX**.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，用于处理图（包括创建、可视化和计算）的最佳库之一是**NetworkX**。
- en: 'Once again, you can use Anaconda to install NetworkX: `conda install networkx`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，你可以使用Anaconda安装NetworkX：`conda install networkx`
- en: 'First, we create a directed graph using NetworkX. By convention, when importing
    NetworkX, we use the abbreviation nx (although this isn''t necessary). The code
    is as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用NetworkX创建一个有向图。按照惯例，在导入NetworkX时，我们使用缩写nx（尽管这并不是必需的）。代码如下：
- en: '[PRE19]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We will only visualize our key users, not all of the friends (as there are
    many thousands of these and it is hard to visualize). We get our main users and
    then add them to our graph as nodes:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将只可视化我们的关键用户，而不是所有朋友（因为有很多这样的朋友，而且很难可视化）。我们获取主要用户，然后将它们作为节点添加到我们的图中：
- en: '[PRE20]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Next we set up the edges. We create an edge from a user to another user if the
    second user is a friend of the first user. To do this, we iterate through all
    of the friends of a given user. We ensure that the friend is one of our main users
    (as we currently aren't interested in visualizing the other users), and add the
    edge if they are.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们设置边。如果第二个用户是第一个用户的朋友，我们就从用户到另一个用户创建一条边。为此，我们遍历给定用户的全部朋友。我们确保这个朋友是我们主要用户之一（因为我们目前不感兴趣可视化其他用户），如果他们是，就添加这条边。
- en: '[PRE21]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can now visualize the network using NetworkX''s draw function, which uses
    matplotlib. To get the image in our notebook, we use the inline function on matplotlib
    and then call the draw function. The code is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用NetworkX的draw函数来可视化网络，该函数使用matplotlib。为了在我们的笔记本中获得图像，我们使用matplotlib的inline函数，然后调用draw函数。代码如下：
- en: '[PRE22]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The results are a bit hard to make sense of; they show just the ring of nodes,
    and its hard to work anything specific out about the dataset. Not a good image
    at all:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 结果有点难以理解；它们只显示了节点环，很难从数据集中得出具体的东西。根本不是一张好图：
- en: '![](img/B06162_07_02.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_07_02.png)'
- en: 'We can make the graph a bit better by using pyplot to handle the creation of
    the figure, which is used by NetworkX to do graph drawing. Import `pyplot,` create
    a larger figure, and then call NetworkX''s `draw` function to increase the size
    of the image:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用pyplot来处理图形的创建，这是NetworkX进行图形绘制所使用的。导入`pyplot`，创建一个更大的图形，然后调用NetworkX的`draw`函数来增加图像的大小：
- en: '[PRE23]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'By making the graph bigger and adding transparency, an outline of how the graph
    appears can now be seen:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通过放大图并增加透明度，现在可以清楚地看到图的轮廓：
- en: '![](img/B06162_07_03.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_07_03.png)'
- en: In my graph, there was a major group of users all highly connected to each other,
    and most other users didn't have many connections at all. As you can see, it is
    very well connected in the center!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的图中，有一个主要用户群，他们之间高度连接，而大多数其他用户几乎没有连接。正如你所见，它们在中心非常连接！
- en: This is actually a property of our method of choosing new users—we choose those
    who are already well linked in our graph, so it is likely they will just make
    this group larger. For social networks, generally the number of connections a
    user has follows a power law. A small percentage of users have many connections,
    and others have only a few. The shape of the graph is often described as having
    a *long tail*.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是我们选择新用户的方法的一个特性——我们选择那些在我们图中已经很好地连接的用户，因此他们很可能只是使这个群体更大。对于社交网络，一般来说，用户拥有的连接数遵循幂律。一小部分用户有很多连接，而其他人只有几个。图的形状通常描述为具有*长尾*。
- en: By zooming into parts of the graph you can start seeing structure. Visualizing
    and analyzing graphs like this is hard - we will see some tools for making this
    process easier in the next section.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 通过放大图的某些部分，你可以开始看到结构。可视化和分析这样的图很困难 - 我们将在下一节中看到一些使这个过程更容易的工具。
- en: Creating a similarity graph
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建相似性图
- en: The final step to this experiment is to recommend users, based on how many friends
    they share. As mentioned previously, our logic is that, if two users have the
    same friends, they are highly similar. We could recommend one user to the other
    on this basis.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 实验的最终步骤是根据用户分享的朋友数量来推荐用户。如前所述，我们的逻辑是，如果两个用户有相同的朋友，他们非常相似。基于这一点，我们可以向一个用户推荐另一个用户。
- en: We are therefore going to take our existing graph (which has edges relating
    to friendship) and create a new graph from its information. The nodes are still
    users, but the edges are going to be **weighted edges**. A weighted edge is simply
    an edge with a weight property. The logic is that a higher weight indicates more
    similarity between the two nodes than a lower weight. This is context-dependent.
    If the weights represent distance, then the lower weights indicate more similarity.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将使用现有的图（其中包含与友谊相关的边）并从其信息中创建一个新的图。节点仍然是用户，但边将是**加权边**。加权边只是一个具有权重属性的边。逻辑是，较高的权重表示两个节点之间的相似性高于较低的权重。这取决于上下文。如果权重代表距离，则较低的权重表示更多的相似性。
- en: For our application, the weight will be the similarity of the two users connected
    by that edge (based on the number of friends they share). This graph also has
    the property that it is not directed. This is due to our similarity computation,
    where the similarity of user A to user B is the same as the similarity of user
    B to user A.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的应用，权重将是连接该边的两个用户的相似度（基于他们共享的朋友数量）。这个图也具有不定向的性质。这归因于我们的相似度计算，其中用户A对用户B的相似度与用户B对用户A的相似度相同。
- en: Other similarity measurements are directed. An example is ratio of similar users,
    which is the number of friends in common divided by the user's total number of
    friends. In this case, you would need a directed graph.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 其他相似度度量是定向的。一个例子是相似用户的比率，即共同朋友数量除以用户的总朋友数量。在这种情况下，你需要一个有向图。
- en: There are many ways to compute the similarity between two lists like this. For
    example, we could compute the number of friends the two have in common. However,
    this measure is always going to be higher for people with more friends. Instead,
    we can normalize it by dividing by the total number of distinct friends the two
    have. This is called the **Jaccard Similarity**.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 计算两个类似列表之间的相似性有很多种方法。例如，我们可以计算两人共同拥有的朋友数量。然而，这个度量对于拥有更多朋友的人来说总是会更高。相反，我们可以通过除以两人拥有的不同朋友的总量来归一化它。这被称为**Jaccard相似度**。
- en: The Jaccard Similarity, always between 0 and 1, represents the percentage overlap
    of the two. As we saw in [Chapter 2](lrn-dtmn-py-2e_ch07.html), *Classifying with
    scikit-learn Estimators*, normalization is an important part of data mining exercises
    and generally a good thing to do. There are fringe cases where you wouldn't normalize
    data, but by default normalize first.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Jaccard相似度，总是在0到1之间，表示两个之间的重叠百分比。正如我们在[第2章](lrn-dtmn-py-2e_ch07.html)中看到的，*使用scikit-learn估计器进行分类*，归一化是数据挖掘练习的重要部分，通常是一个好习惯。有些边缘情况你可能不会对数据进行归一化，但默认情况下首先进行归一化。
- en: 'To compute the Jaccard similarity, we divide the intersection of the two sets
    of followers by the union of the two. These are set operations and we have lists,
    so we will need to convert the friends lists to sets first. The code is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算Jaccard相似度，我们将两个粉丝集合的交集除以它们的并集。这些是集合操作，而我们手头有列表，因此我们需要先将朋友列表转换为集合。代码如下：
- en: '[PRE24]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We then create a function that computes the similarity of two sets of friends
    lists. The code is as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建一个函数来计算两个朋友列表集合的相似度。代码如下：
- en: '[PRE25]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We add 1e-6 (or 0.000001) to the similarity above to ensure we never get a division
    by zero error, in cases where neither user has any friends. It is small enough
    to not really affect our results, but big enough to be more than zero.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在相似度上添加1e-6（或0.000001）以确保我们永远不会遇到除以零的错误，在两个用户都没有朋友的情况下。它足够小，不会真正影响我们的结果，但足够大，以超过零。
- en: 'From here, we can create our weighted graph of the similarity between users.
    We will use this quite a lot in the rest of the chapter, so we will create a function
    to perform this action. Let''s take a look at the threshold parameter:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以创建用户之间的加权相似度图。在接下来的章节中，我们将大量使用这个图，因此我们将创建一个函数来执行此操作。让我们看看阈值参数：
- en: '[PRE26]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can now create a graph by calling this function. We start with no threshold,
    which means all links are created. The code is as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过调用此函数来创建一个图。我们从一个没有阈值的开始，这意味着所有链接都被创建。代码如下：
- en: '[PRE27]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The result is a very strongly connected graph—all nodes have edges, although
    many of those will have a weight of 0\. We will see the weight of the edges by
    drawing the graph with line widths relative to the weight of the edge—thicker
    lines indicate higher weights.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个非常紧密连接的图——所有节点都有边，尽管其中许多边的权重为0。我们将通过绘制具有与边权重成比例的线宽的图来看到边的权重——较粗的线表示较高的权重。
- en: 'Due to the number of nodes, it makes sense to make the figure larger to get
    a clearer sense of the connections:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 由于节点数量较多，将图放大以获得更清晰的连接感是有意义的：
- en: '[PRE28]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We are going to draw the edges with a weight, so we need to draw the nodes first.
    NetworkX uses layouts to determine where to put the nodes and edges, based on
    certain criteria. Visualizing networks is a very difficult problem, especially
    as the number of nodes grows. Various techniques exist for visualizing networks,
    but the degree to which they work depends heavily on your dataset, personal preferences,
    and the aim of the visualization. I found that the spring_layout worked quite
    well, but other options such as circular_layout (which is a good default if nothing
    else works), random_layout, shell_layout, and spectral_layout also exist and have
    uses where the others may fail.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将带有权重的边绘制出来，因此需要先绘制节点。NetworkX使用布局来确定节点和边的位置，基于某些标准。可视化网络是一个非常困难的问题，尤其是随着节点数量的增加。存在各种用于可视化网络的技巧，但它们的工作程度在很大程度上取决于你的数据集、个人偏好和可视化的目标。我发现`spring_layout`工作得相当好，但其他选项，如`circular_layout`（如果没有其他选项可用，这是一个很好的默认选项）、`random_layout`、`shell_layout`和`spectral_layout`也存在，并且在这些其他选项失败的地方有它们的应用。
- en: Visit [http://networkx.lanl.gov/reference/drawing.html](http://networkx.lanl.gov/reference/drawing.html) 
    for more details on layouts in NetworkX. Although it adds some complexity, the
    `draw_graphviz` option works quite well and is worth investigating for better
    visualizations. It is well worth considering in real-world uses.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 访问[http://networkx.lanl.gov/reference/drawing.html](http://networkx.lanl.gov/reference/drawing.html)获取NetworkX中布局的更多详细信息。尽管它增加了一些复杂性，但`draw_graphviz`选项工作得相当好，值得调查以获得更好的可视化效果。在现实世界的应用中，这非常值得考虑。
- en: 'Let''s use `spring_layout` for visualization:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`spring_layout`进行可视化：
- en: '[PRE29]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Using our `pos` layout, we can then position the nodes:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的`pos`布局，我们可以然后定位节点：
- en: '[PRE30]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Next, we draw the edges. To get the weights, we iterate over the edges in the
    graph (in a specific order) and collect the weights:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们绘制边。为了获取权重，我们遍历图中的边（按特定顺序）并收集权重：
- en: '[PRE31]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We then draw the edges:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来绘制边：
- en: '[PRE32]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The result will depend on your data, but it will typically show a graph with
    a large set of nodes connected quite strongly and a few nodes poorly connected
    to the rest of the network.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将取决于你的数据，但通常将显示一个具有大量节点且连接相当紧密的图，以及一些与其他网络连接较差的节点。
- en: '![](img/B06162_07_04.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B06162_07_04.png)'
- en: The difference in this graph compared to the previous graph is that the edges
    determine the similarity between the nodes based on our similarity metric and
    not on whether one is a friend of another (although there are similarities between
    the two!). We can now start extracting information from this graph in order to
    make our recommendations.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一个图相比，这个图的不同之处在于，边是根据我们的相似性度量来决定节点之间的相似性，而不是根据一个人是否是另一个人的朋友（尽管两者之间有相似之处！）。现在我们可以从这个图中提取信息，以便做出我们的推荐。
- en: Finding subgraphs
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找子图
- en: From our similarity function, we could simply rank the results for each user,
    returning the most similar user as a recommendation - as we did with our product
    recommendations. This works, and is indeed one way to perform this type of analysis.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的相似性函数中，我们可以简单地为每个用户对结果进行排名，返回最相似的用户作为推荐——就像我们处理产品推荐那样。这行得通，确实是执行此类分析的一种方式。
- en: Instead, we might want to find clusters of users that are all similar to each
    other. We could advise these users to start a group, create advertising targeting
    this segment, or even just use those clusters to do the recommendations themselves.
    Finding these clusters of similar users is a task called **cluster analysis**.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可能希望找到所有用户都彼此相似的用户群。我们可以建议这些用户开始组建一个群组，为这个细分市场创建广告，或者甚至只是使用这些集群本身来进行推荐。找到这些相似用户群的任务被称为**聚类分析**。
- en: Cluster analysis is a difficult task, with complications that classification
    tasks do not typically have. For example, evaluating classification results is
    relatively easy - we compare our results to the ground truth (from our training
    set) and see what percentage we got right. With cluster analysis, though, there
    isn't typically a ground truth. Evaluation usually comes down to seeing if the
    clusters make sense, based on some preconceived notion we have of what the cluster
    should look like.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类分析是一项困难的任务，具有分类任务通常不具备的复杂性。例如，评估分类结果相对容易——我们将我们的结果与真实情况（来自我们的训练集）进行比较，并查看我们正确了多少百分比。然而，在聚类分析中，通常没有真实情况。评估通常归结为根据我们对聚类应该看起来怎样的先入为主的观念，来判断聚类是否合理。
- en: Another complication with cluster analysis is that the model can't be trained
    against the expected result to learn—it has to use some approximation based on
    a mathematical model of a cluster, not what the user is hoping to achieve from
    the analysis.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类分析另一个复杂之处在于，模型不能针对预期结果进行训练以学习——它必须基于聚类数学模型进行一些近似，而不是用户希望通过分析实现的目标。
- en: Due to these issues, cluster analysis is more of an exploratory tool, rather
    than a prediction tool. Some research and applications use clustering for analysis,
    but its usefulness as a predictive model is dependent on an analyst selecting
    parameters and finding graphs that *look right*, rather than a specific evaluation
    metric.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些问题，聚类分析更倾向于一种探索性工具，而不是预测工具。一些研究和应用使用聚类进行数据分析，但其作为预测模型的有用性取决于分析师选择参数并找到看起来“正确”的图，而不是特定的评估指标。
- en: Connected components
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接分量
- en: One of the simplest methods for clustering is to find the **connected components**
    in a graph. A connected component is a set of nodes in a graph that are connected
    via edges. Not all nodes need to be connected to each other to be a connected
    component. However, for two nodes to be in the same connected component, there
    needs to be a way to *travel* from one node to another in that connected component
    by moving along edges.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类最简单的方法之一是在图中找到**连接分量**。连接分量是图中通过边连接的节点集合。并非所有节点都需要相互连接才能成为连接分量。然而，为了使两个节点处于同一个连接分量中，必须存在一种方法，可以通过沿着边从节点移动到另一个节点。
- en: Connected components do not consider edge weights when being computed; they
    only check for the presence of an edge. For that reason, the code that follows
    will remove any edge with a low weight.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 连接分量在计算时不会考虑边权重；它们只检查边的存在。因此，接下来的代码将移除任何权重低的边。
- en: 'NetworkX has a function for computing connected components that we can call
    on our graph. First, we create a new graph using our `create_graph` function,
    but this time we pass a threshold of 0.1 to get only those edges that have a weight
    of at least 0.1, indicative of 10% of followers in common between the two node
    users:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: NetworkX有一个用于计算连接分量的函数，我们可以调用我们的图。首先，我们使用我们的`create_graph`函数创建一个新的图，但这次我们传递一个阈值为0.1，以仅获取权重至少为0.1的边，这表明两个节点用户之间有10%的共同关注者：
- en: '[PRE33]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We then use NetworkX to find the connected components in the graph:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用NetworkX在图中找到连接分量：
- en: '[PRE34]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To get a sense of the sizes of the graph, we can iterate over the groups and
    print out some basic information:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解图的大小，我们可以遍历组并打印一些基本信息：
- en: '[PRE35]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The results will tell you how big each of the connected components is. My results
    had one large subgraph of 62 users and lots of little ones with a dozen or fewer
    users.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将告诉你每个连接分量有多大。我的结果有一个包含62个用户的大子图和许多小子图，每个子图有十几个或更少的用户。
- en: 'We can alter the **threshold** to alter the connected components. This is because
    a higher threshold has fewer edges connecting nodes, and therefore will have smaller
    connected components and more of them. We can see this by running the preceding
    code with a higher threshold:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以改变**阈值**来改变连接分量。这是因为更高的阈值连接节点的边更少，因此将具有更小的连接分量和更多的连接分量。我们可以通过运行前面的代码并使用更高的阈值来看到这一点：
- en: '[PRE36]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The preceding code gives us much smaller subgraphs and more of them. My largest
    cluster was broken into at least three parts and none of the clusters had more
    than 10 users. An example cluster is shown in the following figure, and the connections
    within this cluster are also shown. Note that, as it is a connected component,
    there were no edges from nodes in this component to other nodes in the graph (at
    least, with the threshold set at 0.25).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码给出了更小的子图和更多的子图。我最大的簇被分割成至少三个部分，而且没有任何一个簇的用户数量超过10个。以下图显示了簇的一个示例，以及该簇内的连接。请注意，由于这是一个连通组件，该组件中的节点到图中其他节点的边不存在（至少，当阈值设置为0.25时）。
- en: We can draw the entire graph, showing each connected component in a different
    color. As these connected components are not connected to each other, it actually
    makes little sense to plot these on a single graph. This is because the positioning
    of the nodes and components is arbitrary, and it can confuse the visualization.
    Instead, we can plot each separately on a separate subfigure.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以绘制整个图，用不同的颜色显示每个连通组件。由于这些连通组件彼此不相连，将它们绘制在单个图上实际上没有太多意义。这是因为节点和组件的位置是任意的，可能会使可视化变得混乱。相反，我们可以将每个组件分别绘制在单独的子图中。
- en: 'In a new cell, obtain the connected components and also the count of the connected
    components:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新的单元中，获取连通组件以及连通组件的数量：
- en: '[PRE37]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '`sub_graphs` is a generator, not a list of the connected components. For this
    reason, use `nx.number_connected_components` to find out how many connected components
    there are; don''t use `len`, as it doesn''t work due to the way that NetworkX
    stores this information. This is why we need to recompute the connected components
    here.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`sub_graphs`是一个生成器，而不是连通组件的列表。因此，使用`nx.number_connected_components`来找出有多少连通组件；不要使用`len`，因为它由于NetworkX存储信息的方式而不起作用。这就是为什么我们需要在这里重新计算连通组件。'
- en: Create a new pyplot figure and give enough room to show all of our connected
    components. For this reason, we allow the graph to increase in size with the number
    of connected components.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的pyplot图，并留出足够的空间来显示所有的连通组件。因此，我们允许图的大小随着连通组件数量的增加而增加。
- en: 'Next, iterate over each connected component and add a subplot for each. The
    parameters to add_subplot are the number of rows of subplots, the number of columns,
    and the index of the subplot we are interested in. My visualization uses three
    columns, but you can try other values instead of three (just remember to change
    both values):'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，遍历每个连通组件，并为每个组件添加一个子图。`add_subplot`的参数是子图行的数量、列的数量以及我们感兴趣的子图的索引。我的可视化使用三列，但你可以尝试其他值而不是三（只是记得要更改两个值）：
- en: '[PRE38]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The results visualize each connected component, giving us a sense of the number
    of nodes in each and also how connected they are.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可视化每个连通组件，让我们对每个组件中的节点数量以及它们的连接程度有一个概念。
- en: '![](img/B06162_07_05.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B06162_07_05.png)'
- en: 'If you are not seeing anything on your graphs, try rerunning the line:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有在你的图上看到任何东西，请尝试重新运行以下行：
- en: '`sub_graphs = nx.connected_component_subgraphs(G)`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`sub_graphs = nx.connected_component_subgraphs(G)`'
- en: The `sub_graphs` object is a generator and is "consumed" after being used.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`sub_graphs`对象是一个生成器，并且在被使用后会被“消耗”。'
- en: Optimizing criteria
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化标准
- en: Our algorithm for finding these connected components relies on the **threshold**
    parameter, which dictates whether edges are added to the graph or not. In turn,
    this directly dictates how many connected components we discover and how big they
    are. From here, we probably want to settle on some notion of which is the *best*
    threshold to use. This is a very subjective problem, and there is no definitive
    answer. This is a major problem with any cluster analysis task.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们找到这些连通组件的算法依赖于**阈值**参数，该参数决定了是否将边添加到图中。反过来，这直接决定了我们发现的连通组件的数量和大小。从这里，我们可能想要确定一个关于哪个是*最佳*阈值的概念。这是一个非常主观的问题，没有明确的答案。这是任何聚类分析任务的一个主要问题。
- en: 'We can, however, determine what we think a good solution should look like and
    define a metric based on that idea. As a general rule, we usually want a solution
    where:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以确定我们认为一个好的解决方案应该是什么样子，并基于这个想法定义一个度量标准。作为一个一般规则，我们通常希望解决方案是这样的：
- en: Samples in the same cluster (connected components) are highly *similar* to each
    other
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一簇（连通组件）中的样本彼此之间高度*相似*。
- en: Samples in different clusters are highly *dissimilar* to each other
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同簇中的样本彼此之间高度*不同*。
- en: 'The **Silhouette Coefficient** is a metric that quantifies these points. Given
    a single sample, we define the Silhouette Coefficient as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**轮廓系数**是一个量化这些点的度量标准。给定一个单个样本，我们定义轮廓系数如下：'
- en: '![](img/B06162_07_06.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_07_06.png)'
- en: Where *a* is the **intra-cluster distance** or the average distance to the other
    samples in the sample's cluster, and <q>b</q> is the **inter-cluster distance**
    or the average distance to the other samples in the *next-nearest* cluster.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *a* 是 **簇内距离** 或样本簇中其他样本的平均距离，而 <q>b</q> 是 **簇间距离** 或到下一个最近邻簇中其他样本的平均距离。
- en: To compute the overall Silhouette Coefficient, we take the mean of the Silhouette
    Coefficients for each sample. A clustering that provides a Silhouette Coefficient
    close to the maximum of 1 has clusters that have samples all similar to each other,
    and these clusters are very spread apart. Values near 0 indicate that the clusters
    all overlap and there is little distinction between clusters. Values close to
    the minimum of -1 indicate that samples are probably in the wrong cluster, that
    is, they would be better off in other clusters.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算整体轮廓系数，我们取每个样本的轮廓系数的平均值。提供接近最大值1的轮廓系数的聚类具有所有样本都相似的簇，并且这些簇分布得很广。接近0的值表明簇全部重叠，簇之间几乎没有区别。接近最小值-1的值表明样本可能位于错误的簇中，也就是说，它们在其他簇中会更好。
- en: Using this metric, we want to find a solution (that is, a value for the threshold)
    that maximizes the Silhouette Coefficient by altering the threshold parameter.
    To do that, we create a function that takes the threshold as a parameter and computes
    the Silhouette Coefficient.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个度量标准，我们希望找到一个解决方案（即阈值的一个值），通过改变阈值参数来最大化轮廓系数。为此，我们创建了一个函数，该函数将阈值作为参数并计算轮廓系数。
- en: We then pass this into the **optimize** module of SciPy, which contains the
    `minimize` function that is used to find the minimum value of a function by altering
    one of the parameters. While we are interested in maximizing the Silhouette Coefficient,
    SciPy doesn't have a maximize function. Instead, we minimize the inverse of the
    Silhouette (which is basically the same thing).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将这个函数传递给SciPy的**优化**模块，其中包含用于通过改变参数来找到函数最小值的`minimize`函数。虽然我们感兴趣的是最大化轮廓系数，但SciPy没有最大化函数。相反，我们最小化轮廓系数的倒数（这基本上是同一件事）。
- en: The scikit-learn library has a function for computing the Silhouette Coefficient,
    `sklearn.metrics.silhouette_score`; however, it doesn't fix the function format
    that is required by the SciPy minimize function. The minimize function requires
    the variable parameter to be first (in our case, the threshold value), and any
    arguments to be after it. In our case, we need to pass the friends dictionary
    as an argument in order to compute the graph.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn库有一个用于计算轮廓系数的函数，`sklearn.metrics.silhouette_score`；然而，它没有修复SciPy最小化函数所需的函数格式。最小化函数需要将变量参数放在第一位（在我们的情况下，是阈值值），并将任何参数放在其后。在我们的情况下，我们需要将好友字典作为参数传递，以便计算图。
- en: The Silhouette Coefficient is not defined unless there are at least two nodes
    (in order for distance to be computed at all). In this case, we define the problem
    scope as invalid. There are a few ways to handle this, but the easiest is to return
    a very poor score. In our case, the minimum value that the Silhouette Coefficient
    can take is -1, and we will return -99 to indicate an invalid problem. Any valid
    solution will score higher than this.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 轮廓系数在至少有两个节点（为了计算距离）的情况下才定义。在这种情况下，我们将问题范围定义为无效。有几种处理方法，但最简单的是返回一个非常差的分数。在我们的情况下，轮廓系数可以取的最小值是-1，我们将返回-99来表示无效问题。任何有效解决方案的得分都将高于这个值。
- en: The function below incorporates all of these issues giving us a function that
    takes a threshold value and a friends list, and computes the Silhouette Coefficient.
    It does this by building a matrix from the graph using NetworkX's `to_scipy_sparse_matrix`
    function.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的函数结合了所有这些问题，它提供了一个接受阈值值和好友列表作为参数的函数，并计算轮廓系数。它是通过使用NetworkX的`to_scipy_sparse_matrix`函数从图中构建矩阵来实现的。
- en: '[PRE39]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: For evaluating sparse datasets, I recommend that you look into V-Measure or
    Adjusted Mutual Information. These are both implemented in scikit-learn, but they
    have very different parameters for performing their evaluation.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于评估稀疏数据集，我建议您查看V-Measure或调整互信息。这两个都在scikit-learn中实现，但它们在执行评估时具有非常不同的参数。
- en: The Silhouette Coefficient implementation in scikit-learn, at the time of writing,
    doesn't support sparse matrices. For this reason, we need to call the `todense`
    function. Typically, this is a bad idea--sparse matrices are usually used because
    the data typically shouldn't be in a dense format. In this case, it will be fine
    because our dataset is relatively small; however, don't try this for larger datasets.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写本文时，scikit-learn中的轮廓系数实现不支持稀疏矩阵。因此，我们需要调用`todense`函数。通常，这不是一个好主意——稀疏矩阵通常用于数据通常不应该以密集格式存在的情况。在这种情况下，这将是可行的，因为我们的数据集相对较小；然而，不要尝试在更大的数据集上这样做。
- en: We have two forms of inversion happening here. The first is taking the inverse
    of the similarity to compute a distance function; this is needed, as the Silhouette
    Coefficient only accepts distances. The second is the inverting of the Silhouette
    Coefficient score so that we can minimize with SciPy's optimize module.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生了两种形式的逆运算。第一种是取相似度的逆来计算距离函数；这是必需的，因为轮廓系数只接受距离。第二种是将轮廓系数分数取逆，这样我们就可以使用SciPy的优化模块进行最小化。
- en: Finally, we create the function that we will minimize. This function is the
    inverse of the `compute_silhouette` function, because we want lower scores to
    be better. We could do this in our `compute_silhouette` function--I've separated
    them here to clarify the different steps involved.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们创建我们将要最小化的函数。这个函数是`compute_silhouette`函数的逆，因为我们希望较低的分数更好。我们可以在我们的`compute_silhouette`函数中这样做——我已经在这里将它们分开，以阐明涉及的不同步骤。
- en: '[PRE40]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: This function creates a new function from an original function. When the new
    function is called, all of the same arguments and keywords are passed onto the
    original function and the return value is returned, except that this returned
    value is negated before it is returned.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数从一个原始函数创建一个新的函数。当调用新函数时，所有相同的参数和关键字都会传递给原始函数，并返回返回值，只是在返回之前取了相反数。
- en: 'Now we can do our actual optimization. We call the minimize function on the
    inverted `compute_silhouette` function we defined:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进行实际的优化了。我们调用我们定义的逆`compute_silhouette`函数上的最小化函数：
- en: '[PRE41]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This function will take quite a while to run. Our graph creation function isn't
    that fast, nor is the function that computes the Silhouette Coefficient. Decreasing
    the `maxiter` parameter's value will result in fewer iterations being performed,
    but we run the risk of finding a suboptimal solution.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数运行起来会花费相当长的时间。我们的图形创建函数并不快，计算轮廓系数的函数也不快。减小`maxiter`参数的值会导致迭代次数减少，但我们面临找到次优解的风险。
- en: Running this function, I got a threshold of 0.135 that returns 10 components.
    The score returned by the minimize function was -0.192\. However, we must remember
    that we negated this value. This means our score was actually 0.192\. The value
    is positive, which indicates that the clusters tend to be better separated than
    not (a good thing). We could run other models and check whether it results in
    a better score, which means that the clusters are better separated.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这个函数，我得到了一个阈值为0.135，返回了10个组件。最小化函数返回的分数是-0.192。然而，我们必须记住我们取了这个值的相反数。这意味着我们的分数实际上是0.192。这个值是正的，这表明簇倾向于比不分离得更好（这是好事）。我们可以运行其他模型并检查它是否会产生更好的分数，这意味着簇被更好地分离了。
- en: We could use this result to recommend users—if a user is in a specific connected
    component, then we can recommend other users in that same component. This recommendation
    follows our use of the Jaccard Similarity to find good connections between users,
    our use of connected components to split them up into clusters, and our use of
    the optimization technique to find the best model in this setting.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个结果来推荐用户——如果一个用户在特定的连通组件中，那么我们可以推荐该组件中的其他用户。这种推荐遵循我们使用Jaccard相似度来找到用户之间良好连接的做法，我们使用连通组件将它们分成簇，以及我们使用优化技术来找到在这种设置下的最佳模型。
- en: However, a large number of users may not be connected at all, so we will use
    a different algorithm to find clusters for them. We will see other methods for
    cluster analysis in [Chapter 10](lrn-dtmn-py-2e_ch10.html)*, Clustering News Articles*.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大量的用户可能根本不连通，因此我们将使用不同的算法为他们找到簇。我们将在第10章[聚类新闻文章](lrn-dtmn-py-2e_ch10.html)*中看到其他聚类分析方法。
- en: Summary
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked at graphs from social networks and how to do cluster
    analysis on them. We also looked at saving and loading models from scikit-learn
    by using the classification model we created in [Chapter 6](lrn-dtmn-py-2e_ch06.html)<q>,</q>
    *Social Media Insight Using Naive Bayes*<q>.</q>
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了社交网络中的图以及如何对它们进行聚类分析。我们还探讨了如何使用我们在[第6章](lrn-dtmn-py-2e_ch06.html)中创建的分类模型通过scikit-learn来保存和加载模型，*《使用朴素贝叶斯进行社交媒体洞察》*。
- en: We created a graph of friends from the social network Twitter. We then examined
    how similar two users were, based on their friends. Users with more friends in
    common were considered more similar, although we normalize this by considering
    the overall number of friends they have. This is a commonly used way to infer
    knowledge (such as age or general topic of discussion) based on similar users.
    We can use this logic for recommending users to others—if they follow user X and
    user Y is similar to user X, they will probably like user Y. This is, in many
    ways, similar to our transaction-led similarity of previous chapters.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个来自社交网络Twitter的朋友关系图。然后，我们根据他们的朋友来考察两个用户之间的相似性。拥有更多共同朋友的用户被认为更相似，尽管我们通过考虑他们拥有的总朋友数来对此进行归一化。这是一种常用的方法，可以根据相似用户推断知识（如年龄或一般讨论主题）。我们可以使用这种逻辑来向其他人推荐用户——如果他们关注用户X，而用户Y与用户X相似，他们可能会喜欢用户Y。这在许多方面与之前章节中提到的基于交易的相似性相似。
- en: The aim of this analysis was to recommend users, and our use of cluster analysis
    allowed us to find clusters of similar users. To do this, we found connected components
    on a weighted graph we created based on this similarity metric. We used the NetworkX
    package for creating graphs, using our graphs, and finding these connected components.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 本分析的目标是推荐用户，而我们使用聚类分析使我们能够找到相似用户的聚类。为此，我们在基于此相似性度量创建的加权图中找到了连通组件。我们使用NetworkX包来创建图、使用我们的图以及找到这些连通组件。
- en: We then used the Silhouette Coefficient, which is a metric that evaluates how
    good a clustering solution is. Higher scores indicate a better clustering, according
    to the concepts of intracluster and intercluster distance. SciPy's optimize module
    was used to find the solution that maximizes this value.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用了轮廓系数，这是一个评估聚类解决方案好坏的指标。根据簇内和簇间距离的概念，更高的分数表示更好的聚类。SciPy的优化模块被用来找到最大化这个值的解。
- en: In this chapter, we saw a few opposites in action. Similarity is a measure between
    two objects, where higher values indicate more similarity between those objects.
    In contrast, distance is a measure where lower values indicate more similarity.
    Another contrast we saw was a loss function, where lower scores are considered
    better (that is, we lost less). Its opposite is the score function, where higher
    scores are considered better.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了一些对立的概念在行动中的表现。相似性是两个对象之间的度量，其中更高的值表示这些对象之间有更多的相似性。相反，距离是一个度量，其中较低的值表示更多的相似性。我们看到的另一个对比是损失函数，其中较低的分数被认为是更好的（也就是说，我们损失更少）。它的对立面是得分函数，其中较高的分数被认为是更好的。
- en: To extend the work in this chapter, examine the V-measure and Adjusted Mutual
    Information scores in scikit-learn. These replace the Silhouette Coefficient used
    in this chapter. Are the clusters that result from maximizing these metrics better
    than the Silhouette Coefficient's clusters? Further, how can you tell? Often,
    the problem with cluster analysis is that you cannot objectively tell and may
    use human intervention to choose the best option.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 为了扩展本章的工作，检查scikit-learn中的V-measure和调整互信息分数。这些取代了本章中使用的轮廓系数。最大化这些指标得到的聚类是否比轮廓系数的聚类更好？进一步地，如何判断？通常，聚类分析的问题在于你无法客观地判断，可能需要人工干预来选择最佳选项。
- en: In the next chapter, we will see how to extract features from another new type
    of data--images. We will discuss how to use neural networks to identify numbers
    in images and develop a program to automatically beat CAPTCHA images.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到如何从另一种新型数据——图像中提取特征。我们将讨论如何使用神经网络来识别图像中的数字，并开发一个程序来自动击败验证码图像。
