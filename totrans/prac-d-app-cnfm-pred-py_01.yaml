- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introducing Conformal Prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is about conformal prediction, a modern framework for uncertainty
    quantification that is becoming increasingly popular in industry and academia.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning and AI applications are everywhere. In the realm of machine
    learning, prediction is a fundamental task. Given a training dataset, we train
    a machine learning model to make predictions on new data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1 – Machine learning prediction model](img/B19925_01_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 – Machine learning prediction model
  prefs: []
  type: TYPE_NORMAL
- en: However, in many real-world applications, the predictions made by statistical,
    machine learning, and deep learning models are often incorrect or unreliable because
    of various factors, such as insufficient or incomplete data, issues arising during
    the modeling process, or simply because of the randomness and complexities of
    the underlying problem.
  prefs: []
  type: TYPE_NORMAL
- en: Predictions made by machine learning models often come without the uncertainty
    quantification required for confident and reliable decision-making. This is where
    conformal prediction comes in. By providing a clear measure of the reliability
    of its predictions, conformal prediction enhances the trustworthiness and explainability
    of machine learning models, making them more transparent and user-friendly for
    decision-makers.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will introduce conformal prediction and explore how it can be applied
    in practical settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to conformal prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The origins of conformal prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How conformal prediction differs from traditional machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The p-value and its role in conformal prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The chapter will provide a practical understanding of conformal prediction and
    its applications. By the end of this chapter, you will be able to understand how
    conformal prediction can be applied to your own machine learning models to improve
    their reliability and interpretability.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This book uses Python. The code for this book is hosted on GitHub and can be
    found here: [https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction](https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction)
    You can run notebooks locally or upload them to Google Colab ([https://colab.research.google.com/](https://colab.research.google.com/)).'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to conformal prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will introduce conformal prediction and explain how it can
    be used to improve the reliability of predictions produced by statistical, machine
    learning, and deep learning models. We will provide an overview of the key ideas
    and concepts behind conformal prediction, including its underlying principles
    and benefits. By the end of this section, you will have a solid understanding
    of conformal prediction and why it is an important framework to know.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction is a powerful machine learning framework that provides
    valid confidence measures for individual predictions. This means that when you
    make a prediction using any model from the conformal prediction framework, you
    can also measure your confidence in that prediction.
  prefs: []
  type: TYPE_NORMAL
- en: This is incredibly useful in many practical applications where it is crucial
    to have reliable and interpretable predictions. For example, in medical diagnosis,
    conformal prediction can provide a confidence level that a tumor is malignant
    versus benign. This enables physicians to make more informed treatment decisions
    based on the prediction confidence. In finance, conformal prediction can provide
    prediction intervals estimating financial risk. This allows investors to quantify
    upside and downside risks.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, conformal prediction can determine a 95% chance a tumor is malignant,
    giving physicians high confidence in a cancer diagnosis. Or, it can predict an
    80% probability that a stock price will fall between $50 and $60 next month, providing
    an estimated trading range. Conformal prediction increases trust and is valuable
    in real-world applications such as medical diagnosis and financial forecasting
    by delivering quantifiable confidence in predictions.
  prefs: []
  type: TYPE_NORMAL
- en: The key benefit of conformal prediction is that it provides valid confidence
    measures for individual predictions. A conformal prediction model usually provides
    a prediction in the form of a prediction interval or prediction set with a specified
    confidence level, for example, 95%. In classification problems, conformal prediction
    can also calibrate class probabilities, enhancing confidence and informed decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: In conformal prediction, “coverage” denotes the likelihood that the predicted
    region – whether a set of potential outcomes in classification tasks or a prediction
    interval in regression tasks – accurately encompasses the true values. Essentially,
    if you choose a coverage of 95%, it means there’s a 95% chance that the true values
    fall within the provided prediction set or interval.
  prefs: []
  type: TYPE_NORMAL
- en: We call such prediction regions “valid.” The requirement for the validity of
    predictions is crucial to ensure that the model does not contain prediction bias
    and is especially important in consequential applications such as health, finance,
    and self-driving cars. Valid predictions are a prerequisite of trust in the machine
    learning model that has produced this prediction.
  prefs: []
  type: TYPE_NORMAL
- en: While there are alternative approaches to uncertainty quantification, such as
    Bayesian methods, Monte Carlo methods, and bootstrapping, to provide validity
    guarantees, such approaches require distribution-specific assumptions about the
    data – for example, an assumption that the data follows a normal distribution.
    However, the true underlying distribution of real-world data is generally unknown.
    Conversely, conformal prediction does not make distributional assumptions and
    can provide validity guarantees without making assumptions about the specifics
    of data distribution. This makes conformal prediction more broadly applicable
    to real data that may not satisfy common statistical assumptions such as normality,
    smoothness, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the need for distribution-specific assumptions limits the ability
    of methods such as Bayesian inference or bootstrapping to make formally rigorous
    statements about arbitrary real data sources. There is no guarantee that predictions
    from such methods will have the claimed confidence level or coverage across all
    data types, since the assumptions may not hold. This can create a mismatch between
    the confidence level communicated to users and the actual coverage achieved, leading
    to inaccurate decisions and misleading users about the reliability of model predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction sidesteps these issues by providing distribution-free finite
    sample validity guarantees without relying on hard-to-verify distributional assumptions
    about the data. This makes conformal prediction confidence estimates more trustworthy
    and robust for real-world applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conformal prediction has multiple benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Guaranteed coverage**: Conformal prediction guarantees the validity of prediction
    regions automatically. Any method from the conformal prediction framework guarantees
    the validity of prediction regions by mathematical design. In comparison, alternative
    methods output predictions that do not provide any validity guarantees. By way
    of an example, the popular NGBoost package does not produce valid prediction intervals
    (you can read more about it at the following link: [https://medium.com/@valeman/does-ngboost-work-evaluating-ngboost-against-critical-criteria-for-good-probabilistic-prediction-28c4871c1bab](https://medium.com/@valeman/does-ngboost-work-evaluating-ngboost-against-critical-criteria-for-good-probabilistic-prediction-28c4871c1bab)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distribution-free**: Conformal prediction is distribution-free and can be
    applied to any data distribution regardless of the properties of the distribution
    as long as the data is exchangeable. Exchangeability means that the order or index
    of the data points does not matter – shuffling or permuting the data points will
    not change the overall data distribution. For example, exchangeability assumes
    that observation 1, 2, 3 has the same distribution as observation 2, 3, 1 or 3,
    1, 2\. This is a weaker assumption than IID and is required to provide validity
    guarantees. Unlike many classical statistical models, conformal prediction does
    not make assumptions such as the data following a normal distribution. The data
    can have any distribution, even with irregularities such as fat tails. The only
    requirement is exchangeability. By relying only on exchangeability rather than
    strict distributional assumptions, conformal prediction provides finite sample
    guarantees on prediction coverage that are distribution-free and applicable to
    any data source.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model-agnostic**: Conformal prediction can be applied to any prediction model
    that produces point predictions in classification, regression, time series, computer
    vision, NLP, reinforcement learning, or other statistical, machine learning, and
    deep learning tasks. Conformal prediction has been successfully applied to many
    innovative model types, including recent innovations such as diffusion models
    and **large language models** (**LLMs**). Conformal prediction does not require
    the model to be statistical, machine learning, or deep learning. It could be any
    model of any type, for example, a business heuristic developed by domain experts.
    If you have a model to make point predictions, you can use conformal prediction
    as an uncertainty quantification layer on top of your point prediction model to
    obtain a well-calibrated, reliable, and safe probabilistic prediction model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-intrusive**: Conformal prediction stands out in its simplicity and efficiency.
    Rather than overhauling your existing point prediction model, it seamlessly integrates
    with it. For businesses with established models already in production, this is
    a game changer. And for data scientists, the process is even more exciting. Simply
    overlay your point prediction model with the uncertainty quantification layer
    provided by conformal prediction, and you’re equipped with a state-of-the-art
    probabilistic prediction model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dataset size**: Conformal prediction stands apart from typical statistical
    methods that depend on stringent data distribution assumptions, such as normality,
    or need vast datasets for solid guarantees. It offers inherent mathematical assurances
    of valid predictions without bias, irrespective of the dataset’s size. While smaller
    datasets may yield broader prediction intervals in regression tasks (or larger
    sets in classification), conformal prediction remains consistently valid. The
    validity is assured no matter the dataset size, underlying prediction model, or
    data distribution, making it a unique and unmatched method for uncertainty quantification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy to use**: A few years back, the adoption of conformal prediction was
    limited due to the scarcity of open source libraries, even though esteemed universities
    and major corporations such as Microsoft had been utilizing it for years. Fast
    forward to today, and the landscape has dramatically shifted. There’s a rich selection
    of top-tier Python packages such as MAPIE and Amazon Fortuna, among others. This
    means that generating well-calibrated probabilistic predictions via conformal
    prediction is just a few lines of code away, making it straightforward to integrate
    into business applications. Furthermore, platforms such as KNIME have democratized
    its use, offering conformal prediction through low-code or no-code solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fast**: The most widely embraced conformal prediction variant, inductive
    conformal prediction, stands out because it operates efficiently without the need
    to retrain the foundational model. In contrast, other methods, such as Bayesian
    networks, often necessitate retraining. This distinction means that inductive
    conformal prediction offers a streamlined approach, eliminating the time and computational
    costs associated with repeated model retraining.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-intrusive**: Unlike many uncertainty quantification techniques, conformal
    prediction seamlessly integrates without altering the underlying point prediction
    models. Its non-invasive nature is cost-effective and convenient, especially compared
    to other methods that demand potentially costly and complex adjustments to the
    machine or deep learning models. The benefits of using conformal prediction are
    truly incredible. You might be interested to know how conformal prediction achieves
    the unique and powerful benefits that it offers to its users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The key objective of conformal prediction is to provide valid confidence measures
    that adapt based on the difficulty of making individual predictions. Conformal
    prediction uses “nonconformity measures” to assess how well new observations fit
    with previous observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The overall workflow consists of the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: A conformal predictor learns from past training examples to quantify uncertainty
    around predictions for the new observations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When quantifying uncertainty around predictions for the new observations, it
    calculates nonconformity scores, measuring how different or “nonconforming” the
    new observation is, compared to the training set (in the classical transductive
    version of conformal prediction) or calibration (in the most popular variant of
    conformal prediction – inductive conformal prediction).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These nonconformity scores are used to determine whether the new observation
    falls within the range of values expected based on the training data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The model calculates personalized confidence measures and prediction sets (in
    classification problems) or prediction intervals (in regression problems and time
    series forecasting) for each prediction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The magic of conformal prediction lies in these nonconformity measures, which
    allow the model to evaluate each new prediction in the context of the previously
    seen data. This simple but powerful approach results in finite sample coverage
    guarantees adapted to the intrinsic difficulty of making a given prediction. The
    validity holds for any data distribution, prediction algorithm, or dataset size.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will talk interchangeably about nonconformity and conformity
    measures; one is the inverse of the other, and depending on the application, it
    will be more convenient to use either conformity or nonconformity measures.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding conformity measures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A conformity measure is a critical component of conformal prediction and is
    essentially a function that assigns a numerical score (conformity score) to each
    object in a dataset. The conformity score indicates how well a new observation
    fits the observed data. When making a new prediction, we can use the conformity
    measure to calculate a conformity score for the new observation and compare it
    to the conformity scores of the previous observations. Based on this comparison,
    we can calculate a measure of confidence for our prediction. The conformity score
    indicates a degree of confidence in the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: The choice of conformity measure is a key step in conformal prediction. The
    conformity measure determines how we assess how similar new observations are to
    past examples. There are many options for defining conformity measures depending
    on the problem.
  prefs: []
  type: TYPE_NORMAL
- en: In a classification setting, a simple conformity measure could calculate the
    probability scores assigned to each class by the prediction model for a new observation.
    The class with the highest probability would have the best conformity or match
    to the training data.
  prefs: []
  type: TYPE_NORMAL
- en: The key advantage of conformal prediction is that we obtain valid prediction
    regions regardless of the conformity measure used. This is because conformal prediction
    relies only on the order induced by the conformity measure rather than its exact
    form.
  prefs: []
  type: TYPE_NORMAL
- en: So, we have the flexibility to incorporate domain knowledge in designing an
    appropriate conformity measure for the problem at hand. If the measure ranks how
    well new observations match past data, conformal prediction can be used to deliver
    finite sample coverage guarantees.
  prefs: []
  type: TYPE_NORMAL
- en: While all conformal predictors provide valid prediction regions, the choice
    of conformity measure impacts their efficiency. Efficiency relates to the width
    of the prediction intervals or sets – narrower intervals contain more valuable
    information for decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: Though validity holds for any conformity measure, thoughtfully choosing one
    tailored to the application can improve efficiency and produce narrower, more
    useful prediction intervals. The intervals should also be adaptable based on the
    model’s uncertainty – expanding for difficult predictions and contracting for
    clear ones.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s illustrate this with an example. Say we have a dataset of patients diagnosed
    with a disease, with features such as age, gender, and test results. We want to
    predict whether new patients are at risk.
  prefs: []
  type: TYPE_NORMAL
- en: A simple conformity measure could calculate how similar the feature values are
    between new patients and those in the training data. New patients very different
    from the data would get low conformity scores and wide prediction intervals, indicating
    high uncertainty. While this conformity measure would produce valid intervals,
    we can improve efficiency with a more tailored approach.
  prefs: []
  type: TYPE_NORMAL
- en: By carefully selecting conformity measures aligned to our prediction problem
    and domain knowledge, we can obtain high-quality conformal predictors that provide
    both validity and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: We will now talk briefly about the origins of conformal prediction.
  prefs: []
  type: TYPE_NORMAL
- en: The origins of conformal prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The origins of conformal prediction are documented in *Gentle Introduction to
    Conformal Prediction and Distribution-Free Uncertainty Quantification* by Anastasios
    N. Angelopoulos and Stephen Bates ([https://arxiv.org/abs/2107.07511](https://arxiv.org/abs/2107.07511)).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction was invented by my PhD supervisor Prof. Vladimir Vovk,
    a professor at Royal Holloway University of London. Vladimir Vovk graduated from
    Moscow State University, where he studied mathematics and became a student of
    one of the most notable mathematicians of the 20th century, Andrey Kolmogorov.
    During this time, initial ideas that later gave rise to the invention of conformal
    prediction appeared.
  prefs: []
  type: TYPE_NORMAL
- en: The first edition of *Algorithmic Learning in a Random World* ([https://link.springer.com/book/10.1007/b106715](https://link.springer.com/book/10.1007/b106715))
    by Vladimir Vovk, Alexander Gammerman, and Glenn Shafer was published in 2005\.
    The second edition of the book was published in 2022 ([https://link.springer.com/book/10.1007/978-3-031-06649-8](https://link.springer.com/book/10.1007/978-3-031-06649-8)).
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction was popularized in United States academia by Professor
    Larry Wasserman (Carnegie Mellon) and his collaborators, who have published some
    key papers and introduced conformal prediction to many other researchers in the
    United States.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In 2022, I finished my PhD in machine learning. In the same year, I created
    *Awesome Conformal Prediction* ([https://github.com/valeman/awesome-conformal-prediction](https://github.com/valeman/awesome-conformal-prediction))
    – the most comprehensive professionally curated resource on conformal prediction,
    which has since received thousands of GitHub stars.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction has grown rapidly from a niche research area into a mainstream
    framework for uncertainty quantification. The field has exploded in recent years,
    with over 1,000 research papers on conformal prediction estimated to be published
    in 2023 alone.
  prefs: []
  type: TYPE_NORMAL
- en: This surge of research reflects the increasing popularity and applicability
    of conformal prediction across academia and industry. Major technology companies
    such as Microsoft, Amazon, DeepMind, and NVIDIA now conduct research into and
    apply conformal prediction. The framework has also been adopted in high-stakes
    domains such as healthcare and finance, where validity and reliability are critical.
  prefs: []
  type: TYPE_NORMAL
- en: In just over two decades since its introduction, conformal prediction has cemented
    itself as one of the premier and most trusted approaches for uncertainty quantification
    in machine learning. The field will continue to expand as more practitioners recognize
    the value of conformal prediction’s finite sample guarantees compared to traditional
    statistical methods reliant on asymptotic theory and unverifiable distributional
    assumptions. With growing research and adoption, conformal prediction is poised
    to become a standard tool for any application requiring rigorous uncertainty estimates
    alongside point predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'At *NeurIPS 2022*, one of the prominent mathematicians of our time, Emmanuel
    Candes (Stanford), delivered a key invited talk titled *Conformal Prediction in
    2022* ([https://slideslive.com/38996063/conformal-prediction-in-2022?ref=speaker-43789](https://slideslive.com/38996063/conformal-prediction-in-2022?ref=speaker-43789))
    to tens of thousands of attendees. In his talk, Emmanuel Candes said:'
  prefs: []
  type: TYPE_NORMAL
- en: Conformal inference methods are becoming all the rage in academia and industry
    alike. In a nutshell, these methods deliver exact prediction intervals for future
    observations without making any distributional assumption whatsoever other than
    having IID, and more generally, exchangeable data.
  prefs: []
  type: TYPE_NORMAL
- en: The future of conformal prediction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For years, I have promoted conformal prediction as the premier framework for
    reliable probabilistic predictions. Excitingly, over the last 2-3 years, there
    has been an explosion of interest in and adoption of conformal prediction, including
    by major tech leaders such as Amazon, Microsoft, Google, and DeepMind. Many universities
    and companies are researching conformal prediction, actively developing real-world
    applications, and releasing open source libraries such as MAPIE and Amazon Fortuna.
  prefs: []
  type: TYPE_NORMAL
- en: 'These trends will only accelerate as more practitioners recognize the power
    of conformal prediction for trustworthy uncertainty quantification. As renowned
    machine learning researcher Michael I. Jordan noted at the ICML 2021 workshop
    ([https://icml.cc/virtual/2021/workshop/8373](https://icml.cc/virtual/2021/workshop/8373)):
    "*Conformal prediction ideas are THE answer to UQ (uncertainty quantification);
    I think it’s the best I have seen – it’s simple, generalizable, and* *so on*."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Conformal prediction has an incredibly bright future as an indispensable tool
    for quantifying uncertainty in machine learning. Several key reasons are driving
    the momentum and adoption of conformal prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Simplicity**: Conformal prediction is straightforward to understand and implement,
    making it accessible to practitioners without deep statistical expertise. At its
    core is the intuitive idea of measuring how new observations conform to past data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility**: It can be applied to any machine learning model and data distribution.
    No modifications to existing predictors are needed. This model-agnostic property
    greatly expands the applicability of conformal prediction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Theoretical guarantees**: The finite sample coverage guarantees provide an
    unmatched level of reliability compared to traditional statistical methods reliant
    on asymptotic theory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These advantages perfectly position conformal prediction as the gold standard
    for uncertainty quantification in machine learning applications where trustworthy
    confidence estimates are critical.
  prefs: []
  type: TYPE_NORMAL
- en: I am confident that the adoption of conformal prediction in academic research
    and industry will accelerate rapidly in the coming years. Its simple yet powerful
    approach is cementing its place as an essential tool for any practitioner or organization
    managing predictive uncertainty. The next few years will be incredibly exciting
    as we realize the full potential of this game-changing framework.
  prefs: []
  type: TYPE_NORMAL
- en: How conformal prediction differs from traditional machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Conformal prediction allows the production of well-calibrated probabilistic
    predictions for any statistical, machine learning, or deep learning model. This
    is achieved without relying on restrictive assumptions required by other methods
    such as Bayesian techniques, Monte Carlo simulation, and bootstrapping. Importantly,
    conformal prediction does not require subjective priors. It provides mathematically
    guaranteed, well-calibrated predictions every time – regardless of the underlying
    prediction model, data distribution, or dataset size.
  prefs: []
  type: TYPE_NORMAL
- en: A key limitation of traditional machine learning is the need for more reasonable
    confidence measures for individual predictions. Models may have excellent overall
    performance but not be able to quantify uncertainty for a given input reliably.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction solves this by outputting prediction regions and confidence
    measures with statistical validity guarantees. It achieves this distribution-free
    reliability without needing to modify the underlying predictor.
  prefs: []
  type: TYPE_NORMAL
- en: While machine learning and deep learning models struggle to quantify uncertainty,
    limiting user trust, conformal prediction has been successfully applied to consequential
    real-world problems. Examples include diagnosing depression, drug discovery, and
    predicting risks of cancer and stroke.
  prefs: []
  type: TYPE_NORMAL
- en: By delivering trustworthy individual prediction uncertainties, conformal prediction
    unlocks the potential of machine learning for high-stakes applications requiring
    confidence measures alongside predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conformal prediction has invaluable applications across many high-stakes domains
    where reliable confidence estimates are critical:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Medicine**: Conformal prediction can improve trust in AI severity ratings
    for medical imaging, assisting radiologists in disease grading using MRI scans'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Health**: It can detect anomalies and provide reliable anomaly scores to
    inform treatment decisions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Self-driving cars**: Conformal prediction can improve autonomous vehicle
    safety by providing reliable prediction intervals for pedestrian positions and
    trajectories'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Finance**: It can ensure algorithmic fairness in lending by providing well-calibrated
    predictions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recommender systems**: Augmenting recommenders with conformal prediction
    can improve recommendations by guaranteeing high-quality suggestions and minimizing
    erroneous items'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By delivering rigorous confidence estimates, conformal prediction unlocks reliable
    and ethical AI applications in medicine, transportation, finance, and beyond.
    Its validity guarantees make it invaluable for high-stakes decisions relying on
    machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: The p-value and its role in conformal prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conformal prediction, p-values are key in constructing prediction regions
    and intervals with a guaranteed confidence level. However, their purpose is different
    than in traditional statistical hypothesis testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s walk through an example binary classification task to understand how
    this works. Suppose we want to predict whether a patient has a medical condition
    based on their symptoms and characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we calculate a nonconformity score that measures how different or “nonconforming”
    the new patient is compared to previously seen patients. We can define this score
    in various ways, such as the distance between feature values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we temporarily assign the patient each possible label – 0 (no condition)
    and 1 (has condition) – and recalculate the nonconformity score with that assigned
    label.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the score is similar to scores for past patients with label 0, then label
    0 conforms well to the data. To measure this fit statistically, we compute the
    p-value by comparing the test object’s “strangeness” using the test object’s nonconformity
    score to the nonconformity scores of the previous patients.
  prefs: []
  type: TYPE_NORMAL
- en: If this p-value exceeds our chosen significance level, we add label 0 to the
    prediction set since it fits the data. We repeat this for label 1 to see whether
    we should include it.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, we construct a prediction set containing all labels whose nonconformity
    scores result in p-values exceeding the significance level. This provides finite
    sample guarantees on the confidence level of the prediction regions.
  prefs: []
  type: TYPE_NORMAL
- en: So, in summary, nonconformity scores measure how well each potential label conforms
    to the training data. Then p-values let us convert these scores into statistically
    rigorous prediction sets and intervals. The two concepts work hand in hand within
    the conformal prediction framework.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have introduced conformal prediction and explained the multiple
    benefits of this powerful framework for reliably quantifying the uncertainty of
    predictions to improve trust in machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: We explained that the key benefit of conformal prediction is that, unlike any
    other probabilistic prediction framework, it provides valid probabilistic predictions
    accompanied by confidence measures, regardless of the underlying model, the dataset
    size, and the data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: We then explored the origins of conformal prediction and saw how it has recently
    become a very popular framework adopted by leading universities and companies.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we looked at how conformal prediction differs from traditional machine
    learning and learned about the role of p-values in conformal prediction.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B19925_02.xhtml#_idTextAnchor024), we will explain why conformal
    prediction is a valuable tool for quantifying the uncertainty of predictions,
    especially in critical settings such as healthcare, self-driving cars, and finance.
    We will also discuss the concept of uncertainty quantification and how the conformal
    prediction framework has successfully addressed the challenge of quantifying uncertainty.
  prefs: []
  type: TYPE_NORMAL
