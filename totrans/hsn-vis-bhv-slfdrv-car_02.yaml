- en: '*Chapter 1*: OpenCV Basics and Camera Calibration'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第一章*：OpenCV基础和相机标定'
- en: This chapter is an introduction to OpenCV and how to use it in the initial phases
    of a self-driving car pipeline, to ingest a video stream, and prepare it for the
    next phases. We will discuss the characteristics of a camera from the point of
    view of a self-driving car and how to improve the quality of what we get out of
    it. We will also study how to manipulate the videos and we will try one of the
    most famous features of OpenCV, object detection, which we will use to detect
    pedestrians.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是关于OpenCV的介绍，以及如何在自动驾驶汽车管道的初期阶段使用它，以摄取视频流并为其下一阶段做准备。我们将从自动驾驶汽车的角度讨论摄像头的特性，以及如何提高我们从中获得的质量。我们还将研究如何操作视频，并尝试OpenCV最著名的功能之一，即目标检测，我们将用它来检测行人。
- en: With this chapter, you will build a solid foundation on how to use OpenCV and
    NumPy, which will be very useful later.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章，您将建立如何使用OpenCV和NumPy的坚实基础，这在以后将非常有用。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: OpenCV and NumPy basics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV和NumPy基础知识
- en: Reading, manipulating, and saving images
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取、操作和保存图像
- en: Reading, manipulating, and saving videos
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取、操作和保存视频
- en: Manipulating images
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作图像
- en: How to detect pedestrians with HOG
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用HOG检测行人
- en: Characteristics of a camera
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摄像头的特性
- en: How to perform the camera calibration
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何进行相机标定
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For the instructions and code in this chapter, you need the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章中的说明和代码，您需要以下内容：
- en: Python 3.7
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.7
- en: The opencv-Python module
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: opencv-Python模块
- en: The NumPy module
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy模块
- en: 'The code for the chapter can be found here:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在以下位置找到：
- en: '[https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter1](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter1)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter1](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter1)'
- en: 'The Code in Action videos for this chapter can be found here:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的“代码在行动”视频可以在以下位置找到：
- en: '[https://bit.ly/2TdfsL7](https://bit.ly/2TdfsL7)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://bit.ly/2TdfsL7](https://bit.ly/2TdfsL7)'
- en: Introduction to OpenCV and NumPy
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCV和NumPy简介
- en: OpenCV is a computer vision and machine learning library that has been developed
    for more than 20 years and provides an impressive number of functionalities. Despite
    some inconsistencies in the API, its simplicity and the remarkable number of algorithms
    implemented make it an extremely popular library and an excellent choice for many
    situations.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV是一个计算机视觉和机器学习库，它已经发展了20多年，提供了令人印象深刻的众多功能。尽管API中存在一些不一致，但其简单性和实现的算法数量惊人，使其成为极其流行的库，并且在许多情况下都是最佳选择。
- en: OpenCV is written in C++, but there are bindings for Python, Java, and Android.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV是用C++编写的，但提供了Python、Java和Android的绑定。
- en: In this book, we will focus on OpenCV for Python, with all the code tested using
    OpenCV 4.2.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将专注于Python的OpenCV，所有代码都使用OpenCV 4.2进行测试。
- en: 'OpenCV in Python is provided by `opencv-python`, which can be installed using
    the following command:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Python中的OpenCV由`opencv-python`提供，可以使用以下命令安装：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: OpenCV can take advantage of hardware acceleration, but to get the best performance,
    you might need to build it from the source code, with different flags than the
    default, to optimize it for your target hardware.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV可以利用硬件加速，但要获得最佳性能，您可能需要从源代码构建它，使用与默认值不同的标志，以针对您的目标硬件进行优化。
- en: OpenCV and NumPy
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenCV和NumPy
- en: The Python bindings use NumPy, which increases the flexibility and makes it
    compatible with many other libraries. As an OpenCV image is a NumPy array, you
    can use normal NumPy operations to get information about the image. A good understanding
    of NumPy can improve the performance and reduce the length of your code.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Python绑定使用NumPy，这增加了灵活性，并使其与许多其他库兼容。由于OpenCV图像是NumPy数组，您可以使用正常的NumPy操作来获取有关图像的信息。对NumPy的良好理解可以提高性能并缩短您的代码长度。
- en: Let's dive right in with some quick examples of what you can do with NumPy in
    OpenCV.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接通过一些NumPy在OpenCV中的快速示例来深入了解。
- en: Image size
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像大小
- en: 'The size of the image can be retrieved using the `shape` attribute:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`shape`属性检索图像的大小：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For a grayscale image of 50x50, `image.shape()` would return the tuple (50,
    50), while for an RGB image, the result would be (50, 50, 3).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于50x50的灰度图像，`image.shape()`会返回元组(50, 50)，而对于RGB图像，结果将是(50, 50, 3)。
- en: False friends
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 拼音错误
- en: In NumPy, the attribute size is the size in bytes of the array; for a 50x50
    gray image, it would be 2,500, while for the same image in RGB, it would be 7,500\.
    It's the `shape` attribute that contains the size of the image – (50, 50) and
    (50, 50, 3), respectively.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在NumPy中，`size`属性是数组的字节数；对于一个50x50的灰度图像，它将是2,500，而对于相同的RGB图像，它将是7,500。`shape`属性包含图像的大小——分别是(50,
    50)和(50, 50, 3)。
- en: Grayscale images
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 灰度图像
- en: Grayscale images are represented by a two-dimensional NumPy array. The first
    index affects the rows (*y* coordinate) and the second index the columns (*x*
    coordinate). The *y* coordinates have their origin in the top corner of the image
    and *x* coordinates have their origin in the left corner of the image.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 灰度图像由一个二维NumPy数组表示。第一个索引影响行(*y*坐标)和第二个索引影响列(*x*坐标)。*y*坐标的起点在图像的顶部角落，而*x*坐标的起点在图像的左上角。
- en: 'It is possible to create a black image using `np.zeros()`, which initializes
    all the pixels to 0:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`np.zeros()`可以创建一个黑色图像，它将所有像素初始化为0：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The previous code creates a grayscale image with size (100, 100), composed of
    10,000 unsigned bytes (`dtype=np.uint8`).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码创建了一个大小为(100, 100)的灰度图像，由10,000个无符号字节组成(`dtype=np.uint8`)。
- en: 'To create an image with pixels with a different value than 0, you can use the
    `full()` method:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个像素值不为0的图像，你可以使用`full()`方法：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To change the color of all the pixels at once, it''s possible to use the `[:]`
    notation:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要一次性改变所有像素的颜色，可以使用`[:]`表示法：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To affect only some rows, it is enough to provide a range of rows in the first
    index:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要只影响某些行，只需要在第一个索引中提供一个行范围：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The previous code changes the color of rows 10-20, including row 10, but excluding
    row 20.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码改变了第10-20行的颜色，包括第10行，但不包括第20行。
- en: 'The same mechanism works for columns; you just need to specify the range in
    the second index. To instruct NumPy to include a full index, we use the `[:]`
    notation that we already encountered:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的机制也适用于列；你只需要在第二个索引中指定范围。要指示NumPy包含一个完整的索引，我们使用之前遇到的`[:]`表示法：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can also combine operations on rows and columns, selecting a rectangular
    area:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以组合行和列的操作，选择一个矩形区域：
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It is, of course, possible to operate on a single pixel, as you would do on
    a normal array:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，可以操作单个像素，就像在普通数组中做的那样：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'It is possible to use NumPy to select a part of an image, also called the **Region
    Of Interest** (**ROI**). For example, the following code copies a 10x10 **ROI**
    from the position (90, 90) to the position (80, 80):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NumPy选择图像的一部分，也称为**感兴趣区域**(**ROI**)是可能的。例如，以下代码从位置(90, 90)复制一个10x10的**ROI**到位置(80,
    80)：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following is the result of the previous operations:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为之前操作的结果：
- en: '![Figure 1.1 – Some manipulation of images using NumPy slicing](img/Figure_1.1_B16322.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1 – 使用NumPy切片对图像进行的一些操作](img/Figure_1.1_B16322.jpg)'
- en: Figure 1.1 – Some manipulation of images using NumPy slicing
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 使用NumPy切片对图像进行的一些操作
- en: 'To make a copy of an image, you can simply use the `copy()` method:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要复制一张图片，你可以简单地使用`copy()`方法：
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: RGB images
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RGB图像
- en: RGB images differ from grayscale because they are three-dimensional, with the
    third index representing the three channels. Please note that OpenCV stores the
    images in BGR format, not RGB, so channel 0 is blue, channel 1 is green, and channel
    2 is red.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: RGB图像与灰度图像不同，因为它们是三维的，第三个索引代表三个通道。请注意，OpenCV以BGR格式存储图像，而不是RGB，所以通道0是蓝色，通道1是绿色，通道2是红色。
- en: Important note
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: OpenCV stores the images as BGR, not RGB. In the rest of the book, when talking
    about RGB images, it will only mean that it is a 24-bit color image, but the internal
    representation will usually be BGR.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV将图像存储为BGR，而不是RGB。在本书的其余部分，当谈到RGB图像时，它仅意味着它是一个24位彩色图像，但内部表示通常是BGR。
- en: 'To create an RGB image, we need to provide three sizes:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个RGB图像，我们需要提供三个尺寸：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If you were going to run the same code previously used on the grayscale image
    with the new RGB image (skipping the third index), you would get the same result.
    This is because NumPy would apply the same color to all the three channels, which
    results in a shade of gray.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算用之前在灰度图像上运行的相同代码来运行新的RGB图像（跳过第三个索引），你会得到相同的结果。这是因为NumPy会将相同的颜色应用到所有三个通道上，这会导致灰色。
- en: 'To select a color, it is enough to provide the third index:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要选择一个颜色，只需要提供第三个索引：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In NumPy, it is also possible to select rows, columns, or channels that are
    not contiguous. You can do this by simply providing a tuple with the required
    indexes. To make the image magenta, you need to set the blue and red channels
    to `255`, which can be achieved with the following code:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在NumPy中，也可以选择非连续的行、列或通道。您可以通过提供一个包含所需索引的元组来完成此操作。要将图像设置为洋红色，需要将蓝色和红色通道设置为`255`，这可以通过以下代码实现：
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You can convert an RGB image into grayscale using `cvtColor()`:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`cvtColor()`将RGB图像转换为灰度图像：
- en: '[PRE14]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Working with image files
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理图像文件
- en: 'OpenCV provides a very simple way to load images, using `imread()`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV提供了一个非常简单的方式来加载图像，使用`imread()`：
- en: '[PRE15]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To show the image, you can use `imshow()`, which accepts two parameters:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要显示图像，可以使用`imshow()`，它接受两个参数：
- en: The name to write on the caption of the window that will show the image
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要写在显示图像的窗口标题上的名称
- en: The image to be shown
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要显示的图像
- en: 'Unfortunately, its behavior is counterintuitive, as it will not show an image
    unless it is followed by a call to `waitKey()`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，它的行为不符合直觉，因为它不会显示图像，除非后面跟着对`waitKey()`的调用：
- en: '[PRE16]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The call to `waitKey()` after `imshow()` will have two effects:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在`imshow()`之后调用`waitKey()`将有两个效果：
- en: It will actually allow OpenCV to show the image provided to `imshow()`.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它实际上允许OpenCV显示`imshow()`提供的图像。
- en: It will wait for the specified amount of milliseconds, or until a key is pressed
    if the amount of milliseconds passed is `<=0`. It will wait indefinitely.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将等待指定的毫秒数，或者如果经过的毫秒数`<=0`，则等待直到按键。它将无限期等待。
- en: 'An image can be saved on disk using the `imwrite()` method, which accepts three
    parameters:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`imwrite()`方法将图像保存到磁盘上，该方法接受三个参数：
- en: The name of the file
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件名
- en: The image
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该图像
- en: 'An optional format-dependent parameter:'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可选的格式相关参数：
- en: '[PRE17]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Sometimes, it can be very useful to combine multiple pictures by putting them
    next to each other. Some examples in this book will use this feature extensively
    to compare images.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，将多张图片并排放置非常有用。本书中的一些示例将广泛使用此功能来比较图像。
- en: 'OpenCV provides two methods for this purpose: `hconcat()` to concatenate the
    pictures horizontally and `vconcat()` to concatenate them vertically, both accepting
    as a parameter a list of images. Take the following example:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV为此提供了两种方法：`hconcat()`用于水平拼接图片，`vconcat()`用于垂直拼接图片，两者都接受一个图像列表作为参数。以下是一个示例：
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here''s the result:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '![Figure 1.2 – Horizontal concatenation with hconcat() and vertical concatenation
    with vconcat()](img/Figure_1.2_B16322.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图1.2 – 使用hconcat()进行水平拼接和vconcat()进行垂直拼接](img/Figure_1.2_B16322.jpg)'
- en: Figure 1.2 – Horizontal concatenation with hconcat() and vertical concatenation
    with vconcat()
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – 使用hconcat()进行水平拼接和vconcat()进行垂直拼接
- en: 'We could use these two methods to create a chequerboard pattern:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这两个方法来创建棋盘图案：
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You will see the following chequerboard:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下棋盘图案：
- en: '![Figure 1.3 – A chequerboard pattern created using hconcat() in combination
    with vconcat()](img/Figure_1.3_B16322.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图1.3 – 使用hconcat()结合vconcat()创建的棋盘图案](img/Figure_1.3_B16322.jpg)'
- en: Figure 1.3 – A chequerboard pattern created using hconcat() in combination with
    vconcat()
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – 使用hconcat()结合vconcat()创建的棋盘图案
- en: After having worked with images, it's time we work with videos.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理完图像后，我们就可以开始处理视频了。
- en: Working with video files
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理视频文件
- en: Using videos in OpenCV is very simple; in fact, every frame is an image and
    can be manipulated with the methods that we have already analyzed.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中使用视频非常简单；实际上，每一帧都是一个图像，可以使用我们已分析的方法进行操作。
- en: 'To open a video in OpenCV, you need to call the `VideoCapture()` method:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 要在OpenCV中打开视频，需要调用`VideoCapture()`方法：
- en: '[PRE20]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After that, you can call `read()`, typically in a loop, to retrieve a single
    frame. The method returns a tuple with two values:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，您可以通过调用`read()`（通常在一个循环中），来检索单个帧。该方法返回一个包含两个值的元组：
- en: A Boolean value that is false when the video is finished
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当视频结束时为false的布尔值
- en: 'The next frame:'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下一帧：
- en: '[PRE21]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'To save a video, there is the `VideoWriter` object; its constructor accepts
    four parameters:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要保存视频，有`VideoWriter`对象；其构造函数接受四个参数：
- en: The filename
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件名
- en: A FOURCC (four-character code) of the video code
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频编码的四字符代码（FOURCC）
- en: The number of frames per second
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每秒帧数
- en: The resolution
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分辨率
- en: 'Take the following example:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例：
- en: '[PRE22]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Once `VideoWriter` has been created, the `write()` method can be used to add
    a frame to the video file:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了`VideoWriter`对象，就可以使用`write()`方法将一帧添加到视频文件中：
- en: '[PRE23]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'When you have finished using the `VideoCapture` and `VideoWriter` objects,
    you should call their release method:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成使用 `VideoCapture` 和 `VideoWriter` 对象后，你应该调用它们的释放方法：
- en: '[PRE24]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Working with webcams
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用网络摄像头
- en: 'Webcams are handled similarly to a video in OpenCV; you just need to provide
    a different parameter to `VideoCapture`, which is the 0-based index identifying
    the webcam:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在 OpenCV 中，网络摄像头被处理得类似于视频；你只需要为 `VideoCapture` 提供一个不同的参数，即表示网络摄像头的 0 基索引：
- en: '[PRE25]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The previous code opens the first webcam; if you need to use a different one,
    you can specify a different index.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码打开了第一个网络摄像头；如果你需要使用不同的一个，你可以指定一个不同的索引。
- en: Now, let's try manipulating some images.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试操作一些图像。
- en: Manipulating images
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作图像
- en: As part of a computer vision pipeline for a self-driving car, with or without
    deep learning, you might need to process the video stream to make other algorithms
    work better as part of a preprocessing step.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 作为自动驾驶汽车计算机视觉管道的一部分，无论是否使用深度学习，你可能需要处理视频流，以便其他算法作为预处理步骤更好地工作。
- en: This section will provide you with a solid foundation to preprocess any video
    stream.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将为你提供一个坚实的基础，以预处理任何视频流。
- en: Flipping an image
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 翻转图像
- en: 'OpenCV provides the `flip()` method to flip an image, and it accepts two parameters:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 提供了 `flip()` 方法来翻转图像，它接受两个参数：
- en: The image
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像
- en: A number that can be 1 (horizontal flip), 0 (vertical flip), or -1 (both horizontal
    and vertical flip)
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可以是 1（水平翻转）、0（垂直翻转）或 -1（水平和垂直翻转）的数字
- en: 'Let''s see a sample code:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个示例代码：
- en: '[PRE26]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This will produce the following result:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下结果：
- en: '![Figure 1.4 – Original image, horizontally flipped, vertically flipped, and
    both](img/Figure_1.4_B16322.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.4 – 原始图像，水平翻转，垂直翻转，以及两者都翻转](img/Figure_1.4_B16322.jpg)'
- en: Figure 1.4 – Original image, horizontally flipped, vertically flipped, and both
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 – 原始图像，水平翻转，垂直翻转，以及两者都翻转
- en: As you can see, the first image is our original image, which was flipped horizontally
    and vertically, and then both, horizontally and vertically together.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，第一幅图像是我们的原始图像，它被水平翻转和垂直翻转，然后两者同时翻转。
- en: Blurring an image
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模糊图像
- en: Sometimes, an image can be too noisy, possibly because of some processing steps
    that you have done. OpenCV provides several methods to blur an image, which can
    help in these situations. Most likely, you will have to take into consideration
    not only the quality of the blur but also the speed of execution.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，图像可能太嘈杂，可能是因为你执行的一些处理步骤。OpenCV 提供了多种模糊图像的方法，这有助于这些情况。你很可能不仅要考虑模糊的质量，还要考虑执行的速率。
- en: 'The simplest method is `blur()`, which applies a low-pass filter to the image
    and requires at least two parameters:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法是 `blur()`，它对图像应用低通滤波器，并且至少需要两个参数：
- en: The image
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像
- en: 'The kernel size (a bigger kernel means more blur):'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心大小（更大的核心意味着更多的模糊）：
- en: '[PRE27]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Another option is to use `GaussianBlur()`, which offers more control and requires
    at least three parameters:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选项是使用 `GaussianBlur()`，它提供了更多的控制，并且至少需要三个参数：
- en: The image
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像
- en: The kernel size
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心大小
- en: '`sigmaX`, which is the standard deviation on X'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sigmaX`，它是 X 轴上的标准差'
- en: 'It is recommended to specify both `sigmaX` and `sigmaY` (standard deviation
    on Y, the forth parameter):'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 建议指定 `sigmaX` 和 `sigmaY`（Y 轴上的标准差，第四个参数）：
- en: '[PRE28]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'An interesting blurring method is `medianBlur()`, which computes the median
    and therefore has the characteristic of emitting only pixels with colors present
    in the image (which does not necessarily happen with the previous method). It
    is effective at reducing "salt and pepper" noise and has two mandatory parameters:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的模糊方法是 `medianBlur()`，它计算中值，因此具有只发出图像中存在的颜色像素（这不一定发生在前一种方法中）的特征。它有效地减少了“盐和胡椒”噪声，并且有两个强制参数：
- en: The image
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像
- en: 'The kernel size (an odd integer greater than 1):'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心大小（一个大于 1 的奇数整数）：
- en: '[PRE29]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'There is also a more complex filter, `bilateralFilter()`, which is effective
    at removing noise while keeping the edge sharp. It is the slowest of the filters,
    and it requires at least four parameters:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一个更复杂的过滤器 `bilateralFilter()`，它在去除噪声的同时保持边缘清晰。这是最慢的过滤器，并且至少需要四个参数：
- en: The image
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像
- en: The diameter of each pixel neighborhood
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个像素邻域的直径
- en: '`sigmaColor`: Filters sigma in the color space, affecting how much the different
    colors are mixed together, inside the pixel neighborhood'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sigmaColor`：在颜色空间中过滤 sigma，影响像素邻域内不同颜色混合的程度'
- en: '`sigmaSpace`: Filters sigma in the coordinate space, affecting how distant
    pixels affect each other, if their colors are closer than `sigmaColor`:'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sigmaSpace`：在坐标空间中过滤 sigma，影响颜色比 `sigmaColor` 更接近的像素如何相互影响：'
- en: '[PRE30]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Choosing the best filter will probably require some experiments. You might
    also need to consider the speed. To give you some ballpark estimations based on
    my tests, and considering that the performance is dependent on the parameters
    supplied, note the following:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 选择最佳过滤器可能需要一些实验。你可能还需要考虑速度。以下是基于我的测试结果和一些基于参数的性能依赖性的大致估计，请注意：
- en: '`blur()` is the fastest.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blur()` 是最快的。'
- en: '`GaussianBlur()` is similar, but it can be 2x slower than blur().'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GaussianBlur()` 类似，但它可能比 blur() 慢 2 倍。'
- en: '`medianBlur()` can easily be 20x slower than `blur()`.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`medianBlur()` 可能会比 `blur()` 慢 20 倍。'
- en: '`BilateralFilter()` is the slowest and can be 45x slower than `blur()`.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BilateralFilter()` 是最慢的，可能比 `blur()` 慢 45 倍。'
- en: 'Here are the resultant images:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是结果图像：
- en: '![Figure 1.5 – Original, blur(), GaussianBlur(), medianBlur(), and BilateralFilter(),
    with the parameters used in the code samples](img/Figure_1.5_B16322.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.5 – 原图、blur()、GaussianBlur()、medianBlur() 和 BilateralFilter()，以及代码示例中使用的参数](img/Figure_1.5_B16322.jpg)'
- en: Figure 1.5 – Original, blur(), GaussianBlur(), medianBlur(), and BilateralFilter(),
    with the parameters used in the code samples
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5 – 原图、blur()、GaussianBlur()、medianBlur() 和 BilateralFilter()，以及代码示例中使用的参数
- en: Changing contrast, brightness, and gamma
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 改变对比度、亮度和伽玛
- en: 'A very useful function is `convertScaleAbs()`, which executes several operations
    on all the values of the array:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常有用的函数是 `convertScaleAbs()`，它会对数组的所有值执行多个操作：
- en: It multiplies them by the scaling parameter, `alpha`.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们乘以缩放参数，`alpha`。
- en: It adds to them the delta parameter, `beta`.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们加上增量参数，`beta`。
- en: If the result is above 255, it is set to 255.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果结果是 255 以上，则将其设置为 255。
- en: The result is converted into an unsigned 8-bit int.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果被转换为无符号 8 位整型。
- en: 'The function accepts four parameters:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数接受四个参数：
- en: The source image
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源图像
- en: The destination (optional)
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标（可选）
- en: The `alpha` parameter used for the scaling
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于缩放的 `alpha` 参数
- en: The `beta` delta parameter
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta` 增量参数'
- en: '`convertScaleAbs()` can be used to affect the contrast, as an `alpha` scaling
    factor above 1 increases the contrast (amplifying the color difference between
    pixels), while a scaling factor below one reduces it (decreasing the color difference
    between pixels):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`convertScaleAbs()` 可以用来影响对比度，因为大于 1 的 `alpha` 缩放因子会增加对比度（放大像素之间的颜色差异），而小于
    1 的缩放因子会减少对比度（减少像素之间的颜色差异）：'
- en: '[PRE31]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'It can also be used to affect the brightness, as the `beta` delta factor can
    be used to increase the value of all the pixels (increasing the brightness) or
    to reduce them (decreasing the brightness):'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可以用来影响亮度，因为 `beta` 增量因子可以用来增加所有像素的值（增加亮度）或减少它们（减少亮度）：
- en: '[PRE32]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let''s see the resulting images:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看结果图像：
- en: '![Figure 1.6 – Original, more contrast (2x), less contrast (0.5x), more brightness
    (+64), and less brightness (-64)](img/Figure_1.6_B16322.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.6 – 原图、更高对比度（2x）、更低对比度（0.5x）、更高亮度（+64）和更低亮度（-64）](img/Figure_1.6_B16322.jpg)'
- en: Figure 1.6 – Original, more contrast (2x), less contrast (0.5x), more brightness
    (+64), and less brightness (-64)
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – 原图、更高对比度（2x）、更低对比度（0.5x）、更高亮度（+64）和更低亮度（-64）
- en: 'A more sophisticated method to change the brightness is to apply gamma correction.
    This can be done with a simple calculation using NumPy. A gamma value above 1
    will increase the brightness, and a gamma value below 1 will reduce it:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 改变亮度的一种更复杂的方法是应用伽玛校正。这可以通过使用 NumPy 进行简单计算来完成。伽玛值大于 1 会增加亮度，而伽玛值小于 1 会减少亮度：
- en: '[PRE33]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The following images will be produced:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 将产生以下图像：
- en: '![Figure 1.7 – Original, higher gamma (1.5), and lower gamma (0.7)](img/Figure_1.7_B16322.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.7 – 原图、更高伽玛（1.5）和更低伽玛（0.7）](img/Figure_1.7_B16322.jpg)'
- en: Figure 1.7 – Original, higher gamma (1.5), and lower gamma (0.7)
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7 – 原图、更高伽玛（1.5）和更低伽玛（0.7）
- en: You can see the effect of different gamma values in the middle and right images.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在中间和右边的图像中看到不同伽玛值的效果。
- en: Drawing rectangles and text
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绘制矩形和文本
- en: 'When working on object detection tasks, it is a common need to highlight an
    area to see what has been detected. OpenCV provides the `rectangle()` function,
    accepting at least the following parameters:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理目标检测任务时，突出显示一个区域以查看检测到的内容是一个常见需求。OpenCV 提供了 `rectangle()` 函数，它至少接受以下参数：
- en: The image
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像
- en: The upper-left corner of the rectangle
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩形的左上角
- en: The lower-right corner of the rectangle
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩形的右下角
- en: The color to use
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用的颜色
- en: '(Optional) The thickness:'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （可选）线条粗细：
- en: '[PRE34]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To write some text in the image, you can use the `putText()` method, accepting
    at least six parameters:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 要在图像中写入一些文本，你可以使用`putText()`方法，至少需要接受六个参数：
- en: The image
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像
- en: The text to print
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要打印的文本
- en: The coordinates of the bottom-left corner
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左下角的坐标
- en: The font face
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字体样式
- en: The scale factor, to change the size
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放因子，用于改变大小
- en: 'The color:'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 颜色：
- en: '[PRE35]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Pedestrian detection using HOG
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用HOG进行行人检测
- en: The **Histogram of Oriented Gradients** (**HOG**) is an object detection technique
    implemented by OpenCV. In simple cases, it can be used to see whether there is
    a certain object present in the image, where it is, and how big it is.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**方向梯度直方图（HOG**）是OpenCV实现的一种目标检测技术。在简单情况下，它可以用来判断图像中是否存在某个特定对象，它在哪里，有多大。'
- en: OpenCV includes a detector trained for pedestrians, and you are going to use
    it. It might not be enough for a real-life situation, but it is useful to learn
    how to use it. You could also train another one with more images to see whether
    it performs better. Later in the book, you will see how to use deep learning to
    detect not only pedestrians but also cars and traffic lights.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV包含一个针对行人训练的检测器，你将使用它。它可能不足以应对现实生活中的情况，但学习如何使用它是很有用的。你也可以用更多图像训练另一个检测器，看看它的表现是否更好。在本书的后面部分，你将看到如何使用深度学习来检测不仅行人，还有汽车和交通灯。
- en: Sliding window
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 滑动窗口
- en: The HOG pedestrian detector in OpenCV is trained with a model that is 48x96
    pixels, and therefore it is not able to detect objects smaller than that (or,
    better, it could, but the box will be 48x96).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV中的HOG行人检测器使用的是48x96像素的模型，因此它无法检测比这更小的对象（或者，更好的说法是，它可以，但检测框将是48x96）。
- en: At the core of the HOG detector, there is a mechanism able to tell whether a
    given 48x96 image is a pedestrian. As this is not terribly useful, OpenCV implements
    a sliding window mechanism, where the detector is applied many times, on slightly
    different positions; the "image window" under consideration slides a bit. Once
    it has analyzed the whole image, the image window is increased in size (scaled)
    and the detector is applied again, to be able to detect bigger objects. Therefore,
    the detector is applied hundreds or even thousands of times for each image, which
    can be slow.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: HOG检测器的核心有一个机制，可以判断给定的48x96像素图像是否为行人。由于这并不特别有用，OpenCV实现了一个滑动窗口机制，其中检测器被多次应用于略微不同的位置；考虑的“图像窗口”稍微滑动一下。一旦分析完整个图像，图像窗口就会增加大小（缩放），然后再次应用检测器，以便能够检测更大的对象。因此，检测器对每个图像应用数百次甚至数千次，这可能会很慢。
- en: Using HOG with OpenCV
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用OpenCV的HOG
- en: 'First, you need to initialize the detector and specify that you want to use
    the detector for pedestrians:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要初始化检测器并指定你想要使用该检测器进行行人检测：
- en: '[PRE36]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Then, it is just a matter of calling `detectMultiScale()`:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，只需调用`detectMultiScale()`函数：
- en: '[PRE37]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The parameters that we used require some explanation, and they are as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的参数需要一些解释，如下所示：
- en: The image
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像
- en: '`winStride`, the window stride, which specifies how much the sliding window
    moves every time'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`winStride`，窗口步长，指定每次滑动窗口移动的距离'
- en: Padding, which can add some padding pixels at the border of the image (useful
    to detect pedestrians close to the border)
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充，可以在图像边界的周围添加一些填充像素（对于检测靠近边界的行人很有用）
- en: Scale, which specifies how much to increase the window image every time
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放，指定每次增加窗口图像的大小
- en: You should consider that `winSize` can improve the accuracy (as more positions
    are considered), but it has a big impact on performance. For example, a stride
    of (4, 4) can be up to 16 times faster than a stride of (1, 1), though in practice,
    the performance difference is a bit less, maybe 10 times.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该考虑`winSize`可以提升准确性（因为考虑了更多位置），但它对性能有较大影响。例如，步长为（4，4）可以比步长为（1，1）快16倍，尽管在实际应用中，性能差异要小一些，可能只有10倍。
- en: In general, **decreasing the scale** also improves the precision and decreases
    the performance, though the impact is not dramatic.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，**减小缩放**可以提高精度并降低性能，尽管影响并不显著。
- en: 'Improving the precision means detecting more pedestrians, but this can also
    increase the false positives. `detectMultiScale()` has a couple of advanced parameters
    that can be used for this:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 提高精度意味着检测到更多行人，但这也可能增加误报。`detectMultiScale()`有几个高级参数可以用于此：
- en: '`hitThreshold`, which changes the distance required from the **Support Vector
    Machine** (**SVM**) plane. A higher threshold means than the detector is more
    confident with the result.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hitThreshold`，它改变了从**支持向量机**（**SVM**）平面所需距离。阈值越高，意味着检测器对结果越有信心。'
- en: '`finalThreshold`, which is related to the number of detections in the same
    area.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`finalThreshold`，它与同一区域内的检测数量相关。'
- en: Tuning these parameters requires some experiments, but in general, a higher
    `hitThreshold` value (typically in the range 0–1.0) should reduce the false positives.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 调整这些参数需要一些实验，但一般来说，较高的`hitThreshold`值（通常在0–1.0的范围内）应该会减少误报。
- en: A higher `finalThreshold` value (such as 10) will also reduce the false positives.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 较高的`finalThreshold`值（例如10）也会减少误报。
- en: 'We will use `detectMultiScale()` on an image with pedestrians generated by
    Carla:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在由Carla生成的行人图像上使用`detectMultiScale()`。
- en: '![Figure 1.8 – HOG detection, winStride=(1, 2), scale=1.05, padding=(0, 0)
    Left: hitThreshold = 0, finalThreshold = 1; Center: hitThreshold = 0, inalThreshold
    = 3; Right: hitThreshold = 0.2, finalThreshold = 1](img/Figure_1.8_B16322.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![图1.8 – HOG检测，winStride=(1, 2)，scale=1.05，padding=(0, 0) 左：hitThreshold =
    0，inalThreshold = 1；中：hitThreshold = 0，inalThreshold = 3；右：hitThreshold = 0.2，finalThreshold
    = 1](img/Figure_1.8_B16322.jpg)'
- en: 'Figure 1.8 – HOG detection, winStride=(1, 2), scale=1.05, padding=(0, 0)Left:
    hitThreshold = 0, finalThreshold = 1; Center: hitThreshold = 0, finalThreshold
    = 3;Right: hitThreshold = 0.2, finalThreshold = 1'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8 – HOG检测，winStride=(1, 2)，scale=1.05，padding=(0, 0) 左：hitThreshold = 0，finalThreshold
    = 1；中：hitThreshold = 0，inalThreshold = 3；右：hitThreshold = 0.2，finalThreshold =
    1
- en: As you can see, we have pedestrians being detected in the image. Using a low
    hit threshold and a low final threshold can result in false positives, as in the
    left image. Your goal is to find the right balance, detecting the pedestrians
    but without having too many false positives.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们在图像中检测到了行人。使用较低的hit阈值和final阈值可能导致误报，如左图所示。你的目标是找到正确的平衡点，检测行人，同时避免有太多的误报。
- en: Introduction to the camera
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相机简介
- en: The camera is probably one of the most ubiquitous sensors in our modern world.
    They are used in everyday life in our mobile phones, laptops, surveillance systems,
    and of course, photography. They provide rich, high-resolution imagery containing
    extensive information about the environment, including spatial, color, and temporal
    information.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 相机可能是我们现代世界中最普遍的传感器之一。它们在我们的手机、笔记本电脑、监控系统以及当然，摄影中都被广泛应用。它们提供了丰富的、高分辨率的图像，包含关于环境的广泛信息，包括空间、颜色和时间信息。
- en: It is no surprise that they are heavily used in self-driving technologies. One
    reason why the camera is so popular is that it mirrors the functionality of the
    human eye. For this reason, we are very comfortable using them as we connect on
    a deep level with their functionality, limitations, and strengths.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 没有什么奇怪的，它们在自动驾驶技术中被广泛使用。相机之所以如此受欢迎，其中一个原因就是它反映了人眼的功能。正因为如此，我们非常习惯于使用它们，因为我们与它们的功能、局限性和优点在深层次上建立了联系。
- en: 'In this section, you will learn about the following:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习以下内容：
- en: Camera terminology
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相机术语
- en: The components of a camera
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相机的组成部分
- en: Strengths and weaknesses
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优缺点
- en: Choosing the right camera for self-driving
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择适合自动驾驶的相机
- en: Let's discuss each in detail.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一详细讨论。
- en: Camera terminology
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相机术语
- en: Before you learn about the components of a camera and its strengths and weaknesses,
    you need to know some basic terminology. These terms will be important when evaluating
    and ultimately choosing your camera for your self-driving application.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习相机的组成部分及其优缺点之前，你需要了解一些基本术语。这些术语在评估和最终选择你的自动驾驶应用中的相机时将非常重要。
- en: Field of View (FoV)
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 视场（FoV）
- en: 'This is the vertical and horizontal angular portion of the environment (scene)
    that is visible to the sensor. In self-driving cars, you typically want to balance
    the FoV with the resolution of the sensor to ensure we see as much of the environment
    as possible with the least number of cameras. There is a trade space related to
    FoV. Larger FoV usually means more lens distortion, which you will need to compensate
    for in your camera calibration (see the section on camera calibration):'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这是环境（场景）中传感器可见的垂直和水平角部分。在自动驾驶汽车中，你通常希望平衡视场与传感器的分辨率，以确保我们尽可能多地看到环境，同时使用最少的相机。视场存在一个权衡空间。较大的视场通常意味着更多的镜头畸变，你需要在相机校准中进行补偿（参见相机校准部分）：
- en: '![Figure 1.9 – Field of View, credit: https://www.researchgate.net/figure/Illustration-of-camera-lenss-field-of-view-FOV_fig4_335011596](img/Figure_1.9_B16322.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.9 – 视场，来源：https://www.researchgate.net/figure/Illustration-of-camera-lenss-field-of-view-FOV_fig4_335011596](img/Figure_1.9_B16322.jpg)'
- en: 'Figure 1.9 – Field of View, credit: [https://www.researchgate.net/figure/Illustration-of-camera-lenss-field-of-view-FOV_fig4_335011596](https://www.researchgate.net/figure/Illustration-of-camera-lenss-field-of-view-FOV_fig4_335011596)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9 – 视场，来源：[https://www.researchgate.net/figure/Illustration-of-camera-lenss-field-of-view-FOV_fig4_335011596](https://www.researchgate.net/figure/Illustration-of-camera-lenss-field-of-view-FOV_fig4_335011596)
- en: Resolution
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分辨率
- en: This is the total number of pixels in the horizontal and vertical directions
    on the sensor. This parameter is often discussed using the term **megapixels**
    (**MP**). For example, a 5 MP camera, such as the FLIR Blackfly, has a sensor
    with 2448 × 2048 pixels, which equates to 5,013,504 pixels.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这是传感器在水平和垂直方向上的像素总数。这个参数通常使用**百万像素**（**MP**）这个术语来讨论。例如，一个 5 MP 的相机，如 FLIR Blackfly，其传感器有
    2448 × 2048 像素，相当于 5,013,504 像素。
- en: Higher resolutions allow you to use a lens with a wider FoV but still provide
    the detail needed for running your computer vision algorithms. This means you
    can use fewer cameras to cover the environment and thereby lower the cost.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 更高的分辨率允许你使用具有更宽视场角（FoV）的镜头，同时仍然提供运行你的计算机视觉算法所需的细节。这意味着你可以使用更少的相机来覆盖环境，从而降低成本。
- en: 'The Blackfly, in all its different flavors, is a common camera used in self-driving
    vehicles thanks to its cost, small form, reliability, robustness, and ease of
    integration:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: Blackfly，以其各种不同的版本，由于成本、小型化、可靠性、鲁棒性和易于集成，是自动驾驶汽车中常用的相机：
- en: '![Figure 1.10 – Pixel resolution](img/Figure_1.10_New.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.10 – 像素分辨率](img/Figure_1.10_New.jpg)'
- en: Figure 1.10 – Pixel resolution
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.10 – 像素分辨率
- en: Focal length
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 焦距
- en: 'This is the length from the lens optical center to the sensor. The focal length
    is best thought of as the zoom of the camera. A longer focal length means you
    will be zoomed in closer to objects in the environment. In your self-driving car,
    you may choose different focal lengths based on what you need to see in the environment.
    For example, you might choose a relatively long focal length of 100 mm to ensure
    enough resolution for your classifier algorithm to detect a traffic signal at
    a distance far enough to allow the car to react with smooth and safe stopping:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从镜头光学中心到传感器的长度。焦距最好理解为相机的变焦。较长的焦距意味着你将更靠近环境中的物体进行放大。在你的自动驾驶汽车中，你可能需要根据你在环境中的需求选择不同的焦距。例如，你可能选择一个相对较长的
    100 毫米焦距，以确保你的分类器算法能够检测到足够远的交通信号，以便汽车能够平稳、安全地停车：
- en: '![Figure 1.11 – Focal length, credit: https://photographylife.com/what-is-focal-length-in-photography](img/Figure_1.11_B16322.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.11 – 焦距，来源：https://photographylife.com/what-is-focal-length-in-photography](img/Figure_1.11_B16322.jpg)'
- en: 'Figure 1.11 – Focal length, credit: [https://photographylife.com/what-is-focal-length-in-photography](https://photographylife.com/what-is-focal-length-in-photography)'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.11 – 焦距，来源：[https://photographylife.com/what-is-focal-length-in-photography](https://photographylife.com/what-is-focal-length-in-photography)
- en: Aperture and f-stop
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 光圈和光圈值
- en: 'This is the opening through which light passes to shine on the sensor. The
    unit that is commonly used to describe the size of the opening is the f-stop,
    which refers to the ratio of the focal length over the aperture size. For example,
    a lens with a 50 mm focal length and an aperture diameter of 35 mm will equate
    to an f-stop of f/1.4\. The following figure illustrates different aperture diameters
    and their f-stop values on a 50 mm focal length lens. Aperture size is very important
    in your self-driving car as it is directly correlated with the **Depth of Field**
    (**DoF**). Large apertures also allow the camera to be tolerant of obscurants
    (for example, bugs) that may be on the lens. Larger apertures allow light to pass
    around the bug and still make it to the sensor:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这是光线通过以照亮传感器的开口。通常用来描述开口大小的单位是光圈，它指的是焦距与开口大小的比率。例如，一个焦距为 50 毫米、光圈直径为 35 毫米的镜头将等于
    f/1.4 的光圈。以下图示展示了不同光圈直径及其在 50 毫米焦距镜头上的光圈值。光圈大小对你的自动驾驶汽车非常重要，因为它与**景深**（**DoF**）直接相关。大光圈还允许相机对镜头上的遮挡物（例如，虫子）具有容忍性：更大的光圈允许光线绕过虫子并仍然到达传感器：
- en: '![Figure 1.12 – Aperture, credit: https://en.wikipedia.org/wiki/Aperture#/media/File:Lenses_with_different_apertures.jpg](img/Figure_1.12_B16322.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.12 – 光圈，来源：https://en.wikipedia.org/wiki/Aperture#/media/File:Lenses_with_different_apertures.jpg](img/Figure_1.12_B16322.jpg)'
- en: 'Figure 1.12 – Aperture, credit: [https://en.wikipedia.org/wiki/Aperture#/media/File:Lenses_with_different_apertures.jpg](https://en.wikipedia.org/wiki/Aperture#/media/File:Lenses_with_different_apertures.jpg)'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.12 – 光圈，来源：[https://en.wikipedia.org/wiki/Aperture#/media/File:Lenses_with_different_apertures.jpg](https://en.wikipedia.org/wiki/Aperture#/media/File:Lenses_with_different_apertures.jpg)
- en: Depth of field (DoF)
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 景深（DoF）
- en: This is the distance range in the environment that will be in focus. This is
    directly correlated to the size of the aperture. Generally, in self-driving cars,
    you will want a deep DoF so that everything in the FoV is in focus for your computer
    vision algorithms. The problem is that deep DoF is achieved with a small aperture,
    which means less light impacting the sensor. So, you will need to balance DoF
    with dynamic range and ISO to ensure you see everything you need to in your environment.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这是环境中将要聚焦的距离范围。这直接关联到光圈的大小。通常情况下，在自动驾驶汽车中，你希望有较深的景深，以便你的计算机视觉算法能够聚焦视野中的所有物体。问题是，深景深是通过小光圈实现的，这意味着传感器接收到的光线较少。因此，你需要平衡景深、动态范围和ISO，以确保你能看到环境中所需看到的一切。
- en: 'The following figure depicts the relationship between DoF and aperture:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了景深与光圈之间的关系：
- en: '![Figure 1.13 – DoF versus aperture, credit: https://thumbs.dreamstime.com/z/aperture-infographic-explaining-depth-field-corresponding-values-their-effect-blur-light-75823732.jpg](img/Figure_1.13_B16322.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.13 – 景深与光圈对比，来源：https://thumbs.dreamstime.com/z/aperture-infographic-explaining-depth-field-corresponding-values-their-effect-blur-light-75823732.jpg](img/Figure_1.13_B16322.jpg)'
- en: 'Figure 1.13 – DoF versus aperture, credit: [https://thumbs.dreamstime.com/z/aperture-infographic-explaining-depth-field-corresponding-values-their-effect-blur-light-75823732.jpg](https://thumbs.dreamstime.com/z/aperture-infographic-explaining-depth-field-corresponding-values-their-effect-blur-light-75823732.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13 – 景深与光圈对比，来源：[https://thumbs.dreamstime.com/z/aperture-infographic-explaining-depth-field-corresponding-values-their-effect-blur-light-75823732.jpg](https://thumbs.dreamstime.com/z/aperture-infographic-explaining-depth-field-corresponding-values-their-effect-blur-light-75823732.jpg)
- en: Dynamic range
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 动态范围
- en: This is a property of the sensor that indicates its contrast ratio or the ratio
    of the brightest over the darkest subjects that it can resolve. This may be referred
    to using the unit dB (for example, 78 dB) or contrast ratio (for example, 2,000,000/1).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这是传感器的一个属性，表示其对比度或它能解析的最亮与最暗主题之间的比率。这可能会用dB（例如，78 dB）或对比度（例如，2,000,000/1）来表示。
- en: 'Self-driving cars need to operate both during the day and at night. This means
    that the sensor needs to be sensitive enough to provide useful detail in dark
    conditions while not oversaturating when driving in bright sunlight. Another reason
    for **High Dynamic Range** (**HDR**) is the example of driving when the sun is
    low on the horizon. I am sure you have experienced this while driving yourself
    to work in the morning and the sun is right in your face and you can barely see
    the environment in front of you because it is saturating your eyes. HDR means
    that the sensor will be able to see the environment even in the face of direct
    sunlight. The following figure illustrates these conditions:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 自动驾驶汽车需要在白天和夜晚运行。这意味着传感器需要在黑暗条件下提供有用的细节，同时不会在明亮阳光下过度饱和。**高动态范围**（HDR）的另一个原因是当太阳在地平线较低时驾驶的情况。我相信你在早上开车上班时一定有过这样的经历，太阳正对着你的脸，你几乎看不到前面的环境，因为它已经让你的眼睛饱和了。HDR意味着即使在直射阳光下，传感器也能看到环境。以下图示说明了这些条件：
- en: '![Figure 1.14 – Example HDR, credit: https://petapixel.com/2011/05/02/use-iso-numbers-that-are-multiples-of-160-when-shooting-dslr-video/](img/Figure_1.14_New.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.14 – HDR 示例，来源：https://petapixel.com/2011/05/02/use-iso-numbers-that-are-multiples-of-160-when-shooting-dslr-video/](img/Figure_1.14_New.jpg)'
- en: 'Figure 1.14 – Example HDR, credit: [https://petapixel.com/2011/05/02/use-iso-numbers-that-are-multiples-of-160-when-shooting-dslr-video/](https://petapixel.com/2011/05/02/use-iso-numbers-that-are-multiples-of-160-when-shooting-dslr-video/)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.14 – HDR 示例，来源：[https://petapixel.com/2011/05/02/use-iso-numbers-that-are-multiples-of-160-when-shooting-dslr-video/](https://petapixel.com/2011/05/02/use-iso-numbers-that-are-multiples-of-160-when-shooting-dslr-video/)
- en: Your dream dynamic range
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 你的梦想动态范围
- en: If you could make a wish and have whatever dynamic range you wanted in your
    sensor, what would it be?
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你可以许愿，并且在你的传感器中拥有你想要的任何动态范围，那会是什么？
- en: International Organization for Standardization (ISO) sensitivity
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 国际标准化组织（ISO）灵敏度
- en: This is the sensitivity of the pixels to incoming photons.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这是像素对入射光子的敏感度。
- en: '*Wait a* *minute*, you say, *do you have your acronym mixed up*? It looks like
    it, but the International Organization for Standardization decided to standardize
    even their acronym since it would be different in every language otherwise. Thanks,
    ISO!'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '*等一下*，你说，*你的缩写搞混了吗*？看起来是这样，但国际标准化组织决定连它们的缩写也要标准化，因为否则每种语言都会不同。谢谢，ISO！'
- en: 'The standardized ISO values can range from 100 to upward of 10,000\. Lower
    ISO values correspond to a lower sensitivity of the sensor. Now you may ask, "why
    wouldn''t I want the highest sensitivity?" Well, sensitivity comes at a cost...NOISE.
    The higher the ISO, the more noise you will see in your images. This added noise
    may cause trouble for your computer vision algorithms when trying to classify
    objects. In the following figure, you can see the effect of higher ISO values
    on noise in an image. These images are all taken with the lens cap on (fully dark).
    As you increase the ISO value, random noise starts to creep in:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化的ISO值可以从100到超过10,000。较低的ISO值对应于传感器较低的灵敏度。现在你可能要问，“为什么我不想要最高的灵敏度？”好吧，灵敏度是有代价的……噪声。ISO值越高，你会在图像中看到更多的噪声。这种额外的噪声可能会在尝试对物体进行分类时给你的计算机视觉算法带来麻烦。在下面的图中，你可以看到较高ISO值对图像噪声的影响。这些图像都是在镜头盖盖上（完全黑暗）的情况下拍摄的。随着ISO值的增加，随机噪声开始渗入：
- en: '![Figure 1.15 – Example ISO values and noise in a dark room](img/Figure_1.15_New.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图1.15 – 暗室中的ISO值示例和噪声](img/Figure_1.15_New.jpg)'
- en: Figure 1.15 – Example ISO values and noise in a dark room
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.15 – 暗室中的ISO值示例和噪声
- en: Frame rate (FPS)
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 帧率（FPS）
- en: 'This is the rate at which the sensor can obtain consecutive images, usually
    expressed in Hz or **Frames Per Second** (**FPS**). Generally speaking, you want
    to have the fastest frame rate so that fast-moving objects are not blurry in your
    scene. The main trade-off here is latency: the time from a real event happening
    until your computer vision algorithm detects it. The higher the frame rate that
    must be processed, the higher the latency. In the following figure, you can see
    the effect of frame rate on motion blur.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这是传感器获取连续图像的速率，通常以Hz或**每秒帧数**（FPS）表示。一般来说，你希望有最快的帧率，这样快速移动的物体在你的场景中就不会模糊。这里的主要权衡是延迟：从真实事件发生到你的计算机视觉算法检测到它的时间。必须处理的帧率越高，延迟就越高。在下面的图中，你可以看到帧率对运动模糊的影响。
- en: 'Blur is not the only reason for choosing a higher frame rate. Depending on
    the speed of your vehicle, you will need a frame rate that will allow the vehicle
    to react if an object suddenly appears in its FoV. If your frame rate is too slow,
    by the time the vehicle sees something, it may be too late to react:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊并不是选择更高帧率的唯一原因。根据你的车辆速度，你需要一个帧率，以便车辆能够在物体突然出现在其视场（FoV）中时做出反应。如果你的帧率太慢，当车辆看到某物时，可能已经太晚做出反应了：
- en: '![Figure 1.16 – 120 Hz versus 60 Hz frame rate, credit: https://gadgetstouse.com/blog/2020/03/18/difference-between-60hz-90hz-120hz-displays/](img/Figure_1.16_B16322.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![图1.16 – 120 Hz与60 Hz帧率对比，来源：https://gadgetstouse.com/blog/2020/03/18/difference-between-60hz-90hz-120hz-displays/](img/Figure_1.16_B16322.jpg)'
- en: 'Figure 1.16 – 120 Hz versus 60 Hz frame rate, credit: [https://gadgetstouse.com/blog/2020/03/18/difference-between-60hz-90hz-120hz-displays/](https://gadgetstouse.com/blog/2020/03/18/difference-between-60hz-90hz-120hz-displays/)'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.16 – 120 Hz与60 Hz帧率对比，来源：[https://gadgetstouse.com/blog/2020/03/18/difference-between-60hz-90hz-120hz-displays/](https://gadgetstouse.com/blog/2020/03/18/difference-between-60hz-90hz-120hz-displays/)
- en: Lens flare
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 镜头眩光
- en: These are the artifacts of light from an object that impact pixels on the sensor
    that do not correlate with the position of the object in the environment. You
    have likely experienced this driving at night when you see oncoming headlights.
    That starry effect is due to light scattered in the lens of your eye (or camera),
    due to imperfections, leading some of the photons to impact "pixels" that do not
    correlate with where the photons came from – that is, the headlights. The following
    figure shows what that effect looks like. You can see that the starburst makes
    it very difficult to see the actual object, the car!
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是来自物体的光线在传感器上产生的伪影，这些伪影与物体在环境中的位置不相关。你可能在夜间驾驶时遇到过这种情况，当时你会看到迎面而来的车灯。那种星光效果是由于你的眼睛（或相机）的镜头中散射的光线，由于不完美，导致一些光子撞击了“像素”，而这些像素与光子来自的地方不相关——也就是说，是车灯。以下图示显示了这种效果。你可以看到星光效果使得实际物体，即汽车，非常难以看清！
- en: '![Figure 1.17 – Lens flare from oncoming headlights, credit: https://s.blogcdn.com/cars.aol.co.uk/media/2011/02/headlights-450-a-g.jpg](img/Figure_1.17_B16322.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![图1.17 – 迎面车灯产生的镜头眩光，来源：https://s.blogcdn.com/cars.aol.co.uk/media/2011/02/headlights-450-a-g.jpg](img/Figure_1.17_B16322.jpg)'
- en: 'Figure 1.17 – Lens flare from oncoming headlights, credit: [https://s.blogcdn.com/cars.aol.co.uk/media/2011/02/headlights-450-a-g.jpg](https://s.blogcdn.com/cars.aol.co.uk/media/2011/02/headlights-450-a-g.jpg)'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.17 – 迎面车灯产生的镜头眩光，来源：[https://s.blogcdn.com/cars.aol.co.uk/media/2011/02/headlights-450-a-g.jpg](https://s.blogcdn.com/cars.aol.co.uk/media/2011/02/headlights-450-a-g.jpg)
- en: Lens distortion
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 镜头畸变
- en: 'This is the difference between the rectilinear or real scene to what your camera
    image sees. If you have ever seen action camera footage, you probably recognized
    the "fish-eye" lens effect. The following figure shows an extreme example of the
    distortion from a wide-angle lens. You will learn to correct this distortion with
    OpenCV:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 这是直线或真实场景与你的相机图像所看到场景之间的区别。如果你曾经看过动作相机的视频，你可能已经注意到了“鱼眼”镜头效果。以下图示显示了广角镜头的极端畸变示例。你将学会如何使用OpenCV来纠正这种畸变：
- en: '![Figure 1.18 – Lens distortion, credit: https://www.slacker.xyz/post/what-lens-should-i-get](img/Figure_1.18_B16322.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![图1.18 – 镜头畸变，来源：https://www.slacker.xyz/post/what-lens-should-i-get](img/Figure_1.18_B16322.jpg)'
- en: 'Figure 1.18 – Lens distortion, credit: [https://www.slacker.xyz/post/what-lens-should-i-get](https://www.slacker.xyz/post/what-lens-should-i-get)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.18 – 镜头畸变，来源：[https://www.slacker.xyz/post/what-lens-should-i-get](https://www.slacker.xyz/post/what-lens-should-i-get)
- en: The components of a camera
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相机的组成部分
- en: Like the eye, a camera is made up of a light-sensitive array, an aperture, and
    a lens.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 就像眼睛一样，相机由光敏感阵列、光圈和镜头组成。
- en: Light sensitive array – CMOS sensor (the camera's retina)
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 光敏感阵列 – CMOS传感器（相机的视网膜）
- en: The light-sensitive array, in most consumer cameras, is called a CMOS active-pixel
    sensor (or just a sensor). Its basic function is to convert incident photons into
    an electrical current that can be digitized based on the color wavelength of the
    photon.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数消费级相机中，光敏感阵列被称为CMOS有源像素传感器（或简称传感器）。其基本功能是将入射光子转换为电信号，该信号可以根据光子的颜色波长进行数字化。
- en: The aperture (the camera's iris)
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 光圈（相机的光圈）
- en: The aperture or iris of a camera is the opening through which light can pass
    on its way to the sensor. This can be variable or fixed depending on the type
    of camera you are using. The aperture is used to control parameters such as depth
    of field and the amount of light hitting the sensor.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 相机的光圈或瞳孔是光线通往传感器的通道。这可以是可变的或固定的，具体取决于你使用的相机类型。光圈用于控制诸如景深和到达传感器的光线量等参数。
- en: The lens (the camera's lens)
  id: totrans-302
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 镜头（相机的镜头）
- en: The lens or optics are the components of the camera that focus the light from
    the environment onto the sensor. The lens primarily determines the **FoV** of
    the camera through its focal length. In self-driving applications, the FoV is
    very important since it determines how much of the environment the car can see
    with a single camera. The optics of a camera are often some of the most expensive
    parts and have a large impact on image quality and lens flare.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 镜头或光学元件是相机将环境中的光线聚焦到传感器上的组成部分。镜头主要通过其焦距决定相机的**视场角（FoV）**。在自动驾驶应用中，视场角非常重要，因为它决定了汽车单次使用一个摄像头可以看到多少环境。相机的光学元件通常是成本最高的部分之一，并对图像质量和镜头眩光有重大影响。
- en: Considerations for choosing a camera
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择相机的考虑因素
- en: 'Now that you have learned all the basics of what a camera is and the relevant
    terminology, it is time to learn how to choose a camera for your self-driving
    application. The following is a list of the primary factors that you will need
    to balance when choosing a camera:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了摄像头的基本知识和相关术语，是时候学习如何为自动驾驶应用选择摄像头了。以下是在选择摄像头时你需要权衡的主要因素列表：
- en: Resolution
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分辨率
- en: FoV
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视场角（FoV）
- en: Dynamic range
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态范围
- en: Cost
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本
- en: Size
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尺寸
- en: Ingress protection (IP rating)
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防护等级（IP等级）
- en: The perfect camera
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完美的摄像头
- en: If you could design the ideal camera, what would it be?
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你能设计出理想的摄像头，那会是什么样子？
- en: My perfect self-driving camera would be able to see in all directions (spherical
    FoV, 360º HFoV x 360º VFoV). It would have infinite resolution and dynamic range,
    so you could digitally resolve objects at any distance in any lighting condition.
    It would be the size of a grain of rice, completely water- and dustproof, and
    would cost $5! Obviously, this is not possible. So, we must make some careful
    trade-offs for what we need.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我理想的自动驾驶摄像头将能够从所有方向（球形视场角，360º HFoV x 360º VFoV）看到。它将具有无限的分辨率和动态范围，因此你可以在任何距离和任何光照条件下以数字方式解析物体。它的大小将和一粒米一样，完全防水防尘，并且只需5美元！显然，这是不可能的。因此，我们必须对我们所需的东西做出一些谨慎的权衡。
- en: The best place to start is with your budget for cameras. This will give you
    an idea of what models and specifications to look for.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 从你的摄像头预算开始是最好的起点。这将给你一个关于要寻找哪些型号和规格的想法。
- en: 'Next, consider what you need to see for your application:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，考虑你的应用需要看到什么：
- en: Do you need to be able to see a child from 200 m away while traveling at 100
    km/h?
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你以100 km/h的速度行驶时，你是否需要从200米外看到孩子？
- en: What coverage around the vehicle do you need, and can you tolerate any blind
    spots on the side of the vehicle?
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要覆盖车辆周围多大的范围，你能否容忍车辆侧面的盲点？
- en: Do you need to see at night and during the day?
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要在夜间和白天都能看到吗？
- en: 'Lastly, consider how much room you have to integrate these cameras. You probably
    don''t want your vehicle to look like this:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，考虑你有多少空间来集成这些摄像头。你可能不希望你的车辆看起来像这样：
- en: '![Figure 1.19 – Camera art, credit: https://www.flickr.com/photos/laughingsquid/1645856255/](img/Figure_1.19_B16322.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![图1.19 – 摄像头艺术，来源：https://www.flickr.com/photos/laughingsquid/1645856255/](img/Figure_1.19_B16322.jpg)'
- en: 'Figure 1.19 – Camera art, credit: [https://www.flickr.com/photos/laughingsquid/1645856255/](https://www.flickr.com/photos/laughingsquid/1645856255/)'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.19 – 摄像头艺术，来源：[https://www.flickr.com/photos/laughingsquid/1645856255/](https://www.flickr.com/photos/laughingsquid/1645856255/)
- en: This may be very overwhelming, but it is important when thinking about how to
    design your computer vision system. A good camera to start with that is very popular
    is the FLIR Blackfly S series. They strike an excellent balance of resolution,
    FPS, and cost. Next, pair it with a lens that meets your FoV needs. There are
    some helpful FoV calculators available on the internet, such as the one from [http://www.bobatkins.com/photography/technical/field_of_view.html](http://www.bobatkins.com/photography/technical/field_of_view.html).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能非常令人不知所措，但在思考如何设计你的计算机视觉系统时，这一点非常重要。一个很好的起点是FLIR Blackfly S系列，它非常受欢迎，在分辨率、帧率（FPS）和成本之间取得了极佳的平衡。接下来，搭配一个满足你视场角（FoV）需求的镜头。互联网上有一些有用的视场角计算器，例如来自[http://www.bobatkins.com/photography/technical/field_of_view.html](http://www.bobatkins.com/photography/technical/field_of_view.html)的计算器。
- en: Strengths and weaknesses of cameras
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摄像头的优缺点
- en: Now, no sensor is perfect, and even your beloved camera will have its pros and
    cons. Let's go over some of them now.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，没有任何传感器是完美的，即使是你的心头好摄像头也会有它的优点和缺点。让我们现在就来看看它们。
- en: 'Let''s look at the strengths first:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看它的优势：
- en: '**High-resolution**: Relative to other sensor types, such as radar, lidar,
    and sonar, cameras have an excellent resolution for picking out objects in your
    scene. You can easily find cameras with 5 MP resolution quite cheaply.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高分辨率**：与其他传感器类型（如雷达、激光雷达和声纳）相比，摄像头在场景中识别物体时具有出色的分辨率。你很容易就能以相当低的价格找到具有500万像素分辨率的摄像头。'
- en: '**Texture, color, and contrast information**: Cameras provide very rich information
    about the environment that other sensor types just can''t. This is because of
    a variety of wavelengths that cameras sense.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**纹理、颜色和对比度信息**：摄像头提供了其他传感器类型无法比拟的关于环境的丰富信息。这是因为摄像头能够感知多种波长的光。'
- en: '**Cost**: Cameras are one of the cheapest sensors you can find, especially
    for the quality of data they provide.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本**：摄像头是你能找到的性价比最高的传感器之一，尤其是考虑到它们提供的数据质量。'
- en: '**Size**: CMOS technology and modern ASICs have made cameras incredibly small,
    many less than 30 mm cubed.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尺寸**：CMOS技术和现代ASIC技术使得相机变得非常小，许多小于30立方毫米。'
- en: '**Range**: This is really thanks to the high resolution and passive nature
    of the sensor.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**范围**：这主要归功于高分辨率和传感器的被动性质。'
- en: 'Next, here are the weaknesses:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，这里有一些弱点：
- en: '**A large amount of data to process for object detection**: With high resolution
    comes a lot of data. Such is the price we pay for such accurate and detailed imagery.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大量数据处理用于物体检测**：随着分辨率的提高，数据量也随之增加。这就是我们为了如此精确和详细的图像所付出的代价。'
- en: '**Passive**: A camera requires an external illumination source, such as the
    sun, headlights, and so on.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**被动**：相机需要一个外部照明源，如太阳、车头灯等。'
- en: '**Obscurants (such as bugs, raindrops, heavy fog, dust, or snow)**: A camera
    is not particularly good at seeing through heavy rain, fog, dust, or snow. Radars
    are typically better suited for this.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遮蔽物（如昆虫、雨滴、浓雾、灰尘或雪）**：相机在穿透大雨、雾、灰尘或雪方面并不特别擅长。雷达通常更适合这项任务。'
- en: '**Lack native depth/velocity information**: A camera image alone doesn''t give
    you any information on an object''s speed or distance.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏原生深度/速度信息**：仅凭相机图像本身无法提供关于物体速度或距离的任何信息。'
- en: Photogrammetry is helping to bolster this weakness but costs valuable processing
    resources (GPU, CPU, latency, and so on.) It is also less accurate than a radar
    or lidar sensor, which produce this information natively.
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测绘学正在帮助弥补这一弱点，但代价是宝贵的处理资源（GPU、CPU、延迟等）。它也比雷达或激光雷达传感器产生的信息准确性低。
- en: Now that you have a good understanding of how a camera works, as well as its
    basic parts and terminology, it's time to get your hands dirty and start calibrating
    a camera with OpenCV.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经很好地理解了相机的工作原理，以及其基本部分和术语，是时候动手使用OpenCV校准相机了。
- en: Camera calibration with OpenCV
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用OpenCV进行相机校准
- en: In this section, you will learn how to take objects with a known pattern and
    use them to correct lens distortion using OpenCV.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何使用已知模式的物体，并使用OpenCV来纠正镜头扭曲。
- en: Remember the lens distortion we talked about in the previous section? You need
    to correct this to ensure you accurately locate where objects are relative to
    your vehicle. It does you no good to see an object if you don't know whether it
    is in front of you or next to you. Even good lenses can distort the image, and
    this is particularly true for wide-angle lenses. Luckily, OpenCV provides a mechanism
    to detect this distortion and correct it!
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们在上一节中提到的镜头扭曲吗？您需要纠正这一点，以确保您能够准确地定位物体相对于车辆的位置。如果您不知道物体是在您前面还是旁边，那么看到物体对您没有任何好处。即使是好的镜头也可能扭曲图像，这尤其适用于广角镜头。幸运的是，OpenCV提供了一个检测这种扭曲并纠正它的机制！
- en: The idea is to take pictures of a chessboard, so OpenCV can use this high-contrast
    pattern to detect the position of the points and compute the distortion based
    on the difference between the expected image and the recorded one.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 策略是拍摄棋盘的图片，这样OpenCV就可以使用这种高对比度图案来检测点的位置，并根据预期图像与记录图像之间的差异来计算扭曲。
- en: 'You need to provide several pictures at different orientations. It might take
    some experiments to find a good set of pictures, but 10 to 20 images should be
    enough. If you use a printed chessboard, take care to have the paper as flat as
    possible so as to not compromise the measurements:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要提供几张不同方向的图片。可能需要一些实验来找到一组好的图片，但10到20张图片应该足够了。如果您使用的是打印的棋盘，请确保纸张尽可能平整，以免影响测量：
- en: '![Figure 1.20 – Some examples of pictures that can be used for calibration](img/Figure_1.20_B16322.jpg)'
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![图1.20 – 一些可用于校准的图片示例](img/Figure_1.20_B16322.jpg)'
- en: Figure 1.20 – Some examples of pictures that can be used for calibration
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.20 – 一些可用于校准的图片示例
- en: As you can see, the central image clearly shows some barrel distortion.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，中心图像清楚地显示了某些桶形扭曲。
- en: Distortion detection
  id: totrans-347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扭曲检测
- en: OpenCV tries to map a series of three-dimensional points to the two-dimensional
    coordinates of the camera. OpenCV will then use this information to correct the
    distortion.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV试图将一系列三维点映射到相机的二维坐标。然后，OpenCV将使用这些信息来纠正扭曲。
- en: 'The first thing to do is to initialize some structures:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 首件事是初始化一些结构：
- en: '[PRE38]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Please note `nX` and `nY`, which are the number of points to find in the chessboard
    on the `x` and `y` axes,, respectively. In practice, this is the number of squares
    minus 1.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意`nX`和`nY`，它们分别是`x`和`y`轴上棋盘上要找到的点数。在实践中，这是方格数减1。
- en: 'Then, we need to call `findChessboardCorners()`:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要调用`findChessboardCorners()`：
- en: '[PRE39]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '`found` is true if OpenCV found the points, and `corners` will contain the
    points found.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 如果OpenCV找到了点，则`found`为真，`corners`将包含找到的点。
- en: In our code, we will assume that the image has been converted into grayscale,
    but you can calibrate using an RGB picture as well.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码中，我们将假设图像已经被转换为灰度图，但您也可以使用RGB图片进行校准。
- en: 'OpenCV provides a nice image depicting the corners found, ensuring that the
    algorithm is working properly:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV提供了一个很好的图像，展示了找到的角点，确保算法正在正常工作：
- en: '[PRE40]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Let''s see the resulting image:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看结果图像：
- en: '![Figure 1.21 – Corners of the calibration image found by OpenCV](img/Figure_1.21_B16322.jpg)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![图1.21 – OpenCV找到的校准图像的角点](img/Figure_1.21_B16322.jpg)'
- en: Figure 1.21 – Corners of the calibration image found by OpenCV
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.21 – OpenCV找到的校准图像的角点
- en: Calibration
  id: totrans-361
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校准
- en: 'After finding the corners in several images, we are finally ready to generate
    the calibration data using `calibrateCamera()`:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 在几幅图像中找到角点后，我们最终可以使用`calibrateCamera()`生成校准数据。
- en: '[PRE41]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, we are ready to correct our images, using `undistort()`:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备使用`undistort()`校正我们的图像：
- en: '[PRE42]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Let''s see the result:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看结果：
- en: '![Figure 1.22 – Original image and calibrated image](img/Figure_1.22_B16322.jpg)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![图1.22 – 原始图像和校准图像](img/Figure_1.22_B16322.jpg)'
- en: Figure 1.22 – Original image and calibrated image
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.22 – 原始图像和校准图像
- en: We can see that the second image has less barrel distortion, but it is not great.
    We probably need more and better calibration samples.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，第二张图像的桶形畸变较少，但并不理想。我们可能需要更多和更好的校准样本。
- en: 'But we can also try to get more precision from the same calibration images
    by looking for `cornerSubPix()` after `findChessboardCorners()`:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们也可以通过在`findChessboardCorners()`之后寻找`cornerSubPix()`来尝试从相同的校准图像中获得更高的精度：
- en: '[PRE43]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The following is the resulting image:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为结果图像：
- en: '![Figure 1.23 – Image calibrated with sub-pixel precision](img/Figure_1.23_B16322.jpg)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![图1.23 – 使用亚像素精度校准的图像](img/Figure_1.23_B16322.jpg)'
- en: Figure 1.23 – Image calibrated with sub-pixel precision
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.23 – 使用亚像素精度校准的图像
- en: As the complete code is a bit long, I recommend checking out the full source
    code on GitHub.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 由于完整的代码有点长，我建议您在GitHub上查看完整的源代码。
- en: Summary
  id: totrans-376
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Well, you have had a great start to your computer vision journey toward making
    a real self-driving car.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，你在通往制作真正自动驾驶汽车的计算机视觉之旅中已经取得了很好的开端。
- en: You learned about a very useful toolset called OpenCV with bindings for Python
    and NumPy. With these tools, you are now able to create and import images using
    methods such as `imread()`, `imshow()`, `hconcat()`, and `vconcat()`. You learned
    how to import and create video files, as well as capturing video from a webcam
    with methods such as `VideoCapture()` and `VideoWriter()`. Watch out Spielberg,
    there is a new movie-maker in town!
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 你了解了一个非常有用的工具集，称为OpenCV，它为Python和NumPy提供了绑定。有了这些工具，你现在可以使用`imread()`、`imshow()`、`hconcat()`和`vconcat()`等方法创建和导入图像。你学会了如何导入和创建视频文件，以及使用`VideoCapture()`和`VideoWriter()`方法从摄像头捕获视频。小心，斯皮尔伯格，镇上来了一个新的电影制作人！
- en: It was wonderful to be able to import images, but how do you start manipulating
    them to help your computer vision algorithms learn what features matter? You learned
    how to do this through methods such as `flip()`, `blur()`, `GaussianBlur()`, `medianBlur()`,
    `bilateralFilter()`, and `convertScaleAbs()`. Then, you learned how to annotate
    images for human consumption with methods such as `rectangle()` and `putText()`.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 能够导入图像是件好事，但如何开始操作它们以帮助你的计算机视觉算法学习哪些特征很重要呢？你通过`flip()`、`blur()`、`GaussianBlur()`、`medianBlur()`、`bilateralFilter()`和`convertScaleAbs()`等方法学会了如何这样做。然后，你学会了如何使用`rectangle()`和`putText()`等方法为人类消费标注图像。
- en: Then came the real magic, where you learned how to take the images and do your
    first piece of real computer vision using HOG to detect pedestrians. You learned
    how to apply a sliding window to scan the detector over an image in various sized
    windows using the `detectMultiScale()` method, with parameters such as `winStride`,
    `padding`, `scale`, `hitThreshold`, and `finalThreshold`.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，真正的魔法出现了，你学会了如何使用HOG检测行人来处理图像并完成你的第一个真正的计算机视觉项目。你学会了如何使用`detectMultiScale()`方法在图像上以不同大小的窗口滑动窗口来扫描检测器，使用参数如`winStride`、`padding`、`scale`、`hitThreshold`和`finalThreshold`。
- en: You had a lot of fun with all the new tools you learned for working with images.
    But there was something missing. How do I get these images on my self-driving
    car? To answer this, you learned about the camera and its basic terminology, such
    as **resolution**, **FoV**, **focal length**, **aperture**, **DoF**, **dynamic
    range**, **ISO**, **frame rate**, **lens flare**, and finally, **lens distortion**.
    Then, you learned the basic components that comprise a camera, namely the lens,
    aperture, and light-sensitive arrays. With these basics, you moved on to some
    considerations for choosing a camera for your application by learning about the
    strengths and weaknesses of a camera.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 你在使用图像处理的新工具时玩得很开心。但似乎还缺少了什么。我该如何将这些图像应用到我的自动驾驶汽车上？为了回答这个问题，你学习了关于相机及其基本术语，例如**分辨率**、**视场角**、**焦距**、**光圈**、**景深**、**动态范围**、**ISO**、**帧率**、**镜头眩光**，以及最后的**镜头畸变**。然后，你学习了组成相机的基本组件，即镜头、光圈和光敏阵列。有了这些基础知识，你继续学习如何根据相机的优缺点来选择适合你应用的相机。
- en: Armed with this knowledge, you boldly began to remove one of these weaknesses,
    lens distortion, with the tools you learned in OpenCV for distortion correction.
    You used methods such as `findChessboardCorners()`, `calibrateCamera()`, `undistort()`,
    and `cornerSubPix()` for this.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 带着这些知识，你勇敢地开始使用在OpenCV中学习的畸变校正工具来消除这些弱点之一，即镜头畸变。你使用了`findChessboardCorners()`、`calibrateCamera()`、`undistort()`和`cornerSubPix()`等方法来完成这项工作。
- en: Wow, you are really on your way to being able to perceive the world in your
    self-driving application. You should take a moment and be proud of what you have
    learned so far. Maybe you can celebrate with a selfie and apply some of what you
    learned!
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，你真的在朝着能够在自动驾驶应用中感知世界的方向前进。你应该花点时间为自己到目前为止所学到的感到自豪。也许你可以通过自拍来庆祝，并应用一些你所学的知识！
- en: In the next chapter, you are going to learn about some of the basic signal types
    and protocols you are likely to encounter when trying to integrate sensors in
    your self-driving application.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习一些基本信号类型和协议，这些类型和协议在你尝试将传感器集成到自动驾驶应用中时可能会遇到。
- en: Questions
  id: totrans-385
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Can OpenCV take advantage of hardware acceleration?
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenCV能否利用硬件加速？
- en: What's the best blurring method if CPU power is not a problem?
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果CPU性能不是问题，最好的模糊方法是什么？
- en: Which detector can be used to find pedestrians in an image?
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个检测器可以用来在图像中找到行人？
- en: How can you read the video stream from a webcam?
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你该如何从网络摄像头中读取视频流？
- en: What is the trade-off between aperture and depth of field?
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 光圈和景深之间的权衡是什么？
- en: When do you need a high ISO?
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在什么情况下你需要高ISO？
- en: Is it worth computing sub-pixel precision for camera calibration?
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为相机校准计算亚像素精度值得吗？
