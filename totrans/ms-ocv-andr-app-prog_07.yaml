- en: Chapter 7. Bringing Your Apps to Life with OpenCV Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 使用OpenCV机器学习让您的应用生动起来
- en: With so much data around us, we need better systems and applications to process
    it and extract relevant information out of it. A field of computer science that
    deals with this is **machine learning**. In this chapter, we will take a look
    at the different machine learning techniques that can be used to exploit all the
    data around us and build smart applications that can deal with unencountered situations
    or scenarios, without any form of human intervention.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们周围有如此多的数据，我们需要更好的系统和应用程序来处理它们，并从中提取相关信息。处理这一问题的计算机科学领域是**机器学习**。在本章中，我们将探讨可以用来利用我们周围的所有数据并构建能够处理未遇到的情况或场景的智能应用程序的不同机器学习技术，而不需要任何形式的人类干预。
- en: In the recent years, computer vision and machine learning have formed a strong
    synergy between them, thus enabling technologies that have helped build some extremely
    efficient and useful applications. Humanoids, robotic arms, and assembly lines
    are some of the examples where computer vision and machine learning find applications.
    Developers and researchers are now trying to exploit mobile platforms and build
    light-weight applications that can be used by common people. In the following
    section, we will build an application for **Optical Character Recognition** (**OCR**)
    using standard OpenCV and Android APIs. Toward the end, we will revisit the Sudoku
    solving application that we started developing in [Chapter 2](ch02.html "Chapter 2. Detecting
    Basic Features in Images"), *Detecting Basic Features in Images*.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，计算机视觉和机器学习之间形成了强大的协同作用，从而使得一些极其高效和有用的技术得以实现。类人机器人、机械臂和装配线是计算机视觉和机器学习应用的一些例子。开发者和研究人员现在正试图利用移动平台构建轻量级的应用程序，供普通人使用。在下一节中，我们将使用标准的OpenCV和Android
    API构建一个用于**光学字符识别**（**OCR**）的应用程序。在结尾部分，我们将回顾我们在[第2章](ch02.html "第2章. 图像中的基本特征检测")中开始开发的应用程序——*图像中的基本特征检测*。
- en: We will understand the machine learning techniques alongside building applications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在构建应用程序的同时理解机器学习技术。
- en: Optical Character Recognition
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 光学字符识别
- en: '**Optical Character Recognition** (**OCR**) is one of the favorite topics of
    research in computer vision and machine learning. There are a lot of efficient
    off-the-shelf implementations and algorithms readily available for OCR, but for
    better understanding of the concepts, we will build our own OCR Android application.
    Before we get down to writing the code for our application, let''s take some time
    to take a look at the different character recognition techniques and how they
    work. In this chapter, we will use two standard machine learning techniques: **k-nearest
    neighbors** (**KNN**) and **Support Vector Machines** (**SVM**), while building
    our applications.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**光学字符识别**（**OCR**）是计算机视觉和机器学习中最受欢迎的研究主题之一。对于OCR，有许多现成的有效实现和算法可供选择，但为了更好地理解概念，我们将构建自己的OCR
    Android应用程序。在我们开始编写应用程序的代码之前，让我们花一些时间来了解一下不同的字符识别技术及其工作原理。在本章中，我们将使用两种标准的机器学习技术：**k最近邻**（**KNN**）和**支持向量机**（**SVM**），来构建我们的应用程序。'
- en: The aim of this chapter is to build a real-time digit recognition application.
    The application will have a live camera output being displayed on the mobile screen
    and as soon as the camera captures a digit, we will recognize the digit.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是构建一个实时数字识别应用程序。该应用程序将在移动屏幕上显示实时摄像头输出，一旦摄像头捕捉到一个数字，我们就会识别该数字。
- en: OCR using k-nearest neighbors
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用k最近邻进行OCR
- en: k-nearest neighbors is the one of the simplest algorithms used for supervised
    classification. In KNN, we give the training dataset and their corresponding labels
    as input. An n-dimensional space is created (where *n* is the length of each training
    data) and every training data is plotted as a point in it. While classification,
    we plot the data to be classified in the same n-dimensional space, and calculate
    the distance of that point from every other point in the space. The distance computed
    is used to find an appropriate class for the testing data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: k最近邻是用于监督分类的最简单算法之一。在KNN中，我们提供训练数据集及其相应的标签作为输入。创建一个n维空间（其中*n*是每个训练数据的长度），并将每个训练数据点绘制在该空间中。在分类过程中，我们将要分类的数据绘制到相同的n维空间中，并计算该点与空间中其他点的距离。计算出的距离用于为测试数据找到一个合适的类别。
- en: 'Here is a step–by-step explanation of the working of the algorithm:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是算法工作步骤的逐步解释：
- en: Choose a user-defined value of *k*.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择用户定义的*k*值。
- en: Store the training data along with their classes in the form of a row vector.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练数据及其类别以行向量的形式存储。
- en: Take the input query (data to be classified) and calculate the distance from
    it to every other row vector in the training data (meaning of distance is explained
    in the following box).
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入查询（待分类的数据）与训练数据中的每个行向量之间的距离计算出来（距离的含义将在下面的框中解释）。
- en: Sort all the row vectors in the ascending order of their distance (calculated
    in the previous step) from the query data.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照查询数据（在上一步计算的距离）的升序对所有的行向量进行排序。
- en: Finally, from the first *k* sorted row vectors, choose the class (training labels),
    which has the majority of row vectors as the predicted class.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，从第一个*k*个排序后的行向量中选择具有多数行向量的类别（训练标签），作为预测类别。
- en: Note
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Distance between vectors**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**向量之间的距离**'
- en: 'In Euclidean Space, we define the distance between two vectors as:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在欧几里得空间中，我们定义两个向量之间的距离如下：
- en: '![OCR using k-nearest neighbors](img/B02052_07_03.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![使用k最近邻进行OCR](img/B02052_07_03.jpg)'
- en: where, *xi* and *yi* are the *i^(th)* dimension values of the two vectors *x*
    and *y* respectively. *n* is the length of the training vectors (*x* and *y* in
    our case). The algorithm does not put any restriction on the type of distance
    we can use. Some other types of distances that we can use are **Manhattan distance**,
    Maximum distance and the likes. Refer to [http://en.wikipedia.org/wiki/Distance](http://en.wikipedia.org/wiki/Distance)
    for some other definitions of distance.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*xi*和*yi*分别是两个向量*x*和*y*的第*i*个维度值。*n*是训练向量（在我们的例子中是*x*和*y*）的长度。该算法不对我们可以使用的距离类型施加任何限制。我们可以使用的其他一些距离类型包括**曼哈顿距离**、最大距离等。有关其他距离定义，请参阅[http://en.wikipedia.org/wiki/Distance](http://en.wikipedia.org/wiki/Distance)。
- en: Simple enough! How do we use it with image data? For us to be able to use KNN
    on the image data, we need to convert the training images to some sort of a row
    vector.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 简单到极点！我们如何使用它来处理图像数据？为了能够使用KNN处理图像数据，我们需要将训练图像转换为某种行向量。
- en: Consider a 10x10 grayscale image of any digit from one to nine. The easiest
    and the fastest way to get a feature vector from the 10x10 image is to convert
    it into a 1x100 row vector. This can be done by appending the rows in the image
    one after another. This way, we can convert all the images in our training set
    to row vectors for later use in the KNN classifier.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个10x10的灰度图像，该图像可以是1到9中的任意一个数字。从10x10图像中获取特征向量的最简单和最快的方法是将它转换成一个1x100的行向量。这可以通过将图像中的行依次连接起来完成。这样，我们可以将训练集中的所有图像转换为行向量，以便以后在KNN分类器中使用。
- en: 'To make it easier for us to build the digit recognition application, we will
    break it down into smaller parts listed as follows and finally use them together:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使我们能够构建数字识别应用程序，我们将将其分解为以下列出的较小部分，并最终将它们组合在一起：
- en: Making a camera application
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制作相机应用程序
- en: Handling the training data
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理训练数据
- en: Recognizing the captured digit
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别捕获的数字
- en: Making a camera application
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 制作相机应用程序
- en: 'We will begin by building a simple camera application that displays the camera
    output on the screen, as we did in [Chapter 4](ch04.html "Chapter 4. Drilling
    Deeper into Object Detection – Using Cascade Classifiers"), *Drilling Deeper into
    Object Detection – Using Cascade Classifiers*:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先构建一个简单的相机应用程序，该程序在屏幕上显示相机输出，就像我们在[第4章](ch04.html "第4章. 深入对象检测 - 使用级联分类器")中做的那样，*深入对象检测
    - 使用级联分类器*：
- en: Create a new Android project in Eclipse (or Android Studio)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Eclipse（或Android Studio）中创建一个新的Android项目
- en: Initialize OpenCV in the project (refer to [Chapter 1](ch01.html "Chapter 1. Applying
    Effects to Images"), *Applying Effects to Images*).
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在项目中初始化OpenCV（参考[第1章](ch01.html "第1章. 应用图像效果")，*应用图像效果*）。
- en: 'Add `JavaCameraView` to the main activity using the following code snippet:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下代码片段将`JavaCameraView`添加到主活动：
- en: '[PRE0]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once the camera is in place, draw a square on the screen that will help the
    user to localize the digit that he/she wants to recognize. The user will point
    to the digit and try to bring it within the square drawn on the screen (as shown
    in Figure 1). Copy the following piece of code in the Mat `onCameraFrame()` function:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦相机就位，在屏幕上画一个方框，这将帮助用户定位他/她想要识别的数字。用户将指向该数字并尝试将其带入屏幕上画出的方框内（如图1所示）。将以下代码片段复制到Mat
    `onCameraFrame()`函数中：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this code, we take the size of the frame captured by the mobile camera and
    draw a 400x400 (can vary according to the screen size) white rectangle in the
    center of the image (as shown in Figure 1). That's it. The camera application
    is ready. Next, is handling the training data in the application.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，我们取移动摄像头捕获的帧的大小，并在图像中心绘制一个 400x400（可根据屏幕大小调整）的白色矩形（如图 1 所示）。就这样。相机应用就准备好了。接下来，是处理应用中的训练数据。
- en: '![Making a camera application](img/B02052_07_01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![制作相机应用](img/B02052_07_01.jpg)'
- en: Figure 1\. Screenshot of the camera application
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1. 相机应用截图
- en: Handling the training data
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理训练数据
- en: This is the trickiest part of the application. Training data plays a crucial
    role in any machine learning application. The amount of data that such applications
    deal with is usually in the order of few megabytes. This may not be a concern
    for a normal desktop application, but for a mobile application (because of resource
    constraints), even handling around 50 megabytes can lead to performance issues,
    if not done properly. The code needs to be concise, to the point, and should have
    minimum memory leaks.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是应用程序中最复杂的一部分。训练数据在任何机器学习应用中都起着至关重要的作用。此类应用处理的数据量通常在几兆字节左右。对于普通桌面应用来说，这可能不是问题，但对于移动应用（由于资源限制），即使正确处理约
    50 兆字节的数据也可能导致性能问题。代码需要简洁、直接，并且应尽量减少内存泄漏。
- en: For this application, we will make use of a publically available handwritten
    digits dataset —MNIST, to train the KNN classifier.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此应用，我们将使用公开可用的手写数字数据集——MNIST 来训练 KNN 分类器。
- en: Note
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The MNIST database ([http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/))
    of handwritten digits available from this page, has a training set of 60,000 examples
    and a test set of 10,000 examples. It is a subset of a larger set available from
    MNIST. The digits have been size-normalized and centered in a fixed-size image.
    (Text taken from Prof. Yann LeCun's web page, which is available at [http://yann.lecun.com](http://yann.lecun.com).)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 从此页面提供的 MNIST 手写数字数据库 ([http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/))
    包含 60,000 个示例的训练集和 10,000 个示例的测试集。它是 MNIST 可用的大集合的一个子集。数字已被尺寸归一化并居中在固定大小的图像中。（文本摘自
    Yann LeCun 教授的网页，该网页可在 [http://yann.lecun.com](http://yann.lecun.com) 上找到。）
- en: 'First, download the MNIST training data using the following links:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用以下链接下载 MNIST 训练数据：
- en: Training images at [http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz](http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz)
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练图像位于 [http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz](http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz)
- en: Training labels at [http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz](http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练标签位于 [http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz](http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz)
- en: Extract the downloaded files and transfer them to an Android phone (make sure
    you have around 60 MB of free space available).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 提取下载的文件并将它们传输到 Android 手机上（确保你有大约 60 MB 的可用空间）。
- en: Getting back to our application, create a new `DigitRecognizer` class that will
    handle all the tasks related to digit recognition, including loading the dataset
    into the application, training the classifier, and finally, recognizing the digit.
    Add a new Java class to the project and name it `DigitRecognizer`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的应用，创建一个新的 `DigitRecognizer` 类，该类将处理与数字识别相关的所有任务，包括将数据集加载到应用中、训练分类器以及最终识别数字。将一个新的
    Java 类添加到项目中，并将其命名为 `DigitRecognizer`。
- en: So, we already have the training images and training labels stored in the phone.
    We need to load the data into the application. For this, all we have to do is
    read the data from these files and make them compatible with OpenCV's API.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经在手机中存储了训练图像和训练标签。我们需要将这些数据加载到应用中。为此，我们只需从这些文件中读取数据，并使其与 OpenCV 的 API
    兼容。
- en: 'Add a new function void `ReadMNISTData()` to the `DigitRecognizer` class created
    earlier. This function will read the MNIST dataset and store it in the form of
    a Mat (OpenCV''s class to store images). Read the dataset in two parts: first,
    the training images and then the training labels.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前创建的 `DigitRecognizer` 类中添加一个新的函数 `void ReadMNISTData()`。这个函数将读取 MNIST 数据集并以
    Mat（OpenCV 存储图像的类）的形式存储。将数据集分为两部分读取：首先，训练图像，然后是训练标签。
- en: 'In `ReadMNISTData()`, create a new `File` object that will store the path to
    the phone''s SD card (as shown in the following code). In case the file is in
    the phone''s internal memory, skip this step and provide an absolute path of the
    file that we wish to use later in the code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ReadMNISTData()`中，创建一个新的`File`对象，它将存储手机SD卡的路径（如下所示）。如果文件在手机的内部存储中，则跳过此步骤，并提供我们希望在代码中稍后使用的文件的绝对路径：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'After doing this, create another `File` object that will point to the exact
    file that we want to read in our application, and an `InputStreamReader` object
    that will help us in reading the file:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些操作后，创建另一个`File`对象，它将指向我们希望在应用程序中读取的确切文件，以及一个`InputStreamReader`对象，它将帮助我们读取文件：
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here, `images_path` is the absolute path of the `train-images-idx3-ubyte.idx3`
    training images file.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`images_path`是`train-images-idx3-ubyte.idx3`训练图像文件的绝对路径。
- en: 'Before we continue with the code, we need to understand how images are stored
    in the file. Here is the description of the contents of the training images file:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续编写代码之前，我们需要了解图像是如何存储在文件中的。以下是训练图像文件内容的描述：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Pixels are organized row-wise. Pixel values are 0 to 255, where 0 represents
    the background (white) and 255 represents the foreground (black).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 像素按行组织。像素值从0到255，其中0表示背景（白色），255表示前景（黑色）。
- en: 'With this information, we can continue writing the code:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些信息，我们可以继续编写代码：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the preceding code, first, we read the first 16 bytes of the file, which
    stores the number of images, height, and width of the images (refer to the aforementioned
    table describing the contents of the file). Using the `ByteBuffer` class, we get
    four integers from the 16 bytes by combining four bytes, one each for an integer.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，首先读取文件的前16个字节，这些字节存储了图像的数量、高度和宽度（参考上述描述文件内容的表格）。通过组合四个字节，每个整数一个字节，使用`ByteBuffer`类从16个字节中获取四个整数。
- en: In OpenCV, KNN's implementation requires us to pass all the feature vectors
    using the Mat class. Every training image needs to be converted to a row vector
    that will form one row of the Mat object, which will be passed to the KNN classifier.
    For example, if we have 5,000 training images each with dimensions 20x20, we will
    need a Mat object with dimensions 5000x400 that can be passed to OpenCV's KNN
    training function. Confused? Continue reading!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中，KNN的实现要求我们使用Mat类传递所有特征向量。每个训练图像都需要被转换为一个行向量，这将形成Mat对象的行，然后传递给KNN分类器。例如，如果我们有5,000个训练图像，每个图像的尺寸为20x20，我们需要一个5000x400维度的Mat对象，可以传递给OpenCV的KNN训练函数。困惑了吗？继续阅读！
- en: Take a 20x20 image from the training dataset and convert it to a 1x400 vector
    by appending rows one after another. Do this for all the images. At the end, we
    will have 5,000 such 1x400 vectors. Now, create a new Mat object with dimensions
    5000x400, and each row of this new Mat object will be the 1x400 vector that we
    got just now by resizing the original images in the dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练数据集中取一个20x20的图像，并将其通过逐行追加的方式转换为1x400的向量。对所有图像都这样做。最后，我们将拥有5,000个这样的1x400向量。现在，创建一个新的Mat对象，其维度为5000x400，这个新Mat对象的每一行都将是我们刚才通过调整数据集中原始图像的大小而获得的1x400向量。
- en: 'This is what the preceding piece of code intends to do. First, read all the
    pixels in an image using the following code:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是前面那段代码想要做的。首先，使用以下代码读取图像中的所有像素：
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here, `px_count` is the total number of pixels in a training image and `image`
    is a row vector that stores the image. As explained earlier, we need to copy these
    row vectors to a Mat object (`training_images` refers to the Mat object that will
    be used to store these training images). Copy the `image` row vector to `training_images`,
    as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`px_count`是训练图像中像素的总数，`image`是一个行向量，用于存储图像。如前所述，我们需要将这些行向量复制到Mat对象中（`training_images`指的是将用于存储这些训练图像的Mat对象）。按照以下方式将`image`行向量复制到`training_images`中：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Training data is in place. We now need their corresponding labels. As we did
    for training images, their corresponding labels (label values are from 0 to 9)
    can be read in the same way. The contents of the `labels` file are arranged in
    the following way:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据已经就绪。我们现在需要它们的对应标签。正如我们为训练图像所做的那样，它们的对应标签（标签值从0到9）也可以以相同的方式读取。`labels`文件的内容按以下方式排列：
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here is the code to read the labels:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是读取标签的代码：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The basis of the preceding code is similar to the code used for reading images.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的基础与用于读取图像的代码类似。
- en: 'We have successfully loaded the training data in our application. At this point,
    you can use some diagnostic tools of Android to check the memory usage of the
    application. An important point that you need to take care of is to not duplicate
    the data. Doing this will increase the amount of memory consumed, which can affect
    the performance of your application as well as other applications running on your
    phone. Pass the `training_images` and `training_labels` Mat objects to OpenCV''s
    KNN classifier object:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功地将训练数据加载到我们的应用程序中。此时，你可以使用 Android 的某些诊断工具来检查应用程序的内存使用情况。你需要注意的一个重要点是不要重复数据。这样做会增加内存消耗量，这可能会影响你应用程序的性能以及手机上运行的其他应用程序的性能。将
    `training_images` 和 `training_labels` Mat 对象传递给 OpenCV 的 KNN 分类器对象：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The KNN classifier is ready. We are now ready to classify the data.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: KNN 分类器已经准备好了。我们现在可以开始对数据进行分类了。
- en: Recognizing digits
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别数字
- en: This is the final part of the application. Here, we use the frames that are
    captured from the camera as an input to the classifier and allow the classifier
    to predict the digit in the frame.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是应用程序的最后一部分。在这里，我们将从摄像头捕获的帧作为分类器的输入，并允许分类器预测帧中的数字。
- en: 'To begin with, add a new function void `FindMatch()` to the `DigitRecognizer`
    class created in the previous section as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在上一节创建的 `DigitRecognizer` 类中添加一个新的函数 `void FindMatch()`，如下所示：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Note: Images in the training dataset are 28x28 binary images.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：训练数据集中的图像是 28x28 的二进制图像。
- en: The camera output is not directly usable. We need to preprocess the images to
    bring them as close as possible to the images in the training dataset for our
    classifier to give accurate results.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 摄像头输出不能直接使用。我们需要对图像进行预处理，使其尽可能接近训练数据集中的图像，以便我们的分类器给出准确的结果。
- en: 'Perform the following steps (preferably in the same order) to make the camera
    output usable by the KNN classifier:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤（最好是按相同顺序）以使摄像头输出可用于 KNN 分类器：
- en: Dilate the image to make the digit more prominent in the image and reduce any
    background noise.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展图像以使数字在图像中更加突出，并减少任何背景噪声。
- en: Resize the image to 28x28\. The training images are also of this dimension.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像调整大小为 28x28。训练图像也是这个尺寸。
- en: Convert the image to a grayscale image.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像转换为灰度图像。
- en: Perform adaptive threshold on the image to get a binary image.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对图像执行自适应阈值以获得二值图像。
- en: Note
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: All the parameters used in the code here are subject to lighting conditions.
    You are requested to tweak these parameters to suit their environment for best
    results.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的所有参数都受光照条件的影响。请根据您的环境调整这些参数以获得最佳结果。
- en: 'After following these steps, we will have a test that needs to go into the
    KNN classifier that we trained in the previous section. Before this can happen,
    there is one more thing that needs to be done to the test image—transforming the
    image to a row vector (remember the transformations we did to training images?).
    Convert the 28x28 test image to a 1x784 row vector. Use the following piece of
    code to transform the image:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这些步骤后，我们将有一个需要放入我们在上一节中训练的 KNN 分类器的测试。在这之前，还需要对测试图像进行一项操作——将图像转换为行向量（记得我们对训练图像所做的转换？）。将
    28x28 的测试图像转换为 1x784 的行向量。使用以下代码片段进行转换：
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, pass the transformed `test` image to the KNN classifier and store
    the result in the 1x1 Mat object `results`. The last two parameters in the `find_nearest`
    function are optional:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将转换后的 `test` 图像传递给 KNN 分类器，并将结果存储在 1x1 Mat 对象 `results` 中。`find_nearest`
    函数中的最后两个参数是可选的：
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'One last thing, how and when do we call the `FindMatch` function? Since we
    are building a real-time digit recognition application, we need to perform the
    matching operation on every output frame of the camera. Because of this, we need
    to call this function in `onCameraFrame()` in the main activity class. The function
    should finally look like this:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一件事情，我们何时以及如何调用 `FindMatch` 函数？由于我们正在构建一个实时数字识别应用程序，我们需要在摄像头的每一帧输出上执行匹配操作。因此，我们需要在主活动类的
    `onCameraFrame()` 中调用这个函数。函数最终应该看起来像这样：
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We take the RGBA image of the camera output and extract the part of the image
    enclosed by the rectangle that we drew on the screen before. We want the user
    to bring the digit within the rectangle for it to be successfully recognized.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从摄像头的 RGBA 输出中提取出我们在屏幕上之前画出的矩形所包围的图像部分。我们希望用户将数字放入矩形内，以便成功识别。
- en: 'Since our application is written for landscape mode (set in the `AndroidManifest.xml`
    file) but we use it in the portrait mode, we need to transpose the test image
    before we can run the recognition algorithm. Hence, run this command:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的应用程序是为横幅模式编写的（在`AndroidManifest.xml`文件中设置），但我们使用的是竖屏模式，因此在我们运行识别算法之前需要转置测试图像。因此，运行以下命令：
- en: '[PRE15]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We have successfully created a real-time digit recognition application. Let's
    take a look at another machine learning technique that can be used in recognizing
    digits.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功创建了一个实时数字识别应用程序。让我们看看另一种可以用于识别数字的机器学习技术。
- en: OCR using Support Vector Machines
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用支持向量机进行OCR
- en: '**Support Vector Machines** (**SVMs**) are supervised learning algorithms that
    are commonly used for classification and regression. In SVMs, the training data
    is divided into different regions using infinite hyperplanes, and each region
    represents a class. To test data, we plot the point in the same space as the training
    points and using the hyperplanes compute the region where the test point lies.
    SVMs are useful when dealing with high-dimensional data.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVMs**）是常用的监督学习算法，常用于分类和回归。在SVMs中，训练数据被无限超平面划分为不同的区域，每个区域代表一个类别。为了测试数据，我们在与训练点相同的空间中绘制点，并使用超平面计算测试点所在的区域。SVMs在处理高维数据时非常有用。'
- en: Note
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For details on SVMs, you can refer to [http://www.support-vector-machines.org/](http://www.support-vector-machines.org/).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 关于SVMs的详细信息，您可以参考[http://www.support-vector-machines.org/](http://www.support-vector-machines.org/)。
- en: In this section, we will learn how to use SVMs for digit recognition. As in
    KNN, to train an SVM, we will directly use the training images without any image
    manipulations or detecting any extra features.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用SVMs进行数字识别。与KNN一样，为了训练SVM，我们将直接使用训练图像，而不进行任何图像处理或检测额外特征。
- en: Note
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Instead of directly using the training images, it is possible to extract some
    features from the images and use those features as training data for the SVM.
    One of the OpenCV tutorials implemented in Python follows a different path. Here,
    they first deskew the image using affine transformations, then compute Histogram
    of Orientation Gradients. These HoG features are used to train the SVM. The reason
    why we are not following the same path is because of the cost of computation involved
    in computing affine transformations and HoG.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是直接使用训练图像，我们可以从图像中提取一些特征，并使用这些特征作为SVM的训练数据。一个用Python实现的OpenCV教程采用了不同的路径。在这里，他们首先使用仿射变换来校正图像，然后计算方向梯度直方图（Histogram
    of Orientation Gradients）。这些HoG特征被用来训练SVM。我们不遵循相同路径的原因是因为计算仿射变换和HoG所涉及的计算成本。
- en: Only slight modifications are involved in using SVM instead of KNN in the application
    that we built in the previous section. The basic camera application and handling
    training data remains as is. The only modification that has to happen is in the
    digit recognition part where we train the classifier.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前构建的应用程序中使用SVM而不是KNN只涉及轻微的修改。基本的相机应用程序和处理训练数据保持不变。唯一需要修改的是数字识别部分，在那里我们训练分类器。
- en: 'In `ReadMNISTData()` function, instead of creating a KNN classifier object,
    we will create an SVM object. Remove the following lines where we declared and
    initialized a KNN object:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ReadMNISTData()`函数中，我们不会创建KNN分类器对象，而是创建一个SVM对象。删除以下声明和初始化KNN对象的行：
- en: '[PRE16]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, replace them with the following lines (declaring and initializing an SVM
    object):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，用以下行替换它们（声明和初始化一个SVM对象）：
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The SVM classifier is now ready. The next step for the KNN classifier is to
    pass a test image to the classifier and check the result. For this, we need to
    modify the `FindMatch()` function. Replace the line that uses KNN for classification
    with an appropriate line which uses SVM.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: SVM分类器现在已经准备好了。KNN分类器的下一步是将测试图像传递给分类器并检查结果。为此，我们需要修改`FindMatch()`函数。将使用KNN进行分类的行替换为使用SVM的适当行。
- en: Note
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: An optimization that the users can incorporate in the preceding application
    is that they can save the trained classifier in a file on the device. This will
    save time in training the classifier again and again.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以在前面的应用程序中采用的一种优化是，他们可以将训练好的分类器保存到设备上的文件中。这将节省重复训练分类器的时间。
- en: 'Let''s take a look at the following command:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下命令：
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We need to replace the preceding command with the following command:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将前面的命令替换为以下命令：
- en: '[PRE19]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: That's all. Our application is ready. We can run the application, check for
    the results, and probably compare which algorithm runs better under what condition.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了。我们的应用程序已经准备好了。我们可以运行应用程序，检查结果，并可能比较在什么条件下哪个算法运行得更好。
- en: Solving a Sudoku puzzle
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决数独谜题
- en: 'Remember the Sudoku puzzle project in [Chapter 2](ch02.html "Chapter 2. Detecting
    Basic Features in Images"), *Detecting Basic Features in Images*? Now is the perfect
    time to revisit this project and see whether we can use anything that we learnt
    in this chapter to complete this application. So, in [Chapter 2](ch02.html "Chapter 2. Detecting
    Basic Features in Images"), *Detecting Basic Features in Images*, we had successfully
    detected the Sudoku puzzle. Only two things were left in that application: recognizing
    digits and solving the Sudoku puzzle.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 记得第 2 章 *检测图像的基本特征* 中提到的数独谜题项目吗？现在是重新审视这个项目的完美时机，看看我们是否可以用本章学到的任何东西来完成这个应用程序。所以，在第
    2 章 *检测图像的基本特征* 中，我们成功检测到了数独谜题。在那个应用程序中，只剩下两件事要做：识别数字和解决数独谜题。
- en: Recognizing digits in the puzzle
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别谜题中的数字
- en: Let's pick up from where we left in [Chapter 2](ch02.html "Chapter 2. Detecting
    Basic Features in Images"), *Detecting Basic Features in Images*. After detecting
    the grid successfully, we need to further break down the grid into 81 small squares.
    There are many possible ways of doing this, but here, we will look at only three
    techniques.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第 2 章 *检测图像的基本特征* 中我们留下的地方继续前进。在成功检测到网格后，我们需要进一步将网格分解成 81 个小方格。有许多可能的方法来做这件事，但在这里，我们只会查看三种技术。
- en: First, the easiest of all is to draw nine equally spaced vertical and horizontal
    lines each on the image, and assume the digits to be placed within the boxes made
    by these lines.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，最容易的方法是在图像上绘制九条等距的垂直和水平线，并假设数字将被放置在这些线形成的方框内。
- en: '![Recognizing digits in the puzzle](img/B02052_07_02.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![识别谜题中的数字](img/B02052_07_02.jpg)'
- en: Figure 2\. Vertical and horizontal lines drawn on a Sudoku grid
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2. 数独网格上绘制的垂直和水平线
- en: The second way is using Hough lines. Apply Hough lines on the Sudoku grid and
    store all the lines that are returned. Ideally, nine vertical and nine horizontal
    lines should be returned but chances of this happening are very bleak, unless
    you have a very good camera and perfect lighting conditions. There will be missing
    or incomplete lines that will reduce the application's performance or may lead
    to false results.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法是使用霍夫线。在数独网格上应用霍夫线，并存储返回的所有线。理想情况下，应该返回九条垂直线和九条水平线，但这种情况发生的可能性非常小，除非你有一个非常好的相机和完美的照明条件。可能会有缺失或不完整的线，这会降低应用程序的性能或可能导致错误的结果。
- en: The third way is using corner detection. Run any corner detection algorithm
    and get all the corners in the image. These corners represent the vertices of
    the boxes enclosing the digits. Once you have all the corners, you can join four
    corners to form a box and extract that part of the image.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种方法是使用角点检测。运行任何角点检测算法，并获取图像中的所有角点。这些角点代表了包围数字的方框的顶点。一旦你有了所有角点，你可以连接四个角来形成一个方框，并提取该图像部分。
- en: The previously mentioned techniques may not always guarantee perfect results.
    Different techniques may perform better, depending on the surroundings and the
    kind of camera being used.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提到的方法并不总是能保证完美的结果。不同的技术可能在不同环境和使用的相机类型下表现更好。
- en: 'Extract all 89 images using any of the previously mentioned technique, and
    pass them through a pretrained digit classifier—SVM or KNN (as seen in the previous
    sections). Done! Take the output of the classifier and make a 9x9 integer matrix
    in your code, and fill it up with the corresponding digits recognized from the
    grid. So now we have the grid with us. Use any brute force or Artificial Intelligence
    algorithm to get the correct solution of the Sudoku puzzle. Different algorithms
    that can be used are as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前提到的任何技术提取所有 89 张图像，并将它们通过一个预训练的数字分类器——SVM 或 KNN（如前几节所示）进行分类。完成！将分类器的输出转换为你的代码中的
    9x9 整数矩阵，并用从网格中识别出的相应数字填充它。现在我们有了这个网格。使用任何暴力破解或人工智能算法来获取数独谜题的正确解决方案。可以使用的不同算法如下：
- en: Backtracking
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回溯法
- en: Genetic algorithms
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遗传算法
- en: Sudoku as a constraint problem
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数独作为约束问题
- en: Refer to [http://en.wikipedia.org/wiki/Sudoku_solving_algorithms](http://en.wikipedia.org/wiki/Sudoku_solving_algorithms)
    for a detailed explanation on these algorithms.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 有关这些算法的详细解释，请参阅[http://en.wikipedia.org/wiki/Sudoku_solving_algorithms](http://en.wikipedia.org/wiki/Sudoku_solving_algorithms)。
- en: Summary
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked at how to make an application intelligent by incorporating
    machine learning into them. We looked at Support Vector Machines and KNNs, and
    how we can use them to build applications that can learn patterns in user entered
    data. Till now we have covered many computer vision algorithms and their implementations
    in detail. In the next chapter, we will take a look at some commonly faced errors
    while building such applications, and some best practices that will help you make
    the applications more efficient.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了如何通过将机器学习融入其中来使应用程序变得智能。我们讨论了支持向量机（Support Vector Machines）和KNN（K-Nearest
    Neighbors），以及我们如何使用它们来构建能够从用户输入数据中学习模式的应用程序。到目前为止，我们已经详细介绍了许多计算机视觉算法及其实现。在下一章中，我们将探讨在构建此类应用程序时常见的一些错误，以及一些有助于使应用程序更高效的最佳实践。
