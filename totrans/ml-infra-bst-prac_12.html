<html><head></head><body>
		<div id="_idContainer096">
			<h1 class="chapter-number"><a id="_idTextAnchor112"/>9</h1>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor113"/>Types of Machine Learning Systems – Feature-Based  and Raw Data-Based  (Deep Learning)</h1>
			<p>In the previous chapters, we learned about data, noise, features, and visualization. Now, it’s time to move on to machine learning models. There is no such thing as one model, but there are plenty of them – starting from the classical models such as random forest to deep learning models for vision systems to generative AI models such <span class="No-Break">as GPT.</span></p>
			<p>The convolutional and GPT models are called deep learning models. Their name comes from the fact that they use raw data as input and the first layers of the models include feature extraction layers. They are also designed to progressively learn more abstract features as the input data moves through <span class="No-Break">these models.</span></p>
			<p>This chapter demonstrates each of these types of models and progresses from classical machine learning to generative <span class="No-Break">AI models.</span></p>
			<p>In this chapter, we’ll cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Why do we need different types <span class="No-Break">of models?</span></li>
				<li>Classical machine learning models and systems, such as random forest, decision tree, and <span class="No-Break">logistic regression</span></li>
				<li>Deep learning models for vision systems, convolutional neural models, and <strong class="bold">You Only Look Once</strong> (<span class="No-Break"><strong class="bold">YOLO</strong></span><span class="No-Break">) models</span></li>
				<li><strong class="bold">General Pretrained Transformers</strong> (<span class="No-Break"><strong class="bold">GPT</strong></span><span class="No-Break">) models</span></li>
			</ul>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor114"/>Why do we need different types of models?</h1>
			<p>So far, we <a id="_idIndexMarker323"/>have invested a significant amount of effort in data processing while focusing on tasks such as noise reduction and annotation. However, we have yet to delve into the models that are employed to work with this processed data. While we briefly mentioned different types of models based on data annotation, including supervised, unsupervised, and reinforced learning, we have not thoroughly explored the user’s perspective when it comes to utilizing <span class="No-Break">these models.</span></p>
			<p>It is important to consider the perspective of the user when employing machine learning models for working with data. The user’s needs, preferences, and specific requirements play a crucial role in selecting and utilizing the <span class="No-Break">appropriate models.</span></p>
			<p>From the user’s standpoint, it becomes essential to assess factors such as model interpretability, ease of integration, computational efficiency, and scalability. Depending on the application and use case, the user might prioritize different aspects of the models, such as accuracy, speed, or the ability to handle <span class="No-Break">large-scale datasets.</span></p>
			<p>Furthermore, the user’s domain expertise and familiarity with the underlying algorithms impact the selection and evaluation of models. Some users might prefer simpler, more transparent models that offer interpretability and comprehensibility, while others might be willing to trade interpretability for improved predictive performance using more complex models such as deep <span class="No-Break">learning networks.</span></p>
			<p>Considering the user’s perspective enables a more holistic approach to model selection and deployment. It involves actively involving the user in the decision-making process, gathering feedback, and continuously refining the models to meet their <span class="No-Break">specific needs.</span></p>
			<p>By incorporating the user’s perspective into the discussion, we can ensure that the models we choose not only satisfy technical requirements but also align with the user’s expectations and objectives, ultimately enhancing the effectiveness and usability of the <span class="No-Break">entire system.</span></p>
			<p>Therefore, moving forward, we’ll explore how different types of users interact with and benefit from various machine learning models while considering their specific requirements, preferences, and domain expertise. We’ll start with the classical machine learning models, which are historically the <span class="No-Break">first ones.</span></p>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor115"/>Classical machine learning models</h1>
			<p>Classical machine learning models<a id="_idIndexMarker324"/> require <a id="_idIndexMarker325"/>pre-processed data in the form of tables and matrices. Classical machine learning models, such as random forest, linear regression, and support vector machines, require a clear set of predictors and classes to find patterns. Due to this, our pre-processing pipelines need to be manually designed for the task <span class="No-Break">at hand.</span></p>
			<p>From the user’s perspective, these systems are designed in a very classical way – there is a user interface, an engine for data processing (our classical machine learning model), and an output. This is depicted in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer093">
					<img alt="Figure 9.1 – Elements of a machine learning system" src="image/B19548_09_1.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – Elements of a machine learning system</p>
			<p><span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.1</em> shows that there are three elements – the input prompt, the model, and the output. For most such systems, the input prompt is a set of properties that are provided for the model. The user fills in some sort of form and the system provides an answer. It can be a form for predicting the price of land or a system for loans, applying for a job, finding the best car, and <span class="No-Break">so on.</span></p>
			<p>The source code for such a system may look something <span class="No-Break">like this:</span></p>
			<pre class="source-code">
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
# Load the stock price data into a pandas DataFrame
data = pd.read_csv('land_property_data.csv')
# Select the features (e.g., historical prices, volume, etc.) and the target variable (price)
X = data[['Feature1', 'Feature2', ...]]  # Relevant features here
y = data['price']
# read the model from the serialized storage here
# Make predictions on the test data
y_pred = model.predict(X)
# Evaluate the model using mean squared error (MSE)
print(f'The predicted value of the property is: {y_pred}')</pre>			<p>This fragment<a id="_idIndexMarker326"/> of code requires<a id="_idIndexMarker327"/> a model to be already trained and only uses it for making predictions. The main line that uses the model is the line in boldface. The rest of the code fragment is for processing the input and the last line is for communicating <span class="No-Break">the output.</span></p>
			<p>In modern ecosystems, the power of machine learning models comes from the ability to change models without the need to change a lot of code. The majority of classical machine learning models use this fit/predict interface, which enables just that. So, which machine learning models can we use? There are just too many of them to provide an exhaustive list. However, certain groups of these models have <span class="No-Break">certain properties:</span></p>
			<ul>
				<li><strong class="bold">Regression models</strong> group machine <a id="_idIndexMarker328"/>learning models that are used for predicting a class value. They can be used both for classification (classifying a module to be defect-prone or not) and prediction tasks (predicting the number of defects in a module). These models are based on finding the best curve to fit the <span class="No-Break">given data.</span></li>
				<li><strong class="bold">Tree-based models</strong> group <a id="_idIndexMarker329"/>models that are based on finding differences in the dataset as if we wrote a set of if-then statements. The logical conditions for these if-then statements are based on the statistical properties of the data. These models are good for both classification and <span class="No-Break">prediction models.</span></li>
				<li><strong class="bold">Clustering algorithms</strong> group <a id="_idIndexMarker330"/>models that are based on finding similarities in the data and grouping similar entities. They are often unsupervised and require some experimentation to find the right set of parameters (for example, the number <span class="No-Break">of clusters).</span></li>
				<li><strong class="bold">Neural networks</strong> group <a id="_idIndexMarker331"/>all kinds of neural networks that can be used for classical machine learning tasks. These algorithms require us to design and train the neural <span class="No-Break">network model.</span></li>
			</ul>
			<p>We can select <a id="_idIndexMarker332"/>these models based on their properties and test them to find the best one. However, if we include hyperparameter training, this process is very time-consuming and effort-intensive. Therefore, I strongly recommend using AutoML approaches for this. AutoML is a group of algorithms that utilize the fit/predict interface for machine learning models to find the best model automatically. By exploring the plethora of models, they can find the model that is the best for the dataset. We say this is with an asterisk. Sometimes, the human ability to understand the data and its properties beats most automated machine learning <span class="No-Break">p</span><a href="https://metrics.blogg.gu.se/?p=682"><span class="No-Break">rocesses (</span><span class="No-Break">https://metrics.blogg.gu</span></a><span class="No-Break">.se/?p=682</span><span class="No-Break">).</span></p>
			<p>So, here is my first best practice for <span class="No-Break">this chapter.</span></p>
			<p class="callout-heading">Best practice #50</p>
			<p class="callout">Use AutoML as your first choice when you’re training classical machine <span class="No-Break">learning models.</span></p>
			<p>Using AutoML is very simple and can be illustrated with the following fragment of code (from the documentation <span class="No-Break">of auto-sklearn):</span></p>
			<pre class="source-code">
import autosklearn.classification
cls = autosklearn.classification.AutoSklearnClassifier()
cls.fit(X_train, y_train)
predictions = cls.predict(X_test)</pre>			<p>The preceding <a id="_idIndexMarker333"/>fragment illustrates how easy it is to use the auto-sklearn toolkit to find the best model. Please note that this toolkit has been designed for Linux-based systems only. To use it on the Microsoft Windows operating system, I recommend using <strong class="bold">Windows Subsystem for Linux 2.0</strong> (<strong class="bold">WSL 2</strong>). The <a id="_idIndexMarker334"/>interface hides the best model in such a way that the user does not even have to see which model is the best for the data <span class="No-Break">at hand.</span></p>
			<p><strong class="source-inline">import autosklearn.classification</strong> imports the auto-sklearn module specifically for classification tasks. <strong class="source-inline">cls = autosklearn.classification.AutoSklearnClassifier()</strong> initializes an instance of the <strong class="source-inline">AutoSklearnClassifier</strong> class, which represents the AutoML classifier in <strong class="source-inline">autosklearn</strong>. It creates an object that will be used to search for the best classifier and its hyperparameters automatically. <strong class="source-inline">cls.fit(X_train, y_train)</strong> fits <strong class="source-inline">AutoSklearnClassifier</strong> to the training data. It automatically explores different classifiers and their hyperparameter configurations to find the best model based on the provided <strong class="source-inline">X_train</strong> (features) and <strong class="source-inline">y_train</strong> (target labels). It trains the AutoML model on the provided <span class="No-Break">training dataset.</span></p>
			<p><strong class="source-inline">predictions = cls.predict(X_test)</strong> uses the fitted <strong class="source-inline">AutoSklearnClassifier</strong> to make predictions on the <strong class="source-inline">X_test</strong> dataset. It applies the best-found model from the previous step to the test data and assigns the predicted labels to the <span class="No-Break"><strong class="source-inline">predictions</strong></span><span class="No-Break"> variable.</span></p>
			<p>Let’s apply auto-sklearn on the same dataset that we used for visualization in <a href="B19548_06.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic">Chapter 6</em></span></a><span class="No-Break">:</span></p>
			<pre class="source-code">
# read the file with data using openpyxl
import pandas as pd
# we read the data from the excel file,
# which is the defect data from the ant 1.3 system
dfDataCamel12 = pd.read_excel('./chapter_6_dataset_numerical.xlsx',
                            sheet_name='camel_1_2',
                            index_col=0)
# prepare the dataset
import sklearn.model_selection
X = dfDataCamel12.drop(['Defect'], axis=1)
y = dfDataCamel12.Defect
X_train, X_test, y_train, y_test = \
        sklearn.model_selection.train_test_split(X, y, random_state=42, train_size=0.9)</pre>			<p>We’ll <a id="_idIndexMarker335"/>use the same code we <span class="No-Break">used previously:</span></p>
			<pre class="source-code">
import autosklearn.classification
cls = autosklearn.classification.AutoSklearnClassifier()
cls.fit(X_train, y_train)
predictions = cls.predict(X_test)</pre>			<p>Once we have trained the model, we can inspect it – for example, by asking auto-sklearn to provide us with information about the best model – using the <strong class="source-inline">print(cls.sprint_statistics())</strong> command. The results are <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
auto-sklearn results:
Dataset name: 4b131006-f653-11ed-814a-00155de31e8a
Metric: accuracy
Best validation score: 0.790909
Number of target algorithm runs: 1273
Number of successful target algorithm runs: 1214
Number of crashed target algorithm runs: 59
Number of target algorithms that exceeded the time limit: 0
Number of target algorithms that exceeded the memory limit: 0</pre>			<p>This <a id="_idIndexMarker336"/>information shows us that the toolkit has tested <strong class="source-inline">1273</strong> algorithms and that <strong class="source-inline">59</strong> of them crashed. This means that they were not compatible with the dataset provided <span class="No-Break">by us.</span></p>
			<p>We can also ask the toolkit to provide us with the best model by using the <strong class="source-inline">print(cls.show_models())</strong> command. This command provides a long list of the models that are used for ensemble learning and their weight on the final score. Finally, we can ask for the accuracy score for the test data by using <strong class="source-inline">print(f\"Accuracy score {sklearn.metrics.accuracy_score(y_test, predictions):.2f}\")</strong>. For this dataset, the accuracy score is 0.59 for the test data, which is not a lot. However, this is the model that’s obtained by using the best ensemble. If we ask the model to provide us with the accuracy score for the training data, we’ll get 0.79, which is much higher, but that’s because the model is very <span class="No-Break">well optimized.</span></p>
			<p>Later in this book, we’ll explore these algorithms and learn how they behave for tasks in software engineering <span class="No-Break">and beyond.</span></p>
			<h1 id="_idParaDest-101"><a id="_idTextAnchor116"/>Convolutional neural networks and image processing</h1>
			<p>The <a id="_idIndexMarker337"/>classical machine learning models are quite powerful, but they are limited in their input. We need to pre-process it so that it’s a set of feature vectors. They are also limited in their ability to learn – they are one-shot learners. We can only train them once and we cannot add more training. If more training is required, we need to train these models from the <span class="No-Break">very beginning.</span></p>
			<p>The classical <a id="_idIndexMarker338"/>machine learning models are also considered to be rather limited in their ability to handle complex structures, such as images. Images, as we have learned before, have at least two different dimensions and they can have three channels of information – red, green, and blue. In more complex applications, the images can contain data from LiDAR or geospatial data that can provide meta-information about <span class="No-Break">the images.</span></p>
			<p>So, to handle images, more complex models are needed. One of these models is the YOLO model. It’s considered to be state-of-the-art in the area of object detection due to its great balance between accuracy <span class="No-Break">and speed.</span></p>
			<p>Let’s take a look at how we can utilize a pre-trained YOLO v5 model from Hugging Face. Here, I would like to provide my next <span class="No-Break">best practice.</span></p>
			<p class="callout-heading">Best practice #51</p>
			<p class="callout">Use pre-trained models from Hugging Face or TensorFlow Hub to <span class="No-Break">start with.</span></p>
			<p>Using a pre-trained model has a <span class="No-Break">few advantages:</span></p>
			<ul>
				<li>First of all, it allows us to use the network as a benchmark for our pipeline. We can experiment with it and understand its limitations before we move forward and start <span class="No-Break">training it.</span></li>
				<li>Second, it provides us with the possibility to add more training for the existing, proven-in-use models that others have <span class="No-Break">also used.</span></li>
				<li>Finally, it provides us with the possibility to share our models with the community to support the ethical and responsible development of <span class="No-Break">artificial intelligence.</span></li>
			</ul>
			<p>The following code <a id="_idIndexMarker339"/>fragment installs the <strong class="source-inline">YoLo</strong> model and <span class="No-Break">instantiates it:</span></p>
			<pre class="source-code">
# install YoLo v5 network
!pip install -q -U yolov5
# then we set up the network
import yolov5
# load model
model = yolov5.load('fcakyon/yolov5s-v7.0')
# set model parameters
model.conf = 0.25  # NMS confidence threshold
model.iou = 0.45  # NMS IoU threshold
model.agnostic = False  # NMS class-agnostic
model.multi_label = False  # NMS multiple labels per box
model.max_det = 1000  # maximum number of detections per image</pre>			<p>The first few<a id="_idIndexMarker340"/> lines load the YOLOv5 model from the specified source – that is, <strong class="source-inline">fcakyon/yolov5s-v7.0</strong> – using the <strong class="source-inline">load</strong> function. They assign the loaded model to the variable model, which can be used to perform object detection. The <strong class="source-inline">model.conf</strong> parameter sets the confidence threshold for <strong class="bold">non-maximum suppression</strong> (<strong class="bold">NMS</strong>), which<a id="_idIndexMarker341"/> is used to filter out detections below this confidence level. In this case, it is set to 0.25, meaning that only detections with a confidence score above 0.25 will <span class="No-Break">be considered.</span></p>
			<p>The <strong class="source-inline">model.iou</strong> parameter sets the <strong class="bold">Intersection over Union</strong> (<strong class="bold">IoU</strong>) threshold for NMS. It determines the degree<a id="_idIndexMarker342"/> of overlap between bounding boxes required to consider them as duplicate detections. Here, it is set to 0.45, meaning that if the IoU between two boxes is above 0.45, the one with the lower confidence score will be suppressed. The <strong class="source-inline">model.agnostic</strong> parameter determines whether NMS is class-agnostic or not. If it’s set to <strong class="source-inline">False</strong>, NMS will consider class labels during suppression, which means that if two bounding boxes <a id="_idIndexMarker343"/>have the same coordinates but different labels, they will not be considered duplicates. Here, it is set to <strong class="source-inline">False</strong>. The <strong class="source-inline">model.multi_label</strong> parameter controls whether NMS allows multiple labels per bounding box. If it’s set to <strong class="source-inline">False</strong>, each box will be assigned a single label with the highest confidence score. Here, it is set <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">False</strong></span><span class="No-Break">.</span></p>
			<p>Finally, the <strong class="source-inline">model.max_det</strong> parameter sets the maximum number of detections allowed per<a id="_idIndexMarker344"/> image. In this case, it is set to <strong class="source-inline">1000</strong>, meaning that only the top 1,000 detections (sorted by confidence score) will <span class="No-Break">be kept.</span></p>
			<p>Now, we can perform inferences – that is, detect objects using the network – but first, we must load <span class="No-Break">the image:</span></p>
			<pre class="source-code">
# and now we prepare the image
from PIL import Image
from torchvision import transforms
# Load and preprocess the image
image = Image.open('./test_image.jpg')</pre>			<p>This code fragment loads the image file located at <strong class="source-inline">./test_image.jpg</strong> using the <strong class="source-inline">open</strong> function from PIL’s Image module. It creates an instance of the <strong class="source-inline">Image</strong> class representing <span class="No-Break">the image.</span></p>
			<p>Once the image has been loaded, you can apply various transformations to pre-process it before feeding it to the YOLOv5 model for object detection. This might involve resizing, normalization, or other pre-processing steps, depending on the <span class="No-Break">model’s requirements:</span></p>
			<pre class="source-code">
# perform inference
results = model(image)
# inference with larger input size
results = model(image, size=640)
# inference with test time augmentation
results = model(image, augment=True)
# parse results
predictions = results.pred[0]
boxes = predictions[:, :4] # x1, y1, x2, y2
scores = predictions[:, 4]
categories = predictions[:, 5]
# show detection bounding boxes on image
results.show()</pre>			<p>The <a id="_idIndexMarker345"/>preceding code fragment performs object detection in the <a id="_idIndexMarker346"/>first few lines and then draws the image, together with the bounding boxes of the detected object. In our case, this is the result of the preceding <span class="No-Break">code fragment:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer094">
					<img alt="Figure 9.2 – Objects detected in the image" src="image/B19548_09_2.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Objects detected in the image</p>
			<p>Please note that <a id="_idIndexMarker347"/>the model identifies the car as a truck, perhaps because of the presence of the additional luggage on the back of the car. The<a id="_idIndexMarker348"/> source of the image is Pixabay. The figure shows that object detection does not identify the object correctly. However, this is not a problem. We can take this pre-trained model and train it even more. However, that is the topic of the next few chapters, so we won’t cover <span class="No-Break">it here.</span></p>
			<p class="callout-heading">Best practice #52</p>
			<p class="callout">Work with pre-trained networks to identify their limitations and then train the network on your <span class="No-Break">own dataset.</span></p>
			<p>I strongly recommend <a id="_idIndexMarker349"/>using the pre-trained models to start with and then train the network on your own data. This ability of deep learning models to continue training is a great property that we can utilize when designing machine<a id="_idIndexMarker350"/> learning-based systems. In this way, we get the best of both worlds – our systems can detect generic objects while being better at detecting objects that our system specifies. This kind of approach is often used in designing <span class="No-Break">automotive systems.</span></p>
			<p>Let’s look at other types of deep learning systems that use pre-training and add one more layer of complexity – <span class="No-Break">prompt engineering.</span></p>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor117"/>BERT and GPT models</h1>
			<p>BERT and GPT models use<a id="_idIndexMarker351"/> raw data as input and their main output is one predicted word. This word can be predicted both in the middle of a sentence and at the end of it. This means that the products that are designed around these models need to process data differently than in the <span class="No-Break">other models.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.3</em> provides<a id="_idIndexMarker352"/> an overview of this kind of processing with a focus on both prompt engineering in the beginning and output processing in the end. This figure shows the machine learning models based on the BERT or GPT architecture in the center. This is an important aspect, but it only provides a very small element of the entire system (<span class="No-Break">or tool).</span></p>
			<p>The tool’s workflow starts on the left-hand side with input processing. For the user, it is a prompt that asks the model to do something, such as <strong class="source-inline">"Write a function that reverses a string in C"</strong>. The tool turns that prompt into a useful input for the model – it can find a similar C program as input for the model and add the <strong class="source-inline">&lt;mask&gt;</strong> token to the end of that program to make the model predict <span class="No-Break">the output.</span></p>
			<p>Then, the model makes the prediction – one token at a time. The tool needs to loop the output until something useful is generated. The tool needs to define the stop criteria and it needs to process the output into a useful one for <span class="No-Break">the user:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer095">
					<img alt="Figure 9.3 – Overview of the design of modern deep learning tools where the machine learning model is only a small (but important) part of the tool" src="image/B19548_09_3.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – Overview of the design of modern deep learning tools where the machine learning model is only a small (but important) part of the tool</p>
			<p>If we<a id="_idIndexMarker353"/> send <a id="_idIndexMarker354"/>this prompt to ChatGPT, we get the following response in three parts. First, we get the actual code of the function, which reverses the string <span class="No-Break">in C:</span></p>
			<pre class="source-code">
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
void reverseString(char* str) {
    int length = strlen(str);
    int i, j;
    for (i = 0, j = length - 1; i &lt; j; i++, j--) {
        char temp = str[i];
        str[i] = str[j];
        str[j] = temp;
    }
}
int main() {
    char str[] = "Hello, world!";
    printf("Original string: %s\n", str);
    reverseString(str);
    printf("Reversed string: %s\n", str);
    return 0;
}</pre>			<p>This <a id="_idIndexMarker355"/>function does not have any comments generated, so ChatGPT uses the <a id="_idIndexMarker356"/>summarization pipeline to describe the model in the <span class="No-Break">following way:</span></p>
			<pre class="source-code">
This code defines a function called reverseString that takes a character array (char*) as input and reverses the string in-place. It uses two pointers, i and j, starting from the beginning and end of the string respectively, and swaps the characters until they meet in the middle.
In the main function, a sample string "Hello, world!" is provided, and the reverseString function is called to reverse it. The original and reversed strings are then printed for verification.</pre>			<p>This explanation is supposed to replace the documentation for the code, which needs to be added for good <span class="No-Break">programming practice.</span></p>
			<p>Finally, the tool provides us with an example of the code that tests <span class="No-Break">this function:</span></p>
			<pre class="source-code">
Original string: Hello, world!
Reversed string: !dlrow ,olleH</pre>			<p>The last part of the response is also generated as part of the prompt. This is because the test code is usually present in similar situations in the dataset. Now, if our prompt is something a bit more than just<a id="_idIndexMarker357"/> reversing a string, maybe in a different programming language, such as C#, we may <a id="_idIndexMarker358"/>get a different structure of the response. For example, if our prompt is <strong class="source-inline">Write a function that creates 3000 random numbers in C# and prints them to the console</strong>, then the response will only contain the C# code for the function, not for the <span class="No-Break">test code:</span></p>
			<pre class="source-code">
using System;
class Program {
    static void Main(string[] args) {
        const int numNumbers = 3000;
        const int minValue = 0;
        const int maxValue = 100;
        Random random = new Random();
        for (int i = 0; i &lt; numNumbers; i++) {
            int num = random.Next(minValue, maxValue + 1);
            Console.WriteLine(num);
        }
    }
}</pre>			<p>The explanations are also generated, but not the code that tests this function. Instead, the function is wrapped as <strong class="source-inline">class Program</strong> and there is no <strong class="source-inline">main()</strong> function to <span class="No-Break">test it.</span></p>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor118"/>Using language models in software systems</h1>
			<p>Using <a id="_idIndexMarker359"/>products such as ChatGPT is great, but they are also limited to the purpose for which they were designed. Now, we can use models<a id="_idIndexMarker360"/> like this from scratch using the Hugging Face interface. In the following code example, we can see how we can use a model dedicated to a specific task – recognizing design patterns – to complete the text – that is, writing the signature of a Singleton design pattern. This illustrates how language models (including GPT-3/4) work with text under <span class="No-Break">the hood.</span></p>
			<p>In the following code fragment, we’re importing the model from the Hugging Face library and instantiating it. The model has been pre-trained on a set of dedicated singleton programs and constructed synthetically by adding random code from the Linux kernel source code as code of a Singleton class <span class="No-Break">in C++:</span></p>
			<pre class="source-code">
# import the model via the huggingface library
from transformers import AutoTokenizer, AutoModelForMaskedLM
# load the tokenizer and the model for the pretrained SingBERTa
tokenizer = AutoTokenizer.from_pretrained('mstaron/SingBERTa')
# load the model
model = AutoModelForMaskedLM.from_pretrained("mstaron/SingBERTa")
# import the feature extraction pipeline
from transformers import pipeline</pre>			<p>This code imports the necessary modules from the Transformers library from Hugging Face. Then, it loads the tokenizer and the model for the pre-trained SingBERTa. The tokenizer is responsible for converting text into numerical tokens, and the model is a pre-trained language model<a id="_idIndexMarker361"/> specifically designed for <strong class="bold">masked language modeling</strong> (<strong class="bold">MLM</strong>) tasks. It loads the model from the pre-trained SingBERTa. After, it imports the feature extraction pipeline from the Transformers library. The feature extraction pipeline allows us to easily extract contextualized embeddings from <span class="No-Break">the model.</span></p>
			<p>Overall, this <a id="_idIndexMarker362"/>code sets up the necessary<a id="_idIndexMarker363"/> components for us to use the SingBERTa model for various natural language processing tasks, such as text tokenization, MLM, and feature extraction. The following code fragment does just that – it creates the pipeline for filling in the blanks. This means that the model is prepared to predict the next word in <span class="No-Break">the sentence:</span></p>
			<pre class="source-code">
fill_mask = pipeline(
    "fill-mask",
    model="./SingletonBERT",
    tokenizer="./SingletonBERT"
)</pre>			<p>We can use this pipeline by using the <strong class="source-inline">fill_mask("static Singleton:: &lt;mask&gt;")</strong> command, which results in the <span class="No-Break">following output:</span></p>
			<pre class="source-code">
[{'score': 0.9703333973884583, 'token': 74, 'token_str': 'f', 'sequence': 'static Singleton::f'},
{'score': 0.025934329256415367, 'token': 313, 'token_str': ' );', 'sequence': 'static Singleton:: );'},
{'score': 0.0003994493163190782, 'token': 279, 'token_str': '();', 'sequence': 'static Singleton::();'},
{'score': 0.00021698368072975427, 'token': 395, 'token_str': ' instance', 'sequence': 'static Singleton:: instance'},
{'score': 0.00016094298916868865, 'token': 407, 'token_str': ' getInstance', 'sequence': 'static Singleton:: getInstance'}]</pre>			<p>The preceding output shows that the best prediction is the <strong class="source-inline">f</strong> token. This is correct since the training example used <strong class="source-inline">f</strong> as the name of the functions that were synthetically added to the Singleton class (<strong class="source-inline">Singleton::f1()</strong>, <span class="No-Break">for example).</span></p>
			<p>If we<a id="_idIndexMarker364"/> want to expand these predictions, just like the ChatGPT code generation feature, we need to loop the preceding code <a id="_idIndexMarker365"/>and generate one token at a time, thus filling in the program. There is no guarantee that the program will compile, so post-processing could essentially select only these constructs (from the list of tokens provided), which would lead to a compiling piece of code. We could even add features for testing this code, thus making our product smarter and smarter, without the need to create a <span class="No-Break">larger model.</span></p>
			<p>Hence, here is my last best practice for <span class="No-Break">this chapter.</span></p>
			<p class="callout-heading">Best practice #53</p>
			<p class="callout">Instead of looking for more complex models, create a <span class="No-Break">smarter pipeline.</span></p>
			<p>Working with a good pipeline can make a good model into a great software product. By providing the right prompt (the beginning of the text to make the prediction), we can create an output that is useful for the use case that our <span class="No-Break">product fulfills.</span></p>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor119"/>Summary</h1>
			<p>In this chapter, we got a glimpse of what machine learning models look like from the inside, at least from the perspective of a programmer. This illustrated the major differences in how we construct machine <span class="No-Break">learning-based software.</span></p>
			<p>In classical models, we need to create a lot of pre-processing pipelines so that the model gets the right input. This means that we need to make sure that the data has the right properties and is in the right format; we need to work with the output to turn the predictions into something <span class="No-Break">more useful.</span></p>
			<p>In deep learning models, the data is pre-processed in a more streamlined way. The models can prepare the images and the text. Therefore, the software engineers’ task is to focus on the product and its use case rather than monitoring concept drift, data preparation, <span class="No-Break">and post-processing.</span></p>
			<p>In the next chapter, we’ll continue looking at examples of training machine learning models – both the classical ones and, most importantly, the deep <span class="No-Break">learning ones.</span></p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor120"/>References</h1>
			<ul>
				<li><em class="italic">Staron, M. and W. Meding. Short-term defect inflow prediction in large software project-an initial evaluation. In International Conference on Empirical Assessment in Software Engineering (</em><span class="No-Break"><em class="italic">EASE). 2007.</em></span></li>
				<li><em class="italic">Prykhodko, S. Developing the software defect prediction models using regression analysis based on normalizing transformations. In Modern problems in testing of the applied software (PTTAS-2016), Abstracts of the Research and Practice Seminar, Poltava, </em><span class="No-Break"><em class="italic">Ukraine. 2016.</em></span></li>
				<li><em class="italic">Ochodek, M., et al., </em><span class="No-Break"><em class="italic">Chapter 8</em></span><em class="italic"> Recognizing Lines of Code Violating Company-Specific Coding Guidelines Using Machine Learning</em><em class="italic">. In Accelerating Digital Transformation: 10 Years of Software Center. 2022, Springer. </em><span class="No-Break"><em class="italic">p. 211-251.</em></span></li>
				<li><em class="italic">Ibrahim, D.R., R. Ghnemat, and A. Hudaib. Software defect prediction using feature selection and random forest algorithm. In 2017 International Conference on New Trends in Computing Sciences (ICTCS). </em><span class="No-Break"><em class="italic">2017. IEEE.</em></span></li>
				<li><em class="italic">Ochodek, M., M. Staron, and W. Meding, </em><span class="No-Break"><em class="italic">Chapter 9</em></span><em class="italic"> SimSAX: A Measure of Project Similarity Based on Symbolic Approximation Method and Software Defect Inflow. In Accelerating Digital Transformation: 10 Years of Software Center. 2022, Springer. </em><span class="No-Break"><em class="italic">p. 253-283.</em></span></li>
				<li><em class="italic">Phan, V.A., Learning Stretch-Shrink Latent Representations With Autoencoder and K-Means for Software Defect Prediction. IEEE Access, 2022. 10: </em><span class="No-Break"><em class="italic">p. 117827-117835.</em></span></li>
				<li><em class="italic">Staron, M., et al., Machine learning to support code reviews in continuous integration. Artificial Intelligence Methods For Software Engineering, 2021: </em><span class="No-Break"><em class="italic">p. 141-167.</em></span></li>
				<li><em class="italic">Li, J., et al. Software defect prediction via convolutional neural network. In 2017 IEEE International Conference on Software Quality, Reliability and Security (QRS). </em><span class="No-Break"><em class="italic">2017. IEEE.</em></span></li>
				<li><em class="italic">Feurer, M., et al., Efficient and robust automated machine learning. Advances in neural information processing systems, </em><span class="No-Break"><em class="italic">2015. 28.</em></span></li>
				<li><em class="italic">Feurer, M., et al., Auto-sklearn 2.0: Hands-free automl via meta-learning. The Journal of Machine Learning Research, 2022. 23(1): </em><span class="No-Break"><em class="italic">p. 11936-11996.</em></span></li>
				<li><em class="italic">Redmon, J., et al. You only look once: Unified, real-time object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern </em><span class="No-Break"><em class="italic">Recognition. 2016.</em></span></li>
				<li><em class="italic">Staron, M., Automotive software architectures. </em><span class="No-Break"><em class="italic">2021: Springer.</em></span></li>
				<li><em class="italic">Gamma, E., et al., Design patterns: elements of reusable object-oriented software. 1995: Pearson </em><span class="No-Break"><em class="italic">Deutschland GmbH.</em></span></li>
			</ul>
		</div>
	</body></html>