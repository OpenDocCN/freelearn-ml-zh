- en: Chapter 6. Creating a Panoramic Image
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 创建全景图像
- en: In this chapter, we are going to learn how to stitch multiple images of the
    same scene together to create a panoramic image.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何将同一场景的多个图像拼接在一起以创建全景图像。
- en: 'By the end of this chapter, you will know:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将知道：
- en: How to match keypoint descriptors between multiple images
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在多张图像之间匹配关键点描述符
- en: How to find overlapping regions between images
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在图像之间找到重叠区域
- en: How to warp images based on the matching keypoints
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何基于匹配的关键点进行图像变换
- en: How to stitch multiple images to create a panoramic image
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将多个图像拼接在一起创建全景图像
- en: Matching keypoint descriptors
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 匹配关键点描述符
- en: 'In the last chapter, we learned how to extract keypoints using various methods.
    The reason that we extract keypoints is because we can use them for image matching.
    Let''s consider the following image:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何使用各种方法提取关键点。我们提取关键点的原因在于我们可以使用它们进行图像匹配。让我们考虑以下图像：
- en: '![Matching keypoint descriptors](img/B04554_06_01.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![匹配关键点描述符](img/B04554_06_01.jpg)'
- en: 'As you can see, it''s the picture of a school bus. Now, let''s take a look
    at the following image:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这是校车的图片。现在，让我们看一下以下图像：
- en: '![Matching keypoint descriptors](img/B04554_06_02.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![匹配关键点描述符](img/B04554_06_02.jpg)'
- en: 'The preceding image is a part of the school bus image and it''s been rotated
    anticlockwise by 90 degrees. We could easily recognize this because our brain
    is invariant to scaling and rotation. Our goal here is to find the matching points
    between these two images. If you do that, it would look something like this:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张图像是校车图像的一部分，并且已经逆时针旋转了90度。我们很容易就能识别出来，因为我们的大脑对缩放和旋转是不变的。我们的目标是找到这两张图像之间的匹配点。如果你这样做，它看起来可能就像这样：
- en: '![Matching keypoint descriptors](img/B04554_06_03.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![匹配关键点描述符](img/B04554_06_03.jpg)'
- en: 'Following is the code to do this:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码用于执行此操作：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: How did we match the keypoints?
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们是如何匹配关键点的？
- en: 'In the preceding code, we used the ORB detector to extract the keypoints. Once
    we extracted the keypoints, we used the Brute Force matcher to match the descriptors.
    Brute Force matching is pretty straightforward! For every descriptor in the first
    image, we match it with every descriptor in the second image and take the closest
    one. To compute the closest descriptor, we use the Hamming distance as the metric,
    as shown in the following line:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用了ORB检测器来提取关键点。一旦提取了关键点，我们就使用暴力匹配器来匹配描述符。暴力匹配非常直接！对于第一张图像中的每个描述符，我们将其与第二张图像中的每个描述符进行匹配，并取最近的那个。为了计算最近的描述符，我们使用汉明距离作为度量标准，如下所示：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can read more about the Hamming distance at [https://en.wikipedia.org/wiki/Hamming_distance](https://en.wikipedia.org/wiki/Hamming_distance).
    The second argument in the preceding line is a Boolean variable. If this is true,
    then the matcher returns only those keypoints that are closest to each other in
    both directions. This means that if we get (i, j) as a match, then we can be sure
    that the i-th descriptor in the first image has the j-th descriptor in the second
    image as its closest match and vice versa. This increases the consistency and
    robustness of descriptor matching.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://en.wikipedia.org/wiki/Hamming_distance](https://en.wikipedia.org/wiki/Hamming_distance)上了解更多关于汉明距离的信息。上一行中的第二个参数是一个布尔变量。如果这是真的，那么匹配器将只返回在两个方向上彼此最接近的关键点。这意味着如果我们得到(i,
    j)作为匹配，那么我们可以确信第一张图像中的第i个描述符是第二张图像中第j个描述符的最近匹配，反之亦然。这增加了描述符匹配的一致性和鲁棒性。
- en: Understanding the matcher object
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解匹配器对象
- en: 'Let''s consider the following line again:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次考虑以下行：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here, the variable matches is a list of DMatch objects. You can read more about
    it in the OpenCV documentation. We just need to quickly understand what it means
    because it will become increasingly relevant in the upcoming chapters. If we are
    iterating over this list of DMatch objects, then each item will have the following
    attributes:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，变量matches是一个DMatch对象的列表。你可以在OpenCV文档中了解更多关于它的信息。我们只需要快速理解它的含义，因为它将在接下来的章节中变得越来越重要。如果我们正在遍历这个DMatch对象的列表，那么每个项目将具有以下属性：
- en: '**item.distance**: This attribute gives us the distance between the descriptors.
    A lower distance indicates a better match.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**item.distance**：此属性给出了描述符之间的距离。距离越低，匹配越好。'
- en: '**item.trainIdx**: This attribute gives us the index of the descriptor in the
    list of train descriptors (in our case, it''s the list of descriptors in the full
    image).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**item.trainIdx**：这个属性给出了训练描述符列表中的索引（在我们的情况下，它是完整图像中的描述符列表）。'
- en: '**item.queryIdx**: This attribute gives us the index of the descriptor in the
    list of query descriptors (in our case, it''s the list of descriptors in the rotated
    subimage).'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**item.queryIdx**：这个属性给出了查询描述符列表中的索引（在我们的情况下，它是旋转子图像中的描述符列表）。'
- en: '**item.imgIdx**: This attribute gives us the index of the train image.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**item.imgIdx**：这个属性给出了训练图像的索引。'
- en: Drawing the matching keypoints
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绘制匹配的关键点
- en: Now that we know how to access different attributes of the matcher object, let's
    see how we can use them to draw the matching keypoints. OpenCV 3.0 provides a
    direct function to draw the matching keypoints, but we will not be using that.
    It's better to take a peek inside to see what's happening underneath.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何访问匹配器对象的不同属性，让我们看看如何使用它们来绘制匹配的关键点。OpenCV 3.0提供了一个直接绘制匹配关键点的函数，但我们将不会使用它。最好看看内部发生了什么。
- en: 'We need to create a big output image that can fit both the images side by side.
    So, we do that in the following line:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要创建一个大的输出图像，可以容纳两张并排的图像。因此，我们在以下行中这样做：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As we can see here, the number of rows is set to the bigger of the two values
    and the number of columns is simply the sum of both the values. For each item
    in the list of matches, we extract the locations of the matching keypoints, as
    we can see in the following lines:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，行数设置为两个值中较大的一个，列数是这两个值的总和。对于匹配列表中的每个项目，我们提取匹配关键点的位置，如下所示：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Once we do that, we just draw circles on those points to indicate their locations
    and then draw a line connecting the two points.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们这样做，我们只需在这些点上画圆圈来指示它们的位置，然后画一条连接两个点的线。
- en: Creating the panoramic image
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建全景图像
- en: 'Now that we know how to match keypoints, let''s go ahead and see how we can
    stitch multiple images together. Consider the following image:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了如何匹配关键点，让我们继续看看如何将多张图像拼接在一起。考虑以下图像：
- en: '![Creating the panoramic image](img/B04554_06_04.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![创建全景图像](img/B04554_06_04.jpg)'
- en: 'Let''s say we want to stitch the following image with the preceding image:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要将以下图像与前面的图像拼接起来：
- en: '![Creating the panoramic image](img/B04554_06_05.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![创建全景图像](img/B04554_06_05.jpg)'
- en: 'If we stitch these images, it will look something like the following one:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这些图像拼接起来，它看起来会像以下这样：
- en: '![Creating the panoramic image](img/B04554_06_06.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![创建全景图像](img/B04554_06_06.jpg)'
- en: 'Now let''s say we captured another part of this house, as seen in the following
    image:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们捕捉到了这个房子的另一部分，如下面的图像所示：
- en: '![Creating the panoramic image](img/B04554_06_07.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![创建全景图像](img/B04554_06_07.jpg)'
- en: 'If we stitch the preceding image with the stitched image we saw earlier, it
    will look something like this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将前面的图像与之前看到的拼接图像拼接起来，它看起来会像这样：
- en: '![Creating the panoramic image](img/B04554_06_08.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![创建全景图像](img/B04554_06_08.jpg)'
- en: 'We can keep stitching images together to create a nice panoramic image. Let''s
    take a look at the code:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将图像拼接在一起以创建一个漂亮的全景图像。让我们看看代码：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Finding the overlapping regions
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找重叠区域
- en: The goal here is to find the matching keypoints so that we can stitch the images
    together. So, the first step is to get these matching keypoints. As discussed
    in the previous section, we use a keypoint detector to extract the keypoints,
    and then use a Flann based matcher to match the keypoints.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标是找到匹配的关键点，以便我们可以将图像拼接在一起。因此，第一步是获取这些匹配的关键点。如前所述，我们使用关键点检测器提取关键点，然后使用基于Flann的匹配器匹配关键点。
- en: Note
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You can learn more about Flann at [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.192.5378&rep=rep1&type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.192.5378&rep=rep1&type=pdf).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.192.5378&rep=rep1&type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.192.5378&rep=rep1&type=pdf)了解更多关于Flann的信息。
- en: The Flann based matcher is faster than Brute Force matching because it doesn't
    compare each point with every single point on the other list. It only considers
    the neighborhood of the current point to get the matching keypoint, thereby making
    it more efficient.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Flann的匹配器比Brute Force匹配更快，因为它不需要将每个点与其他列表上的每个点进行比较。它只考虑当前点的邻域来获取匹配的关键点，从而使其更高效。
- en: Once we get a list of matching keypoints, we use Lowe's ratio test to keep only
    the strong matches. David Lowe proposed this ratio test in order to increase the
    robustness of SIFT.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们得到了匹配关键点的列表，我们使用Lowe的比率测试来只保留强匹配。David Lowe提出了这个比率测试，目的是为了提高SIFT的鲁棒性。
- en: Note
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You can read more about this at [http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)了解更多相关信息。
- en: Basically, when we match the keypoints, we reject the matches in which the ratio
    of the distances to the nearest neighbor and the second nearest neighbor is greater
    than a certain threshold. This helps us in discarding the points that are not
    distinct enough. So, we use that concept here to keep only the good matches and
    discard the rest. If we don't have sufficient matches, we don't proceed further.
    In our case, the default value is 10\. You can play around with this input parameter
    to see how it affects the output.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，当我们匹配关键点时，我们会拒绝那些到最近邻和第二近邻的距离比大于某个特定阈值的匹配。这有助于我们丢弃不够独特的点。因此，我们在这里使用这个概念来只保留好的匹配并丢弃其余的。如果我们没有足够的匹配，我们不会进一步操作。在我们的情况下，默认值是10。你可以尝试调整这个输入参数，看看它如何影响输出。
- en: If we have a sufficient number of matches, then we extract the list of keypoints
    in both the images and extract the homography matrix. If you remember, we have
    already discussed homography in the first chapter. So if you have forgotten about
    it, you may want to take a quick look. We basically take a bunch of points from
    both the images and extract the transformation matrix.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有足够的匹配数，那么我们将在两张图像中提取关键点的列表并提取单应性矩阵。如果你还记得，我们在第一章中已经讨论了单应性。所以如果你已经忘记了，你可能想快速浏览一下。我们基本上从两张图像中取出一组点并提取变换矩阵。
- en: Stitching the images
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像拼接
- en: Now that we have the transformation, we can go ahead and stitch the images.
    We will use the transformation matrix to transform the second list of points.
    We keep the first image as the frame of reference and create an output image that's
    big enough to hold both the images. We need to extract information about the transformation
    of the second image. We need to move it into this frame of reference to make sure
    it aligns with the first image. So, we have to extract the translation information
    and then warp it. We then add the first image into this and construct the final
    output. It is worth mentioning that this works for images with different aspect
    ratios as well. So, if you get a chance, try it out and see what the output looks
    like.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了变换，我们可以继续拼接图像。我们将使用变换矩阵来变换第二组点。我们将第一张图像作为参考框架，创建一个足够大的输出图像来容纳这两张图像。我们需要提取关于第二图像变换的信息。我们需要将其移动到这个参考框架中，以确保它与第一张图像对齐。因此，我们必须提取平移信息并进行变换。然后我们将第一张图像添加进去，构建最终的输出。值得一提的是，这同样适用于不同宽高比的图像。所以，如果你有机会，尝试一下，看看输出是什么样子。
- en: What if the images are at an angle to each other?
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如果图像彼此成角度怎么办？
- en: Until now, we were looking at images that were on the same plane. Stitching
    those images was straightforward and we didn't have to deal with any artifacts.
    In real life, you cannot capture multiple images on exactly the same plane. When
    you are capturing multiple images of the same scene, you are bound to tilt your
    camera and change the plane. So the question is, will our algorithm work in that
    scenario? As it turns out, it can handle those cases as well.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在看同一平面上的图像。拼接这些图像是直接的，我们不需要处理任何伪影。在现实生活中，你不可能在完全相同的平面上捕捉到多张图像。当你捕捉同一场景的多张图像时，你不可避免地会倾斜相机并改变平面。所以问题是，我们的算法在那个场景下是否也能工作？实际上，它也能处理这些情况。
- en: 'Let''s consider the following image:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下图像：
- en: '![What if the images are at an angle to each other?](img/B04554_06_09.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![如果图像彼此成角度怎么办？](img/B04554_06_09.jpg)'
- en: 'Now, let''s consider another image of the same scene. It''s at an angle with
    respect to the first image, and it''s partially overlapping as well:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑同一场景的另一张图像。它与第一张图像成一定角度，并且部分重叠：
- en: '![What if the images are at an angle to each other?](img/B04554_06_10.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![如果图像彼此成角度怎么办？](img/B04554_06_10.jpg)'
- en: 'Let''s consider the first image as our reference. If we stitch these images
    using our algorithm, it will look something like this:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将第一张图像作为我们的参考。如果我们使用我们的算法拼接这些图像，它看起来可能就像这样：
- en: '![What if the images are at an angle to each other?](img/B04554_06_11.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![如果图像彼此成角度怎么办？](img/B04554_06_11.jpg)'
- en: 'If we keep the second image as our reference, it will look something like this:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将第二幅图像作为参考，它看起来可能就像这样：
- en: '![What if the images are at an angle to each other?](img/B04554_06_12.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![如果图像彼此成角度怎么办？](img/B04554_06_12.jpg)'
- en: Why does it look stretched?
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么看起来被拉伸了？
- en: 'If you observe, a portion of the output image corresponding to the query image
    looks stretched. It''s because the query image is transformed and adjusted to
    fit into our frame of reference. The reason it looks stretched is because of the
    following lines in our code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你观察，输出图像中对应查询图像的部分看起来被拉伸了。这是因为查询图像被转换并调整以适应我们的参考框架。它看起来被拉伸的原因是因为我们代码中的以下几行：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Since the images are at an angle with respect to each other, the query image
    will have to undergo a perspective transformation in order to fit into the frame
    of reference. So, we transform the query image first, and then stitch it into
    our main image to form the panoramic image.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像彼此之间成角度，查询图像将不得不进行透视变换以适应参考框架。因此，我们首先对查询图像进行变换，然后将其拼接进主图像中，以形成全景图像。
- en: Summary
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to match keypoints among multiple images. We
    discussed how to stitch multiple images together to create a panoramic image.
    We learned how to deal with images that are not on the same plane.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何在多张图像之间匹配关键点。我们讨论了如何将多张图像拼接在一起以创建全景图像。我们学习了如何处理不在同一平面上的图像。
- en: In the next chapter, we are going to discuss how to do content-aware image resizing
    by detecting "interesting" regions in the image.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何通过检测图像中的“有趣”区域来实现内容感知图像缩放。
