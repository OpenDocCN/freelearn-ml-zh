- en: Creating a Physics Simulation Based on a Pen and Paper Sketch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"James Bond lives in a nightmarish world where laws are written at the point
    of a gun."'
  prefs: []
  type: TYPE_NORMAL
- en: – Yuri Zhukov, Pravda, 30 September 1965
  prefs: []
  type: TYPE_NORMAL
- en: '"Just a moment. Three measures of Gordon''s, one of vodka, half a measure of
    Kina Lillet. Shake it very well until it''s ice-cold, then add a large thin slice
    of lemon peel. Got it?"'
  prefs: []
  type: TYPE_NORMAL
- en: – Casino Royale, Chapter 7, Rouge et Noir (1953)
  prefs: []
  type: TYPE_NORMAL
- en: James Bond is a precise man. Like a physicist, he seems to see order in a world
    where others see chaos. Another mission, another romance, another shaken drink,
    another crashing car or helicopter or skier, and another gunshot, do not change
    the way the world works—the way the Cold War works. He seems to take comfort in
    this consistency.
  prefs: []
  type: TYPE_NORMAL
- en: A psychologist might say that Bond is reenacting an unhappy childhood, which
    the novels reveal to us in brief glimpses. The boy lacked a permanent home. His
    father was an international arms dealer for the Vickers company, so the family
    moved often for work. When James was 11, his parents died in a mountain climbing
    accident, the first of many dramatic, untimely deaths in the Bond saga. An aunt
    in Kent took in the orphaned James, but the next year he was sent to boarding
    at Eton College. There, the lonesome boy became infatuated with a maid, got into
    trouble over it, and was expelled, the first of his many short-lived and fraught
    romances. Next, he was sent even further from family, to Fettes College in Scotland.
    The pattern of displacement and trouble was set. By 16, he was trying to live
    the life of a playboy in Paris. By 20, he was a dropout from the University of
    Geneva and he was off to join the Royal Navy at the height of the Second World
    War.
  prefs: []
  type: TYPE_NORMAL
- en: Amid all that upheaval, Bond did manage to learn a thing or two. He is clever—not
    just with his eyebrow-raising witty remarks, but also with his fast solutions
    to puzzles that involve mechanics, kinematics, or physics. He is never caught
    flat-footed (although he is sometimes caught in other ways).
  prefs: []
  type: TYPE_NORMAL
- en: The moral of the story is that a secret agent must practice his physics, even
    under the most trying of circumstances. An app can help with that.
  prefs: []
  type: TYPE_NORMAL
- en: When I think about problems of geometry or physics, I like to draw them with
    a pen and paper. However, I also like to see animations. Our app, `Rollingball`,
    will allow us to combine these two media. It will use computer vision to detect
    simple geometric shapes that the user can draw on paper. Then, based on the detected
    shapes, the app will create a physics simulation that the user can watch. The
    user can also influence the simulation by tilting the device to alter the simulated
    direction of gravity. The experience is like designing and playing with one's
    own version of a ball-in-a-maze puzzle, a fine toy for aspiring secret agents.
  prefs: []
  type: TYPE_NORMAL
- en: 'Building games is fun, but it is not all fun and games! We have a new list
    of skills to master in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting linear and circular edges with the Hough transform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using OpenCV in the Unity game engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a Unity game for Android
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting coordinates from OpenCV's space to Unity's space and creating three-dimensional
    objects in Unity based on our detection results in OpenCV
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customizing the appearance and physics behavior of three-dimensional objects
    in Unity, using shaders, materials, and physics materials
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drawing lines and rectangles using OpenGL calls from Unity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these goals in mind, let's get ready to play ball!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter''s project has the following software dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: Unity—a cross-platform game engine that supports Windows and Mac as development
    platforms. Development on Linux is not supported in this chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenCV for Unity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Android SDK, which comes with Android Studio.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where not otherwise noted, setup instructions are covered in [Chapter 1](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml),
    *Preparing for the Mission*. You might want to build and run the project in [Chapter
    4](61bdd7aa-b605-4061-8bfe-71084c7c7104.xhtml), *Controlling a Phone App with
    Your Suave Gestures*, to ensure that Android SDK is properly set up as part of
    Android Studio. Setup instructions for OpenCV for Unity are covered in the current
    chapter, in the section *Setting up OpenCV for Unity*. Always refer to the setup
    instructions for any version requirements. Instructions for building and running
    Unity projects are covered in the current chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The completed project from this chapter can be found in this book's GitHub repository,
    at [https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition),
    in the `Chapter006` folder. The repository doesn't contain the OpenCV for Unity
    plugin, which must be licensed and added to the project, as described in the *Setting
    up OpenCV for Unity* section in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Planning the Rollingball app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Rollingball` will be a mobile app. We will develop it in the Unity game engine
    by using a third-party plugin called **OpenCV for Unity**. The app will be compatible
    with both Android and iOS. Our build instructions will focus on Android, but we
    will also provide a few notes for readers who are experienced with the iOS build
    process (on Mac).'
  prefs: []
  type: TYPE_NORMAL
- en: For instructions on setting up Unity and finding relevant documentation and
    tutorials, please refer back to the *Setting up Unity and OpenCV* section in [Chapter
    1](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml), *Preparing for the Mission*. At
    the time of writing this book, Unity's officially supported development environments
    are Windows and Mac, although there is ongoing beta development toward Linux support.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the mobile device''s camera, `Rollingball` will scan two types of primitive
    shapes—circles and lines. The user will start by drawing any combination of these
    primitive shapes, or by setting up linear or circular objects on a plain background.
    For example, refer to the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06aa0190-2658-4f7c-9eea-abf14afcfaef.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, we have several circles drawn on a paper napkin. Our detector will work
    best with outlines, rather than solid circles, and particularly with smoothly
    drawn outlines, rather than lumpy or broken outlines. For this image, our detector
    will work best on the two rightmost circles. We also have a pen with edges that
    look like straight lines against the background of the paper. Our detector will
    work well with these linear edges.
  prefs: []
  type: TYPE_NORMAL
- en: '`Rollingball` is a simple app in which the user primarily interacts with one
    Android activity or one iOS view controller. A live video feed fills most of the
    background. When circles or lines are detected, they are highlighted in red, as
    shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/22b94b14-9bb8-4ad2-b8e4-50ae5c9e93b7.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that some linear edges are detected multiple times. Lighting effects and
    discontinuities in the pen's color create ambiguities about where its edges are
    located.
  prefs: []
  type: TYPE_NORMAL
- en: 'The user can press a button to start the physics simulation. During the simulation,
    the video pauses, the detector stops running, and the red-highlighted areas are
    replaced with cyan balls and lines. The lines are stationary, but the balls fall
    freely and may bounce off each other and off the lines. Real-world gravity, as
    measured by the mobile device''s gravity sensor, is used to control the simulated
    direction of gravity. However, the simulation is two-dimensional, and gravity
    is flattened so that it points toward an edge of the screen. The following screenshot
    shows the simulated balls after they have fallen partway down the page, bounced
    apart, and rolled along the lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15deca3d-40ac-4389-85f1-c7d84167a3d4.png)'
  prefs: []
  type: TYPE_IMG
- en: The user can press the button again to clear all the simulated objects and resume
    the live video and detection. The cycle can continue indefinitely, with the user
    choosing to simulate different drawings or different views of the same drawing.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's consider the techniques for detecting circles and lines.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting circles and lines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From `The Living Headlights` (our project in [Chapter 5](b4619968-1f90-45f0-8a77-3505624bc0c0.xhtml),* Equipping
    Your Car with a Rearview Camera and Hazard Detection*), we are already familiar
    with one technique for detecting circles. We treated the problem as a special
    case of blob detection, and we used an OpenCV class, `SimpleBlobDetector`, which
    allows us to specify many detection criteria, such as a blob's size, color, and
    circularity (or non-circularity, that is, linearity).
  prefs: []
  type: TYPE_NORMAL
- en: 'A **blob** is a shape filled with a solid (or nearly solid) color. This definition
    implies that many circular or linear objects are not detectable as blobs. In the
    following screenshot, we can see a sunlit desk with a china teapot, china bowl,
    and pewter bowl:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0b3b59eb-5cfc-4c51-8188-4198a7036671.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The bowls and the lid of the teapot have approximately circular outlines in
    this top-down view. However, they are unlikely to pass detection as blobs, because
    the interior of each shape is multicolored, especially in uneven light.
  prefs: []
  type: TYPE_NORMAL
- en: Blob detection starts with a simple threshold filter (marking bright regions
    as white and dark regions as black); a more general approach to shape detection
    should start with an edge-finding filter (marking edge regions as white and interior
    regions as black) and then a thresholding process. We define an edge as the discontinuity
    between neighboring regions of different brightness. Thus, an edge pixel has darker
    neighbors on one side and brighter neighbors on the opposite side. An edge-finding
    filter subtracts neighbor values from one side and adds them from the opposite
    side, in order to measure how strongly a pixel exhibits this edge-like contrast
    in a given direction. To achieve a measurement that is independent of edges' directions,
    we can apply multiple filters (each oriented for edges of a different direction)
    and treat each filter's output as a dimension of a vector whose magnitude represents
    the overall **edginess** of the pixel. A set of such measurements for all pixels
    is sometimes called the **derivative** of the image. Having computed the image's
    derivative, we select a threshold value based on the minimum contrast that we
    require in an edge. A high threshold accepts only high-contrast edges, while a
    lower threshold also accepts lower-contrast edges.
  prefs: []
  type: TYPE_NORMAL
- en: A popular edge-finding technique is the **Canny algorithm**. OpenCV's implementation,
    the `Imgproc.Canny` function, performs both filtering and thresholding. As arguments,
    it takes a grayscale image, an output image, a low threshold value, and a high
    threshold value. The low threshold should accept all pixels that might be part
    of a good edge. The high threshold should only accept pixels that are definitely part
    of a good edge. From the set whose members might be edge pixels, the Canny algorithm
    only accepts the members that connect to definite edge pixels. The double criteria
    help to ensure that we can accept thin extremities of a major edge, while rejecting
    edges that are altogether faint. For example, a pen stroke or the curb of a road
    extending into the distance may be a major edge with thin extremities.
  prefs: []
  type: TYPE_NORMAL
- en: Having identified edge pixels, we can count how many of them are intersected
    by a given primitive shape. The greater the number of intersections, the more
    confident we can be that the given primitive shape correctly represents an edge
    in the image. Each intersection is called a **vote**, and a shape needs a specified
    number of votes to be accepted as a real edge's shape. Out of all possible primitive
    shapes (of a given kind) in the image, we consider an evenly spaced, representative
    sample. We do so by specifying a step size for the shapes' geometric parameters.
    (For example, a line's parameters are a point and angle, while a circle's parameters
    are a center point and radius.) This sample of possible shapes is called a **grid**,
    the individual shapes in it are called **cells**, and votes are said to be cast
    in cells. This process (tallying the matches between actual edge pixels and a
    sample of possible shapes) is the core of a technique called the **Hough transform**,
    which has various specializations, such as **Hough line detection** and **Hough
    circle detection**.
  prefs: []
  type: TYPE_NORMAL
- en: Hough line detection has two implementations in OpenCV—`Imgproc.HoughLines`,
    which is based on the original Hough transform, and `Imgproc.HoughLinesP`, which
    is based on a probabilistic variant of the Hough transform. `Imgproc.HoughLines`
    does an exhaustive count of intersections for all possible lines for a given pair
    of step sizes, in pixels and in radians. `Imgproc.HoughLinesP` is usually faster
    (particularly in images with a few long line segments), as it takes possible lines
    in a random order and discards some of the possible lines after finding a good
    line in a region. `Imgproc.HoughLines` expresses each line as a distance from
    the origin and an angle, whereas `Imgproc.HoughLinesP` expresses each line as
    two points, the endpoints of a detected segment of the line, which is a more useful
    representation, since it gives us the option to treat the detection results as
    line segments, rather than indefinitely long lines. For both functions, the arguments
    include the image (which should be preprocessed with Canny, or a similar algorithm),
    the step sizes in pixels and radians, and the minimum number of intersections
    required to accept a line. The arguments to `Imgproc.HoughLinesP` also include
    a minimum length between endpoints and a maximum gap, where a gap consists of
    non-edge pixels between edge pixels that intersect the line.
  prefs: []
  type: TYPE_NORMAL
- en: Hough circle detection has one implementation in OpenCV, `Imgproc.HoughCircles`,
    which is based on a variant of the Hough transform that makes use of gradient
    information at edges. This function's arguments include the image (not preprocessed
    with Canny or a similar algorithm, as `Imgproc.HoughCircles` applies the Canny
    algorithm internally), a downsampling factor (which acts somewhat like a blur
    factor to smooth the edges of potential circles), a minimum distance between detected
    circles' centers, a Canny edge detection threshold, a minimum number of intersections
    required to accept a circle, and minimum and maximum radii. The specified Canny
    threshold is the upper threshold; internally, the lower threshold is hardcoded
    as half of the upper threshold.
  prefs: []
  type: TYPE_NORMAL
- en: For more details on the Canny algorithm, the Hough transform, and OpenCV's implementations
    of them, refer to *Chapter 7, Extracting Lines, Contours, and Components,* in
    Robert Laganière's book, *OpenCV 3 Computer Vision Application Programming Cookbook*
    (*Packt Publishing, 2017*).
  prefs: []
  type: TYPE_NORMAL
- en: Despite using a more efficient algorithm than the original Hough transform,
    `Imgproc.HoughCircles` is a computationally expensive function. Nonetheless, we
    use it in `Rollingball`, since many of today's mobile devices can handle the cost.
    For low-powered devices, such as Raspberry Pi, we would consider blob detection
    as a cheaper alternative. `Imgproc.HoughCircles` tends to work best with outlines
    of circles, whereas blob detection only works on solid circles. For line detection,
    we use the `Imgproc.HoughLinesP` function, which is not as expensive as OpenCV's
    other Hough detectors.
  prefs: []
  type: TYPE_NORMAL
- en: Having chosen the algorithms and their OpenCV implementations, let's set up
    the plugin that will let us easily access this functionality in Unity.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up OpenCV for Unity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unity provides a cross-platform framework for scripting games in C#. However,
    it also supports platform-specific plugins in languages such as C, C++, Objective-C
    (for Mac and iOS), and Java (for Android). Developers may publish these plugins
    (and other assets) on the Unity Asset Store. Many published plugins represent
    a large amount of high-quality work, and buying one may be more economical than
    writing your own.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV for Unity, by ENOX SOFTWARE ([https://enoxsoftware.com](https://enoxsoftware.com)),
    is a $95 plugin (at the time of writing this book). It offers a C# API that is
    closely based on OpenCV's official Java (Android) bindings. However, the plugin
    wraps OpenCV's C++ libraries and is compatible with Android, iOS, Windows Phone,
    Windows, Mac, Linux, and WebGL. It is reliable in my experience, and it saves
    us a lot of work that we would otherwise put into custom C++ code and C# wrappers.
    Moreover, it comes with several valuable samples.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV for Unity is not the only set of third-party C# bindings for OpenCV.
    Alternatives include OpenCvSharp ([https://github.com/shimat/opencvsharp](https://github.com/shimat/opencvsharp))
    and Emgu CV ([http://www.emgu.com](http://www.emgu.com)). However, in this book, we
    use OpenCV for Unity because it offers easy integration with Unity and it tends
    to be updated quickly when new OpenCV versions are released.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go shopping. Open Unity and create a new project. From the menu bar, select
    Window | Asset Store. If you haven''t already created a Unity account, follow
    the prompts to create one. Once you have logged into the store, you should see
    the Asset Store window. Enter `OpenCV for Unity` in the search bar in the upper-right
    corner. Click on the OpenCV for Unity link among the search results. You should
    see something similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e9246272-9d84-4bb3-984f-3315282a08cd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the Add to Cart button and complete the transaction, as directed.
    Click on the Download button and wait for the download to complete. Click on the
    Import button. You should now see the Import Unity Package window, as shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cedde273-d2e9-4bfa-9451-73a684b3cd2c.png)'
  prefs: []
  type: TYPE_IMG
- en: This is a list of all of the files in the bundle that we just purchased. Ensure
    that all of their checkboxes are checked, and then click on the Import button.
    Soon, you should see all of the files in the Project pane of the Unity editor.
  prefs: []
  type: TYPE_NORMAL
- en: The bundle includes further setup instructions and helpful links in the `OpenCVForUnity/ReadMe.pdf`
    file. Read the `ReadMe!` note that contains useful instructions for iOS if you
    wish to build for that platform.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, paths are relative to the project's `Assets` folder,
    unless otherwise specified.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's try the samples.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring and building the Unity project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unity supports many target platforms. Switching to a new target is easy, as
    long as our plugins support it. We just need to set a few build configuration
    values, some of which are shared across multiple targets, and some of which are
    platform-specific.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the menu bar, select Unity | Preferences..., which should bring up the
    Preferenceswindow. Click on the External Tools tab and set Android SDK to be the
    base path to your Android SDK installation. Normally, for an Android Studio environment,
    the path to the SDK is `C:\Users\username\AppData\Local\Android\sdk\` on Windows
    or `Users/<your_username>/Library/Android/sdk/` on Mac. Now, the window should
    look similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a2b0a88-878e-4354-977b-c4ee096370af.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, from the menu bar, select File | Build Settings. The Build Settings window
    should appear. Drag all of the sample scene files, such as `OpenCVForUnity/Examples/OpenCVForUnityExample.unity`
    and `OpenCVForUnity/Examples/Advanced/ComicFilterExample/ComicFilterExample.unity`,
    from the Project pane to the Scenes In Build list in the Build Settings window.
    The first scene in the list is the start-up scene. Ensure that `OpenCVForUnityExample`
    is the first in the list. (Drag and drop the list items to reorder them.) Also,
    ensure that all of the scenes'' checkboxes are checked. Click on the Android platform,
    and then the Switch Platform button. The window should now look like the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/52291210-4d8e-41d0-8e2a-cb3c9db41479.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the Player Settings... button. A list of settings should appear in
    the Inspector pane of the Unity editor. Fill in a Company Name, such as `Nummist
    Media Corporation Limited`, and a Product Name, such as `Rollingball`. Optionally,
    select a Default Icon (which must be an image file that you have added somewhere
    in the Project pane). Click on Resolution and Presentation to expand it, and then,
    for Default Orientation, select Portrait. So far, the PlayerSettings options should
    look similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1a93fd9b-ea54-4d00-8a0b-1c64814e7991.png)'
  prefs: []
  type: TYPE_IMG
- en: Click on Other Settings to expand it, and then fill out a Bundle Identifier
    with something like `com.nummist.rollingball`. Now, we have finished with the
    PlayerSettings options.
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that an Android device is plugged in and that USB debugging is enabled
    on the device. Go back to the Build Settings window and click on Build and Run.
    Specify a path for the build. It is good practice to separate the build path from
    the Unity project folder, just as you would normally separate builds from source
    code. Once the build has begun, a progress bar should appear. Watch the Console
    pane of the Unity editor to be sure that no build errors occur. When the build
    has finished, it is copied onto the Android device, and then it runs.
  prefs: []
  type: TYPE_NORMAL
- en: Enjoy the OpenCV for Unity samples! If you like, browse their source code and
    scenes in the Unity editor.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we have our own scene to build!
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Rollingball scene in Unity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's create a directory, `Rollingball`, to contain our application-specific
    code and assets. Right-click in the Project pane and choose Create | Folder from
    the context menu. Rename the new folder `Rollingball`. Create a subfolder, `Rollingball/Scenes`,
    in a similar way.
  prefs: []
  type: TYPE_NORMAL
- en: From the menu bar, select File | New Scene and then File | Save As.... Save
    the scene as `Rollingball/Scenes/Rollingball.unity`.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, our newly created scene only contains a camera (that is, the virtual
    world''s camera, not a capture device) and a directional light. The light will
    illuminate the balls and lines in our physics simulation. We are going to add
    three more objects, in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: From the menu bar, select GameObject | 3D Object | Quad. An object called `Quad`
    should appear in the Hierarchy pane. Rename `Quad` to `VideoRenderer`. This object
    is going to represent the live video feed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the menu bar, select GameObject | Create Empty. An object called `GameObject`
    should appear in the Hierarchy pane. Rename `GameObject` to `QuitOnAndroidBack`.
    Later, it will hold a script component that responds to the standard back button
    on Android.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Objects in the Hierarchy are called **game objects**, and the sections that
    are visible in their Inspector panes are called **components**.
  prefs: []
  type: TYPE_NORMAL
- en: Drag the Main Camera onto the VideoRenderer to make the former a child of the
    latter. A child moves, rotates, and scales up or down when its parent does. The
    relevance is that we want our camera to maintain a predictable relationship with
    the live video background.
  prefs: []
  type: TYPE_NORMAL
- en: Parent-child relationships in the Hierarchy do not represent object-oriented
    inheritance; in other words, a child does not have an **is** **a** relationship
    with its parent. Rather, a parent who has a one-to-many **has a **relationship
    with its children.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the new objects created and the Main Camera reparented, the Hierarchy
    should look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0d1bae8f-c080-4dfc-89f2-cdb71e85aa4b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The VideoRenderer and Main Camera will be configured in code, based on the
    properties of the mobile device''s video camera. However, let''s set some reasonable
    defaults. Select the VideoRenderer in the Hierarchy, and then, in the Inspector
    pane, edit its Transform properties to match the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cbaee7bf-a058-4e31-a297-3ace58ef5cf3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, select Main Camera and edit its Transform and Camera properties
    to match the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/090ddbd6-3ecf-44c1-b4e5-b04cc88540e5.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that we have configured an orthographic projection, meaning that the objects'
    pixel sizes are constant, regardless of their distance from the camera. This configuration
    is appropriate for a two-dimensional game or simulation, such as `Rollingball`.
  prefs: []
  type: TYPE_NORMAL
- en: These four objects are the foundation of our scene. The rest of the project
    involves attaching custom properties to these objects and using C# scripts to
    control them and create new objects around them.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Unity assets and adding them to the scene
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The custom properties and behaviors in a Unity project are defined through
    various types of files that are generically called **assets**. Our project has
    four remaining questions and requirements that we must address by creating and
    configuring assets:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the appearance of the surfaces in the scene—namely, the video feed,
    the detected circles and lines, and the simulated balls and lines? We need to
    write *shader* code and create *Material* configurations to define the appearance
    of these surfaces.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How bouncy are the balls? We need to create a *Physics Material* configuration
    to answer this all-important question.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What objects represent a simulated ball and a simulated line? We need to create
    and configure *Prefab* objects that the simulation can instantiate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does it all behave? We need to write Unity *scripts*—specifically, code
    that subclasses a Unity class called `MonoBehaviour`—in order to control objects
    in the scene at various stages in their life cycles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following subsections will tackle these requirements one by one.
  prefs: []
  type: TYPE_NORMAL
- en: Writing shaders and creating materials
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **shader** is a set of functions that run on the GPU. Although such functions
    can be applied to general-purpose computing, typically, they are used for graphics
    rendering—that is, to define the color of output pixels on the screen based on
    input that describes the lighting, geometry, surface texture, and perhaps other
    variables, such as time. Unity comes with many shaders for common styles of three-dimensional
    and two-dimensional rendering. We can also write our own shaders.
  prefs: []
  type: TYPE_NORMAL
- en: For in-depth tutorials on shader scripting in Unity, see the *Unity 2018 Shaders
    and Effects Cookbook,* *by John P. Doran and Alan Zucconi* (*Packt Publishing,
    2018*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a folder, `Rollingball/Shaders`, and then create a shader in
    it (by clicking on Create |Shader | Standard Surface Shader in the Project pane''s
    context menu). Rename the shader `DrawSolidColor`. Double-click on it to edit
    it, and replace the contents with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This humble shader has one parameter—a color. The shader renders pixels in this
    color regardless of conditions, such as lighting. For the purposes of the Inspector
    GUI, the shader's name is Draw | Solid Color, and its parameter's name is Main
    Color.
  prefs: []
  type: TYPE_NORMAL
- en: A material has a shader and a set of parameter values for the shader. The same
    shader may be used by multiple materials, which may use different parameter values.
    Let's create a material that draws solid red. We will use this material to highlight
    detected circles and lines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new folder, `Rollingball/Materials`, and then create a material in
    it (by clicking on Create | Material in the context menu). Rename the material
    `DrawSolidRed`. Select it, and in the Inspector, set its shader to Draw | Solid
    Color and its Main Color to the RGBA value for red (`255`, `0`, `0`, `255`). The
    Inspector should now look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/296677c6-e4bd-4767-a931-726f5d53c06c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We are going to create two more materials using shaders that come with Unity.
    First, create a material, name it `Cyan`, and configure it so that its shader
    is Legacy Shaders | Diffuse and its Main Color is cyan (`0`, `255`, `255`, `255`).
    Leave the Base (RBG) texture as None. We will apply this material to the simulated
    balls and lines. Its Inspector should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cc6d7f0e-ff56-4b3f-9b80-5734b44d366e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, create a material named Video and configure it so that its shader is Unlit | Texture.
    Leave the Base (RBG) texture as None. Later, through code, we will assign the
    video texture to this material. Drag the Video material (from the Project pane)
    to VideoRenderer (in the Hierarchy pane) in order to assign the material to the
    quad. Select VideoRenderer and confirm that its Inspector includes the following
    items:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bad6bd55-589a-42f9-bf97-b00382c86d8f.png)'
  prefs: []
  type: TYPE_IMG
- en: We will assign the remaining materials once we have created prefabs and scripts.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have made materials for rendering, let's look at the analogous concept
    of physics materials.
  prefs: []
  type: TYPE_NORMAL
- en: Creating physics materials
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although Unity's rendering pipeline can run custom functions that we write in
    shaders, its physics pipeline runs fixed functions. Nonetheless, we can configure
    the parameters of those functions through physics materials.
  prefs: []
  type: TYPE_NORMAL
- en: Unity's physics engine is based on NVIDIA PhysX. PhysX supports acceleration
    through CUDA on NVIDIA GeForce GPUs. However, on typical mobile devices, the physics
    calculations will run on the CPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a folder, `Rollingball/Physics Materials`, and in it, create
    a physics material (by clicking on Create | Physics Material in the context menu).
    Rename the physics material `Bouncy`. Select it, and note that it has the following
    properties in the Inspector:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dynamic Friction**: This is the ratio between the force that presses two
    objects together (for example, gravity) and the frictional force that resists
    continued motion along the surface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Static Friction**: This is the ratio between the force pressing two objects
    together (for example, gravity) and the frictional force that resists initial
    motion along the surface. Refer to Wikipedia ([https://en.wikipedia.org/wiki/Friction#Approximate_coefficients_of_friction](https://en.wikipedia.org/wiki/Friction#Approximate_coefficients_of_friction))
    for sample values. For static friction, a value of 0.04 is like Teflon on Teflon,
    a value of 1.0 is like rubber on concrete, and a value of 1.05 is like copper
    on cast iron.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bounciness**: This is the proportion of an object''s kinetic energy that
    it retains when it bounces off another surface. Here, a value of `0` means that
    the object doesn''t bounce. A value of `1` means that it bounces without a loss
    of energy. A value greater than 1 means that it (unrealistically) gains energy
    when it bounces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Friction Combine**: When objects collide, which object''s friction value
    affects this object? The options are Average, Minimum, Multiply, and Maximum.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bounce Combine**: When objects collide, which object''s bounciness value
    affects this object? The options are Average, Minimum, Multiply, and Maximum.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Careful! Are those physics materials explosive?
  prefs: []
  type: TYPE_NORMAL
- en: A physics simulation is said to explode when the values grow continually and
    overflow the system's floating-point numeric limits. For example, if a collision's
    combined bounciness is greater than `1` and the collision occurs repeatedly, then
    over time, the forces tend toward infinity. Kaboom! We broke the physics engine.
  prefs: []
  type: TYPE_NORMAL
- en: Even without weird physics materials, numeric problems arise in scenes of an
    extremely large or small scale. For example, consider a multiplayer game that
    uses input from the **Global Positioning System** (**GPS**) so that objects in
    a Unity scene are positioned according to the players' real-world longitude and
    latitude. The physics simulation cannot handle a human-sized object in this scene,
    because the object and the forces acting on it are so small that they vanish inside
    the margin of floating-point error! This is a case where the simulation implodes (rather
    than explodes).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s set the Bounciness to `1` (very bouncy!) and leave the other values
    at their defaults. Later, you can adjust everything to your tastes, if you wish.
    The Inspector should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b0fe9302-677d-4cf1-80bb-24e60d39a813.png)'
  prefs: []
  type: TYPE_IMG
- en: Our simulated lines will use default physics parameters, so they don't need
    a physics material.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our rendering materials and physics materials, let's create
    prefabs for an entire simulated ball and an entire simulated line.
  prefs: []
  type: TYPE_NORMAL
- en: Creating prefabs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **prefab** is an object that isn't a part of a scene itself, but is designed
    to be copied into scenes during editing or at runtime. It can be copied many times
    to make many objects in the scene. At runtime, the copies have no special connection
    to the prefab or each other, and all copies can behave independently. Although
    the role of a prefab is sometimes likened to the role of a class, a prefab is
    not a type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though prefabs are not part of a scene, they are created and typically
    edited through a scene. Let''s create a sphere in the scene by selecting GameObject | 3D
    Object | Sphere from the menu bar. An object named **Sphere** should appear in
    the Hierarchy. Rename it `SimulatedCircle`. Drag each of the following assets
    from the Project pane onto `SimulatedCircle` in the Hierarchy:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cyan** (in `Rollingball/Materials`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bouncy** (in `Rollingball/PhysicsMaterials`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, select SimulatedCircle. In the Inspector, click on Add Component and select
    Physics | Rigidbody. A Rigidbody section should appear in the Inspector. In this
    section, expand the Constraints field and check Freeze Position | Z. The effect
    of this change is to constrain the sphere''s motion to two dimensions. Confirm
    that the Inspector looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf5b268b-0e8a-496c-b5ab-dfcb42e8810d.png)'
  prefs: []
  type: TYPE_IMG
- en: Create a folder, `Rollingball/Prefabs`, and drag `SimulatedCircle` from the Hierarchy
    into the folder in the Project pane. A prefab, also named `SimulatedCircle`, should
    appear in the folder. Meanwhile, the name of the `SimulatedCircle` object in the Hierarchy
    should turn blue to indicate that the object has a prefab connection. Changes
    to the object in the scene may be applied back to the prefab by clicking on the
    Apply button in the scene object's Inspector. Conversely, changes to the prefab
    (at edit time, not at runtime) are automatically applied to instances in scenes,
    except for properties in which an instance has unapplied changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s follow similar steps to create a prefab of a simulated line. Create
    a cube in the scene by selecting GameObject | 3D Object | Cube from the menu bar.
    An object named Cube should appear in the Hierarchy. Rename it `SimulatedLine`.
    Drag Cyan from the Project pane onto SimulatedLine in the Hierarchy. Select SimulatedLine,
    add a Rigidbody component, and, in the Rigidbody section of its Inspector, check
    Is Kinematic, which means that the object is not moved by the physics simulation
    (even though it is a part of the simulation for the purpose of other objects colliding
    with it). Recall that we want the lines to be stationary. They are just obstacles
    for the falling balls. The Inspector should now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3deaf9e6-9d68-4cd7-9796-6ab38e5a9496.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's clean up our scene by deleting the instances of the prefabs from the Hierarchy so
    that we don't have any circles or lines in the scene when it opens. (However,
    we want to keep the prefabs themselves in the Project so that we can instantiate
    them later through our scripts.) Now, let's turn our attention to the writing
    of scripts, which, among other things, are able to copy prefabs at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Writing our first Unity script
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we mentioned earlier, a Unity script is a subclass of `MonoBehaviour`. A
    `MonoBehaviour` object can obtain references to objects in the Hierarchy and components
    that we attach to these objects in the Inspector. A `MonoBehaviour` object also
    has its own Inspector, where we can assign additional references, including references
    to Project assets, such as prefabs. At runtime, Unity sends messages to all `MonoBehaviour`
    objects when certain events occur. A subclass of `MonoBehaviour` may implement
    callbacks for any of these messages. `MonoBehaviour` supports more than 60 standard
    message callbacks. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Awake`: This is called during initialization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Start`: This is called after `Awake`, but before the first call to `Update`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Update`: This is called every frame.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OnGUI`: This is called when the GUI overlay is ready for rendering instructions
    and GUI events are ready to be handled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OnPostRender`: This is called after the scene is rendered. This is an appropriate
    callback in which to implement post-processing effects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OnDestroy`: This is called when this instance of the script is about to be
    destroyed. For example, this happens when the scene is about to end.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information on the standard message callbacks and the arguments that
    some callbacks' implementations may optionally take, see the official documentation
    at [http://docs.unity3d.com/ScriptReference/MonoBehaviour.html](http://docs.unity3d.com/ScriptReference/MonoBehaviour.html).
    Also, note that we can send custom messages to all `MonoBehaviour` objects by
    using the `SendMessage` method.
  prefs: []
  type: TYPE_NORMAL
- en: Implementations of these and Unity's other callbacks may be `private`, `protected`,
    or `public`. Unity calls them regardless of the protection level.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, then, scripts are the glue—the game logic—connecting runtime events
    to various objects that we see in the Project, Hierarchy, and Inspector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a folder, `Rollingball/Scripts`, and in that, create a script
    (by clicking on Create | C# Script in the context menu). Rename the script `QuitOnAndroidBack`
    and double-click on it to edit it. Replace its contents with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We are using a namespace, `com.nummist.rollingball`, to keep our code organized
    and to avoid potential conflicts between our type names and type names in other
    parties' code. Namespaces in C# are like packages in Java. Our class is called
    `QuitOnAndroidBack`. It extends Unity's `MonoBehaviour` class. We use the `sealed`
    modifier (similar to Java's `final` modifier) to indicate that we don't intend
    to create subclasses of `QuitOnAndroidBack`.
  prefs: []
  type: TYPE_NORMAL
- en: Note that `MonoBehaviour` uses the UK English spelling of behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to Unity's callback system, the script's `Start` method is called after
    the object is initialized—in this case, at the start of the scene. Our `Start`
    method ensures that the standard Android navigation bar is visible. After `Start`,
    the script's `Update` method gets called every frame. It checks whether the user
    has pressed a key (or button) that is mapped to the `Escape` keycode. On Android,
    the standard back button is mapped to `Escape`. When the key (or button) is pressed,
    the application quits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the script and drag it from the **Project** pane to the `QuitOnAndroidBack`
    object in the Hierarchy. Click on the `QuitOnAndroidBack` object and confirm that
    its Inspector looks like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a6142e4-2d6c-46e6-8e48-b82452922c60.png)'
  prefs: []
  type: TYPE_IMG
- en: That was an easy script, right? The next one is a bit trickier, but more fun,
    because it handles everything except quitting.
  prefs: []
  type: TYPE_NORMAL
- en: Writing the main Rollingball script
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create a folder, `Rollingball/Scripts`, and in it, create a script (by
    clicking on Create | C# Script in the context menu). Rename the script `DetectAndSimulate`
    and double-click on it to edit it. Delete its default contents and begin the code
    with the following `import` statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let''s declare our namespace and class with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that the class has an attribute, `[RequireComponent (typeof(Camera))]`,
    which means that the script can only be attached to a game object that has a camera
    (not a video camera, but rather, a game-world camera representing the player's
    virtual eye in the scene). We specify this requirement because we are going to
    highlight the detected shapes through an implementation of the standard `OnPostRender`
    callback, and this callback only gets called for scripts attached to a game object
    with a camera.
  prefs: []
  type: TYPE_NORMAL
- en: '`DetectAndSimulate` needs to store representations of circles and lines in
    both two-dimensional screen space and three-dimensional world space. Coordinates
    in screen space (that is, on the user''s screen) are measured in pixels, with
    the screen''s top-left pixel pixel being the origin. Coordinates in world space
    (that is, in the game scene where we recently positioned `VideoRenderer` and `Main
    Camera`) are measured in arbitrary units with an arbitrary origin. The representations
    of circles and lines don''t need to be visible to any other class in our application,
    so it is appropriate to define their types as private inner structs. Our `Circle`
    type stores two-dimensional coordinates representing the circle''s center in screen
    space, a float representing its radius in screen space, and three-dimensional
    coordinates representing the circle''s center in world space. A constructor accepts
    all of these values as arguments. Here is the `Circle` implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We define another inner struct, `Line`, to store two sets of two-dimensional
    coordinates representing endpoints in screen space and two sets of three-dimensional
    coordinates representing the same endpoints in world space. A constructor accepts
    all of these values as arguments. Here is the implementation of `Line`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define member variables that are editable in the Inspector. Such a
    variable is marked with the `[SerializeField]` attribute, which means that Unity
    serializes the variable, despite it being non-public. (Alternatively, public variables
    are also editable in the Inspector.) The following four variables describe our
    preferences for camera input, including the direction the camera faces, its resolution,
    and its frame rate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: At runtime, the camera devices and modes available to us may differ from these
    preferences.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also make several more variables editable in the Inspector—namely,
    a reference to the video background''s renderer, a reference to the material for
    highlighting detected shapes, a factor for adjusting the scale of the simulation''s
    gravity, references to the simulated shapes'' prefabs, and a font size for the
    button:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We also have a number of member variables that don''t need to be editable in
    the Inspector. Among them are references to the game world''s camera, a reference
    to the real-world camera''s video texture, matrices to store images and intermediate
    processing results, and measurements relating to camera images, the screen, simulated
    objects, and the button:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We store a matrix of Hough circle representations in OpenCV''s format (which
    has image coordinates for a landscape image, in this case) and a list of circle
    representations in our own `Circle` format (which has screen coordinates for a
    portrait screen, as well as three-dimensional coordinates for a game world):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we store a matrix of Hough line representations in OpenCV''s format
    and a list of line representations in our own `Line` format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We hold a reference to the gyroscope input device and we store the magnitude
    of gravity to be used in our physics simulation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We (and the Unity API) are using the terms **gyroscope** and **gyro** loosely.
    We are referring to a fusion of motion sensors that may or may not include a real
    gyroscope. A gyroscope can be simulated, albeit poorly, by using other real sensors,
    such as an accelerometer or gravity sensor.
  prefs: []
  type: TYPE_NORMAL
- en: Unity provides a property, `SystemInfo.supportsGyroscope`, to indicate whether
    the device has a real gyroscope. However, this information doesn't concern us.
    We just use Unity's `Gyroscope.gravity` property, which might be derived from
    a real gravity sensor or might be simulated by using other real sensors, such
    as an accelerometer and/or gyroscope. Unity Android apps are configured to require
    an accelerometer by default, so we can safely assume that at least a simulated
    gravity sensor is available.
  prefs: []
  type: TYPE_NORMAL
- en: 'We keep track of a list of simulated objects, and we provide a property, `simulating`,
    that is `true` when the list is non-empty:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s turn our attention to methods. We implement the standard `Start`
    callback. The implementation begins by getting a reference to the attached camera,
    initializing matrices, getting a reference to the gyro, and computing the magnitude
    of the game world''s gravity, as seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `MonoBehaviour` object provides getters for many components that may be
    attached to the same game object as the script. Such components would appear alongside
    the script in the Inspector. For example, the `camera` getter returns a `Camera`
    object (or `null`, if none are present). These getters are expensive because they
    use introspection. Thus, if you need to refer to a component repeatedly, it is
    more efficient to store the reference in a member variable by using a statement
    such as `_camera = camera;`.
  prefs: []
  type: TYPE_NORMAL
- en: You might be wondering why we initialize `Mat` objects in the `Start` method,
    instead of initializing them when we declare them or in a constructor for `DetectAndSimulate`.
    The reason is that the OpenCV libraries are not necessarily loaded until after
    scripts such as `DetectAndSimulate` have been constructed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of `Start` proceeds by finding a camera that faces the required
    direction (either front or rear, depending on the value of the preceding `useFrontFacingCamera`
    field). If we are playing the scene in the Unity editor (in order to debug the
    script and scene during development), we hardcode the camera direction to be front-facing,
    in order to support typical webcams. If no suitable camera is found, the method
    returns early, as seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Throughout our implementation of `DetectAndSimulate`, when we encounter an unrecoverable
    runtime problem, we call `Destroy(this);`, thereby deleting the instance of the
    script and preventing further messages from reaching its callbacks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Start` callback concludes by activating the camera and gyroscope (including
    the gravity sensor) and launching a helper coroutine called `Init`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: A **coroutine** is a method that doesn't necessarily run to completion in one
    frame. Rather, it can `yield` for one or more frames, in order to wait for a certain
    condition to be fulfilled or to make something happen after a defined delay. Note
    that a coroutine runs on the main thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our `Init` coroutine begins by waiting for the camera to capture the first
    frame. Then, we determine the frame''s dimensions and we create OpenCV matrices
    to match these dimensions. Here is the first part of the method''s implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The coroutine proceeds by configuring the game world''s orthographic camera
    and video quad to match the capture resolution and to render the video texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The device''s screen and captured camera images likely have different resolutions.
    Moreover, recall that our application is configured for portrait orientation (in
    PlayerSettings). This orientation affects screen coordinates, but not the coordinates
    in camera images, which will remain in landscape orientation. Thus, we need to
    calculate the conversion factors between image coordinates and screen coordinates,
    as seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Our conversions will be based on fitting the video background to the width of
    the portrait screen, while either letterboxing or cropping the video at the top
    and bottom, if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'The thickness of the simulated lines and the dimensions of the button are based
    on the screen resolution, as seen in the following code, which concludes the `Init`
    coroutine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We implement the standard `Update` callback by processing gravity sensor input
    and processing camera input, provided that certain conditions are met. At the
    beginning of the method, if OpenCV objects are not yet initialized, the method
    returns early. Otherwise, the game world''s direction of gravity is updated based
    on the real-world direction of gravity, as detected by the device''s gravity sensor.
    Here is the first part of the method''s implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, if there is no new camera frame ready or if the simulation is currently
    running, the method returns early. Otherwise, we convert the frame into OpenCV''s
    format, convert it into gray, find the edges, and call two helper methods, `UpdateCircles`
    and `UpdateLines`, to perform shape detection. Here is the relevant code, which
    concludes the `Update` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `UpdateCircles` helper method begins by performing Hough circle detection.
    We are looking for circles at least `10.0` pixels apart, with a radius of at least
    `5.0` pixels, and at most, `60` pixels. We specify that internally, `HoughCircles`
    should use a Canny upper threshold of `200`, down sample by a factor of `2`, and
    require `150.0` intersections to accept a circle. We clear the list of any previously
    detected circles. Then, we iterate over the results of the Hough circle detection.
    Here is the opening of the method''s implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We use a helper method, `ConvertToScreenPosition`, to convert each circle''s
    center point from the image space to the screen space. We also convert its diameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We use another helper method, `ConvertToWorldPosition`, to convert the circle''s
    center point from the screen space to the world space. We also convert its diameter.
    Having done our conversions, we instantiate a `Circle` and add it to the list.
    Here is the code, which completes the `UpdateCircles` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `UpdateLines` helper method begins by performing probabilistic Hough line
    detection with step sizes of one pixel and one degree. For each line, we require
    at least `50` detected intersections with edge pixels, a length of at least `50`
    pixels, and no gaps of more than `10.0` pixels. We clear the list of any previously
    detected lines. Then, we iterate over the results of the Hough line detection.
    Here is the first part of the method''s implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We use our `ConvertToScreenPosition` helper method to convert each line''s
    endpoints from the image space to the screen space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we use our `ConvertToWorldPosition` helper method to convert the
    line''s endpoints from the screen space to the world space. Having done our conversions,
    we instantiate a `Line` and add it to the list. Here is the code, which completes
    the `UpdateLines` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `ConvertToScreenPosition` helper method takes into account the fact that
    our screen coordinates are in portrait format, whereas our image coordinates are
    in landscape format. The conversion from image space to screen space is implemented
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `ConvertToWorldPosition` helper method uses Unity''s built-in raycasting
    functionality and our specified target distance, `raycastDistance`, to convert
    the given two-dimensional screen coordinates into three-dimensional world coordinates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We implement the standard `OnPostRender` callback by checking whether any simulated
    balls or lines are present, and, if not, by calling a helper method, `DrawPreview`.
    Here is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The `DrawPreview` helper method serves to show the positions and dimensions
    of detected circles and lines, if any. To avoid unnecessary draw calls, the method
    returns early if there are no objects to draw, as seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Having determined that there are detected shapes to draw, the method proceeds
    by configuring the OpenGL context to draw in the screen space by using `drawPreviewMaterial`.
    This setup is seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'If there are any detected circles, we do one draw call to highlight them all.
    Specifically, we tell OpenGL to begin drawing quads, we feed it the screen coordinates
    of squares that approximate the circles, and then we tell it to stop drawing quads.
    Here is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, if there are any detected lines, we do one draw call to highlight
    them all. Specifically, we tell OpenGL to begin drawing lines, we feed it the
    lines'' screen coordinates, and then we tell it to stop drawing lines. Here is
    the code, which completes the `DrawPreview` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We implement the standard `OnGUI` callback by drawing a button. Depending on
    whether simulated balls and lines are already present, the button says either
    Stop Simulation or Start Simulation. (However, if there are no simulated balls
    or lines, and there are also no detected balls or lines, then the button is not
    shown at all.) When the button is clicked, a helper method is called (either `StopSimulation`
    or `StartSimulation`). Here is the code for `OnGUI`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The `StartSimulation` helper method begins by pausing the video feed and placing
    copies of the `simulatedCirclePrefab` atop the detected circles. Each instance
    is scaled to match a detected circle''s diameter. Here is the first part of the
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The method finishes by placing copies of `simulatedLinePrefab` atop the detected
    lines. Each instance is scaled to match a detected line''s length. Here is the
    rest of the method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The `StopSimulation` helper method simply serves to resume the video feed,
    delete all simulated balls and lines, and clear the list that contained these
    simulated objects. With the list empty, the conditions for the detectors to run
    (in the `Update` method) are fulfilled again. `StopSimulation` is implemented
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'When the script''s instance is destroyed (at the end of the scene), we ensure
    that the webcam and gyroscope are released, as seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Save the script and drag it from the Project pane to the Main Camera object
    in the Hierarchy. Click on the Main Camera object, and, in the Detect And Simulate
    (Script) section of its Inspector, drag the following objects to the following
    fields:'
  prefs: []
  type: TYPE_NORMAL
- en: Drag `VideoRenderer` (from the Hierarchy) to the Video Renderer field (in the
    Inspector)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drag `DrawSolidRed` (from `Rollingball/Materials` in the Project pane) to the
    Draw Preview Material field (in the Inspector)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drag `SimulatedCircle` (from `Rollingball/Prefabs` in the Project pane) to the
    Simulated Circle Prefab field (in the Inspector)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drag `SimulatedLine` (from `Rollingball/Prefabs` in the Project pane) to the
    Simulated Line Prefab field (in the Inspector)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After these changes, the script''s section in the Inspector should look like
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bcfcbe15-3f81-4b7a-8c3a-cc50e7236ee6.png)'
  prefs: []
  type: TYPE_IMG
- en: Our main scene is complete! Now, we need a simple launcher scene that is responsible
    for obtaining the user's permission to access the camera and for launching the
    main scene.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the launcher scene in Unity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our `Rollingball` scene, and specifically the `DetectAndSimulate` script, attempts
    to access a camera through Unity's `WebCamDevice` and `WebCamTexture` classes.
    Unity is somewhat smart about camera permissions on Android. At the start of the
    `Rollingball` scene (or any scene that requires camera access), Unity will automatically
    check whether the user has granted permission for camera access; if not, Unity
    will request permission. Unfortunately, this automatic request comes too late
    for `DetectAndSimulate` to properly access the camera in its `Start` and `Init`
    methods. To avoid this kind of problem, it is better to write a launcher scene
    with a script that explicitly requests camera access.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new scene and save it as `Launcher` in the `Rollingball/Scenes` folder.
    Delete the Directional Light from the scene. Add an empty object and name it `Launcher`.
    Now, the scene''s Hierarchy should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/82455710-cbb2-4a73-b14b-6a3caf0fbb74.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Edit the Main Camera in the Inspector to give it a solid black background,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fde1c045-a75c-4933-b25a-5e2e9371555f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In `Rollingball/Scripts`, create a new script, rename it `Launcher`, edit it,
    and replace its contents with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Upon `Start`, this script checks whether the user has already granted permission
    to access the camera. If not, the script requests permission by showing a standard
    Android permission request dialog. The `Start` method finishes by loading the
    `Rollingball` scene that we created previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the script and drag it from the Project pane to the `Launcher` object
    in the Hierarchy. Click on the `Launcher` object and confirm that its Inspector
    looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e13afcc0-0c96-4270-949f-7be5ebd10dd5.png)'
  prefs: []
  type: TYPE_IMG
- en: Our launcher scene is complete. All that remains is to configure, build, and
    test our project.
  prefs: []
  type: TYPE_NORMAL
- en: Tidying up and testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s return to the Build Settings window (File | Build Settings...). We no
    longer want the OpenCV for Unity demos in our build. Remove them by either unchecking
    them or selecting and deleting them (*Delete* on Windows or *Cmd* + *Del* on Mac).
    Then, add the `Launcher` and `Rollingball` scenes by dragging them from the Project
    pane into the Scenes In Build list. When you are finished, the Build Settings
    window should look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/49fa420d-dffc-41e7-bd5e-0c81926a40c8.png)'
  prefs: []
  type: TYPE_IMG
- en: Click on the Build and Run button, overwrite any previous builds, and let the
    good times roll!
  prefs: []
  type: TYPE_NORMAL
- en: If you are building for iOS, remember to follow the additional instructions
    in `OpenCVForUnity/ReadMe.pdf`. Particularly, ensure that the project's Camera
    Usage Description is set to a helpful descriptive string, for example `Rollingball`
    uses the camera to detect circles and lines (obviously!) and that the Target minimum
    iOS Version is set to `8.0`.
  prefs: []
  type: TYPE_NORMAL
- en: Test the app by drawing and scanning dots and lines of various sizes, with various
    styles of pen strokes. Also, try scanning some things that are not drawings. Feel
    free to go back to the code, edit the detectors' parameters, rebuild, and see
    how the sensitivity has changed.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has really rounded out our experience and has drawn a line under
    our accomplishments. You have learned how to detect primitive shapes by using
    the Hough transform. We have also used OpenCV and Unity together to turn a pen
    and paper drawing into a physics toy. We have even surpassed the things that Q
    can make a pen do!
  prefs: []
  type: TYPE_NORMAL
- en: Still, a secret agent cannot solve all problems with ink and paper alone. Next,
    we will take off our reading glasses, put down our physics simulations, and consider
    ways of deconstructing real motion in the world around us. Prepare to look through
    the kaleidoscope of the frequency domain!
  prefs: []
  type: TYPE_NORMAL
