["```py\npip install transformers\n```", "```py\n!pip install -Uqq ipdbimport ipdb\n```", "```py\nipdb.set_trace()\n```", "```py\n%pdb off\n```", "```py\n%pdb on\n```", "```py\n!pip install datasets!pip install evaluate\n!pip install transformers\n```", "```py\nimport datasetsfrom datasets import load_dataset\nfrom enum import Enum\nimport evaluate\nfrom evaluate import evaluator\nimport numpy as np\nfrom sklearn.metrics import jaccard_score\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    Pipeline,\n    Trainer,\n    TrainingArguments\n)\nimport pandas as pd\nfrom pathlib import Path\nfrom google.colab import drive\n```", "```py\ndrive.mount(\"/content/gdrive/\", force_remount=True)BASE_PATH = \"/content/gdrive/MyDrive/PacktBook/Data/C9\"\n```", "```py\nclass Dataset(Enum):  SEM4_EN=1\n  WASSA_EN=2\n  CARER_EN=3\n  SEM4_AR=4\n  SEM4_ES=5\n  IMDB_EN=6\n```", "```py\n# set the required dataset hereds = Dataset.SEM4_EN\nNUM_LABELS = 4\nCOLS = 'ID', 'tweet', 'label'\n```", "```py\nif (ds == Dataset.SEM4_EN):  training_file = \"SEM4_EN_train.csv\"\n  test_file = \"SEM4_EN_dev.csv\"\nelif (ds == Dataset.WASSA_EN):\n  training_file = \"WASSA_train.csv\"\n  test_file = \"WASSA_dev.csv\"\nelif(ds == Dataset.CARER_EN):\n  training_file = \"CARER_EN_train.csv\"\n  test_file = \"CARER_EN_dev.csv\"\n  NUM_LABELS = 6\nelif(ds == Dataset.SEM4_ES):\n  training_file = \"SEM4_ES_train.csv\"\n  test_file = \"SEM4_ES_dev.csv\"\n  NUM_LABELS = 5\nelif(ds == Dataset.SEM4_AR):\n  training_file = \"SEM4_AR_train.csv\"\n  test_file = \"SEM4_AR_dev.csv\"\nelif(ds == Dataset.IMDB_EN):\n  NUM_LABELS = 2\n  training_file = \"IMDB_EN_train.csv\"\n  test_file = \"IMDB_EN_dev.csv\"\n```", "```py\n# select a modelif \"_AR_\" in training_file:\n  model_name = \"asafaya/bert-base-arabic\"\nelif \"_EN_\" in training_file:\n  model_name = \"bert-base-cased\"\nelif \"_ES_\" in training_file:\n  model_name = \"dccuchile/bert-base-spanish-wwm-cased\"\n```", "```py\n# add the base pathtraining_file = f\"{BASE_PATH}/{training_file}\"\ntest_file = f\"{BASE_PATH}/{test_file}\"\n```", "```py\n# get file name for savingstub = (Path(training_file).stem)\n```", "```py\ndef get_tweets_dataset():  data_files = {\"train\": training_file, \"test\": test_file}\n  ds = datasets.load_dataset(\"csv\", data_files=data_files,\n                             delimiter=\",\",\n                             encoding='utf-8')\n  ds_columns = ds['train'].column_names\n  drop_columns = [x for x in ds_columns if x not in COLS]\n  ds = ds.remove_columns(drop_columns)\n  dd = datasets.DatasetDict({\"train\":ds[\"train\"],\n                             \"test\":ds[\"test\"]})\n  return dd\ndataset = get_tweets_dataset()\n```", "```py\ntokenizer = AutoTokenizer.from_pretrained(model_name)def tokenise_function(tweets):\n    return tokenizer(tweets[\"tweet\"],\n                     padding=\"max_length\",\n                     truncation=True,\n                     max_length = 512)\ntokenised_datasets = dataset.map(tokenise_function, batched=True)\n```", "```py\nmodel = AutoModelForSequenceClassification.from_pretrained(    model_name,\n    num_labels=NUM_LABELS)\ntraining_args = TrainingArguments(output_dir=f\"{stub}\")\n```", "```py\ntraining_args = TrainingArguments(    output_dir=f\"{stub}\",\n    evaluation_strategy=\"epoch\")\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenised_datasets[\"train\"],\n    eval_dataset=tokenised_datasets[\"test\"],\n)\ntrainer.train()\ntrainer.save_model(stub)\n```", "```py\nThe following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: ID, tweet. If ID, tweet are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message./usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n***** Running training *****\n  Num examples = 3860\n  Num Epochs = 3\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 1449\n  Number of trainable parameters = 108313348\n [1449/1449 19:47, Epoch 3/3]\nEpoch  Training Loss  Validation Loss\n1  No log  0.240059\n2  0.555900  0.210987\n3  0.208900  0.179072\nTraining completed. Do not forget to share your model on huggingface.co/models =)\nSaving model checkpoint to SEM4_EN_train\nConfiguration saved in SEM4_EN_train/config.json\nModel weights saved in SEM4_EN_train/pytorch_model.bin\n```", "```py\npredictions = trainer.predict(tokenized_datasets[\"test\"])\n```", "```py\nmodel_predictions = np.argmax(predictions.predictions,    axis=1)\nmodel_predictions = model_predictions.tolist()\nmodel_references = tokenised_datasets[\"test\"][\"label\"]\nmeasures = [\n              [\"precision\" , \"macro\"],\n              [\"recall\" , \"macro\"],\n              [\"f1\" , \"micro\"],\n              [\"f1\" , \"macro\"],\n              [\"jaccard\" , \"macro\"],\n              [\"accuracy\" , None],\n            ]\nfor measure in measures:\n  measure_name = measure[0]\n  average = measure[1]\n  if measure_name = = \"jaccard\":\n    results = get_jaccard_score(references = model_references,\n    predictions = model_predictions,average = average)\n  else:\n    metric = evaluate.load(measure_name)\n    if measure_name==\"accuracy\":\n      results = metric.compute(references = model_references,\n      predictions = model_predictions)\n    else:\n      results = metric.compute(references = model_references,\n        predictions = model_predictions, average = average)\n  print(measure_name, average, results[measure_name])\n```", "```py\nprecision macro 0.9577305808563304recall macro 0.9592563645499727\nf1 micro 0.9576446280991735\nf1 macro 0.9576513771741846\njaccard macro 0.9192365565992706\naccuracy None 0.9576446280991735\n```", "```py\ndef get_kwt_tweets_dataset(code):  if code == \"KWTM\":\n    training_file = \"train-KWT-M.csv\"\n    test_file = \"test-KWT-M.csv\"\n  else:\n    training_file = \"train-KWT-U.csv\"\n    test_file = \"test-KWT-U.csv\"\n  # add the base path\n  training_file = f\"{BASE_PATH}/{training_file}\"\n  test_file = f\"{BASE_PATH}/{test_file}\"\n  data_files = {\"train\": training_file, \"validation\": test_file}\n  ds = datasets.load_dataset(\"csv\", data_files=data_files,\n        delimiter=\",\",encoding='utf-8')\n  dd = datasets.DatasetDict(\n                            {\"train\":ds[\"train\"],\n                             \"validation\":ds[\"validation\"]\n                            })\n  return dd\n```", "```py\nclass Dataset(Enum):  SEM11_AR=1\n  SEM11_EN=2\n  SEM11_ES=3\n  KWT_M_AR=4\n  KWT_U_AR=5\nds = Dataset.SEM11_EN\nif (ds == Dataset.SEM11_AR):\n  dataset = load_dataset(\"sem_eval_2018_task_1\",\n    \"subtask5.arabic\")\n  model_name = \"asafaya/bert-base-arabic\"\nelif (ds == Dataset.SEM11_EN):\n  dataset = load_dataset(\"sem_eval_2018_task_1\",\n    \"subtask5.english\")\n  model_name = \"bert-base-cased\"\nelif(ds == Dataset.SEM11_ES):\n  dataset = load_dataset(\"sem_eval_2018_task_1\",\n    \"subtask5.spanish\")\n  model_name = \"dccuchile/bert-base-spanish-wwm-cased\"\nelif(ds == Dataset.KWT_M_AR):\n  dataset = get_tweets_dataset(\"KWTM\")\n  model_name = \"asafaya/bert-base-arabic\"\nelif(ds == Dataset.KWT_U_AR):\n  dataset = get_tweets_dataset(\"KWTU\")\n  model_name = \"asafaya/bert-base-arabic\"\n```", "```py\nDatasetDict({    train: Dataset({\n        features: ['ID', 'Tweet', 'anger', 'anticipation',\n        'disgust', 'fear', 'joy', 'love', 'optimism',\n        'pessimism', 'sadness', 'surprise', 'trust'],\n        num_rows: 6838\n    })\n    test: Dataset({\n        features: ['ID', 'Tweet', 'anger', 'anticipation',\n        'disgust', 'fear', 'joy', 'love', 'optimism',\n        'pessimism', 'sadness', 'surprise', 'trust'],\n        num_rows: 3259\n    })\n    validation: Dataset({\n        features: ['ID', 'Tweet', 'anger', 'anticipation',\n        'disgust', 'fear', 'joy', 'love', 'optimism',\n        'pessimism', 'sadness', 'surprise', 'trust'],\n        num_rows: 886\n    })\n})\n```", "```py\nLabels = [label for label in dataset[ 'train'].features.keys() if label not in ['ID', 'Tweet']]id2label = {idx:label for idx, label in enumerate(labels)}\nlabel2id = {label:idx for idx, label in enumerate(labels)}\n```", "```py\n['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']{0: 'anger', 1: 'anticipation', 2: 'disgust', 3: 'fear', 4: 'joy', 5: 'love', 6: 'optimism', 7: 'pessimism', 8: 'sadness', 9: 'surprise', 10: 'trust'}\n{'anger': 0, 'anticipation': 1, 'disgust': 2, 'fear': 3, 'joy': 4, 'love': 5, 'optimism': 6, 'pessimism': 7, 'sadness': 8, 'surprise': 9, 'trust': 10}\n```", "```py\ntokenizer = AutoTokenizer.from_pretrained(model_name)def tokenise_function(tweets):\n  text = tweets[\"Tweet\"]\n encoding = tokenizer(text,\n                      padding=\"max_length\",\n                      truncation=True,\n                      max_length=512)\n  labels_batch = {k: tweets[k] for k in tweets.keys() if k in labels}\n  labels_matrix = np.zeros((len(text), len(labels)))\n  for idx, label in enumerate(labels):\n    labels_matrix[:, idx] = labels_batch[label]\n  encoding[\"labels\"] = labels_matrix.tolist()\n  return encoding\nencoded_dataset = dataset.map(tokenise_function,\n        batched=True,\n        remove_columns = dataset['train'].column_names)\n```", "```py\nencoded_dataset.set_format(\"torch\")\n```", "```py\nmodel = AutoModelForSequenceClassification.from_pretrained(    model_name,\n    problem_type=\"multi_label_classification\",\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id\n    )\n```", "```py\ndef compute_multi_label_metrics(predictions,        labels, threshold=0.5):\n    sigmoid = torch.nn.Sigmoid()\n    probs = sigmoid(torch.Tensor(predictions))\n    y_pred = np.zeros(probs.shape)\n    y_pred[np.where(probs >= threshold)] = 1\n    y_true = labels\n    f1_macro_average = f1_score(y_true=y_true,\n                                y_pred=y_pred,\n                                average='macro')\n    f1_micro_average = f1_score(y_true=y_true,\n                                y_pred=y_pred,\n                                average='micro')\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred,\n        average = 'macro')\n    recall = recall_score(y_true, y_pred,\n        average = 'macro')\n    jaccard = jaccard_score(y_true, y_pred,\n        average='macro')\n    metrics = {\n                'precision': precision,\n                'recall': recall,\n                'f1_micro_average': f1_micro_average,\n                'f1_macro_average': f1_macro_average,\n                'jaccard': jaccard,\n                'accuracy': accuracy\n              }\n    return metrics\ndef compute_metrics(p: EvalPrediction):\n    if isinstance(p.predictions, tuple):\n      preds = p.predictions[0]\n    else:\n      preds = p.predictions\n    result = compute_multi_label_metrics(predictions=preds,\n                                         labels=p.label_ids)\n    return result\n```", "```py\nmetric_name = \"jaccard\"training_args = TrainingArguments(\n    model_name,\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    num_train_epochs = 3,\n    load_best_model_at_end = True,\n    metric_for_best_model = metric_name,\n)\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=encoded_dataset[\"train\"],\n    eval_dataset=encoded_dataset[\"validation\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\ntrainer.train()\n```", "```py\ntrainer.evaluate()\n```", "```py\n{'eval_loss': 0.3063639998435974, 'eval_precision': 0.6944130688122799,\n 'eval_recall': 0.4961206747689895,\n 'eval_f1_micro_average': 0.7107381546134663,\n 'eval_f1_macro_average': 0.539464842236441,\n 'eval_jaccard': 0.4181996269238169,\n 'eval_accuracy': 0.30242437923250563,\n 'eval_runtime': 26.6373,\n 'eval_samples_per_second': 33.262,\n 'eval_steps_per_second': 4.167,\n 'epoch': 3.0}\n```"]