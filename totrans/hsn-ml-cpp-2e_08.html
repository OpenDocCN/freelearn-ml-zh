<html><head></head><body>
		<div id="_idContainer653">
			<h1 class="chapter-number" id="_idParaDest-169"><a id="_idTextAnchor438"/>8</h1>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor439"/>Recommender Systems</h1>
			<p>Recommender systems are algorithms, programs, and services that are designed to use data to predict which objects (goods or services) are of interest to a user. There are two main types of recommender systems: <em class="italic">content-based</em> and <em class="italic">collaborative filtering</em>. <strong class="bold">Content-based recommender systems</strong> are based on data that’s been collected from specific products. They recommend objects to a user that are similar to ones the user has previously acquired or shown interest in. <strong class="bold">Collaborative filtering recommender systems</strong> filter out objects that a user might like based on the reaction history of other, similar users of these systems. They also usually consider the user’s <span class="No-Break">previous reactions.</span></p>
			<p>In this chapter, we’ll learn how to implement recommender system algorithms based on both content and collaborative filtering. We’re going to discuss different approaches for implementing collaborative filtering algorithms, implement systems using only the linear algebra library, and learn how to use the <strong class="source-inline">mlpack</strong> library to solve collaborative filtering problems. We’ll be using the MovieLens dataset provided by GroupLens from a research lab in the Department of Computer Science and Engineering at the University of <span class="No-Break">Minnesota: </span><a href="B19849_08.xhtml#_idTextAnchor473"><span class="No-Break">https://grouplens.org/datasets/movielens/</span></a><span class="No-Break">.</span></p>
			<p>The following topics will be covered in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>An overview of recommender <span class="No-Break">system algorithms</span></li>
				<li>Understanding the collaborative <span class="No-Break">filtering method</span></li>
				<li>Examples of item-based collaborative filtering <span class="No-Break">with C++</span><a id="_idTextAnchor440"/></li>
			</ul>
			<h1 id="_idParaDest-171"><a id="_idTextAnchor441"/>Technical requirements</h1>
			<p>To complete this chapter, you’ll need <span class="No-Break">the following:</span></p>
			<ul>
				<li>The <span class="No-Break"><strong class="source-inline">Eigen</strong></span><span class="No-Break"> library</span></li>
				<li>The <span class="No-Break"><strong class="source-inline">Armadillo</strong></span><span class="No-Break"> library</span></li>
				<li>The <span class="No-Break"><strong class="source-inline">mlpack</strong></span><span class="No-Break"> library</span></li>
				<li>A modern C++ compiler with <span class="No-Break">C++20 support</span></li>
				<li>CMake build system version &gt;= <span class="No-Break">3.10</span></li>
			</ul>
			<p>The code files for this chapter can be found in this book’s GitHub <span class="No-Break">repository: </span><a href="B19849_08.xhtml#_idTextAnchor470"><span class="No-Break">https://github.com/PacktPublishing/Hands-On-Machine-Learning-with-C-Second-Edition/tree/main/Chapter08</span></a><span class="No-Break"><span class="P---URL"><a id="_idTextAnchor442"/></span></span><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-172"><a id="_idTextAnchor443"/>An overview of recommender system algorithms</h1>
			<p>A recommender system’s task is to inform a user about an object that could be the most interesting to them at a given time. Often, such an object is a product or service, but it may be information—for example, in the form of a recommended <span class="No-Break">news article.</span></p>
			<p>Before we dive into the technicalities of the recommender system, let’s look at some real-world scenarios where recommender systems are used to improve user experience and increase sales. The<a id="_idIndexMarker932"/> following are the most <span class="No-Break">common applications:</span></p>
			<ul>
				<li>Recommender systems help online retailers suggest products that might interest a customer based on their past purchases, browsing history, and other data. This helps customers find relevant products more easily and increases the likelihood <span class="No-Break">of conversion.</span></li>
				<li>Music and video streaming services use recommender systems to suggest music or videos based on a user’s listening or viewing history. The goal is to provide personalized content recommendations that keep users engaged with <span class="No-Break">the platform.</span></li>
				<li>Social media platforms such as Meta and Instagram use recommender systems to show users content from friends and pages they might be interested in. This keeps users engaged and spending time on <span class="No-Break">the platform.</span></li>
				<li>Advertisers use recommender systems to target adverts at specific audiences based on their interests, demographics, and behavior. This improves the effectiveness of <span class="No-Break">advertising campaigns.</span></li>
				<li>News websites, blogs, and search engines use recommender systems to recommend articles, stories, or search results based on user preferences and <span class="No-Break">search history.</span></li>
				<li>Recommender systems<a id="_idIndexMarker933"/> can be used to suggest treatments, medications, or medical procedures based on patient data and <span class="No-Break">medical research.</span></li>
				<li>Travel websites and hotel booking platforms use recommender systems to suggest travel destinations, accommodations, and activities based on a traveler’s preferences, budget, and <span class="No-Break">travel history.</span></li>
				<li>Educational platforms and online courses use recommender systems to personalize learning experiences by suggesting courses, materials, and learning paths based on student performance, interests, <span class="No-Break">and goals.</span></li>
				<li>Video game platforms use recommender systems to suggest games based on player preferences, play style, and <span class="No-Break">gaming history.</span></li>
			</ul>
			<p>These are just a few examples of how recommender systems are applied in real-life scenarios. They’ve become an essential tool for businesses looking to improve customer engagement, increase sales, and provide <span class="No-Break">personalized experiences.</span></p>
			<p>Despite the many existing algorithms, we can divide recommender systems into several basic approaches. The most common are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Summary-based</strong>: Non-personal models based on the average <span class="No-Break">product rating</span></li>
				<li><strong class="bold">Content-based</strong>: Models based on the intersection of product descriptions and <span class="No-Break">user interests</span></li>
				<li><strong class="bold">Collaborative filtering</strong>: Models based on interests of similar <span class="No-Break">user groups</span></li>
				<li><strong class="bold">Matrix factorization</strong>: Methods based on the preferences <span class="No-Break">matrix’s decomposition</span></li>
			</ul>
			<p>The basis of any recommender system is the preferences matrix. It has all users of the service laid on one of the axes and recommendation objects on the other. The recommendation <a id="_idIndexMarker934"/>objects are usually called <strong class="bold">items</strong>. At the intersection of rows and columns (user, item), this matrix is filled with ratings that indicate user interest in a product, expressed on a given <a id="_idIndexMarker935"/>scale (for example, from 1 to 5), as illustrated in the <span class="No-Break">following table:</span></p>
			<table class="No-Table-Style _idGenTablePara-1" id="table001-3">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">item1</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">item 2</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">item3</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">user1</span></p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">user2</span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>4</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">user3</span></p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">user4</span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">user5</span></p>
						</td>
						<td class="No-Table-Style">
							<p>3</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">user6</span></p>
						</td>
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p>4</p>
						</td>
						<td class="No-Table-Style"/>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 8.1 – User interest count</p>
			<p>Users usually evaluate only a small number of the items in the catalog; the task of the recommender system is to summarize this information and predict the attitude the user might have toward other items. In other words, you need to fill in all the blank cells in the <span class="No-Break">preceding table.</span></p>
			<p>People’s consumption patterns are different, and new products don’t have to be recommended all the time. You can show repeated items—for example, when a user has bought something they’ll need again. According to this principle, there are two groups <span class="No-Break">of items:</span></p>
			<ul>
				<li><strong class="bold">Repeatable</strong>: For example, shampoos<a id="_idIndexMarker936"/> or razors, which are <span class="No-Break">always needed</span></li>
				<li><strong class="bold">Unrepeatable</strong>: For example, books <a id="_idIndexMarker937"/>or films, which are rarely <span class="No-Break">purchased repeatedly</span></li>
			</ul>
			<p>If the product can’t be attributed to one of these groups, it makes sense to determine the group type of repetitive purchases individually (someone usually buys only a specific brand, but someone else might try everything in <span class="No-Break">the catalog).</span></p>
			<p>Determining what product <em class="italic">interests</em> a user is also subjective. Some users need things only from their favorite category (conservative recommendations), while others respond more to non-standard goods (risky recommendations). For example, a video-hosting service may only recommend new series from their favorite TV series (conservative) but may periodically recommend new shows or new genres. Ideally, you should choose a strategy for displaying recommendations for each client separately by using generalized information about the <span class="No-Break">client’s </span><span class="No-Break"><a id="_idIndexMarker938"/></span><span class="No-Break">preferences.</span></p>
			<p>The essential part of datasets that are used to build recommendation models is user reactions to different objects or items. These reactions are typically called user ratings of objects. We can obtain user ratings in the <a id="_idIndexMarker939"/><span class="No-Break">following ways:</span></p>
			<ul>
				<li><strong class="bold">Explicit ratings</strong>: The user gives their rating for the <a id="_idIndexMarker940"/>product, leaves a review, or <em class="italic">likes</em> <span class="No-Break">the page.</span></li>
				<li><strong class="bold">Implicit ratings</strong>: The user doesn’t express their <a id="_idIndexMarker941"/>attitude, but an indirect conclusion can be made from their actions. For example, if they bought a product, it means they like it; if they read the description for a long time, it means they have <span class="No-Break">serious interest.</span></li>
			</ul>
			<p>Of course, explicit preferences are better. However, in practice, not all services allow users to express their interests clearly, and not all users have the desire to do so. Both types of assessments are often used in tandem and complement each <span class="No-Break">other well.</span></p>
			<p>It’s also essential to distinguish <a id="_idIndexMarker942"/>between the terms <em class="italic">prediction</em> (the prediction of the degree of interest) and the <em class="italic">recommendation</em> itself (showing the recommendation). How to show something is a <a id="_idIndexMarker943"/>separate task from the task of <em class="italic">what to show</em>. <em class="italic">How to show</em> is a task that uses the estimates obtained in the prediction step, and can be implemented in <span class="No-Break">different ways.</span></p>
			<p>In this section, we discussed the basics of recommender systems. In the following sections, we’ll look at the essential building blocks of recommender systems. Let’s begin by looking at the main principles of content-based filtering, user and item-based collaborative filtering, and collaborative filtering based on <span class="No-Break">matrix factor<a id="_idTextAnchor444"/>i<a id="_idTextAnchor445"/>zation.</span></p>
			<h2 id="_idParaDest-173"><a id="_idTextAnchor446"/>Non-personalized recommendations</h2>
			<p>For non-personalized recommendations, the potential interest of the user is determined by the average rating of the product: <em class="italic">if everyone likes it, you’ll like it too</em>. According to this principle, most services <a id="_idIndexMarker944"/>work when the user<a id="_idIndexMarker945"/> isn’t authorized on <span class="No-Break">t<a id="_idTextAnchor447"/>h<a id="_idTextAnchor448"/>e system.</span></p>
			<h2 id="_idParaDest-174"><a id="_idTextAnchor449"/>Content-based recommendations</h2>
			<p>Personal recommendations use the <a id="_idIndexMarker946"/>maximum information available about the user—primarily, information about their previous purchases. Content-based filtering was one of the first approaches to be developed for personalized recommendations. In this approach, the product’s description (content) is compared with the interests of the user, which are obtained from their previous assessments. The more the product meets these interests, the higher the<a id="_idIndexMarker947"/> potential interest of the user. The obvious requirement here is that all products in the catalog should have <span class="No-Break">a description.</span></p>
			<p>Historically, the subject of content-based recommendations was products with unstructured descriptions: films, books, or articles. Their features may be, for example, text descriptions, reviews, or casts. However, nothing prevents the use of usual numerical or <span class="No-Break">categorical features.</span></p>
			<p>Unstructured features are described in a text-typical way—vectors in the space of words (vector-space model). Each element of a vector is a feature that potentially characterizes the interest of the user. Similarly, an item (product) is a vector in the <span class="No-Break">same space.</span></p>
			<p>As users interact with the system (say, they buy films), the vector descriptions of the goods they’ve purchased merge (sum up and normalize) into a single vector and, thus, form the vector of a user’s interests. Using this vector of interests, we can find the product and the description of which is closest to it—that is, we can solve the problem of finding the <span class="No-Break">nearest neighbors.</span></p>
			<p>When forming the vector space of a product presentation, instead of individual words, you can use shingles or n-grams (successive pairs of words, triples of words, or other numbers of words). This approach makes the model more detailed, but more data is required <span class="No-Break">for training.</span></p>
			<p>In different places of the description of the product, the weight of keywords may differ (for example, the description of the film may consist of a title, a brief description, and a detailed description). Product descriptions from different users can be weighed differently. For example, we can give more weight to active users who have many ratings. Similarly, you can weigh them by item. The higher the average rating of an object, the greater its weight (similar to PageRank). If the product description allows links to external sources, then you can<a id="_idIndexMarker948"/> also analyze all third-party information related to <span class="No-Break">the product.</span></p>
			<p>The cosine distance is often <a id="_idIndexMarker949"/>used to compare product representation vectors. This distance measures the value of proximity between <span class="No-Break">two vectors.</span></p>
			<p>When adding a new assessment, the vector of interests is updated incrementally (only for those elements that have changed). During the update, it makes sense to give a bit more weight to new estimates since the user’s preferences may change. You’ll notice that content-based filtering almost wholly repeats the query-document matching mechanism used in search engines such as Google. The only difference lies in the form of a search query—content filtering systems use a vector that describes the interests of the user, whereas search engines use keywords of the requested document. When search engines began to add personalization, this distinction was era<a id="_idTextAnchor450"/>s<a id="_idTextAnchor451"/>ed <span class="No-Break">even more.</span></p>
			<h2 id="_idParaDest-175"><a id="_idTextAnchor452"/>User-based collaborative filtering</h2>
			<p>This class of system began to <a id="_idIndexMarker950"/>develop in the 90s. Under this approach, recommendations are generated based on the interests of other, similar users. Such <a id="_idIndexMarker951"/>recommendations are the result of the <strong class="bold">collaboration</strong> of many users, hence the name of <span class="No-Break">the method.</span></p>
			<p>The classical implementation of the <a id="_idIndexMarker952"/>algorithm is based on the principle of <strong class="bold">k-nearest neighbors</strong> (<strong class="bold">kNN</strong>). For every user, we look for the <strong class="bold">k</strong> most similar to them (in terms of preferences). Then, we supplement the information about the user with known data from their neighbors. So, for example, if it’s known that your neighbors are delighted with a movie, and you haven’t watched it for some reason, this is a great reason to recommend <span class="No-Break">this movie.</span></p>
			<p>The similarity is, in this case, a synonym for a <em class="italic">correlation</em> of interests and can be considered in many ways—Pearson’s correlation, cosine distance, Jaccard distance, Hamming distance, and other types <span class="No-Break">of distances.</span></p>
			<p>The classical implementation of the<a id="_idIndexMarker953"/> algorithm has one distinct disadvantage—it’s poorly applicable in practice due to the quadratic complexity of the calculations. As with any nearest neighbor method, it requires all pairwise distances between users to be calculated (and there may be millions of users). It’s easy to calculate that the complexity of calculating the distance matrix is <img alt="" role="presentation" src="image/B19849_08_01.png"/>, where <img alt="" role="presentation" src="image/B19849_Formula_001.png"/> is the number of users, and <img alt="" role="presentation" src="image/B19849_08_03.png"/> is the number of <span class="No-Break">items (goods).</span></p>
			<p>This problem can be partly<a id="_idIndexMarker954"/> mitigated by purchasing high-performance hardware. But if you approach it wisely, then it’s better to introduce some corrections to the algorithm in the <span class="No-Break">following way:</span></p>
			<ul>
				<li>Update distances not with every purchase but with batches (for example, once <span class="No-Break">a day)</span></li>
				<li>Don’t recalculate the distance matrix completely, but update <span class="No-Break">it incrementally</span></li>
				<li>Choose some iterative <a id="_idIndexMarker955"/>and approximate algorithms (for example, <strong class="bold">Alternating Least </strong><span class="No-Break"><strong class="bold">Squares</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">ALS</strong></span><span class="No-Break">))</span></li>
			</ul>
			<p>Fulfill the following assumptions to make the algorithm <span class="No-Break">more practical:</span></p>
			<ul>
				<li>The tastes of people don’t change over time (or they do change, but they’re the same <span class="No-Break">for everyone)</span></li>
				<li>If people’s tastes are the same, then they’re the same <span class="No-Break">in everything</span></li>
			</ul>
			<p>For example, if two clients prefer the same films, then they also like the same book. This assumption is often the case when the recommended products are homogeneous (for example, films only). If this isn’t the case, then a couple of clients may well have the same eating habits but their political views might be the opposite; here, the algorithm is <span class="No-Break">less efficient.</span></p>
			<p>The neighborhood of the user in the space of preferences (the user’s neighbors), which we analyze to generate new recommendations, can be chosen in different ways. We can work with all users of the system; we can set a certain proximity threshold; we can choose several neighbors at random; or we can take the <strong class="bold">k</strong> most similar neighbors (this is the most popular approach). If we take too many neighbors, we get a higher chance of random noise, and vice versa. If we take too little, we get more accurate recommendations, but fewer goods can <span class="No-Break">be recommended.</span></p>
			<p>An interesting development in the collaborative approach is trust-based recommendations, which take into account not only the proximity of people according to their interests but also their <em class="italic">social</em> proximity and the degree of trust between them. If, for example, we see<a id="_idIndexMarker956"/> that on Facebook, a girl occasionally visits a page that has her friend’s audio recordings, then she trusts her <a id="_idIndexMarker957"/>musical taste. Therefore, when making recommendations to the girl, you can add new songs from her<a id="_idTextAnchor453"/> <a id="_idTextAnchor454"/><span class="No-Break">friend’s playlist.</span></p>
			<h2 id="_idParaDest-176"><a id="_idTextAnchor455"/>Item-based collaborative filtering</h2>
			<p>The item-based approach is a natural alternative to the classic user-based approach described previously and almost<a id="_idIndexMarker958"/> repeats it, except for one thing—it applies to the transposed preference matrix, which looks for similar products instead <span class="No-Break">of users.</span></p>
			<p>For each client, a user-based collaborative<a id="_idIndexMarker959"/> filtering system searches a group of customers who are similar to this user in terms of previous purchases, and then the system averages their preferences. These average preferences serve as recommendations for the user. In the case of item-based collaborative filtering, the nearest neighbors are searched for on a variety of products (items) using the columns of a preference matrix, and the averaging occurs precisely according <span class="No-Break">to them.</span></p>
			<p>If some products are meaningfully similar to each other, then users’ reactions to these products will be the same. Therefore, when we see that some products have a strong correlation between their estimates, this may indicate that these products are equivalent to <span class="No-Break">each other.</span></p>
			<p>The main advantage of the item-based approach over the user-based approach is lower computation complexity. When there are many users (almost always), the task of finding the nearest neighbor becomes poorly computable. For example, for 1 million users, you need to calculate and store ~500 billion distances. If the distance is encoded in 8 bytes, this results in 4 <strong class="bold">terabytes</strong> (<strong class="bold">TB</strong>) for the distance matrix alone. If we take an item-based approach, then the computational complexity decreases from <img alt="" role="presentation" src="image/B19849_08_04.png"/> to <img alt="" role="presentation" src="image/B19849_08_05.png"/>, and the distance matrix has a dimension no longer than 1 million per 1 million but 100 by 100, as per the number of <span class="No-Break">items (goods).</span></p>
			<p>Estimating the proximity of products is much more accurate than assessing the proximity of users. This assumption is a direct consequence of the fact that there are usually many more users than items, and therefore the standard error in calculating the correlation of items is significantly less because we have more information to <span class="No-Break">work from.</span></p>
			<p>In the user-based version, the description <a id="_idIndexMarker960"/>of users usually has a very sparse distribution (there are many goods, but only a few evaluations). On the one hand, this helps to optimize the calculation—we multiply only those elements where an intersection exists. But, on the other hand, the list of items that a system can recommend to a user is minimal due to the limited number of user neighbors (users who have similar preferences). Also, user preferences may change over time, but the descriptions of the goods are much <span class="No-Break">more stable.</span></p>
			<p>The rest of the algorithm almost wholly repeats the user-based version: it uses the same cosine distance as the primary measure of proximity and has the same need for data normalization. Since the correlation<a id="_idIndexMarker961"/> of items is considered on a higher number of observations, it isn’t as critical to recalculate it after each new assessment, and this can be done periodically in a <span class="No-Break">batch mode.</span></p>
			<p>Now, let’s look at another approach to generalizing user interests based on matrix <span class="No-Break">f<a id="_idTextAnchor456"/>a<a id="_idTextAnchor457"/>ctorization methods.</span></p>
			<h2 id="_idParaDest-177"><a id="_idTextAnchor458"/>Factorization algorithms</h2>
			<p>It would be nice to describe the interests<a id="_idIndexMarker962"/> of the user with more extensive features—not in the format of <em class="italic">they love movies X, Y, and Z</em>, but in the format of <em class="italic">they love romantic comedies</em>. Besides the fact that it increases <a id="_idIndexMarker963"/>the generalizability of the model, it also solves the problem of having a large data dimension—after all, the interests are described not by the items vector, but by a significantly smaller <span class="No-Break">preference vector.</span></p>
			<p>Such approaches are <a id="_idIndexMarker964"/>also called <strong class="bold">spectral decomposition</strong> or <strong class="bold">high-frequency filtering</strong> (since we remove the<a id="_idIndexMarker965"/> noise and leave the useful signal). There are many different types of matrix decomposition in algebra, and one of the most commonly <a id="_idIndexMarker966"/>used is called <strong class="bold">singular value </strong><span class="No-Break"><strong class="bold">decomposition</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">SVD</strong></span><span class="No-Break">).</span></p>
			<p>Initially, the SVD method was used to<a id="_idIndexMarker967"/> select pages that are similar in meaning but not in content. More recently, it has started being used in recommendations. The method is based on decomposing the original <em class="italic">R</em> rating matrix into a product of three matrices, <img alt="" role="presentation" src="image/B19849_08_06.png"/>, where the sizes of the matrices are <img alt="" role="presentation" src="image/B19849_08_07.png"/> and <em class="italic">r</em> is the rank of the decomposition, which is the parameter characterizing the degree of <span class="No-Break">detail decomposition.</span></p>
			<p>Applying this decomposition to our matrix of preferences, we can get the following two matrices of factors (<span class="No-Break">abbreviated descriptions):</span></p>
			<ul>
				<li><strong class="bold">U</strong>: A compact description of <span class="No-Break">user preferences</span></li>
				<li><strong class="bold">S</strong>: A compact description of the characteristics of <span class="No-Break">the product</span></li>
			</ul>
			<p>When using this approach, we <a id="_idIndexMarker968"/>can’t know which particular characteristics correspond to the factors in the reduced descriptions; for us, they’re encoded with some numbers. Therefore, SVD is an uninterpreted model. It’s sufficient to multiply the matrix of factors to obtain an approximation of the matrix of preferences. By doing this, we get a rating for all <span class="No-Break">customer-product pairs.</span></p>
			<p>A typical family of such algorithms is called <strong class="bold">non-negative matrix factorization</strong> (<strong class="bold">NMF</strong>). As a rule, the calculation of<a id="_idIndexMarker969"/> such expansions is very computationally expensive. Therefore, in practice, they often resort to their approximate iterative variants. ALS is a popular iterative algorithm for decomposing a matrix of preferences into a product of two matrices: <strong class="bold">user factors</strong> (<strong class="bold">U</strong>) and <strong class="bold">product factors</strong> (<strong class="bold">I</strong>). It works on the principle <a id="_idIndexMarker970"/>of minimizing the <strong class="bold">root mean square error</strong> (<strong class="bold">RMSE</strong>) on the affixed ratings. Optimization takes place alternately—first by <a id="_idIndexMarker971"/>user factors, then by<a id="_idIndexMarker972"/> product factors. Also, to avoid retraining, the regularization coefficients are added to <span class="No-Break">the RMSE.</span></p>
			<p>If we supplement the matrix of preferences with a new dimension containing information about the user or product, then we can work not with the matrix of preferences, but with the tensor. Thus, we use more available information and possibly get a more <span class="No-Break">accurate model.</span></p>
			<p>In this section, we considered different approaches to solving recommender systems’ tasks. Now, we’re going to discuss methods for estimating the s<a id="_idTextAnchor459"/>i<a id="_idTextAnchor460"/>milarity of <span class="No-Break">user preferences.</span></p>
			<h2 id="_idParaDest-178"><a id="_idTextAnchor461"/>Similarity or preferences correlation</h2>
			<p>We can consider the similarity or correlation of two user preferences in different ways, but in general, we need to<a id="_idIndexMarker973"/> compare two vectors. Let’s look at some of the most popu<a id="_idTextAnchor462"/>l<a id="_idTextAnchor463"/>ar vector <span class="No-Break">comparison measures.</span></p>
			<h3>Pearson’s correlation coefficient</h3>
			<p>This measure is a classic coefficient that can be applied when comparing vectors. Its primary disadvantage is that when the intersection<a id="_idIndexMarker974"/> is estimated as low, then the correlation can be high by accident. To combat accidental high correlation, you can multiply by a factor of 50/min (50, rating intersection) or any other damping factor, the effect of which decreases with an increasing number of estimat<a id="_idTextAnchor464"/>e<a id="_idTextAnchor465"/>s. An example is <span class="No-Break">shown here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer595">
					<img alt="" role="presentation" src="image/B19849_08_08.jpg"/>
				</div>
			</div>
			<h3>Spearman’s correlation</h3>
			<p>The main difference compared to <a id="_idIndexMarker975"/>Pearson’s correlation is the rank factor—that is, it doesn’t work with absolute values of ratings, but with their sequence numbers. In general, the result is very close to Pearson’s correlati<a id="_idTextAnchor466"/>o<a id="_idTextAnchor467"/>n. An example is <span class="No-Break">shown here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer596">
					<img alt="" role="presentation" src="image/B19849_08_09.jpg"/>
				</div>
			</div>
			<h3>Cosine distance</h3>
			<p>Cosine distance is another classic measuring factor. If you look closely, the cosine of the angle between the standardized vectors is Pearson’s correlation, the same formula. This distance uses cosine properties: if the two vectors are co-directed (that is, the angle between them is 0), then the cosine of the <a id="_idIndexMarker976"/>angle between them is 1. Conversely, the cosine of the angle between perpendicular vectors is 0. An example is <span class="No-Break">shown here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer597">
					<img alt="" role="presentation" src="image/B19849_08_10.jpg"/>
				</div>
			</div>
			<p>With that, we’ve discussed methods we can use to estimate the similarity of user preferences. The next important issue we’ll discuss is preparing data so that it can be used in<a id="_idTextAnchor468"/> <a id="_idTextAnchor469"/>recommender <span class="No-Break">system algorithms.</span></p>
			<h2 id="_idParaDest-179"><a id="_idTextAnchor470"/>Data scaling and standardization</h2>
			<p>All users evaluate (rate) items differently. If someone puts 5s in a row, instead of waiting for 4s from someone else, it’s better to normalize the data before calculating it—that is, convert the data into a <a id="_idIndexMarker977"/>single scale so that the algorithm can compare the results correctly. After, the predicted estimate needs to be converted into the original scale via inverse transformation (and, if necessary, rounded to the nearest <span class="No-Break">whole number).</span></p>
			<p>There are several ways to <span class="No-Break">normalize data:</span></p>
			<ul>
				<li><strong class="bold">Centering (mean-centering)</strong>: From the user’s ratings, subtract their average rating. This type of normalization is only<a id="_idIndexMarker978"/> relevant for <span class="No-Break">non-binary matrices.</span></li>
				<li><strong class="bold">Standardization (z-score)</strong>: In addition to centering, this divides the user’s rating by the standard deviation <a id="_idIndexMarker979"/>of the user. But in this case, after the inverse transformation, the rating can go beyond the scale (for example, six on a five-point scale), but such situations are quite rare and can be solved by rounding to the nearest <span class="No-Break">acceptable estimate.</span></li>
				<li><strong class="bold">Double standardization</strong>: The first time data is normalized by <a id="_idIndexMarker980"/>user ratings; the second time, by <span class="No-Break">item ratings.</span></li>
			</ul>
			<p>The details of these normalization techniques were provided in <a href="B19849_02.xhtml#_idTextAnchor075"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Data Processing</em>. The following section will describe a problem with recommender systems known as the <strong class="bold">cold start problem</strong>, which <a id="_idIndexMarker981"/>appears in the early stages of system work when the system doesn’t h<a id="_idTextAnchor471"/>a<a id="_idTextAnchor472"/>ve enough data to <span class="No-Break">make predictions.</span></p>
			<h2 id="_idParaDest-180"><a id="_idTextAnchor473"/>Cold start problem</h2>
			<p>A cold start is a typical situation when a sufficient amount of data hasn’t been accumulated for the correct <a id="_idIndexMarker982"/>operation of the recommender system yet (for example, when a product is new or is just rarely bought). If the ratings of <a id="_idIndexMarker983"/>only three users estimate the average rating, such an assessment isn’t reliable, and users understand this. In such situations, ratings are often <span class="No-Break">artificially adjusted.</span></p>
			<p>The first way to do this is to show not the average value, but the smoothed average (damped mean). With a small number of ratings, the displayed rating leans more toward a specific safe <em class="italic">average</em> indicator, and as soon as a sufficient number of new ratings are typed, the <em class="italic">averaging</em> adjustment <span class="No-Break">stops operating.</span></p>
			<p>Another approach is to calculate confidence intervals for each rating. Mathematically, the more estimates we have, the smaller the variation of the average will be and, therefore, the more confidence we have in <span class="No-Break">its accuracy.</span></p>
			<p>For example, we can display the lower<a id="_idIndexMarker984"/> limit of the interval (low <strong class="bold">confidence interval</strong> (<strong class="bold">CI</strong>) bound) as a rating. At the same time, it’s clear that such a system is quite conservative, with a tendency to underestimate ratings for <span class="No-Break">new items.</span></p>
			<p>Since the estimates are limited to a specific scale (for example, from 0 to 1), the usual methods for calculating the confidence interval are poorly applicable here due to the distribution tails that go to infinity, and the symmetry of the interval itself. There’s a more accurate way to calculate it—the <span class="No-Break">Wilson CI.</span></p>
			<p>The cold start problem is also relevant for non-personalized recommendations. The general approach here is to replace what currently can’t be calculated by different heuristics—for example, replace it with an average rating, use a simpler algorithm, or not use the product at all until the data has <span class="No-Break">been collected.</span></p>
			<p>Another issue that should be<a id="_idIndexMarker985"/> considered when we develop a recommender system is the relevance of recommendations, which considers factors other than the user’s interests—for example, it can be the freshn<a id="_idTextAnchor474"/>e<a id="_idTextAnchor475"/>ss of a publication or a <span class="No-Break">user’s rating.</span></p>
			<h2 id="_idParaDest-181"><a id="_idTextAnchor476"/>Relevance of recommendations</h2>
			<p>In some cases, it’s also essential to <a id="_idIndexMarker986"/>consider the <em class="italic">freshness</em> of the recommendation. This consideration is especially important for articles or posts on forums. Fresh entries should often get to the top. The correction factors (damping factors) are usually used to make such updates. The following formulas are used for calculating the rating of articles on <span class="No-Break">media sites.</span></p>
			<p>Here’s an example of a rating calculation in the <em class="italic">Hacker</em> <span class="No-Break">news magazine:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer598">
					<img alt="" role="presentation" src="image/B19849_08_11.jpg"/>
				</div>
			</div>
			<p>Here, <em class="italic">U</em> denotes upvotes, <em class="italic">D</em> denotes downvotes, <em class="italic">P</em> denotes penalty (additional adjustment for the implementation <a id="_idIndexMarker987"/>of other business rules), and <em class="italic">T</em> denotes <span class="No-Break">recording time.</span></p>
			<p>The following equation shows a <em class="italic">Reddit</em> <span class="No-Break">rating calculation:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer599">
					<img alt="" role="presentation" src="image/B19849_08_12.jpg"/>
				</div>
			</div>
			<p>Here, <em class="italic">U</em> denotes the number of upvotes, <em class="italic">D </em>denotes the number of downvotes, and <em class="italic">T</em> denotes the recording time. The first term evaluates the <em class="italic">quality of the record</em>, and the second corrects for <span class="No-Break">the time.</span></p>
			<p>There’s no universal formula, and each service invents the formula that best solves its problem; it can only be <span class="No-Break">tested empirically.</span></p>
			<p>The following section will discuss the existing approaches to testing recommender systems. This isn’t a straightforward task because it’s usually hard to estimate the quality of a recommendation without having ex<a id="_idTextAnchor477"/>a<a id="_idTextAnchor478"/>ct target values in a <span class="No-Break">training dataset.</span></p>
			<h2 id="_idParaDest-182"><a id="_idTextAnchor479"/>Assessing system quality</h2>
			<p>Testing a recommender system is a complicated process that always poses many questions, mainly due to the <a id="_idIndexMarker988"/>ambiguity of the concept <span class="No-Break">of </span><span class="No-Break"><em class="italic">quality</em></span><span class="No-Break">.</span></p>
			<p>In general, in machine learning problems, there are two main approaches <span class="No-Break">to testing:</span></p>
			<ul>
				<li>Offline model testing on historical data using <span class="No-Break">retro tests</span></li>
				<li>Testing the model using A/B testing (we run several options and see which one gives the <span class="No-Break">best result)</span></li>
			</ul>
			<p>Both of these approaches are actively used in developing recommender systems. The main limitation that we have to face is that we can only evaluate the accuracy of the forecast on those products that the user has already evaluated or rated. The standard approach is to use <a id="_idIndexMarker989"/>cross-validation alongside the <strong class="bold">leave-one-out</strong> and <strong class="bold">leave-p-out</strong> methods. Repeating the<a id="_idIndexMarker990"/> test and averaging the results provides a more stable assessment <span class="No-Break">of quality.</span></p>
			<p>The <em class="italic">leave-one-out</em> approach uses the model that’s been trained on all items except one and is evaluated by the user. This excluded item is used for model testing. This procedure is done for all <em class="italic">n</em> items, and an average is calculated among the obtained <em class="italic">n</em> <span class="No-Break">quality estimates.</span></p>
			<p>The <em class="italic">leave-p-out</em> approach is the <a id="_idIndexMarker991"/>same, but at each step, <img alt="" role="presentation" src="image/B19849_Formula_119.png"/> points <span class="No-Break">are excluded.</span></p>
			<p>We can divide all quality metrics into the following <span class="No-Break">three categories:</span></p>
			<ul>
				<li><strong class="bold">Prediction accuracy</strong>: Estimates the accuracy of the <span class="No-Break">predicted rating</span></li>
				<li><strong class="bold">Decision support</strong>: Evaluates the relevance of <span class="No-Break">the recommendations</span></li>
				<li><strong class="bold">Rank accuracy metrics</strong>: Evaluates the quality of the ranking of <span class="No-Break">recommendations issued</span></li>
			</ul>
			<p>Unfortunately, there’s no single recommended metric for all occasions, and everyone who’s involved in testing a recommender system selects it to fit <span class="No-Break">their goals.</span></p>
			<p>In the following section, we’ll formalize the collaborative fi<a id="_idTextAnchor480"/>l<a id="_idTextAnchor481"/>tering method and show the math <span class="No-Break">behind it.</span></p>
			<h1 id="_idParaDest-183"><a id="_idTextAnchor482"/>Understanding the collaborative filtering method</h1>
			<p>In this section, we’ll formalize the <a id="_idIndexMarker992"/>recommender system problem. We have a set of users, <img alt="" role="presentation" src="image/B19849_08_14.png"/>, a set of items, <img alt="" role="presentation" src="image/B19849_08_15.png"/> (movies, tracks, products, and so on), and a set of estimates, <img alt="" role="presentation" src="image/B19849_08_16.png"/>. Each estimate is given by a user <img alt="" role="presentation" src="image/B19849_08_17.png"/>, an object <img alt="" role="presentation" src="image/B19849_Formula_0721.png"/>, its result <img alt="" role="presentation" src="image/B19849_08_19.png"/>, and, possibly, some <span class="No-Break">other characteristics.</span></p>
			<p>We’re required to predict preference <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer607">
					<img alt="" role="presentation" src="image/B19849_08_20.jpg"/>
				</div>
			</div>
			<p>We’re required to predict personal recommendations <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer608">
					<img alt="" role="presentation" src="image/B19849_08_21.jpg"/>
				</div>
			</div>
			<p>We’re required to predict similar objects <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer609">
					<img alt="" role="presentation" src="image/B19849_08_22.jpg"/>
				</div>
			</div>
			<p>Remember that the main idea behind collaborative filtering is that similar users usually like similar objects. Let’s start with the <span class="No-Break">simplest method:</span></p>
			<ol>
				<li>Select some conditional measures of similarity of users according to their history of <img alt="" role="presentation" src="image/B19849_08_23.png"/> <span class="No-Break">ratings.</span></li>
				<li>Unite users into groups (clusters) so that similar users will end up in the same <span class="No-Break">cluster: <img alt="" role="presentation" src="image/B19849_08_24.png"/></span><span class="No-Break"><span class="subscript">.</span></span></li>
				<li>Predict the item’s user rating as the cluster’s average rating for <span class="No-Break">this object:</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer612">
					<img alt="" role="presentation" src="image/B19849_08_25.jpg"/>
				</div>
			</div>
			<p>This algorithm has <span class="No-Break">several problems:</span></p>
			<ul>
				<li>There’s nothing to recommend to new or atypical users. For such users, there’s no suitable cluster with <span class="No-Break">similar users.</span></li>
				<li>It ignores the specificity of each user. In a sense, we divide all users into <span class="No-Break">classes (templates).</span></li>
				<li>If no one in the cluster has rated the item, the prediction <span class="No-Break">won’t work.</span></li>
			</ul>
			<p>We can improve this <a id="_idIndexMarker993"/>method and replace hard clustering with the <span class="No-Break">following formula:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer613">
					<img alt="" role="presentation" src="image/B19849_08_26.jpg"/>
				</div>
			</div>
			<p>For an item-based version, the formula will be symmetrical, <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer614">
					<img alt="" role="presentation" src="image/B19849_08_27.jpg"/>
				</div>
			</div>
			<p>These approaches have the <span class="No-Break">following disadvantages:</span></p>
			<ul>
				<li>Cold <span class="No-Break">start problem</span></li>
				<li>Bad predictions for new and atypical users <span class="No-Break">or items</span></li>
				<li><span class="No-Break">Trivial recommendations</span></li>
				<li>Resource <span class="No-Break">intensity calculations</span></li>
			</ul>
			<p>To overcome these problems, you can use SVD. The preference (ratings) matrix can be decomposed into the product of three matrices, <img alt="" role="presentation" src="image/B19849_08_28.png"/>. Let’s denote the product of the first two matrices for one matrix, <img alt="" role="presentation" src="image/B19849_08_29.png"/>, where <em class="italic">R</em> is the matrix of preferences, <em class="italic">U</em> is the matrix of parameters of users, and <em class="italic">V</em> is the matrix of parameters <span class="No-Break">of items.</span></p>
			<p>To predict the user rating, <em class="italic">U</em>, for an item, <img alt="" role="presentation" src="image/B19849_08_30.png"/>, we take a vector, <img alt="" role="presentation" src="image/B19849_08_31.png"/> (parameter set), for a given user and a vector for a given item, <img alt="" role="presentation" src="image/B19849_08_32.png"/>. Their scalar product is the prediction we need: <img alt="" role="presentation" src="image/B19849_08_33.png"/>. Using this approach, we can identify the hidden features of items and user interests by user history. For example, it may happen that at the first coordinate of the vector, each user has a number indicating whether the user is more likely to be a boy or a girl, and the second coordinate is a number reflecting the approximate age of the user. In the item, the first coordinate shows whether it’s more interesting to boys or girls, and the second one shows the age group of users this item <span class="No-Break">appeals to.</span></p>
			<p>However, there are also several problems. The first one is the preferences matrix, <em class="italic">R</em>, which isn’t entirely known to us, so we can’t merely take its SVD decomposition. Secondly, the SVD decomposition isn’t the only one we have, so even if we find at least some decomposition, it’s unlikely that it’s optimal for <span class="No-Break">our task.</span></p>
			<p>Here, we need machine learning. We <a id="_idIndexMarker994"/>can’t find the SVD decomposition of the matrix since we don’t know the matrix itself. However, we can take advantage of this idea and come up with a prediction model that works like SVD. Our model depends on many parameters—vectors of users and items. For the given parameters, to predict the estimate, we must take the user vector, the vector of the item, and get their scalar product, <img alt="" role="presentation" src="image/B19849_08_34.png"/>. However, since we don’t know vectors, they still need to be obtained. The idea is that we have user ratings with which we can find optimal parameters so that our model can predict these estimates as accurately as possible using the following equation: <img alt="" role="presentation" src="image/B19849_08_35.png"/>. We want to find such parameters’ <em class="italic">θ</em> values so that the square error is as small as possible. We also want to make fewer mistakes in the future, but we don’t know what estimates we need. Accordingly, we can’t optimize parameters’ <em class="italic">θ</em> values. We already know the ratings given by users, so we can try to choose parameters based on the estimates we already have to minimize the error. We can also add another term, the <em class="italic">regularizer</em>, as <span class="No-Break">shown here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer623">
					<img alt="" role="presentation" src="image/B19849_08_36.jpg"/>
				</div>
			</div>
			<p>Regularization is needed to combat overfitting. To find the optimal parameters, you need to optimize the <span class="No-Break">following function:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer624">
					<img alt="" role="presentation" src="image/B19849_08_37.jpg"/>
				</div>
			</div>
			<p>There are many parameters: for each user and item, we have the vector that we want to optimize. The most well-known method for<a id="_idIndexMarker995"/> optimizing functions is <strong class="bold">gradient descent</strong> (<strong class="bold">GD</strong>). Suppose we have a function of many variables, and we want to optimize it. We take an initial value, and then we look at where we can move to minimize this value. The GD method is an iterative algorithm—it takes the parameters of a certain point repeatedly, looks at the gradient, and steps against its direction, as <span class="No-Break">shown here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer625">
					<img alt="" role="presentation" src="image/B19849_08_38.jpg"/>
				</div>
			</div>
			<p>There are various problems with this method: it works very slowly and it finds local, rather than global, minima. The second problem isn’t so bad for us because in our case, the value of the function in local minima is close to the <span class="No-Break">global optimum.</span></p>
			<p>However, the GD method isn’t<a id="_idIndexMarker996"/> always necessary. For example, if we need to calculate the minimum for a parabola, there’s no need to act by this method as we know precisely where its minimum is. It turns out that the functionality that we’re trying to optimize—the sum of the squares of errors plus the sum of the squares of all the parameters—is also a quadratic function, which is very similar to a parabola. For each specific parameter, if we fix all the others, it’s just a parabola. For those, we can accurately determine at least one coordinate. The ALS method is based on this assumption. We alternate between accurately finding minima in one coordinate or another, as <span class="No-Break">shown here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer626">
					<img alt="" role="presentation" src="image/B19849_08_39.jpg"/>
				</div>
			</div>
			<p>We fix all the parameters of the items, optimize the parameters of users, fix the parameters of users, and then optimize the parameters of items. We act iteratively, as <span class="No-Break">shown here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer627">
					<img alt="" role="presentation" src="image/B19849_08_40.jpg"/>
				</div>
			</div>
			<p>This method works reasonably quickly, and you can parallelize each step. However, there’s still a problem with implicit data because we have neither full user data nor full item data. So, we can penalize the items that don’t have ratings in the update rule. By doing so, we depend only on the items that have ratings from the users and don’t make any assumptions about the items that aren’t rated. So, let’s define a weight matrix, <img alt="" role="presentation" src="image/B19849_08_41.png"/>, <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer629">
					<img alt="" role="presentation" src="image/B19849_08_42.jpg"/>
				</div>
			</div>
			<p>The cost functions that we’re trying to minimize look <span class="No-Break">like this:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer630">
					<img alt="" role="presentation" src="image/B19849_08_43.jpg"/>
				</div>
			</div>
			<p>Note that we need regularization terms to avoid overfitting the data. We can use the following solutions for <span class="No-Break">factor vectors:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer631">
					<img alt="" role="presentation" src="image/B19849_08_44.jpg"/>
				</div>
			</div>
			<p>Here, <img alt="" role="presentation" src="image/B19849_08_45.png"/> and <img alt="" role="presentation" src="image/B19849_08_46.png"/>are <span class="No-Break">diagonal matrices.</span></p>
			<p>Another approach for dealing with implicit data is to introduce confidence levels. Let’s define a set of binary <span class="No-Break">observation variables:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer634">
					<img alt="" role="presentation" src="image/B19849_08_47.jpg"/>
				</div>
			</div>
			<p>Now, we can define confidence levels for each <img alt="" role="presentation" src="image/B19849_08_48.png"/> value. When <img alt="" role="presentation" src="image/B19849_08_49.png"/>, we have low confidence. This can be because the user has never been exposed to that item or it may be unavailable at the time. For<a id="_idIndexMarker997"/> example, it could be explained by the user buying a gift for someone else. Hence, we would have <em class="italic">low confidence</em>. When <img alt="" role="presentation" src="image/B19849_08_50.png"/> is larger, we should have much more confidence. For example, we can define confidence <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer638">
					<img alt="" role="presentation" src="image/B19849_08_51.jpg"/>
				</div>
			</div>
			<p>Here, <img alt="" role="presentation" src="image/B19849_08_52.png"/> is a hyperparameter that should be tuned for a given dataset. The updated optimization function is <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer640">
					<img alt="" role="presentation" src="image/B19849_08_53.jpg"/>
				</div>
			</div>
			<p>Here, <img alt="" role="presentation" src="image/B19849_08_54.png"/> is a diagonal matrix with <img alt="" role="presentation" src="image/B19849_08_55.png"/> values. The following solutions are for user and <span class="No-Break">item ratings:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer643">
					<img alt="" role="presentation" src="image/B19849_08_56.jpg"/>
				</div>
			</div>
			<p>However, it’s an expensive computational problem to calculate the <img alt="" role="presentation" src="image/B19849_08_57.png"/> expression. However, it can be optimized in the<a id="_idIndexMarker998"/> <span class="No-Break">following way:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer645">
					<img alt="" role="presentation" src="image/B19849_08_58.jpg"/>
				</div>
			</div>
			<p>This means that <img alt="" role="presentation" src="image/B19849_08_59.png"/> can be precomputed at each of the steps, and <img alt="" role="presentation" src="image/B19849_08_60.png"/> only contains the non-zero entries where <img alt="" role="presentation" src="image/B19849_08_61.png"/> was non-zero. Now that we’ve learned about collaborative filtering in detail, let’s understand it further practically by considering a few examples of how to implement a collaborative filtering <span class="No-Break">recommender system.</span></p>
			<p>In the following sections, we’ll learn how to use different C++ libraries for developing <span class="No-Break">recommender system<a id="_idTextAnchor483"/>s<a id="_idTextAnchor484"/>.</span></p>
			<h1 id="_idParaDest-184"><a id="_idTextAnchor485"/>Examples of item-based collaborative filtering with C++</h1>
			<p>Let’s look at how we can implement a collaborative filtering recommender system. We’ll be using the MovieLens dataset provided <a id="_idIndexMarker999"/>by GroupLens from the research lab in the Department of Computer Science and Engineering at the University of Minnesota: <a href="B19849_08.xhtml#_idTextAnchor473">https://grouplens.org/datasets/movielens/</a>. They’ve provided a full dataset containing 20 million movie ratings and a smaller one for education that contains 100,000 ratings. We recommend starting with the smaller one because it allows us to see results earlier and detect implementation <span class="No-Break">errors faster.</span></p>
			<p>This dataset consists of several files, but we’re only interested in two of them: <strong class="source-inline">ratings.csv</strong> and <strong class="source-inline">movies.csv</strong>. The rating file contains lines with the following format: the user ID, the movie ID, the rating, and the timestamp. In this dataset, users made ratings on a 5-star scale, with half-star increments (0.5 stars to 5.0 stars). The movie’s file contains lines with the following format: the movie ID, the title, and the genre. The movie ID is the same in both files so that we can see which movies users <span class="No-Break">are rati<a id="_idTextAnchor486"/>n<a id="_idTextAnchor487"/>g.</span></p>
			<h2 id="_idParaDest-185"><a id="_idTextAnchor488"/>Using the Eigen library</h2>
			<p>First, let’s learn how to implement a collaborative filtering<a id="_idIndexMarker1000"/> recommender system based on matrix factorization with ALS and with a pure linear algebra library as a backend. In the following sample, we’re <a id="_idIndexMarker1001"/>using the <strong class="source-inline">Eigen</strong> library. The steps to implement a collaborative filtering recommender system are <span class="No-Break">as follows:</span></p>
			<ol>
				<li>First, we must make base type definitions, <span class="No-Break">as follows:</span><pre class="source-code">
using DataType = float;
// using Eigen::ColMajor is Eigen restriction - todense method always returns
// matrices in ColMajor order
using Matrix = Eigen::Matrix&lt;DataType,
                             Eigen::Dynamic,
                             Eigen::Dynamic,
                             Eigen::ColMajor&gt;;
using SparseMatrix =
    Eigen::SparseMatrix&lt;DataType, Eigen::ColMajor&gt;;
using DiagonalMatrix =
    Eigen::DiagonalMatrix&lt;DataType,
                          Eigen::Dynamic,
                          Eigen::Dynamic&gt;;</pre></li>				<li>These definitions allow us to write less source code for matrices’ types and to quickly change floating-point <a id="_idIndexMarker1002"/>precision. Next, we must define and initialize the ratings (preferences) matrix, list of movie titles, and binary rating flags matrix, <span class="No-Break">as follows:</span><pre class="source-code">
SparseMatrix ratings_matrix; // user-item ratings
SparseMatrix p; // binary variables
std::vector&lt;std::string&gt; movie_titles;</pre><p class="list-inset">We have a particular helper function, <strong class="source-inline">LoadMovies</strong>, which loads files into the map container, as shown in the following <span class="No-Break">code snippet:</span></p><pre class="source-code">auto movies_file = root_path / "movies.csv";
auto movies = LoadMovies(movies_file);
auto ratings_file = root_path / "ratings.csv";
auto ratings = LoadRatings(ratings_file);</pre></li>				<li>Once the data has been<a id="_idIndexMarker1003"/> loaded, we can initialize matrix objects so that they’re the <span class="No-Break">right size:</span><pre class="source-code">
ratings_matrix.resize(
  static_cast&lt;Eigen::Index&gt;(ratings.size()),
  static_cast&lt;Eigen::Index&gt;(movies.size()));
ratings_matrix.setZero();
p.resize(ratings_matrix.rows(), ratings_matrix.cols());
p.setZero();
movie_titles.resize(movies.size());</pre><p class="list-inset">However, because we’ve loaded data into the map, we need to move the required rating values to the<a id="_idIndexMarker1004"/> <span class="No-Break">matrix object.</span></p></li>				<li>Now, we must initialize the movie titles list, convert user IDs into our zero-based sequential order, and initialize the binary rating matrix (this is used in the algorithm to deal with implicit data), <span class="No-Break">as follows:</span><pre class="source-code">
Eigen::Index user_idx = 0;
for (auto&amp; r : ratings) {
  for (auto&amp; m : r.second) {
    auto mi = movies.find(m.first);
    Eigen::Index movie_idx =
        std::distance(movies.begin(), mi);
    movie_titles[static_cast&lt;size_t&gt;(movie_idx)] =
        mi-&gt;second;
    ratings_matrix.insert(user_idx, movie_idx) =
        static_cast&lt;DataType&gt;(m.second);
    p.insert(user_idx, movie_idx) = 1.0;
  }
  ++user_idx;
}
ratings_matrix.makeCompressed();</pre></li>				<li>Once the<a id="_idIndexMarker1005"/> rating matrix has<a id="_idIndexMarker1006"/> been initialized, we must define and initialize our <span class="No-Break">training variables:</span><pre class="source-code">
auto m = ratings_matrix.rows();
auto n = ratings_matrix.cols();
Eigen::Index n_factors = 100;
auto y = InitializeMatrix(n, n_factors);
auto x = InitializeMatrix(m, n_factors);</pre><p class="list-inset">In the preceding code snippet, the <strong class="source-inline">y</strong> matrix corresponds to user preferences, while the <strong class="source-inline">x</strong> matrix corresponds to the item parameters. We’ve also defined the number of factors we’ll be interested in after decomposition. These matrices are initialized with random values and normalized. Such an approach is used to speed up algorithm convergence. This can be seen in the following <span class="No-Break">code snippet:</span></p><pre class="source-code">Matrix InitializeMatrix(Eigen::Index rows,
                        Eigen::Index cols) {
  Matrix mat = Matrix::Random(rows, cols).array().abs();
  auto row_sums = mat.rowwise().sum();
  mat.array().colwise() /= row_sums.array();
  return mat;
}</pre></li>				<li>Then, we must define and initialize<a id="_idIndexMarker1007"/> the regularization matrix and identity matrices, which are <a id="_idIndexMarker1008"/>constant during all <span class="No-Break">learning cycles:</span><pre class="source-code">
DataType reg_lambda = 0.1f;
SparseMatrix reg = (reg_lambda * Matrix::Identity(
                    n_factors, n_factors)).sparseView();
// Define diagonal identity terms
SparseMatrix user_diag = -1 * Matrix::Identity(
                             n, n).sparseView();
SparseMatrix item_diag = -1 * Matrix::Identity(
                             m, m).sparseView();</pre></li>				<li>Additionally, because we’re implementing an algorithm version that can handle implicit data, we need to convert our rating matrix into another format to decrease computational complexity. Our version of the algorithm needs user ratings in the form of <img alt="" role="presentation" src="image/B19849_08_62.png"/> and diagonal matrices for every user and item so that we can make two containers with corresponding matrix objects. The code for this can be seen in the <span class="No-Break">following block:</span><pre class="source-code">
std::vector&lt;DiagonalMatrix&gt; user_weights(
    static_cast&lt;size_t&gt;(m));
std::vector&lt;DiagonalMatrix&gt; item_weights(
    static_cast&lt;size_t&gt;(n));
{
  Matrix weights(ratings_matrix);
  weights.array() *= alpha;
  weights.array() += 1;
  for (Eigen::Index i = 0; i &lt; m; ++i) {
    user_weights[static_cast&lt;size_t&gt;(i)] =
        weights.row(i).asDiagonal();
  }
  for (Eigen::Index i = 0; i &lt; n; ++i) {
    item_weights[static_cast&lt;size_t&gt;(i)] =
        weights.col(i).asDiagonal();
  }
}</pre><p class="list-inset">Now, we’re ready to<a id="_idIndexMarker1009"/> implement the main learning loop. As discussed previously, the ALS algorithm can be easily parallelized, so we use the <strong class="source-inline">OpenMP</strong> compiler extension to calculate<a id="_idIndexMarker1010"/> user and item parameters <span class="No-Break">in parallel.</span></p></li>				<li>Let’s define the main learning cycle, which runs for a specified number <span class="No-Break">of iterations:</span><pre class="source-code">
size_t n_iterations = 5;
for (size_t k = 0; k &lt; n_iterations; ++k) {
  auto yt = y.transpose();
  auto yty = yt * y;
  ...
      // update item parameters
      ... auto xt = x.transpose();
  auto xtx = xt * x;
  ...
      // update users preferences
      ... auto w_mse = CalculateWeightedMse(
          x, y, p, ratings_matrix, alpha);
}</pre></li>				<li>The following code<a id="_idIndexMarker1011"/> shows how to update<a id="_idIndexMarker1012"/> <span class="No-Break">item parameters:</span><pre class="source-code">
#pragma omp parallel
{
  Matrix diff;
  Matrix ytcuy;
  Matrix a, b, update_y;
  #pragma omp for private(diff, ytcuy, a, b, update_y)
  for (size_t i = 0; i &lt; static_cast&lt;size_t&gt;(m); ++i) {
    diff = user_diag;
    diff += user_weights[i];
    ytcuy = yty + yt * diff * y;
    auto p_val =
        p.row(static_cast&lt;Eigen::Index&gt;(i)).transpose();
    a = ytcuy + reg;
    b = yt * user_weights[i] * p_val;
    update_y = a.colPivHouseholderQr().solve(b);
    x.row(static_cast&lt;Eigen::Index&gt;(i)) =
        update_y.transpose();
  }
}</pre></li>				<li>The following code <a id="_idIndexMarker1013"/>shows how to update<a id="_idIndexMarker1014"/> <span class="No-Break">users’ preferences:</span><pre class="source-code">
#pragma omp parallel
{
  Matrix diff;
  Matrix xtcux;
  Matrix a, b, update_x;
  #pragma omp for private(diff, xtcux, a, b, update_x)
  for (size_t i = 0; i &lt; static_cast&lt;size_t&gt;(n); ++i) {
    diff = item_diag;
    diff += item_weights[i];
    xtcux = xtx + xt * diff * x;
    auto p_val = p.col(static_cast&lt;Eigen::Index&gt;(i));
    a = xtcux + reg;
    b = xt * item_weights[i] * p_val;
    update_x = a.colPivHouseholderQr().solve(b);
    y.row(static_cast&lt;Eigen::Index&gt;(i)) =
        update_x.transpose();
  }
}</pre><p class="list-inset">Here, we have two parts of the loop<a id="_idIndexMarker1015"/> body that are pretty much the same. First, we updated item parameters with frizzed user options, and then we updated user preferences with<a id="_idIndexMarker1016"/> frizzed item parameters. Notice that all matrix objects were moved outside of the internal loop body to reduce memory allocations and significantly improve program performance. Also, notice that we parallelized the user and item parameters’ calculations separately because one of them should always be frizzed when the other is being calculated. To calculate exact values for user preferences and item parameters, we must use the <span class="No-Break">following formula:</span></p></li>			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer650">
					<img alt="" role="presentation" src="image/B19849_08_63.jpg"/>
				</div>
			</div>
			<p class="list-inset"><em class="italic">X T X</em> and <em class="italic">Y T Y</em> are precomputed at each step. Also, notice that these formulas are expressed in the form of the linear equation system, <em class="italic">X = AB</em>. We use the <strong class="source-inline">colPivHouseholderQr</strong> function from the <strong class="source-inline">Eigen</strong> library to solve it and get exact values for the user and item parameters. This linear equation system can also be solved with other methods. The <strong class="source-inline">colPivHouseholderQr</strong> function was chosen because it shows a better ratio between computational speed and accuracy in the <strong class="source-inline">Eigen</strong> <span class="No-Break">library implementation.</span></p>
			<ol>
				<li value="11">To estimate the progress of the learning process of our system, we can calculate the <strong class="bold">mean squared error</strong> (<strong class="bold">MSE</strong>) between the original rating matrix and a predicted one. To calculate the predicted <a id="_idIndexMarker1017"/>rating matrix, we must define <span class="No-Break">another function:</span><pre class="source-code">
Matrix RatingsPredictions(const Matrix&amp; x, const Matrix&amp; y) {
        return x * y.transpose();
}</pre></li>				<li>To calculate the <a id="_idIndexMarker1018"/>MSE, we can use the <img alt="" role="presentation" src="image/B19849_08_64.png"/>  expression from our <span class="No-Break">optimization function:</span><pre class="source-code">
DataType CalculateWeightedMse(const Matrix&amp; x,
                              const Matrix&amp; y,
                              const SparseMatrix&amp; p,
                              const SparseMatrix&amp; ratings_matrix,
                              DataType alpha) {
Matrix c(ratings_matrix);
  c.array() *= alpha;
  c.array() += 1.0;
  Matrix diff(p - RatingsPredictions(x, y));
  diff = diff.array().pow(2.f);
  Matrix weighted_diff = c.array() * diff.array();
  return weighted_diff.array().mean();
}</pre><p class="list-inset">Please note that we have to use weights and binary ratings to get a meaningful value for the error because a similar approach was used during the learning process. Direct error calculation gives the wrong result because the predicted matrix has non-zero predictions, whereas the original rating matrix has zeros. It’s essential to understand that this algorithm doesn’t learn the original scale of ratings (from 0 to 5); instead, it learns prediction values in a range from 0 to 1. It follows on from the function we optimize, as <span class="No-Break">shown here:</span></p></li>			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer652">
					<img alt="" role="presentation" src="image/B19849_08_65.jpg"/>
				</div>
			</div>
			<ol>
				<li value="13">We can use the previously defined movies list to show movie recommendations. The following function shows<a id="_idIndexMarker1019"/> user preferences and system recommendations. To identify what a user likes, we’ll show movie titles that the user has rated with a rating value of more than 3. We’ll also<a id="_idIndexMarker1020"/> show movies that the system rates as equal to or higher than a 0.8 rating coefficient to identify which movie the system recommends to the user by running the <span class="No-Break">following code:</span></li>
			</ol>
			<pre class="source-code">
void PrintRecommendations(
    const Matrix&amp; ratings_matrix,
    const Matrix&amp; ratings_matrix_pred,
    const std::vector&lt;std::string&gt;&amp; movie_titles) {
  // collect recommendations
  auto n = ratings_matrix.cols();
  std::vector&lt;std::string&gt; liked;
  std::vector&lt;std::string&gt; recommended;
  for (Eigen::Index u = 0; u &lt; 5; ++u) {
    for (Eigen::Index i = 0; i &lt; n; ++i) {
      DataType orig_value = ratings_matrix(u, i);
      if (orig_value &gt;= 3.f) {
        liked.push_back(
            movie_titles[static_cast&lt;size_t&gt;(i)]);
      }
      DataType pred_value = ratings_matrix_pred(u, i);
      if (pred_value &gt;= 0.8f &amp;&amp; orig_value &lt; 1.f) {
        recommended.push_back(
            movie_titles[static_cast&lt;size_t&gt;(i)]);
      }
    }
    // print recommendations
    std::cout &lt;&lt; "\nUser " &lt;&lt; u &lt;&lt; " liked :";
    for (auto&amp; l : liked) {
      std::cout &lt;&lt; l &lt;&lt; "; ";
    }
    std::cout &lt;&lt; "\nUser " &lt;&lt; u &lt;&lt; " recommended :";
    for (auto&amp; r : recommended) {
      std::cout &lt;&lt; r &lt;&lt; "; ";
    }
    std::cout &lt;&lt; std::endl;
    liked.clear();
    recommended.clear();
  }
}</pre>			<p>This function can be <a id="_idIndexMarker1021"/>used <span class="No-Break">as</span><span class="No-Break"><a id="_idIndexMarker1022"/></span><span class="No-Break"> follows:</span></p>
			<pre class="source-code">
PrintRecommendations(ratings_matrix,
                     RatingsPredictions(x, y),
                     movie_titles);</pre>			<h2 id="_idParaDest-186"><a id="_idTextAnchor489"/>Using the mlpack library</h2>
			<p>The <strong class="source-inline">mlpack</strong> library is a general-purpose machine learning library that provides a lot of different algorithms and command-line<a id="_idIndexMarker1023"/> tools to process the data and learn these algorithms without explicit programming. As a basis, this library uses the <strong class="source-inline">Armadillo</strong> linear algebra library for math calculations. Other<a id="_idIndexMarker1024"/> libraries we’ve used in previous chapters don’t have collaborative filtering <span class="No-Break">algorithm implementations.</span></p>
			<p>To load the <strong class="source-inline">MovieLens</strong> dataset, use the same loading helper function that you did in the previous section. Once the data has been loaded, convert it into a format suitable for an object of the <strong class="source-inline">mlpack::cf::CFType</strong> type. This type implements a collaborative filtering algorithm and can be configured with different types of matrix factorization approaches. An object of this type can use dense as well as sparse rating matrices. In the case of a dense matrix, it should have three rows. The first row corresponds to users, the second row corresponds to items, and the third row corresponds to the rating. This structure is called a <strong class="bold">coordinate list format</strong>. In the case of the sparse matrix, it should be<a id="_idIndexMarker1025"/> a regular (user, item) table, as in the previous example. So, let’s define the sparse matrix for ratings. It should have the <strong class="source-inline">arma::SpMat&lt;DataType&gt;</strong> type from the <strong class="source-inline">Armadillo</strong> library, as illustrated in the following <span class="No-Break">code block:</span></p>
			<pre class="source-code">
arma::SpMat&lt;DataType&gt; ratings_matrix(ratings.size(),
                                     movies.size());
std::vector&lt;std::string&gt; movie_titles;
{
  // fill matrix with data
  movie_titles.resize(movies.size());
  size_t user_idx = 0;
  for (auto&amp; r : ratings) {
    for (auto&amp; m : r.second) {
      auto mi = movies.find(m.first);
      auto movie_idx = std::distance(movies.begin(), mi);
      movie_titles[static_cast&lt;size_t&gt;(movie_idx)] =
          mi-&gt;second;
      ratings_matrix(user_idx, movie_idx) =
          static_cast&lt;DataType&gt;(m.second);
    }
    ++user_idx;
  }
}</pre>			<p>Now, we can initialize the <strong class="source-inline">mlpack::cf::CFType</strong> class object. It takes the next parameters in the constructor: the rating<a id="_idIndexMarker1026"/> matrix, the matrix decomposition policy, the number of neighbors, the number<a id="_idIndexMarker1027"/> of target factors, the number of iterations, and the minimum value of learning error, after which the algorithm <span class="No-Break">can stop.</span></p>
			<p>For this object, only perform the nearest neighbor search on the <strong class="bold">H</strong> matrix. This means you avoid calculating the full rating matrix, using the observation that if the rating matrix is <strong class="bold">X = W H</strong>, then the <span class="No-Break">following applies:</span></p>
			<pre class="source-code">
distance(X.col(i), X.col(j)) = distance(W H.col(i), W H.col(j))
    </pre>			<p>This expression can be seen as the nearest neighbor search on the <strong class="bold">H</strong> matrix with the Mahalanobis distance, as illustrated in<a id="_idIndexMarker1028"/> the following <span class="No-Break">code block:</span></p>
			<pre class="source-code">
// factorization rank
size_t n_factors = 100;
size_t neighborhood = 50;
mlpack::NMFPolicy decomposition_policy;
// stopping criterions
size_t max_iterations = 20;
double min_residue = 1e-3;
mlpack::CFType cf(ratings_matrix,
                  decomposition_policy,
                  neighborhood,
                  n_factors,
                  max_iterations,
                  min_residue);</pre>			<p>Notice that as a decomposition policy, the object of the <strong class="source-inline">mlpack::NMFPolicy</strong> type was used. This shows how to implement the non-negative matrix factorization algorithm with the ALS approach. There are <a id="_idIndexMarker1029"/>several decomposition algorithms in the <strong class="source-inline">mlpack</strong> library. For example, batch SVD decomposition is implemented in the <strong class="source-inline">mlpack::BatchSVDPolicy</strong> type. The constructor of this object also does the complete training, so after its call has finished, we can use this object to get recommendations. Recommendations can be retrieved with the <strong class="source-inline">GetRecommendations</strong> method. This method gets the number of recommendations you want to get, the output matrix for recommendations, and the list of user IDs for users you want to get recommendations<a id="_idIndexMarker1030"/> from, as shown in the following <span class="No-Break">code block:</span></p>
			<pre class="source-code">
arma::Mat&lt;size_t&gt; recommendations;
// Get 5 recommendations for specified users.
arma::Col&lt;size_t&gt; users;
users &lt;&lt; 1 &lt;&lt; 2 &lt;&lt; 3;
cf.GetRecommendations(5, recommendations, users);
for (size_t u = 0; u &lt; recommendations.n_cols; ++u) {
  std::cout &lt;&lt; "User " &lt;&lt; users(u) &lt;&lt;" recommendations are: ";
  
  for (size_t i = 0; i &lt; recommendations.n_rows; ++i) {
    std::cout &lt;&lt; movie_titles[recommendations(i, u)] &lt;&lt; ";";
  }
  std::cout &lt;&lt; std::endl;
}</pre>			<p>Notice that the <strong class="source-inline">GetRecommendations</strong> method returns the item IDs as its output. So, we can see that using this library for implementing a recommender system is much easier than writing it from scratch. Also, there are many more configuration options in the <strong class="source-inline">mlpack</strong> library for building <a id="_idIndexMarker1031"/>such systems—for example, we can configure the neighbor detection policy and which distance measure to use. These configurations can significantly improve the quality of the system you build because you can make them acc<a id="_idTextAnchor490"/>o<a id="_idTextAnchor491"/>rding to your <span class="No-Break">particular task.</span></p>
			<h1 id="_idParaDest-187"><a id="_idTextAnchor492"/>Summary</h1>
			<p>In this chapter, we discussed what recommender systems are and the types that exist today. We studied two main approaches to building recommender systems: content-based recommendations and collaborative filtering. We identified two types of collaborative filtering: user-based and item-based. Then, we looked at how to implement these approaches, as well as their pros and cons. We found out that an important issue we must rectify when implementing recommender systems is the amount of data and the associated large computational complexity of algorithms. We considered approaches to overcome computational complexity problems, such as partial data updates and approximate iterative algorithms such as ALS. We found out how matrix factorization can help to solve the problem with incomplete data, improve the generalizability of the model, and speed up the calculations. We also implemented a system of collaborative filtering based on the linear algebra library and used the <strong class="source-inline">mlpack</strong> general-purpose machine <span class="No-Break">learning library.</span></p>
			<p>It makes sense to look at new methods that can be applied to recommender system tasks, such as autoencoders, variational autoencoders, or deep collaborative approaches. In recent research papers, these approaches show more impressive results than classical methods such as ALS. All these new methods are non-linear models, so they can potentially beat the limited modeling capacity of linear <span class="No-Break">factor models.</span></p>
			<p>In the next chapter, we’ll discuss ensemble learning techniques. The main idea of these techniques is to combine either different types of machine learning algorithms or use a set of the same kind of algorithms to obtain better predictive performance. Combining several algorithms into one ensemble allows us to get the best characteristics of each so that we can cover the disad<a id="_idTextAnchor493"/>v<a id="_idTextAnchor494"/>antages in a <span class="No-Break">single algorithm.</span></p>
			<h1 id="_idParaDest-188"><a id="_idTextAnchor495"/>Further reading</h1>
			<ul>
				<li><em class="italic">Collaborative Filtering for Implicit Feedback </em><span class="No-Break"><em class="italic">Datasets</em></span><span class="No-Break">: </span><a href="B19849_08.xhtml#_idTextAnchor476"><span class="No-Break">http://yifanhu.net/PUB/cf.pdf</span></a></li>
				<li><em class="italic">ALS Implicit Collaborative </em><span class="No-Break"><em class="italic">Filtering</em></span><span class="No-Break">: </span><a href="B19849_08.xhtml#_idTextAnchor482"><span class="No-Break">https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe</span></a></li>
				<li><em class="italic">Collaborative </em><span class="No-Break"><em class="italic">Filtering</em></span><span class="No-Break">: </span><a href="B19849_08.xhtml#_idTextAnchor485"><span class="No-Break">https://datasciencemadesimpler.wordpress.com/tag/alternating-least-squares/</span></a></li>
				<li>The <strong class="source-inline">mlpack</strong> library’s official <span class="No-Break">site: </span><a href="B19849_08.xhtml#_idTextAnchor488"><span class="No-Break">https://www.mlpack.org/</span></a></li>
				<li>The <strong class="source-inline">Armadillo</strong> library’s official <span class="No-Break">site: </span><a href="B19849_08.xhtml#_idTextAnchor489"><span class="No-Break">http://arma.sourceforge.net/</span></a></li>
				<li><em class="italic">Variational Autoencoders for Collaborative Filtering,</em> by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony <span class="No-Break">Jebara: </span><a href="B19849_08.xhtml#_idTextAnchor492"><span class="No-Break">https://arxiv.org/abs/1802.05814</span></a></li>
				<li><em class="italic">Deep Learning-Based Recommender System: A Survey and New Perspectives</em>, by Shuai Zhang, Lina Yao, Aixin Sun, and Yi <span class="No-Break">Tay: </span><a href="B19849_08.xhtml#_idTextAnchor495"><span class="No-Break">https://arxiv.org/abs/1707.07435</span></a></li>
				<li><em class="italic">Training Deep AutoEncoders for Collaborative Filtering</em>, by Oleksii Kuchaiev, and Boris <span class="No-Break">Ginsburg: </span><a href="B19849_08.xhtml#_idTextAnchor438"><span class="No-Break">https://arxiv.org/abs/1708.01715</span></a></li>
			</ul>
		</div>
	</body></html>