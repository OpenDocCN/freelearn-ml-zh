- en: '*Chapter 5*: Deep Learning Workflow'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第5章*：深度学习工作流程'
- en: In this chapter, we will go through the steps that you might perform while training
    your neural network, and when putting it into production. We will discuss more
    about the theory behind deep learning, to explain better what we actually did
    in [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091), *Deep Learning
    with Neural Networks*, but we will stay mostly focused on arguments related to
    self-driving cars. We will also introduce some concepts that will help us to achieve
    better precision on CIFAR-10, a famous dataset of small images. We are sure that
    the theory exposed in this chapter, plus the more practical knowledge associated
    with [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091), *Deep Learning
    with Neural Networks*, and [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142),
    *Improving Your Neural Network*, will give you enough tools to be able to perform
    tasks that are common in the field of self-driving cars.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍您在训练神经网络和将其投入生产过程中可能执行的操作步骤。我们将更深入地讨论深度学习背后的理论，以更好地解释我们在[*第4章*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091)，“使用神经网络的深度学习”中实际所做的工作，但我们主要关注与自动驾驶汽车相关的论点。我们还将介绍一些有助于我们在CIFAR-10（一个小型图像的著名数据集）上获得更高精度的概念。我们相信，本章中提出的理论，加上与[*第4章*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091)，“使用神经网络的深度学习”和[*第6章*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142)，“改进您的神经网络”相关的更实际的知识，将为您提供足够的工具来执行自动驾驶汽车领域中的常见任务。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Obtaining or creating the dataset
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取或创建数据集
- en: Training, validation, and test datasets
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练、验证和测试数据集
- en: Classifiers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类器
- en: Data augmentation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据增强
- en: Defining the model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义模型
- en: How to tune convolutional layers, `MaxPooling` layers, and dense layers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何调整卷积层、`MaxPooling`层和密集层
- en: Training and the role of randomness
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和随机性的作用
- en: Underfitting and overfitting
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欠拟合和过拟合
- en: Visualization of activations
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活的可视化
- en: Running inference
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行推理
- en: Retraining
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新训练
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To be able to use the code explained in this chapter, you need to have the
    following tools and modules installed:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够使用本章中解释的代码，您需要安装以下工具和模块：
- en: Python 3.7
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.7
- en: The NumPy module
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy模块
- en: The Matplotlib module
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib模块
- en: The TensorFlow module
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow模块
- en: The Keras module
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras模块
- en: The OpenCV-Python module
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV-Python模块
- en: The code for the chapter can be found at [https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter5](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter5).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在[https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter5](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter5)找到。
- en: 'The Code in Action videos for this chapter can be found here:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的“代码在行动”视频可以在以下位置找到：
- en: '[https://bit.ly/3dJrcys](https://bit.ly/3dJrcys)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://bit.ly/3dJrcys](https://bit.ly/3dJrcys)'
- en: Obtaining the dataset
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据集
- en: Once you have a task that you want to perform with a neural network, the first
    step is usually to obtain the dataset, which is the data that you need to feed
    to the neural network. In the tasks that we perform in this book, the dataset
    is usually composed of images or videos, but it could be anything, or a mix of
    images and other data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有一个想要用神经网络执行的任务，通常的第一步是获取数据集，这是您需要喂给神经网络的那些数据。在我们这本书中执行的任务中，数据集通常由图像或视频组成，但它可以是任何东西，或者图像和其他数据的混合。
- en: The dataset represents the input that you feed to your neural network, but as
    you may have noticed, your dataset also contains the desired output, the labels.
    We will call `x` the input to the neural network, and `y` the output. The dataset
    is composed of the inputs/features (for example, the images in the MNIST dataset),
    and the output/labels (for example, the number associated with each image).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集代表您喂给神经网络的输入，但如您所注意到的，您的数据集还包含期望的输出，即标签。我们将用`x`表示神经网络的输入，用`y`表示输出。数据集由输入/特征（例如，MNIST数据集中的图像）和输出/标签（例如，与每个图像关联的数字）组成。
- en: We have different dataset types. Let's start with the easiest – the datasets
    included in Keras – before proceeding to the next ones.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有不同的数据集类型。让我们从最简单的开始——Keras中包含的数据集——然后再继续到下一个。
- en: Datasets in the Keras module
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Keras模块中的数据集
- en: Usually a dataset is a lot of data. It's normal to train a neural network on
    tens of thousands of images, but the best neural networks are trained with many
    millions of images. So how do we use them?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，数据库包含大量数据。在成千上万张图片上训练神经网络是正常的，但最好的神经网络是用数百万张图片训练的。那么我们如何使用它们呢？
- en: 'The easiest way, which is usually mostly helpful for experiments, is to use
    the datasets included in Keras, as we did in [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091),
    *Deep Learning with Neural Networks*, using `load_data()`, shown as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法，通常对实验很有帮助，是使用Keras中包含的数据库，就像我们在[*第4章*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091)中做的那样，*使用神经网络进行深度学习*，使用`load_data()`，如下所示：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Keras provides a variety of datasets:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Keras提供了各种数据库：
- en: MNIST – the classification of digits
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MNIST – 数字分类
- en: CIFAR10 – the classification of small images
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CIFAR10 – 小图像的分类
- en: CIFAR100 – the classification of small images
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CIFAR100 – 小图像的分类
- en: IMDB movie review sentiment classification
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IMDB电影评论情感分类
- en: Reuters newswire classification
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路透社新闻社分类
- en: Fashion MNIST dataset
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fashion MNIST数据库
- en: Boston Housing prices
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 波士顿房价
- en: These datasets are useful in learning how to build neural networks in general.
    In the next section, we will look at some datasets that are more useful for self-driving
    cars.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据库对于学习如何构建神经网络非常有用。在下一节中，我们将探讨一些对自动驾驶汽车更有用的数据库。
- en: Existing datasets
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现有数据库
- en: Luckily, there are several interesting public datasets available, but you have
    to always carefully check the license to see what you are allowed to do with it,
    and eventually get or acquire a more permissive license.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有几个有趣的公共数据库可供使用，但你必须始终仔细检查许可证，以了解你可以用它做什么，并最终获取或获得更宽松的许可证。
- en: 'The following are some datasets related to self-driving cars that you might
    want to check:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些你可能想要检查的与自动驾驶汽车相关的数据库：
- en: BDD100K, a large-scale diverse driving video database; refer to [https://bdd-data.berkeley.edu/](https://bdd-data.berkeley.edu/).
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BDD100K，一个大规模多样化的驾驶视频数据库；参考[https://bdd-data.berkeley.edu/](https://bdd-data.berkeley.edu/)。
- en: Bosch small traffic lights database; refer to [https://hci.iwr.uni-heidelberg.de/content/bosch-small-traffic-lights-dataset](https://hci.iwr.uni-heidelberg.de/content/bosch-small-traffic-lights-dataset).
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 博世小型交通信号灯数据库；参考[https://hci.iwr.uni-heidelberg.de/content/bosch-small-traffic-lights-dataset](https://hci.iwr.uni-heidelberg.de/content/bosch-small-traffic-lights-dataset)。
- en: CULane, a large-scale dataset for academic research on traffic lane detection;
    refer to [https://xingangpan.github.io/projects/CULane.html](https://xingangpan.github.io/projects/CULane.html).
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CULane，一个用于交通车道检测学术研究的大规模数据库；参考[https://xingangpan.github.io/projects/CULane.html](https://xingangpan.github.io/projects/CULane.html)。
- en: KITTI Vision Benchmark Suite; refer to [http://www.cvlibs.net/datasets/kitti/](http://www.cvlibs.net/datasets/kitti/).
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KITTI视觉基准套件；参考[http://www.cvlibs.net/datasets/kitti/](http://www.cvlibs.net/datasets/kitti/)。
- en: Mapillary Traffic Sign Dataset; refer to [https://www.mapillary.com/dataset/trafficsign](https://www.mapillary.com/dataset/trafficsign).
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mapillary交通标志数据库；参考[https://www.mapillary.com/dataset/trafficsign](https://www.mapillary.com/dataset/trafficsign)。
- en: In addition, there are other more generic datasets that you might find interesting,
    in particular, ImageNet, [http://www.image-net.org/](http://www.image-net.org/),
    an image dataset organized according to the WordNet hierarchy.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一些其他更通用的数据库你可能觉得很有趣，特别是WordNet层次结构组织的图像数据库ImageNet，[http://www.image-net.org/](http://www.image-net.org/)。
- en: This dataset contains millions of URLs pointing to images on the internet, and
    has been very influential in developing neural networks. We will talk more about
    this later.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据库包含数百万个指向互联网上图片的URL，对神经网络的发展产生了重大影响。我们将在稍后详细讨论。
- en: Public datasets are great, but you might consider their content, as it is not
    uncommon to have some images incorrectly classified. This is not necessarily a
    big deal for your neural network, but you might still want to get a dataset as
    good as possible.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 公共数据库很棒，但你也可能需要考虑其内容，因为有些图片被错误分类并不罕见。这对你的神经网络来说可能不是什么大问题，但你可能仍然希望获得尽可能好的数据库。
- en: If you cannot find a satisfactory dataset, you can always generate one. Let's
    see how you can quickly build good datasets for self-driving car tasks.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果找不到令人满意的数据库，你总是可以生成一个。让我们看看如何快速构建用于自动驾驶汽车任务的优质数据库。
- en: Synthetic datasets
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 合成数据库
- en: When possible, you might want to generate a dataset from a program that can
    create *good enough* images. We used this technique in [*Chapter 3*](B16322_03_Final_NM_ePUB.xhtml#_idTextAnchor066),
    *Lane Detection*, where we detected pedestrians from Carla, and images from the
    open source video game Speed Dreams, and you could write your own generator using
    a 3D engine or 3D modeling software.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当可能时，您可能希望从可以创建*足够好*的图像的程序中生成数据集。我们在[*第3章*](B16322_03_Final_NM_ePUB.xhtml#_idTextAnchor066)
    *车道检测*中使用这项技术，我们从Carla中检测行人，从开源视频游戏Speed Dreams中获取图像，您也可以使用3D引擎或3D建模软件编写自己的生成器。
- en: These are a relatively easy, quick, and very cheap way to generate massive datasets,
    and, in fact, are sometimes invaluable, as in many cases you can automatically
    annotate the images and save a lot of time. However synthetic images tend to be
    less complex than real images, with the result that your network will probably
    not perform as well as you think in a real-world scenario. We will use this technique
    in [*Chapter 8*](B16322_08_Final_NM_ePUB.xhtml#_idTextAnchor182), *Behavioral
    Cloning*.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法相对简单、快捷且非常便宜，可以生成大量数据集，实际上有时是无价的，因为在许多情况下，你可以自动标注图像并节省大量时间。然而，合成图像通常比真实图像简单，结果可能是你的网络在现实世界场景中的表现可能不如你想象的那么好。我们将在[*第8章*](B16322_08_Final_NM_ePUB.xhtml#_idTextAnchor182)
    *行为克隆*中使用这项技术。
- en: One of the best simulators available, if not the best, is Carla.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不是最好的话，Carla是当前最好的模拟器之一。
- en: 'Carla, the open source simulator for autonomous driving research, uses the
    following websites:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Carla，自动驾驶研究的开源模拟器，使用了以下网站：
- en: '[https://carla.org/](https://carla.org/)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://carla.org/](https://carla.org/)'
- en: '[https://github.com/carla-simulator/carla](https://github.com/carla-simulator/carla)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/carla-simulator/carla](https://github.com/carla-simulator/carla)'
- en: You can use it to generate the images that you need for your tasks.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用它来生成您任务所需的图像。
- en: When this is not enough, you have to follow a manual process.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当这还不够时，您必须遵循手动流程。
- en: Your custom dataset
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 您的定制数据集
- en: Sometimes, you may have no satisfactory alternative and you need to collect
    the images by yourself. This might require the collection of footage and the classification
    of thousands of images. If the images are extracted from a video, you might be
    able to just classify a video, and then extract hundreds or thousands of images
    from it.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，您可能没有令人满意的替代方案，您需要自己收集图像。这可能需要收集录像并对数千张图像进行分类。如果图像是从视频中提取的，您可能只需对视频进行分类，然后从中提取数百或数千张图像。
- en: Sometimes this is not the case, and you need to go through tens of thousands
    of images by yourself. Alternatively, you can use the services of specialized
    companies to label the images for you.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 有时情况并非如此，您可能需要自己浏览成千上万张图片。或者，您可以使用专业公司的服务来为您标注图像。
- en: Sometimes you might have the images, but the classification might be difficult.
    Imagine having access to video footage of cars, and then having to annotate the
    images, adding the boxes where the cars are. If you are lucky, you might get access
    to a neural network that can do the job for you. You might still need to manually
    go through the result, and reclassify some images, but this can still save a lot
    of work.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 有时您可能拥有图像，但分类可能很困难。想象一下，如果您可以访问汽车的录像，然后需要标注图像，添加汽车所在的框。如果您很幸运，您可能可以访问一个可以为您完成这项工作的神经网络。您可能仍然需要手动检查结果，并对一些图像进行重新分类，但这仍然可以节省大量工作。
- en: Next, we will learn in depth about these datasets.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入了解这些数据集。
- en: Understanding the three datasets
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解三个数据集
- en: In reality, you don't need one dataset, but ideally three. These are required
    for training, validation, and testing. Before defining them, please consider that
    unfortunately sometimes, there is some confusion regarding the meaning of validation
    and test, typically where only two datasets are available, as in this case, validation
    and test datasets coincide. We did the same in [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091),
    *Deep Learning with Neural Networks*, where we used the test dataset as validation.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你可能不需要一个数据集，但理想情况下需要三个。这些数据集用于训练、验证和测试。在定义它们之前，请考虑不幸的是，有时关于验证和测试的含义存在一些混淆，通常情况下只有两个数据集可用，就像这种情况，验证集和测试集是重合的。我们在[*第4章*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091)
    *使用神经网络的深度学习*中也做了同样的事情，我们使用了测试集作为验证集。
- en: 'Let''s now define these three datasets, and then we can explain how ideally
    we should have tested the MNIST dataset:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在定义这三个数据集，然后我们可以解释理想情况下我们应该如何测试MNIST数据集：
- en: '**Training dataset**: This is the dataset used to train the neural network,
    and it is typically the biggest of the three datasets.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据集**：这是用于训练神经网络的数据库，通常是三个数据集中最大的一个。'
- en: '**Validation dataset**: This is usually a hold-out part of the training dataset
    that is not used for training, but only to evaluate the performance of a model
    and tune its hyperparameters (for example, the topology of the network or the
    learning rate of the optimizer).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证数据集**：这通常是指训练数据集的一部分，这部分数据不用于训练，而仅用于评估模型的性能和调整其超参数（例如，网络的拓扑结构或优化器的学习率）。'
- en: '**Test dataset**: Ideally this is a throw-away dataset used to evaluate the
    performance of the model once all the tuning is complete.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试数据集**：理想情况下，这是一个一次性数据集，用于在所有调整完成后评估模型的性能。'
- en: You cannot use the training dataset to evaluate the performance of a model because
    the training dataset is used by the optimizer to train the network, so this is
    the best case scenario. However, we usually don't need the neural network to perform
    well in the training dataset but in whatever the user will throw at it. So, we
    need the network to be able to *generalize*. Going back to the student metaphor
    from [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091), *Deep Learning
    with Neural Networks*, a high score in the training dataset means that the student
    learned the book (the training dataset) by heart, but what we want is the student
    to have understood the content of the book and be able to apply this knowledge
    to real-world situations (the validation dataset).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 您不能使用训练数据集来评估模型的性能，因为训练数据集被优化器用于训练网络，所以这是最佳情况。然而，我们通常不需要神经网络在训练数据集上表现良好，而是在用户抛给它的任何东西上表现良好。因此，我们需要网络能够*泛化*。回到[*第4章*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091)“使用神经网络的深度学习”中的学生比喻，训练数据集上的高分意味着学生已经把书（训练数据集）背得滚瓜烂熟，但我们希望的是学生能够理解书的内容，并能够将这种知识应用到现实世界的情境中（验证数据集）。
- en: So, if validation represents the real world, why do we need the test dataset?
    The problem is that while tuning your network, you will make choices that will
    be biased toward the validation dataset (such as choosing one model instead of
    another one based on its performance in the validation dataset). As a result,
    the performance in the validation dataset might still be higher than in the real
    world.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果验证代表现实世界，为什么我们还需要测试数据集呢？问题是，在调整您的网络时，您将做出一些选择，这些选择将偏向于验证数据集（例如，根据其在验证数据集上的性能选择一个模型而不是另一个模型）。结果，验证数据集上的性能可能仍然高于现实世界。
- en: The test dataset solves this problem as we only apply it after all the tuning.
    That also explains why ideally, we want to throw away the test dataset after using
    it only once.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据集解决了这个问题，因为我们只在所有调整完成后才应用它。这也解释了为什么理想情况下，我们希望在仅使用一次后丢弃测试数据集。
- en: This can be impractical, but not always, as sometimes you can easily generate
    some samples on demand.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能不切实际，但并非总是如此，因为有时您可以很容易地根据需要生成一些样本。
- en: So, how could we use three datasets in the MNIST task? Maybe you remember from
    [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091), *Deep Learning
    with Neural Networks*, that the MNIST dataset has 60,000 (60 K) samples for training
    and 10,000 (10 K) for testing.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何在MNIST任务中使用三个数据集呢？也许您还记得从[*第4章*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091)，“使用神经网络的深度学习”，MNIST数据集有60,000（60
    K）个样本用于训练，10,000（10 K）个用于测试。
- en: 'Ideally, you could use the following approach:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，您可以采用以下方法：
- en: The training dataset could use the full 60,000 samples intended for training.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据集可以使用为训练准备的60,000个样本。
- en: The validation dataset could use the 10,000 samples intended for testing (as
    we did).
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证数据集可以使用为测试准备的10,000个样本（正如我们所做的那样）。
- en: The test dataset could be generated on demand, writing digits on the spot.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试数据集可以根据需要生成，现场写数字。
- en: After discussing the three datasets, we can now see how to split your full dataset
    into three parts. While this seems an easy operation, you need to be careful in
    terms of how you go about it.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论了三个数据集之后，我们现在可以看看如何将您的完整数据集分成三部分。虽然这似乎是一个简单的操作，但在如何进行操作方面您需要小心。
- en: Splitting the dataset
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集拆分
- en: Given your full dataset, you might need to split it into training, validation,
    and testing parts. As stated previously, ideally you want the test to be generated
    on the spot, but if this is not possible, you might choose to use 15-20% of the
    total dataset for testing.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 给定你的完整数据集，你可能需要将其分成训练、验证和测试三个部分。如前所述，理想情况下，你希望测试是在现场生成的，但如果这不可能，你可能会选择使用总数据集的15-20%进行测试。
- en: Of the remaining dataset, you might use 15-20% as validation.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在剩余的数据集中，你可能使用15-20%作为验证。
- en: If you have many samples, you might use a smaller percentage for validation
    and testing. If you have a small dataset, after you are satisfied with your model
    performance (such as if you chose it because it performs well both on the validation
    and on the test dataset), you might add the test dataset to the training dataset
    to get more samples. If you do this, there is no point in evaluating the performance
    in the test dataset, as effectively, it will become part of the training. In this
    case, you trust the results in the validation dataset.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有很多样本，你可能为验证和测试使用更小的百分比。如果你有较小的数据集，在你对模型性能满意后（例如，如果你选择它是因为它在验证和测试数据集上都表现良好），你可能会将测试数据集添加到训练数据集中以获得更多样本。如果你这样做，就没有必要在测试数据集中评估性能，因为实际上它将成为训练的一部分。在这种情况下，你信任验证数据集的结果。
- en: But even with the same size, not all splits are created equal. Let's take a
    practical example.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 但即使大小相同，并不是所有的分割都是一样的。让我们用一个实际的例子来说明。
- en: You want to detect cats and dogs. You have a dataset of 10,000 pictures. You
    decide to use 8 K for training, 2 K for validation, and testing is done via the
    real-time recording of a video of 1 dog and 1 cat that you have at home; every
    time you test, you make a new video. Looks perfect. What can possibly go wrong?
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你想检测猫和狗。你有一个包含10,000张图片的数据集。你决定使用8,000张进行训练，2,000张进行验证，测试是通过你家中1只狗和1只猫的视频实时记录来完成的；每次测试时，你都会制作一个新的视频。看起来完美。可能出什么问题？
- en: First, you need more or less an equal number of cats and dogs in each dataset.
    If that's not the case, the network will be biased toward one of them. Intuitively,
    if during training, the network sees that 90% of the images are of dogs, just
    predicting always a dog will give you 90% accuracy!
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要在每个数据集中大致有相同数量的猫和狗。如果不是这样，网络将偏向于其中之一。直观地说，如果在训练过程中，网络看到90%的图像是狗的，那么总是预测狗将给你90%的准确率！
- en: You read that it is a best practice to randomize the order of the samples and
    you do it. Then you split. Your model performs well in the training, validation,
    and test datasets. Everything looks good. Then you try with pets of a few friends,
    and nothing works. What happened?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你读到随机化样本顺序是一种最佳实践，你就这样做了。然后你进行了分割。你的模型在训练、验证和测试数据集上表现良好。一切看起来都很不错。然后你尝试使用几个朋友的宠物，但什么都没发生。发生了什么？
- en: One possibility is that your split is not good in terms of measuring generalization.
    Even if you have 10 K images, they might have been taken from 100 pets (including
    yours), and every dog and cat is present 100 times, in slightly different positions
    (for example, from a video). If you shuffle the samples, all the dogs and cats
    will be present in all the datasets, so validation and testing will be relatively
    easy, as the network *already knows* those pets.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能性是，你的分割在衡量泛化方面并不好。即使你有1万张图片，它们可能只来自100只宠物（包括你的），每只狗和猫都出现了100次，位置略有不同（例如，来自视频）。如果你打乱样本，所有的狗和猫都会出现在所有数据集中，因此验证和测试将相对容易，因为网络*已经知道*那些宠物。
- en: If, instead, you keep 20 pets for validation, and take care to not include pictures
    of your pets in the training or validation dataset, then your estimation would
    be much more realistic, and you have a chance to build a neural network that is
    much better at generalizing.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果，相反，你为了验证而养了20只宠物，并且注意不要在训练或验证数据集中包含你的宠物照片，那么你的估计将更加现实，你有机会构建一个在泛化方面更好的神经网络。
- en: Now that we have three datasets, it's time to define the task that we need to
    perform, which typically will be image classification.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了三个数据集，是时候定义我们需要执行的任务了，这通常将是图像分类。
- en: Understanding classifiers
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解分类器
- en: Deep learning can be used for many different tasks. For what concerns images
    and CNN, a very common task is classification. Given an image, the neural network
    needs to classify it, using one of the labels provided during training. Not surprisingly,
    a network of this type is called a *classifier*.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习可以用于许多不同的任务。对于图像和CNN来说，一个非常常见的任务是分类。给定一个图像，神经网络需要使用在训练期间提供的标签之一对其进行分类。不出所料，这种类型的网络被称为*分类器*。
- en: To do so, the neural network will have one output for each label (for example,
    on the 10 digits MNIST dataset, we have 10 labels and so 10 outputs) and only
    one output should be 1, while all the other outputs should be 0.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，神经网络将为每个标签有一个输出（例如，在10个数字的MNIST数据集上，我们有10个标签和10个输出），而只有一个输出应该是1，其他所有输出应该是0。
- en: How will a neural network achieve this state? Well, it doesn't. The neural network
    produces floating point outputs as a result of the internal multiplications and
    sums, and very seldom you get a similar output. However, we can consider the highest
    value as the hot one (1), and all the others can be considered cold (0).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络如何达到这种状态呢？其实，它并不能。神经网络通过内部乘法和求和产生浮点输出，而且很少能得到相似的输出。然而，我们可以将最大值视为热点（1），而所有其他值都可以视为冷点（0）。
- en: We usually apply a softmax layer at the end of the neural network, which converts
    the outputs in to probability, meaning that the sum of the output after softmax
    will be 1.0\. This is quite convenient, as we can easily know how confident the
    neural network is regarding the prediction. Keras offers a method in the model
    to get the probability, `predict()`, and one to get the label, `predict_classes()`.
    The label can easily be converted to the one-hot encoding format, if you need
    it, using `to_categorical()`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常在神经网络的末尾应用一个softmax层，它将输出转换为概率，这意味着softmax后的输出总和将是1.0。这非常方便，因为我们可以很容易地知道神经网络对预测的信心程度。Keras在模型中提供了一个获取概率的方法`predict()`，以及一个获取标签的方法`predict_classes()`。如果需要，可以使用`to_categorical()`将标签轻松转换为独热编码格式。
- en: If you need to go from one-hot encoding to a label, you can use the `argmax()`
    NumPy function.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要从独热编码转换到标签，可以使用NumPy的`argmax()`函数。
- en: Now we know what our task is, classifying images, but we need to be sure that
    our dataset is similar to what our network will need to detect when deployed in
    production.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了我们的任务是图像分类，但我们需要确保我们的数据集与我们的网络在生产部署时需要检测的内容相似。
- en: Creating a real-world dataset
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建真实世界的数据集
- en: 'When you collect your dataset, either by using your images or an other suitable
    dataset, you need to take care that the images reflect conditions that you might
    find in real life. For example, you should try to get *problematic images*, listed
    as follows, as you will most likely encounter these problems in production:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当你收集数据集时，无论是使用自己的图像还是其他合适的数据集，你需要确保图像反映了你可能在现实生活中遇到的条件。例如，你应该尝试获取以下列出的*问题图像*，因为你很可能在生产中遇到这些问题：
- en: Bad light (over-exposed and under-exposed)
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恶劣的光线（过曝和欠曝）
- en: Strong shadows
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强烈的阴影
- en: Obstacles obstructing the object
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 障碍物遮挡物体
- en: Object partially out of the picture
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物体部分出图
- en: Object rotated
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物体旋转
- en: If you cannot easily obtain these types of images, you can use data augmentation,
    which is what our next section is about.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不能轻松地获得这些类型的图像，可以使用数据增强，这正是我们下一节要讨论的内容。
- en: Data augmentation
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据增强
- en: Data augmentation is the process of increasing the samples in your dataset,
    and deriving new pictures from the one that you already have; for example, reducing
    the brightness or rotating them.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强是增加你数据集中样本的过程，并从你已有的图像中派生新的图像；例如，降低亮度或旋转它们。
- en: Keras includes a convenient way to augment your dataset, `ImageDataGenerator()`,
    which randomly applies the specified transformations, but unfortunately is not
    particularly well documented and it lacks some coherence in terms of the parameters.
    Therefore, we will now analyze some of the most useful transformations. For clarity,
    we will build a generator with only one parameter, to see the effect, but you
    will most likely want to use more than one at the same time, which we will do
    later.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Keras包括一个方便的方式来增强你的数据集，`ImageDataGenerator()`，它可以随机应用指定的转换，但不幸的是，它的文档并不特别完善，并且在参数方面缺乏一致性。因此，我们现在将分析一些最有用的转换。为了清晰起见，我们将构建一个只有一个参数的生成器，以观察其效果，但你很可能希望同时使用多个参数，我们将在稍后这样做。
- en: 'The `ImageDataGenerator()` constructor accepts many parameters, such as the
    following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`ImageDataGenerator()` 构造函数接受许多参数，例如以下这些：'
- en: '`brightness_range`: This will change the brightness of the image and it accepts
    a list of two arguments, the minimum and the maximum brightness, for example,
    [0.1, 1.5].'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`brightness_range`：这将改变图像的亮度，它接受两个参数的列表，分别是最小和最大亮度，例如 [0.1, 1.5]。'
- en: '`rotation_range`: This will rotate the image and accept a single parameter
    that represents the range of rotation in degrees, for example, 60.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rotation_range`：这将旋转图像，并接受一个表示旋转范围的度数参数，例如 60。'
- en: '`width_shift_range`: This will shift the image horizontally; it accepts the
    parameter in different forms. I would recommend using the list of acceptable values,
    such as [-50, -25, 25, 50].'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`width_shift_range`：这将使图像水平移动；它接受不同形式的参数。我建议使用可接受值的列表，例如 [-50, -25, 25, 50]。'
- en: '`height_shift_range`: This will shift the image vertically; it accepts the
    parameter in different forms. I would recommend using the list of acceptable values,
    such as [-50, -25, 25, 50].'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`height_shift_range`：这将使图像垂直移动；它接受不同形式的参数。我建议使用可接受值的列表，例如 [-50, -25, 25, 50]。'
- en: '`shear_range`: This is the shear intensity, accepting a number in degrees,
    such as 60.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shear_range`：这是剪切强度，接受以度为单位的一个数字，例如 60。'
- en: '`zoom_range`: This zooms in or zooms out of the image and it accepts a list
    of two arguments, the minimum and the maximum zoom, such as [0.5, 2].'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zoom_range`：这将放大或缩小图像，它接受两个参数的列表，分别是最小和最大缩放，例如 [0.5, 2]。'
- en: '`horizontal_flip`: This flips the image horizontally, and the parameter is
    a Boolean.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`horizontal_flip`：这将水平翻转图像，参数是一个布尔值。'
- en: '`vertical_flip`: This flips the image vertically, and the parameter is a Boolean.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vertical_flip`：这将垂直翻转图像，参数是一个布尔值。'
- en: Of these, the horizontal flip is usually quite effective.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，水平翻转通常非常有效。
- en: 'The following figure shows the result of augmenting the images with brightness,
    rotation, width shift, and height shift:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了使用亮度、旋转、宽度移动和高度移动增强图像的结果：
- en: '![Figure 5.1 – ImageDataGenerator() results. From the top: brightness_range=[0.1,
    1.5], rotation_range=60, width_shift_range=[-50, -25, 25, 50], and height_shift_range=[-75,
    -35, 35, 75]](img/Figure_5.1_B16322.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.1 – ImageDataGenerator() 结果。从上到下：brightness_range=[0.1, 1.5], rotation_range=60,
    width_shift_range=[-50, -25, 25, 50], 和 height_shift_range=[-75, -35, 35, 75]](img/Figure_5.1_B16322.jpg)'
- en: 'Figure 5.1 – ImageDataGenerator() results. From the top: brightness_range=[0.1,
    1.5], rotation_range=60, width_shift_range=[-50, -25, 25, 50], and height_shift_range=[-75,
    -35, 35, 75]'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – ImageDataGenerator() 结果。从上到下：brightness_range=[0.1, 1.5], rotation_range=60,
    width_shift_range=[-50, -25, 25, 50], 和 height_shift_range=[-75, -35, 35, 75]
- en: 'The following images are generated using shearing, zoom, horizontal flip, and
    vertical flip:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 下图是使用剪切、缩放、水平翻转和垂直翻转生成的图像：
- en: '![Figure 5.2 – ImageDataGenerator() results. From the top: shear_range=60,
    zoom_range=[0.5, 2], horizontal_flip=True, and vertical_flip=True](img/Figure_5.2_B16322.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2 – ImageDataGenerator() 结果。从上到下：shear_range=60, zoom_range=[0.5, 2],
    horizontal_flip=True, 和 vertical_flip=True](img/Figure_5.2_B16322.jpg)'
- en: 'Figure 5.2 – ImageDataGenerator() results. From the top: shear_range=60, zoom_range=[0.5,
    2], horizontal_flip=True, and vertical_flip=True'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – ImageDataGenerator() 结果。从上到下：shear_range=60, zoom_range=[0.5, 2], horizontal_flip=True,
    和 vertical_flip=True
- en: 'The effects are usually combined, as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这些效果通常会组合使用，如下所示：
- en: '[PRE1]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And this is the final result:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最终结果：
- en: '![Figure 5.3 – ImageDataGenerator() results. Parameters applied: brightness_range=[0.1,
    1.5], rotation_range=60, width_shift_range=[-50, -25, 25, 50], and horizontal_flip=True](img/Figure_5.3_B16322.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.3 – ImageDataGenerator() 结果。应用参数：brightness_range=[0.1, 1.5], rotation_range=60,
    width_shift_range=[-50, -25, 25, 50], 和 horizontal_flip=True](img/Figure_5.3_B16322.jpg)'
- en: 'Figure 5.3 – ImageDataGenerator() results. Parameters applied: brightness_range=[0.1,
    1.5], rotation_range=60, width_shift_range=[-50, -25, 25, 50], and horizontal_flip=True'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 – ImageDataGenerator() 结果。应用参数：brightness_range=[0.1, 1.5], rotation_range=60,
    width_shift_range=[-50, -25, 25, 50], 和 horizontal_flip=True
- en: Intuitively, the network should become much more tolerant to variations in the
    image, and it should learn to generalize better.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，网络应该对图像的变化更加宽容，并且应该学会更好地泛化。
- en: Please keep in mind that the data augmentation of Keras is more like a data
    substitution, as it replaces the original images, meaning that the original, unchanged
    images are not sent to the neural network, unless the random combination is as
    such that they are presented unchanged.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，Keras的数据增强更像是数据替换，因为它替换了原始图像，这意味着原始的、未更改的图像不会被发送到神经网络，除非随机组合是这样的，它们以未更改的形式呈现。
- en: The great effect of data augmentation is that the samples will change at every
    epoch. So, to be clear, data augmentation in Keras does not increase the number
    of samples per epoch, but the samples will change every epoch, according to the
    specified transformation. You might want to train more epochs.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强的巨大效果是样本会在每个周期改变。所以，为了清楚起见，Keras中的数据增强不会在每个周期增加样本数量，但样本会根据指定的转换在每个周期改变。你可能想训练更多的周期。
- en: Next, we will see how to build the model.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看到如何构建模型。
- en: The model
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型
- en: Now that you have a dataset of images and you know what you want to do (for
    instance, a classification), it's time to build your model!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有一个图像数据集，你知道你想做什么（例如，分类），是时候构建你的模型了！
- en: We assume that you are working on a *convolutional neural network*, so you might
    even just use convolutional blocks, *MaxPooling*, and *dense layers*. But how
    to size them? How many layers should be used?
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设你正在工作于一个**卷积神经网络**，所以你可能甚至只需要使用卷积块、**MaxPooling**和**密集层**。但如何确定它们的大小？应该使用多少层？
- en: Let's do some tests with CIFAR-10, as MINST is too easy, and see what happens.
    We will not change the other parameters, but just play with these layers a bit.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用CIFAR-10做一些测试，因为MINST太简单了，看看会发生什么。我们不会改变其他参数，但只是稍微玩一下这些层。
- en: We will also train for 5 epochs, so as to speed up training. This is not about
    getting the best neural network; it is about measuring the impact of some parameters.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将训练5个周期，以加快训练速度。这并不是为了得到最好的神经网络；这是为了衡量一些参数的影响。
- en: 'Our starting point is a network with one convolutional layer, one MaxPooling
    layer, and one dense layer, shown as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的起点是一个包含一个卷积层、一个MaxPooling层和一个密集层的网络，如下所示：
- en: '[PRE2]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following is a summary of this:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对此的总结：
- en: '[PRE3]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can see that this is such a simple network, and it already has 463 K parameters.
    The number of layers is misleading. You don't necessarily need many layers to
    get a slow network.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到这是一个如此简单的网络，它已经有了463 K个参数。层数的数量是误导性的。你并不一定需要很多层来得到一个慢速的网络。
- en: 'This is the performance:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这是性能：
- en: '[PRE4]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now, the next step is to tune it. So, let's try that.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，下一步是调整它。所以，让我们试试吧。
- en: Tuning convolutional layers
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整卷积层
- en: 'Let''s use 32 channels in the convolutional layer:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在卷积层中使用32个通道：
- en: '[PRE5]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Not bad! The accuracy increased, and despite being 4 times bigger than before,
    it is less than 50% slower.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 还不错！准确率提高了，尽管比之前大4倍，但它的速度慢了不到50%。
- en: 'Let''s now try to stack 4 layers instead:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试堆叠4层：
- en: '[PRE6]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s check the size of the network, using `model.summary()` as usual:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用`model.summary()`检查网络的大小，就像通常那样：
- en: '[PRE7]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It''s just slightly bigger than the initial model! The reason is that most
    of the parameters are present due to the dense layer, and stacking convolutional
    layers of the same size does not change the parameters required by the dense layer.
    And this is the result:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 它只是比初始模型稍微大一点！原因是由于密集层，大多数参数都存在，并且堆叠相同大小的卷积层并不会改变密集层所需的参数。这就是结果：
- en: '[PRE8]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It is very similar – a bit faster and the accuracy is basically the same. The
    network can now learn more complex functions because it has multiple layers. However,
    it has a much smaller dense layer, so it loses some accuracy because of that.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 它非常相似——稍微快一点，准确率基本上相同。由于网络有多个层，它可以学习更复杂的函数。然而，它有一个更小的密集层，因此由于这个原因，它失去了一些准确率。
- en: 'Instead of using the *same* padding, let''s try to use `valid`, which will
    reduce the size of the output of the convolutional layer every time:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不使用**相同的**填充，而是尝试使用`valid`，这将每次减少卷积层的输出大小：
- en: '[PRE9]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The number of parameters decreased significantly, from 465,602:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 参数数量显著减少，从465,602：
- en: '[PRE10]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We are now using fewer than 300 K parameters, shown as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用不到300 K个参数，如下所示：
- en: '[PRE11]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Very interestingly, the training accuracy dropped 7%, as the network is too
    small for this task. However, the validation accuracy only went down 2%.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 非常有趣的是，训练准确率下降了7%，因为网络对于这个任务来说太小了。然而，验证准确率只下降了2%。
- en: 'Let''s now use the initial model, but with the same padding, as that would
    give us a slightly bigger image to work with after the convolution:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用初始模型，但使用相同的填充，因为这会给我们在卷积后处理一个稍微大一点的图像：
- en: '[PRE12]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We now have more parameters, and this is the performance:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有更多的参数，这是性能：
- en: '[PRE13]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Compared to the reference model, both accuracies improved, and the time is almost
    unchanged, so this was a positive experiment.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 与参考模型相比，准确度都有所提高，而时间几乎保持不变，因此这是一个积极的实验。
- en: 'Let''s now increase the size of the kernel to 7x7:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将核的大小增加到7x7：
- en: '[PRE14]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There is a negligible increase in the number of parameters, as the kernels
    are now bigger. But how does it perform? Let''s check:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 由于核现在更大，参数的数量增加是可以忽略不计的。但是它的表现如何？让我们检查一下：
- en: '[PRE15]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Not well. It is slightly slower and slightly less accurate. It is difficult
    to know why; maybe it's because the input image is too small.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 不太理想。它稍微慢一些，准确度也稍微低一些。很难知道原因；也许是因为输入图像太小。
- en: We know that it is a typical pattern to add a MaxPooling layer after a convolutional
    layer, so let's see how we can tune it.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道在卷积层之后添加MaxPooling层是一个典型的模式，所以让我们看看我们如何调整它。
- en: Tuning MaxPooling
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整MaxPooling
- en: 'Let''s go back to the previous model and let''s just drop `MaxPooling`:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到之前的模型，并且只去掉`MaxPooling`：
- en: '[PRE16]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Removing `MaxPooling` means that the dense layer is now 4 times as big, since
    the resolution of the convolutional layer is no longer reduced:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 移除`MaxPooling`意味着密集层现在大了4倍，因为卷积层的分辨率不再降低：
- en: '[PRE17]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This does not seem very efficient. Compared to the original network, it is slower,
    the accuracy improved, but the validation accuracy decreased. Compared to the
    networks with four convolutional layers, it has the same speed, but a far inferior
    validation accuracy.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来并不太高效。与原始网络相比，它更慢，准确度有所提高，但验证准确度却下降了。与具有四个卷积层的网络相比，它具有相同的速度，但验证准确度却远远低于后者。
- en: It seems that `MaxPooling` improves generalization while reducing computations.
    Not surprisingly, it is widely used.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来MaxPooling在减少计算的同时提高了泛化能力。毫不奇怪，它被广泛使用。
- en: 'Let''s now increase the number of MaxPooling layers:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们增加MaxPooling层的数量：
- en: '[PRE18]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The size is now much smaller because the second convolutional layers are now
    one fourth of the size:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 由于第二卷积层现在是原来大小的四分之一，因此大小现在要小得多：
- en: '[PRE19]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Let''s check the performance:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下性能：
- en: '[PRE20]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: While the training accuracy is not great, the validation accuracy is the best
    that we achieved, and all while using only 100 K parameters!
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然训练准确度并不高，但验证准确度是我们所达到的最佳水平，而且所有这些只使用了100 K个参数！
- en: After tuning the convolutional part of the network, is time to see how we can
    tune the part composed by dense layers.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在调整网络的卷积部分之后，现在是时候看看我们如何调整由密集层组成的部分。
- en: Tuning the dense layer
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整密集层
- en: 'Let''s go back to the initial model, and increase the dense layer 4 times,
    which is to 1,024 neurons:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到初始模型，并将密集层增加到4倍，即1,024个神经元：
- en: '[PRE21]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As expected, the number of parameters increased almost four fold. But what about
    performance?
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，参数的数量几乎增加了四倍。但是性能如何？
- en: '[PRE22]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The training accuracy is not bad, but the validation accuracy is lower compared
    with the best models.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 训练准确度还不错，但与最佳模型相比，验证准确度较低。
- en: 'Let''s try to use three dense layers:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用三个密集层：
- en: '[PRE23]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now we get the following parameters:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们得到了以下参数：
- en: '[PRE24]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The number of parameters is now lower:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 参数的数量现在更少了：
- en: '[PRE25]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The result is maybe somehow disappointing. We should probably not count too
    much on increasing the number of dense layers.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可能有些令人失望。我们可能不应该过多地依赖增加密集层的数量。
- en: The next step now is to train the network. Let's begin.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步现在是要训练网络。让我们开始。
- en: Training the network
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练网络
- en: We are now ready to discuss the training phase in greater depth, which is where
    the *magic happens*. We will not even attempt to describe the mathematical concepts
    behind it. We will just discuss in very generic and simplified terms the algorithm
    that is used to train neural networks.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以更深入地讨论训练阶段，这是“魔法”发生的地方。我们甚至不会尝试描述其背后的数学概念。我们只会用非常通用和简化的术语讨论用于训练神经网络的算法。
- en: 'We need some definitions:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一些定义：
- en: '**Loss function** or **cost function**: A function that computes how far the
    prediction of the neural network is from the expected label; it could be the **MSE**
    (which is the **mean squared error**) or something more elaborate.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**损失函数**或**代价函数**：一个计算神经网络预测与预期标签之间距离的函数；它可能是**MSE**（即**均方误差**）或更复杂的某种函数。'
- en: '**Derivative**: The derivative of a function is a new function that can measure
    how much a function is changing (and in which direction) in a specific point.
    For example, if you imagine being in a car, the speed can be your initial function,
    and its derivative is the acceleration. If the speed is constant, the derivative
    (for example, the acceleration) is zero; if the speed is increasing, the derivative
    will be positive and if the speed is decreasing, the derivative will be negative.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**导数**：函数的导数是一个新函数，可以测量函数在特定点上的变化程度（以及变化方向）。例如，如果你想象自己在一辆车上，速度可以是你的初始函数，其导数是加速度。如果速度是恒定的，导数（例如，加速度）为零；如果速度在增加，导数将是正的，如果速度在减少，导数将是负的。'
- en: '**Local minimum**: The job of a neural network is to minimize the loss function.
    Given the incredible number of parameters, the function of the neural network
    can be very complex and therefore reaching a global minimum can be impossible,
    but the network could still reach a good local minimum.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局部最小值**：神经网络的工作是使损失函数最小化。考虑到参数数量巨大，神经网络的函数可以非常复杂，因此达到全局最小值可能是不可能的，但网络仍然可以达到一个很好的局部最小值。'
- en: '**Convergence**: If the network keeps approaching a good local minimum, then
    it is converging.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收敛**：如果网络持续接近一个好的局部最小值，那么它就是在收敛。'
- en: Using these definitions, we will now see how the training actually works.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些定义，我们现在将看到训练实际上是如何进行的。
- en: How to train the network
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何训练网络
- en: 'The algorithm is composed of two parts, and, to simplify, let''s say that it
    is performed for every sample and, of course, the whole thing is repeated for
    every epoch. So, let''s see how it works:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 算法由两部分组成，为了简化，让我们说它是为每个样本执行的，当然，整个过程在每个epoch都会重复。所以，让我们看看它是如何工作的：
- en: '**Forward pass**: At the end of the day, your neural network is just a function
    with many parameters (weights and possibly biases) and many operations that, when
    provided with an input, can compute some outputs. In the forward pass, we compute
    the prediction and the loss.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前向传播**：最终，你的神经网络只是一个具有许多参数（权重和可能的偏差）以及许多操作的函数，当提供输入时，可以计算一些输出。在前向传播中，我们计算预测和损失。'
- en: '**Backward pass**: The optimizer (for example, Adam or stochastic gradient
    descent) goes *backward* (from the last layer to the first layer) updating all
    the weights (for instance, all the parameters) trying to minimize the loss function;
    the *learning rate* (a number between 0 and 1.0, typically worth 0.01 or less)
    determines how much the weights will be adjusted.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反向传播**：优化器（例如，Adam或随机梯度下降）向**后**（从最后一层到第一层）更新所有权重（例如，所有参数），试图最小化损失函数；**学习率**（一个介于0和1.0之间的数字，通常为0.01或更小）决定了权重将调整多少。'
- en: A bigger learning rate makes them train faster, but it might skip local minimums,
    while a smaller learning rate might converge, but taking too much time. Optimizers
    are actively researched to improve training speed as much as possible, and they
    are dynamically changing the learning rate to improve speed and precision.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 更大的学习率可以使它们训练得更快，但可能会跳过局部最小值，而较小的学习率可能会收敛，但花费太多时间。优化器正在积极研究，以尽可能提高训练速度，并且它们会动态地改变学习率来提高速度和精度。
- en: 'Adam is an example of an optimizer that can dynamically change the learning
    rate for each parameter:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Adam是一个可以动态改变每个参数学习率的优化器示例：
- en: '![Figure 5.4 – Gradient descent looking for a minimum](img/Figure_5.4_B16322.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![图5.4 – 梯度下降寻找最小值](img/Figure_5.4_B16322.jpg)'
- en: Figure 5.4 – Gradient descent looking for a minimum
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 – 梯度下降寻找最小值
- en: While writing an algorithm to train a neural network is very complex, the concept
    is, in a way, similar to somebody trying to learn to play pool, while repeating
    the same complex shoot until it works. You choose the point that you want to hit
    (label), you make your move (forward pass), you evaluate how far you ended up
    from the target, and then you retry adjusting the power, direction, and all the
    other variables at play (weights). We also have a way to do this with random initialization.
    Let's try this next.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然编写训练神经网络的算法非常复杂，但从某种意义上说，这个概念与某人试图学习打台球类似，直到重复相同的复杂射击直到成功。你选择你想要击中的点（标签），你做出你的动作（前向传播），你评估你离目标有多远，然后你尝试调整力量、方向以及所有其他变量（权重）。我们也有一种随机初始化的方法。让我们试试下一个。
- en: Random initialization
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机初始化
- en: You might wonder what the values of the parameters are the first time that you
    run the neural network. Initializing the weights to zero does not work well, while
    having small random numbers is quite effective. Keras has a variety of algorithms
    that you can choose from, and you can also change the standard deviation.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道第一次运行神经网络时参数的值。将权重初始化为零效果不佳，而使用小的随机数则相当有效。Keras 提供了多种算法供你选择，你也可以更改标准差。
- en: An interesting consequence of this is that the neural network starts with a
    considerable amount of random data, and you might notice that training the same
    model on the same dataset actually produces different results. Let's try with
    our previous basic CIFAR-10 CNN.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这个有趣的结果是，神经网络开始时带有相当数量的随机数据，你可能注意到在同一个数据集上用同一个模型训练实际上会产生不同的结果。让我们用我们之前的基本 CIFAR-10
    CNN 来尝试。
- en: 'The first attempt produces the following results:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次尝试产生了以下结果：
- en: '[PRE26]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The second attempt produces the following results:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次尝试产生了以下结果：
- en: '[PRE27]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You can try to reduce the randomness using the following code:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试使用以下代码来减少随机性：
- en: '[PRE28]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: However, if you train on a GPU, there could still be a number of variations.
    You should take this into consideration while you tune your network model, or
    you risk disqualifying small improvements due to randomness.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你在GPU上训练，仍然可能存在许多变化。在调整你的网络模型时，你应该考虑这一点，否则你可能会因为随机性而排除小的改进。
- en: The next stage is to see what overfitting and underfitting are.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个阶段是了解过拟合和欠拟合是什么。
- en: Overfitting and underfitting
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过拟合和欠拟合
- en: 'While training a neural network, you will fight between **underfitting** and
    **overfitting**. Let''s see how:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练神经网络时，你将在**欠拟合**和**过拟合**之间进行斗争。让我们看看如何：
- en: Underfitting is where the model is too simple, and it is not able to learn the
    dataset properly. You need to add parameters, filters, and neurons to increase
    the capacity of the model.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欠拟合是指模型过于简单，无法正确学习数据集。你需要添加参数、滤波器和神经元来增加模型的容量。
- en: Overfitting is where your model is big enough to learn the training dataset,
    but it is not able to generalize (for example, it *memorizes* the dataset but
    it is not good when you provide other data).
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过拟合是指你的模型足够大，可以学习训练数据集，但它无法泛化（例如，它*记忆*了数据集，但当你提供其他数据时效果不佳）。
- en: 'You can also see it from the plot over time of accuracy and loss:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以从准确率和损失随时间变化的图中看到：
- en: '![Figure 5.5 – Underfitting: the model is too small (7,590 parameters) and
    is not learning much](img/Figure_5.5_B16322.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图5.5 – 欠拟合：模型太小（7,590个参数）且没有学习到很多](img/Figure_5.5_B16322.jpg)'
- en: 'Figure 5.5 – Underfitting: the model is too small (7,590 parameters) and is
    not learning much'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 – 欠拟合：模型太小（7,590个参数）且没有学习到很多
- en: 'The preceding graph shows an extreme underfitting, and the accuracies stay
    very low. Now refer to the following graph:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表显示了一个极端的欠拟合，准确率保持非常低。现在参考以下图表：
- en: '![Figure 5.6 – Overfitting: the model is very big (29,766,666 parameters) and
    is not generalizing well](img/Figure_5.6_B16322.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![图5.6 – 过拟合：模型非常大（29,766,666个参数）且没有很好地泛化](img/Figure_5.6_B16322.jpg)'
- en: 'Figure 5.6 – Overfitting: the model is very big (29,766,666 parameters) and
    is not generalizing well'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 – 过拟合：模型非常大（29,766,666个参数）且没有很好地泛化
- en: '*Figure 5.6* shows a somewhat extreme example of a neural network in overfitting.
    You may notice that while the training loss keeps decreasing with the epochs,
    the validation loss reaches a minimum at epoch one, and then keeps increasing.
    The minimum of the validation loss is where you want to stop your training. In
    [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142), *Improving Your
    Neural Network*, we will see a technique that allows us to do more or less that—*early
    stopping*.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5.6* 展示了一个神经网络过拟合的相对极端例子。你可能注意到，虽然训练损失随着epoch的增加而持续下降，但验证损失在第一个epoch达到最小值，然后持续增加。验证损失的最小值是你想要停止训练的地方。在[*第6章*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142)，“改进你的神经网络”中，我们将看到一个允许我们做到这一点或类似的技术——*提前停止*。'
- en: While you might hear that overfitting is a big problem, actually it could be
    a good strategy first trying to get a model that can overfit the training dataset,
    and then apply techniques that can reduce the overfitting and improve generalization.
    However, this is good only if you can overfit the training dataset with a very
    high degree of accuracy.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可能听说过过拟合是一个大问题，但实际上，首先尝试得到一个可以过拟合训练数据集的模型，然后应用可以减少过拟合并提高泛化能力的技术的策略可能是一个好方法。然而，这只有在你能以非常高的精度过拟合训练数据集的情况下才是好的。
- en: We will see very effective ways to reduce overfitting in [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142),
    *Improving Your Neural Network*, but one thing to consider is that a smaller model
    is less prone to overfit, and it is usually also faster. So, while you are trying
    to overfit the training dataset, try not to use a model that is extremely big.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第6章*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142)“改进你的神经网络”中看到非常有效的方法来减少过拟合，但有一点需要考虑的是，较小的模型不太容易过拟合，而且通常也更快。所以，当你试图过拟合训练数据集时，尽量不要使用一个非常大的模型。
- en: In this section, we have seen how to use the graph of the losses to understand
    where we are in the training of our network. In the next section, we will see
    how to visualize the activations in order to get an idea of what our network is
    learning.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了如何使用损失图来了解我们在网络训练中的位置。在下一节中，我们将看到如何可视化激活，以了解我们的网络正在学习什么。
- en: Visualizing the activations
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化激活
- en: 'Now we can train a neural network. Great. But what exactly is the neural network
    able to see and understand? That''s a difficult question to answer, but as convolutions
    output an image, we could try to show this. Let''s now try to show the activation
    for the first 10 images of the MINST test dataset:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以训练一个神经网络。太好了。但神经网络能看懂和理解什么？这是一个很难回答的问题，但既然卷积输出一个图像，我们可以尝试展示这一点。现在让我们尝试展示MINST测试数据集前10个图像的激活：
- en: 'First, we need to build a model, derived from our previous model, that reads
    from the input and gets as output the convolutional layer that we want. The name
    can be taken from the summary. We will visualize the first convolutional layer,
    `conv2d_1`:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要构建一个模型，这个模型是从我们之前的模型派生出来的，它从输入读取并得到我们想要的卷积层作为输出。名称可以来自摘要。我们将可视化第一个卷积层，`conv2d_1`：
- en: '[PRE29]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, for each test image, we can take all the activations and chain them together
    to get an image:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，对于每个测试图像，我们可以取所有激活并将它们连接起来以得到一个图像：
- en: '[PRE30]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'And then we can show it:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们可以展示它：
- en: '[PRE31]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This is the result for the first convolutional layer, `conv2d_1`, which has
    6 channels, 28x28:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第一卷积层`conv2d_1`的结果，它有6个通道，28x28：
- en: '![Figure 5.7 – MNIST, activations of the first convolutional layer](img/Figure_5.7_B16322.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![图5.7 – MNIST，第一卷积层的激活](img/Figure_5.7_B16322.jpg)'
- en: Figure 5.7 – MNIST, activations of the first convolutional layer
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 – MNIST，第一卷积层的激活
- en: This looks interesting, but trying to understand the activations, and what the
    channels learned to recognize, always involves some guesswork. The last channel
    seems to focus on horizontal lines, and the third and fourth channels are not
    very strong, which might mean that the network is not properly trained or it is
    already bigger than required. But it looks good.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来很有趣，但试图理解激活，以及通道学习识别的内容，总是涉及一些猜测工作。最后一个通道似乎专注于水平线，第三和第四个通道不是很强，这可能意味着网络没有正确训练，或者它已经比所需的要大。但看起来不错。
- en: 'Let''s now check the second layer, `conv2d_2`, which has 16 channels, 10x10:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在检查第二层，`conv2d_2`，它有16个通道，10x10：
- en: '![Figure 5.8 – MNIST, activations of the second convolutional layer](img/Figure_5.8_B16322.jpg)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![图5.8 – MNIST，第二卷积层的激活](img/Figure_5.8_B16322.jpg)'
- en: Figure 5.8 – MNIST, activations of the second convolutional layer
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 – MNIST，第二卷积层的激活
- en: 'Now it''s more complex – the outputs are much smaller, and we have more channels.
    It seems that some channels are detecting horizontal lines, and some of them are
    focusing on diagonal or vertical lines. And what about the first MaxPooling layer,
    `max_pooling2d_1`? It''s a lower resolution than the original channel, at 10x10,
    but as it selects the maximum activation, it should be understandable. Refer to
    the following screenshot:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 现在更复杂了——输出要小得多，我们有的通道也更多。看起来有些通道正在检测水平线，而有些则专注于对角线或垂直线。那么第一个最大池化层，`max_pooling2d_1`呢？它的分辨率低于原始通道，为10x10，但它选择最大激活，应该是可以理解的。参考以下截图：
- en: '![Figure 5.9 – MNIST, activations of the first MaxPooling layer](img/Figure_5.9_B16322.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.9 – MNIST，第一个最大池化层的激活状态](img/Figure_5.9_B16322.jpg)'
- en: Figure 5.9 – MNIST, activations of the first MaxPooling layer
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 – MNIST，第一个最大池化层的激活状态
- en: 'Indeed, the activation looks good. Just for fun, let''s check the second MaxPooling
    layer, `max_pooling2d_2`, which is only 5x5:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，激活状态看起来很好。为了好玩，让我们检查第二个最大池化层，`max_pooling2d_2`，它的大小是 5x5：
- en: '![Figure 5.10 – MNIST, activations of the second MaxPooling layer](img/Figure_5.10_B16322.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.10 – MNIST，第二个最大池化层的激活状态](img/Figure_5.10_B16322.jpg)'
- en: Figure 5.10 – MNIST, activations of the second MaxPooling layer
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – MNIST，第二个最大池化层的激活状态
- en: Now it looks chaotic, but it still looks like some channels are recognizing
    horizontal lines and some are focusing on vertical ones. Here is when the dense
    layers will come into play, as they try to make sense of these activations that
    are difficult to understand but not at all random.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 现在看起来很混乱，但仍然可以看出一些通道正在识别水平线，而另一些则专注于垂直线。这就是密集层发挥作用的时候，因为它们试图理解这些难以理解但并非完全随机的激活状态。
- en: Visualizing the activation is useful to get an idea of what the neural network
    is learning, and how the channels are used, and it is another tool that you can
    use while training your neural network, above all when you feel that it is not
    learning well and you are looking for problems.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化激活状态对于了解神经网络正在学习什么、通道是如何被使用的非常有用，并且它是你在训练神经网络时可以使用的另一个工具，尤其是当你觉得它学习得不好，正在寻找问题时。
- en: Now we will talk about inference, which is actually the whole point of training
    a neural network.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将讨论推理，这实际上是训练神经网络的全部目的。
- en: Inference
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推理
- en: Inference is the process of giving an input to your network and getting a classification
    or prediction. When the neural network has been trained and deployed in production,
    we use it, for example, to classify images or to decide how to drive in a road,
    and this process is called inference.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 推理是将输入提供给你的网络并得到分类或预测的过程。当神经网络经过训练并部署到生产环境中时，我们使用它，例如，来分类图像或决定如何在道路上驾驶，这个过程称为推理。
- en: 'The first step is to load the model:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是加载模型：
- en: '[PRE32]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Then you simply call `predict()`, which is the method for inference in Keras.
    Let''s try with the first test sample of MNIST:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你只需调用 `predict()`，这是 Keras 中的推理方法。让我们用 MNIST 的第一个测试样本来试一试：
- en: '[PRE33]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This is the result for my MNIST network:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我的 MNIST 网络的结果：
- en: '[PRE34]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The result of `predict()` is an array of probabilities, which is very handy
    for evaluating the confidence of the network. In this case, all the numbers are
    very close to zero, except for the number `7`, which is therefore the prediction
    of the network, with a confidence above 99.999%! In real life, unfortunately,
    you seldom see a network working so well!
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict()` 函数的结果是一个概率数组，这对于评估网络的置信度非常方便。在这种情况下，所有数字都非常接近零，除了数字 `7`，因此它是网络的预测，置信度超过
    99.999%！在现实生活中，不幸的是，你很少看到网络工作得如此好！'
- en: After inference, sometimes you want to periodically retrain on new samples,
    to improve the network. Let's see what this entails next.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理之后，有时你可能想要定期在新样本上重新训练，以改进网络。让我们看看这需要做什么。
- en: Retraining
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新训练
- en: Sometimes, once you get a neural network that performs well, you job is done.
    Sometimes, however, you might want to retrain it on new samples, to get better
    precision (as your dataset is now bigger) or to get fresher results if your training
    dataset becomes obsolete relatively quickly.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，一旦你得到了一个表现良好的神经网络，你的工作就完成了。然而，有时候你可能想要在新样本上重新训练它，以获得更高的精度（因为你的数据集现在更大了），或者如果你的训练数据集变得相对快速过时，以获得更新的结果。
- en: In some cases, you might even want to retrain continuously, for example, every
    week, and have the new model automatically deployed in production.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，你可能甚至想要持续不断地重新训练，例如每周一次，并将新模型自动部署到生产环境中。
- en: In this case, it's critical that you have a strong procedure in place to verify
    the performance of your new model in the validation dataset and, hopefully, in
    a new, throwaway test dataset. It may also be advisable to keep a backup of all
    the models and try to find a way to monitor the performance in production, to
    quickly identify anomalies. In the case of a self-driving car, I expect a model
    to undergo rigorous automated and manual testing before being deployed in production,
    but other industries that don't have safety concerns might be much less strict.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你有一个强大的程序来验证你在验证数据集上新的模型性能，以及在新的、可丢弃的测试数据集上性能是至关重要的。也许还建议保留所有模型的备份，并尝试找到一种方法来监控生产中的性能，以便快速识别异常。在自动驾驶汽车的情况下，我预计模型在投入生产之前将经历严格的自动和手动测试，但其他没有安全问题的行业可能要宽松得多。
- en: With this, we conclude our topic on retraining.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们结束了关于重新训练的主题。
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This has been a dense chapter, but hopefully you got a better overview of what
    neural networks are and how to train them.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一章内容密集的章节，但希望你能更好地了解神经网络是什么以及如何训练它们。
- en: We talked a lot about the dataset, including how to get correct datasets for
    training, validation, and testing. We described what a classifier is and we implemented
    data augmentation. Then we discussed the model and how to tune the convolutional
    layers, the MaxPooling layers, and the dense layers. We saw how training is done,
    what backpropagation is, discussed the role of randomness on the initialization
    of the weights, and we saw graphs of underfitting and overfitting networks. To
    understand how well our CNN is doing, we went as far as visualizing the activations.
    Then we discussed inference and retraining.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了很多关于数据集的内容，包括如何获取用于训练、验证和测试的正确数据集。我们描述了分类器是什么，并实现了数据增强。然后我们讨论了模型以及如何调整卷积层、MaxPooling层和密集层。我们看到了训练是如何进行的，什么是反向传播，讨论了随机性在权重初始化中的作用，并展示了欠拟合和过度拟合网络的图表。为了了解我们的CNN表现如何，我们甚至可视化激活。然后我们讨论了推理和重新训练。
- en: This means that you now have sufficient knowledge to choose or create a dataset
    and train a neural network from scratch, and you will be able to understand if
    a change in the model or in the dataset improves precision.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你现在有足够的知识来选择或创建一个数据集，从头开始训练一个神经网络，并且你将能够理解模型或数据集的变化是否提高了精度。
- en: In [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142), *Improving
    Your Neural Network*, we will see how to apply all this knowledge in practice,
    so as to improve the precision of a neural network significantly.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第6章*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142) *提高你的神经网络*中，我们将看到如何将这些知识应用到实践中，以便显著提高神经网络的精度。
- en: Questions
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'After reading this chapter, you should be able to answer the following questions:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读这一章后，你应该能够回答以下问题：
- en: Can you reuse the test dataset?
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以重复使用测试数据集吗？
- en: What is data augmentation?
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据增强是什么？
- en: Does data augmentation in Keras add images to your dataset?
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Keras中的数据增强是否向你的数据集添加图像？
- en: Which layer tends to have the highest number of parameters?
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪一层倾向于具有最多的参数？
- en: Watching the plot of the losses, how can you tell that a network is overfitting?
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 观察损失曲线，你如何判断一个网络正在过度拟合？
- en: Is it always bad to have a network that overfits?
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络过度拟合是否总是不好的？
