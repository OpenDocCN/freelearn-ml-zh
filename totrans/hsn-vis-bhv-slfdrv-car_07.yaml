- en: '*Chapter 5*: Deep Learning Workflow'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will go through the steps that you might perform while training
    your neural network, and when putting it into production. We will discuss more
    about the theory behind deep learning, to explain better what we actually did
    in [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091), *Deep Learning
    with Neural Networks*, but we will stay mostly focused on arguments related to
    self-driving cars. We will also introduce some concepts that will help us to achieve
    better precision on CIFAR-10, a famous dataset of small images. We are sure that
    the theory exposed in this chapter, plus the more practical knowledge associated
    with [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091), *Deep Learning
    with Neural Networks*, and [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142),
    *Improving Your Neural Network*, will give you enough tools to be able to perform
    tasks that are common in the field of self-driving cars.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining or creating the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training, validation, and test datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifiers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data augmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to tune convolutional layers, `MaxPooling` layers, and dense layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training and the role of randomness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Underfitting and overfitting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualization of activations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running inference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retraining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to use the code explained in this chapter, you need to have the
    following tools and modules installed:'
  prefs: []
  type: TYPE_NORMAL
- en: Python 3.7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The NumPy module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Matplotlib module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The TensorFlow module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Keras module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The OpenCV-Python module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code for the chapter can be found at [https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter5](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter5).
  prefs: []
  type: TYPE_NORMAL
- en: 'The Code in Action videos for this chapter can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://bit.ly/3dJrcys](https://bit.ly/3dJrcys)'
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you have a task that you want to perform with a neural network, the first
    step is usually to obtain the dataset, which is the data that you need to feed
    to the neural network. In the tasks that we perform in this book, the dataset
    is usually composed of images or videos, but it could be anything, or a mix of
    images and other data.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset represents the input that you feed to your neural network, but as
    you may have noticed, your dataset also contains the desired output, the labels.
    We will call `x` the input to the neural network, and `y` the output. The dataset
    is composed of the inputs/features (for example, the images in the MNIST dataset),
    and the output/labels (for example, the number associated with each image).
  prefs: []
  type: TYPE_NORMAL
- en: We have different dataset types. Let's start with the easiest – the datasets
    included in Keras – before proceeding to the next ones.
  prefs: []
  type: TYPE_NORMAL
- en: Datasets in the Keras module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Usually a dataset is a lot of data. It's normal to train a neural network on
    tens of thousands of images, but the best neural networks are trained with many
    millions of images. So how do we use them?
  prefs: []
  type: TYPE_NORMAL
- en: 'The easiest way, which is usually mostly helpful for experiments, is to use
    the datasets included in Keras, as we did in [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091),
    *Deep Learning with Neural Networks*, using `load_data()`, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Keras provides a variety of datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: MNIST – the classification of digits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CIFAR10 – the classification of small images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CIFAR100 – the classification of small images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IMDB movie review sentiment classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reuters newswire classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fashion MNIST dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boston Housing prices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These datasets are useful in learning how to build neural networks in general.
    In the next section, we will look at some datasets that are more useful for self-driving
    cars.
  prefs: []
  type: TYPE_NORMAL
- en: Existing datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Luckily, there are several interesting public datasets available, but you have
    to always carefully check the license to see what you are allowed to do with it,
    and eventually get or acquire a more permissive license.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some datasets related to self-driving cars that you might
    want to check:'
  prefs: []
  type: TYPE_NORMAL
- en: BDD100K, a large-scale diverse driving video database; refer to [https://bdd-data.berkeley.edu/](https://bdd-data.berkeley.edu/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bosch small traffic lights database; refer to [https://hci.iwr.uni-heidelberg.de/content/bosch-small-traffic-lights-dataset](https://hci.iwr.uni-heidelberg.de/content/bosch-small-traffic-lights-dataset).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CULane, a large-scale dataset for academic research on traffic lane detection;
    refer to [https://xingangpan.github.io/projects/CULane.html](https://xingangpan.github.io/projects/CULane.html).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: KITTI Vision Benchmark Suite; refer to [http://www.cvlibs.net/datasets/kitti/](http://www.cvlibs.net/datasets/kitti/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapillary Traffic Sign Dataset; refer to [https://www.mapillary.com/dataset/trafficsign](https://www.mapillary.com/dataset/trafficsign).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, there are other more generic datasets that you might find interesting,
    in particular, ImageNet, [http://www.image-net.org/](http://www.image-net.org/),
    an image dataset organized according to the WordNet hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: This dataset contains millions of URLs pointing to images on the internet, and
    has been very influential in developing neural networks. We will talk more about
    this later.
  prefs: []
  type: TYPE_NORMAL
- en: Public datasets are great, but you might consider their content, as it is not
    uncommon to have some images incorrectly classified. This is not necessarily a
    big deal for your neural network, but you might still want to get a dataset as
    good as possible.
  prefs: []
  type: TYPE_NORMAL
- en: If you cannot find a satisfactory dataset, you can always generate one. Let's
    see how you can quickly build good datasets for self-driving car tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When possible, you might want to generate a dataset from a program that can
    create *good enough* images. We used this technique in [*Chapter 3*](B16322_03_Final_NM_ePUB.xhtml#_idTextAnchor066),
    *Lane Detection*, where we detected pedestrians from Carla, and images from the
    open source video game Speed Dreams, and you could write your own generator using
    a 3D engine or 3D modeling software.
  prefs: []
  type: TYPE_NORMAL
- en: These are a relatively easy, quick, and very cheap way to generate massive datasets,
    and, in fact, are sometimes invaluable, as in many cases you can automatically
    annotate the images and save a lot of time. However synthetic images tend to be
    less complex than real images, with the result that your network will probably
    not perform as well as you think in a real-world scenario. We will use this technique
    in [*Chapter 8*](B16322_08_Final_NM_ePUB.xhtml#_idTextAnchor182), *Behavioral
    Cloning*.
  prefs: []
  type: TYPE_NORMAL
- en: One of the best simulators available, if not the best, is Carla.
  prefs: []
  type: TYPE_NORMAL
- en: 'Carla, the open source simulator for autonomous driving research, uses the
    following websites:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://carla.org/](https://carla.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/carla-simulator/carla](https://github.com/carla-simulator/carla)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use it to generate the images that you need for your tasks.
  prefs: []
  type: TYPE_NORMAL
- en: When this is not enough, you have to follow a manual process.
  prefs: []
  type: TYPE_NORMAL
- en: Your custom dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, you may have no satisfactory alternative and you need to collect
    the images by yourself. This might require the collection of footage and the classification
    of thousands of images. If the images are extracted from a video, you might be
    able to just classify a video, and then extract hundreds or thousands of images
    from it.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes this is not the case, and you need to go through tens of thousands
    of images by yourself. Alternatively, you can use the services of specialized
    companies to label the images for you.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes you might have the images, but the classification might be difficult.
    Imagine having access to video footage of cars, and then having to annotate the
    images, adding the boxes where the cars are. If you are lucky, you might get access
    to a neural network that can do the job for you. You might still need to manually
    go through the result, and reclassify some images, but this can still save a lot
    of work.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will learn in depth about these datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the three datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In reality, you don't need one dataset, but ideally three. These are required
    for training, validation, and testing. Before defining them, please consider that
    unfortunately sometimes, there is some confusion regarding the meaning of validation
    and test, typically where only two datasets are available, as in this case, validation
    and test datasets coincide. We did the same in [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091),
    *Deep Learning with Neural Networks*, where we used the test dataset as validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now define these three datasets, and then we can explain how ideally
    we should have tested the MNIST dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Training dataset**: This is the dataset used to train the neural network,
    and it is typically the biggest of the three datasets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Validation dataset**: This is usually a hold-out part of the training dataset
    that is not used for training, but only to evaluate the performance of a model
    and tune its hyperparameters (for example, the topology of the network or the
    learning rate of the optimizer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test dataset**: Ideally this is a throw-away dataset used to evaluate the
    performance of the model once all the tuning is complete.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You cannot use the training dataset to evaluate the performance of a model because
    the training dataset is used by the optimizer to train the network, so this is
    the best case scenario. However, we usually don't need the neural network to perform
    well in the training dataset but in whatever the user will throw at it. So, we
    need the network to be able to *generalize*. Going back to the student metaphor
    from [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091), *Deep Learning
    with Neural Networks*, a high score in the training dataset means that the student
    learned the book (the training dataset) by heart, but what we want is the student
    to have understood the content of the book and be able to apply this knowledge
    to real-world situations (the validation dataset).
  prefs: []
  type: TYPE_NORMAL
- en: So, if validation represents the real world, why do we need the test dataset?
    The problem is that while tuning your network, you will make choices that will
    be biased toward the validation dataset (such as choosing one model instead of
    another one based on its performance in the validation dataset). As a result,
    the performance in the validation dataset might still be higher than in the real
    world.
  prefs: []
  type: TYPE_NORMAL
- en: The test dataset solves this problem as we only apply it after all the tuning.
    That also explains why ideally, we want to throw away the test dataset after using
    it only once.
  prefs: []
  type: TYPE_NORMAL
- en: This can be impractical, but not always, as sometimes you can easily generate
    some samples on demand.
  prefs: []
  type: TYPE_NORMAL
- en: So, how could we use three datasets in the MNIST task? Maybe you remember from
    [*Chapter 4*](B16322_04_Final_NM_ePUB.xhtml#_idTextAnchor091), *Deep Learning
    with Neural Networks*, that the MNIST dataset has 60,000 (60 K) samples for training
    and 10,000 (10 K) for testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ideally, you could use the following approach:'
  prefs: []
  type: TYPE_NORMAL
- en: The training dataset could use the full 60,000 samples intended for training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The validation dataset could use the 10,000 samples intended for testing (as
    we did).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The test dataset could be generated on demand, writing digits on the spot.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After discussing the three datasets, we can now see how to split your full dataset
    into three parts. While this seems an easy operation, you need to be careful in
    terms of how you go about it.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given your full dataset, you might need to split it into training, validation,
    and testing parts. As stated previously, ideally you want the test to be generated
    on the spot, but if this is not possible, you might choose to use 15-20% of the
    total dataset for testing.
  prefs: []
  type: TYPE_NORMAL
- en: Of the remaining dataset, you might use 15-20% as validation.
  prefs: []
  type: TYPE_NORMAL
- en: If you have many samples, you might use a smaller percentage for validation
    and testing. If you have a small dataset, after you are satisfied with your model
    performance (such as if you chose it because it performs well both on the validation
    and on the test dataset), you might add the test dataset to the training dataset
    to get more samples. If you do this, there is no point in evaluating the performance
    in the test dataset, as effectively, it will become part of the training. In this
    case, you trust the results in the validation dataset.
  prefs: []
  type: TYPE_NORMAL
- en: But even with the same size, not all splits are created equal. Let's take a
    practical example.
  prefs: []
  type: TYPE_NORMAL
- en: You want to detect cats and dogs. You have a dataset of 10,000 pictures. You
    decide to use 8 K for training, 2 K for validation, and testing is done via the
    real-time recording of a video of 1 dog and 1 cat that you have at home; every
    time you test, you make a new video. Looks perfect. What can possibly go wrong?
  prefs: []
  type: TYPE_NORMAL
- en: First, you need more or less an equal number of cats and dogs in each dataset.
    If that's not the case, the network will be biased toward one of them. Intuitively,
    if during training, the network sees that 90% of the images are of dogs, just
    predicting always a dog will give you 90% accuracy!
  prefs: []
  type: TYPE_NORMAL
- en: You read that it is a best practice to randomize the order of the samples and
    you do it. Then you split. Your model performs well in the training, validation,
    and test datasets. Everything looks good. Then you try with pets of a few friends,
    and nothing works. What happened?
  prefs: []
  type: TYPE_NORMAL
- en: One possibility is that your split is not good in terms of measuring generalization.
    Even if you have 10 K images, they might have been taken from 100 pets (including
    yours), and every dog and cat is present 100 times, in slightly different positions
    (for example, from a video). If you shuffle the samples, all the dogs and cats
    will be present in all the datasets, so validation and testing will be relatively
    easy, as the network *already knows* those pets.
  prefs: []
  type: TYPE_NORMAL
- en: If, instead, you keep 20 pets for validation, and take care to not include pictures
    of your pets in the training or validation dataset, then your estimation would
    be much more realistic, and you have a chance to build a neural network that is
    much better at generalizing.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have three datasets, it's time to define the task that we need to
    perform, which typically will be image classification.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding classifiers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning can be used for many different tasks. For what concerns images
    and CNN, a very common task is classification. Given an image, the neural network
    needs to classify it, using one of the labels provided during training. Not surprisingly,
    a network of this type is called a *classifier*.
  prefs: []
  type: TYPE_NORMAL
- en: To do so, the neural network will have one output for each label (for example,
    on the 10 digits MNIST dataset, we have 10 labels and so 10 outputs) and only
    one output should be 1, while all the other outputs should be 0.
  prefs: []
  type: TYPE_NORMAL
- en: How will a neural network achieve this state? Well, it doesn't. The neural network
    produces floating point outputs as a result of the internal multiplications and
    sums, and very seldom you get a similar output. However, we can consider the highest
    value as the hot one (1), and all the others can be considered cold (0).
  prefs: []
  type: TYPE_NORMAL
- en: We usually apply a softmax layer at the end of the neural network, which converts
    the outputs in to probability, meaning that the sum of the output after softmax
    will be 1.0\. This is quite convenient, as we can easily know how confident the
    neural network is regarding the prediction. Keras offers a method in the model
    to get the probability, `predict()`, and one to get the label, `predict_classes()`.
    The label can easily be converted to the one-hot encoding format, if you need
    it, using `to_categorical()`.
  prefs: []
  type: TYPE_NORMAL
- en: If you need to go from one-hot encoding to a label, you can use the `argmax()`
    NumPy function.
  prefs: []
  type: TYPE_NORMAL
- en: Now we know what our task is, classifying images, but we need to be sure that
    our dataset is similar to what our network will need to detect when deployed in
    production.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a real-world dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you collect your dataset, either by using your images or an other suitable
    dataset, you need to take care that the images reflect conditions that you might
    find in real life. For example, you should try to get *problematic images*, listed
    as follows, as you will most likely encounter these problems in production:'
  prefs: []
  type: TYPE_NORMAL
- en: Bad light (over-exposed and under-exposed)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strong shadows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obstacles obstructing the object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object partially out of the picture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object rotated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you cannot easily obtain these types of images, you can use data augmentation,
    which is what our next section is about.
  prefs: []
  type: TYPE_NORMAL
- en: Data augmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data augmentation is the process of increasing the samples in your dataset,
    and deriving new pictures from the one that you already have; for example, reducing
    the brightness or rotating them.
  prefs: []
  type: TYPE_NORMAL
- en: Keras includes a convenient way to augment your dataset, `ImageDataGenerator()`,
    which randomly applies the specified transformations, but unfortunately is not
    particularly well documented and it lacks some coherence in terms of the parameters.
    Therefore, we will now analyze some of the most useful transformations. For clarity,
    we will build a generator with only one parameter, to see the effect, but you
    will most likely want to use more than one at the same time, which we will do
    later.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ImageDataGenerator()` constructor accepts many parameters, such as the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`brightness_range`: This will change the brightness of the image and it accepts
    a list of two arguments, the minimum and the maximum brightness, for example,
    [0.1, 1.5].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rotation_range`: This will rotate the image and accept a single parameter
    that represents the range of rotation in degrees, for example, 60.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`width_shift_range`: This will shift the image horizontally; it accepts the
    parameter in different forms. I would recommend using the list of acceptable values,
    such as [-50, -25, 25, 50].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`height_shift_range`: This will shift the image vertically; it accepts the
    parameter in different forms. I would recommend using the list of acceptable values,
    such as [-50, -25, 25, 50].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`shear_range`: This is the shear intensity, accepting a number in degrees,
    such as 60.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`zoom_range`: This zooms in or zooms out of the image and it accepts a list
    of two arguments, the minimum and the maximum zoom, such as [0.5, 2].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`horizontal_flip`: This flips the image horizontally, and the parameter is
    a Boolean.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vertical_flip`: This flips the image vertically, and the parameter is a Boolean.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of these, the horizontal flip is usually quite effective.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the result of augmenting the images with brightness,
    rotation, width shift, and height shift:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – ImageDataGenerator() results. From the top: brightness_range=[0.1,
    1.5], rotation_range=60, width_shift_range=[-50, -25, 25, 50], and height_shift_range=[-75,
    -35, 35, 75]](img/Figure_5.1_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.1 – ImageDataGenerator() results. From the top: brightness_range=[0.1,
    1.5], rotation_range=60, width_shift_range=[-50, -25, 25, 50], and height_shift_range=[-75,
    -35, 35, 75]'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following images are generated using shearing, zoom, horizontal flip, and
    vertical flip:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – ImageDataGenerator() results. From the top: shear_range=60,
    zoom_range=[0.5, 2], horizontal_flip=True, and vertical_flip=True](img/Figure_5.2_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.2 – ImageDataGenerator() results. From the top: shear_range=60, zoom_range=[0.5,
    2], horizontal_flip=True, and vertical_flip=True'
  prefs: []
  type: TYPE_NORMAL
- en: 'The effects are usually combined, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'And this is the final result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – ImageDataGenerator() results. Parameters applied: brightness_range=[0.1,
    1.5], rotation_range=60, width_shift_range=[-50, -25, 25, 50], and horizontal_flip=True](img/Figure_5.3_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.3 – ImageDataGenerator() results. Parameters applied: brightness_range=[0.1,
    1.5], rotation_range=60, width_shift_range=[-50, -25, 25, 50], and horizontal_flip=True'
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, the network should become much more tolerant to variations in the
    image, and it should learn to generalize better.
  prefs: []
  type: TYPE_NORMAL
- en: Please keep in mind that the data augmentation of Keras is more like a data
    substitution, as it replaces the original images, meaning that the original, unchanged
    images are not sent to the neural network, unless the random combination is as
    such that they are presented unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: The great effect of data augmentation is that the samples will change at every
    epoch. So, to be clear, data augmentation in Keras does not increase the number
    of samples per epoch, but the samples will change every epoch, according to the
    specified transformation. You might want to train more epochs.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will see how to build the model.
  prefs: []
  type: TYPE_NORMAL
- en: The model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have a dataset of images and you know what you want to do (for
    instance, a classification), it's time to build your model!
  prefs: []
  type: TYPE_NORMAL
- en: We assume that you are working on a *convolutional neural network*, so you might
    even just use convolutional blocks, *MaxPooling*, and *dense layers*. But how
    to size them? How many layers should be used?
  prefs: []
  type: TYPE_NORMAL
- en: Let's do some tests with CIFAR-10, as MINST is too easy, and see what happens.
    We will not change the other parameters, but just play with these layers a bit.
  prefs: []
  type: TYPE_NORMAL
- en: We will also train for 5 epochs, so as to speed up training. This is not about
    getting the best neural network; it is about measuring the impact of some parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our starting point is a network with one convolutional layer, one MaxPooling
    layer, and one dense layer, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a summary of this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You can see that this is such a simple network, and it already has 463 K parameters.
    The number of layers is misleading. You don't necessarily need many layers to
    get a slow network.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now, the next step is to tune it. So, let's try that.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning convolutional layers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s use 32 channels in the convolutional layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Not bad! The accuracy increased, and despite being 4 times bigger than before,
    it is less than 50% slower.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now try to stack 4 layers instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check the size of the network, using `model.summary()` as usual:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s just slightly bigger than the initial model! The reason is that most
    of the parameters are present due to the dense layer, and stacking convolutional
    layers of the same size does not change the parameters required by the dense layer.
    And this is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: It is very similar – a bit faster and the accuracy is basically the same. The
    network can now learn more complex functions because it has multiple layers. However,
    it has a much smaller dense layer, so it loses some accuracy because of that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of using the *same* padding, let''s try to use `valid`, which will
    reduce the size of the output of the convolutional layer every time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The number of parameters decreased significantly, from 465,602:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now using fewer than 300 K parameters, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Very interestingly, the training accuracy dropped 7%, as the network is too
    small for this task. However, the validation accuracy only went down 2%.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now use the initial model, but with the same padding, as that would
    give us a slightly bigger image to work with after the convolution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have more parameters, and this is the performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Compared to the reference model, both accuracies improved, and the time is almost
    unchanged, so this was a positive experiment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now increase the size of the kernel to 7x7:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'There is a negligible increase in the number of parameters, as the kernels
    are now bigger. But how does it perform? Let''s check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Not well. It is slightly slower and slightly less accurate. It is difficult
    to know why; maybe it's because the input image is too small.
  prefs: []
  type: TYPE_NORMAL
- en: We know that it is a typical pattern to add a MaxPooling layer after a convolutional
    layer, so let's see how we can tune it.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning MaxPooling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s go back to the previous model and let''s just drop `MaxPooling`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Removing `MaxPooling` means that the dense layer is now 4 times as big, since
    the resolution of the convolutional layer is no longer reduced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This does not seem very efficient. Compared to the original network, it is slower,
    the accuracy improved, but the validation accuracy decreased. Compared to the
    networks with four convolutional layers, it has the same speed, but a far inferior
    validation accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: It seems that `MaxPooling` improves generalization while reducing computations.
    Not surprisingly, it is widely used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now increase the number of MaxPooling layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The size is now much smaller because the second convolutional layers are now
    one fourth of the size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check the performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: While the training accuracy is not great, the validation accuracy is the best
    that we achieved, and all while using only 100 K parameters!
  prefs: []
  type: TYPE_NORMAL
- en: After tuning the convolutional part of the network, is time to see how we can
    tune the part composed by dense layers.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning the dense layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s go back to the initial model, and increase the dense layer 4 times,
    which is to 1,024 neurons:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As expected, the number of parameters increased almost four fold. But what about
    performance?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The training accuracy is not bad, but the validation accuracy is lower compared
    with the best models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try to use three dense layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we get the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The number of parameters is now lower:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The result is maybe somehow disappointing. We should probably not count too
    much on increasing the number of dense layers.
  prefs: []
  type: TYPE_NORMAL
- en: The next step now is to train the network. Let's begin.
  prefs: []
  type: TYPE_NORMAL
- en: Training the network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We are now ready to discuss the training phase in greater depth, which is where
    the *magic happens*. We will not even attempt to describe the mathematical concepts
    behind it. We will just discuss in very generic and simplified terms the algorithm
    that is used to train neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need some definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Loss function** or **cost function**: A function that computes how far the
    prediction of the neural network is from the expected label; it could be the **MSE**
    (which is the **mean squared error**) or something more elaborate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Derivative**: The derivative of a function is a new function that can measure
    how much a function is changing (and in which direction) in a specific point.
    For example, if you imagine being in a car, the speed can be your initial function,
    and its derivative is the acceleration. If the speed is constant, the derivative
    (for example, the acceleration) is zero; if the speed is increasing, the derivative
    will be positive and if the speed is decreasing, the derivative will be negative.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local minimum**: The job of a neural network is to minimize the loss function.
    Given the incredible number of parameters, the function of the neural network
    can be very complex and therefore reaching a global minimum can be impossible,
    but the network could still reach a good local minimum.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Convergence**: If the network keeps approaching a good local minimum, then
    it is converging.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using these definitions, we will now see how the training actually works.
  prefs: []
  type: TYPE_NORMAL
- en: How to train the network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The algorithm is composed of two parts, and, to simplify, let''s say that it
    is performed for every sample and, of course, the whole thing is repeated for
    every epoch. So, let''s see how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Forward pass**: At the end of the day, your neural network is just a function
    with many parameters (weights and possibly biases) and many operations that, when
    provided with an input, can compute some outputs. In the forward pass, we compute
    the prediction and the loss.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backward pass**: The optimizer (for example, Adam or stochastic gradient
    descent) goes *backward* (from the last layer to the first layer) updating all
    the weights (for instance, all the parameters) trying to minimize the loss function;
    the *learning rate* (a number between 0 and 1.0, typically worth 0.01 or less)
    determines how much the weights will be adjusted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A bigger learning rate makes them train faster, but it might skip local minimums,
    while a smaller learning rate might converge, but taking too much time. Optimizers
    are actively researched to improve training speed as much as possible, and they
    are dynamically changing the learning rate to improve speed and precision.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adam is an example of an optimizer that can dynamically change the learning
    rate for each parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Gradient descent looking for a minimum](img/Figure_5.4_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Gradient descent looking for a minimum
  prefs: []
  type: TYPE_NORMAL
- en: While writing an algorithm to train a neural network is very complex, the concept
    is, in a way, similar to somebody trying to learn to play pool, while repeating
    the same complex shoot until it works. You choose the point that you want to hit
    (label), you make your move (forward pass), you evaluate how far you ended up
    from the target, and then you retry adjusting the power, direction, and all the
    other variables at play (weights). We also have a way to do this with random initialization.
    Let's try this next.
  prefs: []
  type: TYPE_NORMAL
- en: Random initialization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might wonder what the values of the parameters are the first time that you
    run the neural network. Initializing the weights to zero does not work well, while
    having small random numbers is quite effective. Keras has a variety of algorithms
    that you can choose from, and you can also change the standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: An interesting consequence of this is that the neural network starts with a
    considerable amount of random data, and you might notice that training the same
    model on the same dataset actually produces different results. Let's try with
    our previous basic CIFAR-10 CNN.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first attempt produces the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The second attempt produces the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You can try to reduce the randomness using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: However, if you train on a GPU, there could still be a number of variations.
    You should take this into consideration while you tune your network model, or
    you risk disqualifying small improvements due to randomness.
  prefs: []
  type: TYPE_NORMAL
- en: The next stage is to see what overfitting and underfitting are.
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting and underfitting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While training a neural network, you will fight between **underfitting** and
    **overfitting**. Let''s see how:'
  prefs: []
  type: TYPE_NORMAL
- en: Underfitting is where the model is too simple, and it is not able to learn the
    dataset properly. You need to add parameters, filters, and neurons to increase
    the capacity of the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overfitting is where your model is big enough to learn the training dataset,
    but it is not able to generalize (for example, it *memorizes* the dataset but
    it is not good when you provide other data).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can also see it from the plot over time of accuracy and loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Underfitting: the model is too small (7,590 parameters) and
    is not learning much](img/Figure_5.5_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.5 – Underfitting: the model is too small (7,590 parameters) and is
    not learning much'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding graph shows an extreme underfitting, and the accuracies stay
    very low. Now refer to the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Overfitting: the model is very big (29,766,666 parameters) and
    is not generalizing well](img/Figure_5.6_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.6 – Overfitting: the model is very big (29,766,666 parameters) and
    is not generalizing well'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5.6* shows a somewhat extreme example of a neural network in overfitting.
    You may notice that while the training loss keeps decreasing with the epochs,
    the validation loss reaches a minimum at epoch one, and then keeps increasing.
    The minimum of the validation loss is where you want to stop your training. In
    [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142), *Improving Your
    Neural Network*, we will see a technique that allows us to do more or less that—*early
    stopping*.'
  prefs: []
  type: TYPE_NORMAL
- en: While you might hear that overfitting is a big problem, actually it could be
    a good strategy first trying to get a model that can overfit the training dataset,
    and then apply techniques that can reduce the overfitting and improve generalization.
    However, this is good only if you can overfit the training dataset with a very
    high degree of accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: We will see very effective ways to reduce overfitting in [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142),
    *Improving Your Neural Network*, but one thing to consider is that a smaller model
    is less prone to overfit, and it is usually also faster. So, while you are trying
    to overfit the training dataset, try not to use a model that is extremely big.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have seen how to use the graph of the losses to understand
    where we are in the training of our network. In the next section, we will see
    how to visualize the activations in order to get an idea of what our network is
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the activations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we can train a neural network. Great. But what exactly is the neural network
    able to see and understand? That''s a difficult question to answer, but as convolutions
    output an image, we could try to show this. Let''s now try to show the activation
    for the first 10 images of the MINST test dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to build a model, derived from our previous model, that reads
    from the input and gets as output the convolutional layer that we want. The name
    can be taken from the summary. We will visualize the first convolutional layer,
    `conv2d_1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, for each test image, we can take all the activations and chain them together
    to get an image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And then we can show it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This is the result for the first convolutional layer, `conv2d_1`, which has
    6 channels, 28x28:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – MNIST, activations of the first convolutional layer](img/Figure_5.7_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – MNIST, activations of the first convolutional layer
  prefs: []
  type: TYPE_NORMAL
- en: This looks interesting, but trying to understand the activations, and what the
    channels learned to recognize, always involves some guesswork. The last channel
    seems to focus on horizontal lines, and the third and fourth channels are not
    very strong, which might mean that the network is not properly trained or it is
    already bigger than required. But it looks good.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now check the second layer, `conv2d_2`, which has 16 channels, 10x10:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – MNIST, activations of the second convolutional layer](img/Figure_5.8_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – MNIST, activations of the second convolutional layer
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it''s more complex – the outputs are much smaller, and we have more channels.
    It seems that some channels are detecting horizontal lines, and some of them are
    focusing on diagonal or vertical lines. And what about the first MaxPooling layer,
    `max_pooling2d_1`? It''s a lower resolution than the original channel, at 10x10,
    but as it selects the maximum activation, it should be understandable. Refer to
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9 – MNIST, activations of the first MaxPooling layer](img/Figure_5.9_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – MNIST, activations of the first MaxPooling layer
  prefs: []
  type: TYPE_NORMAL
- en: 'Indeed, the activation looks good. Just for fun, let''s check the second MaxPooling
    layer, `max_pooling2d_2`, which is only 5x5:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.10 – MNIST, activations of the second MaxPooling layer](img/Figure_5.10_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – MNIST, activations of the second MaxPooling layer
  prefs: []
  type: TYPE_NORMAL
- en: Now it looks chaotic, but it still looks like some channels are recognizing
    horizontal lines and some are focusing on vertical ones. Here is when the dense
    layers will come into play, as they try to make sense of these activations that
    are difficult to understand but not at all random.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the activation is useful to get an idea of what the neural network
    is learning, and how the channels are used, and it is another tool that you can
    use while training your neural network, above all when you feel that it is not
    learning well and you are looking for problems.
  prefs: []
  type: TYPE_NORMAL
- en: Now we will talk about inference, which is actually the whole point of training
    a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Inference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inference is the process of giving an input to your network and getting a classification
    or prediction. When the neural network has been trained and deployed in production,
    we use it, for example, to classify images or to decide how to drive in a road,
    and this process is called inference.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to load the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Then you simply call `predict()`, which is the method for inference in Keras.
    Let''s try with the first test sample of MNIST:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the result for my MNIST network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The result of `predict()` is an array of probabilities, which is very handy
    for evaluating the confidence of the network. In this case, all the numbers are
    very close to zero, except for the number `7`, which is therefore the prediction
    of the network, with a confidence above 99.999%! In real life, unfortunately,
    you seldom see a network working so well!
  prefs: []
  type: TYPE_NORMAL
- en: After inference, sometimes you want to periodically retrain on new samples,
    to improve the network. Let's see what this entails next.
  prefs: []
  type: TYPE_NORMAL
- en: Retraining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, once you get a neural network that performs well, you job is done.
    Sometimes, however, you might want to retrain it on new samples, to get better
    precision (as your dataset is now bigger) or to get fresher results if your training
    dataset becomes obsolete relatively quickly.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, you might even want to retrain continuously, for example, every
    week, and have the new model automatically deployed in production.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, it's critical that you have a strong procedure in place to verify
    the performance of your new model in the validation dataset and, hopefully, in
    a new, throwaway test dataset. It may also be advisable to keep a backup of all
    the models and try to find a way to monitor the performance in production, to
    quickly identify anomalies. In the case of a self-driving car, I expect a model
    to undergo rigorous automated and manual testing before being deployed in production,
    but other industries that don't have safety concerns might be much less strict.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we conclude our topic on retraining.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This has been a dense chapter, but hopefully you got a better overview of what
    neural networks are and how to train them.
  prefs: []
  type: TYPE_NORMAL
- en: We talked a lot about the dataset, including how to get correct datasets for
    training, validation, and testing. We described what a classifier is and we implemented
    data augmentation. Then we discussed the model and how to tune the convolutional
    layers, the MaxPooling layers, and the dense layers. We saw how training is done,
    what backpropagation is, discussed the role of randomness on the initialization
    of the weights, and we saw graphs of underfitting and overfitting networks. To
    understand how well our CNN is doing, we went as far as visualizing the activations.
    Then we discussed inference and retraining.
  prefs: []
  type: TYPE_NORMAL
- en: This means that you now have sufficient knowledge to choose or create a dataset
    and train a neural network from scratch, and you will be able to understand if
    a change in the model or in the dataset improves precision.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142), *Improving
    Your Neural Network*, we will see how to apply all this knowledge in practice,
    so as to improve the precision of a neural network significantly.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After reading this chapter, you should be able to answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Can you reuse the test dataset?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is data augmentation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does data augmentation in Keras add images to your dataset?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which layer tends to have the highest number of parameters?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Watching the plot of the losses, how can you tell that a network is overfitting?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it always bad to have a network that overfits?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
