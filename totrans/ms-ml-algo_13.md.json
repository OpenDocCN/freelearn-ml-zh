["```py\nimport numpy as np\n\nfrom keras.datasets import mnist\nfrom sklearn.utils import shuffle\n\n(X_train, Y_train), (_, _) = mnist.load_data()\nX_train, Y_train = shuffle(X_train, Y_train, random_state=1000)\n\nnb_samples = 400\n\nwidth = X_train.shape[1]\nheight = X_train.shape[2]\n\nX = X_train[0:nb_samples].reshape((nb_samples, width * height)).astype(np.float32) / 255.0\nY = Y_train[0:nb_samples]\n```", "```py\nfrom dbn.tensorflow import UnsupervisedDBN\n\nunsupervised_dbn = UnsupervisedDBN(hidden_layers_structure=[512, 256, 64],\n                                   learning_rate_rbm=0.05,\n                                   n_epochs_rbm=100,\n                                   batch_size=64,\n                                   activation_function='sigmoid')\n\nX_dbn = unsupervised_dbn.fit_transform(X)\n\n[START] Pre-training step:\n>> Epoch 1 finished       RBM Reconstruction error 55.562027\n>> Epoch 2 finished       RBM Reconstruction error 53.663380\n\n...\n\n>> Epoch 99 finished       RBM Reconstruction error 5.169244\n>> Epoch 100 finished     RBM Reconstruction error 5.130809\n[END] Pre-training step\n```", "```py\nfrom sklearn.manifold import TSNE\n\ntsne = TSNE(n_components=2, perplexity=20, random_state=1000)\nX_tsne = tsne.fit_transform(X_dbn)\n```", "```py\nfrom sklearn.datasets import fetch_kddcup99\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nkddcup = fetch_kddcup99(subset='smtp', shuffle=True, random_state=1000)\n\nss = StandardScaler()\nX = ss.fit_transform(kddcup['data']).astype(np.float32)\n\nle = LabelEncoder()\nY = le.fit_transform(kddcup['target']).astype(np.float32)\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=1000)\n```", "```py\nfrom dbn.tensorflow import SupervisedDBNClassification\n\nclassifier = SupervisedDBNClassification(hidden_layers_structure=[64, 64],\n                                         learning_rate_rbm=0.001,\n                                         learning_rate=0.01,\n                                         n_epochs_rbm=20,\n                                         n_iter_backprop=150,\n                                         batch_size=256,\n                                         activation_function='relu',\n                                         dropout_p=0.25)\n\nclassifier.fit(X_train, Y_train)\n\n[START] Pre-training step:\n>> Epoch 1 finished       RBM Reconstruction error 2.478997\n>> Epoch 2 finished       RBM Reconstruction error 2.459004\n\n...\n\n>> Epoch 147 finished       ANN training loss 0.006651\n>> Epoch 148 finished     ANN training loss 0.006631\n>> Epoch 149 finished     ANN training loss 0.006612\n[END] Fine tuning step\n\nSupervisedDBNClassification(batch_size=256, dropout_p=0.25,\n              idx_to_label_map={0: 1.0, 1: 0.0, 2: 2.0},\n              l2_regularization=1.0,\n              label_to_idx_map={0.0: 1, 1.0: 0, 2.0: 2},\n              learning_rate=0.01, n_iter_backprop=150, verbose=True)\n```", "```py\nfrom sklearn.metrics.classification import accuracy_score\n\nY_pred = classifier.predict(X_test)\nprint(accuracy_score(Y_test, Y_pred))\n1.0\n```"]