<html><head></head><body>
		<div id="_idContainer047">
			<h1 id="_idParaDest-44" class="chapter-number"><a id="_idTextAnchor015"/>3</h1>
			<h1 id="_idParaDest-45">Malware Detection Using Transformers and BERT</h1>
			<p>Malware refers to malicious software applications that run on computers, smartphones, and other devices for nefarious purposes. They execute surreptitiously in the background, and often, users are not even aware that their device is infected with malware. They can be used to steal sensitive user information (such as passwords or banking information) and share it with an adversary, use your device resources for cryptocurrency mining or click fraud, or corrupt your data (such as deleting photos and emails) and ask for a ransom to recover it. In the 21st century, where smartphones are our lifeline, malware can have catastrophic effects. Learning how to identify, detect, and remove malware is an important and emerging problem <span class="No-Break">in cybersecurity.</span></p>
			<p>Because of its ability to identify and learn patterns in behavior, machine learning techniques have been applied to detect malware. This chapter will begin with an overview of malware including its life cycle and operating characteristics. We will then cover an upcoming and state-of-the-art <a id="_idIndexMarker202"/>architecture, known as the <strong class="bold">transformer</strong>, which is typically used for <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) applications. Finally, we will combine the two and show how we can build an extremely high-precision malware classifier using BERT, which is a model built on top of the <span class="No-Break">transformer architecture.</span></p>
			<p>In this chapter, we will cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Basics <span class="No-Break">of malware</span></li>
				<li>Transformers <span class="No-Break">and attention</span></li>
				<li>Detecting malware <span class="No-Break">with BERT</span></li>
			</ul>
			<p>By the end of this chapter, you will have a better understanding of how malware works. Most importantly, you will be able to apply transformers and BERT to a variety of security-related classification problems based on the concepts we will <span class="No-Break">study here.</span></p>
			<h1 id="_idParaDest-46">Technical requirements</h1>
			<p>You can find the code files for this chapter on GitHub <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%203"><span class="No-Break">https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%203</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-47">Basics of malware</h1>
			<p>Before we learn about <em class="italic">detecting</em> malware, let us briefly understand what exactly malware is and how <span class="No-Break">it works.</span></p>
			<h2 id="_idParaDest-48">What is malware?</h2>
			<p>Malware is simply any <em class="italic">mal</em>icious soft<em class="italic">ware</em>. It will install itself on your device (such as a computer, tablet, or smartphone) and <a id="_idIndexMarker203"/>operate in the background, often without your knowledge. It is designed to quietly change files on your device, and thus steal or corrupt sensitive information. Malware is generally camouflaged and pretends to be an otherwise innocent application. For example, a browser extension that offers free emojis can actually be malware that is secretly reading your passwords and siphoning them off to a <span class="No-Break">third party.</span></p>
			<p>Devices can be infected by malware in multiple ways. Here are some of the popular vectors attackers exploit to deliver malware to a <span class="No-Break">user device:</span></p>
			<ul>
				<li>Leveraging the premise of “free” software, such as a cracked version of expensive software such as <span class="No-Break">Adobe Photoshop</span></li>
				<li>USB devices with the malware installed plugged into the <span class="No-Break">user’s computer</span></li>
				<li>Phishing emails where attackers pretend to be the employer or IT support and ask to download and install a <span class="No-Break">malicious software</span></li>
				<li>Websites that prompt users to install malicious extensions <span class="No-Break">to continue</span></li>
			</ul>
			<p>An example (<a href="https://www.myantispyware.com/2017/02/20/remove-to-continue-the-work-of-your-browser-you-should-install-the-extension-pop-ups/">https://www.myantispyware.com/2017/02/20/remove-to-continue-the-work-of-your-browser-you-should-install-the-extension-pop-ups/</a>) of a website prompting users to install an extension is <span class="No-Break">shown here:</span></p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/B19327_03_01.jpg" alt="Figure 3.1 – A suspicious website prompting malware downloads"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.1 – A suspicious website prompting malware downloads</p>
			<p>Malware applications <a id="_idIndexMarker204"/>come in multiple forms and flavors, each with a different attack strategy. In the next subsection, we will study some popular variants <span class="No-Break">of malware.</span></p>
			<h2 id="_idParaDest-49">Types of malware</h2>
			<p>Now, let us <a id="_idIndexMarker205"/>briefly take a look at the various kinds <span class="No-Break">of malware.</span></p>
			<h3>Virus</h3>
			<p>A virus is a malicious <a id="_idIndexMarker206"/>software application that functions in a manner similar to its biological counterpart – an actual virus. A virus program is one that replicates by creating <a id="_idIndexMarker207"/>multiple copies of itself and hogs all system resources. Viruses hide in computer files, and once the file is run, they can begin replicating and spreading. Viruses can be boot infectors (which target the operating system directly and install them as part of the booting process) or file infectors (those which are hidden away in executable files, such as free versions of software downloaded from shady websites). Some applications also allow third-party extensions to interface with them. Examples include macros or extensions. Viruses can also run as part of <span class="No-Break">these macros.</span></p>
			<h3>Worms</h3>
			<p>Worms are similar to<a id="_idIndexMarker208"/> viruses in operation in terms of their modus operandi, which is to<a id="_idIndexMarker209"/> replicate and spread. However, worms are standalone applications; they are not embedded into files like viruses are. While viruses require users to execute the file (such as a <strong class="source-inline">.exe</strong> file or a macro), worms are more dangerous because<a id="_idIndexMarker210"/> they can execute by themselves. Once they infect a computer, they can automatically replicate <a id="_idIndexMarker211"/>across the entire network. Worms generally crash the device or overload the network by increasing <span class="No-Break">resource usage.</span></p>
			<h3>Rootkits</h3>
			<p>Rootkits are malware applications that work with<a id="_idIndexMarker212"/> the goal of getting the attacker complete <a id="_idIndexMarker213"/>administrative rights to your system (the term <strong class="bold">root</strong> refers to<a id="_idIndexMarker214"/> the administrator or master user in operating systems, and is a user account that can control permissions and other user accounts). A rootkit can allow an adversary to have full control of the user’s computer without the user knowing. This means that the attacker can read and write to all files, execute malicious applications, and lock legitimate users out of the system. The attacker can also execute illegal activities, such as launching a DDoS attack, and avoid being caught (as it is the user’s machine to which the crime will be traced back). While malicious for the most part, some rootkits are also used for good. For example, if a system that contains highly sensitive data (such as information pertaining to national security) is accessed by an adversary, a rootkit can<a id="_idIndexMarker215"/> be used as a <strong class="bold">backdoor</strong> (a secret or hidden entry point into a system, and one that can be used to bypass security mechanisms and gain unauthorized access to a system or data) to access it and wipe it off to prevent the information from falling into the <span class="No-Break">wrong hands.</span></p>
			<h3>Ransomware</h3>
			<p>Ransomware are malware applications that block user access to data. Ransomware may encrypt the data so that users <a id="_idIndexMarker216"/>are powerless to do anything with their devices. Attackers<a id="_idIndexMarker217"/> ask for a <em class="italic">ransom</em> to be paid, and threaten that the data will be deleted forever or published on the Internet if they do not receive the ransom. There is no guarantee that the attacker will actually hold up their end of the bargain once the ransom is paid. Ransomware attacks have been on the rise, and the emergence of cryptocurrency (such as BTC) has made it possible for attackers to receive and spend <span class="No-Break">money pseudo-anonymously.</span></p>
			<h3>Keyloggers</h3>
			<p>A keylogger is an application that records the keyboard activities of a user. All information typed is <a id="_idIndexMarker218"/>logged as keystrokes and siphoned off to an attacker. The attacker can extract information such as usernames, passwords, credit card numbers, and<a id="_idIndexMarker219"/> secure PINs. As keyloggers do not cause any visible harm (such as deleting or locking files), they are hard to detect from a user’s perspective. They sit quietly in the background <a id="_idIndexMarker220"/>and ship your keystroke information to <span class="No-Break">the attacker.</span></p>
			<p>Now that we have explored the different kinds of malware, let us turn to how malware <span class="No-Break">detectors work.</span></p>
			<h1 id="_idParaDest-50">Malware detection</h1>
			<p>As the prevalence <a id="_idIndexMarker221"/>of malware grows, so does the need for detecting it. Routine system scans and analysis by malware detection algorithms can help users stay safe and keep their <span class="No-Break">systems clean.</span></p>
			<h2 id="_idParaDest-51">Malware detection methods</h2>
			<p>Malware detection <a id="_idIndexMarker222"/>can be divided broadly into three main categories: signature-based, behavioral-based, and heuristic methods. In this section, we will look at what these methods are in short and also discuss techniques <span class="No-Break">for analysis.</span></p>
			<h4>Signature-based methods</h4>
			<p>These methods aim to <a id="_idIndexMarker223"/>detect malware by storing a database of known malware examples. All applications are checked against this database to<a id="_idIndexMarker224"/> identify whether they are malicious. The algorithm examines each application and calculates a signature using a hash function. In computer security, the hash of a file can be treated as its unique identity. It is nearly impossible to have two files with the same hash unless they are identical. Therefore, this method works really well in detecting known malware. While the simplicity of this technique is unmatched, it is easily thwarted; a change of even a single bit in the executable file will cause the hash to be completely different, and undetectable by <span class="No-Break">its signature.</span></p>
			<h4>Behavioral-based methods</h4>
			<p>These methods aim to<a id="_idIndexMarker225"/> detect malware by looking for evidence of certain malicious activity. Signature-based methods detect malware based on <a id="_idIndexMarker226"/>what the application says, but behavioral methods detect it based on what the application does. It can collect a variety of features from the behavior of the application, <span class="No-Break">such as:</span></p>
			<ul>
				<li>How many GET requests did the <span class="No-Break">app make?</span></li>
				<li>How many suspicious URLs did it <span class="No-Break">connect to?</span></li>
				<li>Does the application have access to <span class="No-Break">file storage?</span></li>
				<li>How many distinct IP addresses did the application contact in the past <span class="No-Break">seven days?</span></li>
			</ul>
			<p>Using these features, common-sense rules <a id="_idIndexMarker227"/>can be built to flag malicious behavior. Past examples of known malware are also studied in detail to identify strategies that can be checked for. Behavioral methods are more robust against evasion, as an adversary will have to explicitly change the behavior of an app to <span class="No-Break">avoid detection.</span></p>
			<h4>Heuristic methods</h4>
			<p>These are the most powerful methods known to us. Rather than look for a specific behavior, they use data mining <a id="_idIndexMarker228"/>and machine learning models to learn what malicious applications look like. These methods leverage API calls, OpCode <a id="_idIndexMarker229"/>Sequences, call graphs, and other features from the application and train a classification model. Neural networks and Random Forests have been shown to achieve a high-accuracy and high-precision classifier for malware. Heuristic methods are even more robust than behavioral methods, as changing specific parameters may not necessarily fool <span class="No-Break">the model.</span></p>
			<h2 id="_idParaDest-52">Malware analysis</h2>
			<p>In the <a id="_idIndexMarker230"/>previous section, we discussed malware detection methods. Once a potential malware application has been flagged, it needs to be examined to identify its behavior, method of spreading, origin, and any potential impact. Researchers often dissect malware as it can provide insights into the skills and tactics available to an adversary. This process of examining a malware file in detail is known as malware analysis. There are two methods for malware analysis: static <span class="No-Break">and dynamic.</span></p>
			<h3>Static analysis</h3>
			<p>This method examines the malware<a id="_idIndexMarker231"/> file as a whole by collecting information about the application without actually<a id="_idIndexMarker232"/> running it. The hash of the application is checked against known malware samples. The executable file is decompiled and the code is analyzed in detail; this provides a deep insight into what the goal of the malware was and what the adversary was looking for. Common patterns in the code may also indicate the origin or developer of the malware. Any strategies found can now be used to develop stronger <span class="No-Break">detection mechanisms.</span></p>
			<h3>Dynamic analysis</h3>
			<p>Dynamic analysis involves studying malware by actually executing it. A protected sandbox environment is created, and the malware is allowed to execute in it. This allows researchers the opportunity<a id="_idIndexMarker233"/> to look at the malware in action. Some <a id="_idIndexMarker234"/>behavior may not be obvious in the code or may dynamically evolve at runtime. Such behavior can be observed when the malware is actually running. Moreover, allowing the application to run allows you to collect API call sequences and other behavioral features, which can be used for <span class="No-Break">heuristic methods.</span></p>
			<p>It is important to note that handling malware can be a dangerous task. Inadvertently running it may cause the virus or Trojan to take control of your system. There are several commercial tools that facilitate malware analysis in a secure way. In later sections, we will be using files generated by one <span class="No-Break">such tool.</span></p>
			<h1 id="_idParaDest-53">Transformers and attention</h1>
			<p>Transformers are an architecture taking the machine learning world by storm, especially in the fields of natural language processing. An improvement <a id="_idIndexMarker235"/>over classical <strong class="bold">recurrent neural networks</strong> (<strong class="bold">RNN</strong>) for sequence modeling, transformers work<a id="_idIndexMarker236"/> on the principle of attention. In this section, we will discuss the attention mechanism, transformers, and the <span class="No-Break">BERT architecture.</span></p>
			<h2 id="_idParaDest-54">Understanding attention</h2>
			<p>We will now take a look at <em class="italic">attention</em>, a recent <a id="_idIndexMarker237"/>deep learning paradigm that has made great advances in the world of natural <span class="No-Break">language processing.</span></p>
			<h3>Sequence-to-sequence models</h3>
			<p>Most natural language tasks rely heavily on sequence-to-sequence models. While traditional methods are<a id="_idIndexMarker238"/> used for classifying a particular data point, sequence-to-sequence architectures map sequences in one domain to sequences in another. An excellent example of this is language translation. An automatic machine translator will take in sequences of tokens (sentences and words) from the source language and map them to other sentences in the <span class="No-Break">target language.</span></p>
			<p>A sequence-to-sequence model generally has two components: the encoder and the decoder. The encoder takes in the source sequences as input and maps them to an intermediate vector <a id="_idIndexMarker239"/>known as a <strong class="bold">context vector</strong>, or embedding. The decoder takes in the embedding and maps it to sequences in the target domain. The entire model is trained end to end instead of encoders and decoders being trained separately as shown in <span class="No-Break"><em class="italic">Figure 3</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="image/B19327_03_02.jpg" alt="Figure 3.2 – Traditional sequence-to-sequence architecture"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.2 – Traditional sequence-to-sequence architecture</p>
			<p>The encoder and decoder are typically RNNs, which maintain an internal state (hidden state) that has some memory of past inputs. In a traditional sequence-to-sequence model, the context vector would simply be a high-dimensional representation of the input sentence in a vector space. In <span class="No-Break"><em class="italic">Figure 3</em></span><em class="italic">.2</em>, the words from the French sentence are passed one by one to the model (one every time step). The encoder contains an RNN that maintains some memory at every time step. After the final time step, the hidden state of the RNN becomes the <span class="No-Break">context vector.</span></p>
			<p>This is similar to autoencoders discussed previously, except for one major difference: in sequence-to-sequence models, the input and output sequences can be of different lengths. This is often the case<a id="_idIndexMarker240"/> in language translation. For example, the French sentence “Ca va?” translates to “How are you?” in English. Sequence-to-sequence models are powerful because they learn the relationships and order between tokens and map them to tokens in the <span class="No-Break">target language.</span></p>
			<h3>Attention</h3>
			<p>The key challenge in the<a id="_idIndexMarker241"/> standard encoder/decoder architecture is the bottleneck created by the context vector. Being a fixed-size vector, there is a limitation on how much information can be compressed into it. As a result, it cannot retain information from longer sequences and cannot capture information from multiple timesteps that the RNN encoder goes through. RNNs have a tendency to forget the information they learn. In longer sequences, they will remember the later parts of the sequence and start forgetting <span class="No-Break">earlier ones.</span></p>
			<p>The attention mechanism aims to solve the problem of long-term dependencies and allow the decoder to access as much information as it needs in order to decode the sequence properly. Via attention, the decoder focuses only on the relevant parts of the input sequence in order to produce the output sequence. The model examines multiple time steps from the encoder and "pays attention" to only the ones that it deems to <span class="No-Break">be important.</span></p>
			<p>Concretely speaking, while a traditional sequence-to-sequence model would just pass the last hidden state of the RNN to the decoder, an attention model will pass all of the hidden states. For example, in an English-French translation model, input sentences are English sentences. A hidden state will be created at every word position as the RNN encoder steps through the sequence, and all of these will be passed to <span class="No-Break">the decoder.</span></p>
			<p>The decoder now has access to the context vector at each time step in the input. While decoding, it will try to focus on the parts of the input that are meaningful to decoding this time step. It will examine the encoder’s hidden states (remember, all of the hidden states have been passed) and score each hidden state. The score represents the relevance of that hidden state to the current word being decoded; the higher the score, the greater the relevance. The score for each state is normalized using a <strong class="source-inline">softmax</strong> function overall scores. Finally, each hidden state is multiplied by the <strong class="source-inline">softmax</strong> transformed score. Hidden states with high scores (relevant to decoding at this time step) are amplified in value, whereas the ones with low scores are diminished. Using the values of these vectors, the decoded output word can <span class="No-Break">be produced.</span></p>
			<h3>Attention in action</h3>
			<p>We discussed that the <a id="_idIndexMarker242"/>attention decoder is able to selectively pay attention to the relevant words in the source sequence. To demonstrate that the model does not mindlessly do a word-by-word translation, we show an example here from the paper that first presented the idea of <span class="No-Break">attention (</span><a href="https://arxiv.org/abs/1409.0473"><span class="No-Break">https://arxiv.org/abs/1409.0473</span></a><span class="No-Break">).</span></p>
			<p>Consider the problem of translating French sentences into English. This is the perfect domain in which to demonstrate attention. The French language has a peculiar ordering of the parts of speech (adverbs, adjectives, and nouns) that is different from English. If a model is doing a word-by-word translation without attention, the translated output would be <span class="No-Break">grammatically incorrect.</span></p>
			<p>Here is a confusion matrix that demonstrates the attention that the model paid to specific tokens in the input to generate specific tokens in the output. The brighter the color, the stronger <span class="No-Break">the attention:</span></p>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="image/B19327_03_03.jpg" alt="Figure 3.3 – Confusion matrix denoting attention"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.3 – Confusion matrix denoting attention</p>
			<p>In French, the adjective is generally placed after the noun. So the “European Economic Zone” becomes the “Zone économique européenne.” Looking at the confusion matrix, note how the <a id="_idIndexMarker243"/>model has paid attention to the correct word pairs, irrespective of their order. If a model was simply mapping words, the sentence would have been translated from the French version to “Area Economic European.” The confusion matrix shows that irrespective of the order, the model knew what words to pay attention to while decoding certain <span class="No-Break">time steps.</span></p>
			<p>This is the fundamental concept of attention. The actual mechanisms (how the hidden states are scored, and how the feature vector is constructed) are out of scope here. However, those of you who are interested can refer to the foundational paper behind attention for a detailed description of <span class="No-Break">the mechanism.</span></p>
			<h2 id="_idParaDest-55">Understanding transformers</h2>
			<p>In the previous<a id="_idIndexMarker244"/> section, we discussed the attention mechanism and how it helps sequence-to-sequence applications such as neural machine translation. Now, we will look at the transformer: an architecture that leverages attention in multiple forms and stages to get the best out <span class="No-Break">of it.</span></p>
			<p>The fundamental architecture of the transformer model is reproduced in <span class="No-Break"><em class="italic">Figure 3</em></span><em class="italic">.4</em> from a 2017 paper (<a href="https://arxiv.org/pdf/1706.03762.pdf">https://arxiv.org/pdf/1706.03762.pdf</a>) <span class="No-Break">for convenience:</span></p>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="image/B19327_03_04.jpg" alt="Figure 3.4 – Transformer architecture"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.4 – Transformer architecture</p>
			<p>The model has two components: the encoder (depicted by the blocks on the left) and the decoder (depicted by the blocks on the right). The goal of the blocks on the left is to take in the input sequence<a id="_idIndexMarker245"/> and transform it into the context vectors that are fed to the decoder. The decoder blocks on the right receive the output of the encoder along with the output of the decoder at the previous time step to generate the output sequence. Let us now look at the encoder and decoder blocks in <span class="No-Break">more detail.</span></p>
			<h3>The encoder</h3>
			<p>The encoder consists of two modules: a multi-headed attention module and a fully connected feed-forward <a id="_idIndexMarker246"/>neural network. The multi-headed attention module will apply <a id="_idIndexMarker247"/>a technique called self-attention, which allows the model to associate each word in the input with other words. For example, consider the sentence, <em class="italic">I could not drink the soup because it was too hot</em>. Here, the word <em class="italic">it</em> in the latter half of the sentence refers to the word <em class="italic">soup</em> in the first half. Self-attention would be able to discover such relationships. As the name suggests, multi-headed attention includes multiple blocks (or heads) for attention. The expectation is that each head will learn a different relationship. The multi-headed attention module calculates the attention weights for the input sequence and generates a vector as output that indicates how each word in the sequence should <em class="italic">pay attention</em> to <span class="No-Break">the others.</span></p>
			<p>The output of the attention module is added back to the input and then passed through a normalization layer. Normalization helps control the range of parameters and keeps the model stable. The normalized output is passed to the second module, which is a feed-forward neural network. This can be any neural network, but generally speaking, it consists of multiple fully connected layers with a ReLU activation. The addition and normalization process repeats once again, and the final encoder output <span class="No-Break">is produced.</span></p>
			<h3>The decoder</h3>
			<p>The role of the<a id="_idIndexMarker248"/> decoder is to take in the encoder’s output and produce an output sequence. Note that the general modules remain the same, but the structure <span class="No-Break">differs slightly.</span></p>
			<p>The decoder has two attention modules. One of them takes in the embedding of the previously produced output and applies the attention mechanism to it. This module applies <em class="italic">masked attention</em>. During the training, we will have pairs of input and output sequences that the model will learn from. It is important that the decoder learns to produce the next output by looking at only past tokens. It should not pay attention to the future tokens (otherwise, the whole point of developing a predictive model is moot). The masked attention module zeroes out the attention weights for the <span class="No-Break">future tokens.</span></p>
			<p>The second attention module takes in two inputs: the normalized output of the first module and the output from our encoder. The attention module has three inputs, known as the <em class="italic">query</em>, <em class="italic">key</em>, and <em class="italic">value</em> vectors. However, we will not go into specifics <span class="No-Break">of these.</span></p>
			<p>Finally, note that the decoder <a id="_idIndexMarker249"/>has an additional linear layer and a <strong class="source-inline">softmax</strong> layer at the end. The goal of the decoder is to produce sequences (mainly text) in the target language. Therefore, the embeddings that are generated must be somehow mapped to words. The <strong class="source-inline">softmax</strong> layer outputs a probability distribution over the vocabulary of tokens. The one with the maximum probability is chosen to be the <span class="No-Break">output word.</span></p>
			<h2 id="_idParaDest-56">Understanding BERT</h2>
			<p>So far, we have seen how the attention mechanism works and how the transformers leverage it for effective sequence-to-sequence modeling. As a final step, we will learn about BERT, a model that uses transformers and a novel set of training methodologies. The effectiveness of BERT and the utility of a pre-trained model in downstream tasks will be critical for our malware <span class="No-Break">detection task.</span></p>
			<p><strong class="bold">BERT</strong> stands for <strong class="bold">Bidirectional Encoder Representations from Transformers</strong>. Ever since its introduction in <a id="_idIndexMarker250"/>2018, it has made great impacts on the natural language processing world. It is a significant discovery that allows researchers and scientists to harness the power of large-scale machine learning language models, without the need for massive data or extensive <span class="No-Break">computing resources.</span></p>
			<h3>BERT architecture</h3>
			<p>Architecturally speaking, BERT leverages<a id="_idIndexMarker251"/> transformers to create a structure. The BERT base model has 12 transformers stacked on top of each other and 12 self-attention heads. The BERT large model has 24 transformer layers and 16 self-attention heads. Both these models are <em class="italic">tremendously large</em> (with 110M and 40M <span class="No-Break">parameters respectively).</span></p>
			<p>Both of these models have been released by Google as open source and are freely available for anyone <span class="No-Break">to use.</span></p>
			<h3>MLM as a training task</h3>
			<p>Traditional language models examine <a id="_idIndexMarker252"/>text sequences in only one direction: from left to right or right to left. This approach works just fine for generating sentences. The overarching goal in a language model is, given the words that have occurred so far, to predict the next word likely <span class="No-Break">to appear.</span></p>
			<p>However, BERT takes this a step further. Instead of looking at the sequence either left to right or right to left, it looks at the sequence both ways. It is trained on a task known as <strong class="bold">masked language modeling </strong>(<strong class="bold">MLM</strong>). The concept here is fairly simple. We randomly mask out some words (around 15%) from the sentence and replace them with a <strong class="source-inline">[MASK]</strong> token. Now, the goal is not to predict the next word in the sentence. The model will now learn to predict the masked words, given the surrounding words in <span class="No-Break">both directions.</span></p>
			<p>The word embeddings generated by traditional models represent words in a numeric space such that words similar in meaning are close to one another in the vector space. However, BERT will generate embeddings for a word depending on the context of the word. In such embeddings, the vector representation of a word changes with the context in which the word is <span class="No-Break">being used.</span></p>
			<p>In traditional word embeddings, a word will have the same embedding irrespective of the context. The word <em class="italic">match</em> will have the same embedding in the sentence “They were a perfect match” and “I lit a match last night.” We clearly see that although the word is the same, the context matters and changes the meaning. BERT recognizes this and conditions the embeddings based on context. The word match has different embeddings in these <span class="No-Break">two sentences.</span></p>
			<h3>Fine-tuning BERT</h3>
			<p>As mentioned before, the power<a id="_idIndexMarker253"/> of BERT lies in fine-tuning. The original BERT model has been trained on the masked language model task using the BooksCorpus data (containing 800 million words) and the Wikipedia data (containing 2.5 billion words). The model learns from large-scale datasets, training that we cannot reproduce trivially. For context, the BERT large model required 4 days and 16 cloud TPUs <span class="No-Break">for training.</span></p>
			<p>The concept of transfer learning helps us leverage this already-trained model for our downstream tasks. The idea behind this is that we take a generic language model, and fine-tune it for our specific task. High-level concepts are already learned by the model; we simply need to teach it more about a <span class="No-Break">specific task.</span></p>
			<p>In order to do this, we use the pre-trained model and add a single layer (often a single-layered neural network) on top of it. The nature of the layer will depend on the task we are fine-tuning for. For any <a id="_idIndexMarker254"/>task, we simply plug in the task-specific inputs and outputs in the correct format into BERT and fine-tune all the parameters end to end. As we fine-tune, we will achieve <span class="No-Break">two tasks:</span></p>
			<ul>
				<li>The parameters of the transformer will be updated iteratively to refine the embeddings and generate task-specific <span class="No-Break">contextual embeddings</span></li>
				<li>The newly added layer will be trained (that is, will learn appropriate parameters) to classify the new class <span class="No-Break">of embeddings</span></li>
			</ul>
			<p>Fine-tuning BERT is an inexpensive task both in terms of time and resources. Classification models can be built using an hour on a TPU, around 4 hours on a GPU, and 8-10 hours on a regular CPU. BERT has been used after fine-tuning several tasks such as question-answering, sentence completion, and <span class="No-Break">text understanding.</span></p>
			<h1 id="_idParaDest-57">Detecting malware with BERT</h1>
			<p>So far, we have seen<a id="_idIndexMarker255"/> attention, transformers, and BERT. But all of it has been very specific to language-related tasks. How is all of what we have learned relevant to our task of malware detection, which has nothing to do with language? In this section, we will first discuss how we can leverage BERT for malware detection and then demonstrate an implementation of <span class="No-Break">the same.</span></p>
			<h2 id="_idParaDest-58">Malware as language</h2>
			<p>We saw that BERT shows <a id="_idIndexMarker256"/>excellent performance on sentence-related tasks. A sentence is merely a sequence of words. Note that we as humans find meaning in a sequence because we understand language. Instead of words, the tokens could be anything: integers, symbols, or images. So BERT performs well on <span class="No-Break">sequence tasks.</span></p>
			<p>Now, imagine that instead of words, our tokens were calls made by an application. The life cycle of an application could be described as a series of API calls it makes. For instance, <strong class="source-inline">&lt;START&gt;</strong> <strong class="source-inline">&lt;REQUEST-URL&gt;</strong> <strong class="source-inline">&lt;DOWNLOAD-FILE&gt;</strong> <strong class="source-inline">&lt;EXECUTE-FILE&gt;</strong> <strong class="source-inline">&lt;OPEN-CONTACTS&gt;</strong> <strong class="source-inline">&lt;POST-URL&gt;</strong> <strong class="source-inline">&lt;END&gt;</strong> could <a id="_idIndexMarker257"/>represent the behavior of an application. Just like a sentence is a sequence of words, an application can be thought of as a sequence of <span class="No-Break">API calls.</span></p>
			<h2 id="_idParaDest-59">The relevance of BERT</h2>
			<p>Recall that BERT learned <a id="_idIndexMarker258"/>contextual embeddings for a word. If we use BERT with malware data (with API calls as words and their sequence as sentences), the model will be able to learn embedding representations for each API call and condition it on the context. This is useful for malware detection because a single API call cannot determine whether an application is malware or not, but the context in which it is called might. For example, by itself, the API call for making a request to a third-party URL may not be malicious, but coupled with accessing stored passwords and contacts, it may indicate malware at work. This is our motivation behind choosing BERT as a model for <span class="No-Break">malware detection.</span></p>
			<p>We will use BERT on the malware classification task just like a sentence classification task. Here we have <span class="No-Break">two options:</span></p>
			<ul>
				<li>Train a new BERT model <span class="No-Break">from scratch</span></li>
				<li>Fine-tune the existing BERT model (pre-trained on language data) on <span class="No-Break">malware classification</span></li>
			</ul>
			<p>As the domains of the pre-trained model are different from malware (that is, tokens in malware API sequences will not appear in the Wikipedia or BooksCorpus datasets), the first option might seem better. However, recall that the datasets for pre-training were massive, and we do not have access to malware data at <span class="No-Break">that scale.</span></p>
			<p>Prior research has shown that a BERT model, even when pre-trained in the English language, serves as an excellent candidate for malware detection. This is because the pre-training results in an optimal set of parameters that results in faster convergence of any downstream task such as malware detection. In the following sections, this is the approach we will take. We will first preprocess the data, read it into a DataFrame, and then fine-tune it on a pre-trained <span class="No-Break">BERT model.</span></p>
			<h2 id="_idParaDest-60">Getting the data</h2>
			<p>As described previously, malware<a id="_idIndexMarker259"/> can be analyzed using both static and dynamic methods. Several commercial tools exist for decompiling malware binaries, understanding the behavior, and examining their activities. One such tool for malware analysis is WildFire (<a href="https://www.paloaltonetworks.com/products/secure-the-network/wildfire">https://www.paloaltonetworks.com/products/secure-the-network/wildfire</a>), developed by Palo Alto Networks. It is a cloud malware protection engine that utilizes advanced machine learning models to detect targeted malware attacks in <span class="No-Break">real time.</span></p>
			<p>Creating your own datasets for malware detection is challenging. First, using tools such as WildFire to generate dynamic analysis files is an expensive task (commercial tools are generally patented and require a license) and also outside the scope of this book. Second, examples of malware, particularly those seen in the wild, are hard to come by. Finally, experimenting with malware executables may inadvertently infect your systems. We will, therefore, use a commercially available <span class="No-Break">malware dataset.</span></p>
			<p>In 2018, Palo Alto Networks released a research paper (<a href="https://arxiv.org/pdf/1812.07858.pdf">https://arxiv.org/pdf/1812.07858.pdf</a>) that discussed common cybersecurity problems, in which malware detection was discussed in great detail. Along with the paper, they released a malware dataset that contained analysis files for over 180,000 different applications. The dataset is made of a sample of malware identified by Palo Alto Networks in a given period. For each malware, they provide identifiers and the domains accessed by the file, along with the sequence of API calls made by <span class="No-Break">the application.</span></p>
			<p>The dataset is freely available for students and researchers and can be obtained by contacting Palo Alto Networks as described in the paper. However, the method we present is fairly generic and can be applied to any malware dataset that you can gain <span class="No-Break">access to.</span></p>
			<h2 id="_idParaDest-61">Preprocessing the data</h2>
			<p>The Palo Alto Networks dataset <a id="_idIndexMarker260"/>contains several features for every application, including static and dynamic analysis files. However, of particular interest to us is the API call sequence. This is because we want to exploit the power of transformers. A defining characteristic of transformers is that they excel at handling sequential data via <span class="No-Break">attention mechanisms.</span></p>
			<p>The dynamic analysis file will give us the sequence of API calls made by the application. Each API call consists of two parts: the <strong class="bold">action</strong> and the <strong class="bold">key</strong>. The action refers to the actual task behind the API call (such as opening a file, turning on Bluetooth, or sending a <strong class="source-inline">GET</strong> request). The key refers to the parameters passed to the API call (such as the actual domain to which the <a id="_idIndexMarker261"/>application is connected). While examining the parameters will also reveal significant information about whether an app is malicious, here we simply focus on the action of the <span class="No-Break">API call.</span></p>
			<p>Every application (whether malware or benign) has an associated XML file that contains the API call logs. Once they are extracted, we will have access to the set of actions taken by the application. An example snippet could look <span class="No-Break">like this:</span></p>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="image/B19327_03_05.jpg" alt="Figure 3.5 – API call sequence"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.5 – API call sequence</p>
			<p>We first extract the sequence for all the applications. Now that we have the sequence, it must be converted into tokens suitable for consumption by a machine learning model. Once we have all the sequences, we can compute the universe of known API calls, and assign a unique integer to each API call. Every application can now be represented as a sequence <span class="No-Break">of integers.</span></p>
			<p>Note that the steps discussed so far are not specific to the Palo Alto Networks dataset, and this is the reason why we did not introduce any specific functions or code to do the preprocessing. You can apply this same technique to construct a feature vector from any <span class="No-Break">malware dataset.</span></p>
			<p>For convenience and simplicity, we will provide the preprocessed versions of the dataset. Note that the API call sequences are represented by integers, as we cannot share the exact API calls publicly. Interested readers can refer to the original paper and data if they are curious to <span class="No-Break">learn more.</span></p>
			<h2 id="_idParaDest-62">Building a classifier</h2>
			<p>We will leverage<a id="_idIndexMarker262"/> the BERT model to build our classifier. Much of the code here is borrowed from the official notebooks released by Google when they released the BERT model in 2019. Some of the code may seem intimidating; however, do not worry. A lot of this is just boilerplate environment setup and function definitions that you absolutely do not need to understand in detail. We will go over the code and discuss what parts need to be changed when you implement this on your own or wish to use this setup for a <span class="No-Break">different problem.</span></p>
			<p>First, we will import the required libraries. If any of these are not already installed (and Python will throw an error saying so), then they can be installed using the <span class="No-Break"><strong class="source-inline">pip</strong></span><span class="No-Break"> utility:</span></p>
			<pre class="source-code">
import bert
from bert import run_classifier
from bert import optimization
from bert import tokenization
<strong class="bold">import</strong> tensorflow <strong class="bold">as</strong> tf
<strong class="bold">import</strong> numpy <strong class="bold">as</strong> np
<strong class="bold">import</strong> pandas <strong class="bold">as</strong> pd
<strong class="bold">import</strong> tensorflow_hub <strong class="bold">as</strong> hub</pre>
			<p>We will leverage a pre-trained BERT model for building our classifier. TensorFlow Hub contains all of these pre-trained models and they are available for use by the public. This function reads the model and its vocabulary and generates a tokenizer. The tokenizer is responsible for converting the words we see into tokens that can be understood by the machine <span class="No-Break">learning model:</span></p>
			<pre class="source-code">
BERT_MODEL_HUB = "https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1"
<strong class="bold">def</strong> create_tokenizer_from_hub_module():
  <strong class="bold">with</strong> tf.Graph().as_default():
    bert_module = hub.Module(BERT_MODEL_HUB)
    tokenization_info = bert_module(signature="tokenization_info", as_dict=<strong class="bold">True</strong>)
  <strong class="bold">with</strong> tf.Session() <strong class="bold">as</strong> sess:
    vocab_file, do_lower_case = sess.run([tokenization_info["vocab_file"],
                                                 tokenization_info["do_lower_case"]])
  <strong class="bold">return</strong> bert.tokenization.FullTokenizer(
      vocab_file=vocab_file, do_lower_case=do_lower_case)
tokenizer = create_tokenizer_from_hub_module()</pre>
			<p>Now, we actually create the classification model. This function will create a BERT module and define the input and output structures. We will then obtain the output layer and find the parameters there; these are the ones that would be used to run inference. We apply a dropout to this layer and calculate the logits (that is, the <strong class="source-inline">softmax</strong> output of the layer). During<a id="_idIndexMarker263"/> the training phase, the <strong class="source-inline">softmax</strong> output is used to compute the loss relative to the ground truth. In the inferencing phase, the output can be used to predict the token depending on which probability in the <strong class="source-inline">softmax</strong> output is the highest. Note that the ground truth is in the form of categorical tokens (in our case, API calls) and, therefore, needs to be converted into a numeric form using <span class="No-Break">one-hot encoding:</span></p>
			<pre class="source-code">
<strong class="bold">def</strong> create_model(is_predicting, input_ids, input_mask, segment_ids, labels,num_labels):
  """Creates a classification model."""
  bert_module = hub.Module(
      BERT_MODEL_HUB,
      trainable=<strong class="bold">True</strong>)
  bert_inputs = dict(
      input_ids=input_ids,
      input_mask=input_mask,
      segment_ids=segment_ids)
  bert_outputs = bert_module(
      inputs=bert_inputs,
      signature="tokens",as_dict=<strong class="bold">True</strong>)
  output_layer = bert_outputs["pooled_output"]
  hidden_size = output_layer.shape[-1].value
  output_weights = tf.get_variable("output_weights", [num_labels, hidden_size],      initializer=tf.truncated_normal_initializer(stddev=0.02))
  output_bias = tf.get_variable("output_bias",[num_labels], initializer=tf.zeros_initializer())
  <strong class="bold">with</strong> tf.variable_scope("loss"):
    # Dropout helps prevent overfitting
  output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)
    logits = tf.matmul(output_layer, output_weights, transpose_b=<strong class="bold">True</strong>)
    logits = tf.nn.bias_add(logits, output_bias)
    log_probs = tf.nn.log_softmax(logits, axis=-1)
    # Convert labels into one-hot encoding
    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)
    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))
    # If we're predicting, we want predicted labels and the probabilties.
    <strong class="bold">if</strong> is_predicting:
      <strong class="bold">return</strong> (predicted_labels, log_probs)
    # If we're train/eval, compute loss between predicted and actual label
    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)
    loss = tf.reduce_mean(per_example_loss)
    <strong class="bold">return</strong> (loss, predicted_labels, log_probs)</pre>
			<p>The code so far has been mostly boilerplate functions for setting up the parameters. Now, we will create a function that actually defines our training and inference settings. Recall that the previous <a id="_idIndexMarker264"/>function defined the steps to create the model. This function will leverage the previous one for training <span class="No-Break">and inference.</span></p>
			<p>First, we read the input features and labels that are crucial to training. These will be passed to the function as parameters. If the training phase is going on, the function will use the <strong class="source-inline">create_model</strong> function to calculate a loss that will be optimized for training. If not, it will simply score the data point on the model and return a predicted label and <span class="No-Break">output probabilities.</span></p>
			<p>This function also has a metric calculation function defined. This is crucial to analyzing and comparing the performance of our model. TensorFlow has built-in functions that calculate common metrics such as precision, recall, false positives, false negatives, F1 score, and so on. We leverage these built-in functions and return a dictionary, which contains <span class="No-Break">various metrics:</span></p>
			<pre class="source-code">
<strong class="bold">def</strong> model_fn_builder(num_labels, learning_rate, num_train_steps,num_warmup_steps):
  <strong class="bold">def</strong> model_fn(features, labels, mode, params):
    input_ids = features["input_ids"]
    input_mask = features["input_mask"]
    segment_ids = features["segment_ids"]
    label_ids = features["label_ids"]
    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)
    # TRAIN and EVAL
    <strong class="bold">if</strong> not is_predicting:
      (loss, predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)
      train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=<strong class="bold">False</strong>)
    # Calculate evaluation metrics.
    <strong class="bold">def</strong> metric_fn(label_ids, predicted_labels):
       accuracy = tf.metrics.accuracy(label_ids, predicted_labels)
        f1_score = tf.contrib.metrics.f1_score(
            label_ids,
            predicted_labels)
        auc = tf.metrics.auc(
            label_ids,
            predicted_labels)
        recall = tf.metrics.recall(
            label_ids,
            predicted_labels)
        precision = tf.metrics.precision(
            label_ids,
            predicted_labels)
        true_pos = tf.metrics.true_positives(
            label_ids,
            predicted_labels)
        true_neg = tf.metrics.true_negatives(
            label_ids,
            predicted_labels)
        false_pos = tf.metrics.false_positives(
            label_ids,
            predicted_labels)
        false_neg = tf.metrics.false_negatives(
            label_ids,
            predicted_labels)
        <strong class="bold">return</strong> {
            "eval_accuracy": accuracy,
            "f1_score": f1_score,
            "auc": auc,
            "precision": precision,
            "recall": recall,
            "true_positives": true_pos,
            "true_negatives": true_neg,
            "false_positives": false_pos,
            "false_negatives": false_neg
        }
      eval_metrics = metric_fn(label_ids, predicted_labels)
      <strong class="bold">if</strong> mode == tf.estimator.ModeKeys.TRAIN:
        <strong class="bold">return</strong> tf.estimator.EstimatorSpec(mode=mode,
          loss=loss,
          train_op=train_op)
      <strong class="bold">else</strong>:
        <strong class="bold">return</strong> tf.estimator.EstimatorSpec(mode=mode,
            loss=loss,
            eval_metric_ops=eval_metrics)
      <strong class="bold">else</strong>:
        (predicted_labels, log_probs) = create_model(
        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)
      predictions = {
          'probabilities': log_probs,
          'labels': predicted_labels
      }
     <strong class="bold">return</strong> tf.estimator.EstimatorSpec(mode, predictions=predictions)
  # Return the actual model function in the closure
<strong class="bold">return</strong> model_fn</pre>
			<p>Now that all of the functions to initialize the model, compute loss and training, and inferencing are good to go, we can use this setup by plugging in our malware data. Note that the procedure so far is generically applicable to any fine-tuning problem you are trying to solve using BERT; nothing has been hardcoded or is specific to malware data. If you want to use the fine-tuning approach to BERT on another task (sentiment analysis, hate speech detection, or misinformation detection), all of the steps we have completed so far <span class="No-Break">remain valid.</span></p>
			<p>We will now define some parameters used for training. The first set of parameters are standard machine<a id="_idIndexMarker265"/> learning ones. The batch size defines the number of examples that will be used to calculate loss at a time, and the learning rate defines the rate at which parameters will be updated in the gradient descent optimization algorithm. The number of epochs is set here to <strong class="source-inline">3</strong>, which is a small number. This is because we are not training a model from scratch; we are simply using an already trained model, and fine-tuning it to operate on <span class="No-Break">our dataset.</span></p>
			<p>The next set of parameters exists for optimization and ease in training. It defines after how many steps a new version of the model should be saved. Here, we have set it to <strong class="source-inline">500</strong>, meaning that after every 500 steps, a new model will be saved. This helps us if we run into an unexpected error or crash; the model simply reads the latest saved model and picks up training from <span class="No-Break">that point.</span></p>
			<p>Finally, the last set of parameters defines the positive ratio. This is the proportion of malware samples in the training data. Here we set it to 0.001, which amounts <span class="No-Break">to 0.1%:</span></p>
			<pre class="source-code">
BATCH_SIZE = 32
LEARNING_RATE = 2e-5
NUM_TRAIN_EPOCHS = 3.0
WARMUP_PROPORTION = 0.1
SAVE_CHECKPOINTS_STEPS = 500
SAVE_SUMMARY_STEPS = 100
POSRATIO=0.001 # 0.1%
NPOS=10000*POSRATIO</pre>
			<p>Now, we read the data frame that contains our data. Recall that the <strong class="source-inline">VERDICT</strong> column contained a 0/1 label indicating whether that particular data point was malware or not. We separate the malware and benign samples, sample the required fraction from the positive class, and <a id="_idIndexMarker266"/>then combine it with the negative class. This way, we have a dataset that contains only the required proportion of <span class="No-Break">malware samples:</span></p>
			<pre class="source-code">
df_a=pd.read_csv('dataset.csv')
df_a_1=df_a[df_a['VERDICT']==1]
df_a_0=df_a[df_a['VERDICT']==0]
df_a_sampled=pd.concat([df_a_1[:nPos],df_a_0[:NPOS]])</pre>
			<p>We now split our data into training and testing sets. Note that here we have a very small proportion of malware in our sampled data. If we split randomly, we might end up with all of the malware entirely in the training or testing set. To avoid this, we apply stratified sampling. With stratified sampling, the proportion of labels remains roughly the same in both the training and <span class="No-Break">testing datasets:</span></p>
			<pre class="source-code">
<strong class="bold">from</strong> sklearn.model_selection <strong class="bold">import</strong> train_test_split
df_train_n,df_test_n=train_test_split(df_a_sampled,stratify=df_a_sampled['VERDICT'])</pre>
			<p>Remember that the data we have is in the form of API call sequences. This has to be converted into a form suitable for being consumed by BERT. We do this in our next step and transform both the training <a id="_idIndexMarker267"/>and test data into the <span class="No-Break">required format.</span></p>
			<p>First, we use the <strong class="source-inline">InputExample</strong> class to wrap our API sequence string and <span class="No-Break">labels together:</span></p>
			<pre class="source-code">
DATA_COLUMN='API_CALL_SEQ'
LABEL_COLUMN='VERDICT'
train_InputExamples_a = df_train_n.apply(<strong class="bold">lambda</strong> x: bert.run_classifier.InputExample(guid=<strong class="bold">None</strong>,
                        text_a = x[DATA_COLUMN],
                        text_b = <strong class="bold">None</strong>,
                        label = x[LABEL_COLUMN]),
                        axis = 1)
test_InputExamples_a = df_test_n.apply(<strong class="bold">lambda</strong> x: bert.run_classifier.InputExample(guid=<strong class="bold">None</strong>,
                        text_a = x[DATA_COLUMN],
                        text_b = <strong class="bold">None</strong>,
                        label = x[LABEL_COLUMN]),
                        axis = 1)</pre>
			<p>Then, we transform the sequence into features using <span class="No-Break">our tokenizer:</span></p>
			<pre class="source-code">
label_list=[0,1]
MAX_SEQ_LENGTH = 128
train_features_a = bert.run_classifier.convert_examples_to_features(
                train_InputExamples_a,
                label_list,
                MAX_SEQ_LENGTH,
                tokenizer)
test_features_a = bert.run_classifier.convert_examples_to_features(
                test_InputExamples_a,
                label_list,
                MAX_SEQ_LENGTH,
                tokenizer)</pre>
			<p>We now have our features and labels. We are ready to train the model! We will use the model function builder we defined earlier to create the model and pass it to the TensorFlow estimator, which will take care of the training for us. We specify the output directory in which to save the trained <a id="_idIndexMarker268"/>model as well as the parameters we defined earlier (summary and checkpoint steps) in a run configuration. This also gets passed to <span class="No-Break">the estimator:</span></p>
			<pre class="source-code">
OUTPUT_DIR='saved_models/rate_'+str(posRatio*100)
num_train_steps = int(len(train_features_a) / BATCH_SIZE * NUM_TRAIN_EPOCHS)
num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)
run_config = tf.estimator.RunConfig(
    model_dir=OUTPUT_DIR,
    save_summary_steps=SAVE_SUMMARY_STEPS,
    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)
model_fn = model_fn_builder(
  num_labels=len(label_list),
  learning_rate=LEARNING_RATE,
  num_train_steps=num_train_steps,
  num_warmup_steps=num_warmup_steps)
estimator_android = tf.estimator.Estimator(
  model_fn=model_fn,
  config=run_config,
  params={"batch_size": BATCH_SIZE})
train_input_fn_a = bert.run_classifier.input_fn_builder(
    features=train_features_a,
    seq_length=MAX_SEQ_LENGTH,
    is_training=<strong class="bold">True</strong>,
    drop_remainder=<strong class="bold">False</strong>)
<strong class="bold">import</strong> time
print(f'Beginning Training!')
current_time = time.time()
estimator_android.train(input_fn=train_input_fn_a, max_steps=num_train_steps)
print("Training took time ", time.time() - current_time)</pre>
			<p>This will produce a lot of output, most of which you do not need to understand. The training time will vary<a id="_idIndexMarker269"/> depending on the processor you are using, the GPU (if any), and system usage. Without a GPU, the fine-tuning took approximately 29,000 seconds, which amounts to roughly <span class="No-Break">eight hours.</span></p>
			<p>Finally, we want to use this fine-tuned model to make predictions for new data and evaluate its performance. We can use the same estimator in <span class="No-Break">inference mode:</span></p>
			<pre class="source-code">
test_input_fn_a = bert.run_classifier.input_fn_builder(
    features=test_features_a,
    seq_length=MAX_SEQ_LENGTH,
    is_training=<strong class="bold">False</strong>,
    drop_remainder=<strong class="bold">False</strong>)
metrics = estimator_android.evaluate(input_fn=test_input_fn_a, steps=<strong class="bold">None</strong>)</pre>
			<p>This should show you an<a id="_idIndexMarker270"/> output that prints out the metrics. Note that your numbers may differ slightly from the ones you <span class="No-Break">see here:</span></p>
			<pre class="source-code">
{'auc': 0.95666675,
 'eval_accuracy': 0.99920094,
 'f1_score': 0.49999997,
 'false_negatives': 2.0,
 'false_positives': 0.0,
 'loss': 0.0076462436,
 'precision': 0.974,
 'recall': 0.871,
 'true_negatives': 2500.0,
 'true_positives': 1.0,
 'global_step': 703}</pre>
			<p>Recall that earlier, we defined a model evaluation function. The variable metrics will contain the dictionary with the various evaluation metrics. If you print it out, you should be able to examine the accuracy, precision, recall, and <span class="No-Break">F-1 score.</span></p>
			<p>This completes our experiment! We have successfully used a BERT model pre-trained on a language task and fine-tuned it to classify malicious applications based on the API call sequence. Feel free to <a id="_idIndexMarker271"/>experiment with the code. Here are some things <span class="No-Break">to ponder:</span></p>
			<ul>
				<li>What happens if you use the BERT large model instead of the BERT <span class="No-Break">base model?</span></li>
				<li>How does the performance vary with the positive <span class="No-Break">rate fraction?</span></li>
				<li>What happens if you vary the architecture (add <span class="No-Break">more layers)?</span></li>
			</ul>
			<p>With that, we have come to the end of <span class="No-Break">this chapter.</span></p>
			<h1 id="_idParaDest-63">Summary</h1>
			<p>This chapter provided an introduction to malware and a hands-on blueprint for how it can be detected using transformers. First, we discussed the concepts of malware and the various forms they come in (rootkits, viruses, and worms). We then discussed the attention mechanism and transformer architecture, which are recent advances that have taken the machine learning world by storm. We also looked at BERT, a model that has beat several baselines in tasks such as sentence classification and question-answering. We leveraged BERT for malware detection by fine-tuning a pre-trained model on API call <span class="No-Break">sequence data.</span></p>
			<p>Malware is a pressing problem that places users of phones and computers at great risk. Data scientists and machine learning practitioners who are interested in the security space need to have a strong understanding of how malware works and the architecture of models that can be used for detection. This chapter provided all of the knowledge needed and is a must to master for a <span class="No-Break">SecML professional.</span></p>
			<p>In the next chapter, we will switch gears and turn to a different problem: fake <span class="No-Break">online reviews.</span></p>
		</div>
	</body></html>