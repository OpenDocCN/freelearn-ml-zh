- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: From Model-Centric to Data-Centric – ML’s Evolution
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从模型为中心到数据为中心——机器学习的演变
- en: 'By now, you might be thinking: if data-centricity is essential to the further
    evolution of AI and ML, how come model-centricity is the dominant approach?'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你可能已经在想：如果数据中心性对于人工智能和机器学习的进一步发展至关重要，那么为什么模型中心性是主导方法？
- en: This is a very relevant question to ask, and one we will answer in this chapter.
    To understand what it takes to shift to a data-centric approach, we must understand
    the forces that have led to model-centricity being the predominant approach, and
    how to overcome them.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常相关的问题，我们将在本章中回答。为了了解转向数据中心方法需要什么，我们必须了解导致模型中心性成为主导方法的力量，以及如何克服它们。
- en: We will start this chapter by exploring why the evolution of AI and ML has predominately
    followed a model-centric approach, before diving into the huge opportunity that
    can be unlocked through data-centricity.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先探讨为什么人工智能和机器学习的演变主要遵循以模型为中心的方法，然后深入探讨通过数据中心性可以解锁的巨大机会。
- en: Throughout this chapter, we will challenge the notion that ML requires big datasets
    and that more data is always better. There is a long tail of *small data* ML use
    cases that open up when we shift our mindset from *bigger data* to *better data*.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将挑战机器学习需要大数据集以及更多数据总是更好的观念。当我们从“更大数据”转向“更好数据”时，会出现一系列小数据机器学习用例的长尾。
- en: By the end of this chapter, you will have a clear understanding of the progression
    of ML to date, and know what it takes to build on the current paradigm and achieve
    even better results with ML.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将清楚地了解机器学习至今的发展历程，并知道如何在此基础上构建并使用机器学习取得更好的成果。
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Exploring why ML development ended up being mostly model-centric
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探讨为什么机器学习的发展最终变成了以模型为中心
- en: The opportunity for small-data ML
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小数据机器学习的机会
- en: Why we need data-centric ML more than ever
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么我们比以往任何时候都需要以数据为中心的机器学习
- en: Exploring why ML development ended up being mostly model-centric
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探讨为什么机器学习的发展最终变成了以模型为中心
- en: A short history lesson is in order to truly appreciate why a data-centric approach
    is the key to unlocking the full potential of ML.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了真正理解为什么以数据为中心的方法是释放机器学习（ML）全部潜力的关键，我们需要上一堂简短的历史课。
- en: The fields of data science and ML have achieved significant advancements since
    the earliest attempts to make electronic computers act *intelligently*. The *intelligent*
    tasks performed by most smartphones today were nearly unimaginable at the turn
    of the 21st century. Moreover, we are producing more data every single day than
    was created from the beginning of human civilization to the 21st century – and
    we’re doing so at an estimated growth rate of 23% per annum1.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学和机器学习领域自从最早尝试让电子计算机表现出“智能”行为以来，已经取得了显著的进步。今天大多数智能手机所执行的“智能”任务，在21世纪初几乎无法想象。此外，我们每天产生的数据量比从人类文明开始到21世纪所创造的数据量还要多——而且我们以每年约23%的增长率在这样做。
- en: Despite these incredible developments in technology and data volumes, some elements
    of data science are very old. Statistics and data analysis have been in use for
    centuries and the mathematical components of today’s ML models were mostly developed
    long before the advent of digital computers.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在技术和数据量方面取得了这些令人难以置信的进步，但数据科学的一些元素非常古老。统计学和数据分析已经使用了几个世纪，而今天机器学习模型的数学组成部分大多是在数字计算机出现之前开发的。
- en: For our purposes, the history of ML and AI starts with the introduction of the
    first electronic calculation machines during World War II.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 就我们的目的而言，机器学习和人工智能的历史始于第二次世界大战期间首次电子计算机的引入。
- en: The 1940s to 1970s – the early days
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1940年代至1970年代——早期阶段
- en: Historian and former US Army officer Adrian R. Lewis wrote in his book *The
    American Culture of War* that “war created the conditions for great advances in
    technology… without war, men would not traverse oceans in hours, travel in space,
    or microwave popcorn2.”
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 历史学家和前美国陆军军官Adrian R. Lewis在他的书《美国的战争文化》中写道：“战争创造了技术巨大进步的条件……如果没有战争，人们不会在几小时内穿越海洋，在太空中旅行，或者用微波炉爆米花2。”
- en: This was indeed the case during World War II, and in the decades that followed.
    Huge leaps were made in computer science, cryptology, and hardware technology,
    as fighting nations around the world were racing each other for dominance on every
    front.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是在第二次世界大战期间，以及随后的几十年里。计算机科学、密码学和硬件技术取得了巨大的飞跃，因为世界各地的战斗国家在全球各个战线上相互竞争以获得主导地位。
- en: In the 1940s and 1950s, innovations such as compilers, semiconductor transistors,
    integrated circuits, and computer chips made digital electronic computers capable
    of performing more complex processes (until this point, a *computer* was predominately
    the job title of mathematically gifted humans employed to perform complex calculations3).
    This, in turn, led to some early innovations that underpin today’s ML models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪40年代和50年代，编译器、半导体晶体管、集成电路和计算机芯片等创新使得数字电子计算机能够执行更复杂的过程（在此之前，*计算机*主要是指那些被雇佣来执行复杂计算的计算天赋异禀的人类的工作职位3）。这反过来又导致了今天机器学习模型的一些早期创新。
- en: In 1943, American scientists Walter Pitts and Warren McCullough created the
    world’s first computational model for neural networks. This formed the basis for
    other innovations in AI, including Arthur Samuel’s self-improving checkers-playing
    program in 1952 and the **perceptron**, a neural network for classifying images
    funded by the US Navy and IBM in 1958.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在1943年，美国科学家沃尔特·皮茨和沃伦·麦克库洛赫创造了世界上第一个神经网络计算模型。这为人工智能的其他创新奠定了基础，包括1952年亚瑟·塞缪尔的自改进国际象棋程序和由美国海军和IBM资助的1958年的**感知器**，这是一个用于图像分类的神经网络。
- en: In 1950, British mathematician and computer scientist Alan Turing introduced
    the *Turing test* for assessing a computer’s ability to perform intelligent operations
    comparable to those of humans. The test was often used as a benchmark for the
    *intelligence* of a computer and became very influential to the philosophy of
    AI in general.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在1950年，英国数学家和计算机科学家艾伦·图灵提出了用于评估计算机执行与人类相当智能操作的*图灵测试*。这个测试常被用作衡量计算机*智能*的基准，并对人工智能的一般哲学产生了深远的影响。
- en: The expansion of ML research continued throughout the 1960s, with the development
    of the nearest neighbor algorithm being one of the most noticeable advances. The
    work of Stanford researchers Thomas Cover and Peter Hart formed the basis for
    the rise of the k-nearest neighbor algorithm as a powerful statistical classification
    method4.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习研究在20世纪60年代继续扩展，其中最近邻算法的发展是最显著的进步之一。斯坦福研究人员托马斯·科弗和彼得·哈特的工作为k-最近邻算法作为一种强大的统计分类方法的出现奠定了基础4。
- en: In 1965, co-founder of Fairchild Semiconductor and Intel, Gordon Moore proposed
    that processing power and hard drive storage for computers would double every
    two years, also known as *Moore’s law*5\. Even though Moore’s law proved to be
    reasonably accurate, it would take many decades to reach a point where vast amounts
    of data could be processed at a reasonable speed and cost.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在1965年，Fairchild半导体和Intel的联合创始人戈登·摩尔提出了一个观点，即计算机的处理能力和硬盘存储容量每两年会翻一番，这也被称为*摩尔定律*5。尽管摩尔定律被证明是相当准确的，但要达到一个可以以合理速度和成本处理大量数据的地步，还需要许多十年。
- en: To put things into perspective, IBM’s leading product in 1970 was the System/370
    Model 145, which had 500 KB of RAM and 233 MB of hard disk space6\. The computer
    took up a whole room and cost $705,775 to $1,783,0007, circa $5 to $13 million
    in today’s inflation-adjusted dollars. At the time of writing, the latest iPhone
    14 has 12,000 times the amount of RAM and up to 2,200 times the amount of hard
    disk space of the System/370 Model 145, depending on the iPhone configuration8.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更清楚地说明问题，IBM在1970年的主要产品是System/370 Model 145，它有500 KB的RAM和233 MB的硬盘空间6。这台计算机占据了整整一个房间，成本为705,775美元到1,783,000美元7，约合今天的5到13百万美元。在撰写本文时，最新的iPhone
    14的RAM是System/370 Model 145的12,000倍，硬盘空间高达2,200倍，具体取决于iPhone的配置8。
- en: '![Figure 2.1 – The IBM System/370 Model 145\. Everything in this picture is
    part of the computer’s operation (except the clock on the wall). Source: Jean
    Weber/INRA, DIST](img/B19297_02_1.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1 – IBM System/370 Model 145\. 这张图片中的所有东西都是计算机操作的一部分（除了墙上的时钟）。来源：Jean
    Weber/INRA, DIST](img/B19297_02_1.jpg)'
- en: 'Figure 2.1 – The IBM System/370 Model 145\. Everything in this picture is part
    of the computer’s operation (except the clock on the wall). Source: Jean Weber/INRA,
    DIST'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 – IBM System/370 Model 145\. 这张图片中的所有东西都是计算机操作的一部分（除了墙上的时钟）。来源：Jean Weber/INRA,
    DIST
- en: Most of the 1970s are widely recognized as a period of “AI Winter” – a period
    with very little ground-breaking research or developments in the field of AI.
    The business world saw little short-term potential in AI, mainly because computer
    processing power and data storage capacity were underdeveloped and prohibitively
    expensive.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 20世纪70年代的大部分时间被广泛认为是“人工智能寒冬”的时期——在这个时期，人工智能领域几乎没有突破性的研究或发展。商业界对人工智能的短期潜力看得很低，主要是因为计算机处理能力和数据存储容量尚未充分发展，且成本高昂。
- en: The 1980s to 1990s – the rise of personal computing and the internet
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1980年代到1990年代——个人电脑和互联网的兴起
- en: In 1982, IBM introduced the first personal computer (IBM PC), which sparked
    a revolution in computer technology at work and in people’s homes. It also led
    to the meteoric rise of companies such as Apple, Microsoft, Hewlett-Packard, Intel,
    and many other hardware and software enterprises that rode the wave of technological
    innovation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 1982年，IBM推出了第一台个人电脑（IBM PC），这引发了工作场所和人们家庭中计算机技术的革命。它还导致了苹果、微软、惠普、英特尔和其他许多硬件和软件企业如流星般崛起，这些企业乘上了技术创新的浪潮。
- en: The increased ability to digitize processes and information also amplified the
    corporate world’s interest in using stored data for analytical purposes. Relational
    databases became mainstream, at the expense of network and hierarchical database
    models9.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 处理和信息的数字化能力的提高也加剧了企业界对使用存储数据进行分析目的的兴趣。关系型数据库成为主流，以牺牲网络和层次数据库模型为代价。
- en: The query language SQL was developed in the 1970s; throughout the 1980s, it
    became widely accepted as the main database language, achieving the ISO and ANSI
    certifications in 198610.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: SQL查询语言在20世纪70年代开发；在整个80年代，它成为主要的数据库语言，并在1986年获得了ISO和ANSI认证。
- en: The explosion in digital information created a need for new techniques to make
    sense of data from a statistical point of view. Stanford University researchers
    developed the first software to generate classification and regression trees in
    1984, and innovations such as the lexical database WordNet created the early foundations
    for text analysis and natural language processing.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数字信息的爆炸性增长需要新的技术来从统计角度理解数据。斯坦福大学的研究人员在1984年开发了第一个生成分类和回归树的软件，而像WordNet这样的词汇数据库创新为文本分析和自然语言处理奠定了早期基础。
- en: Personal computers continued to replace typewriters and mainframes into the
    1990s, which allowed for the World Wide Web to be formed in 1991\. Websites, blogs,
    internet forums, emails, instant messages, and VoIP calls created yet another
    explosion in the volume, variety, and velocity of data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 个人电脑继续在20世纪90年代取代打字机和大型机，这促使万维网在1991年形成。网站、博客、互联网论坛、电子邮件、即时消息和VoIP电话又引发了数据量、种类和速度的另一次爆炸性增长。
- en: As a result, new methods for organizing more complex and disparate types of
    data evolved. Gradient boosting algorithms such as AdaBoost and gradient boosting
    machines were developed by Stanford researchers throughout the late nineties,
    paving the way for search engines to rank all sorts of information.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，新的方法逐渐发展起来，用于组织更复杂和不同类型的数据。例如，AdaBoost和梯度提升机等梯度提升算法在90年代末由斯坦福研究人员开发，为搜索引擎对各种信息进行排序铺平了道路。
- en: The rise of the internet also created a huge business opportunity for those
    who could organize the information on it. Companies such as Amazon, Alibaba, Yahoo!,
    and Google were founded during this period to fight for dominance in e-commerce
    and web search. These companies saw enormous potential in computer science, AI,
    and ML and invested heavily in developing algorithms to manage their vast stores
    of information.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网的兴起也为那些能够组织其上信息的人创造了巨大的商业机会。在此期间，亚马逊、阿里巴巴、雅虎和谷歌等公司成立，争夺电子商务和网页搜索的主导地位。这些公司看到了计算机科学、人工智能和机器学习的巨大潜力，并大量投资于开发算法来管理他们庞大的信息库。
- en: The 2000s – the rise of tech giants
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2000年代——科技巨头的崛起
- en: ML research picked up pace throughout the 2000s, whether it be in universities
    or corporate **research and development** (**R&D**) departments. Computer processing
    power had finally reached a point where large-scale data processing was feasible
    for most corporations and researchers.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习研究在2000年代全速前进，无论是在大学还是在企业的**研发部门**（**R&D**）。计算机处理能力终于达到了大多数公司和研究人员可以进行大规模数据处理的水平。
- en: While internet search engine providers were busy developing algorithms to sort
    and categorize the ever-growing information being published online, university
    researchers were creating new tools and techniques that would fuel the evolution
    of ML.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当互联网搜索引擎提供商忙于开发算法来排序和分类在线发布的不断增长的信息时，大学研究人员正在创造新的工具和技术，这些工具和技术将推动机器学习的演变。
- en: In 2003, The R Foundation was created to develop and support the open source
    ML tool and programming language R. As a freely available and open source programming
    language for statistical computing and graphics11, R significantly lowered the
    barrier to entry for researchers looking to use statistical programming in their
    work and for data enthusiasts wanting to practice and learn ML techniques.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 2003年，R基金会成立，旨在开发和支持开源机器学习工具和编程语言R。作为统计计算和图形的免费开源编程语言，R显著降低了研究人员在工作中使用统计编程的门槛，以及数据爱好者练习和学习机器学习技术的门槛。
- en: Random Forest algorithms were introduced in 2001 and later patented in 2006
    by statisticians and ML pioneers Leo Breiman from the University of California,
    Berkley, and Adele Cutler from Utah State University12.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林算法于2001年推出，并在2006年由加州大学伯克利分校的统计学家和机器学习先驱Leo Breiman以及犹他州立大学的Adele Cutler获得专利。
- en: Stanford professor Fei-Fei Li introduced the ImageNet project in 2008 as a free
    and open image database for training object recognition models13\. The database
    was created to provide a high-quality, standardized dataset for object categorization
    models to be trained and benchmarked on. At the time of writing, ImageNet contains
    more than 14 million labeled images, organized according to the WordNet hierarchy.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 斯坦福大学教授李飞飞在2008年推出了ImageNet项目，作为一个免费和开放的图像数据库，用于训练对象识别模型。该数据库的创建是为了提供一个高质量、标准化的数据集，用于训练和基准测试对象分类模型。截至撰写本文时，ImageNet包含超过1400万张标记的图像，按照WordNet层次结构组织。
- en: This period also saw the meteoric rise of the network-based business model as
    a way to create internet dominance. Social media platforms such as LinkedIn, Facebook,
    Twitter, and YouTube were launched during this period and became supernational
    tech giants by using ML algorithms to organize information and content created
    by their users.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这个时期也见证了基于网络的商业模式如雨后春笋般崛起，成为创造互联网霸权的一种方式。LinkedIn、Facebook、Twitter和YouTube等社交媒体平台在这个时期推出，并利用机器学习算法组织用户创建的信息和内容，成为了跨国的科技巨头。
- en: As data volumes exploded, so did the need for cheap and flexible data storage.
    Cloud compute and storage services such as AWS, Dropbox, and Google Drive were
    launched, while universities joined forces with Google and IBM to establish server
    farms that could be used for data-intensive research14\. Increasingly, the availability
    of processing power was now based on the user’s economic justification rather
    than technical limitations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据量的激增，对廉价且灵活的数据存储的需求也随之增加。AWS、Dropbox和Google Drive等云计算和存储服务应运而生，而大学与谷歌和IBM合作建立了服务器农场，用于数据密集型研究。日益增多的是，处理能力的可用性现在基于用户的成本效益而非技术限制。
- en: 2010–now – big data drives AI innovation
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2010年至今 – 大数据推动人工智能创新
- en: Network-based businesses continued to define the direction for the internet
    and ML development. Search engines, social media platforms, and software and hardware
    providers invested heavily in R&D activities surrounding AI. As an example, the
    Google Brain research team was founded in 2011 to provide cutting-edge AI research
    on big data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基于网络的商业模式继续为互联网和机器学习的发展指明方向。搜索引擎、社交媒体平台以及软件和硬件提供商在围绕人工智能的R&D活动上投入了大量资金。例如，谷歌大脑研究团队成立于2011年，旨在提供关于大数据的前沿人工智能研究。
- en: New network-based companies were disrupting industries such as taxis, hotels,
    travel services, payments, restaurant and food services, media, music, banking,
    consumer retail, and education – utilizing digital platforms, ML, and vast amounts
    of consumer data as their powerful competitive advantage.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 新的基于网络的公司正在颠覆出租车、酒店、旅游服务、支付、餐饮和食品服务、媒体、音乐、银行、消费零售和教育等行业，利用数字平台、机器学习和大量消费者数据作为其强大的竞争优势。
- en: Traditional research institutions formed tight collaborations with big tech
    companies, resulting in big leaps in deep learning techniques for audio and image
    recognition, natural language understanding, anomaly detection, synthetic data
    generation, and much more.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 传统研究机构与大型科技公司紧密合作，在音频和图像识别、自然语言理解、异常检测、合成数据生成等领域，深度学习技术取得了重大突破。
- en: By 2017, three out of four teams competing in the annual ImageNet Challenge
    achieved greater than 95% accuracy, proving that image recognition algorithms
    were now highly advanced.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 到2017年，在年度ImageNet挑战赛中，四分之三的参赛团队达到了95%以上的准确率，证明了图像识别算法现在已经非常先进。
- en: Powerful algorithms for generating new data were also developed during this
    golden decade of AI. In 2014, a researcher from the Google Brain team named Ian
    Goodfellow invented the **Generative Adversarial Network** (**GAN**), a neural
    network that works by pairing two models against each other15\. Another form of
    generative model framework, the **Generative Pre-trained Transformer** (**GPT**),
    entered the scene in 2018, courtesy of the OpenAI research lab.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能的黄金十年中，也开发了用于生成新数据的有力算法。2014年，谷歌大脑团队的一名研究人员伊恩·古德费洛发明了**生成对抗网络**（**GAN**），这是一种通过配对两个模型相互竞争来工作的神经网络15。另一种生成模型框架，**生成预训练转换器**（**GPT**），在2018年由OpenAI研究实验室推出。
- en: With generative models in operation, it was now possible to produce *human-like*
    outputs such as text snippets, images, artwork, music, and deepfakes – audio and
    video impersonations of someone’s voice and mannerisms.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成模型运行的情况下，现在可以产生类似人类的输出，如文本片段、图像、艺术品、音乐和深度伪造——对某人声音和举止的音频和视频模仿。
- en: As *big data*, *ML*, and *AI* became part of the vernacular, the demand for
    analysts, data scientists, data engineers, and other data professionals increased
    substantially. In 2011, job listings for data scientists increased by 15,000%
    year on year16\. The massive enthusiasm for the potential of data and ML caused
    analytics pioneers Tom Davenport and DJ Patil to label data science as *the sexiest
    job of the 21*st *century* in 201217.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 随着“大数据”、“机器学习”和“人工智能”成为日常用语的一部分，对分析师、数据科学家、数据工程师和其他数据专业人士的需求大幅增加。2011年，数据科学家的职位空缺年增长率为1500%16。对数据和机器学习潜力的巨大热情导致分析先驱汤姆·达文波特和DJ帕蒂尔将数据科学称为21世纪的**最具魅力的工作**17。
- en: Millions of data enthusiasts around the world sought out places to learn the
    latest ML and data mining techniques. Platforms such as Kaggle and Coursera allowed
    millions of users to learn through open online courses, enter ML contests, access
    quality datasets, and share knowledge.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 全世界成千上万的数据爱好者都在寻找学习最新机器学习和数据挖掘技术的地方。Kaggle和Coursera等平台允许数百万用户通过公开在线课程学习，参加机器学习竞赛，访问高质量数据集，并分享知识。
- en: 'On the tooling front, the proliferation of freely downloadable software programs
    and packages running on R, Python, or SQL made it relatively easy to access advanced
    data science techniques at a low cost:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在工具方面，R、Python或SQL上运行的免费可下载软件程序和包的激增，使得以低成本访问高级数据科学技术变得相对容易：
- en: '![Figure 2.2 – A history of ML from 1940 to now](img/B19297_02_2.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2 – 从1940年到现在的机器学习历史](img/B19297_02_2.jpg)'
- en: Figure 2.2 – A history of ML from 1940 to now
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – 从1940年到现在的机器学习历史
- en: As the advancements in information technology, data, and AI converged during
    AI’s golden decade of 2010 to 2020, ML model architectures have matured significantly.
    At this point, most of the opportunities to create better models lie in improving
    data quality.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在2010年至2020年人工智能的黄金十年中，随着信息技术、数据和人工智能的进步，机器学习模型架构已经显著成熟。此时，大多数创造更好模型的机会在于提高数据质量。
- en: Model-centricity was the logical evolutionary outcome
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以模型为中心是逻辑上的进化结果
- en: The last eight decades of data science history have followed a logical evolutionary
    path that has led to model-centricity being the principal approach to ML.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学历史的最后八十年遵循了一条逻辑的进化路径，导致以模型为中心成为机器学习的主要方法。
- en: The ideas and mathematical concepts behind ML were imagined long before the
    technology was mature enough to match them. Before the 1990s, computers were not
    powerful enough to allow university researchers to evolve the field of ML substantially.
    These technical limitations also meant that there was limited research conducted
    for commercial gain by private enterprises during this period.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习背后的思想和数学概念在技术成熟到足以与之匹配之前就已经被构想出来了。在20世纪90年代之前，计算机的运算能力不足以让大学研究人员显著地发展机器学习领域。这些技术限制还意味着，在这一时期，私营企业为了商业利益进行的有限研究。
- en: At the advent of the internet era in the early 1990s, hardware and software
    solutions were beginning to be advanced enough to eliminate these age-old limitations.
    The internet also sparked an information revolution that increased the volume
    and variety of available data enormously. All of a sudden, ML was not just financially
    viable, it became the driving force behind tech companies such as Amazon, Yahoo!,
    and Google. With more digital information available than ever before, there was
    a need to advance the way we interpreted and modeled various kinds of data. In
    other words, ML research needed a model-centric focus first and foremost.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪90年代初互联网时代到来之际，硬件和软件解决方案开始变得足够先进，足以消除这些古老的限制。互联网还引发了一场信息革命，极大地增加了可用数据的数量和种类。突然之间，机器学习不仅在经济上可行，而且成为亚马逊、雅虎和谷歌等科技公司背后的驱动力。随着比以往任何时候都更多的数字信息可用，我们需要推进我们解释和建模各种数据的方式。换句话说，机器学习研究首先需要以模型为中心的关注点。
- en: Throughout the 2000s, a new kind of business model came to dominate our lives.
    Network-based digital businesses such as social media platforms, search engines,
    software creators, and online marketplaces created platforms where users could
    create and interact with content and products. By applying ML to massive amounts
    of user-generated data, these businesses watched and optimized every interaction
    along the way.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在2000年代，一种新型的商业模式开始主导我们的生活。基于网络的数字业务，如社交媒体平台、搜索引擎、软件创造者和在线市场，为用户提供了创建和互动内容与产品的平台。通过将机器学习应用于大量用户生成数据，这些业务在过程中观察并优化了每一次互动。
- en: These “AI-first” big tech businesses were less constrained by data quality or
    volume. Their constraints lay mostly in fast and affordable compute and storage
    capacity, and the sophistication of ML techniques. Through in-house research,
    partnerships with universities, and strategic investments in promising AI technologies,
    big tech companies have been able to drive the agenda for ML development over
    the last two decades. What these companies needed primarily was a model-centric
    approach.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这些“以AI为先”的大型科技公司受数据质量或数量的限制较小。它们的限制主要在于快速且经济的计算和存储能力，以及机器学习技术的复杂性。通过内部研究、与大学的合作以及战略投资于有希望的AI技术，大型科技公司在过去二十年里能够推动机器学习发展的议程。这些公司最需要的是以模型为中心的方法。
- en: As a result of the model-centric research that has occurred since the mid-1990s,
    we now have algorithms that can organize all the world’s information, identify
    individuals in a crowd, drive vehicles in open traffic, recognize and generate
    sound, speech, and imagery, and much more. Our ability to make accurate models
    *given the input data* is very advanced thanks to this period of innovation.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 自1995年中叶以来，由于以模型为中心的研究，我们现在拥有了能够组织全世界信息的算法，识别人群中的个体，在开放交通中驾驶车辆，识别和生成声音、语音和图像，以及更多。由于这一创新时期，我们根据输入数据构建准确模型的能力非常先进。
- en: 'As data continued to become a more ubiquitous asset, there was a sudden strong
    need to train more data scientists and other data professionals. Today, there
    is no shortage of learning opportunities through online learning platforms, university
    courses, and ML competitions, but they typically have one thing in common: the
    initial input dataset is predefined.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据成为更普遍的资产，突然出现了对更多数据科学家和其他数据专业人士的强烈需求。如今，通过在线学习平台、大学课程和机器学习竞赛，学习机会并不缺乏，但它们通常有一个共同点：初始输入数据集是预定义的。
- en: It makes a lot of sense to teach ML on a fixed dataset. Without a replicable
    output, it is difficult to verify whether learners have mastered a particular
    technique, or benchmark different models against each other. However, the natural
    consequence is that learning is centered around model improvement through model-centric
    tasks such as model selection, hyperparameter tuning, feature engineering, and
    other enhancements of the *existing* dataset.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在固定数据集上教授机器学习是有意义的。没有可复制的输出，很难验证学习者是否掌握了特定的技术，或者将不同的模型相互基准测试。然而，自然的结果是，学习以通过模型为中心的任务为中心，例如模型选择、超参数调整、特征工程和对现有数据集的其他增强。
- en: 'Model-centric skills must be mastered by experienced data scientists, but they
    are just the foundation of a data-centric paradigm. This is because ML progress
    comes in four parts:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 经验丰富的数据科学家必须掌握以模型为中心的技能，但它们只是以数据为中心范式的基础。这是因为机器学习的进步分为四个部分：
- en: Improving computer power
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提高计算机能力
- en: Improving algorithms
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 改进算法
- en: Improving data
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提高数据
- en: Improving measurement
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提高测量
- en: So far, we have made huge progress on items 1 and 2, to a point where they are
    largely a solved problem for the majority of ML use cases. Most of the opportunity
    now lies in evolving our approach to improving data and measurement. When we improve
    our data, we can build better models, but we also unlock the long tail of ML use
    cases that are often out of reach because we only have a few thousand rows (or
    less) of data to build our models on.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在第1点和第2点上取得了巨大的进步，到了它们在很大程度上已成为大多数机器学习用例的解决方案。现在，大部分机会在于我们改进数据和质量的方法。当我们改进我们的数据时，我们可以构建更好的模型，但我们还解锁了那些通常因为只有几千行（或更少）数据而无法触及的机器学习用例的长尾。
- en: Unlocking the opportunity for small data ML
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解锁小数据机器学习的机会
- en: The group of tech companies famously labeled *The Big Nine* by author Amy Webb18
    are examples of consumer internet companies that have leveraged big data and AI
    to build world dominance. Amazon, Apple, Alibaba, Baidu, Meta, Google, IBM, Microsoft,
    and Tencent dominate in the digital era because they utilize enormous amounts
    of user data to power their AI systems.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 被作者艾米·韦伯18称为“九大巨头”的科技企业群体是利用大数据和人工智能建立全球主导地位的消费互联网公司的典型例子。亚马逊、苹果、阿里巴巴、百度、Meta、谷歌、IBM、微软和腾讯在数字时代占据主导地位，因为他们利用了大量的用户数据来驱动他们的AI系统。
- en: As network-based *AI-first* businesses, they have amassed customers on an unprecedented
    scale because users are happy to co-create and share their data, so long as it
    is a net benefit to them. For the Big Nine, getting enough modeling data is rarely
    a problem, and investing in the most advanced ML capabilities is a virtuous circle
    that enables more market dominance.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 作为基于网络的“AI优先”企业，他们以前所未有的规模积累了客户，因为用户乐于共同创造并分享他们的数据，只要这对他们有净收益。对于九大巨头来说，获取足够的建模数据很少是问题，投资于最先进的机器学习能力是一个良性循环，这有助于增强市场主导地位。
- en: 'For most other organizations – and ML use cases – this sort of scale is unachievable.
    As we explored in [*Chapter 1*](B19297_01.xhtml#_idTextAnchor015), *Exploring
    Data-Centric Machine Learning* the long tail of ML opportunities doesn’t offer
    the option to build models on large volumes of training data because of the following
    challenges:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数其他组织和机器学习用例来说，这种规模是无法实现的。正如我们在[*第一章*](B19297_01.xhtml#_idTextAnchor015)中探讨的，*探索数据中心的机器学习*，机器学习机会的长尾并不提供在大量训练数据上构建模型的选择，因为以下挑战：
- en: '**The lack of training data observations**: Datasets are smaller in the long
    tail – typically in the order of only a few thousand rows or less. On top of that,
    most organizations are capturing data in the non-digitized physical world, which
    makes it harder to capture and finetune some data points.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏训练数据观察**：长尾中的数据集较小——通常只有几千行或更少。此外，大多数组织在非数字化的物理世界中捕获数据，这使得捕捉和微调某些数据点变得更加困难。'
- en: '**Dirty data**: Unlike network-based *AI-first* businesses, most organizations
    generate data through a large variety of sources such as internal (but externally
    developed) IT systems, third-party platforms, and manual collection by staff or
    customers. This creates a complex patchwork of data sources that come with a variety
    of data quality challenges.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**脏数据**：与基于网络的“AI优先”企业不同，大多数组织通过大量不同的来源生成数据，如内部（但外部开发）IT系统、第三方平台以及员工或客户的手动收集。这创造了一个复杂的数据来源拼凑，伴随着各种数据质量挑战。'
- en: '**Risk of bias and unfairness in high-stakes domains**: Poor data quality in
    high-stakes domains such as healthcare, legal services, education, public safety,
    and crime prevention may lead to disastrous impacts on individuals or vulnerable
    populations. For example, predicting whether a person has cancer based on medical
    images is a high-stakes activity – recommending the next video to watch based
    on your YouTube history video is not.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高风险领域的偏差和不公平风险**：在医疗保健、法律服务、教育、公共安全和犯罪预防等高风险领域，数据质量差可能导致对个人或弱势群体产生灾难性的影响。例如，根据医学图像预测一个人是否患有癌症是一项高风险活动——根据你的YouTube观看历史推荐下一个视频则不是。'
- en: '**Model complexity and lack of economies of scale**: Even though there is plenty
    of value to be found in the long tail, individual ML projects typically need a
    lot of customization to deal with distinct scenarios. Customization is costly
    as it creates an accumulation of many models, datasets, and processes that must
    be maintained pre- and post-model implementation.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型复杂性和缺乏规模经济**：尽管在长尾中可以找到大量价值，但单个机器学习项目通常需要大量定制来处理不同的场景。定制成本高昂，因为它会创建许多模型、数据集和流程的积累，这些必须在模型实施前后维护。'
- en: '**The need for domain expertise in data and model development**: The combination
    of small datasets, higher stakes, and more complex scenarios makes it difficult
    to build ML models without the involvement of subject-matter experts during data
    collection, labeling and validation, model development, and testing.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在数据和模型开发中需要领域专业知识**：小数据集、高风险和更复杂场景的结合使得在数据收集、标注和验证、模型开发和测试过程中，没有领域专家的参与很难构建机器学习模型。'
- en: It is important to note that many companies have the opportunity to unlock significant
    value with *small data* ML. For example, only a few organizations will have individual
    ML projects worth $50 million or more, but many more organizations will have 50
    potential ML opportunities worth $1 million each. In practice, this means we must
    get maximum value out of our raw material if we want smaller projects to become
    feasible and financially viable.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，许多公司有机会通过小数据机器学习解锁重大价值。例如，只有少数组织会有价值5000万美元或以上的单个机器学习项目，但许多组织会有50个潜在的价值100万美元的机器学习机会。在实践中，这意味着如果我们想让小型项目变得可行和具有财务可行性，我们必须从我们的原材料中获得最大价值。
- en: 'Dr Andrew Ng, CEO and founder of Landing AI, summarizes these challenges as
    follows19:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 安德鲁·吴博士，Landing AI的CEO和创始人，将这些挑战总结如下19：
- en: “In the consumer software Internet, we could train a handful of ML models to
    serve a billion users. In manufacturing, you might have 10,000 manufacturers building
    10,000 custom AI models.”
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: “在消费者软件互联网中，我们可以训练几个机器学习模型来服务十亿用户。在制造业，可能有1万家制造商正在构建1万家定制的AI模型。”
- en: “In many industries, where giant data sets simply don’t exist, I think the focus
    has to shift from big data to good data. Having 50 thoughtfully engineered examples
    can be sufficient to explain to the neural network what you want it to learn.”
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: “在许多行业中，由于大型数据集根本不存在，我认为重点必须从大数据转向优质数据。拥有50个精心设计的示例就足以向神经网络解释你希望它学习的内容。”
- en: '*Figure 2**.3* illustrates the challenge and opportunity of *small data* ML.
    While the low-hanging fruits of big data/high-value ML use cases have been picked
    by *AI-first* businesses, the long tail of small data/moderate value is underexploited.
    In reality, most ML use cases exist in the long tail of smaller datasets and low
    economies of scale. A strong focus on data quality is needed to make ML useful
    when datasets are small:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2.3* 展示了小数据机器学习的挑战和机遇。虽然大数据/高价值机器学习用例的低垂之果已被“以AI为先”的企业摘取，但小数据/中等价值的长尾尚未得到充分利用。实际上，大多数机器学习用例存在于小数据集和低规模经济的长尾中。当数据集较小时，需要高度重视数据质量，以使机器学习变得有用：'
- en: "![Figure 2.3 – \uFEFFThe long tail of ML opportunities](img/B19297_02_3.jpg)"
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图2.3 – 机器学习机会的长尾](img/B19297_02_3.jpg)'
- en: Figure 2.3 – The long tail of ML opportunities
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – 机器学习机会的长尾
- en: In the next section, we will explore the challenges in working with smaller
    and more complex datasets, and how you can overcome them.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨处理更小、更复杂的数据集的挑战，以及如何克服这些挑战。
- en: Why we need data-centric AI more than ever
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么我们比以往任何时候都需要以数据为中心的人工智能
- en: The leading organizations in AI, such as the Big Nine, have achieved incredible
    results with ML since the turn of the century, but how is AI being used in the
    long tail?
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 自世纪初以来，人工智能的领先组织，如“大九”，在机器学习方面取得了惊人的成果，但人工智能在长尾中的应用情况如何？
- en: A 2020 survey published by MIT Sloan Management Review and Boston Consulting
    Group concluded that most companies struggle to turn their vision for AI into
    reality. In a survey of over 3,000 business leaders from 29 industries in 112
    countries, 70% of respondents understood how AI can generate business value and
    57% had piloted or productionized AI solutions. However, only 1 in 10 had been
    able to generate significant financial benefits with AI.20
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 2020年由麻省理工学院斯隆管理评论和波士顿咨询集团发布的一项调查得出结论，大多数公司都难以将他们对人工智能的愿景变为现实。在对来自112个国家的29个行业的3000多名商业领袖的调查中，70%的受访者理解人工智能如何创造商业价值，57%的人已经试点或生产化了人工智能解决方案。然而，只有十分之一的人能够通过人工智能产生显著的财务收益20。
- en: 'The survey authors found that companies that were realizing significant financial
    benefits with AI had built their success on two pillars:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 调查作者发现，那些通过人工智能实现显著财务收益的公司，他们的成功建立在两个支柱之上：
- en: They had a solid foundation of the right data, technology, and talent.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们拥有正确的数据、技术和人才坚实的基础。
- en: They had defined several effective ways for humans and AI to work and learn
    together. In other words, they had created an iterative feedback loop between
    humans and AI, going from data collection and curation to solution deployment.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们定义了人类和人工智能共同工作和学习的一些有效方式。换句话说，他们创造了一个人类与人工智能之间的迭代反馈循环，从数据收集和整理到解决方案部署。
- en: Why are these two pillars critical to success with ML and AI? Because the ML
    model is only a small part of an ML system.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这两个支柱对机器学习和人工智能的成功至关重要？因为机器学习模型只是机器学习系统的一小部分。
- en: In 2015, Google researchers Sculley et al.21 published a seminal paper called
    *Hidden Technical Debt in Machine Learning Systems*, in which they describe how
    “*only a small fraction of real-world ML systems are composed of the ML code…
    the required surrounding infrastructure is vast* *and complex.*”
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在2015年，谷歌研究人员Sculley等人21发表了一篇开创性的论文，名为《机器学习系统中的隐藏技术债务》，在其中他们描述了“**只有一小部分现实世界的机器学习系统由机器学习代码组成……所需的环境基础设施庞大且复杂**”。
- en: In traditional information technology jargon, *technical debt* refers to the
    long-term costs incurred by cutting corners in the software development life cycle.
    It’s the hardcoded logic, the missing documentation, the lack of integration with
    other platforms, inefficient code, and anything else that is a roadblock to better
    system performance and future improvements. Technical debt can be “paid down”
    by removing these issues.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的信息技术术语中，**技术债务**指的是在软件开发生命周期中走捷径所造成的长期成本。它包括硬编码的逻辑、缺失的文档、与其他平台的集成不足、代码效率低下，以及其他任何阻碍系统性能提升和未来改进的因素。技术债务可以通过消除这些问题来“偿还”。
- en: 'ML systems are different in that they can carry technical debt in code, but
    they also have the added complexity that technical debt may exist in the data
    components of the system. Input data is the foundational ingredient in the system
    and the data is variable. Because ML models are driven by weighted impacts from
    many features in both data and code, a change in one variable may change the logical
    structure of the rest of the model. This is also known as the CACE principle:
    *Changing Anything* *Changes Everything*.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统不同之处在于它们可以在代码中承载技术债务，但它们还增加了技术债务可能存在于系统数据组件中的复杂性。输入数据是系统的基础成分，数据是可变的。由于机器学习模型是由数据和代码中许多特征加权影响驱动的，一个变量的变化可能会改变模型其余部分的逻辑结构。这也被称为CACE原则：**改变任何东西都会改变一切**。
- en: 'As illustrated in *Figure 2**.4*, a productionized ML system is much more than
    the model code. In a typical ML project, it is estimated that only 5-10% of the
    overall system is the model code22\. The remaining 90-95% of the solution is related
    to data and infrastructure:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如**图2.4**4所示，一个商业化的机器学习系统远不止模型代码。在一个典型的机器学习项目中，估计只有5-10%的系统是模型代码22。其余的90-95%的解决方案与数据和基础设施相关：
- en: "![Figure 2.4 – ML systems are much more than code. Source: Adapted from Sculley\
    \ et al\uFEFF., 2015](img/B19297_02_4.jpg)"
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图2.4 – 机器学习系统远不止代码。来源：改编自Sculley等人，2015](img/B19297_02_4.jpg)'
- en: 'Figure 2.4 – ML systems are much more than code. Source: Adapted from Sculley
    et al., 2015'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 – 机器学习系统远不止代码。来源：改编自Sculley等人，2015
- en: As Sculley et al. described, the data collection and curation activities in
    an ML solution are often significantly more resource-intensive than direct model
    development activities. Given this, data engineering should be a data scientist’s
    best friend. Yet, there is a disconnect between the importance of data quality
    and how most ML solutions are developed in practice.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如Sculley等人所描述，机器学习解决方案中的数据收集和整理活动通常比直接模型开发活动资源密集得多。鉴于这一点，数据工程应该是数据科学家的最佳伙伴。然而，数据质量的重要性与大多数机器学习解决方案在实际开发中的发展之间存在脱节。
- en: The cascading effects of data quality
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据质量级联效应
- en: In 2021, Google researchers Sambasivan et al.23 conducted a research study of
    the practices of 53 ML practitioners from the US, India, and East and West Africa
    working in a variety of industries. The study participants were selected from
    high-stakes domains such as healthcare, agriculture, finance, public safety, environmental
    conversation, and education.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在2021年，谷歌研究人员Sambasivan等人对来自美国、印度、东非和西非的53名机器学习从业者的实践进行了研究。研究参与者来自高风险领域，如医疗保健、农业、金融、公共安全、环境对话和教育。
- en: The purpose of the study was to identify and describe the downstream impact
    of data quality on ML systems and present empirical evidence of what they call
    *data cascades* – compounding negative effects stemming from data quality issues.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 研究的目的是确定和描述数据质量对机器学习系统的影响，并展示他们所说的*数据级联*的实证证据——由数据质量问题引起的累积负面效应。
- en: '**Data cascades** are caused by conventional model-centric ML practices that
    undervalue data quality and typically lead to invisible and delayed impacts on
    model performance – in other words, ML-specific technical debt. According to the
    researchers, data cascades are highly prevalent, with 92% of ML practitioners
    in the study experiencing one or more data cascades in a given project.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据级联**是由传统的以模型为中心的机器学习实践引起的，这些实践低估了数据质量，通常会导致对模型性能的不可见和延迟影响——换句话说，这是机器学习特有的技术债务。根据研究人员的说法，数据级联非常普遍，研究中92%的机器学习从业者在一个特定项目中经历过一个或多个数据级联。'
- en: The causes of data cascades fit into four categories explained in the following
    subsections.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 数据级联的原因可以分为以下小节中解释的四个类别。
- en: The perceived low value of data work and lack of reward systems
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据工作的感知价值低和缺乏奖励系统。
- en: 'There are often two underlying reasons for the lack of available data in the
    long tail of ML opportunities:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习机会的长尾中，数据不可用通常有两个潜在原因：
- en: Firstly, the events being modeled are bespoke and rare, so there is a physical
    limit to the amount of data that can be collected for a given use case
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，正在建模的事件是定制化和罕见的，因此对于特定用例可以收集的数据量有一个物理限制。
- en: Secondly, data collection and curation activities are considered relatively
    expensive and difficult, especially when they involve manual collection
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，数据收集和整理活动被认为是相对昂贵和困难的，尤其是在涉及手动收集时。
- en: In truth, most data-related work is not done by data scientists. The roles directly
    responsible for creating, collecting, and curating data are often performing these
    tasks as a secondary duty in their job. The responsibility of collecting high-quality
    data is frequently at odds with other duties because of competing priorities,
    time constraints, technical limitations of collection systems, or simply a lack
    of understanding of how to carry out good data collection.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，大多数与数据相关的工作并不是由数据科学家完成的。直接负责创建、收集和整理数据的角色通常将这些任务作为他们工作中的次要职责。由于优先级竞争、时间限制、收集系统的技术限制或简单地缺乏如何进行良好数据收集的理解，收集高质量数据的责任经常与其他职责相冲突。
- en: Take, for example, a hospital nurse who is responsible for a wide variety of
    tasks relating to the care of patients, some of which are data collection. High-quality
    data in healthcare has the potential to create huge benefits for patients and
    healthcare providers around the world if it can be aggregated and generalized
    through ML. However, for the individual nurse, there is more incentive to do the
    minimum required to document patient status and medical interventions, so more
    time can be spent on primary patient care. The typical result of this kind of
    scenario is suboptimal data collection in terms of depth of detail and consistency
    of labeling.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以医院护士为例，他们负责与患者护理相关的各种任务，其中一些是数据收集。如果可以通过机器学习进行聚合和推广，高质量的健康数据有可能为全球的患者和医疗保健提供者创造巨大的利益。然而，对于个别护士来说，完成记录患者状况和医疗干预措施所需的最少工作有更大的激励，这样就可以有更多的时间用于初级患者护理。这种场景的典型结果是数据收集在细节深度和标签一致性方面表现不佳。
- en: ML practitioners face a similar challenge further downstream. Sambasivan et
    al. describe how business and project goals such as cost, revenue, time to market,
    and competitive pressures lead data scientists to hurry through model development,
    leaving insufficient room for data quality and ethics concerns. As one practitioner
    states, *everyone wants to do the model work, not the* *data work*.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习实践者在下游也面临着类似的挑战。Sambasivan等人描述了商业和项目目标，如成本、收入、上市时间和竞争压力如何导致数据科学家匆忙进行模型开发，从而为数据质量和伦理问题留下不足的空间。正如一位实践者所说，*每个人都想做模型工作，而不是*
    *数据工作*。
- en: Lack of cross-functional collaboration
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缺乏跨职能协作
- en: When it comes to high-stakes or bespoke ML projects, subject-matter experts
    are often critical participants in upstream data collection as well as the ultimate
    consumers of model outputs.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到高风险或定制化的机器学习项目时，领域专家通常在数据收集的上游阶段是关键参与者，同时也是模型输出的最终消费者。
- en: On the face of it, subject-matter experts should be very willing to participate
    actively in ML projects because they get to reap the benefits of useful models.
    However, the opposite is often the case.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 表面上看，领域专家应该非常愿意积极参与机器学习项目，因为他们能够获得有用模型的益处。然而，情况往往相反。
- en: A requirement to collect additional information for ML purposes typically means
    that data collectors and curators have to work harder to get their job done. It
    can be difficult for frontline workers with limited data literacy to appreciate
    the importance of data collection, and unfortunately, the cascading effect of
    this conduct shows up much later in the project life cycle – often after deployment.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了机器学习目的而收集额外信息的要求通常意味着数据收集者和编纂者必须更加努力地完成工作。对于数据素养有限的前线工作者来说，可能很难理解数据收集的重要性，而且不幸的是，这种行为的级联效应往往在项目生命周期后期显现出来——通常是在部署之后。
- en: Data scientists should also play a critical role in data collection as they
    will make many decisions on how to interpret and manipulate datasets during model
    development. Therefore, an ML practitioner’s curiosity and willingness to understand
    the technical and social contexts of a given domain is a critical part of any
    project’s success. It is the invisible glue that makes ML solutions relevant and
    accurate.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家在数据收集中也应该扮演关键角色，因为他们将在模型开发过程中做出许多关于如何解释和操作数据集的决定。因此，机器学习实践者对特定领域的技术和社会背景的好奇心和愿意理解是任何项目成功的关键部分。它是使机器学习解决方案相关和准确的无形粘合剂。
- en: Unfortunately, data scientists often lack domain-specific expertise and rely
    on subject-matter experts to validate their interpretation of datasets. If ML
    practitioners do not constantly question their assumptions, rely too heavily on
    their technical expertise, and take the accuracy of input data for granted, they
    will miss the finer points of the context they’re trying to model. When this happens,
    ML projects will suffer from data cascades.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，数据科学家通常缺乏特定领域的专业知识，并依赖领域专家来验证他们对数据集的解释。如果机器学习实践者不不断质疑他们的假设，过度依赖他们的技术专长，并且理所当然地认为输入数据的准确性，他们就会错过他们试图建模的上下文的细微之处。当这种情况发生时，机器学习项目将遭受数据级联的影响。
- en: Insufficient cross-functional collaboration results in costly project challenges
    such as additional data collection, misinterpretation of results, and lack of
    trust in ML as a relevant solution to a given problem.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 跨职能协作不足会导致成本高昂的项目挑战，例如额外的数据收集、结果误解释以及对机器学习作为特定问题相关解决方案的信任缺失。
- en: Educational and knowledge gaps for ML practitioners
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习实践者的教育和知识差距
- en: Even the most technically skilled ML practitioners may fail to build useful
    models for real-life scenarios if they lack end-to-end knowledge of ML pipelines.
    Unfortunately, most learning paths for data scientists lack appropriate attention
    to data engineering practices.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是最技术娴熟的机器学习实践者，如果他们缺乏机器学习管道的端到端知识，也可能无法为现实场景构建有用的模型。不幸的是，大多数数据科学家的学习路径都缺乏对数据工程实践的适当关注。
- en: Graduate programs and online training courses are built on clean datasets, but
    real life is full of dirty data. Data scientists are simply not trained in building
    ML solutions from scratch, including data collection design, data management,
    and data governance processes, training data collectors, cleaning dirty data,
    and building domain knowledge.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 研究生课程和在线培训课程建立在干净的数据集之上，但现实生活中充满了脏数据。数据科学家并没有接受过从头开始构建机器学习解决方案的训练，包括数据收集设计、数据管理和数据治理流程、培训数据收集者、清理脏数据和构建领域知识。
- en: As a result, data engineering and MLOps practices are poorly understood and
    under-appreciated by those who are directly responsible for turning raw data into
    useful insights.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据工程和MLOps实践被那些直接负责将原始数据转化为有用洞察的人理解不足且评价不高。
- en: Lack of measurement of and accountability for data quality
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缺乏对数据质量的测量和问责
- en: Conventional ML practices rely on statistical accuracy tests, such as *precision*
    and *recall*, as proxies for model *and* data quality. These measures don’t provide
    any direct information on the quality of a dataset as it pertains to representing
    specific events and relevant situational context. The lack of standardized approaches
    for identifying and rectifying data quality issues early in the process makes
    data improvement work reactive, as opposed to planned and aligned to project goals.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的ML实践依赖于统计准确性测试，如*精确度*和*召回率*，作为模型*和*数据质量的代理。这些措施并不提供关于数据集质量直接信息的任何直接信息，这些信息与表示特定事件和相关的情境背景相关。在过程早期缺乏标准化的方法来识别和纠正数据质量问题，使得数据改进工作变得反应性，而不是有计划地与项目目标保持一致。
- en: The much-used management phrase *what gets measured gets managed* is also true
    in a data quality setting. Without appropriate processes in place for identifying
    data quality issues, it is difficult to incentivize and assign accountability
    to individuals for good data collection.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 广泛使用的管理短语“衡量什么，管理什么”在数据质量环境中也是正确的。如果没有适当的流程来识别数据质量问题，就难以激励和分配个人对良好数据收集的责任。
- en: The importance of assigning accountability for data quality in high-stakes domains
    is underpinned by the fact that model accuracy typically has to be very high,
    based on small datasets. For example, a poorly performing model in a low-risk
    and data-rich industry, such as online retailing or digital advertising, can be
    modified relatively quickly given the automated and persistent nature of data
    collection.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在高风险领域对数据质量进行问责的重要性得到了这样一个事实的支持：模型准确性通常必须非常高，基于小数据集。例如，在低风险且数据丰富的行业，如在线零售或数字广告，由于数据收集的自动化和持续性，一个表现不佳的模型可以相对快速地修改。
- en: ML models deployed in the long tail are often harder to validate because of
    a much lower frequency of events. At the same time, high-stakes domains typically
    demand a higher model accuracy threshold. Online advertisers can probably live
    with an accuracy score of 75%, but a model built for cancer diagnosis typically
    has to have an error rate of less than 1% to be viable.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在长尾部署的ML模型通常更难以验证，因为事件发生的频率要低得多。同时，高风险领域通常要求更高的模型准确性阈值。在线广告商可能可以接受75%的准确性分数，但用于癌症诊断的模型通常必须具有低于1%的错误率才能具有可行性。
- en: Avoiding data cascades and technical debt
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 避免数据级联和技术债务
- en: 'The pervasiveness of data cascades highlights a larger underlying problem:
    the dominant conventions in ML development are drawn from the practices of *big
    data* companies. These practices have been developed in an environment of plentiful
    and expendable data where each user has one account24\. Combine this with a culture
    of *move fast and break things*25 while viewing data work as undesirable drudgery,
    and you have an approach that will fail in most high-stakes domains.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 数据级联的普遍性突显了一个更大的潜在问题：ML开发中的主导惯例是从*大数据*公司的实践中借鉴的。这些实践是在数据丰富且可消耗的环境中开发的，每个用户都有一个账户24。结合“快速行动，打破事物”25的文化，将数据工作视为不受欢迎的苦差事，这种做法在大多数高风险领域都会失败。
- en: 'The cascading effects of poor data are opaque and hard to track in any standardized
    way, even though they occur frequently and persistently. Fortunately, data cascades
    are also fixable. Sambasivan et al. define the concept of *data excellence* as
    the solution: a cultural shift toward recognizing data management as a core business
    discipline and establishing the right processes and incentives for those who are
    a part of the ML pipeline.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量不佳的级联效应难以透明化和以标准化的方式追踪，尽管它们频繁发生且持续存在。幸运的是，数据级联也是可以修复的。Sambasivan等人将“数据卓越”定义为解决方案：一种文化转变，将数据管理视为核心业务学科，并为ML管道中的相关人员建立正确的流程和激励机制。
- en: As data professionals, it’s up to us to decide whether ML should remain a tool
    for the few or whether it’s time to allow projects with smaller financial value
    or higher stakes to become viable. To do this, we must strive for data excellence.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据专业人士，我们决定ML是否应该继续成为少数人的工具，或者是否是时候允许具有较小财务价值或更高风险的项目变得可行。为此，我们必须努力追求数据卓越。
- en: Now, let’s summarize the key takeaways from this chapter.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们总结本章的关键要点。
- en: Summary
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we reviewed the history of ML to give us a clear understanding
    of why model-centric ML is the dominant approach today. We also learned how a
    model-centric approach limits us from unlocking the potential value tied up in
    the long tale of ML opportunities.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了机器学习的历史，以帮助我们清楚地理解为什么以模型为中心的机器学习是当今占主导地位的方法。我们还学习了以模型为中心的方法如何限制我们从机器学习机会的长河中释放潜在价值。
- en: By now, you should have a strong appreciation for why data-centricity is needed
    for the discipline of ML to achieve its full potential but also recognize that
    it will require substantial effort to make the shift. To become an effective data-centric
    ML practitioner, old habits must be broken and new ones formed.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该已经深刻理解为什么数据中心化对于机器学习学科实现其全部潜力是必要的，同时也认识到这将需要巨大的努力来实现这一转变。要成为一名有效的数据中心化机器学习实践者，必须打破旧习惯并形成新习惯。
- en: Now, it’s time to start exploring the tools and techniques to make that shift.
    In the next chapter, we will discuss the principles of data-centric ML and the
    techniques and approaches associated with each principle.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候开始探索实现这一转变的工具和技术了。在下一章中，我们将讨论数据中心化机器学习的原则以及与每个原则相关的技术和方法。
- en: References
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[https://www.idc.com/getdoc.jsp?containerId=prUS47560321](https://www.idc.com/getdoc.jsp?containerId=prUS47560321),
    viewed on 23 September 2022'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.idc.com/getdoc.jsp?containerId=prUS47560321](https://www.idc.com/getdoc.jsp?containerId=prUS47560321)，于2022年9月23日查阅'
- en: Lewis, A. R., 2006, *The American Culture of War*, Routledge, New York, USA
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Lewis, A. R., 2006, *《美国的战争文化》*，Routledge，纽约，美国
- en: '[https://www.nasa.gov/feature/when-the-computer-wore-a-skirt-langley-s-computers-1935-1970](https://www.nasa.gov/feature/when-the-computer-wore-a-skirt-langley-s-computers-1935-1970),
    viewed on 23 September 2022'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.nasa.gov/feature/when-the-computer-wore-a-skirt-langley-s-computers-1935-1970](https://www.nasa.gov/feature/when-the-computer-wore-a-skirt-langley-s-computers-1935-1970)，于2022年9月23日查阅'
- en: '[https://www.historyofdatascience.com/k-nearest-neighbors-algorithm-classification-and-regression-star/](https://www.historyofdatascience.com/k-nearest-neighbors-algorithm-classification-and-regression-star/),
    viewed on 23 September 2022'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.historyofdatascience.com/k-nearest-neighbors-algorithm-classification-and-regression-star/](https://www.historyofdatascience.com/k-nearest-neighbors-algorithm-classification-and-regression-star/)，于2022年9月23日查阅'
- en: '[http://large.stanford.edu/courses/2012/ph250/lee1/docs/Excepts_A_Conversation_with_Gordon_Moore.pdf](http://large.stanford.edu/courses/2012/ph250/lee1/docs/Excepts_A_Conversation_with_Gordon_Moore.pdf),
    viewed on 23 September 2022'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[http://large.stanford.edu/courses/2012/ph250/lee1/docs/Excepts_A_Conversation_with_Gordon_Moore.pdf](http://large.stanford.edu/courses/2012/ph250/lee1/docs/Excepts_A_Conversation_with_Gordon_Moore.pdf)，于2022年9月23日查阅'
- en: '[https://www.businessinsider.com/ibm-1970-mainframe-specs-are-ridiculous-today-2014-5](https://www.businessinsider.com/ibm-1970-mainframe-specs-are-ridiculous-today-2014-5),
    viewed on 22 September 2022'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.businessinsider.com/ibm-1970-mainframe-specs-are-ridiculous-today-2014-5](https://www.businessinsider.com/ibm-1970-mainframe-specs-are-ridiculous-today-2014-5)，于2022年9月22日查阅'
- en: '[https://www.ibm.com/ibm/history/exhibits/mainframe/mainframe_PP3145.html](https://www.ibm.com/ibm/history/exhibits/mainframe/mainframe_PP3145.html),
    viewed on 22 September 2022'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.ibm.com/ibm/history/exhibits/mainframe/mainframe_PP3145.html](https://www.ibm.com/ibm/history/exhibits/mainframe/mainframe_PP3145.html)，于2022年9月22日查阅'
- en: '[https://www.apple.com/au/iphone-14/specs/](https://www.apple.com/au/iphone-14/specs/),
    viewed on 23 September 2022'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.apple.com/au/iphone-14/specs/](https://www.apple.com/au/iphone-14/specs/)，于2022年9月23日查阅'
- en: '[https://www.quickbase.com/articles/timeline-of-database-history](https://www.quickbase.com/articles/timeline-of-database-history),
    viewed on 24 September 2022'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.quickbase.com/articles/timeline-of-database-history](https://www.quickbase.com/articles/timeline-of-database-history)，于2022年9月24日查阅'
- en: '[https://www.dataversity.net/brief-history-database-management/](https://www.dataversity.net/brief-history-database-management/),
    viewed on 24 September 2022'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.dataversity.net/brief-history-database-management/](https://www.dataversity.net/brief-history-database-management/)，于2022年9月24日查阅'
- en: '[https://www.r-project.org/about.html](https://www.r-project.org/about.html),
    viewed on 24 September 2022'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.r-project.org/about.html](https://www.r-project.org/about.html)，于2022年9月24日查阅'
- en: '[https://www.historyofdatascience.com/leo-breiman-statistics-at-the-service-of-others/](https://www.historyofdatascience.com/leo-breiman-statistics-at-the-service-of-others/),
    viewed on 24 September 2022'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.historyofdatascience.com/leo-breiman-statistics-at-the-service-of-others/](https://www.historyofdatascience.com/leo-breiman-statistics-at-the-service-of-others/)，于2022年9月24日查阅'
- en: '[https://www.image-net.org/about.php](https://www.image-net.org/about.php),
    viewed on 24 September 2022'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.image-net.org/about.php](https://www.image-net.org/about.php),
    查阅于2022年9月24日'
- en: '[https://www.dataversity.net/brief-history-cloud-computing/](https://www.dataversity.net/brief-history-cloud-computing/),
    viewed on 25 September 2022'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.dataversity.net/brief-history-cloud-computing/](https://www.dataversity.net/brief-history-cloud-computing/),
    查阅于2022年9月25日'
- en: '[https://thenextweb.com/news/2010-2019-the-rise-of-deep-learning](https://thenextweb.com/news/2010-2019-the-rise-of-deep-learning),
    viewed on 25 September 2022'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://thenextweb.com/news/2010-2019-the-rise-of-deep-learning](https://thenextweb.com/news/2010-2019-the-rise-of-deep-learning),
    查阅于2022年9月25日'
- en: '[https://www.dataversity.net/brief-history-data-science/](https://www.dataversity.net/brief-history-data-science/),
    viewed on 25 September 2022'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.dataversity.net/brief-history-data-science/](https://www.dataversity.net/brief-history-data-science/),
    查阅于2022年9月25日'
- en: '[https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century),
    viewed on 25 September 2022'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century),
    查阅于2022年9月25日'
- en: 'Webb, A., 2019, *The Big Nine: How Tech Titans and Their Thinking Machines
    Could Warp Humanity*, Hachette Book Group, New York, USA'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Webb, A., 2019, *The Big Nine: How Tech Titans and Their Thinking Machines
    Could Warp Humanity*, Hachette Book Group, 纽约，美国'
- en: '[https://spectrum.ieee.org/andrew-ng-data-centric-ai](https://spectrum.ieee.org/andrew-ng-data-centric-ai),
    viewed on 25 September 2022'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://spectrum.ieee.org/andrew-ng-data-centric-ai](https://spectrum.ieee.org/andrew-ng-data-centric-ai),
    查阅于2022年9月25日'
- en: Ransbotham, S., Khodabandeh, S., Kiron, D., Candelon, F., Chu, M., and LaFountain,
    B., *Expanding AI’s Impact With Organizational Learning*, MIT Sloan Management
    Review and Boston Consulting Group, October 2020
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ransbotham, S., Khodabandeh, S., Kiron, D., Candelon, F., Chu, M., and LaFountain,
    B., *Expanding AI’s Impact With Organizational Learning*, MIT Sloan Management
    Review and Boston Consulting Group, 2020年10月
- en: '[https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf),
    Sculley et al., 2015, viewed 23 July 2022,'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf),
    Sculley et al., 2015, 查阅于2022年7月23日，'
- en: Yang, K., 2022, *Landing AI – Moving Beyond the Software* *Industry*, [https://community.ai-infrastructure.org/public/videos/landing-ai-ai-moving-beyond-the-software-industry-2022-09-30](https://community.ai-infrastructure.org/public/videos/landing-ai-ai-moving-beyond-the-software-industry-2022-09-30)
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Yang, K., 2022, *Landing AI – Moving Beyond the Software* *Industry*, [https://community.ai-infrastructure.org/public/videos/landing-ai-ai-moving-beyond-the-software-industry-2022-09-30](https://community.ai-infrastructure.org/public/videos/landing-ai-ai-moving-beyond-the-software-industry-2022-09-30)
- en: Sambasivan, N., Kapania, S., Highfill, H., Akrong, D., Paritosh, P., Aroyo,
    L., 2021, *Everyone wants to do the model work, not the data work:* *Data Cascades
    in* *High-Stakes AI*
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Sambasivan, N., Kapania, S., Highfill, H., Akrong, D., Paritosh, P., Aroyo,
    L., 2021, *Everyone wants to do the model work, not the data work:* *Data Cascades
    in* *High-Stakes AI*
- en: '[https://hbr.org/2019/01/the-era-of-move-fast-and-break-things-is-over](https://hbr.org/2019/01/the-era-of-move-fast-and-break-things-is-over),
    viewed on 8 October 2022'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://hbr.org/2019/01/the-era-of-move-fast-and-break-things-is-over](https://hbr.org/2019/01/the-era-of-move-fast-and-break-things-is-over),
    查阅于2022年10月8日'
- en: 'Part 2: The Building Blocks of Data-Centric ML'
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分：数据驱动机器学习的构建模块
- en: In this part, we lay the groundwork for data-centric ML with four key principles
    that underpin this approach, giving you essential context before exploring specific
    techniques. Then we explore human-centric and non-technical approaches to data
    quality, examining how expert knowledge, trained labelers, and clear instructions
    can enhance your ML output.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分中，我们通过四个关键原则为数据驱动机器学习奠定基础，这些原则支撑了这种方法，在探索具体技术之前，为您提供必要的背景知识。然后我们探讨了以人为中心和非技术性的数据质量方法，考察了专家知识、训练有素的标注员和清晰的指示如何增强您的机器学习输出。
- en: 'This part has the following chapters:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 3*](B19297_03.xhtml#_idTextAnchor043)*, Principles of Data-Centric
    ML*'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第3章*](B19297_03.xhtml#_idTextAnchor043)*, 数据驱动机器学习的原则*'
- en: '[*Chapter 4*](B19297_04.xhtml#_idTextAnchor056)*, Data Labeling Is a Collaborative
    Process*'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第4章*](B19297_04.xhtml#_idTextAnchor056)*, 数据标注是一个协作过程*'
