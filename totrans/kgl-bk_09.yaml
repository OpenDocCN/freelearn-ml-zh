- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Modeling for Tabular Competitions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Until 2017, there was no need to distinguish too much between competition types
    and, since the vast majority of competitions were based on tabular data, you could
    not even find mention of “tabular competitions” on Kaggle forums. Suddenly, something
    changed. After a relative shortage of competitions (see [https://www.kaggle.com/general/49904](https://www.kaggle.com/general/49904)),
    deep learning competitions took the upper hand and tabular competitions became
    rarer, disappointing many. They became so rare that Kaggle recently had to launch
    a series of tabular competitions based on synthetic data. What happened?
  prefs: []
  type: TYPE_NORMAL
- en: By 2017-2018, data science had grown to full maturity and many companies had
    initiated their data journeys. Data science was still a hot topic, but no longer
    such an uncommon one. Solutions to problems similar to those that had populated
    Kaggle for years at the time had become standard practice in many companies. Under
    these circumstances, sponsors were less motivated to launch external tabular competitions,
    since they were already dealing with the same problems internally. By contrast,
    deep learning is still a much-undiscovered domain and will continue to be for
    a long time, so it makes sense to start competitions to challenge the state of
    the art and see if something new emerges.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss tabular competitions. We will touch on some
    famous historical ones and also focus on the more recent reality of the Tabular
    Playground Series, because tabular problems are standard practice for the majority
    of data scientists around and there really is a lot to learn from Kaggle. We will
    start by discussing **exploratory data analysis** (**EDA**) and **feature engineering**,
    two common activities in these competitions.
  prefs: []
  type: TYPE_NORMAL
- en: After presenting key strategies for feature engineering, we will expand to many
    related topics, such as categorical encoding, feature selection, target transformations,
    and pseudo-labeling. We will end by touching on deep learning methodologies for
    tabular data, presenting a few specialized deep neural networks such as TabNet
    and illustrating a denoising autoencoder. We will explain why autoencoders have
    become so relevant for recent Kaggle competitions while still being marginal in
    real-world applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: The Tabular Playground Series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting a random state for reproducibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The importance of EDA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing the size of your data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying feature engineering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pseudo-labeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Denoising with autoencoders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks for tabular competitions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The chapter won’t cover every topic related to tabular competitions, but you
    can easily find this in many other books since they are at the core of data science.
    What this chapter will do is present a range of special techniques and approaches
    that characterize tabular competitions on Kaggle and that you won’t easily find
    elsewhere, except on Kaggle forums.
  prefs: []
  type: TYPE_NORMAL
- en: The Tabular Playground Series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Due to the large demand for tabular problems, Kaggle staff started an experiment
    in 2021, launching a monthly contest called the Tabular Playground Series. The
    contests were based on synthetic datasets that replicated public data or data
    from previous competitions. The synthetic data was created thanks to a deep learning
    generative network called **CTGAN**.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the CTGAN code at [https://github.com/sdv-dev/CTGAN](https://github.com/sdv-dev/CTGAN).
    There’s also a relevant paper explaining how it works by modeling the probability
    distribution of rows in tabular data and then generating realistic synthetic data
    (see [https://arxiv.org/pdf/1907.00503v2.pdf](https://arxiv.org/pdf/1907.00503v2.pdf)).
  prefs: []
  type: TYPE_NORMAL
- en: '*Synthetic Data Vault* ([https://sdv.dev/](https://sdv.dev/)), an MIT initiative,
    created the technology behind CTGAN and quite a number of tools around it. The
    result is a set of open-source software systems built to help enterprises generate
    synthetic data that mimics real data; it can help data scientists to create anonymous
    datasets based on real ones, as well as augment existing ones for modeling purposes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kaggle launched 13 fairly successful competitions in 2021, which have attracted
    many Kagglers despite not offering points, medals, or prizes (only some merchandise).
    Here is the 2021 list; you can use it to locate specific problems by type or metric
    and look for related resources such as focused discussions or Notebooks:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Month** | **Problem** | **Variables** | **Metric** | **Missing data** |'
  prefs: []
  type: TYPE_TB
- en: '| **January 2021** | Regression on an unspecified problem | Numeric | RMSE
    | No |'
  prefs: []
  type: TYPE_TB
- en: '| **February 2021** | Regression predicting the value of an insurance claim
    | Numeric and categorical | RMSE | No |'
  prefs: []
  type: TYPE_TB
- en: '| **March 2021** | Binary classification predicting an insurance claim | Numeric
    and categorical | AUC | No |'
  prefs: []
  type: TYPE_TB
- en: '| **April 2021** | Binary classification on a replica very similar to the original
    Titanic dataset | Numeric and categorical | Accuracy | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| **May 2021** | Multiclass classification predicting the category on an e-commerce
    product given various attributes about the listing | Categorical | Multiclass
    LogLoss | No |'
  prefs: []
  type: TYPE_TB
- en: '| **June 2021** | Multiclass classification predicting the category on an e-commerce
    product given various attributes about the listing | Numeric and categorical |
    Multiclass LogLoss | No |'
  prefs: []
  type: TYPE_TB
- en: '| **July 2021** | Multiple regression predicting air pollution in a city via
    various input sensor values (for example, a time series) | Numeric, time | RMSLE
    | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| **August 2021** | Regression calculating the loss associated with a loan
    default | Numeric | RMSE | No |'
  prefs: []
  type: TYPE_TB
- en: '| **30 Days of ML** | Regression on the value of an insurance claim | Numeric
    and categorical | RMSE | No |'
  prefs: []
  type: TYPE_TB
- en: '| **September 2021** | Binary classification predicting whether a claim will
    be made on an insurance policy | Numeric | AUC | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| **October 2021** | Binary classification predicting the biological response
    of molecules given various chemical properties | Numeric and categorical | AUC
    | No |'
  prefs: []
  type: TYPE_TB
- en: '| **November 2021** | Binary classification identifying spam emails via various
    features extracted from the email | Numeric | AUC | No |'
  prefs: []
  type: TYPE_TB
- en: '| **December 2021** | Multiclass classification based on the original *Forest
    Cover Type Prediction* competition | Numeric and categorical | Multiclass classification
    accuracy | No |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7.1: Tabular Playground Series competitions in 2021'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Tabular Playground competitions continued in 2022, with even more sophisticated
    and challenging problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **January 2022** | Forecasting the sales of Kaggle merchandise from two fictitious
    independent store chains | Dates and categorical | Symmetric mean absolute percentage
    error (SMAPE) | No |'
  prefs: []
  type: TYPE_TB
- en: '| **February 2022** | Classifying 10 different bacteria species using data
    from a genomic analysis technique that contains some data compression and data
    loss | Numeric | Categorization accuracy | No |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7.2: Tabular Playground Series competitions in 2022'
  prefs: []
  type: TYPE_NORMAL
- en: Much of this chapter has been written by observing the code and discussion that
    emerged in these competitions, instead of analyzing more glorious competitions
    from the past. As we mentioned, we believe that tabular competitions are indeed
    gone for good given the changed professional landscape, and that you will find
    it more useful to read suggestions and hints relating to the present than the
    past.
  prefs: []
  type: TYPE_NORMAL
- en: 'As in other fully fledged competitions with Kaggle points and medals, in tabular
    competitions we recommend you follow a simple, yet very effective, pipeline that
    we have discussed elsewhere in the book:'
  prefs: []
  type: TYPE_NORMAL
- en: Explorative data analysis (EDA)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling (using a cross-validation strategy for model validation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Post-processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Submission
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a rule, you also have to take care to maintain reproducibility and to save
    all the models (from every fold), the list of the parameters used, all the fold
    predictions, all the out-of-fold predictions, and all predictions from models
    trained on all the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should save all this information in a way that makes it easy to recover
    and reconstruct, for instance using appropriate labeling, keeping track of MD5
    hashing values (you can refer to this Stack Overflow answer for details: [https://stackoverflow.com/questions/16874598/how-do-i-calculate-the-md5-checksum-of-a-file-in-python](https://stackoverflow.com/questions/16874598/how-do-i-calculate-the-md5-checksum-of-a-file-in-python)),
    and tracking the CV scores and leaderboard results from each experiment. Most
    Kagglers do this with simple tools such as `.txt` files or Excel spreadsheets,
    but there exist ways that are more sophisticated, such as using:'
  prefs: []
  type: TYPE_NORMAL
- en: '**DVC** ([https://dvc.org/](https://dvc.org/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weights and Biases** ([https://wandb.ai/site](https://wandb.ai/site))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MLflow** ([https://mlflow.org/](https://mlflow.org/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neptune** ([https://neptune.ai/experiment-tracking](https://neptune.ai/experiment-tracking))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the end, what matters are the results, not the tool you use, so try your
    best to keep order in your experiments and models, even in the heat of a competition.
  prefs: []
  type: TYPE_NORMAL
- en: Before we proceed, consider also thinking about the technology that Kaggle used
    to generate the data for these competitions; if you can properly understand how
    the data has been generated, you get an important advantage. In addition, understanding
    how synthetic data works can really have an impact on the way you do data science
    in the real world, because it gives you a way to easily obtain more varied data
    for training.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, let’s take the *Google Brain – Ventilator Pressure Prediction*
    competition ([https://www.kaggle.com/c/ventilator-pressure-prediction](https://www.kaggle.com/c/ventilator-pressure-prediction)).
    In this competition, you had to develop machine learning for mechanical ventilation
    control. Although you could obtain good results by modeling the data provided
    with deep learning, given the synthetic origin of the data, you could also reverse
    engineer its generative process and obtain a top leaderboard result, as *Jun Koda*
    ([https://www.kaggle.com/junkoda](https://www.kaggle.com/junkoda)) did and explains
    in his post: [https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/285278](https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/285278).'
  prefs: []
  type: TYPE_NORMAL
- en: Generating artificial data by yourself and understanding synthetic data has
    never been so easy, as you can verify from this Notebook ([https://www.kaggle.com/lucamassaron/how-to-use-ctgan-to-generate-more-data](https://www.kaggle.com/lucamassaron/how-to-use-ctgan-to-generate-more-data)),
    derived from a Notebook originally coded and tested by *Dariush Bahrami* ([https://www.kaggle.com/dariushbahrami](https://www.kaggle.com/dariushbahrami)).
  prefs: []
  type: TYPE_NORMAL
- en: Setting a random state for reproducibility
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start discussing the steps and models you may use in a tabular competition,
    it will be useful to return to the theme of **reproducibility** we mentioned above.
  prefs: []
  type: TYPE_NORMAL
- en: 'In most of the commands in the code you see on Kaggle Notebooks, you will find
    a parameter declaring a number, a **seed**, as the random state. This setting
    is important for the reproducibility of your results. Since many algorithms are
    not deterministic but are based on randomness, by setting a seed you influence
    the behavior of the random generator, making it *predictable* in its randomness:
    the same random seed corresponds to the same sequence of random numbers. In other
    words, it allows you to obtain the same results after every run of the same code.'
  prefs: []
  type: TYPE_NORMAL
- en: That is why you find a random seed setting parameter in all machine learning
    algorithms in Scikit-learn as well as in all Scikit-learn-compatible models (for
    instance, XGBoost, LightGBM, and CatBoost, to name the most popular ones).
  prefs: []
  type: TYPE_NORMAL
- en: Reproducibility of results is important in real-world projects as well as in
    Kaggle competitions. In the real world, having a reproducible model allows for
    better tracking of model development and consistency. In Kaggle competitions,
    reproducibility helps in testing hypotheses better because you are controlling
    any source of variation in your models. For instance, if you created a new feature,
    putting it into a reproducible pipeline will help you understand if the feature
    is advantageous or not. You will be sure that any improvement or deterioration
    in the model can be attributed only to the feature, and not to the effects of
    some random process that has changed since the last time you ran the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, reproducibility can be used to your advantage when dealing with public
    Notebooks. Most often, these Notebooks will have a fixed seed that could be 0,
    1, or 42\. The value 42 is quite popular because it is a reference to Douglas
    Adam’s *The Hitchhiker’s Guide to the Galaxy*, in which it is the “Answer to the
    Ultimate Question of Life, the Universe, and Everything,” calculated by an enormous
    supercomputer named Deep Thought over a period of 7.5 million years. Now, if everyone
    in a competition is using the same random seed, it could have a double effect:'
  prefs: []
  type: TYPE_NORMAL
- en: The random seed might be working too well with the public leaderboard, which
    means overfitting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lot of Kagglers will produce similar results that will influence their standings
    in the private leaderboard in the same way
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By changing the random seed, you are avoiding overfitting and also breaking
    rank; in other words, you are getting different results from everyone else, which
    could put you at an advantage in the end. In addition, if you end up winning a
    Kaggle competition, you need to demonstrate how your models produced the winning
    submission, so it is paramount that everything is completely reproducible if you
    want to obtain your prize quickly.
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow and PyTorch models don’t explicitly use a random seed parameter,
    so it is more challenging to ensure their complete reproducibility. The following
    code snippet, when run, sets the same random seed for TensorFlow and PyTorch models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As for Scikit-learn, it is instead advisable to set the random seed directly
    – when it is allowed by the class or the function – using the `random_state` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: The importance of EDA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term **EDA** comes from the work of *John W. Tukey*, one of the most prominent
    exponents of modern statistical methodology. In his 1977 book *Exploratory Data
    Analysis* (hence the acronym EDA), Tukey thinks of EDA as a way to explore data,
    uncover evidence, and develop hypotheses that can later be confirmed by statistical
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: His idea was that how we define statistical hypotheses could be based more on
    observation and reasoning than just sequential tests based on mathematical computations.
    This idea translates well to the world of machine learning because, as we will
    discuss in the next section, data can be improved and pre-digested so that learning
    algorithms can work better and more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: 'In an EDA for a Kaggle competition, you will be looking for:'
  prefs: []
  type: TYPE_NORMAL
- en: Missing values and, most importantly, missing value patterns correlated with
    the target.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Skewed numeric variables and their possible transformations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rare categories in categorical variables that can be grouped together.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Potential outliers, both univariate and multivariate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highly correlated (or even duplicated) features. For categorical variables,
    focus on categories that overlap.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The most predictive features for the problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You achieve this by several descriptive analyses, graphs, and charts, first
    examining each distinct feature (**univariate analysis**, in statistical terms),
    then matching a couple of variables (**bivariate** analysis, such as in a scatterplot),
    and finally considering more features together at once (a **multivariate** approach).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are feeling lazy or unsure about how and where to start, relying on
    automated strategies initially can help you. For instance, you may find that **AutoViz**
    ([https://github.com/AutoViML/AutoViz](https://github.com/AutoViML/AutoViz)),
    a popular rapid EDA freeware tool, can save you a lot of time. You can install
    it on your Notebook by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can obtain a clearer understanding of what AutoViz can do for you by reading
    this Medium article by *Dan Roth* at [https://towardsdatascience.com/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad](https://towardsdatascience.com/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad)
    or browsing a few interesting public Notebooks such as [https://www.kaggle.com/gvyshnya/automating-eda-and-feature-importance-detection](https://www.kaggle.com/gvyshnya/automating-eda-and-feature-importance-detection)
    by *Georgii Vyshnia* ([https://www.kaggle.com/gvyshnya](https://www.kaggle.com/gvyshnya)).
  prefs: []
  type: TYPE_NORMAL
- en: In the latter link, you will also find references to another tool, **Sweetviz**
    ([https://github.com/fbdesignpro/sweetviz](https://github.com/fbdesignpro/sweetviz)).
    Sweetviz has an overview article and tutorial based on the Titanic dataset, at
    [https://towardsdatascience.com/powerful-eda-exploratory-data-analysis-in-just-two-lines-of-code-using-sweetviz-6c943d32f34](https://towardsdatascience.com/powerful-eda-exploratory-data-analysis-in-just-two-lines-of-code-using-sweetviz-6c943d32f34).
  prefs: []
  type: TYPE_NORMAL
- en: 'Another popular tool that you may find useful using is **Pandas Profiling**
    ([https://github.com/pandas-profiling/pandas-profiling](https://github.com/pandas-profiling/pandas-profiling)),
    which is more reliant on classical statistical descriptive statistics and visualization,
    as explained by this article: [https://medium.com/analytics-vidhya/pandas-profiling-5ecd0b977ecd](https://medium.com/analytics-vidhya/pandas-profiling-5ecd0b977ecd).'
  prefs: []
  type: TYPE_NORMAL
- en: Waiting for other Kagglers to publish interesting EDA Notebooks could also be
    a solution, so always keep an eye on the Notebooks sections; sometimes, precious
    hints may appear. This should kick-start your modeling phase and help you understand
    the basic dos and don’ts of the competition. However, remember that EDA stops
    being a commodity and becomes an asset for the competition when it is *highly
    specific to the problem at hand*; this is something that you will never find from
    automated solutions and seldom in public Notebooks. You have to do your EDA by
    yourself and gather key, winning insights.
  prefs: []
  type: TYPE_NORMAL
- en: All things considered, our suggestion is to look into the automated tools a
    bit because they are really easy to learn and run. You will save a lot of time
    that you can instead spend looking at charts and reasoning about possible insights,
    and that will certainly help your competition performance. However, after doing
    that, you need to pick up Matplotlib and Seaborn and try something by yourself
    on not-so-standard plots that depend on the type of data provided and the problem.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you are given a series of measurements performed over time,
    plotting the continuous function based on time is as useful as plotting the single
    recorded points in time, for instance showing different lags between one observation
    and another, a fact that may point to revealing insights for better predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality reduction with t-SNE and UMAP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many possible plots you can create when doing EDA and it is not our
    intention to list them all here, but there are a couple of dimensionality reduction
    plots that are worth spending a few words on because they can provide as much
    information as very specific and data-tailored charts. These are **t-SNE** ([https://lvdmaaten.github.io/tsne/](https://lvdmaaten.github.io/tsne/))
    and **UMAP** ([https://github.com/lmcinnes/umap](https://github.com/lmcinnes/umap)).
  prefs: []
  type: TYPE_NORMAL
- en: t-SNE and UMAP are two techniques, often used by data scientists, that allow
    you to project multivariate data into lower dimensions. They are often used to
    represent complex sets of data in two dimensions. 2-D UMAP and t-SNE plots can
    reveal the presence of outliers and relevant clusters for your data problem.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, if you can plot the scatter graph of the resulting 2-D projection and
    color it by target value, the plot may give you hints about possible strategies
    for dealing with subgroups.
  prefs: []
  type: TYPE_NORMAL
- en: Although it is related to an image competition, a good example of how UMAP and
    t-SNE can help you understand your data better is *Chris Deotte*’s analysis for
    the *SIIM-ISIC Melanoma Classification* competition (see [https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/168028](https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/168028)).
    In this example, Chris has related training and test data on the same low-dimensionality
    projections, highlighting portions where only test examples were present.
  prefs: []
  type: TYPE_NORMAL
- en: Though UMAP and t-SNE offer invaluable help in discovering patterns in data
    that are hard to find, you still can use them as features in your modeling efforts.
    An interesting example of this usage was demonstrated in the *Otto Group Product
    Classification Challenge*, where *Mike Kim* used t-SNE projections as training
    features for the competition ([https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14295](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14295)).
  prefs: []
  type: TYPE_NORMAL
- en: As stated by the article *How to t-SNE Effectively* ([https://distill.pub/2016/misread-tsne/](https://distill.pub/2016/misread-tsne/)),
    you have to use these techniques properly, because it is easy to spot clusters
    and patterns where there are none. The same warning is valid for UMAP, because
    it can also produce plots that can be misread. Guides such as [https://pair-code.github.io/understanding-umap/](https://pair-code.github.io/understanding-umap/)
    offer sound advice on the performance of both UMAP and t-SNE on real-world data,
    providing suggestions and caveats.
  prefs: []
  type: TYPE_NORMAL
- en: Despite these dangers, in our experience, these approaches are certainly more
    revealing than the classical methods based on variance restructuring by linear
    combination such as PCA or SVD. Compared to these approaches, UMAP and t-SNE manage
    to reduce the dimensionality extremely, allowing visual charting of the results
    while maintaining the topography of the data. As a side effect, they are much
    slower to fit. However, NVIDIA has released its **RAPIDS** suite ([https://developer.nvidia.com/rapids](https://developer.nvidia.com/rapids))
    based on CUDA, which, using a GPU-powered Notebook or script, returns the results
    of both UMAP and t-SNE in a very reasonable timeframe, allowing their effective
    use as an EDA tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find a useful example of applying both UMAP and t-SNE with a RAPIDS
    implementation and a GPU for data exploration purposes for the *30 Days of ML*
    competition at the following link: [https://www.kaggle.com/lucamassaron/interesting-eda-tsne-umap/](https://www.kaggle.com/lucamassaron/interesting-eda-tsne-umap/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the figure below, which is the output of the example Notebook above, you
    can see how multiple clusters populate the dataset, but none of them could be
    deemed to reveal a particular relationship with the target:'
  prefs: []
  type: TYPE_NORMAL
- en: '![__results___9_0.png](img/B17574_07_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.1: Multiple clusters appearing in a t-SNE plot'
  prefs: []
  type: TYPE_NORMAL
- en: 'In another Notebook ([https://www.kaggle.com/lucamassaron/really-not-missing-at-random](https://www.kaggle.com/lucamassaron/really-not-missing-at-random)),
    the same techniques are applied to the binary indicators for missing samples instead,
    revealing evocative figures that hint at specific and separate areas dominated
    by a certain type of response. Indeed, in that example, missing samples did not
    occur at random and they were quite predictive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![__results___10_0.png](img/B17574_07_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.2: This t-SNE plot easily reveals areas where the positive target
    is predominant'
  prefs: []
  type: TYPE_NORMAL
- en: Reducing the size of your data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are working directly on Kaggle Notebooks, you will find their limitations
    quite annoying and dealing with them a timesink. One of these limitations is the
    out-of-memory errors that will stop the execution and force you to restart the
    script from the beginning. This is quite common in many competitions. However,
    unlike deep learning competitions based on text or images where you can retrieve
    the data from disk in small batches and have them processed, most of the algorithms
    that work with tabular data require handling all the data in memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common situation is when you have uploaded the data from a CSV file
    using Pandas’ `read_csv`, but the DataFrame is too large to be handled for feature
    engineering and machine learning in a Kaggle Notebook. The solution is to compress
    the size of the Pandas DataFrame you are using without losing any information
    (**lossless compression**). This can easily be achieved using the following script
    derived from the work by *Guillaume Martin* (you can find the original Notebook
    here: [https://www.kaggle.com/gemartin/load-data-reduce-memory-usage](https://www.kaggle.com/gemartin/load-data-reduce-memory-usage)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*Guillaume Martin* was not the first to propose an idea like this on Kaggle.
    The very first Kaggler with this idea of compressing a Pandas DataFrame was *Arjan
    Groen*, who wrote a reducing function during the Zillow competition ([https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65](https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65)).'
  prefs: []
  type: TYPE_NORMAL
- en: This script leverages the fact that all the numeric features in a dataset reside
    in a specific range of values. Since we have different types of integer and floating-point
    numeric variables in Python, based on the number of bytes they occupy in memory,
    the script compares the range of values found in each feature to the maximum and
    minimum value that each numeric type can accept. This is done in order to set
    the feature to the numeric type that works with its range of values and that requires
    the lowest memory.
  prefs: []
  type: TYPE_NORMAL
- en: The approach works like a breeze on Kaggle Notebooks, but with some caveats.
    Once you have set the best-fitting numeric type for each feature by compression,
    you cannot apply any feature engineering that may result in values exceeding the
    capacity of the set numeric types, because such an operation will produce erroneous
    results. Our suggestion is to apply it after feature engineering or before major
    transformations that do not rescale your existing data. Combining it with the
    garbage collection library `gc` and the `gc.collect()` method will improve the
    memory situation of your Kaggle Notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to reduce the size of your data (among other things) is to use feature
    engineering (in particular, feature selection and data compression).
  prefs: []
  type: TYPE_NORMAL
- en: Applying feature engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In real-world projects, what can make the difference between a successful machine
    learning model and a mediocre one is often the data, not the model. When we talk
    about data, the differentiator between bad, good, and excellent data is not just
    the lack of missing values and the reliability of the values (its “quality”),
    or the number of available examples (its “quantity”). In our experience, the real
    differentiator is the informational value of the content itself, which is represented
    by the type of features.
  prefs: []
  type: TYPE_NORMAL
- en: The features are the real clay to mold in a data science project, because they
    contain the information that models use to separate the classes or estimate the
    values. Every model has an expressiveness and an ability to transform features
    into predictions, but if you are lacking on the side of features, no model can
    bootstrap you and offer better predictions. *Models only make apparent the value
    in data. They are not magic in themselves*.
  prefs: []
  type: TYPE_NORMAL
- en: On Kaggle, apart from the rare competitions where you can look for further data
    to add, all participants have the same data available from the beginning. At that
    point, how you handle the data makes most of the difference. Overlooking the fact
    that you can improve the data you have is a common mistake made by many Kagglers.
    **Feature engineering**, a set of techniques for transforming data into more useful
    information for your models, is invariably the key to performing better in competitions.
    Even the more powerful models you can apply need you to process the data and render
    it into a more understandable form.
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature engineering is also the way you embed any **prior knowledge** (usually
    specialist expertise on the problem) into the data: by summing, subtracting, or
    dividing the existing features, you obtain indicators or estimates that you know
    can better explain the problem you are dealing with. There are also other purposes
    of feature engineering, which are less valuable in a Kaggle competition but could
    prove important in a real-world project. The first is to reduce the size of the
    training data (this could also be useful in a Kaggle competition when working
    with Notebooks, which have limits in memory). The second is to make interpretation
    of the resulting model easier by using features understandable to humans.'
  prefs: []
  type: TYPE_NORMAL
- en: Each domain may have encoded specific variable transformations that are not
    necessarily self-evident, but well known to experts of the fields. Just think
    of finance, where you have to separate signals from noise for different sets of
    features representing market and company data, by applying specific transformations
    like Kalman filters or wavelet transformations. Given the large number of possible
    fields and the complexity of many feature engineering procedures, in this section,
    we won’t enter into specific domains of expertise and their particular ways of
    dealing with features.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, we will present you with the most common and most general techniques
    that you can apply in any tabular competition.
  prefs: []
  type: TYPE_NORMAL
- en: Easily derived features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Deriving features with transformations is the simplest approach, but often
    the most effective. For instance, computing feature ratios (dividing one feature
    by another) can prove quite effective because many algorithms cannot mimic divisions
    (for example, gradient boosting) or can have a hard time trying to (for example,
    deep neural networks). Here are the most common transformations to try out:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Time feature processing**: Splitting a date into its elements (year, month,
    day); transforming it into week of the year and weekday; computing differences
    between dates; computing differences with key events (for instance, holidays).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For dates, another common transformation is extracting time elements from a
    date or a time. Cyclic continuous transformations (based on sine and cosine transformations)
    are also useful for representing the continuity of time and creating periodic
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Numeric feature transformations**: Scaling; normalization; logarithmic or
    exponential transformations; separating the integer and decimal parts; summing,
    subtracting, multiplying, or dividing two numeric features. Scaling obtained by
    standardization (the z-score method used in statistics) or by normalization (also
    called min-max scaling) of numeric features can make sense if you are using algorithms
    sensitive to the scale of features, such as any neural network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Binning of numeric features**: This is used to transform continuous variables
    into discrete ones by distributing their values into a number of bins. Binning
    helps remove noise and errors in data and it allows easy modeling of non-linear
    relationships between the binned features and the target variable when paired
    with **one-hot encoding** (see the Scikit-learn implementation, for instance:
    [https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Categorical feature encoding**: One-hot encoding; a categorical data processing
    that merges two or three categorical features together; or the more sophisticated
    target encoding (more on this in the following sections).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Splitting and aggregating categorical features based on the levels**: For
    instance, in the *Titanic* competition ([https://www.kaggle.com/c/titanic](https://www.kaggle.com/c/titanic))
    you can split names and surnames, as well their initials, to create new features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Polynomial features** are created by raising features to an exponent. See,
    for instance, this Scikit-learn function: [https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While they are not proper feature engineering but more data cleaning techniques,
    missing data and outlier treatments involve making changes to the data that nevertheless
    transform your features, and they can help signals from the data emerge:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Missing values treatment**: Make binary features that point out missing values,
    because sometimes missingness is not random and a missing value could have some
    important reason behind it. Usually, missingness points out something about the
    way data is recorded, acting like a proxy variable for something else. It is just
    like in census surveys: if someone doesn’t tell you their income, it means they
    are extremely poor or are extremely rich. If required by your learning algorithm,
    replace the missing values with the mean, median, or mode (it is seldom necessary
    to use methods that are more sophisticated).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can refer to this complete guide written by *Parul Pandey* ([https://www.kaggle.com/parulpandey](https://www.kaggle.com/parulpandey))
    as a reference: [https://www.kaggle.com/parulpandey/a-guide-to-handling-missing-values-in-python](https://www.kaggle.com/parulpandey/a-guide-to-handling-missing-values-in-python).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Just keep in mind that some models can handle missing values by themselves
    and do so fairly better than many standard approaches, because the missing-values
    handling is part of their optimization procedure. The models that can handle missing
    values by themselves are all gradient boosting models:'
  prefs: []
  type: TYPE_NORMAL
- en: 'XGBoost: [https://xgboost.readthedocs.io/en/latest/faq.html](https://xgboost.readthedocs.io/en/latest/faq.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LightGBM: [https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html](https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CatBoost: [https://catboost.ai/docs/concepts/algorithm-missing-values-processing.html](https://catboost.ai/docs/concepts/algorithm-missing-values-processing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outlier capping or removal**: Exclude, cap to a maximum or minimum value,
    or modify outlier values in your data. To do so, you can use sophisticated multivariate
    models, such as those present in Scikit-learn ([https://scikit-learn.org/stable/modules/outlier_detection.html](https://scikit-learn.org/stable/modules/outlier_detection.html)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Otherwise, you can simply locate the outlying samples in a univariate fashion,
    basing your judgment on how many standard deviations they are from the mean, or
    their distance from the boundaries of the **interquartile range** (**IQR**). In
    this case, you might simply exclude any points that are above the value of `1.5
    * IQR + Q3` (upper outliers) and any points that are below `Q1 - 1.5 * IQR` (lower
    outliers). Once you have found the outliers, you can also proceed by pointing
    them out with a binary variable.
  prefs: []
  type: TYPE_NORMAL
- en: All these data transformations can add predictive performance to your models,
    but they are seldom decisive in a competition. Though it is necessary, you cannot
    simply rely on basic feature engineering. In the following sections, we’ll suggest
    more complex procedures for extracting value from your data.
  prefs: []
  type: TYPE_NORMAL
- en: Meta-features based on rows and columns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to perform competitively, you need trickier feature engineering. A
    good place to start is looking at features based on each **row**, considered separately:'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the mean, median, sum, standard deviation, minimum, or maximum of the
    numeric values (or of a subset of them)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Count the missing values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute the frequencies of common values found in the rows (for instance, considering
    the binary features and counting the positive values)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assign each row to a cluster derived from a cluster analysis such as *k*-means
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These **meta-features** (called thus because they are features that are representative
    of a set of single features) help to distinguish the different kinds of samples
    found in your data by pointing out specific groups of samples to your algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Meta-features can also be built based on **columns**. Aggregation and summarization
    operations on single features instead have the objective of providing further
    information about the value of numeric and categorical features; *is this characteristic
    common or rare?* This is information that the model cannot grasp because it cannot
    count categorical instances in a feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'As meta-features, you can use any kind of column statistic (such as mode, mean,
    median, sum, standard deviation, min, max, and also skewness and kurtosis for
    numerical features). For column-wise meta-features, you can proceed in a few different
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Frequency encoding**: Simply count the frequency of the values in a categorical
    feature and then create a new feature where you replace those values with their
    frequency. You can also apply frequency encoding to numeric features when there
    are frequently recurring values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequencies and column statistics computed with respect to a relevant group**:
    In this case, you can create new features from the values of both numeric and
    categorical features because you are considering distinct groups in the data.
    A group could be a cluster you compute by cluster analysis, or a group you can
    define using a feature (for instance, age may produce age groups, locality may
    provide areas, and so on). The meta-features describing each group are then applied
    to each sample based on its group. For instance, using a Pandas `groupby` function,
    you can create your meta-features, which are then merged with the original data
    based on the grouping variable. The trickiest part of this feature engineering
    technique is finding meaningful groups in data to compute the features on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further column frequencies and statistics can be derived by combining more groups
    together.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list is certainly not exhaustive, but it should give you an idea of how
    to look for new features at the feature level and at the row level using frequencies
    and statistics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see a simple example based on the *Amazon Employee Access Challenge*
    data. First, we will apply a frequency encoding on the `ROLE_TITLE` feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The result will show that the feature classes have been replaced by their observed
    frequency.
  prefs: []
  type: TYPE_NORMAL
- en: We now proceed to encode the `ROLE_TITLE` feature based on the groupings of
    the `ROLE_DEPTNAME`, because we expect that different titles may be more common
    in certain departments and rarer in others.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result is a new feature composed of both, which we use to count the frequency
    of its values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You can find all the working code and the results in this Kaggle Notebook:
    [https://www.kaggle.com/lucamassaron/meta-features-and-target-encoding/](https://www.kaggle.com/lucamassaron/meta-features-and-target-encoding/).'
  prefs: []
  type: TYPE_NORMAL
- en: Target encoding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Categorical features are usually not a challenge to deal with, thanks to simple
    functions offered by Scikit-learn such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '`LabelEncoder`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OneHotEncoder`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OrdinalEncoder`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These functions can transform categories into numeric features and then into
    binary features that are easily dealt with by machine learning algorithms. However,
    when the number of categories to deal with is too large, the dataset resulting
    from a one-hot encoding strategy becomes **sparse** (most values in it will be
    zero values) and cumbersome to handle for the memory and processor of your computer
    or Notebook. In these situations, we talk about a **high-cardinality feature**,
    which requires special handling.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since early Kaggle competitions, high-cardinality variables have in fact been
    processed using an encoding function that is computed according to Micci-Barreca,
    D. *A preprocessing scheme for high-cardinality categorical attributes in classification
    and prediction problems*. ACM SIGKDD Explorations Newsletter 3.1 (2001): 27-32.'
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind this approach is to transform the many categories of a categorical
    feature into their corresponding expected target value. In the case of a regression,
    this is the average expected value for that category; for a binary classification,
    it is the conditional probability given that category; for a multiclass classification,
    you have instead the conditional probability for each possible outcome.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in the *Titanic* GettingStarted competition ([https://www.kaggle.com/competitions/titanic](https://www.kaggle.com/competitions/titanic)),
    where you have to figure out the survival probability of each passenger, target
    encoding a categorical feature, such as the gender feature, would mean replacing
    the gender value with its average probability of survival.
  prefs: []
  type: TYPE_NORMAL
- en: In this way, the categorical feature is transformed into a numeric one without
    having to convert the data into a larger and sparser dataset. In short, this is
    **target encoding** and it is indeed very effective in many situations because
    it resembles a stacked prediction based on the high-cardinality feature. Like
    stacked predictions, however, where you are essentially using a prediction from
    another model as a feature, target encoding brings about the risk of overfitting.
    In fact, when some categories are too rare, using target encoding is almost equivalent
    to providing the target label. There are ways to avoid this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before seeing the implementation you can directly import into your code, let’s
    see an actual code example of target encoding. This code was used for one of the
    top-scoring submissions of the *PetFinder.my Adoption Prediction* competition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The input parameters of the function are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`categories`: The column names of the features you want to target-encode. You
    can leave `''auto''` on and the class will pick the object strings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`k` (int): Minimum number of samples to take a category average into account.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`f` (int): Smoothing effect to balance the category average versus the prior
    probability, or the mean value relative to all the training examples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`noise_level`: The amount of noise you want to add to the target encoding in
    order to avoid overfitting. Start with very small numbers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_state`: The reproducibility seed in order to replicate the same target
    encoding when `noise_level > 0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notice the presence of the `k` and the `f` parameters. In fact, for a level
    *i* of a categorical feature, we are looking for an approximate value that can
    help us better predict the target using a single encoded variable. Replacing the
    level with the observed conditional probability could be the solution, but doesn’t
    work well for levels with few observations. The solution is to blend the observed
    posterior probability on that level (the probability of the target given a certain
    value of the encoded feature) with the a priori probability (the probability of
    the target observed on the entire sample) using a lambda factor. This is called
    the **empirical Bayesian approach**.
  prefs: []
  type: TYPE_NORMAL
- en: In practical terms, we are using a function to determine if, for a given level
    of a categorical variable, we are going to use the conditional target value, the
    average target value, or a blend of the two. This is dictated by the lambda factor,
    which, for a fixed `k` parameter (usually it has a unit value, implying a minimum
    cell frequency of two samples) has different output values depending on the `f`
    value that we choose.
  prefs: []
  type: TYPE_NORMAL
- en: '![__results___2_0.png](img/B17574_07_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: Plot of lambda values (on the y-axis) depending on f values and
    sample size of the categorical value (on the x-axis)'
  prefs: []
  type: TYPE_NORMAL
- en: As shown by the chart, where the *x*-axis represents the number of cases for
    a given categorical level and the *y*-axis the weight of the conditional target
    value, smaller `f` values tend to switch abruptly from using the average target
    to using the conditional value. Higher values of `f` tend to blend the conditional
    value with the average unless we are dealing with a categorical level with a large
    sample size.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, for a fixed `k`, higher values of `f` dictate less trust in the observed
    empirical frequency and more reliance on the empirical probability for all cells.
    The right value for `f` is usually a matter of testing (supported by cross-validation),
    since you can consider the `f` parameter a hyperparameter in itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'After all these explanations, the class is actually quite straightforward to
    use. Instantiate it with the name of the features you want to target-encode and
    the parameters you want to try and fit it on some training data. Then, you can
    transform any other piece of data, target-encoding only the fitted features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The example works on the same *Amazon Employee Access Challenge* data we used
    before and it target-encodes only the `ROLE_TITLE` feature.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of writing your own code, you can also use the package from [https://github.com/scikit-learn-contrib/category_encoders](https://github.com/scikit-learn-contrib/category_encoders)
    and its Target Encoder ([http://contrib.scikit-learn.org/category_encoders/targetencoder.html](http://contrib.scikit-learn.org/category_encoders/targetencoder.html)).
    It is an out-of-the-box solution that works exactly like the code in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Using feature importance to evaluate your work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Applying too much feature engineering can have side effects. If you create
    too many correlated features or features that are not important for the problem,
    models could take too long to complete their training and you may get worse results.
    This may seem like a paradox, but it is explained by the fact that every variable
    carries some noise (a random component due to measurement or recording errors)
    that may be picked by mistake by the model: the more variables you use, the higher
    the chance your model may pick up noise instead of signals. Therefore, you should
    try to keep only the relevant features in the dataset you use for training; consider
    feature selection as a part of your feature engineering process (the pruning phase).'
  prefs: []
  type: TYPE_NORMAL
- en: Figuring out the features you need to keep is a hard problem because, as the
    number of available features grows, the number of possible combinations grows
    too. There are various ways to select features, but first it is important to think
    about the stage in your data preparation pipeline where the selection has to happen.
  prefs: []
  type: TYPE_NORMAL
- en: Based on our experiences, we suggest you consider placing feature selection
    at the *end* of your data preparation pipeline. Since features share a part of
    their variance with other features, you cannot evaluate their effectiveness by
    testing them one at a time; you have to consider them all at once in order to
    correctly figure out which you should use.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, you should then test the effectiveness of your selected features
    using cross-validation. Therefore, after you have all the features prepared and
    you have a consistent pipeline and a working model (it doesn’t need to be a fully
    optimized model, but it should work properly and return acceptable results for
    the competition), you are ready to test what features should be retained and what
    could be discarded. At this point, there are various ways to operate feature selection:'
  prefs: []
  type: TYPE_NORMAL
- en: Classical approaches used in statistics resort to forward addition or backward
    elimination by testing each feature entering or leaving the set of predictors.
    Such an approach can be quite time-consuming, though, because it relies on some
    measure of internal importance of variables or on their effect on the performance
    of the model with respect to a specific metric, which you have to recalculate
    for every feature at every step of the process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For regression models, using lasso selection can provide a hint about all the
    important yet correlated features (the procedure may, in fact, retain even highly
    correlated features), by using the **stability selection** procedure. In stability
    selection, you test multiple times (using a bagging procedure) what features should
    be retained – considering only the features whose coefficients are not zero at
    each test – and then you apply a voting system to keep the ones that are most
    frequently assigned non-zero coefficients.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can get more details about the procedure at this repository: [https://github.com/scikit-learn-contrib/stability-selection](https://github.com/scikit-learn-contrib/stability-selection).'
  prefs: []
  type: TYPE_NORMAL
- en: For tree-based models, such as random forests or gradient boosting, a decrease
    in impurity or a gain in the target metric based on splits are common ways to
    rank features. A threshold can cut away the least important ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Always for tree-based models, but easily generalizable to other models, test-based
    randomization of features (or simple comparisons with random features) helps to
    distinguish features that do help the model to predict correctly from features
    that are just noise or redundant.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An example of how randomizing features helps in selecting important features
    is proposed in this example by *Chris Deotte* in the *Ventilator Pressure Prediction*
    competition: [https://www.kaggle.com/cdeotte/lstm-feature-importance](https://www.kaggle.com/cdeotte/lstm-feature-importance).
    This Notebook tests the role of features in an LSTM-based neural network. First,
    the model is built and the baseline performance is recorded. Then, one by one,
    features are shuffled and the model is required to predict again. If the resulting
    prediction worsens, it suggests that you shuffled an important feature that shouldn’t
    be touched. Instead, if the prediction performance stays the same or even improves,
    the shuffled feature is not influential or even detrimental to the model.'
  prefs: []
  type: TYPE_NORMAL
- en: There is also No Free Lunch in importance evaluation. Shuffling doesn’t require
    any re-training, which is a great advantage when training a fresh model costs
    time. However, it can fail in certain situations. Shuffling can sometimes create
    unrealistic input combinations that make no sense to evaluate. In other cases,
    it can be fooled by the presence of highly correlated features (incorrectly determining
    that one is important and the other is not). In this case, proceeding by removing
    the feature (instead of shuffling it), retraining the model, and then evaluating
    its performance against the baseline is the best solution.
  prefs: []
  type: TYPE_NORMAL
- en: In another approach based on shuffled features, **Boruta** ([https://github.com/scikit-learn-contrib/boruta_py](https://github.com/scikit-learn-contrib/boruta_py))
    uses random features to test the validity of the model in an iterative fashion.
    An alternative version of the Boruta selection procedure, **BorutaShap** ([https://github.com/Ekeany/Boruta-Shap](https://github.com/Ekeany/Boruta-Shap)),
    leverages SHAP values in order to combine feature selection and for explainability
    reasons. The resulting selection is usually more reliable than simple rounds of
    removal or randomization of features, because features are tested multiple times
    against random features until they can statistically prove their importance. Boruta
    or BorutaShap may take up to 100 iterations and it can only be performed using
    tree-based machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: If you are selecting features for a linear model, Boruta may actually overshoot.
    This is because it will consider the features important both for their main effects
    and their interactions together with other features (but in a linear model, you
    care only about the main effects and a selected subset of interactions). You can
    still effectively use Boruta when selecting for a linear model by using a gradient
    boosting whose max depth is set to one tree, so you are considering only the main
    effects of the features and not their interactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can have a look at how simple and quick it is to set up a BorutaShap feature
    selection by following this tutorial Notebook presented during the *30 Days of
    ML* competition: [https://www.kaggle.com/lucamassaron/tutorial-feature-selection-with-boruta-shap](https://www.kaggle.com/lucamassaron/tutorial-feature-selection-with-boruta-shap).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Bojan_Tunguz.png)'
  prefs: []
  type: TYPE_IMG
- en: Bojan Tunguz
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/tunguz](https://www.kaggle.com/tunguz)'
  prefs: []
  type: TYPE_NORMAL
- en: Bojan Tunguz is one Kaggler who definitely understands the importance of feature
    engineering (and is also a great fan of XGBoost ![](img/Smiley_face.png)). We
    were keen to speak to him about his experiences as a Machine Learning Modeler
    at NVIDIA and, impressively, a Kaggle Quadruple Grandmaster.
  prefs: []
  type: TYPE_NORMAL
- en: What’s your favorite kind of competition and why? In terms of techniques and
    solving approaches, what is your specialty on Kaggle?
  prefs: []
  type: TYPE_NORMAL
- en: '*I love any non-code competition. This has changed a lot over the years. I
    used to be really into the image competitions, but the sophistication of the engineering
    stack required to be competitive in these has increased tremendously over the
    years. For a while I was really into the NLP competitions, but those have always
    been rare on Kaggle. One constant over the years, though, has been my interest
    in tabular data problems. Those used to be the quintessential Kaggle competition
    problems but have unfortunately become extinct. I am still very interested in
    that area of ML and have moved into doing some basic research in this domain.
    Compared to the other areas of ML/DL, there has been very little progress on improving
    ML for tabular data, and I believe there is a lot of opportunity here.*'
  prefs: []
  type: TYPE_NORMAL
- en: How do you approach a Kaggle competition? How different is this approach to
    what you do in your day-to-day work?
  prefs: []
  type: TYPE_NORMAL
- en: '*I have always taken the game aspect of Kaggle seriously. What that means for
    me is I usually start new Kaggle competitions very playfully – submitting simple
    solutions, whimsical solutions, modified solutions from other players, blends,
    etc. These help me get a feel for the problem, what sorts of things work, how
    far can I get with a few simple tricks, etc. Some of this is also applicable to
    my day-to-day modeling, but there one important aspect is missing – and that’s
    the support and feedback from the community and the leaderboard. When you are
    working on your own or with a small team, you never know if what you are building
    is the best that can be done, or if a better solution is possible.*'
  prefs: []
  type: TYPE_NORMAL
- en: Tell us about a particularly challenging competition you entered, and what insights
    you used to tackle the task.
  prefs: []
  type: TYPE_NORMAL
- en: '*The most challenging and the most important competition of my Kaggle career
    was the* Home Credit Default Risk *competition. It is the second biggest Kaggle
    competition of all time, and it happened during a particularly challenging time
    in my life.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Credit underwriting is a very challenging data science problem and requires
    a lot of intelligent feature engineering and a reliable validation scheme. My
    own personal insight was to use simple linear modeling for feature selection,
    and it helped our overall model. Our team won that competition, and to this day
    I consider this victory the highlight of my Kaggle career.*'
  prefs: []
  type: TYPE_NORMAL
- en: Has Kaggle helped you in your career? If so, how?
  prefs: []
  type: TYPE_NORMAL
- en: '*Kaggle has been the single biggest booster of my ML career. Out of four ML
    jobs that I have held, three have been a direct consequence of my Kaggle success.
    It is impossible to overstate how important a Kaggle credential can be in one’s
    career.*'
  prefs: []
  type: TYPE_NORMAL
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  prefs: []
  type: TYPE_NORMAL
- en: '*There are two aspects of all ML problems, and Kaggle competitions in particular,
    that I have either underappreciated or not bothered enough with for way too long:
    feature engineering and a robust validation strategy. I love ML libraries and
    algorithms and have a tendency to start building the ML algorithm as soon as I
    can. But the single biggest impact on your model’s performance will come from
    very good features. Unfortunately, feature engineering is more of an art than
    a science and is usually very model- and dataset-dependent. Most of the more interesting
    feature engineering tricks and practices are rarely, if ever, taught in standard
    ML courses or resources. Many of them cannot be taught and are dependent on some
    special problem-specific insights. But the mindset of looking into feature engineering
    as default is something that can be cultivated. It will usually take many years
    of practice to get good at it.*'
  prefs: []
  type: TYPE_NORMAL
- en: Are there any tools or libraries that you would recommend using for Kaggling?
  prefs: []
  type: TYPE_NORMAL
- en: '*XGBoost is all you need!*'
  prefs: []
  type: TYPE_NORMAL
- en: Pseudo-labeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In competitions where the number of examples used for training can make a difference,
    **pseudo-labeling** can boost your scores by providing further examples taken
    from the test set. The idea is to add examples from the test set whose predictions
    you are confident about to your training set.
  prefs: []
  type: TYPE_NORMAL
- en: 'First introduced in the *Santander Customer Transaction Prediction* competition
    by team Wizardry (read here: [https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/89003](https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/89003)),
    pseudo-labeling simply helps models to refine their coefficients thanks to more
    data available, but it won’t always work. First of all, it is not necessary in
    some competitions. That is, adding pseudo-labels won’t change the result; it may
    even worsen it if there is some added noise in the pseudo-labeled data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, you cannot know for sure beforehand whether or not pseudo-labeling
    will work in a competition (you have to test it empirically), though plotting
    learning curves may provide you with a hint as to whether having more data could
    be useful (see this example provided by Scikit-learn: [https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, it is not easy to decide which parts of the test set predictions to
    add or how to tune the entire procedure for the best results. Generally, this
    is the procedure:'
  prefs: []
  type: TYPE_NORMAL
- en: Train your model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Predict on the test set
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Establish a confidence measure
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the test set elements to add
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build a new model with the combined data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Predict using this model and submit
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A good example of the complete procedure for obtaining pseudo-labeling is offered
    by Chris Deotte in the *Instant Gratification* competition: [https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969).
    You don’t need to know more than a few tricks in order to apply it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few caveats you should consider when trying to apply pseudo-labeling:'
  prefs: []
  type: TYPE_NORMAL
- en: You should have a very good model that produces good predictions for them to
    be usable in training. Otherwise, you will just add more noise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since it is impossible to have entirely perfect predictions in the test set,
    you need to distinguish the good ones from the ones you shouldn’t use. If you
    are predicting using CV folds, check the standard deviation of your predictions
    (this works both with regression and classification problems) and pick only the
    test examples where the standard deviation is the lowest. If you are predicting
    probabilities, use only high-end or low-end predicted probabilities (the cases
    where the model is actually more confident).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the second stage, when you concatenate the training examples with the test
    ones, do not put in more than 50% test examples. Ideally, a share of 70% original
    training examples and 30% pseudo-labeled examples is the best. If you put in too
    many pseudo-labeled examples, your new model will risk learning little from the
    original data and more from the easier test examples, resulting in a distilled
    model that does not perform better than the original. In fact, as you are training,
    your model is also learning how to deal with noise in labels, but pseudo-labeled
    examples do not have this noise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t forget that you cannot completely trust your pseudo-labels, so keep in
    mind that you are also partially spoiling your data by using test predictions
    as training examples. The trick works when you get more benefits from doing so
    than negative effects.
  prefs: []
  type: TYPE_NORMAL
- en: If you depend on validation for early stopping, fixing hyperparameters, or simply
    evaluating your model, do not use pseudo-labels in the validation. They could
    be highly misleading. Always use the original training cases for the same reasons
    we quoted above.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If possible, use a different kind of model when training to estimate the pseudo-labels
    and when training your final model using both the original labels and the pseudo-labels.
    This will ensure you are not simply enforcing the same information your previous
    model used, but you are also extracting new information from the pseudo-labels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clearly, pseudo-labeling is more of an art than a science. It can make the difference
    in certain competitions but needs to be executed very well to generate results.
    Consider it a resource, and always try one submission based on pseudo-labels.
  prefs: []
  type: TYPE_NORMAL
- en: Denoising with autoencoders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Autoencoders**, initially better known for non-linear data compression (a
    kind of non-linear PCA) and image denoising, started being recognized as an interesting
    tool for tabular competitions after *Michael Jahrer* ([https://www.kaggle.com/mjahrer](https://www.kaggle.com/mjahrer))
    successfully used them to win the *Porto Seguro’s Safe Driver Prediction* competition
    ([https://www.kaggle.com/c/porto-seguro-safe-driver-prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)).
    *Porto Seguro* was a popular, insurance-based risk analysis competition (more
    than 5,000 participants) characterized by particularly noisy features.'
  prefs: []
  type: TYPE_NORMAL
- en: Michael Jahrer describes how he found a better representation of the numeric
    data for subsequent neural net supervised learning by using **denoising autoencoders**
    (**DAEs**). A DAE can produce a new dataset with a huge number of features based
    on the activations of the hidden layers at the center of the network, as well
    as the activations of the middle layers encoding the information.
  prefs: []
  type: TYPE_NORMAL
- en: In his famous post ([https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629)),
    Michael Jahrer describes how a DAE can not only remove noise but also automatically
    create new features, so the representation of the features is learned in a similar
    way to what happens in image competitions. In the post, he mentions the secret
    sauce for the DAE recipe, which is not simply the layers, but the **noise** you
    put into the data in order to augment it. He also made clear that the technique
    requires stacking together training and test data, implying that the technique
    would not have applications beyond winning a Kaggle competition. In fact, after
    this winning exploit, the technique disappeared from the forums and most competitions
    until its recent re-emergence during the Tabular Playground Series.
  prefs: []
  type: TYPE_NORMAL
- en: DAEs are technically composed of an **encoding** part and a **decoding** part.
    The encoding part takes the training data as input and is followed by a few dense
    layers. Ideally, you have a hidden middle layer, whose activations just encode
    all the training information. If the number of nodes in this middle layer is smaller
    than the original input shape, you have a **compression** and hopefully, in statistical
    terms, you are representing some latent dimensionality that is behind the generative
    process of the input data; otherwise, you are simply eliminating redundancies
    and separating noise from signal (which is not a bad result).
  prefs: []
  type: TYPE_NORMAL
- en: In the second part of the layer, the decoder part, you are enlarging the layers
    again until they regain the shape of the original input. The output is compared
    with the input to compute an error loss to backpropagate to the network.
  prefs: []
  type: TYPE_NORMAL
- en: 'From these solutions, you can deduce that there are two types of DAEs:'
  prefs: []
  type: TYPE_NORMAL
- en: In **bottleneck DAEs**, mimicking the approach used in image processing, you
    take as new features the activations from the middle layer, the one separating
    the encoding part from the decoding part. These architectures have an hourglass
    shape, first reducing the number of neurons layer by layer until the middle bottleneck
    layer, then enlarging it back in the second part. The number of hidden layers
    is always odd.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B17574_07_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: In a bottleneck DAE, you take only the bottleneck layer weights
    as features'
  prefs: []
  type: TYPE_NORMAL
- en: In **deep stack DAEs**, you take all the activations from the hidden layers,
    without distinguishing between the encoding, decoding, or middle layer. In these
    architectures, layers are the same size. The number of hidden layers can be even
    or odd.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B17574_07_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.5: In a deep stack DAE, you take all the stacked hidden layer weights
    as features'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned, an important aspect often discussed is adding some **random
    noise** to your DAE. In order to help train any kind of DAE, you need to inject
    noise that helps to augment the training data and avoid the overparameterized
    neural network just memorizing inputs (in other words, overfitting). In the *Porto
    Seguro* competition, Michael Jahrer added noise by using a technique called **swap
    noise**, which he described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Here I sample from the feature itself with a certain probability “inputSwapNoise”
    in the table above. 0.15 means 15% of features replaced by values from another
    row.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'What is described is basically an augmentation technique called **mixup** (which
    is also used in image augmentation: [https://arxiv.org/abs/1710.09412](https://arxiv.org/abs/1710.09412)).
    In mixup for tabular data, you decide a probability for mixing up. Based on that
    probability, you change some of the original values in a sample, replacing them
    with values from a more or less similar sample from the same training data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In his walkthrough ([https://www.kaggle.com/springmanndaniel/1st-place-turn-your-data-into-daeta](https://www.kaggle.com/springmanndaniel/1st-place-turn-your-data-into-daeta)),
    *Danzel* describes three approaches to this: column-wise, row-wise, and random:'
  prefs: []
  type: TYPE_NORMAL
- en: In **column-wise** noise swapping, you swap values in a certain number of columns.
    The proportion of columns whose values are to be swapped is decided based on your
    mixup probability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In **row-wise** noise swapping, you always swap a certain number of the values
    in each row. Essentially, every row contains the same proportion of swapped values,
    based on the mixup probability, but the features swapped change from row to row.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In **random** noise swapping, you fix a number of values to be swapped, based
    on the mixup probability, and you randomly pick them up from the entire dataset
    (this is somewhat similar to row-wise swapping in effect).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Like pseudo-labeling, DAE is also more of an art than a science, which is another
    way to say that it is all trial and error. It won’t always work and the details
    that make it work on one problem probably won’t help for another. In order to
    obtain a good DAE for your competition, you need to keep an eye on a series of
    aspects that need to be tested and tuned:'
  prefs: []
  type: TYPE_NORMAL
- en: Architecture of the DAE (deep stack tends to work better, but you need to determine
    the number of units per layer and the number of layers)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning rate and batch size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loss (also distinguishing between the loss of numeric and categorical features
    helps)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stopping point (the lowest loss is not always the best; use validation and early
    stopping if possible)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Depending on the problem, you should expect to face some difficulties in setting
    up the right architecture and adjusting it to work properly. Your efforts, however,
    could be rewarded by a top result on the final private leaderboard. In fact, in
    recent tabular competitions, DAE techniques appeared as part of the recipe of
    many winning submissions:'
  prefs: []
  type: TYPE_NORMAL
- en: Danzel ([https://www.kaggle.com/springmanndaniel](https://www.kaggle.com/springmanndaniel))
    reported in [https://www.kaggle.com/c/tabular-playground-series-jan-2021/discussion/216037](https://www.kaggle.com/c/tabular-playground-series-jan-2021/discussion/216037)
    having used the hidden weights of three 1,500-neuron layers, expanding the original
    data from 14 columns to 4,500\. This new, processed dataset was used as input
    in other neural networks and gradient boosting models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Ren Zhang* ([https://www.kaggle.com/ryanzhang](https://www.kaggle.com/ryanzhang))
    discussed his solution ([https://www.kaggle.com/c/tabular-playground-series-feb-2021/discussion/222745](https://www.kaggle.com/c/tabular-playground-series-feb-2021/discussion/222745))
    and shared his code ([https://github.com/ryancheunggit/Denoise-Transformer-AutoEncoder](https://github.com/ryancheunggit/Denoise-Transformer-AutoEncoder)),
    revealing that he used stacked transformer encoders rather than your typical linear
    and ReLU activated hidden layers (and that such an approach can mean it takes
    up to 20 hours to train a proper DAE). In his approach, he also suggested adding
    some random noise to the data (by using a noise mask) to be reconstructed and
    to compute the loss based not only on the error from reconstructing the original
    data, but also from the noise mask. Using this combined loss helps the network
    to converge better. Studying the code provided in the GitHub link and the graph
    in the Kaggle discussion post will help you to understand better and easily replicate
    this innovative approach.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*JianTT* ([https://www.kaggle.com/jiangtt](https://www.kaggle.com/jiangtt))
    noticed how some techniques key to DAEs, in particular creating new observations
    by adding noise, can be useful for training better algorithms without the need
    of creating a complete DAE: [https://www.kaggle.com/c/tabular-playground-series-apr-2021/discussion/235739](https://www.kaggle.com/c/tabular-playground-series-apr-2021/discussion/235739).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you don’t want to spend too much time building your own DAE, but you would
    like to explore whether something like it could work for the competition you are
    taking on, you can test out a couple of pre-prepared solutions. First, you can
    refer to a Notebook for a PyTorch network from *Hung Khoi* ([https://www.kaggle.com/hungkhoi/train-denoise-transformer-autoencoder](https://www.kaggle.com/hungkhoi/train-denoise-transformer-autoencoder))
    and re-adapt it to your needs, or you can use the Kaggler library from *Jeong-Yoon
    Lee* ([https://www.kaggle.com/jeongyoonlee](https://www.kaggle.com/jeongyoonlee)).
    In his Notebook, Jeong-Yoon Lee presents how it works on one of the Tabular Playground
    competitions: [https://www.kaggle.com/jeongyoonlee/dae-with-2-lines-of-code-with-kaggler](https://www.kaggle.com/jeongyoonlee/dae-with-2-lines-of-code-with-kaggler).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Neural networks for tabular competitions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having discussed neural networks with DAEs, we have to complete this chapter
    by discussing how neural networks can help you in a tabular competition more generally.
    Gradient boosting solutions still clearly dominate tabular competitions (as well
    as real-world projects); however, sometimes neural networks can catch signals
    that gradient boosting models cannot get, and can be excellent single models or
    models that shine in an ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: 'As many Grandmasters of the present and the past often quote, mixing together
    diverse models (such as a neural network and a gradient boosting model) always
    produces better results than single models taken separately in a tabular data
    problem. *Owen Zhang*, previously number one on Kaggle, discusses at length in
    the following interview how neural networks and GBMs can be blended nicely for
    better results in a competition: [https://www.youtube.com/watch?v=LgLcfZjNF44](https://www.youtube.com/watch?v=LgLcfZjNF44).'
  prefs: []
  type: TYPE_NORMAL
- en: Building a neural network quickly for a tabular competition is no longer a daunting
    challenge. Libraries such as TensorFlow/Keras and PyTorch make things easy, and
    having some pre-made networks such as TabNet already packaged for you into libraries
    makes them even easier.
  prefs: []
  type: TYPE_NORMAL
- en: To quickly get started with building your own network, you can use various resources.
    We warmly suggest referring to the book we published, *Machine Learning Using
    TensorFlow Cookbook* ([https://www.packtpub.com/product/machine-learning-using-tensorflow-cookbook/9781800208865](https://www.packtpub.com/product/machine-learning-using-tensorflow-cookbook/9781800208865)),
    since there is an extensive chapter devoted to building DNNs with TensorFlow for
    tabular problems (*Chapter 7*, *Predicting with Tabular Data*). In the book, you
    can also find many other suggestions and recipes for using TensorFlow for Kaggle.
  prefs: []
  type: TYPE_NORMAL
- en: 'Otherwise, you can refer to a few online resources introducing you to the topic,
    as presented during the *30 Days of ML* competition:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Watch this video that explains how to use TensorFlow for tabular data: [https://www.youtube.com/watch?v=nQgUt_uADSE](https://www.youtube.com/watch?v=nQgUt_uADSE)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use the code from the tutorial on GitHub: [https://github.com/lmassaron/deep_learning_for_tabular_data](https://github.com/lmassaron/deep_learning_for_tabular_data)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Most importantly, find the tutorial Notebook applied to the competition here:
    [https://www.kaggle.com/lucamassaron/tutorial-tensorflow-2-x-for-tabular-data](https://www.kaggle.com/lucamassaron/tutorial-tensorflow-2-x-for-tabular-data)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The key things to take into account when building these solutions are:'
  prefs: []
  type: TYPE_NORMAL
- en: Use activations such as GeLU, SeLU, or Mish instead of ReLU; they are quoted
    in quite a few papers as being more suitable for modeling tabular data and our
    own experience confirms that they tend to perform better.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experiment with batch size.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use augmentation with mixup (discussed in the section on autoencoders).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use quantile transformation on numeric features and force, as a result, uniform
    or Gaussian distributions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverage embedding layers, but also remember that embeddings do not model everything.
    In fact, they miss interactions between the embedded feature and all the others
    (so you have to force these interactions into the network with direct feature
    engineering).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In particular, remember that embedding layers are reusable. In fact, they consist
    only of a matrix multiplication that reduces the input (a sparse one-hot encoding
    of the high cardinality variable) to a dense one of lower dimensionality. By recording
    and storing away the embedding of a trained neural network, you can transform
    the same feature and use the resulting embeddings in many other different algorithms,
    from gradient boosting to linear models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Refer to the diagram in *Figure 7.6* for a clearer understanding of the process
    involving a categorical variable with 24 levels. In the chart, we demonstrate
    how a value from a categorical feature is transformed from a textual or an integer
    value into a vector of values that a neural network can handle:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17574_07_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.6: How an embedding layer works'
  prefs: []
  type: TYPE_NORMAL
- en: Everything starts with knowing how many distinct values the feature has. This
    constitutes the dictionary size and it is an important piece of information. In
    this example, we considered a feature presenting 24 distinct values. This information
    allows us to create a one-hot-encoded vector of size 24 representing each of the
    possible feature values. The resulting vector is then multiplied by a matrix whose
    row size corresponds to the size of the one-hot-encoded vector and column size
    to the size of the output dimensions. In this way, with a vector-matrix multiplication,
    the input of the categorical variable will be transformed into a multidimensional
    numeric one. The effectiveness of the multiplication is ensured by the backpropagation
    algorithm of the neural network, which will update each value in the matrix so
    the most predictive result is obtained from the multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you don’t want to build your own deep neural network in TensorFlow or PyTorch,
    you can rely on a few out-of-the-box architectural solutions. All these solutions
    come out of the box because they are packaged or because other Kagglers have written
    them based on the original papers. Based on their success in tabular competitions,
    here are the main ones you can try when taking on a tabular competition yourself:'
  prefs: []
  type: TYPE_NORMAL
- en: '**TabNet** is a network devised by Google researchers (Arık, S. O. and Pfister.
    T. *Tabnet: Attentive interpretable tabular learning.* arXiv 2020\. [https://www.aaai.org/AAAI21Papers/AAAI-1063.ArikS.pdf](https://www.aaai.org/AAAI21Papers/AAAI-1063.ArikS.pdf))
    that promises to help you select and process the relevant features and to deal
    with both categorical and numeric features in a smart way. It doesn’t have many
    hyperparameters to tune, though the results may deeply differ between an untuned
    network and a tuned one (hence the necessity of spending some time to make it
    work at its best). Here you have a few implementations, such as the excellent
    `pytorch-tabnet` package ([https://github.com/dreamquark-ai/tabnet](https://github.com/dreamquark-ai/tabnet))
    or the implementations coded by *Yirun Zhang* ([https://www.kaggle.com/gogo827jz](https://www.kaggle.com/gogo827jz)),
    found at [https://www.kaggle.com/ludovick/introduction-to-tabnet-kfold-10-training](https://www.kaggle.com/ludovick/introduction-to-tabnet-kfold-10-training)
    and [https://www.kaggle.com/ludovick/introduction-to-tabnet-kfold-10-inference](https://www.kaggle.com/ludovick/introduction-to-tabnet-kfold-10-inference).
    Both were devised for the *Mechanism of Action (MoA) Prediction* competition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neural Oblivious Decision Ensembles** (**NODE**) is an architecture that
    tries to mimic in a neural network how a decision tree works (Popov, S., Morozov,
    S., and Babenko, A. *Neural oblivious decision ensembles for deep learning on
    tabular data*. arXiv preprint arXiv:1909.06312, 2019\. [https://arxiv.org/abs/1909.06312](https://arxiv.org/abs/1909.06312)).
    You can use the implementation offered by Yirun Zhang for TensorFlow at [https://www.kaggle.com/gogo827jz/moa-neural-oblivious-decision-ensembles-tf-keras](https://www.kaggle.com/gogo827jz/moa-neural-oblivious-decision-ensembles-tf-keras)
    or for PyTorch at [https://www.kaggle.com/gogo827jz/moa-public-pytorch-node](https://www.kaggle.com/gogo827jz/moa-public-pytorch-node).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use a wide range of models, such as Wide & Deep, DeepFM, xDeepFM, AutoInt,
    and many others based on factorization machines and mostly devised for click-through
    rate estimation. You don’t have to build all these neural architectures by yourself;
    you can rely on packages such as DeepCTR ([https://github.com/shenweichen/DeepCTR](https://github.com/shenweichen/DeepCTR))
    or DeepTables ([https://github.com/DataCanvasIO/deeptables](https://github.com/DataCanvasIO/deeptables))
    as suggested by *Changhao Lee* ([https://www.kaggle.com/leechh](https://www.kaggle.com/leechh))
    and *Jian Yang* ([https://www.kaggle.com/jackguagua](https://www.kaggle.com/jackguagua)),
    second and first place respectively in the *Categorical Feature Encoding Challenge
    II* competition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In conclusion, you can build your own neural network for tabular data by mixing
    together embedding layers for categorical features and dense layers for numeric
    ones. However, if it doesn’t pay off, you can always rely on quite a wide range
    of good solutions provided by well-written packages. Always be on the lookout
    for a new package appearing: it may help you to perform better both in Kaggle
    competitions and real-world projects. Also, as a piece of advice based on our
    experience, don’t expect a neural network to be the best model in a tabular competition;
    this seldom happens. Instead, blend solutions from classical tabular data models,
    such as gradient boosting models and neural networks, because they tend to pick
    up different signals from the data that you can integrate together in an ensemble.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Jean-Francois_Puget.png)'
  prefs: []
  type: TYPE_IMG
- en: Jean-François Puget
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/cpmpml](https://www.kaggle.com/cpmpml)'
  prefs: []
  type: TYPE_NORMAL
- en: We spoke to Jean-François Puget, aka CPMP, about the importance of reproducibility,
    how to work with data, his best competition, and more. As a Kaggle Grandmaster
    in Competitions and Discussions, and a Distinguished Engineer at RAPIDS, NVIDIA,
    he had many good insights to share with us. The editor particularly likes what
    he has to say about the scientific method.
  prefs: []
  type: TYPE_NORMAL
- en: What’s your favorite kind of competition and why? In terms of techniques and
    solving approaches, what is your specialty on Kaggle?
  prefs: []
  type: TYPE_NORMAL
- en: '*I like competitions with a scientific background, or a background I can relate
    to. I dislike anonymous data and synthetic data, unless the data is generated
    via a very precise physics simulation. More generally, I like Kaggle competitions
    on domains I don’t know much about, as this is where I will learn the most. It
    is not the most effective way to get ranking points, but it is the one I entertain
    most.*'
  prefs: []
  type: TYPE_NORMAL
- en: How do you approach a Kaggle competition? How different is this approach to
    what you do in your day-to-day work?
  prefs: []
  type: TYPE_NORMAL
- en: '*I start by looking at data and understanding it as well as possible. I try
    to find patterns in it, especially predictive patterns. What I often do is plot
    samples using two features or derived features on the x and y axis, and a third
    feature for color coding samples. One of the three features can be the target.
    I use lots of visualization, as I believe that human vision is the best data analysis
    tool there is.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The second thing I spend time on is how to assess model or pipeline performance.
    Indeed, it is extremely important to be able to evaluate the performance of a
    model as accurately as possible. There is no surprise here; evaluation is often
    a variant of k-fold cross-validation. But the fold definition can be tailored
    to the competition type (time-based folds for forecasting competitions, group
    k-fold when samples are linked together for some reason, e.g., actions with the
    same user ID, etc.).*'
  prefs: []
  type: TYPE_NORMAL
- en: '*I then create an end-to-end baseline that goes from data to submission, and
    try it. If this is a code competition, then testing that you have gotten your
    pipeline right is key.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Then I try more complex models (if using deep learning models), or more features
    (if using XGBoost or other models from RAPIDS or sklearn). I submit these to see
    if there is a correlation between my local evaluation score and the public test
    score. If the correlation is good, then I submit less and less.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*After a few weeks, I spend time doing hyperparameter tuning. But I do it only
    once, or maybe twice with a last tuning near the end of the competition. Indeed,
    hyperparameter tuning is one of the best ways to overfit, and I fear overfitting
    a lot.*'
  prefs: []
  type: TYPE_NORMAL
- en: Tell us about a particularly challenging competition you entered, and what insights
    you used to tackle the task.
  prefs: []
  type: TYPE_NORMAL
- en: '*One of the competitions I am the most proud of is the* TalkingData AdTracking
    Fraud Detection Challenge *competition, where we had a very large volume of click
    history and we had to predict which clicks led to some app downloads. There were
    very few features and a large number of rows (like half a billion). At the time
    I only had a 64 GB machine, and I had to implement a very efficient way to create
    new features and evaluate them. I had a few insights in this competition. First,
    that the click that led to an app download was the last click on the app download
    page for a user. Therefore, the “time to next click from the same user on the
    same app” was the most important feature. A derived insight was this: there were
    quite a number of clicks from the same user and app with the same timestamp. I
    hypothesized that the one with a download, if any, was the last one. A third insight
    was to use a matrix factorization approach to approximate feature value co-occurrences.
    I implemented a libFM model in Keras at the time, and adding the latent vectors
    as features helped. The only other team doing this was the top team. With this,
    I got a solo 6th place among teams of GMs. I was not a Kaggle GM yet.*'
  prefs: []
  type: TYPE_NORMAL
- en: Has Kaggle helped you in your career? If so, how?
  prefs: []
  type: TYPE_NORMAL
- en: '*Kaggle helped me twice. At IBM, Kaggle was a great source of knowledge on
    SOTA machine learning practices. I used that knowledge to inform and guide the
    development of IBM machine learning tooling (IBM Watson Studio and IBM Watson
    Machine Learning).*'
  prefs: []
  type: TYPE_NORMAL
- en: '*For instance, I managed to have IBM support Python packages in 2016 at a time
    when IBM was a Java/Scala powerhouse. Without me, IBM would have bet on Spark
    and Scala for machine learning, and would have missed the Python wave entirely.
    I also pushed for XGBoost very early, when IBM wanted to only support Spark ML
    or TensorFlow.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The second time Kaggle helped me was for getting my current job. NVIDIA was
    looking for Kaggle competition GMs with good social presence to help promote the
    NVIDIA stack, including the RAPIDS GPU accelerated ML package.*'
  prefs: []
  type: TYPE_NORMAL
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  prefs: []
  type: TYPE_NORMAL
- en: '*The one thing that differentiates Kagglers from other data scientists is the
    evaluation of model performance. Kagglers need to master this, because if they
    don’t, then they choose submissions that look great on the public leaderboard
    but perform poorly on the private leaderboard. Once a Kaggler knows how to build
    models that perform well on the private leaderboard, then they know how to build
    models that perform well on new data, i.e., models that do not overfit.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The other thing that inexperienced Kagglers do is to ask if method/model X
    can work in a given competition. My answer to this is always, “Try it and see
    if it works or not.” People often miss that machine learning is an experimental
    science. In order to build good models, one must follow the scientific method:*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Make a hypothesis (e.g., adding this feature, or adding this NN layer, will
    improve pipeline performance)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Run an experiment to test the hypothesis (train the modified pipeline)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Analyze experiment results (is CV score better than before? Where is it better?
    Where is it worse?)*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Each experiment should be done so that it can confirm or reject a hypothesis.
    For this, an experiment should change only one thing at a time. Often, inexperienced
    people change many things, then cannot conclude what worked or not.*'
  prefs: []
  type: TYPE_NORMAL
- en: Are there any particular tools or libraries that you would recommend using for
    data analysis and machine learning?
  prefs: []
  type: TYPE_NORMAL
- en: '*I use Matplotlib plots mostly for data exploration. I do data wrangling in
    Pandas if the dataset is small, or in cuDF (from RAPIDS) if the dataset is large.
    For machine learning, I use cuML from RAPIDS, XGBoost with GPU acceleration, and
    PyTorch. If possible, I will use pretrained models, for instance NLP models from
    Hugging Face, or image classification models from the timm package.*'
  prefs: []
  type: TYPE_NORMAL
- en: What’s the most important thing someone should keep in mind or do when they’re
    entering a competition?
  prefs: []
  type: TYPE_NORMAL
- en: '*Make sure you can spend enough time on it.*'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have discussed tabular competitions on Kaggle. Since most
    of the knowledge applicable in a tabular competition overlaps with standard data
    science knowledge and practices, we have focused our attention on techniques more
    specific to Kaggle.
  prefs: []
  type: TYPE_NORMAL
- en: Starting from the recently introduced Tabular Playground Series, we touched
    on topics relating to reproducibility, EDA, feature engineering, feature selection,
    target encoding, pseudo-labeling, and neural networks applied to tabular datasets.
  prefs: []
  type: TYPE_NORMAL
- en: EDA is a crucial phase if you want to get insights on how to win a competition.
    It is also quite unstructured and heavily dependent on the kind of data you have.
    Aside from giving you general advice on EDA, we brought your attention to techniques
    such as t-SNE and UMAP that can summarize your entire dataset at a glance. The
    next phase, feature engineering, is also strongly dependent on the kind of data
    you are working on. We therefore provided a series of possible feature engineering
    ideas that you can try applying to your specific case. As for feature selection,
    after a brief overview, we drew your attention to techniques based on feature
    importance and randomization, which can be applied to almost any machine learning
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'After explaining target encoding, which we wanted to point out cannot be dealt
    with in an automated way, we moved on to special techniques that you probably
    won’t apply in your real-world projects but that can work very well in Kaggle
    competitions: pseudo-labeling and denoising autoencoders for tabular competitions.
    Finally, after discussing how categorical features can also be dealt with using
    embedding layers in neural networks, we gave you a quick overview of the pre-made
    neural architectures that could work for tabular data.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will complete our overview of all the techniques that
    you need to take on tabular competitions by discussing how best to perform hyperparameter
    optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/KaggleDiscord](https://packt.link/KaggleDiscord)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code40480600921811704671.png)'
  prefs: []
  type: TYPE_IMG
