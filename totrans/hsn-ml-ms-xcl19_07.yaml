- en: Correlations and the Importance of Variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Correlation between variables, in general, means that a change in one variable
    reflects on the other. However, it does not mean that the change in one variable
    is *caused* by the change in the correlated variable. For example, the selling
    price of a product is correlated to its manufacturing cost, but the price increase
    is not totally caused by it, since there are other factors such as transportation
    and inflation to take into account.
  prefs: []
  type: TYPE_NORMAL
- en: Not every variable or feature in a dataset is useful for the analysis that we
    are planning and, sometimes, many of them are redundant. Strong correlations between
    pairs of variables tell us which ones can be discarded and which ones are important
    to predict or explain the target variable.
  prefs: []
  type: TYPE_NORMAL
- en: Different correlation calculations can be performed in Excel and used to determine
    the relative importance of the input features. We will show some of them in this
    chapter, together with graphical methods.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset that will be used in this chapter has been taken from the StatLib
    library, which is maintained at Carnegie Mellon University, and relates the different
    variables of a car to its fuel consumption.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a scatter diagram
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating the covariance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating the Pearson's coefficient of correlation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studying the Spearman's correlation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding least squares
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focusing on feature selection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need to download the `auto-mpg.xlsx` file from the GitHub repository
    at [https://github.com/PacktPublishing/Hands-On-Machine-Learning-with-Microsoft-Excel-2019/tree/master/Chapter05](https://github.com/PacktPublishing/Hands-On-Machine-Learning-with-Microsoft-Excel-2019/tree/master/Chapter05)[.](https://github.com/PacktPublishing/Hands-On-Machine-Learning-with-Microsoft-Excel-2019/tree/master/Chapter05)
  prefs: []
  type: TYPE_NORMAL
- en: Building a scatter diagram
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, load the `auto-mpg.xlsx` file. We will use the data in it to illustrate
    different aspects of this chapter. The meaning of the variables are described
    in the Excel file and in its references.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest way of assessing correlations between variables is to create a
    scatter diagram, taking all features in pairs. If we plot, for example, the `Cylinders` variable
    in the *x *axis against the `Displacement` variable in the *y *axis, we will see
    a *positive* *correlation* (that is, the greater the number of cylinders the higher
    the displacement value). This is to be expected, since the calculation of the
    engine displacement, here expressed in cubic inches, is linearly dependent on
    the number of cylinders.
  prefs: []
  type: TYPE_NORMAL
- en: 'The scatter diagram can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cbb435b0-cc7e-46b7-b0c1-756db3eb7a9f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we, instead, look at the relationship between fuel consumption and car weight,
    the diagram will be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7290f2f2-a217-4d79-b998-542b38460ff8.png)'
  prefs: []
  type: TYPE_IMG
- en: In this case, there is a negative correlation between the weight of the car
    and the number of miles per fuel gallon (that is, the heavier the car, the fewer
    number of miles it can run on a gallon of fuel). We also notice that the correlation
    is non-linear, meaning that a straight line will not describe the relationship
    between these variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, what if we plot two uncorrelated variables? Could there be any correlation
    between, for example, the number of cylinders in the engine and the year that
    the car was manufactured? Let''s take a look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b9267c13-4116-4d9c-81da-a133e48cbeae.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we notice that cars with **3** or **5** cylinders were not very common
    in the time period that we are analyzing, as there are only a few examples of
    them. Years **78** to **80** seem to be the **5**-cylinder engine period, but,
    apart from these facts, there were also **4**-, **6**-, and **8**-cylinder engines
    being produced for each year of our dataset. There is no clear correlation between
    these two variables, and one of them cannot give us any information about the
    other.
  prefs: []
  type: TYPE_NORMAL
- en: 'This method of finding correlations in scatter diagrams is fine if we have
    a few variables, but the number of diagrams needs scales fast. In fact, if the
    number of variables is *N[v]*, then the number of combinations needed to see all
    correlations is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*N[v ]* (N[v ]-1)*'
  prefs: []
  type: TYPE_NORMAL
- en: Even with a small dataset such as ours, to include 8 numerical variables, we
    need 28 diagrams to cover all the possible combinations. If we were to have hundreds
    of variables, then the task of finding which variables are correlated by eye is
    simply impossible. In the next section, we will describe methods to automatically
    calculate correlations, making it possible to deal with big datasets and a large
    number of features.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the covariance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need to define a statistical method that quantitatively measures the degree
    of association between two features. The covariance of two variables does exactly
    that, so let''s see how it is calculated. If there are two variables, *x* and
    *y*, we first center their values around their mean values, ![](img/69efd6ca-3339-4487-b25a-d98481e9c20a.png) and ![](img/11a5b30d-ca86-4e2c-8eae-20607818ddf9.png);
    then, we multiply the new values and take the mean of the product:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de5b5ebf-f471-42fa-9bb1-ebd671867b85.png)'
  prefs: []
  type: TYPE_IMG
- en: This definition implies that if both variables increase or decrease at the same
    time, then the covariance is positive, whereas if they move in opposite directions,
    then the covariance is negative. If there is no correlation, the covariance value
    will be small, that is, close to zero.
  prefs: []
  type: TYPE_NORMAL
- en: It is also clear from the definition that, since the variables keep their scale,
    it is difficult to compare features that have very different mean values and it
    is impossible to compare two covariances.
  prefs: []
  type: TYPE_NORMAL
- en: It is easy to calculate covariances in Excel by using the Data analysis add-in
    (we explain how to activate it in the Appendix).
  prefs: []
  type: TYPE_NORMAL
- en: 'To calculate the covariances, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the data file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to Data | Data Analysis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the pop-up window, select Covariance, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3188dae5-2b12-4074-86b5-6c369067ca59.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select the data range; in this case, it is the whole table except the last
    column, which contains the car name and is non-numeric:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b25c1e26-4f31-45d5-996d-9413910fc748.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The result is the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d68062e0-ddfb-4091-a3f1-999cecaf14d8.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see a positive covariance value between `displacement` and `cylinders`,
    and a negative value between `weight` and `mpg`. We cannot say much more, since
    comparing the values is impossible, as we explained previously. The big change
    here is that we calculated all that values at the same time, and so we don't need
    to watch the diagrams one by one. The matrix is symmetrical, so only one half
    is shown.
  prefs: []
  type: TYPE_NORMAL
- en: There is a way to quantify correlations and compare them, and it was developed
    by Karl Pearson in the 1880s. Let's explore it in more detail in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the Pearson's coefficient of correlation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Pearson''s coefficient is most commonly used when comparing two variables
    and it works by measuring the linear relationship between them. The original definition
    given by Pearson is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2171e11a-435a-4b49-96bd-f7cbcb0ce262.png)'
  prefs: []
  type: TYPE_IMG
- en: The numerator is proportional to the covariance, and the denominator is the
    product of the standard deviations (σ) of the centered variables. This normalization
    ensures that the limits in the possible values of *ρ* are *-1* and *1*.
  prefs: []
  type: TYPE_NORMAL
- en: We can repeat the steps outlined in the *Calculating the covariance* section
    to calculate the Pearson correlation in Excel by selecting Correlation in the
    pop-up window.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting table is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8ea53abc-e1dc-4de7-849a-817a21ec4bcd.png)'
  prefs: []
  type: TYPE_IMG
- en: The cells containing a value of `1` represent the linear relationship between
    itself and each variable. A negative correlation implies, again, that one variable
    increases while the other decreases, while a positive correlation implies that
    both variables change in the same direction.
  prefs: []
  type: TYPE_NORMAL
- en: Pearson's coefficient is good for comparing feature relationships. For example,
    we can see that `cylinders` and `displacement` are more linearly correlated (by
    the definition of displacement, in fact) than `weight` and `mpg`, even when the
    ones in the second pair are related.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another definition for the Pearson coefficient is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/94bae1ba-6a8f-4afe-8364-eac87f254abe.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *b* is the slope of the linear regression that best fits *x* versus *y*,
    and *σ[i]* are the standard deviations of *x* and *y*. This definition clearly
    shows that the coefficient measures the linearity of the relationship and, at
    the same time, how much the two features can vary.
  prefs: []
  type: TYPE_NORMAL
- en: So, what if the relationship is not linear? In the next section, we can discuss
    another coefficient that will help us calculate a non-linear correlation.
  prefs: []
  type: TYPE_NORMAL
- en: Studying the Spearman's correlation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To calculate the Spearman's coefficient, we need to first rank the values of
    each variable, that is, the order of the values when we sort them from highest
    to lowest. Once we have the new table, we will calculate Pearson's *ρ* on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a new sheet, we define the following formula in a cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '*=RANK.AVG(Data!A2;auto_mpg[mpg])*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we are asking Excel to write in that cell the ranking corresponding to
    the first cell of the `mpg` column in our data table, taking into account the
    full range of the column. We copy the formula to the cells on the right until
    we complete the number of columns of the data table (8 columns). It doesn''t matter
    if you copy the formula to an extra cell – you will just get an error message
    since you are out of the data table range. In a similar way, we can copy the formulas
    to the remaining rows until we get to row **399** (the vertical range of the data
    table). We can even add a title to the new columns by using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '*=CONCAT("Rank_";auto_mpg[[#Headers];[mpg]])*'
  prefs: []
  type: TYPE_NORMAL
- en: Then, we copy it to all the cells in the first row.
  prefs: []
  type: TYPE_NORMAL
- en: 'A sample of the table that we obtain is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b8b0b6ca-d128-4561-a8c5-5bf4a2206932.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Because `horsepower`is missing some values, they cannot be ranked and so appear
    as `#N/A`*.* Since there are only a few of them, we can remove them manually.
    This will avoid errors when calculating the Pearson coefficient in the next step, exactly
    as we did before; the result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/33243ad4-e948-4605-bacf-f5af6f1fe46b.png)'
  prefs: []
  type: TYPE_IMG
- en: We get similar values to that of the Pearson's coefficients, but they are slightly
    higher when there is a non-linear but strong correlation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spearman is only close to **1** if the correlation is monotonically increasing
    or decreasing. This is better shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/942e1f3a-667e-410d-8b06-41966fc144d5.png)'
  prefs: []
  type: TYPE_IMG
- en: In the first diagram, Pearson is high, since the relationship can be adjusted
    by a straight line, even if it is not the best fit. Spearman is **1** since there
    is a relationship and it is monotonically increasing. The second diagram shows
    a relationship with an abrupt change, giving a small value for both coefficients.
    The third diagram shows a quadratic relationship between variables, which is neither
    linear nor monotonic. Looking at the three examples, we can understand that coefficients
    don't always give all the necessary information about the correlation between
    variables, but they are useful to get a general idea.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding least squares
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In some instances, we might want to prove that there is a functional relationship
    between two variables and, hence, just use one of them in our model – since the
    other can be easily approximated by an expression. In this case, it is useful
    to rely on the least squares method. Given a set of points (*x[i],y[i]*) and a
    function such as *y''[i] = f(x[i])*, this method minimizes the square of the differences
    between *y''[i]* and *y[i]*. The general expression for the minimization that
    we are calculating is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e1580832-57ab-4e80-9900-c20bd1c646d9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will use two columns from our data table, namely `weight` and `mpg`:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new table in a new sheet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the values of the `weight` and `mpg` columns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Order the rows by the value of `weight`; the resulting table is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0e981124-8900-4e46-9cdb-c7cae4f4f009.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Insert a line chart to see what the functional relationship looks like, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/406a31b6-bcca-4f3e-babb-ea52ab3d1997.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's say that we assume that *mpg = A*weight^(-b)* and try to find the constants, *a*
    and *b*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new column, `prediction`, using the following formula:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*=$H$2*POWER([@weight];$H$3)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting table is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/47292ee2-d5eb-41a2-b63e-84b02b6efbff.png)'
  prefs: []
  type: TYPE_IMG
- en: In order to fill the table, we choose the initial values of *a = 60* (in cell
    *H2*) and *b = -0.5* (in cell *H3*). These will be the starting points of the
    least squares method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The quantity to minimize is the sum of the squares of the errors. To calculate
    it, we create a new column, `Squared error`, with the following formula:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*=([@mpg]-[@prediction])^2*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, use the following formula to sum all the values in that column in a cell:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*=SUM(Table9[Squared error])*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to Data | Solver; if you cannot see this option, please refer to the
    Appendix for instructions on how to activate Solver. You will see the following
    window pop up on your screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7aef1ec0-6598-4927-a310-1f6e1b31b3a2.png)'
  prefs: []
  type: TYPE_IMG
- en: The Set Objective option is filled with the cell ID where we calculated the
    sum of the squared errors, and the By Changing Variable Cells option is filled
    with the ID of the two cells containing the values of *a* and *b*. We can leave
    the rest of the parameters as their default value settings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on Solve; if the regression converges, then you will see the following
    window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0684e405-de49-43f1-b240-b8ba8e9df0a9.png)'
  prefs: []
  type: TYPE_IMG
- en: Choose Keep Solver Solution to replace the values of *a* and *b* by the ones
    calculated, and get new values for all predictions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If we include the real values and the prediction in the same diagram, you should
    see something similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/21a796f8-d911-490e-a168-808e667456bb.png)'
  prefs: []
  type: TYPE_IMG
- en: So, the adjusted function of the data points is approximately *mpg = 68564/weight*.
  prefs: []
  type: TYPE_NORMAL
- en: This adjustment is not precise due to the large dispersion in the y variable,
    but it could be used as a quick estimation of the fuel consumption, given the
    weight of the car.
  prefs: []
  type: TYPE_NORMAL
- en: We have explored a number of methods for finding correlated variables. This
    is useful for understanding which ones are related and which ones are redundant.
    The next section explains how to use this knowledge to simplify the input to our
    machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Focusing on feature selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned previously, none of these described methods will tell us precisely
    how to choose the input features by themselves. It is true that in some particular
    cases, if the correlations are strong enough, we could discard one or more features
    and just keep the ones that represent them by correlation. In general, feature
    engineering is a long and time-consuming task that became almost a separate field
    of study within machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: There are automatic techniques to perform feature engineering, which are part
    of what is generically called **Automatic Machine Learning** (**AutoML**). The
    method consists of letting the computer try different feature sets, including
    combinations of them, and test the results until the best set is found. In spite
    of this, there is no general recipe for selecting features, and each problem has
    to be analyzed—in particular, finding the set of features that lead to a better
    model training and predictive power.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we described the most widely used methods to establish correlations
    between variables, which will later be used as features in a machine learning
    model. This is a long and difficult task, but is the basis of a good predictive
    model.
  prefs: []
  type: TYPE_NORMAL
- en: No method can be used alone to determine which features are important and which
    can be discarded. A combination of methods, plus a deep knowledge of the dataset,
    are fundamental to complete this task.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will leave the preliminary tasks and start focusing
    on some real use cases of the machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What method would be better to find a correlation between a numerical and a
    categorical variable?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build some other plot graphs between a pair of variables and study the correlations
    and the logic behind them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does a negative Pearson coefficient value imply that one of the variables has
    negative values?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The table of the Pearson's coefficient can be colored or have bars added to
    it in order to better compare the different values. Explore these options in Quick
    Analysis | Formatting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The quality of the least square regression is usually measured by the value
    of R². Calculate this value for the function that was adjusted in the `mpg` column
    versus the `weight` data value (hint: you only need to calculate one more sum
    of values – refer to the literature for more information).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The value that was calculated in the previous question should be close to 0.7,
    which is not good enough to prove that the function reproduces the data well.
    Try a different function and see what the result is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Statistics: A Gentle Introduction*, written by Frederick L. Coolidge (refer
    to Chapter 6 and the references within)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
