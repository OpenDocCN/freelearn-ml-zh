<html><head></head><body>
  <div id="_idContainer006">
    <h1 id="_idParaDest-7" class="mainHeading">Preface</h1>
    <p class="normal">Having competed on Kaggle for over ten years, both of us have experienced highs and lows over many competitions. We often found ourselves refocusing our efforts on different activities relating to Kaggle. Over time, we devoted ourselves not just to competitions but also to creating content and code based on the demands of the data science market and our own professional aspirations. At this point in our journey, we felt that our combined experience and still-burning passion for competitions could really help other participants who have just started, or who would like to get inspired, to get hold of the essential expertise they need, so they can start their own journey in data science competitions.</p>
    <p class="normal">We then decided to work on this book with a purpose:</p>
    <ul>
      <li class="bulletList">To offer, in a single place, the best tips for being competitive and approaching most of the problems you may find when participating on Kaggle and also other data science competitions.</li>
      <li class="bulletList">To offer enough suggestions to allow anyone to reach at least the Expert level in any Kaggle discipline: Competitions, Datasets, Notebooks, or Discussions.</li>
      <li class="bulletList">To provide tips on how to learn the most from Kaggle and leverage this experience for professional growth in data science.</li>
      <li class="bulletList">To gather in a single source the largest number of perspectives on the experience of participating in competitions, by interviewing Kaggle Masters and Grandmasters and listening to their stories.</li>
    </ul>
    <p class="normal">In short, we have written a book that demonstrates how to participate in competitions successfully and make the most of all the opportunities that Kaggle offers. The book is also intended as a practical reference that saves you time and effort, through its selection of many competition tips and tricks that are hard to learn about and find on the internet or on Kaggle forums. Nevertheless, the book doesn’t limit itself to providing practical help; it also aspires to help you figure out how to boost your career in data science by participating in competitions.</p>
    <p class="normal">Please be aware: this book doesn’t teach you data science from the basics. We don’t explain in detail how linear regression or random forests or gradient boosting work, but how to use them in the best way and obtain the best results from them in a data problem. We expect solid foundations and at least a basic proficiency in data science topics and Python usage from our readers. If you are still a data science beginner, you need to supplement this book with other books on data science, machine learning, and deep learning, and train up on online courses, such as those offered by Kaggle itself or by MOOCs such as edX or Coursera.</p>
    <p class="normal">If you want to start learning data science in a practical way, if you want to challenge yourself with tricky and intriguing data problems and simultaneously build a network of great fellow data scientists as passionate about their work in data as you are, this is indeed the book for you. Let’s get started!</p>
    <h1 id="_idParaDest-8" class="heading-1">Who this book is for</h1>
    <p class="normal">At the time of completion of this book, there are 96,190 Kaggle novices (users who have just registered on the website) and 67,666 Kaggle contributors (users who have just filled in their profile) enlisted in Kaggle competitions. This book has been written for all of them and for anyone else wanting to break the ice and start taking part in competitions on Kaggle and learning from them.</p>
    <h1 id="_idParaDest-9" class="heading-1">What this book covers</h1>
    <h2 id="_idParaDest-10" class="heading-2">Part 1: Introduction to Competitions</h2>
    <p class="normal"><em class="chapterRef">Chapter 1</em>, <em class="italic">Introducing Kaggle and Other Data Science Competitions</em>, discusses how competitive programming evolved into data science competitions. It explains why the Kaggle platform is the most popular site for these competitions and provides you with an idea about how it works.</p>
    <p class="normal"><em class="chapterRef">Chapter 2</em>, <em class="italic">Organizing Data with Datasets</em>, introduces you to Kaggle Datasets, the standard method of data storage on the platform. We discuss setup, gathering data, and utilizing it in your work on Kaggle.</p>
    <p class="normal"><em class="chapterRef">Chapter 3</em>, <em class="italic">Working and Learning with Kaggle Notebooks</em>, discusses Kaggle Notebooks, the baseline coding environment. We talk about the basics of Notebook usage, as well as how to leverage the GCP environment, and using them to build up your data science portfolio.</p>
    <p class="normal"><em class="chapterRef">Chapter 4</em>, <em class="italic">Leveraging Discussion Forums</em>, allows you to familiarize yourself with discussion forums, the primary manner of communication and idea exchange on Kaggle.</p>
    <h2 id="_idParaDest-11" class="heading-2">Part 2: Sharpening Your Skills for Competitions</h2>
    <p class="normal"><em class="chapterRef">Chapter 5</em>, <em class="italic">Competition Tasks and Metrics</em>, details how evaluation metrics for certain kinds of problems strongly influence the way you can operate when building your model solution in a data science competition. The chapter also addresses the large variety of metrics available in Kaggle competitions.</p>
    <p class="normal"><em class="chapterRef">Chapter 6</em>, <em class="italic">Designing Good Validation</em>, will introduce you to the importance of validation in data competitions, discussing overfitting, shake-ups, leakage, adversarial validation, different kinds of validation strategies, and strategies for your final submissions.</p>
    <p class="normal"><em class="chapterRef">Chapter 7</em>, <em class="italic">Modeling for Tabular Competitions</em>, discusses tabular competitions, mostly focusing on the more recent reality of Kaggle, the Tabular Playground Series. Tabular problems are standard practice for the majority of data scientists around and there is a lot to learn from Kaggle.</p>
    <p class="normal"><em class="chapterRef">Chapter 8</em>, <em class="italic">Hyperparameter Optimization</em>, explores how to extend the cross-validation approach to find the best hyperparameters for your models – in other words, those that can generalize in the best way on the private leaderboard – under the pressure and scarcity of time and resources that you experience in Kaggle competitions.</p>
    <p class="normal"><em class="chapterRef">Chapter 9</em>, <em class="italic">Ensembling with Blending and Stacking Solutions</em>, explains ensembling techniques for multiple models such as averaging, blending, and stacking. We will provide you with some theory, some practice, and some code examples you can use as templates when building your own solutions on Kaggle.</p>
    <p class="normal"><em class="chapterRef">Chapter 10</em>, <em class="italic">Modeling for Computer Vision</em>, we discuss problems related to computer vision, one of the most popular topics in AI in general, and on Kaggle specifically. We demonstrate full pipelines for building solutions to challenges in image classification, object detection, and image segmentation.</p>
    <p class="normal"><em class="chapterRef">Chapter 11</em>, <em class="italic">Modeling for NLP</em>, focuses on the frequently encountered types of Kaggle challenges related to natural language processing. We demonstrate how to build an end-to-end solution for popular problems like open domain question answering.</p>
    <p class="normal"><em class="chapterRef">Chapter 12</em>, <em class="italic">Simulation and Optimization Competitions</em>, provides an overview of simulation competitions, a new class of contests gaining popularity on Kaggle over the last few years.</p>
    <h2 id="_idParaDest-12" class="heading-2">Part 3: Leveraging Competitions for Your Career</h2>
    <p class="normal"><em class="chapterRef">Chapter 13</em>, <em class="italic">Creating Your Portfolio of Projects and Ideas</em>, explores ways you can stand out by showcasing your work on Kaggle itself and other sites in an appropriate way.</p>
    <p class="normal"><em class="chapterRef">Chapter 14</em>, <em class="italic">Finding New Professional Opportunities</em>, concludes the overview of how Kaggle can positively affect your career by discussing the best ways to leverage all your Kaggle experience in order to find new professional opportunities.</p>
    <h1 id="_idParaDest-13" class="heading-1">To get the most out of this book</h1>
    <p class="normal">The Python code in this book has been designed to be run on a Kaggle Notebook, without any installation on a local computer. Therefore, don’t worry about what machine you have available or what version of Python packages you should install. </p>
    <p class="normal">All you need is a computer with access to the internet and a free Kaggle account. In fact, to run the code on a Kaggle Notebook (you will find instructions about the procedure in <em class="chapterRef">Chapter 3</em>), you first need to open an account on Kaggle. If you don’t have one yet, just go to <a href="https://www.kaggle.com"><span class="url">www.kaggle.com</span></a> and follow the instructions on the website.</p>
    <p class="normal">We link out to many different resources throughout the book that we think you will find useful. When referred to a link, explore it: you will find code available on public Kaggle Notebooks that you can reuse, or further materials to illustrate concepts and ideas that we have discussed in the book.</p>
    <h2 id="_idParaDest-14" class="heading-2">Download the example code files</h2>
    <p class="normal">The code bundle for the book is hosted on GitHub at <a href="https://github.com/PacktPublishing/The-Kaggle-Book"><span class="url">https://github.com/PacktPublishing/The-Kaggle-Book</span></a>. We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/"><span class="url">https://github.com/PacktPublishing/</span></a>. Check them out!</p>
    <h2 id="_idParaDest-15" class="heading-2">Download the color images</h2>
    <p class="normal">We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="https://static.packt-cdn.com/downloads/9781801817479_ColorImages.pdf"><span class="url">https://static.packt-cdn.com/downloads/9781801817479_ColorImages.pdf</span></a>.</p>
    <h2 id="_idParaDest-16" class="heading-2">Conventions used</h2>
    <p class="normal">There are a few text conventions used throughout this book.</p>
    <p class="normal"><code class="inlineCode">CodeInText</code>: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. For example; “ The dataset will be downloaded to the <code class="inlineCode">Kaggle</code> folder as a <code class="inlineCode">.zip</code> archive – unpack it and you are good to go.”</p>
    <p class="normal">A block of code is set as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive
drive.mount(<span class="hljs-string">'/content/gdrive'</span>)
</code></pre>
    <p class="normal">Any command-line input or output is written as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">I genuinely have no idea what the output of this sequence of words will be - it will be interesting to find out what nlpaug can do with this!
</code></pre>
    <p class="normal"><strong class="keyWord">Bold</strong>: Indicates a new term, an important word, or words that you see on the screen, for example, in menus or dialog boxes. For example: “ The specific limits at the time of writing are <strong class="keyWord">100 GB per private dataset</strong> and a <strong class="keyWord">100 GB total</strong> quota.”</p>
    <div class="note">
      <p class="normal">Further notes, references, and links to useful places appear like this.</p>
    </div>
    <div class="packt_tip">
      <p class="normal">Tips and tricks appear like this.</p>
    </div>
    <h1 id="_idParaDest-17" class="heading-1">Get in touch</h1>
    <p class="normal">Feedback from our readers is always welcome.</p>
    <p class="normal"><strong class="keyWord">General feedback</strong>: Email <code class="inlineCode">feedback@packtpub.com</code>, and mention the book’s title in the subject of your message. If you have questions about any aspect of this book, please email us at <code class="inlineCode">questions@packtpub.com</code>.</p>
    <p class="normal"><strong class="keyWord">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/submit-errata"><span class="url">http://www.packtpub.com/submit-errata</span></a>, selecting your book, clicking on the <strong class="screenText">Errata Submission Form</strong> link, and entering the details.</p>
    <p class="normal"><strong class="keyWord">Piracy</strong>: If you come across any illegal copies of our works in any form on the Internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <code class="inlineCode">copyright@packtpub.com</code> with a link to the material.</p>
    <p class="normal"><strong class="keyWord">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com"><span class="url">http://authors.packtpub.com</span></a>.</p>
  </div>
  <div id="_idContainer007" class="Basic-Text-Frame">
    <h1 id="_idParaDest-18" class="heading-1">Share your thoughts</h1>
    <p class="normal">Once you’ve read <em class="italic">The Kaggle Book</em>, we’d love to hear your thoughts! Please <a href="https://packt.link/r/1-801-81747-2"><span class="url">click here to go straight to the Amazon review page</span></a> for this book and share your feedback.</p>
    <p class="normal">Your review is important to us and the tech community and will help us make sure we’re delivering excellent quality content.</p>
  </div>
</body></html>