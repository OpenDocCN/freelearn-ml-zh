["```py\n    int main() \n    { \n      // Open the video file \n      cv::VideoCapture capture(\"bike.avi\"); \n      // check if video successfully opened \n      if (!capture.isOpened()) \n        return 1; \n\n      // Get the frame rate \n      double rate= capture.get(CV_CAP_PROP_FPS); \n\n      bool stop(false); \n      cv::Mat frame;    // current video frame \n      cv::namedWindow(\"Extracted Frame\"); \n\n      // Delay between each frame in ms \n      // corresponds to video frame rate \n      int delay= 1000/rate; \n\n      // for all frames in video \n      while (!stop) { \n\n        // read next frame if any \n        if (!capture.read(frame)) \n          break; \n\n        cv::imshow(\"Extracted Frame\",frame); \n\n        // introduce a delay \n        // or press key to stop \n        if (cv::waitKey(delay)>=0) \n          stop= true; \n      } \n\n      // Close the video file. \n      // Not required since called by destructor \n      capture.release(); \n      return 0; \n    } \n\n```", "```py\n    long t= static_cast<long>( capture.get(CV_CAP_PROP_FRAME_COUNT)); \n\n```", "```py\n    // goto frame 100 \n    double position= 100.0; \n    capture.set(CV_CAP_PROP_POS_FRAMES, position); \n\n```", "```py\n    capture >> frame; \n\n```", "```py\n    capture.grab(); \n    capture.retrieve(frame); \n\n```", "```py\n    cv::VideoCapture capture(\"http://www.laganiere.name/bike.avi\"); \n\n```", "```py\n    void processFrame(cv::Mat& img, cv::Mat& out); \n\n```", "```py\n    void canny(cv::Mat& img, cv::Mat& out) { \n      // Convert to gray \n      if (img.channels()==3) \n        cv::cvtColor(img,out, cv::COLOR_BGR2GRAY); \n      // Compute Canny edges \n      cv::Canny(out,out,100,200); \n      // Invert the image \n      cv::threshold(out,out,128,255,cv::THRESH_BINARY_INV); \n    } \n\n```", "```py\n      // Create instance \n      VideoProcessor processor; \n      // Open video file \n      processor.setInput(\"bike.avi\"); \n      // Declare a window to display the video \n      processor.displayInput(\"Current Frame\"); \n      processor.displayOutput(\"Output Frame\"); \n      // Play the video at the original frame rate \n      processor.setDelay(1000./processor.getFrameRate()); \n      // Set the frame processor callback function \n      processor.setFrameProcessor(canny); \n      // Start the process \n      processor.run(); \n\n```", "```py\n    class VideoProcessor { \n\n      private: \n\n       // the OpenCV video capture object \n       cv::VideoCapture capture; \n       // the callback function to be called  \n       // for the processing of each frame \n       void (*process)(cv::Mat&, cv::Mat&); \n       // a bool to determine if the  \n       // process callback will be called \n       bool callIt; \n       // Input display window name \n       std::string windowNameInput; \n       // Output display window name \n       std::string windowNameOutput; \n       // delay between each frame processing \n       int delay; \n       // number of processed frames  \n       long fnumber; \n       // stop at this frame number \n       long frameToStop; \n       // to stop the processing \n       bool stop; \n\n```", "```py\n      // set the callback function that \n      // will be called for each frame \n      void setFrameProcessor(void (*frameProcessingCallback)\n                             (cv::Mat&, cv::Mat&)) { \n\n        process= frameProcessingCallback; \n      } \n\n```", "```py\n      //set the name of the video file \n      bool setInput(std::string filename) { \n\n        fnumber= 0; \n        // In case a resource was already  \n        // associated with the VideoCapture instance \n        capture.release(); \n        // Open the video file \n        return capture.open(filename); \n      } \n\n```", "```py\n      // to display the input frames \n      void displayInput(std::string wn) { \n\n        windowNameInput= wn; \n        cv::namedWindow(windowNameInput); \n      } \n\n      // to display the processed frames \n      void displayOutput(std::string wn) { \n        windowNameOutput= wn; \n        cv::namedWindow(windowNameOutput); \n      } \n\n```", "```py\n    // to grab (and process) the frames of the sequence \n    void run() { \n      // current frame \n      cv::Mat frame; \n      //output frame \n      cv::Mat output; \n\n      // if no capture device has been set \n      if (!isOpened()) \n        return; \n\n        stop= false; \n      while (!isStopped()) { \n\n        // read next frame if any \n        if (!readNextFrame(frame)) \n          break; \n\n        // display input frame \n        if (windowNameInput.length()!=0)  \n          cv::imshow(windowNameInput,frame); \n\n         // calling the process function \n        if (callIt) { \n\n          //process the frame \n          process(frame, output); \n          //increment frame number \n          fnumber++; \n\n        } \n        else { \n          // no processing \n          output= frame; \n        } \n\n        // display output frame \n        if (windowNameOutput.length()!=0) \n          cv::imshow(windowNameOutput,output); \n          // introduce a delay \n          if (delay>=0 && cv::waitKey(delay)>=0) \n            stopIt(); \n\n          // check if we should stop \n          if (frameToStop>=0 && getFrameNumber()==frameToStop) \n            stopIt(); \n         } \n     } \n\n    // Stop the processing \n    void stopIt() { \n      stop= true; \n    } \n\n    // Is the process stopped? \n    bool isStopped() { \n      return stop; \n    } \n\n    // Is a capture device opened? \n    bool isOpened() { \n      capture.isOpened(); \n    } \n\n    // set a delay between each frame \n    // 0 means wait at each frame \n    // negative means no delay \n    void setDelay(int d) { \n      delay= d; \n    } \n\n```", "```py\n    // to get the next frame  \n    // could be: video file or camera \n    bool readNextFrame(cv::Mat& frame) { \n      return capture.read(frame); \n    } \n\n```", "```py\n    // process callback to be called \n    void callProcess() { \n      callIt= true; \n    } \n\n    // do not call process callback \n    void dontCallProcess() { \n      callIt= false; \n    } \n\n```", "```py\n    void stopAtFrameNo(long frame) { \n      frameToStop= frame; \n    } \n\n    // return the frame number of the next frame \n    long getFrameNumber() { \n      // get info of from the capture device \n      long fnumber= static_cast<long>(capture.get(CV_CAP_PROP_POS_FRAMES)); \n      return fnumber;  \n    } \n\n```", "```py\n    // vector of image filename to be used as input \n    std::vector<std::string> images; \n    // image vector iterator \n    std::vector<std::string>::const_iterator itImg; \n\n```", "```py\n    // set the vector of input images \n    bool setInput(const std::vector<std::string>& imgs) { \n      fnumber= 0; \n      // In case a resource was already  \n      // associated with the VideoCapture instance \n      capture.release(); \n\n      // the input will be this vector of images \n      images= imgs; \n      itImg= images.begin(); \n      return true; \n    } \n\n```", "```py\n    // Is a capture device opened? \n    bool isOpened() { \n      return capture.isOpened() || !images.empty(); \n    } \n\n```", "```py\n    // to get the next frame  \n    // could be: video file; camera; vector of images \n    bool readNextFrame(cv::Mat& frame) { \n\n      if (images.size()==0) \n        return capture.read(frame); \n\n      else { \n        if (itImg != images.end()) { \n          frame= cv::imread(*itImg); \n          itImg++; \n          return frame.data != 0; \n        } else \n\n          return false; \n      } \n    } \n\n```", "```py\n    // The frame processor interface \n    class FrameProcessor { \n      public: \n      // processing method \n      virtual void process(cv:: Mat &input, cv:: Mat &output)= 0; \n    }; \n\n```", "```py\n    // set the instance of the class that  \n    // implements the FrameProcessor interface \n    void setFrameProcessor(FrameProcessor* frameProcessorPtr) { \n      // invalidate callback function \n      process= 0; \n       // this is the frame processor instance  \n       // that will be called \n       frameProcessor= frameProcessorPtr; \n       callProcess(); \n    } \n\n```", "```py\n    while (!isStopped()) { \n\n      // read next frame if any \n      if (!readNextFrame(frame)) \n        break; \n\n      // display input frame \n      if (windowNameInput.length()!=0) \n        cv::imshow(windowNameInput,frame); \n\n      //** calling the process function or method ** \n      if (callIt) { \n\n        // process the frame \n        if (process) // if call back function \n          process(frame, output); \n        else if (frameProcessor)  \n          // if class interface instance \n          frameProcessor->process(frame,output); \n        // increment frame number \n        fnumber++; \n      } \n      else { \n        output= frame; \n      } \n      // display output frame \n      if (windowNameOutput.length()!=0) \n        cv::imshow(windowNameOutput,output); \n      // introduce a delay \n      if (delay>=0 && cv::waitKey(delay)>=0) \n        stopIt(); \n      // check if we should stop \n      if (frameToStop>=0 && getFrameNumber()==frameToStop) \n        stopIt(); \n    } \n\n```", "```py\n    writer.open(outputFile,     // filename \n                codec,          // codec to be used  \n                framerate,      // frame rate of the video \n                frameSize,      // frame size \n                isColor);       // color video? \n\n```", "```py\n    writer.write(frame);   // add the frame to the video file \n\n```", "```py\n    // Create instance \n\n    VideoProcessor processor; \n\n    // Open video file \n    processor.setInput(\"bike.avi\"); \n    processor.setFrameProcessor(canny); \n    processor.setOutput(\"bikeOut.avi\"); \n    // Start the process \n    processor.run(); \n\n```", "```py\n    processor.setOutput(\"bikeOut\",  //prefix \n                        \".jpg\",     // extension \n                        3,          // number of digits \n                        0);         // starting index \n\n```", "```py\n    class VideoProcessor { \n\n      private: \n\n      // the OpenCV video writer object \n      cv::VideoWriter writer; \n      // output filename \n      std::string outputFile; \n      // current index for output images \n      int currentIndex; \n      // number of digits in output image filename \n      int digits; \n      // extension of output images \n      std::string extension; \n\n```", "```py\n    // set the output video file \n    // by default the same parameters than  \n    // input video will be used \n    bool setOutput(const std::string &filename, int codec=0,          \n                   double framerate=0.0, bool isColor=true) { \n\n      outputFile= filename; \n      extension.clear(); \n\n      if (framerate==0.0) \n        framerate= getFrameRate(); // same as input \n\n      char c[4]; \n      // use same codec as input \n      if (codec==0) {  \n        codec= getCodec(c); \n      } \n\n      // Open output video \n      return writer.open(outputFile,      // filename \n                         codec,           // codec to be used  \n                         framerate,       // frame rate of the video \n                         getFrameSize(),  // frame size \n                         isColor);        // color video? \n    } \n\n```", "```py\n    // to write the output frame  \n    // could be: video file or images \n    void writeNextFrame(cv::Mat& frame) { \n      if (extension.length()) { // then we write images \n\n        std::stringstream ss; \n        // compose the output filename \n        ss << outputFile << std::setfill('0')  \n           << std::setw(digits) << currentIndex++ << extension; \n        cv::imwrite(ss.str(),frame); \n\n      } else { \n        // then write to video file \n        writer.write(frame); \n      } \n    } \n\n```", "```py\n    // set the output as a series of image files \n    // extension must be \".jpg\", \".bmp\" \n    bool setOutput(const std::string &filename, // prefix \n                   const std::string &ext,      // image file extension \n                   int numberOfDigits=3,        // number of digits \n                   int startIndex=0) {          // start index \n\n      // number of digits must be positive \n      if (numberOfDigits<0) \n        return false; \n\n      // filenames and their common extension \n      outputFile= filename; \n      extension= ext; \n\n      // number of digits in the file numbering scheme \n      digits= numberOfDigits; \n      // start numbering at this index \n      currentIndex= startIndex; \n\n      return true; \n    } \n\n```", "```py\n  while (!isStopped()) { \n\n    // read next frame if any \n    if (!readNextFrame(frame)) \n      break; \n\n    // display input frame \n    if (windowNameInput.length()!=0) \n      cv::imshow(windowNameInput,frame); \n\n    // calling the process function or method \n    if (callIt) { \n\n      // process the frame \n      if (process) \n        process(frame, output); \n      else if (frameProcessor) \n        frameProcessor->process(frame,output); \n      // increment frame number \n      fnumber++; \n    }  else { \n      output= frame; \n    } \n\n    //** write output sequence ** \n    if (outputFile.length()!=0) \n      writeNextFrame(output); \n    // display output frame \n    if (windowNameOutput.length()!=0) \n      cv::imshow(windowNameOutput,output); \n    // introduce a delay \n    if (delay>=0 && cv::waitKey(delay)>=0) \n      stopIt(); \n\n    // check if we should stop \n    if (frameToStop>=0 && getFrameNumber()==frameToStop) \n      stopIt(); \n    } \n  } \n\n```", "```py\n    // get the codec of input video \n    int getCodec(char codec[4]) { \n\n      // undefined for vector of images \n      if (images.size()!=0) return -1; \n      union { // data structure for the 4-char code \n        nt value; \n        char code[4]; \n      } returned; \n\n      // get the code \n      returned.value= static_cast<int>(capture.get(cv::CAP_PROP_FOURCC)); \n      // get the 4 characters \n      codec[0]= returned.code[0]; \n      codec[1]= returned.code[1]; \n      codec[2]= returned.code[2]; \n      codec[3]= returned.code[3]; \n\n      // return the int value corresponding to the code \n      return returned.value; \n    } \n\n```", "```py\n    char codec[4]; \n    processor.getCodec(codec); \n    std::cout << \"Codec: \" << codec[0] << codec[1] \n              << codec[2] << codec[3] << std::endl; \n\n```", "```py\n    Codec : XVID \n\n```", "```py\n    // compute difference between current image and background \n    cv::absdiff(backgroundImage,currentImage,foreground); \n\n```", "```py\n    class BGFGSegmentor : public FrameProcessor { \n      cv::Mat gray;          // current gray-level image \n      cv::Mat background;    // accumulated background \n      cv::Mat backImage;     // current background image \n      cv::Mat foreground;    // foreground image \n      // learning rate in background accumulation \n      double learningRate; \n      int threshold;         // threshold for foreground extraction \n\n```", "```py\n    // processing method \n    void process(cv:: Mat &frame, cv:: Mat &output) { \n      // convert to gray-level image \n      cv::cvtColor(frame, gray, cv::COLOR_BGR2GRAY); \n      // initialize background to 1st frame \n      if (background.empty()) \n        gray.convertTo(background, CV_32F); \n      // convert background to 8U \n      background.convertTo(backImage,CV_8U); \n\n      // compute difference between image and background \n      cv::absdiff(backImage,gray,foreground); \n      // apply threshold to foreground image         \n      cv::threshold(foreground,output,threshold, \n                    255,cv::THRESH_BINARY_INV); \n\n      // accumulate background \n      cv::accumulateWeighted(gray, background,  \n                             // alpha*gray + (1-alpha)*background \n                             learningRate,  // alpha \n                             output);       // mask \n    } \n\n```", "```py\n    int main() { \n      // Create video procesor instance \n      VideoProcessor processor; \n\n      // Create background/foreground segmentor \n       BGFGSegmentor segmentor; \n       segmentor.setThreshold(25); \n\n      // Open video file \n      processor.setInput(\"bike.avi\"); \n\n      // Set frame processor \n      processor.setFrameProcessor(&segmentor); \n\n      // Declare a window to display the video \n      processor.displayOutput(\"Extracted Foreground\"); \n\n      // Play the video at the original frame rate \n      processor.setDelay(1000./processor.getFrameRate()); \n\n      // Start the process \n      processor.run(); \n    } \n\n```", "```py\n    int main(){ \n      // Open the video file \n      cv::VideoCapture capture(\"bike.avi\"); \n      // check if video successfully opened \n      if (!capture.isOpened()) \n        return 0; \n\n      // current video frame \n      cv::Mat frame; \n      // foreground binary image \n      cv::Mat foreground; \n      // background image \n      cv::Mat background; \n      cv::namedWindow(\"Extracted Foreground\"); \n\n      // The Mixture of Gaussian object \n      // used with all default parameters \n      cv::Ptr<cv::BackgroundSubtractor> ptrMOG =\n                      cv::bgsegm::createBackgroundSubtractorMOG(); \n      bool stop(false); \n      // for all frames in video \n      while (!stop) { \n        // read next frame if any \n        if (!capture.read(frame)) \n          break; \n\n        // update the background \n        // and return the foreground \n         ptrMOG->apply(frame,foreground,0.01); \n\n        // Complement the image \n        cv::threshold(foreground,foreground,128, \n                      255,cv::THRESH_BINARY_INV); \n        //show foreground and background \n        cv::imshow(\"Extracted Foreground\",foreground); \n\n        // introduce a delay \n        // or press key to stop \n        if (cv::waitKey(10)>=0) \n          stop= true; \n      } \n    } \n\n```"]