<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer014">
<h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">1</span></h1>
<h1 class="chapterTitle" id="_idParaDest-15"><span class="koboSpan" id="kobo.2.1">Introducing Kaggle and Its Basic Functions</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">Kaggle is currently the main platform for competitive predictive modeling. </span><span class="koboSpan" id="kobo.3.2">Here, those who are passionate about machine learning, both experts and beginners, have a collaborative and competitive environment to learn, win recognition, share knowledge, and give back to the community. </span><span class="koboSpan" id="kobo.3.3">The company was launched in 2010, offering only machine learning competitions. </span><span class="koboSpan" id="kobo.3.4">Currently, it is a data platform that includes sections titled </span><strong class="keyWord"><span class="koboSpan" id="kobo.4.1">Competitions</span></strong><span class="koboSpan" id="kobo.5.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.6.1">Datasets</span></strong><span class="koboSpan" id="kobo.7.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.8.1">Code</span></strong><span class="koboSpan" id="kobo.9.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.10.1">Discussions</span></strong><span class="koboSpan" id="kobo.11.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.12.1">Learn</span></strong><span class="koboSpan" id="kobo.13.1">, and, most recently, </span><strong class="keyWord"><span class="koboSpan" id="kobo.14.1">Models</span></strong><span class="koboSpan" id="kobo.15.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.16.1">In 2011, Kaggle went through an investment round, valuing the company above $25 million. </span><span class="koboSpan" id="kobo.16.2">In 2017, it was acquired by Google (now Alphabet Inc.), becoming associated with Google Cloud. </span><span class="koboSpan" id="kobo.16.3">The most notable key persons from Kaggle are co-founders Anthony Goldbloom (long-time CEO until 2022) and Ben Hammer (CTO). </span><span class="koboSpan" id="kobo.16.4">Recently, D. </span><span class="koboSpan" id="kobo.16.5">Sculley, the legendary Google engineer, became Kaggle’s new CEO, after Anthony Goldbloom stepped down to become involved in the development of a new start-up.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.17.1">In this first chapter, we’ll explore the main sections that the Kaggle platform offers its members. </span><span class="koboSpan" id="kobo.17.2">We will also learn how to create an account, how the platform is organized, and what its main sections are. </span><span class="koboSpan" id="kobo.17.3">In short, this chapter will cover the following topics:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.18.1">The Kaggle platform</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.19.1">Kaggle Competitions</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.20.1">Kaggle Datasets</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.21.1">Kaggle Code</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.22.1">Kaggle Discussions</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.23.1">Kaggle Learn</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.24.1">Kaggle Models</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.25.1">If you are familiar with the Kaggle platform, you probably know about these features already. </span><span class="koboSpan" id="kobo.25.2">You can choose to continue reading the following sections to refresh your knowledge about the platform or you can skip them and go directly to the next chapter.</span></p>
<h1 class="heading-1" id="_idParaDest-16"><span class="koboSpan" id="kobo.26.1">The Kaggle platform</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.27.1">To start using Kaggle, you will have to create an account. </span><span class="koboSpan" id="kobo.27.2">You can register with your email and password </span><a id="_idIndexMarker000"/><span class="koboSpan" id="kobo.28.1">or authenticate using your Google account directly. </span><span class="koboSpan" id="kobo.28.2">Once registered, you can start by creating a profile with your name, picture, role, and current organization. </span><span class="koboSpan" id="kobo.28.3">You then can add your location, which is optional, and a short personal presentation as well. </span><span class="koboSpan" id="kobo.28.4">After you perform an SMS verification and add some minimal content on the platform (run one notebook or script, make one competition submission, make one comment, or give one upvote), you will also be promoted from </span><strong class="keyWord"><span class="koboSpan" id="kobo.29.1">Novice</span></strong><span class="koboSpan" id="kobo.30.1"> to </span><strong class="keyWord"><span class="koboSpan" id="kobo.31.1">Contributor</span></strong><span class="koboSpan" id="kobo.32.1">. </span><span class="koboSpan" id="kobo.32.2">The following figure shows a checklist for how to become a contributor. </span><span class="koboSpan" id="kobo.32.3">As you can see, all items are checked, which means that the user has already been promoted to the </span><strong class="keyWord"><span class="koboSpan" id="kobo.33.1">Contributor</span></strong><span class="koboSpan" id="kobo.34.1"> tier.</span></p>
<p class="packt_figref"><span class="koboSpan" id="kobo.35.1"><img alt="A close-up of a white background  Description automatically generated" src="../Images/B20963_01_01.png"/></span></p>
<p class="packt_figref"><span class="koboSpan" id="kobo.36.1">Figure 1.1: Checklist to become a contributor</span></p>
<p class="normal"><span class="koboSpan" id="kobo.37.1">With the entire </span><strong class="keyWord"><span class="koboSpan" id="kobo.38.1">Contributor</span></strong><span class="koboSpan" id="kobo.39.1"> checklist completed, you are ready to start your Kaggle journey.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.40.1">The current platform contains multiple features. </span><span class="koboSpan" id="kobo.40.2">The most important are:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.41.1">Competitions</span></strong><span class="koboSpan" id="kobo.42.1">: This is where Kagglers can take part in competitions and submit their solutions to be scored.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.43.1">Datasets</span></strong><span class="koboSpan" id="kobo.44.1">: In this section, users can upload datasets.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.45.1">Code</span></strong><span class="koboSpan" id="kobo.46.1">: This is one of the most complex features of Kaggle. </span><span class="koboSpan" id="kobo.46.2">Also known as Kernels or Notebooks, it allows users to add code (independently or connected to datasets and competitions), modify it, run it to perform analysis, prepare models, and generate submission files for competitions.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.47.1">Discussions</span></strong><span class="koboSpan" id="kobo.48.1">: In this section, contributors on the platform can add topics and comments to competitions, Notebooks, or datasets. </span><span class="koboSpan" id="kobo.48.2">Topics can also be added independently and linked to themes such as </span><em class="italic"><span class="koboSpan" id="kobo.49.1">Getting Started</span></em><span class="koboSpan" id="kobo.50.1">. </span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.51.1">Each of these sections allows you to gain medals, according to Kaggle’s progression system. </span><span class="koboSpan" id="kobo.51.2">Once you start to contribute to one of these sections, you can also be ranked in the overall Kaggle </span><a id="_idIndexMarker001"/><span class="koboSpan" id="kobo.52.1">ranking system for the respective section. </span><span class="koboSpan" id="kobo.52.2">There are two main methods to gain medals: by winning top positions in competitions and by getting upvotes for your work in the </span><strong class="screenText"><span class="koboSpan" id="kobo.53.1">Datasets</span></strong><span class="koboSpan" id="kobo.54.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.55.1">Code</span></strong><span class="koboSpan" id="kobo.56.1">, and </span><strong class="screenText"><span class="koboSpan" id="kobo.57.1">Discussions</span></strong><span class="koboSpan" id="kobo.58.1"> sections.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.59.1">Besides </span><strong class="screenText"><span class="koboSpan" id="kobo.60.1">Competitions</span></strong><span class="koboSpan" id="kobo.61.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.62.1">Datasets</span></strong><span class="koboSpan" id="kobo.63.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.64.1">Code</span></strong><span class="koboSpan" id="kobo.65.1">, and </span><strong class="screenText"><span class="koboSpan" id="kobo.66.1">Discussions</span></strong><span class="koboSpan" id="kobo.67.1">, there are two more sections with content on Kaggle:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.68.1">Learn</span></strong><span class="koboSpan" id="kobo.69.1">: This is one </span><a id="_idIndexMarker002"/><span class="koboSpan" id="kobo.70.1">of the coolest features of Kaggle. </span><span class="koboSpan" id="kobo.70.2">It contains a series of lectures and tutorials on various topics, from a basic introduction to programming languages to advanced topics like computer vision, model interpretability, and AI ethics. </span><span class="koboSpan" id="kobo.70.3">You can use all the other Kaggle resources as support materials for the lectures (Datasets, Competitions, Code, and Discussions).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.71.1">Models</span></strong><span class="koboSpan" id="kobo.72.1">: This is the </span><a id="_idIndexMarker003"/><span class="koboSpan" id="kobo.73.1">newest feature introduced on Kaggle. </span><span class="koboSpan" id="kobo.73.2">It allows you to load a model into your code, in the same way that you currently add datasets.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.74.1">Now that we’ve had a quick overview of the various features of the Kaggle platform, the following sections will give you an in-depth view of Competitions, Datasets, Code, Discussions, Learn, and Models. </span><span class="koboSpan" id="kobo.74.2">Let’s get started!</span></p>
<h1 class="heading-1" id="_idParaDest-17"><span class="koboSpan" id="kobo.75.1">Kaggle Competitions</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.76.1">It all started with </span><a id="_idIndexMarker004"/><span class="koboSpan" id="kobo.77.1">Competitions more than 12 years ago. </span><span class="koboSpan" id="kobo.77.2">The first competition had just a few participants. </span><span class="koboSpan" id="kobo.77.3">With the growing interest in machine learning and the increased community around Kaggle, the complexity of the competitions, the number of participants, and the interest around competitions increased significantly.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.78.1">To start a competition, the competition host prepares a dataset, typically split between train and test. </span><span class="koboSpan" id="kobo.78.2">In the most common form, the train set has labeled data available, while the test set only contains the feature data. </span><span class="koboSpan" id="kobo.78.3">The host also adds information about the data and a presentation of the competition objective. </span><span class="koboSpan" id="kobo.78.4">This includes a description of the problem to set the background for the competitors. </span><span class="koboSpan" id="kobo.78.5">The host also adds information about the metrics used to evaluate the solutions to the competition. </span><span class="koboSpan" id="kobo.78.6">The terms and conditions of the competitions are also specified. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.79.1">Competitors are allowed to submit a limited number of solutions per day and, at the end, the best two solutions (evaluated based on a portion </span><a id="_idIndexMarker005"/><span class="koboSpan" id="kobo.80.1">of the test set used to calculate the public score) will be selected. </span><span class="koboSpan" id="kobo.80.2">Competitors also have the option to select two solutions themselves based on their own judgment. </span><span class="koboSpan" id="kobo.80.3">Then, these two selected solutions will be evaluated on the reserved subset of test data to generate the private score. </span><span class="koboSpan" id="kobo.80.4">This will be the final score used to rank the competitors.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.81.1">There are several types of competitions:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.82.1">Featured competitions</span></strong><span class="koboSpan" id="kobo.83.1">: The most important are the featured competitions. </span><span class="koboSpan" id="kobo.83.2">Currently, featured competitions might reunite several thousand teams, with tens </span><a id="_idIndexMarker006"/><span class="koboSpan" id="kobo.84.1">or even hundreds of thousands of solutions submitted. </span><span class="koboSpan" id="kobo.84.2">Featured competitions are typically hosted by companies but also sometimes by research organizations or universities, and are usually aimed at solving a difficult problem related to a company or a research topic. </span><span class="koboSpan" id="kobo.84.3">The organizer turns to the large Kaggle community to bring their knowledge and skills, and the competitive aspect of the setup accelerates the development of a solution. </span><span class="koboSpan" id="kobo.84.4">Usually, a featured competition will also have a significant prize, which will be distributed according to the competition rules to the top competitors. </span><span class="koboSpan" id="kobo.84.5">Sometimes, the host will not include a prize but will offer a different incentive, such as recruiting the top competitors to work for them (with high-profile companies, this might be more interesting than a prize), vouchers for using cloud resources, or acceptance of the top solutions to be presented at high-profile conferences. </span><span class="koboSpan" id="kobo.84.6">Besides the Featured competitions, there are also Getting Started, Research, Community, Playground, Simulations, and Analytics competitions.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.85.1">Getting Started competitions</span></strong><span class="koboSpan" id="kobo.86.1">: These are aimed at mostly beginners and tackle </span><a id="_idIndexMarker007"/><span class="koboSpan" id="kobo.87.1">easily approachable machine learning problems to help build basic skills. </span><span class="koboSpan" id="kobo.87.2">These competitions are restarted periodically and the leaderboard is reset. </span><span class="koboSpan" id="kobo.87.3">The most notable ones are </span><em class="italic"><span class="koboSpan" id="kobo.88.1">Titanic – Machine Learning for Disaster</span></em><span class="koboSpan" id="kobo.89.1">, </span><em class="italic"><span class="koboSpan" id="kobo.90.1">Digit Recognizer</span></em><span class="koboSpan" id="kobo.91.1">, </span><em class="italic"><span class="koboSpan" id="kobo.92.1">House Prices – Advanced Regression Techniques</span></em><span class="koboSpan" id="kobo.93.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.94.1">Natural Language Processing with Disaster Tweets</span></em><span class="koboSpan" id="kobo.95.1">.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.96.1">Research competitions</span></strong><span class="koboSpan" id="kobo.97.1">: In Research competitions, the themes are related to finding the solution to a difficult scientific problem in various domains such </span><a id="_idIndexMarker008"/><span class="koboSpan" id="kobo.98.1">as medicine, genetics, cell biology, and astronomy by applying a machine learning approach. </span><span class="koboSpan" id="kobo.98.2">Some of the most popular competitions in recent years were from this category and with the rising use of machine learning in many fields of fundamental and applied research, we can expect that this type of competition will be more and more frequent and popular.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.99.1">Community competitions</span></strong><span class="koboSpan" id="kobo.100.1">: These are created by Kagglers and are either open to </span><a id="_idIndexMarker009"/><span class="koboSpan" id="kobo.101.1">the public or private competitions, where only those invited can take part. </span><span class="koboSpan" id="kobo.101.2">For example, you can host a Community competition as a school or university project, where students are invited to join and compete to get the best grades. 
    </span><p class="normal"><span class="koboSpan" id="kobo.102.1">Kaggle offers the infrastructure, which makes it very simple for you to define and start a new competition. </span><span class="koboSpan" id="kobo.102.2">You have to provide the training and test data, but this can be as simple as two files in CSV format. </span><span class="koboSpan" id="kobo.102.3">Additionally, you need to add a submission sample file, which gives the expected format for submissions. </span><span class="koboSpan" id="kobo.102.4">Participants in the competition have to replace the prediction in this file with their own prediction, save the file, and then submit it. </span><span class="koboSpan" id="kobo.102.5">Then, you have to choose a metric to assess the performance of a machine learning model (no need to define one, as you have a large collection of predefined metrics). </span><span class="koboSpan" id="kobo.102.6">At the same time, as the host, you will be required to upload a file with the correct, expected solution to the competition challenge, which will serve as reference against which all competitors’ submissions will be checked. </span><span class="koboSpan" id="kobo.102.7">Once this is done, you just need to edit the terms and conditions, choose a start and end date for the competition, write the data description and objectives, and you are good to go. </span><span class="koboSpan" id="kobo.102.8">Other options that you can choose from are whether participants can team up or not, and whether joining the competition is open to everybody or just to people who receive the competition link.</span></p></li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.103.1">Playground competitions</span></strong><span class="koboSpan" id="kobo.104.1">: Around three years ago, a new section of competitions </span><a id="_idIndexMarker010"/><span class="koboSpan" id="kobo.105.1">was launched: Playground competitions. </span><span class="koboSpan" id="kobo.105.2">These are generally simple competitions, like the Getting Started ones, but will have a shorter lifespan (it was initially one month, but currently it is from one to four weeks). </span><span class="koboSpan" id="kobo.105.3">These competitions will be of low or medium difficulty and will help participants gain new skills. </span><span class="koboSpan" id="kobo.105.4">Such competitions are highly recommended to beginners but also to competitors with more experience who want to refine their skills in a certain domain.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.106.1">Simulation competitions</span></strong><span class="koboSpan" id="kobo.107.1">: If the previous types are all supervised machine learning </span><a id="_idIndexMarker011"/><span class="koboSpan" id="kobo.108.1">competitions, Simulations competitions are, in general, optimization competitions. </span><span class="koboSpan" id="kobo.108.2">The most well known are those around Christmas and New Year (Santa competitions) and also the Lux AI Challenge, which is currently in the third season. </span><span class="koboSpan" id="kobo.108.3">Some of the Simulation competitions are also recurrent and will qualify for an additional category: Annual competitions. </span><span class="koboSpan" id="kobo.108.4">Examples of such competitions that are of both the Simulations type and Annual are the Santa competitions.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.109.1">Analytics competitions</span></strong><span class="koboSpan" id="kobo.110.1">: These are different in both the objective and the modality </span><a id="_idIndexMarker012"/><span class="koboSpan" id="kobo.111.1">of scoring the solutions. </span><span class="koboSpan" id="kobo.111.2">The objective is to perform a detailed analysis of the competition dataset to get insights from the data. </span><span class="koboSpan" id="kobo.111.3">The score is based, in general, on the judgment of the organizers and, in some cases, on the popularity of the solutions that compete; in this case, the organizers will grant parts of the prizes to the most popular notebooks, based on the upvotes of Kagglers. </span><span class="koboSpan" id="kobo.111.4">In </span><em class="italic"><span class="koboSpan" id="kobo.112.1">Chapter 5</span></em><span class="koboSpan" id="kobo.113.1">, we will analyze the data from one of the first Analytics competitions and also provide some insights into how to approach this type of competition.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.114.1">For a long time, competitions required participants to prepare a submission file with the predictions for the test set. </span><span class="koboSpan" id="kobo.114.2">No other constraints were imposed on the method to prepare the submissions; the competitors were supposed to use their own computing resources to train models, validate them, and prepare the submission. </span><span class="koboSpan" id="kobo.114.3">Initially, there were no available </span><a id="_idIndexMarker013"/><span class="koboSpan" id="kobo.115.1">resources on the platform to prepare a submission. </span><span class="koboSpan" id="kobo.115.2">After Kaggle started to provide computational resources, where you could prepare your model using Kaggle Kernels (later named Notebooks and now Code), you could submit directly from the platform, but there was no limitation imposed on this. </span><span class="koboSpan" id="kobo.115.3">Typically, the submission file will be evaluated on the fly and the result will be displayed almost instantly. </span><span class="koboSpan" id="kobo.115.4">The result (i.e., the score according to the competition metric) will be calculated only for a percentage of the test set. </span><span class="koboSpan" id="kobo.115.5">This percentage is announced at the start of the competition and is fixed. </span><span class="koboSpan" id="kobo.115.6">Also, the subset of test data used during the competition to calculate the displayed score (the public score) is fixed. </span><span class="koboSpan" id="kobo.115.7">After the end of the competition, the final score is calculated with the rest of the test data, and this final score (also known as the private score) is the final score for each competitor. </span><span class="koboSpan" id="kobo.115.8">The percentage of the test data used during the competition to evaluate the solution and provide the public score could be anything from a few percent to more than 50%. </span><span class="koboSpan" id="kobo.115.9">In most competitions, it tends to be less than 50%.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.116.1">The reason Kaggle uses this approach is to prevent one unwanted phenomenon. </span><span class="koboSpan" id="kobo.116.2">Rather than improving their models for enhanced generalization, competitors might be inclined to optimize their solution to predict the test set as perfectly as possible, without considering the cross-validation score on their train data. </span><span class="koboSpan" id="kobo.116.3">In other words, the competitors might be inclined to overfit </span><a id="_idIndexMarker014"/><span class="koboSpan" id="kobo.117.1">their solution on the test set. </span><span class="koboSpan" id="kobo.117.2">By splitting this data and only providing the score for a part of the test set – the public score – the organizers intend to prevent this. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.118.1">With more and more complex competitions (sometimes with very large train and test sets), some participants with greater computational resources might gain an advantage, while others with limited resources may struggle to develop advanced models. </span><span class="koboSpan" id="kobo.118.2">Especially in featured competitions, the goal is often to create robust, production-compatible solutions. </span><span class="koboSpan" id="kobo.118.3">However, without setting restrictions on how solutions are obtained, achieving this goal may be difficult, especially if solutions with unrealistic resource use become prevalent. </span><span class="koboSpan" id="kobo.118.4">To limit the negative unwanted consequences of the “arms race” for better and better solutions, a few years ago, Kaggle introduced Code competitions. </span><span class="koboSpan" id="kobo.118.5">This kind of competition requires that all solutions be submitted from a running notebook on the Kaggle platform. </span><span class="koboSpan" id="kobo.118.6">In this way, the infrastructure to run the solution became fully controllable by Kaggle.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.119.1">Also, not only are the computing resources limited in such competitions but there are also additional constraints: the duration of the run and internet access (to prevent the use of additional computing power through the use of external APIs or other remote computing resources). </span></p>
<p class="normal"><span class="koboSpan" id="kobo.120.1">Kagglers discovered quite fast that this was a limitation just for the inference part of the solution and an adaptation appeared: competitors started to train offline, large models that would not fit within the limits of computing power and time of run imposed by the Code competitions. </span><span class="koboSpan" id="kobo.120.2">Then, they uploaded the offline trained models (sometimes using very large computational resources) as datasets and loaded these models in the inference code that observed the limits for memory and computation time for the Code competitions.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.121.1">In some cases, multiple models trained offline were loaded as datasets and inference combined these multiple models to create more precise solutions. </span><span class="koboSpan" id="kobo.121.2">Over time, Code competitions have become more refined. </span><span class="koboSpan" id="kobo.121.3">Some of them will only expose a few rows from the test set and not reveal the size of the real test set used for the public or future private test set. </span><span class="koboSpan" id="kobo.121.4">Therefore, Kagglers have to resort to clever probing techniques to estimate the limitations that might be incurred while running the final, private test set, to avoid a case where their code will fail due to surpassing memory or runtime limits.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.122.1">Currently, there are also Code competitions that, after the active part of the competition (i.e., when competitors are allowed to continue to refine their solutions) ends, will not publish the private score, but will rerun the code with several new sets of test data, and reevaluate the setwo selected solutions against these new datasets, which have never been seen before. </span><span class="koboSpan" id="kobo.122.2">Some of these competitions are about the stock market, cryptocurrency valuation, or credit performance predictions and they use real data. </span><span class="koboSpan" id="kobo.122.3">The evolution of Code </span><a id="_idIndexMarker015"/><span class="koboSpan" id="kobo.123.1">competitions ran in parallel with the evolution of available computational resources on the platform, to provide users with the required computational power.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.124.1">Some of the competitions (most notably the Featured competitions and the Research competitions) grant ranking points and medals to the participants. </span><span class="koboSpan" id="kobo.124.2">Ranking points are used to calculate the relative position of Kagglers in the general leaderboard of the platform. </span><span class="koboSpan" id="kobo.124.3">The formula to calculate the ranking points awarded for a competition hasn’t changed since May 2015:</span></p>
<p class="packt_figref"><span class="koboSpan" id="kobo.125.1"><img alt="" role="presentation" src="../Images/B20963_01_001.png"/></span></p>
<p class="packt_figref"><span class="koboSpan" id="kobo.126.1">Figure 1.2: Formula for calculating ranking points</span></p>
<p class="normal"><span class="koboSpan" id="kobo.127.1">The number of points decreases with the square root of the number of teammates in the current competition team. </span><span class="koboSpan" id="kobo.127.2">More points are awarded for competitions with a larger number of teams. </span><span class="koboSpan" id="kobo.127.3">The number of points will also decrease over time, to keep the ranking up to date and competitive.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.128.1">Medals are counted to get a promotion in the Kaggle progression system for competitions. </span><span class="koboSpan" id="kobo.128.2">Medals for competitions are obtained based on the position at the top of the competition leaderboard. </span><span class="koboSpan" id="kobo.128.3">The actual system is a bit more complicated but, generally, the top 10% will get a bronze medal, the top 5% will get a silver medal, and the top 1% will get a gold medal. </span><span class="koboSpan" id="kobo.128.4">The actual number of medals granted will be larger with an increased number of participants, but this is the basic principle.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.129.1">With two bronze medals, you reach the Competition Expert tier. </span><span class="koboSpan" id="kobo.129.2">With two silver medals and one gold medal, you reach the Competition Master tier. </span><span class="koboSpan" id="kobo.129.3">And with one Solo gold medal (i.e., you obtained this medal without teaming up with others) and a total of five gold medals, you reach the most valuable Kaggle tier: the Competition Grandmaster. </span><span class="koboSpan" id="kobo.129.4">Currently, at the time of preparing this book, among the over 12 million users on Kaggle, there are 280 Kaggle Competition Grandmasters and 1,936 Masters.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.130.1">The ranking system </span><a id="_idIndexMarker016"/><span class="koboSpan" id="kobo.131.1">adds points depending on the position of users in the leaderboard, which grants ranking points. </span><span class="koboSpan" id="kobo.131.2">The points are not permanent, and, as we can see from </span><em class="italic"><span class="koboSpan" id="kobo.132.1">Figure 1.2</span></em><span class="koboSpan" id="kobo.133.1">, there is a quite complex formula for points decreasing. </span><span class="koboSpan" id="kobo.133.2">If you do not continue to compete and get new points, your points will decrease quite fast and the only thing that will remind you of your past glory is the maximum rank you reached in the past. </span><span class="koboSpan" id="kobo.133.3">However, once you achieve a medal, you will always have that medal in your profile, even if your ranking position changes or your points decrease over time.</span></p>
<h1 class="heading-1" id="_idParaDest-18"><span class="koboSpan" id="kobo.134.1">Kaggle Datasets</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.135.1">Kaggle Datasets were added only a few years back. </span><span class="koboSpan" id="kobo.135.2">Currently, there are more than 200,000 datasets </span><a id="_idIndexMarker017"/><span class="koboSpan" id="kobo.136.1">available on the platform, contributed by the users. </span><span class="koboSpan" id="kobo.136.2">There were, of course, datasets in the past, associated with the competitions. </span><span class="koboSpan" id="kobo.136.3">With the new </span><strong class="screenText"><span class="koboSpan" id="kobo.137.1">Datasets</span></strong><span class="koboSpan" id="kobo.138.1"> section, Kagglers can get medals and ranking based on the recognition of other users on the platform, in the form of upvotes for datasets contributed.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.139.1">Everybody can contribute datasets and the process to add a dataset is quite simple. </span><span class="koboSpan" id="kobo.139.2">You first need to identify an interesting subject and a data source. </span><span class="koboSpan" id="kobo.139.3">This can be an external dataset that you are mirroring on Kaggle, provided that the right license is in place, or the data is collected by yourself. </span><span class="koboSpan" id="kobo.139.4">Datasets can also be authored collectively. </span><span class="koboSpan" id="kobo.139.5">There will be a main author, the one that initiates the dataset, but they can add other contributors with view or edit roles. </span><span class="koboSpan" id="kobo.139.6">There are a few compulsory steps to define a dataset on Kaggle.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.140.1">First, you will have to upload one or multiple files and give a name to the dataset. </span><span class="koboSpan" id="kobo.140.2">Alternatively, you can set the dataset to be provided from a public link, which should point to a file or a public repository on GitHub. </span><span class="koboSpan" id="kobo.140.3">Another way to provision a dataset is from a Kaggle Notebook; in this case, the output of the notebook will be the content of the dataset. </span><span class="koboSpan" id="kobo.140.4">The dataset can also be created from a Google Cloud Storage resource. </span><span class="koboSpan" id="kobo.140.5">Before creating a dataset, you have the option to set it as public, and you can also check your current private quota. </span><span class="koboSpan" id="kobo.140.6">Each Kaggler has a limited private quota (which has been increasing slightly over time; currently, it is over 100 GB). </span><span class="koboSpan" id="kobo.140.7">If you decide to keep the dataset private, you will have to fit all your private datasets in this quota. </span><span class="koboSpan" id="kobo.140.8">If a dataset is kept private, you can decide at any time to delete it if you do not need it anymore. </span><span class="koboSpan" id="kobo.140.9">After the dataset is initialized, you can start improving it by adding additional information.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.141.1">When creating a dataset, you have the option to add a subtitle, a description (with a minimum number of characters required), and information about each file in the dataset. </span><span class="koboSpan" id="kobo.141.2">For tabular datasets, you can also add titles and explanations for each column. </span><span class="koboSpan" id="kobo.141.3">Then, you can add </span><a id="_idIndexMarker018"/><span class="koboSpan" id="kobo.142.1">tags to make the dataset easier to find through searching and clearly specify the topic, data type, and possible business or research domains, for those interested. </span><span class="koboSpan" id="kobo.142.2">You can also change the image associated with the dataset. </span><span class="koboSpan" id="kobo.142.3">It is </span><a id="_idIndexMarker019"/><span class="koboSpan" id="kobo.143.1">advisable to use a public domain or personal picture. </span><span class="koboSpan" id="kobo.143.2">Adding metadata about authors, generating </span><strong class="keyWord"><span class="koboSpan" id="kobo.144.1">DOI</span></strong><span class="koboSpan" id="kobo.145.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.146.1">Digital Object Identifier</span></strong><span class="koboSpan" id="kobo.147.1">) citations, and specifying provenance and expected update frequency are all helpful in boosting the visibility of your dataset. </span><span class="koboSpan" id="kobo.147.2">It will also improve the likelihood that your contribution will be correctly cited and used in other works. </span><span class="koboSpan" id="kobo.147.3">License information is also important, and you can select from a large list of frequently used licenses. </span><span class="koboSpan" id="kobo.147.4">With each element added in the description and metadata about the contributed dataset, you also increase the usability score, calculated automatically by Kaggle. </span><span class="koboSpan" id="kobo.147.5">It is not always possible to reach a 10/10 usability score (especially when you have a dataset with tens of thousands of files) but it is always preferable to try to improve the information associated with the dataset.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.148.1">Once you publish your dataset, this will become visible in the </span><strong class="screenText"><span class="koboSpan" id="kobo.149.1">Datasets</span></strong><span class="koboSpan" id="kobo.150.1"> section of the platform, and, depending on the usability and the quality perceived by the content moderators from Kaggle, you might get a special status of </span><strong class="keyWord"><span class="koboSpan" id="kobo.151.1">Featured dataset</span></strong><span class="koboSpan" id="kobo.152.1">. </span><span class="koboSpan" id="kobo.152.2">Featured datasets get more </span><a id="_idIndexMarker020"/><span class="koboSpan" id="kobo.153.1">visibility in searches and are included in the top section of recommended datasets when you select the </span><strong class="keyWord"><span class="koboSpan" id="kobo.154.1">Datasets</span></strong><span class="koboSpan" id="kobo.155.1"> section. </span><span class="koboSpan" id="kobo.155.2">Besides the </span><strong class="screenText"><span class="koboSpan" id="kobo.156.1">Featured</span></strong><span class="koboSpan" id="kobo.157.1"> datasets, presented </span><a id="_idIndexMarker021"/><span class="koboSpan" id="kobo.158.1">under a </span><strong class="keyWord"><span class="koboSpan" id="kobo.159.1">Trending datasets</span></strong><span class="koboSpan" id="kobo.160.1"> lane, you will </span><a id="_idIndexMarker022"/><span class="koboSpan" id="kobo.161.1">see lanes with themes like </span><strong class="keyWord"><span class="koboSpan" id="kobo.162.1">Sport</span></strong><span class="koboSpan" id="kobo.163.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.164.1">Health</span></strong><span class="koboSpan" id="kobo.165.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.166.1">Software</span></strong><span class="koboSpan" id="kobo.167.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.168.1">Food</span></strong><span class="koboSpan" id="kobo.169.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.170.1">Travel</span></strong><span class="koboSpan" id="kobo.171.1">, as well as </span><strong class="keyWord"><span class="koboSpan" id="kobo.172.1">Recently Viewed Datasets</span></strong><span class="koboSpan" id="kobo.173.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.174.1">The datasets can include all kinds of file formats. </span><span class="koboSpan" id="kobo.174.2">The most frequently used format is CSV. </span><span class="koboSpan" id="kobo.174.3">It is a very popular format outside Kaggle too and it is the best format choice for tabular data. </span><span class="koboSpan" id="kobo.174.4">When a file is in CSV format, Kaggle will display it, and you can choose to see the content in detail, by columns, or in a compact form. </span><span class="koboSpan" id="kobo.174.5">Other possible data formats used are JSON, SQLite, and archives. </span><span class="koboSpan" id="kobo.174.6">Although a ZIP archive is not a data format per se, it has full support on Kaggle and you can directly read the content of the archive, without unpacking it. </span><span class="koboSpan" id="kobo.174.7">Datasets also include modality-specific formats, various image formats (JPEG, PNG, and so on), audio signals formats (WAV, OGG, and MP3), and video formats. </span><span class="koboSpan" id="kobo.174.8">Domain-specific formats, like DICOM for medical imaging, are widely used. </span><span class="koboSpan" id="kobo.174.9">BigQuery, a dataset format specific to Google Cloud, is also used for datasets on Kaggle, and there is full support for accessing the content.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.175.1">If you contribute to datasets, you can get ranking points and medals as well. </span><span class="koboSpan" id="kobo.175.2">The system is based on upvotes by other users, upvotes from yourself or from Novice Kagglers, or old upvotes not being included in the calculation for granting ranking points or medals. </span><span class="koboSpan" id="kobo.175.3">You can get to the Datasets Expert tier if you acquire three bronze medals, to Master if you get one gold </span><a id="_idIndexMarker023"/><span class="koboSpan" id="kobo.176.1">medal and four silver medals, and to Datasets Grandmaster with five gold medals and five silver medals. </span><span class="koboSpan" id="kobo.176.2">Acquiring medals in Datasets is not easy, since upvotes in Datasets are not easily granted by users, and you will need 5 upvotes to get a bronze medal, 20 upvotes for a silver medal, and 50 upvotes for a gold medal. </span><span class="koboSpan" id="kobo.176.3">Once you get the medals, as these are based on votes, you can lose your medals over time, and even your status as Expert, Master, or Grandmaster can be lost if the users that upvoted you remove their upvote or if they are banned from the platform. </span><span class="koboSpan" id="kobo.176.4">This happens sometimes, and not so infrequently as you might think. </span><span class="koboSpan" id="kobo.176.5">So, if you want to secure your position, the best approach is to always create high-quality content; this will bring you more upvotes and medals than the minimum required.</span></p>
<h1 class="heading-1" id="_idParaDest-19"><span class="koboSpan" id="kobo.177.1">Kaggle Code</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.178.1">Kaggle Code is one of the most active sections on the platform. </span><span class="koboSpan" id="kobo.178.2">Older names for Code are Kernels and </span><a id="_idIndexMarker024"/><span class="koboSpan" id="kobo.179.1">Notebooks and you will frequently hear them used interchangeably. </span><span class="koboSpan" id="kobo.179.2">The number of current contributors, at the time of writing this book, exceeds 260,000 and is surpassed by only the </span><strong class="keyWord"><span class="koboSpan" id="kobo.180.1">Discussions</span></strong><span class="koboSpan" id="kobo.181.1"> section.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.182.1">Code is used for the analysis of datasets or competition datasets, for preparing models for competition submissions, and for generating models and datasets. </span><span class="koboSpan" id="kobo.182.2">In the past, Code could use either R, Python, or Julia as programming languages; currently, you can only choose between Python (the default option) and R. </span><span class="koboSpan" id="kobo.182.3">You can set your editor as </span><strong class="keyWord"><span class="koboSpan" id="kobo.183.1">Script</span></strong><span class="koboSpan" id="kobo.184.1"> or </span><strong class="keyWord"><span class="koboSpan" id="kobo.185.1">Notebook</span></strong><span class="koboSpan" id="kobo.186.1">. </span><span class="koboSpan" id="kobo.186.2">You can choose the computing resource to run your code, with </span><strong class="keyWord"><span class="koboSpan" id="kobo.187.1">CPU</span></strong><span class="koboSpan" id="kobo.188.1"> being the default. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.189.1">Alternatively, you can choose between four options of accelerators if using Python as a programming language or two if using R. </span><span class="koboSpan" id="kobo.189.2">Accelerators are provided free of charge, but there is a quota, reset weekly. </span><span class="koboSpan" id="kobo.189.3">For high-demand accelerator resources, there might also be a waiting list.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.190.1">Code is under source control and, when editing, you can choose to just save (and create a version) or save and run (and you create a code version and a run version). </span><span class="koboSpan" id="kobo.190.2">You can attach to Code datasets, Competitions datasets, and external utility scripts and models. </span><span class="koboSpan" id="kobo.190.3">As long as you are not rerunning the notebook, changes made in the resources used will not affect its visibility. </span><span class="koboSpan" id="kobo.190.4">If you try to rerun the code and refresh the datasets or utility script versions, you might need to account for changes in those data and code versions. </span><span class="koboSpan" id="kobo.190.5">The output of code can be used as input to other code, in the same way as you include datasets and models. </span><span class="koboSpan" id="kobo.190.6">By default, your code is private, and you do not need to make it public to submit the output to a competition.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.191.1">If you make your code public, you can get upvotes, and these count for both the ranking in the Notebooks </span><a id="_idIndexMarker025"/><span class="koboSpan" id="kobo.192.1">category as well as for getting medals. </span><span class="koboSpan" id="kobo.192.2">You need 5 bronze medals for the Expert tier in Notebooks, 10 silver medals for the Master tier, and 15 gold medals for the Grandmaster tier. </span><span class="koboSpan" id="kobo.192.3">One bronze medal needs 5 upvotes, a silver medal needs 20 upvotes, and a gold medal requires 50 upvotes. </span><span class="koboSpan" id="kobo.192.4">Upvotes in Notebooks can be revoked, and you can also make your public notebooks private again (or delete them). </span><span class="koboSpan" id="kobo.192.5">In such a case, all upvotes and medals associated with that Notebook are no longer counted for your ranking or performance tier. </span><span class="koboSpan" id="kobo.192.6">There are Code sections associated with Competitions, Datasets, and Models. </span><span class="koboSpan" id="kobo.192.7">At the time of writing this book, there were 125 Notebook Grandmasters and 472 Masters.</span></p>
<div class="note">
<p class="normal"><span class="koboSpan" id="kobo.193.1">Kaggle grows and changes continuously, both as a data and competitive machine learning platform and as a community. </span><span class="koboSpan" id="kobo.193.2">At the time of writing this book, starting with the new </span><em class="italic"><span class="koboSpan" id="kobo.194.1">2023 Kaggle AI Report</span></em><span class="koboSpan" id="kobo.195.1">, Kaggle introduced a review system for Notebook competitions where all participants submitting an essay are also asked to provide a review for another three participants’ essays. </span><span class="koboSpan" id="kobo.195.2">The final decision about which submission will win the competition is taken by a panel of experts from veteran Kaggle Grandmasters.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.196.1">Kaggle Code’s many features and options will be described in the next chapter in a more detailed manner.</span></p>
<h1 class="heading-1" id="_idParaDest-20"><span class="koboSpan" id="kobo.197.1">Kaggle Discussions</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.198.1">Kaggle Discussions are either associated with other sections or independent. </span><span class="koboSpan" id="kobo.198.2">Competitions </span><a id="_idIndexMarker026"/><span class="koboSpan" id="kobo.199.1">and Datasets both have Discussions sections. </span><span class="koboSpan" id="kobo.199.2">For Code, there is a Comments section. </span><span class="koboSpan" id="kobo.199.3">In the Discussions section, you can add topics for discussion or comments under a topic. </span><span class="koboSpan" id="kobo.199.4">For Code, you can add comments. </span><span class="koboSpan" id="kobo.199.5">Besides these contexts, you can add topics or comments under Forums, or you can follow discussions under Discussions from across the Kaggle section. </span><span class="koboSpan" id="kobo.199.6">Forums are grouped by subjects, and you can choose between </span><strong class="screenText"><span class="koboSpan" id="kobo.200.1">General</span></strong><span class="koboSpan" id="kobo.201.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.202.1">Getting Started</span></strong><span class="koboSpan" id="kobo.203.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.204.1">Product Feedback</span></strong><span class="koboSpan" id="kobo.205.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.206.1">Questions &amp; Answers</span></strong><span class="koboSpan" id="kobo.207.1">, and </span><strong class="screenText"><span class="koboSpan" id="kobo.208.1">Competition Hosting</span></strong><span class="koboSpan" id="kobo.209.1">. </span><span class="koboSpan" id="kobo.209.2">Under Discussions, across Kaggle, you can search the content or focus on a tagged subtopic, like Your </span><strong class="screenText"><span class="koboSpan" id="kobo.210.1">Activity</span></strong><span class="koboSpan" id="kobo.211.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.212.1">Bookmarks</span></strong><span class="koboSpan" id="kobo.213.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.214.1">Beginner</span></strong><span class="koboSpan" id="kobo.215.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.216.1">Data</span></strong> <strong class="screenText"><span class="koboSpan" id="kobo.217.1">Visualization</span></strong><span class="koboSpan" id="kobo.218.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.219.1">Computer Vision</span></strong><span class="koboSpan" id="kobo.220.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.221.1">NLP</span></strong><span class="koboSpan" id="kobo.222.1">, </span><strong class="screenText"><span class="koboSpan" id="kobo.223.1">Neural Networks</span></strong><span class="koboSpan" id="kobo.224.1">, and more.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.225.1">Discussions also has a progression system and you can get ranking points and medals by accumulating upvotes. </span><span class="koboSpan" id="kobo.225.2">Unlike the other sections in which you can get upvotes, in Discussions, you can get downvotes as well. </span><span class="koboSpan" id="kobo.225.3">Ranking points can vanish over time and upvotes will count for medals only if from non-Novices and if new. </span><span class="koboSpan" id="kobo.225.4">You cannot upvote yourself in Discussions.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.226.1">Performance tiers </span><a id="_idIndexMarker027"/><span class="koboSpan" id="kobo.227.1">in Discussions start with Expert, and you can get this tier by accumulating 50 bronze medals. </span><span class="koboSpan" id="kobo.227.2">To get to the next tier, Master, you need 50 silver medals and 200 medals in total, and to reach the Grandmaster tier, you need 50 gold medals and 500 medals in total. </span><span class="koboSpan" id="kobo.227.3">Medals are easy to obtain in Discussions compared with other sections; you only need 1 upvote for a bronze medal, 5 upvotes for a silver medal, and a total of 10 upvotes for a gold medal. </span><span class="koboSpan" id="kobo.227.4">As with the Datasets and Code cases, the votes are not permanent. </span><span class="koboSpan" id="kobo.227.5">Users can decide to retract their upvotes; therefore, you can lose some of your upvotes, ranking points, medals, or even performance tier status.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.228.1">At the time of writing this book, there were 62 Grandmasters in Discussions and 103 Masters.</span></p>
<h1 class="heading-1" id="_idParaDest-21"><span class="koboSpan" id="kobo.229.1">Kaggle Learn</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.230.1">Kaggle Learn is </span><a id="_idIndexMarker028"/><span class="koboSpan" id="kobo.231.1">one of the lesser-known gems on Kaggle. </span><span class="koboSpan" id="kobo.231.2">It contains compact learning modules, each centered on a certain subject related to data science or machine learning. </span><span class="koboSpan" id="kobo.231.3">Each learning module has several lessons, each one with a </span><em class="italic"><span class="koboSpan" id="kobo.232.1">Tutorial</span></em><span class="koboSpan" id="kobo.233.1"> section followed by an </span><em class="italic"><span class="koboSpan" id="kobo.234.1">Exercise</span></em><span class="koboSpan" id="kobo.235.1"> section. </span><span class="koboSpan" id="kobo.235.2">The </span><em class="italic"><span class="koboSpan" id="kobo.236.1">Tutorial</span></em><span class="koboSpan" id="kobo.237.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.238.1">Exercise</span></em><span class="koboSpan" id="kobo.239.1"> sections are available in the form of interactive Kaggle Notebooks. </span><span class="koboSpan" id="kobo.239.2">To complete a learning module, you need to go through all the lessons. </span><span class="koboSpan" id="kobo.239.3">In each lesson, you will need to review the training material and successfully run the Exercise Notebook. </span><span class="koboSpan" id="kobo.239.4">Some of the cells in the Exercise Notebook have a verification associated with them. </span><span class="koboSpan" id="kobo.239.5">If you need help, there are also special cells in the notebook that reveal hints about how to solve the current exercise. </span><span class="koboSpan" id="kobo.239.6">Upon completing the entire learning module, you receive a certificate of completion from Kaggle.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.240.1">Currently, Kaggle Learn is organized into three main sections:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.241.1">Your Courses</span></strong><span class="koboSpan" id="kobo.242.1">, where you </span><a id="_idIndexMarker029"/><span class="koboSpan" id="kobo.243.1">have the courses that you have completed and those that are now in progress (active).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.244.1">Open courses</span></strong><span class="koboSpan" id="kobo.245.1"> that you </span><a id="_idIndexMarker030"/><span class="koboSpan" id="kobo.246.1">can explore further. </span><span class="koboSpan" id="kobo.246.2">The courses in this main section are from absolute beginner courses (such as </span><em class="italic"><span class="koboSpan" id="kobo.247.1">Intro to Programming</span></em><span class="koboSpan" id="kobo.248.1">, </span><em class="italic"><span class="koboSpan" id="kobo.249.1">Python</span></em><span class="koboSpan" id="kobo.250.1">, </span><em class="italic"><span class="koboSpan" id="kobo.251.1">Pandas</span></em><span class="koboSpan" id="kobo.252.1">, </span><em class="italic"><span class="koboSpan" id="kobo.253.1">Intro to SQL</span></em><span class="koboSpan" id="kobo.254.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.255.1">Intro to Machine Learning</span></em><span class="koboSpan" id="kobo.256.1">) to intermediate courses (such as </span><em class="italic"><span class="koboSpan" id="kobo.257.1">Data Cleaning</span></em><span class="koboSpan" id="kobo.258.1">, </span><em class="italic"><span class="koboSpan" id="kobo.259.1">Intermediate Machine Learning</span></em><span class="koboSpan" id="kobo.260.1">, </span><em class="italic"><span class="koboSpan" id="kobo.261.1">Feature Engineering</span></em><span class="koboSpan" id="kobo.262.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.263.1">Advanced SQL</span></em><span class="koboSpan" id="kobo.264.1">). </span><span class="koboSpan" id="kobo.264.2">Also, it contains topic-specific courses like </span><em class="italic"><span class="koboSpan" id="kobo.265.1">Visualization</span></em><span class="koboSpan" id="kobo.266.1">, </span><em class="italic"><span class="koboSpan" id="kobo.267.1">Geospatial Analysis</span></em><span class="koboSpan" id="kobo.268.1">, </span><em class="italic"><span class="koboSpan" id="kobo.269.1">Computer Vision</span></em><span class="koboSpan" id="kobo.270.1">, </span><em class="italic"><span class="koboSpan" id="kobo.271.1">Time Series</span></em><span class="koboSpan" id="kobo.272.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.273.1">Intro to Game AI and Reinforcement Learning</span></em><span class="koboSpan" id="kobo.274.1">. </span><span class="koboSpan" id="kobo.274.2">Some courses touch on extremely interesting topics such as AI ethics and machine learning interpretability.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.275.1">Guides</span></strong><span class="koboSpan" id="kobo.276.1">, which is </span><a id="_idIndexMarker031"/><span class="koboSpan" id="kobo.277.1">dedicated to various learning guides for programs, frameworks, or domains of interest. </span><span class="koboSpan" id="kobo.277.2">This includes the </span><em class="italic"><span class="koboSpan" id="kobo.278.1">JAX Guide</span></em><span class="koboSpan" id="kobo.279.1">, </span><em class="italic"><span class="koboSpan" id="kobo.280.1">TensorFlow Guide</span></em><span class="koboSpan" id="kobo.281.1">, </span><em class="italic"><span class="koboSpan" id="kobo.282.1">Transfer Learning for Computer Vision Guide</span></em><span class="koboSpan" id="kobo.283.1">, </span><em class="italic"><span class="koboSpan" id="kobo.284.1">Kaggle Competitions Guide</span></em><span class="koboSpan" id="kobo.285.1">, </span><em class="italic"><span class="koboSpan" id="kobo.286.1">Natural Language Processing Guide</span></em><span class="koboSpan" id="kobo.287.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.288.1">R Guide</span></em><span class="koboSpan" id="kobo.289.1">.</span></li>
</ul>
<div class="note">
<p class="normal"><span class="koboSpan" id="kobo.290.1">Kaggle is also committed to supporting continuous learning and helping anyone benefit from the knowledge accumulated on the Kaggle platform and the Kaggle community. </span><span class="koboSpan" id="kobo.290.2">In the last two years, Kaggle has started to reach out and help professionals from underrepresented communities acquire skills and experience </span><a id="_idIndexMarker032"/><span class="koboSpan" id="kobo.291.1">in data science and machine learning in the form of the KaggleX </span><strong class="keyWord"><span class="koboSpan" id="kobo.292.1">BIPOC</span></strong><span class="koboSpan" id="kobo.293.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.294.1">Black, Indigenous, and People of Color</span></strong><span class="koboSpan" id="kobo.295.1">) Grant program, by pairing Kagglers, as mentors, with professionals from BIPOC communities, as mentees.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.296.1">In the next section, we will familiarize ourselves with a rapidly evolving capability of the Kaggle platform: </span><strong class="keyWord"><span class="koboSpan" id="kobo.297.1">Models</span></strong><span class="koboSpan" id="kobo.298.1">.</span></p>
<h1 class="heading-1" id="_idParaDest-22"><span class="koboSpan" id="kobo.299.1">Kaggle Models</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.300.1">Models is the </span><a id="_idIndexMarker033"/><span class="koboSpan" id="kobo.301.1">newest section introduced on the platform; at the time of writing this book, it is less than one month old. </span><span class="koboSpan" id="kobo.301.2">Models started to be contributed quite often by users in several ways and for a few purposes. </span><span class="koboSpan" id="kobo.301.3">Most frequently, models were saved as output of Notebooks (Code) after being trained using custom code, often in the context of a competition. </span><span class="koboSpan" id="kobo.301.4">Subsequently, these models can be optionally included in a dataset or used directly in code. </span><span class="koboSpan" id="kobo.301.5">Also, sometimes, models built outside the platform were uploaded as datasets and then included in the pipeline of users to prepare a solution for a competition. </span><span class="koboSpan" id="kobo.301.6">Meantime, model repositories were available either through a public cloud, like Google Cloud, AWS, or Azure, or from a company specialized in such a service, like Hugging Face.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.302.1">With the concept of downloadable models ready to be used or easy to fine-tune for a custom task, Kaggle chose to include </span><strong class="screenText"><span class="koboSpan" id="kobo.303.1">Models</span></strong><span class="koboSpan" id="kobo.304.1"> in this platform. </span><span class="koboSpan" id="kobo.304.2">Currently, you can search in several categories: </span><em class="italic"><span class="koboSpan" id="kobo.305.1">Text Classification</span></em><span class="koboSpan" id="kobo.306.1">, </span><em class="italic"><span class="koboSpan" id="kobo.307.1">Image Feature Vector</span></em><span class="koboSpan" id="kobo.308.1">, </span><em class="italic"><span class="koboSpan" id="kobo.309.1">Object Detection</span></em><span class="koboSpan" id="kobo.310.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.311.1">Image Segmentation</span></em><span class="koboSpan" id="kobo.312.1">. </span><span class="koboSpan" id="kobo.312.2">Alternatively, you can use the </span><em class="italic"><span class="koboSpan" id="kobo.313.1">Model Finder</span></em><span class="koboSpan" id="kobo.314.1"> feature to explore models specialized in a certain modality: </span><em class="italic"><span class="koboSpan" id="kobo.315.1">Image</span></em><span class="koboSpan" id="kobo.316.1">, </span><em class="italic"><span class="koboSpan" id="kobo.317.1">Text</span></em><span class="koboSpan" id="kobo.318.1">, </span><em class="italic"><span class="koboSpan" id="kobo.319.1">Audio</span></em><span class="koboSpan" id="kobo.320.1">, </span><em class="italic"><span class="koboSpan" id="kobo.321.1">Multimodal</span></em><span class="koboSpan" id="kobo.322.1">, or </span><em class="italic"><span class="koboSpan" id="kobo.323.1">Video</span></em><span class="koboSpan" id="kobo.324.1">. </span><span class="koboSpan" id="kobo.324.2">When searching the Models library, you can apply filters on </span><em class="italic"><span class="koboSpan" id="kobo.325.1">Task</span></em><span class="koboSpan" id="kobo.326.1">, </span><em class="italic"><span class="koboSpan" id="kobo.327.1">Data Type</span></em><span class="koboSpan" id="kobo.328.1">, </span><em class="italic"><span class="koboSpan" id="kobo.329.1">Framework</span></em><span class="koboSpan" id="kobo.330.1">, </span><em class="italic"><span class="koboSpan" id="kobo.331.1">Language</span></em><span class="koboSpan" id="kobo.332.1">, </span><em class="italic"><span class="koboSpan" id="kobo.333.1">License</span></em><span class="koboSpan" id="kobo.334.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.335.1">Size</span></em><span class="koboSpan" id="kobo.336.1">, as well as functional criteria, like </span><em class="italic"><span class="koboSpan" id="kobo.337.1">Fine Tuneable</span></em><span class="koboSpan" id="kobo.338.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.339.1">There are no </span><a id="_idIndexMarker034"/><span class="koboSpan" id="kobo.340.1">ranking points or performance tiers related to models yet. </span><span class="koboSpan" id="kobo.340.2">Models can be upvoted and there is a Code and Discussions section associated with each model. </span><span class="koboSpan" id="kobo.340.3">In the future, it is possible that we will see evolution here as well and have models with ranking points as well as performance tiers if they make it possible to contribute models and get recognition for this. </span><span class="koboSpan" id="kobo.340.4">Currently, models are contributed by Google only.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.341.1">We might see the Models feature evolving immensely in the near future, providing the community with a flexible and powerful tool for the creation of modular and scalable solutions to train and add inference to machine learning pipelines on the Kaggle platform.</span></p>
<h1 class="heading-1" id="_idParaDest-23"><span class="koboSpan" id="kobo.342.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.343.1">In this chapter, we learned a little about the history of the Kaggle platform, its resources, and its capabilities. </span><span class="koboSpan" id="kobo.343.2">We then introduced the basics of how to create an account and start benefiting from the platform’s resources and interaction with other users.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.344.1">Initially a platform only for predictive modeling competitions, Kaggle has grown to become a complex data platform, with sections for Competitions, Datasets, Code (Notebooks), and Discussions. </span><span class="koboSpan" id="kobo.344.2">Hence, we learned how you can move up the ranks by accumulating ranking points and medals in Competitions and medals in Datasets, Notebooks, and Discussions. </span><span class="koboSpan" id="kobo.344.3">In the future, it is possible that Kaggle will also add ranking points for other sections besides Competitions, although this is a subject of debate in the Kaggle community. </span><span class="koboSpan" id="kobo.344.4">Additionally, Kaggle provides a learning platform (with </span><strong class="keyWord"><span class="koboSpan" id="kobo.345.1">Learn</span></strong><span class="koboSpan" id="kobo.346.1">) and </span><strong class="keyWord"><span class="koboSpan" id="kobo.347.1">Models</span></strong><span class="koboSpan" id="kobo.348.1"> (which can be used in Notebooks).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.349.1">It’s now time to get ready for your trip around the data analysis world, using Kaggle resources. </span><span class="koboSpan" id="kobo.349.2">In the next chapter, you will learn how to use the full capacity of the platform to code, get familiar with the development environment, and learn how to use it to its maximum potential. </span><span class="koboSpan" id="kobo.349.3">Let’s get ready!</span></p>
<h1 class="heading-1"><span class="koboSpan" id="kobo.350.1">Join our book’s Discord space</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.351.1">Join our Discord community to meet like-minded people and learn alongside more than 5000 members at:</span></p>
<p class="normal"><a href="https://packt.link/kaggle"><span class="url"><span class="koboSpan" id="kobo.352.1">https://packt.link/kaggle</span></span></a></p>
<p class="normal"><span class="koboSpan" id="kobo.353.1"><img alt="" role="presentation" src="../Images/QR_Code9220780366773140.png"/></span></p>
</div>
</body></html>