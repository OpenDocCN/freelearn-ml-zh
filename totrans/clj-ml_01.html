<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch01"/>Chapter 1. Working with Matrices</h1></div></div></div><p>In this chapter, we will explore an elementary yet elegant mathematical data structure—the <strong>matrix</strong><a id="id0" class="indexterm"/>. Most computer science and mathematics graduates would already be familiar with matrices and their applications. In the context of machine learning, matrices are used to implement several types of machine-learning techniques, such as linear regression and classification. We will study more about these techniques in the later chapters.</p><p>Although this chapter may seem mostly theoretical at first, we will soon see that matrices are a very useful abstraction for quickly organizing and indexing data with multiple dimensions. The data used by machine-learning techniques contains a large number of sample values in several dimensions. Thus, matrices can be used to store and manipulate this sample data.</p><p>An interesting application that uses matrices is Google Search, which is built on the <strong>PageRank</strong> algorithm<a id="id1" class="indexterm"/>. Although a detailed explanation of this algorithm is beyond the scope of this book, it's worth knowing that Google Search essentially finds the <em>eigen-vector</em> of an extremely massive matrix of data (for more information, refer to <em>The Anatomy of a Large-Scale Hypertextual Web Search Engine</em>). Matrices are used for a variety of applications in computing. Although we do not discuss the eigen-vector matrix operation used by Google Search in this book, we will encounter a variety of matrix operations while implementing machine-learning algorithms. In this chapter, we will describe the useful operations that we can perform on matrices.</p><div><div><div><div><h1 class="title"><a id="ch01lvl1sec08"/>Introducing Leiningen</h1></div></div></div><p>Over the course of this book, we will use Leiningen<a id="id2" class="indexterm"/> (<a class="ulink" href="http://leiningen.org/">http://leiningen.org/</a>) to manage third-party libraries and dependencies. Leiningen, or <code class="literal">lein</code>, is the<a id="id3" class="indexterm"/> standard Clojure package management and automation tool, and has several powerful features used to manage Clojure projects.</p><p>To get instructions on how to install Leiningen, visit the project site at <a class="ulink" href="http://leiningen.org/">http://leiningen.org/</a>. The first run of the <code class="literal">lein</code> program could take a while, as it downloads and installs the Leiningen binaries when it's run for the first time. We can create a new Leiningen project using the <code class="literal">new</code> subcommand of <code class="literal">lein</code>, as follows:</p><div><pre class="programlisting">
<strong>$ lein new default my-project</strong>
</pre></div><p>The preceding command creates a new directory, <code class="literal">my-project</code>, which will contain all source and configuration files for a Clojure project. This folder contains the source files in the <code class="literal">src</code> subdirectory and a single <code class="literal">project.clj</code> file. In this command, <code class="literal">default</code> is the type of project template to be used<a id="id4" class="indexterm"/> for the new project. All the examples in this book use the preceding <code class="literal">default</code> project template.</p><p>The <code class="literal">project.clj</code> file contains all the configuration associated with the project and will have the following structure:</p><div><pre class="programlisting">(defproject my-project "0.1.0-SNAPSHOT"
  :description "FIXME: write description"
  :url "http://example.com/FIXME"
  :license 
  {:name "Eclipse Public License"
   :url "http://www.eclipse.org/legal/epl-v10.html"}
  :dependencies [[org.clojure/clojure "1.5.1"]])</pre></div><div><div><h3 class="title"><a id="tip02"/>Tip</h3><p>
<strong>Downloading the example code</strong>
</p><p>You can download the example code files for all Packt books you have purchased from your account at <a class="ulink" href="http://www.packtpub.com">http://www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a class="ulink" href="http://www.packtpub.com/support">http://www.packtpub.com/support</a> and register to have the files e-mailed directly to you.</p></div></div><p>Third-party Clojure libraries can be included in a project by adding the declarations to the vector with the <code class="literal">:dependencies</code> key. For example, the core.matrix Clojure library package on Clojars (<a class="ulink" href="https://clojars.org/net.mikera/core.matrix">https://clojars.org/net.mikera/core.matrix</a>) gives us the package declaration <code class="literal">[net.mikera/core.matrix "0.20.0"]</code>. We simply paste this declaration into the <code class="literal">:dependencies</code> vector to add the core.matrix library package as a dependency for our Clojure project, as shown in the following code:</p><div><pre class="programlisting">  :dependencies [[org.clojure/clojure "1.5.1"]
                 [net.mikera/core.matrix "0.20.0"]])</pre></div><p>To download all the dependencies declared in the <code class="literal">project.clj</code> file, simply run the following <code class="literal">deps</code> subcommand:</p><div><pre class="programlisting">
<strong>$ lein deps</strong>
</pre></div><p>Leiningen also provides an <strong>REPL</strong><a id="id5" class="indexterm"/> (<strong>read-evaluate-print-loop</strong>), which is simply an interactive interpreter that contains<a id="id6" class="indexterm"/> all the dependencies declared in the <code class="literal">project.clj</code> file. This REPL will also reference all the Clojure namespaces that we have defined in our project. We can start the REPL using the following <code class="literal">repl</code> subcommand of <code class="literal">lein</code>. This will start a new REPL session:</p><div><pre class="programlisting">
<strong>$ lein repl</strong>
</pre></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch01lvl1sec09"/>Representing matrices</h1></div></div></div><p>A matrix is simply a rectangular<a id="id7" class="indexterm"/> array of data arranged in rows and columns. Most programming languages, such as C# and Java, have direct support for rectangular arrays, while others, such as Clojure, use the heterogeneous array-of-arrays representation for rectangular arrays. Keep in mind that Clojure has no direct support for handling arrays, and an idiomatic Clojure code uses <em>vectors</em> to store and index an array of elements. As we will see later, a matrix is represented as a vector whose elements are the other vectors in Clojure.</p><p>Matrices also support several arithmetic operations, such as addition and multiplication, which constitute an important field of mathematics known as <strong>Linear Algebra</strong><a id="id8" class="indexterm"/>. Almost every popular programming language has at least one linear algebra library. Clojure takes this a step ahead by letting us choose from several such libraries, all of which have a single standardized API interface that works with matrices.</p><p>The <a id="id9" class="indexterm"/>
<em>core.matrix</em> library<a id="id10" class="indexterm"/> is a versatile Clojure library used to work with matrices. Core.matrix also contains a specification to handle matrices. An interesting fact about core.matrix is that while it provides a default implementation of this specification, it also supports multiple implementations. The core.matrix library is hosted and developed on GitHub<a id="id11" class="indexterm"/> at <a class="ulink" href="http://github.com/mikera/core.matrix">http://github.com/mikera/core.matrix</a>.</p><div><div><h3 class="title"><a id="note02"/>Note</h3><p>The core.matrix library can be added to a Leiningen project by adding the following dependency to the <code class="literal">project.clj</code> file:</p><div><pre class="programlisting">[net.mikera/core.matrix "0.20.0"]</pre></div><p>For the upcoming example, the namespace declaration should look similar to the following declaration:</p><div><pre class="programlisting">(ns my-namespace
  (:use clojure.core.matrix))</pre></div><p>Note that the use of <code class="literal">:import</code> to include library namespaces in Clojure is generally discouraged. Instead, aliased namespaces with the <code class="literal">:require</code> form are preferred. However, for the examples in the following section, we will use the preceding namespace declaration.</p></div></div><p>In Clojure, a matrix is simply a vector of vectors. <a id="id12" class="indexterm"/>This means that a matrix<a id="id13" class="indexterm"/> is represented as a vector whose elements are other vectors. A vector is an array of elements that takes near-constant time to retrieve an element, <a id="id14" class="indexterm"/>unlike a list that has linear lookup time. However, in the mathematical context of matrices, vectors are simply matrices with a single row or column.</p><p>To create a matrix from a vector of vectors<a id="id15" class="indexterm"/>, we use the following <code class="literal">matrix</code> function and pass a vector of vectors or a quoted list to it. Note that all the elements of the <a id="id16" class="indexterm"/>matrix are internally represented as a <code class="literal">double</code> data type (<code class="literal">java.lang.Double</code>) for added precision.</p><div><pre class="programlisting">user&gt; (matrix [[0 1 2] [3 4 5]])    ;; using a vector
[[0 1 2] [3 4 5]]
user&gt; (matrix '((0 1 2) (3 4 5)))   ;; using a quoted list
[[0 1 2] [3 4 5]]</pre></div><p>In the preceding example, the matrix has two rows and three columns, or is a 2 x 3 matrix to be more concise. It should be noted that when a matrix is represented by a vector of vectors, all the vectors that represent the individual rows of the matrix should have the same length.</p><p>The matrix that is created is printed as a vector, which is not the best way to visually represent it. We can use the <code class="literal">pm</code> function to print the matrix as follows:</p><div><pre class="programlisting">user&gt; (def A (matrix [[0 1 2] [3 4 5]]))
#'user/A
user&gt; (pm A)
[[0.000 1.000 2.000]
 [3.000 4.000 5.000]]</pre></div><p>Here, we define a matrix <em>A</em>, which is mathematically represented as follows. Note that the use of uppercase variable names is for illustration only, as all the Clojure variables are conventionally written in lowercase.</p><div><img src="img/4351OS_01_04.jpg" alt="Representing matrices"/></div><p>The matrix <em>A</em> is composed of elements a<sub>i,j</sub> where <em>i</em> is the row index and <em>j</em> is the column index of the matrix. We can mathematically represent a matrix <em>A</em> using brackets as follows:</p><div><img src="img/4351OS_01_05.jpg" alt="Representing matrices"/></div><p>We can use the <code class="literal">matrix?</code> function<a id="id17" class="indexterm"/> to check whether a symbol or variable is, in fact, a matrix. The <code class="literal">matrix?</code> function will return <code class="literal">true</code> for all the matrices that implement the core.matrix specification. Interestingly, the <code class="literal">matrix?</code> function will also return <code class="literal">true</code> for an ordinary vector of vectors.</p><p>The default implementation<a id="id18" class="indexterm"/> of core.matrix is written in pure Clojure, which does affect performance when handling large matrices. The core.matrix specification has two popular contrib implementations, namely <strong>vectorz-clj</strong><a id="id19" class="indexterm"/> (<a class="ulink" href="http://github.com/mikera/vectorz-clj">http://github.com/mikera/vectorz-clj</a>) that is implemented using pure Java and <strong>clatrix</strong><a id="id20" class="indexterm"/> (<a class="ulink" href="http://github.com/tel/clatrix">http://github.com/tel/clatrix</a>) that is implemented through native libraries. While there are several other libraries that implement the core.matrix specification, these two libraries are seen as the most mature ones.</p><div><div><h3 class="title"><a id="note05"/>Note</h3><p>Clojure has three kinds of libraries, namely core, contrib, and third-party libraries. Core and contrib libraries are part of the standard Clojure library. The documentation for both the core and contrib libraries can be found at <a class="ulink" href="http://clojure.github.io/">http://clojure.github.io/</a>. The only difference between the core and contrib libraries is that the contrib libraries are not shipped with the Clojure language and have to be downloaded separately.</p><p>Third-party libraries can be developed by anyone and are made available via Clojars (<a class="ulink" href="https://clojars.org/">https://clojars.org/</a>). Leiningen supports all of the previous libraries and doesn't make much of a distinction between them.</p><p>The contrib libraries are often originally developed as third-party libraries. Interestingly, core.matrix was first developed as a third-party library and was later promoted to a contrib library.</p></div></div><p>The clatrix library<a id="id21" class="indexterm"/> uses the <strong>Basic Linear Algebra Subprograms</strong> (<strong>BLAS</strong>) specification<a id="id22" class="indexterm"/> to interface the native libraries that it uses. BLAS is also a stable specification of the linear algebra operations on matrices and vectors that are mostly used by native languages. In practice, clatrix performs significantly better than other implementations of core.matrix, and defines several utility functions used to work with matrices as well. You should note that matrices are treated as mutable objects by the clatrix library, as opposed to other implementations of the core.matrix specification that idiomatically treat a matrix as an immutable type.</p><p>For most of this chapter, we will <a id="id23" class="indexterm"/>use clatrix to represent and manipulate matrices. However, we can effectively reuse functions from core.matrix that perform matrix operations (such as addition and multiplication) on the matrices created through clatrix. The only difference is that instead of using the <code class="literal">matrix</code> function from the <code class="literal">core.matrix</code> namespace to create matrices, we should use the one defined in the clatrix library.</p><div><div><h3 class="title"><a id="note06"/>Note</h3><p>The clatrix library can be added to a Leiningen project by adding the following dependency to the <code class="literal">project.clj</code> file:</p><div><pre class="programlisting">[clatrix "0.3.0"]</pre></div><p>For the upcoming example, the namespace declaration should look similar to the following declaration:</p><div><pre class="programlisting">(ns my-namespace
  (:use clojure.core.matrix)
  (:require [clatrix.core :as cl]))</pre></div><p>Keep in mind that we can use both the <code class="literal">clatrix.core</code> and <code class="literal">clojure.core.matrix</code> namespaces in the same source file, but a good practice would be to import both these namespaces into aliased namespaces to prevent naming conflicts.</p></div></div><p>We can create a matrix<a id="id24" class="indexterm"/> from the clatrix library using the<a id="id25" class="indexterm"/> following <code class="literal">cl/matrix</code> function. Note that clatrix produces a slightly different, yet more informative representation of the matrix than core.matrix. As mentioned earlier, the <code class="literal">pm</code> function can be used to print the matrix as a vector of vectors:</p><div><pre class="programlisting">user&gt; (def A (cl/matrix [[0 1 2] [3 4 5]]))
#'user/A
user&gt; A
 A 2x3 matrix
 -------------
 0.00e+00  1.00e+00  2.00e+00 
 3.00e+00  4.00e+00  5.00e+00 
user&gt; (pm A)
[[0.000 1.000 2.000]
 [3.000 4.000 5.000]]
nil</pre></div><p>We can also use<a id="id26" class="indexterm"/> an overloaded version of the <code class="literal">matrix</code> function<a id="id27" class="indexterm"/>, which takes a matrix implementation name as the first parameter, and is followed by the usual <a id="id28" class="indexterm"/>definition of the matrix as a vector, to create a matrix. The implementation name is specified as a keyword. For example, the default persistent vector implementation is specified as <code class="literal">:persistent-vector</code> and the clatrix implementation is specified as <code class="literal">:clatrix</code>. We can call the <code class="literal">matrix</code> function by specifying this <a id="id29" class="indexterm"/>keyword argument to create matrices of different implementations, as shown in the following code. In the first call, we call the <code class="literal">matrix</code> function with the <code class="literal">:persistent-vector</code> keyword to specify the default persistent vector implementation. Similarly, we call the <code class="literal">matrix</code> function with the <code class="literal">:clatrix</code> keyword to create a clatrix implementation.</p><div><pre class="programlisting">user&gt; (matrix :persistent-vector [[1 2] [2 1]])
[[1 2] [2 1]]
user&gt; (matrix :clatrix [[1 2] [2 1]])
 A 2x2 matrix
 -------------
 1.00e+00  2.00e+00 
 2.00e+00  1.00e+00</pre></div><p>An interesting point is that the vectors of both vectors and numbers are treated as valid parameters for the <code class="literal">matrix</code> function by clatrix, which is different from how core.matrix handles it. For example, <code class="literal">[0 1]</code> produces a 2 x 1 matrix, while <code class="literal">[[0 1]]</code> produces a 1 x 2 matrix. The <code class="literal">matrix</code> function from core.matrix does not have this functionality and always expects a vector of vectors to be passed to it. However, calling the <code class="literal">cl/matrix</code> function with either <code class="literal">[0 1]</code> or <code class="literal">[[0 1]]</code> will create the following matrices without any error:</p><div><pre class="programlisting">user&gt; (cl/matrix [0 1])
 A 2x1 matrix
 -------------
 0.00e+00 
 1.00e+00 
user&gt; (cl/matrix [[0 1]])
 A 1x2 matrix
 -------------
 0.00e+00  1.00e+00 </pre></div><p>Analogous to the <code class="literal">matrix?</code> function, we can use the <code class="literal">cl/clatrix?</code> function<a id="id30" class="indexterm"/> to check whether a symbol or variable is a matrix from the clatrix library. While <code class="literal">matrix?</code> actually checks for an implementation of the core.matrix specification or protocol, the <code class="literal">cl/clatrix?</code> function checks for a specific type. If the <code class="literal">cl/clatrix?</code> function returns <code class="literal">true</code> for a<a id="id31" class="indexterm"/> particular variable, <code class="literal">matrix?</code> should return <code class="literal">true</code> as well; however, the converse of this axiom isn't true. If we call <code class="literal">cl/clatrix?</code> on a matrix created using the <code class="literal">matrix</code> function and not the <code class="literal">cl/matrix</code> function, it will return <code class="literal">false</code>; this is shown in the following code:</p><div><pre class="programlisting">user&gt; (def A (cl/matrix [[0 1]]))
#'user/A
user&gt; (matrix? A)
true
user&gt; (cl/clatrix? A)
true
user&gt; (def B (matrix [[0 1]]))
#'user/B
user&gt; (matrix? B)
true
user&gt; (cl/clatrix? B)
false</pre></div><p>Size is an important attribute of a matrix, and it often needs to be calculated. We can find the number of rows in a matrix using the <code class="literal">row-count</code> function<a id="id32" class="indexterm"/>. It's actually just the length of the vector composing a matrix, and thus, we can also use the standard <code class="literal">count</code> function to determine the row count of a matrix. Similarly, the <code class="literal">column-count</code> function<a id="id33" class="indexterm"/> returns the number of columns in a matrix. Considering the fact that a matrix comprises equally long vectors, the number of columns should be the length of any inner vector, or rather any row, of a matrix. We can check the return value of the <code class="literal">count</code>, <code class="literal">row-count</code>, and <code class="literal">column-count</code> functions on the following sample matrix in the REPL:</p><div><pre class="programlisting">user&gt; (count (cl/matrix [0 1 2]))
3
user&gt; (row-count (cl/matrix [0 1 2]))
3
user&gt; (column-count (cl/matrix [0 1 2]))
1</pre></div><p>To retrieve an element from a matrix using its row and column indexes, use the following <code class="literal">cl/get</code> function. Apart from the matrix to perform the operation on, this function accepts two parameters as indexes to the matrix. Note that all elements are indexed relative to <em>0</em> in Clojure code, as opposed to the mathematical notation of treating <em>1</em> as the position of the first element in a matrix.</p><div><pre class="programlisting">user&gt; (def A (cl/matrix [[0 1 2] [3 4 5]]))
#'user/A
user&gt; (cl/get A 1 1)
4.0
user&gt; (cl/get A 3)
4.0</pre></div><p>As shown in the preceding<a id="id34" class="indexterm"/> example, the <code class="literal">cl/get</code> function<a id="id35" class="indexterm"/> also has an alternate form where only a single index value is accepted as a function parameter. In this case, the elements are indexed through a row-first traversal. For example, <code class="literal">(cl/get A 1)</code> returns <code class="literal">3.0</code> and <code class="literal">(cl/get A 3)</code> returns <code class="literal">4.0</code>. We can use the following <code class="literal">cl/set</code> function to change an element of a matrix. This function takes parameters similar to <code class="literal">cl/get</code>—a matrix, a row index, a column index, and lastly, the new element to be set in the specified position in the matrix. The <code class="literal">cl/set</code> function actually mutates or modifies the matrix it is supplied.</p><div><pre class="programlisting">user&gt; (pm A)
[[0.000 1.0002.000]
 [3.000 4.0005.000]]
nil
user&gt; (cl/set A 1 2 0)
#&lt;DoubleMatrix [0.000000, 1.000000, … , 0.000000]&gt;
user&gt; (pm A)
[[0.000 1.000 2.000]
 [3.000 4.000 0.000]]
nil</pre></div><p>The clatrix library also provides two handy functions for functional composition: <code class="literal">cl/map</code> and <code class="literal">cl/map-indexed</code>. <a id="id36" class="indexterm"/>Both these<a id="id37" class="indexterm"/> functions accept a function and matrix as arguments and apply the passed function to each element in the matrix, in a manner that is similar to the standard <code class="literal">map</code> function. Also, both these functions return new matrices and do not mutate the matrix that they are supplied as parameters. Note that the function passed to <code class="literal">cl/map-indexed</code> should accept three arguments—the row index, the column index, and the element<a id="id38" class="indexterm"/> itself:</p><div><pre class="programlisting">user&gt; (cl/map-indexed 
      (fn [i j m] (* m 2)) A)
 A 2x3 matrix
 -------------
 0.00e+00  2.00e+00  4.00e+00 
 6.00e+00  8.00e+00  1.00e+01 
user&gt; (pm (cl/map-indexed (fn [i j m] i) A))
[[0.000 0.000 0.000]
 [1.000 1.000 1.000]]
nil
user&gt; (pm (cl/map-indexed (fn [i j m] j) A))
[[0.000 1.000 2.000]
 [0.000 1.000 2.000]]
nil</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch01lvl1sec10"/>Generating matrices</h1></div></div></div><p>If the number of rows and columns<a id="id39" class="indexterm"/> in a matrix are equal, then we term the matrix as a <em>square matrix</em>.<a id="id40" class="indexterm"/> We can easily generate a simple <a id="id41" class="indexterm"/>square matrix of <img src="img/4351OS_01_06.jpg" alt="Generating matrices"/> size by using the <code class="literal">repeat</code> function<a id="id42" class="indexterm"/> to repeat a single element as follows:</p><div><pre class="programlisting">(defn square-mat
  "Creates a square matrix of size n x n 
  whose elements are all e"
  [n e]
  (let [repeater #(repeat n %)]
    (matrix (-&gt; e repeater repeater))))</pre></div><p>In the preceding example, we define a closure to repeat a value <em>n</em> times, which is shown as the <code class="literal">repeater</code>. We then use the <em>thread</em> macro (<code class="literal">-&gt;</code>) to pass the element <code class="literal">e</code> through the closure twice, and finally apply the <code class="literal">matrix</code> function to the result of the thread macro. We can extend this definition to allow us to specify the matrix implementation to be used for the generated matrix; this is done as follows:</p><div><pre class="programlisting">(defn square-mat
  "Creates a square matrix of size n x n whose 
  elements are all e. Accepts an option argument 
  for the matrix implementation."
  [n e &amp; {:keys [implementation] 
          :or {implementation :persistent-vector}}]
  (let [repeater #(repeat n %)]
    (matrix implementation (-&gt; e repeater repeater))))</pre></div><p>The <code class="literal">square-mat</code> function<a id="id43" class="indexterm"/> is defined as <a id="id44" class="indexterm"/>one that accepts optional keyword arguments, which specify the matrix implementation of the generated matrix. We specify the default <code class="literal">:persistent-vector</code> implementation of core.matrix as the default value for the <code class="literal">:implementation</code> keyword.</p><p>Now, we can use this function to create square matrices and optionally specify the matrix implementation when required:</p><div><pre class="programlisting">user&gt; (square-mat 2 1)
[[1 1] [1 1]]
user&gt; (square-mat 2 1 :implementation :clatrix)
 A 2x2 matrix
 -------------
 1.00e+00  1.00e+00
 1.00e+00  1.00e+00</pre></div><p>A special type of matrix that's used frequently is the identity matrix. An<a id="id45" class="indexterm"/> <strong>identity matrix</strong><a id="id46" class="indexterm"/> is a square matrix whose diagonal elements are <em>1</em> and all the other elements are <em>0</em>. We formally define an identity matrix <img src="img/4351OS_01_07.jpg" alt="Generating matrices"/> as follows:</p><div><img src="img/4351OS_01_08.jpg" alt="Generating matrices"/></div><p>We can implement a function to create an identity matrix using the <code class="literal">cl/map-indexed</code> function<a id="id47" class="indexterm"/> that we<a id="id48" class="indexterm"/> previously mentioned,<a id="id49" class="indexterm"/> as shown in the following code snippet. We first create a square matrix <code class="literal">init</code> of <img src="img/4351OS_01_06.jpg" alt="Generating matrices"/> size by using the previously defined <code class="literal">square-mat</code> function, and then map all the diagonal elements to <code class="literal">1</code> using <code class="literal">cl/map-indexed</code>:</p><div><pre class="programlisting">(defn id-mat
  "Creates an identity matrix of n x n size"
  [n]
  (let [init (square-mat :clatrix n 0)
       identity-f (fn [i j n]
                     (if (= i j) 1 n))]
    (cl/map-indexed identity-f init)))</pre></div><p>The core.matrix library also has its own version of this function, named <code class="literal">identity-matrix</code>:</p><div><pre class="programlisting">user&gt; (id-mat 5)
 A 5x5 matrix
 -------------
 1.00e+00  0.00e+00 0.00e+00 0.00e+00 0.00e+00
 0.00e+00  1.00e+00 0.00e+00 0.00e+00 0.00e+00
 0.00e+00  0.00e+00 1.00e+00 0.00e+00 0.00e+00
 0.00e+00  0.00e+00 0.00e+00 1.00e+00 0.00e+00 
 0.00e+00  0.00e+00 0.00e+00 0.00e+00 1.00e+00 
user&gt; (pm (identity-matrix 5))
[[1.000 0.000 0.000 0.000 0.000]
 [0.000 1.000 0.000 0.000 0.000]
 [0.000 0.000 1.000 0.000 0.000]
 [0.000 0.000 0.000 1.000 0.000]
 [0.000 0.000 0.000 0.000 1.000]]
nil</pre></div><p>Another common scenario that we will encounter is the need to generate a matrix with random data. Let's implement the following function to generate a random matrix, just like the previously defined <code class="literal">square-mat</code> function, using the <code class="literal">rand-int</code> function<a id="id50" class="indexterm"/>. Note that the <code class="literal">rand-int</code> function accepts a single argument <code class="literal">n</code>, and returns a random integer between <code class="literal">0</code> and <code class="literal">n</code>:</p><div><pre class="programlisting">(defn rand-square-mat 
  "Generates a random matrix of size n x n"
  [n]
  ;; this won't work
  (matrix (repeat n (repeat n (rand-int 100))))) </pre></div><p>But this function produces<a id="id51" class="indexterm"/> a matrix whose elements are all single random numbers, which is not very useful. For example, if we call the <code class="literal">rand-square-mat</code> function<a id="id52" class="indexterm"/> with any integer as its parameter, then it returns a matrix with a single distinct random number, as shown in the following code snippet:</p><div><pre class="programlisting">user&gt; (rand-square-mat 4)
[[94 94] [94 94] [94 94] [94 94]]</pre></div><p>Instead, we should map each element of the square matrix generated by the <code class="literal">square-mat</code> function using the <code class="literal">rand-int</code> function, to generate a random number for each element. Unfortunately, <code class="literal">cl/map</code> only works with matrices created by the clatrix library, but we can easily replicate this behavior in Clojure using a lazy sequence, as returned by the <code class="literal">repeatedly</code> function<a id="id53" class="indexterm"/>. Note that the <code class="literal">repeatedly</code> function accepts the length of a lazily generated sequence and a function to be used as a generator for this sequence as arguments. Thus, we can implement functions to generate random matrices using the clatrix and core.matrix libraries as follows:</p><div><pre class="programlisting">(defn rand-square-clmat
  "Generates a random clatrix matrix of size n x n"
  [n]
  (cl/map rand-int (square-mat :clatrix n 100)))

(defn rand-square-mat
  "Generates a random matrix of size n x n"
  [n]
  (matrix
   (repeatedly n #(map rand-int (repeat n 100)))))</pre></div><p>This implementation works as expected, and each element of the new matrix is now an independently generated random number. We can verify this in the REPL by calling the following modified <code class="literal">rand-square-mat</code> function:</p><div><pre class="programlisting">user&gt; (pm (rand-square-mat 4))
[[97.000 35.000 69.000 69.000]
 [50.000 93.000 26.000  4.000]
 [27.000 14.000 69.000 30.000]
 [68.000 73.000 0.0007 3.000]]
nil
user&gt; (rand-square-clmat 4)
 A 4x4 matrix
 -------------
 5.30e+01  5.00e+00  3.00e+00  6.40e+01 
 6.20e+01  1.10e+01  4.10e+01  4.20e+01 
 4.30e+01  1.00e+00  3.80e+01  4.70e+01 
 3.00e+00  8.10e+01  1.00e+01  2.00e+01</pre></div><p>We can also generate a matrix of random elements using the <code class="literal">cl/rnorm</code> function from the clatrix library. This <a id="id54" class="indexterm"/>function generates a matrix of normally distributed random elements with optionally specified mean and standard deviations. The matrix is normally distributed in the sense that all the elements are distributed evenly around the specified mean value with a spread specified by the standard deviation. Thus, a low standard deviation produces a set of values that are almost equal to the mean.</p><p>The <code class="literal">cl/rnorm</code> function<a id="id55" class="indexterm"/> has several overloads. Let's examine a couple of them in the REPL:</p><div><pre class="programlisting">user&gt; (cl/rnorm 10 25 10 10)
 A 10x10 matrix
 ---------------
-1.25e-01  5.02e+01 -5.20e+01  .  5.07e+01  2.92e+01  2.18e+01 
-2.13e+01  3.13e+01 -2.05e+01  . -8.84e+00  2.58e+01  8.61e+00 
 4.32e+01  3.35e+00  2.78e+01  . -8.48e+00  4.18e+01  3.94e+01 
 ... 
 1.43e+01 -6.74e+00  2.62e+01  . -2.06e+01  8.14e+00 -2.69e+01 
user&gt; (cl/rnorm 5)
 A 5x1 matrix
 -------------
 1.18e+00 
 3.46e-01 
-1.32e-01 
 3.13e-01 
-8.26e-02 
user&gt; (cl/rnorm 3 4)
 A 3x4 matrix
 -------------
-4.61e-01 -1.81e+00 -6.68e-01  7.46e-01 
 1.87e+00 -7.76e-01 -1.33e+00  5.85e-01 
 1.06e+00 -3.54e-01  3.73e-01 -2.72e-02 </pre></div><p>In the preceding example,<a id="id56" class="indexterm"/> the first call specifies the mean, the standard deviation, and the number of rows and columns. The second call specifies a single argument <em>n</em> and produces a matrix of size <img src="img/4351OS_01_09.jpg" alt="Generating matrices"/>. Lastly, the third call specifies the number of rows and columns of the matrix.</p><p>The core.matrix library also provides a <code class="literal">compute-matrix</code> function<a id="id57" class="indexterm"/> to generate matrices, and will feel idiomatic to Clojure programmers. This function requires a vector that represents the size of the matrix, and a function that takes a number of arguments that is equal to the number of <a id="id58" class="indexterm"/>dimensions of the matrix. In fact, <code class="literal">compute-matrix</code> is versatile enough to implement the generation of an identity matrix, as well as a matrix of randomly generated elements. </p><p>We can implement the following functions to create an identity matrix, as well as a matrix of random elements using the <code class="literal">compute-matrix</code> function:</p><div><pre class="programlisting">(defn id-computed-mat
  "Creates an identity matrix of size n x n 
  using compute-matrix"
  [n]
  (compute-matrix [n n] #(if (= %1 %2) 1 0)))

(defn rand-computed-mat
  "Creates an n x m matrix of random elements 
  using compute-matrix"
  [n m]
  (compute-matrix [n m] 
   (fn [i j] (rand-int 100))))</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch01lvl1sec11"/>Adding matrices</h1></div></div></div><p>Operations on matrices are not <a id="id59" class="indexterm"/>directly supported by the Clojure language but are implemented through the core.matrix specification. Trying to add two matrices in the REPL, as shown in the following code snippet, simply throws an error stating that a vector was found where an integer was expected:</p><div><pre class="programlisting">user&gt; (+ (matrix [[0 1]]) (matrix [[0 1]]))
ClassCastException clojure.lang.PersistentVector cannot be cast to java.lang.Number  clojure.lang.Numbers.add (Numbers.java:126)</pre></div><p>This is because the <code class="literal">+</code> function operates on numbers rather than matrices. To add matrices, we should use functions from the <code class="literal">core.matrix.operators</code> namespace. The namespace declaration should look like the following code snippet after we have included <code class="literal">core.matrix.operators</code>:</p><div><pre class="programlisting">(ns my-namespace
  (:use clojure.core.matrix)
  (:require [clojure.core.matrix.operators :as M]))</pre></div><p>Note that the functions are actually imported into an aliased namespace, as function names such as <code class="literal">+</code> and <code class="literal">*</code> conflict with<a id="id60" class="indexterm"/> those in the default Clojure namespace. In practice, we should always try to use aliased namespaces via the <code class="literal">:require</code> and <code class="literal">:as</code> filters and avoid the <code class="literal">:use</code> filter. Alternatively, we could simply not refer to conflicting function names by using the <code class="literal">:refer-clojure</code> filter in the namespace declaration, which is shown in the following code. However, this should be used sparingly and only as a last resort. </p><p>For the code examples in this section, we will use the previous declaration for clarity:</p><div><pre class="programlisting">(ns my-namespace
  (:use clojure.core.matrix)
  (:require clojure.core.matrix.operators)
  (:refer-clojure :exclude [+ - *])) </pre></div><p>We can use the <code class="literal">M/+</code> function<a id="id61" class="indexterm"/> to perform the matrix addition of two or more matrices. To check the equality of any number of matrices, we use the <code class="literal">M/==</code> function:</p><div><pre class="programlisting">user&gt; (def A (matrix [[0 1 2] [3 4 5]]))
#'user/A
user&gt; (def B (matrix [[0 0 0] [0 0 0]]))
#'user/B
user&gt; (M/== B A)
false
user&gt; (def C (M/+ A B))
#'user/C
user&gt; C
[[0 1 2] [3 4 5]]
user&gt; (M/== C A)
true</pre></div><p>Two matrices <em>A</em> and <em>B</em> are said to be equal if the following equality holds true:</p><div><img src="img/4351OS_01_10.jpg" alt="Adding matrices"/></div><p>Hence, the preceding equation<a id="id62" class="indexterm"/> explains that two or more matrices are equal if and only if the following conditions are satisfied:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Each matrix has the same number of rows and columns</li><li class="listitem" style="list-style-type: disc">All elements with the same row and column indices are equal</li></ul></div><p>The following is a simple, yet elegant implementation of matrix equality. It's basically comparing vector equality using the standard <code class="literal">reduce</code> and <code class="literal">map</code> functions:</p><div><pre class="programlisting">(defn mat-eq
  "Checks if two matrices are equal"
  [A B]
  (and (= (count A) (count B))
       (reduce #(and %1 %2) (map = A B))))</pre></div><p>We first compare the row lengths of the two matrices using the <code class="literal">count</code> and <code class="literal">=</code> functions, and then use the <code class="literal">reduce</code> function<a id="id63" class="indexterm"/> to compare the inner vector elements. Essentially, the <code class="literal">reduce</code> function repeatedly applies<a id="id64" class="indexterm"/> a function that accepts two arguments to consecutive elements in a sequence and returns the final result when all the elements in the sequence have been <em>reduced</em> by the applied function.</p><p>Alternatively, we could use a similar composition using the <code class="literal">every?</code> and <code class="literal">true?</code> Clojure functions. Using the expression <code class="literal">(every? true? (map = A B))</code>, we can check the equality of two matrices. Keep in mind that the <code class="literal">true?</code> function<a id="id65" class="indexterm"/> returns <code class="literal">true</code> if it is passed <code class="literal">true</code> (and <code class="literal">false</code> otherwise), and the <code class="literal">every?</code> function<a id="id66" class="indexterm"/> returns <code class="literal">true</code> if a given predicate function returns <code class="literal">true</code> for all the values in a given sequence.</p><p>To add two matrices, they must have an equal number of rows and columns, and the sum is essentially a matrix composed of the sum of elements with the same row and column indices. The sum of two matrices <em>A</em> and <em>B</em> has been formally defined as follows:</p><div><img src="img/4351OS_01_11.jpg" alt="Adding matrices"/></div><p>It's almost trivial to implement matrix addition using the standard <code class="literal">mapv</code> function<a id="id67" class="indexterm"/>, which is simply a variant of the <code class="literal">map</code> function that returns a vector. We apply <code class="literal">mapv</code> to each row of the matrix as well as to the entire matrix. Note that this implementation is intended for a vector of vectors, although it can be easily used with the <code class="literal">matrix</code> and <code class="literal">as-vec</code> functions from core.matrix to operate on matrices. We can implement the following function to perform matrix addition using the standard <code class="literal">mapv</code> function:</p><div><pre class="programlisting">(defn mat-add
  "Add two matrices"
  [A B]
  (mapv #(mapv + %1 %2) A B))</pre></div><p>We can just as easily generalize the <code class="literal">mat-add</code> function for any number of matrices by using the <code class="literal">reduce</code> function<a id="id68" class="indexterm"/>. As shown in the following code, we can extend the previous definition of <code class="literal">mat-add</code> to apply it to any number of matrices using the <code class="literal">reduce</code> function:</p><div><pre class="programlisting">(defn mat-add
  "Add two or more matrices"
  ([A B]
     (mapv #(mapv + %1 %2) A B))
  ([A B &amp; more]
     (let [M (concat [A B] more)]
       (reduce mat-add M))))</pre></div><p>An interesting unary operation on a <img src="img/4351OS_01_06.jpg" alt="Adding matrices"/> matrix <em>A</em> is the trace of a matrix, represented as <img src="img/4351OS_01_12.jpg" alt="Adding matrices"/>. The trace of a matrix is essentially the sum of its diagonal elements:</p><div><img src="img/4351OS_01_13.jpg" alt="Adding matrices"/></div><p>It's fairly simple enough to<a id="id69" class="indexterm"/> implement the trace function of a matrix using the <code class="literal">cl/map-indexed</code> and <code class="literal">repeatedly</code> functions as described earlier. We have skipped it here to serve as an exercise for you.</p></div>
<div><div><div><div><h1 class="title"><a id="ch01lvl1sec12"/>Multiplying matrices</h1></div></div></div><p>Multiplication is another important<a id="id70" class="indexterm"/> binary operation on matrices. In the broader sense, the term <strong>matrix multiplication</strong> refers to several techniques that multiply matrices to produce a new matrix.</p><p>Let's define three matrices, <em>A</em>, <em>B</em>, and <em>C</em>, and a single value <em>N</em>, in the REPL. The matrices have the following values:</p><div><img src="img/4351OS_01_14.jpg" alt="Multiplying matrices"/></div><p>We can multiply the matrices by using the <code class="literal">M/*</code> function<a id="id71" class="indexterm"/> from the core.matrix library. Apart from being used to multiply two matrices, this function can also be used to multiply any number of matrices, and scalar values as well. We can try out the following <code class="literal">M/*</code> function to multiply two given matrices in the REPL:</p><div><pre class="programlisting">user&gt; (pm (M/* A B))
[[140.000 200.000]
 [320.000 470.000]]
nil
user&gt; (pm (M/* A C))
RuntimeException Mismatched vector sizes  clojure.core.matrix.impl.persistent-vector/... 
user&gt; (def N 10)
#'user/N
user&gt; (pm (M/* A N))
[[10.000 20.000 30.000]
 [40.000 50.000 60.000]]
nil</pre></div><p>First, we calculated the product of two matrices.<a id="id72" class="indexterm"/> This operation is termed as <strong>matrix-matrix multiplication</strong><a id="id73" class="indexterm"/>. However, multiplying matrices <em>A</em> and <em>C</em> doesn't work, as the matrices have incompatible sizes. This brings us to the first rule of multiplying matrices: to multiply two matrices <em>A</em> and <em>B</em>, the number of columns in <em>A</em> have to be equal to the number of rows in <em>B</em>. The resultant matrix has the same number of rows as <em>A</em> and columns as <em>B</em>. That's the reason the REPL didn't agree to multiply <em>A</em> and <em>C</em>, but simply threw an exception.</p><p>For matrix <em>A</em> of size <img src="img/4351OS_01_15.jpg" alt="Multiplying matrices"/>, and <em>B</em> of size <img src="img/4351OS_01_16.jpg" alt="Multiplying matrices"/>, the product of the two matrices only exists if <img src="img/4351OS_01_17.jpg" alt="Multiplying matrices"/>, and the product of <em>A</em> and <em>B</em> is a new matrix of size <img src="img/4351OS_01_18.jpg" alt="Multiplying matrices"/>.</p><p>The product of matrices <em>A</em> and <em>B</em> is calculated by multiplying the elements of rows in <em>A</em> with the corresponding columns in <em>B</em>, and then adding the resulting values to produce a single value for each row in <em>A</em> and each column in <em>B</em>. Hence, the resulting product has the same number of rows as <em>A</em> and columns as <em>B</em>.</p><p>We can define the product of two matrices with compatible sizes as follows:</p><div><img src="img/4351OS_01_19.jpg" alt="Multiplying matrices"/></div><div><img src="img/4351OS_01_20.jpg" alt="Multiplying matrices"/></div><p>The following is an illustration <a id="id74" class="indexterm"/>of how the elements from <em>A</em> and <em>B</em> are used to calculate the product of the two matrices:</p><div><img src="img/4351OS_01_01.jpg" alt="Multiplying matrices"/></div><p>This does look slightly complicated, so let's demonstrate the preceding definition with an example, using the matrices <em>A</em> and <em>B</em> as we had previously defined. The following calculation does, in fact, agree to the value produced in the REPL:</p><div><img src="img/4351OS_01_22.jpg" alt="Multiplying matrices"/></div><p>Note that multiplying matrices is not a commutative operation. However, the operation does exhibit the associative property of functions. For matrices <em>A</em>, <em>B</em>, and <em>C</em> of product-compatible sizes, the following properties are always true, with one exception that we will uncover later:</p><div><img src="img/4351OS_01_23.jpg" alt="Multiplying matrices"/></div><p>An obvious corollary is that a square matrix when multiplied with another square matrix of the same size produces a resultant matrix that has the same size as the two original matrices. Also, the square, cube, and other powers of a square matrix results in matrices of the same size.</p><p>Another interesting property of <a id="id75" class="indexterm"/>square matrices is that they have an identity element for multiplication, that is, an identity matrix of product-compatible size. But, an identity matrix is itself a square matrix, which brings us to the conclusion that <em>the multiplication of a square matrix with an identity matrix is a commutative operation</em>. Hence, the commutative rule for matrices, which states that matrix multiplication is not commutative, is actually not true when one of the matrices is an identity matrix and the other one is a square matrix. This can be formally summarized by the following equality:</p><div><img src="img/4351OS_01_24.jpg" alt="Multiplying matrices"/></div><p>A naïve implementation of matrix multiplication would have a time complexity of <img src="img/4351OS_01_25.jpg" alt="Multiplying matrices"/>, and requires eight multiplication operations for a <img src="img/4351OS_01_26.jpg" alt="Multiplying matrices"/> matrix. By time complexity, we mean the time taken by a particular algorithm to run till completion. Hence, linear algebra libraries use more efficient algorithms, such as <em>Strassen's algorithm</em>, to implement matrix multiplication, which needs only seven multiplication operations and reduces the complexity to <img src="img/4351OS_01_27.jpg" alt="Multiplying matrices"/>.</p><p>The clatrix library implementation for matrix multiplication performs significantly better than the default persistent vector implementation, since it interfaces with native libraries. In practice, we can use a benchmarking library<a id="id76" class="indexterm"/> such as criterium for Clojure (<a class="ulink" href="http://github.com/hugoduncan/criterium">http://github.com/hugoduncan/criterium</a>) to perform this comparison. Alternatively, we can also compare the performance of these two implementations in brief by defining a simple function to multiply two matrices and then passing large matrices of different implementations<a id="id77" class="indexterm"/> to it using our previously defined <code class="literal">rand-square-mat</code> and <code class="literal">rand-square-clmat</code> functions. We can define a function to measure the time taken to multiply two matrices. </p><p>Also, we can define two functions to multiply the matrices that were created using the <code class="literal">rand-square-mat</code> and <code class="literal">rand-square-clmat</code> functions that we previously defined, as follows:</p><div><pre class="programlisting">(defn time-mat-mul
  "Measures the time for multiplication of two matrices A and B"
  [A B]
  (time (M/* A B)))

(defn core-matrix-mul-time []
  (let [A (rand-square-mat 100)
        B (rand-square-mat 100)]
    (time-mat-mul A B)))

(defn clatrix-mul-time []
  (let [A (rand-square-clmat 100)
        B (rand-square-clmat 100)]
    (time-mat-mul A B)))</pre></div><p>We can see that the core.matrix implementation takes a second on average to compute the product of two randomly generated matrices. The clatrix implementation, however, takes less than a millisecond on average, although the first call that's made usually takes 35 to 40 ms to load the native BLAS library. Of course, this value could be slightly different depending on the hardware it's calculated on. Nevertheless, clatrix is preferred when dealing with large matrices unless there's a valid reason, such as hardware incompatibilities or the avoidance of an additional dependency, to avoid its usage.</p><p>Next, let's look at <em>scalar multiplication</em>, which involves simply multiplying a single value <em>N</em> or a scalar with a matrix. The resultant matrix has the same size as the original matrix. For a 2 x 2 matrix, we can define scalar multiplication as follows:</p><div><img src="img/4351OS_01_28.jpg" alt="Multiplying matrices"/></div><p>For matrices <img src="img/4351OS_01_29.jpg" alt="Multiplying matrices"/> and <img src="img/4351OS_01_30.jpg" alt="Multiplying matrices"/>, the following is the product:</p><div><img src="img/4351OS_01_31.jpg" alt="Multiplying matrices"/></div><p>Note that we can also use the <code class="literal">scale</code> function from the core.matrix library to perform scalar multiplication:</p><div><pre class="programlisting">user&gt; (pm (scale A 10))
[[10.000 20.000 30.000]
 [40.000 50.000 60.000]]
nil
user&gt; (M/== (scale A 10) (M/* A 10))
true</pre></div><p>Finally, we will briefly take a<a id="id78" class="indexterm"/> look at a special form of matrix multiplication, termed as <strong>matrix-vector multiplication</strong>.<a id="id79" class="indexterm"/> A vector is simply a matrix with a single row, which on multiplication with a square matrix of product-compatible size produces a new vector with the same size as the original vector. After multiplying a matrix <em>A</em> of size <img src="img/4351OS_01_32.jpg" alt="Multiplying matrices"/> and the transpose <em>V'</em> of a vector <em>V</em>, of size <img src="img/4351OS_01_33.jpg" alt="Multiplying matrices"/>, a new vector <em>V"</em> of size <img src="img/4351OS_01_34.jpg" alt="Multiplying matrices"/> is produced. If <em>A</em> is a square matrix, then <em>V"</em> has an identical size as that of the transpose <em>V'</em>.</p><div><img src="img/4351OS_01_35.jpg" alt="Multiplying matrices"/></div><div><img src="img/4351OS_01_36.jpg" alt="Multiplying matrices"/></div></div>
<div><div><div><div><h1 class="title"><a id="ch01lvl1sec13"/>Transposing and inverting matrices</h1></div></div></div><p>Another frequently used<a id="id80" class="indexterm"/> elementary matrix operation is the <em>transpose</em> of a matrix<a id="id81" class="indexterm"/>. The transpose of a matrix <em>A</em> is represented as <img src="img/4351OS_01_37.jpg" alt="Transposing and inverting matrices"/> or <img src="img/4351OS_01_38.jpg" alt="Transposing and inverting matrices"/>. A simple way to define the transpose of a matrix is by reflecting the matrix over its <em>prime diagonal</em>. By prime diagonal, we mean the diagonal comprising elements whose row and column indices are equal. We can also describe the transpose of a matrix by swapping of the rows and columns of a matrix. We can use the following <code class="literal">transpose</code> function from core.matrix to perform this operation:</p><div><pre class="programlisting">user&gt; (def A (matrix [[1 2 3] [4 5 6]]))
#'user/A
user&gt; (pm (transpose A))
[[1.000 4.000]
 [2.000 5.000]
 [3.000 6.000]]
nil</pre></div><p>We can define the following three possible ways<a id="id82" class="indexterm"/> to obtain the transpose of a matrix:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The original matrix is reflected over its main diagonal</li><li class="listitem" style="list-style-type: disc">The rows of the matrix become the columns of its transpose</li><li class="listitem" style="list-style-type: disc">The columns of the matrix become the rows of its transpose</li></ul></div><p>Hence, every element in a matrix has its row and column swapped in its transpose, and vice versa. This can be<a id="id83" class="indexterm"/> formally represented using the following equation:</p><div><img src="img/4351OS_01_39.jpg" alt="Transposing and inverting matrices"/></div><p>This brings us to the notion of an invertible matrix.<a id="id84" class="indexterm"/> A square matrix is said to be invertible if there exists another square matrix that is the inverse of a matrix, and which produces an identity matrix when multiplied with the original matrix. A matrix <em>A</em> of size <img src="img/4351OS_01_06.jpg" alt="Transposing and inverting matrices"/>, is said to have an inverse matrix <em>B</em> if the following equality is true:</p><div><img src="img/4351OS_01_41.jpg" alt="Transposing and inverting matrices"/></div><p>Let's test this equality using the <code class="literal">inverse</code> function from core.matrix. Note that the default persistent implementation of the core.matrix library does not implement the inverse operation, so we use a matrix from the clatrix library instead. In the following example, we create a matrix from the clatrix library using the <code class="literal">cl/matrix</code> function, determine its inverse using the <code class="literal">inverse</code> function, and multiply these two matrices using the <code class="literal">M/*</code> function:</p><div><pre class="programlisting">user&gt; (def A (cl/matrix [[2 0] [0 2]]))
#'user/A
user&gt; (M/* (inverse A) A)
 A 2x2 matrix
 -------------
 1.00e+00  0.00e+00 
 0.00e+00  1.00e+00</pre></div><p>In the preceding example, we first define a matrix <em>A</em> and then multiply it with its inverse to produce the corresponding identity matrix. An interesting observation when we use double precision numeric types for<a id="id85" class="indexterm"/> the elements in a matrix is that not all matrices produce an identity matrix on multiplication with their inverse. </p><p>A small amount of error can be observed for some matrices, and this happens due to the limitations of using a 32-bit representation for floating-point numbers; this is shown as follows:</p><div><pre class="programlisting">user&gt; (def A (cl/matrix [[1 2] [3 4]]))
#'user/A
user&gt; (inverse A)
 A 2x2 matrix
 -------------
-2.00e+00  1.00e+00 
 1.50e+00 -5.00e-01</pre></div><p>In order to find the inverse of a matrix, we must first define the <em>determinant</em> <a id="id86" class="indexterm"/>of that matrix, which is simply another value<a id="id87" class="indexterm"/> determined from a given matrix. First off, determinants only exist for square matrices, and thus, inverses only exist for matrices with an equal number of rows and columns. The determinant of a matrix is represented as <img src="img/4351OS_01_42.jpg" alt="Transposing and inverting matrices"/> or <img src="img/4351OS_01_43.jpg" alt="Transposing and inverting matrices"/>. A matrix whose determinant is zero is termed as a<a id="id88" class="indexterm"/> <em>singular matrix</em>. For a matrix <em>A</em>, we define its determinant as follows:</p><div><img src="img/4351OS_01_44.jpg" alt="Transposing and inverting matrices"/></div><p>We can use the preceding definitions to express the determinant of a matrix of any size. An interesting observation is that <a id="id89" class="indexterm"/>the determinant of an identity matrix is always <em>1</em>. As an<a id="id90" class="indexterm"/> example, we will find the determinant of a given matrix as follows:</p><div><img src="img/4351OS_01_45.jpg" alt="Transposing and inverting matrices"/></div><p>For a <img src="img/4351OS_01_46.jpg" alt="Transposing and inverting matrices"/> matrix, we can use <em>Sarrus' rule</em> <a id="id91" class="indexterm"/>as an alternative means to calculate the determinant of a matrix. To find the determinant of a matrix using this scheme, we first write <a id="id92" class="indexterm"/>out the first two columns of the matrix to the right of the third column, so that there are five columns in a row. Next, we add the products of the diagonals going from top to bottom, and subtract the products of diagonals from bottom. This process can be illustrated using the following diagram:</p><div><img src="img/4351OS_01_03.jpg" alt="Transposing and inverting matrices"/></div><p>By using Sarrus' rule, we formally express the determinant of a matrix <em>A</em> as follows:</p><div><img src="img/4351OS_01_48.jpg" alt="Transposing and inverting matrices"/></div><p>We can calculate the determinant<a id="id93" class="indexterm"/> of a matrix in the REPL using the following <code class="literal">det </code>function<a id="id94" class="indexterm"/> from core.matrix. Note<a id="id95" class="indexterm"/> that this operation is not implemented by the default persistent vector implementation of core.matrix.</p><div><pre class="programlisting">user&gt; (def A (cl/matrix [[-2 2 3] [-1 1 3] [2 0 -1]]))
#'user/A
user&gt; (det A)
6.0</pre></div><p>Now that we've defined the<a id="id96" class="indexterm"/> determinant of a matrix, let's use it to define the inverse of a matrix. We've already discussed the notion of an invertible matrix; finding the inverse of a matrix is simply determining a matrix such that it produces an identity matrix when multiplied with the original matrix.</p><p>For the inverse of a matrix to exist, its determinant must be nonzero. Next, for each element in the original matrix, we find the determinant of the matrix without the row and column of the selected element. This produces a matrix of an identical size as that of the original matrix (termed as the <em>cofactor matrix</em> of the original matrix). The transpose of the cofactor matrix<a id="id97" class="indexterm"/> is called the <em>adjoint</em> of the original matrix. The adjoint produces the inverse on dividing it by the determinant of the original matrix. Now, let's formally define the inverse of a <img src="img/4351OS_01_26.jpg" alt="Transposing and inverting matrices"/> matrix <em>A</em>. We denote the inverse of a matrix <em>A</em> as <img src="img/4351OS_01_49.jpg" alt="Transposing and inverting matrices"/>, and it can be formally expressed as follows:</p><div><img src="img/4351OS_01_50.jpg" alt="Transposing and inverting matrices"/></div><p>As an example, let's find the inverse of a sample <img src="img/4351OS_01_26.jpg" alt="Transposing and inverting matrices"/> matrix. We can actually verify that the inverse produces an<a id="id98" class="indexterm"/> identity matrix when multiplied with the original matrix, as shown in the following example:</p><div><img src="img/4351OS_01_51.jpg" alt="Transposing and inverting matrices"/></div><p>Similarly, we define the inverse of a <img src="img/4351OS_01_46.jpg" alt="Transposing and inverting matrices"/> matrix as follows:</p><div><img src="img/4351OS_01_52.jpg" alt="Transposing and inverting matrices"/></div><div><img src="img/4351OS_01_53.jpg" alt="Transposing and inverting matrices"/></div><p>Now, let's calculate <a id="id99" class="indexterm"/>the inverse of a <img src="img/4351OS_01_46.jpg" alt="Transposing and inverting matrices"/> matrix:</p><div><img src="img/4351OS_01_54.jpg" alt="Transposing and inverting matrices"/></div><div><img src="img/4351OS_01_55.jpg" alt="Transposing and inverting matrices"/></div><p>We've mentioned that singular and nonsquare matrices don't have inverses, and we can see that the <code class="literal">inverse</code> function<a id="id100" class="indexterm"/> throws an error when supplied with such a matrix. As shown in the following <a id="id101" class="indexterm"/>REPL output, the <code class="literal">inverse</code> function will throw an error if the given matrix is not a square matrix, or if the given matrix is singular:</p><div><pre class="programlisting">user&gt; (def A (cl/matrix [[1 2 3] [4 5 6]]))
#'user/A
user&gt; (inverse A)
ExceptionInfo throw+: {:exception "Cannot invert a non-square matrix."}  clatrix.core/i (core.clj:1033)
user&gt; (def A (cl/matrix [[2 0] [2 0]]))
#'user/A
user&gt; (M/* (inverse A) A)
LapackException LAPACK DGESV: Linear equation cannot be solved because the matrix was singular.  org.jblas.SimpleBlas.gesv (SimpleBlas.java:274)</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch01lvl1sec14"/>Interpolating using matrices</h1></div></div></div><p>Let's try out an example to demonstrate how we use matrices. This example uses matrices to interpolate a curve between<a id="id102" class="indexterm"/> a given set of points. Suppose we have a given set of points representing some data. The objective is to trace a smooth line between the points in order to produce a curve that estimates the shape of the data. Although the mathematical formulae in this example may seem difficult, we should know that this technique is actually just a form of regularization for a linear regression model, and is termed as <strong>Tichonov regularization</strong><a id="id103" class="indexterm"/>. For now, we'll focus on how to use matrices in this technique, and we shall revisit regularization in depth in <a class="link" href="ch02.html" title="Chapter 2. Understanding Linear Regression">Chapter 2</a>, <em>Understanding Linear Regression</em>.</p><p>We will first define an interpolation matrix <em>L</em> that can be used to determine an estimated curve of the given data points. It's essentially the vector <em>[-1, 2, -1]</em> moving diagonally across the columns of the matrix. This kind of a matrix is called a <a id="id104" class="indexterm"/>
<strong>band matrix</strong>:</p><div><img src="img/4351OS_01_56.jpg" alt="Interpolating using matrices"/></div><p>We can concisely define the matrix <em>L</em> using the following <code class="literal">compute-matrix</code> function. Note that for a given size <em>n</em>, we generate a matrix of size <img src="img/4351OS_01_57.jpg" alt="Interpolating using matrices"/>:</p><div><pre class="programlisting">(defn lmatrix [n]
  (compute-matrix :clatrix [n (+ n 2)]
                  (fn [i j] ({0 -1, 1 2, 2 -1} (- j i) 0))))</pre></div><p>The anonymous closure in the preceding example uses a map to decide the value of an element at a specified row and column index. For example, the element at row index <em>2</em> and column index <em>3</em> is <em>2</em>, since <code class="literal">(- j i)</code> is <em>1</em> and the key <em>1</em> in the map has <em>2</em> as its value. We can verify that the generated matrix has a similar structure as that of the matrix <code class="literal">lmatrix</code> through the REPL as follows:</p><div><pre class="programlisting">user&gt; (pm (lmatrix 4))
[[-1.000 2.000 -1.000  0.000  0.000  0.000]
[ 0.000 -1.000  2.000 -1.000  0.000  0.000]
[ 0.000  0.000 -1.000  2.000 -1.000  0.000]
[ 0.000  0.000  0.000 -1.000  2.000 -1.000]]
nil</pre></div><p>Next, we define how to represent<a id="id105" class="indexterm"/> the data points that we intend to interpolate over. Each point has an observed value <em>x</em> that is passed to some function to produce another observed value <em>y</em>. For this example, we simply choose a random value for <em>x</em> and another random value for <em>y</em>. We perform this repeatedly to produce the data points.</p><p>In order to represent the data points along with an <em>L</em> matrix of compatible size, we define the following simple function named <code class="literal">problem</code> that returns a map of the problem definition. This comprises the <em>L</em> matrix, the observed values for <em>x</em>, the hidden values of <em>x</em> for which we have to estimate values of <em>y</em> to create a curve, and the observed values for <em>y</em>.</p><div><pre class="programlisting">(defn problem
  "Return a map of the problem setup for a
  given matrix size, number of observed values 
  and regularization parameter"
  [n n-observed lambda]
  (let [i (shuffle (range n))]
    {:L (M/* (lmatrix n) lambda)
     :observed (take n-observed i)
     :hidden (drop n-observed i)
     :observed-values (matrix :clatrix
                              (repeatedly n-observed rand))}))</pre></div><p>The first two parameters of the function are the number of rows <code class="literal">n</code> in the <em>L</em> matrix, and the number of observed <em>x</em> values <code class="literal">n-observed</code>. The function takes a third argument <code class="literal">lambda</code>, which is actually the regularization parameter for our model. This parameter determines how accurate the estimated curve is, and we shall study more about how it's relevant to this model in the later chapters. In the map returned by the preceding function, the observed values for <em>x</em> and <em>y</em> have keys <code class="literal">:observed</code> and <code class="literal">:observed-values</code>, and the hidden values for <em>x</em> have the key <code class="literal">:hidden</code>. Similarly, the key <code class="literal">:L</code> is mapped to an <em>L</em> matrix of compatible size.</p><p>Now that we've defined our problem (or model), we can plot a smooth curve over the given points. By <em>smooth</em>, we mean that each point in the curve is the average of its immediate neighbors, along with some Gaussian noise. Thus, all the points on the curve of this noise have a Gaussian <a id="id106" class="indexterm"/>distribution, in which all the values are scattered about some mean value along with a spread specified by some standard deviation.</p><p>If we partition matrix <em>L</em> into <img src="img/4351OS_01_58.jpg" alt="Interpolating using matrices"/> and <img src="img/4351OS_01_59.jpg" alt="Interpolating using matrices"/> over the observed and hidden points respectively, we can define a formula to determine the curve as follows. The following equation may seem a bit daunting, but as mentioned earlier, we shall study the reasoning behind this equation in the following chapters. The curve can be represented by a matrix that can be calculated as follows, using the matrix <em>L</em>:</p><div><img src="img/4351OS_01_60.jpg" alt="Interpolating using matrices"/></div><p>We estimate the observed values for the hidden values of <em>x</em> as <img src="img/4351OS_01_62.jpg" alt="Interpolating using matrices"/>, using the originally observed values of <em>y</em>, that is, <img src="img/4351OS_01_63.jpg" alt="Interpolating using matrices"/> and the two matrices that are calculated from the interpolation matrix <em>L</em>. These two matrices are calculated using only the transpose and inverse functions of a matrix. As all the values on the right-hand side of this equation are either matrices or vectors, we use matrix multiplication to find the product of these values.</p><p>The previous equation can be implemented using the functions that we've explored earlier. In fact, the code comprises just this equation written as a prefix expression for the map returned by the <code class="literal">problem</code> function<a id="id107" class="indexterm"/> that we defined previously. We now define the following function to solve the problem returned by the <code class="literal">problem</code> function:</p><div><pre class="programlisting">(defn solve
  "Return a map containing the approximated value 
y of each hidden point x"
  [{:keys [L observed hidden observed-values] :as problem}]
  (let [nc  (column-count L)
        nr  (row-count L)
        L1  (cl/get L (range nr) hidden)
        L2  (cl/get L (range nr) observed)
        l11 (M/* (transpose L1) L1)
        l12 (M/* (transpose L1) L2)]
    (assoc problem :hidden-values
      (M/* -1 (inverse l11) l12 observed-values))))</pre></div><p>The preceding function calculates<a id="id108" class="indexterm"/> the estimated values for <em>y</em> and simply adds them to the original map with the key <code class="literal">:hidden-values</code> using the <code class="literal">assoc</code> function.</p><p>It's rather difficult to mentally visualize the calculated values of the curve, so we will now use the <em>Incanter</em> library<a id="id109" class="indexterm"/> (<a class="ulink" href="http://github.com/liebke/incanter">http://github.com/liebke/incanter</a>) to plot the estimated curve and the original points. This library essentially provides a simple and idiomatic API to create and view various types of plots and charts.</p><div><div><h3 class="title"><a id="note09"/>Note</h3><p>The Incanter library can be added to a Leiningen project by adding the following dependency to the <code class="literal">project.clj</code> file:</p><div><pre class="programlisting">[incanter "1.5.4"]</pre></div><p>For the upcoming example, the namespace declaration should look similar to the following:</p><div><pre class="programlisting">(ns my-namespace
  (:use [incanter.charts :only [xy-plot add-points]]
        [incanter.core   :only [view]])
  (:require [clojure.core.matrix.operators :as M]
            [clatrix.core :as cl]))</pre></div></div></div><p>We now define a simple function that will plot a graph of the given data using functions, such as <code class="literal">xy-plot</code> and <code class="literal">view</code>, from the Incanter library:</p><div><pre class="programlisting">(defn plot-points
  "Plots sample points of a solution s"
  [s]
  (let [X (concat (:hidden s) (:observed s))
        Y (concat (:hidden-values s) (:observed-values s))]
    (view
     (add-points
      (xy-plot X Y) (:observed s) (:observed-values s)))))</pre></div><p>As this is our first encounter with the Incanter library, let's discuss some of the functions that are used to implement <code class="literal">plot-points</code>. We first bind all the values on the <em>x</em> axis to <code class="literal">X</code>, and all values on the <em>y</em> axis to <code class="literal">Y</code>. Then, we plot the points as a curve using the <code class="literal">xy-plot</code> function, which takes two sets of values to plot on the <em>x</em> and <em>y</em> axes as arguments and returns a chart or plot. Next, we add the originally observed points to the plot using the <code class="literal">add-points</code> function. The <code class="literal">add-points</code> function<a id="id110" class="indexterm"/> requires three arguments: the original plot, a vector of all the values<a id="id111" class="indexterm"/> of the <em>x</em> axis component, and a vector of all the values of the <em>y</em> axis component. This function also returns a plot such as the <code class="literal">xy-plot</code> function<a id="id112" class="indexterm"/>, and we can view this plot using the <code class="literal">view</code> function. Note that we could have equivalently used the thread macro (<code class="literal">-&gt;</code>) to compose the <code class="literal">xy-plot</code>, <code class="literal">add-points</code>, and <code class="literal">view</code> functions.</p><p>Now, we can intuitively visualize the estimated curve using the <code class="literal">plot-points</code> function on some random data as shown in the following function:</p><div><pre class="programlisting">(defn plot-rand-sample []
  (plot-points (solve (problem 150 10 30))))</pre></div><p>When we execute the <code class="literal">plot-rand-sample</code> function<a id="id113" class="indexterm"/>, the following plot of the values is displayed:</p><div><img src="img/4351OS_01_02.jpg" alt="Interpolating using matrices"/></div></div>
<div><div><div><div><h1 class="title"><a id="ch01lvl1sec15"/>Summary</h1></div></div></div><p>In this chapter, we introduced matrices through the core.matrix and clatrix libraries. The following are the points that we covered:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">We've discussed how to represent, print, and fetch information from matrices through core.matrix and clatrix. We've also discussed how we can generate matrices with some random data.</li><li class="listitem" style="list-style-type: disc">We've talked about some of the rudimentary operations on matrices, such as equality, addition, multiplication, transpose, and inverse.</li><li class="listitem" style="list-style-type: disc">We've also introduced the versatile Incanter library that is used to visualize plots and charts of data, through an example on using matrices.</li></ul></div><p>Next, we will study some basic techniques for prediction using linear regression. As we will see, some of these techniques, in fact, are based on simple matrix operations. Linear regression is actually a type of supervised learning, which we will discuss in the next chapter.</p></div></body></html>