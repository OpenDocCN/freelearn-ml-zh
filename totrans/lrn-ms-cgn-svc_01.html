<html><head></head><body><div class="chapter" title="Chapter&#xA0;1.&#xA0;Getting Started with Microsoft Cognitive Services"><div class="titlepage"><div><div><h1 class="title"><a id="ch01"/>Chapter 1. Getting Started with Microsoft Cognitive Services</h1></div></div></div><p>You have just started on the road to learning about Microsoft Cognitive Services. This chapter will serve as a gentle introduction to the services that it offers. The end goal is to understand a bit more about what these Cognitive Services APIs can do for you. By the end of this chapter, we will have created an easy-to-use project template. You will have learned how to detect faces in images and have the number of faces spoken back to you.</p><p>Throughout this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Applications that already use Microsoft Cognitive Services</li><li class="listitem" style="list-style-type: disc">Creating a template project</li><li class="listitem" style="list-style-type: disc">Detecting faces in images using a Face API</li><li class="listitem" style="list-style-type: disc">Discovering what Microsoft Cognitive Services can offer</li><li class="listitem" style="list-style-type: disc">Doing text-to-speech conversion using the Bing Speech API</li></ul></div><div class="section" title="Cognitive Services in action for fun and life-changing purposes"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec10"/>Cognitive Services in action for fun and life-changing purposes</h1></div></div></div><p>The best way<a class="indexterm" id="id0"/> to introduce Microsoft Cognitive Services is to see how it can be used in action. Microsoft (as well as other companies) has created a lot of example applications to show off its capabilities. Several may be seen as silly, such as the How-Old.net (<a class="ulink" href="http://how-old.net/">http://how-old.net/</a>) image analysis and the <span class="emphasis"><em>what if I were that person</em></span> application. These applications have generated quite some buzz, and they show off some of the APIs in a good way.</p><p>The one demonstration that is truly inspiring, though, is the one featuring a visually impaired person. Talking computers inspired him to create an application to allow blind and visually impaired people to understand what is going on around them. The application has been built upon Microsoft Cognitive Services. It gives us a good idea of how these APIs can be used to change the world, for the better. Before moving on, head over to <a class="ulink" href="https://www.youtube.com/watch?v=R2mC-NUAmMk">https://www.youtube.com/watch?v=R2mC-NUAmMk</a> and take a peek into the world of<a class="indexterm" id="id1"/> Microsoft Cognitive Services.</p></div></div>
<div class="section" title="Setting up the boilerplate code"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec11"/>Setting up the boilerplate code</h1></div></div></div><p>Before we start diving into the action, we will go through some initial setup. More to the point, we will set up<a class="indexterm" id="id2"/> some boilerplate code that we will utilize throughout this book.</p><p>To get started, you will need to install a version of Visual Studio, preferably Visual Studio 2015 or later. The Community Edition will work fine for this purpose. You do not need anything more than what the default installation offers.</p><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note02"/>Note</h3><p>You can find Visual Studio 2017 at <a class="ulink" href="https://www.microsoft.com/en-us/download/details.aspx?id=48146">https://www.microsoft.com/en-us/download/details.aspx?id=48146</a>.</p></div></div><p>Throughout this book, we will utilize the different APIs to build a smart-house application. The application will be created to see how a futuristic house might appear. If you have seen the Iron Man movies, you can think of the application as resembling Jarvis, in some ways.</p><p>In addition, we will be making smaller sample applications using the Cognitive Services APIs. Doing so will allow us to look at each API, even those that did not make it to the final application.</p><p>What's common<a class="indexterm" id="id3"/> with all the applications that we will build is that they will be <span class="strong"><strong>Windows Presentation Foundation</strong></span> (<span class="strong"><strong>WPF</strong></span>) applications. This is fairly well known, and allows us to build applications using the <span class="strong"><strong>Model-View-ViewModel</strong></span> (<span class="strong"><strong>MVVM</strong></span>) pattern. One of the advantages of taking this road is that we<a class="indexterm" id="id4"/> will be able to see the API usage quite clearly. It also separates code so that you can bring the API logic to other applications with ease.</p><p>The following steps describe the process of creating a new WPF project:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Open Visual Studio and select <span class="strong"><strong>File</strong></span> | <span class="strong"><strong>New</strong></span> | <span class="strong"><strong>Project</strong></span>.</li><li class="listitem">In the dialog, select the <span class="strong"><strong>WPF Application</strong></span> option from <span class="strong"><strong>Templates</strong></span> | <span class="strong"><strong>Visual C#</strong></span>, as shown in the following screenshot:<div class="mediaobject"><img alt="Setting up the boilerplate code" src="graphics/B12373_01_01.jpg"/></div></li><li class="listitem">Delete the <code class="literal">MainWindow.xaml</code> file and create the files and folders that are shown in the<a class="indexterm" id="id5"/> following screenshot:<div class="mediaobject"><img alt="Setting up the boilerplate code" src="graphics/B12373_01_02.jpg"/></div></li></ol></div><p>We will not<a class="indexterm" id="id6"/> go through the MVVM pattern in detail, as this is out of the scope of this book. The key takeaway from the screenshot is that we have separated the <code class="literal">View</code> from what becomes the logic. We then rely on the <code class="literal">ViewModel</code> to connect the pieces.</p><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note03"/>Note</h3><p>If you want to learn more about MVVM, I recommend reading <a class="ulink" href="http://www.codeproject.com/Articles/100175/Model-View-ViewModel-MVVM-Explained">http://www.codeproject.com/Articles/100175/Model-View-ViewModel-MVVM-Explained</a>.</p></div></div><p>To be able to run this, however, we do need to set up our project. Go through the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Open the <code class="literal">App.xaml</code> file and make sure the <code class="literal">StartupUri</code> is set to the correct <code class="literal">View</code>, as shown in the following code (class name and namespace may vary based on the name of your application):<div class="informalexample"><pre class="programlisting">    &lt;Application x:Class="Chapter1.App"
    
    xmlns:x = "http://schemas.microsoft.com/winfx/2006/xaml"
    
    StartupUri="View/MainView.xaml"&gt;</pre></div></li><li class="listitem">Open the <code class="literal">MainViewModel.cs</code> file and make it inherit from the <code class="literal">ObservableObject</code> class.</li><li class="listitem">Open the <code class="literal">MainView.xaml</code> file and add the <code class="literal">MainViewModel</code> file as <code class="literal">DataContext</code> to it, as shown in the following code (namespace and class names may vary based on the name of your application):<div class="informalexample"><pre class="programlisting">        &lt;Window x:Class="Chapter1.View.MainView"
        
            xmlns="http://schemas.microsoft.com/
winfx/2006/xaml/presentation"
            
            xmlns:d="http://schemas.microsoft.com/
expression/blend/2008"
            
            
             mc:Ignorable="d"
            Title="Chapter 1" Height="300" Width="300"&gt;
            &lt;Window.DataContext&gt;
                &lt;viewmodel:MainViewModel /&gt;
            &lt;/Window.DataContext&gt;</pre></div></li></ol></div><p>Following this, we need to fill in the content of the <code class="literal">ObservableObject.cs</code> file. We start off by having it inherit<a class="indexterm" id="id7"/> from the <code class="literal">INotifyPropertyChanged</code> class as follows:</p><div class="informalexample"><pre class="programlisting">        public class ObservableObject : INotifyPropertyChanged</pre></div><p>This is a rather small class, which should contain the following:</p><div class="informalexample"><pre class="programlisting">        public event PropertyChangedEventHandlerPropertyChanged;
        protected void RaisePropertyChangedEvent(string propertyName)
        {
            PropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName));
        }</pre></div><p>We declare a property changed event and create a function to raise the event. This will allow the <span class="strong"><strong>user interface</strong></span> (<span class="strong"><strong>UI</strong></span>) to update its values when a given property has changed.</p><p>We also need<a class="indexterm" id="id8"/> to be able to execute actions when buttons are clicked. This can be achieved when we put some content into the <code class="literal">DelegateCommand.cs</code> file. Start by making the class inherit the <code class="literal">ICommand</code> class, and declare the following two variables:</p><div class="informalexample"><pre class="programlisting">        public class DelegateCommand : ICommand
        {
            private readonly Predicate&lt;object&gt; _canExecute;
            private readonly Action&lt;object&gt; _execute;</pre></div><p>The two variables<a class="indexterm" id="id9"/> we have created will be set in the constructor. As you will notice, you are not required to add the <code class="literal">_canExecute</code> parameter, and you will see why in a bit:</p><div class="informalexample"><pre class="programlisting">            public DelegateCommand(Action&lt;object&gt; execute, Predicate&lt;object&gt; canExecute = null)
            {
                _execute = execute;
                _canExecute = canExecute;
            }</pre></div><p>To complete the class, we add two <code class="literal">public</code> functions and one <code class="literal">public</code> event, as follows:</p><div class="informalexample"><pre class="programlisting">        public bool CanExecute(object parameter)
        {
            if (_canExecute == null) return true;
            return _canExecute(parameter);
        }

        public void Execute(object parameter)
        {
            _execute(parameter);
        }
  
        public event EventHandlerCanExecuteChanged
        {
            add
            {
                CommandManager.RequerySuggested += value;
            }
            remove
            {
                CommandManager.RequerySuggested -= value;
            }
        }
    }</pre></div><p>The functions declared will return the corresponding predicate, or action, declared in the constructor. This will be something we declare in our <code class="literal">ViewModel</code> instances, which, in turn, will be something that executes an action or tells the application that it can or cannot execute an action. If a button is in a state where it is disabled (that is, when the <code class="literal">CanExecute</code> function returns <code class="literal">false</code>) and the state of the <code class="literal">CanExecute</code> function changes, the event that is declared will let the button know.</p><p>With that in place, you should be able to compile and run the application, so go on and try that. You will<a class="indexterm" id="id10"/> notice that the application does not actually do anything or present any data yet, but we have an excellent starting point.</p><p>Before we do anything else with the code, we are going to export the project as a template using the following steps. This is so that we do not have to redo all these steps for each small sample project we create:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Replace the namespace names with substitute parameters:</li><li class="listitem">In all the <code class="literal">.cs</code> files, replace the namespace name with <code class="literal">$safeprojectname$</code></li><li class="listitem">In all the <code class="literal">.xaml</code> files, replace the project name with <code class="literal">$safeprojectname$</code> where applicable (typically the class name and namespace declarations)</li><li class="listitem">Navigate to <span class="strong"><strong>File</strong></span> | <span class="strong"><strong>Export Template</strong></span>. This will open the <span class="strong"><strong>Export Template</strong></span> wizard, as shown in the following screenshot:<div class="mediaobject"><img alt="Setting up the boilerplate code" src="graphics/B12373_01_03.jpg"/></div></li><li class="listitem">Click on the <span class="strong"><strong>Project Template</strong></span> button. Select the project we just created and click on the <span class="strong"><strong>Next</strong></span> button.</li><li class="listitem">Just leave the<a class="indexterm" id="id11"/> icon and preview image empty. Enter a recognizable name and description. Click on the <span class="strong"><strong>Finish</strong></span> button:<div class="mediaobject"><img alt="Setting up the boilerplate code" src="graphics/B12373_01_04.jpg"/></div></li><li class="listitem">The template is now exported to a <code class="literal">.zip</code> file and stored in the specified location.</li></ol></div><p>By default, the template will be imported into Visual Studio again. We are going to test that it works<a class="indexterm" id="id12"/> immediately by creating a project for this chapter. So go ahead and create a new project, selecting the template that we just created. The template should be listed in the <span class="strong"><strong>Visual C#</strong></span> section of the installed templates list. Call the project <code class="literal">Chapter1</code>, or something else, if you prefer. Make sure it compiles and that you are able to run it before we move to the next step.</p></div>
<div class="section" title="Detecting faces with the Face API"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec12"/>Detecting faces with the Face API</h1></div></div></div><p>With the newly<a class="indexterm" id="id13"/> created project, we will now try our first API, the Face API. We will not be doing a whole lot, but we will still see how simple it is to detect faces in images.</p><p>The steps we need to go through in order to do this are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Register for a Face API preview subscription at Microsoft Azure</li><li class="listitem">Add the necessary <span class="strong"><strong>NuGet</strong></span> packages to our project</li><li class="listitem">Add a UI to the application</li><li class="listitem">Detect faces on command</li></ol></div><p>Head over to <a class="ulink" href="https://portal.azure.com">https://portal.azure.com</a> to start the process of registering for a free subscription to the Face API. You will be taken to a login page. Log on with your Microsoft account; if you do not have one, then register for one.</p><p>Once logged in, you will need to add a new resource by clicking on <span class="strong"><strong>+ New</strong></span> on the right-hand menu. Search for <span class="strong"><strong>Face API</strong></span> and select the first entry, as shown in the following screenshot:</p><div class="mediaobject"><img alt="Detecting faces with the Face API" src="graphics/B12373_01_05.jpg"/></div><p>Enter a name and<a class="indexterm" id="id14"/> select the subscription, location, and pricing tier. At the time of writing, there are two pricing options, one free and one paid, as shown in the following screenshot:</p><div class="mediaobject"><img alt="Detecting faces with the Face API" src="graphics/B12373_01_06.jpg"/></div><p>Once created, you can<a class="indexterm" id="id15"/> go into the newly created resource. You will need one of the two available API keys. These can be found in the <span class="strong"><strong>Keys</strong></span> option of the <span class="strong"><strong>Resource Management</strong></span> menu, as shown in the following screenshot:</p><div class="mediaobject"><img alt="Detecting faces with the Face API" src="graphics/B12373_01_07.jpg"/></div><p>Some of the APIs that we will cover have their own NuGet packages created. Whenever this is the case, we will utilize those packages to do the operations we want to perform. A common feature of<a class="indexterm" id="id16"/> all APIs is that they are REST APIs, which means that in practice you can use them with whichever language you want. For those APIs that do not have their own NuGet package, we call the APIs directly through HTTP.</p><p>A NuGet package does exist for the Face API we are using now, so we need to add that to our project. Head over to the <span class="strong"><strong>NuGet Package Manager</strong></span> option for the project we created earlier. In the <span class="strong"><strong>Browse</strong></span> tab, search for the <code class="literal">Microsoft.ProjectOxford.Face</code> package and install the package from Microsoft, as shown in the following screenshot:</p><div class="mediaobject"><img alt="Detecting faces with the Face API" src="graphics/B12373_01_08.jpg"/></div><p>As you will notice, another package will also be installed. This is the <code class="literal">Newtonsoft.Json</code> package, which is<a class="indexterm" id="id17"/> required by the Face API.</p><p>The next step is to add a UI to our application. We will be adding this in the <code class="literal">MainView.xaml</code> file. Open this file where the template code that we created earlier should be. This means that we have <code class="literal">DataContext</code>, and can make bindings for our elements, which we will define now.</p><p>First, we add a grid and define some rows for the grid, as follows:</p><div class="informalexample"><pre class="programlisting">    &lt;Grid&gt;
        &lt;Grid.RowDefinitions&gt;
            &lt;RowDefinition Height="*" /&gt;
            &lt;RowDefinition Height="20" /&gt;
            &lt;RowDefinition Height="30" /&gt;
        &lt;/Grid.RowDefinitions&gt;</pre></div><p>Three rows are defined. The first is a row where we will have an image, the second is a line for the status message, and the last is where we will place some buttons.</p><p>Next, we add our <code class="literal">image</code> element, as follows:</p><div class="informalexample"><pre class="programlisting">        &lt;Image x:Name="FaceImage" Stretch="Uniform" Source=
            "{Binding ImageSource}" Grid.Row="0" /&gt;</pre></div><p>We have given it a unique name. By setting the <code class="literal">Stretch</code> parameter to <code class="literal">Uniform</code>, we ensure that the image keeps its aspect ratio. Further on, we place this element in the first row. Last, we bind the image source to a <code class="literal">BitmapImage</code> in the <code class="literal">ViewModel</code>, which we will look at in a bit.</p><p>The next row will contain a text block with some status text. The <code class="literal">Text</code> property will be bound to a string property in the <code class="literal">ViewModel</code>, as follows:</p><div class="informalexample"><pre class="programlisting">        &lt;TextBlockx:Name="StatusTextBlock" Text=
            "{Binding StatusText}" Grid.Row="1" /&gt;</pre></div><p>The last row will contain<a class="indexterm" id="id18"/> one button to browse for an image and one button to be able to detect faces. The <code class="literal">command</code> properties of both buttons will be bound to the <code class="literal">DelegateCommand</code> properties in the <code class="literal">ViewModel</code>, as follows:</p><div class="informalexample"><pre class="programlisting">        &lt;Button x:Name = "BrowseButton"
                  Content = "Browse" Height="20" Width="140" 
                  HorizontalAlignment = "Left"
                  Command="{Binding BrowseButtonCommand}"
                  Margin="5, 0, 0, 5"Grid.Row="2" /&gt;

        &lt;Button x:Name="DetectFaceButton"
                  Content="Detect face" Height="20" Width="140"
                  HorizontalAlignment="Right"
                  Command="{Binding DetectFaceCommand}"
                  Margin="0, 0, 5, 5"Grid.Row="2"/&gt;</pre></div><p>With the <code class="literal">View</code> in place, make sure that the code compiles and runs it. This should present you with the following UI:</p><div class="mediaobject"><img alt="Detecting faces with the Face API" src="graphics/B12373_01_09.jpg"/></div><p>The last part of the process is to create the binding properties in our <code class="literal">ViewModel</code> and make the buttons execute something. Open the <code class="literal">MainViewModel.cs</code> file. The class should already inherit from the <code class="literal">ObservableObject</code> class. First, we define two variables as follows:</p><div class="informalexample"><pre class="programlisting">    private string _filePath;
    private IFaceServiceClient _faceServiceClient;</pre></div><p>The <code class="literal">string</code> variable will hold the path to our image, while the <code class="literal">IFaceServiceClient</code> variable is to interface the Face API. Next, we define two properties, as follows:</p><div class="informalexample"><pre class="programlisting">    private BitmapImage _imageSource;
    public BitmapImageImageSource
    {
        get { return _imageSource; }
        set
        {
            _imageSource = value;
            RaisePropertyChangedEvent("ImageSource");
        }
    }

    private string _statusText;
    public string StatusText
    {
        get { return _statusText; }
        set
        {
           _statusText = value;
           RaisePropertyChangedEvent("StatusText");
        }
    }</pre></div><p>What we have here is a property for the <code class="literal">BitmapImage</code>, mapped to the <code class="literal">Image</code> element in the <code class="literal">View</code>. We also<a class="indexterm" id="id19"/> have a <code class="literal">string</code> property for the status text, mapped to the text block element in the <code class="literal">View</code>. As you may also notice, when either of the properties is set, we call the <code class="literal">RaisePropertyChangedEvent</code> event. This will ensure that the UI updates when either property has new values.</p><p>Next, we define our two <code class="literal">DelegateCommand</code> objects and perform some initialization through the constructor, as follows:</p><div class="informalexample"><pre class="programlisting">    public ICommandBrowseButtonCommand { get; private set; }
    public ICommandDetectFaceCommand { get; private set; }

    public MainViewModel()
    {
        StatusText = "Status: Waiting for image...";

        _faceServiceClient = new FaceServiceClient("YOUR_API_KEY_HERE", "ROOT_URI);

        BrowseButtonCommand = new DelegateCommand(Browse);
        DetectFaceCommand = new DelegateCommand(DetectFace, CanDetectFace);
    }</pre></div><p>The properties for the commands are <code class="literal">public</code> to get, but <code class="literal">private</code> to set. This means that we can only set<a class="indexterm" id="id20"/> them from within the <code class="literal">ViewModel</code>. In our constructor, we start off by setting the status text. Next, we create an object of the Face API, which needs to be created with the API key we got earlier. In addition, it needs to specify the root URI, pointing at the location of the service. It can, for instance, be <a class="ulink" href="https://westeurope.api.cognitive.microsoft.com/face/v1.0">https://westeurope.api.cognitive.microsoft.com/face/v1.0</a> if the service is located in west Europe.</p><p>If the service is located in the west US, you would replace <code class="literal">westeurope</code> with <code class="literal">westus</code>. The root URI can be found in the following place in Azure Portal:</p><div class="mediaobject"><img alt="Detecting faces with the Face API" src="graphics/B12373_01_10.jpg"/></div><p>At last, we create the <code class="literal">DelegateCommand</code> constructor for our command properties. Note how the <code class="literal">browse</code> command does not specify a predicate. This means that it will always be possible to click on the corresponding button. To make this compile, we need to create the functions specified in the <code class="literal">DelegateCommand</code> constructors: the <code class="literal">Browse</code>, <code class="literal">DetectFace</code>, and <code class="literal">CanDetectFace</code> functions.</p><p>We start the <code class="literal">Browse</code> function by creating an <code class="literal">OpenFileDialog</code> object. This dialog is assigned a filter for JPEG images, and, in turn, it is opened, as shown in the following code. When the dialog is closed, we check the result. If the dialog was canceled, we simply stop further execution:</p><div class="informalexample"><pre class="programlisting">    private void Browse(object obj)
    {
        var openDialog = new Microsoft.Win32.OpenFileDialog();
        openDialog.Filter = "JPEG Image(*.jpg)|*.jpg";
        bool? result = openDialog.ShowDialog();

        if (!(bool)result) return;</pre></div><p>With the dialog closed, we grab the filename of the file selected and create a new URI from it, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">        _filePath = openDialog.FileName;
        Uri fileUri = new Uri(_filePath);</pre></div><p>With the newly created URI, we want to create a new <code class="literal">BitmapImage</code>. We specify it so that it uses<a class="indexterm" id="id21"/> no cache, and we set the URI source of the URI that we created, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">        BitmapImage image = new BitmapImage(fileUri);

        image.CacheOption = BitmapCacheOption.None;
        image.UriSource = fileUri;</pre></div><p>The last step we take is to assign the bitmap image to our <code class="literal">BitmapImage</code> property so that the image is shown in the UI. We also update the status text to let the user know that the image has been loaded, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">        ImageSource = image;
        StatusText = "Status: Image loaded...";
    }</pre></div><p>The <code class="literal">CanDetectFace</code> function checks whether or not the <code class="literal">DetectFacesButton</code> button should be enabled. In this case, it checks whether our image property actually has a URI. If it does by extension, then that means that we have an image and we should be able to detect faces, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">    private boolCanDetectFace(object obj)
    {
        return !string.IsNullOrEmpty(ImageSource?.UriSource.ToString());
    }</pre></div><p>Our <code class="literal">DetectFace</code> method calls an <code class="literal">async</code> method to upload and detect faces. The return value contains an array of the <code class="literal">FaceRectangles</code> variable. This array contains the rectangle area for all face positions in the given image. We will look into the function that we are going to call in a bit.</p><p>After the call has finished executing, we print a line containing the number of faces to the debug console window, as follows:</p><div class="informalexample"><pre class="programlisting">    private async void DetectFace(object obj)
    {
        FaceRectangle[] faceRects = await UploadAndDetectFacesAsync();

        string textToSpeak = "No faces detected";

        if (faceRects.Length == 1)
            textToSpeak = "1 face detected";
        else if (faceRects.Length&gt; 1)
            textToSpeak = $"{faceRects.Length} faces detected";

        Debug.WriteLine(textToSpeak);
    }</pre></div><p>In the <code class="literal">UploadAndDetectFacesAsync</code> function, we create a <code class="literal">Stream</code> from the image, as shown in the<a class="indexterm" id="id22"/> following code. This stream will be used as input for the actual call to the Face API service:</p><div class="informalexample"><pre class="programlisting">    private async Task&lt;FaceRectangle[]&gt;UploadAndDetectFacesAsync()
    {
        StatusText = "Status: Detecting faces...";

        try
        {
            using (Stream imageFileStream = File.OpenRead(_filePath))</pre></div><p>The following line is the actual call to the detection endpoint for the Face API:</p><div class="informalexample"><pre class="programlisting">            Face[] faces = await _faceServiceClient.DetectAsync(imageFileStream, true, true, new List&lt;FaceAttributeType&gt;() { FaceAttributeType.Age });</pre></div><p>The first parameter is the file stream that we created in the previous step. The rest of the parameters are all optional. The second parameter should be <code class="literal">true</code> if you want to get a face ID. The next parameter specifies whether you want to receive face landmarks or not. The last parameter takes a list of facial attributes that you may want to receive. In our case, we want the <code class="literal">age</code> parameter to be returned, so we need to specify that.</p><p>The return type of this function call is an array of faces, with all the parameters that you have specified, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">            List&lt;double&gt; ages = faces.Select(face =&gt;face.FaceAttributes.Age).ToList();
            FaceRectangle[] faceRects = faces.Select(face =&gt;face.FaceRectangle).ToArray();

            StatusText = "Status: Finished detecting faces...";

            foreach(var age in ages) {
                Console.WriteLine(age);
            }
            return faceRects;
        }
    }</pre></div><p>The first line iterates over all faces and retrieves the approximate age of all faces. This is later printed to<a class="indexterm" id="id23"/> the debug console window, in the <code class="literal">foreach</code> loop.</p><p>The second line iterates over all faces and retrieves the face rectangle, with the rectangular location of all faces. This is the data that we return to the calling function.</p><p>Add a <code class="literal">catch</code> clause to finish the method. Where an exception is thrown in our API call, we catch that. We want to show the error message and return an empty <code class="literal">FaceRectangle</code> array.</p><p>With that code in place, you should now be able to run the full example. The end result will look like the following screenshot:</p><div class="mediaobject"><img alt="Detecting faces with the Face API" src="graphics/B12373_01_11.jpg"/></div><p>The result debug console window will print the following text:</p><div class="informalexample"><pre class="programlisting">    1 face detected
    23,7</pre></div></div>
<div class="section" title="An overview of different APIs"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec13"/>An overview of different APIs</h1></div></div></div><p>Now that you have<a class="indexterm" id="id24"/> seen a basic example of how to detect faces, it is time to learn a bit about what else Cognitive Services can do for you. When using Cognitive Services, you have 21 different APIs to hand. These are, in turn, separated into five top-level domains depending on what they do. These domains are vision, speech, language, knowledge, and search. We will learn more about them in the following sections.</p><div class="section" title="Vision"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec05"/>Vision</h2></div></div></div><p>APIs under the <span class="strong"><strong>vision</strong></span> flags allow your apps to understand images and video content. They allow you<a class="indexterm" id="id25"/> to retrieve information about faces, feelings, and other visual content. You can stabilize videos and recognize celebrities. You can read text in images and<a class="indexterm" id="id26"/> generate thumbnails from videos and images.</p><p>There are four APIs contained in the vision domain, which we will look at now.</p><div class="section" title="Computer vision"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec01"/>Computer vision</h3></div></div></div><p>Using the <span class="strong"><strong>computer vision</strong></span> API, you can retrieve actionable information from images. This means that<a class="indexterm" id="id27"/> you can identify content (such as image format, image size, colors, faces, and more). You can detect whether or not an image is adult/racy. This API can recognize text in images and extract it to machine-readable words. It can detect celebrities from a variety of areas. Lastly, it can generate storage-efficient thumbnails with smart-cropping functionality.</p><p>We will look into computer vision in <a class="link" href="ch02.html" title="Chapter 2. Analyzing Images to Recognize a Face">Chapter 2</a>, <span class="emphasis"><em>Analyzing Images to Recognize a Face</em></span>.</p></div><div class="section" title="Face"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec02"/>Face</h3></div></div></div><p>We have<a class="indexterm" id="id28"/> already seen a very basic example of what the Face API can do. The rest of the API revolves around the detection, identification, organization, and tagging of faces in photos. As well as face detection, you can also see how likely it is that two faces belong to the same person. You can identify faces and also find similar-looking faces. We can also use the API to recognize emotions in images.</p><p>We will dive further into the Face API in <a class="link" href="ch02.html" title="Chapter 2. Analyzing Images to Recognize a Face">Chapter 2</a>, <span class="emphasis"><em>Analyzing Images to Recognize a Face</em></span>.</p></div><div class="section" title="Video indexer"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec03"/>Video indexer</h3></div></div></div><p>Using the <span class="strong"><strong>video indexer</strong></span> API, you can start indexing videos immediately upon upload. This means that<a class="indexterm" id="id29"/> you can get video insights without using<a class="indexterm" id="id30"/> experts or custom code. Content discovery can be improved, utilizing the powerful artificial intelligence of this API. This allows you to make your content more discoverable.</p><p>The video indexer API will be covered in greater detail in <a class="link" href="ch03.html" title="Chapter 3. Analyzing Videos">Chapter 3</a>, <span class="emphasis"><em>Analyzing Videos</em></span>.</p></div><div class="section" title="Content moderator"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec04"/>Content moderator</h3></div></div></div><p>The <span class="strong"><strong>content moderator</strong></span> API utilizes machine learning to automatically moderate content. It can detect<a class="indexterm" id="id31"/> potentially offensive and unwanted images, videos, and text for over 100 languages. In addition, it allows you to review<a class="indexterm" id="id32"/> detected material to improve the service.</p><p>The content moderator will be covered in <a class="link" href="ch02.html" title="Chapter 2. Analyzing Images to Recognize a Face">Chapter 2</a>, <span class="emphasis"><em>Analyzing Images to Recognize a Face</em></span>.</p></div><div class="section" title="Custom vision service"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec05"/>Custom vision service</h3></div></div></div><p>The <span class="strong"><strong>custom vision service</strong></span> allows you to upload your own labeled images to a vision service. This means<a class="indexterm" id="id33"/> that you can add images that are specific<a class="indexterm" id="id34"/> to your domain to allow recognition using the computer vision API.</p><p>The custom vision service will be covered in more detail in <a class="link" href="ch02.html" title="Chapter 2. Analyzing Images to Recognize a Face">Chapter 2</a>, <span class="emphasis"><em>Analyzing Images to Recognize a Face</em></span>.</p></div></div><div class="section" title="Speech"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec06"/>Speech</h2></div></div></div><p>Adding one of the Speech APIs allows your application to hear and speak to your users. The APIs can filter<a class="indexterm" id="id35"/> noise and identify speakers. Based on the recognized intent, they can drive further actions in your application.</p><p>The speech domain contains three APIs that are outlined in the following sections.</p><div class="section" title="Bing Speech"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec06"/>Bing Speech</h3></div></div></div><p>Adding the <span class="strong"><strong>Bing Speech</strong></span> API to your application allows you to convert speech to text and vice versa. You can<a class="indexterm" id="id36"/> convert spoken audio to text either by<a class="indexterm" id="id37"/> utilizing a microphone or<a class="indexterm" id="id38"/> other sources in real time or by converting audio from files. The API also offers speech intent recognition, which is trained by the <span class="strong"><strong>Language Understanding Intelligent Service</strong></span> (<span class="strong"><strong>LUIS</strong></span>) to understand the intent.</p></div><div class="section" title="Speaker recognition"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec07"/>Speaker recognition</h3></div></div></div><p>The <span class="strong"><strong>speaker</strong></span> <span class="strong"><strong>recognition</strong></span> API gives your application the ability to know who is talking. By using this API, you can verify that the person that is speaking is who they claim to be. You can also<a class="indexterm" id="id39"/> determine who an unknown speaker is based on a<a class="indexterm" id="id40"/> group of selected speakers.</p></div><div class="section" title="Translator speech API"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec08"/>Translator speech API</h3></div></div></div><p>The <span class="strong"><strong>translator speech</strong></span> API is a cloud-based automatic translation service for spoken audio. Using this API, you can add end-to-end translation across web apps, mobile apps, and desktop<a class="indexterm" id="id41"/> applications. Depending on your use cases, it can provide you<a class="indexterm" id="id42"/> with partial translations, full translations, and transcripts of the translations cover all speech-related APIs in <a class="link" href="ch05.html" title="Chapter 5. Speaking with Your Application">Chapter 5</a>, <span class="emphasis"><em>Speak with Your Application</em></span>.</p></div></div><div class="section" title="Language"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec07"/>Language</h2></div></div></div><p>APIs that are related to the language domain allow your application to process natural language and learn<a class="indexterm" id="id43"/> how to recognize what users want. You can add textual and linguistic analysis to your application, as well as natural language understanding.</p><p>The following five APIs can be found in the language domain.</p><div class="section" title="Bing Spell Check"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec09"/>Bing Spell Check</h3></div></div></div><p>The <span class="strong"><strong>Bing Spell Check</strong></span> API allows you<a class="indexterm" id="id44"/> to add advanced spell checking to your application.</p><p>This API will<a class="indexterm" id="id45"/> be covered in <a class="link" href="ch06.html" title="Chapter 6. Understanding Text">Chapter 6</a>, <span class="emphasis"><em>Understanding Text</em></span>.</p></div><div class="section" title="Language Understanding Intelligent Service (LUIS)"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec10"/>Language Understanding Intelligent Service (LUIS)</h3></div></div></div><p>LUIS is an API<a class="indexterm" id="id46"/> that can help your application understand commands from your users. Using this API, you can create language models that understand intents. By using models from Bing and Cortana, you can make these models<a class="indexterm" id="id47"/> recognize common requests and entities (such as places, times, and numbers). You can add conversational intelligence to your applications.</p><p>LUIS will be covered in <a class="link" href="ch04.html" title="Chapter 4. Letting Applications Understand Commands">Chapter 4</a>, <span class="emphasis"><em>Let Applications Understand Commands</em></span>.</p></div><div class="section" title="Text analytics"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec11"/>Text analytics</h3></div></div></div><p>The <span class="strong"><strong>text analytics</strong></span> API will help you in extracting information from text. You can use it to find the<a class="indexterm" id="id48"/> sentiment of a text (whether the text is positive or negative), and will<a class="indexterm" id="id49"/> also be able to detect the language, topic, key phrases, and entities that are used throughout the will also cover the text analysis API in <a class="link" href="ch06.html" title="Chapter 6. Understanding Text">Chapter 6</a>, <span class="emphasis"><em>Understanding Text</em></span>.</p></div><div class="section" title="Translator Text API"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec12"/>Translator Text API</h3></div></div></div><p>By adding the <span class="strong"><strong>translator text</strong></span> API, you can get textual translations for over 60 languages. It can detect<a class="indexterm" id="id50"/> languages automatically, and you can customize the API to<a class="indexterm" id="id51"/> your needs. In addition, you can improve translations by creating user groups, utilizing the power of crowdsourcing.</p><p>The translator text API will not be covered in this book.</p></div></div><div class="section" title="Knowledge"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec08"/>Knowledge</h2></div></div></div><p>When we talk about <span class="strong"><strong>knowledge</strong></span> APIs, we are talking about APIs that allow you to tap into rich knowledge. This may<a class="indexterm" id="id52"/> be knowledge from the web or from academia, or it<a class="indexterm" id="id53"/> may be your own data. Using these APIs, you will be able to explore the different nuances of knowledge.</p><p>The following four APIs are contained in the knowledge API domain.</p><div class="section" title="Project Academic Knowledge"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec13"/>Project Academic Knowledge</h3></div></div></div><p>Using the <span class="strong"><strong>Project</strong></span> <span class="strong"><strong>Academic Knowledge</strong></span> API, you can explore relationships among academic papers, journals, and authors. This API allows you to interpret natural language user query strings, which allows<a class="indexterm" id="id54"/> your application to<a class="indexterm" id="id55"/> anticipate what the user is typing. It will evaluate what is being typed and return academic knowledge entities.</p><p>This API will be covered in more detail in <a class="link" href="ch08.html" title="Chapter 8. Querying Structured Data in a Natural Way">Chapter 8</a>, <span class="emphasis"><em>Query Structured Data in a Natural Way</em></span>.</p></div><div class="section" title="Knowledge exploration"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec14"/>Knowledge exploration</h3></div></div></div><p>The <span class="strong"><strong>knowledge exploration</strong></span> API will let you add the possibility of using interactive searches for<a class="indexterm" id="id56"/> structured data in your projects. It interprets natural language queries and offers autocompletions to minimize user effort. Based on the<a class="indexterm" id="id57"/> query expression received, it will retrieve detailed information about matching objects.</p><p>Details on<a class="indexterm" id="id58"/> this API will be covered in <a class="link" href="ch08.html" title="Chapter 8. Querying Structured Data in a Natural Way">Chapter 8</a>, <span class="emphasis"><em>Query Structured Data in a Natural Way</em></span>.</p></div><div class="section" title="Recommendations solution"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec15"/>Recommendations solution</h3></div></div></div><p>The <span class="strong"><strong>recommendations solution</strong></span> API allows you to provide personalized product recommendations for your customers. You can use this API to add a frequently-bought-together functionality<a class="indexterm" id="id59"/> to your application. Another feature that you can add is item-to-item recommendations, which allows customers<a class="indexterm" id="id60"/> to see what other customers like. This API will also allow you to add recommendations based on the prior activity of the customer.</p><p>We will go through this API in <a class="link" href="ch07.html" title="Chapter 7. Building Recommendation Systems for Businesses">Chapter 7</a>, <span class="emphasis"><em>Building Recommendation Systems for Businesses</em></span>.</p></div><div class="section" title="QnA Maker"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec16"/>QnA Maker</h3></div></div></div><p>The <span class="strong"><strong>QnA Maker</strong></span> is a service<a class="indexterm" id="id61"/> to distill information for frequently asked questions (FAQ). Using existing FAQs, either online or in a document, you can<a class="indexterm" id="id62"/> create question and answer pairs. Pairs can be edited, removed, and modified, and you can add several similar questions to match a given pair.</p><p>We will cover QnA Maker in <a class="link" href="ch08.html" title="Chapter 8. Querying Structured Data in a Natural Way">Chapter 8</a>, <span class="emphasis"><em>Query Structured Data in a Natural Way</em></span>.</p></div><div class="section" title="Project Custom Decision Service"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec17"/>Project Custom Decision Service</h3></div></div></div><p>
<span class="strong"><strong>Project Custom Decision Service</strong></span> is a<a class="indexterm" id="id63"/> service designed to use reinforced learning to personalize content. The service understands any<a class="indexterm" id="id64"/> context and can provide context-based content.</p><p>This book does not cover Project Custom Decision Service.</p></div></div><div class="section" title="Search"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec09"/>Search</h2></div></div></div><p>
<span class="strong"><strong>Search</strong></span> APIs give you the ability to make your applications more intelligent with the power of Bing. Using these APIs, you can use a single call to access data from billions of web pages, images, videos, and news articles.</p><p>The search domain contains the following APIs.</p><div class="section" title="Bing Web Search"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec18"/>Bing Web Search</h3></div></div></div><p>With <span class="strong"><strong>Bing Web Search</strong></span>, you can search for details in billions of web documents that are indexed by Bing. All the<a class="indexterm" id="id65"/> results can be arranged and ordered according to a layout that you specify, and the results are customized to the location of the<a class="indexterm" id="id66"/> end user.</p><p>Bing Web Search will be covered in <a class="link" href="ch09.html" title="Chapter 9. Adding Specialized Searches">Chapter 9</a>, <span class="emphasis"><em>Adding Specialized Search</em></span>.</p></div><div class="section" title="Bing Image Search"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec19"/>Bing Image Search</h3></div></div></div><p>Using the <span class="strong"><strong>Bing Image Search</strong></span> API, you can add an advanced image and metadata search to your application. Results include URLs to images, thumbnails, and metadata. You will also be able<a class="indexterm" id="id67"/> to get machine-generated captions, similar images, and more. This API allows you to filter the results based on image type, layout, freshness (how new the image is), and license. Bing Image Search will be covered in <a class="link" href="ch09.html" title="Chapter 9. Adding Specialized Searches">Chapter 9</a>, <span class="emphasis"><em>Adding Specialized Search</em></span>.</p></div><div class="section" title="Bing Video Search"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec20"/>Bing Video Search</h3></div></div></div><p>
<span class="strong"><strong>Bing Video Search</strong></span> will allow you to search for videos and return rich results. The results could contain<a class="indexterm" id="id68"/> metadata from the videos, static or motion-based thumbnails, and the video itself. You can add filters to the results based on freshness, video length, resolution, and price.</p><p>Bing Video Search will be covered in <a class="link" href="ch09.html" title="Chapter 9. Adding Specialized Searches">Chapter 9</a>, <span class="emphasis"><em>Adding Specialized Search</em></span>.</p></div><div class="section" title="Bing News Search"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec21"/>Bing News Search</h3></div></div></div><p>If you add <span class="strong"><strong>Bing News Search</strong></span> to your application, you can search for news articles. Results can<a class="indexterm" id="id69"/> include authoritative images, related news and categories, information on the provider, URLs, and more. To be more specific, you can filter news based on topics.</p><p>Bing News Search will be covered in <a class="link" href="ch09.html" title="Chapter 9. Adding Specialized Searches">Chapter 9</a>, <span class="emphasis"><em>Adding Specialized Search</em></span>.</p></div><div class="section" title="Bing Autosuggest"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec22"/>Bing Autosuggest</h3></div></div></div><p>The <span class="strong"><strong>Bing Autosuggest</strong></span> API is a small but powerful one. It will allow your users to search faster using<a class="indexterm" id="id70"/> their search suggestions, allowing you to connect a powerful search functionality to your apps.</p><p>Bing Autosuggest will be covered in <a class="link" href="ch09.html" title="Chapter 9. Adding Specialized Searches">Chapter 9</a>, <span class="emphasis"><em>Adding Specialized Search</em></span>.</p></div><div class="section" title="Bing Visual Search"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec23"/>Bing Visual Search</h3></div></div></div><p>Using the <span class="strong"><strong>Bing Visual Search</strong></span> API, you can identify and classify images. You can also acquire knowledge<a class="indexterm" id="id71"/> about images.</p><p>Bing Visual Search will be covered in <a class="link" href="ch09.html" title="Chapter 9. Adding Specialized Searches">Chapter 9</a>, <span class="emphasis"><em>Adding Specialized Search</em></span>.</p></div><div class="section" title="Bing Custom Search"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec24"/>Bing Custom Search</h3></div></div></div><p>By utilizing the <span class="strong"><strong>Bing Custom Search</strong></span> API, you can create a powerful, customized search that fits<a class="indexterm" id="id72"/> your needs. This tool is an ad-free commercial tool that allows you to deliver the search results you want.</p><p>Bing Custom Search will be covered in <a class="link" href="ch09.html" title="Chapter 9. Adding Specialized Searches">Chapter 9</a>, <span class="emphasis"><em>Adding Specialized Search</em></span>.</p></div><div class="section" title="Bing Entity Search"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec25"/>Bing Entity Search</h3></div></div></div><p>Using the <span class="strong"><strong>Bing Entity Search</strong></span> API, you can enhance your searches. The API will find the most relevant<a class="indexterm" id="id73"/> entity based on your search terms. It will find entities such as famous people, places, movies, and more.</p><p>We will not cover Bing Entity Search in this book.</p></div></div></div>
<div class="section" title="Getting feedback on detected faces"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec14"/>Getting feedback on detected faces</h1></div></div></div><p>Now that we have seen what else Microsoft Cognitive Services can offer, we are going to add an API to our<a class="indexterm" id="id74"/> face detection application. In this section, we will add the Bing Speech API to make the application say the number of faces out loud.</p><p>This feature of the API is not provided in the NuGet package, and as such, we are going to use the REST API.</p><p>To reach our end goal, we are going to add two new classes, <code class="literal">TextToSpeak</code> and <code class="literal">Authentication</code>. The first class will be in charge of generating the correct headers and making the calls to our service endpoint. The latter class will be in charge of generating an authentication token. This will be tied together in our <code class="literal">ViewModel</code>, where we will make the application speak back to us.</p><p>We need to get our hands on an API key first. Head over to the Microsoft Azure Portal. Create a new service for Bing Speech.</p><p>To be able to call the Bing Speech API, we need to have an authorization token. Go back to Visual Studio and create a new file called <code class="literal">Authentication.cs</code>. Place this in the <code class="literal">Model</code> folder.</p><p>We need to add two new references to the project. Find the <code class="literal">System.Runtime.Serialization</code> and <code class="literal">System.Web</code> packages in the <span class="strong"><strong>Assembly</strong></span> tab in the <span class="strong"><strong>Add References</strong></span> window and add them.</p><p>In our <code class="literal">Authentication</code> class, define four <code class="literal">private</code> variables and one <code class="literal">public</code> property, as follows:</p><div class="informalexample"><pre class="programlisting">    private string _requestDetails;
    private string _token;
    private Timer _tokenRenewer;

    private const int TokenRefreshInterval = 9;

    public string Token { get { return _token; } }</pre></div><p>The constructor should accept one string parameter, <code class="literal">clientSecret</code>. The <code class="literal">clientSecret</code> parameter is the<a class="indexterm" id="id75"/> API key you signed up for.</p><p>In the constructor, assign the <code class="literal">_clientSecret</code> variable, as follows:</p><div class="informalexample"><pre class="programlisting">    _clientSecret = clientSecret;</pre></div><p>Create a new function called <code class="literal">Initialize</code>, as follows:</p><div class="informalexample"><pre class="programlisting">    public async Task Initialize()
    {
        _token = GetToken();

        _tokenRenewer = new Timer(new TimerCallback(OnTokenExpiredCallback), this,
        TimeSpan.FromMinutes(TokenRefreshInterval),
        TimeSpan.FromMilliseconds(-1));
    }</pre></div><p>We then fetch the access token in a method that we will create shortly.</p><p>Finally, we create our <code class="literal">timer</code> class, which will call the <code class="literal">callback</code> function in nine minutes. The <code class="literal">callback</code> function will need to fetch the access token again and assign it to the <code class="literal">_token</code> variable. It also needs to ensure that we run the timer again in nine minutes.</p><p>Next, we need to create the <code class="literal">GetToken</code> method. This method should return a <code class="literal">Task&lt;string&gt;</code>object, and it should be declared as <code class="literal">private</code> and marked as <code class="literal">async</code>.</p><p>In the method, we start by creating an <code class="literal">HttpClient</code> object, pointing to an endpoint that will generate our token. We specify the root endpoint and add the token issue path, as follows:</p><div class="informalexample"><pre class="programlisting">    using(var client = new HttpClient())
    {
        client.DefaultRequestHeaders.Add ("Opc-Apim-Subscription-Key", _clientSecret);
        UriBuilder uriBuilder = new UriBuilder (https://api.cognitive.microsoft.com/sts/v1.0");
        uriBuilder.Path = "/issueToken";</pre></div><p>We then go on to make a POST call to generate a token, as follows:</p><div class="informalexample"><pre class="programlisting">var result = await client.PostAsync(uriBuilder.Uri.AbsoluteUri, null);</pre></div><p>When the request has been sent, we expect there to be a response. We want to read this response and return the response string:</p><div class="informalexample"><pre class="programlisting">return await result.Content.ReadAsStringAsync();</pre></div><p>Add a new file called <code class="literal">TextToSpeak.cs</code>, if you have not already done so. Put this file in the <code class="literal">Model</code> folder.</p><p>Beneath the newly<a class="indexterm" id="id76"/> created class (but inside the namespace), we want to add two event argument classes. These will be used to handle audio events, which we will see later.</p><p>The <code class="literal">AudioEventArgs</code> class simply takes a generic <code class="literal">stream</code>, as shown in the following code. You can imagine it being used to send the audio stream to our application:</p><div class="informalexample"><pre class="programlisting">    public class AudioEventArgs : EventArgs
    {
        public AudioEventArgs(Stream eventData)
        {
            EventData = eventData;
        }

        public StreamEventData { get; private set; }
    }</pre></div><p>The next class allows us to send an event with a specific error message:</p><div class="informalexample"><pre class="programlisting">    public class AudioErrorEventArgs : EventArgs
    {
        public AudioErrorEventArgs(string message)
        {
            ErrorMessage = message;
        }

        public string ErrorMessage { get; private set; }
    }</pre></div><p>We move on to start on the <code class="literal">TextToSpeak</code> class, where we start off by declaring some events and class members, as follows:</p><div class="informalexample"><pre class="programlisting">    public class TextToSpeak
    {
        public event EventHandler&lt;AudioEventArgs&gt;OnAudioAvailable;
        public event EventHandler&lt;AudioErrorEventArgs&gt;OnError;

        private string _gender;
        private string _voiceName;
        private string _outputFormat;
        private string _authorizationToken;
        private AccessTokenInfo _token;

        private List&lt;KeyValuePair&lt;string, string&gt;&gt; _headers = new  List&lt;KeyValuePair&lt;string, string&gt;&gt;();</pre></div><p>The first two lines<a class="indexterm" id="id77"/> in the class are events that use the event argument classes that we created earlier. These events will be triggered if a call to the API finishes (returning some audio), or if anything fails. The next few lines are string variables, which we will use as input parameters. We have one line to contain our access token information. The last line creates a new list, which we will use to hold our request headers.</p><p>We add two constant strings to our class, as follows:</p><div class="informalexample"><pre class="programlisting">private const string RequestUri =  "https://speech.platform.bing.com/synthesize";

private const string SsmlTemplate =
    "&lt;speak version='1.0'xml:lang='en-US'&gt;
        &lt;voice xml:lang='en-US'xml:gender='{0}'
        name='{1}'&gt;{2}
        &lt;/voice&gt;
    &lt;/speak&gt;";</pre></div><p>The first string contains the request URI. That is the REST API endpoint that we need to call to execute<a class="indexterm" id="id78"/> our request. Next, we have a string defining our <span class="strong"><strong>Speech Synthesis Markup Language</strong></span> (<span class="strong"><strong>SSML</strong></span>) template. This is where we will specify what the speech service should say, and how it should say it.</p><p>Next, we create our constructor, as follows:</p><div class="informalexample"><pre class="programlisting">        public TextToSpeak()
        {
            _gender = "Female";
            _outputFormat = "riff-16khz-16bit-mono-pcm";
            _voiceName = "Microsoft Server Speech Text to Speech Voice (en-US, ZiraRUS)";
        }</pre></div><p>Here, we are just initializing some of the variables that we declared earlier. As you may see, we are defining the voice as female and we define it so that it uses a specific voice. In terms of gender, it can be either female or male. The voice name can be one of a long list of options. We will look more into the details of that list when we go through this API in a later chapter.</p><p>The last line specifies the output format of the audio. This will define the format and codec in use by the resultant audio stream. Again, this can be a number of varieties, which we will<a class="indexterm" id="id79"/> look into in a later chapter.</p><p>Following the constructor, there are three public methods that we will create. These will generate an authentication token and some HTTP headers, and finally execute our call to the API. Before we create these, you should add two helper methods to be able to raise our events. Call them the <code class="literal">RaiseOnAudioAvailable</code> and <code class="literal">RaiseOnError</code> methods. They should accept <code class="literal">AudioEventArgs</code> and <code class="literal">AudioErrorEventArgs</code> as parameters.</p><p>Next, add a new method called the <code class="literal">GenerateHeaders</code> method, as follows:</p><div class="informalexample"><pre class="programlisting">        public void GenerateHeaders()
        {
            _headers.Add(new KeyValuePair&lt;string, string&gt;("Content-Type", "application/ssml+xml"));
            _headers.Add(new KeyValuePair&lt;string, string&gt;("X-Microsoft-OutputFormat", _outputFormat));
            _headers.Add(new KeyValuePair&lt;string, string&gt;("Authorization", _authorizationToken));
            _headers.Add(new KeyValuePair&lt;string, string&gt;("X-Search-AppId", Guid.NewGuid().ToString("N")));
            _headers.Add(new KeyValuePair&lt;string, string&gt;("X-Search-ClientID", Guid.NewGuid().ToString("N")));
            _headers.Add(new KeyValuePair&lt;string, string&gt;("User-Agent", "Chapter1"));
        }</pre></div><p>Here, we add the HTTP headers to our previously created list. These headers are required for the service to respond, and if any are missing, it will yield an <code class="literal">HTTP/400</code> response. We will cover what we are using as headers in more detail later. For now, just make sure that they are present.</p><p>Following this, we want to add a new method called <code class="literal">GenerateAuthenticationToken</code>, as follows:</p><div class="informalexample"><pre class="programlisting">        public bool GenerateAuthenticationToken(string clientSecret)
        {
            Authentication auth = new Authentication(clientSecret);</pre></div><p>This method accepts one string parameter, the client secret (your API key). First, we create a new object of the <code class="literal">Authentication</code> class, which we looked at earlier, as follows:</p><div class="informalexample"><pre class="programlisting">        try
        {
            _token = auth.Token;

            if (_token != null)
            {
                _authorizationToken = $"Bearer {_token}";

                return true;
            }
            else
            {
                RaiseOnError(new AudioErrorEventArgs("Failed to generate authentication token."));
                return false;
            }
        }</pre></div><p>We use the<a class="indexterm" id="id80"/> authentication object to retrieve an access token. This token is used in our authorization token string, which, as we saw earlier, is being passed on in our headers. If the application for some reason fails to generate the access token, we trigger an error event.</p><p>Finish this method by adding the associated catch clause. If any exceptions occur, we want to raise a new error event.</p><p>The last method that we need to create in this class is going to be called the <code class="literal">SpeakAsync</code> method, as shown in the following screenshot. This method will actually perform the request to the Speech API:</p><div class="informalexample"><pre class="programlisting">        public Task SpeakAsync(string textToSpeak, CancellationTokencancellationToken)
        {
            varcookieContainer = new CookieContainer();
            var handler = new HttpClientHandler() {
                CookieContainer = cookieContainer
            };
            var client = new HttpClient(handler);</pre></div><p>The method takes two parameters. One is the string, which will be the text that we want to be spoken. The next is <code class="literal">cancellationToken</code>; this can be used to propagate the command that the given operation should be cancelled.</p><p>When entering the method, we create three objects that we will use to execute the request. These are classes from the .NET library. We will not be going through them in any more detail.</p><p>We generated some headers earlier, and we need to add these to our HTTP client. We do this by adding the headers in the preceding <code class="literal">foreach</code> loop, basically looping through the entire list, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">            foreach(var header in _headers)
            {
                client.DefaultRequestHeaders.TryAddWithoutValidation (header.Key, header.Value);
            }</pre></div><p>Next, we create an <code class="literal">HTTP Request Message</code>, specifying the request URI and the fact that we will<a class="indexterm" id="id81"/> send data through the <code class="literal">POST</code> method. We also specify the content using the SSML template that we created earlier, adding the correct parameters (gender, voice name, and the text we want to be spoken), as shown in the following code:</p><div class="informalexample"><pre class="programlisting">            var request = new HttpRequestMessage(HttpMethod.Post, RequestUri)
            {
                Content = new StringContent(string.Format(SsmlTemplate, _gender, _voiceName, textToSpeak))
            };</pre></div><p>We use the HTTP client to send the HTTP request asynchronously, as follows:</p><div class="informalexample"><pre class="programlisting">            var httpTask = client.SendAsync(request, HttpCompletionOption.ResponseHeadersRead, cancellationToken);</pre></div><p>The following code is a continuation of the asynchronous send call that we made previously. This will run asynchronously as well, and check the status of the response. If the response is successful, it will read the response message as a stream and trigger the audio event. If everything succeeds, then that stream should contain our text in spoken words:</p><div class="informalexample"><pre class="programlisting">    var saveTask = httpTask.ContinueWith(async (responseMessage, token) =&gt;
    {
        try
        {
            if (responseMessage.IsCompleted &amp;&amp;
                responseMessage.Result != null &amp;&amp;  
                responseMessage.Result.IsSuccessStatusCode) {
                var httpStream = await responseMessage. Result.Content.ReadAsStreamAsync().ConfigureAwait(false);
                RaiseOnAudioAvailable(new AudioEventArgs (httpStream));
            } else {
                RaiseOnError(new AudioErrorEventArgs($"Service returned {responseMessage.Result.StatusCode}"));
            }
        }
        catch(Exception e)
        {
            RaiseOnError(new AudioErrorEventArgs (e.GetBaseException().Message));
        }
    }</pre></div><p>If the response indicates anything other than success, we will raise the error event.</p><p>We also want to<a class="indexterm" id="id82"/> add a catch clause and a <code class="literal">finally</code> clause to this. Raise an error if an exception is caught and dispose of all objects used in the <code class="literal">finally</code> clause.</p><p>The final code we need specifies that the continuation task is attached to the parent task. We also need to add <code class="literal">cancellationToken</code> to this task. Add the following code to finish off the method:</p><div class="informalexample"><pre class="programlisting">    }, TaskContinuationOptions.AttachedToParent, cancellationToken);
    return saveTask;
}</pre></div><p>With this in place, we are now able to utilize this class in our application. Open the <code class="literal">MainViewModel.cs</code> file and declare a new class variable, as follows:</p><div class="informalexample"><pre class="programlisting">        private TextToSpeak _textToSpeak;</pre></div><p>Add the following code in the constructor to initialize the newly added object. We also need to call a function to generate the authentication token, as follows:</p><div class="informalexample"><pre class="programlisting">            _textToSpeak = new TextToSpeak();
            _textToSpeak.OnAudioAvailable +=  _textToSpeak_OnAudioAvailable;
            _textToSpeak.OnError += _textToSpeak_OnError;

            GenerateToken();</pre></div><p>After we have created the object, we hook up the two events to event handlers. Then we generate an authentication token by creating a <code class="literal">GenerateToken</code> function with the following content:</p><div class="informalexample"><pre class="programlisting">public async void GenerateToken()
{
    if (await _textToSpeak.GenerateAuthenticationToken("BING_SPEECH_API_KEY_HERE"))
        _textToSpeak.GenerateHeaders();
}</pre></div><p>Then we generate an authentication token, specifying the API key for the Bing Speech API. If that call succeeds, we generate the HTTP headers required.</p><p>We need to<a class="indexterm" id="id83"/> add the event handlers, so create the <code class="literal">_textToSpeak_OnError </code>method first, as follows:</p><div class="informalexample"><pre class="programlisting">            private void _textToSpeak_OnError(object sender, AudioErrorEventArgs e)
            {
                StatusText = $"Status: Audio service failed -  {e.ErrorMessage}";
            }</pre></div><p>It should be a rather simple method, just outputting the error message to the user in the status text field.</p><p>Next, we need to create a <code class="literal">_textToSpeak_OnAudioAvailable</code> method, as follows:</p><div class="informalexample"><pre class="programlisting">        private void _textToSpeak_OnAudioAvailable(object sender, AudioEventArgs e)
        {
            SoundPlayer player = new SoundPlayer(e.EventData);
            player.Play();
            e.EventData.Dispose();
        }</pre></div><p>Here, we utilize the <code class="literal">SoundPlayer</code> class from the .NET framework. This allows us to add the stream data directly and simply play the message.</p><p>The last part that we need for everything to work is to make the call to the <code class="literal">SpeakAsync</code> method. We can make this by adding the following at the end of our <code class="literal">DetectFace</code> method:</p><div class="informalexample"><pre class="programlisting">    await _textToSpeak.SpeakAsync(textToSpeak, CancellationToken.None);</pre></div><p>With that in place, you should now be able to compile and run the application. By loading a photo and clicking on <span class="strong"><strong>Detect face</strong></span>, you should be able to get the number of faces in the image spoken back to you. Just remember to have your audio turned on!</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec15"/>Summary</h1></div></div></div><p>This chapter was a brief introduction to Microsoft Cognitive Services. We started off by creating a template project to easily create new projects for the coming chapters. We tried this template by creating an example project for this chapter. Then you learned how to detect faces in images by utilizing the Face API. From there, we took a quick tour of what Cognitive Services has to offer. We finished off by adding text-to-speech capabilities to our application by using the Bing Speech API.</p><p>The next chapter will go into more detail of the vision part of the APIs. There, you will learn how to analyze images using the computer vision API. You will go into more detail about the Face API and will learn how to detect emotions in faces by using the emotion API. We will use some of this to start building our smart-house application.</p></div></body></html>