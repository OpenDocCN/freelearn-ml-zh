<html><head></head><body>
<div id="_idContainer080">
<h1 class="chapter-number" id="_idParaDest-119"><a id="_idTextAnchor516"/><span class="koboSpan" id="kobo.1.1" xmlns:="http://www.w3.org/1999/xhtml">4</span></h1>
<h1 id="_idParaDest-120"><a id="_idTextAnchor517"/><a id="_idTextAnchor518"/><span class="koboSpan" id="kobo.2.1" xmlns:="http://www.w3.org/1999/xhtml">Performing Variable Discretization</span></h1>
<p><span class="koboSpan" id="kobo.3.1" xmlns:="http://www.w3.org/1999/xhtml">Discretization is the </span><a id="_idTextAnchor519"/><span class="koboSpan" id="kobo.4.1" xmlns:="http://www.w3.org/1999/xhtml">process of transforming continuous variables into discrete features by creating a set of contiguous intervals, also </span><a id="_idIndexMarker276"/><span class="koboSpan" id="kobo.5.1" xmlns:="http://www.w3.org/1999/xhtml">called </span><strong class="bold"><span class="koboSpan" id="kobo.6.1" xmlns:="http://www.w3.org/1999/xhtml">bins</span></strong><span class="koboSpan" id="kobo.7.1" xmlns:="http://www.w3.org/1999/xhtml">, which span the range of the variable values. </span><span class="koboSpan" id="kobo.7.2" xmlns:="http://www.w3.org/1999/xhtml">Subsequently, these intervals are treated as </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1" xmlns:="http://www.w3.org/1999/xhtml">categorical data.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1" xmlns:="http://www.w3.org/1999/xhtml">Many machine learning models, such as decision trees and Naïve Bayes, work better with discrete attributes. </span><span class="koboSpan" id="kobo.9.2" xmlns:="http://www.w3.org/1999/xhtml">In fact, decision tree-based models make decisions based on discrete partitions over the attributes. </span><span class="koboSpan" id="kobo.9.3" xmlns:="http://www.w3.org/1999/xhtml">During induction, a decision tree evaluates all possible feature values to find the best cut-point. </span><span class="koboSpan" id="kobo.9.4" xmlns:="http://www.w3.org/1999/xhtml">Therefore, the more values the feature has, the longer the induction time of the tree is. </span><span class="koboSpan" id="kobo.9.5" xmlns:="http://www.w3.org/1999/xhtml">In this sense, discretization can reduce the time it takes to train </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1" xmlns:="http://www.w3.org/1999/xhtml">the models.</span></span></p>
<p><span class="koboSpan" id="kobo.11.1" xmlns:="http://www.w3.org/1999/xhtml">Discretization has additional advantages. </span><span class="koboSpan" id="kobo.11.2" xmlns:="http://www.w3.org/1999/xhtml">Data is reduced and simplified; discrete features can be easier to understand by domain experts. </span><span class="koboSpan" id="kobo.11.3" xmlns:="http://www.w3.org/1999/xhtml">Discretization can change the distribution of skewed variables; when sorting observations across bins with equal-frequency, the values are spread more homogeneously across the range. </span><span class="koboSpan" id="kobo.11.4" xmlns:="http://www.w3.org/1999/xhtml">Additionally, discretization can minimize the influence of outliers by placing them at lower or higher intervals, together with the remaining </span><strong class="bold"><span class="koboSpan" id="kobo.12.1" xmlns:="http://www.w3.org/1999/xhtml">inlier</span></strong><span class="koboSpan" id="kobo.13.1" xmlns:="http://www.w3.org/1999/xhtml"> values of the distribution. </span><span class="koboSpan" id="kobo.13.2" xmlns:="http://www.w3.org/1999/xhtml">Overall, discretization reduces and simplifies data, making the learning process faster and potentially yielding more </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1" xmlns:="http://www.w3.org/1999/xhtml">accurate results.</span></span></p>
<p><span class="koboSpan" id="kobo.15.1" xmlns:="http://www.w3.org/1999/xhtml">Discretization can also lead to a loss of information, for example, by combining values that are strongly associated with different classes or target values into the same bin. </span><span class="koboSpan" id="kobo.15.2" xmlns:="http://www.w3.org/1999/xhtml">Therefore, the aim of a discretization algorithm is to find the minimal number of intervals without incurring a significant loss of information. </span><span class="koboSpan" id="kobo.15.3" xmlns:="http://www.w3.org/1999/xhtml">In practice, many discretization procedures require the user to input the number of intervals into which the values will be sorted. </span><span class="koboSpan" id="kobo.15.4" xmlns:="http://www.w3.org/1999/xhtml">Then, the job of the algorithm is to find the cut points for those intervals. </span><span class="koboSpan" id="kobo.15.5" xmlns:="http://www.w3.org/1999/xhtml">Among these procedures, we find the most widely used equal-width and equal-frequency discretization methods. </span><span class="koboSpan" id="kobo.15.6" xmlns:="http://www.w3.org/1999/xhtml">Discretization methods based on decision trees are, otherwise, able to find the optimal number of partitions, as well as the </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1" xmlns:="http://www.w3.org/1999/xhtml">cut points.</span></span></p>
<p><span class="koboSpan" id="kobo.17.1" xmlns:="http://www.w3.org/1999/xhtml">Discretization procedures can be classified as </span><strong class="bold"><span class="koboSpan" id="kobo.18.1" xmlns:="http://www.w3.org/1999/xhtml">supervised</span></strong><span class="koboSpan" id="kobo.19.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="bold"><span class="koboSpan" id="kobo.20.1" xmlns:="http://www.w3.org/1999/xhtml">unsupervised</span></strong><span class="koboSpan" id="kobo.21.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.21.2" xmlns:="http://www.w3.org/1999/xhtml">Unsupervised discretization methods only use the variable’s distribution to determine the limits of the contiguous bins. </span><span class="koboSpan" id="kobo.21.3" xmlns:="http://www.w3.org/1999/xhtml">On the other hand, supervised methods use target information to create </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1" xmlns:="http://www.w3.org/1999/xhtml">the intervals.</span></span></p>
<p><span class="koboSpan" id="kobo.23.1" xmlns:="http://www.w3.org/1999/xhtml">In this chapter, we will discuss widely used supervised and unsupervised discretization procedures that are available in established open source libraries. </span><span class="koboSpan" id="kobo.23.2" xmlns:="http://www.w3.org/1999/xhtml">Among these, we will cover equal-width, equal-frequency, arbitrary, k-means, and decision tree-based discretization. </span><span class="koboSpan" id="kobo.23.3" xmlns:="http://www.w3.org/1999/xhtml">More elaborate methods, such as ChiMerge and CAIM, are out of the scope of this chapter, as their implementation is not yet open </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1" xmlns:="http://www.w3.org/1999/xhtml">source available.</span></span></p>
<p><span class="koboSpan" id="kobo.25.1" xmlns:="http://www.w3.org/1999/xhtml">This chapter contains the </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1" xmlns:="http://www.w3.org/1999/xhtml">following recipes:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.27.1" xmlns:="http://www.w3.org/1999/xhtml">Performing </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1" xmlns:="http://www.w3.org/1999/xhtml">equal-width discretization</span></span></li>
<li><span class="koboSpan" id="kobo.29.1" xmlns:="http://www.w3.org/1999/xhtml">Implementing </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1" xmlns:="http://www.w3.org/1999/xhtml">equal-frequency discretization</span></span></li>
<li><span class="koboSpan" id="kobo.31.1" xmlns:="http://www.w3.org/1999/xhtml">Discretizing the variable into </span><span class="No-Break"><span class="koboSpan" id="kobo.32.1" xmlns:="http://www.w3.org/1999/xhtml">arbitrary intervals</span></span></li>
<li><span class="koboSpan" id="kobo.33.1" xmlns:="http://www.w3.org/1999/xhtml">Performing discretization with </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1" xmlns:="http://www.w3.org/1999/xhtml">k-means clustering</span></span></li>
<li><span class="koboSpan" id="kobo.35.1" xmlns:="http://www.w3.org/1999/xhtml">Implementing </span><span class="No-Break"><span class="koboSpan" id="kobo.36.1" xmlns:="http://www.w3.org/1999/xhtml">feature binarization</span></span></li>
<li><span class="koboSpan" id="kobo.37.1" xmlns:="http://www.w3.org/1999/xhtml">Using decision trees </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1" xmlns:="http://www.w3.org/1999/xhtml">for discretization</span></span><a id="_idTextAnchor520"/></li>
</ul>
<h1 id="_idParaDest-121"><a id="_idTextAnchor521"/><span class="koboSpan" id="kobo.39.1" xmlns:="http://www.w3.org/1999/xhtml">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.40.1" xmlns:="http://www.w3.org/1999/xhtml">In this chapter, we will use the numerical computing libraries </span><strong class="source-inline"><span class="koboSpan" id="kobo.41.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.42.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.43.1" xmlns:="http://www.w3.org/1999/xhtml">numpy</span></strong><span class="koboSpan" id="kobo.44.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.45.1" xmlns:="http://www.w3.org/1999/xhtml">matplotlib</span></strong><span class="koboSpan" id="kobo.46.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.47.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.48.1" xmlns:="http://www.w3.org/1999/xhtml">, and</span><a id="_idTextAnchor522"/> <strong class="source-inline"><span class="koboSpan" id="kobo.49.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.50.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.50.2" xmlns:="http://www.w3.org/1999/xhtml">We will also use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.51.1" xmlns:="http://www.w3.org/1999/xhtml">yellowbrick</span></strong><span class="koboSpan" id="kobo.52.1" xmlns:="http://www.w3.org/1999/xhtml"> Python open source library, which you can install </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1" xmlns:="http://www.w3.org/1999/xhtml">with </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.54.1" xmlns:="http://www.w3.org/1999/xhtml">pip</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.55.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.56.1" xmlns:="http://www.w3.org/1999/xhtml">
 pip install yellowbrick</span></pre> <p><span class="koboSpan" id="kobo.57.1" xmlns:="http://www.w3.org/1999/xhtml">For more details about </span><strong class="source-inline"><span class="koboSpan" id="kobo.58.1" xmlns:="http://www.w3.org/1999/xhtml">yellowbrick</span></strong><span class="koboSpan" id="kobo.59.1" xmlns:="http://www.w3.org/1999/xhtml">, visit the </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1" xmlns:="http://www.w3.org/1999/xhtml">documentation here:</span></span></p>
<p><span class="No-Break"><span class="koboSpan" id="kobo.61.1" xmlns:="http://www.w3.org/1999/xhtml">https://www.scikit-yb.org/en/latest/index.html</span></span><a id="_idTextAnchor523"/></p>
<h1 id="_idParaDest-122"><a id="_idTextAnchor524"/><span class="koboSpan" id="kobo.62.1" xmlns:="http://www.w3.org/1999/xhtml">Performing equal-width discretization</span></h1>
<p><span class="koboSpan" id="kobo.63.1" xmlns:="http://www.w3.org/1999/xhtml">Equal-width</span><a id="_idTextAnchor525"/><span class="koboSpan" id="kobo.64.1" xmlns:="http://www.w3.org/1999/xhtml"> discretization</span><a id="_idIndexMarker277"/><span class="koboSpan" id="kobo.65.1" xmlns:="http://www.w3.org/1999/xhtml"> consists of dividing the range of</span><a id="_idIndexMarker278"/><span class="koboSpan" id="kobo.66.1" xmlns:="http://www.w3.org/1999/xhtml"> observed values for a variable into </span><em class="italic"><span class="koboSpan" id="kobo.67.1" xmlns:="http://www.w3.org/1999/xhtml">k</span></em><span class="koboSpan" id="kobo.68.1" xmlns:="http://www.w3.org/1999/xhtml"> equally sized intervals, where </span><em class="italic"><span class="koboSpan" id="kobo.69.1" xmlns:="http://www.w3.org/1999/xhtml">k</span></em><span class="koboSpan" id="kobo.70.1" xmlns:="http://www.w3.org/1999/xhtml"> is supplied by the user. </span><span class="koboSpan" id="kobo.70.2" xmlns:="http://www.w3.org/1999/xhtml">The interval width for the </span><em class="italic"><span class="koboSpan" id="kobo.71.1" xmlns:="http://www.w3.org/1999/xhtml">X</span></em><span class="koboSpan" id="kobo.72.1" xmlns:="http://www.w3.org/1999/xhtml"> variable is given by </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1" xmlns:="http://www.w3.org/1999/xhtml">the followin</span><a id="_idTextAnchor526"/><span class="koboSpan" id="kobo.74.1" xmlns:="http://www.w3.org/1999/xhtml">g:</span></span></p>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.75.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;W&lt;/mi&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;d&lt;/mi&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;t&lt;/mi&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;h&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;M&lt;/mi&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;x&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;X&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;M&lt;/mi&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;X&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mi mathvariant=&quot;bold-italic&quot;&gt;k&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/20.png" style="vertical-align:-0.398em;height:1.510em;width:9.768em"/></span></p>
<p><span class="koboSpan" id="kobo.76.1" xmlns:="http://www.w3.org/1999/xhtml">Then, if the </span><a id="_idIndexMarker279"/><span class="koboSpan" id="kobo.77.1" xmlns:="http://www.w3.org/1999/xhtml">values of the variable vary between 0 and 100, we can create five bins like this: </span><em class="italic"><span class="koboSpan" id="kobo.78.1" xmlns:="http://www.w3.org/1999/xhtml">width = (100-0) / 5 = 20</span></em><span class="koboSpan" id="kobo.79.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.79.2" xmlns:="http://www.w3.org/1999/xhtml">The bins will be 0–20, 20–40, 40–60, and 80–100. </span><span class="koboSpan" id="kobo.79.3" xmlns:="http://www.w3.org/1999/xhtml">The first and final bins (0–20 and 80–100) can be expanded to accommodate values smaller than 0 or greater than 100 by extending the limits to minus and </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1" xmlns:="http://www.w3.org/1999/xhtml">plus infinity.</span></span></p>
<p><span class="koboSpan" id="kobo.81.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will carry out equal-width discretization using </span><strong class="source-inline"><span class="koboSpan" id="kobo.82.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.83.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.84.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.85.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.87.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engi</span><a id="_idTextAnchor527"/><a id="_idTextAnchor528"/><span class="koboSpan" id="kobo.88.1" xmlns:="http://www.w3.org/1999/xhtml">ne</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.89.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-123"><a id="_idTextAnchor529"/><span class="koboSpan" id="kobo.90.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.91.1" xmlns:="http://www.w3.org/1999/xhtml">First, le</span><a id="_idTextAnchor530"/><span class="koboSpan" id="kobo.92.1" xmlns:="http://www.w3.org/1999/xhtml">t’s import the necessary Python libraries and get the </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1" xmlns:="http://www.w3.org/1999/xhtml">dataset ready:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.94.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1" xmlns:="http://www.w3.org/1999/xhtml">and functions:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.96.1" xmlns:="http://www.w3.org/1999/xhtml">
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split</span></pre></li> <li><span class="koboSpan" id="kobo.97.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the predictor and target variables of the California </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1" xmlns:="http://www.w3.org/1999/xhtml">housing dataset:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.99.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.100.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.101.1" xmlns:="http://www.w3.org/1999/xhtml">To avoid data leakage, we will find the intervals’ limits by using the variables in the train set. </span><span class="koboSpan" id="kobo.101.2" xmlns:="http://www.w3.org/1999/xhtml">Then, we will use these limits to discretize the variables in train and </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1" xmlns:="http://www.w3.org/1999/xhtml">test sets.</span></span></p>
<ol>
<li value="3"><span class="koboSpan" id="kobo.103.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s divide the data into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.105.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.106.1" xmlns:="http://www.w3.org/1999/xhtml">Next, we will divide the continuous </span><strong class="source-inline"><span class="koboSpan" id="kobo.107.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.108.1" xmlns:="http://www.w3.org/1999/xhtml"> variable into 10 intervals using </span><strong class="source-inline"><span class="koboSpan" id="kobo.109.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.110.1" xmlns:="http://www.w3.org/1999/xhtml"> and the formula described at the beginning of </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1" xmlns:="http://www.w3.org/1999/xhtml">the recipe.</span></span></p></li> <li><span class="koboSpan" id="kobo.112.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s capture the minimum and maximum values </span><span class="No-Break"><span class="koboSpan" id="kobo.113.1" xmlns:="http://www.w3.org/1999/xhtml">of </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.114.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.115.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.116.1" xmlns:="http://www.w3.org/1999/xhtml">
min_value = int(X_train["HouseAge"].min())
max_value = int(X_train["HouseAge"].max())</span></pre></li> <li><span class="koboSpan" id="kobo.117.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s </span><a id="_idIndexMarker280"/><span class="koboSpan" id="kobo.118.1" xmlns:="http://www.w3.org/1999/xhtml">determine the interval width, which is the variable’s value range divided by the number </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1" xmlns:="http://www.w3.org/1999/xhtml">of bins:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.120.1" xmlns:="http://www.w3.org/1999/xhtml">
width = int((max_value - min_value) / 10)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.121.1" xmlns:="http://www.w3.org/1999/xhtml">If we execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.122.1" xmlns:="http://www.w3.org/1999/xhtml">print(width)</span></strong><span class="koboSpan" id="kobo.123.1" xmlns:="http://www.w3.org/1999/xhtml">, we will obtain </span><strong class="source-inline"><span class="koboSpan" id="kobo.124.1" xmlns:="http://www.w3.org/1999/xhtml">5</span></strong><span class="koboSpan" id="kobo.125.1" xmlns:="http://www.w3.org/1999/xhtml">, which is the size of </span><span class="No-Break"><span class="koboSpan" id="kobo.126.1" xmlns:="http://www.w3.org/1999/xhtml">the intervals.</span></span></p></li> <li><span class="koboSpan" id="kobo.127.1" xmlns:="http://www.w3.org/1999/xhtml">No</span><a id="_idTextAnchor531"/><span class="koboSpan" id="kobo.128.1" xmlns:="http://www.w3.org/1999/xhtml">w we need to define the interval limits and store them in </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1" xmlns:="http://www.w3.org/1999/xhtml">a list:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.130.1" xmlns:="http://www.w3.org/1999/xhtml">
interval_limits = [i for i in range(
    min_value, max_value, width)]</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.131.1" xmlns:="http://www.w3.org/1999/xhtml">If we now execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.132.1" xmlns:="http://www.w3.org/1999/xhtml">print(interval_limits)</span></strong><span class="koboSpan" id="kobo.133.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see the </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1" xmlns:="http://www.w3.org/1999/xhtml">interval limits:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.135.1" xmlns:="http://www.w3.org/1999/xhtml">[1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51]</span></strong></pre></li> <li><span class="koboSpan" id="kobo.136.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s expand the limits of the first and last intervals to accommodate smaller or greater values that we could find in the test set or in future </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1" xmlns:="http://www.w3.org/1999/xhtml">data sources:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.138.1" xmlns:="http://www.w3.org/1999/xhtml">
interval_limits[0] = -np.inf
interval_limits[-1] = np.inf</span></pre></li> <li><span class="koboSpan" id="kobo.139.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s make a copy of the DataFrames so we don’t overwrite the original ones, which we will need for later steps in </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1" xmlns:="http://www.w3.org/1999/xhtml">the recipe:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.141.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t = X_train.copy()
test_t = X_test.copy()</span></pre></li> <li><span class="koboSpan" id="kobo.142.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s sort </span><a id="_idIndexMarker281"/><span class="koboSpan" id="kobo.143.1" xmlns:="http://www.w3.org/1999/xhtml">the </span><strong class="source-inline"><span class="koboSpan" id="kobo.144.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.145.1" xmlns:="http://www.w3.org/1999/xhtml"> variable into the intervals that we defined in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.146.1" xmlns:="http://www.w3.org/1999/xhtml">step 6</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.147.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.148.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t["HouseAge_disc"] = pd.cut(
    x=X_train["HouseAge"],
    bins=interval_limits,
    include_lowest=True)
test_t["HouseAge_disc"] = pd.cut(
    x=X_test["HouseAge"],
    bins=interval_limits,
    include_lowest=True)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.149.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.150.1" xmlns:="http://www.w3.org/1999/xhtml">We have set </span><strong class="source-inline"><span class="koboSpan" id="kobo.151.1" xmlns:="http://www.w3.org/1999/xhtml">include_lowest=True</span></strong><span class="koboSpan" id="kobo.152.1" xmlns:="http://www.w3.org/1999/xhtml"> to include the lowest value in the first interval. </span><span class="koboSpan" id="kobo.152.2" xmlns:="http://www.w3.org/1999/xhtml">Note that we used the train set to find the intervals and then used those limits to sort the variable in </span><span class="No-Break"><span class="koboSpan" id="kobo.153.1" xmlns:="http://www.w3.org/1999/xhtml">both datasets.</span></span></p>
<ol>
<li value="10"><span class="koboSpan" id="kobo.154.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s print the top </span><strong class="source-inline"><span class="koboSpan" id="kobo.155.1" xmlns:="http://www.w3.org/1999/xhtml">5</span></strong><span class="koboSpan" id="kobo.156.1" xmlns:="http://www.w3.org/1999/xhtml"> observations of the discretized and </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1" xmlns:="http://www.w3.org/1999/xhtml">original variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.158.1" xmlns:="http://www.w3.org/1999/xhtml">
print(train_t[["HouseAge", "HouseAge_disc"]].head(5))</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.159.1" xmlns:="http://www.w3.org/1999/xhtml">In the foll</span><a id="_idTextAnchor532"/><span class="koboSpan" id="kobo.160.1" xmlns:="http://www.w3.org/1999/xhtml">owing output, we can see that the </span><strong class="source-inline"><span class="koboSpan" id="kobo.161.1" xmlns:="http://www.w3.org/1999/xhtml">52</span></strong><span class="koboSpan" id="kobo.162.1" xmlns:="http://www.w3.org/1999/xhtml"> value was allocated to the 46–infinite interval, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.163.1" xmlns:="http://www.w3.org/1999/xhtml">43</span></strong><span class="koboSpan" id="kobo.164.1" xmlns:="http://www.w3.org/1999/xhtml"> value was allocated to the 41–46 interval, and </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1" xmlns:="http://www.w3.org/1999/xhtml">so on:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.166.1" xmlns:="http://www.w3.org/1999/xhtml">         HouseAge HouseAge_disc</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.167.1" xmlns:="http://www.w3.org/1999/xhtml">1989         52.0   (46.0, inf]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.168.1" xmlns:="http://www.w3.org/1999/xhtml">256           43.0  (41.0, 46.0]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.169.1" xmlns:="http://www.w3.org/1999/xhtml">7887         17.0  (16.0, 21.0]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.170.1" xmlns:="http://www.w3.org/1999/xhtml">4581</span></strong><strong class="bold"><span class="koboSpan" id="kobo.171.1" xmlns:="http://www.w3.org/1999/xhtml">         17.0  (16.0, 21.0]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.172.1" xmlns:="http://www.w3.org/1999/xhtml">1993         50.0   (46.0, inf]</span></strong></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.173.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.174.1" xmlns:="http://www.w3.org/1999/xhtml">The parentheses and brackets in the intervals indicate whether a value is included in the interval or not. </span><span class="koboSpan" id="kobo.174.2" xmlns:="http://www.w3.org/1999/xhtml">For example, the (41, 46] interval contains all values greater than 41 and smaller than or equal </span><span class="No-Break"><span class="koboSpan" id="kobo.175.1" xmlns:="http://www.w3.org/1999/xhtml">to 46.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.176.1" xmlns:="http://www.w3.org/1999/xhtml">Equal-width discretization</span><a id="_idIndexMarker282"/><span class="koboSpan" id="kobo.177.1" xmlns:="http://www.w3.org/1999/xhtml"> allocates a different number of observations to </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1" xmlns:="http://www.w3.org/1999/xhtml">each i</span><a id="_idTextAnchor533"/><span class="koboSpan" id="kobo.179.1" xmlns:="http://www.w3.org/1999/xhtml">nterval.</span></span></p>
<ol>
<li value="11"><span class="koboSpan" id="kobo.180.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s make a bar plot with the proportion of observations across the intervals of  </span><strong class="source-inline"><span class="koboSpan" id="kobo.181.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.182.1" xmlns:="http://www.w3.org/1999/xhtml"> in the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.183.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.184.1" xmlns:="http://www.w3.org/1999/xhtml">
t1 = train_t["HouseAge_disc"].value_counts(
    normalize=True, sort=False)
t2 = test_t["HouseAge_disc"].value_counts(
    normalize=True, sort=False)
tmp = pd.concat([t1, t2], axis=1)
tmp.columns = ["train", "test"]
tmp.plot.bar(figsize=(8, 5))
plt.xticks(rotation=45)
plt.ylabel("Number of observations per bin")
plt.xlabel('Discretized HouseAge')
plt.title("HouseAge")
plt.show()</span></pre><p class="list-inset"><a id="_idTextAnchor534"/><span class="koboSpan" id="kobo.185.1" xmlns:="http://www.w3.org/1999/xhtml">In the following output, we can see that the proportion of observations per interval is approximately the same in the train and test sets, but different </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1" xmlns:="http://www.w3.org/1999/xhtml">across inter</span><a id="_idTextAnchor535"/><span class="koboSpan" id="kobo.187.1" xmlns:="http://www.w3.org/1999/xhtml">vals:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer064">
<span class="koboSpan" id="kobo.188.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.1 – The proportion of observations per interval after the discretization" src="image/B22396_04_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.189.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.1 – The proportion of observations per interval after the discretization</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.190.1" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.191.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.192.1" xmlns:="http://www.w3.org/1999/xhtml">, we </span><a id="_idIndexMarker283"/><span class="koboSpan" id="kobo.193.1" xmlns:="http://www.w3.org/1999/xhtml">can perform equal-width discretization in fewer lines of code and for many variables at </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1" xmlns:="http://www.w3.org/1999/xhtml">a time.</span></span></p>
<ol>
<li value="12"><span class="koboSpan" id="kobo.195.1" xmlns:="http://www.w3.org/1999/xhtml">First, let’s import </span><span class="No-Break"><span class="koboSpan" id="kobo.196.1" xmlns:="http://www.w3.org/1999/xhtml">the discretizer:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.197.1" xmlns:="http://www.w3.org/1999/xhtml">
from feature_engine.discretisation import EqualWidthDiscretiser</span><a id="_idTextAnchor536"/></pre></li> <li><span class="koboSpan" id="kobo.198.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up the discretizer to sort three continuous variables into </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1" xmlns:="http://www.w3.org/1999/xhtml">eight intervals:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.200.1" xmlns:="http://www.w3.org/1999/xhtml">
variables = ['MedInc', 'HouseAge', 'AveRooms']
disc = EqualWidthDiscretiser(
    bins=8, variables=variables)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.201.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.202.1" xmlns:="http://www.w3.org/1999/xhtml">EqualWidthDiscretiser()</span></strong><span class="koboSpan" id="kobo.203.1" xmlns:="http://www.w3.org/1999/xhtml"> returns an integer indicating w</span><a id="_idTextAnchor537"/><span class="koboSpan" id="kobo.204.1" xmlns:="http://www.w3.org/1999/xhtml">hether the value was sorted into the first, second, or eighth bin by default. </span><span class="koboSpan" id="kobo.204.2" xmlns:="http://www.w3.org/1999/xhtml">That is the equivalent of ordinal encoding, which we described in the </span><em class="italic"><span class="koboSpan" id="kobo.205.1" xmlns:="http://www.w3.org/1999/xhtml">Replacing categories with ordinal numbers</span></em><span class="koboSpan" id="kobo.206.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe of </span><a href="B22396_02.xhtml#_idTextAnchor182"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.207.1" xmlns:="http://www.w3.org/1999/xhtml">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.208.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><em class="italic"><span class="koboSpan" id="kobo.209.1" xmlns:="http://www.w3.org/1999/xhtml">Encoding Categorical Variables</span></em><span class="koboSpan" id="kobo.210.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.210.2" xmlns:="http://www.w3.org/1999/xhtml">To carry out a different encoding with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.211.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.212.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.213.1" xmlns:="http://www.w3.org/1999/xhtml">category</span></strong> <strong class="source-inline"><span class="koboSpan" id="kobo.214.1" xmlns:="http://www.w3.org/1999/xhtml">encoders </span></strong><span class="koboSpan" id="kobo.215.1" xmlns:="http://www.w3.org/1999/xhtml">Python libraries, cast the returned variables as objects by setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.216.1" xmlns:="http://www.w3.org/1999/xhtml">return_object</span></strong><span class="koboSpan" id="kobo.217.1" xmlns:="http://www.w3.org/1999/xhtml"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.218.1" xmlns:="http://www.w3.org/1999/xhtml">True</span></strong><span class="koboSpan" id="kobo.219.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.219.2" xmlns:="http://www.w3.org/1999/xhtml">Alternatively, make the transformer return the interval limits by setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.220.1" xmlns:="http://www.w3.org/1999/xhtml">return_boundaries</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.221.1" xmlns:="http://www.w3.org/1999/xhtml">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.222.1" xmlns:="http://www.w3.org/1999/xhtml">True</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.223.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="14"><span class="koboSpan" id="kobo.224.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit the </span><a id="_idIndexMarker284"/><span class="koboSpan" id="kobo.225.1" xmlns:="http://www.w3.org/1999/xhtml">discretizer to the train set so that it learns the cut points for </span><span class="No-Break"><span class="koboSpan" id="kobo.226.1" xmlns:="http://www.w3.org/1999/xhtml">each variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.227.1" xmlns:="http://www.w3.org/1999/xhtml">
disc.fit(X_train)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.228.1" xmlns:="http://www.w3.org/1999/xhtml">After fitting, we can inspect the cut points in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.229.1" xmlns:="http://www.w3.org/1999/xhtml">binner_dict_</span></strong><span class="koboSpan" id="kobo.230.1" xmlns:="http://www.w3.org/1999/xhtml"> attribute by </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1" xmlns:="http://www.w3.org/1999/xhtml">executing </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.232.1" xmlns:="http://www.w3.org/1999/xhtml">print(disc.binner_dict_)</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.233.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.234.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.235.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.236.1" xmlns:="http://www.w3.org/1999/xhtml"> will automatically extend the limits of the lower and upper intervals to infinite to accommodate potential outliers in </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1" xmlns:="http://www.w3.org/1999/xhtml">future data.</span></span></p>
<ol>
<li value="15"><span class="koboSpan" id="kobo.238.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s discretize the variables in the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.240.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t = disc.transform(X_train)
test_t = disc.transform(X_test)</span></pre><p class="list-inset"><strong class="source-inline"><span class="koboSpan" id="kobo.241.1" xmlns:="http://www.w3.org/1999/xhtml">EqualWidthDiscretiser()</span></strong><span class="koboSpan" id="kobo.242.1" xmlns:="http://www.w3.org/1999/xhtml"> returns a DataFrame where the selected variables are discretized. </span><span class="koboSpan" id="kobo.242.2" xmlns:="http://www.w3.org/1999/xhtml">If we run </span><strong class="source-inline"><span class="koboSpan" id="kobo.243.1" xmlns:="http://www.w3.org/1999/xhtml">test_t.head()</span></strong><span class="koboSpan" id="kobo.244.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><a id="_idTextAnchor538"/><span class="koboSpan" id="kobo.245.1" xmlns:="http://www.w3.org/1999/xhtml">we will see the following output where the original values of </span><strong class="source-inline"><span class="koboSpan" id="kobo.246.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.247.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.248.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.249.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.250.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms</span></strong><span class="koboSpan" id="kobo.251.1" xmlns:="http://www.w3.org/1999/xhtml"> are replaced by the </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1" xmlns:="http://www.w3.org/1999/xhtml">interval nu</span><a id="_idTextAnchor539"/><span class="koboSpan" id="kobo.253.1" xmlns:="http://www.w3.org/1999/xhtml">mbers:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer065">
<span class="koboSpan" id="kobo.254.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.2 – A DataFrame with three discretized variables: HouseAge, MedInc, and AveRooms" src="image/B22396_04_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.255.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.2 – A DataFrame with three discretized variables: HouseAge, MedInc, and AveRooms</span></p>
<ol>
<li value="16"><span class="koboSpan" id="kobo.256.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s</span><a id="_idIndexMarker285"/><span class="koboSpan" id="kobo.257.1" xmlns:="http://www.w3.org/1999/xhtml"> make bar plots with the proportion of observations per interval to better understand the effect of </span><span class="No-Break"><span class="koboSpan" id="kobo.258.1" xmlns:="http://www.w3.org/1999/xhtml">equal-width discretization:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.259.1" xmlns:="http://www.w3.org/1999/xhtml">
plt.figure(figsize=(6, 12), constrained_layout=True)
for i in range(3):
    # location of plot in figure
    ax = plt.subplot(3, 1, i + 1)
    # the variable to plot
    var = variables[i]
    # determine proportion of observations per bin
    t1 = train_t[var].value_counts(normalize=True,
        sort=False)
    t2 = test_t[var].value_counts(normalize=True,
        sort=False)
    # concatenate proportions
    tmp = pd.concat([t1, t2], axis=1)
    tmp.columns = ['train', 'test']
    # sort the intervals
    tmp.sort_index(inplace=True)
    # make plot
    tmp.plot.bar(ax=ax)
    plt.xticks(rotation=0)
    plt.ylabel('Observations per bin')
    ax.set_title(var)
plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.260.1" xmlns:="http://www.w3.org/1999/xhtml">The in</span><a id="_idTextAnchor540"/><span class="koboSpan" id="kobo.261.1" xmlns:="http://www.w3.org/1999/xhtml">tervals contain</span><a id="_idIndexMarker286"/><span class="koboSpan" id="kobo.262.1" xmlns:="http://www.w3.org/1999/xhtml"> a different number of observations, as shown in the </span><span class="No-Break"><span class="koboSpan" id="kobo.263.1" xmlns:="http://www.w3.org/1999/xhtml">following plots:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer066">
<span class="koboSpan" id="kobo.264.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.3 – Bar plots with the proportion of observations per interval after the discretization" src="image/B22396_04_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.265.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.3 – Bar plots with the proportion of observations per interval after the discretization</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.266.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s </span><a id="_idIndexMarker287"/><span class="koboSpan" id="kobo.267.1" xmlns:="http://www.w3.org/1999/xhtml">implement equal-width discretization </span><span class="No-Break"><span class="koboSpan" id="kobo.268.1" xmlns:="http://www.w3.org/1999/xhtml">with scikit-learn.</span></span></p>
<ol>
<li value="17"><span class="koboSpan" id="kobo.269.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the classes </span><span class="No-Break"><span class="koboSpan" id="kobo.270.1" xmlns:="http://www.w3.org/1999/xhtml">from scikit-learn:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.271.1" xmlns:="http://www.w3.org/1999/xhtml">
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import kBinsDiscretiz</span><a id="_idTextAnchor541"/><span class="koboSpan" id="kobo.272.1" xmlns:="http://www.w3.org/1999/xhtml">er</span></pre></li> <li><span class="koboSpan" id="kobo.273.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up an equal-width discretizer by setting its </span><strong class="source-inline"><span class="koboSpan" id="kobo.274.1" xmlns:="http://www.w3.org/1999/xhtml">strategy</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.275.1" xmlns:="http://www.w3.org/1999/xhtml">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.276.1" xmlns:="http://www.w3.org/1999/xhtml">uniform</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.277.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.278.1" xmlns:="http://www.w3.org/1999/xhtml">
disc = KBinsDiscretizer(
    n_bins=8, encode='ordinal', strategy='uniform')</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.279.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.280.1" xmlns:="http://www.w3.org/1999/xhtml">KBinsDiscretiser()</span></strong><span class="koboSpan" id="kobo.281.1" xmlns:="http://www.w3.org/1999/xhtml"> can return the bins as integers by setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.282.1" xmlns:="http://www.w3.org/1999/xhtml">encoding</span></strong><span class="koboSpan" id="kobo.283.1" xmlns:="http://www.w3.org/1999/xhtml"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.284.1" xmlns:="http://www.w3.org/1999/xhtml">'ordinal'</span></strong><span class="koboSpan" id="kobo.285.1" xmlns:="http://www.w3.org/1999/xhtml"> or one-hot encoded by setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.286.1" xmlns:="http://www.w3.org/1999/xhtml">encoding</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.287.1" xmlns:="http://www.w3.org/1999/xhtml">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.288.1" xmlns:="http://www.w3.org/1999/xhtml">'onehot-dense'</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.289.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="19"><span class="koboSpan" id="kobo.290.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s use </span><strong class="source-inline"><span class="koboSpan" id="kobo.291.1" xmlns:="http://www.w3.org/1999/xhtml">ColumnTransformer()</span></strong><span class="koboSpan" id="kobo.292.1" xmlns:="http://www.w3.org/1999/xhtml"> to restrict the discretization to the selected variables from </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.293.1" xmlns:="http://www.w3.org/1999/xhtml">step 13</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.294.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code">
<strong class="source-inline"><span class="koboSpan" id="kobo.295.1" xmlns:="http://www.w3.org/1999/xhtml">ct = ColumnTransformer(</span></strong>
<strong class="source-inline"><span class="koboSpan" id="kobo.296.1" xmlns:="http://www.w3.org/1999/xhtml">    [("discretizer", disc, variables)],</span></strong>
<strong class="source-inline"><span class="koboSpan" id="kobo.297.1" xmlns:="http://www.w3.org/1999/xhtml">    remainder="passthrough",</span></strong>
<strong class="source-inline"><span class="koboSpan" id="kobo.298.1" xmlns:="http://www.w3.org/1999/xhtml">).set_output(transform="pandas")</span></strong></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.299.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.300.1" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.301.1" xmlns:="http://www.w3.org/1999/xhtml">remainder</span></strong><span class="koboSpan" id="kobo.302.1" xmlns:="http://www.w3.org/1999/xhtml"> set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.303.1" xmlns:="http://www.w3.org/1999/xhtml">passthrough</span></strong><span class="koboSpan" id="kobo.304.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.305.1" xmlns:="http://www.w3.org/1999/xhtml">ColumnTransformer()</span></strong><span class="koboSpan" id="kobo.306.1" xmlns:="http://www.w3.org/1999/xhtml"> returns all the variables in the input DataFrame after the transformation. </span><span class="koboSpan" id="kobo.306.2" xmlns:="http://www.w3.org/1999/xhtml">To return only the transformed variables, set </span><strong class="source-inline"><span class="koboSpan" id="kobo.307.1" xmlns:="http://www.w3.org/1999/xhtml">remainder</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.308.1" xmlns:="http://www.w3.org/1999/xhtml">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.309.1" xmlns:="http://www.w3.org/1999/xhtml">drop</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.310.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="20"><span class="koboSpan" id="kobo.311.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit the discretizer to the train set so that it learns the </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1" xmlns:="http://www.w3.org/1999/xhtml">interval limits:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.313.1" xmlns:="http://www.w3.org/1999/xhtml">
ct.fit(X_train)</span></pre></li> <li><span class="koboSpan" id="kobo.314.1" xmlns:="http://www.w3.org/1999/xhtml">Finall</span><a id="_idTextAnchor542"/><span class="koboSpan" id="kobo.315.1" xmlns:="http://www.w3.org/1999/xhtml">y, let’s </span><a id="_idIndexMarker288"/><span class="koboSpan" id="kobo.316.1" xmlns:="http://www.w3.org/1999/xhtml">discretize the selected variables in the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.318.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t = ct.transform(X_train)
test_t = ct.transform(X_test)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.319.1" xmlns:="http://www.w3.org/1999/xhtml">We can inspect the cut points learned by the transformer by </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1" xmlns:="http://www.w3.org/1999/xhtml">executing </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.321.1" xmlns:="http://www.w3.org/1999/xhtml">ct.named_transformers_["discretizer"].bin_edges_</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.322.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.323.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.324.1" xmlns:="http://www.w3.org/1999/xhtml">ColumnTransformer()</span></strong><span class="koboSpan" id="kobo.325.1" xmlns:="http://www.w3.org/1999/xhtml"> will append </span><strong class="source-inline"><span class="koboSpan" id="kobo.326.1" xmlns:="http://www.w3.org/1999/xhtml">discretize</span></strong><span class="koboSpan" id="kobo.327.1" xmlns:="http://www.w3.org/1999/xhtml"> to the variables that were discretized and </span><strong class="source-inline"><span class="koboSpan" id="kobo.328.1" xmlns:="http://www.w3.org/1999/xhtml">remainder</span></strong><span class="koboSpan" id="kobo.329.1" xmlns:="http://www.w3.org/1999/xhtml"> to those that were </span><span class="No-Break"><span class="koboSpan" id="kobo.330.1" xmlns:="http://www.w3.org/1999/xhtml">not modified.</span></span></p>
<p><span class="koboSpan" id="kobo.331.1" xmlns:="http://www.w3.org/1999/xhtml">We can check the output by </span><span class="No-Break"><span class="koboSpan" id="kobo.332.1" xmlns:="http://www.w3.org/1999/xhtml">executing </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.333.1" xmlns:="http://www.w3.org/1999/xhtml">test_</span><a id="_idTextAnchor543"/><a id="_idTextAnchor544"/><span class="koboSpan" id="kobo.334.1" xmlns:="http://www.w3.org/1999/xhtml">t.head()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.335.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-124"><a id="_idTextAnchor545"/><span class="koboSpan" id="kobo.336.1" xmlns:="http://www.w3.org/1999/xhtml">How it works…</span></h2>
<p><span class="koboSpan" id="kobo.337.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we sorted the variable values into equidistant intervals. </span><span class="koboSpan" id="kobo.337.2" xmlns:="http://www.w3.org/1999/xhtml">To perform discretization with </span><strong class="source-inline"><span class="koboSpan" id="kobo.338.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.339.1" xmlns:="http://www.w3.org/1999/xhtml">, we first found the maximum and minimum values of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.340.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.341.1" xmlns:="http://www.w3.org/1999/xhtml"> variable using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.342.1" xmlns:="http://www.w3.org/1999/xhtml">max()</span></strong><span class="koboSpan" id="kobo.343.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.344.1" xmlns:="http://www.w3.org/1999/xhtml">min()</span></strong><span class="koboSpan" id="kobo.345.1" xmlns:="http://www.w3.org/1999/xhtml"> methods. </span><span class="koboSpan" id="kobo.345.2" xmlns:="http://www.w3.org/1999/xhtml">Then, we estimated the interval width by dividing the value range by the number of arbitrary bins. </span><span class="koboSpan" id="kobo.345.3" xmlns:="http://www.w3.org/1999/xhtml">With the width and the minimum and maximum values, we determined the interval limits and stored them in a list. </span><span class="koboSpan" id="kobo.345.4" xmlns:="http://www.w3.org/1999/xhtml">We</span><a id="_idIndexMarker289"/><span class="koboSpan" id="kobo.346.1" xmlns:="http://www.w3.org/1999/xhtml"> used this list with pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.347.1" xmlns:="http://www.w3.org/1999/xhtml">cut()</span></strong><span class="koboSpan" id="kobo.348.1" xmlns:="http://www.w3.org/1999/xhtml"> to sort the variable values into </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1" xmlns:="http://www.w3.org/1999/xhtml">the intervals.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.350.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.351.1" xmlns:="http://www.w3.org/1999/xhtml">Pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.352.1" xmlns:="http://www.w3.org/1999/xhtml">cut()</span></strong><span class="koboSpan" id="kobo.353.1" xmlns:="http://www.w3.org/1999/xhtml"> sorts the variable into intervals of equal size by default. </span><span class="koboSpan" id="kobo.353.2" xmlns:="http://www.w3.org/1999/xhtml">It will extend the variable range by .1% on each side to include the minimum and maximum values. </span><span class="koboSpan" id="kobo.353.3" xmlns:="http://www.w3.org/1999/xhtml">The reason why we generated the intervals manually is to accommodate potentially smaller or larger values than those seen in the dataset in future data sources when we deploy </span><span class="No-Break"><span class="koboSpan" id="kobo.354.1" xmlns:="http://www.w3.org/1999/xhtml">our model.</span></span></p>
<p><span class="koboSpan" id="kobo.355.1" xmlns:="http://www.w3.org/1999/xhtml">After discretization, we normally treat the intervals as categorical values. </span><span class="koboSpan" id="kobo.355.2" xmlns:="http://www.w3.org/1999/xhtml">By default, pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.356.1" xmlns:="http://www.w3.org/1999/xhtml">cut()</span></strong><span class="koboSpan" id="kobo.357.1" xmlns:="http://www.w3.org/1999/xhtml"> returns the interval values as ordered integers, which is the equivalent of ordinal encoding. </span><span class="koboSpan" id="kobo.357.2" xmlns:="http://www.w3.org/1999/xhtml">Alternatively, we can return the interval limits by setting the </span><strong class="source-inline"><span class="koboSpan" id="kobo.358.1" xmlns:="http://www.w3.org/1999/xhtml">labels</span></strong><span class="koboSpan" id="kobo.359.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter </span><span class="No-Break"><span class="koboSpan" id="kobo.360.1" xmlns:="http://www.w3.org/1999/xhtml">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.361.1" xmlns:="http://www.w3.org/1999/xhtml">None</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.362.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.363.1" xmlns:="http://www.w3.org/1999/xhtml">To display the </span><a id="_idIndexMarker290"/><span class="koboSpan" id="kobo.364.1" xmlns:="http://www.w3.org/1999/xhtml">number of observations per interval, we created a bar plot. </span><span class="koboSpan" id="kobo.364.2" xmlns:="http://www.w3.org/1999/xhtml">We used the pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.365.1" xmlns:="http://www.w3.org/1999/xhtml">value_counts()</span></strong><span class="koboSpan" id="kobo.366.1" xmlns:="http://www.w3.org/1999/xhtml"> function to obtain the fraction of observations per interval, which returns the result in pandas Series, where the index is the interval and the counts are the values. </span><span class="koboSpan" id="kobo.366.2" xmlns:="http://www.w3.org/1999/xhtml">To plot these proportions, first, we concatenated the train and test set series using the pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.367.1" xmlns:="http://www.w3.org/1999/xhtml">concat()</span></strong><span class="koboSpan" id="kobo.368.1" xmlns:="http://www.w3.org/1999/xhtml">function in a DataFrame, and then we assigned the </span><strong class="source-inline"><span class="koboSpan" id="kobo.369.1" xmlns:="http://www.w3.org/1999/xhtml">train</span></strong><span class="koboSpan" id="kobo.370.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.371.1" xmlns:="http://www.w3.org/1999/xhtml">test</span></strong><span class="koboSpan" id="kobo.372.1" xmlns:="http://www.w3.org/1999/xhtml"> column names to it. </span><span class="koboSpan" id="kobo.372.2" xmlns:="http://www.w3.org/1999/xhtml">Finally, we used </span><strong class="source-inline"><span class="koboSpan" id="kobo.373.1" xmlns:="http://www.w3.org/1999/xhtml">plot.bar()</span></strong><span class="koboSpan" id="kobo.374.1" xmlns:="http://www.w3.org/1999/xhtml"> to display a bar plot. </span><span class="koboSpan" id="kobo.374.2" xmlns:="http://www.w3.org/1999/xhtml">We rotated the labels with Matplotlib’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.375.1" xmlns:="http://www.w3.org/1999/xhtml">xticks()</span></strong><span class="koboSpan" id="kobo.376.1" xmlns:="http://www.w3.org/1999/xhtml">function, and added the </span><em class="italic"><span class="koboSpan" id="kobo.377.1" xmlns:="http://www.w3.org/1999/xhtml">x</span></em><span class="koboSpan" id="kobo.378.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><em class="italic"><span class="koboSpan" id="kobo.379.1" xmlns:="http://www.w3.org/1999/xhtml">y</span></em><span class="koboSpan" id="kobo.380.1" xmlns:="http://www.w3.org/1999/xhtml"> legend with </span><strong class="source-inline"><span class="koboSpan" id="kobo.381.1" xmlns:="http://www.w3.org/1999/xhtml">xlabels()</span></strong><span class="koboSpan" id="kobo.382.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.383.1" xmlns:="http://www.w3.org/1999/xhtml">ylabel()</span></strong><span class="koboSpan" id="kobo.384.1" xmlns:="http://www.w3.org/1999/xhtml">, as well as the title </span><span class="No-Break"><span class="koboSpan" id="kobo.385.1" xmlns:="http://www.w3.org/1999/xhtml">with </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.386.1" xmlns:="http://www.w3.org/1999/xhtml">title()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.387.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.388.1" xmlns:="http://www.w3.org/1999/xhtml">To perform equal-width discretization with </span><strong class="source-inline"><span class="koboSpan" id="kobo.389.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.390.1" xmlns:="http://www.w3.org/1999/xhtml">, we </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1" xmlns:="http://www.w3.org/1999/xhtml">used </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.392.1" xmlns:="http://www.w3.org/1999/xhtml">EqualWidth</span></strong></span><strong class="source-inline"><span class="koboSpan" id="kobo.393.1" xmlns:="http://www.w3.org/1999/xhtml"> Discretiser()</span></strong><span class="koboSpan" id="kobo.394.1" xmlns:="http://www.w3.org/1999/xhtml">, which takes the number of bins and the variables to discretize as arguments. </span><span class="koboSpan" id="kobo.394.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.395.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.396.1" xmlns:="http://www.w3.org/1999/xhtml">, the discretizer learned the interval limits for each variable. </span><span class="koboSpan" id="kobo.396.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.397.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.398.1" xmlns:="http://www.w3.org/1999/xhtml">, it sorted the values into </span><span class="No-Break"><span class="koboSpan" id="kobo.399.1" xmlns:="http://www.w3.org/1999/xhtml">each bin.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.400.1" xmlns:="http://www.w3.org/1999/xhtml">EqualWidthDiscretiser()</span></strong><span class="koboSpan" id="kobo.401.1" xmlns:="http://www.w3.org/1999/xhtml"> returns the bins as sorted integers by default, which is the equivalent of ordinal encoding. </span><span class="koboSpan" id="kobo.401.2" xmlns:="http://www.w3.org/1999/xhtml">To follow up the discretization with any other encoding procedure available in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.402.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.403.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.404.1" xmlns:="http://www.w3.org/1999/xhtml">category encoders</span></strong><span class="koboSpan" id="kobo.405.1" xmlns:="http://www.w3.org/1999/xhtml"> libraries, we need to return the bins cast as objects by setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.406.1" xmlns:="http://www.w3.org/1999/xhtml">return_object</span></strong><span class="koboSpan" id="kobo.407.1" xmlns:="http://www.w3.org/1999/xhtml"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.408.1" xmlns:="http://www.w3.org/1999/xhtml">True</span></strong><span class="koboSpan" id="kobo.409.1" xmlns:="http://www.w3.org/1999/xhtml"> when we set up </span><span class="No-Break"><span class="koboSpan" id="kobo.410.1" xmlns:="http://www.w3.org/1999/xhtml">the transformer.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.411.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.412.1" xmlns:="http://www.w3.org/1999/xhtml">EqualWidthDiscretiser()</span></strong><span class="koboSpan" id="kobo.413.1" xmlns:="http://www.w3.org/1999/xhtml"> extends the values of the first and last interval to minus and plus infinity by default to automatically accommodate smaller and greater values than those seen in the </span><span class="No-Break"><span class="koboSpan" id="kobo.414.1" xmlns:="http://www.w3.org/1999/xhtml">training set.</span></span></p>
<p><span class="koboSpan" id="kobo.415.1" xmlns:="http://www.w3.org/1999/xhtml">We followed the discretization with bar plots to display the fraction of observations per interval for each of the transformed variables. </span><span class="koboSpan" id="kobo.415.2" xmlns:="http://www.w3.org/1999/xhtml">We could see that if the original variable was skewed, the bar plot was also skewed. </span><span class="koboSpan" id="kobo.415.3" xmlns:="http://www.w3.org/1999/xhtml">Note how some of the intervals of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.416.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.417.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.418.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms</span></strong><span class="koboSpan" id="kobo.419.1" xmlns:="http://www.w3.org/1999/xhtml"> variables, which had skewed distributions, contained very few observations. </span><span class="koboSpan" id="kobo.419.2" xmlns:="http://www.w3.org/1999/xhtml">In particular, even though we wanted to create eight bins for </span><strong class="source-inline"><span class="koboSpan" id="kobo.420.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms</span></strong><span class="koboSpan" id="kobo.421.1" xmlns:="http://www.w3.org/1999/xhtml">, there were only enough values to create five, and most values of the variables were allocated to the </span><span class="No-Break"><span class="koboSpan" id="kobo.422.1" xmlns:="http://www.w3.org/1999/xhtml">first interval.</span></span></p>
<p><span class="koboSpan" id="kobo.423.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, we </span><a id="_idTextAnchor546"/><span class="koboSpan" id="kobo.424.1" xmlns:="http://www.w3.org/1999/xhtml">discretized</span><a id="_idIndexMarker291"/><span class="koboSpan" id="kobo.425.1" xmlns:="http://www.w3.org/1999/xhtml"> three continuous variables into equal-width bins with </span><strong class="source-inline"><span class="koboSpan" id="kobo.426.1" xmlns:="http://www.w3.org/1999/xhtml">KBinsDiscretizer()</span></strong><span class="koboSpan" id="kobo.427.1" xmlns:="http://www.w3.org/1999/xhtml"> from scikit-learn. </span><span class="koboSpan" id="kobo.427.2" xmlns:="http://www.w3.org/1999/xhtml">To create equal-width bins, we set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.428.1" xmlns:="http://www.w3.org/1999/xhtml">strategy</span></strong><span class="koboSpan" id="kobo.429.1" xmlns:="http://www.w3.org/1999/xhtml"> argument to </span><strong class="source-inline"><span class="koboSpan" id="kobo.430.1" xmlns:="http://www.w3.org/1999/xhtml">uniform</span></strong><span class="koboSpan" id="kobo.431.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.431.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.432.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.433.1" xmlns:="http://www.w3.org/1999/xhtml">, the transformer learned the limits of the intervals, and with </span><strong class="source-inline"><span class="koboSpan" id="kobo.434.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.435.1" xmlns:="http://www.w3.org/1999/xhtml">, it sorted the values into </span><span class="No-Break"><span class="koboSpan" id="kobo.436.1" xmlns:="http://www.w3.org/1999/xhtml">each interval.</span></span></p>
<p><span class="koboSpan" id="kobo.437.1" xmlns:="http://www.w3.org/1999/xhtml">We used the </span><strong class="source-inline"><span class="koboSpan" id="kobo.438.1" xmlns:="http://www.w3.org/1999/xhtml">ColumnTransformer()</span></strong><span class="koboSpan" id="kobo.439.1" xmlns:="http://www.w3.org/1999/xhtml"> to restrict the discretization to the selected variables, setting the transform output to pandas to obtain a DataFrame after the transformation. </span><strong class="source-inline"><span class="koboSpan" id="kobo.440.1" xmlns:="http://www.w3.org/1999/xhtml">KBinsDiscretizer()</span></strong><span class="koboSpan" id="kobo.441.1" xmlns:="http://www.w3.org/1999/xhtml"> can return the intervals as ordinal numbers, as we had it do in the recipe, or as one-hot-encoded variables. </span><span class="koboSpan" id="kobo.441.2" xmlns:="http://www.w3.org/1999/xhtml">The behavior can be modified through the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.442.1" xmlns:="http://www.w3.org/1999/xhtml">encod</span><a id="_idTextAnchor547"/><a id="_idTextAnchor548"/><span class="koboSpan" id="kobo.443.1" xmlns:="http://www.w3.org/1999/xhtml">e</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.444.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter.</span></span></p>
<h2 id="_idParaDest-125"><a id="_idTextAnchor549"/><span class="koboSpan" id="kobo.445.1" xmlns:="http://www.w3.org/1999/xhtml">See also</span></h2>
<p><span class="koboSpan" id="kobo.446.1" xmlns:="http://www.w3.org/1999/xhtml">For a comparison of equal-width discretization with more sophisticated methods, see Dougherty J, Kohavi R, Sahami M. </span><em class="italic"><span class="koboSpan" id="kobo.447.1" xmlns:="http://www.w3.org/1999/xhtml">Supervised and unsupervised discretization of continuous features</span></em><span class="koboSpan" id="kobo.448.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.448.2" xmlns:="http://www.w3.org/1999/xhtml">In: Proceedings of the 12th international conference on machine learning. </span><span class="koboSpan" id="kobo.448.3" xmlns:="http://www.w3.org/1999/xhtml">San Francisco: Morgan Kaufma</span><a id="_idTextAnchor550"/><span class="koboSpan" id="kobo.449.1" xmlns:="http://www.w3.org/1999/xhtml">nn; 1995.</span><a id="_idTextAnchor551"/><a id="_idTextAnchor552"/> <span class="No-Break"><span class="koboSpan" id="kobo.450.1" xmlns:="http://www.w3.org/1999/xhtml">p. </span><span class="koboSpan" id="kobo.450.2" xmlns:="http://www.w3.org/1999/xhtml">194–202.</span></span></p>
<h1 id="_idParaDest-126"><a id="_idTextAnchor553"/><span class="koboSpan" id="kobo.451.1" xmlns:="http://www.w3.org/1999/xhtml">Implementing equal-frequency discretization</span></h1>
<p><span class="koboSpan" id="kobo.452.1" xmlns:="http://www.w3.org/1999/xhtml">Equal-width discretization</span><a id="_idIndexMarker292"/><span class="koboSpan" id="kobo.453.1" xmlns:="http://www.w3.org/1999/xhtml"> is intuitive and easy to compute. </span><span class="koboSpan" id="kobo.453.2" xmlns:="http://www.w3.org/1999/xhtml">However, if the variables are skewe</span><a id="_idTextAnchor554"/><span class="koboSpan" id="kobo.454.1" xmlns:="http://www.w3.org/1999/xhtml">d, then there will be many empty bins or bins with only a few values, while most observations will be allocated to a few intervals. </span><span class="koboSpan" id="kobo.454.2" xmlns:="http://www.w3.org/1999/xhtml">This could result in a loss of information. </span><span class="koboSpan" id="kobo.454.3" xmlns:="http://www.w3.org/1999/xhtml">This problem can be solved by adaptively finding the interval cut-points so that each interval contains a similar fraction </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1" xmlns:="http://www.w3.org/1999/xhtml">of observations.</span></span></p>
<p><span class="koboSpan" id="kobo.456.1" xmlns:="http://www.w3.org/1999/xhtml">Equal-frequency discretization</span><a id="_idIndexMarker293"/><span class="koboSpan" id="kobo.457.1" xmlns:="http://www.w3.org/1999/xhtml"> divides the values of the variable into intervals that carry the same proportion of observations. </span><span class="koboSpan" id="kobo.457.2" xmlns:="http://www.w3.org/1999/xhtml">The interval width is</span><a id="_idIndexMarker294"/><span class="koboSpan" id="kobo.458.1" xmlns:="http://www.w3.org/1999/xhtml"> determined by </span><strong class="bold"><span class="koboSpan" id="kobo.459.1" xmlns:="http://www.w3.org/1999/xhtml">quantiles</span></strong><span class="koboSpan" id="kobo.460.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.460.2" xmlns:="http://www.w3.org/1999/xhtml">Quantiles are values that divide data into equal portions. </span><span class="koboSpan" id="kobo.460.3" xmlns:="http://www.w3.org/1999/xhtml">For example, the median is a quantile that divides the data into two halves. </span><span class="koboSpan" id="kobo.460.4" xmlns:="http://www.w3.org/1999/xhtml">Quartiles divide the data into four equal portions, and percentiles divide the data into 100 equal-sized portions. </span><span class="koboSpan" id="kobo.460.5" xmlns:="http://www.w3.org/1999/xhtml">As a result, the intervals will most likely have different widths, but a similar number of observations. </span><span class="koboSpan" id="kobo.460.6" xmlns:="http://www.w3.org/1999/xhtml">The number of intervals is defined by </span><span class="No-Break"><span class="koboSpan" id="kobo.461.1" xmlns:="http://www.w3.org/1999/xhtml">the user.</span></span></p>
<p><span class="koboSpan" id="kobo.462.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will perform equal-frequency discretization using </span><strong class="source-inline"><span class="koboSpan" id="kobo.463.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.464.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.465.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.466.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1" xmlns:="http://www.w3.org/1999/xhtml">and </span><a id="_idTextAnchor555"/><a id="_idTextAnchor556"/></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.468.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.469.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-127"><a id="_idTextAnchor557"/><span class="koboSpan" id="kobo.470.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.471.1" xmlns:="http://www.w3.org/1999/xhtml">First, let’s</span><a id="_idIndexMarker295"/><span class="koboSpan" id="kobo.472.1" xmlns:="http://www.w3.org/1999/xhtml"> import the necessary Python libraries and get the </span><span class="No-Break"><span class="koboSpan" id="kobo.473.1" xmlns:="http://www.w3.org/1999/xhtml">dataset ready:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.474.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the required Python libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.475.1" xmlns:="http://www.w3.org/1999/xhtml">and functions:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.476.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split</span></pre></li> <li><span class="koboSpan" id="kobo.477.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the California housing dataset into </span><span class="No-Break"><span class="koboSpan" id="kobo.478.1" xmlns:="http://www.w3.org/1999/xhtml">a DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.479.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.480.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.481.1" xmlns:="http://www.w3.org/1999/xhtml">To avoid data leakage, we will determine the interval boundaries or quantiles from the </span><span class="No-Break"><span class="koboSpan" id="kobo.482.1" xmlns:="http://www.w3.org/1999/xhtml">train set.</span></span></p>
<ol>
<li value="3"><span class="koboSpan" id="kobo.483.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s divide the data into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.484.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.485.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.486.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s make a copy of </span><span class="No-Break"><span class="koboSpan" id="kobo.487.1" xmlns:="http://www.w3.org/1999/xhtml">the DataFrames:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.488.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t = X_train.copy()
test_t = X_test.copy()</span></pre></li> <li><span class="koboSpan" id="kobo.489.1" xmlns:="http://www.w3.org/1999/xhtml">We’ll use pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.490.1" xmlns:="http://www.w3.org/1999/xhtml">qcut()</span></strong><span class="koboSpan" id="kobo.491.1" xmlns:="http://www.w3.org/1999/xhtml">to obtain a discretized copy of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.492.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.493.1" xmlns:="http://www.w3.org/1999/xhtml"> variable, which we will store as a new column in the training set, and the limits of eight </span><span class="No-Break"><span class="koboSpan" id="kobo.494.1" xmlns:="http://www.w3.org/1999/xhtml">equal-frequency intervals:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.495.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t["House_disc"], interval_limits = pd.qcut(
    x=X_train["HouseAge"],
    q=8,
    labels=None,
    retbins=True,
)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.496.1" xmlns:="http://www.w3.org/1999/xhtml">If you execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.497.1" xmlns:="http://www.w3.org/1999/xhtml">print(interval_limits)</span></strong><span class="koboSpan" id="kobo.498.1" xmlns:="http://www.w3.org/1999/xhtml">, you’ll see the following interval limits: </span><strong class="source-inline"><span class="koboSpan" id="kobo.499.1" xmlns:="http://www.w3.org/1999/xhtml">array([ 1., 14., 18., 24., 29., 34., 37., </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.500.1" xmlns:="http://www.w3.org/1999/xhtml">44., 52.])</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.501.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p></li> <li><span class="koboSpan" id="kobo.502.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s </span><a id="_idIndexMarker296"/><span class="koboSpan" id="kobo.503.1" xmlns:="http://www.w3.org/1999/xhtml">print the top five observations of the discretized and </span><span class="No-Break"><span class="koboSpan" id="kobo.504.1" xmlns:="http://www.w3.org/1999/xhtml">original variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.505.1" xmlns:="http://www.w3.org/1999/xhtml">
print(train_t[["HouseAge", "House_disc"]].head(5))</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.506.1" xmlns:="http://www.w3.org/1999/xhtml">In the following output, we see that the </span><strong class="source-inline"><span class="koboSpan" id="kobo.507.1" xmlns:="http://www.w3.org/1999/xhtml">52</span></strong><span class="koboSpan" id="kobo.508.1" xmlns:="http://www.w3.org/1999/xhtml"> value was allocated to the 44–52 interval, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.509.1" xmlns:="http://www.w3.org/1999/xhtml">43</span></strong><span class="koboSpan" id="kobo.510.1" xmlns:="http://www.w3.org/1999/xhtml"> value was allocated to the 37–44 interval, and </span><span class="No-Break"><span class="koboSpan" id="kobo.511.1" xmlns:="http://www.w3.org/1999/xhtml">so on:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.512.1" xmlns:="http://www.w3.org/1999/xhtml">       HouseAge     House_disc</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.513.1" xmlns:="http://www.w3.org/1999/xhtml">1989       52.0   (44.0, 52.0]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.514.1" xmlns:="http://www.w3.org/1999/xhtml">256        43.0   (37.0, 44.0]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.515.1" xmlns:="http://www.w3.org/1999/xhtml">7887       17.0   (14.0, 18.0]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.516.1" xmlns:="http://www.w3.org/1999/xhtml">4581       17.0   (14.0, 18.0]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.517.1" xmlns:="http://www.w3.org/1999/xhtml">1993       50.0   (44.0,</span><a id="_idTextAnchor558"/><span class="koboSpan" id="kobo.518.1" xmlns:="http://www.w3.org/1999/xhtml"> 52.0]</span></strong></pre></li> <li><span class="koboSpan" id="kobo.519.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s discretize </span><strong class="source-inline"><span class="koboSpan" id="kobo.520.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.521.1" xmlns:="http://www.w3.org/1999/xhtml"> in the test set, using pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.522.1" xmlns:="http://www.w3.org/1999/xhtml">cut()</span></strong><span class="koboSpan" id="kobo.523.1" xmlns:="http://www.w3.org/1999/xhtml"> with the interval limits determined in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.524.1" xmlns:="http://www.w3.org/1999/xhtml">step 5</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.525.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.526.1" xmlns:="http://www.w3.org/1999/xhtml">
test_t["House_disc"] = pd.cut(
    x=X_test["HouseAge"],
    bins=interval_limits,
    include_lowest=True)</span></pre></li> <li><span class="koboSpan" id="kobo.527.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s </span><a id="_idIndexMarker297"/><span class="koboSpan" id="kobo.528.1" xmlns:="http://www.w3.org/1999/xhtml">make a bar plot with the proportion of observations per interval in the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.529.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.530.1" xmlns:="http://www.w3.org/1999/xhtml">
# determine proportion of observations per bin
t1 = train_t["House_disc"].value_counts(
    normalize=True)
t2 = test_t["House_disc"].value_counts(normalize=True)
# concatenate proportions
tmp = pd.concat([t1, t2], axis=1)
tmp.columns = ["train", "test"]
tmp.sort_index(inplace=True)
# plot
tmp.plot.bar()
plt.xticks(rotation=45)
plt.ylabel("Number of observations per bin")
plt.title("HouseAge")
plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.531.1" xmlns:="http://www.w3.org/1999/xhtml">In the following plot, we can see that the bins contain a similar fraction</span><a id="_idTextAnchor559"/> <span class="No-Break"><span class="koboSpan" id="kobo.532.1" xmlns:="http://www.w3.org/1999/xhtml">of observations:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer067">
<span class="koboSpan" id="kobo.533.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.4 – The proportion of observations per interval of HouseAge after equal-frequency discretization" src="image/B22396_04_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.534.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.4 – The proportion of observations per interval of HouseAge after equal-frequency discretization</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.535.1" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.536.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.537.1" xmlns:="http://www.w3.org/1999/xhtml">, we can apply equal-frequency discretization to </span><span class="No-Break"><span class="koboSpan" id="kobo.538.1" xmlns:="http://www.w3.org/1999/xhtml">multiple </span><a id="_idTextAnchor560"/><span class="koboSpan" id="kobo.539.1" xmlns:="http://www.w3.org/1999/xhtml">variables.</span></span></p>
<ol>
<li value="9"><span class="koboSpan" id="kobo.540.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s </span><a id="_idIndexMarker298"/><span class="koboSpan" id="kobo.541.1" xmlns:="http://www.w3.org/1999/xhtml">import </span><span class="No-Break"><span class="koboSpan" id="kobo.542.1" xmlns:="http://www.w3.org/1999/xhtml">the discretizer:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.543.1" xmlns:="http://www.w3.org/1999/xhtml">
from feature_engine.discretisation import EqualFrequencyDiscretiser</span></pre></li> <li><span class="koboSpan" id="kobo.544.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up the transformer to discretize three continuous variables into </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1" xmlns:="http://www.w3.org/1999/xhtml">eight bins:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.546.1" xmlns:="http://www.w3.org/1999/xhtml">
variables = ['MedInc', 'HouseAge', 'AveRooms']
disc = EqualFrequencyDiscretiser(
    q=8, variables=variables, return_boundaries=True)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.547.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.548.1" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.549.1" xmlns:="http://www.w3.org/1999/xhtml">return_boundaries=True</span></strong><span class="koboSpan" id="kobo.550.1" xmlns:="http://www.w3.org/1999/xhtml">, the transformer will return the interval boundaries after the discretization. </span><span class="koboSpan" id="kobo.550.2" xmlns:="http://www.w3.org/1999/xhtml">To return the interval number, set it </span><span class="No-Break"><span class="koboSpan" id="kobo.551.1" xmlns:="http://www.w3.org/1999/xhtml">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.552.1" xmlns:="http://www.w3.org/1999/xhtml">False</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.553.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="11"><span class="koboSpan" id="kobo.554.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit the </span><a id="_idIndexMarker299"/><span class="koboSpan" id="kobo.555.1" xmlns:="http://www.w3.org/1999/xhtml">discretizer to the train set so that it learns the </span><span class="No-Break"><span class="koboSpan" id="kobo.556.1" xmlns:="http://www.w3.org/1999/xhtml">interval limits:</span></span><pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.557.1" xmlns:="http://www.w3.org/1999/xhtml">disc.fit(X_train)</span></strong></pre><p class="list-inset"><span class="koboSpan" id="kobo.558.1" xmlns:="http://www.w3.org/1999/xhtml">The transformer stores the limits of the intervals for each variable in a dictionary in its </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.559.1" xmlns:="http://www.w3.org/1999/xhtml">disc.binner_dict_</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.560.1" xmlns:="http://www.w3.org/1999/xhtml"> attribute.</span></span></p></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.561.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.562.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.563.1" xmlns:="http://www.w3.org/1999/xhtml"> will automatically extend the limits of the lower and upper intervals to infinite to accommodate potential outliers in </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1" xmlns:="http://www.w3.org/1999/xhtml">future data.</span></span></p>
<ol>
<li value="12"><span class="koboSpan" id="kobo.565.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s transform the variables in the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.566.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.567.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t = disc.transform(X_train)
test_t = disc.tran</span><a id="_idTextAnchor561"/><span class="koboSpan" id="kobo.568.1" xmlns:="http://www.w3.org/1999/xhtml">sform(X_test)</span></pre></li> <li><span class="koboSpan" id="kobo.569.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s make bar plots with the fraction of observations per interval to better understand the effect of </span><span class="No-Break"><span class="koboSpan" id="kobo.570.1" xmlns:="http://www.w3.org/1999/xhtml">equal-frequency discretization:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.571.1" xmlns:="http://www.w3.org/1999/xhtml">
plt.figure(figsize=(6, 12), constrained_layout=True)
for i in range(3):
    # location of plot in figure
    ax = plt.subplot(3, 1, i + 1)
    # the variable to plot
    var = variables[i]
    # determine proportion of observations per bin
    t1 = train_t[var].value_counts(normalize=True)
    t2 = test_t[var].value_counts(normalize=True)
    # concatenate proportions
    tmp = pd.concat([t1, t2], axis=1)
    tmp.columns = ['train', 'test']
    # sort the intervals
    tmp.sort_index(inplace=True)
    # make plot
    tmp.plot.bar(ax=ax)
    plt.xticks(rotation=45)
    plt.ylabel("Observations per bin")
    # add variable name as title
    ax.set_title(var)
 plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.572.1" xmlns:="http://www.w3.org/1999/xhtml">In the following </span><a id="_idIndexMarker300"/><span class="koboSpan" id="kobo.573.1" xmlns:="http://www.w3.org/1999/xhtml">figure, we can se</span><a id="_idTextAnchor562"/><span class="koboSpan" id="kobo.574.1" xmlns:="http://www.w3.org/1999/xhtml">e that the intervals have a similar fracti</span><a id="_idTextAnchor563"/><span class="koboSpan" id="kobo.575.1" xmlns:="http://www.w3.org/1999/xhtml">on </span><span class="No-Break"><span class="koboSpan" id="kobo.576.1" xmlns:="http://www.w3.org/1999/xhtml">of observations:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer068">
<span class="koboSpan" id="kobo.577.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.5 – The proportion of observations per interval after  equal-frequency discretization of three va﻿riables." src="image/B22396_04_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.578.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.5 – The proportion of observations per interval after equal-frequency discretization of three va</span><a id="_idTextAnchor564"/><span class="koboSpan" id="kobo.579.1" xmlns:="http://www.w3.org/1999/xhtml">riables.</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.580.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s carry </span><a id="_idIndexMarker301"/><span class="koboSpan" id="kobo.581.1" xmlns:="http://www.w3.org/1999/xhtml">out equal-frequency discretization </span><span class="No-Break"><span class="koboSpan" id="kobo.582.1" xmlns:="http://www.w3.org/1999/xhtml">with scikit-learn:</span></span></p>
<ol>
<li value="14"><span class="koboSpan" id="kobo.583.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import </span><span class="No-Break"><span class="koboSpan" id="kobo.584.1" xmlns:="http://www.w3.org/1999/xhtml">the transformer:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.585.1" xmlns:="http://www.w3.org/1999/xhtml">
from sklearn.preprocessing import KBinsDiscretizer</span></pre></li> <li><span class="koboSpan" id="kobo.586.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up the discretizer to sort variables into eight </span><span class="No-Break"><span class="koboSpan" id="kobo.587.1" xmlns:="http://www.w3.org/1999/xhtml">equal-frequency bins:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.588.1" xmlns:="http://www.w3.org/1999/xhtml">
disc = KBinsDiscretizer(
    n_bins=8, encode='ordinal', strategy='quantile')</span></pre></li> <li><span class="koboSpan" id="kobo.589.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit the </span><a id="_idIndexMarker302"/><span class="koboSpan" id="kobo.590.1" xmlns:="http://www.w3.org/1999/xhtml">discretizer to a slice of the train set containing the variables from </span><em class="italic"><span class="koboSpan" id="kobo.591.1" xmlns:="http://www.w3.org/1999/xhtml">step 10</span></em><span class="koboSpan" id="kobo.592.1" xmlns:="http://www.w3.org/1999/xhtml"> so that it learns the </span><span class="No-Break"><span class="koboSpan" id="kobo.593.1" xmlns:="http://www.w3.org/1999/xhtml">interval limits:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.594.1" xmlns:="http://www.w3.org/1999/xhtml">
disc.fit(X_train[variables])</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.595.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.596.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.597.1" xmlns:="http://www.w3.org/1999/xhtml">KBinsDiscretiser()</span></strong><span class="koboSpan" id="kobo.598.1" xmlns:="http://www.w3.org/1999/xhtml"> will discretize all the variables in the dataset. </span><span class="koboSpan" id="kobo.598.2" xmlns:="http://www.w3.org/1999/xhtml">To discretize only a subset, we apply the transformer to the slice of the DataFrame that contains the variables of interest. </span><span class="koboSpan" id="kobo.598.3" xmlns:="http://www.w3.org/1999/xhtml">Alternatively, we can restrict the discretization to a subset of variables by using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.599.1" xmlns:="http://www.w3.org/1999/xhtml">ColumnTransformer()</span></strong><span class="koboSpan" id="kobo.600.1" xmlns:="http://www.w3.org/1999/xhtml">, as we did in the </span><em class="italic"><span class="koboSpan" id="kobo.601.1" xmlns:="http://www.w3.org/1999/xhtml">Performing equal-width </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.602.1" xmlns:="http://www.w3.org/1999/xhtml">discretization</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.603.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe.</span></span></p>
<ol>
<li value="17"><span class="koboSpan" id="kobo.604.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s make a copy of the DataFrames where we’ll store the </span><span class="No-Break"><span class="koboSpan" id="kobo.605.1" xmlns:="http://www.w3.org/1999/xhtml">discretized variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.606.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t = X_train.copy()
test_t = X_test.copy()</span></pre></li> <li><span class="koboSpan" id="kobo.607.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s transform the variables in both the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.608.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.609.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t[variables] = disc.transform(
    X_train[variables])
test_t[variables] = disc.transform(X_test[variables])</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.610.1" xmlns:="http://www.w3.org/1999/xhtml">We can inspect the cut points by </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1" xmlns:="http://www.w3.org/1999/xhtml">execu</span><a id="_idTextAnchor565"/><a id="_idTextAnchor566"/><span class="koboSpan" id="kobo.612.1" xmlns:="http://www.w3.org/1999/xhtml">ting </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.613.1" xmlns:="http://www.w3.org/1999/xhtml">disc.bin_edges_</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.614.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-128"><a id="_idTextAnchor567"/><span class="koboSpan" id="kobo.615.1" xmlns:="http://www.w3.org/1999/xhtml">How it works…</span></h2>
<p><span class="koboSpan" id="kobo.616.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we sorted the variable values into intervals with a similar proportion </span><span class="No-Break"><span class="koboSpan" id="kobo.617.1" xmlns:="http://www.w3.org/1999/xhtml">of observations.</span></span></p>
<p><span class="koboSpan" id="kobo.618.1" xmlns:="http://www.w3.org/1999/xhtml">We used pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.619.1" xmlns:="http://www.w3.org/1999/xhtml">qcut()</span></strong><span class="koboSpan" id="kobo.620.1" xmlns:="http://www.w3.org/1999/xhtml"> to identify the interval limits from the train set and sort the values of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.621.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.622.1" xmlns:="http://www.w3.org/1999/xhtml"> variable into those intervals. </span><span class="koboSpan" id="kobo.622.2" xmlns:="http://www.w3.org/1999/xhtml">Next, we passed those interval limits to pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.623.1" xmlns:="http://www.w3.org/1999/xhtml">cut()</span></strong><span class="koboSpan" id="kobo.624.1" xmlns:="http://www.w3.org/1999/xhtml"> to discretize </span><strong class="source-inline"><span class="koboSpan" id="kobo.625.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.626.1" xmlns:="http://www.w3.org/1999/xhtml"> in the test set. </span><span class="koboSpan" id="kobo.626.2" xmlns:="http://www.w3.org/1999/xhtml">Note that pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.627.1" xmlns:="http://www.w3.org/1999/xhtml">qcut()</span></strong><span class="koboSpan" id="kobo.628.1" xmlns:="http://www.w3.org/1999/xhtml">, like pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.629.1" xmlns:="http://www.w3.org/1999/xhtml">cut()</span></strong><span class="koboSpan" id="kobo.630.1" xmlns:="http://www.w3.org/1999/xhtml">, returned the interval values as ordered integers, which is the equivalent of </span><a id="_idIndexMarker303"/><span class="No-Break"><span class="koboSpan" id="kobo.631.1" xmlns:="http://www.w3.org/1999/xhtml">ordinal encoding,</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.632.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.633.1" xmlns:="http://www.w3.org/1999/xhtml">With equal-frequency discretization, many occurrences of values within a small continuous range could cause observations with very similar values, resulting in different intervals. </span><span class="koboSpan" id="kobo.633.2" xmlns:="http://www.w3.org/1999/xhtml">The problem with this is that it can introduce artificial distinctions between data points that are actually quite similar in nature, biasing models or subsequent </span><span class="No-Break"><span class="koboSpan" id="kobo.634.1" xmlns:="http://www.w3.org/1999/xhtml">data analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.635.1" xmlns:="http://www.w3.org/1999/xhtml">With Feature-engine’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.636.1" xmlns:="http://www.w3.org/1999/xhtml">EqualFrequencyDiscretiser()</span></strong><span class="koboSpan" id="kobo.637.1" xmlns:="http://www.w3.org/1999/xhtml">, we discretized three variables into eight bins. </span><span class="koboSpan" id="kobo.637.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.638.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.639.1" xmlns:="http://www.w3.org/1999/xhtml">, the discretizer learned the interval limits and stored them in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.640.1" xmlns:="http://www.w3.org/1999/xhtml">binner_dict_</span></strong><span class="koboSpan" id="kobo.641.1" xmlns:="http://www.w3.org/1999/xhtml"> attribute. </span><span class="koboSpan" id="kobo.641.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.642.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.643.1" xmlns:="http://www.w3.org/1999/xhtml">, the observations were allocated to </span><span class="No-Break"><span class="koboSpan" id="kobo.644.1" xmlns:="http://www.w3.org/1999/xhtml">the bins.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.645.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.646.1" xmlns:="http://www.w3.org/1999/xhtml">EqualFrequencyDiscretiser()</span></strong><span class="koboSpan" id="kobo.647.1" xmlns:="http://www.w3.org/1999/xhtml"> returns an integer indicating whether the value was sorted into the first, second, or eighth bin by default. </span><span class="koboSpan" id="kobo.647.2" xmlns:="http://www.w3.org/1999/xhtml">That is the equivalent of ordinal encoding, which we described in the </span><em class="italic"><span class="koboSpan" id="kobo.648.1" xmlns:="http://www.w3.org/1999/xhtml">Replacing categories with ordinal numbers</span></em><span class="koboSpan" id="kobo.649.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe in </span><a href="B22396_02.xhtml#_idTextAnchor182"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.650.1" xmlns:="http://www.w3.org/1999/xhtml">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.651.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><em class="italic"><span class="koboSpan" id="kobo.652.1" xmlns:="http://www.w3.org/1999/xhtml">Encoding </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.653.1" xmlns:="http://www.w3.org/1999/xhtml">Categorical Variables</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.654.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p class="callout"><span class="koboSpan" id="kobo.655.1" xmlns:="http://www.w3.org/1999/xhtml">To follow up the discretization with a different type of encoding, we can return the variables cast as objects by setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.656.1" xmlns:="http://www.w3.org/1999/xhtml">return_object</span></strong><span class="koboSpan" id="kobo.657.1" xmlns:="http://www.w3.org/1999/xhtml"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.658.1" xmlns:="http://www.w3.org/1999/xhtml">True</span></strong><span class="koboSpan" id="kobo.659.1" xmlns:="http://www.w3.org/1999/xhtml"> and then use any of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.660.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.661.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.662.1" xmlns:="http://www.w3.org/1999/xhtml">category encoders</span></strong><span class="koboSpan" id="kobo.663.1" xmlns:="http://www.w3.org/1999/xhtml">  transformers</span><span class="Annotation-reference"> </span><span class="koboSpan" id="kobo.664.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.664.2" xmlns:="http://www.w3.org/1999/xhtml">Alternatively, we can return the interval limits, as we did in </span><span class="No-Break"><span class="koboSpan" id="kobo.665.1" xmlns:="http://www.w3.org/1999/xhtml">this recipe.</span></span></p>
<p><span class="koboSpan" id="kobo.666.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, we discretized variables into eight equal-frequency bins using </span><strong class="source-inline"><span class="koboSpan" id="kobo.667.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.668.1" xmlns:="http://www.w3.org/1999/xhtml">’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.669.1" xmlns:="http://www.w3.org/1999/xhtml">KBinsDiscretizer()</span></strong><span class="koboSpan" id="kobo.670.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.670.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.671.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.672.1" xmlns:="http://www.w3.org/1999/xhtml">, the transformer learned the cut points and stored them in its </span><strong class="source-inline"><span class="koboSpan" id="kobo.673.1" xmlns:="http://www.w3.org/1999/xhtml">bin_edges_</span></strong><span class="koboSpan" id="kobo.674.1" xmlns:="http://www.w3.org/1999/xhtml"> attribute. </span><span class="koboSpan" id="kobo.674.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.675.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.676.1" xmlns:="http://www.w3.org/1999/xhtml">, it sorted the values into each interval. </span><span class="koboSpan" id="kobo.676.2" xmlns:="http://www.w3.org/1999/xhtml">Note that, differently from </span><strong class="source-inline"><span class="koboSpan" id="kobo.677.1" xmlns:="http://www.w3.org/1999/xhtml">EqualFrequencyDiscretiser()</span></strong><span class="koboSpan" id="kobo.678.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.679.1" xmlns:="http://www.w3.org/1999/xhtml">KBinsDiscretizer()</span></strong><span class="koboSpan" id="kobo.680.1" xmlns:="http://www.w3.org/1999/xhtml"> will transform all of the variables in the dataset. </span><span class="koboSpan" id="kobo.680.2" xmlns:="http://www.w3.org/1999/xhtml">To avoid this, we only applied the discretizer on a slice of the data with the variables </span><span class="No-Break"><span class="koboSpan" id="kobo.681.1" xmlns:="http://www.w3.org/1999/xhtml">to modify.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.682.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.683.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.684.1" xmlns:="http://www.w3.org/1999/xhtml">KbinsDiscretizer</span></strong><span class="koboSpan" id="kobo.685.1" xmlns:="http://www.w3.org/1999/xhtml"> has the option to return the intervals as ordinal numbers or one-hot encoded. </span><span class="koboSpan" id="kobo.685.2" xmlns:="http://www.w3.org/1999/xhtml">The behavior can be modified through</span><a id="_idTextAnchor568"/><span class="koboSpan" id="kobo.686.1" xmlns:="http://www.w3.org/1999/xhtml"> the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.687.1" xmlns:="http://www.w3.org/1999/xhtml">encode</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.688.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter.</span></span></p>
<h1 id="_idParaDest-129"><span class="koboSpan" id="kobo.689.1" xmlns:="http://www.w3.org/1999/xhtml">Discretizing the va</span><a id="_idTextAnchor569"/><a id="_idTextAnchor570"/><span class="koboSpan" id="kobo.690.1" xmlns:="http://www.w3.org/1999/xhtml">riable into arbitrar</span><a id="_idTextAnchor571"/><span class="koboSpan" id="kobo.691.1" xmlns:="http://www.w3.org/1999/xhtml">y intervals</span></h1>
<p><span class="koboSpan" id="kobo.692.1" xmlns:="http://www.w3.org/1999/xhtml">In various</span><a id="_idIndexMarker304"/><span class="koboSpan" id="kobo.693.1" xmlns:="http://www.w3.org/1999/xhtml"> industries</span><a id="_idTextAnchor572"/><span class="koboSpan" id="kobo.694.1" xmlns:="http://www.w3.org/1999/xhtml">, it is common to group variable values into segments that make sense for the business. </span><span class="koboSpan" id="kobo.694.2" xmlns:="http://www.w3.org/1999/xhtml">For example, we might want to group the variable age in intervals representing children, young adults, middle-aged people, and retirees. </span><span class="koboSpan" id="kobo.694.3" xmlns:="http://www.w3.org/1999/xhtml">Alternatively, we might group ratings into bad, good, and excellent. </span><span class="koboSpan" id="kobo.694.4" xmlns:="http://www.w3.org/1999/xhtml">On occasion, if we know that the variable is in a certain scale (for example, logarithmic), we might want to define the interval cut points within </span><span class="No-Break"><span class="koboSpan" id="kobo.695.1" xmlns:="http://www.w3.org/1999/xhtml">that scale.</span></span></p>
<p><span class="koboSpan" id="kobo.696.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will discretize a variable into pre-defined user intervals using </span><strong class="source-inline"><span class="koboSpan" id="kobo.697.1" xmlns:="http://www.w3.org/1999/xhtml">pan</span><a id="_idTextAnchor573"/><a id="_idTextAnchor574"/><span class="koboSpan" id="kobo.698.1" xmlns:="http://www.w3.org/1999/xhtml">das</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.699.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.700.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.701.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-130"><span class="koboSpan" id="kobo.702.1" xmlns:="http://www.w3.org/1999/xhtml">How t</span><a id="_idTextAnchor575"/><span class="koboSpan" id="kobo.703.1" xmlns:="http://www.w3.org/1999/xhtml">o do it...</span></h2>
<p><span class="koboSpan" id="kobo.704.1" xmlns:="http://www.w3.org/1999/xhtml">First, let’s </span><a id="_idIndexMarker305"/><span class="koboSpan" id="kobo.705.1" xmlns:="http://www.w3.org/1999/xhtml">imp</span><a id="_idTextAnchor576"/><span class="koboSpan" id="kobo.706.1" xmlns:="http://www.w3.org/1999/xhtml">ort the necessary Python libraries and get the </span><span class="No-Break"><span class="koboSpan" id="kobo.707.1" xmlns:="http://www.w3.org/1999/xhtml">dataset ready:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.708.1" xmlns:="http://www.w3.org/1999/xhtml">Import Python libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.709.1" xmlns:="http://www.w3.org/1999/xhtml">and classes:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.710.1" xmlns:="http://www.w3.org/1999/xhtml">
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing</span></pre></li> <li><span class="koboSpan" id="kobo.711.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the California housing dataset into a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.712.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.713.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.714.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)</span></pre></li> <li><span class="koboSpan" id="kobo.715.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s plot a</span><a id="_idIndexMarker306"/><span class="koboSpan" id="kobo.716.1" xmlns:="http://www.w3.org/1999/xhtml"> histogram of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.717.1" xmlns:="http://www.w3.org/1999/xhtml">Population</span></strong><span class="koboSpan" id="kobo.718.1" xmlns:="http://www.w3.org/1999/xhtml"> variable to find out its </span><span class="No-Break"><span class="koboSpan" id="kobo.719.1" xmlns:="http://www.w3.org/1999/xhtml">value range:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.720.1" xmlns:="http://www.w3.org/1999/xhtml">
X["Population"].hist(bins=30)
plt.title("Population")
plt.ylabel("Number of observations")
plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.721.1" xmlns:="http://www.w3.org/1999/xhtml">Population </span><a id="_idIndexMarker307"/><span class="koboSpan" id="kobo.722.1" xmlns:="http://www.w3.org/1999/xhtml">values vary between 0 </span><a id="_idTextAnchor577"/><span class="koboSpan" id="kobo.723.1" xmlns:="http://www.w3.org/1999/xhtml">and </span><span class="No-Break"><span class="koboSpan" id="kobo.724.1" xmlns:="http://www.w3.org/1999/xhtml">approximately 40,000:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer069">
<span class="koboSpan" id="kobo.725.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.6 – Histogram of the ﻿Population variable" src="image/B22396_04_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.726.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.6 – Histogram of the </span><a id="_idTextAnchor578"/><span class="koboSpan" id="kobo.727.1" xmlns:="http://www.w3.org/1999/xhtml">Population variable</span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.728.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s cre</span><a id="_idTextAnchor579"/><span class="koboSpan" id="kobo.729.1" xmlns:="http://www.w3.org/1999/xhtml">ate a list with arbitrary interval limits, setting the upper limit to infinity to accommodate </span><span class="No-Break"><span class="koboSpan" id="kobo.730.1" xmlns:="http://www.w3.org/1999/xhtml">bigger values:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.731.1" xmlns:="http://www.w3.org/1999/xhtml">
intervals = [0, 200, 500, 1000, 2000, np.inf]</span></pre></li> <li><span class="koboSpan" id="kobo.732.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create a list with the interval limits </span><span class="No-Break"><span class="koboSpan" id="kobo.733.1" xmlns:="http://www.w3.org/1999/xhtml">as strings:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.734.1" xmlns:="http://www.w3.org/1999/xhtml">
labels = ["0-200", "200-500", "500-1000", "1000-2000",
    "&gt;2000"]</span></pre></li> <li><span class="koboSpan" id="kobo.735.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s make</span><a id="_idIndexMarker308"/><span class="koboSpan" id="kobo.736.1" xmlns:="http://www.w3.org/1999/xhtml"> a copy of the dataset and discretize the </span><strong class="source-inline"><span class="koboSpan" id="kobo.737.1" xmlns:="http://www.w3.org/1999/xhtml">Population</span></strong><span class="koboSpan" id="kobo.738.1" xmlns:="http://www.w3.org/1999/xhtml"> variable into the pre-defined limits from </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.739.1" xmlns:="http://www.w3.org/1999/xhtml">step 4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.740.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.741.1" xmlns:="http://www.w3.org/1999/xhtml">
X_t = X.copy()
X_t[«Population_limits»] = pd.cut(
    X["Population"],
    bins=intervals,
    labels=None,
    include_lowest=True)</span></pre></li> <li><span class="koboSpan" id="kobo.742.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s </span><a id="_idIndexMarker309"/><span class="koboSpan" id="kobo.743.1" xmlns:="http://www.w3.org/1999/xhtml">discretize </span><strong class="source-inline"><span class="koboSpan" id="kobo.744.1" xmlns:="http://www.w3.org/1999/xhtml">Population</span></strong><span class="koboSpan" id="kobo.745.1" xmlns:="http://www.w3.org/1999/xhtml"> into pre-defined intervals and name the intervals with the labels that we defined in </span><em class="italic"><span class="koboSpan" id="kobo.746.1" xmlns:="http://www.w3.org/1999/xhtml">step 5</span></em> <span class="No-Break"><span class="koboSpan" id="kobo.747.1" xmlns:="http://www.w3.org/1999/xhtml">for comparison:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.748.1" xmlns:="http://www.w3.org/1999/xhtml">
X_t[«Population_range»] = pd.cut(
    X[„Population"],
    bins=intervals,
    labels=labels,
    include_lowest=True)</span></pre></li> <li><span class="koboSpan" id="kobo.749.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s </span><a id="_idTextAnchor580"/><span class="koboSpan" id="kobo.750.1" xmlns:="http://www.w3.org/1999/xhtml">inspect the first five rows of the original and </span><span class="No-Break"><span class="koboSpan" id="kobo.751.1" xmlns:="http://www.w3.org/1999/xhtml">discretized variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.752.1" xmlns:="http://www.w3.org/1999/xhtml">
X_t[['Population', 'Population_range',
    'Population_limits']].head()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.753.1" xmlns:="http://www.w3.org/1999/xhtml">In the last two columns of the DataFrame, we can see the discretized variables: the first one with the strings that we created in </span><em class="italic"><span class="koboSpan" id="kobo.754.1" xmlns:="http://www.w3.org/1999/xhtml">step 5</span></em><span class="koboSpan" id="kobo.755.1" xmlns:="http://www.w3.org/1999/xhtml"> as values, and the second one with the </span><span class="No-Break"><span class="koboSpan" id="kobo.756.1" xmlns:="http://www.w3.org/1999/xhtml">interval limits:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.757.1" xmlns:="http://www.w3.org/1999/xhtml">   Population Population_range Population_limits</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.758.1" xmlns:="http://www.w3.org/1999/xhtml">0       322.0          200-500    (200.0, 500.0]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.759.1" xmlns:="http://www.w3.org/1999/xhtml">1      2401.0            &gt;2000     (2000.0, inf]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.760.1" xmlns:="http://www.w3.org/1999/xhtml">2       496.0          200-500    (200.0, 500.0]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.761.1" xmlns:="http://www.w3.org/1999/xhtml">3       558.0         500-1000   (500.0, 1000.0]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.762.1" xmlns:="http://www.w3.org/1999/xhtml">4       565.0         500-1000   (500.0, 1000.0]</span></strong></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.763.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.764.1" xmlns:="http://www.w3.org/1999/xhtml">We only need one of the variable versions, either the one with the value range or the one with the interval limits. </span><span class="koboSpan" id="kobo.764.2" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, I created both to highlight the different options offered </span><span class="No-Break"><span class="koboSpan" id="kobo.765.1" xmlns:="http://www.w3.org/1999/xhtml">by </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.766.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.767.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="9"><span class="koboSpan" id="kobo.768.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, we </span><a id="_idIndexMarker310"/><span class="koboSpan" id="kobo.769.1" xmlns:="http://www.w3.org/1999/xhtml">can count and plot the </span><a id="_idIndexMarker311"/><span class="koboSpan" id="kobo.770.1" xmlns:="http://www.w3.org/1999/xhtml">number of observations within </span><span class="No-Break"><span class="koboSpan" id="kobo.771.1" xmlns:="http://www.w3.org/1999/xhtml">each interval:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.772.1" xmlns:="http://www.w3.org/1999/xhtml">
X_t['Population_range'
    ].value_counts().sort_index().plot.bar()
plt.xticks(rotation=0)
plt.ylabel("Number of observations")
plt.title("Population")
plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.773.1" xmlns:="http://www.w3.org/1999/xhtml">In the foll</span><a id="_idTextAnchor581"/><span class="koboSpan" id="kobo.774.1" xmlns:="http://www.w3.org/1999/xhtml">owing figure, we can see that t</span><a id="_idTextAnchor582"/><span class="koboSpan" id="kobo.775.1" xmlns:="http://www.w3.org/1999/xhtml">he number of obser</span><a id="_idTextAnchor583"/><span class="koboSpan" id="kobo.776.1" xmlns:="http://www.w3.org/1999/xhtml">vations per </span><span class="No-Break"><span class="koboSpan" id="kobo.777.1" xmlns:="http://www.w3.org/1999/xhtml">interval varies:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer070">
<span class="koboSpan" id="kobo.778.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.7 – The proportion of observations per interval after the discretization." src="image/B22396_04_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.779.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.7 – The proportion of observations per interval after the discretization.</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.780.1" xmlns:="http://www.w3.org/1999/xhtml">To wrap up</span><a id="_idIndexMarker312"/><span class="koboSpan" id="kobo.781.1" xmlns:="http://www.w3.org/1999/xhtml"> the recipe, let’s discretize multiple variables </span><span class="No-Break"><span class="koboSpan" id="kobo.782.1" xmlns:="http://www.w3.org/1999/xhtml">ut</span><a id="_idTextAnchor584"/><span class="koboSpan" id="kobo.783.1" xmlns:="http://www.w3.org/1999/xhtml">ilizing </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.784.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.785.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span></p>
<ol>
<li value="10"><span class="koboSpan" id="kobo.786.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s</span><a id="_idIndexMarker313"/><span class="koboSpan" id="kobo.787.1" xmlns:="http://www.w3.org/1999/xhtml"> import </span><span class="No-Break"><span class="koboSpan" id="kobo.788.1" xmlns:="http://www.w3.org/1999/xhtml">the transformer:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.789.1" xmlns:="http://www.w3.org/1999/xhtml">
from feature_engine.discretisation import
    ArbitraryDiscretiser</span></pre></li> <li><span class="koboSpan" id="kobo.790.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create a dictionary with the variables as keys and the interval limits </span><span class="No-Break"><span class="koboSpan" id="kobo.791.1" xmlns:="http://www.w3.org/1999/xhtml">as values:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.792.1" xmlns:="http://www.w3.org/1999/xhtml">
intervals = {
    "Population": [0, 200, 500, 1000, 2000, np.inf],
    "MedInc": [</span><a id="_idTextAnchor585"/><span class="koboSpan" id="kobo.793.1" xmlns:="http://www.w3.org/1999/xhtml">0, 2, 4, 6, np.inf]}</span></pre></li> <li><span class="koboSpan" id="kobo.794.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up the discretizer with the limits from </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.795.1" xmlns:="http://www.w3.org/1999/xhtml">step 11</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.796.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.797.1" xmlns:="http://www.w3.org/1999/xhtml">
discretizer = ArbitraryDiscretiser(
    binning_dict=intervals, return_boundaries=True)</span></pre></li> <li><span class="koboSpan" id="kobo.798.1" xmlns:="http://www.w3.org/1999/xhtml">Now, we can go ahead and discretize </span><span class="No-Break"><span class="koboSpan" id="kobo.799.1" xmlns:="http://www.w3.org/1999/xhtml">the variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.800.1" xmlns:="http://www.w3.org/1999/xhtml">
X_t = discretizer.fit_transform(X)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.801.1" xmlns:="http://www.w3.org/1999/xhtml">If we execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.802.1" xmlns:="http://www.w3.org/1999/xhtml">X_t.head()</span></strong><span class="koboSpan" id="kobo.803.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see the following output, where the </span><strong class="source-inline"><span class="koboSpan" id="kobo.804.1" xmlns:="http://www.w3.org/1999/xhtml">Population</span></strong><span class="koboSpan" id="kobo.805.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.806.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.807.1" xmlns:="http://www.w3.org/1999/xhtml"> var</span><a id="_idTextAnchor586"/><span class="koboSpan" id="kobo.808.1" xmlns:="http://www.w3.org/1999/xhtml">iables have </span><span class="No-Break"><span class="koboSpan" id="kobo.809.1" xmlns:="http://www.w3.org/1999/xhtml">been discretized:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer071">
<span class="koboSpan" id="kobo.810.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.8 – A DataFrame containing the discretized variables" src="image/B22396_04_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.811.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.8 – A DataFrame containing the discretized variables</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.812.1" xmlns:="http://www.w3.org/1999/xhtml">The advantage</span><a id="_idIndexMarker314"/><span class="koboSpan" id="kobo.813.1" xmlns:="http://www.w3.org/1999/xhtml"> of using </span><strong class="source-inline"><span class="koboSpan" id="kobo.814.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.815.1" xmlns:="http://www.w3.org/1999/xhtml"> is that we </span><a id="_idIndexMarker315"/><span class="koboSpan" id="kobo.816.1" xmlns:="http://www.w3.org/1999/xhtml">can discretize multiple variables at the same time and apply arbitrary discretization as p</span><a id="_idTextAnchor587"/><a id="_idTextAnchor588"/><span class="koboSpan" id="kobo.817.1" xmlns:="http://www.w3.org/1999/xhtml">art of a </span><span class="No-Break"><span class="koboSpan" id="kobo.818.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.819.1" xmlns:="http://www.w3.org/1999/xhtml">Pipeline</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.820.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-131"><a id="_idTextAnchor589"/><span class="koboSpan" id="kobo.821.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.822.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we sorted the values of a variable into user-defin</span><a id="_idTextAnchor590"/><span class="koboSpan" id="kobo.823.1" xmlns:="http://www.w3.org/1999/xhtml">ed intervals. </span><span class="koboSpan" id="kobo.823.2" xmlns:="http://www.w3.org/1999/xhtml">First, we plotted a histogram of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.824.1" xmlns:="http://www.w3.org/1999/xhtml">Population</span></strong><span class="koboSpan" id="kobo.825.1" xmlns:="http://www.w3.org/1999/xhtml"> variable to get an idea of its va</span><a id="_idTextAnchor591"/><span class="koboSpan" id="kobo.826.1" xmlns:="http://www.w3.org/1999/xhtml">lue range. </span><span class="koboSpan" id="kobo.826.2" xmlns:="http://www.w3.org/1999/xhtml">Next, we arbitrarily determined the limits of the intervals and captured them in a list. </span><span class="koboSpan" id="kobo.826.3" xmlns:="http://www.w3.org/1999/xhtml">We created intervals that included 0–200, 200–500, 500–1000, 1000–2000, and more than 2,000 by setting the upper limit to infinite with </span><strong class="source-inline"><span class="koboSpan" id="kobo.827.1" xmlns:="http://www.w3.org/1999/xhtml">np.inf</span></strong><span class="koboSpan" id="kobo.828.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.828.2" xmlns:="http://www.w3.org/1999/xhtml">Next, we created a list with the interval names as strings. </span><span class="koboSpan" id="kobo.828.3" xmlns:="http://www.w3.org/1999/xhtml">Using pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.829.1" xmlns:="http://www.w3.org/1999/xhtml">cut()</span></strong><span class="koboSpan" id="kobo.830.1" xmlns:="http://www.w3.org/1999/xhtml"> and passing the list with the interval limits, we sorted the variable values into the pre-defined bins. </span><span class="koboSpan" id="kobo.830.2" xmlns:="http://www.w3.org/1999/xhtml">We executed the command twice; in the first run, we set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.831.1" xmlns:="http://www.w3.org/1999/xhtml">labels</span></strong><span class="koboSpan" id="kobo.832.1" xmlns:="http://www.w3.org/1999/xhtml"> argument to </span><strong class="source-inline"><span class="koboSpan" id="kobo.833.1" xmlns:="http://www.w3.org/1999/xhtml">None</span></strong><span class="koboSpan" id="kobo.834.1" xmlns:="http://www.w3.org/1999/xhtml">, returning the interval limits as a result. </span><span class="koboSpan" id="kobo.834.2" xmlns:="http://www.w3.org/1999/xhtml">In the second run, we set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.835.1" xmlns:="http://www.w3.org/1999/xhtml">labels</span></strong><span class="koboSpan" id="kobo.836.1" xmlns:="http://www.w3.org/1999/xhtml"> argument to the list of strings. </span><span class="koboSpan" id="kobo.836.2" xmlns:="http://www.w3.org/1999/xhtml">We captured the returned output in two variables: the first one displays the interval limits as values and the second one has strings as values. </span><span class="koboSpan" id="kobo.836.3" xmlns:="http://www.w3.org/1999/xhtml">Finally, we counted the number of observations per variable using </span><span class="No-Break"><span class="koboSpan" id="kobo.837.1" xmlns:="http://www.w3.org/1999/xhtml">pandas </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.838.1" xmlns:="http://www.w3.org/1999/xhtml">value_counts()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.839.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.840.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, we automated the procedure with </span><strong class="source-inline"><span class="koboSpan" id="kobo.841.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.842.1" xmlns:="http://www.w3.org/1999/xhtml">’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.843.1" xmlns:="http://www.w3.org/1999/xhtml">ArbitraryDiscretiser()</span></strong><span class="koboSpan" id="kobo.844.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.844.2" xmlns:="http://www.w3.org/1999/xhtml">This transformer takes a dictionary with the variables to discretize as keys and the interval limits in a list as values, and then uses pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.845.1" xmlns:="http://www.w3.org/1999/xhtml">cut()</span></strong><span class="koboSpan" id="kobo.846.1" xmlns:="http://www.w3.org/1999/xhtml"> under the hood to discretize the variables. </span><span class="koboSpan" id="kobo.846.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.847.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.848.1" xmlns:="http://www.w3.org/1999/xhtml">, the transformer does not learn any parameters but checks that the variables are numerical. </span><span class="koboSpan" id="kobo.848.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.849.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span><a id="_idTextAnchor592"/><a id="_idTextAnchor593"/></strong><span class="koboSpan" id="kobo.850.1" xmlns:="http://www.w3.org/1999/xhtml">, it discretizes </span><span class="No-Break"><span class="koboSpan" id="kobo.851.1" xmlns:="http://www.w3.org/1999/xhtml">the variables.</span></span></p>
<h1 id="_idParaDest-132"><span class="koboSpan" id="kobo.852.1" xmlns:="http://www.w3.org/1999/xhtml">Performing discretization </span><a id="_idTextAnchor594"/><span class="koboSpan" id="kobo.853.1" xmlns:="http://www.w3.org/1999/xhtml">with k-means clustering</span></h1>
<p><span class="koboSpan" id="kobo.854.1" xmlns:="http://www.w3.org/1999/xhtml">The aim o</span><a id="_idTextAnchor595"/><span class="koboSpan" id="kobo.855.1" xmlns:="http://www.w3.org/1999/xhtml">f a discretization </span><a id="_idIndexMarker316"/><span class="koboSpan" id="kobo.856.1" xmlns:="http://www.w3.org/1999/xhtml">procedure is to find a set of cut points that</span><a id="_idIndexMarker317"/><span class="koboSpan" id="kobo.857.1" xmlns:="http://www.w3.org/1999/xhtml"> partition a variable into a small number of intervals that have good class coherence. </span><span class="koboSpan" id="kobo.857.2" xmlns:="http://www.w3.org/1999/xhtml">To create partitions that group similar observations, we can use clustering algorithms such </span><span class="No-Break"><span class="koboSpan" id="kobo.858.1" xmlns:="http://www.w3.org/1999/xhtml">as k-means.</span></span></p>
<p><span class="koboSpan" id="kobo.859.1" xmlns:="http://www.w3.org/1999/xhtml">In</span><a id="_idIndexMarker318"/><span class="koboSpan" id="kobo.860.1" xmlns:="http://www.w3.org/1999/xhtml"> discretization using k-means clustering, the partitions are the clusters identified by the k-means algorithm. </span><span class="koboSpan" id="kobo.860.2" xmlns:="http://www.w3.org/1999/xhtml">The k-means clustering algorithm has two main steps. </span><span class="koboSpan" id="kobo.860.3" xmlns:="http://www.w3.org/1999/xhtml">In the initialization step, </span><em class="italic"><span class="koboSpan" id="kobo.861.1" xmlns:="http://www.w3.org/1999/xhtml">k</span></em><span class="koboSpan" id="kobo.862.1" xmlns:="http://www.w3.org/1999/xhtml"> observations are chosen randomly as the initial centers of the </span><em class="italic"><span class="koboSpan" id="kobo.863.1" xmlns:="http://www.w3.org/1999/xhtml">k</span></em><span class="koboSpan" id="kobo.864.1" xmlns:="http://www.w3.org/1999/xhtml"> clusters, and the remaining data points are assigned to the closest cluster. </span><span class="koboSpan" id="kobo.864.2" xmlns:="http://www.w3.org/1999/xhtml">The proximity to the cluster is measured by a distance measure, such as the Euclidean distance. </span><span class="koboSpan" id="kobo.864.3" xmlns:="http://www.w3.org/1999/xhtml">In the iteration step, the centers of the clusters are re-computed as the average of all of the observations within the cluster, and the observations are reassigned to the newly created closest cluster. </span><span class="koboSpan" id="kobo.864.4" xmlns:="http://www.w3.org/1999/xhtml">The iteration step continues until the optimal </span><em class="italic"><span class="koboSpan" id="kobo.865.1" xmlns:="http://www.w3.org/1999/xhtml">k</span></em><span class="koboSpan" id="kobo.866.1" xmlns:="http://www.w3.org/1999/xhtml"> centers </span><span class="No-Break"><span class="koboSpan" id="kobo.867.1" xmlns:="http://www.w3.org/1999/xhtml">are found.</span></span></p>
<p><span class="koboSpan" id="kobo.868.1" xmlns:="http://www.w3.org/1999/xhtml">Discretization with k-means requires one parameter, which is </span><em class="italic"><span class="koboSpan" id="kobo.869.1" xmlns:="http://www.w3.org/1999/xhtml">k</span></em><span class="koboSpan" id="kobo.870.1" xmlns:="http://www.w3.org/1999/xhtml">, the number of clusters. </span><span class="koboSpan" id="kobo.870.2" xmlns:="http://www.w3.org/1999/xhtml">There are a few methods to determine the optimal number of clusters. </span><span class="koboSpan" id="kobo.870.3" xmlns:="http://www.w3.org/1999/xhtml">One of them is the elbow method, which we will use in this recipe. </span><span class="koboSpan" id="kobo.870.4" xmlns:="http://www.w3.org/1999/xhtml">This m</span><a id="_idTextAnchor596"/><span class="koboSpan" id="kobo.871.1" xmlns:="http://www.w3.org/1999/xhtml">ethod consists of training s</span><a id="_idTextAnchor597"/><span class="koboSpan" id="kobo.872.1" xmlns:="http://www.w3.org/1999/xhtml">everal k-means algorithms over the data using different values of </span><em class="italic"><span class="koboSpan" id="kobo.873.1" xmlns:="http://www.w3.org/1999/xhtml">k</span></em><span class="koboSpan" id="kobo.874.1" xmlns:="http://www.w3.org/1999/xhtml">, and then determining the explained variation returned by the clustering. </span><span class="koboSpan" id="kobo.874.2" xmlns:="http://www.w3.org/1999/xhtml">In the next step, we plot the explained variation as a function of the number of clusters, </span><em class="italic"><span class="koboSpan" id="kobo.875.1" xmlns:="http://www.w3.org/1999/xhtml">k</span></em><span class="koboSpan" id="kobo.876.1" xmlns:="http://www.w3.org/1999/xhtml">, and pick the </span><em class="italic"><span class="koboSpan" id="kobo.877.1" xmlns:="http://www.w3.org/1999/xhtml">elbow</span></em><span class="koboSpan" id="kobo.878.1" xmlns:="http://www.w3.org/1999/xhtml"> of the curve as the number of clusters to use. </span><span class="koboSpan" id="kobo.878.2" xmlns:="http://www.w3.org/1999/xhtml">The elbow is the inflection point that indicates that increasing the number of </span><em class="italic"><span class="koboSpan" id="kobo.879.1" xmlns:="http://www.w3.org/1999/xhtml">k</span></em><span class="koboSpan" id="kobo.880.1" xmlns:="http://www.w3.org/1999/xhtml"> further does not significantly increase the variance explained by the model. </span><span class="koboSpan" id="kobo.880.2" xmlns:="http://www.w3.org/1999/xhtml">There are different metrics to quantify the explained variation. </span><span class="koboSpan" id="kobo.880.3" xmlns:="http://www.w3.org/1999/xhtml">We will use the sum of the square distances from each point to its </span><span class="No-Break"><span class="koboSpan" id="kobo.881.1" xmlns:="http://www.w3.org/1999/xhtml">assigned center.</span></span></p>
<p><span class="koboSpan" id="kobo.882.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will use the Python library </span><strong class="source-inline"><span class="koboSpan" id="kobo.883.1" xmlns:="http://www.w3.org/1999/xhtml">yellowbrick</span></strong><span class="koboSpan" id="kobo.884.1" xmlns:="http://www.w3.org/1999/xhtml"> to determine the optimal number of clusters and then carry out k-means</span><a id="_idTextAnchor598"/><a id="_idTextAnchor599"/><span class="koboSpan" id="kobo.885.1" xmlns:="http://www.w3.org/1999/xhtml"> discretization </span><span class="No-Break"><span class="koboSpan" id="kobo.886.1" xmlns:="http://www.w3.org/1999/xhtml">with scikit-learn.</span></span></p>
<h2 id="_idParaDest-133"><a id="_idTextAnchor600"/><span class="koboSpan" id="kobo.887.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.888.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s start by importing the necessary Python libraries and get the </span><span class="No-Break"><span class="koboSpan" id="kobo.889.1" xmlns:="http://www.w3.org/1999/xhtml">dataset ready:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.890.1" xmlns:="http://www.w3.org/1999/xhtml">Import </span><a id="_idIndexMarker319"/><span class="koboSpan" id="kobo.891.1" xmlns:="http://www.w3.org/1999/xhtml">the required Python libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.892.1" xmlns:="http://www.w3.org/1999/xhtml">and classes:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.893.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import KBinsDiscretizer
from yellowbrick.cluster import KElbowVisualizer</span></pre></li> <li><span class="koboSpan" id="kobo.894.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s </span><a id="_idIndexMarker320"/><span class="koboSpan" id="kobo.895.1" xmlns:="http://www.w3.org/1999/xhtml">load the California housing dataset into a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.896.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.897.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.898.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_</span><a id="_idTextAnchor601"/><span class="koboSpan" id="kobo.899.1" xmlns:="http://www.w3.org/1999/xhtml">X_y=True, as_fram</span><a id="_idTextAnchor602"/><span class="koboSpan" id="kobo.900.1" xmlns:="http://www.w3.org/1999/xhtml">e=True)</span></pre></li> <li><span class="koboSpan" id="kobo.901.1" xmlns:="http://www.w3.org/1999/xhtml">The k-means optimal clusters should be determined using the train set, so let’s divide the data into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.902.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.903.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.904.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s make a list with the variables </span><span class="No-Break"><span class="koboSpan" id="kobo.905.1" xmlns:="http://www.w3.org/1999/xhtml">to transform:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.906.1" xmlns:="http://www.w3.org/1999/xhtml">
variables = ['MedInc', 'HouseAge', 'AveRooms']</span></pre></li> <li><span class="koboSpan" id="kobo.907.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up a k-means </span><span class="No-Break"><span class="koboSpan" id="kobo.908.1" xmlns:="http://www.w3.org/1999/xhtml">clustering algorithm:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.909.1" xmlns:="http://www.w3.org/1999/xhtml">
k_means = KMeans(random_state=10)</span></pre></li> <li><span class="koboSpan" id="kobo.910.1" xmlns:="http://www.w3.org/1999/xhtml">Now, using Yellowbrick’s visualizer and the elbow method, let’s find the optimal number of clusters for </span><span class="No-Break"><span class="koboSpan" id="kobo.911.1" xmlns:="http://www.w3.org/1999/xhtml">each variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.912.1" xmlns:="http://www.w3.org/1999/xhtml">
for variable in variables:
    # set up a visualizer
    visualizer = KElbowVisualizer(
        k_means, k=(4,12),
        metric='distortion',
        timings=False)
    visualizer.fit(X_train[variable].to_f</span><a id="_idTextAnchor603"/><span class="koboSpan" id="kobo.913.1" xmlns:="http://www.w3.org/1999/xhtml">rame())
    visualiz</span><a id="_idTextAnchor604"/><span class="koboSpan" id="kobo.914.1" xmlns:="http://www.w3.org/1999/xhtml">er.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.915.1" xmlns:="http://www.w3.org/1999/xhtml">In the </span><a id="_idIndexMarker321"/><span class="koboSpan" id="kobo.916.1" xmlns:="http://www.w3.org/1999/xhtml">following </span><a id="_idIndexMarker322"/><span class="koboSpan" id="kobo.917.1" xmlns:="http://www.w3.org/1999/xhtml">plots, we see that the optimal number of clusters is six for the first t</span><a id="_idTextAnchor605"/><span class="koboSpan" id="kobo.918.1" xmlns:="http://www.w3.org/1999/xhtml">wo variables and seven for </span><span class="No-Break"><span class="koboSpan" id="kobo.919.1" xmlns:="http://www.w3.org/1999/xhtml">the third:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer072">
<span class="koboSpan" id="kobo.920.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.9 – The number of clusters versus the explained variation for the MedInc, HouseAge, and AveRooms variables, from top to bottom" src="image/B22396_04_9.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.921.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.9 – The number of clusters versus the explained variation for the MedInc, HouseAge, and AveRooms variables, from top to bottom</span></p>
<ol>
<li value="7"><span class="koboSpan" id="kobo.922.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set </span><a id="_idIndexMarker323"/><span class="koboSpan" id="kobo.923.1" xmlns:="http://www.w3.org/1999/xhtml">up a discretizer that</span><a id="_idIndexMarker324"/><span class="koboSpan" id="kobo.924.1" xmlns:="http://www.w3.org/1999/xhtml"> uses k-means clustering to create six partitions and returns the clusters as </span><span class="No-Break"><span class="koboSpan" id="kobo.925.1" xmlns:="http://www.w3.org/1999/xhtml">one-hot-encoded variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.926.1" xmlns:="http://www.w3.org/1999/xhtml">
disc = KBinsDiscretizer(
    n_bins=6,
    encode="onehot-dense",
    strategy="kmeans",
    subsample=None,
).set_output(transform="pandas")</span></pre></li> <li><span class="koboSpan" id="kobo.927.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit </span><a id="_idIndexMarker325"/><span class="koboSpan" id="kobo.928.1" xmlns:="http://www.w3.org/1999/xhtml">the discretizer to the slice of the</span><a id="_idIndexMarker326"/><span class="koboSpan" id="kobo.929.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame that contains the variables to discretize so that it finds the clusters for </span><span class="No-Break"><span class="koboSpan" id="kobo.930.1" xmlns:="http://www.w3.org/1999/xhtml">each variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.931.1" xmlns:="http://www.w3.org/1999/xhtml">
disc.fit(X_train[variables])</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.932.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.933.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we sort the values of all three of the variables into six clusters. </span><span class="koboSpan" id="kobo.933.2" xmlns:="http://www.w3.org/1999/xhtml">To discretize </span><strong class="source-inline"><span class="koboSpan" id="kobo.934.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.935.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.936.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.937.1" xmlns:="http://www.w3.org/1999/xhtml"> into six partitions and </span><strong class="source-inline"><span class="koboSpan" id="kobo.938.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms</span></strong><span class="koboSpan" id="kobo.939.1" xmlns:="http://www.w3.org/1999/xhtml"> into seven, we would set up one instance of the discretizer for each variable group and use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.940.1" xmlns:="http://www.w3.org/1999/xhtml">ColumnTransformer()</span></strong><span class="koboSpan" id="kobo.941.1" xmlns:="http://www.w3.org/1999/xhtml"> to restrict the discretization to </span><span class="No-Break"><span class="koboSpan" id="kobo.942.1" xmlns:="http://www.w3.org/1999/xhtml">each group.</span></span></p>
<ol>
<li value="9"><span class="koboSpan" id="kobo.943.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s inspect the </span><span class="No-Break"><span class="koboSpan" id="kobo.944.1" xmlns:="http://www.w3.org/1999/xhtml">cut points:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.945.1" xmlns:="http://www.w3.org/1999/xhtml">
disc.bin_edges_</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.946.1" xmlns:="http://www.w3.org/1999/xhtml">Each array contains the cut points for the six clusters for </span><strong class="source-inline"><span class="koboSpan" id="kobo.947.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.948.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.949.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.950.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><span class="No-Break"><span class="koboSpan" id="kobo.951.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.952.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.953.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.954.1" xmlns:="http://www.w3.org/1999/xhtml">array([array([0.4999, 2.49587954, 3.66599029, 4.95730115, 6.67700141, 9.67326677, 15.0001]),</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.955.1" xmlns:="http://www.w3.org/1999/xhtml">array([1., 11.7038878, 19.88430419, 27.81472503, 35.39424098, 43.90930314, 52.]),</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.956.1" xmlns:="http://www.w3.org/1999/xhtml">array([0.84615385, 4.84568771, 6.62222005, 15.24138445, 37.60664483, 92.4473438, 132.53333333])], dtype=object)</span></strong></pre></li> <li><span class="koboSpan" id="kobo.957.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s obtain the discretized form of the variables in the train </span><span class="No-Break"><span class="koboSpan" id="kobo.958.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.959.1" xmlns:="http://www.w3.org/1999/xhtml">
train_features = disc.transform(X_train[variables])
test_features = disc.transform(X_test[variables])</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.960.1" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.961.1" xmlns:="http://www.w3.org/1999/xhtml">print(test_features)</span></strong><span class="koboSpan" id="kobo.962.1" xmlns:="http://www.w3.org/1999/xhtml">, we can </span><a id="_idTextAnchor606"/><span class="koboSpan" id="kobo.963.1" xmlns:="http://www.w3.org/1999/xhtml">inspect the DataFrame that is returned by the discretizer. </span><span class="koboSpan" id="kobo.963.2" xmlns:="http://www.w3.org/1999/xhtml">It contains 18 binary variables correspond</span><a id="_idTextAnchor607"/><span class="koboSpan" id="kobo.964.1" xmlns:="http://www.w3.org/1999/xhtml">ing to the one-hot-encoded </span><a id="_idIndexMarker327"/><span class="koboSpan" id="kobo.965.1" xmlns:="http://www.w3.org/1999/xhtml">transformation </span><a id="_idIndexMarker328"/><span class="koboSpan" id="kobo.966.1" xmlns:="http://www.w3.org/1999/xhtml">of the six clusters returned for each of the three </span><span class="No-Break"><span class="koboSpan" id="kobo.967.1" xmlns:="http://www.w3.org/1999/xhtml">numerical variables:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.968.1" xmlns:="http://www.w3.org/1999/xhtml">         MedInc_0.0  MedInc_1.0  MedInc_2.0  MedInc_3.0  MedInc_4.0  MedInc_5.0  \</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.969.1" xmlns:="http://www.w3.org/1999/xhtml">14740            0.0            0.0            </span></strong><strong class="bold"><span class="koboSpan" id="kobo.970.1" xmlns:="http://www.w3.org/1999/xhtml">1.0            0.0            0.0            0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.971.1" xmlns:="http://www.w3.org/1999/xhtml">10101            0.0            0.0            0.0            1.0            0.0            </span></strong><strong class="bold"><span class="koboSpan" id="kobo.972.1" xmlns:="http://www.w3.org/1999/xhtml">0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.973.1" xmlns:="http://www.w3.org/1999/xhtml">20566            0.0            0.0            1.0            0.0            0.0            0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.974.1" xmlns:="http://www.w3.org/1999/xhtml">2670              1.0            </span></strong><strong class="bold"><span class="koboSpan" id="kobo.975.1" xmlns:="http://www.w3.org/1999/xhtml">0.0            0.0            0.0            0.0            0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.976.1" xmlns:="http://www.w3.org/1999/xhtml">15709            0.0            0.0            0.0            1.0            </span></strong><strong class="bold"><span class="koboSpan" id="kobo.977.1" xmlns:="http://www.w3.org/1999/xhtml">0.0            0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.978.1" xmlns:="http://www.w3.org/1999/xhtml">         HouseAge_0.0  HouseAge_1.0  HouseAge_2.0  HouseAge_3.0  HouseAge_4.0  \</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.979.1" xmlns:="http://www.w3.org/1999/xhtml">14740               0.0</span></strong><strong class="bold"><span class="koboSpan" id="kobo.980.1" xmlns:="http://www.w3.org/1999/xhtml">               0.0               1.0               0.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.981.1" xmlns:="http://www.w3.org/1999/xhtml">10101               0.0               0.0               0.0               1.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.982.1" xmlns:="http://www.w3.org/1999/xhtml">20566               0.0               0.0               0.0               1.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.983.1" xmlns:="http://www.w3.org/1999/xhtml">2670                 0.0               0.0               0.0</span></strong><strong class="bold"><span class="koboSpan" id="kobo.984.1" xmlns:="http://www.w3.org/1999/xhtml">               0.0               1.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.985.1" xmlns:="http://www.w3.org/1999/xhtml">15709               0.0               0.0               1.0               0.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.986.1" xmlns:="http://www.w3.org/1999/xhtml">         HouseAge_5.0</span></strong><strong class="bold"><span class="koboSpan" id="kobo.987.1" xmlns:="http://www.w3.org/1999/xhtml">  AveRooms_0.0  AveRooms_1.0  AveRooms_2.0  AveRooms_3.0  \</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.988.1" xmlns:="http://www.w3.org/1999/xhtml">14740               0.0               0.0               1.0               0.0               </span></strong><strong class="bold"><span class="koboSpan" id="kobo.989.1" xmlns:="http://www.w3.org/1999/xhtml">0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.990.1" xmlns:="http://www.w3.org/1999/xhtml">10101               0.0               0.0               1.0               0.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.991.1" xmlns:="http://www.w3.org/1999/xhtml">20566               0.0               0.0               </span></strong><strong class="bold"><span class="koboSpan" id="kobo.992.1" xmlns:="http://www.w3.org/1999/xhtml">1.0               0.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.993.1" xmlns:="http://www.w3.org/1999/xhtml">2670                 0.0               0.0               1.0               0.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.994.1" xmlns:="http://www.w3.org/1999/xhtml">15709               </span></strong><strong class="bold"><span class="koboSpan" id="kobo.995.1" xmlns:="http://www.w3.org/1999/xhtml">0.0               1.0               0.0               0.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.996.1" xmlns:="http://www.w3.org/1999/xhtml">         AveRooms_4.0  AveRooms_5.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.997.1" xmlns:="http://www.w3.org/1999/xhtml">14740               0.0               </span></strong><strong class="bold"><span class="koboSpan" id="kobo.998.1" xmlns:="http://www.w3.org/1999/xhtml">0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.999.1" xmlns:="http://www.w3.org/1999/xhtml">10101               0.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.1000.1" xmlns:="http://www.w3.org/1999/xhtml">20566               0.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.1001.1" xmlns:="http://www.w3.org/1999/xhtml">2670                 0.0               0.0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.1002.1" xmlns:="http://www.w3.org/1999/xhtml">15709               0.0               0.0</span></strong></pre></li> </ol>
<p><span class="koboSpan" id="kobo.1003.1" xmlns:="http://www.w3.org/1999/xhtml">You</span><a id="_idIndexMarker329"/><span class="koboSpan" id="kobo.1004.1" xmlns:="http://www.w3.org/1999/xhtml"> can </span><a id="_idIndexMarker330"/><span class="koboSpan" id="kobo.1005.1" xmlns:="http://www.w3.org/1999/xhtml">concatenate the result to the original DataFrame using </span><strong class="source-inline"><span class="koboSpan" id="kobo.1006.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.1007.1" xmlns:="http://www.w3.org/1999/xhtml"> and then drop the original numerical variables. </span><span class="koboSpan" id="kobo.1007.2" xmlns:="http://www.w3.org/1999/xhtml">Alternatively, use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1008.1" xmlns:="http://www.w3.org/1999/xhtml">ColumnTransformer()</span></strong><span class="koboSpan" id="kobo.1009.1" xmlns:="http://www.w3.org/1999/xhtml"> class to restrict the discretization to the selected variables and add the result to th</span><a id="_idTextAnchor608"/><a id="_idTextAnchor609"/><span class="koboSpan" id="kobo.1010.1" xmlns:="http://www.w3.org/1999/xhtml">e data by setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.1011.1" xmlns:="http://www.w3.org/1999/xhtml">remainder</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.1012.1" xmlns:="http://www.w3.org/1999/xhtml">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1013.1" xmlns:="http://www.w3.org/1999/xhtml">"passthrough"</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1014.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-134"><a id="_idTextAnchor610"/><span class="koboSpan" id="kobo.1015.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.1016.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we performed discretization</span><a id="_idIndexMarker331"/><span class="koboSpan" id="kobo.1017.1" xmlns:="http://www.w3.org/1999/xhtml"> with k-means clustering. </span><span class="koboSpan" id="kobo.1017.2" xmlns:="http://www.w3.org/1999/xhtml">First</span><a id="_idTextAnchor611"/><span class="koboSpan" id="kobo.1018.1" xmlns:="http://www.w3.org/1999/xhtml">, we identified the optimal number of clusters utilizing the elbow method by using </span><span class="No-Break"><span class="koboSpan" id="kobo.1019.1" xmlns:="http://www.w3.org/1999/xhtml">Yellowbrick’s </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1020.1" xmlns:="http://www.w3.org/1999/xhtml">KElbowVisualizer()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1021.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.1022.1" xmlns:="http://www.w3.org/1999/xhtml">To perform k-means</span><a id="_idIndexMarker332"/><span class="koboSpan" id="kobo.1023.1" xmlns:="http://www.w3.org/1999/xhtml"> discretization, we used scikit-learn’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.1024.1" xmlns:="http://www.w3.org/1999/xhtml">KBinsDiscretizer()</span></strong><span class="koboSpan" id="kobo.1025.1" xmlns:="http://www.w3.org/1999/xhtml">, setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.1026.1" xmlns:="http://www.w3.org/1999/xhtml">strategy</span></strong><span class="koboSpan" id="kobo.1027.1" xmlns:="http://www.w3.org/1999/xhtml"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.1028.1" xmlns:="http://www.w3.org/1999/xhtml">kmeans</span></strong><span class="koboSpan" id="kobo.1029.1" xmlns:="http://www.w3.org/1999/xhtml"> and the number of clusters to six in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1030.1" xmlns:="http://www.w3.org/1999/xhtml">n_bins</span></strong><span class="koboSpan" id="kobo.1031.1" xmlns:="http://www.w3.org/1999/xhtml"> argument. </span><span class="koboSpan" id="kobo.1031.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.1032.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.1033.1" xmlns:="http://www.w3.org/1999/xhtml">, the transformer learned the cluster boundaries using the k-means algorithm. </span><span class="koboSpan" id="kobo.1033.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.1034.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.1035.1" xmlns:="http://www.w3.org/1999/xhtml">, it sorted the variable values to their corresponding cluster. </span><span class="koboSpan" id="kobo.1035.2" xmlns:="http://www.w3.org/1999/xhtml">We set </span><strong class="source-inline"><span class="koboSpan" id="kobo.1036.1" xmlns:="http://www.w3.org/1999/xhtml">encode</span></strong><span class="koboSpan" id="kobo.1037.1" xmlns:="http://www.w3.org/1999/xhtml"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.1038.1" xmlns:="http://www.w3.org/1999/xhtml">"onehot-dense"</span></strong><span class="koboSpan" id="kobo.1039.1" xmlns:="http://www.w3.org/1999/xhtml">; hence, after the discretization, the transformer applied one-hot encoding to the clusters. </span><span class="koboSpan" id="kobo.1039.2" xmlns:="http://www.w3.org/1999/xhtml">We also set the output of the discretizer to </span><strong class="source-inline"><span class="koboSpan" id="kobo.1040.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.1041.1" xmlns:="http://www.w3.org/1999/xhtml">, and with that, the transformer returned the one-hot encoded ver</span><a id="_idTextAnchor612"/><a id="_idTextAnchor613"/><span class="koboSpan" id="kobo.1042.1" xmlns:="http://www.w3.org/1999/xhtml">sion of the clustered variables as </span><span class="No-Break"><span class="koboSpan" id="kobo.1043.1" xmlns:="http://www.w3.org/1999/xhtml">a DataFrame.</span></span></p>
<h2 id="_idParaDest-135"><a id="_idTextAnchor614"/><span class="koboSpan" id="kobo.1044.1" xmlns:="http://www.w3.org/1999/xhtml">See also</span></h2>
<ul>
<li><span class="koboSpan" id="kobo.1045.1" xmlns:="http://www.w3.org/1999/xhtml">Discretization with k-means is described in the article found  in </span><em class="italic"><span class="koboSpan" id="kobo.1046.1" xmlns:="http://www.w3.org/1999/xhtml">Palaniappan and Hong, Discretization of Continuous Valued Dimensions in OLAP Data Cube</span></em><span class="koboSpan" id="kobo.1047.1" xmlns:="http://www.w3.org/1999/xhtml">s. </span><span class="koboSpan" id="kobo.1047.2" xmlns:="http://www.w3.org/1999/xhtml">International Journal of Computer Science and Network Security, VOL.8 No.11, November </span><span class="No-Break"><span class="koboSpan" id="kobo.1048.1" xmlns:="http://www.w3.org/1999/xhtml">2008. </span></span><a href="http://paper.ijcsns.org/07_book/200811/20081117.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.1049.1" xmlns:="http://www.w3.org/1999/xhtml">http://paper.i</span><span id="_idTextAnchor615"/><span class="koboSpan" id="kobo.1050.1" xmlns:="http://www.w3.org/1999/xhtml">jcsns.org/07_book/200811/20081117.pdf</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1051.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></li>
<li><span class="koboSpan" id="kobo.1052.1" xmlns:="http://www.w3.org/1999/xhtml">To learn more about the elbow method, visit Yellowbrick’s documentation and references </span><span class="No-Break"><span class="koboSpan" id="kobo.1053.1" xmlns:="http://www.w3.org/1999/xhtml">at </span></span><a href="https://www.scikit-yb.org/en/latest/api/cluster/elbow.html"><span class="No-Break"><span class="koboSpan" id="kobo.1054.1" xmlns:="http://www.w3.org/1999/xhtml">https://www.scikit-yb.org/en/latest/api/cluster/elbow.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1055.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></li>
<li><span class="koboSpan" id="kobo.1056.1" xmlns:="http://www.w3.org/1999/xhtml">For other ways of determining the fit of k-means clustering, check out the additional visualizers in Yellowbrick </span><span class="No-Break"><span class="koboSpan" id="kobo.1057.1" xmlns:="http://www.w3.org/1999/xhtml">at </span><a id="_idTextAnchor616"/></span><a href="https://www.scikit-yb.org/en/latest/api/cluster/index.html"><span class="No-Break"><span class="koboSpan" id="kobo.1058.1" xmlns:="http://www.w3.org/1999/xhtml">https://www.</span><span id="_idTextAnchor617"/><span id="_idTextAnchor618"/><span class="koboSpan" id="kobo.1059.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-yb.org/en/latest/api/cluster/index.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1060.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></li>
</ul>
<h1 id="_idParaDest-136"><a id="_idTextAnchor619"/><span class="koboSpan" id="kobo.1061.1" xmlns:="http://www.w3.org/1999/xhtml">Implementing feature binarization</span></h1>
<p><span class="koboSpan" id="kobo.1062.1" xmlns:="http://www.w3.org/1999/xhtml">Some datasets</span><a id="_idIndexMarker333"/><span class="koboSpan" id="kobo.1063.1" xmlns:="http://www.w3.org/1999/xhtml"> contain sparse variables. </span><span class="koboSpan" id="kobo.1063.2" xmlns:="http://www.w3.org/1999/xhtml">Sparse variables are those where the majority of the values are 0. </span><span class="koboSpan" id="kobo.1063.3" xmlns:="http://www.w3.org/1999/xhtml">The classical example of sparse va</span><a id="_idTextAnchor620"/><span class="koboSpan" id="kobo.1064.1" xmlns:="http://www.w3.org/1999/xhtml">riables are those derived from text data through the bag-of-words model, where each variable is a word and each value represents the number of times the word appears in a certain document. </span><span class="koboSpan" id="kobo.1064.2" xmlns:="http://www.w3.org/1999/xhtml">Given that a document contains a limited number of words, whereas the feature space contains the words that appear across all documents, most documents, that is, most rows, will show a value of 0 for most columns. </span><span class="koboSpan" id="kobo.1064.3" xmlns:="http://www.w3.org/1999/xhtml">However, words are not the </span><a id="_idIndexMarker334"/><span class="koboSpan" id="kobo.1065.1" xmlns:="http://www.w3.org/1999/xhtml">sole example. </span><span class="koboSpan" id="kobo.1065.2" xmlns:="http://www.w3.org/1999/xhtml">If we think about house details data, the </span><em class="italic"><span class="koboSpan" id="kobo.1066.1" xmlns:="http://www.w3.org/1999/xhtml">number of saunas</span></em><span class="koboSpan" id="kobo.1067.1" xmlns:="http://www.w3.org/1999/xhtml"> variable will also be 0 for most houses. </span><span class="koboSpan" id="kobo.1067.2" xmlns:="http://www.w3.org/1999/xhtml">In summary, some variables have very skewed distributions, where most observations show the same value, usually 0, and only a few observations show different, usually </span><span class="No-Break"><span class="koboSpan" id="kobo.1068.1" xmlns:="http://www.w3.org/1999/xhtml">higher, values.</span></span></p>
<p><span class="koboSpan" id="kobo.1069.1" xmlns:="http://www.w3.org/1999/xhtml">For a simpler representation of these sparse or highly skewed variables, we can binarize them by clipping all values greater than 1 to 1. </span><span class="koboSpan" id="kobo.1069.2" xmlns:="http://www.w3.org/1999/xhtml">In fact, binarization is commonly performed on text count data, where we consider the presence or absence of a feature rather than a quantified number of occurrences of </span><span class="No-Break"><span class="koboSpan" id="kobo.1070.1" xmlns:="http://www.w3.org/1999/xhtml">a word.</span></span></p>
<p><span class="koboSpan" id="kobo.1071.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe,</span><a id="_idTextAnchor621"/><a id="_idTextAnchor622"/><span class="koboSpan" id="kobo.1072.1" xmlns:="http://www.w3.org/1999/xhtml"> we will perform binarizat</span><a id="_idTextAnchor623"/><span class="koboSpan" id="kobo.1073.1" xmlns:="http://www.w3.org/1999/xhtml">ion </span><span class="No-Break"><span class="koboSpan" id="kobo.1074.1" xmlns:="http://www.w3.org/1999/xhtml">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1075.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1076.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-137"><a id="_idTextAnchor624"/><span class="koboSpan" id="kobo.1077.1" xmlns:="http://www.w3.org/1999/xhtml">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.1078.1" xmlns:="http://www.w3.org/1999/xhtml">We will use a dataset consisting of a bag of words, which is available in the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Bag+of+Words). </span><span class="koboSpan" id="kobo.1078.2" xmlns:="http://www.w3.org/1999/xhtml">It is licensed under CC BY </span><span class="No-Break"><span class="koboSpan" id="kobo.1079.1" xmlns:="http://www.w3.org/1999/xhtml">4.0 (</span></span><a href="https://creativecommons.org/licenses/by/4.0/legalcode"><span class="No-Break"><span class="koboSpan" id="kobo.1080.1" xmlns:="http://www.w3.org/1999/xhtml">https://creativecommons.org/licenses/by/4.0/legalcode</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1081.1" xmlns:="http://www.w3.org/1999/xhtml">).</span></span></p>
<p><span class="koboSpan" id="kobo.1082.1" xmlns:="http://www.w3.org/1999/xhtml">I downloaded and prepared a small bag of words representing a simplified version of one of those datasets. </span><span class="koboSpan" id="kobo.1082.2" xmlns:="http://www.w3.org/1999/xhtml">You will find this dataset in the accompanying </span><span class="No-Break"><span class="koboSpan" id="kobo.1083.1" xmlns:="http://www.w3.org/1999/xhtml">GitHub repository:</span></span></p>
<p><span class="No-Break"><span class="koboSpan" id="kobo.1084.1" xmlns:="http://www.w3.org/1999/xhtml">https://github.com/PacktPublishing/Python-Feature-Engineering-Coo</span><a id="_idTextAnchor625"/><a id="_idTextAnchor626"/><span class="koboSpan" id="kobo.1085.1" xmlns:="http://www.w3.org/1999/xhtml">kbook-Third-Edition/tr</span><a id="_idTextAnchor627"/><span class="koboSpan" id="kobo.1086.1" xmlns:="http://www.w3.org/1999/xhtml">ee/main/ch04-discretization</span></span></p>
<h2 id="_idParaDest-138"><a id="_idTextAnchor628"/><span class="koboSpan" id="kobo.1087.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.1088.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by importing the libraries and loading </span><span class="No-Break"><span class="koboSpan" id="kobo.1089.1" xmlns:="http://www.w3.org/1999/xhtml">the data:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.1090.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the required Python libraries, classes, </span><span class="No-Break"><span class="koboSpan" id="kobo.1091.1" xmlns:="http://www.w3.org/1999/xhtml">and datasets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1092.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import Binarizer</span></pre></li> <li><span class="koboSpan" id="kobo.1093.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the bag of words dataset, which contains words as columns and different texts </span><span class="No-Break"><span class="koboSpan" id="kobo.1094.1" xmlns:="http://www.w3.org/1999/xhtml">as rows:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1095.1" xmlns:="http://www.w3.org/1999/xhtml">
data = pd.read_csv("bag_of_words.csv")</span></pre></li> <li><span class="koboSpan" id="kobo.1096.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s</span><a id="_idIndexMarker335"/><span class="koboSpan" id="kobo.1097.1" xmlns:="http://www.w3.org/1999/xhtml"> display histograms to visualize the sparsity of </span><span class="No-Break"><span class="koboSpan" id="kobo.1098.1" xmlns:="http://www.w3.org/1999/xhtml">the variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1099.1" xmlns:="http://www.w3.org/1999/xhtml">
data.hist(bins=30, figsize=(20, 20), layout=(3,4))
plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1100.1" xmlns:="http://www.w3.org/1999/xhtml">In the following histograms, we can see that the dif</span><a id="_idTextAnchor629"/><span class="koboSpan" id="kobo.1101.1" xmlns:="http://www.w3.org/1999/xhtml">ferent words appear zero times in </span><span class="No-Break"><span class="koboSpan" id="kobo.1102.1" xmlns:="http://www.w3.org/1999/xhtml">most documents:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer073">
<span class="koboSpan" id="kobo.1103.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.10 – Histograms representing th﻿e number of times each word appears in a document" src="image/B22396_04_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1104.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.10 – Histograms representing th</span><a id="_idTextAnchor630"/><span class="koboSpan" id="kobo.1105.1" xmlns:="http://www.w3.org/1999/xhtml">e number of times each word appears in a document</span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.1106.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s </span><a id="_idIndexMarker336"/><span class="koboSpan" id="kobo.1107.1" xmlns:="http://www.w3.org/1999/xhtml">set up </span><strong class="source-inline"><span class="koboSpan" id="kobo.1108.1" xmlns:="http://www.w3.org/1999/xhtml">binarizer</span></strong><span class="koboSpan" id="kobo.1109.1" xmlns:="http://www.w3.org/1999/xhtml"> to clip all values greater than 1 to 1 and return DataFrames as </span><span class="No-Break"><span class="koboSpan" id="kobo.1110.1" xmlns:="http://www.w3.org/1999/xhtml">a result:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1111.1" xmlns:="http://www.w3.org/1999/xhtml">
binarizer = Binarizer(th</span><a id="_idTextAnchor631"/><span class="koboSpan" id="kobo.1112.1" xmlns:="http://www.w3.org/1999/xhtml">reshold = 0) .set_output(transform="pandas")</span></pre></li> <li><span class="koboSpan" id="kobo.1113.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s binarize </span><span class="No-Break"><span class="koboSpan" id="kobo.1114.1" xmlns:="http://www.w3.org/1999/xhtml">the variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1115.1" xmlns:="http://www.w3.org/1999/xhtml">
data_t = binarizer.fit_transform(data)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1116.1" xmlns:="http://www.w3.org/1999/xhtml">Now we can explore the distribution of the binarized variables by displaying the histograms as </span><a id="_idTextAnchor632"/><span class="koboSpan" id="kobo.1117.1" xmlns:="http://www.w3.org/1999/xhtml">in </span><em class="italic"><span class="koboSpan" id="kobo.1118.1" xmlns:="http://www.w3.org/1999/xhtml">step 3</span></em><span class="koboSpan" id="kobo.1119.1" xmlns:="http://www.w3.org/1999/xhtml">, or better, by creating </span><span class="No-Break"><span class="koboSpan" id="kobo.1120.1" xmlns:="http://www.w3.org/1999/xhtml">bar plots.</span></span></p></li> <li><span class="koboSpan" id="kobo.1121.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s</span><a id="_idIndexMarker337"/><span class="koboSpan" id="kobo.1122.1" xmlns:="http://www.w3.org/1999/xhtml"> create a bar plot with the number of observations per bin </span><span class="No-Break"><span class="koboSpan" id="kobo.1123.1" xmlns:="http://www.w3.org/1999/xhtml">per variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1124.1" xmlns:="http://www.w3.org/1999/xhtml">
variables = data_t.columns.to_list()
plt.figure(figsize=(20, 20), constrained_layout=True)
for i in range(10):
    ax = plt.subplot(3, 4, i + 1)
    var = variables[i]
    t = data_t[var].value_counts(normalize=True)
    t.plot.bar(ax=ax)
    plt.xticks(rotation=0)
    plt.ylabel("Observations per bin")
    ax.set_title(var)
plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1125.1" xmlns:="http://www.w3.org/1999/xhtml">In the following plot, we can see the binarized v</span><a id="_idTextAnchor633"/><span class="koboSpan" id="kobo.1126.1" xmlns:="http://www.w3.org/1999/xhtml">ariables, where most occurrences show the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1127.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1128.1" xmlns:="http://www.w3.org/1999/xhtml"> value:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer074">
<span class="koboSpan" id="kobo.1129.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.11 – Bar plots containing the number of documents that eithe﻿r show each one of the words or not" src="image/B22396_04_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1130.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.11 – Bar plots containing the number of documents that eithe</span><a id="_idTextAnchor634"/><span class="koboSpan" id="kobo.1131.1" xmlns:="http://www.w3.org/1999/xhtml">r show each one of the words or not</span></p>
<p><span class="koboSpan" id="kobo.1132.1" xmlns:="http://www.w3.org/1999/xhtml">That’s it;</span><a id="_idTextAnchor635"/><a id="_idTextAnchor636"/><span class="koboSpan" id="kobo.1133.1" xmlns:="http://www.w3.org/1999/xhtml"> now</span><a id="_idIndexMarker338"/><span class="koboSpan" id="kobo.1134.1" xmlns:="http://www.w3.org/1999/xhtml"> we have a simpler representation of </span><span class="No-Break"><span class="koboSpan" id="kobo.1135.1" xmlns:="http://www.w3.org/1999/xhtml">the data.</span></span></p>
<h2 id="_idParaDest-139"><a id="_idTextAnchor637"/><span class="koboSpan" id="kobo.1136.1" xmlns:="http://www.w3.org/1999/xhtml">How it works…</span></h2>
<p><span class="koboSpan" id="kobo.1137.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we changed the representation of sparse variables to consider the presence or absence of an occurrence, which, in our case, is a word. </span><span class="koboSpan" id="kobo.1137.2" xmlns:="http://www.w3.org/1999/xhtml">The data consisted of a bag of words, where each variable (column) is a wor</span><a id="_idTextAnchor638"/><span class="koboSpan" id="kobo.1138.1" xmlns:="http://www.w3.org/1999/xhtml">d, each row is a document, and the values represent the number of times the word appears in a document. </span><span class="koboSpan" id="kobo.1138.2" xmlns:="http://www.w3.org/1999/xhtml">Most words do not appear in</span><a id="_idIndexMarker339"/><span class="koboSpan" id="kobo.1139.1" xmlns:="http://www.w3.org/1999/xhtml"> most documents; therefore, most values in the data are 0. </span><span class="koboSpan" id="kobo.1139.2" xmlns:="http://www.w3.org/1999/xhtml">We corroborated the sparsity of our data </span><span class="No-Break"><span class="koboSpan" id="kobo.1140.1" xmlns:="http://www.w3.org/1999/xhtml">with histograms.</span></span></p>
<p><span class="koboSpan" id="kobo.1141.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.1142.1" xmlns:="http://www.w3.org/1999/xhtml">Binarizer()</span></strong><span class="koboSpan" id="kobo.1143.1" xmlns:="http://www.w3.org/1999/xhtml"> mapped values greater than the threshold, which, in our case, was 0, to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1144.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.1145.1" xmlns:="http://www.w3.org/1999/xhtml"> value, while values less than or equal to the threshold were mapped to 0. </span><strong class="source-inline"><span class="koboSpan" id="kobo.1146.1" xmlns:="http://www.w3.org/1999/xhtml">Binarizer()</span></strong><span class="koboSpan" id="kobo.1147.1" xmlns:="http://www.w3.org/1999/xhtml"> has the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1148.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.1149.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1150.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.1151.1" xmlns:="http://www.w3.org/1999/xhtml"> methods, where </span><strong class="source-inline"><span class="koboSpan" id="kobo.1152.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.1153.1" xmlns:="http://www.w3.org/1999/xhtml"> does not do anything and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1154.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.1155.1" xmlns:="http://www.w3.org/1999/xhtml"> binarizes </span><span class="No-Break"><span class="koboSpan" id="kobo.1156.1" xmlns:="http://www.w3.org/1999/xhtml">the variables.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1157.1" xmlns:="http://www.w3.org/1999/xhtml">Binarizer()</span></strong><span class="koboSpan" id="kobo.1158.1" xmlns:="http://www.w3.org/1999/xhtml"> modifies all variables in a dataset returning NumPy arrays by default. </span><span class="koboSpan" id="kobo.1158.2" xmlns:="http://www.w3.org/1999/xhtml">To return </span><strong class="source-inline"><span class="koboSpan" id="kobo.1159.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.1160.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFr</span><a id="_idTextAnchor639"/><a id="_idTextAnchor640"/><span class="koboSpan" id="kobo.1161.1" xmlns:="http://www.w3.org/1999/xhtml">ames instead, we set the transform output </span><span class="No-Break"><span class="koboSpan" id="kobo.1162.1" xmlns:="http://www.w3.org/1999/xhtml">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1163.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1164.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h1 id="_idParaDest-140"><a id="_idTextAnchor641"/><span class="koboSpan" id="kobo.1165.1" xmlns:="http://www.w3.org/1999/xhtml">Using decision trees for discretization</span></h1>
<p><span class="koboSpan" id="kobo.1166.1" xmlns:="http://www.w3.org/1999/xhtml">In all previous</span><a id="_idIndexMarker340"/><span class="koboSpan" id="kobo.1167.1" xmlns:="http://www.w3.org/1999/xhtml"> recipes in this chapter, we determined the number of intervals arbitrarily, and then the discretization algorithm would find the interval limits one way or another. </span><span class="koboSpan" id="kobo.1167.2" xmlns:="http://www.w3.org/1999/xhtml">Decision trees can find the interval limits and th</span><a id="_idTextAnchor642"/><span class="koboSpan" id="kobo.1168.1" xmlns:="http://www.w3.org/1999/xhtml">e optimal number of </span><span class="No-Break"><span class="koboSpan" id="kobo.1169.1" xmlns:="http://www.w3.org/1999/xhtml">bins autom</span><a id="_idTextAnchor643"/><span class="koboSpan" id="kobo.1170.1" xmlns:="http://www.w3.org/1999/xhtml">atically.</span></span></p>
<p><span class="koboSpan" id="kobo.1171.1" xmlns:="http://www.w3.org/1999/xhtml">Decision</span><a id="_idIndexMarker341"/><span class="koboSpan" id="kobo.1172.1" xmlns:="http://www.w3.org/1999/xhtml"> tree methods discretize continuous attributes during the learning process. </span><span class="koboSpan" id="kobo.1172.2" xmlns:="http://www.w3.org/1999/xhtml">At each node, a decision tree evaluates all possible values of a feature and selects the cut point that maximizes the class separation, or sample coherence, by utilizing a performance metric such as entropy or Gini impurity for classification, or the squared or absolute error for regression. </span><span class="koboSpan" id="kobo.1172.3" xmlns:="http://www.w3.org/1999/xhtml">As a result, the observations end up in certain leaves based on whether their feature values are greater or smaller than certain </span><span class="No-Break"><span class="koboSpan" id="kobo.1173.1" xmlns:="http://www.w3.org/1999/xhtml">cut points.</span></span></p>
<p><span class="koboSpan" id="kobo.1174.1" xmlns:="http://www.w3.org/1999/xhtml">In the following figure, we can see the diagram of a decision tree that is trained to predict house prices based on the property’s average number </span><span class="No-Break"><span class="koboSpan" id="kobo.1175.1" xmlns:="http://www.w3.org/1999/xhtml">of rooms:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer075">
<span class="koboSpan" id="kobo.1176.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.12 – A diagram of a decision tree trained to predict house price based on the property’s average number of rooms" src="image/B22396_04_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1177.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.12 – A diagram of a decision tree trained to predict house price based on the property’s average number of rooms</span></p>
<p><span class="koboSpan" id="kobo.1178.1" xmlns:="http://www.w3.org/1999/xhtml">Based on this decision tree, houses with a smaller mean number of rooms than 5.5 will go to the first leaf, houses with a mean number of rooms between 5.5 and 6.37 will fall into the second leaf, houses with mean values between 6.37 and 10.77 will end up in the third leaf, and </span><a id="_idIndexMarker342"/><span class="koboSpan" id="kobo.1179.1" xmlns:="http://www.w3.org/1999/xhtml">houses with mean values greater than 10.77 will land in the </span><span class="No-Break"><span class="koboSpan" id="kobo.1180.1" xmlns:="http://www.w3.org/1999/xhtml">fourth leaf.</span></span></p>
<p><span class="koboSpan" id="kobo.1181.1" xmlns:="http://www.w3.org/1999/xhtml">As you see, by design, decision trees</span><a id="_idIndexMarker343"/><span class="koboSpan" id="kobo.1182.1" xmlns:="http://www.w3.org/1999/xhtml"> can find the set of cut points that partition a variable into intervals with good </span><span class="No-Break"><span class="koboSpan" id="kobo.1183.1" xmlns:="http://www.w3.org/1999/xhtml">class coherence.</span></span></p>
<p><span class="koboSpan" id="kobo.1184.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, </span><a id="_idTextAnchor644"/><span class="koboSpan" id="kobo.1185.1" xmlns:="http://www.w3.org/1999/xhtml">we will perform d</span><a id="_idTextAnchor645"/><a id="_idTextAnchor646"/><span class="koboSpan" id="kobo.1186.1" xmlns:="http://www.w3.org/1999/xhtml">ecision tree-based discretization </span><span class="No-Break"><span class="koboSpan" id="kobo.1187.1" xmlns:="http://www.w3.org/1999/xhtml">using Feature-engine.</span></span></p>
<h2 id="_idParaDest-141"><a id="_idTextAnchor647"/><span class="koboSpan" id="kobo.1188.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.1189.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by importing some libraries and loading </span><span class="No-Break"><span class="koboSpan" id="kobo.1190.1" xmlns:="http://www.w3.org/1999/xhtml">the data:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.1191.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the required Python libraries, classes, </span><span class="No-Break"><span class="koboSpan" id="kobo.1192.1" xmlns:="http://www.w3.org/1999/xhtml">and datasets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1193.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.tree import plot_tree
from feature_engine.discretisation import DecisionTreeDiscretiser</span></pre></li> <li><span class="koboSpan" id="kobo.1194.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the California housing dataset into a </span><strong class="source-inline"><span class="koboSpan" id="kobo.1195.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.1196.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame and then split it into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.1197.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1198.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(return_X_y=True,
    as_frame=True)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.1199.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s make a list with the names of the variables </span><span class="No-Break"><span class="koboSpan" id="kobo.1200.1" xmlns:="http://www.w3.org/1999/xhtml">to discretize:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1201.1" xmlns:="http://www.w3.org/1999/xhtml">
variables = list(X.columns)[:-2]</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1202.1" xmlns:="http://www.w3.org/1999/xhtml">If we execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.1203.1" xmlns:="http://www.w3.org/1999/xhtml">print(variables)</span></strong><span class="koboSpan" id="kobo.1204.1" xmlns:="http://www.w3.org/1999/xhtml">, we’ll see the following variable names: </span><strong class="source-inline"><span class="koboSpan" id="kobo.1205.1" xmlns:="http://www.w3.org/1999/xhtml">['MedInc'</span></strong><span class="koboSpan" id="kobo.1206.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1207.1" xmlns:="http://www.w3.org/1999/xhtml">'HouseAge'</span></strong><span class="koboSpan" id="kobo.1208.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1209.1" xmlns:="http://www.w3.org/1999/xhtml">'AveRooms'</span></strong><span class="koboSpan" id="kobo.1210.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1211.1" xmlns:="http://www.w3.org/1999/xhtml">'AveBedrms'</span></strong><span class="koboSpan" id="kobo.1212.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1213.1" xmlns:="http://www.w3.org/1999/xhtml">'</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1214.1" xmlns:="http://www.w3.org/1999/xhtml">Population'</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1215.1" xmlns:="http://www.w3.org/1999/xhtml">, </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1216.1" xmlns:="http://www.w3.org/1999/xhtml">'AveOccup']</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1217.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p></li> <li><span class="koboSpan" id="kobo.1218.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set </span><a id="_idIndexMarker344"/><span class="koboSpan" id="kobo.1219.1" xmlns:="http://www.w3.org/1999/xhtml">up the transformer to discretize</span><a id="_idIndexMarker345"/><span class="koboSpan" id="kobo.1220.1" xmlns:="http://www.w3.org/1999/xhtml"> the variables from </span><em class="italic"><span class="koboSpan" id="kobo.1221.1" xmlns:="http://www.w3.org/1999/xhtml">step 3</span></em><span class="koboSpan" id="kobo.1222.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1222.2" xmlns:="http://www.w3.org/1999/xhtml">We want the transformer to optimize the hyperparameter’s maximum depth and minimum samples per leaf of each tree based on the negative mean square error metric using three-fold cross-validation. </span><span class="koboSpan" id="kobo.1222.3" xmlns:="http://www.w3.org/1999/xhtml">As the output of the discretization, we want the limits of </span><span class="No-Break"><span class="koboSpan" id="kobo.1223.1" xmlns:="http://www.w3.org/1999/xhtml">the intervals:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1224.1" xmlns:="http://www.w3.org/1999/xhtml">
disc = DecisionTreeDiscretiser(
    bin_output="boundaries",
    precision=3,
    cv=3,
    scoring="neg_mean_squared_error",
    variables=variables,
    regression=True,
    param_grid={
        "max_depth": [1, 2, 3],
        "min_samples_leaf": [10, 20, 50]},
)</span></pre></li> <li><span class="koboSpan" id="kobo.1225.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit the discretizer using the train set so that it finds the best decision trees for each of </span><span class="No-Break"><span class="koboSpan" id="kobo.1226.1" xmlns:="http://www.w3.org/1999/xhtml">the variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1227.1" xmlns:="http://www.w3.org/1999/xhtml">
disc.fit(X_train, y_train)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.1228.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.1229.1" xmlns:="http://www.w3.org/1999/xhtml">You can inspect the limits of the found intervals for each variable in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1230.1" xmlns:="http://www.w3.org/1999/xhtml">binner_dict_</span></strong><span class="koboSpan" id="kobo.1231.1" xmlns:="http://www.w3.org/1999/xhtml"> attribute by executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.1232.1" xmlns:="http://www.w3.org/1999/xhtml">disc.binner_dict_</span></strong><span class="koboSpan" id="kobo.1233.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1233.2" xmlns:="http://www.w3.org/1999/xhtml">Note how the discretizer appended minus and plus infinity to the limits to accommodate smaller and greater values than those observed in the </span><span class="No-Break"><span class="koboSpan" id="kobo.1234.1" xmlns:="http://www.w3.org/1999/xhtml">training set.</span></span></p>
<ol>
<li value="6"><span class="koboSpan" id="kobo.1235.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s discretize the variables and then display the first five rows of the transformed </span><span class="No-Break"><span class="koboSpan" id="kobo.1236.1" xmlns:="http://www.w3.org/1999/xhtml">training set:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1237.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t = disc.transform(X_train)
test_t = disc.transform(X_test)
train_t[variables].head()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1238.1" xmlns:="http://www.w3.org/1999/xhtml">In the following</span><a id="_idIndexMarker346"/><span class="koboSpan" id="kobo.1239.1" xmlns:="http://www.w3.org/1999/xhtml"> output, we can see the limits of the</span><a id="_idIndexMarker347"/><span class="koboSpan" id="kobo.1240.1" xmlns:="http://www.w3.org/1999/xhtml"> intervals to which each observation </span><span class="No-Break"><span class="koboSpan" id="kobo.1241.1" xmlns:="http://www.w3.org/1999/xhtml">was allocated:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer076">
<span class="koboSpan" id="kobo.1242.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.13 – The first five rows of the transformed training set containing the discretized variables" src="image/B22396_04_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1243.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.13 – The first five rows of the transformed training set containing the discretized variables</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.1244.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.1245.1" xmlns:="http://www.w3.org/1999/xhtml">If you choose to return the interval limits and want to use these datasets to train machine learning models, you will need to follow up the discretization with one-hot encoding or ordinal encoding. </span><span class="koboSpan" id="kobo.1245.2" xmlns:="http://www.w3.org/1999/xhtml">Check the recipes in </span><a href="B22396_02.xhtml#_idTextAnchor182"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1246.1" xmlns:="http://www.w3.org/1999/xhtml">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.1247.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><em class="italic"><span class="koboSpan" id="kobo.1248.1" xmlns:="http://www.w3.org/1999/xhtml">Encoding Categorical Variables</span></em><span class="koboSpan" id="kobo.1249.1" xmlns:="http://www.w3.org/1999/xhtml">, for </span><span class="No-Break"><span class="koboSpan" id="kobo.1250.1" xmlns:="http://www.w3.org/1999/xhtml">more details.</span></span></p>
<ol>
<li value="7"><span class="koboSpan" id="kobo.1251.1" xmlns:="http://www.w3.org/1999/xhtml">Instead of returning the interval limits, we can return the interval number to which</span><a id="_idIndexMarker348"/><span class="koboSpan" id="kobo.1252.1" xmlns:="http://www.w3.org/1999/xhtml"> each observation is allocated by setting</span><a id="_idIndexMarker349"/><span class="koboSpan" id="kobo.1253.1" xmlns:="http://www.w3.org/1999/xhtml"> up the transformer </span><span class="No-Break"><span class="koboSpan" id="kobo.1254.1" xmlns:="http://www.w3.org/1999/xhtml">like this:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1255.1" xmlns:="http://www.w3.org/1999/xhtml">
disc = DecisionTreeDiscretiser(
    bin_output="bin_number",
    cv=3,
    scoring="neg_mean_squared_error",
    variables=variables,
    regression=True,
    param_grid={
        "max_depth": [1, 2, 3],
        "min_samples_leaf": [10, 20, 50]})</span></pre></li> <li><span class="koboSpan" id="kobo.1256.1" xmlns:="http://www.w3.org/1999/xhtml">We can now fit and then transform the training and </span><span class="No-Break"><span class="koboSpan" id="kobo.1257.1" xmlns:="http://www.w3.org/1999/xhtml">testing sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1258.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t = disc.fit_transform(X_train, y_train)
test_t = disc.transform(X_test)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1259.1" xmlns:="http://www.w3.org/1999/xhtml">If you now execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.1260.1" xmlns:="http://www.w3.org/1999/xhtml">train_t[variables].head()</span></strong><span class="koboSpan" id="kobo.1261.1" xmlns:="http://www.w3.org/1999/xhtml">, you will see integers as a result instead of the </span><span class="No-Break"><span class="koboSpan" id="kobo.1262.1" xmlns:="http://www.w3.org/1999/xhtml">interval limits:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer077">
<span class="koboSpan" id="kobo.1263.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.14 – The first five rows of the transformed training set containing the discretized variables" src="image/B22396_04_14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1264.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.14 – The first five rows of the transformed training set containing the discretized variables</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.1265.1" xmlns:="http://www.w3.org/1999/xhtml">To wrap up the recipe, we will make the discretizer return the predictions of the trees as replacement values for the </span><span class="No-Break"><span class="koboSpan" id="kobo.1266.1" xmlns:="http://www.w3.org/1999/xhtml">discretized variables:</span></span></p>
<ol>
<li value="9"><span class="koboSpan" id="kobo.1267.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up</span><a id="_idIndexMarker350"/><span class="koboSpan" id="kobo.1268.1" xmlns:="http://www.w3.org/1999/xhtml"> the transformer to return the </span><a id="_idIndexMarker351"/><span class="koboSpan" id="kobo.1269.1" xmlns:="http://www.w3.org/1999/xhtml">predictions, then fit it to the training set, and finally transform </span><span class="No-Break"><span class="koboSpan" id="kobo.1270.1" xmlns:="http://www.w3.org/1999/xhtml">both datasets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1271.1" xmlns:="http://www.w3.org/1999/xhtml">
disc = DecisionTreeDiscretiser(
    bin_output="prediction",
    precision=1,
    cv=3,
    scoring="neg_mean_squared_error",
    variables=variables,
    regression=True,
    param_grid=
        {"max_depth": [1, 2, 3],
            "min_samples_leaf": [10, 20, 50]},
)
train_t = disc.fit_transform(X_train, y_train)
test_t = disc.transform(X_test)</span></pre></li> <li><span class="koboSpan" id="kobo.1272.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s explore the number of unique values of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1273.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms</span></strong><span class="koboSpan" id="kobo.1274.1" xmlns:="http://www.w3.org/1999/xhtml"> variable before and after </span><span class="No-Break"><span class="koboSpan" id="kobo.1275.1" xmlns:="http://www.w3.org/1999/xhtml">the discretization:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1276.1" xmlns:="http://www.w3.org/1999/xhtml">
X_test["AveRooms"].nunique(), test_t["AveRooms"].nunique()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1277.1" xmlns:="http://www.w3.org/1999/xhtml">In the following output, we can see that the predictions of the decision trees are also discrete or finite because the trees contain a finite number of end leaves; </span><strong class="source-inline"><span class="koboSpan" id="kobo.1278.1" xmlns:="http://www.w3.org/1999/xhtml">7</span></strong><span class="koboSpan" id="kobo.1279.1" xmlns:="http://www.w3.org/1999/xhtml">, while the original</span><a id="_idIndexMarker352"/><span class="koboSpan" id="kobo.1280.1" xmlns:="http://www.w3.org/1999/xhtml"> variable </span><a id="_idIndexMarker353"/><span class="koboSpan" id="kobo.1281.1" xmlns:="http://www.w3.org/1999/xhtml">contained more than 6000 </span><span class="No-Break"><span class="koboSpan" id="kobo.1282.1" xmlns:="http://www.w3.org/1999/xhtml">different values:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.1283.1" xmlns:="http://www.w3.org/1999/xhtml">(6034, 7)</span></pre></li> <li><span class="koboSpan" id="kobo.1284.1" xmlns:="http://www.w3.org/1999/xhtml">To better understand the structure of the tree, we can capture it into </span><span class="No-Break"><span class="koboSpan" id="kobo.1285.1" xmlns:="http://www.w3.org/1999/xhtml">a variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1286.1" xmlns:="http://www.w3.org/1999/xhtml">
tree = disc.binner_dict_["AveRooms"].best_estimator_</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.1287.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.1288.1" xmlns:="http://www.w3.org/1999/xhtml">When we set the transformer to return integers or bin limits, we will obtain the bin limits in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1289.1" xmlns:="http://www.w3.org/1999/xhtml">binner_dict_</span></strong><span class="koboSpan" id="kobo.1290.1" xmlns:="http://www.w3.org/1999/xhtml"> attribute. </span><span class="koboSpan" id="kobo.1290.2" xmlns:="http://www.w3.org/1999/xhtml">If we set the transformer to return the tree predictions, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1291.1" xmlns:="http://www.w3.org/1999/xhtml">binner_dict_</span></strong><span class="koboSpan" id="kobo.1292.1" xmlns:="http://www.w3.org/1999/xhtml"> will contain the trained tree for </span><span class="No-Break"><span class="koboSpan" id="kobo.1293.1" xmlns:="http://www.w3.org/1999/xhtml">each variable.</span></span></p>
<ol>
<li value="12"><span class="koboSpan" id="kobo.1294.1" xmlns:="http://www.w3.org/1999/xhtml">Now, we can display the </span><span class="No-Break"><span class="koboSpan" id="kobo.1295.1" xmlns:="http://www.w3.org/1999/xhtml">tree structure:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1296.1" xmlns:="http://www.w3.org/1999/xhtml">
fig = plt.figure(figsize=(20, 6))
plot_tree(tree, fontsize=10, proportion=True)
plt.show()</span></pre></li> <li><span class="koboSpan" id="kobo.1297.1" xmlns:="http://www.w3.org/1999/xhtml">In the following figure, we can see the values used by the tree to allocate samples to the different end leaves based on the mean number </span><span class="No-Break"><span class="koboSpan" id="kobo.1298.1" xmlns:="http://www.w3.org/1999/xhtml">of rooms:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer078">
<span class="koboSpan" id="kobo.1299.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.15 – The structure of the decision tree trained to discretize AveRooms" src="image/B22396_04_15.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1300.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.15 – The structure of the decision tree trained to discretize AveRooms</span></p>
<ol>
<li value="14"><span class="koboSpan" id="kobo.1301.1" xmlns:="http://www.w3.org/1999/xhtml">To wrap up the recipe, we can plot the number of observations per bin for three of </span><span class="No-Break"><span class="koboSpan" id="kobo.1302.1" xmlns:="http://www.w3.org/1999/xhtml">the </span></span><span class="No-Break"><a id="_idIndexMarker354"/></span><span class="No-Break"><span class="koboSpan" id="kobo.1303.1" xmlns:="http://www.w3.org/1999/xhtml">variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1304.1" xmlns:="http://www.w3.org/1999/xhtml">
plt.figure(figsize=(6, 12), constrained_layout=True)
for i in range(3):
    ax = plt.subplot(3, 1, i + 1)
    var = variables[i]
    t1 = train_t[var].value_counts(normalize=True)
    t2 = test_t[var].value_counts(normalize=True)
    tmp = pd.concat([t1, t2], axis=1)
    tmp.columns = ["train", "test"]
    tmp.sort_index(inplace=True)
    tmp.plot.bar(ax=ax)
    plt.xticks(rotation=0)
    plt.ylabel(</span><a id="_idTextAnchor648"/><span class="koboSpan" id="kobo.1305.1" xmlns:="http://www.w3.org/1999/xhtml">"Observations per bin")
    ax.</span><a id="_idTextAnchor649"/><span class="koboSpan" id="kobo.1306.1" xmlns:="http://www.w3.org/1999/xhtml">set_title(var)
plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1307.1" xmlns:="http://www.w3.org/1999/xhtml">We can s</span><a id="_idTextAnchor650"/><span class="koboSpan" id="kobo.1308.1" xmlns:="http://www.w3.org/1999/xhtml">ee the </span><a id="_idIndexMarker355"/><span class="koboSpan" id="kobo.1309.1" xmlns:="http://www.w3.org/1999/xhtml">number of observations per bin in the </span><span class="No-Break"><span class="koboSpan" id="kobo.1310.1" xmlns:="http://www.w3.org/1999/xhtml">following output:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer079">
<span class="koboSpan" id="kobo.1311.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 4.16 – The proportion of observations ﻿per bin after discretizing the variables with decision trees" src="image/B22396_04_16.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1312.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 4.16 – The proportion of observations </span><a id="_idTextAnchor651"/><span class="koboSpan" id="kobo.1313.1" xmlns:="http://www.w3.org/1999/xhtml">per bin after discretizing the variables with decision trees</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.1314.1" xmlns:="http://www.w3.org/1999/xhtml">As </span><a id="_idIndexMarker356"/><span class="koboSpan" id="kobo.1315.1" xmlns:="http://www.w3.org/1999/xhtml">evidenced in </span><a id="_idIndexMarker357"/><span class="koboSpan" id="kobo.1316.1" xmlns:="http://www.w3.org/1999/xhtml">the plots, discretization with decision tree</span><a id="_idTextAnchor652"/><span class="koboSpan" id="kobo.1317.1" xmlns:="http://www.w3.org/1999/xhtml">s </span><a id="_idTextAnchor653"/><a id="_idTextAnchor654"/><span class="koboSpan" id="kobo.1318.1" xmlns:="http://www.w3.org/1999/xhtml">returns a different fraction of observations at each node </span><span class="No-Break"><span class="koboSpan" id="kobo.1319.1" xmlns:="http://www.w3.org/1999/xhtml">or bin.</span></span></p>
<h2 id="_idParaDest-142"><a id="_idTextAnchor655"/><span class="koboSpan" id="kobo.1320.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.1321.1" xmlns:="http://www.w3.org/1999/xhtml">To perform discretization with decision trees, we used </span><span class="No-Break"><span class="koboSpan" id="kobo.1322.1" xmlns:="http://www.w3.org/1999/xhtml">f</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1323.1" xmlns:="http://www.w3.org/1999/xhtml">eature-engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1324.1" xmlns:="http://www.w3.org/1999/xhtml">’s </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1325.1" xmlns:="http://www.w3.org/1999/xhtml">Decision</span></strong></span><strong class="source-inline"><span class="koboSpan" id="kobo.1326.1" xmlns:="http://www.w3.org/1999/xhtml"> TreeDiscretiser()</span></strong><span class="koboSpan" id="kobo.1327.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1327.2" xmlns:="http://www.w3.org/1999/xhtml">This transformer fitted a decision tree using each variable to discretize as input and optimized the hyperparameters of the model to find the best </span><a id="_idIndexMarker358"/><span class="koboSpan" id="kobo.1328.1" xmlns:="http://www.w3.org/1999/xhtml">partitions </span><a id="_idIndexMarker359"/><span class="koboSpan" id="kobo.1329.1" xmlns:="http://www.w3.org/1999/xhtml">based on a performance metric. </span><span class="koboSpan" id="kobo.1329.2" xmlns:="http://www.w3.org/1999/xhtml">It automatically found the optimal number of intervals, as well as their limits, returning</span><a id="_idTextAnchor656"/><a id="_idTextAnchor657"/><a id="_idTextAnchor658"/><span class="koboSpan" id="kobo.1330.1" xmlns:="http://www.w3.org/1999/xhtml"> either the limits, the bin number, or the predictions as </span><span class="No-Break"><span class="koboSpan" id="kobo.1331.1" xmlns:="http://www.w3.org/1999/xhtml">a result.</span></span></p>
<h2 id="_idParaDest-143"><a id="_idTextAnchor659"/><span class="koboSpan" id="kobo.1332.1" xmlns:="http://www.w3.org/1999/xhtml">There’s more...</span></h2>
<p><span class="koboSpan" id="kobo.1333.1" xmlns:="http://www.w3.org/1999/xhtml">The implementation of </span><strong class="source-inline"><span class="koboSpan" id="kobo.1334.1" xmlns:="http://www.w3.org/1999/xhtml">feat</span><a id="_idTextAnchor660"/><span class="koboSpan" id="kobo.1335.1" xmlns:="http://www.w3.org/1999/xhtml">ure-engine</span></strong><span class="koboSpan" id="kobo.1336.1" xmlns:="http://www.w3.org/1999/xhtml"> is inspired by the winning solution of the KDD 2009 data science competition. </span><span class="koboSpan" id="kobo.1336.2" xmlns:="http://www.w3.org/1999/xhtml">The winners created new features by obtaining predictions of decision trees based on continuous features. </span><span class="koboSpan" id="kobo.1336.3" xmlns:="http://www.w3.org/1999/xhtml">You can find more details in the </span><em class="italic"><span class="koboSpan" id="kobo.1337.1" xmlns:="http://www.w3.org/1999/xhtml">Winning the KDD Cup Orange Challenge with Ensemble Selection</span></em><span class="koboSpan" id="kobo.1338.1" xmlns:="http://www.w3.org/1999/xhtml"> article on </span><em class="italic"><span class="koboSpan" id="kobo.1339.1" xmlns:="http://www.w3.org/1999/xhtml">page 27</span></em><span class="koboSpan" id="kobo.1340.1" xmlns:="http://www.w3.org/1999/xhtml"> of the article series </span><span class="No-Break"><span class="koboSpan" id="kobo.1341.1" xmlns:="http://www.w3.org/1999/xhtml">at </span></span><a href="http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.1342.1" xmlns:="http://www.w3.org/1999/xhtml">http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1343.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.1344.1" xmlns:="http://www.w3.org/1999/xhtml">For a review of discretization techniques, you might find the following </span><span class="No-Break"><span class="koboSpan" id="kobo.1345.1" xmlns:="http://www.w3.org/1999/xhtml">articles useful:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.1346.1" xmlns:="http://www.w3.org/1999/xhtml">Dougherty et al, </span><em class="italic"><span class="koboSpan" id="kobo.1347.1" xmlns:="http://www.w3.org/1999/xhtml">Supervised and Unsupervised Discretization of Continuous Features, Machine Learning: Proceedings of the 12th International Conference</span></em><span class="koboSpan" id="kobo.1348.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><span class="No-Break"><span class="koboSpan" id="kobo.1349.1" xmlns:="http://www.w3.org/1999/xhtml">1995, (</span></span><a href="https://ai.stanford.edu/~ronnyk/disc.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.1350.1" xmlns:="http://www.w3.org/1999/xhtml">https://ai.stanford.edu/~ronnyk/disc.pdf</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1351.1" xmlns:="http://www.w3.org/1999/xhtml">).</span></span></li>
<li><span class="koboSpan" id="kobo.1352.1" xmlns:="http://www.w3.org/1999/xhtml">Lu et al, </span><em class="italic"><span class="koboSpan" id="kobo.1353.1" xmlns:="http://www.w3.org/1999/xhtml">Discretization: An Enabling Technique, Data Mining, and Knowledge Discovery</span></em><span class="koboSpan" id="kobo.1354.1" xmlns:="http://www.w3.org/1999/xhtml">, 6, 393–423, </span><span class="No-Break"><span class="koboSpan" id="kobo.1355.1" xmlns:="http://www.w3.org/1999/xhtml">2002, (</span></span><a href="https://www.researchgate.net/publication/220451974_Discretization_An_Enabling_Technique"><span class="No-Break"><span class="koboSpan" id="kobo.1356.1" xmlns:="http://www.w3.org/1999/xhtml">https://www.researchgate.net/publication/220451974_Discretization_An_Enabling_Technique</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1357.1" xmlns:="http://www.w3.org/1999/xhtml">).</span></span></li>
<li><span class="koboSpan" id="kobo.1358.1" xmlns:="http://www.w3.org/1999/xhtml">Garcia et al, </span><em class="italic"><span class="koboSpan" id="kobo.1359.1" xmlns:="http://www.w3.org/1999/xhtml">A Survey of Discretization Techniques: Taxonomy and Empirical Analysis in Supervised Learning, IEEE Transactions on Knowledge in Data</span><a id="_idTextAnchor661"/><span class="koboSpan" id="kobo.1360.1" xmlns:="http://www.w3.org/1999/xhtml"> Engineering 25 (4)</span></em><span class="koboSpan" id="kobo.1361.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><span class="No-Break"><span class="koboSpan" id="kobo.1362.1" xmlns:="http://www.w3.org/1999/xhtml">2013, (</span></span><a href="https://ieeexplore.ieee.org/document/6152258"><span class="No-Break"><span class="koboSpan" id="kobo.1363.1" xmlns:="http://www.w3.org/1999/xhtml">https://ieeexplore.ieee.org/document/6152258</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1364.1" xmlns:="http://www.w3.org/1999/xhtml">).</span></span></li>
</ul>
</div>
</body></html>