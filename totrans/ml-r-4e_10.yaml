- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Evaluating Model Performance
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型性能
- en: When only the wealthy could afford education, tests and exams were not used
    to evaluate students. Instead, tests evaluated the teachers for parents who wanted
    to know whether their children learned enough to justify the instructors’ wages.
    Obviously, this is different today. Now, such evaluations are used to distinguish
    between high-achieving and low-achieving students, filtering them into careers
    and other opportunities.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当只有富人才能负担得起教育时，考试和测试并不是用来评估学生的。相反，测试评估的是教师，以便父母了解他们的孩子是否学到了足够的知识来证明教师工资的合理性。显然，这与今天的情况不同。现在，这样的评估被用来区分表现优异和表现不佳的学生，将他们筛选到不同的职业和其他机会中。
- en: Given the significance of this process, a great deal of effort is invested in
    developing accurate student assessments. Fair assessments have a large number
    of questions that cover a wide breadth of topics and reward true knowledge over
    lucky guesses. A good assessment also requires students to think about problems
    they have never faced before. Correct responses, therefore, reflect an ability
    to generalize knowledge more broadly.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个过程的重要性，大量的努力被投入到开发准确的学业评估中。公平的评估包含大量的问题，覆盖广泛的主题，并奖励真正的知识而非幸运猜测。一个好的评估还要求学生思考他们以前从未面临过的问题。因此，正确的回答反映了更广泛地概括知识的能力。
- en: The process of evaluating machine learning algorithms is very similar to the
    process of evaluating students. Since algorithms have varying strengths and weaknesses,
    tests should distinguish between learners. It is also important to understand
    how a learner will perform on future data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 评估机器学习算法的过程与评估学生的过程非常相似。由于算法具有不同的优势和劣势，测试应该区分学习者。了解学习者如何在未来的数据上表现也很重要。
- en: 'This chapter provides the information needed to assess machine learners, such
    as:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了评估机器学习者的所需信息，例如：
- en: The reasons why predictive accuracy is not sufficient to measure performance,
    and the performance measures you might use instead
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么预测准确性不足以衡量性能，以及你可能使用的其他性能衡量指标
- en: Methods to ensure that the performance measures reasonably reflect a model’s
    ability to predict or forecast unseen cases
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保性能衡量指标合理反映模型预测或预测未见案例的能力的方法
- en: How to use R to apply these more useful measures and methods to the predictive
    models covered in previous chapters
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用R将这些更有用的衡量指标和方法应用于前面章节中涵盖的预测模型
- en: Just as the best way to learn a topic is to attempt to teach it to someone else,
    the process of teaching and evaluating machine learners will provide you with
    greater insight into the methods you’ve learned so far.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 正如学习一个主题的最佳方式是尝试向其他人教授它一样，教授和评估机器学习者的过程将使你对迄今为止学到的方法有更深入的了解。
- en: Measuring performance for classification
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量分类性能
- en: In the previous chapters, we measured classifier accuracy by dividing the number
    of correct predictions by the total number of predictions. This finds the proportion
    of cases in which the learner is correct, and the proportion of incorrect cases
    follows directly. For example, suppose that a classifier correctly predicted whether
    newborn babies were a carrier of a treatable but potentially fatal genetic defect
    in 99,990 out of 100,000 cases. This would imply an accuracy of 99.99 percent
    and an error rate of only 0.01 percent.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们通过将正确预测的数量除以总预测数量来衡量分类器的准确性。这找到了学习者正确案例的比例，错误案例的比例直接得出。例如，假设一个分类器在10,000个案例中有99,990个正确预测了新生婴儿是否携带可治疗但可能致命的遗传缺陷。这将意味着准确率为99.99%，错误率仅为0.01%。
- en: At first glance, this appears to be an extremely valuable classifier. However,
    it would be wise to collect additional information before trusting a child’s life
    to the test. What if the genetic defect is found in only 10 out of every 100,000
    babies? A test that invariably predicts no defect will be correct for 99.99 percent
    of all cases, but incorrect for 100 percent of the cases that matter most. In
    other words, even though the classifier is extremely accurate, it is not very
    useful for preventing treatable birth defects.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 初看起来，这似乎是一个非常宝贵的分类器。然而，在将孩子的生命托付给测试之前收集更多信息是明智的。如果仅在每10万个婴儿中有10个发现遗传缺陷呢？一个总是预测无缺陷的测试在所有案例中都是正确的，但在最重要的案例中却是错误的。换句话说，尽管分类器非常准确，但它对预防可治疗的出生缺陷并不很有用。
- en: This is one consequence of the **class imbalance problem**, which refers to
    the trouble associated with data having a large majority of records belonging
    to a single class.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这是**类别不平衡问题**的一个后果，它指的是数据中大多数记录属于单个类别时所带来的麻烦。
- en: Though there are many ways to measure a classifier’s performance, the best measure
    is always that which captures whether the classifier is successful at its intended
    purpose. It is crucial to define performance measures in terms of utility rather
    than raw accuracy. To this end, we will explore a variety of alternative performance
    measures derived from the confusion matrix. Before we get started, however, we
    need to consider how to prepare a classifier for evaluation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有许多方法可以衡量分类器的性能，但最好的衡量标准始终是捕捉分类器是否在其预期目的上成功的标准。在定义性能指标时，以效用而不是原始准确率为准至关重要。为此，我们将探讨从混淆矩阵中衍生出的各种替代性能指标。然而，在我们开始之前，我们需要考虑如何为评估准备分类器。
- en: Understanding a classifier’s predictions
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解分类器的预测
- en: The goal of evaluating a classification model is to better understand how its
    performance will extrapolate to future cases. Since it is usually infeasible to
    test an unproven model in a live environment, we typically simulate future conditions
    by asking the model to classify cases in a dataset made of cases that resemble
    what it will be asked to do in the future. By observing the learner’s responses
    to this examination, we can learn about its strengths and weaknesses.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 评估分类模型的目标是更好地理解其性能如何外推到未来的案例。由于通常在真实环境中测试未经证实的模型是不切实际的，我们通常通过要求模型对由类似未来将要求其执行的任务的案例组成的测试数据集中的案例进行分类来模拟未来条件。通过观察学习者的响应，我们可以了解其优势和劣势。
- en: 'Though we’ve evaluated classifiers in prior chapters, it’s worth reflecting
    on the types of data at our disposal:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们在前面的章节中已经评估了分类器，但值得反思我们可用的数据类型：
- en: Actual class values
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际的类别值
- en: Predicted class values
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测的类别值
- en: The estimated probability of the prediction
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测的估计概率
- en: 'The actual and predicted class values may be self-evident, but they are the
    key to the evaluation. Just like a teacher uses an answer key—a list of correct
    answers—to assess the student’s answers, we need to know the correct answer for
    a machine learner’s predictions. The goal is to maintain two vectors of data:
    one holding the correct or actual class values, and the other holding the predicted
    class values. Both vectors must have the same number of values stored in the same
    order. The predicted and actual values may be stored as separate R vectors or
    as columns in a single R data frame.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 实际和预测的类别值可能显而易见，但它们是评估的关键。就像老师使用答案键——一个正确答案的列表——来评估学生的答案一样，我们需要知道机器学习者的预测的正确答案。目标是维护两个数据向量：一个包含正确或实际类别值，另一个包含预测类别值。这两个向量必须存储相同数量的值，并且顺序相同。预测和实际值可以存储为单独的R向量，或者作为单个R数据框中的列。
- en: Obtaining this data is easy. The actual class values come directly from the
    target in the test dataset. Predicted class values are obtained from the classifier
    built upon the training data, which is then applied to the test data. For most
    machine learning packages, this involves applying the `predict()` function to
    a model object and a data frame of test data, such as `predictions <- predict(model,
    test_data)`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 获取这些数据很容易。实际的类别值直接来自测试数据集中的目标。预测的类别值是从基于训练数据构建的分类器中获得的，然后将它应用于测试数据。对于大多数机器学习包来说，这涉及到对一个模型对象和一个测试数据框应用`predict()`函数，例如`predictions
    <- predict(model, test_data)`。
- en: Until now, we have only examined classification predictions using these two
    vectors of data, but most models can supply another piece of useful information.
    Even though the classifier makes a single prediction about each example, it may
    be more confident about some decisions than others.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只使用这两个数据向量来检查分类预测，但大多数模型可以提供另一条有用的信息。尽管分类器对每个示例只做出一个预测，但它可能对某些决策比其他决策更有信心。
- en: For instance, a classifier may be 99 percent certain that an SMS with the words
    “free” and “ringtones” is spam, but only 51 percent certain that an SMS with the
    word “tonight” is spam. In both cases, the classifier classifies the message as
    spam, but it is far more certain about one decision than the other.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个分类器可能对包含“免费”和“铃声”这两个词的短信有99%的确定性认为是垃圾邮件，但对包含“tonight”这个词的短信只有51%的确定性认为是垃圾邮件。在这两种情况下，分类器都将消息分类为垃圾邮件，但它对其中一个决策的确定性远高于另一个。
- en: '![A picture containing diagram  Description automatically generated](img/B17290_10_01.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![包含图表的图片 自动生成描述](img/B17290_10_01.png)'
- en: 'Figure 10.1: Learners may differ in their prediction confidence even when trained
    on the same data'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：即使训练数据相同，学习者的预测信心也可能不同
- en: Studying these internal prediction probabilities provides useful data for evaluating
    a model’s performance. If two models make the same number of mistakes, but one
    is more able to accurately assess its uncertainty, then it is a smarter model.
    It’s ideal to find a learner that is extremely confident when making a correct
    prediction, but timid in the face of doubt. The balance between confidence and
    caution is a key part of model evaluation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 研究这些内部预测概率为评估模型性能提供了有用的数据。如果两个模型犯同样的错误次数，但其中一个更能准确评估其不确定性，那么它就是一个更智能的模型。理想的情况是找到一个在做出正确预测时非常自信，但在面对怀疑时又很谨慎的学习者。信心与谨慎之间的平衡是模型评估的关键部分。
- en: The function call to obtain the internal prediction probabilities varies across
    R packages. For most classifiers, the `predict()` function allows an additional
    parameter to specify the desired type of prediction. To obtain a single predicted
    class, such as spam or ham, you typically set the `type = "class"` parameter.
    To obtain the prediction probability, the `type` parameter should be set to one
    of `"prob"`, `"posterior"`, `"raw"`, or `"probability"`, depending on the classifier
    used.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 获取内部预测概率的函数调用在R包之间有所不同。对于大多数分类器，`predict()`函数允许一个额外的参数来指定所需的预测类型。要获取单个预测类别，例如垃圾邮件或正常邮件，通常设置`type
    = "class"`参数。要获取预测概率，`type`参数应根据所使用的分类器设置为`"prob"`、`"posterior"`、`"raw"`或`"probability"`之一。
- en: All classifiers presented in this book can provide prediction probabilities.
    The correct setting for the `type` parameter is included in the syntax box introducing
    each model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本书介绍的所有分类器都可以提供预测概率。每个模型的`type`参数的正确设置都包含在每个模型的语法框中。
- en: 'For example, to output the predicted probabilities for the C5.0 classifier
    built in *Chapter 5*, *Divide and Conquer – Classification Using Decision Trees
    and Rules*, use the `predict()` function with `type = "prob"` as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要输出在*第5章*中构建的C5.0分类器的预测概率，请使用`predict()`函数并设置`type = "prob"`，如下所示：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To output the Naive Bayes predicted probabilities for the SMS spam classification
    model developed in *Chapter 4*, *Probabilistic Learning – Classification Using
    Naive Bayes*, use `predict()` with `type = "raw"` as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要输出在*第4章*中开发的短信垃圾邮件分类模型的朴素贝叶斯预测概率，请使用`predict()`函数并设置`type = "raw"`，如下所示：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In most cases, the `predict()` function returns a probability for each category
    of the outcome. For example, in the case of a two-outcome model like the SMS classifier,
    the predicted probabilities might be stored in a matrix or data frame, as shown
    here:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，`predict()`函数为每个结果类别返回一个概率。例如，在像短信分类器这样的双结局模型中，预测概率可能存储在一个矩阵或数据框中，如下所示：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Each line in this output shows the classifier’s predicted probability of spam
    and ham. According to probability rules, the sum of the probabilities across each
    row is 1 because these are mutually exclusive and exhaustive outcomes. For convenience,
    during the evaluation process, it can be helpful to construct a data frame collecting
    the predicted class, the actual class, and the predicted probability of the class
    level (or levels) of interest.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的每一行显示了分类器对垃圾邮件和正常邮件的预测概率。根据概率规则，每行的概率之和为1，因为这些是相互排斥且穷尽的结局。为了方便起见，在评估过程中，构建一个收集预测类别、实际类别以及感兴趣类别级别的预测概率的数据框可能会有所帮助。
- en: 'The `sms_results.csv` file available in the GitHub repository for this chapter
    is an example of a data frame in exactly this format and is built from the predictions
    of the SMS classifier built in *Chapter 4*, *Probabilistic Learning – Classification
    Using Naive Bayes*. The steps required to construct this evaluation dataset have
    been omitted for brevity, so to follow along with the example here, simply download
    the file and load it into a data frame using the following command:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 本章GitHub仓库中可用的`sms_results.csv`文件是一个符合这种格式的数据框的示例，它是由*第4章*中构建的短信分类器的预测构建的。为了简洁起见，省略了构建此评估数据集所需的步骤，因此要跟随这里的示例，只需下载文件并将其使用以下命令加载到数据框中：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The resulting `sms_results` data frame is simple. It contains four vectors
    of 1,390 values. One column contains values indicating the actual type of SMS
    message (spam or ham), another indicates the Naive Bayes model’s predicted message
    type, and the third and fourth columns indicate the probability that the message
    was spam or ham, respectively:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的`sms_results`数据框很简单。它包含四个包含1,390个值的向量。一列包含表示实际短信消息类型（垃圾邮件或正常邮件）的值，另一列表示朴素贝叶斯模型预测的消息类型，第三和第四列分别表示消息是垃圾邮件或正常邮件的概率：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For these six test cases, the predicted and actual SMS message types agree;
    the model predicted their statuses correctly. Furthermore, the prediction probabilities
    suggest that the model was extremely confident about these predictions because
    they all fall close to or are exactly 0 or 1.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这六个测试案例，预测值和实际短信消息类型一致；模型正确预测了它们的状态。此外，预测概率表明模型对这些预测非常有信心，因为它们都接近或正好是0或1。
- en: 'What happens when the predicted and actual values are further from 0 and 1?
    Using the `subset()` function, we can identify a few of these records. The following
    output shows test cases where the model estimated the probability of spam as being
    between 40 and 60 percent:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当预测值和实际值与0和1的距离更远时会发生什么？使用`subset()`函数，我们可以识别出这些记录中的一小部分。以下输出显示了模型估计垃圾邮件概率在40%到60%之间的测试案例：
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'By the model’s own estimation, these were cases in which a correct prediction
    was virtually a coin flip. Yet all three predictions were wrong—an unlucky result.
    Let’s look at a few more cases where the model was wrong:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型自己的估计，这些是正确预测几乎等同于抛硬币的情况。然而，所有三个预测都是错误的——一个不幸的结果。让我们看看更多模型预测错误的情况：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: These cases illustrate the important fact that a model can be extremely confident
    and yet it can still be extremely wrong. All six of these test cases were spam
    messages that the classifier believed to have no less than a 98 percent chance
    of being ham.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些案例说明了重要的事实，即一个模型可以非常自信，但仍然可能非常错误。所有六个测试案例都是垃圾邮件，分类器认为它们至少有98%的概率是正常邮件。
- en: Despite such mistakes, is the model still useful? We can answer this question
    by applying various error metrics to this evaluation data. In fact, many such
    metrics are based on a tool we’ve already used extensively in previous chapters.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这样的错误，模型仍然有用吗？我们可以通过将各种错误度量应用于评估数据来回答这个问题。实际上，许多这样的度量都是基于我们在前几章中广泛使用的工具。
- en: A closer look at confusion matrices
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵的更详细分析
- en: A **confusion matrix** is a table that categorizes predictions according to
    whether they match the actual value. One of the table’s dimensions indicates the
    possible categories of predicted values, while the other dimension indicates the
    same thing for actual values. Although we have mostly worked with 2x2 confusion
    matrices so far, a matrix can be created for models that predict any number of
    class values. The following figure depicts the familiar confusion matrix for a
    two-class binary model, as well as the 3x3 confusion matrix for a three-class
    model.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**混淆矩阵**是一个表格，根据预测值是否与实际值匹配来分类预测。表格的一个维度表示预测值的可能类别，而另一个维度表示实际值的相同类别。尽管我们到目前为止主要使用的是2x2的混淆矩阵，但可以为预测任何数量类别值的模型创建矩阵。以下图显示了熟悉的二类二元模型的混淆矩阵，以及三类的3x3混淆矩阵。'
- en: 'When the predicted value is the same as the actual value, this is a correct
    classification. Correct predictions fall on the diagonal in the confusion matrix
    (denoted by **O**). The off-diagonal matrix cells (denoted by **X**) indicate
    the cases where the predicted value differs from the actual value. These are incorrect
    predictions. Performance measures for classification models are based on the counts
    of predictions falling on and off the diagonal in these tables:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当预测值与实际值相同时，这是一种正确的分类。正确的预测位于混淆矩阵的对角线上（用**O**表示）。对角线外的矩阵单元格（用**X**表示）表示预测值与实际值不一致的情况。这些都是错误的预测。分类模型的性能度量基于这些表中位于对角线和偏离对角线上的预测数量：
- en: '![Diagram  Description automatically generated](img/B17290_10_02.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B17290_10_02.png)'
- en: 'Figure 10.2: Confusion matrices count cases where the predicted class agrees
    or disagrees with the actual value'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：混淆矩阵统计预测类别与实际值一致或不一致的情况
- en: The most common performance measures consider the model’s ability to discern
    one class versus all others. The class of interest is known as the **positive**
    class, while all others are known as **negative**.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的性能度量考虑模型区分一个类别与其他所有类别的能力。目标类别被称为**正类**，而所有其他类别被称为**负类**。
- en: The use of the terms positive and negative is not intended to imply any value
    judgment (that is, good versus bad), nor does it necessarily suggest that the
    outcome is present or absent (such as there being a birth defect versus there
    not being one). The choice of the positive outcome can even be arbitrary, as in
    cases where a model is predicting categories such as sunny versus rainy, or dog
    versus cat.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用正负术语并不旨在暗示任何价值判断（即，好与坏），也不一定意味着结果的存在或不存在（例如，存在出生缺陷或不存在）。正结果的选择甚至可以是任意的，例如在模型预测晴朗与雨天、狗与猫等类别的情况下。
- en: 'The relationship between positive class and negative class predictions can
    be depicted as a 2x2 confusion matrix that tabulates whether predictions fall
    into one of four categories:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 正类和负类预测之间的关系可以用一个2x2的混淆矩阵来表示，该矩阵列出了预测是否属于以下四个类别之一：
- en: '**True positive** (**TP**): Correctly classified as the class of interest'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性**（**TP**）：正确地被分类为目标类'
- en: '**True negative** (**TN**): Correctly classified as not the class of interest'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阴性**（**TN**）：正确地被分类为非目标类'
- en: '**False positive** (**FP**): Incorrectly classified as the class of interest'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**（**FP**）：错误地被分类为目标类'
- en: '**False negative** (**FN**): Incorrectly classified as not the class of interest'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性**（**FN**）：错误地被分类为非目标类'
- en: 'For the spam classifier, the positive class is spam, as this is the outcome
    we hope to detect. We then can imagine the confusion matrix as shown in *Figure
    10.3*:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对于垃圾邮件分类器，正类是垃圾邮件，因为这是我们希望检测的结果。然后我们可以想象混淆矩阵如图*图10.3*所示：
- en: '![Diagram  Description automatically generated](img/B17290_10_03.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图示 描述自动生成](img/B17290_10_03.png)'
- en: 'Figure 10.3: Distinguishing between positive and negative classes adds detail
    to the confusion matrix'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：区分正类和负类使混淆矩阵更加详细
- en: The confusion matrix presented in this way is the basis for many of the most
    important measures of model performance. In the next section, we’ll use this matrix
    to better understand exactly what is meant by accuracy.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式展示的混淆矩阵是许多最重要的模型性能度量指标的基础。在下一节中，我们将使用这个矩阵来更好地理解准确率的确切含义。
- en: Using confusion matrices to measure performance
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用混淆矩阵来衡量性能
- en: 'With the 2x2 confusion matrix, we can formalize our definition of **prediction
    accuracy** (sometimes called the **success rate**) as:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用2x2混淆矩阵，我们可以将**预测准确率**（有时称为**成功率**）的定义形式化如下：
- en: '![](img/B17290_10_001.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17290_10_001.png)'
- en: In this formula, the terms *TP*, *TN*, *FP*, and *FN* refer to the number of
    times the model’s predictions fell into each of these categories. The accuracy
    is therefore a proportion that represents the number of true positives and true
    negatives divided by the total number of predictions.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，术语*TP*、*TN*、*FP*和*FN*分别指模型预测落在这些类别中的次数。因此，准确率是一个比例，表示真实正例和真实负例的数量除以预测总数。
- en: 'The **error rate**, or the proportion of incorrectly classified examples, is
    specified as:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**错误率**，即错误分类的样本比例，被定义为：'
- en: '![](img/B17290_10_002.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17290_10_002.png)'
- en: Notice that the error rate can be calculated as 1 minus the accuracy. Intuitively,
    this makes sense; a model that is correct 95 percent of the time is incorrect
    five percent of the time.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，错误率可以计算为1减去准确率。直观上，这是有道理的；一个正确率95%的模型在5%的时间内是错误的。
- en: 'An easy way to tabulate a classifier’s predictions into a confusion matrix
    is to use R’s `table()` function. The command for creating a confusion matrix
    for the SMS data is shown as follows. The counts in this table could then be used
    to calculate accuracy and other statistics:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 将分类器的预测整理成混淆矩阵的一个简单方法是使用R的`table()`函数。创建SMS数据混淆矩阵的命令如下所示。该表中的计数可以用来计算准确率和其他统计量：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: If you would like to create a confusion matrix with more informative output,
    the `CrossTable()` function in the `gmodels` package offers a customizable solution.
    If you recall, we first used this function in *Chapter 2*, *Managing and Understanding
    Data*. If you didn’t install the package at that time, you will need to do so
    using the `install.packages("gmodels")` command.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要创建一个具有更多信息的混淆矩阵，`gmodels`包中的`CrossTable()`函数提供了一个可定制的解决方案。如果你还记得，我们第一次使用这个函数是在*第二章*，*管理和理解数据*。如果你当时没有安装这个包，你需要使用`install.packages("gmodels")`命令来安装。
- en: 'By default, the `CrossTable()` output includes proportions in each cell that
    indicate the cell count as a percentage of the table’s row, column, and overall
    total counts. The output also includes row and column totals. As shown in the
    following code, the syntax is similar to the `table()` function:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`CrossTable()`的输出包括每个单元格中的比例，这些比例表示单元格计数占表格行、列和总计数百分比。输出还包括行和列总计。如下面的代码所示，语法与`table()`函数类似：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The result is a confusion matrix with a wealth of additional detail:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个包含大量额外详细信息的混淆矩阵：
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We’ve used `CrossTable()` in several previous chapters, so by now, you should
    be familiar with its output. If you ever forget how to interpret the output, simply
    refer to the key (labeled `Cell Contents`), which provides the definition of each
    number in the table cells.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在几个前面的章节中使用了`CrossTable()`，所以到现在你应该熟悉它的输出了。如果你忘记了如何解释输出，只需参考键（标记为“单元格内容”），它提供了表格单元格中每个数字的定义。
- en: 'We can use the confusion matrix to obtain the accuracy and error rate. Since
    accuracy is (TP + TN) / (TP + TN + FP + FN), we can calculate it as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用混淆矩阵来获取准确率和错误率。由于准确率是（TP + TN）/（TP + TN + FP + FN），我们可以按以下方式计算：
- en: '[PRE15]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can also calculate the error rate (FP + FN) / (TP + TN + FP + FN) as:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以计算错误率（FP + FN）/（TP + TN + FP + FN）如下：
- en: '[PRE17]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This is the same as 1 minus accuracy:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这与1减去准确率相同：
- en: '[PRE19]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Although these calculations may seem simple, it is important to practice thinking
    about how the components of the confusion matrix relate to one another. In the
    next section, you will see how these same pieces can be combined in different
    ways to create a variety of additional performance measures.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些计算可能看起来很简单，但重要的是要练习思考混淆矩阵的各个组成部分是如何相互关联的。在下一节中，你将看到这些相同的部分可以以不同的方式组合，以创建各种额外的性能指标。
- en: Beyond accuracy – other measures of performance
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不仅仅是准确性 – 其他性能指标
- en: Countless performance measures have been developed and used for specific purposes
    in disciplines as diverse as medicine, information retrieval, marketing, and signal
    detection theory, among others. To cover all of them could fill hundreds of pages,
    which makes a comprehensive description infeasible here. Instead, we’ll consider
    only some of the most useful and most cited measures in machine learning literature.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 无数性能指标已经被开发并用于各种学科中，如医学、信息检索、营销和信号检测理论等特定目的。要涵盖所有这些指标可能需要数百页，这使得在这里进行全面的描述变得不可行。相反，我们将仅考虑机器学习文献中最有用和最常引用的一些指标。
- en: The `caret` package by Max Kuhn includes functions for computing many such performance
    measures. This package provides tools for preparing, training, evaluating, and
    visualizing machine learning models and data; the name “caret” is a simplification
    of “classification and regression training.” Because it is also valuable for tuning
    models, in addition to its use here, we will also employ the `caret` package extensively
    in *Chapter 14*, *Building Better Learners*. Before proceeding, you will need
    to install the package using the `install.packages("caret")` command.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Max Kuhn的`caret`包包括计算许多此类性能指标的功能。这个包提供了准备、训练、评估和可视化机器学习模型和数据工具；"caret"这个名字是“分类和回归训练”的缩写。由于它对调整模型也很有价值，除了在这里的使用外，我们还将广泛使用`caret`包在*第14章*，*构建更好的学习者*。在继续之前，你需要使用`install.packages("caret")`命令来安装这个包。
- en: For more information on `caret`, refer to *Building Predictive Models in R Using
    the caret Package, Kuhn, M, Journal of Statistical Software, 2008, Vol. 28* or
    the package’s very informative documentation pages at [http://topepo.github.io/caret/index.html](http://topepo.github.io/caret/index.html)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`caret`的更多信息，请参阅*Kuhn, M, 使用caret包在R中构建预测模型，统计软件杂志，2008，第28卷*或包的非常详尽的文档页面[http://topepo.github.io/caret/index.html](http://topepo.github.io/caret/index.html)
- en: 'The `caret` package adds yet another function for creating a confusion matrix.
    As shown in the following command, the syntax is similar to `table()`, but with
    a minor difference. Because `caret` computes the measures of model performance
    that reflect the ability to classify the positive class, a `positive` parameter
    should be specified. In this case, since the SMS classifier is intended to detect
    spam, we will set `positive = "spam"` as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`caret` 包添加了创建混淆矩阵的另一个函数。如下所示，语法与 `table()` 类似，但略有不同。因为 `caret` 计算反映分类正类能力的模型性能度量，所以应指定
    `positive` 参数。在这种情况下，由于 SMS 分类器旨在检测垃圾邮件，我们将设置 `positive = "spam"` 如下：'
- en: '[PRE21]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This results in the following output:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致以下输出：
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: At the top of the output is a confusion matrix much like the one produced by
    the `table()` function, but transposed. The output also includes a set of performance
    measures. Some of these, like accuracy, are familiar, while many others are new.
    Let’s look at some of the most important metrics.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 输出顶部是一个类似于 `table()` 函数生成的混淆矩阵，但已转置。输出还包括一组性能度量。其中一些，如准确度，是熟悉的，而许多其他则是新的。让我们看看一些最重要的指标。
- en: The kappa statistic
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卡方统计量
- en: The **kappa statistic** (labeled `Kappa` in the previous output) adjusts the
    accuracy by accounting for the possibility of a correct prediction by chance alone.
    This is especially important for datasets with a severe class imbalance because
    a classifier can obtain high accuracy simply by always guessing the most frequent
    class. The kappa statistic will only reward the classifier if it is correct more
    often than this simplistic strategy.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**卡方统计量**（在之前的输出中标记为 `Kappa`）通过考虑仅凭偶然正确预测的可能性来调整准确性。这对于具有严重类别不平衡的数据集尤为重要，因为分类器可以通过始终猜测最频繁的类别来获得高准确率。卡方统计量只会奖励那些比这种简单策略更频繁正确分类的分类器。'
- en: There is more than one way to define the kappa statistic. The most common method,
    described here, uses **Cohen’s kappa coefficient**, as described in the paper
    *A coefficient of agreement for nominal scales, Cohen, J, Education and Psychological
    Measurement, 1960, Vol. 20, pp. 37-46*.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 定义卡方统计量的方法不止一种。这里描述的最常见的方法使用 **Cohen 的卡方系数**，如论文 *《名义量度的协议系数，Cohen, J, 教育与心理测量，1960，第20卷，第37-46页》*
    所述。
- en: Kappa values typically range from 0 to a maximum of 1, with higher values reflecting
    stronger agreement between the model’s predictions and the true values. It is
    possible to observe values less than 0 if the predictions are consistently in
    the wrong direction—that is, the predictions disagree with the actual values or
    are wrong more often than would be expected by random guessing. This rarely occurs
    for machine learning models and usually reflects a coding issue, which can be
    fixed by simply reversing the predictions.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 卡方值通常在 0 到最大值 1 之间，更高的值反映了模型预测与真实值之间更强的协议。如果预测始终错误，则可能观察到小于 0 的值——也就是说，预测与实际值不一致或错误率高于随机猜测的预期。这种情况在机器学习模型中很少发生，通常反映编码问题，可以通过简单地反转预测来修复。
- en: 'Depending on how a model is to be used, the interpretation of the kappa statistic
    might vary. One common interpretation is shown as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型的使用方式，卡方统计量的解释可能会有所不同。以下是一个常见的解释示例：
- en: Poor agreement = less than 0.2
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 差一致性 = 小于 0.2
- en: Fair agreement = 0.2 to 0.4
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公平一致性 = 0.2 至 0.4
- en: Moderate agreement = 0.4 to 0.6
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中等一致性 = 0.4 至 0.6
- en: Good agreement = 0.6 to 0.8
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 良好一致性 = 0.6 至 0.8
- en: Very good agreement = 0.8 to 1.0
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好一致性 = 0.8 至 1.0
- en: It’s important to note that these categories are subjective. While “good agreement”
    may be more than adequate for predicting someone’s favorite ice cream flavor,
    “very good agreement” may not suffice if your goal is to identify birth defects.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，这些类别是主观的。虽然“良好一致性”可能足以预测某人的最爱冰淇淋口味，但如果目标是识别出生缺陷，“非常好一致性”可能就不够了。
- en: For more information on the previous scale, refer to *The measurement of observer
    agreement for categorical data, Landis, JR, Koch, GG. Biometrics, 1997, Vol. 33,
    pp. 159-174*.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 关于前述量表更详细的信息，请参阅 *《分类数据的观察者一致性测量，Landis, JR, Koch, GG. 生物统计学，1997，第33卷，第159-174页》*。
- en: 'The following is the formula for calculating the kappa statistic. In this formula,
    Pr(*a*) refers to the proportion of actual agreement and Pr(*e*) refers to the
    expected agreement between the classifier and the true values, under the assumption
    that they were chosen at random:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为计算 kappa 统计量提供的公式。在这个公式中，Pr(*a*) 指的是实际协议的比例，而 Pr(*e*) 指的是在假设它们是随机选择的情况下，分类器和真实值之间预期协议的比例：
- en: '![](img/B17290_10_003.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17290_10_003.png)'
- en: 'These proportions are easy to obtain from a confusion matrix once you know
    where to look. Let’s consider the confusion matrix for the SMS classification
    model created with the `CrossTable()` function, which is repeated here for convenience:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这些比例一旦你知道在哪里寻找，就可以从混淆矩阵中获得。让我们考虑使用 `CrossTable()` 函数创建的 SMS 分类模型的混淆矩阵，这里为了方便起见重复列出：
- en: '[PRE23]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Remember that the bottom value in each cell indicates the proportion of all
    instances falling into that cell. Therefore, to calculate the observed agreement
    Pr(*a*), we simply add the proportion of all instances where the predicted type
    and actual SMS type agree.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，每个单元格的底部值表示所有实例落入该单元格的比例。因此，为了计算观察到的协议比例 Pr(*a*)，我们只需将预测类型和实际短信类型达成一致的实例比例相加。
- en: 'Thus, we can calculate Pr(*a*) as:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以计算 Pr(*a*) 如下：
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: For this classifier, the observed and actual values agree 97.4 percent of the
    time—you will note that this is the same as the accuracy. The kappa statistic
    adjusts the accuracy relative to the expected agreement, Pr(*e*), which is the
    probability that chance alone would lead the predicted and actual values to match,
    under the assumption that both are selected randomly according to the observed
    proportions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '对于这个分类器，观察值和实际值有 97.4% 的时间达成一致——你会注意到这与准确率相同。kappa 统计量调整了相对于预期一致性 Pr(*e*) 的准确率，即仅凭偶然，在假设两者都是根据观察比例随机选择的情况下，预测值和实际值匹配的概率。 '
- en: 'To find these observed proportions, we can use the probability rules we learned
    in *Chapter 4*, *Probabilistic Learning – Classification Using Naive Bayes*. Assuming
    two events are independent (meaning one does not affect the other), probability
    rules note that the probability of both occurring is equal to the product of the
    probabilities of each one occurring. For instance, we know that the probability
    of both choosing ham is:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到这些观察到的比例，我们可以使用我们在 *第 4 章* 中学到的概率规则。假设两个事件是独立的（意味着一个不会影响另一个），概率规则指出，两个事件同时发生的概率等于各自发生的概率的乘积。例如，我们知道选择非垃圾邮件的概率是：
- en: Pr(*actual_type is ham*) * Pr(*predicted_type is ham*)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Pr(*实际类型是非垃圾邮件*) * Pr(*预测类型是非垃圾邮件*)
- en: 'And the probability of both choosing spam is:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 选择垃圾邮件的概率是：
- en: Pr(*actual_type is spam*) * Pr(*predicted_type is spam*)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Pr(*实际类型是垃圾邮件*) * Pr(*预测类型是垃圾邮件*)
- en: The probability that the predicted or actual type is spam or ham can be obtained
    from the row or column totals. For instance, Pr(*actual_type is ham*) = 0.868
    and Pr(*predicted type is ham*) = 0.888.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 预测或实际类型是垃圾邮件或非垃圾邮件的概率可以从行或列总数中获得。例如，Pr(*实际类型是非垃圾邮件*) = 0.868 和 Pr(*预测类型是非垃圾邮件*)
    = 0.888。
- en: 'Pr(*e*) can be calculated as the sum of the probabilities that the predicted
    and actual values agree that the message is either spam or ham. Recall that for
    mutually exclusive events (events that cannot happen simultaneously), the probability
    of either occurring is equal to the sum of their probabilities. Therefore, to
    obtain the final Pr(*e*), we simply add both products, as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Pr(*e*) 可以通过预测值和实际值都认为消息是垃圾邮件或非垃圾邮件的概率之和来计算。回想一下，对于互斥事件（不能同时发生的事件），任一事件发生的概率等于其概率之和。因此，为了获得最终的
    Pr(*e*)，我们只需将两个乘积相加，如下所示：
- en: '[PRE26]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Since Pr(*e*) is 0.786, by chance alone, we would expect the observed and actual
    values to agree about 78.6 percent of the time.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Pr(*e*) 是 0.786，仅凭偶然，我们预计观察值和实际值将有大约 78.6% 的时间达成一致。
- en: 'This means that we now have all the information needed to complete the kappa
    formula. Plugging the Pr(*a*) and Pr(*e*) values into the kappa formula, we find:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们现在拥有了完成 kappa 公式的所有信息。将 Pr(*a*) 和 Pr(*e*) 值代入 kappa 公式，我们得到：
- en: '[PRE28]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The kappa is about 0.88, which agrees with the previous `confusionMatrix()`
    output from `caret` (the small difference is due to rounding). Using the suggested
    interpretation, we note that there is very good agreement between the classifier’s
    predictions and the actual values.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: kappa 大约是 0.88，这与之前 `caret` 的 `confusionMatrix()` 输出相符（小的差异是由于四舍五入）。使用建议的解释，我们注意到分类器的预测值和实际值之间有非常好的协议。
- en: 'There are a couple of R functions for calculating kappa automatically. The
    `Kappa()` function (be sure to note the capital “K”) in the **Visualizing Categorical
    Data** (**VCD**) package uses a confusion matrix of predicted and actual values.
    After installing the package by typing `install.packages("vcd")`, the following
    commands can be used to obtain kappa:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个R函数可以自动计算kappa。**可视化分类数据**（`VCD`）包中的`Kappa()`函数（请注意大写的“K”），使用预测值和实际值的混淆矩阵。通过输入`install.packages("vcd")`安装包后，可以使用以下命令获取kappa：
- en: '[PRE30]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We’re interested in the unweighted kappa. The value of 0.88 matches what we
    computed manually.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对无权重的kappa值感兴趣。0.88的值与我们手动计算的结果相符。
- en: The weighted kappa is used when there are varying degrees of agreement. For
    example, using a scale of cold, cool, warm, and hot, the value of warm agrees
    more with hot than it does with the value of cold. In the case of a two-outcome
    event, such as spam and ham, the weighted and unweighted kappa statistics will
    be identical.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当存在不同程度的协议时，使用加权kappa。例如，使用冷、凉爽、温暖和热的刻度，温暖与热的值比与冷的值更一致。在两个结果事件的情况下，如垃圾邮件和正常邮件，加权kappa和未加权kappa统计量将是相同的。
- en: 'The `kappa2()` function in the **Interrater Reliability** (`irr`) package can
    be used to calculate kappa from vectors of predicted and actual values stored
    in a data frame. After installing the package using `install.packages("irr")`,
    the following commands can be used to obtain kappa:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**Interrater Reliability**（`irr`）包中的`kappa2()`函数可以用来从数据框中存储的预测值和实际值的向量中计算kappa。在通过`install.packages("irr")`安装包之后，可以使用以下命令获取kappa：'
- en: '[PRE32]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `Kappa()` and `kappa2()` functions report the same kappa statistic, so use
    whichever option you are more comfortable with.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`Kappa()`和`kappa2()`函数报告相同的kappa统计量，因此使用您更舒适的选项。'
- en: Be careful not to use the built-in `kappa()` function. It is completely unrelated
    to the kappa statistic reported previously!
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意不要使用内置的`kappa()`函数。它与之前报告的kappa统计量完全无关！
- en: The Matthews correlation coefficient
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 矩阵相关系数
- en: Although accuracy and kappa have been popular measures of performance for many
    years, a third option has quickly become a de facto standard in the field of machine
    learning. Like both prior metrics, the **Matthews correlation coefficient** (**MCC**)
    is a single statistic intended to reflect the overall performance of a classification
    model. Additionally, the MCC is like kappa in that it is useful even in the case
    that the dataset is severely imbalanced—the types of situations in which the traditional
    accuracy measure can be very misleading.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管准确性和kappa多年来一直是性能的流行指标，但第三个选项迅速成为机器学习领域的实际标准。与先前的指标一样，**矩阵相关系数**（**MCC**）是一个单一统计量，旨在反映分类模型的总体性能。此外，MCC与kappa类似，即使在数据集严重不平衡的情况下（在这种情况下，传统的准确度度量可能会非常误导），它也是有用的。
- en: The MCC has grown in popularity due to its ease of interpretation, as well as
    a growing body of evidence suggesting that it performs better in a wider variety
    of circumstances than kappa. Recent empirical research has indicated that the
    MCC may be the best single metric for describing the real-world performance of
    a binary classification model. Other studies have identified potential circumstances
    in which the kappa statistic provides a misleading or incorrect depiction of model
    performance. In these cases, when the MCC and kappa disagree, the MCC metric tends
    to provide a more reasonable assessment of the model’s true capabilities.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其易于解释，以及越来越多的证据表明它在比kappa更广泛的情境下表现更好，MCC越来越受欢迎。最近的经验研究表明，MCC可能是描述二元分类模型现实世界性能的最佳单一指标。其他研究已经确定了可能导致kappa统计量提供误导或不正确模型性能描述的潜在情境。在这些情况下，当MCC和kappa不一致时，MCC指标往往能更合理地评估模型的真正能力。
- en: For more information on the relative advantages of the Matthews correlation
    coefficient versus kappa, see *The Matthews correlation coefficient (MCC) is more
    informative than Cohen’s kappa and brier score in binary classification assessment,
    Chicco D, Warrens MJ, Jurman G, IEEE Access, 2021, Vol. 9, pp. 78368-78381*. Alternatively,
    refer to *Why Cohen’s Kappa should be avoided as performance measure in classification,
    Delgado R, Tibau XA, PLoS One, 2019, Vol. 14(9):e0222916*.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 关于马修斯相关系数与 k 值相对优势的更多信息，请参阅 *The Matthews correlation coefficient (MCC) is more
    informative than Cohen’s kappa and brier score in binary classification assessment,
    Chicco D, Warrens MJ, Jurman G, IEEE Access, 2021, Vol. 9, pp. 78368-78381*。或者，参考
    *Why Cohen’s Kappa should be avoided as performance measure in classification,
    Delgado R, Tibau XA, PLoS One, 2019, Vol. 14(9):e0222916*。
- en: 'Values of the MCC are interpreted on the same scale as Pearson’s correlation
    coefficient, which was introduced in *Chapter 6*, *Forecasting Numeric Data –
    Regression Methods*. This ranges from -1 to +1, which indicate perfectly inaccurate
    and perfectly accurate predictions, respectively. A value of 0 indicates a model
    that performs no better than random guessing. As most MCC scores fall somewhere
    in the range of values between 0 and 1, some subjectivity is involved in knowing
    what is a “good” score. Much like the scale used for Pearson correlations, one
    potential interpretation is as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: MCC 的值解释与皮尔逊相关系数相同，该系数在 *第 6 章*，*预测数值数据 – 回归方法* 中介绍。这个范围从 -1 到 +1，分别表示完全不准确和完全准确的预测。值为
    0 表示模型的表现不优于随机猜测。由于大多数 MCC 分数都位于 0 和 1 之间的某个值域内，因此“良好”分数的判断具有一定的主观性。与皮尔逊相关系数使用的刻度类似，一种可能的解释如下：
- en: Perfectly incorrect = -1.0
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全错误 = -1.0
- en: Strongly incorrect = -0.5 to -1.0
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强度错误 = -0.5 到 -1.0
- en: Moderately incorrect = -0.3 to -0.5
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中度错误 = -0.3 到 -0.5
- en: Weakly incorrect = -0.1 to 0.3
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弱度错误 = -0.1 到 0.3
- en: Randomly correct = -0.1 to 0.1
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机正确 = -0.1 到 0.1
- en: Weakly correct = 0.1 to 0.3
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轻度正确 = 0.1 到 0.3
- en: Moderately correct = 0.3 to 0.5
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中度正确 = 0.3 到 0.5
- en: Strongly correct = 0.5 to 1.0
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强度正确 = 0.5 到 1.0
- en: Perfectly correct = 1.0
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全正确 = 1.0
- en: Note that the worst-performing models fall in the middle of the scale. In other
    words, a model on the negative side of the scale (from perfectly to weakly incorrect)
    still performs better than a model predicting at random. For instance, even though
    the accuracy of a strongly incorrect model is poor, the predictions can simply
    be reversed to obtain the correct result.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，表现最差的模型位于刻度中间。换句话说，位于刻度负侧（从完全错误到轻度错误）的模型仍然比随机预测的模型表现更好。例如，即使强度错误的模型的准确度很差，预测结果也可以简单地反转以获得正确的结果。
- en: As with all such scales, these should be used only as rough guidelines. Furthermore,
    the key benefit of a metric like the MCC is not to understand a model’s performance
    in isolation, but rather, to facilitate performance comparisons across several
    models.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有此类刻度一样，这些刻度只能作为粗略的指南。此外，像 MCC 这样的度量标准的关键好处不是理解模型在孤立状态下的性能，而是促进跨多个模型的性能比较。
- en: 'The MCC can be computed from the confusion matrix for a binary classifier as
    shown in the following formula:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二分类器的混淆矩阵，MCC 可以通过以下公式计算：
- en: '![](img/B17290_10_004.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17290_10_004.png)'
- en: 'Using the confusion matrix for the SMS spam classification model, we obtain
    the following values:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SMS 垃圾邮件分类模型的混淆矩阵，我们得到以下值：
- en: TN = 1203
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TN = 1203
- en: FP = 4
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FP = 4
- en: FN = 31
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FN = 31
- en: TP = 152
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TP = 152
- en: 'The MCC can then be computed manually in R as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以在 R 中手动计算 MCC，如下所示：
- en: '[PRE34]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The `mltools` package by Ben Gorman provides an `mcc()` function which can
    perform the MCC calculation using vectors of predicted and actual values. After
    installing the package, the following R code produces the same result as the calculation
    done by hand:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Ben Gorman 开发的 `mltools` 包提供了一个 `mcc()` 函数，该函数可以使用预测值和实际值的向量执行 MCC 计算。安装该包后，以下
    R 代码产生的结果与手动计算的结果相同：
- en: '[PRE36]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Alternatively, for a binary classifier where the positive class is coded as
    1 and the negative class is coded as 0, the MCC is identical to the Pearson correlation
    between the predicted and actual values. We can demonstrate this using the `cor()`
    function in R, after using `ifelse()` to convert the categorical (`"spam"` or
    `"ham"`) values into binary (`1` or `0`) values as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，对于将正类编码为 1 且将负类编码为 0 的二分类器，MCC 与预测值和实际值之间的皮尔逊相关系数相同。我们可以使用 R 中的 `cor()` 函数来演示这一点，在将分类值（`"spam"`
    或 `"ham"`）转换为二进制值（`1` 或 `0`）后，如下所示：
- en: '[PRE38]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The fact that such an obvious classification performance metric was hiding in
    plain sight, as a simple adaptation of Pearson’s correlation introduced in the
    late 1800s, makes it quite remarkable that the MCC has only become popular in
    recent decades! Biochemist Brian W. Matthews is responsible for popularizing this
    metric in 1975 for use in two-outcome classification problems and thus receives
    naming credit for this specific application. However, it seems quite likely that
    the metric was already used widely, even if it had not garnered much attention
    until much later. Today, it is used across industry, academic research, and even
    as a benchmark for machine learning competitions. There may be no single metric
    that better captures the overall performance of a binary classification model.
    However, as you will soon see, a more in-depth understanding of model performance
    can be obtained using combinations of metrics.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这样一个显然的分类性能指标竟然隐藏在显而易见的地方，作为一个简单的对19世纪末引入的皮尔逊相关性的改编，这使得MCC（Matthews Correlation
    Coefficient）仅在最近几十年才变得流行！生物化学家布莱恩·W·马修斯在1975年负责推广这个指标用于双分类问题，因此他因这一特定应用而获得命名荣誉。然而，似乎很可能是这个指标已经被广泛使用，即使它直到很久以后才引起了很多关注。如今，它在工业界、学术研究和甚至作为机器学习竞赛的基准中得到应用。可能没有单一的指标能更好地捕捉二元分类模型的总体性能。然而，正如你很快就会看到的，通过组合多个指标可以获得对模型性能的更深入理解。
- en: 'Although the MCC is defined here for binary classification, it is unclear whether
    it is the best metric for multi-class outcomes. For a discussion of this and other
    alternatives, see *A comparison of MCC and CEN error measures in multi-class prediction,
    Jurman G, Riccadonna S, Furlanello C, 2012, PLOS One 7(8): e41882*.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然MCC在这里是为二元分类定义的，但它是否是多类结果的最佳指标尚不清楚。关于这一点和其他替代方案的讨论，请参阅*“多类预测中MCC和CEN误差测量的比较，Jurman
    G，Riccadonna S，Furlanello C，2012，PLOS One 7(8): e41882”*。'
- en: Sensitivity and specificity
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 灵敏度和特异性
- en: 'Finding a useful classifier often involves a balance between predictions that
    are overly conservative and overly aggressive. For example, an email filter could
    guarantee to eliminate every spam message by aggressively filtering nearly every
    ham message. On the other hand, to guarantee that no ham messages will be inadvertently
    filtered might require us to allow an unacceptable amount of spam to pass through
    the filter. A pair of performance measures captures this tradeoff: sensitivity
    and specificity.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找一个有用的分类器通常需要在过于保守的预测和过于激进的预测之间取得平衡。例如，一个电子邮件过滤器可以通过激进地过滤几乎所有的正常邮件来保证消除每一封垃圾邮件。另一方面，为了保证没有正常邮件被意外过滤，可能需要我们允许通过过滤器的不合理数量的垃圾邮件。一对性能指标捕捉了这种权衡：灵敏度和特异性。
- en: 'The **sensitivity** of a model (also called the **true positive rate**) measures
    the proportion of positive examples that were correctly classified. Therefore,
    as shown in the following formula, it is calculated as the number of true positives
    divided by the total number of positives, both those correctly classified (the
    true positives) and those incorrectly classified (the false negatives):'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的**灵敏度**（也称为**真正率**）衡量的是正确分类的正面样本占所有正面样本的比例。因此，正如以下公式所示，它是通过将真正例的数量除以所有正面样本的总数来计算的，包括那些正确分类的（真正例）和那些错误分类的（假阴性）：
- en: '![](img/B17290_10_005.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_10_005.png)'
- en: The **specificity** of a model (also called the **true negative rate**) measures
    the proportion of negative examples that were correctly classified. As with sensitivity,
    this is computed as the number of true negatives divided by the total number of
    negatives—the true negatives plus the false positives.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的**特异性**（也称为**真正率**）衡量的是正确分类的负面样本占所有负面样本的比例。与灵敏度一样，这是通过将真正例的数量除以所有负面样本的总数来计算的——包括真正例和假阳性。
- en: '![](img/B17290_10_006.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_10_006.png)'
- en: 'Given the confusion matrix for the SMS classifier, we can easily calculate
    these measures by hand. Assuming that spam is a positive class, we can confirm
    that the numbers in the `confusionMatrix()` output are correct. For example, the
    calculation for sensitivity is:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 对于短信分类器的混淆矩阵，我们可以很容易地手动计算这些指标。假设垃圾邮件是一个正面类别，我们可以确认`confusionMatrix()`输出中的数字是正确的。例如，灵敏度的计算如下：
- en: '[PRE40]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Similarly, for specificity, we can calculate:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，对于特异性，我们可以计算：
- en: '[PRE42]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The `caret` package provides functions for calculating sensitivity and specificity
    directly from vectors of predicted and actual values. Be careful to specify the
    `positive` or `negative` parameter appropriately, as shown in the following lines:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`caret`包提供了从预测值和实际值向量直接计算敏感性和特异性的函数。请确保适当地指定`positive`或`negative`参数，如下所示：'
- en: '[PRE44]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Sensitivity and specificity range from 0 to 1, with values close to 1 being
    more desirable. Of course, it is important to find an appropriate balance between
    the two—a task that is often quite context-specific.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感性和特异性范围从0到1，接近1的值更受欢迎。当然，找到两者之间的适当平衡是很重要的——这是一个通常非常具体于上下文的任务。
- en: For example, in this case, the sensitivity of 0.831 implies that 83.1 percent
    of the spam messages were correctly classified. Similarly, the specificity of
    0.997 implies that 99.7 percent of non-spam messages were correctly classified,
    or alternatively, 0.3 percent of valid messages were rejected as spam. The idea
    of rejecting 0.3 percent of valid SMS messages may be unacceptable, or it may
    be a reasonable tradeoff given the reduction in spam.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在这种情况下，0.831的敏感性意味着83.1%的垃圾邮件被正确分类。同样，0.997的特异性意味着99.7%的非垃圾邮件被正确分类，或者换句话说，0.3%的有效消息被错误地标记为垃圾邮件。拒绝0.3%的有效短信消息可能是不被接受的，或者考虑到垃圾邮件数量的减少，这可能是合理的权衡。
- en: Sensitivity and specificity provide tools for thinking about such tradeoffs.
    Typically, changes are made to the model and different models are tested until
    you find one that meets a desired sensitivity and specificity threshold. Visualizations,
    such as those discussed later in this chapter, can also assist with understanding
    the balance between sensitivity and specificity.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感性和特异性提供了思考此类权衡的工具。通常，会调整模型并测试不同的模型，直到找到一个满足所需敏感性和特异性阈值的模型。本章后面讨论的可视化也可以帮助理解敏感性和特异性之间的平衡。
- en: Precision and recall
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精确度和召回率
- en: 'Closely related to sensitivity and specificity are two other performance measures
    related to compromises made in classification: precision and recall. Used primarily
    in the context of information retrieval, these statistics are intended to indicate
    how interesting and relevant a model’s results are, or whether the predictions
    are diluted by meaningless noise.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 与敏感性和特异性密切相关的是另外两个与分类中做出的妥协相关的性能指标：精确度和召回率。主要在信息检索的背景下使用，这些统计数据旨在表明模型的结果有多有趣和相关性，或者预测是否被无意义的噪声稀释。
- en: The **precision** (also known as the **positive predictive value**) is defined
    as the proportion of positive predictions that are truly positive; in other words,
    when a model predicts the positive class, how often is it correct? A precise model
    will only predict the positive class in cases very likely to be positive. It will
    be very trustworthy.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确度**（也称为**阳性预测值**）定义为真正阳性的预测比例；换句话说，当模型预测阳性类别时，它有多正确？一个精确的模型只会预测那些非常可能是阳性的情况。它将非常可靠。'
- en: '![](img/B17290_10_007.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_10_007.png)'
- en: Consider what would happen if the model was very imprecise. Over time, the results
    would be less likely to be trusted. In the context of information retrieval, this
    would be analogous to a search engine like Google returning irrelevant results.
    Eventually, users would switch to a competitor like Bing. In the case of the SMS
    spam filter, high precision means that the model is able to carefully target only
    the spam while avoiding false positives in the ham.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下，如果模型非常不精确会发生什么。随着时间的推移，结果不太可能被信任。在信息检索的背景下，这类似于像Google这样的搜索引擎返回不相关结果。最终，用户可能会转向像Bing这样的竞争对手。在短信垃圾邮件过滤器的例子中，高精确度意味着模型能够仔细地只针对垃圾邮件，同时避免在正常邮件中出现误报。
- en: On the other hand, **recall** is a measure of how complete the results are.
    As shown in the following formula, this is defined as the number of true positives
    over the total number of positives. You may have already recognized this as the
    same as sensitivity; however, the interpretation differs slightly.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**召回率**是衡量结果完整性的一个指标。如下公式所示，这定义为真正阳性数除以总阳性数。你可能已经认识到这与敏感性相同；然而，解释略有不同。
- en: '![](img/B17290_10_008.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_10_008.png)'
- en: A model with high recall captures a large portion of the positive examples,
    meaning that it has a wide breadth. For example, a search engine with high recall
    returns a large number of documents pertinent to the search query. Similarly,
    the SMS spam filter has high recall if the majority of spam messages are correctly
    identified.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 具有高召回率的模型能够捕获大量正例，这意味着它具有广泛的覆盖面。例如，具有高召回率的搜索引擎会返回大量与搜索查询相关的文档。同样，如果大多数垃圾邮件消息被正确识别，短信垃圾邮件过滤器也具有高召回率。
- en: 'We can calculate precision and recall from the confusion matrix. Again, assuming
    that spam is a positive class, the precision is:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从混淆矩阵中计算出精确度和召回率。再次假设垃圾邮件是一个正类，精确度是：
- en: '[PRE48]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'And the recall is:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率是：
- en: '[PRE50]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The `caret` package can be used to compute either of these measures from vectors
    of predicted and actual classes. Precision uses the `posPredValue()` function:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`caret`包从预测和实际类别的向量中计算这些度量之一。精确度使用`posPredValue()`函数：
- en: '[PRE52]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Recall uses the `sensitivity()` function that we used earlier:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率使用我们之前使用的`sensitivity()`函数：
- en: '[PRE54]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Like the tradeoff between sensitivity and specificity, for most real-world problems,
    it is difficult to build a model with both high precision and high recall. It
    is easy to be precise if you target only the low-hanging fruit—the easiest-to-classify
    examples. Similarly, it is easy for a model to have a high recall by casting a
    very wide net, meaning that the model is overly aggressive at identifying positive
    cases. In contrast, having both high precision and recall at the same time is
    very challenging. It is therefore important to test a variety of models in order
    to find the combination of precision and recall that meets the needs of your project.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 就像敏感性和特异性之间的权衡一样，对于大多数现实世界的问题，很难构建一个既具有高精确度又具有高召回率的模型。如果你只针对容易分类的例子（即低垂的果实），那么很容易做到精确。同样，一个模型通过撒一个非常宽的网，意味着模型在识别正例时过于激进，也容易具有高召回率。相比之下，同时具有高精确度和召回率是非常具有挑战性的。因此，为了找到满足你项目需求的精确度和召回率的组合，测试各种模型是非常重要的。
- en: The F-measure
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F度量
- en: 'A measure of model performance that combines precision and recall into a single
    number is known as the **F-measure** (also sometimes called the **F**[1] **score**
    or the **F-score**). The F-measure combines precision and recall using the **harmonic
    mean**, a type of average that is used for rates of change. The harmonic mean
    is used rather than the more common arithmetic mean since both precision and recall
    are expressed as proportions between 0 and 1, which can be interpreted as rates.
    The following is the formula for the F-measure:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 将精确度和召回率结合成一个单一数字的模型性能度量称为**F度量**（有时也称为**F**[1] **分数**或**F分数**）。F度量通过**调和平均数**结合精确度和召回率，这是一种用于变化率的平均数类型。由于精确度和召回率都表示为0到1之间的比例，可以解释为变化率，因此使用调和平均数而不是更常见的算术平均数。以下为F度量的公式：
- en: '![](img/B17290_10_009.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17290_10_009.png)'
- en: 'To calculate the F-measure, use the precision and recall values computed previously:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算F度量，使用之前计算出的精确度和召回率值：
- en: '[PRE56]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'This comes out exactly the same as using the counts from the confusion matrix:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这与使用混淆矩阵中的计数完全相同：
- en: '[PRE58]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Since the F-measure describes model performance in a single number, it provides
    a convenient, quantitative metric to compare several models directly. Indeed,
    the F-measure was once virtually a gold standard measure of a model of performance,
    but today, it seems to be much less widely used than it was previously. One potential
    explanation is that it assumes that equal weight should be assigned to precision
    and recall, an assumption that is not always valid, depending on the real-world
    costs of false positives and false negatives. Of course, it is possible to calculate
    F-scores using different weights for precision and recall, but choosing the weights
    can be tricky at best and arbitrary at worst. This being said, perhaps a more
    important reason why this metric has fallen out of favor is the adoption of methods
    that visually depict a model’s performance on different subsets of data, such
    as those described in the next section.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 由于F度量将模型性能描述为一个单一数字，它提供了一个方便的、定量的指标，可以直接比较多个模型。确实，F度量曾经几乎成为衡量模型性能的黄金标准，但今天，它似乎比以前使用得少得多。一个可能的解释是，它假设精确度和召回度应该被赋予相同的权重，这个假设并不总是有效的，这取决于现实世界中假阳性和假阴性的实际成本。当然，可以使用不同的精确度和召回度权重来计算F分数，但选择权重可能最坏的情况是随意的。尽管如此，也许这个指标不再受欢迎的更重要原因是采用了方法，这些方法可以直观地描绘模型在不同数据子集上的性能，如下一节所述。
- en: Visualizing performance tradeoffs with ROC curves
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ROC曲线可视化性能权衡
- en: Visualizations are helpful for understanding the performance of machine learning
    algorithms in greater detail. Where statistics such as sensitivity and specificity,
    or precision and recall, attempt to boil model performance down to a single number,
    visualizations depict how a learner performs across a wide range of conditions.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化有助于更详细地理解机器学习算法的性能。当诸如敏感度、特异性、精确度和召回率等统计量试图将模型性能简化为一个单一数字时，可视化则描绘了学习者在广泛条件下的表现。
- en: Because learning algorithms have different biases, it is possible that two models
    with similar accuracy could have drastic differences in how they achieve their
    accuracy. Some models may struggle with certain predictions that others make with
    ease while breezing through cases that others struggle to get right. Visualizations
    provide a method for understanding these tradeoffs by comparing learners side
    by side in a single chart.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 由于学习算法有不同的偏差，两个具有相似准确率的模型可能在达到准确率的方式上存在巨大差异。一些模型可能在某些预测上挣扎，而其他模型则轻松完成，同时轻松处理其他模型难以正确处理的案例。可视化提供了一种方法，通过在单个图表中并排比较学习器来理解这些权衡。
- en: The **receiver operating characteristic** (**ROC**) curve is commonly used to
    examine the tradeoff between the detection of true positives while avoiding false
    positives. As you might suspect from the name, ROC curves were developed by engineers
    in the field of communications. Around the time of World War II, radar and radio
    operators used ROC curves to measure a receiver’s ability to discriminate between
    true signals and false alarms. The same technique is useful today for visualizing
    the efficacy of machine learning models.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '**接收者操作特征**（**ROC**）曲线通常用于检查在避免假阳性同时检测真阳性的权衡。正如你可能从其名称中猜测到的，ROC曲线是由通信领域的工程师开发的。在第二次世界大战期间，雷达和无线电操作员使用ROC曲线来衡量接收器区分真实信号和虚假警报的能力。同样的技术今天对于可视化机器学习模型的功效也很有用。'
- en: For more reading on ROC curves, see *An introduction to ROC analysis, Fawcett
    T, Pattern Recognition Letters, 2006, Vol. 27, pp. 861–874*.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 关于ROC曲线的更多阅读，请参阅*《ROC分析简介》，Fawcett T，Pattern Recognition Letters，2006年，第27卷，第861-874页*。
- en: The characteristics of a typical ROC diagram are depicted in *Figure 10.4*.
    The ROC curve is drawn using the proportion of true positives on the vertical
    axis and the proportion of false positives on the horizontal axis. Because these
    values are equivalent to sensitivity and (1 – specificity), respectively, the
    diagram is also known as a **sensitivity/specificity plot**.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 典型ROC图的特征在*图10.4*中展示。ROC曲线使用垂直轴上的真阳性比例和水平轴上的假阳性比例来绘制。因为这些值分别等同于敏感度和（1 – 特异性），所以该图也被称为**敏感度/特异性图**。
- en: '![Chart  Description automatically generated](img/B17290_10_07.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![图表描述自动生成](img/B17290_10_07.png)'
- en: 'Figure 10.4: The ROC curve depicts classifier shapes relative to perfect and
    useless classifiers'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4：ROC曲线描绘了分类器形状相对于完美和无用分类器
- en: The points comprising ROC curves indicate the true positive rate at varying
    false positive thresholds. To illustrate this concept, three hypothetical classifiers
    are contrasted in the previous plot. First, the *perfect classifier* has a curve
    that passes through the point at a 100 percent true positive rate and a 0 percent
    false positive rate. It is able to correctly identify all of the true positives
    before it incorrectly classifies any negative result. Next, the diagonal line
    from the bottom-left to the top-right corner of the diagram represents a *classifier
    with no predictive value*. This type of classifier detects true positives and
    false positives at exactly the same rate, implying that the classifier cannot
    discriminate between the two. This is the baseline by which other classifiers
    may be judged. ROC curves falling close to this line indicate models that are
    not very useful. Lastly, most real-world classifiers are like the *test classifier*,
    in that they fall somewhere in the zone between perfect and useless.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 组成ROC曲线的点表示在变化的假阳性阈值下的真正例率。为了说明这个概念，前一个图表中对比了三个假设的分类器。首先，*完美分类器*的曲线通过100%真正例率和0%假阳性率的点。它能够在错误地分类任何负例之前正确地识别所有真正例。接下来，从图的下左角到上右角的斜线代表一个*无预测价值的分类器*。这种分类器以相同的速率检测真正例和假阳性，这意味着分类器无法区分两者。这是其他分类器可以评判的基准。接近这条线的ROC曲线表示模型不太有用。最后，大多数现实世界的分类器都像*测试分类器*一样，它们位于完美和无用之间的区域。
- en: The best way to understand how the ROC curve is constructed is to create one
    by hand. The values in the table depicted in *Figure 10.5* indicate predictions
    of a hypothetical spam model applied to a test set containing 20 examples, of
    which six are the positive class (spam) and 14 are the negative class (ham).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 理解ROC曲线构建的最佳方式是亲手绘制一个。*图10.5*中表格中的数值表示了一个假设的垃圾邮件模型在包含20个示例的测试集上的预测结果，其中6个是正类（垃圾邮件），14个是负类（正常邮件）。
- en: '![Table  Description automatically generated](img/B17290_10_08.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![表格描述自动生成](img/B17290_10_08.png)'
- en: 'Figure 10.5: To construct the ROC curve, the estimated probability values for
    the positive class are sorted in descending order, then compared to the actual
    class value'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5：为了构建ROC曲线，将正类的估计概率值按降序排序，然后与实际类别值进行比较
- en: 'To create the curves, the classifier’s predictions are sorted by the model’s
    estimated probability of the positive class, in descending order, with the largest
    values first, as shown in the table. Then, beginning at the plot’s origin, each
    prediction’s impact on the true positive rate and false positive rate results
    in a curve tracing vertically for each positive example and horizontally for each
    negative example. This process can be performed by hand on a piece of graph paper,
    as depicted in *Figure 10.6*:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建曲线，需要按照模型对正类估计概率的降序对分类器的预测进行排序，最大的值排在前面，如表中所示。然后，从图表的原点开始，每个预测对真正例率和假阳性率的影响导致曲线垂直于每个正例进行追踪，水平于每个负例进行追踪。这个过程可以在一张坐标纸上手工完成，如图*图10.6*所示：
- en: '![Chart  Description automatically generated](img/B17290_10_09.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![图表描述自动生成](img/B17290_10_09.png)'
- en: 'Figure 10.6: The ROC curve can be created by hand on graph paper by plotting
    the number of positive examples versus the number of negative examples'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6：可以在坐标纸上通过绘制正例数量与负例数量的对比来手工绘制ROC曲线
- en: 'Note that the ROC curve is not complete at this point, because the axes are
    skewed due to the presence of more than twice as many negative examples as positive
    examples in the test set. A simple fix for this is to scale the plot proportionally
    so that the two axes are equivalent in size, as depicted in *Figure 10.7*:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，此时ROC曲线并不完整，因为测试集中负例的数量是正例的两倍以上，导致坐标轴倾斜。一个简单的解决方案是将图表按比例缩放，使得两个坐标轴的大小相等，如图*图10.7*所示：
- en: '![Chart, scatter chart  Description automatically generated](img/B17290_10_10.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![图表，散点图描述自动生成](img/B17290_10_10.png)'
- en: 'Figure 10.7: Scaling the plot’s axes creates a proportionate comparison, regardless
    of the initial balance of positive and negative examples'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7：调整图表的坐标轴比例，可以创建一个无论初始正负例平衡如何都成比例的比较
- en: If we imagine that both the *x* and *y* axes now range from 0 to 1, we can interpret
    each axis as a percentage. The *y* axis is the number of positives and originally
    ranged from 0 to 6; after shrinking it to a scale from 0 to 1, each increment
    becomes 1/6\. On this scale, we can think of the vertical coordinate of the ROC
    curve as the number of true positives divided by the total number of positives,
    which is the true positive rate, or sensitivity. Similarly, the *x* axis measures
    the number of negatives; by dividing by the total number of negatives (14 in this
    example), we obtain the true negative rate, or specificity.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想象现在 *x* 轴和 *y* 轴的范围都是从 0 到 1，我们可以将每个轴解释为百分比。*y* 轴表示正例的数量，最初的范围是从 0 到 6；将其缩小到
    0 到 1 的比例后，每个增量变为 1/6。在这个比例上，我们可以将 ROC 曲线的垂直坐标视为真阳性数除以总正例数，即真阳性率，或灵敏度。同样，*x* 轴衡量的是负例的数量；通过除以总负例数（本例中为
    14），我们得到真阴性率，或特异性。
- en: 'The table in *Figure 10.8* depicts these calculations for all 20 examples in
    the hypothetical test set:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10.8* 中的表格描述了假设测试集中所有 20 个示例的计算：'
- en: '![Table  Description automatically generated](img/B17290_10_11.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![表格描述自动生成](img/B17290_10_11.png)'
- en: 'Figure 10.8: The ROC curve traces what happens to the model’s true positive
    rate versus the false positive rate, for increasingly large sets of examples'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8：ROC 曲线追踪模型真阳性率与假阳性率随示例集规模逐渐增大而发生的变化
- en: An important property of ROC curves is that they are not affected by the class
    imbalance problem in which one of the two outcomes—typically the positive class—is
    much rarer than the other. Many performance metrics, such as accuracy, can be
    misleading for imbalanced data. This is not the case for ROC curves, because both
    dimensions of the plot are based solely on rates *within* the positive and negative
    values, and thus the ratio *across* positives and negatives does not affect the
    result. Because many of the most important machine learning tasks involve severely
    imbalanced outcomes, ROC curves are a very useful tool for understanding the overall
    quality of a model.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线的一个重要特性是它们不受类别不平衡问题的影响，其中一个结果（通常是正类）比另一个结果要罕见得多。许多性能指标，如准确率，对于不平衡数据可能会产生误导。ROC
    曲线并非如此，因为图表的两个维度完全基于正负值内的比率，因此正负之间的比率不会影响结果。由于许多最重要的机器学习任务都涉及严重不平衡的结果，ROC 曲线是理解模型整体质量的一个非常有用的工具。
- en: Comparing ROC curves
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比较ROC曲线
- en: If ROC curves are helpful for evaluating a single model, it is unsurprising
    that they are also useful for comparing across models. Intuitively, we know that
    curves closer to the top-left of the plot area are better. In practice, the comparison
    is often more challenging than this, as differences between curves are often subtle
    rather than obvious, and the interpretation is nuanced and specific to how the
    model is to be used.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 ROC 曲线有助于评估单个模型，那么它们也用于跨模型比较也就不足为奇了。直观上，我们知道靠近图表区域右上角的曲线更好。在实践中，这种比较往往比这更具有挑战性，因为曲线之间的差异通常是微妙的而不是明显的，而且解释是细微的、具体的，并且与模型的使用方式有关。
- en: 'To understand the nuances, let’s begin by considering what causes two models
    to trace different curves on the ROC plot. Beginning at the origin, the curve’s
    length is extended as additional test set examples are predicted to be positive.
    Because the *y* axis represents the true positive rate and the *x* axis represents
    the false positive rate, a steeper upward trajectory is an implicit ratio, implying
    that the model is better at identifying the positive examples without making as
    many mistakes. This is illustrated in *Figure 10.9*, which depicts the start of
    ROC curves for two imaginary models. For the same number of predictions—indicated
    by the equal lengths of the vectors emerging from the origin—the first model has
    a higher true positive rate and a lower false positive rate, which implies it
    is the better performer of the two:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解细微差别，让我们首先考虑是什么原因导致两个模型在 ROC 图上绘制出不同的曲线。从原点开始，曲线长度随着预测为正的测试集示例数量的增加而延长。因为
    *y* 轴代表真阳性率，而 *x* 轴代表假阳性率，更陡峭的上升轨迹是一个隐含的比率，意味着模型在识别正例时犯的错误更少。这如图 10.9 所示，它描绘了两个虚构模型的
    ROC 曲线的起点。对于相同数量的预测——由从原点发出的向量的长度相等表示——第一个模型具有更高的真阳性率和更低的假阳性率，这意味着它是两个模型中表现更好的一个：
- en: '![](img/B17290_10_12.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17290_10_12.png)'
- en: 'Figure 10.9: For the same number of predictions, model 1 outperforms model
    2 because it has a higher true positive rate'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9：对于相同数量的预测，模型1优于模型2，因为它具有更高的真正阳性率
- en: Suppose we continue to trace the ROC curves for each of these two models, evaluating
    the model’s predictions on the entire dataset. In this case, perhaps the first
    model continues to outperform the second at all points on the curve, as shown
    in *Figure 10.10*.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们继续追踪这两个模型的ROC曲线，评估模型在整个数据集上的预测。在这种情况下，也许第一个模型在曲线的所有点上继续优于第二个模型，如*图10.10*所示。
- en: 'For all points on the curve, the first model has a higher true positive rate
    and a lower false positive rate, which means it is the better performer across
    the entire dataset:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在曲线的所有点上，第一个模型具有更高的真正阳性率和更低的假阳性率，这意味着它在整个数据集上是更好的表现者：
- en: '![Chart  Description automatically generated](img/B17290_10_13.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![图表描述自动生成](img/B17290_10_13.png)'
- en: 'Figure 10.10: Model 1 consistently performs better than model 2, with a higher
    true positive rate and a lower false positive rate at all points on the curve'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10：模型1在所有曲线点上始终优于模型2，具有更高的真正阳性和更低的假阳性率
- en: 'Although the second model is clearly inferior in the prior example, choosing
    the better performer is not always so easy. *Figure 10.11* depicts intersecting
    ROC curves, which suggests that neither model is the best performer for all applications:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在先前的例子中第二个模型明显劣于第一个模型，但选择更好的表现者并不总是那么容易。*图10.11*展示了相交的ROC曲线，这表明没有哪个模型是所有应用的最好表现者：
- en: '![Chart  Description automatically generated](img/B17290_10_14.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图表描述自动生成](img/B17290_10_14.png)'
- en: 'Figure 10.11: Both model 1 and model 2 are the better performers for different
    subsets of the data'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11：对于数据的不同子集，模型1和模型2都是更好的表现者
- en: 'The point of intersection between the two ROC curves splits the plot into two
    areas: one in which the first model has a higher true positive rate and the other
    in which the opposite is true. So, how do we know which model is “best” for any
    given use case?'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 两个ROC曲线的交点将图表分为两个区域：一个区域中第一个模型具有更高的真正阳性率，另一个区域中则相反。那么，我们如何知道哪个模型对于任何特定的用例是“最佳”的呢？
- en: To answer this question, when comparing two curves, it helps to understand that
    both models are trying to sort the dataset in order of the highest to the lowest
    probability that each example is of the positive class. Models that are better
    able to sort the dataset in this way will have ROC curves closer to the top-left
    of the plot.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，当比较两条曲线时，了解两个模型都在尝试按照每个示例属于正类概率从高到低的顺序对数据集进行排序是有帮助的。那些能够更好地以这种方式排序数据集的模型将具有更靠近图表左上角的ROC曲线。
- en: The first model in *Figure 10.11* jumps to an early lead because it was able
    to sort a larger number of positive examples to the very front of the dataset,
    but after this initial surge, the second model was able to catch up and outperform
    the other by slowly and steadily sorting positive examples in front of negative
    examples over the remainder of the dataset. Although the second model may have
    better overall performance on the full dataset, we tend to prefer models that
    perform better early—the ones that take the so-called “low-hanging fruit” in the
    dataset. The justification for preferring these models is that many real-world
    models are used only for action on a subset of the data.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10.11*中的第一个模型之所以能迅速领先，是因为它能够将更多的正例排序到数据集的前端，但在此初始激增之后，第二个模型能够逐渐赶上，并在数据集剩余部分中缓慢而稳定地将正例排序在负例之前，从而超越了其他模型。尽管第二个模型可能在整个数据集上具有更好的整体性能，但我们更倾向于选择早期表现更好的模型——那些在数据集中“低垂的果实”上表现更好的模型。选择这些模型的理由是，许多现实世界的模型仅用于对数据子集采取行动。'
- en: For example, consider a model used to identify customers that are most likely
    to respond to a direct mail advertising campaign. If we could afford to mail all
    potential customers, a model would be unnecessary. But because we don’t have the
    budget to send the advertisement to every address, the model is used to estimate
    the probability that the recipient will purchase the product after viewing the
    advertisement. A model that is better at sorting the true most likely purchasers
    to the front of the list will have a greater slope early in the ROC curve and
    will shrink the marketing budget needed to acquire purchasers. In *Figure 10.11*,
    the first model would be a better fit for this task.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个用于识别最有可能对直接邮件广告活动做出反应的客户的模型。如果我们能够向所有潜在客户发送邮件，那么模型就是不必要的。但由于我们没有足够的预算向每个地址发送广告，因此模型被用来估计收件人在查看广告后购买产品的概率。一个能够更好地将真正最有可能购买的产品放在列表前面的模型将会有一个更陡峭的ROC曲线早期斜率，并将缩小获取购买者所需的营销预算。在*图10.11*中，第一个模型更适合这项任务。
- en: In contrast to this approach, another consideration is the relative costs of
    various types of errors; false positives and false negatives often have a different
    impact in the real world. If we know that a spam filter or a cancer screening
    needs to target a specific true positive rate, such as 90 percent or 99 percent,
    we will favor the model that has the lower false positive rate at the desired
    levels. Although neither model would be very good due to the high false positive
    rate, *Figure 10.11* suggests that the second model would be slightly preferable
    for these applications.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 与这种方法相反，另一个考虑因素是各种类型错误的相对成本；在现实世界中，假阳性和假阴性通常有不同的影响。如果我们知道垃圾邮件过滤器或癌症筛查需要针对特定的真正阳性率，例如90%或99%，我们将倾向于选择在期望水平上具有较低假阳性率的模型。尽管由于高假阳性率，这两个模型都不会很好，但*图10.11*表明，第二个模型对于这些应用来说稍微更可取。
- en: As these examples demonstrate, ROC curves allow model performance comparisons
    that also consider how the models will be used. This flexibility is appreciated
    over simpler numeric metrics like accuracy or kappa, but it may also be desirable
    to quantify the ROC curve in a single metric that can be compared quantitatively,
    much like these statistics. The next section introduces exactly this type of measure.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 如这些示例所示，ROC曲线允许比较模型性能，同时也考虑了模型的使用方式。这种灵活性比简单的数值指标如准确度或kappa更受欢迎，但可能也希望通过一个单一的指标来量化ROC曲线，以便可以进行定量比较，就像这些统计数据一样。下一节将介绍这种类型的度量。
- en: The area under the ROC curve
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ROC曲线下的面积
- en: 'Comparing ROC curves can be somewhat subjective and context-specific, so metrics
    that reduce performance to a single numeric value are always in demand to simplify
    and bring objectivity into the comparison. While it may be difficult to say what
    makes a “good” ROC curve, in general, we know that the closer the ROC curve is
    to the top-left of the plot, the better it is at identifying positive values.
    This can be measured using a statistic known as the **area under the ROC curve**
    (**AUC**). The AUC treats the ROC diagram as a two-dimensional square and measures
    the total area under the ROC curve. The AUC ranges from 0.5 (for a classifier
    with no predictive value) to 1.0 (for a perfect classifier). A convention for
    interpreting AUC scores uses a system similar to academic letter grades:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 比较ROC曲线可能具有一定的主观性和情境特异性，因此将性能简化为单一数值的指标总是有需求的，以便简化并使比较具有客观性。虽然可能难以说清楚什么是一个“好的”ROC曲线，但一般来说，我们知道ROC曲线越接近图表的右上角，它在识别正值方面的能力就越好。这可以通过一个称为**ROC曲线下面积**（**AUC**）的统计量来衡量。AUC将ROC图视为一个二维正方形，并测量ROC曲线下的总面积。AUC的范围从0.5（对于没有预测价值的分类器）到1.0（对于完美的分类器）。解释AUC分数的惯例使用了一个类似于学术成绩等级的系统：
- en: '**A**: Outstanding = 0.9 to 1.0'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A**：杰出 = 0.9到1.0'
- en: '**B**: Excellent/Good = 0.8 to 0.9'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**B**：优秀/良好 = 0.8到0.9'
- en: '**C**: Acceptable/Fair = 0.7 to 0.8'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C**：可接受/公平 = 0.7到0.8'
- en: '**D**: Poor = 0.6 to 0.7'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**D**：差 = 0.6到0.7'
- en: '**E**: No Discrimination = 0.5 to 0.6'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**E**：无区分度 = 0.5到0.6'
- en: As with most scales like this, the levels may work better for some tasks than
    others; the boundaries across categories are naturally somewhat fuzzy.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数此类量表一样，某些任务可能比其他任务更适合这些级别；类别之间的边界自然是有些模糊的。
- en: It is rare but possible for the ROC curve to fall below the diagonal, which
    causes the AUC to be less than 0.50\. This means the classifier performs worse
    than random. Usually, this is caused by a coding error, because a model that consistently
    makes the wrong prediction has obviously learned something useful about the data—it
    is merely applying the predictions in the wrong direction. To fix this issue,
    confirm that the positive cases are coded correctly, or simply reverse the predictions
    such that when the model predicts the negative class, choose the positive class
    instead.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ROC曲线低于对角线的情况虽然罕见但可能发生，这会导致AUC小于0.50。这意味着分类器的性能不如随机。通常，这是由于编码错误造成的，因为一个始终做出错误预测的模型显然已经从数据中学习到了一些有用的信息——它只是错误地应用了预测。要解决这个问题，请确认正例的编码是否正确，或者简单地反转预测，使得当模型预测负类时，选择正类代替。
- en: 'When the use of AUC started to become widespread, some treated it as a definitive
    measure of model performance, although unfortunately, this is not true in all
    cases. Generally speaking, higher AUC values reflect classifiers that are better
    at sorting a random positive example higher than a random negative example. However,
    *Figure 10.12* illustrates the important fact that two ROC curves may be shaped
    very differently, yet have an identical AUC:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 当AUC的使用开始变得普遍时，有些人将其视为模型性能的最终衡量标准，尽管不幸的是，在所有情况下这并不成立。一般来说，更高的AUC值反映了分类器在将随机正例排序高于随机负例方面表现更好。然而，*图10.12*说明了重要的事实：两条ROC曲线可能形状非常不同，但AUC却相同：
- en: '![](img/B17290_10_15.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17290_10_15.png)'
- en: 'Figure 10.12: ROC curves may have different performances despite having the
    same AUC'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12：尽管AUC相同，ROC曲线可能具有不同的性能
- en: Because the AUC is a simplification of the ROC curve, the AUC alone is insufficient
    to identify the “best” model for all use cases. The safest practice is to use
    the AUC in combination with a qualitative examination of the ROC curve, as described
    earlier in this chapter. If two models have an identical or similar AUC, it is
    usually preferable to choose the one that performs better early. Furthermore,
    even in the case that one model has a better overall AUC, a model that has a higher
    initial true positive rate may be preferred for applications that will use only
    a subset of the most confident predictions.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 由于AUC是ROC曲线的简化，仅凭AUC本身不足以识别适用于所有用例的“最佳”模型。最安全的做法是将AUC与对ROC曲线的定性检查结合起来，正如本章前面所述。如果两个模型的AUC相同或相似，通常更倾向于选择早期表现更好的模型。此外，即使一个模型的整体AUC更好，对于仅将使用最自信预测子集的应用，具有更高初始真正阳性率的模型可能更受欢迎。
- en: Creating ROC curves and computing AUC in R
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在R中创建ROC曲线和计算AUC
- en: The `pROC` package provides an easy-to-use set of functions for creating ROC
    curves and computing the AUC. The `pROC` website (at [https://web.expasy.org/pROC/](https://web.expasy.org/pROC/))
    includes a list of the full set of features, as well as several examples of visualization
    capabilities. Before continuing, be sure that you have installed the package using
    the `install.packages("pROC")` command.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`pROC`包提供了一套易于使用的函数，用于创建ROC曲线和计算AUC。`pROC`网站（[https://web.expasy.org/pROC/](https://web.expasy.org/pROC/））列出了完整的功能列表，以及几个可视化功能的示例。在继续之前，请确保您已使用`install.packages("pROC")`命令安装了该包。'
- en: 'For more information on the `pROC` package, see *pROC: an open-source package
    for R and S+ to analyze and compare ROC curves, Robin, X, Turck, N, Hainard, A,
    Tiberti, N, Lisacek, F, Sanchez, JC, and Mueller M, BMC Bioinformatics, 2011,
    pp. 12-77*.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`pROC`包的更多信息，请参阅*pROC：用于R和S+的开源包，用于分析和比较ROC曲线，Robin, X, Turck, N, Hainard,
    A, Tiberti, N, Lisacek, F, Sanchez, JC, 和 Mueller M, BMC Bioinformatics, 2011,
    第12-77页*。
- en: To create visualizations with `pROC`, two vectors of data are needed. The first
    must contain the estimated probability of the positive class and the second must
    contain the predicted class values.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`pROC`创建可视化，需要两个数据向量。第一个必须包含正类估计概率，第二个必须包含预测类别值。
- en: 'For the SMS classifier, we’ll supply the estimated spam probabilities and the
    actual class labels to the `roc()` function as follows:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SMS分类器，我们将按照以下方式将估计的垃圾邮件概率和实际类别标签提供给`roc()`函数：
- en: '[PRE60]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Using the `sms_roc` object, we can visualize the ROC curve with R’s `plot()`
    function. As shown in the following command, many of the standard parameters for
    adjusting the plot can be used, such as `main` (for adding a title), `col` (for
    changing the line color), and `lwd` (for adjusting the line width). The `grid`
    parameter adds faint gridlines to the plot to aid readability, and the `legacy.axes`
    parameter instructs `pROC` to label the *x* axis as 1 – specificity, which is
    a popular convention because it is equivalent to the false positive rate:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`sms_roc`对象，我们可以通过R的`plot()`函数来可视化ROC曲线。如下所示，许多用于调整图形的标准参数都可以使用，例如`main`（用于添加标题）、`col`（用于更改线条颜色）和`lwd`（用于调整线条宽度）。`grid`参数在图形上添加了浅色的网格线，有助于提高可读性，而`legacy.axes`参数指示`pROC`将*x*轴标记为1
    – 特异性，这是一个流行的约定，因为它等同于假阳性率：
- en: '[PRE61]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The result is an ROC curve for the Naive Bayes classifier and a diagonal reference
    line representing the baseline classifier with no predictive value:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个Naive Bayes分类器的ROC曲线和一个表示无预测价值的基线分类器的对角参考线：
- en: '![Chart, line chart  Description automatically generated](img/B17290_10_16.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![图表，折线图  自动生成的描述](img/B17290_10_16.png)'
- en: 'Figure 10.13: The ROC curve for the Naive Bayes SMS classifier'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13：Naive Bayes SMS分类器的ROC曲线
- en: Qualitatively, we can see that this ROC curve appears to occupy the space in
    the top-left corner of the diagram, which suggests that it is closer to a perfect
    classifier than the dashed line representing a useless classifier.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 定性来看，我们可以看到这条ROC曲线似乎占据了图表的右上角空间，这表明它比代表无用分类器的虚线更接近完美分类器。
- en: 'To compare this model’s performance to other models making predictions on the
    same dataset, we can add additional ROC curves to the same plot. Suppose that
    we had also trained a k-NN model on the SMS data using the `knn()` function described
    in *Chapter 3*, *Lazy Learning – Classification Using Nearest Neighbors*. Using
    this model, the predicted probabilities of spam were computed for each record
    in the test set and saved to a CSV file, which we can load here. After loading
    the file, we’ll apply the `roc()` function as before to compute the ROC curve,
    then use the `plot()` function with the parameter `add = TRUE` to add the curve
    to the previous plot:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将此模型的性能与其他在同一数据集上预测的其他模型进行比较，我们可以在同一图表上添加额外的ROC曲线。假设我们已经在SMS数据上使用第3章中描述的`knn()`函数训练了一个k-NN模型。使用此模型，我们计算了测试集中每个记录的垃圾邮件预测概率，并将其保存到CSV文件中，我们可以在这里加载它。加载文件后，我们将像之前一样应用`roc()`函数来计算ROC曲线，然后使用`plot()`函数并设置参数`add
    = TRUE`将曲线添加到之前的图表中：
- en: '[PRE62]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The resulting visualization has a second curve depicting the performance of
    the k-NN model making predictions on the same test set as the Naive Bayes model.
    The curve for k-NN is consistently lower, suggesting that it is a consistently
    worse model than the Naive Bayes approach:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可视化中还有一个第二曲线，描述了k-NN模型在相同的测试集上对Naive Bayes模型进行预测的性能。k-NN的曲线始终较低，表明它比Naive
    Bayes方法是一个持续较差的模型：
- en: '![Chart, line chart  Description automatically generated](img/B17290_10_17.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![图表，折线图  自动生成的描述](img/B17290_10_17.png)'
- en: 'Figure 10.14: ROC curves comparing the performance of Naive Bayes (topmost
    curve) and k-NN (bottom curve) on the SMS test set'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14：比较Naive Bayes（最上面的曲线）和k-NN（底部曲线）在SMS测试集上的性能的ROC曲线
- en: 'To confirm this quantitatively, we can use the `pROC` package to calculate
    the AUC. To do so, we simply apply the package’s `auc()` function to the `sms_roc`
    object for each model, as shown in the following code:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定量地确认这一点，我们可以使用`pROC`包来计算AUC。为此，我们只需将包的`auc()`函数应用于每个模型的`sms_roc`对象，如下所示：
- en: '[PRE63]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: The AUC for the Naive Bayes SMS classifier is 0.98, which is extremely high
    and substantially better than the k-NN classifier’s AUC of 0.89\. But how do we
    know whether the model is just as likely to perform well on another dataset, or
    whether the difference is greater than expected by chance alone? In order to answer
    such questions, we need to better understand how far we can extrapolate a model’s
    predictions beyond the test data. Such methods are described in the sections that
    follow.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: Naive Bayes SMS分类器的AUC为0.98，这非常高，并且比k-NN分类器的AUC 0.89要好得多。但我们是怎样知道模型在另一个数据集上表现同样好的可能性，或者这种差异是否大于仅由偶然性预期的？为了回答这些问题，我们需要更好地理解我们可以将模型的预测外推多远超出测试数据。这些方法将在接下来的章节中描述。
- en: 'This was mentioned before, but is worth repeating: the AUC value alone is often
    insufficient for identifying a “best” model. In this example, the AUC does identify
    the better model because the ROC curves do not intersect—the Naive Bayes model
    has a better true positive rate at all points on the ROC curve. When ROC curves
    *do* intersect, the “best” model will depend on how the model will be used. Additionally,
    it is possible to combine learners with intersecting ROC curves into even stronger
    models using the techniques covered in *Chapter 14*, *Building Better Learners*.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点之前已经提到过，但值得再次强调：仅凭AUC值往往不足以确定一个“最佳”模型。在这个例子中，AUC值确实能够识别出更好的模型，因为ROC曲线没有交叉——朴素贝叶斯模型在ROC曲线的所有点上都具有更好的真正阳性率。当ROC曲线*确实*交叉时，“最佳”模型将取决于模型的使用方式。此外，还可以使用第14章中介绍的*构建更好的学习器*技术，将具有交叉ROC曲线的学习者组合成更强大的模型。
- en: Estimating future performance
  id: totrans-310
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估计未来性能
- en: Some R machine learning packages present confusion matrices and performance
    measures during the model-building process. The purpose of these statistics is
    to provide insight into the model’s **resubstitution error**, which occurs when
    the target values of training examples are incorrectly predicted, despite the
    model being trained on this data. This can be used as a rough diagnostic to identify
    obviously poor performers. A model that cannot perform sufficiently well on the
    data it was trained on is unlikely to do well on future data.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 一些R机器学习包在模型构建过程中会展示混淆矩阵和性能指标。这些统计数据的目的是为了提供对模型**重新替换误差**的洞察，这种误差发生在尽管模型是在这些数据上训练的，但训练样本的目标值被错误预测的情况下。这可以用作粗略的诊断工具，以识别明显表现不佳的模型。一个在训练数据上表现不佳的模型不太可能在未来的数据上表现良好。
- en: The opposite is not true. In other words, a model that performs well on the
    training data cannot be assumed to perform well on future datasets. For example,
    a model that used rote memorization to perfectly classify every training instance
    with zero resubstitution error would be unable to generalize its predictions to
    data it has never seen before. For this reason, the error rate on the training
    data can be assumed to be optimistic about a model’s future performance.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 反过来则不成立。换句话说，一个在训练数据上表现良好的模型不能假设它在未来的数据集上也会表现良好。例如，一个使用死记硬背来完美分类每个训练实例且零重新替换误差的模型将无法将其预测推广到它以前从未见过的数据。因此，训练数据上的错误率可以假设是对模型未来性能的乐观估计。
- en: Instead of relying on resubstitution error, a better practice is to evaluate
    a model’s performance on data it has not yet seen. We used such a method in previous
    chapters when we split the available data into a set for training and a set for
    testing. In some cases, however, it is not always ideal to create training and
    test datasets. For instance, in a situation where you have only a small pool of
    data, you might not want to reduce the sample any further.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 与依赖于重新替换误差相比，更好的做法是评估模型在尚未见过的数据上的性能。我们在前面的章节中已经使用过这种方法，当时我们将可用的数据分成训练集和测试集。然而，在某些情况下，创建训练集和测试集并不总是理想的。例如，在你只有一小部分数据的情况下，你可能不想进一步减少样本量。
- en: Fortunately, as you will soon learn, there are other ways to estimate a model’s
    performance on unseen data. The `caret` package we used to calculate performance
    measures also offers functions to estimate future performance. If you are following
    along with the R code examples and haven’t already installed the `caret` package,
    please do so. You will also need to load the package to the R session using the
    `library(caret)` command.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，你很快就会了解到，还有其他方法可以估计模型在未见数据上的性能。我们用来计算性能指标的`caret`包也提供了估计未来性能的函数。如果你正在跟随R代码示例，并且尚未安装`caret`包，请先安装。你还需要使用`library(caret)`命令将包加载到R会话中。
- en: The holdout method
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保留法
- en: The procedure of partitioning data into training and test datasets that we used
    in previous chapters is known as the **holdout method**. As shown in *Figure 10.15*,
    the **training dataset** is used to generate the model, which is then applied
    to the **test dataset** to generate predictions for evaluation. Typically, about
    one-third of the data is held out for testing and two-thirds is used for training,
    but this proportion can vary depending on the amount of available data or the
    complexity of the learning task. To ensure that the training and test datasets
    do not have systematic differences, their examples are randomly divided into two
    groups.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面章节中使用的数据划分为训练集和测试集的过程被称为**保留法**。如图10.15所示，**训练集**用于生成模型，然后该模型应用于**测试集**以生成用于评估的预测。通常，大约三分之一的用于测试，三分之二用于训练，但这个比例可能会根据可用数据的数量或学习任务的复杂性而变化。为了确保训练集和测试集没有系统性差异，它们的示例被随机分为两组。
- en: '![Diagram  Description automatically generated](img/B17290_10_18.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![图示  自动生成的描述](img/B17290_10_18.png)'
- en: 'Figure 10.15: The simplest holdout method divides the data into training and
    test sets'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.15：最简单的保留法将数据分为训练集和测试集
- en: For the holdout method to result in a truly accurate estimate of future performance,
    at no time should performance on the test dataset be allowed to influence the
    modeling process. In the words of Stanford professor and renowned machine learning
    expert Trevor Hastie, “*ideally the test set should be kept in a ‘vault,’ and
    be brought out only at the end of the data analysis*.” In other words, the test
    data should remain untouched aside from its one and only purpose, which is to
    evaluate a single, final model.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使保留法得到对未来性能的真正准确估计，在任何时候都不应允许测试集上的性能影响建模过程。正如斯坦福大学教授、著名机器学习专家Trevor Hastie所说：“*理想情况下，测试集应该被保存在一个‘保险库’中，只有在数据分析结束时才取出*。”换句话说，测试数据除了其唯一目的之外，不应被触及，即评估一个单一、最终的模型。
- en: For more information, see *The Elements of Statistical Learning (2nd edition),
    Hastie, Tibshirani, and Friedman (2009), p. 222*.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息，请参阅*《统计学习元素》（第2版），Hastie，Tibshirani和Friedman（2009），第222页*。
- en: It is easy to unknowingly violate this rule and peek into the metaphorical “vault”
    when choosing one of several models or changing a single model based on the results
    of repeated testing. For example, suppose we built several models on the training
    data and selected the one with the highest accuracy on the test data. In this
    case, because we have used the test dataset to cherry-pick the best result, the
    test performance is not an unbiased measure of future performance on unseen data
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易在不经意间违反这个规则，在选择多个模型之一或根据重复测试的结果更改单个模型时窥视这个比喻性的“保险库”。例如，假设我们在训练数据上构建了几个模型，并在测试数据上选择了准确率最高的模型。在这种情况下，因为我们已经使用了测试集来挑选最佳结果，所以测试性能并不是对未来未见数据性能的无偏度量
- en: A keen reader will note that holdout test data was used in previous chapters
    to both evaluate models and improve model performance. This was done for illustrative
    purposes but would indeed violate the rule stated previously. Consequently, the
    model performance statistics shown were not truly unbiased estimates of future
    performance on unseen data.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 留心观察的读者会发现，在前几章中使用了保留测试数据来评估模型并提高模型性能。这样做是为了说明目的，但实际上违反了之前陈述的规则。因此，所显示的模型性能统计数据并不是对未来未见数据的真正无偏估计。
- en: .
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 。
- en: To avoid this problem, it is better to divide the original data so that in addition
    to the training and test datasets, a **validation dataset** is available. The
    validation dataset can be used for iterating and refining the model or models
    chosen, leaving the test dataset to be used only once as a final step to report
    an estimated error rate for future predictions. A typical split between training,
    test, and validation would be 50 percent, 25 percent, and 25 percent, respectively.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这个问题，最好将原始数据划分为除了训练集和测试集之外，还有一个**验证集**。验证集可以用于迭代和细化选定的模型或模型，而将测试集仅用于最终步骤，以报告对未来预测的估计错误率。典型的划分比例是训练集50%，测试集25%，验证集25%。
- en: '![Diagram  Description automatically generated](img/B17290_10_19.png)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![图示  自动生成的描述](img/B17290_10_19.png)'
- en: 'Figure 10.16: A validation dataset can be held out from training to select
    from multiple candidate models'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.16：验证集可以从训练集中保留出来，以选择多个候选模型
- en: A simple method for creating holdout samples uses random number generators to
    assign records to partitions. This technique was first used in *Chapter 5*, *Divide
    and Conquer – Classification Using Decision Trees and Rules*, to create training
    and test datasets.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 使用随机数生成器将记录分配到分区是一种创建保留样本的简单方法。这种技术首次在**第5章**，**分而治之 – 使用决策树和规则进行分类**中使用，用于创建训练和测试数据集。
- en: If you’d like to follow along with the following examples, download the `credit.csv`
    dataset from Packt Publishing’s website and load it into a data frame using the
    `credit <- read.csv("credit.csv", stringsAsFactors = TRUE)` command.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要跟随以下示例，请从Packt Publishing的网站上下载`credit.csv`数据集，并使用`credit <- read.csv("credit.csv",
    stringsAsFactors = TRUE)`命令将其加载到数据框中。
- en: Suppose we have a data frame named `credit` with 1,000 rows of data. We can
    divide this into three partitions as follows. First, we create a vector of randomly
    ordered row IDs from 1 to 1,000 using the `runif()` function, which, by default,
    generates a specified number of random values between 0 and 1\. The `runif()`
    function gets its name from the random uniform distribution, which was discussed
    in *Chapter 2*, *Managing and Understanding Data*.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个名为`credit`的数据框，包含1,000行数据。我们可以将其划分为三个分区，如下所示。首先，我们使用`runif()`函数创建一个从1到1,000的随机排序行ID向量，该函数默认在0和1之间生成指定数量的随机值。`runif()`函数的名字来源于随机均匀分布，这在**第2章**，**管理和理解数据**中讨论过。
- en: 'The `order()` function then returns a vector indicating the rank order of the
    1,000 random numbers. For instance, `order(c(0.5, 0.25, 0.75, 0.1))` returns the
    sequence `4 2 1 3` because the smallest number (0.1) appears fourth, the second
    smallest (0.25) appears second, and so on:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`order()`函数返回一个指示1,000个随机数排名顺序的向量。例如，`order(c(0.5, 0.25, 0.75, 0.1))`返回序列`4
    2 1 3`，因为最小的数字（0.1）出现在第四位，第二小的（0.25）出现在第二位，以此类推：
- en: '[PRE67]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Next, the random IDs are used to divide the credit data frame into 500, 250,
    and 250 records comprising the training, validation, and test datasets:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用随机ID将信用数据框划分为包含训练、验证和测试数据集的500、250和250条记录：
- en: '[PRE68]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: One problem with holdout sampling is that each partition may have a larger or
    smaller proportion of some classes. In cases where one (or more) class is a very
    small proportion of the dataset, this can lead to it being omitted from the training
    dataset—a significant problem because the model cannot then learn this class.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 保留样本的一个问题是，每个分区可能包含某些类别的较大或较小的比例。在某个（或多个）类别在数据集中占非常小比例的情况下，这可能导致该类别被排除在训练数据集之外——这是一个重大问题，因为模型无法学习这个类别。
- en: To reduce the chance of this occurring, a technique called **stratified random
    sampling** can be used. Although a random sample should generally contain roughly
    the same proportion of each class value as the full dataset, stratified random
    sampling guarantees that the random partitions have nearly the same proportion
    of each class as the full dataset, even when some classes are small.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少这种情况发生的可能性，可以使用一种称为**分层随机抽样**的技术。尽管随机样本通常应该包含与完整数据集大致相同的每个类别值的比例，但分层随机抽样保证随机分区几乎与完整数据集具有相同的每个类别的比例，即使某些类别很小。
- en: 'The `caret` package provides a `createDataPartition()` function, which creates
    partitions based on stratified holdout sampling. The steps for creating a stratified
    sample of training and test data for the `credit` dataset are shown in the following
    commands. To use the function, a vector of class values must be specified (here,
    `default` refers to whether a loan went into default), in addition to a parameter,
    `p`, which specifies the proportion of instances to be included in the partition.
    The `list = FALSE` parameter prevents the result from being stored as a list object—a
    capability that is needed for more complex sampling techniques, but is unnecessary
    here:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '`caret`包提供了一个`createDataPartition()`函数，它根据分层保留样本创建分区。以下命令显示了为`credit`数据集创建训练和测试数据集分层样本的步骤。要使用此函数，必须指定一个类别值向量（在这里，`default`表示一笔贷款是否违约），以及一个参数`p`，它指定要包含在分区中的实例比例。`list
    = FALSE`参数防止结果被存储为列表对象——这是更复杂采样技术所需的，但在这里是不必要的：'
- en: '[PRE69]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: The `in_train` vector indicates the row numbers included in the training sample.
    We can use these row numbers to select examples for the `credit_train` data frame.
    Similarly, by using a negative symbol, we can use the rows not found in the `in_train`
    vector for the `credit_test` dataset.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '`in_train`向量指示包含在训练样本中的行号。我们可以使用这些行号来选择`credit_train`数据框中的示例。同样，通过使用负号，我们可以使用`in_train`向量中未找到的行号来为`credit_test`数据集。'
- en: Although it distributes the classes evenly, stratified sampling does not guarantee
    other types of representativeness. Some samples may have too many or too few difficult
    cases, easy-to-predict cases, or outliers. This is especially true for smaller
    datasets, which may not have a large enough portion of such cases to divide among
    training and test sets.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然分层抽样将类别均匀分布，但它并不能保证其他类型的代表性。一些样本可能包含过多或过少的困难案例、易于预测的案例或异常值。这对于较小的数据集尤其如此，因为可能没有足够多的此类案例来分配到训练集和测试集中。
- en: In addition to potentially biased samples, another problem with the holdout
    method is that substantial portions of data must be reserved for testing and validating
    the model. Since this data cannot be used to train the model until its performance
    has been measured, the performance estimates are likely to be overly conservative.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 除了可能存在偏差的样本外，保留法还存在另一个问题，即必须保留大量数据用于测试和验证模型。由于在测量其性能之前，这些数据不能用于训练模型，因此性能估计可能过于保守。
- en: Since models trained on larger datasets generally perform better, a common practice
    is to retrain the model on the full set of data (that is, training plus test and
    validation) after a final model has been selected and evaluated.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在较大数据集上训练的模型通常表现更好，一个常见的做法是在选择并评估最终模型后，在全部数据集（即训练、测试和验证）上重新训练模型。
- en: A technique called **repeated holdout** is sometimes used to mitigate the problems
    of randomly composed training datasets. The repeated holdout method is a special
    case of the holdout method that uses the average result from several random holdout
    samples to evaluate a model’s performance. As multiple holdout samples are used,
    it is less likely that the model is trained or tested on non-representative data.
    We’ll expand on this idea in the next section.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 一种称为**重复保留法**的技术有时被用来减轻随机组成训练数据集的问题。重复保留法是保留法的一个特例，它使用几个随机保留样本的平均结果来评估模型性能。由于使用了多个保留样本，因此模型训练或测试在非代表性数据上的可能性较小。我们将在下一节中进一步阐述这一想法。
- en: Cross-validation
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证
- en: The repeated holdout is the basis of a technique known as **k-fold cross-validation**
    (**k-fold CV**), which has become the industry standard for estimating model performance.
    Rather than taking repeated random samples that could potentially use the same
    record more than once, k-fold CV randomly divides the data into *k* separate random
    partitions called **folds**.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 重复保留法是称为**k折交叉验证**（**k-fold CV**）的技术基础，它已成为估计模型性能的行业标准。k折交叉验证不是采取重复的随机样本，这些样本可能会多次使用相同的记录，而是将数据随机分为*k*个独立的随机分区，称为**折**。
- en: Although *k* can be set to any number, by far the most common convention is
    to use a 10-fold CV. Why 10 folds? The reason is that empirical evidence suggests
    that there is little added benefit to using a greater number. For each of the
    10 folds (each comprising 10 percent of the total data), a machine learning model
    is built on the remaining 90 percent of the data. The fold’s 10 percent sample
    is then used for model evaluation. After the process of training and evaluating
    the model has occurred 10 times (with 10 different training/testing combinations),
    the average performance across all folds is reported.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然*k*可以设置为任何数字，但到目前为止最常用的惯例是使用10折交叉验证。为什么是10折？原因是经验证据表明，使用更多折数的好处很小。对于每个10折（每个包含总数据的10%），在剩余的90%数据上构建一个机器学习模型。然后使用该折的10%样本进行模型评估。经过10次训练和评估模型的过程（使用10种不同的训练/测试组合）后，报告所有折的平均性能。
- en: An extreme case of k-fold CV is the **leave-one-out method**, which performs
    k-fold CV using a fold for each one of the data’s examples. This ensures that
    the greatest amount of data is used for training the model. Although this may
    seem useful, it is so computationally expensive that it is rarely used in practice.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: k折交叉验证的一个极端情况是**留一法**，它使用数据的一个示例作为每个折进行k折交叉验证。这确保了用于训练模型的数据量最大。尽管这可能看起来很有用，但由于计算成本极高，因此在实践中很少使用。
- en: 'Datasets for CV can be created using the `createFolds()` function in the `caret`
    package. Like stratified random holdout sampling, this function will attempt to
    maintain the same class balance in each of the folds as in the original dataset.
    The following is the command to create 10 folds, using `set.seed(123)` to ensure
    the results are reproducible:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`caret`包中的`createFolds()`函数创建CV数据集。类似于分层随机留出采样，此函数将尝试在每个折叠中保持与原始数据集相同的类别平衡。以下命令用于创建10个折叠，使用`set.seed(123)`确保结果可重复：
- en: '[PRE70]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The result of the `createFolds()` function is a list of vectors storing the
    row numbers for each of the `k = 10` requested folds. We can peek at the contents
    using `str()`:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '`createFolds()`函数的结果是一个包含每个请求的`k = 10`个折叠的行号的向量列表。我们可以使用`str()`来查看其内容：'
- en: '[PRE71]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Here, we see that the first fold is named `Fold01` and stores 100 integers,
    indicating the 100 rows in the `credit` data frame for the first fold. To create
    training and test datasets to build and evaluate a model, an additional step is
    needed. The following commands show how to create data for the first fold. We’ll
    assign the selected 10 percent to the test dataset and use the negative symbol
    to assign the remaining 90 percent to the training dataset:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到第一个折叠被命名为`Fold01`，并存储了100个整数，表示第一个折叠中`credit`数据框的100行。为了创建用于构建和评估模型的训练和测试数据集，需要额外的步骤。以下命令显示了如何为第一个折叠创建数据。我们将选定的10%分配给测试数据集，并使用负号将剩余的90%分配给训练数据集：
- en: '[PRE73]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: To perform the full 10-fold CV, this step would need to be repeated a total
    of 10 times, first building a model and then calculating the model’s performance
    each time. In the end, the performance measures would be averaged to obtain the
    overall performance. Thankfully, we can automate this task by applying several
    of the techniques we learned earlier.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行完整的10折交叉验证，这个步骤需要重复10次，每次都构建一个模型并计算模型性能。最后，将性能度量平均以获得整体性能。幸运的是，我们可以通过应用我们之前学到的几种技术来自动化这项任务。
- en: 'To demonstrate the process, we’ll estimate the kappa statistic for a C5.0 decision
    tree model of the credit data using 10-fold CV. First, we need to load some R
    packages: `caret` (to create the folds), `C50` (to build the decision tree), and
    `irr` (to calculate kappa). The latter two packages were chosen for illustrative
    purposes; if you desire, you can use a different model or a different performance
    measure with the same series of steps:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示这个过程，我们将使用10折交叉验证来估计信用数据C5.0决策树模型的kappa统计量。首先，我们需要加载一些R包：`caret`（用于创建折叠）、`C50`（用于构建决策树）和`irr`（用于计算kappa）。后两个包是为了演示目的选择的；如果你愿意，你可以使用不同的模型或不同的性能度量，但步骤序列保持不变：
- en: '[PRE74]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Next, we’ll create a list of 10 folds as we have done previously. As before,
    the `set.seed()` function is used here to ensure that the results are consistent
    if the same code is run again:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个包含10个折叠的列表，就像之前做的那样。同样，这里使用`set.seed()`函数是为了确保如果再次运行相同的代码，结果是一致的：
- en: '[PRE75]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Finally, we will apply a series of identical steps to the list of folds using
    the `lapply()` function. As shown in the following code, because there is no existing
    function that does exactly what we need, we must define our own function to pass
    to `lapply()`. Our custom function divides the `credit` data frame into training
    and test data, builds a decision tree using the `C5.0()` function on the training
    data, generates a set of predictions from the test data, and compares the predicted
    and actual values using the `kappa2()` function:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用`lapply()`函数对折叠列表应用一系列相同的步骤。如以下代码所示，因为没有现成的函数能完全满足我们的需求，我们必须定义自己的函数并将其传递给`lapply()`。我们的自定义函数将`credit`数据框分为训练数据和测试数据，使用训练数据上的`C5.0()`函数构建决策树，从测试数据生成一组预测，并使用`kappa2()`函数比较预测值和实际值：
- en: '[PRE76]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The resulting kappa statistics are compiled into a list stored in the `cv_results`
    object, which we can examine using `str()`:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 最终得到的kappa统计量被编译成一个列表，存储在`cv_results`对象中，我们可以使用`str()`来检查它：
- en: '[PRE77]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'There’s just one more step remaining in the 10-fold-CV process: we must calculate
    the average of these 10 values. Although you will be tempted to type `mean(cv_results)`,
    because `cv_results` is not a numeric vector, the result would be an error. Instead,
    use the `unlist()` function, which eliminates the list structure and reduces `cv_results`
    to a numeric vector. From there, we can calculate the mean kappa as expected:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 10折交叉验证过程只剩下一步：我们必须计算这10个值的平均值。虽然你可能会想输入`mean(cv_results)`，因为`cv_results`不是一个数值向量，所以结果会出错。相反，使用`unlist()`函数，它可以消除列表结构并将`cv_results`简化为一个数值向量。从那里，我们可以计算出预期的平均kappa值：
- en: '[PRE79]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: This kappa statistic is relatively low, corresponding to “fair” on the interpretation
    scale, which suggests that the credit scoring model performs only marginally better
    than random chance. In *Chapter 14*, *Building Better Learners*, we’ll examine
    automated methods based on a 10-fold CV, which can assist us with improving the
    performance of this model.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 这个kappa统计量相对较低，对应于解释尺度上的“公平”，这表明信用评分模型仅略优于随机机会。在*第14章*，“构建更好的学习者”中，我们将检查基于10折交叉验证的自动化方法，这些方法可以帮助我们提高该模型的表现。
- en: 'Because CV provides a performance estimate from multiple test sets, we can
    also compute the variability in the estimate. For example, the standard deviation
    of the 10 iterations can be computed as:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CV从多个测试集中提供性能估计，我们还可以计算估计的变异性。例如，10次迭代的方差可以计算如下：
- en: '[PRE81]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: After finding the average and standard deviation of the performance metric,
    it is possible to calculate a confidence interval or determine whether two models
    have a **statistically significant** difference in performance, which means that
    it is likely that the difference is real and not due to random variation.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在找到性能指标的平均值和标准差后，可以计算置信区间或确定两个模型在性能上是否有**统计显著**的差异，这意味着差异很可能是真实的，而不是由于随机变化。
- en: Unfortunately, recent research has demonstrated that CV violates assumptions
    of such statistical tests, particularly the need for the data to be drawn from
    independent random samples, which is clearly not the case for CV folds, which
    are linked to one another by definition.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，最近的研究表明CV违反了此类统计测试的假设，尤其是数据需要来自独立随机样本的需要，而CV的折叠由于定义上的原因相互关联，这显然是不成立的。
- en: 'For a discussion of the limitations of performance estimates taken from 10-fold
    CV, see *Cross-validation: what does it estimate and how well does it do it?,
    Bates S, Hastie T, and Tibshirani R, 2022, https://arxiv.org/abs/2104.00673*.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 关于从10折交叉验证中获得的性能估计局限性的讨论，请参阅*Bates S, Hastie T, and Tibshirani R, 2022, https://arxiv.org/abs/2104.00673*中的“交叉验证：它估计了什么以及它做得如何？”。
- en: More sophisticated variants of CV have been developed to improve the robustness
    of model performance estimates. One such technique is **repeated k-fold CV**,
    which involves repeatedly applying k-fold CV and averaging the results. A common
    strategy is to perform 10-fold CV 10 times. Although computationally intensive,
    this provides an even more robust performance estimate than a standard 10-fold
    CV, as the performance is averaged over many more trials. However, it too violates
    statistical assumptions, and thus statistical tests performed on the results may
    be slightly biased.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: CV的更复杂变体已被开发出来，以提高模型性能估计的鲁棒性。其中一种技术是**重复k折交叉验证**，它涉及反复应用k折交叉验证并平均结果。一种常见的策略是进行10折交叉验证10次。尽管计算量较大，但这种方法提供的性能估计比标准的10折交叉验证更加鲁棒，因为性能是在许多更多次试验中平均得出的。然而，它也违反了统计假设，因此对结果进行的统计测试可能略有偏差。
- en: Perhaps the current gold standard for estimating model performance is **nested
    cross-validation**, which literally performs k-fold CV within another k-fold CV
    process. This technique is described in *Chapter 11*, *Being Successful with Machine
    Learning*, and is not only extremely computationally expensive but is also more
    challenging to implement and interpret. The upside of nested k-fold CV is that
    it produces truly valid comparisons of model performance compared to standard
    k-fold CV, which is biased due to its violation of statistical assumptions. On
    the other hand, the bias caused by this issue seems to be less important for very
    large datasets, so it may still be reasonable—and remains a common practice—to
    use the confidence intervals or significance tests derived from the simpler CV
    approach to help identify the “best” model.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 目前估计模型性能的黄金标准可能是**嵌套交叉验证**，它实际上是在另一个 k 折交叉验证过程中执行 k 折交叉验证。这项技术在本章 11 的《用机器学习取得成功》中有所描述，它不仅计算成本极高，而且实施和解释起来也更具挑战性。嵌套
    k 折交叉验证的优点是，它产生了与标准 k 折交叉验证相比真正有效的模型性能比较，因为标准 k 折交叉验证由于违反了统计假设而存在偏差。另一方面，这个问题引起的偏差对于非常大的数据集似乎不太重要，因此使用从更简单的
    CV 方法中得出的置信区间或显著性测试来帮助识别“最佳”模型仍然是合理且常见的做法。
- en: Bootstrap sampling
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自举采样
- en: A slightly less popular, but very important, alternative to k-fold CV is known
    as **bootstrap sampling**, the **bootstrap**, or **bootstrapping** for short.
    Generally speaking, these refer to statistical methods that use random samples
    of data to estimate the properties of a larger set. When this principle is applied
    to machine learning model performance, it implies the creation of several randomly
    selected training and test datasets, which are then used to estimate performance
    statistics. The results from the various random datasets are then averaged to
    obtain a final estimate of future performance.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 相比于 k 折交叉验证（k-fold CV）来说，一个稍微不那么流行但非常重要的替代方法是称为**自举采样**、**自举**或简称为**bootstrapping**。一般来说，这些指的是使用数据的随机样本来估计更大集属性的统计方法。当这个原理应用于机器学习模型性能时，它意味着创建几个随机选择的训练和测试数据集，然后使用这些数据集来估计性能统计量。然后，从各种随机数据集中得出的结果被平均，以获得对未来性能的最终估计。
- en: So, what makes this procedure different from k-fold CV? Whereas CV divides the
    data into separate partitions in which each example can appear only once, the
    bootstrap allows examples to be selected multiple times through a process of **sampling
    with replacement**. This means that from the original dataset of *n* examples,
    the bootstrap procedure will create one or more new training datasets that also
    contain *n* examples, some of which are repeated.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，是什么使得这个程序与 k 折交叉验证（k-fold CV）不同呢？CV 将数据分成单独的分区，其中每个示例只能出现一次，而自举允许通过**有放回抽样**的过程多次选择示例。这意味着从原始的
    *n* 个示例数据集中，自举过程将创建一个或多个新的训练数据集，这些数据集也包含 *n* 个示例，其中一些是重复的。
- en: The corresponding test datasets are then constructed from the set of examples
    that were not selected for the respective training datasets.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 然后从未被选为相应训练数据集的示例集中构建相应的测试数据集。
- en: 'In a bootstrapped dataset, the probability that any given instance is excluded
    from the training dataset is 36.8 percent. We can prove this mathematically by
    recognizing that each example has a 1/*n* chance of being sampled each time one
    of *n* rows is added to the training dataset. Therefore, to be in the test set,
    an example must *not* be selected *n* times. As the chance of being chosen is
    1/*n*, the chance of *not* being chosen is therefore 1 - 1/*n*, and the probability
    of going unselected *n* times is as follows:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 在自举数据集中，任何给定实例被排除在训练数据集之外的几率是 36.8%。我们可以通过认识到每个示例在每次向训练数据集添加 *n* 行时都有 1/*n*
    的机会被采样来数学上证明这一点。因此，要进入测试集，一个示例必须**没有**被选择 *n* 次。由于被选择的机会是 1/*n*，因此未被选择的机会是 1 -
    1/*n*，未被选择 *n* 次的概率如下：
- en: '![](img/B17290_10_010.png)'
  id: totrans-381
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_10_010.png)'
- en: 'Using this formula, if the dataset to be bootstrapped contains 1,000 rows,
    the probability of a random record being unselected is:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个公式，如果自举的数据集包含 1,000 行，随机记录未被选中的概率是：
- en: '[PRE83]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Similarly, for a dataset with 100,000 rows:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，对于一个有 100,000 行的数据集：
- en: '[PRE85]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'And as *n* approaches infinity, the formula reduces to 1/*e*, as shown here:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *n* 趋近于无穷大时，公式简化为 1/*e*，如下所示：
- en: '[PRE87]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Given that the probability of being unselected is 36.8 percent, the probability
    of any instance being selected for the training dataset is 100 - 36.8 = 63.2 percent.
    In other words, the training data represents only 63.2 percent of available examples,
    some of which are repeated. In contrast with 10-fold CV, which uses 90 percent
    of examples for training, the bootstrap sample is less representative of the full
    dataset.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 由于未被选中的概率为36.8%，任何实例被选入训练数据集的概率为100% - 36.8% = 63.2%。换句话说，训练数据仅代表可用示例的63.2%，其中一些是重复的。与使用90%示例进行训练的10折交叉验证相比，自举样本对整个数据集的代表性较低。
- en: Because a model trained on only 63.2 percent of the training data is likely
    to perform worse than a model trained on a larger training set, the bootstrap’s
    performance estimates may be substantially lower than what will be obtained when
    the model is later trained on the full dataset.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 由于仅用63.2%的训练数据进行训练的模型可能比在更大的训练集上训练的模型表现更差，因此自举的性能估计可能比模型稍后训练在完整数据集上获得的估计要低得多。
- en: 'A special case of bootstrapping, known as the **0.632 bootstrap**, accounts
    for this by calculating the final performance measure as a function of performance
    on both the training data (which is overly optimistic) and the test data (which
    is overly pessimistic). The final error rate is then estimated as:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 一种称为**0.632自举**的特殊自举情况，通过将最终性能指标视为训练数据（过于乐观）和测试数据（过于悲观）性能的函数来解决这个问题。然后，最终错误率估计如下：
- en: '![](img/B17290_10_011.png)'
  id: totrans-394
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_10_011.png)'
- en: One advantage of bootstrap sampling over CV is that it tends to work better
    with very small datasets. Additionally, bootstrap sampling has applications beyond
    performance measurement. In particular, in *Chapter 14*, *Building Better Learners*,
    you will learn how the principles of bootstrap sampling can be used to improve
    model performance.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 与交叉验证相比，自举采样的一项优势是它通常在非常小的数据集上表现更好。此外，自举采样在性能测量之外还有应用。特别是，在*第14章* *构建更好的学习者*中，你将了解如何使用自举采样的原则来提高模型性能。
- en: Summary
  id: totrans-396
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter presented several of the most common measures and techniques for
    evaluating the performance of machine learning classification models. Although
    accuracy provides a simple method for examining how often a model is correct,
    this can be misleading in the case of rare events because the real-life importance
    of such events may be inversely proportional to how frequently they appear in
    the data.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了评估机器学习分类模型性能的几种最常见指标和技术。尽管准确率提供了一种简单的方法来检查模型正确性的频率，但在罕见事件的情况下，这可能会产生误导，因为这类事件在现实生活中的重要性可能与它们在数据中出现的频率成反比。
- en: Some measures based on confusion matrices better capture a model’s performance
    as well as the balance between the costs of various types of errors. The kappa
    statistic and Matthews correlation coefficient are two more sophisticated measures
    of performance, which work well even for severely unbalanced datasets. Additionally,
    closely examining the tradeoffs between sensitivity and specificity, or precision
    and recall, can be a useful tool for thinking about the implications of errors
    in the real world. Visualizations such as the ROC curve are also helpful to this
    end.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 一些基于混淆矩阵的指标更好地捕捉了模型性能以及各种类型错误成本的平衡。Kappa统计量和Matthews相关系数是两种更复杂的性能指标，即使在严重不平衡的数据集上也能很好地工作。此外，仔细检查敏感性和特异性，或精确率和召回率之间的权衡，可以成为思考现实世界中错误影响的有用工具。ROC曲线等可视化也有助于此目的。
- en: It is also worth mentioning that, sometimes, the best measure of a model’s performance
    is to consider how well it meets, or doesn’t meet, other objectives. For instance,
    you may need to explain a model’s logic in simple language, which would eliminate
    some models from consideration. Additionally, even if it performs very well, a
    model that is too slow or difficult to scale to a production environment is completely
    useless.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，有时衡量模型性能的最佳方法就是考虑它如何满足，或未能满足，其他目标。例如，你可能需要用简单语言解释模型的逻辑，这将排除一些模型。此外，即使模型表现非常好，但如果模型运行速度过慢或难以扩展到生产环境，那么它将完全无用。
- en: Looking ahead to the chapters that follow, an obvious extension of *measuring*
    performance is finding ways to *improve* performance. As you continue in this
    book, you will apply many of the principles in this chapter while strengthening
    your machine learning abilities and adding more advanced skills. CV techniques,
    ROC curves, bootstrapping, and the `caret` package will reappear regularly in
    the coming pages, as we build upon our work so far to investigate ways to make
    smarter models by systematically iterating, refining, and combining learning algorithms.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 展望接下来的章节，对性能进行**测量**的明显扩展是找到**提高**性能的方法。随着你继续阅读本书，你将应用本章中的许多原则，同时加强你的机器学习能力并增加更多高级技能。在接下来的页面中，CV
    技术、ROC 曲线、自助法和 `caret` 包将定期出现，因为我们将在已有的工作基础上，通过系统地迭代、精炼和组合学习算法来研究如何制作更智能的模型。
- en: Join our book’s Discord space
  id: totrans-401
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的 Discord 空间
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 4000 people at:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区，与志同道合的人相聚，并和超过 4000 人在以下地点一起学习：
- en: '[https://packt.link/r](https://packt.link/r)'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/r](https://packt.link/r)'
- en: '![](img/r.jpg)'
  id: totrans-404
  prefs: []
  type: TYPE_IMG
  zh: '![](img/r.jpg)'
