- en: '17'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Natural Language Models – Detecting Fake News Articles!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A significant amount of content on the internet is in textual format. Almost
    every organization stores lots of internal data and resources as text documents.
    **Natural language processing** (**NLP**) is a subfield of machine learning that’s
    concerned with organizing, understanding, and making decisions based on textual
    input data. Over the past decade, NLP has become the utmost important aspect of
    transforming business processes and making informed decisions. For example, a
    sentiment analysis model can help a business understand the high-level sentiments
    of their customers toward their products and services. A topic modeling algorithm
    combined with sentiment analysis can figure out the key pain points of the customers
    and thus it can inform the business decisions to make customer satisfaction a
    priority.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will develop an ML system that can recognize fake news
    articles. Such systems can help in keeping the information and news on the internet
    more accurate and safer. We will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting fake news using NLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Launching model training on Vertex AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BERT-based fake news classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code samples used in this chapter can be found in this book’s GitHub repository:
    [https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/tree/main/Chapter17](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/tree/main/Chapter17).'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting fake news using NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nowadays, due to the increase in the use of the internet, it has become really
    easy to spread fake news. A large number of users are consuming and posting content
    on the internet via their social media accounts daily. It has become difficult
    to distinguish the real news from the fake news. Fake news, however, can do significant
    damage to a person, society, organization, or political party. Looking at the
    scale, it is impossible to skim through every article manually or using a human
    reviewer. Thus, there is a need to develop smart algorithms that can automatically
    detect fake news articles and stop the spread of dangerous news as soon as it
    is generated.
  prefs: []
  type: TYPE_NORMAL
- en: ML-based classification algorithms can be used to detect fake news. First, we
    need a good training dataset to train the classification model on so that it can
    learn the common patterns of fake news and thus automatically distinguish it from
    real news. In this section, we will train an ML model to classify articles as
    “fake” versus “real.”
  prefs: []
  type: TYPE_NORMAL
- en: Fake news classification with random forest
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will use a tree-based classification algorithm known as
    random forest to detect fake news articles. In the last section of this chapter,
    we will also train a complex deep learning-based classifier and compare the accuracy
    of both models. Let’s dive into the experiment. All the code related to these
    experiments can be found in this book’s GitHub repository, as mentioned in the
    Technical requirements section.
  prefs: []
  type: TYPE_NORMAL
- en: About the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have downloaded the dataset from Kaggle, which has an open-to-use license.
    The dataset contains about 72k news articles with titles, texts, and labels. Almost
    50% of the articles are “fake,” while the remainder are “real.” We will utilize
    this dataset to train an NLP-based classification model that can detect fake news.
    We will keep some parts of this dataset as unseen data so that we can test the
    model results after training. The link for downloading the data can be found in
    the Jupyter Notebook in this book’s GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We have already downloaded and decompressed the data in the same directory as
    the Jupyter Notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s jump into the implementation part. We will start by importing useful
    Python libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Importing useful libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step is to load some useful Python libraries in a notebook cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will load and verify the input dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Reading and verifying the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we will read the data from a CSV file into a pandas DataFrame called
    `news_df`. We will print the shape of the DataFrame and a few top entries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this cell is shown in *Figure 17**.1*. As we can see, there are
    72,134 news articles in this table, each with a title, body, and label:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.1 – Fake news article detection dataset overview](img/B17792_17_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.1 – Fake news article detection dataset overview
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s see if there are any missing values present in this data table.
  prefs: []
  type: TYPE_NORMAL
- en: NULL value check
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We need to check if there are any NULL values present in the dataset. There
    are different ways of handling NULL values. If the percentage of NULL values is
    very low, we can choose to drop those rows from the table; otherwise, we can fill
    those entries with some value. In our case, we will fill the NULL fields using
    an empty string value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output of this cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, there’s a very small number of entries with NULL values. Let’s
    fill them with empty strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We can now move on to data cleaning and pre-processing.
  prefs: []
  type: TYPE_NORMAL
- en: Combining title and text into a single column
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s create a new column called `content` with combined `title` and `text`
    elements so that it contains all the textual information available related to
    the news article. Once we’ve done this, we will be able to use this column for
    model training and classification purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now that our textual content is in a single column, we can start cleaning and
    preparing it for the model.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning and pre-processing data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ML algorithms are very sensitive to noisy data. So, it is of utmost importance
    to clean and process the data before passing it into the model for training; this
    will allow the model to learn useful information from it. As we are using a classical
    ML algorithm here, we will need to do some aggressive cleaning and pre-processing.
    In the case of deep learning, data processing is not required (as shown in the
    last section of this chapter). When we solve NLP problems using classical ML algorithms,
    we often use feature extraction methods such as TF and TF-IDF. As we know, these
    feature extraction methods are sensitive to the count of words, so it becomes
    important to remove less meaningful words (such as stopwords) and characters from
    the text.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this experiment, we will follow these steps to clean and pre-process the
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: Remove special characters and numbers from the text.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the text into lowercase (so that “HELLO” and “hello” are the same for
    the classification algorithm).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Split the content by space to get a list of words.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove stopwords. These are common English words and are often meaningless in
    a sentence. Examples include they, the, and, he, and him.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply stemming. This involves reducing the words to their root forms (for example,
    “happiness” should be reduced to “happy” so that different variations of the same
    word are equal for the model).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'When we install the `nltk` library, it doesn’t automatically download all the
    required resources related to it. In our case, we will have to explicitly download
    the English language stopwords. We can do that by running the following command
    in a terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is our data cleaning and pre-processing function. As this function runs
    on the entire dataset, it takes some time to complete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s separate our content and labels into arrays for modeling purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Separating the data and labels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we are separating the data and labels and putting them into two separate
    lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s convert the text into numeric values.
  prefs: []
  type: TYPE_NORMAL
- en: Converting text into numeric data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As ML algorithms only understand numbers, we will need to convert the textual
    data into numeric format. In our experiment, we will be creating TF-IDF features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We can now split the data into training and test partitions so that we can test
    the results of our model after training.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In a real NLP project, We must split the dataset into training and test sets
    before applying numerical transformations. The transformation function (such as
    `TfidfVectorizer`) should only be fit to the training data and then applied to
    test data. This is because, in a real-world setting, we might get some unknown
    words in the dataset and our model is not supposed to see those words during training.
    Another issue with this setting is that it causes data leakage as the statistics
    that are calculated over the entire dataset also belong to the test partition.
    In this example, we have done this transformation before splitting the dataset
    just for simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we must split the data into training and test partitions. We will use
    about 80% of the data for training and the remaining 20% for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Our training and test data partitions are now ready to be fed to the model.
    Next, we’ll define the model.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the random forest classifier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For our simple experiment, we are using default hyperparameter values for the
    random forest model. However, in a real-world use case, we can experiment with
    different sets of hyperparameter values to get the best results. Alternatively,
    we can utilize hyperparameter tuning to find the best hyperparameters for our
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Let’s go ahead and train the model on the training partition.
  prefs: []
  type: TYPE_NORMAL
- en: Training the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s fit our model to the training dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Our model training is now complete, which means we can start predicting the
    test data to check the model’s results.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the test data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we’re using our trained random forest classifier to make predictions
    on the test partition. The `predict` function gives the class-level output, while
    the `predict_proba` function gives the probabilistic outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have made predictions on the entire set. Let’s check how well our model
    did.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the results/metrics on the test dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next important step is to check and verify the performance of our model
    on the test dataset. Here, we will use sklearn’s classification report method
    to get the precision, recall, and F1 score for each class. Check out the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output of the classification report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, our model has about 93% precision and recall for both classes.
    The overall accuracy is also about 93%. So, we can say that our model is good
    enough to identify about 93% of the fake news articles.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s plot the ROC curve. The ROC curve is a graph between the **false
    positive rate** (**FPR**) and **true positive rate** (**TPR**) of a classification
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Check out *Figure 17**.2* to see the ROC curve for our experiment. In a typical
    ROC curve, the X-axis represents the FPR and the Y-axis represents the TPR of
    the model. The **area under the ROC curve**, also known as **ROC-AUC**, indicates
    the quality of a classification model. Having a higher area value signifies a
    better model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.2 – The ROC curve for the fake news classification model](img/B17792_17_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.2 – The ROC curve for the fake news classification model
  prefs: []
  type: TYPE_NORMAL
- en: Let’s also check out the confusion matrix to see where our model is making mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: Confusion matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, let’s also print the confusion matrix for our classification. A confusion
    matrix shows the number of correct and incorrect classifications of each class.
    It also shows which other classes were predicted as mistakes if the classification
    is wrong (false positives and false negatives):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Our experiment is now complete. If the results are satisfactory, we can go ahead
    and deploy this model as an API. If the results are still not acceptable, we can
    do more experiments with different settings.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to do a lot of experiments in parallel, we can launch many parallel
    experiments via Vertex AI training jobs without needing to monitor them constantly
    and check back later when training is complete. In the next section, we will see
    how Vertex AI training jobs can be configured.
  prefs: []
  type: TYPE_NORMAL
- en: Launching model training on Vertex AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will launch our training experiment as a Vertex AI training
    job. There are multiple advantages of launching training jobs on Vertex AI instead
    of doing it in a Juypter Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: The flexibility to launch any number of parallel experiments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can choose the best hardware for model training, which is very important
    when accelerators are needed to train deep learning models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We don’t need active monitoring regarding training progress
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There’s no fear of the Jupyter Notebook crashing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vertex AI training jobs can be configured to log metadata and experiments in
    the Google Cloud Console UI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we will create and launch a Vertex AI training job for our
    experiment. There are two main things we need to do to launch a Vertex AI training
    job. First, we need to put the dataset in a location that will be accessible to
    the Vertex AI job (such as GCS or BigQuery). Second, we need to put the model
    training code together into a single `task.py` file so that it can be packaged
    into a training container with all the necessary dependencies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are the steps we need to follow to create and launch our Vertex AI training
    job:'
  prefs: []
  type: TYPE_NORMAL
- en: Upload the dataset to GCS or BigQuery (we will use GCS).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a `task.py` file that does the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reads data from GCS
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the necessary data preparation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Trains the RF model
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Saves the trained model into GCS
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Does prediction on the test set
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: (Optionally) Saves predictions to GCS
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Prints some results/metrics
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a prebuilt training image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch Vertex AI training.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Monitor the progress on the Google Cloud Console UI.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Considering these steps, we have already created a `task.py` file for our experiment;
    it can be found in this book’s GitHub repository. Next, we will learn how to launch
    the job using this `task.py` file.
  prefs: []
  type: TYPE_NORMAL
- en: Setting configurations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we will define the configurations related to the project and data locations
    that will be necessary while launching the training job on Vertex AI. The following
    snippet shows some configurations related to our experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Let’s initialize the Vertex AI SDK with appropriate variables.
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the Vertex AI SDK
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we’re initializing the Vertex AI SDK to set the project, location, and
    staging bucket for our jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Now that our configurations have been set, we can start defining the Vertex
    AI training job.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Vertex AI training job
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following code block defines a Vertex AI training job for our experiment.
    Here, we pass `display_name`, which will help us locate our job within the console
    UI. Note that we are passing our `task.py` file as the script path variable. `container_uri`
    is the prebuilt container that will be used to launch the job. Finally, we can
    specify any additional Python packages that are required to run our training code.
    In our case, we need to install the `nltk` package for some NLP-related functionalities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Our Vertex AI-based custom training job is now ready. Let’s run it.
  prefs: []
  type: TYPE_NORMAL
- en: Running the Vertex AI job
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are all set to launch our training job. We are using an `n1-standard-16`
    type of machine for our experiment that can be modified as per our needs. Check
    out the following snippet, which launches our training job on Vertex AI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'After launching the job, we should see a URL in the output pointing to the
    job within the Cloud Console UI. The output should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: With that, we have successfully launched our experiment as a training job on
    Vertex. We can now monitor the progress of our job using the Cloud Console UI.
    Next, we’ll solve this problem using a deep learning approach so that we hopefully
    get better results.
  prefs: []
  type: TYPE_NORMAL
- en: BERT-based fake news classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our first experiment, we trained a classical random forest classifier on
    TF-IDF features to detect fake versus real news articles and got an accuracy score
    of about 93%. In this section, we will train a deep learning model for the same
    task and see if we get any accuracy gains over the classical tree-based approach.
    Deep learning has changed the way we used to solve NLP problems. Classical approaches
    required hand-crafted features, most of which were related to the frequency of
    words appearing in a document. Looking at the complexity of languages, just knowing
    the count of words in a paragraph is not enough. The order in which words occur
    also has a significant impact on the overall meaning of the paragraph or sentence.
    Deep learning approaches such as **Long-Short-Term-Memory** (**LSTM**) also consider
    the sequential dependency of words in sentences or paragraphs to get a more meaningful
    feature representation. LSTM has achieved great success in many NLP tasks but
    there have been some limitations. As these models are trained sequentially, it
    becomes really difficult to scale these models. Secondly, when we work with very
    long sequences, LSTMs suffer from context loss and thus they are not ideal for
    understanding the context of longer sequences. Due to some limitations, including
    the ones discussed here, new ways of learning context from sequential inputs were
    invented.
  prefs: []
  type: TYPE_NORMAL
- en: The advent of transformer-based models was groundbreaking for the field of NLP,
    as well as Vision AI. Transformer-based models heavily rely on attention mechanisms
    to capture the context and inter-sequence patterns, and they are also able to
    handle very long sequences of inputs. **Bidirectional Encoder Representations
    from Transformers** (**BERT**) is a family of NLP models that are based on some
    parts of the transformer architecture. BERT-based models have achieved great success
    in tons of NLP tasks, some of which seemed close to impossible in past decades.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of working with deep learning models is that we don’t have
    to train them from scratch every time. We always utilize pre-trained models and
    then fine-tune them on our domain-specific data to get great results faster and
    without requiring a lot of domain-specific training data. This approach is termed
    **transfer learning** and is where large deep learning models are pre-trained
    with huge amounts of data, after which they can be utilized for many downstream
    domain-specific tasks as they can be fine-tuned with a small amount of domain-specific
    training data.
  prefs: []
  type: TYPE_NORMAL
- en: BERT for fake news classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this experiment, we will utilize a pre-trained BERT model and fine-tune it
    slightly on our news article training dataset. Let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: Importing useful libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this experiment, we will utilize PyTorch as a framework for fine-tuning
    the BERT model. We also utilize the `transformers` library from Hugging Face to
    load the pre-trained weights of the BERT-based model with some other tooling that
    is useful for setting up fine-tuning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s start preparing the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will work with the same dataset that we used in the first experiment. So,
    we will follow the same steps here as well – we will load the data, treat NULL
    values, and create a content column with all the necessary text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will convert the text in the content column to lowercase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will separate text from labels and store them as lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: 72134 72134
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s prepare our dataset as per the requirements of BERT model inputs.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we are working with the BERT model now, we don’t need to perform lots of
    data cleanups, such as removing numbers, removing stopwords, stemming, and so
    on. Each BERT model has a tokenizer that is utilized to convert textual data into
    numeric IDs. So, we will need to find the appropriate BERT tokenizer (which can
    be loaded by the `transformers` library from Hugging Face), do tokenization, and
    also create attention masks for training purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create the tokenizer object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we’re defining a function that will create tokenized text and attention
    masks for training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we must generate encodings and attention masks for each input text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s convert the lists into PyTorch tensors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we’re calling the necessary method, to prepare our data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s split our data into training and test partitions.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we will create a tensor dataset out of our input IDs, attention masks,
    and labels and split it into training and test sets. Similar to the first experiment,
    we will be using about 80% of the data for training (or fine-tuning) purposes
    and the remaining 20% to test the results and metrics. The following snippet shows
    how to create and split the tensor dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s define data loader objects with the required batch size.
  prefs: []
  type: TYPE_NORMAL
- en: Creating data loader objects for batching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next step is to create data loader objects for both the training and test
    partitions. We will have a batch size of 32 for the training data and a batch
    size of 1 for the test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Our data is now ready for the model. This means we can load the model and start
    training.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the pre-trained BERT model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we will load the pre-trained weights of the BERT-based model so that
    we can fine-tune it further on our custom dataset. The pre-trained weights of
    many BERT variants are available on Hugging Face and can be loaded through the
    `transformers` library, as shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `device` variable, we can choose to load our model on an accelerator,
    such as a GPU. This snippet downloads the pre-trained weights of the `bert-base-uncased`
    model with a classification layer of two labels. Executing this snippet also prints
    the BERT architecture summary, which will look something similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Now that our model has been loaded, let’s define the optimization settings.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizer
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we’re defining the `AdamW` optimizer and setting a custom learning rate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Let’s also define a scheduler for our model training.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we’re setting up training steps and a training scheduler. We’re planning
    to fine-tune our model for just `3` epochs on our training partition, after which
    we will check the results on our test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Now, we are all set to start training the model.
  prefs: []
  type: TYPE_NORMAL
- en: Training BERT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we will fine-tune the BERT model on our training data for `3` epochs,
    as defined in the previous sub-section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This training snippet prints the model loss after each epoch of training is
    completed. The loss output from our experiment is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that our model training (or fine-tuning) is complete, we can save the model
    weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: With that, we have successfully trained and saved the model. Now, let’s move
    on to model evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: Loading model weights for evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we’re loading our trained model weights for evaluation purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Let’s check the accuracy of the trained model on the test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the accuracy of the test dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that our model has been trained and loaded for evaluation, we can make predictions
    on the test dataset and check its accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will store the predictions in lists and also count the number of correct
    predictions in the following variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we’re running model predictions on the test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We can calculate the accuracy by dividing the correct predictions by the total
    predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this cell shows that our model has about 99% accuracy on the
    test dataset. This is a huge improvement over the classic random forest model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let’s print the confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can generate a classification report for our model.
  prefs: []
  type: TYPE_NORMAL
- en: Classification report
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we will print the classification report of our experiment to understand
    the precision, recall, and F1 score of each class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The preceding output shows that our BERT-based classification model is extremely
    accurate with an accuracy of about 99%. Similarly, for each class, we have precision
    and recall scores of about 99%. This experiment showed that using a pre-trained
    deep learning model can enhance the accuracy of classification by a great margin.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter was about a real-world NLP use case for detecting fake news. In
    the current era of the internet, spreading fake news has become quite easy and
    it can be dangerous for the reputation of a person, society, organization, or
    political party. As we have seen in our experiments, ML classification can be
    used as a powerful tool for detecting fake news articles. Deep learning-based
    approaches can further improve the results of text classification use cases without
    requiring much fine-tuning data.
  prefs: []
  type: TYPE_NORMAL
- en: After reading this chapter, you should be confident about training and applying
    classification models on text classification use cases, similar to fake news detection.
    You should also have a good understanding of the cleaning and pre-processing steps
    that are needed to apply classical models, such as random forest, on text data.
    At this point, you should be able to launch large-scale ML experiments as Vertex
    AI training jobs. Finally, you should have a good understanding of how deep learning-based
    BERT models can be applied and fine-tuned for text classification use cases.
  prefs: []
  type: TYPE_NORMAL
