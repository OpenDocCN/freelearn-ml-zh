<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Using TensorFlow with ML.NET</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will be using a pre-trained TensorFlow model, specifically the Inception model, and we’ll integrate the model into a <strong>Windows Presentation Foundation</strong> (<strong>WPF</strong>) application. We will be taking the pre-trained model and applying transfer learning, by adding some pictures of food and bodies of water. After the transfer learning has been performed, we then allow the user to select their own images. By the end of the chapter, you should have a firm grasp of what it takes to integrate a TensorFlow model into your ML.NET application.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Breaking down Google's Inception model</li>
<li>Creating the image classification<span> </span>desktop application</li>
<li>Exploring additional production application enhancements</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Breaking down Google's Inception model</h1>
                </header>
            
            <article>
                
<p>Google's Inception model (<a href="https://github.com/google/inception">https://github.com/google/inception</a>) has been trained on millions of images to help with one of the growing questions in our society—what is in my image? The type of applications wanting to answer this question range from matching faces, automatically detecting weapons or unwanted objects, sports branding in game pictures (such as the brand of sneakers), and image archivers that provide users with the support they need to search without manual tags, to name just a few.</p>
<p>This type of question is typically answered with <strong>object recognition</strong>. An application of object recognition that you might already be familiar with is <strong>optical</strong> <strong>character</strong> <strong>recognition</strong> (<strong>OCR</strong>). OCR is when an image of characters can be interpreted as text, such as what is found in Microsoft's OneNote Handwriting to Text feature, or in a toll booth that reads license plates. The particular application of object recognition that we will be looking into specifically is called <strong>image classification</strong>.</p>
<p class="mce-root"/>
<p>The Inception model helps with this problem by using deep learning to classify images. The model was trained in a supervised approach on millions of images, with the output being a neural network. The advantage of this approach is that the pre-built model can be enhanced with a smaller subset of images, which is what we will be doing in the next section of this chapter. This approach of adding additional data and labels is called <strong>transfer</strong> <strong>learning</strong>. This approach can also be helpful when creating customer-specific models.</p>
<p>Think of it like creating a branch from your master branch in GitHub; you might want to just add one class or modify one element without having to re-create the entire code base. In regards to models, take for instance, an image classifier for automobiles. Let us assume that you obtain millions of images covering US and foreign cars, trucks, vans, and more. A new customer comes to you requesting you to create a model to help monitor vehicles entering a government facility. The previous model should not be thrown away and won't need to be fully retrained, simply adding more commercial (or maybe military) vehicles with labels would be needed. </p>
<div class="packt_tip packt_infobox">For a larger and more in-depth deep dive into Google's image classification, a good resource is their developer documentation, which can be found from <a href="https://developers.google.com/machine-learning/practica/image-classification/">https://developers.google.com/machine-learning/practica/image-classification/</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the WPF image classification application</h1>
                </header>
            
            <article>
                
<p>As mentioned earlier, the application that we will be creating is an image classification application, specifically allowing the user to select an image and determine whether it is either food or water. This is achieved through the aforementioned and included, pre-trained TensorFlow Inception model. The first time that the application is run, the ML.NET version of the model is trained with the images and the <kbd>tags.tsv</kbd> file (to be reviewed in the next section).</p>
<p>As with previous chapters, the completed project code, sample dataset, and project files can be downloaded here: <a href="https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter12">https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter12</a><a href="https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter10">.</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring the project architecture</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will dive into a WPF desktop application. As mentioned in the first section of this chapter, we will be using the WPF framework to create our application. You might be asking, why not a UWP application such as the browser application that we created in <a href="9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml">Chapter 10</a>, <em>Using ML.NET with UWP</em>? The reasoning, at least at the time of writing, is that TensorFlow support, specifically for image classification, is not fully supported in a UWP application. Perhaps, in future versions of ML.NET, this will be added. For other non-image-based applications, you may be able to use TensorFlow in a UWP application.</p>
<p>Those who have done WPF development previously, and are looking closely, will notice that the project utilizes .NET Core 3.1. In .NET Core 3.0, Microsoft added support for WPF and WinForms, therefore, you are no longer tied to the Windows-only .NET Framework for GUI development. Instead, this support is added through the <kbd>Microsoft.WindowsDesktop.App.WPF</kbd> NuGet package.</p>
<p>For this example, we will be using the <kbd>Microsoft.ML</kbd> (1.3.1) NuGet package—in addition to several additional NuGet packages—to be able to utilize TensorFlow within our .NET application. These include the following:</p>
<ul>
<li><kbd>Microsoft.ML.ImageAnalytics</kbd> (1.3.1)</li>
<li><kbd>Microsoft.ML.TensorFlow</kbd> (1.3.1)</li>
<li><kbd>SciSharp.TensorFlow.Redist</kbd> (1.14.0)</li>
</ul>
<p>By the time you are reading this, there may very well be newer versions of the packages and they should work, however, the versions that were noted above are the ones that we are going to use in this deep dive, and what is available in the GitHub repository.</p>
<p>In the following screenshot, you will find the Visual Studio Solution Explorer view of the solution. Due to the TensorFlow support being much more particular about project types and CPU targets, we have gone back to a single project, as opposed to the three-project architecture that was used in the previous several chapters:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-599 image-border" src="assets/26d6470c-1bff-4a86-b49e-2c37a72775a9.png" style="width:20.50em;height:39.00em;"/></p>
<p class="mce-root">The<span> </span><kbd>tags.tsv</kbd><span> </span>file (found in the<span> </span><kbd>assets\images</kbd><span> </span>folder in the code repository) contains eight rows, which map the included images to the preclassification:</p>
<pre>ChickenWings.jpg food<br/>Steak.jpg food<br/>Pizza.jpg food<br/>MongolianGrill.jpg food<br/>Bay.jpg water<br/>Bay2.jpg water<br/>Bay3.jpg water<br/>Beach.jpg water</pre>
<p>If you want to experiment with your own classification, delete the included images, copy your images, and update the <kbd>tags.tsv</kbd> file with the label. I should note, all of the images that are included were taken by me on various vacations to California—feel free to use them as you wish.</p>
<p>The files in the <kbd>assets/inception</kbd> folder contain all of the Google pre-trained files (and license file).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Diving into the WPF image classification application</h1>
                </header>
            
            <article>
                
<p>As discussed in the opening section, our desktop application is a WPF application. For the scope of this example, as found in <a href="9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml">Chapter 10</a>, <em>Using ML.NET with UWP</em>, we are using standard approaches for handling the application architecture by following the <strong>Model-View-ViewModel</strong> (<strong>MVVM</strong>) design pattern.</p>
<p>The files that we will be diving into in this section are as follows:</p>
<ul>
<li><kbd>MainWindowViewModel</kbd></li>
<li><kbd>MainWindow.xaml</kbd></li>
<li><kbd>MainWindow.xaml.cs</kbd></li>
<li><kbd>BaseML</kbd></li>
<li><kbd>ImageDataInputItem</kbd></li>
<li><kbd>ImageDataPredictionItem</kbd></li>
<li><kbd>ImageClassificationPredictor</kbd></li>
</ul>
<p>The rest of the files inside the WPF project were untouched from the default Visual Studio .NET Core 3.1 WPF application template; for example, the <kbd>App.xaml</kbd> and <kbd>AssemblyInfo.cs</kbd> files.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The MainWindowViewModel class</h1>
                </header>
            
            <article>
                
<p>The purpose of the <kbd>MainWindowViewModel</kbd> class is to contain our business logic and control the view, as shown here:</p>
<ol>
<li>The first thing we do is instantiate our previously discussed<span> </span><kbd>ImageClassificationPredictor</kbd><span> </span>class, so that it can be used to run predictions:</li>
</ol>
<pre style="padding-left: 60px">private readonly ImageClassificationPredictor _prediction = new ImageClassificationPredictor();</pre>
<ol start="2">
<li> The next block of code handles the power of MVVM for the classification string, and also stores the selected image. For each of these properties, we call <kbd>OnPropertyChanged</kbd> upon a change in values, which triggers the binding of the View to refresh for any field that is bound to these properties:</li>
</ol>
<pre style="padding-left: 60px">private string _imageClassification;<br/><br/>public string ImageClassification<br/>{<br/>    get =&gt; _imageClassification;<br/><br/>    set<br/>    {<br/>        _imageClassification = value;<br/>        OnPropertyChanged();<br/>    }<br/>}<br/><br/>private ImageSource _imageSource;<br/><br/>public ImageSource SelectedImageSource<br/>{<br/>    get =&gt; _imageSource;<br/><br/>    set<br/>    {<br/>        _imageSource = value;<br/>        OnPropertyChanged();<br/>    }<br/>}</pre>
<ol start="3">
<li>Next, we define the <kbd>Initialize</kbd> method, which calls the predictor's <kbd>Initialize</kbd> method. The method will return a tuple, which indicates whether the model can't be loaded or whether it is not found, along with the exception (if thrown):</li>
</ol>
<pre style="padding-left: 60px">public (bool Success, string Exception) Initialize() =&gt; _prediction.Initialize();</pre>
<ol start="4">
<li>Then, we handle what happens when the user clicks the <span class="packt_screen">Select Image</span> button. This method opens a dialog box prompting the user to select an image. If the user cancels the dialog, the method returns. Otherwise, we call the two helper methods to load the image into memory and classify the image:</li>
</ol>
<pre style="padding-left: 60px">public void SelectFile()<br/>{<br/>    var ofd = new OpenFileDialog<br/>    {<br/>        Filter = "Image Files(*.BMP;*.JPG;*.PNG)|*.BMP;*.JPG;*.PNG"<br/>    };<br/><br/>    var result = ofd.ShowDialog();<br/><br/>    if (!result.HasValue || !result.Value)<br/>    {<br/>        return;<br/>    }<br/><br/>    LoadImageBytes(ofd.FileName);<br/><br/>    Classify(ofd.FileName);<br/>}</pre>
<ol start="5">
<li>The <kbd>LoadImageBytes</kbd> method takes the filename and loads the image into our MVVM-based <kbd>ImageSource</kbd> property so, after selection, the image control is automatically updated to a view of the selected image:</li>
</ol>
<pre style="padding-left: 60px">private void LoadImageBytes(string fileName)<br/>{<br/>    var image = new BitmapImage();<br/><br/>    var imageData = File.ReadAllBytes(fileName);<br/><br/>    using (var mem = new MemoryStream(imageData))<br/>    {<br/>        mem.Position = 0;<br/><br/>        image.BeginInit();<br/>        <br/>        image.CreateOptions = BitmapCreateOptions.PreservePixelFormat;<br/>        image.CacheOption = BitmapCacheOption.OnLoad;<br/>        image.UriSource = null;<br/>        image.StreamSource = mem;<br/>        <br/>        image.EndInit();<br/>    }<br/><br/>    image.Freeze();<br/><br/>    SelectedImageSource = image;<br/>}</pre>
<ol start="6">
<li>And lastly, the <kbd>Classify</kbd> method takes the path and passes it into the <kbd>Predictor</kbd> class. Upon returning the prediction, the classification and confidence are built into our MVVM <kbd>ImageClassification</kbd> property, therefore, the UI is updated automatically:</li>
</ol>
<pre style="padding-left: 60px">public void Classify(string imagePath)<br/>{<br/> var result = _prediction.Predict(imagePath);<br/><br/> ImageClassification = $"Image ({imagePath}) is a picture of {result.PredictedLabelValue} with a confidence of {result.Score.Max().ToString("P2")}";<br/>}</pre>
<p>The last element of the <kbd>MainWindowViewModel</kbd> class is the same <kbd>OnPropertyChanged</kbd> method that we defined in <a href="9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml">Chapter 10</a>, <em>Using ML.NET with UWP</em>, which allows the MVVM magic to happen. With our <kbd>ViewModel</kbd> class defined, let us move on to the <kbd>MainWindow</kbd> XAML file.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The MainWindow.xaml class</h1>
                </header>
            
            <article>
                
<p>As discussed in the <em>Breaking down UWP architecture </em><span>section of </span><a href="9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml">Chapter 10</a>,<em> Using ML.NET with UWP</em>, when describing the development, XAML markup is used to define your user interface. For the scope of this application, our UI is relatively simple:  <kbd>Button</kbd>, <kbd>Image Control</kbd>, and <kbd>TextBlock</kbd>.</p>
<p>We will look at the code now:</p>
<ol>
<li>The first thing that we define is our grid. In XAML, a grid is a container similar to a <span><kbd>&lt;div&gt;</kbd> </span>in web development. We then define our rows. Similar to Bootstrap (but easier to understand in my opinion), is the pre-definition of the height of each row. Setting a row to <kbd>Auto</kbd> will auto-size the height to the content's height, while an asterisk translates to using all remaining height based on the main container's height:</li>
</ol>
<pre style="padding-left: 60px">&lt;Grid.RowDefinitions&gt;<br/>    &lt;RowDefinition Height="Auto" /&gt;<br/>    &lt;RowDefinition Height="*" /&gt;<br/>    &lt;RowDefinition Height="Auto" /&gt;<br/>&lt;/Grid.RowDefinitions&gt;</pre>
<ol start="2">
<li>We first define our <kbd>Button</kbd> object, which will trigger the aforementioned <kbd>SelectFile</kbd> method in our <kbd>ViewModel</kbd> class:</li>
</ol>
<pre style="padding-left: 60px">&lt;Button Grid.Row="0" Margin="0,10,0,0" Width="200" Height="35" Content="Select Image File" HorizontalAlignment="Center" Click="btnSelectFile_Click" /&gt;</pre>
<ol start="3">
<li>We then define our <kbd>Image</kbd> control, which is bound to our previously reviewed <kbd>SelectedImageSource</kbd> property that is found in our <kbd>ViewModel</kbd> class:</li>
</ol>
<pre style="padding-left: 60px">&lt;Image Grid.Row="1" Margin="10,10,10,10" Source="{Binding SelectedImageSource}" /&gt;</pre>
<ol start="4">
<li><span>We then add the <kbd>TextBlock</kbd> control that will display our classification</span>:</li>
</ol>
<pre style="padding-left: 60px">&lt;TextBlock Grid.Row="2" Text="{Binding ImageClassification, Mode=OneWay}" TextWrapping="Wrap" Foreground="White" Margin="10,10,10,10" HorizontalAlignment="Center" FontSize="16" /&gt;</pre>
<p>With the XAML aspect of our View defined, let us now dive into the code behind of the <kbd>MainWindow</kbd> class.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The MainWindow.xaml.cs file</h1>
                </header>
            
            <article>
                
<p>The <kbd>MainWindow.xaml.cs</kbd> file contains the code behind the XAML view, which is discussed here:</p>
<ol>
<li>The first thing that we define is a wrapper property around the <kbd>DataContext</kbd> property, which is built into the base <kbd>Window</kbd> class:</li>
</ol>
<pre style="padding-left: 60px">private MainWindowViewModel ViewModel =&gt; (MainWindowViewModel) DataContext;</pre>
<ol start="2">
<li class="mce-root">Next, we define the constructor for <kbd>MainWindow</kbd>, in order to initialize the <kbd>DataContext</kbd> property to our <kbd>MainWindowViewModel</kbd> object. If the initialization fails, we do not want the application to continue. In addition, we need to let the user know why it failed, using a <kbd>MessageBox</kbd> object:</li>
</ol>
<pre style="padding-left: 60px">public MainWindow()<br/>{<br/>    InitializeComponent();<br/><br/>    DataContext = new MainWindowViewModel();<br/><br/>    var (success, exception) = ViewModel.Initialize();<br/><br/>    if (success)<br/>    {<br/>        return;<br/>    }<br/><br/>    MessageBox.Show($"Failed to initialize model - {exception}");<br/><br/>    Application.Current.Shutdown();<br/>}</pre>
<ol start="3">
<li>Lastly, we call the ViewModel's <kbd>SelectFile</kbd> method to handle the image selection and classification:</li>
</ol>
<pre style="padding-left: 60px">private void btnSelectFile_Click(object sender, RoutedEventArgs e) =&gt; ViewModel.SelectFile();</pre>
<p>With the code behind of the <kbd>MainWindow</kbd> class behind us, that concludes the WPF component. Let us now focus on the machine learning part of the example.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The BaseML class</h1>
                </header>
            
            <article>
                
<p>The <kbd>BaseML</kbd> class, as used in most of the previous examples, exposes a base class for our ML.NET classes. In the case of this example, we actually streamlined the class due to the nature of using a pre-trained model. The class now simply initializes the <kbd>MLContext</kbd> property:</p>
<pre>public class BaseML<br/>{<br/>    protected MLContext MlContext;<br/><br/>    public BaseML()<br/>    {<br/>        MlContext = new MLContext(2020);<br/>    }<br/>}</pre>
<p>With the streamlined <kbd>BaseML</kbd> class reviewed, let us dive into the <kbd>ImageDataInputItem</kbd> class.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The ImageDataInputItem class</h1>
                </header>
            
            <article>
                
<p>The <kbd>ImageDataInputItem</kbd> class contains our class to pass into the model; the essential property is the <kbd>ImagePath</kbd> property:</p>
<pre>public class ImageDataInputItem<br/>{<br/>    [LoadColumn(0)]<br/>    public string ImagePath;<br/><br/>    [LoadColumn(1)]<br/>    public string Label;<br/>}</pre>
<p>While smaller than most of our input classes, the Inception model only requires the two properties. Now, let us dive into the output class that is called <kbd>ImageDataPredictionItem</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The ImageDataPredictionItem class</h1>
                </header>
            
            <article>
                
<p>The <kbd>ImageDataPredictionItem</kbd> class contains the prediction response, including the confidence of the predicted value string (to contain <kbd>Water</kbd> or <kbd>Food</kbd> in the case of the included images):</p>
<pre>public class ImageDataPredictionItem : ImageDataInputItem<br/>{<br/>    public float[] Score;<br/><br/>    public string PredictedLabelValue;<br/>}</pre>
<p>Much like the input class, the output class has only two properties, similar to previous examples. With the input and output classes behind us, let us dive into the <kbd>ImageClassificationPredictor</kbd> class, which uses these classes for transfer learning and predictions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The ImageClassificationPredictor class</h1>
                </header>
            
            <article>
                
<p>The <kbd>ImageClassificationPredictor</kbd> class contains all of the code that is needed to load and predict against the Inception TensorFlow model:</p>
<ol>
<li>First, we need to define several helper variables to access the images and <kbd>.tsv</kbd> files:</li>
</ol>
<pre style="padding-left: 60px">// Training Variables<br/>private static readonly string _assetsPath = Path.Combine(Environment.CurrentDirectory, "assets");<br/>private static readonly string _imagesFolder = Path.Combine(_assetsPath, "images");<br/>private readonly string _trainTagsTsv = Path.Combine(_imagesFolder, "tags.tsv");<br/>private readonly string _inceptionTensorFlowModel = Path.Combine(_assetsPath, "inception", "tensorflow_inception_graph.pb");<br/><br/>private const string TF_SOFTMAX = "softmax2_pre_activation";<br/>private const string INPUT = "input";<br/><br/>private static readonly string ML_NET_MODEL = Path.Combine(Environment.CurrentDirectory, "chapter12.mdl");</pre>
<ol start="2">
<li class="mce-root">Next, we define the settings that the pre-trained Inception model needs:</li>
</ol>
<pre style="padding-left: 60px">private struct InceptionSettings<br/>{<br/>    public const int ImageHeight = 224;<br/>    public const int ImageWidth = 224;<br/>    public const float Mean = 117;<br/>    public const float Scale = 1;<br/>    public const bool ChannelsLast = true;<br/>}</pre>
<ol start="3">
<li>Next, we create our <kbd>Predict</kbd> method and overload that simply takes the image file path. Like in previous examples, we create <kbd>PredictionEngine</kbd> with a call to our <kbd>MLContext</kbd> object, passing in our input class (<kbd>ImageDataInputItem</kbd>) and our output class (<kbd>ImageDataPredictionItem</kbd>), and then calling the <kbd>Predict</kbd> method to get our model prediction:</li>
</ol>
<pre style="padding-left: 60px">public ImageDataPredictionItem Predict(string filePath) =&gt; <br/>    Predict(new ImageDataInputItem <br/>        {<br/>            ImagePath = filePath <br/>        }<br/>    );<br/><br/>public ImageDataPredictionItem Predict(ImageDataInputItem image)<br/>{<br/>    var predictor = MlContext.Model.CreatePredictionEngine&lt;ImageDataInputItem, ImageDataPredictionItem&gt;(_model);<br/><br/>    return predictor.Predict(image);<br/>}</pre>
<p style="padding-left: 60px">4. Finally, we initialize and extend our pre-trained model with our own samples:</p>
<pre style="padding-left: 60px">public (bool Success, string Exception) Initialize()<br/>{<br/>    try<br/>    {<br/>        if (File.Exists(ML_NET_MODEL))<br/>        {<br/>            _model = MlContext.Model.Load(ML_NET_MODEL, out DataViewSchema modelSchema);<br/><br/>            return (true, string.Empty);<br/>        }<br/><br/>       ...<br/>    }<br/>    catch (Exception ex)<br/>    {<br/>        return (false, ex.ToString());<br/>    }<br/>} </pre>
<p>For the full code, please refer to the following GitHub repository link: <a href="https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/blob/master/chapter12/chapter12.wpf/ML/ImageClassificationPredictor.cs">https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/blob/master/chapter12/chapter12.wpf/ML/ImageClassificationPredictor.cs</a>. With the <kbd>Initialize</kbd> method completed, that concludes the code deep dive. Let us now run the application!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the image classification application</h1>
                </header>
            
            <article>
                
<p>Since we are using a pre-trained model, we can just run the application from Visual Studio. Upon running the application, you will be presented with a mostly empty window:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-600 image-border" src="assets/6f1449c0-2b5e-4219-a885-954599f1646e.png" style="width:40.50em;height:11.25em;"/></p>
<p>Clicking on the <span class="packt_screen">Select Image File</span> button and then selecting an image file will trigger the model to run. In my case, I selected a picture from a recent vacation to Germany, which came back with a 98.84% confidence score:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-601 image-border" src="assets/4a2c3d00-de73-40ec-8779-590ab092c4c1.png" style="width:39.08em;height:22.08em;"/></p>
<p>Feel free to try various files on your machine to see the confidence score and classification—if you start noticing issues, add more samples to the images folder and <kbd>tags.tsv</kbd> file, as noted in the earlier section. Be sure to delete the <kbd>chapter12.mdl</kbd> file prior to making these changes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Additional ideas for improvements</h1>
                </header>
            
            <article>
                
<p>Now that we have completed our deep dive, there are a couple of additional elements that could possibly further enhance the application. A few ideas are discussed here.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Self-training based on the end user's input</h1>
                </header>
            
            <article>
                
<p>One of the advantages, as noted in the opening section of this chapter, is the ability to utilize transfer learning in dynamic applications. Unlike previous example applications that have been reviewed in this book, this application could actually allow the end user to select a series (or folder) of images, and with a few code changes, build the new <kbd>.tsv</kbd> file and train a new model. For a web application or commercial product, this would provide a high value and would also reduce the burden on you to, for instance, obtain images of every type—a daunting, and more than likely futile, goal. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logging</h1>
                </header>
            
            <article>
                
<p>As mentioned in the <span><em>Logging</em> section of</span> <a href="9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml">Chapter 10</a>, <em>Using ML.NET with UWP</em>, having a desktop application has its pros and cons. The biggest con necessitating the need for logging is that your desktop application could be installed on any number of configurations of Windows 7 to Windows 10, with an almost unlimited number of permutations. As mentioned previously, logging by utilizing<span> </span>NLog<span> </span>(<a href="https://nlog-project.org/">https://nlog-project.org/</a>) or a similar open source project is highly recommended, coupled with a remote logging solution such as Loggly, so that you can get error data from your user's machines. Given the GDPR and recent CCPA, we need to ensure that the data that is leaving the end user's machines is conveyed and that these logs do not include personal data (or actual images uploaded to a remote server via the logging mechanism).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Utilizing a database</h1>
                </header>
            
            <article>
                
<p>Similar to the performance optimization suggestion in <a href="9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml">Chapter 10</a>, <em>Using ML.NET with UWP</em>, if a user selects the same image more than once, especially if this application was being used in a kiosk or converted to a web application, the performance advantages of storing the classification could be fairly significant. A quick and easy method for achieving this could be to perform a SHA256 of the image, and check that hash against a database. Depending on the number of users and if they are going to be concurrent, I would suggest one of two options:</p>
<ul>
<li>If the users are going one at a time and the application is going to remain a WPF application, using the previously mentioned lightweight database—LiteDB (<a href="http://www.litedb.org/">http://www.litedb.org/</a>)—would be recommended.</li>
<li>If you are launching a large web application using a production, then MongoDB or a horizontally scalable database, such as Microsoft's CosmosDB would be recommended in order to ensure that the database lookups wouldn't be slower than simply re-performing the model prediction.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Over the course of this chapter, we have deep-dived into what goes into creating a WPF application using a pre-trained TensorFlow model. We also reviewed and looked closely into Google's image classification Inception model. In addition, we learned how to take that model and integrate it in order to perform image classification on user-selected images. Lastly, we also discussed some ways to further enhance the example application.</p>
<p>In the next and last chapter, we will focus on using a pre-trained ONNX model in a WPF application for object detection.</p>


            </article>

            
        </section>
    </body></html>