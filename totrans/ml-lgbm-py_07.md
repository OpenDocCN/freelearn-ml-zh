# 7

# 使用 LightGBM 和 FLAML 进行 AutoML

在上一章中，我们讨论了两个案例研究，展示了如何处理数据科学问题的端到端示例。在典型的数据科学生命周期中，通常最耗时的工作是准备数据、寻找正确的模型以及调整模型。

本章探讨了自动机器学习的概念。自动机器学习系统旨在自动化机器学习生命周期的某些或全部部分。我们将探讨 **FLAML**，这是一个库，使用高效的超参数优化算法来自动化模型选择和调优步骤。

最后，我们将通过一个案例研究来展示如何使用 FLAML 和另一个名为 Featuretools 的开源工具。我们将讨论和展示 FLAML 的实际应用，并展示 FLAML 的零样本 AutoML 功能，该功能完全绕过了调优过程。

本章的主要内容包括：

+   自动机器学习简介

+   FLAML 用于 AutoML

+   案例研究 – 使用 FLAML 和 LightGBM

# 技术要求

本章包含了一些示例和代码片段，展示了如何使用 FLAML 和 LightGBM 进行 AutoML 应用。关于设置本章所需环境的完整示例和说明可在[https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-7](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-7)找到。

# 自动机器学习

**自动机器学习**（**AutoML**）是一个新兴领域，旨在自动化机器学习工作流程的复杂方面，从而更高效、更易于部署机器学习模型。AutoML 的出现反映了人工智能和机器学习技术的日益复杂化，以及它们在各个行业和研究领域的渗透。它旨在减轻数据科学过程中的某些复杂、耗时的工作，使机器学习技术的应用更加广泛和易于获取。

对于熟悉机器学习和数据科学流程的软件工程师来说，机器学习模型的日益复杂性和算法宇宙的不断扩大可能构成重大挑战。构建一个稳健、高性能的模型需要大量的专业知识、时间和计算资源来选择合适的算法、调整超参数以及进行深入的比较。AutoML 作为解决这些挑战的解决方案应运而生，旨在自动化这些复杂且劳动密集型的工作。

AutoML 还有助于民主化机器学习领域。通过抽象化数据工程和模型构建及调优的一些复杂性，AutoML 使得那些在机器学习方面经验较少的个人和组织能够利用这些强大的技术。因此，机器学习可以在更广泛的背景下发挥作用，更多个人和组织能够部署机器学习解决方案。

AutoML系统在复杂度方面各不相同。尽管所有AutoML系统都旨在简化机器学习（ML）工作流程，但大多数系统和工具仅关注工作流程的一部分。通常，数据预处理、特征工程、模型选择和超参数调整等步骤被自动化。这种自动化可以节省时间，并通过系统地探索更全面的选项集来提高机器学习模型的鲁棒性和性能，这些选项可能由于人为偏见或时间限制而被忽视或未探索。

## 自动化特征工程

如在第[*第6章*](B16690_06.xhtml#_idTextAnchor094)《使用LightGBM解决现实世界数据科学问题》中所述，数据清洗和特征工程是机器学习工作流程的关键部分。它们涉及处理不可用数据、处理缺失值以及创建可以输入到模型中的有意义的特征。手动特征工程可能特别具有挑战性和耗时。AutoML系统旨在有效地处理这些任务，实现自动特征提取和转换，从而产生更鲁棒的模型。

数据清洗自动化通常是通过遵循处理异常值和缺失值等问题的特定知名技术来实现的。在之前的章节中，我们手动应用了一些这些技术：异常值可以通过统计测试进行测试，并截断或截顶。缺失值通常使用描述性统计量，如平均值或众数进行插补。AutoML系统要么使用启发式算法和测试来选择最佳的数据清洗技术，要么通过训练模型来采取多种最佳方法和测试。

自动化特征工程的方法通常相似：将许多可能的转换应用于所有现有特征，并在建模后测试生成的特征的有用性。以下案例研究中可以找到转换如何生成特征的示例。

自动化特征工程的另一种方法是使用基于特征数据类型的规则提取特征。例如，可以从日期字段中提取日期、周、月和年。或者可以计算单词或句子特征的字符数、词元、词干或嵌入。

正如你可能注意到的，特征工程自动化技术的应用依赖于手头特征的技术信息，通常包括数据类型，以及与其他特征的关联和关系。重要的是，在创建新特征时没有应用领域知识。这突显了AutoML的一个缺点：它无法处理需要人类专业知识的特定、领域驱动型决策。例如，考虑一个包含空腹血糖特征的糖尿病数据集。医学专业人士（领域专家）知道，空腹血糖在100到125 mg/dL之间的人被认为是糖尿病前期，任何更高都被认为是糖尿病患者。这个连续特征可以被工程化为特定的类别：正常、糖尿病前期和糖尿病患者，从而简化了建模数据。这种类型的转换是无法通过AutoML系统实现的。

## 自动化模型选择和调整

AutoML特别有用的领域包括模型选择和超参数调整。鉴于可用的算法众多，为特定数据集和问题选择最佳算法可能会令人望而却步。AutoML系统使用各种技术，包括贝叶斯优化和元学习，来选择最佳模型。它们还自动调整超参数，以最大化模型性能。

AutoML系统可以提供自动交叉验证，降低过拟合的风险，并确保模型对未见数据的泛化能力。一旦选定了最佳模型并进行了训练，许多AutoML工具还可以帮助部署模型，使其可用于对新数据的推理。

除了初始模型部署之外，一些AutoML解决方案在持续模型监控和维护方面也提供了价值。随着现实世界数据的发展，模型可能会出现漂移，其性能可能会下降。AutoML可以帮助监控模型性能，并在需要时重新训练模型，确保您的机器学习系统在长期内保持有效。

## 使用AutoML系统的风险

如前所述，AutoML系统通常不使用领域知识来辅助特征工程、模型选择或其他自动化任务。相反，它们采用一种试错的方法。

一些AutoML系统的“黑盒”特性也可能使得解释系统做出的决策变得具有挑战性，这使得它们对于需要高解释性的应用不太适合。

因此，仍然非常重要的是要有一个数据科学家或领域专家参与其中，与AutoML系统协同工作，以识别并利用领域知识可以带来更好模型的机遇。然而，AutoML系统有时会阻碍数据科学家，而不是通过在科学家和数据之间增加一个额外的层次来使他们能够发挥作用。

我们已经看到了一个自动化机器学习框架的实际应用。在[*第五章*](B16690_05.xhtml#_idTextAnchor083)中讨论的Optuna，*使用Optuna进行LightGBM参数优化*，是一个专注于超参数调整的自动化机器学习框架的例子。在下一节中，我们将讨论另一个自动化机器学习框架：FLAML。

# 介绍FLAML

**FLAML**（**快速轻量级自动化机器学习**）是由微软研究院开发的Python库*[1]*。它旨在自动生成高质量的机器学习模型，降低计算成本。FLAML的主要目标是最大限度地减少调整超参数和识别最佳机器学习模型所需的资源，使自动化机器学习更加易于访问和成本效益，尤其是对于预算有限的用户。

FLAML提供了一些关键特性，使其与众不同。其中之一是它的效率。它为机器学习任务提供了一种快速轻量级的解决方案，最大限度地减少了所需的时间和计算资源。它在不影响所产生模型质量的情况下实现了这一点。FLAML还强调其在各种机器学习算法和不同应用领域中的多功能性。

FLAML的高效核心在于其新颖且成本效益高的搜索算法。这些算法智能地探索超参数空间，最初专注于“低成本”配置。随着对搜索空间的深入了解，它逐渐探索更多“高成本”配置。这确保了平衡的探索和利用，在用户指定的时间和资源预算内提供优化的模型。

FLAML在模型选择过程中也表现出色。它支持各种机器学习算法，包括XGBoost、LightGBM、CatBoost、随机森林和各种线性模型。该库可以自动为给定数据集选择最佳算法并优化其超参数，为用户提供一个无需大量手动干预的优化模型。

FLAML提供了一个简单直观的API，可以无缝集成到现有的基于Python的数据科学和机器学习工作流程中。用户指定数据集、时间预算（以秒为单位）和优化任务，FLAML处理其余部分。这种用户友好性和效率使其成为机器学习初学者和希望加快工作流程的资深从业者的一项实用选择。

FLAML效率背后的新意来自于其**超参数优化**（HPO）算法。FLAML提供了两种HPO算法：**成本节约优化**和**BlendSearch**。

## 成本节约优化

**成本节约优化**（CFO）是一种局部搜索方法，利用随机直接搜索来探索超参数空间*[2]*。CFO算法从一个低成本的超参数配置开始（例如，对于LightGBM，一个低成本配置可能只有少数提升树）。它在超参数空间中随机移动固定次数的迭代，朝着更高成本的参数区域前进。

CFO的步长是自适应的，这意味着如果连续几次迭代没有改进，算法会降低步长。这样做意味着不会在成本高昂的方向上采取大步长。

CFO还利用随机重启。作为一个局部搜索算法，CFO可能会陷入局部最优。如果没有任何进展且步长已经很小，算法会在一个随机点重新启动。

总结来说，CFO快速（使用大步长）尝试在搜索空间中达到更有希望的领域，尽可能少地使用优化预算（通过在低成本区域开始）。当优化预算允许时，CFO会继续搜索，如果出现停滞，会在随机区域重新启动。FLAML允许用户以秒为单位设置优化预算。

## BlendSearch

FLAML为BlendSearch中的CFO算法提供了一种替代方案。BlendSearch与CFO的不同之处在于，它使用多线程方法*[3]*同时运行全局和局部搜索过程。

与CFO类似，BlendSearch从一个低成本配置开始，并继续进行局部搜索。然而，与CFO不同，BlendSearch不会等待局部搜索停滞后再探索新的区域。相反，全局搜索算法（如贝叶斯优化）会不断提出新的起始点。起始点会根据它们与现有点的距离进行过滤，并按成本优先排序。

BlendSearch的每次迭代都会根据前一次迭代的表现来决定是继续进行局部搜索还是从新的全局搜索点开始。与CFO类似，全局搜索方法提出的配置会经过可行性验证。

由于BlendSearch使用全局优化，因此它不太可能陷入局部最小值。如果超参数搜索空间非常复杂，建议使用BlendSearch而不是CFO。通常，先尝试CFO，如果CFO遇到困难，再切换到BlendSearch是个不错的主意。

## FLAML局限性

尽管FLAML有其优势，但也存在局限性。该库的自动化流程可能不会始终优于专家的手动调整，尤其是在处理复杂、特定领域的任务时。此外，与其他AutoML解决方案一样，生成的模型的可解释性可能具有挑战性，尤其是在处理如提升树或神经网络等模型时。

FLAML只执行ML过程中的模型选择和调整部分。这些是模型开发中最耗时的部分之一，但FLAML不提供执行特征工程或数据准备的功能。

以下部分展示了使用FLAML与LightGBM的案例研究，展示了日常用例、不同的优化算法以及FLAML的零样本AutoML。

# 案例研究 - 使用FLAML与LightGBM

我们将使用前一章中的风力涡轮机数据集作为案例研究。数据集像以前一样进行了清理，填补了缺失值，并将异常值限制在适当的范围内。然而，我们在特征工程上采取了不同的方法。为了进一步探索AutoML，我们使用了一个名为Featuretools的开源框架。

## 特征工程

**Featuretools** ([https://featuretools.alteryx.com/en/stable/#](https://featuretools.alteryx.com/en/stable/#)) 是一个用于自动特征工程的开源框架。具体来说，Featuretools非常适合转换关系数据集和时间序列数据。

如前所述，自动特征工程工具通常使用特征的组合转换来为数据集生成新特征。Featuretools通过其**深度特征合成**（**DFS**）过程支持特征转换。

例如，考虑一个在线客户网络会话的数据集。此类数据集中可能有用的典型特征包括客户访问网站的会话总数，或客户注册的月份。使用Featuretools和DFS，可以通过以下代码实现（感谢[https://featuretools.alteryx.com/](https://featuretools.alteryx.com/)）：

[PRE0]

这里应用了两种转换：一个是“`month`”的转换，另一个是“`count`”的聚合。通过这些转换，会自动从客户的任何日期（如加入日期）中提取月份，并为每个客户（如会话数或交易数）计算聚合计数。Featuretools提供了一套丰富的转换和聚合功能。[完整的列表可在https://featuretools.alteryx.](https://featuretools.alteryx.com/en/stable/api_reference.xhtml)com/en/stable/api_reference.xhtml上找到。

让我们看看如何使用Featuretools为风力涡轮机数据集的特征进行工程。

### 使用Featuretools和风力涡轮机数据集

我们必须为我们数据集执行两个特征工程任务：为日期时间字段生成特征，并对分类特征进行编码。为了开始，我们为我们的数据创建一个`EntitySet`：

[PRE1]

`EntitySet`告诉Featuretools框架我们在数据中处理的数据实体和关系。在先前的例子中，客户是一个实体示例；对于这个案例，它是风力涡轮机。然后我们传递数据框和用作索引的列。

然后我们应用`dfs`和`encode_features`来为我们数据集的特征进行工程：

[PRE2]

上述代码提取了每个风力涡轮机测量值的日、年、月和星期几。特征编码随后自动将数据集中的分类特征进行one-hot编码，包括新的日期字段。

下面的内容是从数据集列列表的摘录，显示了Featuretools创建的一些列：

[PRE3]

注意分类特征的独热编码：每个值现在都分割成单独的列。这包括未知值的列（例如，`YEAR(datetime) is unknown`），这说明了处理分类特征中缺失值的另一种方法。我们不是通过使用诸如众数之类的值来填充值，而是有一个列向模型（`true`或`false`）发出信号，表示该值缺失。

自动特征工程将我们的列数从22列增加到66列。这说明了自动特征工程和AutoML的另一个一般性警告：自动化可能导致数据集过于复杂。在[*第6章*](B16690_06.xhtml#_idTextAnchor094)《使用LightGBM解决现实世界数据科学问题》中，我们可以根据对学习算法的理解有选择性地编码特征。LightGBM可以自动处理分类特征；因此，如果只使用LightGBM作为学习算法，则独热编码是多余的。

此外，日期字段可以以数值方式处理。通过应用我们对问题和算法的了解，我们可以降低学习问题的维度，从而简化它。自动系统的易用性必须与专家特征工程的手动工作相平衡，这可能在以后节省时间。

数据集现在已准备好进行模型开发；我们仅用两行代码就完成了数据集的特征工程。

## FLAML AutoML

我们现在将探讨模型选择和调优。我们将使用FLAML比较五种不同的模型：LightGBM、RandomForest、XGBoost、ExtraTrees以及XGBoost的有限深度版本。我们还想找到最佳模型的最佳参数。整个流程只需两行代码即可使用FLAML完成：

[PRE4]

上一段代码在60秒的时间预算内拟合了一个最优回归模型。FLAML自动使用保留集来计算验证结果，然后使用默认的CFO作为调优器进行优化。

AutoML类提供“面向任务的AutoML”。用户设置学习任务，FLAML完成剩余工作。支持的任务包括：分类、回归、时间序列预测和时间序列分类、排序以及与NLP相关的任务，如摘要和词元分类。

`fit`函数的调用是可定制的。例如，我们可以这样定制它：

[PRE5]

在这里，我们通过显式声明学习率作为一个在范围内对数缩放的均匀变量来自定义超参数搜索空间。设置参数搜索空间的其它选项包括均匀抽样、随机整数抽样以及用于分类参数的选择性抽样。

此外，我们将估计器列表设置为仅关注三种建模算法：LightGBM、随机森林和 XGBoost。最后，我们可以自定义 HPO 算法，在这里我们将其设置为 BlendSearch，它使用之前讨论过的多线程优化方法。

完整的自定义列表可在 https://microsoft.github.io/FLAML/docs/reference/automl/automl/#automl-objects 找到。

一旦调用 `fit`，我们可以像使用任何其他模型一样使用 AutoML 训练的模型。FLAML 提供了类似 scikit-learn 的 API 用于预测和基于概率的预测（用于分类问题）。

以下代码从给定数据创建预测并计算指标和特征重要性：

[PRE6]

我们还可以通过调用以下代码来获取获胜模型和每个试验模型的最佳超参数配置：

[PRE7]

FLAML 的一个最终显著特点是零样本 AutoML，它完全绕过了模型调整的需求。

## 零样本 AutoML

**零样本 AutoML** 是 FLAML 的一个功能，其中不执行超参数优化。相反，通过分析算法在广泛数据集上的性能，离线确定合适的超参数配置。该过程可以描述如下：

1.  在构建模型之前：

    +   使用 AutoML 在许多数据集上训练模型

    +   将所有数据集的超参数配置、评估结果和元数据存储为零样本解决方案。

1.  当为新的问题构建模型时：

    +   使用 FLAML 分析新数据集与零样本解决方案结果，以确定合适的超参数。

    +   使用超参数在新数据集上训练模型。

第一步对于给定的模型类型（例如 LightGBM）只执行一次。之后，对于任何新的问题都可以构建新的模型，无需调整。解决方案是“零样本”，因为对于新的数据集，在第一次拟合时使用了合适的参数。

FLAML 的零样本 AutoML 方法具有许多优点：

+   如前所述，不涉及调整，在解决新问题时节省了大量计算努力和时间。

+   由于不需要调整，因此也不需要验证数据集，更多的数据可以用于训练。

+   用户需要的参与更少。

+   通常，不需要更改代码，正如我们接下来将要看到的。

当然，为模型类型创建零样本解决方案仍然很困难，需要各种数据集和大量计算来训练许多模型。幸运的是，FLAML 为许多流行的模型提供了预训练的零样本解决方案，包括 LightGBM、XGBoost 和 scikit-learn 的随机森林。

要使用零样本解决方案，将常规的 LightGBM 导入替换为 FLAML 包装的版本：

[PRE8]

调用 `fit` 会分析 `X` 中的数据，选择合适的参数，并使用这些参数训练模型。训练只执行一次，不进行任何调整。

这标志着FLAML案例研究的结束。正如我们所见，FLAML提供了一个直观的API，用于复杂的模型选择和调优功能，这在处理ML问题时可以节省很多精力。

# 概述

总结来说，本章讨论了AutoML系统和它们的用途。我们讨论了自动化特征工程、模型选择和调优的典型方法。我们还提到了使用这些系统可能存在的风险和注意事项。

本章还介绍了FLAML，这是一个提供自动化模型选择和调优工具的AutoML库。我们还介绍了FLAML提供的两个高效的超参数优化算法：CFO和BlendSearch。

FLAML的实际应用通过案例研究的形式展示。除了FLAML，我们还展示了一个开源工具Featuretools，它提供自动化特征工程的功能。我们展示了如何使用FLAML在固定时间内开发优化模型。最后，我们提供了使用FLAML零样本AutoML功能示例，该功能通过分析数据集与已知问题的配置来确定合适的超参数，从而消除了模型调优的需要。

下一章将讨论围绕LightGBM模型构建ML管道，重点关注导出、打包和部署LightGBM模型以用于生产。

# 参考文献

| *[**1]* | *王晨，吴强，魏梅，朱易，“FLAML：一个快速且轻量级的AutoML库”，发表于* *MLSys，2021.* |
| --- | --- |
| *[**2]* | *吴强，王晨，黄思，关于成本相关超参数的节约优化，2020.* |
| *[**3]* | *王晨，吴强，黄思，赛义德，“使用混合搜索策略进行经济超参数优化”，发表于* *ICLR，2021.* |

# 第3部分：使用LightGBM的生产就绪机器学习

在第3部分，我们将深入探讨机器学习解决方案在生产环境中的实际应用。我们将揭示机器学习管道的复杂性，确保系统性地处理数据并构建模型以获得一致的结果。MLOps，DevOps和ML的结合，成为焦点，突出了在现实场景中部署和维护强大ML系统的重要性。通过实际案例，我们将探讨在平台（如Google Cloud、Amazon SageMaker和创新的PostgresML）上部署ML管道，强调每个平台提供的独特优势。最后，我们将探讨分布式计算和基于GPU的训练，展示加速训练过程和管理大数据集的有效方法。本部分将强调将ML无缝集成到实际、生产就绪的解决方案中，为读者提供将他们的模型在动态环境中实现的知识。

本部分将包括以下章节：

+   [*第8章*](B16690_08.xhtml#_idTextAnchor134)*，使用LightGBM的机器学习管道和MLOps*

+   [*第9章*](B16690_09.xhtml#_idTextAnchor146)*，使用AWS SageMaker进行LightGBM MLOps*

+   [*第10章*](B16690_10.xhtml#_idTextAnchor162)*，PostgresML的LightGBM* *模型*

+   [*第11章*](B16690_11.xhtml#_idTextAnchor177)*，基于分布式和GPU的LightGBM学习*
