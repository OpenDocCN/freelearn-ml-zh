- en: Chapter 8. Advanced Topics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章. 高级主题
- en: This chapter covers the less commonly used topics, such as machine learning
    with multiple classes and GPU-based optimizations. Both the topics are seeing
    a growth in interest and practical applications, so they deserve a complete chapter.
    We consider them advanced only as long as additional knowledge is required about
    machine learning / statistical classification and parallelization. We will start
    by explaining some of the most well-known classifiers such as KNN, SVM, and Random
    Forests, all of which are available in the `ml` module and show how they work
    with different database formats and multiple classes. Finally, a set of classes
    and functions to utilize GPU-based computational resources will be described.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了较少使用的主题，例如多类机器学习和基于 GPU 的优化。这两个主题都看到了兴趣和实际应用的增长，因此它们值得一个完整的章节。我们认为它们是高级的，只要需要关于机器学习/统计分类和并行化的额外知识。我们将从解释一些最著名的分类器开始，如
    KNN、SVM 和随机森林，它们都可在 `ml` 模块中找到，并展示它们如何与不同的数据库格式和多类工作。最后，将描述一组用于利用基于 GPU 的计算资源的类和函数。
- en: Machine learning
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: 'Machine learning deals with techniques that allow computers to learn and make
    decisions by themselves. A central concept in machine learning is the classifier.
    A classifier learns from the examples in a dataset, where the label of each sample
    is known. Usually, we have two datasets at hand: training and test. The classifier
    builds a model using the training set. This trained classifier is expected to
    predict the label of new unseen samples, so we finally use the test set to validate
    it and assess label recognition rates.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习处理允许计算机通过自身学习并做出决策的技术。机器学习的一个核心概念是分类器。分类器从数据集中的示例中学习，其中每个样本的标签是已知的。通常，我们手头有两个数据集：训练集和测试集。分类器使用训练集构建模型。这个训练好的分类器预计可以预测未见过的样本的标签，因此我们最终使用测试集来验证它并评估标签识别率。
- en: In this section, we explain the different classes and functions that OpenCV
    provides for classification, and simple examples of their use. Machine learning
    classes and functions for statistical classification, regression, and clustering
    of data are all included in the `ml` module.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们解释了 OpenCV 提供的不同类和函数，用于分类，以及它们使用的简单示例。机器学习类和函数包括用于数据统计分类、回归和聚类的 `ml`
    模块。
- en: The KNN classifier
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: KNN 分类器
- en: '**K-nearest neighbors** (**KNN**) is one of the simplest classifiers. It is
    a supervised classification method, which learns from available cases and classifies
    new cases by a minimum distance. K is the number of neighbors to be analyzed in
    the decision. The new data point to classify (the query) is projected to the same
    space as the learning points, and its class is given by the most frequent class
    among its KNN from the training set.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**K 近邻算法**（**KNN**）是最简单的分类器之一。它是一种监督分类方法，通过学习现有案例并通过最小距离对新的案例进行分类。K 是决策中要分析的邻居数量。要分类的新数据点（查询）被投影到与学习点相同的空间，其类别由训练集中其
    KNN 中最频繁的类别给出。'
- en: 'The following `KNNClassifier` code is an example of using the KNN algorithm
    to classify each image pixel to the nearest color: black (0, 0, 0), white (255,
    255, 255), blue (255, 0, 0), green (0, 255, 0), or red (0, 0, 255):'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `KNNClassifier` 代码是使用 KNN 算法对每个图像像素进行分类的示例，分类到最近的颜色：黑色（0, 0, 0）、白色（255, 255,
    255）、蓝色（255, 0, 0）、绿色（0, 255, 0）或红色（0, 0, 255）：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Remember that OpenCV uses a BGR color scheme.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，OpenCV 使用 BGR 颜色方案。
- en: OpenCV provides the KNN algorithm through the `CvKNearest` class. The training
    information is added to the KNN classifier through the `bool CvKNearest::train(const
    Mat& trainData, const Mat& responses, const Mat& sampleIdx, bool isRegression,
    int maxK, bool updateBase)` function. The example creates a training set with
    five samples, (`Mat colors(5, 3, CV_32FC1)`), which represent each class (color)
    (`Mat classes(5, 1, CV_32FC1)`); these are the first two input parameters. The
    `isRegression` is parameter is a Boolean value that defines whether we want to
    perform a classification or a regression. The `maxK` value indicates the maximum
    number of neighbors that will be used in the test phase.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV通过 `CvKNearest` 类提供KNN算法。通过 `bool CvKNearest::train(const Mat& trainData,
    const Mat& responses, const Mat& sampleIdx, bool isRegression, int maxK, bool
    updateBase)` 函数将训练信息添加到KNN分类器中。示例创建了一个包含五个样本的训练集（`Mat colors(5, 3, CV_32FC1)`），代表每个类别（颜色）（`Mat
    classes(5, 1, CV_32FC1)`）；这些是前两个输入参数。`isRegression` 参数是一个布尔值，定义了是否想要执行分类或回归。`maxK`
    值表示测试阶段将使用的最大邻居数。
- en: Finally, `updateBaseparameter` allows us to indicate whether we want to train
    a new classifier with the data or use it to update the previous training data.
    Then, the code sample performs the test phase with each pixel of the original
    image using the `float CvKNearest::find_nearest(const Mat& samples, int k, Mat*
    results=0, const float** neighbors=0, Mat* neighborResponses=0, Mat* dist=0)`
    function. The function tests the input sample, selecting the KNN, and finally
    predicts the class value for this sample.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`updateBaseparameter` 允许我们指示是否想要使用数据训练新的分类器或使用它来更新之前的训练数据。然后，代码示例使用 `float
    CvKNearest::find_nearest(const Mat& samples, int k, Mat* results=0, const float**
    neighbors=0, Mat* neighborResponses=0, Mat* dist=0)` 函数对原始图像的每个像素执行测试阶段。该函数测试输入样本，选择KNN，并最终预测此样本的类别值。
- en: 'In the following screenshot, we can see the code output and the difference
    between the original and the result images after this KNN classification:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下屏幕截图中，我们可以看到代码输出以及此KNN分类后原始图像和结果图像之间的差异：
- en: '![The KNN classifier](img/00054.jpeg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![KNN分类器](img/00054.jpeg)'
- en: 'KNN classification using the primary colors as classes (left: the original
    image, right: the result image)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用原色作为类别的KNN分类（左：原始图像，右：结果图像）
- en: The Random Forest classifier
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林分类器
- en: Random Forests are a general class of ensemble building methods that use a decision
    tree as the base classifier. The Random Forest classifier is a variation of the
    Bagging classifier (Bootstrap Aggregating). The Bagging algorithm is a method
    of classification that generates weak individual classifiers using bootstrap.
    Each classifier is trained on a random redistribution of the training set so that
    many of the original examples may be repeated in each classification.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是一类使用决策树作为基分类器的集成构建方法。随机森林分类器是Bagging分类器（Bootstrap Aggregating）的一种变体。Bagging算法是一种分类方法，使用自助法生成弱个体分类器。每个分类器都在训练集的随机重新分配上训练，以便许多原始示例可能在每个分类中重复。
- en: 'The principal difference between Bagging and Random Forest is that Bagging
    uses all the features in each tree node and Random Forest selects a random subset
    of the features. The suitable number of randomized features corresponds to the
    square root of the total number of features. For prediction, a new sample is pushed
    down the tree and it is assigned the class of the terminal (or leaf) node in the
    tree. This method is iterated over all the trees, and finally, the average vote
    of all the tree predictions is considered as the prediction result. The following
    diagram shows the Random Forest algorithm:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging 和随机森林的主要区别在于，Bagging 使用每个树节点中的所有特征，而随机森林则选择特征的一个随机子集。合适的随机特征数量对应于特征总数的平方根。对于预测，一个新的样本被推送到树中，并分配给树中终端（或叶）节点的类别。这种方法在所有树上迭代，最后，将所有树的预测的平均投票作为预测结果。以下图表显示了随机森林算法：
- en: '![The Random Forest classifier](img/00055.jpeg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![随机森林分类器](img/00055.jpeg)'
- en: The RF classifier
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: RF分类器
- en: 'Random Forests are currently one of the best classifiers available, both in
    recognition power and efficiency. In our example `RFClassifier`, we use the OpenCV
    Random Forest classifier and also the OpenCV `CvMLData` class. A large amount
    of information is typically handled in machine learning problems, and for this
    reason, it is convenient to use a `.cvs` file. The `CvMLData` class is used to
    load the training set information from such a file as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林目前在识别能力和效率方面都是最好的分类器之一。在我们的示例`RFClassifier`中，我们使用了OpenCV随机森林分类器和OpenCV的`CvMLData`类。在机器学习问题中通常处理大量信息，因此使用`.cvs`文件很方便。`CvMLData`类用于以下方式从这样的文件中加载训练集信息：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Tip
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: The dataset has been provided by the UC Irvine Machine Learning Repository,
    available at [http://archive.ics.uci.edu/ml/](http://archive.ics.uci.edu/ml/).
    For this code sample, the Iris dataset was used.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集由UC Irvine机器学习仓库提供，可在[http://archive.ics.uci.edu/ml/](http://archive.ics.uci.edu/ml/)找到。对于此代码示例，使用了Iris数据集。
- en: As we mentioned previously, the `CvMLData` class allows you to load the dataset
    from a `.csv` file using the `read_csv` function and indicates the class column
    by the `set_response_idx` function. In this case, we use this dataset to perform
    the training and test phases. It is possible to split the dataset into two disjoint
    sets for training and test. For this, we use the `CvTrainTestSplit` struct and
    the `void CvMLData::set_train_test_split(const CvTrainTestSplit* spl)` function.
    In the `CvTrainTestSplit` struct, we indicate the percentage of samples to be
    used as the training set (0.75 percent in our case) and whether we want to mix
    the indices of the training and test samples from the dataset. The `set_train_test_split`
    function performs the split. Then, we can store each set in `Mat` with the `get_train_sample_idx()`
    and `get_test_sample_idx()`functions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，`CvMLData`类允许您使用`read_csv`函数从`.csv`文件加载数据集，并通过`set_response_idx`函数指示类列。在这种情况下，我们使用这个数据集进行训练和测试阶段。可以将数据集分成两个不相交的集合用于训练和测试。为此，我们使用`CvTrainTestSplit`结构和`void
    CvMLData::set_train_test_split(const CvTrainTestSplit* spl)`函数。在`CvTrainTestSplit`结构中，我们指示用作训练集的样本百分比（在我们的情况下为0.75%），以及我们是否希望从数据集中混合训练和测试样本的索引。`set_train_test_split`函数执行分割。然后，我们可以使用`get_train_sample_idx()`和`get_test_sample_idx()`函数将每个集合存储在`Mat`中。
- en: The Random Forest classifier is created using the `CvRTrees` class, and its
    parameters are defined by the `CvRTParams::CvRTParams(int max_depth, int min_sample_count,
    float regression_accuracy, bool use_surrogates, int max_categories, const float*
    priors, bool calc_var_importance, int nactive_vars, int max_num_of_trees_in_the_forest,
    float forest_accuracy, int termcrit_type)` constructor. Some of the most important
    input parameters refer to the maximum depth of the trees (`max_depth`)—in our
    sample, it has a value of 3—the number of randomized features in each node (`nactive_vars`),
    and the maximum number of trees in the forest (`max_num_of_trees_in_the_forest`).
    If we set the `nactive_vars` parameter to 0, the number of randomized features
    will be the square root of the total number of features.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林分类器是通过`CvRTrees`类创建的，其参数由`CvRTParams::CvRTParams(int max_depth, int min_sample_count,
    float regression_accuracy, bool use_surrogates, int max_categories, const float*
    priors, bool calc_var_importance, int nactive_vars, int max_num_of_trees_in_the_forest,
    float forest_accuracy, int termcrit_type)`构造函数定义。其中一些最重要的输入参数指的是树的最大深度(`max_depth`)——在我们的示例中，它的值为3——每个节点中随机特征的数量(`nactive_vars`)，以及森林中树的最大数量(`max_num_of_trees_in_the_forest`)。如果我们将`nactive_vars`参数设置为0，随机特征的数量将是特征总数的平方根。
- en: 'Finally, once the classifier is trained with the `train` function, we can obtain
    the percentage of misclassified samples using the `float CvRTrees::calc_error(CvMLData*
    data, int type, std::vector<float>* resp=0 )` method. The parameter type allows
    you to select the source of the error: `CV_TRAIN_ERROR` (an error in the training
    samples) or `CV_TEST_ERROR` (an error in the test samples).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一旦使用`train`函数训练了分类器，我们可以使用`float CvRTrees::calc_error(CvMLData* data, int
    type, std::vector<float>* resp=0 )`方法获得误分类样本的百分比。参数类型允许您选择错误的来源：`CV_TRAIN_ERROR`（训练样本中的错误）或`CV_TEST_ERROR`（测试样本中的错误）。
- en: 'The following screenshot shows the training and test errors and the classifier
    responses in both the sets:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了训练和测试错误以及两个集合中的分类器响应：
- en: '![The Random Forest classifier](img/00056.jpeg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![随机森林分类器](img/00056.jpeg)'
- en: The RF classifier sample results
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林分类器示例结果
- en: SVM for classification
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于分类的支持向量机（SVM）
- en: 'The **Support Vector Machine** (**SVM**) classifier finds a discriminant function
    by maximizing the geometrical margin between the classes. Thus, the space is mapped
    in such a way that the classes are as widely separated as possible. SVM minimizes
    both the training error and the geometrical margin. Nowadays, this classifier
    is one of the best classifiers available and has been applied to many real-world
    problems. The following `SVMClassifier` sample code performs a classification
    using the SVM classifier and a dataset of 66 image objects. The dataset is divided
    into four classes: a training shoe (class 1), a cuddly toy (class 2), a plastic
    cup (class 3), and a bow (class 4). The following screenshot shows the examples
    of the four classes. A total of 56 images and 10 images were used for the training
    and the test sets, respectively. Images in the training set take the following
    name structure: `[1-14].png` corresponds to class 1, `[15-28].png` to class 2,
    `[29-42].png` to class 3, and `[43-56].png` to class 4\. On the other hand, images
    in the test set are characterized by the word unknown followed by a number, for
    example, `unknown1.png`.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVM**）分类器通过最大化类别之间的几何间隔来找到一个判别函数。因此，空间被映射得尽可能使类别之间尽可能分离。SVM 最小化训练误差和几何间隔。如今，这种分类器是可用的最佳分类器之一，并被应用于许多实际问题。下面的
    `SVMClassifier` 示例代码使用 SVM 分类器和包含 66 个图像对象的数据库进行分类。该数据库分为四个类别：一双训练鞋（类别 1）、一个毛绒玩具（类别
    2）、一个塑料杯子（类别 3）和一个蝴蝶结（类别 4）。以下截图显示了四个类别的示例。总共使用了 56 张图像用于训练集，10 张图像用于测试集。训练集中的图像采用以下名称结构：`[1-14].png`
    对应于类别 1，`[15-28].png` 对应于类别 2，`[29-42].png` 对应于类别 3，`[43-56].png` 对应于类别 4。另一方面，测试集中的图像以“unknown”一词开头，后跟一个数字，例如，`unknown1.png`。'
- en: Tip
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: The images of the four classes have been extracted from the **Amsterdam Library
    of Object Images** (**ALOI**) available at [http://aloi.science.uva.nl/](http://aloi.science.uva.nl/).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 四个类别的图像已从位于 [http://aloi.science.uva.nl/](http://aloi.science.uva.nl/) 的**阿姆斯特丹物体图像库**（**ALOI**）中提取。
- en: '![SVM for classification](img/00057.jpeg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![SVM for classification](img/00057.jpeg)'
- en: Classes selected for the SVM classification example
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为 SVM 分类示例选择的类别
- en: 'The `SVMClassifier` sample code is as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`SVMClassifier` 示例代码如下：'
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The explanation of the code is given as follows. In this example, images are
    represented by their descriptors (see [Chapter 5](part0042_split_000.html#page
    "Chapter 5. Focusing on the Interesting 2D Features"), *Focusing on the Interesting
    2D Features*). For each image in the training set, its interest points are detected
    using an **Oriented FAST and Rotated BRIEF** (**ORB**) detector (`OrbFeatureDetector`)
    and its descriptors are computed using the **Speeded Up Robust Features** (**SURF**)
    descriptor (`SurfDescriptorExtractor`).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的解释如下。在这个例子中，图像通过其描述符来表示（参见[第5章](part0042_split_000.html#page "第5章. 专注于有趣的2D特征")，*专注于有趣的2D特征*）。对于训练集中的每个图像，使用**Oriented
    FAST and Rotated BRIEF**（**ORB**）检测器（`OrbFeatureDetector`）检测其兴趣点，并使用**Speeded
    Up Robust Features**（**SURF**）描述符（`SurfDescriptorExtractor`）计算其描述符。
- en: 'An SVM classifier is created using the `CvSVM` class and its parameters are
    set using the `CvSVMParams::CvSVMParams(int svm_type, int kernel_type, double
    degree, double gamma, double coef0, double Cvalue, double nu, double p, CvMat*
    class_weights, CvTermCriteria term_crit)` constructor. The interesting parameters
    in this constructor are the type of SVM (`svm_type`) and the type of kernel (`kernel_type`).
    The first specified parameter takes, in our case, the `CvSVM::C_SVC` value because
    an n-classification (n ![SVM for classification](img/00058.jpeg) 2) with an imperfect
    separation of the classes is needed. It also uses a C penalty value for atypical
    values. C acts, therefore, as a regularizer. The `kernel_type` parameter indicates
    the type of SVM kernel. The kernel represents the basis function required to separate
    the cases. For the SVM classifier, OpenCV includes the following kernels:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `CvSVM` 类创建 SVM 分类器，并使用 `CvSVMParams::CvSVMParams(int svm_type, int kernel_type,
    double degree, double gamma, double coef0, double Cvalue, double nu, double p,
    CvMat* class_weights, CvTermCriteria term_crit)` 构造函数设置其参数。在这个构造函数中，有趣的参数是 SVM
    的类型（`svm_type`）和核的类型（`kernel_type`）。第一个指定的参数在我们的情况下采用 `CvSVM::C_SVC` 值，因为我们需要一个
    n 类分类（n ![SVM for classification](img/00058.jpeg) 2）且类别之间不完全分离。它还使用 C 惩罚值来处理异常值。因此，C
    起到正则化的作用。`kernel_type` 参数指示 SVM 核的类型。核代表分离案例所需的基础函数。对于 SVM 分类器，OpenCV 包含以下核：
- en: '`CvSVM::LINEAR`: The linear kernel'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CvSVM::LINEAR`：线性核'
- en: '`CvSVM::POLY`: The polynomial kernel'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CvSVM::POLY`：多项式核'
- en: '`CvSVM::RBF`: The radial basis function'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CvSVM::RBF`：径向基函数'
- en: '`CvSVM::SIGMOID`: The sigmoid kernel'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CvSVM::SIGMOID`：Sigmoid核'
- en: 'Then, the classifier builds an optimal linear discriminating function using
    the training set (with the `train` function). Now, it is prepared to classify
    new unlabeled samples. The test set is used for this purpose. Note that we also
    have to calculate the ORB detector and the SURF descriptors for each image in
    the test set. The result is as shown in the following screenshot, where all the
    classes have been classified correctly:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，分类器使用训练集（通过`train`函数）构建一个最优的线性判别函数。现在，它已准备好对新未标记样本进行分类。测试集用于此目的。请注意，我们还需要为测试集中的每张图像计算ORB检测器和SURF描述符。结果如下所示，其中所有类别都已正确分类：
- en: '![SVM for classification](img/00059.jpeg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![SVM for classification](img/00059.jpeg)'
- en: The classification result using SVM
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SVM进行分类的结果
- en: What about GPUs?
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 那么，GPU怎么样？
- en: CPUs seem to have reached their speed and thermal power limits. It has become
    complex and expensive to build a computer with several processors. Here is where
    GPUs come into play. **General-Purpose Computing on Graphics Processing Units**
    (**GPGPU**) is a new programming paradigm that uses the GPU to perform computations
    and enables the faster execution of programs and a reduction of power consumption.
    They include hundreds of general-purpose computing processors that can do much
    more than render graphics, especially if they are used in tasks that can be parallelized,
    which is the case with computer vision algorithms.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: CPU似乎已经达到了它们的速度和热功率极限。构建具有多个处理器的计算机变得复杂且昂贵。这就是GPU发挥作用的地方。**通用计算图形处理单元**（**GPGPU**）是一种新的编程范式，它使用GPU进行计算，并使程序执行更快，功耗降低。它们包括数百个通用计算处理器，可以完成比渲染图形更多的工作，特别是如果它们用于可以并行化的任务，这在计算机视觉算法中是常见的情况。
- en: OpenCV includes support for the OpenCL and CUDA architectures, with the latter
    having more implemented algorithms and a better optimization. This is the reason
    why we are introducing the CUDA GPU module in this chapter.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV包括对OpenCL和CUDA架构的支持，后者实现了更多算法，并且优化更好。这就是为什么我们在本章中引入CUDA GPU模块的原因。
- en: Setting up OpenCV with CUDA
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置OpenCV与CUDA
- en: The installation guide presented in [Chapter 1](part0014_split_000.html#page
    "Chapter 1. Getting Started"), *Getting Started*, needs a few additional steps
    in order to include the GPU module. We assume that the computer in which OpenCV
    is going to be installed already has the software detailed in that guide.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](part0014_split_000.html#page "第1章。入门")中介绍的安装指南，*入门*，为了包含GPU模块，需要一些额外的步骤。我们假设OpenCV将要安装的计算机已经安装了该指南中详细说明的软件。
- en: 'There are new requirements to be satisfied in order to compile OpenCV with
    CUDA on Windows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上编译OpenCV与CUDA结合时，需要满足以下新要求：
- en: '**CUDA-capable GPU**: This is the main requirement. Note that CUDA is developed
    by NVIDIA and, consequently, it is only compatible with NVIDIA graphic cards.
    Besides, the model of the card has to be listed at [http://developer.nvidia.com/cuda-gpus](http://developer.nvidia.com/cuda-gpus).
    The so-called **Compute Capability** (**CC**) can also be checked on this website
    as it will be needed later.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CUDA兼容的GPU**：这是主要要求。请注意，CUDA由NVIDIA开发，因此它仅与NVIDIA显卡兼容。此外，显卡的型号必须列在[http://developer.nvidia.com/cuda-gpus](http://developer.nvidia.com/cuda-gpus)上。所谓的**计算能力**（**CC**）也可以在这个网站上检查，因为它将在以后需要。'
- en: '**Microsoft Visual Studio**: CUDA is compatible only with this Microsoft compiler.
    It is possible to install the Visual Studio Express edition, which is free. Note
    that Visual Studio 2013 is still not compatible with CUDA at the time of writing,
    so we are using Visual Studio 2012 in this book.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Microsoft Visual Studio**：CUDA仅与此Microsoft编译器兼容。可以安装免费的Visual Studio Express版本。请注意，截至写作时，Visual
    Studio 2013仍然与CUDA不兼容，所以我们在这本书中使用Visual Studio 2012。'
- en: '**NVIDIA CUDA Toolkit**: This includes a compiler for GPUs, libraries, tools,
    and documentation. This toolkit is available at [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NVIDIA CUDA Toolkit**：这包括GPU编译器、库、工具和文档。此工具包可在[https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)获取。'
- en: '**Qt library for Visual C++ compiler**: In [Chapter 1](part0014_split_000.html#page
    "Chapter 1. Getting Started"), *Getting Started*, the MinGW binaries of the Qt
    library were installed, but they are not compatible with the Visual C++ compiler.
    A compatible version can be downloaded using the package manager by means of the
    `MaintenanceTool` application located in `C:\Qt`. A good choice is the `msvc2012`
    32-bit component, as can be seen in the following screenshot. It is also necessary
    to update the `Path` environment with the new location (for example, in our local
    system, it is `C:\Qt\5.2.1\msvc2012\bin`). The Qt library is included in the compilation
    to take advantage of its user interface features.![Setting up OpenCV with CUDA](img/00060.jpeg)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Qt库针对Visual C++编译器**：在[第1章](part0014_split_000.html#page "第1章. 入门")，*入门*中，安装了Qt库的MinGW二进制文件，但它们与Visual
    C++编译器不兼容。可以通过位于`C:\Qt`中的`MaintenanceTool`应用程序使用软件包管理器下载兼容版本。一个好的选择是下面的截图所示的`msvc2012`
    32位组件。还需要更新`Path`环境变量以包含新位置（例如，在我们的本地系统中，它是`C:\Qt\5.2.1\msvc2012\bin`）。Qt库包含在编译中，以便利用其用户界面功能。![设置带有CUDA的OpenCV](img/00060.jpeg)'
- en: Downloading a new version of the Qt libraries
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下载Qt库的新版本
- en: Configuring the OpenCV build
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置OpenCV的构建
- en: 'The build configuration with CMake differs in some points from the typical
    one explained in the first chapter. These differences are explained as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CMake的构建配置与第一章中解释的典型配置在某些方面有所不同。以下是对这些差异的解释：
- en: When you select the generator for the project, you have to choose the Visual
    Studio compiler version that corresponds to the installed environment in the machine.
    In our case, Visual Studio 11 is the correct compiler, as it corresponds to the
    version of the compiler included in Visual Studio 2012\. The following screenshot
    shows this selection.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当选择项目的生成器时，你必须选择与机器中安装的环境相对应的Visual Studio编译器版本。在我们的例子中，Visual Studio 11是正确的编译器，因为它对应于Visual
    Studio 2012中包含的编译器版本。以下截图显示了此选择。
- en: In the selection of build options, we have to focus on the CUDA-related ones.
    If the installation of the CUDA toolkit was correct, CMake should automatically
    detect its location and activate the `WITH_CUDA` option. In addition, the installation
    path of the toolkit is shown through `CUDA_TOOLKIT_ROOT_DIR`. Another interesting
    option is `CUDA_ARCH_BIN` because the compilation time can be significantly reduced
    if we just select the corresponding version of our GPU; otherwise, it will compile
    the code for all the architectures. As mentioned previously, the version can be
    checked at [http://developer.nvidia.com/cuda-gpus](http://developer.nvidia.com/cuda-gpus).
    The following screenshot shows the options set in our build configuration:![Configuring
    the OpenCV build](img/00061.jpeg)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在选择构建选项时，我们必须关注与CUDA相关的选项。如果CUDA工具包的安装正确，CMake应自动检测其位置并激活`WITH_CUDA`选项。此外，工具包的安装路径通过`CUDA_TOOLKIT_ROOT_DIR`显示。另一个有趣的选项是`CUDA_ARCH_BIN`，因为如果我们只选择我们GPU的相应版本，编译时间可以显著减少；否则，它将为所有架构编译代码。如前所述，版本可以在[http://developer.nvidia.com/cuda-gpus](http://developer.nvidia.com/cuda-gpus)上检查。以下截图显示了我们的构建配置中设置的选项：![配置OpenCV的构建](img/00061.jpeg)
- en: The CMake build configuration
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CMake构建配置
- en: Building and installing the library
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建和安装库
- en: CMake generates several Visual Studio projects in the target directory, `ALL_BUILD`
    being the essential one. Once it is opened in Visual Studio, we can choose the
    build configuration (Debug or Release) as well as the architecture (Win32 or Win64).
    The compilation starts by pressing *F7* or by clicking on **Build Solution**.
    After the compilation has finished, it is recommended that you open and build
    the `INSTALL` project as it generates an install directory with all the necessary
    files.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: CMake在目标目录中生成多个Visual Studio项目，`ALL_BUILD`是基本的项目。一旦在Visual Studio中打开，我们可以选择构建配置（调试或发布）以及架构（Win32或Win64）。通过按*F7*或点击**构建解决方案**开始编译。编译完成后，建议打开并构建`INSTALL`项目，因为它会生成包含所有必要文件的安装目录。
- en: Finally, the `Path` system needs to be updated with the location of the newly
    generated binaries. It is important to remove the previous location from the `Path`
    variable and have only one version of the binaries in it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，需要使用新生成的二进制文件的位置更新`Path`系统。重要的是要从`Path`变量中删除旧位置，并只在其中包含一个版本的二进制文件。
- en: Note
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Qt Creator should now find two compilers and two Qt versions: one for Visual
    C++ and one for MingGW. We have to choose the correct kit depending on the developed
    application when creating a new project. It is also possible to change the configuration
    of an existing project as kits are manageable.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: A quick recipe for setting up OpenCV with CUDA
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The installation process can be summarized in the following steps:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Install Microsoft Visual Studio Express 2012.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download and install the NVIDIA CUDA Toolkit (available at [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)).
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the binaries for the Visual C++ compiler to the Qt installation and update
    the `Path` system with the new location (for example, `C:\Qt\5.2.1\msvc2012\bin`).
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure the OpenCV build with CMake. Set the `WITH_CUDA`, `CUDA_ARCH_BIN`,
    `WITH_QT`, and `BUILD_EXAMPLES` options.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `ALL_BUILD` Visual Studio project and build it. Do the same operation
    with the `INSTALL` project.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the `Path` environment variable to update the OpenCV bin directory (for
    example, `C:\opencv-buildCudaQt\install\x86\vc11\bin`).
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our first GPU-based program
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we show two versions of the same program: one version uses
    the CPU to perform computations, and the other version uses the GPU. These two
    examples are called `edgesCPU` and `edgesGPU`, respectively, and allow us to point
    out the differences when using the `GPU` module in OpenCV.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'The `edgesCPU` example is presented in the first place:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now the `edgesGPU` example is shown as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The explanation of the code is given as follows. There are several differences
    in the previous examples, although they ultimately obtain the same result, as
    shown in the following screenshot. A new header file is added as the new data
    type and different implementations of the algorithms are used. `#include <opencv2/gpu/gpu.hpp>`
    contains the `GpuMat` data type, which is the basic container that stores images
    in the GPU memory. It also includes the specific GPU versions of the filter algorithms
    used in the second example.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: An important consideration is that we need to transfer the images between the
    CPU and the GPU. This is achieved with the `g_orig.upload(orig)` and `g_gray.download(dst)`
    methods. Once the image is uploaded to the GPU, we can apply different operations
    to it that are executed on the GPU. In order to distinguish the version of the
    algorithm that needs to run, the `gpu` namespace is used as in `gpu::bilateralFilter`,
    `gpu::cvtColor`, and `gpu::Canny`. After the filters have been applied, the image
    is copied to the CPU memory again and displayed.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Regarding performance, the CPU version runs in 297 milliseconds, whereas the
    GPU version runs in just 18 milliseconds. In other words, the GPU version runs
    16.5x faster.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '![Our first GPU-based program](img/00062.jpeg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
- en: The output of the edgesCPU and edgesGPU examples
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Going real time
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the main advantages of using the GPU to perform computations in images
    is that they are much faster. This increase in speed allows you to run heavy computational
    algorithms in real-time applications, such as stereo vision, pedestrian detection,
    or dense optical flow. In the next `matchTemplateGPU` example, we show an application
    that matches a template in a video sequence:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GPU在图像中进行计算的主要优点之一是它们要快得多。这种速度的提升允许你在实时应用中运行重量级的计算算法，例如立体视觉、行人检测或密集光流。在下一个`matchTemplateGPU`示例中，我们展示了一个在视频序列中匹配模板的应用：
- en: '[PRE5]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The explanation of the code is given as follows. As detailed in [Chapter 5](part0042_split_000.html#page
    "Chapter 5. Focusing on the Interesting 2D Features"), *Focusing on the Interesting
    2D Features*, features can be used to find the correspondence between two images.
    The template image, which is searched afterwards within every frame, is processed
    in the first place using the GPU version of SURF (`gpu::SURF_GPU surf;`) to detect
    interest points and extract descriptors. This is accomplished by running `surf(img_template,gpu::GpuMat(),keypoints_template,
    descriptors_template);`. The same process is performed for every frame taken from
    the video sequence. In order to match the descriptors of both images, a GPU version
    of the BruteForce matcher is also created with `gpu::BFMatcher_GPU matcher(NORM_L2);`.
    An extra step is needed due to the fact that interest points and descriptors are
    stored in the GPU memory, and they need to be downloaded before we can show them.
    That''s why `surf.downloadKeypoints(keypoints, keypoints);` and `surf.downloadDescriptors(descriptors,
    descriptors);` are executed. The following screenshot shows the example running:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的解释如下。正如[第5章](part0042_split_000.html#page "第5章. 专注于有趣的2D特征")中详细描述的，*专注于有趣的2D特征*，可以使用特征来找到两张图像之间的对应关系。随后在每一帧中搜索的模板图像首先使用GPU版本的SURF（`gpu::SURF_GPU
    surf;`）来检测兴趣点和提取描述符。这是通过运行`surf(img_template,gpu::GpuMat(),keypoints_template,
    descriptors_template);`来实现的。对于视频序列中取出的每一帧，都执行相同的处理过程。为了匹配两张图像的描述符，还创建了一个GPU版本的BruteForce匹配器`gpu::BFMatcher_GPU
    matcher(NORM_L2);`。由于兴趣点和描述符存储在GPU内存中，并且在我们能够显示它们之前需要下载，因此需要额外的步骤。这就是为什么执行了`surf.downloadKeypoints(keypoints,
    keypoints);`和`surf.downloadDescriptors(descriptors, descriptors);`。下面的截图显示了示例运行的情况：
- en: '![Going real time](img/00063.jpeg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![实时进行](img/00063.jpeg)'
- en: Template matching using a webcam
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用摄像头进行模板匹配
- en: Performance
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能
- en: 'The principal motivation for choosing GPU programming is performance. Therefore,
    this example includes time measurements to compare the speedups obtained with
    respect to the CPU version. Specifically, time is saved at the beginning of the
    main loop of the program by means of the `getTickCount()` method. At the end of
    this loop, the same method is used as well as `getTickFrequency`, which helps
    to calculate the FPS of the current frame. The time elapsed in each frame is accumulated,
    and at the end of the program, the mean is computed. The previous example has
    an average latency of 15 FPS, whereas the same example using CPU data types and
    algorithms achieves a mere 0.5 FPS. Both examples have been tested on the same
    hardware: a PC equipped with an i5-4570 processor and an NVIDIA GeForce GTX 750
    graphics card. Obviously, a speed increment of 30x is significant, especially
    when we just need to change a few lines of code.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 选择GPU编程的主要动机是性能。因此，这个例子包括了时间测量，以比较相对于CPU版本获得的速度提升。具体来说，通过`getTickCount()`方法在程序主循环的开始处节省了时间。在这个循环的末尾，同样使用了`getTickFrequency`，这有助于计算当前帧的FPS。每一帧所花费的时间被累积，在程序结束时计算平均值。前一个例子平均延迟为15
    FPS，而使用CPU数据类型和算法的相同例子仅达到0.5 FPS。这两个例子都在相同的硬件上进行了测试：一台配备i5-4570处理器的PC和NVIDIA GeForce
    GTX 750显卡。显然，速度提升30倍是显著的，尤其是在我们只需要更改几行代码的情况下。
- en: Summary
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we have covered two advanced modules of OpenCV: machine learning
    and GPU. Machine learning has the capability to learn computers to make decisions.
    For this, a classifier is trained and validated. This chapter provides three classification
    samples: KNN classifier, Random Forest using a `.cvs` database, and SVM using
    an image database. The chapter also addresses the use of OpenCV with CUDA. GPUs
    have a growing role in intensive tasks because they can offload the CPU and run
    parallel tasks such as those encountered in computer vision algorithms. Several
    GPU examples have been provided: GPU module installation, a basic first GPU program,
    and real-time template matching.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了 OpenCV 的两个高级模块：机器学习和 GPU。机器学习具有让计算机做出决策的能力。为此，需要训练和验证一个分类器。本章提供了三个分类示例：KNN
    分类器、使用 `.cvs` 数据库的随机森林，以及使用图像数据库的 SVM。本章还讨论了与 CUDA 一起使用 OpenCV 的方法。GPU 在密集型任务中发挥着越来越重要的作用，因为它们可以卸载
    CPU 并运行并行任务，例如在计算机视觉算法中遇到的任务。已经提供了几个 GPU 示例：GPU 模块安装、一个基本的第一个 GPU 程序，以及实时模板匹配。
- en: What else?
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有什么吗？
- en: The GPU module now covers most of the functionalities of OpenCV; so, it is recommended
    that you explore the library and check which algorithms are available. In addition,
    the `performance_gpu` program can be found at `[opencv_build]/install/x86/vc11/samples/gpu]`,
    which shows the speedups of many OpenCV algorithms when using the GPU version.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的 GPU 模块涵盖了 OpenCV 的大多数功能；因此，建议您探索这个库并检查哪些算法可用。此外，`performance_gpu` 程序可以在
    `[opencv_build]/install/x86/vc11/samples/gpu` 找到，它展示了使用 GPU 版本时许多 OpenCV 算法的加速效果。
