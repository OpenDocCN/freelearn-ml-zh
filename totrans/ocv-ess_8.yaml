- en: Chapter 8. Advanced Topics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers the less commonly used topics, such as machine learning
    with multiple classes and GPU-based optimizations. Both the topics are seeing
    a growth in interest and practical applications, so they deserve a complete chapter.
    We consider them advanced only as long as additional knowledge is required about
    machine learning / statistical classification and parallelization. We will start
    by explaining some of the most well-known classifiers such as KNN, SVM, and Random
    Forests, all of which are available in the `ml` module and show how they work
    with different database formats and multiple classes. Finally, a set of classes
    and functions to utilize GPU-based computational resources will be described.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Machine learning deals with techniques that allow computers to learn and make
    decisions by themselves. A central concept in machine learning is the classifier.
    A classifier learns from the examples in a dataset, where the label of each sample
    is known. Usually, we have two datasets at hand: training and test. The classifier
    builds a model using the training set. This trained classifier is expected to
    predict the label of new unseen samples, so we finally use the test set to validate
    it and assess label recognition rates.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we explain the different classes and functions that OpenCV
    provides for classification, and simple examples of their use. Machine learning
    classes and functions for statistical classification, regression, and clustering
    of data are all included in the `ml` module.
  prefs: []
  type: TYPE_NORMAL
- en: The KNN classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**K-nearest neighbors** (**KNN**) is one of the simplest classifiers. It is
    a supervised classification method, which learns from available cases and classifies
    new cases by a minimum distance. K is the number of neighbors to be analyzed in
    the decision. The new data point to classify (the query) is projected to the same
    space as the learning points, and its class is given by the most frequent class
    among its KNN from the training set.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `KNNClassifier` code is an example of using the KNN algorithm
    to classify each image pixel to the nearest color: black (0, 0, 0), white (255,
    255, 255), blue (255, 0, 0), green (0, 255, 0), or red (0, 0, 255):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember that OpenCV uses a BGR color scheme.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV provides the KNN algorithm through the `CvKNearest` class. The training
    information is added to the KNN classifier through the `bool CvKNearest::train(const
    Mat& trainData, const Mat& responses, const Mat& sampleIdx, bool isRegression,
    int maxK, bool updateBase)` function. The example creates a training set with
    five samples, (`Mat colors(5, 3, CV_32FC1)`), which represent each class (color)
    (`Mat classes(5, 1, CV_32FC1)`); these are the first two input parameters. The
    `isRegression` is parameter is a Boolean value that defines whether we want to
    perform a classification or a regression. The `maxK` value indicates the maximum
    number of neighbors that will be used in the test phase.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `updateBaseparameter` allows us to indicate whether we want to train
    a new classifier with the data or use it to update the previous training data.
    Then, the code sample performs the test phase with each pixel of the original
    image using the `float CvKNearest::find_nearest(const Mat& samples, int k, Mat*
    results=0, const float** neighbors=0, Mat* neighborResponses=0, Mat* dist=0)`
    function. The function tests the input sample, selecting the KNN, and finally
    predicts the class value for this sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can see the code output and the difference
    between the original and the result images after this KNN classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The KNN classifier](img/00054.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'KNN classification using the primary colors as classes (left: the original
    image, right: the result image)'
  prefs: []
  type: TYPE_NORMAL
- en: The Random Forest classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Random Forests are a general class of ensemble building methods that use a decision
    tree as the base classifier. The Random Forest classifier is a variation of the
    Bagging classifier (Bootstrap Aggregating). The Bagging algorithm is a method
    of classification that generates weak individual classifiers using bootstrap.
    Each classifier is trained on a random redistribution of the training set so that
    many of the original examples may be repeated in each classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'The principal difference between Bagging and Random Forest is that Bagging
    uses all the features in each tree node and Random Forest selects a random subset
    of the features. The suitable number of randomized features corresponds to the
    square root of the total number of features. For prediction, a new sample is pushed
    down the tree and it is assigned the class of the terminal (or leaf) node in the
    tree. This method is iterated over all the trees, and finally, the average vote
    of all the tree predictions is considered as the prediction result. The following
    diagram shows the Random Forest algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Random Forest classifier](img/00055.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The RF classifier
  prefs: []
  type: TYPE_NORMAL
- en: 'Random Forests are currently one of the best classifiers available, both in
    recognition power and efficiency. In our example `RFClassifier`, we use the OpenCV
    Random Forest classifier and also the OpenCV `CvMLData` class. A large amount
    of information is typically handled in machine learning problems, and for this
    reason, it is convenient to use a `.cvs` file. The `CvMLData` class is used to
    load the training set information from such a file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The dataset has been provided by the UC Irvine Machine Learning Repository,
    available at [http://archive.ics.uci.edu/ml/](http://archive.ics.uci.edu/ml/).
    For this code sample, the Iris dataset was used.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned previously, the `CvMLData` class allows you to load the dataset
    from a `.csv` file using the `read_csv` function and indicates the class column
    by the `set_response_idx` function. In this case, we use this dataset to perform
    the training and test phases. It is possible to split the dataset into two disjoint
    sets for training and test. For this, we use the `CvTrainTestSplit` struct and
    the `void CvMLData::set_train_test_split(const CvTrainTestSplit* spl)` function.
    In the `CvTrainTestSplit` struct, we indicate the percentage of samples to be
    used as the training set (0.75 percent in our case) and whether we want to mix
    the indices of the training and test samples from the dataset. The `set_train_test_split`
    function performs the split. Then, we can store each set in `Mat` with the `get_train_sample_idx()`
    and `get_test_sample_idx()`functions.
  prefs: []
  type: TYPE_NORMAL
- en: The Random Forest classifier is created using the `CvRTrees` class, and its
    parameters are defined by the `CvRTParams::CvRTParams(int max_depth, int min_sample_count,
    float regression_accuracy, bool use_surrogates, int max_categories, const float*
    priors, bool calc_var_importance, int nactive_vars, int max_num_of_trees_in_the_forest,
    float forest_accuracy, int termcrit_type)` constructor. Some of the most important
    input parameters refer to the maximum depth of the trees (`max_depth`)—in our
    sample, it has a value of 3—the number of randomized features in each node (`nactive_vars`),
    and the maximum number of trees in the forest (`max_num_of_trees_in_the_forest`).
    If we set the `nactive_vars` parameter to 0, the number of randomized features
    will be the square root of the total number of features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, once the classifier is trained with the `train` function, we can obtain
    the percentage of misclassified samples using the `float CvRTrees::calc_error(CvMLData*
    data, int type, std::vector<float>* resp=0 )` method. The parameter type allows
    you to select the source of the error: `CV_TRAIN_ERROR` (an error in the training
    samples) or `CV_TEST_ERROR` (an error in the test samples).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the training and test errors and the classifier
    responses in both the sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Random Forest classifier](img/00056.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The RF classifier sample results
  prefs: []
  type: TYPE_NORMAL
- en: SVM for classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Support Vector Machine** (**SVM**) classifier finds a discriminant function
    by maximizing the geometrical margin between the classes. Thus, the space is mapped
    in such a way that the classes are as widely separated as possible. SVM minimizes
    both the training error and the geometrical margin. Nowadays, this classifier
    is one of the best classifiers available and has been applied to many real-world
    problems. The following `SVMClassifier` sample code performs a classification
    using the SVM classifier and a dataset of 66 image objects. The dataset is divided
    into four classes: a training shoe (class 1), a cuddly toy (class 2), a plastic
    cup (class 3), and a bow (class 4). The following screenshot shows the examples
    of the four classes. A total of 56 images and 10 images were used for the training
    and the test sets, respectively. Images in the training set take the following
    name structure: `[1-14].png` corresponds to class 1, `[15-28].png` to class 2,
    `[29-42].png` to class 3, and `[43-56].png` to class 4\. On the other hand, images
    in the test set are characterized by the word unknown followed by a number, for
    example, `unknown1.png`.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The images of the four classes have been extracted from the **Amsterdam Library
    of Object Images** (**ALOI**) available at [http://aloi.science.uva.nl/](http://aloi.science.uva.nl/).
  prefs: []
  type: TYPE_NORMAL
- en: '![SVM for classification](img/00057.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Classes selected for the SVM classification example
  prefs: []
  type: TYPE_NORMAL
- en: 'The `SVMClassifier` sample code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The explanation of the code is given as follows. In this example, images are
    represented by their descriptors (see [Chapter 5](part0042_split_000.html#page
    "Chapter 5. Focusing on the Interesting 2D Features"), *Focusing on the Interesting
    2D Features*). For each image in the training set, its interest points are detected
    using an **Oriented FAST and Rotated BRIEF** (**ORB**) detector (`OrbFeatureDetector`)
    and its descriptors are computed using the **Speeded Up Robust Features** (**SURF**)
    descriptor (`SurfDescriptorExtractor`).
  prefs: []
  type: TYPE_NORMAL
- en: 'An SVM classifier is created using the `CvSVM` class and its parameters are
    set using the `CvSVMParams::CvSVMParams(int svm_type, int kernel_type, double
    degree, double gamma, double coef0, double Cvalue, double nu, double p, CvMat*
    class_weights, CvTermCriteria term_crit)` constructor. The interesting parameters
    in this constructor are the type of SVM (`svm_type`) and the type of kernel (`kernel_type`).
    The first specified parameter takes, in our case, the `CvSVM::C_SVC` value because
    an n-classification (n ![SVM for classification](img/00058.jpeg) 2) with an imperfect
    separation of the classes is needed. It also uses a C penalty value for atypical
    values. C acts, therefore, as a regularizer. The `kernel_type` parameter indicates
    the type of SVM kernel. The kernel represents the basis function required to separate
    the cases. For the SVM classifier, OpenCV includes the following kernels:'
  prefs: []
  type: TYPE_NORMAL
- en: '`CvSVM::LINEAR`: The linear kernel'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CvSVM::POLY`: The polynomial kernel'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CvSVM::RBF`: The radial basis function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CvSVM::SIGMOID`: The sigmoid kernel'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, the classifier builds an optimal linear discriminating function using
    the training set (with the `train` function). Now, it is prepared to classify
    new unlabeled samples. The test set is used for this purpose. Note that we also
    have to calculate the ORB detector and the SURF descriptors for each image in
    the test set. The result is as shown in the following screenshot, where all the
    classes have been classified correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![SVM for classification](img/00059.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The classification result using SVM
  prefs: []
  type: TYPE_NORMAL
- en: What about GPUs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CPUs seem to have reached their speed and thermal power limits. It has become
    complex and expensive to build a computer with several processors. Here is where
    GPUs come into play. **General-Purpose Computing on Graphics Processing Units**
    (**GPGPU**) is a new programming paradigm that uses the GPU to perform computations
    and enables the faster execution of programs and a reduction of power consumption.
    They include hundreds of general-purpose computing processors that can do much
    more than render graphics, especially if they are used in tasks that can be parallelized,
    which is the case with computer vision algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV includes support for the OpenCL and CUDA architectures, with the latter
    having more implemented algorithms and a better optimization. This is the reason
    why we are introducing the CUDA GPU module in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up OpenCV with CUDA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The installation guide presented in [Chapter 1](part0014_split_000.html#page
    "Chapter 1. Getting Started"), *Getting Started*, needs a few additional steps
    in order to include the GPU module. We assume that the computer in which OpenCV
    is going to be installed already has the software detailed in that guide.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are new requirements to be satisfied in order to compile OpenCV with
    CUDA on Windows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CUDA-capable GPU**: This is the main requirement. Note that CUDA is developed
    by NVIDIA and, consequently, it is only compatible with NVIDIA graphic cards.
    Besides, the model of the card has to be listed at [http://developer.nvidia.com/cuda-gpus](http://developer.nvidia.com/cuda-gpus).
    The so-called **Compute Capability** (**CC**) can also be checked on this website
    as it will be needed later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Microsoft Visual Studio**: CUDA is compatible only with this Microsoft compiler.
    It is possible to install the Visual Studio Express edition, which is free. Note
    that Visual Studio 2013 is still not compatible with CUDA at the time of writing,
    so we are using Visual Studio 2012 in this book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NVIDIA CUDA Toolkit**: This includes a compiler for GPUs, libraries, tools,
    and documentation. This toolkit is available at [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Qt library for Visual C++ compiler**: In [Chapter 1](part0014_split_000.html#page
    "Chapter 1. Getting Started"), *Getting Started*, the MinGW binaries of the Qt
    library were installed, but they are not compatible with the Visual C++ compiler.
    A compatible version can be downloaded using the package manager by means of the
    `MaintenanceTool` application located in `C:\Qt`. A good choice is the `msvc2012`
    32-bit component, as can be seen in the following screenshot. It is also necessary
    to update the `Path` environment with the new location (for example, in our local
    system, it is `C:\Qt\5.2.1\msvc2012\bin`). The Qt library is included in the compilation
    to take advantage of its user interface features.![Setting up OpenCV with CUDA](img/00060.jpeg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Downloading a new version of the Qt libraries
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Configuring the OpenCV build
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The build configuration with CMake differs in some points from the typical
    one explained in the first chapter. These differences are explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: When you select the generator for the project, you have to choose the Visual
    Studio compiler version that corresponds to the installed environment in the machine.
    In our case, Visual Studio 11 is the correct compiler, as it corresponds to the
    version of the compiler included in Visual Studio 2012\. The following screenshot
    shows this selection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the selection of build options, we have to focus on the CUDA-related ones.
    If the installation of the CUDA toolkit was correct, CMake should automatically
    detect its location and activate the `WITH_CUDA` option. In addition, the installation
    path of the toolkit is shown through `CUDA_TOOLKIT_ROOT_DIR`. Another interesting
    option is `CUDA_ARCH_BIN` because the compilation time can be significantly reduced
    if we just select the corresponding version of our GPU; otherwise, it will compile
    the code for all the architectures. As mentioned previously, the version can be
    checked at [http://developer.nvidia.com/cuda-gpus](http://developer.nvidia.com/cuda-gpus).
    The following screenshot shows the options set in our build configuration:![Configuring
    the OpenCV build](img/00061.jpeg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The CMake build configuration
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Building and installing the library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CMake generates several Visual Studio projects in the target directory, `ALL_BUILD`
    being the essential one. Once it is opened in Visual Studio, we can choose the
    build configuration (Debug or Release) as well as the architecture (Win32 or Win64).
    The compilation starts by pressing *F7* or by clicking on **Build Solution**.
    After the compilation has finished, it is recommended that you open and build
    the `INSTALL` project as it generates an install directory with all the necessary
    files.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `Path` system needs to be updated with the location of the newly
    generated binaries. It is important to remove the previous location from the `Path`
    variable and have only one version of the binaries in it.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Qt Creator should now find two compilers and two Qt versions: one for Visual
    C++ and one for MingGW. We have to choose the correct kit depending on the developed
    application when creating a new project. It is also possible to change the configuration
    of an existing project as kits are manageable.'
  prefs: []
  type: TYPE_NORMAL
- en: A quick recipe for setting up OpenCV with CUDA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The installation process can be summarized in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Install Microsoft Visual Studio Express 2012.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download and install the NVIDIA CUDA Toolkit (available at [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the binaries for the Visual C++ compiler to the Qt installation and update
    the `Path` system with the new location (for example, `C:\Qt\5.2.1\msvc2012\bin`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure the OpenCV build with CMake. Set the `WITH_CUDA`, `CUDA_ARCH_BIN`,
    `WITH_QT`, and `BUILD_EXAMPLES` options.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `ALL_BUILD` Visual Studio project and build it. Do the same operation
    with the `INSTALL` project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the `Path` environment variable to update the OpenCV bin directory (for
    example, `C:\opencv-buildCudaQt\install\x86\vc11\bin`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our first GPU-based program
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we show two versions of the same program: one version uses
    the CPU to perform computations, and the other version uses the GPU. These two
    examples are called `edgesCPU` and `edgesGPU`, respectively, and allow us to point
    out the differences when using the `GPU` module in OpenCV.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `edgesCPU` example is presented in the first place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the `edgesGPU` example is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The explanation of the code is given as follows. There are several differences
    in the previous examples, although they ultimately obtain the same result, as
    shown in the following screenshot. A new header file is added as the new data
    type and different implementations of the algorithms are used. `#include <opencv2/gpu/gpu.hpp>`
    contains the `GpuMat` data type, which is the basic container that stores images
    in the GPU memory. It also includes the specific GPU versions of the filter algorithms
    used in the second example.
  prefs: []
  type: TYPE_NORMAL
- en: An important consideration is that we need to transfer the images between the
    CPU and the GPU. This is achieved with the `g_orig.upload(orig)` and `g_gray.download(dst)`
    methods. Once the image is uploaded to the GPU, we can apply different operations
    to it that are executed on the GPU. In order to distinguish the version of the
    algorithm that needs to run, the `gpu` namespace is used as in `gpu::bilateralFilter`,
    `gpu::cvtColor`, and `gpu::Canny`. After the filters have been applied, the image
    is copied to the CPU memory again and displayed.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding performance, the CPU version runs in 297 milliseconds, whereas the
    GPU version runs in just 18 milliseconds. In other words, the GPU version runs
    16.5x faster.
  prefs: []
  type: TYPE_NORMAL
- en: '![Our first GPU-based program](img/00062.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The output of the edgesCPU and edgesGPU examples
  prefs: []
  type: TYPE_NORMAL
- en: Going real time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the main advantages of using the GPU to perform computations in images
    is that they are much faster. This increase in speed allows you to run heavy computational
    algorithms in real-time applications, such as stereo vision, pedestrian detection,
    or dense optical flow. In the next `matchTemplateGPU` example, we show an application
    that matches a template in a video sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The explanation of the code is given as follows. As detailed in [Chapter 5](part0042_split_000.html#page
    "Chapter 5. Focusing on the Interesting 2D Features"), *Focusing on the Interesting
    2D Features*, features can be used to find the correspondence between two images.
    The template image, which is searched afterwards within every frame, is processed
    in the first place using the GPU version of SURF (`gpu::SURF_GPU surf;`) to detect
    interest points and extract descriptors. This is accomplished by running `surf(img_template,gpu::GpuMat(),keypoints_template,
    descriptors_template);`. The same process is performed for every frame taken from
    the video sequence. In order to match the descriptors of both images, a GPU version
    of the BruteForce matcher is also created with `gpu::BFMatcher_GPU matcher(NORM_L2);`.
    An extra step is needed due to the fact that interest points and descriptors are
    stored in the GPU memory, and they need to be downloaded before we can show them.
    That''s why `surf.downloadKeypoints(keypoints, keypoints);` and `surf.downloadDescriptors(descriptors,
    descriptors);` are executed. The following screenshot shows the example running:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Going real time](img/00063.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Template matching using a webcam
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The principal motivation for choosing GPU programming is performance. Therefore,
    this example includes time measurements to compare the speedups obtained with
    respect to the CPU version. Specifically, time is saved at the beginning of the
    main loop of the program by means of the `getTickCount()` method. At the end of
    this loop, the same method is used as well as `getTickFrequency`, which helps
    to calculate the FPS of the current frame. The time elapsed in each frame is accumulated,
    and at the end of the program, the mean is computed. The previous example has
    an average latency of 15 FPS, whereas the same example using CPU data types and
    algorithms achieves a mere 0.5 FPS. Both examples have been tested on the same
    hardware: a PC equipped with an i5-4570 processor and an NVIDIA GeForce GTX 750
    graphics card. Obviously, a speed increment of 30x is significant, especially
    when we just need to change a few lines of code.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we have covered two advanced modules of OpenCV: machine learning
    and GPU. Machine learning has the capability to learn computers to make decisions.
    For this, a classifier is trained and validated. This chapter provides three classification
    samples: KNN classifier, Random Forest using a `.cvs` database, and SVM using
    an image database. The chapter also addresses the use of OpenCV with CUDA. GPUs
    have a growing role in intensive tasks because they can offload the CPU and run
    parallel tasks such as those encountered in computer vision algorithms. Several
    GPU examples have been provided: GPU module installation, a basic first GPU program,
    and real-time template matching.'
  prefs: []
  type: TYPE_NORMAL
- en: What else?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The GPU module now covers most of the functionalities of OpenCV; so, it is recommended
    that you explore the library and check which algorithms are available. In addition,
    the `performance_gpu` program can be found at `[opencv_build]/install/x86/vc11/samples/gpu]`,
    which shows the speedups of many OpenCV algorithms when using the GPU version.
  prefs: []
  type: TYPE_NORMAL
