<html><head></head><body>
		<div id="_idContainer553">
			<h1 id="_idParaDest-139"><a id="_idTextAnchor150"/>Chapter 10: Novel Trends on Graphs</h1>
			<p>In the previous chapters, we described different supervised and unsupervised algorithms that can be used in a wide range of problems concerning graph data structures. However, the scientific literature on graph machine learning is vast and constantly evolving and every month, new algorithms are published. In this chapter, we will provide a high-level description of some new techniques and applications concerning graph machine learning. </p>
			<p>This chapter will be divided into two main parts – advanced algorithms and applications. The first part is mainly devoted to describing some interesting new techniques in the graph machine learning domain. You will learn about some data sampling and data augmentation techniques for graphs based on random walk and generative neural networks. Then, you will learn about topological data analysis, a relatively novel tool for analyzing high-dimensional data. In the second part, we will provide you with some interesting applications of graph machine learning in different domains, ranging from biology to geometrical analysis. After reading this chapter, you will be aware of how looking at the relationships between data opened the door to novel intriguing solutions.</p>
			<p>Specifically, we will cover the following topics in this chapter:</p>
			<ul>
				<li>Learning about data augmentation for graphs</li>
				<li>Learning about topological data analysis</li>
				<li>Applying graph theory in new domains</li>
			</ul>
			<p>Before we get started, let's ensure we have the prerequisites mentioned in the following section. </p>
			<h1 id="_idParaDest-140"><a id="_idTextAnchor151"/>Technical requirements </h1>
			<p>We will be using Python 3.6.9 for all our exercises. The following is the list of Python libraries that you must install for this chapter using <strong class="source-inline">pip</strong>. For example, you can run <strong class="source-inline">pip install networkx==2.5</strong> on the command line, and so on:</p>
			<p class="source-code">networkx==2.5 </p>
			<p class="source-code">littleballoffur==2.1.8</p>
			<p>All the code files relevant to this chapter are available at <strong class="source-inline">URL TO BE DECIDED</strong>.</p>
			<h1 id="_idParaDest-141"><a id="_idTextAnchor152"/>Learning about data augmentation for graphs</h1>
			<p>In <a href="B16069_08_Final_JM_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 8</em></a>, <em class="italic">Graph Analysis for Credit Card Transactions</em>, we described how graph machine learning can be used to study and automatically detect fraudulent credit card transactions. While <a id="_idIndexMarker940"/>describing the use case, we faced two main obstacles:</p>
			<ul>
				<li>There were too many nodes in the original dataset to handle. As a consequence, the computational cost was too high to be computed. This is why we selected only 20% of the dataset.</li>
				<li>From the original dataset, we saw that less than 1% of the data had been labeled as fraudulent transactions, while the other 99% of the dataset contained genuine transactions. This is why, during the edge classification task, we randomly subsampled the dataset. </li>
			</ul>
			<p>The techniques we used to solve these two obstacles, in general, are not optimal. For graph data, more complex and innovative techniques are needed to solve the task. Moreover, when datasets are highly unbalanced, as we mentioned in <a href="B16069_08_Final_JM_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 8</em></a>, <em class="italic">Graph Analysis for Credit Card Transactions</em>, we can solve this using anomaly detection algorithms.</p>
			<p>In this section, we will provide a description of some techniques and algorithms we can use to solve the aforementioned problems. We will start by describing the graph sampling problem and we will finish by describing some graph data augmentation techniques. We will share some useful references and Python libraries for both of these.</p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor153"/>Sampling strategies</h2>
			<p>In <a href="B16069_08_Final_JM_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 8</em></a>, <em class="italic">Graph Analysis for Credit Card Transactions</em>, to perform the edge classification task, we <a id="_idIndexMarker941"/>started our analysis by sampling only 20% of the whole dataset. Unfortunately, this strategy, in general, it is not an optimal one. Indeed, the subset of nodes that are selected with this simple strategy could generate a subgraph that is not representative of the topology of the whole graph. Due to this, we need to define a strategy for building a subgraph of a given graph by sampling the right nodes. The process of building a (small) subgraph from a given (large) graph by <a id="_idIndexMarker942"/>minimizing the loss of <em class="italic">topological</em> information is known as <strong class="bold">graph sampling</strong>. </p>
			<p>A good starting point so that we have a full overview of the graph sampling algorithm is available in the paper <em class="italic">Little Ball of Fur: A Python Library for Graph Sampling</em>, which can be downloaded from the following URL: <a href="https://arxiv.org/pdf/2006.04311.pdf">https://arxiv.org/pdf/2006.04311.pdf</a>. Their Python implementation of using the <strong class="source-inline">networkx</strong> library is available at the following URL: <a href="https://github.com/benedekrozemberczki/littleballoffur">https://github.com/benedekrozemberczki/littleballoffur</a>. The algorithms that are available in this library can be divided into nodes and edges sampling <a id="_idIndexMarker943"/>algorithms. These algorithms sample the nodes and edges in the graph bundling, respectively. As a result, we get a node- or edge-induced subgraph from the original graph. We will leave you to perform the analysis proposed in <a href="B16069_08_Final_JM_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 8</em></a>, <em class="italic">Graph Analysis for Credit Card Transactions</em>, using the different graph sampling strategies available in the <strong class="source-inline">littleballoffur</strong> Python package.</p>
			<h2 id="_idParaDest-143"><a id="_idTextAnchor154"/>Exploring data augmentation techniques</h2>
			<p>Data augmentation is a <a id="_idIndexMarker944"/>common technique when we're dealing with unbalanced data. In unbalanced problems, we usually have labeled data from two or more classes. Only a few samples are available for one or more classes in the dataset. A class that <a id="_idIndexMarker945"/>contains a few samples is also known as a <em class="italic">minority</em> class, while a class that contains a large number of samples is <a id="_idIndexMarker946"/>known as a <em class="italic">majority</em> class. For instance, in the use case described in <a href="B16069_08_Final_JM_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 8</em></a>, <em class="italic">Graph Analysis for Credit Card Transactions</em>, we had a clear example of an unbalanced dataset. In the input dataset, only 1% of all the available transactions were marked as fraudulent (the minority class), while the other 99% were genuine transactions (the majority class). When dealing with <em class="italic">classical</em> datasets, the problem is usually solved using random down or up sampling or using data generation algorithms <a id="_idIndexMarker947"/>such as <em class="italic">SMOTE</em>. However, for graph data, this process may not be as easy since generating new nodes or graphs is not a straightforward process. This is due to the presence of complex topological relations. In the last decade, a large range of data augmentation graph algorithms have been made. Here, we will introduce two of the latest available algorithms, namely <em class="italic">GAug</em> and <em class="italic">GRAN</em>. </p>
			<p>The GAug algorithm is a node-based data augmentation algorithm. It is described in the paper <em class="italic">Data Augmentation for Graph Neural Networks</em>, which is available at the following URL: <a href="https://arxiv.org/pdf/2006.06830.pdf">https://arxiv.org/pdf/2006.06830.pdf</a>. The Python code for this library is available at the following URL: <a href="https://github.com/zhao-tong/GAug">https://github.com/zhao-tong/GAug</a>. This algorithm can be useful for use cases where edge or node classification is needed, as in the use case provided in <a href="B16069_08_Final_JM_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 8</em></a>, <em class="italic">Graph Analysis for Credit Card Transactions</em>, where the nodes belonging to the <a id="_idIndexMarker948"/>minority class can be augmented using the algorithm. As an exercise, you can extend on the analysis we proposed in <a href="B16069_08_Final_JM_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 8</em></a>, <em class="italic">Graph Analysis for Credit Card Transactions</em>, using the GAug algorithm.</p>
			<p>The GRAN algorithm is a <a id="_idIndexMarker949"/>graph-based data augmentation algorithm. It is described in the paper <em class="italic">Efficient Graph Generation with Graph Recurrent Attention Networks</em>, which is available at the following URL: <a href="https://arxiv.org/pdf/1910.00760.pdf">https://arxiv.org/pdf/1910.00760.pdf</a>. The Python code for the library is available at the following URL: <a href="https://github.com/lrjconan/GRAN">https://github.com/lrjconan/GRAN</a>. This algorithm is useful for generating new graphs when we're dealing with graph classification/clustering problems. For example, if we're dealing with an unbalanced graph classification problem, it could be useful to create a balance step for the dataset using the GRAN algorithm and then perform the classification task. </p>
			<h1 id="_idParaDest-144"><a id="_idTextAnchor155"/>Learning about topological data analysis</h1>
			<p><strong class="bold">Topological Data Analysis </strong>(<strong class="bold">TDA</strong>) is a rather novel <a id="_idIndexMarker950"/>technique that's used to extract features that quantify the <em class="italic">shape of the data</em>. The idea of this approach is that by observing how datapoints are organized in a certain space, we can reveal some important information about the process that generated it.</p>
			<p>The main tool for <a id="_idIndexMarker951"/>applying TDA is <strong class="bold">persistent homology</strong>. The math behind this method is quite advanced, so let's introduce this concept through an example. Suppose you have a set of data points distributed on a space, and let's suppose you are "observing" them over time. Points are static (they do not move across the space); thus, you will observe those independent points forever. However, let's imagine we can create associations between these data points by connecting them together through some well-defined rules. In particular, let's imagine a sphere expanding from these points through time. Each point will have its own expanding sphere and, once two spheres collide, an "edge" can be placed by these two points. This can be exemplified with the following diagram:</p>
			<div>
				<div id="_idContainer548" class="IMG---Figure">
					<img src="image/B16069_10_01.jpg" alt="Figure 10.1 – Example of how relationships between points can be created&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.1 – Example of how relationships between points can be created</p>
			<p>The more spheres that collide, the more <a id="_idIndexMarker952"/>associations that will be created, and the more edges that will be placed. This happens when multiple spheres intersect more complex geometrical structures such as triangles, tetrahedrons, and so on appear:</p>
			<div>
				<div id="_idContainer549" class="IMG---Figure">
					<img src="image/B16069_10_02.jpg" alt="Figure 10.2 – Example of how connections among points generate geometrical structures&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.2 – Example of how connections among points generate geometrical structures</p>
			<p>When a new geometrical structure appears, we can note its "<em class="italic">birth</em>" time. On the other hand, when an existing geometrical structure disappears (for example, it becomes part of a more complex geometrical structure), we can note its "<em class="italic">death</em>" time. The survival time (time between birth and death) of each geometrical structure that's observed during the simulation can be used as a new feature for analyzing the original dataset.</p>
			<p>We can also <a id="_idIndexMarker953"/>define the so-called <strong class="bold">persistent diagram</strong> by placing each structure's corresponding pair (birth, death) on a two-axis system. Points closer to the diagonal normally reflect noise, whereas points distant from the diagonal represent persisting features. An example of a persistence diagram is as follows. Notice that we described the whole process by using expanding "<em class="italic">spheres</em>" as an example. In practice, we can change the dimension of this expanding shape (for instance, using 2D circles), thus producing a set of features for each dimension (commonly indicated using the letter <em class="italic">H</em>):</p>
			<div>
				<div id="_idContainer550" class="IMG---Figure">
					<img src="image/B16069_10_03.jpg" alt="Figure 10.3 – Example of a 2D point cloud (right) and its corresponding persistence diagram (left)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.3 – Example of a 2D point cloud (right) and its corresponding persistence diagram (left)</p>
			<p>A good Python library <a id="_idIndexMarker954"/>for performing topological data analysis is <strong class="source-inline">giotto-tda</strong>, which is available at the following URL: <a href="https://github.com/giotto-ai/giotto-tda">https://github.com/giotto-ai/giotto-tda</a>. Using the giotto-tda library, it is easy to build the simplicial complex and its relative persistence diagram, as shown in the preceding image.</p>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor156"/>Topological machine learning</h2>
			<p>Now that we know the <a id="_idIndexMarker955"/>fundamentals behind TDA, let's see how it can be used for machine learning. By providing machine learning algorithms with topological data (such as persistent features), we can capture patterns that might be missed by other traditional approaches.</p>
			<p>In the previous section, we saw that persistence diagrams are useful for describing data. Nevertheless, using them to feed machine learning algorithms (such as <strong class="source-inline">RandomForest</strong>) is not a good choice. For instance, different persistent diagrams may have different numbers of points, and basic algebraic operations would not be well defined.</p>
			<p>One common way to overcome such a limitation is to transform diagrams into more suitable representations. Embeddings or kernel methods can be used to obtain a "<em class="italic">vectorized</em>" representation of the diagrams. Moreover, advanced representation methods such as <em class="italic">persistence images</em>, <em class="italic">persistence landscapes</em>, and <em class="italic">B</em><em class="italic">etti curves</em>, among others, have been shown to be very useful in practical applications. Persistent images (<em class="italic">Figure 10.4</em>), for instance, are bi-dimensional representations of persistence diagrams that can easily be fed into convolutional neural networks.</p>
			<p>Several possibilities <a id="_idIndexMarker956"/>arise out of this theory, and there is still a connection between the findings and deep learning. Several new ideas are being proposed, making the subject both hot and fascinating:</p>
			<div>
				<div id="_idContainer551" class="IMG---Figure">
					<img src="image/B16069_10_04.jpg" alt="Figure 10.4 – Example of a persistent images&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.4 – Example of a persistent images</p>
			<p>Topological data analysis is a rapidly growing field, especially since it can be combined with machine learning techniques. Several scientific papers are published on this topic every year and we expect novel exciting applications in the near future.</p>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor157"/>Applying graph theory in new domains</h1>
			<p>In recent years, due to there <a id="_idIndexMarker957"/>being a more solid theoretical understanding of graph machine learning, as well as an increase in available storage space and computational power, we can identify a number of domains in which such learning theories are spreading. With a bit of imagination, you can start looking at the surrounding world as a set of "<em class="italic">nodes</em>" and "<em class="italic">links</em>." Our work or study place, the technological devices we use every day, and even our brain can be represented as networks. In this section, we will look at some examples of how graph theory (and graph machine learning) has been <a id="_idIndexMarker958"/>applied to, apparently, unrelated domains.</p>
			<h2 id="_idParaDest-147"><a id="_idTextAnchor158"/>Graph machine learning and neuroscience</h2>
			<p>The study of the <a id="_idIndexMarker959"/>brain by means of graph theory is a prosperous and expanding field. Several ways of representing the <em class="italic">brain as a network</em> have been investigated, with the aim of understanding how different parts of the brain (nodes) are <em class="italic">functionally</em> or <em class="italic">structurally</em> connected to each other.</p>
			<p>By means of medical <a id="_idIndexMarker960"/>techniques such as <strong class="bold">Magnetic Resonance Imaging</strong> (<strong class="bold">MRI</strong>), a three-dimensional representation of the brain can be obtained. Such an image can be processed by different kinds of algorithms to obtain distinct partitions of the brain (parcellation).  </p>
			<p>There are different ways we can define connections between those regions, depending on whether we are interested in analyzing their functional or structural connectivity:</p>
			<ul>
				<li><strong class="bold">Functional Magnetic Resonance Imaging</strong> (<strong class="bold">fMRI</strong>) is a <a id="_idIndexMarker961"/>technique that's used to measure whether a part of the brain is "active" or not. Specifically, it measures the <strong class="bold">blood-oxygen-level-dependent</strong> (<strong class="bold">BOLD</strong>) signal of <a id="_idIndexMarker962"/>each region (a signal indicating the variation of the level of blood and oxygen at a certain time). Then, the <em class="italic">Pearson correlation</em> between the BOLD series of two brain regions of interest can be computed. High correlation means that the two parts are "functionally connected," and an edge can be placed between them. An interesting paper on graphically analyzing fMRI data is <em class="italic">Graph-based network analysis of resting-state functional MRI</em>, which is available at <a href="https://www.frontiersin.org/articles/10.3389/fnsys.2010.00016/full">https://www.frontiersin.org/articles/10.3389/fnsys.2010.00016/full</a>.</li>
				<li>On the other hand, by using advanced MRI techniques such as <strong class="bold">Diffusion Tensor Imaging</strong> (<strong class="bold">DTI</strong>), we can <a id="_idIndexMarker963"/>also measure the strength of the white matter fiber bundles physically connecting two brain regions of interest. Thus, we can obtain a graph representing the structural connectivity of the brain. A paper where graphs neural networks are used in combination with graphs generated from DTI data is called <em class="italic">Multiple Sclerosis Clinical Profiles via Graph Convolutional Neural Networks</em> and is available at<em class="italic"> </em><a href="https://www.frontiersin.org/articles/10.3389/fnins.2019.00594/full">https://www.frontiersin.org/articles/10.3389/fnins.2019.00594/full</a>.</li>
				<li>Functional and structural <a id="_idIndexMarker964"/>connectivity can be analyzed using graph theory. There are several studies that enhance significant alterations of such networks related to neurodegenerative diseases, such as Alzheimer's, multiple sclerosis, and Parkinson's, among others.</li>
			</ul>
			<p>The final result is a graph describing the connection between the different brain regions, as shown here:</p>
			<div>
				<div id="_idContainer552" class="IMG---Figure">
					<img src="image/B16069_10_05.jpg" alt="Figure 10.5 – Connection between brain regions as a graph&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.5 – Connection between brain regions as a graph</p>
			<p>Here, we can see how different brain regions can be seen as nodes of a graph, while the connections between those regions are edges.</p>
			<p>Graph machine learning has been shown to be very useful for this kind of analysis. Different studies have been conducted to automatically diagnose a particular pathology based on the brain network, thus predicting the evolution of the network (for example, identifying potentially vulnerable regions that are likely to be affected by the pathology in the future).</p>
			<p>Network neuroscience is a <a id="_idIndexMarker965"/>promising field, and, in the future, more and more insight will be collected from those networks so that we can understand pathological alterations and predict a disease's evolution.</p>
			<h2 id="_idParaDest-148"><a id="_idTextAnchor159"/>Graph theory and chemistry and biology</h2>
			<p>Graph machine learning can be applied to <a id="_idIndexMarker966"/>chemistry. For example, graphs provide a natural method for <a id="_idIndexMarker967"/>describing <strong class="bold">molecular structures</strong> by treating atoms as the nodes of a graph and bonds as their connections. Such methods have been used to investigate different aspects of chemical systems, including representing reactions, and learning chemical fingerprints (indicating the presence or absence of chemical features or substructures), among others.</p>
			<p>Several applications can be also found in <a id="_idIndexMarker968"/>biology, where many different elements can be represented as a graph. <strong class="bold">Protein-protein interactions</strong> (<strong class="bold">PPI</strong>), for example, is one of the most widely <a id="_idIndexMarker969"/>studied topics. Here, a graph is constructed, where nodes represent protein and edges represent their interaction. Such a method allows us to exploit the structural information of PPI networks, which has proved to be informative in PPI prediction.</p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor160"/>Graph machine learning and computer vision</h2>
			<p>The rise of deep <a id="_idIndexMarker970"/>learning, especially <strong class="bold">convolutional neural network</strong> (<strong class="bold">CNN</strong>) techniques, has <a id="_idIndexMarker971"/>achieved amazing results in computer vision research. For a wide range of tasks, such as <a id="_idIndexMarker972"/>image classification, object detection, and semantic segmentation, CNNs can be considered as the state-of-the-art. However, recently, central challenges in computer vision have started to be addressed using graph machine <a id="_idIndexMarker973"/>learning techniques – <strong class="bold">geometric deep learning</strong> in particular. As we have learned throughout this book, there are fundamental differences between the 2D Euclidean domain in which images are represented and more complex objects such as <a id="_idIndexMarker974"/>3D shapes and point clouds. Restoring <a id="_idIndexMarker975"/>the world's 3D geometry from 2D and 3D visual data, scene understanding, stereo matching, and depth estimation are only a few examples of what can be done.</p>
			<h3>Image classification and scene understanding</h3>
			<p>Image classification, one of the most <a id="_idIndexMarker976"/>widely studied tasks in computer vision, nowadays dominated by CNN-based algorithms, has started to be addressed from a different perspective. Graph neural network models have shown attractive results, especially when huge amounts of labeled data is not available. In particular, there is a trend in combining these models with <em class="italic">zero-shot and few-shot learning techniques</em>. Here, the goal is to classify classes that the model has never seen during training. For instance, this can be achieved by exploiting the knowledge of how the unseen object is "semantically" related to the seen ones.</p>
			<p>Similar approaches have been <a id="_idIndexMarker977"/>also used for scene understanding. Using a relational graph between detected objects in a scene provides an interpretable structured representation of the image. This can be used to support high-level reasoning for various tasks, including captioning and visual question answering, among others.</p>
			<h3>Shape analysis</h3>
			<p>Differently from images, which are <a id="_idIndexMarker978"/>represented by a bi-dimensional grid of pixels, there are several methods for representing 3D shapes, such as <em class="italic">multi-view images</em>, <em class="italic">depth maps</em>, <em class="italic">voxels</em>, <em class="italic">point clouds</em>, <em class="italic">meshes</em>, and <em class="italic">implicit surfaces</em>, among others. Nevertheless, when applying machine and deep learning algorithms, such representations can be exploited to learn specific geometric features, which can be useful for designing a better analysis.</p>
			<p>In this context, geometric deep learning techniques have shown promising results. For instance, GNN techniques have been successfully applied for finding correspondence between deformable shapes, a classical problem that leads to several applications, including texture animation and mapping, as well as <a id="_idIndexMarker979"/>scene understanding. For those of you who are interested, some good resources to help you understand this application of graph machine learning are available at <a href="https://arxiv.org/pdf/1611.08097.pdf">https://arxiv.org/pdf/1611.08097.pdf</a> and <a href="http://geometricdeeplearning.com/">http://geometricdeeplearning.com/</a>.</p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor161"/>Recommendation systems</h2>
			<p>Another interesting application of <a id="_idIndexMarker980"/>graph machine learning is in recommendation systems, which we can use to predict the "rating" or the "preference" that a user would assign to an item. In <a href="B16069_06_Final_JM_ePub.xhtml#_idTextAnchor100"><em class="italic">Chapter 6</em></a>, <em class="italic">Social Network Graphs</em>, we provided an example of how link prediction can be used to build automatic algorithms that provide recommendations to a given user and/or customer. In the paper <em class="italic">Graph Neural Networks in Recommender Systems: A Survey</em>, available at <a href="https://arxiv.org/pdf/2011.02260.pdf">https://arxiv.org/pdf/2011.02260.pdf</a>, the authors provide an extensive survey of graph machine learning that's been applied to build recommendation systems. More specifically, the authors describe different graph machine learning algorithms and their applications.</p>
			<h1 id="_idParaDest-151"><a id="_idTextAnchor162"/>Summary</h1>
			<p>In this chapter, we provided a high-level overview of some emerging graph machine learning algorithms and their applications for new domains. At the beginning of this chapter, we described, using the example provided in <a href="B16069_08_Final_JM_ePub.xhtml#_idTextAnchor129"><em class="italic">Chapter 8</em></a>, <em class="italic">Graph Analysis for Credit Card Transactions</em>, some sampling and augmentation algorithms for graph data. We provided some Python libraries that can be used to deal with graph sampling and graph data augmentation tasks.</p>
			<p>We continued by providing a general description of topological data analysis and how this technique has recently been used in different domains.</p>
			<p>Finally, we provided several descriptions of new application domains, such as neuroscience chemistry, and biology. We also described how machine learning algorithms can also be used to solve other tasks, such as image classification, shape analysis, and recommendation systems.</p>
			<p>This is it! In this book, we provided an overview of the most important graph machine learning techniques and algorithms. You should now be able to deal with graph data and build machine learning algorithms. We hope that you are now in possession of more tools in your toolkit and that you will use them to develop exciting applications. We also invite you to check the references we provided in this book and to address the challenges we proposed in the different chapters.</p>
			<p>The world of graph machine learning is fascinating and rapidly evolving. New research papers are published every day with incredible findings. As usual, a continuous review of the scientific literature is the best way to discover new algorithms, and arXiv (<a href="https://arxiv.org/">https://arxiv.org/</a>) is the best place to search for freely available scientific papers.</p>
		</div>
	</body></html>