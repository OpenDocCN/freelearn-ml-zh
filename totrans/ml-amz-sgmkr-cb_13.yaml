- en: '*Chapter 10*: Recommender Systems'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn about what recommender systems are, discuss their
    various types, and work through a **DataRobot** implementation of a content-based
    recommender system. Within this chapter, **recommender system**, **recommendation
    system**, **recommender engines**, and **recommendation engines** are used interchangeably.
  prefs: []
  type: TYPE_NORMAL
- en: In their simplest form, recommender systems suggest potentially relevant items
    to users or buyers. In today's commercial environment, businesses tend to have
    numerous items, products, or services for sale, making it more challenging for
    users or buyers to connect with their desired products or services. This chapter
    explains the ubiquity of recommendation engines in the current business space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although this book is not the place to cover every aspect of recommendation
    systems, we will discuss how to utilize DataRobot to build and (make predictions
    from) recommendation engines and present a conceptual overview of these systems,
    as well as a brief discussion of their types. Thus, by the end of this chapter,
    you will learn how to utilize DataRobot to build a content-based recommendation
    engine. The main topics in this chapter include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A conceptual introduction to recommender systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approaches to building recommender systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining and setting up recommender systems in DataRobot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building recommender systems in DataRobot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making recommender system predictions with DataRobot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most parts of this chapter require access to the DataRobot software. The code
    example is based on a relatively small dataset, Book-Crossing, consisting of three
    tables, whose manipulation was carried out with **Jupyter Notebook**.
  prefs: []
  type: TYPE_NORMAL
- en: Check out the following video to see the Code in Action at [https://bit.ly/3HxcNUL](https://bit.ly/3HxcNUL).
  prefs: []
  type: TYPE_NORMAL
- en: Book-Crossing dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The example used to illustrate the use of DataRobot in building recommendation
    systems is based on the Book-Crossing dataset by Cai-Nicolas Ziegler and colleagues.
    This dataset was accessed at [http://www2.informatik.uni-freiburg.de/~cziegler/BX/](http://www2.informatik.uni-freiburg.de/~cziegler/BX/).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Before using this dataset, the authors of this book have informed the owner
    of the dataset about its use in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, Georg Lausen (2005).
    *Improving Recommendation Lists Through Topic Diversification. Proceedings of
    the 14th International World Wide Web Conference (WWW '05)*. May 10 – 14, 2005,
    Chiba, Japan.
  prefs: []
  type: TYPE_NORMAL
- en: The data was collected during a four-week collection of the Book-Crossing community
    between August and September 2004\. The subsequent three tables, provided in CSV
    format, make up this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '`User-ID` presented as integers. Also provided are the users'' `Location` and
    `Age` values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ISBM`, `Book-Title`, `Book-Author`, `Year-Of-Publication`, `Publisher`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Book-Rating` value is either implicit as `0` or explicit between `1` and `10`
    (the higher the number, the better the rating). However, within the context of
    this project, we will focus solely on ratings that are explicit for the model
    development. The table also includes the `User-ID` and `ISBN` values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A conceptual introduction to recommender systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Businesses have a long-standing history of recommending their products or services
    to customers. For instance, walk into a bookshop and you are likely to see a list
    of popular books bought by other customers. This is a simple kind of recommendation
    system, as it gives buyers a snapshot of potential products to purchase.
  prefs: []
  type: TYPE_NORMAL
- en: In a bid to win in the digital economy, businesses are becoming increasingly
    customer-centric. **Customer centricity** implies that companies aim to put the
    needs of the customer first. Still, with the needs of customers being as diverse
    as the customers themselves, businesses need to take a unique approach in putting
    forward their products. This explains, in part, the failings of **popularity-based
    recommendation systems**, as they fail to consider the unique profiles of buyers.
    As such, with growing digitalization, increased business offerings, and a growing
    diversity of customers' needs, this approach is unlikely to win.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, data science tools can offer a number of approaches to make recommender
    systems more intelligent by considering the needs of the buyers in a variety of
    ways.
  prefs: []
  type: TYPE_NORMAL
- en: In presenting the different types of recommender systems, we will continue to
    use the bookshop example.
  prefs: []
  type: TYPE_NORMAL
- en: First, the **item-based collaborative filtering** approach to recommendation
    systems makes product suggestions to book buyers based on the buyer's product
    purchase history and how those *products* relate to others. As such, if an individual
    bought *Book A*, and *Book A* is linked to *Book B*, then *Book B* is suggested.
    The second approach, **user-based collaborative filtering**, considers similarities
    between *buyers* when making suggestions. As such, if *Buyer A* is similar to
    *Buyer B*, and *Buyer A* buys *Book C*, then *Book C* would be recommended to
    *Buyer B*. The third approach, **content-based recommendation**, takes into account
    both the book and user characteristics in making suggestions. Finally, the **hybrid
    system** approach uses a combination of collaborative-based and content-based
    methods in making recommendations. It is easy to see that both of these methods
    come with strengths and weaknesses. We will now take a deeper look at these approaches
    and how DataRobot can be used to build a content-based recommendation system.
  prefs: []
  type: TYPE_NORMAL
- en: Approaches to building recommender systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recommender systems aim to suggest relevant products to buyers. Because of
    their ability to consider the uniqueness of buyers, intelligent recommender engines
    have generated billions of dollars for businesses and helped buyers find relevant
    products. They represent a win-win for both consumers and businesses. Various
    data-driven approaches to creating intelligent recommendation systems have been
    introduced. There are three major approaches to recommendation systems: collaborative
    filtering systems, content-based systems, and hybrid systems. Let''s discuss each
    of these approaches in the following sub-sections.'
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering recommender systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The core idea behind collaborative filtering recommender systems is leveraging
    past actions by others to infer what an individual might be interested in. Collaborative
    filtering approaches draw on data stores of the historic interaction between products
    and users. *Table 10.1* presents an interaction matrix of users rating books.
    Each user rated a book with a number between 1 and 5, with 5 representing the
    highest level of enjoyment. Where there are no ratings, the individual is assumed
    not to have read the book. There are two broad types of collaborative filtering:
    *item-based* collaborative and *user-based* collaborative filtering.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 10.1 – User/product interaction matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.01_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 10.1 – User/product interaction matrix
  prefs: []
  type: TYPE_NORMAL
- en: '*Item-based collaborative filtering* systems (or **item-to-item collaborative
    algorithms**) find similarities between items and base their recommendations on
    these similarities. This approach is grounded in suggesting items to individuals
    based on how similar items are to the ones these individuals previously enjoyed
    or bought. Drawing on *Table 10.1*, an item-based filtering approach would easily
    see that *Book C* and *Book E* are rated in a similar way by previous readers.
    Based on this item relationship, if an individual rates *Book C* highly, a recommendation
    of *Book E* is made and vice versa. So, since *User 5* highly rated *Book E* and
    has not seen *Book C*, a recommendation of *Book C* is put forward, as there is
    a high likelihood of them liking *Book C*.'
  prefs: []
  type: TYPE_NORMAL
- en: With *user-based collaborative filtering* systems, similarities are found between
    *users*, and recommendations are based on these. **User-to-user collaborative
    algorithms** aim to find users with similar behavior or who are in the same behavioral
    neighborhood, as established by their historic actions. The algorithm then considers
    what their preferences are and makes recommendations. The core idea of these recommendation
    systems is the assumption that if individuals *are* alike, *what* they like will
    be similar. From *Table 10.1*, it could be inferred that *User 2* and *User 4*
    have similar book interests. Because *User 4* has rated *Book D* highly, the likelihood
    of *User 2* liking *Book D* is considered high and therefore recommended. As we
    can see, both collaborative filtering approaches are based on the idea of *similarities*.
  prefs: []
  type: TYPE_NORMAL
- en: Similarity metrics offer a basis for recommendations to be made. There are several
    similarity metrics, with the **Pearson correlation coefficient** and **Cosine
    similarity** being among the most popular. Others have approached this measurement
    of similarity drawing on *neighborhoods*. The **K-nearest neighbors** algorithm
    is utilized to find the nearest items or users to the one being recommended or
    recommended to, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Because the interaction dataset is easily acquired, building collaborative filtering
    is considerably easier than content-based systems, as will be discussed in the
    next sections. However, the collaborative approach to recommendation systems has
    a few shortcomings. Within the context of *Table 10.1*, a new user, *User 6*,
    is introduced with no history. It is easy to see that the collaborative filtering
    system will struggle to make recommendations to this user. The problem is similar
    for an item without historic data. This problem, otherwise known as the **cold
    start** problem, is well documented. **Data sparsity** is another problem commonly
    associated with collaborative filtering. Most platforms and large businesses have
    buyers and products. Still, the most active users would only buy a fraction of
    the available products. As such, there is a gap in the data needed to meaningfully
    compute the similarities when powering these engines.
  prefs: []
  type: TYPE_NORMAL
- en: Content-based recommender systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Content-based recommender* systems make suggestions based on the item characteristics
    and user profiles. This approach has a different type of data structure underpinning
    it. Content-based systems are `1` and `5`, the model is regression-based, as it
    predicts an interval variable. This model becomes a content-based recommendation
    engine.'
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding discussion, we can see that a content-based system can easily
    mitigate the cold start problem, as books and users are likely to have some forms
    of descriptions. In comparison to collaborative filtering systems, content-based
    systems are more scalable, as in the production environment, predictions can easily
    be made when needed, rather than having to make predictions for all users and
    products at the same time. Importantly, even when users only rate or buy a few
    products, content-based systems will still perform well, as they focus on the
    descriptions and not necessarily the users or products. That said, most content-based
    systems struggle when the characteristics of the items are not readily available.
    Within certain contexts, it could be challenging to generate attributes for a
    product (for instance, if the product is or has images or sounds). In cases of
    this nature, content-based systems will have no descriptions to analyze. Additionally,
    demographic information of users might not be readily available due to growing
    online privacy concerns. The limitations of both the collaborative filtering and
    content-based approaches to recommendation gave rise to the use of hybrid systems.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid recommender systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Hybrid recommender systems* are an integrated approach to recommendation systems.
    Hybrid systems generate recommendations to users by leveraging a combination of
    two or more recommendation strategies. By doing so, they mitigate the limitations
    attributed to either of the strategies, thereby benefiting from *the wisdom of
    the many*.'
  prefs: []
  type: TYPE_NORMAL
- en: There are several approaches to hybrid systems. The most commonly used (and
    the easiest to implement) is the **weighted approach**. Here, scores from independent
    recommendation systems are aggregated to give an overall recommendation score.
    Aggregation methods vary and can include basic averaging, applying rules, and
    using linear functions. The **staged approach** could also be deployed. This typically
    involves the recommendation systems' results being integrated as input features
    in another recommendation system. As such, the output of the *Stage 1* system
    becomes an additional input for the *Stage 2* system. The **switching approach**
    involves using a rule to switch between different recommendation systems to capitalize
    on their advantages in a given context. For instance, if collaborative filtering
    is seen to give better results, a switch regime could use the collaborative filtering
    approach, but when there is a cold start, it could change to the content-based
    approach. An advantage the hybrid system has over content-based systems is the
    ability to develop recommendations when item features are difficult to establish.
    As will be demonstrated in [*Chapter 11*](B17159_11_Final_NM_ePub.xhtml#_idTextAnchor161),
    *Working with Geospatial Data, NLP, and Image Processing*, DataRobot has advanced
    feature extraction capabilities for images and text data.
  prefs: []
  type: TYPE_NORMAL
- en: Defining and setting up recommender systems in DataRobot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DataRobot, due to its ability to extract features from images, audio, and text
    data, effectively manages the feature availability limitation of the content-based
    recommender systems. This, in addition to DataRobot''s automated ML models'' processes,
    means it is well positioned to leverage the advantages of the content-based approach
    while compensating for the feature-unavailability limitation of this approach.
    As described in the *Technical requirements* section, the dataset used for our
    example consists of three tables. This includes the user table (presenting profiles
    of the users), the book table (outlining characteristics of the books), and the
    rating table (containing user book ratings). Since we have one table describing
    the books, and another, the users, integrating these and the ratings sets the
    scene for the content-based recommender system. To do this, we employed Jupyter
    Notebook. *Figure 10.1* presents the script we ran to ingest the dataset, manipulate
    it, merge the tables, and write it back as a CSV file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Data manipulations in Jupyter Notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.02_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.1 – Data manipulations in Jupyter Notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'Rows on the rating table where `rating` had a value of `0` were excluded, as
    the ratings were implicit. These rows will be used to demonstrate how to make
    predictions with recommendation engines in the *Making recommender system predictions
    with DataRobot* section. Having manipulated the tables by changing their headings,
    as well as consolidating the `ratings`, `books`, and `users` values into a table,
    each row has the description of a user and a book, and also a rating. A snapshot
    of the data is shown in *Table 10.2*. Although we could create the DataRobot project
    in Jupyter Notebook using the Python API method (as will be illustrated in [*Chapter
    12*](B17159_12_Final_NM_ePub.xhtml#_idTextAnchor176), *DataRobot Python API*)
    for consistency, we downloaded the data as a file: `rating.csv`.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 10.2 – Data snapshot'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.03_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 10.2 – Data snapshot
  prefs: []
  type: TYPE_NORMAL
- en: Following the process established in [*Chapter 6*](B17159_06_Final_NM_ePub.xhtml#_idTextAnchor104),
    *Model Building with DataRobot*, we created a DataRobot project for the recommender
    system. When doing this, we drag the `rating.csv` file into the initial project
    window. This opens up the window shown in *Figure 10.2*. For each row, since the
    book rating is used as an indicator of the user's interest, it can be used as
    the target variable. Due to the nature of the target variable, `ratings`, the
    ML models for this recommender system will be of the regression models type.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – DataRobot project initiation window'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.04_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 – DataRobot project initiation window
  prefs: []
  type: TYPE_NORMAL
- en: As expected, ratings made are the range of `1` to `10`. Ideally, we will drop
    the rows with implicit ratings (of `0`) and `user_ID` fields to create a robust
    dataset for modeling. The next thing to do is build the recommender system's ML
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Building recommender systems in DataRobot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the strengths of driverless `user_id` in the **Group ID Feature** field.
  prefs: []
  type: TYPE_NORMAL
- en: 'As detailed in [*Chapter 6*](B17159_06_Final_NM_ePub.xhtml#_idTextAnchor104),
    *Model Building with DataRobot*, DataRobot commences the development of ML models
    when the `Training Schedule` or simply `Training` in the search field in the model
    **Repository** tab during model creation. This will bring up a list of relevant
    models (see *Figure 10.3*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Selecting the advanced modeling approaches most suitable for
    recommender systems'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.05_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.3 – Selecting the advanced modeling approaches most suitable for recommender
    systems
  prefs: []
  type: TYPE_NORMAL
- en: In addition to selecting these modeling methods to be included in the list of
    models to be created, the models' `Autopilot Stage 1`) based on the `Informative
    Features`, and then carried out all five `Cross Validation` runs. A final click
    on **Run Tasks** includes these in the processing queue.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the models have been created, the next step is to evaluate them in terms
    of their accuracy. Prior to this, it is important to examine the **Relative Importance**
    chart to check if our model aligns with common sense. As is apparent in *Figure
    10.4*, opening the **Variable Importance** window through the **Insight** window
    offers us the opportunity to explore these models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Variable importance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.06_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.4 – Variable importance
  prefs: []
  type: TYPE_NORMAL
- en: The values next to `London`) and an aspect of the title (for example, `Kingdom`)
    could be interpreted as influential to the model. So, in this simplified example,
    a higher-order feature that is an interaction between `London` and `Kingdom` is
    created. The rating predictions consequently change considerably depending on
    the presence of this newly created higher-order feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'In model selection, using the definite `Keras Slim Residual Neural Network
    Regressor using Adaptive Training Schedule (1 Layer: 64 Units)` is the best-performing
    model (see *Figure 10.5*). It is important to highlight that measuring the accuracy
    of models for recommendation systems in some contexts is not as straightforward.
    Imagine that in this case, we could only have a rating of `1` when an individual
    buys a book, and otherwise it would be `0`. Naively measuring how accurate the
    model is becomes limited, as a `0` rating does not necessarily imply that an individual
    is not interested in an item. This is because it is possible that the individual
    has never read the book. Because a good recommender system will recommend items
    whose characteristics align with an individual''s profile as a potential book
    to read that are unread, it is likely to have a significant proportion of false
    positives. This is because, although their current rating is `0`, the user in
    question will most likely be interested in reading them. In cases like these,
    the **Recall** type becomes a more important metric in evaluating the model performance.
    Given that we are only certain of cases where individuals buy items, it is reasonable
    to evaluate those cases in isolation. Therefore, the extent to which the model
    accuracy predicts books that are read correctly, usually referred to as the **Recall**,
    becomes a more suitable metric.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Leaderboard tab for recommendation systems'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.07_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.5 – Leaderboard tab for recommendation systems
  prefs: []
  type: TYPE_NORMAL
- en: 'For a recommendation system, accuracy and prediction speed is very important
    to consider when deciding which model to use. To ground this discussion, it is
    important to understand that there are two major approaches to making predictions
    with recommendation systems. The first approach is a batch scoring of combinations
    of users by items, where items are yet to be read by the user. This dataset becomes
    larger exponentially as items and users increase. The second approach is a *real-time
    prediction*. For instance, imagine an individual arrives at an e-commerce platform.
    That individual''s data with those of the products is rapidly scored and suggestions
    are scored nearly instantly. In both cases, the speed of the prediction is pivotal
    for commercial success. The DataRobot `Keras Slim Residual Neural Network Regressor
    using Adaptive Training Schedule (1 Layer: 64 Units)` is `1.6746`, and its prediction
    speed is `35.57` ms per every 1,000 predictions. The validation scores for some
    blender models appear better, but these are much weaker in terms of the speed
    of prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6 – DataRobots'' Speed vs Accuracy chart'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.08_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.6 – DataRobots' Speed vs Accuracy chart
  prefs: []
  type: TYPE_NORMAL
- en: This suggests that though it is very accurate, this model is very slow in making
    predictions. The **Speed vs Accuracy** chart presents a snapshot visualization
    of several models' speed and accuracy. A more in-depth pairwise comparison can
    be carried out using the **Model Comparison** tool. To continue the discussion
    of prediction, we will now turn to making recommendation system predictions in
    DataRobot.
  prefs: []
  type: TYPE_NORMAL
- en: Making recommender system predictions with DataRobot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating suggestions from recommendation engines on DataRobot is straightforward.
    We use the drag and drop approach (as discussed in earlier chapters), as our prediction
    dataset is only small. With larger datasets (over 1 GB), as is more typical for
    recommender systems, using the DataRobot prediction API is advised. The API approach
    to creating models and making predictions is covered in depth in [*Chapter 12*](B17159_12_Final_NM_ePub.xhtml#_idTextAnchor176),
    *DataRobot Python API*.
  prefs: []
  type: TYPE_NORMAL
- en: Our prediction dataset for our example is 64 MB in size, and so the drag and
    drop approach is appropriate. For this prediction approach, we specify the columns
    we want to use from the original dataset. Ideally, we at least need an identifier
    for the item and user. As illustrated in *Figure 10.7*, we have chosen to include
    the `ISBN`, `user_id`, and `title` fields in our predictions. We drag and drop
    the prediction dataset into the specified region. As usual, this dataset is quickly
    evaluated, and we are presented with the **Run external test** or **Compute prediction**
    options.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7 – A recommendation engine prediction setup'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.09_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.7 – A recommendation engine prediction setup
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we click on `.csv` file (see *Table 10.3*). As noted previously,
    the prediction set is drawn from the original dataset where the ratings were implicit
    (so the rating score was zero). Thus, the prediction dataset has only a limited
    sample of the possible person-item interactions. Some users (for instance, the
    user with `8` as  `user_id`), have about `10` items scored, while some have only
    `1` item scored. In an ideal situation, all items not seen by an individual would
    be rated. That said, suggestions served to the user are then made in order of
    predicted interests. For user `8`, the book titled `A Second Chicken Soup for
    the Woman's Soul (Chicken Soup for the Soul Series)` is served first. In some
    cases, the top *n* recommendations is used. By top *n* in our book case, we mean,
    for each user the top *n* books are selected based on their prediction values.
  prefs: []
  type: TYPE_NORMAL
- en: '![ Table 10.3 – A recommendation engine sample prediction'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10.10_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 10.3 – A recommendation engine sample prediction
  prefs: []
  type: TYPE_NORMAL
- en: The selected model can be deployed as a **REST** API using DataRobot, as shown
    in [*Chapter 8*](B17159_08_Final_NM_ePub.xhtml#_idTextAnchor116), *Model Scoring
    and Deployment*, and then the data can be scored via the DataRobot API call (which
    we will discuss in [*Chapter 12*](B17159_12_Final_NM_ePub.xhtml#_idTextAnchor176),
    *DataRobot Python API*). Some DataRobot models can be downloaded as **JAR** files,
    which can be integrated with other applications to make real-time predictions.
    Elsewhere, a batch prediction can be made using different person-item interactions,
    before being stored in a big data storage table, such as **Google Cloud BigQuery**.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced and appraised different approaches to recommendation
    systems. We examined the data structure requirements for content-based and collaborative
    filtering recommendation systems, and we discussed their underlining assumptions.
    We then point out the strengths of DataRobot in extracting features from challenging
    data types (for instance, image data) that normally limit the use of content-based
    systems. We then illustrated the use of DataRobot in building and making predictions
    using a content-based recommender system based on a small dataset.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to highlight that the dataset used for this project was made
    up of multiple data types. DataRobot is capable of extracting features and integrating
    different data types to create ML models. In the next chapter, we will explore
    how to use datasets with a combination of image, text, and location data when
    creating ML models.
  prefs: []
  type: TYPE_NORMAL
