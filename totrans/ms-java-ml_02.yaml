- en: Chapter 2. Practical Approach to Real-World Supervised Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章. 实际应用中的现实世界监督学习
- en: The ability to learn from observations accompanied by marked targets or labels,
    usually in order to make predictions about unseen data, is known as **supervised
    machine learning**. If the targets are categories, the problem is one of classification
    and if they are numeric values, it is called **regression**. In effect, what is
    being attempted is to infer the function that maps the data to the target. Supervised
    machine learning is used extensively in a wide variety of machine learning applications,
    whenever labeled data is available or the labels can be added manually.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 从带有明显目标或标签的观察中学习的能力，通常是为了对未见数据做出预测，这被称为**监督机器学习**。如果目标是类别，则问题属于分类；如果目标是数值，则称为**回归**。实际上，所尝试的是推断将数据映射到目标的功能。监督机器学习在广泛的机器学习应用中被广泛使用，无论是有标签数据可用还是标签可以手动添加。
- en: The core assumption of supervised machine learning is that the patterns that
    are learned from the data used in training will manifest themselves in yet unseen
    data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习的核心假设是，从训练数据中学习到的模式将在未见数据中表现出来。
- en: In this chapter, we will discuss the steps used to explore, analyze, and pre-process
    the data before proceeding to training models. We will then introduce different
    modeling techniques ranging from simple linear models to complex ensemble models.
    We will present different evaluation metrics and validation criteria that allow
    us to compare model performance. Some of the discussions are accompanied by brief
    mathematical explanations that should help express the concepts more precisely
    and whet the appetite of the more mathematically inclined readers. In this chapter,
    we will focus on classification as a method of supervised learning, but the principles
    apply to both classification and regression, the two broad applications of supervised
    learning.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论在训练模型之前用于探索、分析和预处理数据的步骤。然后，我们将介绍从简单的线性模型到复杂的集成模型的不同建模技术。我们将展示不同的评估指标和验证标准，这些标准使我们能够比较模型性能。一些讨论伴随着简短的数学解释，这有助于更精确地表达概念并激发更多数学倾向读者的兴趣。在本章中，我们将重点关注分类作为监督学习方法，但原则同样适用于分类和回归，这是监督学习的两个广泛应用。
- en: Beginning with this chapter, we will introduce tools to help illustrate how
    the concepts presented in each chapter are used to solve machine learning problems.
    Nothing reinforces the understanding of newly learned material better than the
    opportunity to apply that material to a real-world problem directly. In the process,
    we often gain a clearer and more relatable understanding of the subject than what
    is possible with passive absorption of the theory alone. If the opportunity to
    learn new tools is part of the learning, so much the better! To meet this goal,
    we will introduce a classification dataset familiar to most data science practitioners
    and use it to solve a classification problem while highlighting the process and
    methodologies that guide the solution.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 从本章开始，我们将介绍工具来帮助说明每个章节中提出的概念是如何用于解决机器学习问题的。没有什么比将新学的材料直接应用于现实世界问题更能加强对新材料的理解了。在这个过程中，我们往往比仅仅被动吸收理论更能获得更清晰、更相关的理解。如果学习新工具的机会是学习的一部分，那就更好了！为了达到这个目标，我们将介绍一个大多数数据科学从业者都熟悉的数据集，并使用它来解决一个分类问题，同时突出引导解决方案的过程和方法。
- en: In this chapter, we will use RapidMiner and Weka for building the process by
    which we learn from a single well-known dataset. The workflows and code are available
    on the website for readers to download, execute, and modify.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用RapidMiner和Weka来构建从单个知名数据集中学习的过程。工作流程和代码可在网站上供读者下载、执行和修改。
- en: RapidMiner is a GUI-based Java framework that makes it very easy to conduct
    a data science project, end-to-end, from within the tool. It has a simple drag-and-drop
    interface to build process workflows to ingest and clean data, explore and transform
    features, perform training using a wide selection of machine learning algorithms,
    do validation and model evaluation, apply your best models to test data, and more.
    It is an excellent tool to learn how to make the various parts of the process
    work together and produce rapid results. Weka is another GUI-based framework and
    it has a Java API that we will use to illustrate more of the coding required for
    performing analysis.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: RapidMiner是一个基于GUI的Java框架，它使得在工具内部从头到尾进行数据科学项目变得非常容易。它有一个简单的拖放界面来构建工作流程，用于摄取和清理数据，探索和转换特征，使用广泛的机器学习算法进行训练，进行验证和模型评估，将最佳模型应用于测试数据，等等。它是学习如何使流程的各个部分协同工作并快速产生结果的一个优秀工具。Weka是另一个基于GUI的框架，它有一个我们将用于说明执行分析所需的更多编码的Java
    API。
- en: 'The major topics that we will cover in this chapter are:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖的主要主题包括：
- en: Data quality analysis
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据质量分析
- en: Descriptive data analysis
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述性数据分析
- en: Visualization analysis
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化分析
- en: Data transformation and preprocessing
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据转换和预处理
- en: Data sampling
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据采样
- en: Feature relevance analysis and dimensionality reduction
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征相关性分析和降维
- en: Model building
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型构建
- en: Model assessment, evaluation, and comparison
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型评估、评估和比较
- en: Detailed case study—Horse Colic Classification
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 案例研究—马绞痛分类
- en: Formal description and notation
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 形式描述和符号
- en: We would like to introduce some notation and formal definitions for the terms
    used in supervised learning. We will follow this notation through the rest of
    the book when not specified and extend it as appropriate when new concepts are
    encountered. The notation will provide a precise and consistent language to describe
    the terms of art and enable a more rapid and efficient comprehension of the subject.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望介绍一些用于监督学习中使用的术语的符号和形式定义。在不指定的情况下，我们将遵循这种符号贯穿本书的其余部分，并在遇到新概念时适当扩展。这种符号将提供一个精确和一致的语言来描述术语，并使对主题的理解更加快速和高效。
- en: '**Instance**: Every observation is a data instance. Normally the variable *X*
    is used to represent the input space. Each data instance has many variables (also
    called features) and is referred to as **x** (vector representation with bold)
    of dimension *d* where *d* denotes the number of variables or features or attributes
    in each instance. The features are represented as **x** = *(x*[1]*,x*[2]*,…x*[d]*)*^T,
    where each value is a scalar when it is numeric corresponding to the feature value.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实例**：每个观察都是数据实例。通常变量 *X* 用于表示输入空间。每个数据实例有许多变量（也称为特征），被称为 **x**（用粗体表示的向量表示）的维度为
    *d*，其中 *d* 表示每个实例中的变量或特征或属性的数量。特征表示为 **x** = *(x*[1]*,x*[2]*,…x*[d]*)*^T，其中每个值在它是数值时对应于特征值。'
- en: '**Label**: The label (also called target) is the dependent variable of interest,
    generally denoted by *y*. In **classification**, values of the label are well-defined
    categories in the problem domain; they need not be numeric or things that can
    be ordered. In **regression**, the label is real-valued.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签**：标签（也称为目标）是感兴趣的因变量，通常用 *y* 表示。在 **分类** 中，标签的值是问题域中定义良好的类别；它们不需要是数值或可以排序的事物。在
    **回归** 中，标签是实数值。'
- en: '**Binary classification**, where the target takes only two values, it is mathematically
    represented as:'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二元分类**，其中目标只取两个值，在数学上表示为：'
- en: y ∈ {1,–1}
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: y ∈ {1,–1}
- en: '**Regression**, where the target can take any value in the real number domain,
    is represented as:![Formal description and notation](img/B05137_02_008.jpg)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**，其中目标可以取实数域内的任何值，表示为：![形式描述和符号](img/B05137_02_008.jpg)'
- en: '**Dataset**: Generally, the dataset is denoted by *D* and consists of individual
    data instances and their labels. The instances are normally represented as set
    {**x**[1],**x**[2]…**x**[n]}. The labels for each instance are represented as
    the set **y** = {*y*[1]*,y*[2]*,…y*[n]}. The entire labeled dataset is represented
    as paired elements in a set as given by *D* = {(**x**[1], *y*[1]),(**x**[2], *y*[2])…(**x**[n],
    *y*[n])} where ![Formal description and notation](img/B05137_02_013.jpg) for real-valued
    features.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集**：通常，数据集用 *D* 表示，由单个数据实例及其标签组成。实例通常表示为集合 {**x**[1],**x**[2]…**x**[n]}。每个实例的标签表示为集合
    **y** = {*y*[1]*,y*[2]*,…y*[n]}。整个标记数据集表示为集合中的配对元素，如 *D* = {(**x**[1], *y*[1]),(**x**[2],
    *y*[2])…(**x**[n], *y*[n])}，其中 ![形式描述和符号](img/B05137_02_013.jpg) 用于实值特征。'
- en: Data quality analysis
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据质量分析
- en: There are limitations to what can be learned from data that suffers from poor
    quality. Problems with quality can include, among other factors, noisy data, missing
    values, and errors in labeling. Therefore, the first step is to understand the
    data before us in order that we may determine how to address any data quality
    issues. Are the outliers merely noise or indicative of interesting anomalies in
    the population? Should missing data be handled the same way for all features?
    How should sparse features be treated? These and similar questions present themselves
    at the very outset.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从质量较差的数据中可以学习到的东西有限。质量问题的因素可能包括，但不仅限于，噪声数据、缺失值和标签错误。因此，第一步是理解我们面前的数据，以便我们确定如何解决任何数据质量问题。异常值仅仅是噪声，还是表明人口中有有趣的异常？对于所有特征，缺失数据是否应该以相同的方式处理？稀疏特征应该如何处理？这些问题以及类似的问题在最初就显现出来。
- en: If we're fortunate, we receive a cleansed, accurately labeled dataset accompanied
    by documentation describing the data elements, the data's pedigree, and what if
    any transformations were already done to the data. Such a dataset would be ready
    to be split into train, validation, and test samples, using methods described
    in the section on Data Sampling. However, if data is not cleansed and suitable
    to be partitioned for our purposes, we must first prepare the data in a principled
    way before sampling can begin. (The significance of partitioning the data is explained
    later in this chapter in a section dedicated to train, validation, and test sets).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们很幸运，我们会收到一个清洗过的、准确标记的数据集，并附带描述数据元素、数据的血统以及是否对数据进行过任何转换的文档。这样的数据集就可以准备好按照数据采样部分描述的方法分成训练、验证和测试样本。然而，如果数据没有清洗并且不适合用于我们的目的，我们必须在采样开始之前以原则性的方式准备数据。（数据分区的意义将在本章的“训练、验证和测试集”部分中解释）。
- en: In the following sections, we will discuss the data quality analysis and transformation
    steps that are needed before we can analyze the features.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将讨论在分析特征之前所需的数据质量分析和转换步骤。
- en: Descriptive data analysis
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述性数据分析
- en: The complete data sample (including train, validation, and test) should be analyzed
    and summarized for the following characteristics. In cases where the data is not
    already split into train, validate, and test, the task of data transformation
    needs to make sure that the samples have similar characteristics and statistics.
    This is of paramount importance to ensure that the trained model can generalize
    over unseen data, as we will learn in the section on data sampling.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 应对以下特征进行分析和总结的完整数据样本（包括训练、验证和测试）。在数据尚未分成训练、验证和测试的情况下，数据转换的任务需要确保样本具有相似的特征和统计信息。这对于确保训练的模型可以泛化到未见过的数据至关重要，正如我们将在数据采样部分所学到的。
- en: Basic label analysis
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本标签分析
- en: The first step of analysis is understanding the distribution of labels in different
    sets as well as in the data as a whole. This helps to determine whether, for example,
    there is imbalance in the distribution of the target variable, and if so, whether
    it is consistent across all the samples. Thus, the very first step is usually
    to find out how many examples in the training and test sets belong to each class.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 分析的第一步是理解不同集合以及整体数据中标签的分布。这有助于确定例如目标变量的分布是否存在不平衡，以及这种不平衡是否在所有样本中一致。因此，第一步通常是找出训练集和测试集中每个类别的例子数量。
- en: Basic feature analysis
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本特征分析
- en: The next step is to calculate the statistics for each feature, such as
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是计算每个特征的统计信息，例如
- en: Number of unique values
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 唯一值的数量
- en: 'Number of missing values: May include counts grouped by different missing value
    surrogates (NA, null, ?, and so on).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值的数量：可能包括按不同缺失值代理（NA、null、?等）分组的计数。
- en: 'For categorical: This counts across feature categories, counts across feature
    categories by label category, most frequently occurring category (mode), mode
    by label category, and so on.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于分类：这是跨特征类别的计数，按标签类别跨特征类别的计数，最频繁出现的类别（众数），按标签类别的众数等。
- en: 'For numeric: Minimum, maximum, median, standard deviation, variance, and so
    on.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于数值：最小值、最大值、中位数、标准差、方差等。
- en: Feature analysis gives basic insights that can be a useful indicator of missing
    values and noise that can affect the learning process or choice of the algorithms.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 特征分析提供了基本的见解，这些见解可以作为缺失值和噪声的有用指标，这些缺失值和噪声可能会影响学习过程或算法的选择。
- en: Visualization analysis
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化分析
- en: Visualization of the data is a broad topic and it is a continuously evolving
    area in the field of machine learning and data mining. We will only cover some
    of the important aspects of visualization that help us analyze the data in practice.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的可视化是一个广泛的话题，它是在机器学习和数据挖掘领域不断发展的一个领域。我们只将涵盖一些有助于我们在实践中分析数据的可视化重要方面。
- en: Univariate feature analysis
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单变量特征分析
- en: 'The goal here is to visualize one feature at a time, in relation to the label.
    The techniques used are as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标是每次可视化一个特征，与标签相关。使用的技术如下：
- en: Categorical features
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分类特征
- en: Stacked bar graphs are a simple way of showing the distribution of each feature
    category among the labels, when the problem is one of classification.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠条形图是一种简单的方式来展示每个特征类别在标签中的分布，当问题是一类分类时。
- en: Continuous features
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 连续特征
- en: Histograms and box plots are two basic visualization techniques for continuous
    features.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图和箱线图是连续特征的两种基本可视化技术。
- en: Histograms have predefined bins whose widths are either fixed intervals or based
    on some calculation used to split the full range of values of the feature. The
    number of instances of data that falls within each bin is then counted and the
    height of the bin is adjusted based on this count. There are variations of histograms
    such as relative or frequency-based histograms, Pareto histograms, two-dimensional
    histograms, and so on; each is a slight variation of the concept and permits a
    different insight into the feature. For those interested in finding out more about
    these variants, the Wikipedia article on histograms is a great resource.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图有预定义的区间，其宽度要么是固定的间隔，要么是基于某种用于分割特征值全范围的计算。然后计算每个区间内的数据实例数量，并根据这个计数调整区间的身高。直方图有各种变体，如相对直方图或基于频率的直方图、帕累托直方图、二维直方图等；每个都是概念的一小部分变化，允许对特征有不同见解。对于那些想了解更多关于这些变体的人来说，维基百科上的直方图文章是一个很好的资源。
- en: Box plots are a key visualization technique for numeric features as they show
    distributions in terms of percentiles and outliers.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图是数值特征的键视觉技术，因为它们以百分位数和异常值来展示分布。
- en: Multivariate feature analysis
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多变量特征分析
- en: The idea of multivariate feature analysis is to visualize more than one feature
    to get insights into relationships between them. Some of the well-known plots
    are explained here.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 多变量特征分析的想法是可视化多个特征，以深入了解它们之间的关系。这里解释了一些著名的图表。
- en: '**Scatter plots**: An important technique for understanding the relationship
    between different features and between features and labels. Typically, two-dimensional
    scatter plots are used in practice where numeric features form the dimensions.
    Alignment of data points on some imaginary axis shows correlation while scattering
    of the data points shows no correlation. It can also be useful to identify clusters
    in lower dimensional space. A bubble chart is a variation of a scatter plot where
    two features form the dimensional axes and the third is proportional to the size
    of the data point, with the plot giving the appearance of a field of "bubbles".
    Density charts help visualize even more features together by introducing data
    point color, background color, and so on, to give additional insights.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**散点图**：理解不同特征之间以及特征和标签之间关系的重要技术。在实践中通常使用二维散点图，其中数值特征形成维度。数据点在某些想象轴上的对齐显示相关性，而数据点的散射则显示无相关性。它还可以用于在低维空间中识别簇。气泡图是散点图的变体，其中两个特征形成维度轴，第三个特征与数据点的尺寸成比例，该图呈现出“气泡”场的样子。密度图通过引入数据点颜色、背景颜色等，帮助可视化更多特征，从而提供额外的见解。'
- en: '**ScatterPlot Matrix**: ScatterPlot Matrix is an extension of scatter plots
    where pair-wise scatter plots for each feature (and label) is visualized. It gives
    a way to compare and perform multivariate analysis of high dimensional data in
    an effective way.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**散点图矩阵**：散点图矩阵是散点图的扩展，其中为每个特征（和标签）可视化了成对的散点图。它提供了一种有效的方式，以比较和执行高维数据的多元分析。'
- en: '**Parallel Plots**: In this visualization, each feature is linearly arranged
    on the x-axis and the ranges of values for each feature form the *y* axis. So
    each data element is represented as a line with values for each feature on the
    parallel axis. Class labels, if available, are used to color the lines. Parallel
    plots offer a great understanding of features that are effective in separating
    the data. Deviation charts are variations of parallel plots, where instead of
    showing actual data points, mean and standard deviations are plotted. Andrews
    plots are another variation of parallel plots where data is transformed using
    Fourier series and the function values corresponding to each is projected.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行图**：在这种可视化中，每个特征线性排列在x轴上，每个特征的值域形成y轴。因此，每个数据元素都表示为一条线，该线上的每个特征值都位于平行轴上。如果可用，类标签用于着色线条。并行图提供了对有效分离数据的特征的良好理解。偏差图是并行图的变体，其中不是显示实际数据点，而是绘制均值和标准偏差。Andrews图是并行图的另一种变体，其中使用傅里叶级数转换数据，并将对应于每个数据的函数值投影。'
- en: Data transformation and preprocessing
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据转换和预处理
- en: In this section, we will cover the broad topic of data transformation. The main
    idea of data transformation is to take the input data and transform it in careful
    ways so as to clean it, extract the most relevant information from it, and to
    turn it into a usable form for further analysis and learning. During these transformations,
    we must only use methods that are designed while keeping in mind not to add any
    bias or artifacts that would affect the integrity of the data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将涵盖数据转换的广泛主题。数据转换的主要思想是将输入数据以谨慎的方式进行转换，以便对其进行清理，从中提取最相关的信息，并将其转换为可用于进一步分析和学习的可用形式。在这些转换过程中，我们必须只使用在设计时考虑到不添加任何可能影响数据完整性的偏差或伪影的方法。
- en: Feature construction
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征构建
- en: In the case of some datasets, we need to create more features from features
    we are already given. Typically, some form of aggregation is done using common
    aggregators such as average, sum, minimum, or maximum to create additional features.
    In financial fraud detection, for example, Card Fraud datasets usually contain
    transactional behaviors of accounts over various time periods during which the
    accounts were active. Performing behavioral synthesis such as by capturing the
    "Sum of Amounts whenever a Debit transaction occurred, for each Account, over
    One Day" is an example of feature construction that adds a new dimension to the
    dataset, built from existing features. In general, designing new features that
    enhance the predictive power of the data requires domain knowledge and experience
    with data, making it as much an art as a science.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些数据集的情况下，我们需要从已给出的特征中创建更多特征。通常，会使用常见的聚合器，如平均值、总和、最小值或最大值，以创建额外的特征。例如，在金融欺诈检测中，卡欺诈数据集通常包含账户在活跃期间不同时间段的交易行为。通过捕获“每天发生借记交易时的金额总和，对于每个账户，一天之内”的行为合成，就是一个特征构建的例子，它为数据集添加了一个新的维度，这个维度是由现有特征构建的。一般来说，设计新的特征以增强数据的预测能力需要领域知识和对数据的经验，这使得它既是一门艺术也是一门科学。
- en: Handling missing values
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理缺失值
- en: In real-world datasets, often, many features have missing values. In some cases,
    they are missing due to errors in measurement, lapses in recording, or because
    they are not available due to various circumstances; for example, individuals
    may choose not to disclose age or occupation. Why care about missing values at
    all? One extreme and not uncommon way to deal with it is to ignore the records
    that have any missing features, in other words, retain only examples that are
    "whole". This approach may severely reduce the size of the dataset when missing
    features are widespread in the data. As we shall see later, if the system we are
    dealing with is complex, dataset size can afford us precious advantage. Besides,
    there is often predictive value that can be exploited even in the "un-whole" records,
    despite the missing values, as long as we use appropriate measures to deal with
    the problem. On the other hand, one may unwittingly be throwing out key information
    when the omission of the data itself is significant, as in the case of deliberate
    misrepresentation or obfuscation on a loan application by withholding information
    that could be used to conclusively establish bone fides.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界的数据集中，通常许多特征都有缺失值。在某些情况下，它们是因测量错误、记录失误或由于各种情况下的不可用而缺失；例如，个人可能选择不透露年龄或职业。为什么要在乎缺失值呢？一种极端且不罕见的方法是忽略任何具有缺失特征的记录，换句话说，只保留“完整”的例子。当数据中广泛存在缺失特征时，这种方法可能会严重减少数据集的大小。正如我们稍后将要看到的，如果我们处理的是一个复杂系统，数据集的大小可以给我们带来宝贵的优势。此外，即使存在缺失值，只要我们使用适当的措施来处理问题，即使在“不完整”的记录中，也常常可以挖掘出有预测价值的值。另一方面，当数据本身的省略本身具有重要意义时，如贷款申请中故意隐瞒信息以掩盖事实的情况，可能会无意中丢弃关键信息。
- en: Suffice it to say, that an important step in the learning process is to adopt
    some systematic way to handle missing values and understand the consequences of
    the decision in each case. There are some algorithms such as Naïve Bayes that
    are less sensitive to missing values, but in general, it is good practice to handle
    these missing values as a pre-processing step before any form of analysis is done
    on the data. Here are some of the ways to handle missing values.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是学习过程中的一个重要步骤，即采用某种系统的方式来处理缺失值，并理解每个案例中决策的后果。有一些算法，如朴素贝叶斯，对缺失值不太敏感，但通常，在数据上进行分析之前，将这些缺失值作为预处理步骤处理是良好的实践。以下是一些处理缺失值的方法。
- en: '**Replacing by means and modes**: When we replace the missing value of a continuous
    value feature with the mean value of that feature, the new mean clearly remains
    the same. But if the mean is heavily influenced by outliers, a better approach
    may be to use the mean after dropping the outliers from the calculation, or use
    the median or mode, instead. Likewise, when a feature is sparsely represented
    in the dataset, the mean value may not be meaningful. In the case of features
    with categorical values, replacing the missing value with the one that occurs
    with the highest frequency in the sample makes for a reasonable choice.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用均值和众数替换**：当我们用特征的均值替换连续值特征的缺失值时，新的均值显然保持不变。但如果均值受到异常值的影响很大，更好的方法可能是使用计算中去除异常值后的均值，或者使用中位数或众数，而不是均值。同样，当特征在数据集中稀疏表示时，均值可能没有意义。对于具有分类值的特征，用样本中出现频率最高的值替换缺失值是一个合理的选择。'
- en: '**Replacing by imputation**: When we impute a missing value, we are in effect
    constructing a classification or regression model of the feature and making a
    prediction based on the other features in the record in order to classify or estimate
    the missing value.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过插补替换**：当我们插补一个缺失值时，实际上是在构建一个关于该特征的分类或回归模型，并基于记录中的其他特征进行预测，以便对缺失值进行分类或估计。'
- en: '**Nearest Neighbor imputation**: For missing values of a categorical feature,
    we consider the feature in question to be the target and train a KNN model with
    k taken to be the known number of distinct categories. This model is then used
    to predict the missing values. (A KNN model is non-parametric and assigns a value
    to the "incoming" data instance based on a function of its neighbors—the algorithm
    is described later in this chapter when we talk about non-linear models).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最近邻插补法**：对于分类特征的缺失值，我们将该特征视为目标，并使用已知的类别数量k训练一个KNN模型。然后使用此模型来预测缺失值。（KNN模型是非参数的，根据其邻居的函数为其“传入”数据实例分配一个值——该算法将在本章后面关于非线性模型时进行描述）。'
- en: '**Regression-based imputation**: In the case of continuous value variables,
    we use linear models like Linear Regression to estimate the missing data—the principle
    is the same as for categorical values.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于回归的插补**：在连续值变量的情况下，我们使用线性模型如线性回归来估计缺失数据——原理与分类值相同。'
- en: '**User-defined imputation**: In many cases, the most suitable value for imputing
    missing values must come from the problem domain. For instance, a pH value of
    7.0 is neutral, higher is basic, and lower is acidic. It may make most sense to
    impute a neutral value for pH than either mean or median, and this insight is
    an instance of a user-defined imputation. Likewise, in the case of substitution
    with normal body temperature or resting heart rate—all are examples from medicine.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户定义的插补**：在许多情况下，用于插补缺失值的最合适的值必须来自问题域。例如，pH值为7.0是中性的，更高的是碱性，更低的是酸性。对于pH值，插补一个中性值可能比均值或中位数更有意义，这种洞察力是用户定义插补的一个例子。同样，在用正常体温或静息心率进行替换的情况下——所有这些都是来自医学的例子。'
- en: Outliers
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异常值
- en: Handling outliers requires a lot of care and analysis. Outliers can be noise
    or errors in the data, or they can be anomalous behavior of particular interest.
    The latter case is treated in depth in [Chapter 3](ch03.html "Chapter 3. Unsupervised
    Machine Learning Techniques"), *Unsupervised Machine Learning Techniques*. Here
    we assume the former case, that the domain expert is satisfied that the values
    are indeed outliers in the first sense, that is, noise or erroneously acquired
    or recorded data that needs to be handled appropriately.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 处理异常值需要大量的注意和分析。异常值可能是数据中的噪声或错误，也可能是特定感兴趣的特殊行为。后一种情况在[第3章](ch03.html "第3章。无监督机器学习技术")“无监督机器学习技术”中进行了深入讨论。在这里，我们假设前一种情况，即领域专家满意地认为这些值确实是第一种意义上的异常值，即噪声或错误获取或记录的数据，需要适当处理。
- en: Following are different techniques in detecting outliers in the data
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是检测数据中异常值的不同技术
- en: '**Interquartile Ranges (IQR)**: Interquartile ranges are a measure of variability
    in the data or, equivalently, the statistical dispersion. Each numeric feature
    is sorted based on its value in the dataset and the ordered set is then divided
    into quartiles. The median value is generally used to measure central tendency.
    IQR is measured as the difference between upper and lower quartiles, Q3-Q1\. The
    outliers are generally considered to be data values above Q3 + 1.5 * IQR and below
    Q1 - 1.5 * IQR.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**四分位数范围（IQR）**：四分位数范围是数据变异性的度量，或者说，是统计分散度的度量。每个数值特征根据其在数据集中的值进行排序，然后有序集被分为四分位数。通常使用中位数来衡量集中趋势。IQR被测量为上四分位数和下四分位数的差，即Q3-Q1。通常认为，异常值是高于Q3
    + 1.5 * IQR和低于Q1 - 1.5 * IQR的数据值。'
- en: '**Distance-based Methods**: The most basic form of distance-based methods uses
    **k-Nearest Neighbors** (**k-NN**) and distance metrics to score the data points.
    The usual parameter is the value *k* in k-NN and a distance metric such as Euclidean
    distance. The data points at the farthest distance are considered outliers. There
    are many variants of these that use local neighborhoods, probabilities, or other
    factors, which will all be covered in [Chapter 3](ch03.html "Chapter 3. Unsupervised
    Machine Learning Techniques"), *Unsupervised Machine Learning Techniques*. Mixed
    datasets, which have both categorical and numeric features, can skew distance-based
    metrics.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于距离的方法**：基于距离的最基本方法使用**k-最近邻**（**k-NN**）和距离度量来评分数据点。通常的参数是k-NN中的值*k*和一个距离度量，如欧几里得距离。距离最远的数据点被认为是异常值。有许多变体使用局部邻域、概率或其他因素，这些将在[第3章](ch03.html
    "第3章。无监督机器学习技术")，*无监督机器学习技术*中全部涵盖。混合数据集，既有分类特征又有数值特征，可能会扭曲基于距离的度量。'
- en: '**Density-based methods**: Density-based methods calculate the proportion of
    data points within a given distance *D*, and if the proportion is less than the
    specified threshold p, it is considered an outlier. The parameter p and D are
    considered user-defined values; the challenge of selecting these values appropriately
    presents one of the main hurdles in using these methods in the preprocessing stage.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于密度的方法**：基于密度的方法计算给定距离*D*内数据点的比例，如果比例小于指定的阈值*p*，则被认为是异常值。参数*p*和*D*被认为是用户定义的值；选择这些值适当的挑战是使用这些方法在预处理阶段的主要障碍之一。'
- en: '**Mathematical transformation of feature**: With non-normal data, comparing
    the mean value is highly misleading, as in the case when outliers are present.
    Non-parametric statistics allow us to make meaningful observations about highly
    skewed data. Transformation of such values using the logarithm or square root
    function tends to normalize the data in many cases, or make them more amenable
    to statistical tests. These transformations alter the shape of the distribution
    of the feature drastically—the more extreme an outlier, the greater the effect
    of the log transformation, for example.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征的数学变换**：对于非正态数据，比较平均值是非常误导的，例如在存在异常值的情况下。非参数统计使我们能够对高度偏斜的数据做出有意义的观察。使用对数或平方根函数对这些值进行变换往往会在许多情况下使数据归一化，或者使它们更容易进行统计测试。这些变换会极大地改变特征的分布形状——异常值越极端，对数变换的影响就越大，例如。'
- en: '**Handling outliers using robust statistical algorithms in machine learning
    models**: Many classification algorithms which we discuss in the next section
    on modeling, implicitly or explicitly handle outliers. Bagging and Boosting variants,
    which work as meta-learning frameworks, are generally resilient to outliers or
    noisy data points and may not need a preprocessing step to handle them.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在机器学习模型中使用鲁棒统计算法处理异常值**：我们将在下一节建模中讨论的许多分类算法，隐式或显式地处理异常值。作为元学习框架的Bagging和Boosting变体，通常对异常值或噪声数据点具有弹性，可能不需要预处理步骤来处理它们。'
- en: '**Normalization**: Many algorithms—distance-based methods are a case in point—are
    very sensitive to the scale of the features. Preprocessing the numeric features
    makes sure that all of them are in a well-behaved range. The most well-known techniques
    of normalization of features are given here:'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**归一化**：许多算法——基于距离的方法就是一个例子——对特征的规模非常敏感。预处理数值特征确保它们都在一个良好的行为范围内。这里给出了特征归一化的最知名技术：'
- en: '**Min-Max Normalization**: In this technique, given the range *[L,U]*, which
    is typically *[0,1]*, each feature with value *x* is normalized in terms of the
    minimum and maximum values, *x*[max] and *x*[min], respectively, using the formula:![Outliers](img/B05137_02_016.jpg)'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最小-最大标准化**：在这种技术中，给定范围 *[L,U]*，通常是 *[0,1]*，每个具有值 *x* 的特征分别使用最小值和最大值 *x*[max]
    和 *x*[min] 进行归一化，使用以下公式：![异常值](img/B05137_02_016.jpg)'
- en: '**Z-Score Normalization**: In this technique, also known as standardization,
    the feature values get auto-transformed so that the mean is 0 and standard deviation
    is 1\. The technique to transform is as follows: for each feature *f*, the mean
    value µ(*f*) and standard deviation σ(*f*) are computed and then the feature with
    value *x* is transformed as:'
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Z分数标准化**：在这种技术中，也称为标准化，特征值会自动转换，使得平均值是0，标准差是1。转换的技术如下：对于每个特征 *f*，计算其均值 µ(*f*)
    和标准差 σ(*f*)，然后将具有值 *x* 的特征转换如下：'
- en: '![Outliers](img/B05137_02_019.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![异常值](img/B05137_02_019.jpg)'
- en: Discretization
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 离散化
- en: 'Many algorithms can only handle categorical values or nominal values to be
    effective, for example Bayesian Networks. In such cases, it becomes imperative
    to discretize the numeric features into categories using either supervised or
    unsupervised methods. Some of the techniques discussed are:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 许多算法只能处理分类值或名义值才能有效，例如贝叶斯网络。在这种情况下，将数值特征通过监督或无监督方法离散化为类别变得至关重要。讨论的一些技术包括：
- en: '**Discretization by binning**: This technique is also referred to as equal
    width discretization. The entire scale of data for each feature *f*, ranging from
    values *x*[max] and *x*[min] is divided into a predefined number, *k*, of equal
    intervals, each having the width ![Discretization](img/B05137_02_020.jpg). The
    "cut points" or discretization intervals are:![Discretization](img/B05137_02_021.jpg)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过分箱进行离散化**：这种技术也被称为等宽离散化。对于每个特征 *f* 的整个数据范围，从值 *x*[max] 到 *x*[min]，被划分为预定义的
    *k* 个等间隔，每个间隔的宽度为 ![离散化](img/B05137_02_020.jpg)。"切割点"或离散化间隔如下：![离散化](img/B05137_02_021.jpg)'
- en: '**Discretization by frequency**: This technique is also referred to as equal
    frequency discretization. The feature is sorted and then the entire data is discretized
    into predefined *k* intervals, such that each interval contains the same proportion.
    Both the techniques, discretization by binning and discretization by frequency,
    suffer from loss of information due to the predefined value of *k*.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过频率进行离散化**：这种技术也被称为等频率离散化。特征被排序后，整个数据被离散化为预定义的 *k* 个间隔，使得每个间隔包含相同比例的数据。这两种技术，通过分箱和通过频率的离散化，由于预定义的
    *k* 值而损失信息。'
- en: '**Discretization by entropy**: Given the labels, the entropy is calculated
    over the split points where the value changes in an iterative way, so that the
    bins of intervals are as pure or discriminating as possible. Refer to the *Feature
    evaluation techniques* section for entropy-based (information gain) theory and
    calculations.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过熵进行离散化**：给定标签，计算在值变化的迭代点处的熵，使得区间的箱子尽可能纯净或具有区分性。请参阅*特征评估技术*部分，了解基于熵（信息增益）的理论和计算。'
- en: Data sampling
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据采样
- en: The dataset one receives may often require judicious sampling in order to effectively
    learn from the data. The characteristics of the data as well as the goals of the
    modeling exercise determine whether sampling is needed, and if so, how to go about
    it. Before we begin to learn from this data it is crucially important to create
    train, validate, and test data samples, as explained in this section.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接收到的数据集可能经常需要谨慎采样，以便有效地从数据中学习。数据的特征以及建模练习的目标决定了是否需要采样，以及如何进行。在我们开始从这些数据中学习之前，创建训练、验证和测试数据样本至关重要，如本节所述。
- en: Is sampling needed?
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 是否需要采样？
- en: When the dataset is large or noisy, or skewed towards one type, the question
    as to whether to sample or not to sample becomes important. The answer depends
    on various aspects such as the dataset itself, the objective and the evaluation
    criteria used for selecting the models, and potentially other practical considerations.
    In some situations, algorithms have scalability issues in memory and space, but
    work effectively on samples, as measured by model performance with respect to
    the regression or classification goals they are expected to achieve. For example,
    SVM scales as *O(n*²*)* and *O(n*³*)* in memory and training times, respectively.
    In other situations, the data is so imbalanced that many algorithms are not robust
    enough to handle the skew. In the literature, the step intended to re-balance
    the distribution of classes in the original data extract by creating new training
    samples is also called **resampling**.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据集很大或噪声较多，或者偏向于某一类型时，是否进行采样的问题变得重要。答案取决于各种方面，如数据集本身、目标以及用于选择模型的评估标准，以及可能的其他实际考虑。在某些情况下，算法在内存和空间方面存在可扩展性问题，但通过模型性能（根据它们预期实现的回归或分类目标）在样本上工作得很好。例如，SVM在内存和训练时间上的可扩展性分别为*O(n²)*和*O(n³)*。在其他情况下，数据的不平衡程度如此之高，以至于许多算法不足以处理偏斜。在文献中，通过创建新的训练样本来重新平衡原始数据集中类别分布的步骤也被称为**重采样**。
- en: Undersampling and oversampling
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 欠采样和过采样
- en: Datasets exhibiting a marked imbalance in the distribution of classes can be
    said to contain a distinct minority class. Often, this minority class is the set
    of instances that we are especially interested in precisely because its members
    occur in such rare cases. For example, in credit card fraud, less than 0.1% of
    the data belongs to fraud. This skewness is not conducive to learning; after all,
    when we seek to minimize the total error in classification, we give equal weight
    to all classes regardless of whether one class is underrepresented compared to
    another. In binary classification problems, we call the minority class the positive
    class and the majority class as the negative class, a convention that we will
    follow in the following discussion.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在类别分布上存在明显不平衡的数据集可以称为包含一个独特的少数类。通常，这个少数类是我们特别感兴趣的实例集合，因为其成员在如此罕见的情况下出现。例如，在信用卡欺诈中，不到0.1%的数据属于欺诈。这种偏斜不利于学习；毕竟，当我们寻求最小化分类的总误差时，我们给予所有类别相同的权重，无论一个类别相对于另一个类别是否代表性不足。在二元分类问题中，我们将少数类称为正类，将多数类称为负类，这是我们将在以下讨论中遵循的惯例。
- en: Undersampling of the majority class is a technique that is commonly used to
    address skewness in data. Taking credit-card fraud as an example, we can create
    different training samples from the original dataset such that each sample has
    all the fraud cases from the original dataset, whereas the non-fraud instances
    are distributed across all the training samples in some fixed ratios. Thus, in
    a given training set created by this method, the majority class is now underrepresented
    compared to the original skewed dataset, effectively balancing out the distribution
    of classes. Training samples with labeled positive and labeled negative instances
    in ratios of, say, 1:20 to 1:50 can be created in this way, but care must be taken
    that the sample of negative instances used should have similar characteristics
    to the data statistics and distributions of the main datasets. The reason for
    using multiple training samples, and in different proportions of positive and
    negative instances, is so that any sampling bias that may be present becomes evident.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 大类欠采样是一种常用的技术，用于解决数据中的偏斜问题。以信用卡欺诈为例，我们可以从原始数据集中创建不同的训练样本，使得每个样本都包含原始数据集中的所有欺诈案例，而非欺诈实例则以某种固定的比例分布在所有训练样本中。因此，通过这种方法创建的给定训练集中，与原始偏斜数据集相比，多数类现在代表性不足，从而有效地平衡了类别的分布。可以通过这种方式创建带有标记的正例和负例实例，比例为，例如，1:20到1:50，但必须注意，使用的负例样本应具有与主要数据集的数据统计和分布相似的特征。使用多个训练样本，以及正负实例的不同比例，是为了使任何可能存在的采样偏差变得明显。
- en: Alternatively, we may choose to oversample the minority class. As before, we
    create multiple samples wherein instances from the minority class have been selected
    by either sampling with replacement or without replacement from the original dataset.
    When sampling without replacement, there are no replicated instances across samples.
    With replacement, some instances may be found in more than one sample. After this
    initial seeding of the samples, we can produce more balanced distributions of
    classes by random sampling with replacement from within the minority class in
    each sample until we have the desired ratios of positive to negative instances.
    Oversampling can be prone to over-fitting as classification decision boundaries
    tend to become more specific due to replicated values. **SMOTE** (**Synthetic
    Minority Oversampling Technique**) is a technique that alleviates this problem
    by creating synthetic data points in the interstices of the feature space by interpolating
    between neighboring instances of the positive class (*References* [20]).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们也可以选择对少数类进行过采样。和之前一样，我们创建多个样本，其中少数类的实例是通过从原始数据集中有放回或无放回地采样选出的。当无放回地采样时，样本之间没有重复的实例。有放回地采样时，某些实例可能出现在多个样本中。在完成样本的初始播种后，我们可以通过在每个样本中对少数类进行随机有放回采样，直到我们得到所需的正负实例比例，从而产生更平衡的类别分布。过采样可能导致过拟合，因为分类决策边界由于重复值而变得更加具体。**SMOTE（合成少数类过采样技术**）是一种通过在特征空间中创建合成数据点来缓解此问题的技术，它通过在正类相邻实例之间进行插值来实现（*参考文献*
    [20]）。
- en: Stratified sampling
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分层采样
- en: Creating samples so that data with similar characteristics is drawn in the same
    proportion as they appear in the population is known as stratified sampling. In
    multi-class classification, if there are *N* classes each in a certain proportion,
    then samples are created such that they represent each class in the same proportion
    as in the original dataset. Generally, it is good practice to create multiple
    samples to train and test the models to validate against biases of sampling.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 创建样本，使得具有相似特征的数据以与它们在总体中出现的相同比例被抽取，这被称为分层采样。在多类分类中，如果有 *N* 个类别，每个类别以一定的比例存在，那么创建的样本将代表原始数据集中每个类别的相同比例。通常，创建多个样本来训练和测试模型，以验证采样偏差是良好的实践。
- en: Training, validation, and test set
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练集、验证集和测试集
- en: The Holy Grail of creating good classification models is to train on a set of
    good quality, representative, (training data), tune the parameters and find effective
    models (validation data), and finally, estimate the model's performance by its
    behavior on unseen data (test data).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 创建良好的分类模型的圣杯是在一组高质量、具有代表性的（训练数据）上训练，调整参数并找到有效的模型（验证数据），最后，通过其在未见数据上的行为来估计模型的表现（测试数据）。
- en: The central idea behind the logical grouping is to make sure models are validated
    or tested on data that has not been seen during training. Otherwise, a simple
    "rote learner" can outperform the algorithm. The generalization capability of
    the learning algorithm must be evaluated on a dataset which is different from
    the training dataset, but comes from the same population (*References* [11]).
    The balance between removing too much data from training to increase the budget
    of validation and testing can result in models which suffer from "underfitting",
    that is, not having enough examples to build patterns that can help in generalization.
    On the other hand, the extreme choice of allocating all the labeled data for training
    and not performing any validation or testing can lead to "overfitting", that is,
    models that fit the examples too faithfully and do not generalize well enough.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑分组背后的核心思想是确保模型在训练期间未见过的数据上进行验证或测试。否则，一个简单的“死记硬背的学习者”可能会优于算法。学习算法的泛化能力必须在不同于训练数据集但来自同一总体的数据集上评估（*参考文献*
    [11]）。在从训练数据中移除过多数据以增加验证和测试预算之间取得平衡可能导致模型“欠拟合”，即没有足够的例子来构建有助于泛化的模式。另一方面，将所有标记数据分配给训练，而不进行任何验证或测试的极端选择可能导致“过拟合”，即模型过于忠实于例子，泛化能力不足。
- en: Typically, in most machine learning challenges and real world customer problems,
    one is given a training set and testing set upfront for evaluating the performance
    of the models. In these engagements, the only question is how to validate and
    find the most effective parameters given the training set. In some engagements,
    only the labeled dataset is given and you need to consider the training, validation,
    and testing sets to make sure your models do not overfit or underfit the data.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Three logical processes are needed for modeling and hence three logical datasets
    are needed, namely, training, validation, and testing. The purpose of the training
    dataset is to give labeled data to the learning algorithm to build the models.
    The purpose of the validation set is to see the effect of the parameters of the
    training model being evaluated by training on the validation set. Finally, the
    best parameters or models are retrained on the combination of the training and
    validation sets to find an optimum model that is then tested on the blind test
    set.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '![Training, validation, and test set](img/B05137_02_022.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Training, Validation, and Test data and how to use them'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'Two things affect the learning or the generalization capability: the choice
    of the algorithm (and its parameters) and number of training data. This ability
    to generalize can be estimated by various metrics including the prediction errors.
    The overall estimate of unseen error or risk of the model is given by:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![Training, validation, and test set](img/B05137_02_023.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: Here, *Noise* is the stochastic noise, *Var (G,n)* is called the variance error
    and is a measure of how susceptible our hypothesis or the algorithm *(G)* is,
    if given different datasets. ![Training, validation, and test set](img/B05137_02_023a.jpg)
    is called the bias error and represents how far away the best algorithm in the
    model (average learner over all possible datasets) is from the optimal one.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Learning curves as shown in *Figure 2* and *Figure 3*—where training and testing
    errors are plotted keeping either the algorithm with its parameters constant or
    the training data size constant—give an indication of underfitting or overfitting.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: When the training data size is fixed, different algorithms or the same algorithms
    with different parameter choices can exhibit different learning curves. The *Figure
    2* shows two cases of algorithms on the same data size giving two different learning
    curves based on bias and variance.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '![Training, validation, and test set](img/B05137_02_028.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The training data relationship with error rate when the model complexity
    is fixed indicates different choices of models.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm or model choice also impacts model performance. A complex algorithm,
    with more parameters to tune, can result in overfitting, while a simple algorithm
    with less parameters might be underfitting. The classic figure to illustrate the
    model performance and complexity when the training data size is fixed is as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 算法或模型选择也会影响模型性能。一个复杂的算法，具有更多可调整的参数，可能导致过拟合，而一个简单的算法，参数较少，可能存在欠拟合。当训练数据量固定时，以下经典图示了模型性能和复杂性的关系：
- en: '![Training, validation, and test set](img/B05137_02_030.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![训练、验证和测试集](img/B05137_02_030.jpg)'
- en: 'Figure 3: The Model Complexity relationship with Error rate, over the training
    and the testing data when training data size is fixed.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：当训练数据量固定时，模型复杂性与训练和测试数据中的错误率的关系。
- en: 'Validation allows for exploring the parameter space to find the model that
    generalizes best. Regularization (will be discussed in linear models) and validation
    are two mechanisms that should be used for preventing overfitting. Sometimes the
    "k-fold cross-validation" process is used for validation, which involves creating
    *k* samples of the data and using *(k – 1)* to train on and the remaining one
    to test, repeated *k* times to give an average estimate. The following figure
    shows 5-fold cross-validation as an example:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 验证允许探索参数空间以找到最佳泛化模型。正则化（将在线性模型中讨论）和验证是两种用于防止过拟合的机制。有时使用“k折交叉验证”过程进行验证，这涉及到创建*k*个数据样本，使用*(k
    – 1)*个进行训练，剩余的一个进行测试，重复*k*次以给出平均估计。以下图示了5折交叉验证作为示例：
- en: '![Training, validation, and test set](img/B05137_02_034.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![训练、验证和测试集](img/B05137_02_034.jpg)'
- en: 'Figure 4: 5-fold cross-validation.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：5折交叉验证。
- en: 'The following are some commonly used techniques to perform data sampling, validation,
    and learning:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些常用的数据采样、验证和学习的技巧：
- en: '**Random split of training, validation, and testing**: 60, 20, 20\. Train on
    60%, use 20% for validation, and then combine the train and validation datasets
    to train a final model that is used to test on the remaining 20%. Split may be
    done randomly, based on time, based on region, and so on.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练、验证和测试的随机分割**：60%，20%，20%。在60%的数据上训练，使用20%进行验证，然后将训练集和验证集合并以训练一个最终模型，用于在剩余的20%上进行测试。分割可以是随机的，基于时间、基于地区等。'
- en: '**Training, cross-validation, and testing**: Split into Train and Test two
    to one, do validation using cross-validation on the train set, train on whole
    two-thirds and test on one-third. Split may be done randomly, based on time, based
    on region, and so on.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练、交叉验证和测试**：分为训练集和测试集各占三分之一，在训练集上使用交叉验证进行验证，在全部三分之二的数据上训练，在三分之一的数据上测试。分割可以是随机的，基于时间、基于地区等。'
- en: '**Training and cross-validation**: When the training set is small and only
    model selection can be done without much parameter tuning. Run cross-validation
    on the whole dataset and chose the best models with learning on the entire dataset.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练和交叉验证**：当训练集较小时，只能进行模型选择而不需要大量参数调整。在整个数据集上运行交叉验证，并选择在整个数据集上学习的最佳模型。'
- en: Feature relevance analysis and dimensionality reduction
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征相关性分析和降维
- en: The goal of feature relevance and selection is to find the features that are
    discriminating with respect to the target variable and help reduce the dimensions
    of the data [1,2,3]. This improves the model performance mainly by ameliorating
    the effects of the curse of dimensionality and by removing noise due to irrelevant
    features. By carefully evaluating models on the validation set with and without
    features removed, we can see the impact of feature relevance. Since the exhaustive
    search for *k* features involves 2^k – 1 sets (consider all combinations of *^k*
    features where each feature is either retained or removed, disregarding the degenerate
    case where none is present) the corresponding number of models that have to be
    evaluated can become prohibitive, so some form of heuristic search techniques
    are needed. The most common of these techniques are described next.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 特征相关性和选择的目标是找到对目标变量有区分性的特征，并帮助减少数据的维度[1,2,3]。这主要通过改善维度灾难的影响和去除无关特征的噪声来提高模型性能。通过仔细评估在验证集上添加和去除特征时的模型，我们可以看到特征相关性的影响。由于对*k*个特征的穷举搜索涉及2^k
    – 1个集合（考虑所有*k*个特征的组合，每个特征要么保留要么去除，不考虑一个特征都不存在的退化情况），因此需要评估的模型数量可能变得不可接受，因此需要某种启发式搜索技术。以下将描述这些技术中最常见的一些。
- en: Feature search techniques
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征搜索技术
- en: 'Some of the very common search techniques employed to find feature sets are:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 一些非常常见的搜索技术被用来寻找特征集：
- en: '**Forward or hill climbing**: In this search, one feature is added at a time
    until the evaluation module outputs no further change in performance.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前向或爬山搜索**：在这种搜索中，每次添加一个特征，直到评估模块输出性能不再进一步变化。'
- en: '**Backward search**: Starting from the whole set, one feature at a time is
    removed until no performance improvement occurs. Some applications interleave
    both forward and backward techniques to search for features.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反向搜索**：从整个集合开始，每次移除一个特征，直到不再发生性能改进。某些应用程序交替使用前向和反向技术来搜索特征。'
- en: '**Evolutionary search**: Various evolutionary techniques such as genetic algorithms
    can be used as a search mechanism and the evaluation metrics from either filter-
    or wrapper-based methods can be used as fitness criterion to guide the process.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进化搜索**：可以使用各种进化技术，如遗传算法，作为搜索机制，并且可以使用基于过滤器或包装器的评估指标作为适应度标准来指导过程。'
- en: Feature evaluation techniques
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征评估技术
- en: At a high level, there are three basic methods to evaluate features.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，评估特征有三个基本方法。
- en: Filter approach
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过滤器方法
- en: This approach refers to the use of techniques without using machine learning
    algorithms for evaluation. The basic idea of the filter approach is to use a search
    technique to select a feature (or subset of features) and measure its importance
    using some statistical measure until a stopping criterion is reached.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法指的是使用技术而不使用机器学习算法进行评估。过滤器方法的基本思想是使用搜索技术选择一个特征（或特征子集）并使用某种统计量来衡量其重要性，直到达到停止标准。
- en: Univariate feature selection
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 单变量特征选择
- en: This search is as simple as ranking each feature based on the statistical measure
    employed.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这种搜索与根据使用的统计量对每个特征进行排名一样简单。
- en: Information theoretic approach
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 信息论方法
- en: All information theoretic approaches use the concept of entropy mechanism at
    their core. The idea is that if the feature is randomly present in the dataset,
    there is maximum entropy, or, equivalently, the ability to compress or encode
    is low, and the feature may be irrelevant. On the other hand, if the distribution
    of the feature value is such some range of values are more prevalent in one class
    relative to the others, then the entropy is minimized and the feature is discriminating.
    Casting the problem in terms of entropy in this way requires some form of discretization
    to convert the numeric features into categories in order to compute the probabilities.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 所有信息论方法都以熵机制为核心概念。其思想是，如果特征在数据集中随机出现，则熵最大，或者说，压缩或编码的能力低，特征可能是不相关的。另一方面，如果特征值的分布使得某些值在一个类别中相对于其他类别更普遍，那么熵最小化，特征具有区分性。以这种方式将问题表述为熵需要某种形式的离散化，以便将数值特征转换为类别，以便计算概率。
- en: 'Consider a binary classification problem with training data *D*[X]. If *X*[i]
    is the *i*^(th) feature with *v* distinct categorical values such that *D*[Xi]
    *= {D*[1]*, D*[2]*… D*[v]*}*, then information or the entropy in feature *X*[i]
    is:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个具有训练数据 *D*[X] 的二分类问题。如果 *X*[i] 是具有 *v* 个不同分类值的 *i*^(th) 特征，使得 *D*[Xi] *=
    {D*[1]*, D*[2]*… D*[v]*}*，那么特征 *X*[i] 中的信息或熵为：
- en: '![Information theoretic approach](img/B05137_02_041.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![信息论方法](img/B05137_02_041.jpg)'
- en: 'Here, *Info(D*[j]*)* is the entropy of the partition and is calculated as:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*Info(D*[j]*)* 是分割的熵，其计算如下：
- en: '![Information theoretic approach](img/B05137_02_043.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![信息论方法](img/B05137_02_043.jpg)'
- en: Here, *p*[+]*(D)* is the probability that the data in set *D* is in the positive
    class and *p_(D)* is the probability that it is in the negative class, in that
    sample. Information gain for the feature is calculated in terms of the overall
    information and information of the feature as
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*p*[+]*(D)* 是数据集 *D* 中的数据属于正类的概率，而 *p_(D)* 是它属于负类的概率，在该样本中。特征的信息增益是根据整体信息和特征信息来计算的
- en: '*InfoGain(X*[i]*) = Info(D) – Info(D*[Xi]*)*'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*InfoGain(X*[i]*) = Info(D) – Info(D*[Xi]*)*'
- en: For numeric features, the values are sorted in ascending order and split points
    between neighboring values are considered as distinct values.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数值特征，值按升序排序，并且考虑相邻值之间的分割点作为不同的值。
- en: 'The greater the decrease in entropy, the higher the relevance of the feature.
    Information gain has problems when the feature has a large number of values; that
    is when Gain Ratio comes in handy. Gain Ratio corrects the information gain over
    large splits by introducing Split Information. Split Information for feature *X*[i]
    and *GainRatio* is given by:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '![Information theoretic approach](img/B05137_02_048.jpg)![Information theoretic
    approach](img/B05137_02_049.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
- en: There are other impurity measures such as Gini Impurity Index (as described
    in the section on the *Decision Tree* algorithm) and Uncertainty-based measures
    to compute feature relevance.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Statistical approach
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Chi-Squared feature selection is one of the most common feature selection methods
    that has statistical hypothesis testing as its base. The null hypothesis is that
    the feature and the class variable are independent of each other. The numeric
    features are discretized so that all features have categorical values. The contingency
    table is calculated as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature Values | Class=P | Class=N | Sum over classes *niP* + *niN* |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
- en: '| *X*[1] | (*n*[1P]&#124;*µ*[1P]) | (*n*[1N]&#124;*µ*[1N]) | *n*[1] |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
- en: '| …. | … | …. | … |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
- en: '| *X*[m] | (*n*[mP]&#124;*µ*[mP]) | (*n*[mN]&#124;*µ*[mN]) | *n*[m] |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
- en: '|   | *n*[*P] | *n*[*P] | *n* |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
- en: '*Contingency Table 1: Showing feature values and class distribution for binary
    class.*'
  id: totrans-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the preceding table, *n*[ij] is a count of the number of features with value—after
    discretization—equal to *x*[i] and class value of *j*.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'The value summations are:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '![Statistical approach](img/B05137_02_065.jpg)![Statistical approach](img/B05137_02_066.jpg)![Statistical
    approach](img/B05137_02_067.jpg)![Statistical approach](img/B05137_02_068.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
- en: Here *n* is number of data instances, *j = P, N* is the class value and *i =1,2,
    … m* indexes the different discretized values of the feature and the table has
    *m – 1* degrees of freedom.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 'The Chi-Square Statistic is given by:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '![Statistical approach](img/B05137_02_072.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
- en: The Chi-Square value is compared to confidence level thresholds for testing
    significance. For example, for *i = 2*, the Chi-Squared value at threshold of
    5% is 3.84; if our value is smaller than the table value of 3.83, then we know
    that the feature is interesting and the null hypothesis is rejected.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate feature selection
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Most multivariate methods of feature selection have two goals:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Reduce the redundancy between the feature and other selected features
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximize the relevance or correlation of the feature with the class label
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The task of finding such subsets of features cannot be exhaustive as the process
    can have a large search space. Heuristic search methods such as backward search,
    forward search, hill-climbing, and genetic algorithms are typically used to find
    a subset of features. Two very well-known evaluation techniques for meeting the
    preceding goals are presented next.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Minimal redundancy maximal relevance (mRMR)
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this technique, numeric features are often discretized—as done in univariate
    pre-processing—to get distinct categories of values.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'For each subset *S*, the redundancy between two features *X*[i] and *X*[j]
    can be measured as:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![Minimal redundancy maximal relevance (mRMR)](img/B05137_02_077.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: 'Here, *MI (X*[i]*, X*[j]*)* = measure of mutual information between two features
    *X*[i] and *X*[j]. Relevance between feature *X*[i] and class *C* can be measured
    as:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '![Minimal redundancy maximal relevance (mRMR)](img/B05137_02_081.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: 'Also, the two goals can be combined to find the best feature subset using:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '![Minimal redundancy maximal relevance (mRMR)](img/B05137_02_082.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
- en: Correlation-based feature selection (CFS)
  id: totrans-172
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The basic idea is similar to the previous example; the overall merit of subset
    *S* is measured as:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '![Correlation-based feature selection (CFS)](img/B05137_02_083.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
- en: Here, *k* is the total number of features, ![Correlation-based feature selection
    (CFS)](img/B05137_02_084.jpg) is the average feature class correlation and ![Correlation-based
    feature selection (CFS)](img/B05137_02_085.jpg) is the average feature-feature
    inter correlation. The numerator gives the relevance factor while the denominator
    gives the redundancy factor and hence the goal of the search is to maximize the
    overall ratio or the *Merit (S)*.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: There are other techniques such as Fast-Correlation-based feature selection
    that is based on the same principles, but with variations in computing the metrics.
    Readers can experiment with this and other techniques in Weka.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of the Filter approach is that its methods are independent of
    learning algorithms and hence one is freed from choosing the algorithms and parameters.
    They are also faster than wrapper-based approaches.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Wrapper approach
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The search technique remains the same as discussed in the feature search approach;
    only the evaluation method changes. In the wrapper approach, a machine learning
    algorithm is used to evaluate the subset of features that are found to be discriminating
    based on various metrics. The machine learning algorithm used as the wrapper approach
    may be the same or different from the one used for modeling.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Most commonly, cross-validation is used in the learning algorithm. Performance
    metrics such as area under curve or F-score, obtained as an average on cross-validation,
    guide the search process. Since the cost of training and evaluating models is
    very high, we choose algorithms that have fast training speed, such as Linear
    Regression, linear SVM, or ones that are Decision Tree-based.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Some wrapper approaches have been very successful using specific algorithms
    such as Random Forest to measure feature relevance.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Embedded approach
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This approach does not require feature search techniques. Instead of performing
    feature selection as preprocessing, it is done in the machine learning algorithm
    itself. Rule Induction, Decision Trees, Random Forest, and so on, perform feature
    selection as part of the training algorithm. Some algorithms such as regression
    or SVM-based methods, known as **shrinking methods**, can add a regularization
    term in the model to overcome the impact of noisy features in the dataset. Ridge
    and lasso-based regularization are well-known techniques available in regressions
    to provide feature selection implicitly.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: There are other techniques using unsupervised algorithms that will be discussed
    in [Chapter 3](ch03.html "Chapter 3. Unsupervised Machine Learning Techniques"),
    *Unsupervised Machine Learning Techniques*, that can be used effectively in a
    supervised setting too, for example, **Principal Component Analysis** (**PCA**).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Model building
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In real-world problems, there are many constraints on learning and many ways
    to assess model performance on unseen data. Each modeling algorithm has its strengths
    and weaknesses when applied to a given problem or to a class of problems in a
    particular domain. This is articulated in the famous **No Free Lunch Theorem**
    (**NFLT**), which says—for the case of supervised learning—that averaged over
    all distributions of data, every classification algorithm performs about as well
    as any other, including one that always picks the same class! Application of NFLT
    to supervised learning and search and optimization can be found at [http://www.no-free-lunch.org/](http://www.no-free-lunch.org/).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will discuss the most commonly used practical algorithms,
    giving the necessary details to answer questions such as what are the algorithm's
    inputs and outputs? How does it work? What are the advantages and limitations
    to consider while choosing the algorithm? For each model, we will include sample
    code and outputs obtained from testing the model on the chosen dataset. This should
    provide the reader with insights into the process. Some algorithms such as neural
    networks and deep learning, Bayesian networks, stream-based earning, and so on,
    will be covered separately in their own chapters.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Linear models
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Linear models work well when the data is linearly separable. This should always
    be the first thing to establish.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Linear Regression
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Linear Regression can be used for both classification and estimation problems.
    It is one of the most widely used methods in practice. It consists of finding
    the best-fitting hyperplane through the data points.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm input and output
  id: totrans-192
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Features must be numeric. Categorical features are transformed using various
    pre-processing techniques, as when a categorical value becomes a feature with
    1 and 0 values. Linear Regression models output a categorical class in classification
    or numeric values in regression. Many implementations also give confidence values.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The model tries to learn a "hyperplane" in the input space that minimizes the
    error between the data points of each class (*References* [4]).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'A hyperplane in d-dimensional inputs that linear model learns is given by:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_087.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
- en: 'The two regions (binary classification) the model divides the input space into
    are ![How does it work?](img/B05137_02_088.jpg) and ![How does it work?](img/B05137_02_089.jpg).
    Associating a value of 1 to the coordinate of feature 0, that is, *x*0=1, the
    vector representation of hypothesis space or the model is:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_091.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
- en: 'The weight matrix can be derived using various methods such as ordinary least
    squares or iterative methods using matrix notation as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_092.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
- en: 'Here **X** is the input matrix and **y** is the label. If the matrix **X**^T**X**
    in the least squares problem is not of full rank or if encountering various numerical
    stability issues, the solution is modified as:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_096.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
- en: Here, ![How does it work?](img/B05137_02_097.jpg) is added to the diagonal of
    an identity matrix **I**[n] of size (*n* + 1, *n* + 1) with the rest of the values
    being set to 0\. This solution is called **ridge regression** and parameter λ
    theoretically controls the trade-off between the square loss and low norm of the
    solution. The constant λ is also known as regularization constant and helps in
    preventing "overfitting".
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  id: totrans-205
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is an appropriate method to try and get insights when there are less than
    100 features and a few thousand data points.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpretable to some level as the weights give insights on the impact of each
    feature.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assumes linear relationship, additive and uncorrelated features, hence it doesn't
    model complex non-linear real-world data. Some implementations of Linear Regression
    allow removing collinear features to overcome this issue.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Very susceptible to outliers in the data, if there are huge outliers, they have
    to be treated prior to performing Linear Regression.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heteroskedasticity, that is, unequal training point variances, can affect the
    simple least square regression models. Techniques such as weighted least squares
    are employed to overcome this situation.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naïve Bayes
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Based on the Bayes rule, the Naïve Bayes classifier assumes the features of
    the data are independent of each other (*References* [9]). It is especially suited
    for large datasets and frequently performs better than other, more elaborate techniques,
    despite its naïve assumption of feature independence.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm input and output
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Naïve Bayes model can take features that are both categorical and continuous.
    Generally, the performance of Naïve Bayes models improves if the continuous features
    are discretized in the right format. Naïve Bayes outputs the class and the probability
    score for all class values, making it a good classifier for scoring models.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is a probability-based modeling algorithm. The basic idea is using Bayes'
    rule and measuring the probabilities of different terms, as given here. Measuring
    probabilities can be done either using pre-processing such as discretization,
    assuming a certain distribution, or, given enough data, mapping the distribution
    for numeric features.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'Bayes'' rule is applied to get the posterior probability as predictions and
    *k* represents *k*^(th) class.:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_101.jpg)![How does it work?](img/B05137_02_102.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
- en: Advantages and limitations
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is robust against isolated noisy data points because such points are averaged
    when estimating the probabilities of input data.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probabilistic scores as confidence values from Bayes classification can be used
    as scoring models.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can handle missing values very well as they are not used in estimating probabilities.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, it is robust against irrelevant attributes. If the features are not useful
    the probability distribution for the classes will be uniform and will cancel itself
    out.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Very good in training speed and memory, it can be parallelized as each computation
    of probability in the equation is independent of the other.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Correlated features can be a big issue when using Naïve Bayes because the conditional
    independence assumption is no longer valid.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normal distribution of errors is an assumption in most optimization algorithms.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic Regression
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If we employ Linear Regression model using, say, the least squares regression
    method, the outputs have to be converted to classes, say 0 and 1\. Many Linear
    Regression algorithms output class and confidence as probability. As a rule of
    thumb, if we see that the probabilities of Linear Regression are mostly beyond
    the ranges of 0.2 to 0.8, then logistic regression algorithm may be a better choice.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm input and output
  id: totrans-229
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Similar to Linear Regression, all features must be numeric. Categorical features
    have to be transformed to numeric. Like in Naïve Bayes, this algorithm outputs
    class and probability for each class and can be used as a scoring model.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  id: totrans-231
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Logistic regression models the posterior probabilities of classes using linear
    functions in the input features.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'The logistic regression model for a binary classification is given as:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_104.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
- en: The model is a log-odds or logit transformation of linear models (*References*
    [6]). The weight vector is generally computed using various optimization methods
    such as **iterative reweighted least squares** (**IRLS**) or the **Broyden–Fletcher–Goldfarb–Shanno**
    (**BFGS**) method, or variants of these methods.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  id: totrans-236
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Overcomes the issue of heteroskedasticity and some non-linearity between inputs
    and outputs.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No need of normal distribution assumptions in the error estimates.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is interpretable, but less so than Linear Regression models as some understanding
    of statistics is required. It gives information such as odds ratio, *p* values,
    and so on, which are useful in understanding the effects of features on the classes
    as well as doing implicit feature relevance based on significance of *p* values.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: L1 or L2 regularization has to be employed in practice to overcome overfitting
    in the logistic regression models.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many optimization algorithms are available for improving speed of training and
    robustness.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-linear models
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, we will discuss some of the well-known, practical, and most commonly used
    non-linear models.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Decision Trees
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Decision Trees are also known as **Classification and Regression Trees** (**CART**)
    (*References* [5]). Their representation is a binary tree constructed by evaluating
    an inequality in terms of a single attribute at each internal node, with each
    leaf-node corresponding to the output value or class resulting from the decisions
    in the path leading to it. When a new input is provided, the output is predicted
    by traversing the tree starting at the root.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm inputs and outputs
  id: totrans-246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Features can be both categorical and numeric. It generates class as an output
    and most implementations give a score or probability using frequency-based estimation.
    Decision Trees probabilities are not smooth functions like Naïve Bayes and Logistic
    Regression, though there are extensions that are.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  id: totrans-248
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Generally, a single tree is created, starting with single features at the root
    with decisions split into branches based on the values of the features while at
    the leaf there is either a class or more features. There are many choices to be
    made, such as how many trees, how to choose features at the root level or at subsequent
    leaf level, and how to split the feature values when not categorical. This has
    resulted in many different algorithms or modifications to the basic Decision Tree.
    Many techniques to split the feature values are similar to what was discussed
    in the section on discretization. Generally, some form of pruning is applied to
    reduce the size of the tree, which helps in addressing overfitting.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Gini index is another popular technique used to split the features. Gini index
    of data in set *S* of all the data points is ![How does it work?](img/B05137_02_106.jpg)
    where *p*[1], *p*[2] … *p*[k] are probability distribution for each class.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 'If *p* is the fraction or probability of data in set *S* of all the data points
    belonging to say class positive, then 1 – *p* is the fraction for the other class
    or the error rate in binary classification. If the dataset *S* is split in *r*
    ways *S*[1]*, S*[2]*, …S*[r] then the error rate of each set can be quantified
    as |*S*[i]|. Gini index for an *r* way split is as follows:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_113.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
- en: The split with the lowest Gini index is used for selection. The CART algorithm,
    a popular Decision Tree algorithm, uses Gini index for split criteria.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: 'The entropy of the set of data points *S* can similarly be computed as:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_114.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, entropy-based split is computed as:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_115.jpg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
- en: The lower the value of the entropy split, the better the feature, and this is
    used in ID3 and C4.5 Decision Tree algorithms (*References* [12]).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: The stopping criteria and pruning criteria are related. The idea behind stopping
    the growth of the tree early or pruning is to reduce the "overfitting" and it
    works similar to regularization in linear and logistic models. Normally, the training
    set is divided into tree growing sets and pruning sets so that pruning uses different
    data to overcome any biases from the growing set. **Minimum Description Length**
    (**MDL**), which penalizes the complexity of the tree based on number of nodes
    is a popular methodology used in many Decision Tree algorithms.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_116.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Shows a two-dimensional binary classification problem and a Decision
    Tree induced using splits at thresholds *X*[1t] and *X*[1t], respectively'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  id: totrans-262
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The main advantages of Decision Trees are they are quite easily interpretable.
    They can be understood in layman's terms and are especially suited for business
    domain experts to easily understand the exact model.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there are a large number of features, then building Decision Tree can take
    lots of training time as the complexity of the algorithm increases.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision Trees have an inherent problem with overfitting. Many tree algorithms
    have pruning options to reduce the effect. Using pruning and validation techniques
    can alleviate the problem to a large extent.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision Trees work well when there is correlation between the features.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision Trees build axis-parallel boundaries across classes, the bias of which
    can introduce errors, especially in a complex, smooth, non-linear boundary.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: K-Nearest Neighbors (KNN)
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: K-Nearest Neighbors falls under the branch of non-parametric and lazy algorithms.
    K-Nearest neighbors doesn't make any assumptions on the underlying data and doesn't
    build and generalize models from training data (*References* [10]).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm inputs and outputs
  id: totrans-270
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Though KNN's can work with categorical and numeric features, the distance computation,
    which is the core of finding the neighbors, works better with numeric features.
    Normalization of numeric features to be in the same ranges is one of the mandatory
    steps required. KNN's outputs are generally the classes based on the neighbors'
    distance calculation.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'KNN uses the entire training data to make predictions on unseen test data.
    When unseen test data is presented KNN finds the K "nearest neighbors" using some
    distance computation and based on the neighbors and the metric of deciding the
    category it classifies the new point. If we consider two vectors represented by
    **x**[1] and **x**[2] corresponding to two data points the distance is calculated
    as:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Euclidean Distance:![How does it work?](img/B05137_02_121.jpg)
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cosine Distance or similarity:![How does it work?](img/B05137_02_122.jpg)
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The metric used to classify an unseen may simply be the majority class among
    the *K* neighbors.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: The training time is small as all it has to do is build data structures to hold
    the data in such a way that the computation of the nearest neighbor is minimized
    when unseen data is presented. The algorithm relies on choices of how the data
    is stored from training data points for efficiency of searching the neighbors,
    which distance computation is used to find the nearest neighbor, and which metrics
    are used to categorize based on classes of all neighbors. Choosing the value of
    "*K*" in KNN by using validation techniques is critical.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_123.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: K-Nearest Neighbor illustrated using two-dimensional data with different
    choices of k.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  id: totrans-280
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: No assumption on underlying data distribution and minimal training time makes
    it a very attractive method for learning.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: KNN uses local information for computing the distances and in certain domains
    can yield highly adaptive behaviors.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is robust to noisy training data when *K* is effectively chosen.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Holding the entire training data for classification can be problematic depending
    on the number of data points and hardware constraints
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of features and the curse of dimensionality affects this algorithm more
    hence some form of dimensionality reduction or feature selection has to be done
    prior to modeling in KNN.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support vector machines (SVM)
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SVMs, in simple terms, can be viewed as linear classifiers that maximize the
    margin between the separating hyperplane and the data by solving a constrained
    optimization problem. SVMs can even deal with data that is not linearly separable
    by invoking transformation to a higher dimensional space using kernels described
    later.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm inputs and outputs
  id: totrans-288
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SVM is effective with numeric features only, though most implementations can
    handle categorical features with transformation to numeric or binary. Normalization
    is often a choice as it helps the optimization part of the training. Outputs of
    SVM are class predictions. There are implementations that give probability estimates
    as confidences, but this requires considerable training time as they use k-fold
    cross-validation to build the estimates.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  id: totrans-290
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In its linear form, SVM works similar to Linear Regression classifier, where
    a linear decision boundary is drawn between the two classes. The difference between
    the two is that with SVM, the boundary is drawn in such a way that the "margin"
    or the distance between the points near the boundary is maximized. The points
    on the boundaries are known as "support vectors" (*References* [13 and 8]).
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, SVM tries to find the weight vector in linear models similar to Linear
    Regression model as given by the following:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_124.jpg)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
- en: 'The weight *w*[0] is represented by *b* here. SVM for a binary class y ∈{1,-1}
    tries to find a hyperplane:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_127.jpg)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
- en: 'The hyperplane tries to separate the data points such that all points with
    the class lie on the side of the hyperplane as:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_128.jpg)![How does it work?](img/B05137_02_129.jpg)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
- en: 'The models are subjected to maximize the margin using constraint-based optimization
    with a penalty function denoted by *C* for overcoming the errors denoted by ![How
    does it work?](img/B05137_02_131.jpg):'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_132.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
- en: Such that ![How does it work?](img/B05137_02_133.jpg) and ![How does it work?](img/B05137_02_134.jpg).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: They are also known as large margin classifiers for the preceding reason. The
    kernel-based SVM transforms the input data into a hypothetical feature space where
    SV machinery works in a linear way and the boundaries are drawn in the feature
    spaces.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: 'A kernel function on the transformed representation is given by:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_135.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
- en: Here Φ is a transformation on the input space. It can be seen that the entire
    optimization and solution of SVM remains the same with the only exception that
    the dot-product **x**[i] · **x**[j] is replaced by the kernel function *k*(**x**[i],
    **x**[j]), which is a function involving the two vectors in a different space
    without actually transforming to that space. This is known as the **kernel trick**.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: 'The most well-known kernels that are normally used are:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '**Gaussian Radial Basis Kernel**:![How does it work?](img/B05137_02_139.jpg)'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Polynomial Kernel**:![How does it work?](img/B05137_02_140.jpg)'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sigmoid Kernel**:![How does it work?](img/B05137_02_141.jpg)'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVM's performance is very sensitive to some of the parameters of optimization
    and the kernel parameters and the core SV parameter such as the cost function
    *C*. Search techniques such as grid search or evolutionary search combined with
    validation techniques such as cross-validation are generally used to find the
    best parameter values.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_142.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: SVM Linear Hyperplane learned from training data that creates a maximum
    margin separation between two classes.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_144.jpg)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Kernel transformation illustrating how two-dimensional input space
    can be transformed using a polynomial transformation into a three-dimensional
    feature space where data is linearly separable.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  id: totrans-314
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SVMs are among the best in generalization, low overfitting, and have a good
    theoretical foundation for complex non-linear data if the parameters are chosen
    judiciously.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVMs work well even with a large number of features and less training data.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVMs are less sensitive to noisy training data.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The biggest disadvantage of SVMs is that they are not interpretable.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another big issue with SVM is its training time and memory requirements. They
    are *O(n*²*)* and *O(n*³*)* and can result in major scalability issues when the
    data is large or there are hardware constraints. There are some modifications
    that help in reducing both.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVM generally works well for binary classification problems, but for multiclass
    classification problems, though there are techniques such as one versus many and
    one versus all, it is not as robust as some other classifiers such as Decision
    Trees.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensemble learning and meta learners
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Combining multiple algorithms or models to classify instead of relying on just
    one is known as ensemble learning. It helps to combine various models as each
    model can be considered—at a high level—as an expert in detecting specific patterns
    in the whole dataset. Each base learner can be made to learn on slightly different
    datasets too. Finally, the results from all models are combined to perform prediction.
    Based on how similar the algorithms used in combination are, how the training
    dataset is presented to each algorithm, and how the algorithms combine the results
    to finally classify the unseen dataset, there are many branches of ensemble learning:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '![Ensemble learning and meta learners](img/B05137_02_145.jpg)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Illustration of ensemble learning strategies'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: 'Some common types of ensemble learning are:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Different learning algorithms
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Same learning algorithms, but with different parameter choices
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different learning algorithms on different feature sets
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different learning algorithms with different training data
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bootstrap aggregating or bagging
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is one of the most commonly used ensemble methods for dividing the data in
    different samples and building classifiers on each sample.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm inputs and outputs
  id: totrans-332
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The input is constrained by the choice of the base learner used—if using Decision
    Trees there are basically no restrictions. The method outputs class membership
    along with the probability distribution for classes.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  id: totrans-334
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The core idea of bagging is to apply the bootstrapping estimation to different
    learners that have high variance, such as Decision Trees. Bootstrapping is any
    statistical measure that depends on random sampling with replacement. The entire
    data is split into different samples using bootstrapping and for each sample,
    a model is built using the base learner. Finally, while predicting, the average
    prediction is arrived at using a majority vote—this is one technique to combine
    over all the learners.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: Random Forest
  id: totrans-336
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Random Forest is an improvement over basic bagged Decision Trees. Even with
    bagging, the basic Decision Tree has a choice of all the features at every split
    point in creating a tree. Because of this, even with different samples, many trees
    can form highly correlated submodels, which causes the performance of bagging
    to deteriorate. By giving random features to different models in addition to a
    random dataset, the correlation between the submodels reduces and Random Forest
    shows much better performance compared to basic bagged trees. Each tree in Random
    Forest grows its structure on the random features, thereby minimizing the bias;
    combining many such trees on decision reduces the variance (*References* [15]).
    Random Forest is also used to measure feature relevance by averaging the impurity
    decrease in the trees and ranking them across all the features to give the relative
    importance of each.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  id: totrans-338
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Better generalization than the single base learner. Overcomes the issue of overfitting
    of base learners.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpretability of bagging is very low as it works as meta learner combining
    even the interpretable learners.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like most other ensemble learners, Bagging is resilient to noise and outliers.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random Forest generally does not tend to overfit given the training data is
    iid.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boosting
  id: totrans-343
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Boosting is another popular form of ensemble learning, which is based on using
    a weak learner and iteratively learning the points that are "misclassified" or
    difficult to learn. Thus, the idea is to "boost" the difficult to learn instances
    and making the base learners learn the decision boundaries more effectively. There
    are various flavors of boosting such as AdaBoost, LogitBoost, ConfidenceBoost,
    Gradient Boosting, and so on. We present a very basic form of AdaBoost here (*References*
    [14]).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm inputs and outputs
  id: totrans-345
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The input is constrained by the choice of the base learner used—if using Decision
    Trees there are basically no restrictions. Outputs class membership along with
    probability distribution for classes.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  id: totrans-347
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The basic idea behind boosting is iterative reweighting of input samples to
    create new distribution of the data for learning a model from a simple base learner
    in every iteration.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Initially, all the instances are uniformly weighted with weights ![How does
    it work?](img/B05137_02_146.jpg) and at every iteration *t*, the population is
    resampled or reweighted as ![How does it work?](img/B05137_02_148.jpg) where ![How
    does it work?](img/B05137_02_149.jpg) and *Z*t is the normalization constant.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: 'The final model works as a linear combination of all the models learned in
    the iteration:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_02_151.jpg)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
- en: The reweighting or resampling of the data in each iteration is based on "errors";
    the data points that result in errors are sampled more or have larger weights.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  id: totrans-353
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Better generalization than the base learner and overcomes the issue of overfitting
    very effectively.
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some boosting algorithms such as AdaBoost can be susceptible to uniform noise.
    There are variants of boosting such as "GentleBoost" and "BrownBoost" that decrease
    the effect of outliers.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boosting has a theoretical bounds and guarantee on the error estimation making
    it a statistically robust algorithm.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model assessment, evaluation, and comparisons
  id: totrans-357
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The key ideas discussed here are:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: How to assess or estimate the performance of the classifier on unseen datasets
    that it will be predicting on future unseen datasets.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the metrics that we should use to assess the performance of the model?
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we compare algorithms if we have to choose between them?
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model assessment
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to train the model(s), tune the model parameters, select the models,
    and finally estimate the predictive behavior of models on unseen data, we need
    many datasets. We cannot train the model on one set of data and estimate its behavior
    on the same set of data, as it will have a clear optimistic bias and estimations
    will be unlikely to match the behavior in the unseen data. So at a minimum, there
    is a need to partition data available into training sets and testing sets. Also,
    we need to tune the parameters of the model and test the effect of the tuning
    on a separate dataset before we perform testing on the test set. The same argument
    of optimistic bias and wrong estimation applies if we use the same dataset for
    training, parameter tuning, and testing. Thus there is a theoretical and practical
    need to have three datasets, that is, training, validation, and testing.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: The models are trained on the training set, the effect of different parameters
    on the training set are validated on the validation set, and the finalized model
    with the selected parameters is run on the test set to gauge the performance of
    the model on future unseen data. When the dataset is not large enough, or is large
    but the imbalance between classes is wide, that is, one class is present only
    in a small fraction of the total population, we cannot create too many samples.
    Recall that one of the steps described in our methodology is to create different
    data samples and datasets. If the total training data is large and has a good
    proportion of data and class ratios, then creating these three sets using random
    stratified partitioning is the most common option employed. In certain datasets
    that show seasonality and time-dependent behaviors, creating datasets based on
    time bounds is a common practice. In many cases, when the dataset is not large
    enough, only two physical partitions, that is, training and testing may be created.
    The training dataset ranges roughly from 66% to 80% while the rest is used for
    testing. The validation set is then created from the training dataset using the
    k-fold cross-validation technique. The training dataset is split *k* times, each
    time producing *k-1/k* random training *1/k* testing data samples, and the average
    metrics of performance needed is generated. This way the limited training data
    is partitioned *k* times and average performance across different split of training/testing
    is used for gauging the effect of the parameters. Using 10-fold cross-validation
    is the most common practice employed in cross-validation.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: Model evaluation metrics
  id: totrans-365
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next important decision when tuning parameters or selecting models is to
    base your decision on certain performance metrics. In classification learning,
    there are different metrics available on which you can base your decision, depending
    on the business requirement. For example, in certain domains, not missing a single
    true positive is the most important concern, while in other domains where humans
    are involved in adjudicating results of models, having too many false positives
    is the greater concern. In certain cases, having overall good accuracy is considered
    more vital. In highly imbalanced datasets such as fraud or cyber attacks, there
    are just a handful of instances of one class and millions of the other classes.
    In such cases accuracy gives a wrong indication of model performance and some
    other metrics such as precision, true positive ratio, or area under the curve
    are used as metrics.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: We will now discuss the most commonly employed metrics in classification algorithms
    evaluation (*References* [16, 17, and 19]).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '![Model evaluation metrics](img/B05137_02_152.jpg)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Model evaluation metrics for classification models'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: Confusion matrix and related metrics
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Confusion matrix and related metrics](img/B05137_02_153.jpg)'
  id: totrans-371
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Confusion Matrix'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: The confusion matrix is central to the definition of a number of model performance
    metrics. The proliferation of metrics and synonymous terms is a result of the
    utility of different quantities derived from the elements of the matrix in various
    disciplines, each emphasizing a different aspect of the model's behavior.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: The four elements of the matrix are raw counts of the number of False Positives,
    False Negatives, True Positives, and True Negatives. Often more interesting are
    the different ratios of these quantities, the True Positive Rate (or Sensitivity,
    or Recall), and the False Positive Rate (FPR, or 1—Specificity, or Fallout). Accuracy
    reflects the percentage of correct predictions, whether Class 1 or Class 0\. For
    skewed datasets, accuracy is not particularly useful, as even a constant prediction
    can appear to perform well.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: ROC and PRC curves
  id: totrans-375
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The previously mentioned metrics such as accuracy, precision, recall, sensitivity,
    and specificity are aggregates, that is, they describe the behavior of the entire
    dataset. In many complex problems it is often valuable to see the trade-off between
    metrics such as TPs and say FPs.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: Many classifiers, mostly probability-based classifiers, give confidence or probability
    of the prediction, in addition to giving classification. The process to obtain
    the ROC or PRC curves is to run the unseen validation or test set on the learned
    models, and then obtain the prediction and the probability of prediction. Sort
    the predictions based on the confidences in decreasing order. For every probability
    or confidence calculate two metrics, the fraction of FP (FP rate) and the fraction
    of TP (TP rate).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: 'Plotting the TP rate on the *y* axis and FP rate on the *x* axis gives the
    ROC curves. ROC curves of random classifiers lie close to the diagonal while the
    ROC curves of good classifiers tend towards the upper left of the plot. The **area
    under the curve** (**AUC**) is the area measured under the ROC curve by using
    the trapezoidal area from 0 to 1 of ROC curves. While running cross-validation
    for instance there can be many ROC curves. There are two ways to get "average"
    ROC curves: first, using vertical averaging, that is, TPR average is plotted at
    different FP rate or second, using horizontal averaging, that is, FPR average
    is plotted at different TP rate. The classifiers that have area under curves greater
    than 0.8, as a rule-of-thumb are considered good for prediction for unseen data.'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: Precision Recall curves or PRC curves are similar to ROC curves, but instead
    of TPR versus FPR, metrics Precision and Recall are plotted on the *y* and *x*
    axis, respectively. When the data is highly imbalanced, that is, ROC curves don't
    really show the impact while PRC curves are more reliable in judging performance.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: Gain charts and lift curves
  id: totrans-380
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Lift and Gain charts are more biased towards sensitivity or true positives.
    The whole purpose of these two charts is to show how instead of random selection,
    the models prediction and confidence can detect better quality or true positives
    in the sample of unseen data.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: This is usually very appealing for detection engines that are used in detecting
    fraud in financial crime or threats in cyber security. The gain charts and lift
    curves give exact estimates of real true positives that will be detected at different
    quartiles or intervals of total data. This will give insight to the business decision
    makers on how many investigators would be needed or how many hours would be spent
    towards detecting fraudulent actions or cyber attacks and thus can give real ROI
    of the models.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: The process for generating gain charts or lift curves has a similar process
    of running unseen validation or test data through the models and getting the predictions
    along with the confidences or probabilities. It involves ranking the probabilities
    in decreasing order and keeping count of TPs per quartile of the dataset. Finally,
    the histogram of counts per quartile give the lift curve, while the cumulative
    count of TPs added over quartile gives the gains chart. In many tools such as
    RapidMiner, instead of coarse intervals such as quartiles, fixed larger intervals
    using binning is employed for obtaining the counts and cumulative counts.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: Model comparisons
  id: totrans-384
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When it comes to choosing between algorithms, or the right parameters for a
    given algorithm, we make the comparison either on different datasets, or, as in
    the case of cross-validation, on different splits of the same dataset. Measures
    of statistical testing are employed in decisions involved in these comparisons.
    The basic idea of using hypothesis testing from classical statistics is to compare
    the two metrics from the algorithms. The null hypothesis is that there is no difference
    between the algorithms based on the measured metrics and so the test is done to
    validate or reject the null hypothesis based on the measured metrics (*References*
    [16]). The main question answered by statistical tests is- are the results or
    metrics obtained by the algorithm its real characteristics, or is it by chance?
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will discuss the most common methods for comparing classification
    algorithms used in practical scenarios.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: Comparing two algorithms
  id: totrans-387
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The general process is to train the algorithms on the same training set and
    run the models on either multiple validation sets, different test sets, or cross-validation,
    gauge the metrics of interest discussed previously, such as error rate or area
    under curve, and then get the statistics of the metrics for each of the algorithms
    to decide which worked better. Each method has its advantages and disadvantages.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: McNemar's Test
  id: totrans-389
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This is a non-parametric test and thus it makes no assumptions on data and
    distribution. McNemar''s test builds a contingency table of a performance metric
    such as "misclassification or errors" with:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: Count of misclassification by both algorithms (*c*[00])
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: Count of misclassification by algorithm *G1*, but correctly classified by algorithm
    *G2*(*c*[01])
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Count of misclassification by algorithm *G2*, but correctly classified by algorithm
    *G1* (*c*[10])
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Count of correctly classified by both *G1* and *G2*(*c*[11])![McNemar's Test](img/B05137_02_162.jpg)
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If χ² exceeds ![McNemar's Test](img/B05137_02_164.jpg) statistic then we can
    reject the null hypothesis that the two performance metrics on algorithms *G1*
    and *G2* were equal under the confidence value of 1 – α.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: Paired-t test
  id: totrans-396
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This is a parametric test and an assumption of normally distributed computed
    metrics becomes valid. Normally it is coupled with cross-validation processes
    and results of metrics such as area under curve or precision or error rate is
    computed for each and then the mean and standard deviations are measured. Apart
    from normal distribution assumption, the additional assumption that two metrics
    come from a population of equal variance can be a big disadvantage for this method.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: '![Paired-t test](img/B05137_02_166.jpg)'
  id: totrans-398
  prefs: []
  type: TYPE_IMG
- en: '![Paired-t test](img/B05137_02_167.jpg) is difference of means in performance
    metrics of two algorithms *G1* and *G2*.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '![Paired-t test](img/B05137_02_168.jpg)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
- en: Here, *d*i is the difference between the performance metrics of two algorithms
    *G1* and *G2* in the trial and there are *n* trials.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: 'The *t*-statistic is computed using the mean differences and the standard errors
    from the standard deviation as follows and is compared to the table for the right
    alpha value to check for significance:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: '![Paired-t test](img/B05137_02_170.jpg)'
  id: totrans-403
  prefs: []
  type: TYPE_IMG
- en: Wilcoxon signed-rank test
  id: totrans-404
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The most popular non-parametric method of testing two metrics over datasets
    is to use the Wilcoxon signed-rank test. The algorithms are trained on the same
    training data and metrics such as error rate or area under accuracy are calculated
    over different validation or test sets. Let *d*[i] be the difference between the
    performance metrics of two classifiers in the *i*^(th) trial for *N* datasets.
    Differences are then ranked according to their absolute values, and mean ranks
    associated for ties. Let *R*^+ be the sum of ranks where the second algorithm
    outperformed the first and R^– be the sum of ranks where the first outperformed
    the second:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: '![Wilcoxon signed-rank test](img/B05137_02_174.jpg)![Wilcoxon signed-rank test](img/B05137_02_175.jpg)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
- en: The statistic ![Wilcoxon signed-rank test](img/B05137_02_176.jpg) is then compared
    to threshold value at an alpha, ![Wilcoxon signed-rank test](img/B05137_02_177.jpg)
    to reject the hypothesis.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: Comparing multiple algorithms
  id: totrans-408
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will now discuss the two most common techniques used when there are more
    than two algorithms involved and we need to perform comparison across many algorithms
    for evaluation metrics.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: ANOVA test
  id: totrans-410
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: These are parametric tests that assume normal distribution of the samples, that
    is, metrics we are calculating for evaluations. ANOVA test follows the same process
    as others, that is, train the models/algorithms on similar training sets and run
    it on different validation or test sets. The main quantities computed in ANOVA
    are the metric means for each algorithm performance and then compute the overall
    metric means across all algorithms.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: 'Let *p*[ij] be the performance metric for *i = 1,2… k* and *j = 1,2 …l* for
    *k* trials and *l* classifiers. The mean performance of classifier *j* on all
    trials and overall mean performance is:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: '![ANOVA test](img/B05137_02_182.jpg)![ANOVA test](img/B05137_02_183.jpg)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
- en: 'Two types of variation are evaluated. The first is within-group variation,
    that is, total deviation of each algorithm from the overall metric mean, and the
    second is between-group variation, that is, deviation of each algorithm metric
    mean. Within-group variation and between-group variation are used to compute the
    respective within- and between- sum of squares as:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: '![ANOVA test](img/B05137_02_184.jpg)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
- en: 'Using the two sum of squares and a computation such as F-statistic, which is
    the ratio of the two, the significance test can be done at alpha values to accept
    or reject the null hypothesis:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: '![ANOVA test](img/B05137_02_185.jpg)'
  id: totrans-417
  prefs: []
  type: TYPE_IMG
- en: ANOVA tests have the same limitations as paired-t tests on the lines of assumptions
    of normal distribution of metrics and assuming the variances being equal.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: Friedman's test
  id: totrans-419
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Friedman''s test is a non-parametric test for multiple algorithm comparisons
    and it has no assumption on the data distribution or variances of metrics that
    ANOVA does. It uses ranks instead of the performance metrics directly for its
    computation. On each dataset or trials, the algorithms are sorted and the best
    one is ranked 1 and so on for all classifiers. The average rank of an algorithm
    over *n* datasets is computed, say *R*[j]. The Friedman''s statistic over *l*
    classifiers is computed as follows and compared to alpha values to accept or reject
    the null hypothesis:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: '![Friedman''s test](img/B05137_02_187.jpg)'
  id: totrans-421
  prefs: []
  type: TYPE_IMG
- en: Case Study – Horse Colic Classification
  id: totrans-422
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To illustrate the different steps and methodologies described in [Chapter 1](ch01.html
    "Chapter 1. Machine Learning Review"), *Machine Learning Review*, from data analysis
    to model evaluation, a representative dataset that has real-world characteristics
    is essential.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: 'We have chosen "Horse Colic Dataset" from the UCI Repository available at the
    following link: [https://archive.ics.uci.edu/ml/datasets/Horse+Colic](https://archive.ics.uci.edu/ml/datasets/Horse+Colic)'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: The dataset has 23 features and has a good mix of categorical and continuous
    features. It has a large number of features and instances with missing values,
    hence understanding how to replace these missing values and using it in modeling
    is made more practical in this treatment. The large number of missing data (30%)
    is in fact a notable feature of this dataset. The data consists of attributes
    that are continuous, as well as nominal in type. Also, the presence of self-predictors
    makes working with this dataset instructive from a practical standpoint.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: The goal of the exercise is to apply the techniques of supervised learning that
    we have assimilated so far. We will do this using a real dataset and by working
    with two open source toolkits—WEKA and RapidMiner. With the help of these tools,
    we will construct the pipeline that will allow us to start with the ingestion
    of the data file through data cleansing, the learning process, and model evaluation.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: Weka is a Java framework for machine learning—we will see how to use this framework
    to solve a classification problem from beginning to end in a few lines of code.
    In addition to a Java API, Weka also has a GUI.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: RapidMiner is a graphical environment with drag and drop capability and a large
    suite of algorithms and visualization tools that makes it extremely easy to quickly
    run experiments with data and different modeling techniques.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: Business problem
  id: totrans-429
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The business problem is to determine given values for the well-known variables
    of the dataset—if the lesion of the horse was surgical. We will use the test set
    as the unseen data that must be classified.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning mapping
  id: totrans-431
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Based on the data and labels, this is a binary classification problem. The data
    is already split into training and testing data. This makes the evaluation technique
    simpler as all methodologies from feature selection to models can be evaluated
    on the same test data.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: The dataset contains 300 training and 68 test examples. There are 28 attributes
    and the target corresponds to whether or not a lesion is surgical.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis
  id: totrans-434
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After looking at the distribution of the label categories over the training
    and test samples, we combine the 300 training samples and the 68 test samples
    prior to feature analyzes.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: Label analysis
  id: totrans-436
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The ratio of the No Class to Yes Class is 109/191 = 0.57 in the Training set
    and 0.66 in the Test set:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: '| Training dataset |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
- en: '| Surgical Lesion? | 1 (Yes) | 2 (No) |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
- en: '| Number of examples | 191 | 109 |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
- en: '| Testing dataset |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
- en: '| Surgical Lesion? | 1 (Yes) | 2 (No) |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
- en: '| Number of examples | 41 | 27 |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
- en: '*Table 2: Label analysis*'
  id: totrans-445
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Features analysis
  id: totrans-446
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following is a screenshot of top features with characteristics of types,
    missing values, basic statistics of minimum, maximum, modes, and standard deviations
    sorted by missing values. Observations are as follows:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: There are no categorical or continuous features with non-missing values; the
    least is the feature "pulse" with 74 out of 368 missing, that is, 20% values missing,
    which is higher than general noise threshold!
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most numeric features have missing values, for example, "nasogastric reflux
    PH" has 247 out of 368 values missing, that is, 67% values are missing!
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many categorical features have missing values, for example, "abidominocentesis
    appearance" have 165 out of 368 missing, that is, 45% values are missing!
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Missing values have to be handled in some way to overcome the noise created
    by such large numbers!![Features analysis](img/B05137_02_188.jpg)
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Figure 12: Basic statistics of features from datasets.'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Supervised learning experiments
  id: totrans-453
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will cover supervised learning experiments using two different
    tools—highlighting coding and analysis in one tool and the GUI framework in the
    other. This gives the developers the opportunity to explore whichever route they
    are most comfortable with.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: Weka experiments
  id: totrans-455
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we have given the entire code and will walk through the process
    from loading data, transforming the data, selecting features, building sample
    models, evaluating them on test data, and even comparing the algorithms for statistical
    significance.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: Sample end-to-end process in Java
  id: totrans-457
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In each algorithm, the same training/testing data is used and evaluation is
    performed for all the metrics as follows. The training and testing file is loaded
    in memory as follows:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The generic code, using WEKA, is shown here, where each classifier is wrapped
    by a filtered classifier for replacing missing values:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When the classifier needs to perform Feature Selection, in Weka, `AttributeSelectedClassifier`
    further wraps the `FilteredClassifier` as shown in the following listing:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The sample output of evaluation is given here:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Weka experimenter and model selection
  id: totrans-466
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As explained in the *Model evaluation metrics* section, to select models, we
    need to validate which one will work well on unseen datasets. Cross-validation
    must be done on the training set and the performance metric of choice needs to
    be analyzed using standard statistical testing metrics. Here we show an example
    using the same training data, 10-fold cross validation, performing 30 experiments
    on two models, and comparison of results using paired-t tests.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: One uses Naïve Bayes with preprocessing that includes replacing missing values
    and performing feature selection by removing any features with a score below 0.0.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: Another uses the same preprocessing and AdaBoostM1 with Naïve Bayes.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: '![Weka experimenter and model selection](img/B05137_02_189.jpg)'
  id: totrans-470
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: WEKA experimenter showing the process of using cross-validation
    runs with 30 repetitions with two algorithms.'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: '![Weka experimenter and model selection](img/B05137_02_190.jpg)'
  id: totrans-472
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: WEKA Experimenter results showing two algorithms compared on metric
    of percent correct or accuracy using paired-t test.'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: RapidMiner experiments
  id: totrans-474
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's now run some experiments using the Horse-colic dataset in RapidMiner.
    We will again follow the methodology presented in the first part of the chapter.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-476
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section is not intended as a tutorial on the RapidMiner tool. The experimenter
    is expected to read the excellent documentation and user guide to familiarize
    themselves with the use of the tool. There is a tutorial dedicated to every operator
    in the software—we recommend you make use of these tutorials whenever you want
    to learn how a particular operator is to be used.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: Once we have imported the test and training data files using the data access
    tools, we will want to visually explore the dataset to familiarize ourselves with
    the lay of the land. Of particular importance is to recognize whether each of
    the 28 attributes are continuous (numeric, integer, or real in RapidMiner) or
    categorical (nominal, binominal, or polynominal in RapidMiner).
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: Visualization analysis
  id: totrans-479
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: From the **Results** panel of the tool, we perform univariate, bivariate, and
    multivariate analyses of the data. The Statistics tool gives a short summary for
    each feature—min, max, mean, and standard deviation for continuous types and least,
    most, and frequency by category for nominal types.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: 'Interesting characteristics of the data begin to show themselves as we get
    into bivariate analysis. In the Quartile Color Matrix, the color represents the
    two possible target values. As seen in the box plots, we immediately notice some
    attributes discriminate between the two target values more clearly than others.
    Let''s examine a few:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualization analysis](img/B05137_02_191.jpg)'
  id: totrans-482
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: Quartile Color Matrix'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: 'Peristalsis: This feature shows a marked difference in distribution when separated
    by target value. There is almost no overlap in the inter-quartile regions between
    the two. This points to the discriminating power of this feature with respect
    to the target.'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: The plot for Rectal Temperature, on the other hand, shows no perceptible difference
    in the distributions. This suggests that this feature has low correlation with
    the target. A similar inference may be drawn from the feature Pulse. We expect
    these features to rank fairly low when we evaluate the features for their discriminating
    power with respect to the target.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, the plot for Pain has a very different characteristic. It is also discriminating
    of the target, but in a very different way than Peristalsis. In the case of Pain,
    the variance in data for Class 2 is much larger than Class 1\. Abdominal Distension
    also has markedly dissimilar variance across the classes, except with the larger
    variance in Class 2 compared to Class 1.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualization analysis](img/B05137_02_192.jpg)'
  id: totrans-487
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: Scatter plot matrix'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: An important part of exploring the data is understanding how different attributes
    correlate with each other and with the target. Here we consider pairs of features
    and see if the occurrence of values *in combination* tells us something about
    the target. In these plots, the color of the data points is the target.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualization analysis](img/B05137_02_193.jpg)'
  id: totrans-490
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17: Bubble chart'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: In the bubble chart we can visualize four features at once by using the graphing
    tools to specify the *x* and *y* axes as well as a third dimension expressed as
    the size of bubble representing the feature. The target class is denoted by the
    color.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: At the low end of total protein, we see higher pH values in the mid-range of
    rectal temperature values. In this cluster, high pH values appear to show a stronger
    correlation to lesions that were surgical. Another cluster with wider variance
    in total protein is also found for values of total protein greater than 50\. The
    variance in pH is also low in this cluster.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: Feature selection
  id: totrans-494
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Having gained some insight into the data, we are ready to use some of the techniques
    presented in the theory that evaluate feature relevance.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we use two techniques: one that calculates the weights for features based
    on Chi-squared statistics with respect to the target attribute and the other based
    on the Gini Impurity Index. The results are shown in the table. Note that as we
    inferred while doing analysis of the features via visualization, both Pulse and
    Rectal Temperature prove to have low relevance as shown by both techniques.'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: '| Chi-squared | Gini index |'
  id: totrans-497
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-498
  prefs: []
  type: TYPE_TB
- en: '| Attribute | Weight | Attribute | Weight |'
  id: totrans-499
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-500
  prefs: []
  type: TYPE_TB
- en: '| Pain | 54.20626 | Pain | 0.083594 |'
  id: totrans-501
  prefs: []
  type: TYPE_TB
- en: '| Abdomen | 53.93882 | Abdomen | 0.083182 |'
  id: totrans-502
  prefs: []
  type: TYPE_TB
- en: '| Peristalsis | 38.73474 | Peristalsis | 0.059735 |'
  id: totrans-503
  prefs: []
  type: TYPE_TB
- en: '| AbdominalDistension | 35.11441 | AbdominalDistension | 0.054152 |'
  id: totrans-504
  prefs: []
  type: TYPE_TB
- en: '| PeripheralPulse | 23.65301 | PeripheralPulse | 0.036476 |'
  id: totrans-505
  prefs: []
  type: TYPE_TB
- en: '| AbdominocentesisAppearance | 20.00392 | AbdominocentesisAppearance | 0.030849
    |'
  id: totrans-506
  prefs: []
  type: TYPE_TB
- en: '| TemperatureOfExtremeties | 17.07852 | TemperatureOfExtremeties | 0.026338
    |'
  id: totrans-507
  prefs: []
  type: TYPE_TB
- en: '| MucousMembranes | 15.0938 | MucousMembranes | 0.023277 |'
  id: totrans-508
  prefs: []
  type: TYPE_TB
- en: '| NasogastricReflux | 14.95926 | NasogastricReflux | 0.023069 |'
  id: totrans-509
  prefs: []
  type: TYPE_TB
- en: '| PackedCellVolume | 13.5733 | PackedCellVolume | 0.020932 |'
  id: totrans-510
  prefs: []
  type: TYPE_TB
- en: '| RectalExamination-Feces | 11.88078 | RectalExamination-Feces | 0.018322 |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
- en: '| CapillaryRefillTime | 8.078319 | CapillaryRefillTime | 0.012458 |'
  id: totrans-512
  prefs: []
  type: TYPE_TB
- en: '| RespiratoryRate | 7.616813 | RespiratoryRate | 0.011746 |'
  id: totrans-513
  prefs: []
  type: TYPE_TB
- en: '| TotalProtein | 5.616841 | TotalProtein | 0.008662 |'
  id: totrans-514
  prefs: []
  type: TYPE_TB
- en: '| NasogastricRefluxPH | 2.047565 | NasogastricRefluxPH | 0.003158 |'
  id: totrans-515
  prefs: []
  type: TYPE_TB
- en: '| Pulse | 1.931511 | Pulse | 0.002979 |'
  id: totrans-516
  prefs: []
  type: TYPE_TB
- en: '| Age | 0.579216 | Age | 8.93E-04 |'
  id: totrans-517
  prefs: []
  type: TYPE_TB
- en: '| NasogastricTube | 0.237519 |   |   |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
- en: '| AbdomcentecisTotalProtein | 0.181868 |   |   |'
  id: totrans-519
  prefs: []
  type: TYPE_TB
- en: '| RectalTemperature | 0.139387 |   |   |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
- en: '*Table 3: Relevant features determined by two different techniques, Chi-squared
    and Gini index.*'
  id: totrans-521
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Model process flow
  id: totrans-522
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In RapidMiner you can define a pipeline of computations using operators with
    inputs and outputs that can be chained together. The following process represents
    the flow used to perform the entire set of operations starting with loading the
    training and test data, handling missing values, weighting features by relevance,
    filtering out low scoring features, training an ensemble model that uses Bagging
    with Random Forest as the algorithm, and finally applying the learned model to
    the test data and outputting the performance metrics. Note that all the preprocessing
    steps that are applied to the training dataset must also be applied, in the same
    order, to the test set by means of the Group Models operator:'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
- en: '![Model process flow](img/B05137_02_194.jpg)'
  id: totrans-524
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18: RapidMiner process diagram'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: Following the top of the process, the training set is ingested in the left-most
    operator, followed by the exclusion of non-predictors (Hospital Number, CP data)
    and self-predictors (Lesion 1). This is followed by the operator that replaces
    missing values with the mean and mode for continuous and categorical attributes,
    respectively. Next, the Feature Weights operator evaluates weights for each feature
    based on the Chi-squared statistic, which is followed by a filter that ignores
    low-weighted features. This pre-processed dataset is then used to train a model
    using Bagging with a Random Forest classifier.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
- en: The preprocessing steps used on the training data are grouped together in the
    appropriate order via the Group Models operator and applied to the test data in
    the penultimate step. Finally, the predictions of the target variable on the test
    examples accompanied by the confusion matrix and other performance metrics are
    made evaluated and presented in the last step.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
- en: Model evaluation metrics
  id: totrans-528
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We are now ready to compare the results from the various models. If you have
    followed along you may find that your results vary from what's presented here—that
    may be due to the stochastic nature of some learning algorithms, or differences
    in the values of some hyper-parameters used in the models.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: 'We have considered three different training datasets:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
- en: Original training data with missing values
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training data transformed with missing values handled
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training data transformed with missing values handled and with feature selection
    (Chi-Square) applied to select features that are highly discriminatory.
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We have considered three different sets of algorithms on each of the datasets:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
- en: Linear algorithms (Naïve Bayes and Logistic Regression)
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-linear algorithms (Decision Tree and KNN)
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensemble algorithms (Bagging, Ada Boost, and Random Forest).
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation on Confusion Metrics
  id: totrans-538
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Models | TPR | FPR | Precision | Specificity | Accuracy | AUC |'
  id: totrans-539
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-540
  prefs: []
  type: TYPE_TB
- en: '| Naïve Bayes | 68.29% | 14.81% | 87.50% | 85.19% | 75.00% | 0.836 |'
  id: totrans-541
  prefs: []
  type: TYPE_TB
- en: '| Logistic Regression | 78.05% | 14.81% | 88.89% | 85.19% | 80.88% | 0.856
    |'
  id: totrans-542
  prefs: []
  type: TYPE_TB
- en: '| Decision Tree | 68.29% | 33.33% | 75.68% | 66.67% | 67.65% | 0.696 |'
  id: totrans-543
  prefs: []
  type: TYPE_TB
- en: '| k-NN | 90.24% | 85.19% | 61.67% | 14.81% | 60.29% | 0.556 |'
  id: totrans-544
  prefs: []
  type: TYPE_TB
- en: '| Bagging (GBT) | 90.24% | 74.07% | 64.91% | 25.93% | 64.71% | 0.737 |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
- en: '| Ada Boost (Naïve Bayes) | 63.41% | 48.15% | 66.67% | 51.85% | 58.82% | 0.613
    |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
- en: '*Table 4: Results on unseen (Test) data for models trained on Horse-colic data
    with missing values*'
  id: totrans-547
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '| Models | TPR | FPR | Precision | Specificity | Accuracy | AUC |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
- en: '| Naïve Bayes | 68.29% | 66.67% | 60.87% | 33.33% | 54.41% | 0.559 |'
  id: totrans-550
  prefs: []
  type: TYPE_TB
- en: '| Logistic Regression | 78.05% | 62.96% | 65.31% | 37.04% | 61.76% | 0.689
    |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
- en: '| Decision Tree | 97.56% | 96.30% | 60.61% | 3.70% | 60.29% | 0.812 |'
  id: totrans-552
  prefs: []
  type: TYPE_TB
- en: '| k-NN | 75.61% | 48.15% | 70.45% | 51.85% | 66.18% | 0.648 |'
  id: totrans-553
  prefs: []
  type: TYPE_TB
- en: '| Bagging (Random Forest) | 97.56% | 74.07% | 66.67% | 25.93% | 69.12% | 0.892
    |'
  id: totrans-554
  prefs: []
  type: TYPE_TB
- en: '| Bagging (GBT) | 82.93% | 18.52% | 87.18% | 81.48% | 82.35% | 0.870 |'
  id: totrans-555
  prefs: []
  type: TYPE_TB
- en: '| Ada Boost (Naïve Bayes) | 68.29% | 7.41% | 93.33% | 92.59% | 77.94% | 0.895
    |'
  id: totrans-556
  prefs: []
  type: TYPE_TB
- en: '*Table 5: Results on unseen (Test) data for models trained on Horse-colic data
    with missing values replaced*'
  id: totrans-557
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '| Models | TPR | FPR | Precision | Specificity | Accuracy | AUC |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
- en: '| Naïve Bayes | 75.61% | 77.78% | 59.62% | 29.63% | 54.41% | 0.551 |'
  id: totrans-560
  prefs: []
  type: TYPE_TB
- en: '| Logistic Regression | 82.93% | 62.96% | 66.67% | 37.04% | 64.71% | 0.692
    |'
  id: totrans-561
  prefs: []
  type: TYPE_TB
- en: '| Decision Tree | 95.12% | 92.59% | 60.94% | 7.41% | 60.29% | 0.824 |'
  id: totrans-562
  prefs: []
  type: TYPE_TB
- en: '| k-NN | 75.61% | 48.15% | 70.45% | 51.85% | 66.18% | 0.669 |'
  id: totrans-563
  prefs: []
  type: TYPE_TB
- en: '| Bagging (Random Forest) | 92.68% | 33.33% | 80.85% | 66.67% | 82.35% | 0.915
    |'
  id: totrans-564
  prefs: []
  type: TYPE_TB
- en: '| Bagging (GBT) | 78.05% | 22.22% | 84.21% | 77.78% | 77.94% | 0.872 |'
  id: totrans-565
  prefs: []
  type: TYPE_TB
- en: '| Ada Boost (Naïve Bayes) | 68.29% | 18.52% | 84.85% | 81.48% | 73.53% | 0.848
    |'
  id: totrans-566
  prefs: []
  type: TYPE_TB
- en: '*Table 6: Results on unseen (Test) data for models trained on Horse-colic data
    using features selected by Chi-squared statistic technique*'
  id: totrans-567
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ROC Curves, Lift Curves, and Gain Charts
  id: totrans-568
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The performance plots enable us to visually assess the models used in two of
    the three experiments—without any replacement of missing data, and with using
    features from Chi-squared weighting after replacing missing data—and to compare
    them against each other. Pairs of plots display the performance curves of each
    Linear (Logistic Regression), Non-linear (Decision Tree), and Ensemble (Bagging,
    using Gradient Boosted Tree) technique we learned about earlier in the chapter,
    drawn from results of the two experiments.
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
- en: '![ROC Curves, Lift Curves, and Gain Charts](img/B05137_02_195.jpg)'
  id: totrans-570
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19: ROC Performance curves for experiment using Missing Data'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
- en: '![ROC Curves, Lift Curves, and Gain Charts](img/B05137_02_196.jpg)'
  id: totrans-572
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20: Cumulative Gains performance curves for experiment using Missing
    Data'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
- en: '![ROC Curves, Lift Curves, and Gain Charts](img/B05137_02_197.jpg)'
  id: totrans-574
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21: Lift performance curves for experiment using Missing Data'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
- en: Results, observations, and analysis
  id: totrans-576
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The impact of handling missing values is significant. Of the seven classifiers,
    with the exception of Naïve Bayes and Logistic Regression, all show remarkable
    improvement when missing values are handled as indicated by various metrics, including
    AUC, precision, accuracy, and specificity. This tells us that handling missing
    values that can be "noisy" is an important aspect of data transformation. Naive
    Bayes has its own internal way of managing missing values and the results from
    our experiments show that it does a better job of null-handling than our external
    transformations. But in general, the idea of transforming missing values seems
    beneficial when you consider all of the classifiers.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
- en: As discussed in the section on modeling, some of the algorithms require the
    right handling of missing values and feature selection to get optimum performance.
    From the results, we can see that the performance of Decision Trees, for example,
    improved incrementally from 0.696 with missing data, 0.812 with managed missing
    data, and for the best performance of 0.824 with missing data handled together
    with feature selection. Six out of seven classifiers improve the performance in
    AUC (and in others metrics) when both the steps are performed; comparing *Table
    5* and *Table 6* for AUC gives us these quick insights. This demonstrates the
    importance of doing preprocessing such as missing value handling along with feature
    selection before performing modeling.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
- en: A major conclusion from the results is that the problem is highly non-linear
    and therefore most non-linear classifiers from the simplest Decision Trees to
    ensemble Random Forest perform very well. The best performance comes from the
    meta-learning algorithm Random Forest, with missing values properly handled and
    the most relevant features used in training. The best linear model performance
    measured by AUC was 0.856 for Logistic Regression with data as-is (that is, with
    missing values), whereas Random Forest achieved AUC performance of 0.915 with
    proper handling of missing data accompanied by feature selection. Generally, as
    evident from *Table 3*, the non-linear classifiers or meta-learners performed
    better than linear classifiers by most performance measures.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
- en: Handling missing values, which can be thought as "noise", in the appropriate
    manner improves the performance of AdaBoost by a significant amount. The AUC improves
    from 0.613 to 0.895 and FPR reduces from 48.15 to 7.41%. This indeed conforms
    to the expected theoretical behavior for this technique.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
- en: Meta-learning techniques, which use concepts of boosting and bagging, are relatively
    more effective when dealing with real-world data, when compared to other common
    techniques. This seems to be justified by the results since AdaBoost with Naïve
    Bayes as base learner trained on data that has undergone proper handling of noise
    outperforms Naive Bayes in most of the metrics, as shown in *Table 5* and *Table
    6*. Random Forest and GBTs also show the best performance along with AdaBoost
    as compared to base classifiers in *Table 6*, again confirming that the right
    process and ensemble learning can produce the most optimum results in real-world
    noisy datasets.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-582
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'All data, models, and results for both WEKA and RapidMiner process files from
    this chapter are available at: [https://github.com/mjmlbook/mastering-java-machine-learning/tree/master/Chapter2](https://github.com/mjmlbook/mastering-java-machine-learning/tree/master/Chapter2).'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-584
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Supervised learning is the predominant technique used in machine learning applications.
    The methodology consists of a series of steps beginning with data exploration,
    data transformation, and data sampling, through feature reduction, model building,
    and ultimately, model assessment and comparison. Each step of the process involves
    some decision making which must answer key questions: How should we impute missing
    values? What data sampling strategy should we use? What is the most appropriate
    algorithm given the amount of noise in the dataset and the prescribed goal of
    interpretability? This chapter demonstrated the application of these processes
    and techniques to a real-world problem—the classification problem using the UCI
    Horse Colic dataset.'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
- en: Whether the problem is one of classification, when the target is a categorical
    value, or Regression, when it is a real-valued continuous variable, the methodology
    used for supervised learning is similar. In this chapter, we have used classification
    for illustration.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
- en: The first step is data quality analysis, which includes descriptive statistics
    of the features, visualization analysis using univariate, and multivariate feature
    analysis. With the help of various plot types, we can uncover different trends
    in the data and examine how certain features may or may not correlate with the
    label values and with each other. Data analysis is followed by data pre-processing,
    where the techniques include ways to address noise, as in the case of missing
    data, and outliers, as well as preparing the data for modeling techniques through
    normalization and discretization.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
- en: Following pre-processing, we must suitably split the data into train, validation,
    and test samples. Different sampling strategies may be used depending on the characteristics
    of the data and the problem at hand, for example, when the data is skewed or when
    we have a multi-class classification problem. Depending on data size, cross-validation
    is a common alternative to creating a separate validation set.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
- en: The next step is the culling of irrelevant features. In the filter approach,
    techniques that use univariate analysis are either entropy-based (Information
    Gain, Gains Ratio) or based on statistical hypothesis testing (Chi-Squared). With
    the main multivariate methods, the aim is reduction of redundant features when
    considered together, or using the ones that correlate most closely with the target
    label. In the wrapper approach, we use machine learning algorithms to tell us
    about the more discriminating features. Finally, some learning techniques have
    feature selection embedded in the algorithm in the form of a regularization term,
    typically using ridge or lasso techniques. These represent the embedded approach.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
- en: Modeling techniques are broadly classified into linear, non-linear, and ensemble
    methods. Among linear algorithms, the type of features can determine the algorithms
    to use—Linear Regression (numeric features only), Naïve Bayes (numeric or categorical),
    and logistic regression (numeric features only, or categorical transformed to
    numeric) are the work-horses. The outlined advantages and disadvantages of each
    method must be understood when choosing between them or interpreting the results
    of learning using these models.
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: Decision Tree, k-NN, and SVM are non-linear techniques, each with their own
    strengths and limitations. For example, interpretability is the main advantage
    of Decision Tree. k-NN is robust in the face of noisy data, but it does poorly
    with high-dimensional data. SVM suffers from poor interpretability, but shines
    even when the dataset is limited, and the number of features is large.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
- en: With a number of different models collaborating, ensemble methods can leverage
    the best of all. Bagging and boosting both are techniques that generalize better
    in the ensemble compared to the base learner they use and are popular in many
    applications.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
- en: Finally, what are the strategies and methods that can be used in evaluating
    model performance and comparing models to each other? The role of validation sets
    or cross-validation is essential to the ability to generalize over unseen data.
    Performance evaluation metrics derived from the confusion matrix are used universally
    to evaluate classifiers; some are used more commonly in certain domains and disciplines
    than others. ROC, Gain, and Lift curves are great visual representations of the
    range of model performance as the classification threshold is varied. When comparing
    models in pairs, several metrics based on statistical hypothesis testing are used.
    Wilcoxon and McNemar's are two non-parametric tests; Paired-t test is an example
    of a parametric method. Likewise, when comparing multiple algorithms, a common
    non-parametric test that does not make assumptions about the data distribution
    is Friedman's test. ANOVA, which are parametric tests, assume normal distribution
    of the metrics and equal variances.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
- en: The final sections of the chapter present the process undertaken using the RapidMiner
    tool to develop and evaluate models generated to classify test data from the UCI
    Horse-colic dataset. Three experiments are designed to compare and contrast the
    performance of models under different data pre-processing conditions, namely,
    without handling missing data, with replacement of missing data using standard
    techniques, and finally, with feature selection following null replacement. In
    each experiment we choose multiple linear, non-linear, and ensemble methods. As
    part of the overall process, we illustrate how the modeling environment is used.
    We can draw revealing conclusions from the results, which give us insights into
    the data as well as demonstrating the relative strengths and weakness of the various
    classes of techniques in different situations. We conclude that the data is highly
    non-linear and that ensemble learning demonstrates clear advantages over other
    techniques.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-595
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: D. Bell and H. Wang (2000). *A Formalism for Relevance and its Application in
    Feature Subset Selection. Machine Learning*, 41(2):175–195.
  id: totrans-596
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'J. Doak (1992). *An Evaluation of Feature Selection Methods and their Application
    to Computer Security*. Technical Report CSE–92–18, Davis, CA: University of California,
    Department of Computer Science.'
  id: totrans-597
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: M. Ben-Bassat (1982). *Use of Distance Measures, Information Measures and Error
    Bounds in Feature Evaluation*. In P. R. Krishnaiah and L. N. Kanal, editors, Handbook
    of Statistics, volume 2, pages 773–791, North Holland.
  id: totrans-598
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Littlestone N, Warmuth M (1994) *The weighted majority algorithm*. Information
    Computing 108(2):212–261
  id: totrans-599
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Breiman L., Friedman J.H., Olshen R.A., Stone C.J. (1984) *Classification and
    Regression Trees*, Wadsforth International Group.
  id: totrans-600
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: B. Ripley(1996), *Pattern recognition and neural networks*. Cambridge University
    Press, Cambridge.
  id: totrans-601
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Breiman, L., (1996). *Bagging Predictors, Machine Learning*, 24 123-140.
  id: totrans-602
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Burges, C. (1998). *A tutorial on support vector machines for pattern recognition.
    Data Mining and Knowledge Discovery*. 2(2):1-47.
  id: totrans-603
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bouckaert, R. (2004), *Naive Bayes Classifiers That Perform Well with Continuous
    Variables, Lecture Notes in Computer Science*, Volume 3339, Pages 1089 – 1094.
  id: totrans-604
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Aha D (1997). *Lazy learning*, Kluwer Academic Publishers, Dordrecht
  id: totrans-605
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Nadeau, C. and Bengio, Y. (2003), *Inference for the generalization error*.
    In Machine Learning 52:239– 281.
  id: totrans-606
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Quinlan, J.R. (1993). C4.5: *Programs for machine learning*, Morgan Kaufmann,
    San Francisco.'
  id: totrans-607
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Vapnik, V. (1995), *The Nature of Statistical Learning Theory*. Springer Verlag.
  id: totrans-608
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Schapire RE, Singer Y, Singhal A (1998). *Boosting and Rocchio applied to text
    filtering*. In SIGIR ''98: Proceedings of the 21st Annual International Conference
    on Research and Development in Information Retrieval, pp 215–223'
  id: totrans-609
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Breiman L.(2001). *Random Forests*. Machine Learning, 45 (1), pp 5-32.
  id: totrans-610
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Nathalie Japkowicz and Mohak Shah (2011). *Evaluating Learning Algorithms:
    A Classification Perspective*. Cambridge University Press.'
  id: totrans-611
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hanley, J. & McNeil, B. (1982). *The meaning and use of the area under a receiver
    operating characteristic (ROC) curve*. Radiology 143, 29–36.
  id: totrans-612
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Tjen-Sien, L., Wei-Yin, L., Yu-Shan, S. (2000). *A Comparison of Prediction
    Accuracy, Complexity, and Training Time of Thirty-Three Old and New Classification
    Algorithms*. Machine Learning 40: 203–228.'
  id: totrans-613
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. W. Moore and M. S. Lee (1994). *Efficient Algorithms for Minimizing Cross
    Validation Error*. In Proc. of the 11th Int. Conf. on Machine Learning, pages
    190–198, New Brunswick, NJ. Morgan Kaufmann.
  id: totrans-614
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Nitesh V. Chawla et. al. (2002). *Synthetic Minority Over-sampling Technique*.
    Journal of Artificial Intelligence Research. 16:321-357.
  id: totrans-615
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
