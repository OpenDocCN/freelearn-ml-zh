["```py\nfrom data_quality_stats import missing_data, most_frequent_values, unique_values \n```", "```py\ncolumns = ['local_authority', 'longitude', 'latitude', 'northing', 'easting', 'postcode', 'address']\n# use the rows indexes to locate the rows\nfor index in [768, 43212]:\n    for idx in range(len(columns) - 1):\n        # we use `at` to make sure the changes are done on the actual dataframe, not on a copy of it\n        pub_df.at[index, columns[idx]] = pub_df.loc[index][columns[idx + 1]]\n\n    # split the corrupted name and assign the name and address\n    name_and_addresse = pub_df.loc[index]['name'].split(\"\\\",\\\"\")\n    pub_df.at[index, 'name'] = name_and_addresse[0]\n    pub_df.at[index, 'address'] = name_and_addresse[1] \n```", "```py\npost_code_df = pd.read_csv(\"/kaggle/input/open-postcode-geo/open_postcode_geo.csv\", header=None, low_memory=False)\npost_code_df = post_code_df[[0, 6, 7, 8]]\npost_code_df.columns = ['postcode', 'country', 'latitude', 'longitude'] \n```", "```py\npub_df = pub_df.merge(post_code_df, on=\"postcode\", how=\"left\")\npub_df['latitude'] = pub_df['latitude_x'].fillna(pub_df['latitude_y'])\npub_df['longitude'] = pub_df['longitude_x'].fillna(pub_df['longitude_y'])\npub_df = pub_df.drop([\"country\", \"latitude_x\", \"latitude_y\", \"longitude_x\", \"longitude_y\"], axis=1) \n```", "```py\nfrom plot_utils import set_color_map, plot_count, show_wordcloud \n```", "```py\ndef get_city(text):\n    try:\n        split_text = text.split(\",\")\n        if len(split_text) > 3:\n            return split_text[-2]\n    except:\n        return None\npub_df[\"address_city\"] = pub_df[\"address\"].apply(lambda x: get_city(x)) \n```", "```py\nimport folium\nfrom folium.plugins import MarkerCluster\nuk_coords = [55, -3]\nuk_map = folium.Map(location = uk_coords, zoom_start = 6)\nuk_map \n```", "```py\nlocations_data = np.array(pub_map_df[[\"latitude\", \"longitude\"]].astype(float))\nmarker_cluster = MarkerCluster(locations = locations_data)\nmarker_cluster.add_to(uk_map)\nuk_map \n```", "```py\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nlocations_data = np.array(pub_map_df[[\"longitude\", \"latitude\"]].astype(float))\npub_voronoi = Voronoi(locations_data) \n```", "```py\nfig = voronoi_plot_2d(pub_voronoi,\n                     show_vertices=False)\nplt.xlim([-8, 3])\nplt.ylim([49, 60])\nplt.show() \n```", "```py\nimport geopandas as gpd\nuk_all = gpd.read_file(\"/kaggle/input/gadm-data-for-uk/GBR_adm0.shp\")\nuk_countries = gpd.read_file(\"/kaggle/input/gadm-data-for-uk/GBR_adm1.shp\")\nuk_counties = gpd.read_file(\"/kaggle/input/gadm-data-for-uk/GBR_adm2.shp\") \n```", "```py\nfig, ax = plt.subplots(1, 3, figsize = (15, 6))\nuk_all.plot(ax = ax[0], color = color_list[2], edgecolor = color_list[6])\nuk_countries.plot(ax = ax[1], color = color_list[1], edgecolor = color_list[6])\nuk_counties.plot(ax = ax[2], color = color_list[0], edgecolor = color_list[6])\nplt.suptitle(\"United Kingdom territory (all, countries and counties level)\")\nplt.show() \n```", "```py\nuk_countries_selected = uk_countries.loc[~uk_countries.NAME_1.isin([\"Northern Ireland\"])]\nuk_countries_dissolved = uk_countries_selected.dissolve()\nfig, ax = plt.subplots(1, 1, figsize = (6, 6))\nuk_countries_dissolved.plot(ax = ax, color = color_list[1], edgecolor = color_list[6])\nplt.suptitle(\"Great Britain territory (without Northern Ireland)\")\nplt.show() \n```", "```py\ndef extract_voronoi_polygon_list(voronoi_polygons):\n    voronoi_poly_list = []\n    for region in voronoi_polygons.regions:\n        if -1 in region:\n            continue\nelse:\n            pass\nif len(region) != 0:\n            voronoi_poly_region = Polygon(voronoi_polygons.vertices[region])\n            voronoi_poly_list.append(voronoi_poly_region)\n        else:\n            continue\nreturn voronoi_poly_list\nvoronoi_poly_list = extract_voronoi_polygon_list(pub_voronoi) \n```", "```py\nvoronoi_polygons = gpd.GeoDataFrame(voronoi_poly_list, columns = ['geometry'], crs=uk_countries_dissolved.crs)\nstart_time = time.time()\nvoronoi_polys_clipped = gpd.clip(voronoi_polygons, uk_countries_dissolved)\nend_time = time.time()\nprint(f\"Total time: {round(end_time - start_time, 4)} sec.\") \n```", "```py\nfig, ax = plt.subplots(1, 1, figsize = (20, 20))\nplt.style.use('bmh')\nuk_all.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\nvoronoi_polys_clipped.plot(ax = ax, cmap = cmap_custom, edgecolor = 'black', linewidth = 0.25)\nplt.title(\"All pubs in England - Voronoi polygons with each pub area\")\nplt.show() \n```", "```py\npub_df[\"latitude\"] = pub_df[\"latitude\"].apply(lambda x: float(x))\npub_df[\"longitude\"] = pub_df[\"longitude\"].apply(lambda x: float(x))\npubs_df = pub_df.groupby([\"local_authority\"])[\"name\"].count().reset_index()\npubs_df.columns = [\"local_authority\", \"pubs\"]\nlat_df = pub_df.groupby([\"local_authority\"])[\"latitude\"].mean().reset_index()\nlat_df.columns = [\"local_authority\", \"latitude\"]\nlong_df = pub_df.groupby([\"local_authority\"])[\"longitude\"].mean().reset_index()\nlong_df.columns = [\"local_authority\", \"longitude\"]\npubs_df = pubs_df.merge(lat_df)\npubs_df = pubs_df.merge(long_df)\nmean_loc_data = np.array(pubs_df[[\"longitude\", \"latitude\"]].astype(float)) \n```", "```py\nmean_loc_data = np.array(pubs_df[[\"longitude\", \"latitude\"]].astype(float))\npub_mean_voronoi = Voronoi(mean_loc_data)\nmean_pub_poly_list = extract_voronoi_polygon_list(pub_mean_voronoi)\nmean_voronoi_polygons = gpd.GeoDataFrame(mean_pub_poly_list, columns = ['geometry'], crs=uk_countries_dissolved.crs) \n```", "```py\nmean_voronoi_polys_clipped = gpd.clip(mean_voronoi_polygons, uk_countries_dissolved) \n```", "```py\nfig, ax = plt.subplots(1, 1, figsize = (10,10))\nplt.style.use('bmh')\nuk_all.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\nmean_voronoi_polys_clipped.plot(ax = ax, cmap = \"Greens_r\")\nplt.title(\"All pubs in England\\nPubs density per local authority\\nVoronoi polygons for mean of pubs positions\")\nplt.show() \n```", "```py\ncoffee_df = coffee_df.loc[(~coffee_df.Latitude.isna()) & (~coffee_df.Longitude.isna())]\nlocations_data = np.array(coffee_df[[\"Latitude\", \"Longitude\"]])\npopups = coffee_df.apply(lambda row: f\"Name: {row['Store Name']}\", axis=1)\nmarker_cluster = MarkerCluster(\n    locations = locations_data,\n)\nworld_coords = [0., 0.]\nworld_map = folium.Map(location = world_coords, zoom_start = 1)\nmarker_cluster.add_to(world_map) \nworld_map \n```", "```py\ncoffee_agg_df = coffee_df.groupby([\"Country\"])[\"Brand\"].count().reset_index()\ncoffee_agg_df.columns = [\"Country\", \"Shops\"] \n```", "```py\nimport geopandas as gpd\nimport matplotlib\nimport country_converter as cc\n# convert ISO2 to ISO3 country codes - to be used with geopandas plot of countries\ncoffee_agg_df[\"iso_a3\"] = coffee_agg_df[\"Country\"].apply(lambda x: cc.convert(x, to='ISO3')) \n```", "```py\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nworld_shop = world.merge(coffee_agg_df, on=\"iso_a3\", how=\"right\") \n```", "```py\nworld_shop.loc[world_shop.Shops.isna(), \"Shops\"] = 0\nf, ax = plt.subplots(1, 1, figsize=(12, 5))\nworld_cp = world.copy() \n```", "```py\n# transform, in the copied data, the projection in Cylindrical equal-area,\n# which preserves the areas \nworld_cp= world_cp.to_crs({'proj':'cea'})\nworld_cp[\"area\"] = world_cp['geometry'].area / 10**6 # km^2\nworld[\"area\"] = world_cp[\"area\"]='black', linewidth=0.25, ax=ax) \n# draw countries polygons with log scale colormap\nworld_shop.plot(column='Shops', legend=True,\\\n           norm=matplotlib.colors.LogNorm(vmin=world_shop.Shops.min(),\\\n                                          vmax=world_shop.Shops.max()), \n           cmap=\"rainbow\",\n           ax=ax)\nplt.grid(color=\"black\", linestyle=\":\", linewidth=0.1, axis=\"y\", which=\"major\")\nplt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\")\nplt.title(\"Starbucks coffee shops distribution at country level\")\nplt.show() \n```", "```py\nworld_cp = world.copy()\n# transform, in the copied data, the projection in Cylindrical equal-area,\n# which preserves the areas \nworld_cp= world_cp.to_crs({'proj':'cea'})\nworld_cp[\"area\"] = world_cp['geometry'].area / 10**6 # km^2\nworld[\"area\"] = world_cp[\"area\"] \n```", "```py\nworld.loc[world.iso_a3.isin([\"GBR\", \"USA\", \"ROU\"])] \n```", "```py\nworld_shop = world.merge(coffee_agg_df, on=\"iso_a3\", how=\"right\")\nworld_shop[\"Shops / Population\"] = world_shop[\"Shops\"] / world_shop[\"pop_est\"] * 10**6 # shops/1 million population\nworld_shop[\"Shops / Area\"] = world_shop[\"Shops\"] / world_shop[\"area\"] * 10**3\\. # shops / 1000 Km^2 \n```", "```py\nf, ax = plt.subplots(1, 1, figsize=(12, 5))\n# show all countries contour with black and color while\nworld.plot(column=None, color=\"white\", edgecolor='black', linewidth=0.25, ax=ax) \n# draw countries polygons\nworld_shop.plot(column='Shops / Population', legend=True,\\\n           cmap=\"rainbow\",\n           ax=ax)\nplt.grid(color=\"black\", linestyle=\":\", linewidth=0.1, axis=\"y\", which=\"major\")\nplt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\")\nplt.title(\"Starbucks coffee shops / 1 million population - distribution at country level\")\nplt.show() \n```", "```py\nboroughs_df = counties_df.loc[counties_df.NAME_2.isin(london_boroughs)]\nboroughs_df.plot(color=color_list[0], edgecolor=color_list[4])\nplt.show() \n```", "```py\ncoffee_df = coffee_df.loc[(coffee_df.City.isin(london_boroughs + [\"London\"])) &\\\n             (coffee_df.Country==\"GB\")] \n```", "```py\ndef verify_data_availability():\n    f, ax = plt.subplots(1, 1, figsize=(10, 10))\n    boroughs_df.plot(color=\"white\", edgecolor=color_list[4], ax=ax)\n    plt.scatter(x=pub_df[\"longitude\"],y=pub_df[\"latitude\"], color=color_list[0], marker=\"+\", label=\"Pubs\")\n    plt.scatter(x=coffee_df[\"Longitude\"],y=coffee_df[\"Latitude\"], color=color_list[5], marker=\"o\", label=\"Starbucks\")\n    plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\"); plt.title(\"London boroughs - verify data availability\")\n    plt.grid(color=\"black\", linestyle=\":\", linewidth=0.1, axis=\"both\", which=\"major\")\n    plt.legend()\n    plt.show() \n```", "```py\ncoffee_df = coffee_df.loc[coffee_df.Latitude<=51.7] \n```", "```py\npub_voronoi = get_voronoi_polygons(pub_df)\nplot_voronoi_polygons(pub_voronoi, \n                      title=\"Voronoi polygons from pubs locations in London\",\n                      lat_limits=[51.2, 51.7],\n                      long_limits=[-0.5, 0.3]) \n```", "```py\ndef get_voronoi_polygons(data_df, latitude=\"latitude\", longitude=\"longitude\"):\n    \"\"\"\n    Create a list of Voronoi polygons from a list of points\n    Args\n        data_df: dataframe containing lat/long\n        latitude: latitude feature\n        longitude: longitude feature\n    Returns\n        Voronoi polygons graph (points, polygons) from the seed points in data_df\n        (a scipy.spatial.Voronoi object)\n    \"\"\"\n\n    locations_data = np.array(data_df[[latitude, longitude]].astype(float))\n    data_voronoi = [[x[1], x[0]] for x in locations_data]\n    voronoi_polygons = Voronoi(data_voronoi)\n    print(f\"Voronoi polygons: {len(voronoi_polygons.points)}\")\n    return voronoi_polygons \n```", "```py\ndef plot_voronoi_polygons(voronoi_polygons, title, lat_limits, long_limits):\n    \"\"\"\n    Plot Voronoi polygons (visualization tool)\n    Args\n        voronoi_polygons: Voronoi polygons object (a scipy.spatial.Voronoi object)\n        title: graph title\n        lat_limits: graph latitude (y) limits\n        long_limits: graph longitude (x) limits\n    Returns\n        None\n    \"\"\"\n# do not show the vertices, only show edges and centers\n    fig = voronoi_plot_2d(voronoi_polygons,\n                     show_vertices=False)\n    plt.xlim(long_limits)\n    plt.ylim(lat_limits)    \n    plt.title(title)\n    plt.show() \n```", "```py\nboroughs_dissolved = boroughs_df.dissolve()\nvoronoi_polys_clipped = clip_polygons(voronoi_poly_list, boroughs_df) \n```", "```py\ndef clip_polygons(poly_list_origin, poly_clipping):\n    \"\"\"\n    Clip a list of polygons using an external polygon\n    Args:\n        poly_list_origin: list of polygons to clip\n        poly_clipping: polygon used to clip the original list\n\n    Returns:\n        The original list of polygons, with the polygons clipped using the clipping polygon\n    \"\"\"\n#convert the initial polygons list to a geodataframe\n    polygons_gdf = gpd.GeoDataFrame(poly_list_origin, columns = ['geometry'], crs=poly_clipping.crs)\n    start_time = time.time()\n    polygons_clipped = gpd.clip(polygons_gdf, poly_clipping)\n    end_time = time.time()\n    print(f\"Total time: {round(end_time - start_time, 4)} sec.\")\n    return polygons_clipped \n```", "```py\ncoffee_voronoi = get_voronoi_polygons(coffee_df, latitude=\"Latitude\", longitude=\"Longitude\")\nplot_voronoi_polygons(coffee_voronoi, \n                      title=\"Voronoi polygons from Starbucks locations in London\",\n                      lat_limits=[51.2, 51.7],\n                      long_limits=[-0.5, 0.3]) \n```", "```py\ncoffee_voronoi_poly_list = extract_voronoi_polygon_list(coffee_voronoi)\ncoffee_voronoi_polys_clipped = clip_polygons(coffee_voronoi_poly_list, boroughs_df) \n```", "```py\ndef within_polygon(data_original_df, polygon, latitude=\"latitude\", longitude=\"longitude\"):\n    \"\"\"\n    Args\n        data_original_df: dataframe with latitude / longitude\n        polygon: polygon (Polygon object)\n        latitude: feature name for latitude n data_original_df\n        longitude: feature name for longitude in data_original_df\n    Returns\n        coordinates of points inside polygon\n        coordinates of points outside polygon\n        polygon transformed into a geopandas dataframe\n    \"\"\"\n    data_df = data_original_df.copy()\n    data_df[\"in_poly\"] = data_df.apply(lambda x: Point(x[longitude], x[latitude]).within(polygon), axis=1)\n    data_in_df = data_df[[longitude, latitude]].loc[data_df[\"in_poly\"]==True]\n    data_out_df = data_df[[longitude, latitude]].loc[data_df[\"in_poly\"]==False]\n    data_in_df.columns = [\"long\", \"lat\"]\n    data_out_df.columns = [\"long\", \"lat\"]\n    sel_polygon_gdf = gpd.GeoDataFrame([polygon], columns = ['geometry'])\n    return data_in_df, data_out_df, sel_polygon_gdf \n```", "```py\ndata_in_df, data_out_df, sel_polygon_gdf = within_polygon(pub_df, coffee_voronoi_poly_list[6]) \n```", "```py\n# map with zoom on London area\nm = folium.Map(location=[51.5, 0], zoom_start=10, tiles=\"Stamen Toner\")\n# London boroughs geo jsons\nfor _, r in boroughs_df.iterrows():\n    simplified_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)\n    geo_json = simplified_geo.to_json()\n    geo_json = folium.GeoJson(data=geo_json,\n                           style_function=lambda x: {'fillColor': color_list[1],\n                                                    'color': color_list[2],\n                                                    'weight': 1})\n    geo_json.add_to(m)\n# pubs as CircleMarkers with popup with Name & Address info    \nfor _, r in pub_df.iterrows():\n    folium.CircleMarker(location=[r['latitude'], r['longitude']],\n                        fill=True,\n                        color=color_list[4],\n                        fill_color=color_list[5],\n                        weight=0.5,\n                        radius=4,\n                        popup=\"<strong>Name</strong>: <font color='red'>{}</font> <br> <strong>Address</strong>: {}\".format(r['name'], r['address'])).add_to(m)\n# display map\nm \n```", "```py\ndef get_polygons_area(data_gdf):\n    \"\"\"\n    Add a column with polygons area to a GeoDataFrame\n    A Cylindrical equal area projection is used to calculate \n    polygons area\n\n    Args\n        data_gdf: a GeoDataFrame\n    Returns\n        the original data_gdf with an `area` column added\n    \"\"\"\n# copy the data, to not affect initial data projection\n    data_cp = data_gdf.copy()\n    # transform, in the copied data, the projection in Cylindrical equal-area,\n# which preserves the areas \n    data_cp = data_cp.to_crs({'proj':'cea'})\n    data_cp[\"area\"] = data_cp['geometry'].area / 10**6 # km^2\n    data_gdf[\"area\"] = data_cp[\"area\"]\n    # returns the initial data, with added area columns\nreturn data_gdf \n```", "```py\nboroughs_df = get_polygons_area(boroughs_df)\nagg_pub_df = pub_df.groupby(\"local_authority\")[\"name\"].count().reset_index()\nagg_pub_df.columns = [\"NAME_2\", \"pubs\"]\nboroughs_df = boroughs_df.merge(agg_pub_df) \n```", "```py\nvmin = boroughs_df.pubs.min()\nvmax = boroughs_df.pubs.max()\nnorm=plt.Normalize(vmin, vmax)\ncustom_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\", color_list[0], color_list[2]]) \n```", "```py\nfig, ax = plt.subplots(1, 1, figsize = (10, 5))\nax.set_facecolor(\"white\")\nboroughs_df.plot(ax = ax, column=\"pubs per sq.km\", \n                 norm=matplotlib.colors.LogNorm(vmin=boroughs_df[\"pubs per sq.km\"].min(),\\\n                                          vmax=boroughs_df[\"pubs per sq.km\"].max()),\n                 cmap = custom_cmap, edgecolor = color_list[3], \n                 linewidth = 1, legend=True),\nplt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\");\nplt.title(\"Pubs density (pubs / sq.km) in London\")\nplt.show() \n```"]