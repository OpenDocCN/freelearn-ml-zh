["```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.preprocessing import OneHotEncoder\n    from sklearn.pipeline import make_pipeline\n    from sklearn.impute import SimpleImputer\n    from sklearn.compose import ColumnTransformer\n    from sklearn.model_selection import StratifiedKFold\n    from sklearn.feature_selection import RFECV\n    from sklearn.linear_model import LogisticRegression\n    import sklearn.metrics as skmet\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    ```", "```py\n    import os\n    import sys\n    sys.path.append(os.getcwd() + \"/helperfunctions\")\n    from preprocfunc import OutlierTrans,\\\n      MakeOrdinal, ReplaceVals\n    ```", "```py\nclass MakeOrdinal(BaseEstimator,TransformerMixin):\n  def fit(self,X,y=None):\n    return self\n\n  def transform(self,X,y=None):\n    Xnew = X.copy()\n    for col in Xnew.columns:\n      cats = np.sort(Xnew[col].unique())\n      Xnew[col] = Xnew.\\\n        apply(lambda x: int(np.where(cats==\\\n        x[col])[0]), axis=1)\n    return Xnew.values\n```", "```py\nclass ReplaceVals(BaseEstimator,TransformerMixin):\n  def __init__(self,repdict):\n    self.repdict = repdict\n  def fit(self,X,y=None):\n    return self\n\n  def transform(self,X,y=None):\n    Xnew = X.copy().replace(self.repdict)\nreturn Xnew.values\n```", "```py\nhealthinfo = pd.read_csv(\"data/healthinfo.csv\")\nhealthinfo.set_index(\"personid\", inplace=True)\nhealthinfo.head(2).T\npersonid                    299391       252786\nheartdisease                Yes          No\nbmi                         28.48        25.24\nsmoking                     Yes          Yes\nalcoholdrinkingheavy        No           No\nstroke                      No           No\nphysicalhealthbaddays       7            0\nmentalhealthbaddays         0            2\nwalkingdifficult            No           No\ngender                      Male         Female\nagecategory                 70-74        65-69\nethnicity                   White        White\ndiabetic    No, borderline diabetes      No\nphysicalactivity            Yes          Yes\ngenhealth                   Good         Very good\nsleeptimenightly            8            8\nasthma                      No           No\nkidneydisease               No           No\nskincancer                  No           Yes\n```", "```py\n    healthinfo.shape\n    (30000, 18)\n    healthinfo.isnull().sum()\n    heartdisease                0\n    bmi                         0\n    smoking                     0\n    alcoholdrinkingheavy        0\n    stroke                      0\n    physicalhealthbaddays       0\n    mentalhealthbaddays         0\n    walkingdifficult            0\n    gender                      0\n    agecategory                 0\n    ethnicity                   0\n    diabetic                    0\n    physicalactivity            0\n    genhealth                   0\n    sleeptimenightly            0\n    asthma                      0\n    kidneydisease               0\n    skincancer                  0\n    dtype: int64\n    ```", "```py\n    healthinfo.heartdisease.value_counts()\n    No        27467\n    Yes       2533\n    Name: heartdisease, dtype: int64\n    healthinfo['heartdisease'] = \\\n      np.where(healthinfo.heartdisease=='No',0,1).\\\n         astype('int')\n    healthinfo.heartdisease.value_counts()\n    0        27467\n    1        2533\n    Name: heartdisease, dtype: int64\n    ```", "```py\nnum_cols = ['bmi','physicalhealthbaddays',\n   'mentalhealthbaddays','sleeptimenightly']\nbinary_cols = ['smoking','alcoholdrinkingheavy',\n  'stroke','walkingdifficult','physicalactivity',\n  'asthma','kidneydisease','skincancer']\ncat_cols = ['gender','ethnicity']\nspec_cols1 = ['agecategory']\nspec_cols2 = ['genhealth']\nspec_cols3 = ['diabetic']\nrep_dict = {\n  'genhealth': {'Poor':0,'Fair':1,'Good':2,\n    'Very good':3,'Excellent':4},\n  'diabetic': {'No':0,\n    'No, borderline diabetes':0,'Yes':1,\n    'Yes (during pregnancy)':1}           \n}\n```", "```py\n    healthinfo[binary_cols].\\\n      apply(pd.value_counts, normalize=True).T\n                            No       Yes\n    smoking                 0.58     0.42\n    alcoholdrinkingheavy    0.93     0.07\n    stroke                  0.96     0.04\n    walkingdifficult        0.86     0.14\n    physicalactivity        0.23     0.77\n    asthma                  0.87     0.13\n    kidneydisease           0.96     0.04\n    skincancer              0.91     0.09\n    ```", "```py\n    for col in healthinfo[cat_cols + \n    ['genhealth','diabetic']].columns:\n      print(col, \"----------------------\",\n      healthinfo[col].value_counts(normalize=True).\\\n          sort_index(), sep=\"\\n\", end=\"\\n\\n\")\n    ```", "```py\ngender\n----------------------\nFemale   0.52\nMale     0.48\nName: gender, dtype: float64\nethnicity\n----------------------\nAmerican Indian/Alaskan Native   0.02\nAsian                            0.03\nBlack                            0.07\nHispanic                         0.09\nOther                            0.03\nWhite                            0.77\nName: ethnicity, dtype: float64\ngenhealth\n----------------------\nExcellent   0.21\nFair        0.11\nGood        0.29\nPoor        0.04\nVery good   0.36\nName: genhealth, dtype: float64\ndiabetic\n----------------------\nNo                        0.84\nNo, borderline diabetes   0.02\nYes                       0.13\nYes (during pregnancy)    0.01\nName: diabetic, dtype: float64\n```", "```py\n    healthinfo[num_cols].\\\n      agg(['count','min','median','max']).T\n                           count    min    median  max\n    bmi                    30,000   12     27      92\n    physicalhealthbaddays  30,000   0      0       30\n    mentalhealthbaddays    30,000   0      0       30\n    sleeptimenightly       30,000   1      7       24\n    ```", "```py\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(healthinfo[num_cols + \n        binary_cols + cat_cols + spec_cols1 +\n        spec_cols2 + spec_cols3],\\\n      healthinfo[['heartdisease']], test_size=0.2,\n        random_state=0)\n    ```", "```py\nohe = OneHotEncoder(drop='first', sparse=False)\nstandtrans = make_pipeline(OutlierTrans(3),\n  SimpleImputer(strategy=\"median\"),\n  StandardScaler())\nspectrans1 = make_pipeline(MakeOrdinal(),\n  StandardScaler())\nspectrans2 = make_pipeline(ReplaceVals(rep_dict),\n  StandardScaler())\nspectrans3 = make_pipeline(ReplaceVals(rep_dict))\nbintrans = make_pipeline(ohe)\ncattrans = make_pipeline(ohe)\ncoltrans = ColumnTransformer(\n  transformers=[\n    (\"stand\", standtrans, num_cols),\n    (\"spec1\", spectrans1, spec_cols1),\n    (\"spec2\", spectrans2, spec_cols2),\n    (\"spec3\", spectrans3, spec_cols3),\n    (\"bin\", bintrans, binary_cols),\n    (\"cat\", cattrans, cat_cols),\n  ]\n)\n```", "```py\nlrsel = LogisticRegression(random_state=1, \n  max_iter=1000)\nkf = StratifiedKFold(n_splits=5, shuffle=True)\nrfecv = RFECV(estimator=lrsel, cv=kf)\nlr = LogisticRegression(random_state=1,\n  class_weight='balanced', max_iter=1000)\npipe1 = make_pipeline(coltrans, rfecv, lr)\npipe1.fit(X_train, y_train.values.ravel())\n```", "```py\n    new_binary_cols = \\\n      pipe1.named_steps['columntransformer'].\\\n      named_transformers_['bin'].\\\n      named_steps['onehotencoder'].\\\n      get_feature_names(binary_cols)\n    new_cat_cols = \\\n      pipe1.named_steps['columntransformer'].\\\n      named_transformers_['cat'].\\\n      named_steps['onehotencoder'].\\\n      get_feature_names(cat_cols)\n    new_cols = np.concatenate((np.array(num_cols +\n      spec_cols1 + spec_cols2 + spec_cols3),\n      new_binary_cols, new_cat_cols))\n    new_cols\n    array(['bmi', 'physicalhealthbaddays',\n           'mentalhealthbaddays', 'sleeptimenightly',\n           'agecategory', 'genhealth', 'diabetic',\n           'smoking_Yes', 'alcoholdrinkingheavy_Yes',\n           'stroke_Yes', 'walkingdifficult_Yes',\n           'physicalactivity_Yes', 'asthma_Yes',\n           'kidneydisease_Yes', 'skincancer_Yes',\n           'gender_Male', 'ethnicity_Asian',\n           'ethnicity_Black', 'ethnicity_Hispanic',\n           'ethnicity_Other', 'ethnicity_White'],\n          dtype=object)\n    ```", "```py\nrankinglabs = \\\n np.column_stack((pipe1.named_steps['rfecv'].ranking_,\n new_cols))\npd.DataFrame(rankinglabs,\n columns=['rank','feature']).\\\n sort_values(['rank','feature']).\\\n set_index(\"rank\")\n                       feature\nrank                          \n1                  agecategory\n1     alcoholdrinkingheavy_Yes\n1                   asthma_Yes\n1                     diabetic\n1              ethnicity_Asian\n1              ethnicity_Other\n1              ethnicity_White\n1                  gender_Male\n1                    genhealth\n1            kidneydisease_Yes\n1                  smoking_Yes\n1                   stroke_Yes\n1         walkingdifficult_Yes\n2           ethnicity_Hispanic\n3               skincancer_Yes\n4                          bmi\n5        physicalhealthbaddays\n6             sleeptimenightly\n7          mentalhealthbaddays\n8         physicalactivity_Yes\n9              ethnicity_Black\n```", "```py\noddsratios = np.exp(pipe1.\\\n  named_steps['logisticregression'].coef_)\noddsratios.shape\n(1, 13)\nselcols = new_cols[pipe1.\\\n  named_steps['rfecv'].get_support()]\noddswithlabs = np.column_stack((oddsratios.\\\n  ravel(), selcols))\npd.DataFrame(oddswithlabs, \n  columns=['odds','feature']).\\\n  sort_values(['odds'], ascending=False).\\\n  set_index('odds')\n                        feature\nodds                          \n3.01                stroke_Yes\n2.88               agecategory\n2.12               gender_Male\n1.97         kidneydisease_Yes\n1.75                  diabetic\n1.55               smoking_Yes\n1.52                asthma_Yes\n1.30      walkingdifficult_Yes\n1.27           ethnicity_Other\n1.22           ethnicity_White\n0.72           ethnicity_Asian\n0.61  alcoholdrinkingheavy_Yes\n0.57                 genhealth\n```", "```py\n    pred = pipe1.predict(X_test)\n    cm = skmet.confusion_matrix(y_test, pred)\n    cmplot = skmet.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n    cmplot.plot()\n    cmplot.ax_.set(title='Heart Disease Prediction Confusion Matrix', \n      xlabel='Predicted Value', ylabel='Actual Value')\n    ```", "```py\n    tn, fp, fn, tp = skmet.confusion_matrix(y_test.values.ravel(), pred).ravel()\n    tn, fp, fn, tp\n    (4076, 1430, 102, 392)\n    accuracy = (tp + tn) / pred.shape[0]\n    accuracy\n    0.7446666666666667\n    sensitivity = tp / (tp + fn)\n    sensitivity\n    0.7935222672064778\n    specificity = tn / (tn+fp)\n    specificity\n    0.7402833272793317\n    precision = tp / (tp + fp)\n    precision\n    0.21514818880351264\n    ```", "```py\n    print(\"accuracy: %.2f, sensitivity: %.2f, specificity: %.2f, precision: %.2f\"  %\n      (skmet.accuracy_score(y_test.values.ravel(), pred),\n      skmet.recall_score(y_test.values.ravel(), pred),\n      skmet.recall_score(y_test.values.ravel(), pred,\n      pos_label=0),\n      skmet.precision_score(y_test.values.ravel(), pred)))\n    accuracy: 0.74, sensitivity: 0.79, specificity: 0.74, precision: 0.22\n    ```", "```py\n    falsepositiverate = fp / (tn + fp)\n    falsepositiverate\n    0.25971667272066834\n    ```", "```py\n    pred_probs = pipe1.predict_proba(X_test)[:, 1]\n    probdf = \\\n      pd.DataFrame(zip(pred_probs, pred,\n      y_test.values.ravel()),\n      columns=(['prob','pred','actual']))\n    probdf.groupby(['pred'])['prob'].\\\n      agg(['min','max','count'])\n            min        max        count\n    pred                 \n    0       0.01       0.50       4178\n    1       0.50       0.99       1822\n    ```", "```py\n    sns.kdeplot(probdf.loc[probdf.actual==1].prob,\n      shade=True, color='red',label=\"Heart Disease\")\n    sns.kdeplot(probdf.loc[probdf.actual==0].prob,\n      shade=True,color='green',label=\"No Heart Disease\")\n    plt.axvline(0.25, color='black', linestyle='dashed',\n      linewidth=1)\n    plt.axvline(0.5, color='black', linestyle='dashed',\n      linewidth=1)\n    plt.title(\"Predicted Probability Distribution\")\n    plt.legend(loc=\"upper left\")\n    ```", "```py\n    prec, sens, ths = skmet.precision_recall_curve(y_test, pred_probs)\n    sens = sens[1:-20]\n    prec = prec[1:-20]\n    ths  = ths[:-20]\n    fig, ax = plt.subplots()\n    ax.plot(ths, prec, label='Precision')\n    ax.plot(ths, sens, label='Sensitivity')\n    ax.set_title('Precision and Sensitivity by Threshold')\n    ax.set_xlabel('Threshold')\n    ax.set_ylabel('Precision and Sensitivity')\n    ax.legend()\n    ```", "```py\n    fpr, tpr, ths = skmet.roc_curve(y_test, pred_probs)\n    ths = ths[1:]\n    fpr = fpr[1:]\n    tpr = tpr[1:]\n    fig, ax = plt.subplots()\n    ax.plot(fpr, tpr, linewidth=4, color=\"black\")\n    ax.set_title('ROC curve')\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('Sensitivity')\n    ```", "```py\n    fig, ax = plt.subplots()\n    ax.plot(ths, fpr, label=\"False Positive Rate\")\n    ax.plot(ths, tpr, label=\"Sensitivity\")\n    ax.set_title('False Positive Rate and Sensitivity by Threshold')\n    ax.set_xlabel('Threshold')\n    ax.set_ylabel('False Positive Rate and Sensitivity')\n    ax.legend()\n    ```", "```py\n    jthresh = ths[np.argmax(tpr – fpr)]\n    jthresh\n    0.45946882675453804\n    ```", "```py\n    pred2 = np.where(pred_probs>=jthresh,1,0)\n    cm = skmet.confusion_matrix(y_test, pred2)\n    cmplot = skmet.ConfusionMatrixDisplay(\n      confusion_matrix=cm, \n      display_labels=['Negative', 'Positive'])\n    cmplot.plot()\n    cmplot.ax_.set(\n      title='Heart Disease Prediction Confusion Matrix', \n      xlabel='Predicted Value', ylabel='Actual Value')\n    ```", "```py\n    skmet.recall_score(y_test.values.ravel(), pred)\n    0.7935222672064778\n    skmet.recall_score(y_test.values.ravel(), pred2)\n    0.8380566801619433\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.preprocessing import OneHotEncoder\n    from sklearn.pipeline import make_pipeline\n    from sklearn.impute import SimpleImputer\n    from sklearn.compose import ColumnTransformer\n    from sklearn.model_selection import RepeatedStratifiedKFold\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.model_selection import RandomizedSearchCV\n    from scipy.stats import uniform\n    import os\n    import sys\n    sys.path.append(os.getcwd() + \"/helperfunctions\")\n    from preprocfunc import OutlierTrans,\\\n      MakeOrdinal, ReplaceVals\n    ```", "```py\n    healthinfo = pd.read_csv(\"data/healthinfosample.csv\")\n    healthinfo.set_index(\"personid\", inplace=True)\n    healthinfo['heartdisease'] = \\\n      np.where(healthinfo.heartdisease=='No',0,1).\\\n      astype('int')\n    ```", "```py\n    num_cols = ['bmi','physicalhealthbaddays',\n       'mentalhealthbaddays','sleeptimenightly']\n    binary_cols = ['smoking','alcoholdrinkingheavy',\n      'stroke','walkingdifficult','physicalactivity',\n      'asthma','kidneydisease','skincancer']\n    cat_cols = ['gender','ethnicity']\n    spec_cols1 = ['agecategory']\n    spec_cols2 = ['genhealth']\n    spec_cols3 = ['diabetic']\n    rep_dict = {\n      'genhealth': {'Poor':0,'Fair':1,'Good':2,\n        'Very good':3,'Excellent':4},\n      'diabetic': {'No':0,\n        'No, borderline diabetes':0,'Yes':1,\n        'Yes (during pregnancy)':1}           \n    }\n    ```", "```py\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(healthinfo[num_cols + \n        binary_cols + cat_cols + spec_cols1 +\n        spec_cols2 + spec_cols3],\\\n      healthinfo[['heartdisease']], test_size=0.2,\n        random_state=0)\n    ```", "```py\n    ohe = OneHotEncoder(drop='first', sparse=False)\n    standtrans = make_pipeline(OutlierTrans(3),\n      SimpleImputer(strategy=\"median\"),\n      StandardScaler())\n    spectrans1 = make_pipeline(MakeOrdinal(),\n      StandardScaler())\n    spectrans2 = make_pipeline(ReplaceVals(rep_dict),\n      StandardScaler())\n    spectrans3 = make_pipeline(ReplaceVals(rep_dict))\n    bintrans = make_pipeline(ohe)\n    cattrans = make_pipeline(ohe)\n    coltrans = ColumnTransformer(\n      transformers=[\n        (\"stand\", standtrans, num_cols),\n        (\"spec1\", spectrans1, spec_cols1),\n        (\"spec2\", spectrans2, spec_cols2),\n        (\"spec3\", spectrans3, spec_cols3),\n        (\"bin\", bintrans, binary_cols),\n        (\"cat\", cattrans, cat_cols),\n      ]\n    )\n    ```", "```py\nlr = LogisticRegression(random_state=1, class_weight='balanced', max_iter=1000)\nkf = RepeatedStratifiedKFold(n_splits=7, n_repeats=3, random_state=0)\npipe1 = make_pipeline(coltrans, lr)\nreg_params = [\n  {\n    'logisticregression__solver': ['liblinear'],\n    'logisticregression__penalty': ['l1','l2'],\n    'logisticregression__C': uniform(loc=0, scale=10)\n  },\n  {\n    'logisticregression__solver': ['newton-cg'],\n    'logisticregression__penalty': ['l2'],\n    'logisticregression__C': uniform(loc=0, scale=10)\n  },\n  {\n    'logisticregression__solver': ['saga'],\n    'logisticregression__penalty': ['elasticnet'],\n    'logisticregression__l1_ratio': uniform(loc=0, scale=1),   \n    'logisticregression__C': uniform(loc=0, scale=10)\n  }\n]\nrs = RandomizedSearchCV(pipe1, reg_params, cv=kf, \n  n_iter=20, scoring='roc_auc')\nrs.fit(X_train, y_train.values.ravel())\n```", "```py\n    rs.best_params_\n    {'logisticregression__C': 0.6918282397356423,\n     'logisticregression__l1_ratio': 0.758705704020254,\n     'logisticregression__penalty': 'elasticnet',\n     'logisticregression__solver': 'saga'}\n    rs.best_score_\n    0.8410275986723489\n    ```", "```py\nresults = \\\n  pd.DataFrame(rs.cv_results_['mean_test_score'], \\\n    columns=['meanscore']).\\\n  join(pd.json_normalize(rs.cv_results_['params'])).\\\n  sort_values(['meanscore'], ascending=False)\nresults.head(3).T\n                              15          4      12\nmeanscore                     0.841       0.841  0.841\nlogisticregression__C         0.692       1.235  0.914\nlogisticregression__l1_ratio  0.759       NaN    NaN\nlogisticregression__penalty   elasticnet  l1     l2\nlogisticregression__solver  saga  liblinear  liblinear\n```", "```py\n    pred = rs.predict(X_test)\n    cm = skmet.confusion_matrix(y_test, pred)\n    cmplot = \\\n      skmet.ConfusionMatrixDisplay(confusion_matrix=cm,\n      display_labels=['Negative', 'Positive'])\n    cmplot.plot()\n    cmplot.ax_.\\\n      set(title='Heart Disease Prediction Confusion Matrix', \n      xlabel='Predicted Value', ylabel='Actual Value')\n    ```", "```py\n    print(\"accuracy: %.2f, sensitivity: %.2f, specificity: %.2f, precision: %.2f\"  %\n      (skmet.accuracy_score(y_test.values.ravel(), pred),\n      skmet.recall_score(y_test.values.ravel(), pred),\n      skmet.recall_score(y_test.values.ravel(), pred,\n        pos_label=0),\n      skmet.precision_score(y_test.values.ravel(), pred)))\n    accuracy: 0.74, sensitivity: 0.79, specificity: 0.74, precision: 0.21\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.preprocessing import OneHotEncoder\n    from sklearn.pipeline import make_pipeline\n    from sklearn.impute import SimpleImputer\n    from sklearn.compose import ColumnTransformer\n    from sklearn.model_selection import RepeatedStratifiedKFold\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.model_selection import cross_validate\n    import os\n    import sys\n    sys.path.append(os.getcwd() + \"/helperfunctions\")\n    from preprocfunc import OutlierTrans\n    ```", "```py\n    machinefailuretype = pd.read_csv(\"data/machinefailuretype.csv\")\n    machinefailuretype.info()\n    <class 'pandas.core.frame.DataFrame'>\n    RangeIndex: 10000 entries, 0 to 9999\n    Data columns (total 10 columns):\n     #   Column              Non-Null Count      Dtype\n    ---  ------             --------------       ----  \n     0   udi                 10000 non-null      int64\n     1   product             10000 non-null      object \n     2   machinetype         10000 non-null      object \n     3   airtemp             10000 non-null      float64\n     4   processtemperature  10000 non-null      float64\n     5   rotationalspeed     10000 non-null      int64\n     6   torque              10000 non-null      float64\n     7   toolwear            10000 non-null      int64\n     8   fail                10000 non-null      int64\n     9   failtype            10000 non-null      object \n    dtypes: float64(3), int64(4), object(3)\n    memory usage: 781.4+ KB\n    ```", "```py\n    machinefailuretype.head()\n       udi product machinetype airtemp processtemperature\\\n    0  1   M14860  M           298     309 \n    1  2   L47181  L           298     309 \n    2  3   L47182  L           298     308 \n    3  4   L47183  L           298     309 \n    4  5   L47184  L           298     309 \n       Rotationalspeed  torque  toolwear  fail  failtype  \n    0   1551             43       0        0    No Failure\n    1   1408             46       3        0    No Failure\n    2   1498             49       5        0    No Failure\n    3   1433             40       7        0    No Failure\n    4   1408             40       9        0    No Failure\n    ```", "```py\n    machinefailuretype.failtype.value_counts(dropna=False).sort_index()\n    Heat Dissipation Failure    112\n    No Failure                  9652\n    Overstrain Failure          78\n    Power Failure               95\n    Random Failures             18\n    Tool Wear Failure           45\n    Name: failtype, dtype: int64\n    machinefailuretype.machinetype.\\\n      value_counts(dropna=False).sort_index()\n    H    1003\n    L    6000\n    M    2997\n    Name: machinetype, dtype: int64\n    ```", "```py\n    def setcode(typetext):\n      if (typetext==\"No Failure\"):\n        typecode = 1\n      elif (typetext==\"Heat Dissipation Failure\"):\n        typecode = 2\n      elif (typetext==\"Power Failure\"):\n        typecode = 3\n      elif (typetext==\"Overstrain Failure\"):\n        typecode = 4\n      else:\n        typecode = 5\n      return typecode\n    machinefailuretype[\"failtypecode\"] = \\\n      machinefailuretype.apply(lambda x: setcode(x.failtype), axis=1)\n    ```", "```py\n    machinefailuretype.groupby(['failtypecode','failtype']).size().\\\n      reset_index()\n      failtypecode   failtype                     0\n    0     1          No Failure                   9652\n    1     2          Heat Dissipation Failure     112\n    2     3          Power Failure                95\n    3     4          Overstrain Failure           78\n    4     5          Random Failures              18\n    5     5          Tool Wear Failure            45\n    ```", "```py\n    num_cols = ['airtemp','processtemperature','rotationalspeed',\n      'torque','toolwear']\n    cat_cols = ['machinetype']\n    machinefailuretype[num_cols].agg(['min','median','max']).T\n                          min      median    max\n    airtemp               295      300       304\n    processtemperature    306      310       314\n    rotationalspeed       1,168    1,503     2,886\n    torque                4        40        77\n    toolwear              0        108       253\n    ```", "```py\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(machinefailuretype[num_cols +\n      cat_cols], machinefailuretype[['failtypecode']],\n      test_size=0.2, random_state=0)\n    ohe = OneHotEncoder(drop='first', sparse=False)\n    standtrans = make_pipeline(OutlierTrans(3),\n      SimpleImputer(strategy=\"median\"),\n      StandardScaler())\n    cattrans = make_pipeline(ohe)\n    coltrans = ColumnTransformer(\n      transformers=[\n        (\"stand\", standtrans, num_cols),\n        (\"cat\", cattrans, cat_cols),\n      ]\n    )\n    ```", "```py\n    lr = LogisticRegression(random_state=0, \n      multi_class='multinomial', solver='lbfgs',\n      max_iter=1000)\n    kf = RepeatedStratifiedKFold(n_splits=10,\n      n_repeats=5, random_state=0)\n    pipe1 = make_pipeline(coltrans, lr)\n    ```", "```py\n    cm = skmet.confusion_matrix(y_test, \n       pipe1.fit(X_train, y_train.values.ravel()).\\\n       predict(X_test))\n    cmplot = \\\n       skmet.ConfusionMatrixDisplay(confusion_matrix=cm,\n       display_labels=['None', 'Heat','Power','Overstrain','Other'])\n    cmplot.plot()\n    cmplot.ax_.\\\n      set(title='Machine Failure Type Confusion Matrix', \n      xlabel='Predicted Value', ylabel='Actual Value')\n    ```", "```py\nscores = cross_validate(\n  pipe1, X_train, y_train.values.ravel(), \\\n  scoring=['accuracy', 'precision_weighted',\n           'recall_weighted', 'f1_macro',\n           'f1_weighted'], \n  cv=kf, n_jobs=-1)\naccuracy, precision, sensitivity, f1_macro, f1_weighted = \\\n  np.mean(scores['test_accuracy']),\\\n  np.mean(scores['test_precision_weighted']),\\\n  np.mean(scores['test_recall_weighted']),\\\n  np.mean(scores['test_f1_macro']),\\\n  np.mean(scores['test_f1_weighted'])\naccuracy, precision, sensitivity, f1_macro, f1_weighted\n(0.9716499999999999,\n 0.9541025493784612,\n 0.9716499999999999,\n 0.3820938909478524,\n 0.9611411229222823)\n```"]