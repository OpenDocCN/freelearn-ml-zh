- en: Profiling and Accelerating Your Apps
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能分析和加速你的应用程序
- en: 'When you have a problem with a slow app, first of all, you need to find which
    exact parts of your code are taking quite a lot of processing time. A good way
    of finding such parts of the code, which are also called **bottlenecks**, is to
    profile the app. One of the good profilers available that allow an app to be profiled
    without modifications being introduced to the app is called `pyinstrument` ([https://github.com/joerick/pyinstrument](https://github.com/joerick/pyinstrument)).
    Here, we profile the app of [Chapter 10](7eaac815-5888-4352-aa83-7a3b50d0d275.xhtml), *Learning
    to Detect and Track Objects*, using `pyinstrument`, as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当你遇到一个运行缓慢的应用程序时，首先，你需要找出你的代码中哪些部分花费了相当多的处理时间。找到这些代码部分（也称为 **瓶颈**）的一个好方法是对应用程序进行性能分析。一个允许在不修改应用程序的情况下对应用程序进行性能分析的好分析器是
    `pyinstrument`（[https://github.com/joerick/pyinstrument](https://github.com/joerick/pyinstrument)）。在这里，我们使用
    `pyinstrument` 对 [第 10 章](7eaac815-5888-4352-aa83-7a3b50d0d275.xhtml)，*学习检测和跟踪对象*
    的应用程序进行性能分析，如下所示：
- en: '[PRE0]'
  id: totrans-2
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We have passed an output `.html` file where we want the profiling report information
    to be saved with a `-o` option.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `-o` 选项传递了一个输出 `.html` 文件，其中包含性能分析报告信息要保存的位置。
- en: We have also specified how the report should be rendered with a `-r` option,
    to state that we want an HTML output. Once the app is terminated, the profiling
    report will be generated, and it can be viewed in a browser.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用 `-r` 选项指定了报告的渲染方式，以声明我们想要 HTML 输出。一旦应用程序终止，性能分析报告将被生成，并且可以在浏览器中查看。
- en: You can omit both options.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以省略这两个选项。
- en: 'In the latter case, the report will be shown in the console. Once we terminate
    the app, we can open the generated `.html` file in the browser, which will show
    a report similar to the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在后一种情况下，报告将在控制台中显示。一旦我们终止应用程序，我们可以在浏览器中打开生成的 `.html` 文件，它将显示类似于以下内容的报告：
- en: '![](img/ae15457c-82a9-4805-a06c-09b66ee7469c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ae15457c-82a9-4805-a06c-09b66ee7469c.png)'
- en: First of all, we can note that quite a lot of time is spent on the script itself.
    This should be expected, as an object detection model is making an inference on
    each frame, and that it is quite a heavy operation. We can also note that tracking
    also takes quite a lot of time, especially in the `iou` function.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以注意到在脚本本身上花费了相当多的时间。这是可以预料的，因为目标检测模型正在对每一帧进行推理，这是一个相当重的操作。我们还可以注意到跟踪也花费了相当多的时间，尤其是在
    `iou` 函数中。
- en: Generally, depending on a particular application of the app, in order to accelerate
    tracking, it can be enough to replace the `iou` function with a different one
    that is more efficient. In this app, the `iou` function was used to compute `iou_matrix`,
    which stores the **Intersection Over Union** (**IOU**) metric for each possible
    pair of detection and tracking boxes. When you work on accelerating your code,
    in order to save time, it might be a good idea to change the code with an accelerated
    version in place and profile it again, in order to check whether it meets your
    needs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，根据应用程序的特定应用，为了加速跟踪，只需将 `iou` 函数替换为更高效的另一个函数就足够了。在这个应用程序中，`iou` 函数被用来计算 `iou_matrix`，它存储了每个可能的检测和跟踪框对的
    **交集与并集**（**IOU**）度量。当你致力于加速你的代码时，为了节省时间，将代码替换为加速版本并再次进行性能分析，以检查它是否满足你的需求可能是个好主意。
- en: But let's take the appropriate relevant code out of the app and analyze the
    possibilities of accelerating it using **Numba**, which we will cover in the next
    section.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们从应用程序中提取适当的代码，并分析使用 **Numba** 加速的可能性，我们将在下一节中介绍。
- en: Accelerating with Numba
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Numba 加速
- en: Numba is a compiler that optimizes code written in pure Python using the **Low-Level
    Virtual Machine** (**LLVM**) compiler infrastructure. It efficiently compiles
    math-heavy Python code to reach performance similar to **C**, **C++**, and **Fortran**.
    It understands a range of `numpy` functions, Python `construct` libraries, and
    operators, as well as a range of math functions from the standard library, and
    generates corresponding native code for **Graphical Processing Units** (**GPUs**)
    and **Central Processing Units** (**CPUs**), with simple annotations.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Numba 是一个编译器，它使用 **低级虚拟机**（**LLVM**）编译器基础设施优化纯 Python 编写的代码。它有效地将数学密集型的 Python
    代码编译成与 **C**、**C++** 和 **Fortran** 相似性能的代码。它理解一系列 `numpy` 函数、Python `construct`
    库和运算符，以及标准库中的一系列数学函数，并为 **图形处理单元**（**GPU**）和 **中央处理单元**（**CPU**）生成相应的本地代码，只需简单的注释。
- en: In this section, we will use the **IPython** interactive interpreter to work
    with the code. It is an enhanced interactive Python shell that particularly supports
    so-called **magic commands**, which—in our case—we will use for timing functions.
    One of the options is to use the interpreter directly in the console. A couple
    of other options are to use **Jupyter Notebook** or **JupyterLab**. If you are
    using the **Atom **editor, you might want to consider the **Hydrogen** plugin,
    which implements an interactive coding environment right in the editor.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用**IPython**交互式解释器来处理代码。它是一个增强的交互式Python外壳，特别支持所谓的**魔法命令**，在我们的案例中，我们将使用这些命令来计时函数。一个选项是直接在控制台中使用解释器。其他几个选项是使用**Jupyter
    Notebook**或**JupyterLab**。如果您使用的是**Atom**编辑器，您可能想要考虑**Hydrogen**插件，该插件在编辑器中实现了一个交互式编码环境。
- en: 'To import NumPy and Numba, run the following code:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要导入NumPy和Numba，请运行以下代码：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We are using **Numba version 0.49**, which is the most recent version at the
    time of writing. Throughout this section, you will note that we will have to change
    the code in such a way that it could be compiled using this version of Numba.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用**Numba版本0.49**，这是撰写本文时的最新版本。在整个这一节中，您会注意到我们不得不以这种方式更改代码，以便可以使用这个版本的Numba进行编译。
- en: Supposedly, in future versions, Numba will support more functions, and some—or
    all—modifications might be not required. When you work on the code of your app,
    please refer to the **Numba** documentation for the supported features, available
    at [https://numba.pydata.org/numba-doc/latest/index.html](https://numba.pydata.org/numba-doc/latest/index.html) at
    the time of writing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 据说，在未来的版本中，Numba将支持更多函数，并且一些或所有修改可能不再需要。当您在您的应用程序代码上工作时，请参考撰写本文时的**Numba**文档，以了解支持的功能，文档可在[https://numba.pydata.org/numba-doc/latest/index.html](https://numba.pydata.org/numba-doc/latest/index.html)找到。
- en: Here, we cover some important possibilities of Numba and illustrate results
    on a certain example, so that you will have your vision on how Numba can help
    you with accelerating the code of your own apps.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们介绍了Numba的一些重要可能性，并在某个示例上展示了结果，以便您了解Numba如何帮助您加速您自己的应用程序代码。
- en: 'Let''s now isolate the code that we want to accelerate, as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将我们想要加速的代码隔离出来，如下所示：
- en: 'First of all, this is the function that computes the `iou` of two boxes:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，这是一个计算两个框的`iou`的函数：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For now, we have left it as it is from [Chapter 10](7eaac815-5888-4352-aa83-7a3b50d0d275.xhtml), *Learning
    to Detect and Track Objects*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们将其保留为[第10章](7eaac815-5888-4352-aa83-7a3b50d0d275.xhtml)中的原样，*学习检测和跟踪对象*。
- en: 'Next is the part of the code that calculates `iou_matrix` using the previous
    function, as follows:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来是使用先前函数计算`iou_matrix`的代码部分，如下所示：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We have wrapped up the corresponding loops and matrix definition in a single
    new function.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将相应的循环和矩阵定义封装在一个新的函数中。
- en: 'In order to test performance, let''s define two sets of `random` bounding boxes,
    like this:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了测试性能，让我们定义两组`随机`边界框，如下所示：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We have defined two sets of `100` bounding boxes.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了两组`100`个边界框。
- en: 'Now, we can estimate how much time it takes to compose `iou_matrix` of these
    bounding boxes by running the following code:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以通过运行以下代码来估计计算这些边界框的`iou_matrix`所需的时间：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `%timeit` magic command executes the function multiple times, computes
    the average execution time, as well as the deviation from the average, and outputs
    the result, which looks as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`%timeit`魔法命令会多次执行函数，计算平均执行时间以及与平均值的偏差，并输出结果，如下所示：'
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can note that it takes about one-third of 1 second to compute the matrix.
    Hence, if we have 100 objects in the scene and we want to process multiple frames
    in 1 second, there will be a huge bottleneck in the app. Let's now accelerate
    this code on a CPU.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以注意到计算矩阵大约需要1/3秒。因此，如果我们场景中有100个对象，并且我们想在1秒内处理多个帧，应用程序中将会出现巨大的瓶颈。现在让我们在CPU上加速这段代码。
- en: Accelerating with the CPU
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CPU加速
- en: 'Numba has several code-generation utilities that generate machine code out
    of Python code. One of its central features is the `@numba.jit` decorator. This
    decorator allows you to mark a function for optimization by Numba''s compiler.
    For example, the following function calculates the product of all the elements
    in an array:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Numba有几个代码生成实用工具，可以将Python代码转换为机器代码。其核心特性之一是`@numba.jit`装饰器。这个装饰器允许您通过Numba编译器优化标记一个函数。例如，以下函数计算数组中所有元素的总乘积：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It can be viewed as a `np.product`. custom implementation. The decorator tells
    Numba to compile the function into machine code, which results in much faster
    execution time compared to the Python version. Numba always tries to compile the
    specified function. In the case of operations in the function that cannot be fully
    compiled, Numba falls back to the so-called **object mode**, which uses the **Python/C
    API** and handles all values as Python objects, to perform operations on them.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以被视为一个`np.product`的自定义实现。装饰器告诉Numba将函数编译成机器代码，这比Python版本有更快的执行时间。Numba总是尝试编译指定的函数。在函数中的操作无法完全编译的情况下，Numba会回退到所谓的**对象模式**，使用**Python/C
    API**，并将所有值作为Python对象处理，以对它们进行操作。
- en: The latter is much slower than the former. When we pass `nopython=True`, we
    explicitly tell it to raise an exception when the function cannot be compiled
    to full machine code.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 后者比前者慢得多。当我们传递`nopython=True`时，我们明确告诉它，当函数无法编译为完整的机器代码时，抛出异常。
- en: 'We can use the same decorator with the `iou` function, as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用与`iou`函数相同的装饰器，如下所示：
- en: '[PRE8]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can note that this function differs slightly from the Python function. First
    of all, we have used our custom implementation of `np.product`. If we try to use
    the native implementation with the current version of Numba, we will end up with
    an exception, as the native `np.product` is not currently supported by the Numba
    compiler. It's a similar story with the first two lines of the function, where
    Numba fails to interpret the automatic unpacking of the array into a tuple.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以注意到这个函数与Python函数略有不同。首先，我们使用了我们自定义的`np.product`实现。如果我们尝试使用当前版本的Numba的本地实现，我们将遇到异常，因为本地的`np.product`目前不被Numba编译器支持。这与函数的前两行类似，Numba无法解释数组的自动解包。
- en: 'Now, we are ready to time our function, as we did previously, as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备像之前一样计时我们的函数，如下所示：
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The latter produces the following output:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 后者产生以下输出：
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can note that we already have a huge acceleration (about 20 times), but
    let''s proceed further. We can note that `calc_iou_matrix` is still in pure Python
    and it has nested loops, which might take quite a lot of time. Let''s create a
    compiled version of it, like this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以注意到，我们已经实现了巨大的加速（大约20倍），但让我们继续前进。我们可以注意到`calc_iou_matrix`仍然是用纯Python编写的，并且有嵌套循环，这可能会花费相当多的时间。让我们创建它的编译版本，如下所示：
- en: '[PRE11]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Again, this function differs from the original one, as Numba could not interpret `enumerate`.
    Timing this implementation will produce an output similar to the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，这个函数与原始函数不同，因为Numba无法解释`enumerate`。对这个实现进行计时将产生类似于以下输出的结果：
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We again have an acceleration. This version is twice as fast compared with the
    previous one. Let's continue with the acceleration and get it as fast as possible,
    but before doing that, let's first familiarize ourselves with the `vectorize` decorator.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次实现了加速。这个版本比之前的版本快一倍。让我们继续加速，尽可能让它变得更快，但在做之前，让我们首先熟悉一下`vectorize`装饰器。
- en: 'The `vectorize` decorator allows functions to be created that can be used as
    NumPy `ufuncs` class out of functions that work on scalar arguments, as in the
    following function:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`vectorize`装饰器允许创建函数，这些函数可以用作NumPy`ufuncs`类，从在标量参数上工作的函数中创建，如下面的函数所示：'
- en: '[PRE13]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The function performs some specific operation when given a pair of scalars,
    and the `vectorize` decorator makes it possible to do the same operation on NumPy
    arrays, for example, as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当给函数一对标量时，该函数执行一些特定的操作，而`vectorize`装饰器使得在NumPy数组上执行相同的操作成为可能，例如，如下所示：
- en: '[PRE14]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'NumPy casting rules also work—for example, you can replace one of the arrays
    with a scalar or an array with shape `(1,4)`, as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy类型转换规则也适用——例如，你可以用一个标量替换一个数组，或者用一个形状为`(1,4)`的数组替换一个数组，如下所示：
- en: '[PRE15]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Another decorator that we will use to accelerate our `iou_matrix` computation
    is `guvectorize`. This decorator takes the concept of `vectorize` one step further.
    It allows `ufuncs` to be written that return arrays with different dimensionality.
    We can note that, when calculating the IOU matrix, the output array has a shape
    composed of the numbers of bounding boxes in each passed array. We use the decorator
    as follows to compute the matrix:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用另一个装饰器`guvectorize`来加速我们的`iou_matrix`计算。这个装饰器将`vectorize`的概念推进了一步。它允许编写返回不同维度数组的`ufuncs`。我们可以注意到，在计算IOU矩阵时，输出数组的形状由每个传递数组中边界框的数量组成。我们如下使用装饰器来计算矩阵：
- en: '[PRE16]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The first parameter tells Numba to compile a function that works on 8-byte floats
    (`float64`). It also specifies the dimensionalities of the input and output arrays
    with semicolons. The second parameter is the signature, which specifies how the
    dimensions of the input and output arrays are matched with each other. Once we
    execute the function with the input, the `z` output is waiting there with the
    correct shape and just needs to be filled in the function.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数告诉Numba编译一个在8字节浮点数（`float64`）上工作的函数。它还使用分号指定输入和输出数组的维度。第二个参数是签名，它指定了输入和输出数组的维度是如何相互匹配的。一旦我们用输入执行了函数，`z`输出就会在那里等待，具有正确的形状，只需要在函数中填充即可。
- en: 'If we time this implementation as we did previously, we obtain an output similar
    to the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们像之前那样计时这个实现，我们会得到一个类似于以下输出的结果：
- en: '[PRE17]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Again, we are about 30 times faster compared to the previous case. In comparison
    with the initial pure Python implementation, we are about 1,000 times faster,
    which is quite impressive.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们的速度比之前的情况快了大约30倍。与最初的纯Python实现相比，我们快了大约1,000倍，这相当令人印象深刻。
- en: Understanding Numba, CUDA, and GPU acceleration
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Numba、CUDA和GPU加速
- en: You have seen how simple it is to create CPU-accelerated code using Numba. Numba
    also provides a similar interface to make a computation on a GPU using **Compute
    Unified Device Architecture** (**CUDA**). Let's port our IOU matrix calculation
    function to be computed on a GPU using Numba.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了使用Numba创建CPU加速代码是多么简单。Numba还提供了一个类似的接口，使用**Compute Unified Device Architecture**（**CUDA**）进行GPU计算。让我们将我们的IOU矩阵计算函数移植到使用Numba在GPU上进行计算。
- en: 'We can instruct Numba to make the computation on a GPU by slightly modifying
    the decorator parameters, as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过稍微修改装饰器参数来指示Numba在GPU上进行计算，如下所示：
- en: '[PRE18]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here, we have instructed Numba to make the computation on a GPU by passing `target="cuda"`.
    We also have work to do on the `iou` function. The new function looks as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通过传递`target="cuda"`来指示Numba在GPU上进行计算。我们还需要在`iou`函数上做一些工作。新的函数如下所示：
- en: '[PRE19]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: First of all, we have changed the decorator, which now uses `numba.cuda.jit`
    instead of `numba.jit`. The latter instructs Numba to create a function that is
    executed on a GPU. This function itself is called from a function that is running
    on a GPU device. For that purpose, we have passed `device=True`, which explicitly
    states that this function is intended to be used from functions that are calculated
    on a GPU.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们更改了装饰器，现在使用`numba.cuda.jit`而不是`numba.jit`。后者指示Numba创建一个在GPU上执行的功能。这个函数本身是从在GPU设备上运行的功能中调用的。为此，我们传递了`device=True`，这明确指出这个函数打算用于从在GPU上计算的功能中调用。
- en: You can also note that we made quite a few modifications so that we have eliminated
    all the NumPy function calls. As with CPU acceleration, this is due to the fact
    that `numba.cuda` cannot currently perform all operations that were available
    in the function, and we replaced them with the ones that `numba.cuda` supports.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以注意到，我们做了相当多的修改，以便我们消除了所有的NumPy函数调用。正如CPU加速一样，这是因为`numba.cuda`目前无法执行函数中所有可用的操作，我们将它们替换成了`numba.cuda`支持的那些操作。
- en: Usually, in computer vision, your app will require GPU acceleration only when
    you are working with **deep neural network**s (**DNNs**). Most of the modern deep
    learning frameworks, such as **TensorFlow**, **PyTorch**, and **MXNet**, support
    GPU acceleration out of the box, allowing you to be away from low-level GPU programming
    and to concentrate on your models instead. After analyzing the frameworks, if
    you find yourself with a specific algorithm that you think should be necessarily
    implemented with CUDA directly, you might want to analyze the `numba.cuda` API,
    which supports most of the CUDA features.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在计算机视觉中，你的应用程序只有在处理**深度神经网络**（**DNNs**）时才需要GPU加速。大多数现代深度学习框架，如**TensorFlow**、**PyTorch**和**MXNet**，都支持开箱即用的GPU加速，让你远离底层GPU编程，专注于你的模型。在分析了这些框架之后，如果你发现自己有一个你认为必须直接使用CUDA实现的特定算法，你可能想分析`numba.cuda`
    API，它支持大多数CUDA功能。
