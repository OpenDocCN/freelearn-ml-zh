["```py\ntrain_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\") \n```", "```py\ndef missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt)) \n```", "```py\ndef most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        try:\n            itm = data[col].value_counts().index[0]\n            val = data[col].value_counts().values[0]\n            items.append(itm)\n            vals.append(val)\n        except Exception as ex:\n            print(ex)\n            items.append(0)\n            vals.append(0)\n            continue\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals / total * 100, 3)\n    return(np.transpose(tt)) \n```", "```py\ndef unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    return(np.transpose(tt)) \n```", "```py\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\ndef set_color_map(color_list):\n    cmap_custom = ListedColormap(color_list)\n    print(\"Notebook Color Schema:\")\n    sns.palplot(sns.color_palette(color_list))\n    plt.show()\n    return cmap_custom\ncolor_list = [\"#A5D7E8\", \"#576CBC\", \"#19376D\", \"#0b2447\"]\ncmap_custom = set_color_map(color_list) \n```", "```py\ndef plot_count_pairs(data_df, feature, title, hue=\"set\"):\n    f, ax = plt.subplots(1, 1, figsize=(8, 4))\n    sns.countplot(x=feature, data=data_df, hue=hue, palette= color_list)\n    plt.grid(color=\"black\", linestyle=\"-.\", linewidth=0.5, axis=\"y\", which=\"major\")\n    ax.set_title(f\"Number of passengers / {title}\")\n    plt.show() \n```", "```py\ndef plot_distribution_pairs(data_df, feature, title, hue=\"set\"):\n    f, ax = plt.subplots(1, 1, figsize=(8, 4))\n    for i, h in enumerate(data_df[hue].unique()):\n        g = sns.histplot(data_df.loc[data_df[hue]==h, feature], color=color_list[i], ax=ax, label=h)\n    #plt.grid(color=\"black\", linestyle=\"-.\", linewidth=0.5, axis=\"y\", which=\"major\")\n    ax.set_title(f\"Number of passengers / {title}\")\n    g.legend()\n    plt.show() \n```", "```py\nAge Interval, to form five classes, from 0 to 4, corresponding to Age intervals between 0 and 16, 16 and 32, 32 and 48, 48 and 64, and above 64, respectively:\n```", "```py\nall_df[\"Age Interval\"] = 0.0\nall_df.loc[ all_df['Age'] <= 16, 'Age Interval']  = 0\nall_df.loc[(all_df['Age'] > 16) & (all_df['Age'] <= 32), 'Age Interval'] = 1\nall_df.loc[(all_df['Age'] > 32) & (all_df['Age'] <= 48), 'Age Interval'] = 2\nall_df.loc[(all_df['Age'] > 48) & (all_df['Age'] <= 64), 'Age Interval'] = 3\nall_df.loc[ all_df['Age'] > 64, 'Age Interval'] = 4 \n```", "```py\nall_df['Fare Interval'] = 0.0\nall_df.loc[ all_df['Fare'] <= 7.91, 'Fare Interval'] = 0\nall_df.loc[(all_df['Fare'] > 7.91) & (all_df['Fare'] <= 14.454), 'Fare Interval'] = 1\nall_df.loc[(all_df['Fare'] > 14.454) & (all_df['Fare'] <= 31), 'Fare Interval']   = 2\nall_df.loc[ all_df['Fare'] > 31, 'Fare Interval'] = 3 \n```", "```py\ndef parse_names(row):\n    try:\n        text = row[\"Name\"]\n        split_text = text.split(\",\")\n        family_name = split_text[0]\n        next_text = split_text[1]\n        split_text = next_text.split(\".\")\n        title =  (split_text[0] + \".\").lstrip().rstrip()\n        next_text = split_text[1]\n        if \"(\" in next_text:\n            split_text = next_text.split(\"(\")\n            given_name = split_text[0]\n            maiden_name = split_text[1].rstrip(\")\")\n            return pd.Series([family_name, title, given_name, maiden_name])\n        else:\n            given_name = next_text\n            return pd.Series([family_name, title, given_name, None])\n    except Exception as ex:\n        print(f\"Exception: {ex}\")\nall_df[[\"Family Name\", \"Title\", \"Given Name\", \"Maiden Name\"]] = all_df.apply(lambda row: parse_names(row), axis=1) \n```", "```py\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\n# convert categorical data in numerical\nfor dataset in [train_df, test_df]:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n# train-validation split (20% validation)\nVALID_SIZE = 0.2\ntrain, valid = train_test_split(train_df, test_size=VALID_SIZE, random_state=42, shuffle=True)\n# define predictors and target feature (labels)\npredictors = [\"Sex\", \"Pclass\"]\ntarget = 'Survived'\n# train and validation data and labels\ntrain_X = train[predictors]\ntrain_Y = train[target].values\nvalid_X = valid[predictors]\nvalid_Y = valid[target].values\n# define the classification model (Random Forest)\nclf = RandomForestClassifier(n_jobs=-1, \n                             random_state=42,\n                             criterion=\"gini\",\n                             n_estimators=100,\n                             verbose=False)\n# fit the model with training data and labels\nclf.fit(train_X, train_Y)\n# predict the survival status for the validation set\npreds = clf.predict(valid_X) \n```"]