- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Multi-Class Conformal Prediction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多类一致性预测
- en: Welcome to the last chapter of this book, where we delve into the fascinating
    world of multi-class **Conformal Prediction**. This chapter introduces you to
    various conformal prediction methods that can be effectively applied to multi-class
    classification problems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到本书的最后一章，我们将深入探讨多类**一致性预测**的迷人世界。本章将向您介绍各种可以有效地应用于多类分类问题的一致性预测方法。
- en: We will explore the concept of multi-class classification, a common scenario
    in **machine learning** (**ML**), where an instance can belong to one of many
    classes. Understanding this problem is the first step toward applying conformal
    prediction techniques effectively.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨多类分类的概念，这是机器学习（ML）中的一种常见场景，其中实例可以属于许多类别之一。理解这个问题是有效应用一致性预测技术的第一步。
- en: Next, we will investigate the metrics used to evaluate multi-class classification
    problems. These metrics provide a quantitative measure of the performance of our
    models, and understanding them is crucial for effective model evaluation and selection.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将研究用于评估多类分类问题的度量标准。这些度量标准为我们模型的性能提供了定量衡量，理解它们对于有效模型评估和选择至关重要。
- en: Finally, we will learn how to apply conformal prediction to multi-class classification
    problems. This section will provide practical insights and techniques to apply
    directly to your industrial applications.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将学习如何将一致性预测应用于多类分类问题。本节将提供实用的见解和技术，可以直接应用于你的工业应用。
- en: By the end of this chapter, you will have gained valuable skills and knowledge
    in multi-class classification and learned how conformal prediction can be effectively
    applied to these problems. So, let’s dive in and start our journey into multi-class
    conformal prediction!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将掌握在多类分类中的宝贵技能和知识，并学会如何有效地将这些方法应用于这些问题。那么，让我们深入其中，开始我们的多类一致性预测之旅！
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Multi-class classification problems
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多类分类问题
- en: Metrics for multi-class classification problems
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多类分类问题的度量标准
- en: How conformal prediction can be applied to multi-class classification problems
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将一致性预测应用于多类分类问题
- en: Multi-class classification problems
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多类分类问题
- en: In ML, classification problems are ubiquitous. They involve predicting a discrete
    class label output for an instance. While binary classification – predicting one
    of two possible outcomes – is a common scenario, many real-world problems require
    predicting more than two classes. This is where multi-class classification comes
    into play.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，分类问题是普遍存在的。它们涉及为实例预测一个离散的类别标签输出。虽然二元分类——预测两种可能结果之一——是一种常见场景，但许多现实世界的问题需要预测超过两个类别。这就是多类分类发挥作用的地方。
- en: Multi-class classification is a problem where an instance can belong to one
    of many classes. For example, consider an ML model designed to categorize news
    articles into topics. The articles could be classified into categories such as
    *Sports*, *Politics*, *Technology*, *Health*, and so on. Each of these categories
    represents a class, and since there are more than two classes, this is a multi-class
    classification problem.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类是一个实例可以属于许多类别之一的问题。例如，考虑一个设计用于将新闻文章分类到主题的机器学习模型。这些文章可以被分类到如*体育*、*政治*、*科技*、*健康*等类别。每个这些类别代表一个类别，由于有超过两个类别，这是一个多类分类问题。
- en: It’s important to note that each instance belongs to exactly one class in multi-class
    classification. If each instance could belong to multiple classes, it would be
    a multi-label classification problem, which is a different kind of problem.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，在多类分类中，每个实例恰好属于一个类别。如果每个实例可以属于多个类别，那么它将是一个多标签分类问题，这属于不同类型的问题。
- en: Multi-class classification problems are a staple in ML, and they require a slightly
    different approach than binary classification problems. Let’s dive deeper into
    the intricacies of multi-class classification.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类问题是机器学习中的基本问题，它们需要与二元分类问题略有不同的方法。让我们更深入地探讨多类分类的复杂性。
- en: Algorithms for multi-class classification
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类分类算法
- en: 'Several ML algorithms can handle multi-class classification problems directly.
    These include, but are not limited to, the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 几种机器学习算法可以直接处理多类分类问题。这些包括但不限于以下：
- en: '**Decision trees**: Decision tree algorithms such as **Classification and Regression
    Trees** (**CARTs**) can naturally handle multi-class classification.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树**：如**分类与回归树**（CARTs）之类的决策树算法可以自然地处理多分类。'
- en: '**Naive Bayes**: Naive Bayes treats each class as a separate one-versus-all
    binary classification problem and picks the outcome with the highest probability.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**朴素贝叶斯**：朴素贝叶斯将每个类别视为一个单独的一对多二分类问题，并选择概率最高的结果。'
- en: '`softmax` activation function can then be used to calculate the probability
    distribution of each class.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，可以使用`softmax`激活函数来计算每个类别的概率分布。
- en: Many ML algorithms are inherently designed for binary classification between
    two classes. Special strategies must be employed to extend these models to multi-class
    problems with more than two categories. Two common approaches are one-vs-all and
    one-vs-one.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法天生是为两个类别之间的二分类设计的。为了将这些模型扩展到具有两个以上类别的多分类问题，必须采用特殊策略。两种常见的方法是“一对多”和“一对一”。
- en: Next, we will explore these one-vs-all and one-vs-one strategies in more detail,
    including how binary classification outcomes get aggregated to make final multi-class
    predictions. We will also discuss evaluating multi-class classifiers using specialized
    performance metrics suited for problems with more than two categories.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将更详细地探讨这些一对多和一对一策略，包括如何将二分类结果汇总以做出最终的多分类预测。我们还将讨论使用适用于具有两个以上类别的问题的专用性能指标来评估多分类分类器。
- en: One-vs-all and one-vs-one strategies
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一对多和一对一策略
- en: 'For algorithms that do not natively support multi-class classification, strategies
    such as one-vs-all (also known as one-vs-rest) and one-vs-one are used as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不原生支持多分类的算法，可以使用以下策略，如一对多（也称为一对余）和一对一：
- en: '**One-vs-all strategy**: For a problem with *n* classes, *n* separate binary
    classification models are trained. Each model is trained to distinguish instances
    of one class from instances of all other classes. All *n* models are applied for
    a new instance, and the model that gives the highest confidence score determines
    the instance’s class.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一对一策略**：对于具有*n*个类别的难题，将训练*n*个独立的二分类模型。每个模型被训练以区分一个类别的实例与其他所有类别的实例。所有*n*个模型都应用于一个新实例，并且给出最高置信度分数的模型确定实例的类别。'
- en: '**One-vs-one strategy**: A binary classification model is trained for every
    pair of classes in this strategy. For *n* classes, this results in *n(n-1)/2*
    models. Each model’s decision contributes to a voting scheme, and the class with
    the most votes is chosen as the final class of the instance. For example, for
    a 4-class problem, 4*3/2 = 6 binary models would be built, one for each pair of
    classes. Each model casts a vote for its predicted class, and the class with the
    most votes across all models is chosen as the final prediction. So, with four
    classes, if three models predicted class A, two predicted class B, and one predicted
    class C, class A would be selected since it received the most votes. In this way,
    each model’s decision contributes to a voting scheme to determine the overall
    predicted class.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一对一策略**：在这种策略中，为每一对类别训练一个二分类模型。对于*n*个类别，这将产生*n(n-1)/2*个模型。每个模型的决策都会对投票方案做出贡献，并且获得最多投票的类别被选为实例的最终类别。例如，对于4个类别的难题，将构建4*3/2=6个二进制模型，每个类别一对。每个模型对其预测的类别投一票，所有模型中投票最多的类别被选为最终预测。因此，如果有四个类别，如果三个模型预测类别A，两个预测类别B，一个预测类别C，则由于它获得了最多的投票，类别A将被选中。这样，每个模型的决策都会对投票方案做出贡献，以确定整体预测的类别。'
- en: The following section will discuss the metrics used for evaluating multi-class
    classification problems. Understanding these metrics is crucial for assessing
    the performance of our models and making informed decisions about model selection
    and optimization.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分将讨论用于评估多分类问题的指标。理解这些指标对于评估我们模型的性能以及就模型选择和优化做出明智决策至关重要。
- en: Metrics for multi-class classification problems
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多分类问题的指标
- en: In the multi-class classification field, evaluating models’ performance is as
    crucial as developing them. Effective evaluation hinges upon utilizing the right
    metrics that can accurately measure the performance of the multi-class classification
    models and provide insights for improvement. This section demystifies the various
    metrics essential for assessing the performance of multi-class classification
    models, providing a solid foundation for selecting and employing the right metric
    for your specific use case.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在多类分类领域，评估模型性能与开发模型一样重要。有效的评估依赖于利用正确的指标，这些指标可以准确衡量多类分类模型的性能并提供改进的见解。本节揭示了评估多类分类模型性能所必需的各种指标，为选择和采用适合您特定用例的正确指标提供了坚实的基础。
- en: Confusion matrix
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: One of the fundamental metrics for evaluating multi-class classification models
    is the **confusion matrix.** It provides a visualization of the performance of
    an algorithm, typically a **supervised learning** (**SL**) one. Each row of the
    confusion matrix represents the instances of an actual class, while each column
    represents the instances of a predicted class. It’s an essential tool for understanding
    the model’s performance beyond overall accuracy, offering insight into classification
    errors.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 评估多类分类模型的基本指标之一是**混淆矩阵**。它提供了一个算法性能的可视化，通常是**监督学习**（**SL**）算法。混淆矩阵的每一行代表实际类别的实例，每一列代表预测类别的实例。它是理解模型性能（超越整体准确率）的重要工具，可以深入了解分类错误。
- en: Precision
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精确率
- en: '**Precision** (or **positive predictive value**; **PPV** in short) is a measure
    that examines the number of true positive predictions among the total positive
    predictions made by the model. High precision indicates that the false positive
    rate is low. For multi-class classification problems, precision is calculated
    for each class separately and can be averaged to understand the overall performance.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确率**（或**阳性预测值**；简称**PPV**）是一个衡量指标，它检查模型做出的所有正预测中真正正预测的数量。高精确率表明假正率低。对于多类分类问题，每个类别的精确率分别计算，可以平均以了解整体性能。'
- en: Recall
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 召回率
- en: '**Recall** (or **sensitivity** or **true positive rate**; **TPR** in short)
    gauges the number of true positive predictions among the actual positives. It
    is a crucial metric for problems where identifying all actual positives is essential.
    As with precision, recall is calculated for each class and can be averaged for
    overall performance assessment.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率**（或**灵敏度**或**真正正率**；简称**TPR**）衡量实际正例中真正正预测的数量。对于识别所有实际正例至关重要的问题，这是一个关键指标。与精确率一样，召回率对每个类别进行计算，可以平均以进行整体性能评估。'
- en: F1 score
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: F1分数
- en: '**F1 score** is the harmonic mean of precision and recall, balancing the two
    metrics. It is particularly useful when dealing with imbalanced datasets, offering
    a more holistic view of the model’s performance beyond accuracy.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**F1分数**是精确率和召回率的调和平均数，平衡了这两个指标。在处理不平衡数据集时尤其有用，它提供了一个超越准确率的模型性能的更全面视角。'
- en: Macro- and micro-averaged metrics
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 宏观和微观平均指标
- en: 'In multi-class classification problems, averaging metrics such as precision,
    recall, and F1 score, commonly known as macro- and micro-averaging, can be done
    in multiple ways:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在多类分类问题中，对精确率、召回率和F1分数等指标进行平均，通常称为宏观和微观平均，可以以多种方式完成：
- en: '**Macro-averaging** computes the metric independently for each class and then
    takes the average, treating all classes equally'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**宏观平均**为每个类别独立计算指标，然后取平均值，对待所有类别同等对待'
- en: '**Micro-averaging** aggregates the contributions of all classes to compute
    the average metric'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微观平均**将所有类别的贡献汇总起来计算平均指标'
- en: Area Under Curve (AUC-ROC)
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 曲线下面积（AUC-ROC）
- en: Another important metric is the **Area Under the Receiver Operating Characteristic
    Curve** (**AUC-ROC**). While it is primarily used for binary classification problems,
    it can be extended to multi-class classification by considering each class against
    the rest.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的指标是**受试者工作特征曲线下面积**（**AUC-ROC**）。虽然它主要用于二元分类问题，但可以通过考虑每个类别与其他类别的关系来扩展到多类分类。
- en: Log loss and its application in measuring calibration of multi-class models
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对数损失及其在衡量多类模型校准中的应用
- en: Log loss, also known as **logistic loss** or **cross-entropy loss**, is a commonly
    used loss function for classification problems, including multi-class classification.
    It quantifies the performance of a classification model by measuring the uncertainty
    in the predictions. Log loss assigns a penalty for incorrect classifications;
    the penalty is higher for confidently wrong predictions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对数损失，也称为 **逻辑损失** 或 **交叉熵损失**，是分类问题（包括多类分类）中常用的损失函数。它通过衡量预测的不确定性来量化分类模型的性能。对数损失对错误分类施加惩罚；对自信错误的预测的惩罚更高。
- en: Mathematical representation
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数学表示
- en: 'Mathematically, log loss for multi-class classification can be represented
    as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，多类分类的对数损失可以表示如下：
- en: −  1 _ N  ∑ i=1 N ∑ j=1 M y ij log(p ij)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: − 1/N ∑(i=1 to N) ∑(j=1 to M) y_ij log(p_ij)
- en: 'Here, the following apply:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，以下适用：
- en: '*N* is the number of observations'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*N* 是观察的数量'
- en: '*M* is the number of classes.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*M* 是类别的数量。'
- en: y ij is a binary indicator for whether class *j* is the correct classification
    for observation i.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: y_ij 是一个二进制指示符，表示类 *j* 是否是观察 i 的正确分类。
- en: p ij is the predicted probability that observation *i* is of class *j*.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: p_ij 是观察 *i* 属于类 *j* 的预测概率。
- en: Using log loss to measure calibration
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用对数损失来衡量校准
- en: A calibrated model is one whose predicted probabilities reliably reflect the
    true likelihood of the predicted outcomes. Calibration in multi-class classification
    means that if a model predicts a class with a probability *p*, then that class
    should occur about *p* percent of the time among all instances where that class
    is predicted with probability *p*.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一个校准良好的模型是指其预测概率可靠地反映了预测结果的真正可能性。在多类分类中，校准意味着如果模型预测一个类别的概率为 *p*，那么该类别应该在大约 *p*
    百分比的所有实例中发生，这些实例被预测为具有概率 *p*。
- en: Log loss and calibration
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对数损失和校准
- en: Log loss is an appropriate metric to assess the calibration of a multi-class
    classification model because it directly compares the predicted probabilities
    (the confidence of the predictions) with the actual classes. A well-calibrated
    model will have a lower log loss as the predicted probabilities for the actual
    classes will be higher.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对数损失是评估多类分类模型校准的适当指标，因为它直接比较了预测概率（预测的置信度）与实际类别。一个校准良好的模型将具有较低的对数损失，因为实际类别的预测概率将更高。
- en: How to evaluate calibration using Log loss
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 如何使用对数损失评估校准
- en: '**Predict the probabilities**: Use your multi-class classification model to
    predict the probabilities for each class for each observation in a validation
    dataset'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测概率**：使用您的多类分类模型预测验证数据集中每个观察的每个类别的概率'
- en: '**Compute log loss**: Calculate the log loss using the formula previously shown'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算对数损失**：使用之前显示的公式计算对数损失'
- en: '**Interpret the result**: A lower log loss value indicates better calibration
    as it shows that the predicted probabilities are closer to the actual classes'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解释结果**：较低的对数损失值表示校准更好，因为它表明预测概率更接近实际类别'
- en: Evaluating the log loss of your multi-class classification model gives you insights
    into the calibration of the model. A model with a lower log loss is more calibrated,
    providing more reliable prediction probability estimates. Understanding and using
    log loss as a metric to measure the calibration is vital to ensure that your multi-class
    classification model performs optimally in real-world applications.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 评估您的多类分类模型的对数损失可以为您提供有关模型校准的见解。具有较低对数损失的模型校准更好，提供更可靠的预测概率估计。理解和使用对数损失作为衡量校准的指标对于确保您的多类分类模型在现实世界应用中表现最佳至关重要。
- en: Brier score and its application in measuring the calibration of multi-class
    models
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Brier 分数及其在衡量多类模型校准中的应用
- en: The Brier score, or quadratic loss, is another popular metric used to evaluate
    the performance of classification models, including multi-class classification
    problems. It quantifies the difference between the predicted probabilities and
    the actual classes, assigning a lower score to better-calibrated models.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Brier 分数，或二次损失，是另一个用于评估分类模型性能的流行指标，包括多类分类问题。它量化了预测概率与实际类别之间的差异，对校准良好的模型赋予较低的分值。
- en: Mathematical representation
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数学表示
- en: 'For multi-class classification, the Brier score is calculated as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多类分类，Brier 分数的计算如下：
- en: 1 _ N  ∑ i=1 N ∑ j=1 M (p ij − o ij) 2
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 1/N ∑(i=1 to N) ∑(j=1 to M) (p_ij − o_ij)^2
- en: 'Here, the following apply:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，以下适用：
- en: '*N* is the number of observations'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*N*是观察值的数量。'
- en: '*M* is the number of classes.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*M*是类别的数量。'
- en: y ij is a binary indicator for whether class j is the correct classification
    for observation i.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: y_ij是一个二元指示器，表示类别j是否是观察i的正确分类。
- en: p ij is the predicted probability that observation i is of class j.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: p_ij是预测观察i属于类别j的概率。
- en: Using the Brier score to measure calibration
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Brier分数来衡量校准
- en: The Brier score is an effective metric for assessing the calibration of multi-class
    models as it penalizes the model more when there is a larger difference between
    the predicted probabilities and the actual outcomes. A well-calibrated model will
    have a lower Brier score as its predicted probabilities will be closer to the
    actual outcomes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Brier分数是一种有效的指标，用于评估多类模型的校准情况，因为它在预测概率与实际结果之间存在较大差异时对模型进行更多惩罚。一个校准良好的模型将具有较低的Brier分数，因为其预测概率将更接近实际结果。
- en: How to evaluate calibration using Brier Score
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何使用Brier分数评估校准
- en: The Brier score provides a way to quantitatively assess how well calibrated
    a multi-class classifier’s predicted probabilities are. Evaluating calibration
    is key for ensuring reliability in real-world deployment.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Brier分数提供了一种定量评估多类分类器预测概率校准程度的方法。评估校准对于确保在实际部署中的可靠性至关重要。
- en: 'To utilize the Brier score, there are three main steps:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Brier分数，主要有三个步骤：
- en: '**Predict the probabilities**: Use your multi-class classification model to
    estimate the probabilities for each class for every observation in a validation
    dataset.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测概率**：使用你的多类分类模型来估计验证数据集中每个观察值的每个类别的概率。'
- en: '**Compute the Brier score**: Calculate the Brier score using the provided formula.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算Brier分数**：使用提供的公式计算Brier分数。'
- en: '**Interpret the result**: A lower Brier score indicates better calibration.
    It signifies that the model’s predicted probabilities are more aligned with the
    actual outcomes, thus making the model more reliable.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**解释结果**：较低的Brier分数表示校准更好。它表明模型的预测概率与实际结果更一致，从而使模型更可靠。'
- en: In essence, employing the Brier score to evaluate the calibration of your multi-class
    model helps ensure the reliability of your model’s probability estimates. A lower
    Brier score, reflecting smaller differences between predicted and actual probabilities,
    indicates a well-calibrated model, enhancing the model’s trustworthiness in real-world
    applications. Understanding and utilizing the Brier score as a calibration metric
    is essential for optimizing the performance of your multi-class classification
    model in practical scenarios.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，使用Brier分数来评估你的多类模型的校准有助于确保模型概率估计的可靠性。较低的Brier分数，反映了预测概率与实际概率之间差异较小，表明模型校准良好，增强了模型在实际应用中的可信度。理解并利用Brier分数作为校准指标对于优化实际场景中多类分类模型的性能至关重要。
- en: Understanding and employing the appropriate metrics is pivotal for evaluating
    and improving multi-class classification models. A thorough grasp of these metrics
    allows for a more nuanced analysis, paving the way for developing robust and efficient
    multi-class classification models and ensuring their successful deployment in
    real-world scenarios.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 理解和运用适当的指标对于评估和改进多类分类模型至关重要。对这些指标有深入的了解可以让我们进行更细致的分析，为开发稳健且高效的多类分类模型以及确保其在实际场景中的成功部署铺平道路。
- en: How conformal prediction can be applied to multi-class classification problems
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一致性预测如何应用于多类分类问题
- en: conformal prediction is a powerful framework that can be applied to multi-class
    classification problems. It provides a way to make predictions with a measure
    of certainty, which is particularly useful when dealing with multiple classes.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性预测是一个强大的框架，可以应用于多类分类问题。它提供了一种带有确定性度量的预测方法，这在处理多个类别时尤其有用。
- en: In the previous chapters, we have already looked at how conformal prediction
    assigns a *p*-value to each class for a given instance in the context of multi-class
    classification.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们已经探讨了在多类分类的背景下，一致性预测是如何为给定实例的每个类别分配一个*p*值的。
- en: The p-value represents the confidence level of the prediction for that class.
    The higher the p-value, the more confident the model is that the instance belongs
    to that class.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: p值代表了对该类别的预测置信水平。p值越高，模型对该实例属于该类别的信心就越强。
- en: 'The procedure for applying conformal prediction to multi-class classification
    is as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 将共形预测应用于多类分类的步骤如下：
- en: '**Calibration**: A portion of the training data, known as the calibration set,
    is set aside. The model is trained on the remaining data.'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**校准**：将一部分训练数据，称为校准集，留出。模型在剩余数据上训练。'
- en: '**Prediction**: For each class, the model predicts class scores. The conformity
    score, which measures how well the prediction conforms to the actual outcomes
    in the calibration set, is calculated.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测**：对于每个类别，模型预测类别得分。一致性得分，它衡量预测与校准集中实际结果的一致性，被计算出来。'
- en: '**P-value calculation**: For a new instance, the model calculates a nonconformity
    score for each class. The p-value for each class is then calculated as the proportion
    of instances in the calibration set with a higher nonconformity score.'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**p 值计算**：对于一个新的实例，模型为每个类别计算一个非一致性得分。然后，每个类别的 p 值被计算为校准集中具有更高非一致性得分的实例比例。'
- en: '**Output**: The model outputs the predicted class labels along with their p-values.
    The classes are ranked by their p-values, providing a measure of confidence for
    each prediction.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**输出**：模型输出预测的类别标签及其 p 值。类别按其 p 值排序，为每个预测提供了置信度度量。'
- en: 'Applying conformal prediction to multi-class classification problems offers
    several benefits:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 将共形预测应用于多类分类问题提供了几个好处：
- en: '**Confidence measures**: conformal prediction provides a measure of confidence
    (the p-value) for each prediction, which can be very useful in decision-making
    processes'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**置信度度量**：共形预测为每个预测提供了一个置信度度量（p 值），这在决策过程中非常有用'
- en: '**Validity**: conformal prediction offers a theoretical guarantee of validity,
    meaning that the error rate of the predictions will be close to the significance
    level set by the user'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有效性**：共形预测提供了有效性的理论保证，这意味着预测的错误率将接近用户设定的显著性水平'
- en: '**Efficiency**: conformal prediction is computationally efficient and can be
    applied to large datasets'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：共形预测在计算上效率高，可以应用于大型数据集'
- en: '**Versatility**: conformal prediction can be used with any ML algorithm, making
    it a versatile tool for multi-class classification problems'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用性**：共形预测可以与任何机器学习算法一起使用，使其成为多类分类问题的多功能工具'
- en: The next section will examine how Venn-ABERS predictors can be applied to multi-class
    classification problems.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分将探讨如何将 Venn-ABERS 预测器应用于多类分类问题。
- en: Multi-class probabilistic classification using inductive and cross-Venn-ABERS
    predictors
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用归纳和交叉 Venn-ABERS 预测器进行多类概率分类
- en: Venn-ABERS is a conformal prediction method developed by Vladimir Vovk, Ivan
    Petej, and Valentina Fedorova (*Large-scale probabilistic predictors with and
    without guarantees of validity*, [https://papers.nips.cc/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html](https://papers.nips.cc/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html))
    to address the limitations of classical calibrators such as Platt scaling and
    isotonic regression. It guarantees mathematical validity, regardless of the data
    distribution, dataset size, or underlying classification model.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Venn-ABERS 是由 Vladimir Vovk、Ivan Petej 和 Valentina Fedorova 开发的一种共形预测方法（*带有和没有有效性保证的大规模概率预测器*，[https://papers.nips.cc/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html](https://papers.nips.cc/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html)），以解决像
    Platt 缩放和等调回归这样的经典校准器的局限性。它无论数据分布、数据集大小或底层分类模型如何，都保证了数学有效性。
- en: Venn-ABERS predictors work by fitting isotonic regression twice, assuming that
    each test object can have both the label `0` and the label `1`. This results in
    two probabilities, *p0* and *p1*, for each test object, representing probabilities
    of the object belonging to class 1\. These probabilities create a prediction interval
    for the probability of class 1, with mathematical guarantees that the actual probability
    falls within this interval.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Venn-ABERS 预测器通过拟合等调回归两次来工作，假设每个测试对象都可以具有标签 `0` 和标签 `1`。这为每个测试对象产生两个概率，*p0*
    和 *p1*，代表该对象属于类别 1 的概率。这些概率为类别 1 的概率创建了一个预测区间，并提供了数学保证，即实际概率落在这个区间内。
- en: The Venn-ABERS prediction is a multi-predictor, and the width of the interval
    (p0, p1) contains valuable information about the classification confidence. In
    critical situations, the Venn-ABERS predictor outputs accurate and well-calibrated
    probabilities and issues an “alert” by widening the (p0, p1) interval. This alert
    indicates that the decision-making process should consider the increased uncertainty.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Venn-ABERS预测是一个多预测因子，区间（p0, p1）的宽度包含了关于分类置信度的宝贵信息。在关键情况下，Venn-ABERS预测器输出准确且校准良好的概率，并通过扩大（p0,
    p1）区间发出“警报”。这个警报表明决策过程应考虑增加的不确定性。
- en: The probabilities can be combined into a single value using *p = p1 / (1 - p0
    + p1)* for practical decision-making purposes. This combined probability of class
    1, *p*, can be used for decision-making tasks.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这些概率可以通过*p = p1 / (1 - p0 + p1)*组合成一个单一值，用于实际决策目的。这个类别1的联合概率*p*可以用于决策任务。
- en: 'The research paper by Valery Manokhin, *Multi-class probabilistic classification
    using inductive and cross Venn–Abers predictors*, introduces a method for adapting
    Venn-ABERS predictors for multi-class classification. You can access the paper
    here: http://proceedings.mlr.press/v60/manokhin17a/manokhin17a.pdf.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Valery Manokhin的研究论文《使用归纳和交叉Venn-Abers预测器的多类概率分类》，介绍了一种将Venn-ABERS预测器应用于多类分类的方法。您可以通过以下链接访问该论文：http://proceedings.mlr.press/v60/manokhin17a/manokhin17a.pdf。
- en: Experimental results demonstrate that the proposed multi-class predictors outperform
    uncalibrated and existing classical calibration methods in terms of accuracy,
    indicating potential substantial advancements in multi-class probabilistic classification.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 实验结果表明，所提出的多类预测器在准确性方面优于未校准和现有的经典校准方法，这表明在多类概率分类方面可能取得了实质性的进步。
- en: 'For practitioners and researchers eager to employ this technique, a Python
    implementation of the fast Venn-ABERS predictor for binary classification is accessible
    on GitHub (*Multi-class probabilistic classification using inductive and cross
    Venn–Abers predictors*: [https://github.com/valeman/Multi-class-probabilistic-classification](https://github.com/valeman/Multi-class-probabilistic-classification)).
    This educational resource offers a hands-on opportunity to explore the details
    of implementation and practical advantages of utilizing Venn-ABERS predictors
    in real-world ML scenarios.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于渴望采用这种技术的实践者和研究人员，GitHub上有一个快速Venn-ABERS预测器的Python实现，用于二元分类（[https://github.com/valeman/Multi-class-probabilistic-classification](https://github.com/valeman/Multi-class-probabilistic-classification)）。这个教育资源提供了亲身体验实现细节和利用Venn-ABERS预测器在现实世界机器学习场景中的实际优势的机会。
- en: The proposed approach to multi-class probability estimation using **inductive**
    and **cross-Venn-ABERS predictors** (**IVAPs** and **CVAPs**) is based on transforming
    multi-class classifiers into binary classifiers. In this approach, the binary
    classifiers are trained to distinguish between each class and all other classes
    combined.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的使用**归纳**和**交叉-Venn-ABERS预测器**（**IVAPs**和**CVAPs**）进行多类概率估计的方法，基于将多类分类器转换为二元分类器。在此方法中，二元分类器被训练以区分每个类别与其他所有类别的组合。
- en: 'For example, in a three-class problem with classes A, B, and C, three binary
    classifiers are trained: one to distinguish between A and (B or C), one to distinguish
    between B and (A or C), and one to distinguish between C and (A or B). The IVAP
    is then used to estimate the probability of each class for a given test instance.
    The IVAP computes the probability of a class as the fraction of binary classifiers
    that classify the instance as belonging to that class.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一个有三个类别A、B和C的三类问题中，训练了三个二元分类器：一个用于区分A和（B或C），一个用于区分B和（A或C），一个用于区分C和（A或B）。然后使用IVAP来估计给定测试实例每个类别的概率。IVAP计算一个类别的概率为将实例分类为属于该类别的二元分类器的比例。
- en: The formula for converting pairwise classification scores and pairwise class
    probabilities uses a method introduced in the paper *Pairwise Neural Network Classifiers
    with Probabilistic* *Outputs* ([https://proceedings.neurips.cc/paper_files/paper/1994/file/210f760a89db30aa72ca258a3483cc7f-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/1994/file/210f760a89db30aa72ca258a3483cc7f-Paper.pdf)).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 转换成对分类得分和成对类概率的公式使用了论文《具有概率输出的成对神经网络分类器》中介绍的方法（[https://proceedings.neurips.cc/paper_files/paper/1994/file/210f760a89db30aa72ca258a3483cc7f-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/1994/file/210f760a89db30aa72ca258a3483cc7f-Paper.pdf)）。
- en: Specifically, if *rij* is the class score *i* over class *j* from the respective
    binary model, the estimated probability for class *i* is calculated as follows.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，如果 *rij* 是从相应的二元模型中得到的类 *j* 上类 *i* 的分数，则类 *i* 的估计概率按以下方式计算。
- en: 'The key idea is to first compute pairwise probabilities between each pair of
    classes using the dedicated binary classifiers. Then, these pairwise probabilities
    can be combined to estimate a normalized probability distribution over all classes:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 关键思想是首先使用专门的二元分类器计算每对类之间的成对概率。然后，可以将这些成对概率组合起来，估计所有类别的归一化概率分布：
- en: p i PKPD =  1 ___________ ∑ j:j≠i n   1 _ r ij − (k − 2)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: p i PKPD =  1 ___________ ∑ j:j≠i n   1 _ r ij − (k − 2)
- en: This provides a principled approach to converting pairwise binary classification
    outcomes into class probability estimates suitable for multi-class evaluation
    and calibration.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了一种将成对二元分类结果转换为适合多类评估和校准的类概率估计的原则性方法。
- en: After calculating the probabilities (this technique is dubbed the **PKPD** method),
    normalizing these values is crucial to ensure their total sum is 1\. These pairwise
    probabilities can be obtained by applying IVAPs and CVAPs to the pairwise classification
    scores/probabilities, which are used to calibrate classification scores produced
    by underlying classification models.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算概率（这种技术被称为 **PKPD** 方法）之后，对这些值进行归一化是至关重要的，以确保它们的总和为1。这些成对概率可以通过对成对分类分数/概率应用IVAPs和CVAPs来获得，这些分数/概率用于校准底层分类模型产生的分类分数。
- en: In simpler terms, the PKPD method helps convert probabilities from binary comparisons
    (pairwise probabilities) into multi-class probabilities. The calculated multi-class
    probabilities are then used to classify test objects into one of the *k* possible
    classes. This classification enables the computation of metrics, which can be
    compared across various calibration algorithms to evaluate their performance.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，PKPD方法有助于将二元比较（成对概率）中的概率转换为多类概率。然后，计算出的多类概率被用来将测试对象分类为 *k* 个可能类别之一。这种分类使得可以计算指标，这些指标可以与各种校准算法的性能进行比较。
- en: Now, let’s explore a real-world example to understand how to apply conformal
    prediction to multi-class classification problems. The following is a code walk-through
    that demonstrates this application.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一个现实世界的例子来了解如何将一致性预测应用于多类分类问题。以下是一个代码示例，展示了这一应用。
- en: Let’s analyze the code from the `Chapter_12.ipynb` notebook (the code can be
    found in the book’s GitHub repo at [https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_12.ipynb](https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_12.ipynb)).
    The notebook demonstrates the application of conformal prediction to a multi-class
    classification problem.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析来自 `Chapter_12.ipynb` 笔记本（代码可以在本书的GitHub仓库[https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_12.ipynb](https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_12.ipynb)）的代码。该笔记本演示了一致性预测在多类分类问题中的应用。
- en: 'The general steps of multi-class classification are as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类的一般步骤如下：
- en: '**Data preparation**:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据准备**：'
- en: Load the dataset.
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集。
- en: Divide the dataset into features (*X*) and target (*y*).
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集划分为特征 (*X*) 和目标 (*y*)。
- en: Split the data into training and test sets.
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为训练集和测试集。
- en: '**Model training**:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型训练**：'
- en: Train a classification model on the training data.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上训练一个分类模型。
- en: Use the trained model to make predictions on the test data.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练好的模型在测试数据上进行预测。
- en: '**Applying** **conformal prediction**:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**应用** **一致性预测**：'
- en: Apply conformal prediction to the trained model.
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将一致性预测应用于训练好的模型。
- en: Obtain confidence and credibility measures for the predictions.
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取预测的置信度和可信度度量。
- en: '**Evaluation**:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估**：'
- en: Evaluate the model using appropriate metrics.
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用适当的指标评估模型。
- en: Compare the performance of the calibrated model with the original model.
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较校准模型与原始模型的性能。
- en: '`evaluate_model_performance` function is used to evaluate the performance of
    different models and calibration methods.'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `evaluate_model_performance` 函数评估不同模型和校准方法的性能。
- en: It trains the model, makes predictions, and evaluates the performance using
    various metrics such as accuracy, log loss, and Brier loss.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它训练模型，进行预测，并使用各种指标（如准确率、对数损失和Brier损失）来评估性能。
- en: '**Calibration**:'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**校准**：'
- en: Different calibration methods, such as Platt, isotonic, and others, are applied
    to the model.
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不同的校准方法，如Platt、等调和其他方法，被应用于模型中。
- en: The predictions of the calibrated models are evaluated to analyze the performance
    improvement.*   `evaluate_model_performance` function to each model.*   The results
    for each model and calibration method are stored and can be analyzed to determine
    the best-performing model and calibration method.
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 校准模型的预测被评估以分析性能改进。*   `evaluate_model_performance` 函数应用于每个模型。*   每个模型和校准方法的成果被存储，可以进行分析以确定表现最佳的模型和校准方法。
- en: Let’s summarize the chapter next.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们接下来总结本章内容。
- en: Summary
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this book’s final chapter, we explored the intriguing domain of multi-class
    conformal prediction. We began by understanding the concept of multi-class classification,
    a prevalent scenario in ML where an instance can belong to one of many classes.
    This understanding is crucial for effectively applying conformal prediction techniques.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的最后一章，我们探索了多类一致性预测这个迷人的领域。我们首先理解了多类分类的概念，这是机器学习中一个普遍的场景，其中实例可以属于许多类别之一。这种理解对于有效地应用一致性预测技术至关重要。
- en: We then delved into the metrics used for evaluating multi-class classification
    problems. These metrics quantitatively measure our model’s performance and are
    vital for effective model evaluation and selection.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着深入探讨了用于评估多类分类问题的指标。这些指标定量地衡量我们模型的表现，对于有效的模型评估和选择至关重要。
- en: Finally, we learned how to apply conformal prediction to multi-class classification
    problems. This section provided practical insights and techniques to apply to
    your industrial applications directly.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们学习了如何将一致性预测应用于多类分类问题。本节提供了可以直接应用于您工业应用的实用见解和技术。
- en: By the end of this chapter, you should have gained valuable skills and knowledge
    in multi-class classification and how conformal prediction can be effectively
    applied to these problems. This knowledge will prove invaluable in your journey
    as a data scientist, ML engineer, or researcher.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该已经获得了在多类分类以及如何有效地将这些问题应用于一致性预测方面的宝贵技能和知识。这些知识将在你作为数据科学家、机器学习工程师或研究人员的旅程中证明是无价的。
- en: We covered different main topics, including multi-class classification problems,
    where we explored multi-class classification and its importance in ML. We also
    discussed the difference between multi-class and multi-label classification problems.
    We then investigated the metrics used to evaluate multi-class classification problems.
    Understanding these metrics is crucial for assessing the performance of our models
    and making informed decisions about model selection and optimization. Finally,
    we learned how to apply conformal prediction to multi-class classification problems.
    This section provided practical insights and techniques to apply directly to your
    industrial applications.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们涵盖了不同的主要主题，包括多类分类问题，我们探讨了多类分类及其在机器学习中的重要性。我们还讨论了多类分类和多标签分类问题的区别。然后我们研究了用于评估多类分类问题的指标。理解这些指标对于评估我们模型的表现和做出关于模型选择和优化的明智决策至关重要。最后，我们学习了如何将一致性预测应用于多类分类问题。本节提供了可以直接应用于您工业应用的实用见解和技术。
- en: This chapter marks the end of our journey into conformal prediction. We hope
    that the knowledge and skills you’ve gained will serve you well in your future
    endeavors in ML. Happy learning!
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 本章标志着我们进入一致性预测旅程的结束。我们希望你所获得的知识和技能将在你未来在机器学习领域的努力中大有裨益。祝您学习愉快！
