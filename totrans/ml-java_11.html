<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">What Is Next?</h1>
                </header>
            
            <article>
                
<p>This chapter brings us to the end of our journey of reviewing machine learning in Java libraries and discussing how to leverage them to solve real-life problems. However, this should not be the end of your journey by all means. This chapter will give you some practical advice on how to start deploying your models in the real world, what are the catches, and where to go to deepen your knowledge. It also gives you further pointers about where to find additional resources, materials, venues, and technologies to dive deeper into machine learning.</p>
<p>This chapter will cover the following topics:</p>
<ul>
<li>Important aspects of machine learning in real life</li>
<li>Standards and markup languages</li>
<li>Machine learning in the cloud</li>
<li>Web resources and competitions</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Machine learning in real life</h1>
                </header>
            
            <article>
                
<p>Papers, conference presentations, and talks often don't discuss how the models were actually deployed and maintained in a production environment. In this section, we'll look into some aspects that should be taken into consideration.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Noisy data</h1>
                </header>
            
            <article>
                
<p>In practice, data typically contains errors and imperfections due to various reasons such as measurement errors, human mistakes, and errors of expert judgment in classifying training examples. We refer to all of these as <strong>noise</strong>. Noise can also come from the treatment of missing values when an example with unknown attribute value is replaced by a set of weighted examples corresponding to the probability distribution of the missing value. The typical consequences of noise in learning data are low prediction accuracy of a learned model in new data and complex models that are hard to interpret and understand for the user.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Class unbalance</h1>
                </header>
            
            <article>
                
<p>Class unbalance is a problem we come across in <span class="ChapterrefPACKT"><a href="bed72516-7a74-4875-a082-43364a4d6c59.xhtml">Chapter 7</a></span>, <em>Fraud and Anomaly Detection</em>, where the goal was to detect fraudulent insurance claims. The challenge is that a very large part of the dataset, usually more than 90%, describes normal activities, and only a small fraction of the dataset contains fraudulent examples. In such a case, if the model always predicts normal, then it is correct 90% of the time. This problem is extremely common in practice and can be observed in various applications, including fraud detection, anomaly detection, medical diagnosis, oil spillage detection, and facial recognition.</p>
<p>Now, knowing what the class unbalance problem is and why it<span> is</span> a problem, let's take a look at how to deal with this problem. The first approach is to focus on measures other than classification accuracy, such as recall, precision, and f-measure. Such measures focus on how accurate a model is at predicting minority class (<strong>recall</strong>) and what is the share of false alarms (<strong>precision</strong>). The other approach is based on resampling, where the main idea is to reduce the number of overrepresented examples in such a way that the new set contains a balanced ratio of both classes.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Feature selection</h1>
                </header>
            
            <article>
                
<p><strong>Feature selection</strong> is arguably the most challenging part of modeling that requires domain knowledge and good insights into the problem at hand. Nevertheless, properties of well-behaved features are as follows:</p>
<ul>
<li><strong>Reusability</strong>: Features should be available for reuse in different models, applications, and teams.</li>
<li><strong>Transformability</strong>: You should be able to transform a feature with an operation, for example, <kbd>log()</kbd>, <kbd>max()</kbd>, or combine multiple features together with a custom calculation.</li>
<li><strong>Reliability</strong>: Features should be easy to monitor and appropriate unit tests should exist to minimize bugs or issues.</li>
<li><strong>Interpretability</strong>: To perform any of the previous actions, you need to be able to understand the meaning of features and interpret their values.</li>
</ul>
<p>The better you are able to capture the features, the more accurate your results will be.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Model chaining</h1>
                </header>
            
            <article>
                
<p>Some models might produce output, which is used as the feature in another model. Moreover, we can use multiple models—ensembles—turning any model into a feature. This is a great way to get better results, but this can lead to problems too. Care must be taken that the output of your model is ready to accept dependencies. Also, try to avoid feedback loops, as they can create dependencies and bottlenecks in the pipeline.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The importance of evaluation</h1>
                </header>
            
            <article>
                
<p>Another important aspect is model evaluation. Unless you apply your models to new data and measure a business objective, you're not doing predictive analytics. Evaluation techniques, such as cross-validation and separated train/test sets, simply split your test data, which can give only you an estimate of how your model will perform. Life often doesn't hand you a train dataset with all of the cases defined, so there is a lot of creativity involved in defining these two sets in a real-world dataset.</p>
<p>At the end of the day, we want to improve a business objective, such as improve ad conversion rate, and get more clicks on recommended items. To measure the improvement, execute A/B tests, measuring differences in metrics across statistically identical populations that each experience a different algorithm. Decisions on the product are always data-driven.</p>
<div class="packt_infobox">A/B testing is a method for a randomized experiment with two variants: A, which corresponds to the original version, controlling the experiment; and B, which corresponds to a variation. The method can be used to determine whether the variation outperforms the original version. It can be used to test everything from website changes to sales emails to search ads. Udacity offers a free course, covering design and analysis of A/B tests at <span class="URLPACKT"><a href="https://www.udacity.com/course/ab-testing--ud257">https://www.udacity.com/course/ab-testing--ud257</a></span>.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting models into production</h1>
                </header>
            
            <article>
                
<p>The path from building an accurate model in a lab to deploying it in a product involves collaboration of data science and engineering, as shown in the following three steps:</p>
<ol>
<li><strong>Data research and hypothesis building</strong> involves modeling the problem and executing initial evaluation.</li>
<li><strong>Solution building and implementation</strong> is where your model finds its way into the product flow by rewriting it into more efficient, stable, and scalable code.</li>
<li><strong>Online evaluation</strong> is the last stage where the model is evaluated with live data using A/B testing on business objectives.</li>
</ol>
<p>This is better illustrated in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-576 image-border" src="Images/7095ba24-aa68-47ee-9fce-88b0768f9971.png" style="width:22.50em;height:17.42em;" width="433" height="335"/></p>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Model maintenance</h1>
                </header>
            
            <article>
                
<p>Another aspect that we need to address is how the model will be maintained. Is this a model that will not change over time? Is it modeling a dynamic phenomenon requiring the model to adjust its prediction over time?</p>
<p>The model is usually built in an offline batch training and then used on live data to serve predictions as shown in the following diagram. If we are able to receive feedback on model predictions, for instance, whether the stock went up as the model predicted, and whether the candidate responded to campaign, the feedback should be used to improve the initial model:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-577 image-border" src="Images/267950ab-2c7c-4c66-8bec-61e8169c8cdc.png" style="width:36.75em;height:20.67em;" width="484" height="272"/></div>
<p>The feedback could be really useful to improve the initial model, but make sure to pay attention to the data you are sampling. For instance, if you have a model that predicts who will respond to a campaign, you will initially use a set of randomly contacted clients with specific responded/not responded distribution and feature properties. The model will focus only on a subset of clients that will most likely respond and your feedback will return you a subset of clients that responded. By including this data, the model is more accurate in a specific subgroup, but might completely miss some other group. We call this problem exploration versus exploitation. Some approaches to address this problem can be found in Osugi et al. (2005) and Bondu et al. (2010).</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Standards and markup languages</h1>
                </header>
            
            <article>
                
<p>As predictive models become more pervasive, the need for sharing the models and completing the modeling process leads to formalization of development process and interchangeable formats. In this section, we'll review two de facto standards, one covering data science processes and the other specifying an interchangeable format for sharing models between applications.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">CRISP-DM</h1>
                </header>
            
            <article>
                
<p><strong>Cross Industry Standard Process for Data Mining</strong> (<strong>CRISP-DM</strong>) describes a data-mining process commonly used by data scientists in industry. CRISP-DM breaks the data-mining science process into six major phases:</p>
<ul>
<li><strong>Business understanding</strong></li>
<li><strong>Data understanding</strong></li>
<li><strong>Data preparation</strong></li>
<li><strong>Modeling</strong></li>
<li><strong>Evaluation</strong></li>
<li><strong>Deployment</strong></li>
</ul>
<p>In the following diagram, the arrows indicate the process flow, which can move back and forth through the phases. Also, the process doesn't stop with model deployment. The outer arrow indicates the cyclic nature of data science. Lessons learned during the process can trigger new questions and repeat the process while improving previous results:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-583 image-border" src="Images/0ac100ae-cf9b-4d29-83fd-4a0a50322dbd.png" style="width:32.00em;height:32.08em;" width="672" height="674"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">SEMMA methodology</h1>
                </header>
            
            <article>
                
<p>Another methodology is <strong>Sample, Explore, Modify, Model, and Assess</strong> (<strong>SEMMA</strong>). SEMMA describes the main modeling tasks in data science, while leaving aside business aspects such as data understanding and deployment. SEMMA was developed by SAS Institute, which is one of the largest vendors of statistical software, aiming to help the users of their software to carry out core tasks of data mining.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Predictive model markup language</h1>
                </header>
            
            <article>
                
<p><strong>Predictive</strong> <strong>Model Markup Language</strong> (<strong>PMML</strong>) is an XML-based interchange format that allows machine- learning models to be easily shared between applications and systems. Supported models include logistic regression, neural networks, decision trees, naïve Bayes, regression models, and many others. A typical PMML file consists of the following sections:</p>
<ul>
<li>Header containing general information</li>
<li>Data dictionary, describing data types</li>
<li>Data transformations, specifying steps for normalization, discretization, aggregations, or custom functions</li>
<li>Model definition, including parameters</li>
<li>Mining schema listing attributes used by the model</li>
<li>Targets allowing post-processing of the predicted results</li>
<li>Output listing fields to be output and other post-processing steps</li>
</ul>
<p>The generated PMML files can be imported to any PMML-consuming application, such as Zementis <strong>adaptive decision and</strong> <strong>predictive analytics</strong> (<strong>ADAPA</strong>) and <strong>universal PMML Plug-In</strong> (<strong>UPPI</strong>) scoring engines; Weka, which has built-in support for regression, general regression, neural network, TreeModel, RuleSetModel, and <strong>support vector machine</strong> (<strong>SVM</strong>) model; Spark, which can export k-means clustering, linear regression, ridge regression, lasso model, binary logistic model, and SVM; and cascading, which can transform PMML files into an application on Apache Hadoop.</p>
<p>The next generation of PMML is an emerging format called <strong>portable format for analytics</strong> (<strong>PFA</strong>), providing a common interface to deploy the complete workflows across environments.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Machine learning in the cloud</h1>
                </header>
            
            <article>
                
<p>Setting up a complete machine learning stack that is able to scale with the increasing amount of data could be challenging. A recent wave of the <strong>Software as a Service (SaaS)</strong> and <strong>Infrastructure as a Service</strong> (<strong>IaaS</strong>) paradigm has spilled over to the machine learning domain as well. The trend today is to move the actual data preprocessing, modeling, and prediction to cloud environments and focus on modeling tasks only.</p>
<p>In this section, we'll review some of the promising services offering algorithms, predictive models already train in specific domain, and environments empowering collaborative workflows in data science teams.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Machine learning as a service</h1>
                </header>
            
            <article>
                
<p>The first category is algorithms as a service, where you are provided with an API or even graphical user interface to connect preprogrammed components of data science pipeline together:</p>
<ul>
<li><strong>Google Prediction API</strong>: It was one of the first companies that introduced prediction services through its web API. The service is integrated with Google Cloud Storage serving as data storage. The user can build a model and call an API to get predictions.</li>
<li><strong>BigML</strong>: It implements a user-friendly graphical interface, supports many storage providers (for instance, Amazon S3) and offers a wide variety of data processing tools, algorithms, and powerful visualizations.</li>
<li><strong>Microsoft Azure Machine Learning</strong>: This provides a large library of machine learning algorithms and data processing functions, as well as graphical user interface, to connect these components to an application. Additionally, it offers a fully-managed service that you can use to deploy your predictive models as ready-to-consume web services.</li>
<li><strong>Amazon Machine Learning</strong>: It entered the market quite late. It's main strength is seamless integration with other Amazon services, while the number of algorithms and user interface needs further improvements.</li>
<li><strong>IBM Watson Analytics</strong>: It focuses on providing models that are already handcrafted to a particular domain such as speech recognition, machine translations, and anomaly detection. It targets a wide range of industries by solving specific use cases.</li>
<li><strong>Prediction.IO</strong>: It is a self-hosted open source platform, providing the full stack from data storage to modeling to serving the predictions. Prediction.IO can talk to Apache Spark to leverage its learning algorithms. In addition, it is shipped with a wide variety of models targeting specific domains, for instance, recommender system, churn prediction, and others.</li>
</ul>
<p>Predictive API is an emerging new field, so these are just some of the well-known examples; <strong>KDnuggets</strong> compiled a list of 50 machine-learning APIs at <span class="URLPACKT"><a href="http://www.kdnuggets.com/2015/12/machine-learning-data-science-apis.html">http://www.kdnuggets.com/2015/12/machine-learning-data-science-apis.html</a></span>.</p>
<div class="packt_infobox">To learn more about it, you can visit PAPI, the International Conference on Predictive APIs and apps at <span class="URLPACKT"><a href="http://www.papi.io/">http://www.papi.io</a></span> or take a look at this book: <em>Bootstrapping Machine Learning, </em>L Dorard<em>, <span>Createspace Independent Pub, 2014.</span></em></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Web resources and competitions</h1>
                </header>
            
            <article>
                
<p>In this section, we'll review where to find additional resources for learning, discussing, presenting, or sharpening our data science skills.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Datasets</h1>
                </header>
            
            <article>
                
<p>One of the most well-known repositories of machine learning datasets is hosted by the University of California Irvine. The UCI repository contains over 300 datasets covering a wide variety of challenges, including poker, movies, wine quality, activity recognition, stocks, taxi service trajectories, advertisements, and many others. Each dataset is usually equipped with a research paper where the dataset was used, which can give you a hint on how to start and what the prediction baseline<span> is</span>.</p>
<p>The UCI machine-learning repository can be accessed at <span class="URLPACKT"><a href="https://archive.ics.uci.edu/">https://archive.ics.uci.edu</a></span>, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-584 image-border" src="Images/a7659a4d-8810-41b5-84aa-e86f8846d282.png" style="width:83.42em;height:74.58em;" width="1001" height="895"/></p>
<p>Another well-maintained collection by Xiaming Chen is hosted on GitHub: <span class="URLPACKT"><a href="https://github.com/caesar0301/awesome-public-datasets">https://github.com/caesar0301/awesome-public-datasets</a>.</span></p>
<p><span class="URLPACKT"> </span>The awesome public dataset repository maintains links to more than 400 data sources from a variety of domains, ranging from agriculture, biology, economics, psychology, museums, and transportation. Datasets, specifically targeting machine learning, are collected under the image processing, machine learning, and data challenges sections.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Online courses</h1>
                </header>
            
            <article>
                
<p>Learning how to become a data scientist has became much more accessible due to the availability of online courses. The following is a list of free resources to learn different skills online:</p>
<ul>
<li><strong>Udemy—</strong><strong>Learn</strong> <strong>Java Programming From Scratch</strong> at <span class="URLPACKT"><a href="https://www.udemy.com/learn-java-programming-from-scratch">https://www.udemy.com/learn-java-programming-from-scratch</a>.</span></li>
<li><strong>Udemy—</strong><strong>Java Tutorial for Complete Beginners</strong> at <span class="URLPACKT"><a href="https://www.udemy.com/java-tutorial">https://www.udemy.com/java-tutorial</a>.</span></li>
<li><span class="URLPACKT"><strong>LearnJAvaOnline—</strong></span><strong>Interactive Java tutorial</strong> at <span class="URLPACKT"><a href="http://www.learnjavaonline.org/">http://www.learnjavaonline.org</a>.</span></li>
</ul>
<p>Some online courses to learn more about machine learning are as follows:</p>
<ul>
<li><strong>Coursera—Machine Learning (Stanford) by Andrew Ng</strong>: This teaches you the math behind many machine-learning algorithms, explains how they work, and explores why they make sense at <span class="URLPACKT"><a href="https://www.coursera.org/learn/machine-learning">https://www.coursera.org/learn/machine-learning</a></span>.</li>
<li><strong>Statistics 110 (Harvard) by Joe Biltzstein</strong>: This course lets you discover the probability of related terms that you will hear many times in your data science journey. Lectures are available on YouTube at <span class="URLPACKT"><a href="http://projects.iq.harvard.edu/stat110/youtube">http://projects.iq.harvard.edu/stat110/youtube</a></span>.</li>
<li><strong>Data Science CS109 (Harvard) by John A. Paulson</strong>: This is a hands-on course where you'll learn about Python libraries for data science, as well as how to handle machine-learning algorithms at <span class="URLPACKT"><a href="http://cs109.github.io/2015/">http://cs109.github.io/2015/</a></span>.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Competitions</h1>
                </header>
            
            <article>
                
<p>The best way to sharpen your knowledge is to work on real problems and, if you want to build a proven portfolio of your projects, machine-learning competitions are a viable place to start:</p>
<ul>
<li><strong>Kaggle</strong>: This is the number one competition platform, hosting a wide variety of challenges with large prizes, strong data science community, and lots of helpful resources. You can check it out at <span class="URLPACKT"><a href="https://www.kaggle.com/">https://www.kaggle.com/</a></span>.</li>
<li><strong>CrowdANALYTIX</strong>: This is a crowdsourced data analytics service that is focused on the life sciences and financial services industries at <span class="URLPACKT"><a href="https://www.crowdanalytix.com/">https://www.crowdanalytix.com</a></span>.</li>
<li><strong>DrivenData</strong>: This hosts data science competitions for social good at <span class="URLPACKT"><a href="http://www.drivendata.org/">http://www.drivendata.org/</a></span>.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Websites and blogs</h1>
                </header>
            
            <article>
                
<p>In addition to online courses and competitions, there are numerous websites and blogs publishing the latest developments in the data science community, their experience in attacking different problems, or just best practices. Some good starting points are as follows:</p>
<ul>
<li><strong>KDnuggets</strong>: This is the de facto portal for data mining, analytics, big data, and data science, covering the latest news, stories, events, and other relevant issues at <span class="URLPACKT"><a href="http://www.kdnuggets.com/">http://www.kdnuggets.com/</a></span>.</li>
<li><strong>Machine Learning Mastery</strong>: This is an introductory-level blog with practical advice and pointers where to start. Check it out at <span class="URLPACKT"><a href="http://machinelearningmastery.com/">http://machinelearningmastery.com/</a></span>.</li>
<li><strong>Data Science Central</strong>: This consists of practical community articles on a variety of topics, algorithms, caches, and business cases at <span class="URLPACKT"><a href="http://www.datasciencecentral.com/">http://www.datasciencecentral.com/</a></span>.</li>
<li><strong>Data Mining</strong> <strong>Research</strong> by Sandro Saitta at <span class="URLPACKT"><a href="http://www.dataminingblog.com/">http://www.dataminingblog.com/</a></span>.</li>
<li><strong>Data Mining: Text Mining, Visualization and Social Media</strong> by Matthew Hurst, which covers interesting text and web mining topics, frequently with applications to Bing and Microsoft at <span class="URLPACKT"><a href="http://datamining.typepad.com/data_mining/">http://datamining.typepad.com/data_mining/</a></span>.</li>
<li><strong>Geeking with Greg</strong> by Greg Linden, inventor of the Amazon recommendation engine and internet entrepreneur. You can check it out at <span class="URLPACKT"><a href="http://glinden.blogspot.si/">http://glinden.blogspot.si/</a></span>.</li>
<li><strong>DSGuide</strong>: This is a collection of over 150 data science blogs at <span class="URLPACKT"><a href="http://dsguide.biz/reader/sources">http://dsguide.biz/reader/sources</a></span>.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Venues and conferences</h1>
                </header>
            
            <article>
                
<p>The following are a few top-tier academic conferences with the latest algorithms:</p>
<ul>
<li><strong>Knowledge Discovery in Databases</strong> (<strong>KDD</strong>)</li>
<li><strong>Computer Vision and Pattern Recognition</strong> (<strong>CVPR</strong>)</li>
<li><strong>Annual Conference on Neural Information Processing Systems</strong> (<strong>NIPS</strong>)</li>
<li><strong>International Conference on Machine Learning</strong> (<strong>ICML</strong>)</li>
<li><strong>International Conference on Data Mining</strong> (<strong>ICDM</strong>)</li>
<li><strong>International Joint Conference on Pervasive and Ubiquitous Computing</strong> (<strong>UbiComp</strong>)</li>
<li><strong>International Joint Conference on Artificial Intelligence</strong> (<strong>IJCAI</strong>)</li>
</ul>
<p>Some business conferences are as follows:</p>
<ul>
<li>O'Reilly Strata Conference</li>
<li>The Strata + Hadoop World Conferences</li>
<li>Predictive Analytics World</li>
<li>MLconf</li>
</ul>
<p>You can also check local meet-up groups.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we concluded this book by discussing some aspects of model deployment, and we looked into standards for the data science process and the interchangeable predictive model format. We also reviewed online courses, competitions, web resources, and conferences that could help you in your journey towards mastering the art of machine learning.</p>
<p>I hope this book inspired you to dive deeper into data science and has motivated you to get your hands dirty, experiment with various libraries, and get a grasp of how different problems could be attacked. Remember, all of the source code and additional resources are available on the Packt Publishing website: <a href="https://www.packtpub.com/">https://www.packtpub.com/</a>.</p>


            </article>

            
        </section>
    </div>



  </body></html>