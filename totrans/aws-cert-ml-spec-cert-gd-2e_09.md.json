["```py\n    sh-4.2$ cd ~/SageMaker/\n    ```", "```py\n    sh-4.2$ git clone https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide-Second-Edition.git\n    ```", "```py\ntuning_job_config = {\n```", "```py\n    \"ParameterRanges\": {\n```", "```py\n      \"CategoricalParameterRanges\": [],\n```", "```py\n      \"ContinuousParameterRanges\": [],\n```", "```py\n      \"IntegerParameterRanges\": [\n```", "```py\n        {\n```", "```py\n          \"MaxValue\": \"10\",\n```", "```py\n          \"MinValue\": \"1\",\n```", "```py\n          \"Name\": \"max_depth\"\n```", "```py\n        }\n```", "```py\n      ]\n```", "```py\n    },\n```", "```py\n    \"ResourceLimits\": {\n```", "```py\n      \"MaxNumberOfTrainingJobs\": 10,\n```", "```py\n      \"MaxParallelTrainingJobs\": 2\n```", "```py\n    },\n```", "```py\n    \"Strategy\": \"Bayesian\",\n```", "```py\n    \"HyperParameterTuningJobObjective\": {\n```", "```py\n      \"MetricName\": \"validation:auc\",\n```", "```py\n      \"Type\": \"Maximize\"\n```", "```py\n    }\n```", "```py\n  }\n```", "```py\ntraining_image = sagemaker.image_uris.retrieve('xgboost', region, '1.0-1')\n```", "```py\ntraining_job_definition = {\n```", "```py\n    \"AlgorithmSpecification\": {\n```", "```py\n      \"TrainingImage\": training_image,\n```", "```py\n      \"TrainingInputMode\": \"File\"\n```", "```py\n    },\n```", "```py\n    \"InputDataConfig\": [\n```", "```py\n      {\n```", "```py\n        \"ChannelName\": \"train\",\n```", "```py\n        \"CompressionType\": \"None\",\n```", "```py\n        \"ContentType\": \"csv\",\n```", "```py\n        \"DataSource\": {\n```", "```py\n          \"S3DataSource\": {\n```", "```py\n            \"S3DataDistributionType\": \"FullyReplicated\",\n```", "```py\n            \"S3DataType\": \"S3Prefix\",\n```", "```py\n            \"S3Uri\": s3_input_train\n```", "```py\n          }\n```", "```py\n        }\n```", "```py\n      },\n```", "```py\n      {\n```", "```py\n        \"ChannelName\": \"validation\",\n```", "```py\n        \"CompressionType\": \"None\",\n```", "```py\n        \"ContentType\": \"csv\",\n```", "```py\n        \"DataSource\": {\n```", "```py\n          \"S3DataSource\": {\n```", "```py\n            \"S3DataDistributionType\": \"FullyReplicated\",\n```", "```py\n            \"S3DataType\": \"S3Prefix\",\n```", "```py\n            \"S3Uri\": s3_input_validation\n```", "```py\n          }\n```", "```py\n        }\n```", "```py\n      }\n```", "```py\n    ],\n```", "```py\n    \"OutputDataConfig\": {\n```", "```py\n      \"S3OutputPath\": \"s3://{}/{}/output\".format(bucket,prefix)\n```", "```py\n    },\n```", "```py\n    \"ResourceConfig\": {\n```", "```py\n      \"InstanceCount\": 2,\n```", "```py\n      \"InstanceType\": \"ml.c4.2xlarge\",\n```", "```py\n      \"VolumeSizeInGB\": 10\n```", "```py\n    },\n```", "```py\n    \"RoleArn\": <<your_role_name>>,\n```", "```py\n    \"StaticHyperParameters\": {\n```", "```py\n      \"eval_metric\": \"auc\",\n```", "```py\n      \"num_round\": \"100\",\n```", "```py\n      \"objective\": \"binary:logistic\",\n```", "```py\n      \"rate_drop\": \"0.3\",\n```", "```py\n      \"tweedie_variance_power\": \"1.4\"\n```", "```py\n    },\n```", "```py\n    \"StoppingCondition\": {\n```", "```py\n      \"MaxRuntimeInSeconds\": 43200\n```", "```py\n    }\n```", "```py\n}\n```", "```py\nsmclient.create_hyper_parameter_tuning_job(\n```", "```py\n     HyperParameterTuningJobName = \"my-tuning-example\",\n```", "```py\n     HyperParameterTuningJobConfig = tuning_job_config,\n```", "```py\n     TrainingJobDefinition = training_job_definition\n```", "```py\n)\n```", "```py\n    # Example code for ingesting data into Feature Store\n    ```", "```py\n    from sagemaker.feature_store.feature_group import FeatureGroup\n    ```", "```py\n    feature_group_name = \"financial-transaction-feature-group\"\n    ```", "```py\n    feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sagemaker_session)\n    ```", "```py\n    feature_group.load_feature_definitions(data_frame=df)\n    ```", "```py\n    feature_group.create()\n    ```", "```py\n    feature_group.ingest(data_frame=df, max_workers=3, wait=True)\n    ```", "```py\n    from sagemaker.compiler import compile_model\n    ```", "```py\n    compiled_model = compile_model(\n    ```", "```py\n        target_instance_family='ml.m5.large',\n    ```", "```py\n        target_platform_os='LINUX',\n    ```", "```py\n        sources=['train.py'],\n    ```", "```py\n        dependencies=['requirements.txt'],\n    ```", "```py\n        framework='pytorch',\n    ```", "```py\n        framework_version='1.8.0',\n    ```", "```py\n        role='arn:aws:iam::123456789012:role/service-role/AmazonSageMaker-ExecutionRole-20201231T000001',\n    ```", "```py\n        entry_point='train.py',\n    ```", "```py\n        instance_type='ml.m5.large',\n    ```", "```py\n    )\n    ```", "```py\n    from smdebug import SaveConfig\n    ```", "```py\n    from smdebug.pytorch import Hook\n    ```", "```py\n    # Create an instance of your model\n    ```", "```py\n    model = FraudDetectionModel(input_size, hidden_size, output_size)\n    ```", "```py\n    hook = Hook.create_from_json_file()\n    ```", "```py\n    hook.register_hook(model)\n    ```", "```py\n    # Your training script here...\n    ```", "```py\n    # Train the model train_model(model, train_loader, criterion, optimizer, num_epochs=5)\n    ```", "```py\n    from sagemaker.model_monitor import DefaultModelMonitor\n    ```", "```py\n    from sagemaker.model_monitor.dataset_format import DatasetFormat\n    ```", "```py\n    monitor = DefaultModelMonitor(\n    ```", "```py\n        role=role,\n    ```", "```py\n        instance_count=1,\n    ```", "```py\n        instance_type='ml.m5.large',\n    ```", "```py\n        volume_size_in_gb=20,\n    ```", "```py\n        max_runtime_in_seconds=3600,\n    ```", "```py\n    )\n    ```", "```py\n    baseline_data_uri = 's3://path/to/baseline_data'\n    ```", "```py\n    monitor.suggest_baseline(\n    ```", "```py\n        baseline_dataset=baseline_data_uri,\n    ```", "```py\n        dataset_format=DatasetFormat.csv(header=True),\n    ```", "```py\n        output_s3_uri='s3://path/to/baseline_output',\n    ```", "```py\n    )\n    ```"]