<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Recommendation Engines with Apache Mahout</h1>
                </header>
            
            <article>
                
<p>Recommendation engines are one of the most applied data science approaches in startups today. There are two principal techniques for building a recommendation system: content-based filtering and collaborative filtering. The content-based algorithm uses the properties of the items to find items with similar properties. Collaborative filtering algorithms take user ratings, or other user behaviors, and make recommendations based on what users with similar behaviors liked or purchased.</p>
<p>In this chapter, we will first explain the basic concepts required to understand recommendation engine principles, and then we will demonstrate how to utilize Apache Mahout's implementation of various algorithms in order to quickly get a scalable recommendation engine.</p>
<p>This chapter will cover the following topics:</p>
<ul>
<li>How to build a recommendation engine</li>
<li>Getting Apache Mahout ready</li>
<li>The content-based approach</li>
<li>The collaborative filtering approach</li>
</ul>
<p>By the end of this chapter, you will have learned about the kind of recommendation engine that is appropriate for our problem and how to quickly implement that engine.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Basic concepts</h1>
                </header>
            
            <article>
                
<p>Recommendation engines aim at showing users items of interest. What makes them different from search engines is the relevant content usually appears on a website without having been requested, and users don't have to build queries, as recommendation engines observe the users' actions and construct the queries for users without their knowledge.</p>
<p>Arguably, the most well-known example of a recommendation engine is <a href="http://www.amazon.com"><span class="URLPACKT">www.amazon.com</span></a>, which provides personalized recommendation in a number of ways. The following screenshot shows an example of <span class="packt_screen">Customers Who Bought This Item Also Bought</span>. As you will see later on, this is an example of collaborative item-based recommendation, where items similar to a particular item are recommended:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-666 image-border" src="Images/bc5d5436-b9f5-42ba-8642-1f2bb6e0e6e3.png" style="width:76.83em;height:30.33em;" width="922" height="364"/></p>
<p>In this section, we will introduce key concepts related to understanding and building recommendation engines.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Key concepts</h1>
                </header>
            
            <article>
                
<p>Recommendation engines require the following pieces of input in order to make recommendations:</p>
<ul>
<li>Item information, described with attributes</li>
<li>A user profile, such as age range, gender, location, friends, and so on</li>
<li>User interactions, in the form of rating, browsing, tagging, comparing, saving, and emailing</li>
<li>The context where the items will be displayed; for example, the item's category and the item's geographical location</li>
</ul>
<p>This input is then combined by the recommendation engine to help obtain the following:</p>
<ul>
<li>Users who bought, watched, viewed, or bookmarked this item also bought, watched, viewed, or bookmarked</li>
<li>Items similar to this item</li>
<li>Other users you may know</li>
<li>Other users who are similar to you</li>
</ul>
<p>Now, let's take a closer look at how this combination works.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">User-based and item-based analysis</h1>
                </header>
            
            <article>
                
<p>Building a recommendation engine depends on whether the engine searches for related items or users when trying to recommend a particular item.</p>
<p>In item-based analysis, the engine focuses on identifying items that are similar to a particular item, while in user-based analysis, users similar to the particular user are determined first. For example, users with the same profile information (age, gender, and so on) or action history (bought, watched, viewed, and so on) are determined, and then the same items are recommended to other, similar users.</p>
<p>Both approaches require us to compute a similarity matrix, depending on whether we're analyzing item attributes or user actions. Let's take a deeper look at how this is done.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Calculating similarity</h1>
                </header>
            
            <article>
                
<p>There are three fundamental approaches to calculating similarity, as follows:</p>
<ul>
<li>Collaborative filtering algorithms take user ratings or other user behaviors and make recommendations based on what users with similar behaviors liked or purchased</li>
<li>The content-based algorithm uses the properties of the items to find items with similar properties</li>
<li>A hybrid approach combines collaborative and content-based filtering</li>
</ul>
<p>Let's take a look at each approach in detail in the following sections.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Collaborative filtering</h1>
                </header>
            
            <article>
                
<p><strong>Collaborative filtering</strong> is based solely on user ratings or other user behaviors, making recommendations based on what users with similar behaviors liked or purchased.</p>
<p>A key advantage of collaborative filtering is that it does not rely on item content, and therefore, it is capable of accurately recommending complex items, such as movies, without understanding the item itself. The underlying assumption is that people that agreed in the past will agree in the future, and that they will like similar kinds of items to what they liked in the past.</p>
<p>A major disadvantage of this approach is the so-called cold start, meaning that if we want to build an accurate collaborative filtering system, the algorithm often needs a large amount of user ratings. This usually takes collaborative filtering out of the first version of the product, and it is introduced later, when a decent amount of data has been collected.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Content-based filtering</h1>
                </header>
            
            <article>
                
<p>Content-based filtering, on the other hand, is based on a description of items and a profile of a user's preferences, which is combined as follows. First, the items are described with attributes, and to find similar items, we measure the distances between items using a distance measure, such as the cosine distance or Pearson coefficient (there is more about distance measures in <a href="11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml"><span class="ChapterrefPACKT">Chapter 1</span></a>, <em>Applied Machine Learning Quick Start</em>). Now, the user profile enters the equation. Given the feedback about the kinds of items the user likes, we can introduce weights, specifying the importance of a specific item attribute. For instance, the Pandora Radio streaming service applies content-based filtering to create stations, using more than 400 attributes. A user initially picks a song with specific attributes, and, by providing feedback, important song attributes are emphasized.</p>
<p>Initially, this approach needs very little information on user feedback; thus, it effectively avoids the cold start issue.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Hybrid approach</h1>
                </header>
            
            <article>
                
<p>Now, between collaborative and content-based, which one should you choose? Collaborative filtering is able to learn user preferences from a user's actions regarding one content source, and use them across other content types. Content-based filtering is limited to recommending content of the same type that the user is already using. This provides value in certain use cases; for example, recommending news articles based on news browsing is useful, but it is much more useful if different sources, such as books and movies, can be recommended based on news browsing.</p>
<p>Collaborative filtering and content-based filtering are not mutually exclusive; they can be combined to be more effective in some cases. For example, Netflix uses collaborative filtering to analyze the searching and watching patterns of similar users, as well as content-based filtering to offer movies that share characteristics with films that the user has rated highly.</p>
<p>There is a wide variety of hybridization techniques: weighted, switching, and mixed, feature combination, feature augmentation, cascade, meta-level, and so on. Recommendation systems are an active area in the machine learning and data mining community, with special tracks on data science conferences. A good overview of techniques is summarized in the paper <em>Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions,</em> by Adomavicius and Tuzhilin (2005), where the authors discuss different approaches and underlying algorithms, and provide references to further papers. To get more technical and understand all of the tiny details when a particular approach makes sense, you should look at the book edited by Ricci, et al.: <em>Recommender Systems Handbook</em> (First Edition, 2010, <em>S</em>pringer-Verlag, New York).</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Exploitation versus exploration</h1>
                </header>
            
            <article>
                
<p>In recommendation systems, there is always a trade-off between recommending items that fall into the user's sweet spot, based on what we already know about the user (<strong>exploitation</strong>), and recommending items that don't fall into the user's sweet spot, with the aim to expose the user to some novelties (<strong>exploration</strong>). Recommendation systems with little exploration will only recommend items that are consistent with the previous user ratings, thus preventing showing items outside of their current bubble. In practice, the serendipity of getting new items out of the user's sweet spot is often desirable, leading to a pleasant surprise, and potentially, the discovery of new sweet spots.</p>
<p>In this section, we discussed the essential concepts required to start building recommendation engines. Now, let's take a look at how to actually build one with Apache Mahout.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting Apache Mahout</h1>
                </header>
            
            <article>
                
<p>Mahout was introduced in <a href="6fd557d7-2807-4a6d-8f93-d7c4ca094b7e.xhtml"><span class="ChapterrefPACKT">Chapter 2</span></a>, <em>Java Libraries and Platforms for Machine Learning</em>, as a scalable machine learning library. It provides a rich set of components with which you can construct a customized recommendation system from a selection of algorithms. The creators of Mahout say that it is designed to be enterprise-ready; it's designed for performance, scalability, and flexibility.</p>
<p>Mahout can be configured to run in two flavors: with or without Hadoop, and for a single machine and distributed processing, respectively. We will focus on configuring Mahout without Hadoop. For more advanced configurations and further uses of Mahout, I would recommend two recent books: <em>Learning Apache Mahout,</em> by <em>C</em>handramani Tiwary, Packt Publishing, and <em>Learning Apache Mahout Classification,</em> by Ashish Gupta, Packt Publishing.</p>
<p>As Apache Mahout's build and release system is based on Maven, you will need to learn how to install it. We will look at the most convenient approach; using Eclipse with the Maven plugin.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Configuring Mahout in Eclipse with the Maven plugin</h1>
                </header>
            
            <article>
                
<p>You will need a recent version of Eclipse, which can be downloaded from its home page (<a href="https://www.eclipse.org/downloads/">https://www.eclipse.org/downloads/</a>). In this book, we will use Eclipse Luna. Open Eclipse and start a new <span class="packt_screen">Maven Project</span> with the default settings, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-668 image-border" src="Images/d0f0d765-b4d9-4f6b-9e91-da68d83c8b55.png" style="width:33.17em;height:29.58em;" width="453" height="404"/></p>
<p>The <span class="packt_screen">New Maven project</span> screen will appear, as shown in the following screenshot:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-669 image-border" src="Images/09486760-7963-446f-a3a7-a8f436d10cbc.png" style="width:30.00em;height:28.33em;" width="489" height="462"/></div>
<p>Now, we need to tell the project to add the Mahout JAR file and its dependencies to the project. Locate the <kbd>pom.xml</kbd> file and open it with the text editor (left-click on <span class="packt_screen">Open With</span> | <span class="packt_screen">Text Editor</span>), as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-670 image-border" src="Images/ad5a51b9-7f0e-44ad-a6bc-0cd4695675ef.png" style="width:38.42em;height:19.08em;" width="751" height="373"/></p>
<p>Locate the line starting with <kbd>&lt;dependencies&gt;</kbd> and add the following code in the next line:</p>
<pre>&lt;dependency&gt; 
 &lt;groupId&gt;org.apache.mahout&lt;/groupId&gt; 
  &lt;artifactId&gt;mahout-mr&lt;/artifactId&gt; 
  &lt;version&gt;0.10.0&lt;/version&gt; 
&lt;/dependency&gt; </pre>
<p>That's it; Mahout has been added, and we are ready to begin.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building a recommendation engine</h1>
                </header>
            
            <article>
                
<p>To demonstrate both the content-based filtering and collaborative filtering approaches, we'll build a book recommendation engine.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Book ratings dataset</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will work with a book ratings dataset (Ziegler et al., 2005) that was collected in a four-week crawl. It contains data on 278,858 members of the Book-Crossing website and 1,157,112 ratings, both implicit and explicit, referring to 271,379 distinct ISBNs. User data is anonymized, but with demographic information. The dataset is taken from <a href="http://www2.informatik.uni-freiburg.de/~dbis/Publications/05/WWW05.html">Improving Recommendation Lists Through Topic Diversification</a><span>,</span> <em>C</em>ai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, Georg Lausen: <em>Proceedings of the 14th International World Wide Web Conference</em> (WWW '05)<em>,</em> May 10-14, 2005, Chiba, Japan (<span class="URLPACKT"><a href="http://www2.informatik.uni-freiburg.de/~cziegler/BX/">http://www2.informatik.uni-freiburg.de/~cziegler/BX/</a>).</span></p>
<p>The Book-Crossing dataset is comprised of three files, as follows:</p>
<ul>
<li><kbd>BX-Users</kbd>: This contains the users. Note that user IDs (<span class="packt_screen">User-ID</span>) have been anonymized and mapped to integers. Demographic data is provided (<span class="packt_screen">Location</span> and <span class="packt_screen">Age</span>) if available. Otherwise, these fields contain null values.</li>
<li><kbd>BX-Books</kbd>: Books are identified by their respective ISBNs. Invalid ISBNs have already been removed from the dataset. Moreover, some content-based information is given (<span class="packt_screen">Book-Title</span>, <span class="packt_screen">Book-Author</span>, <span class="packt_screen">Year-Of-Publication</span>, and <span class="packt_screen">Publisher</span>), which has been obtained from Amazon Web Services. Note that in the case of several authors, only the first author is provided. URLs linking to cover images are also given, appearing in three different flavors (<span class="packt_screen">Image-URL-S</span>, <span class="packt_screen">Image-URL-M</span>, and <span class="packt_screen">Image-URL-L</span>), referring to small, medium, and large URLs. These URLs point to the Amazon website.</li>
<li><kbd>BX-Book-Ratings</kbd>: This contains the book rating information. Ratings (<span class="packt_screen">Book-Rating</span>) are either explicit, expressed on a scale of 1-10 (with higher values denoting higher appreciation), or implicit, expressed by 0.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Loading the data</h1>
                </header>
            
            <article>
                
<p>There are two approaches to loading the data, according to where the data is stored: a file or database. First, we will take a detailed look at how to load the data from a file, including how to deal with custom formats. At the end, we will quickly take a look at how to load the data from a database.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Loading data from a file</h1>
                </header>
            
            <article>
                
<p>Loading data from a file can be achieved with the <kbd>FileDataModel</kbd> class. We will be expecting a comma-delimited file, where each line contains a <kbd>userID</kbd>, an <kbd>itemID</kbd>, an optional <kbd>preference</kbd> value, and an optional <kbd>timestamp</kbd>, in the same order, as follows:</p>
<pre>userID,itemID[,preference[,timestamp]] </pre>
<p>An optional preference accommodates applications with binary preference values, that is, the user either expresses a preference for an item or not, without a degree of preference; for example, with a like or dislike.</p>
<p>A line that begins with a hash (<kbd>#</kbd>) or an empty line will be ignored. It is also acceptable for the lines to contain additional fields, which will be ignored.</p>
<p>The <kbd>DataModel</kbd> class assumes the following types:</p>
<ul>
<li>The <kbd>userID</kbd> and <kbd>itemID</kbd> can be parsed as <kbd>long</kbd></li>
<li>The <kbd>preference</kbd> value can be parsed as <kbd>double</kbd></li>
<li>The <kbd>timestamp</kbd> can be parsed as <kbd>long</kbd></li>
</ul>
<p>If you are able to provide the dataset in the preceding format, you can simply use the following line to load the data:</p>
<pre>DataModel model = new FileDataModel(new File(path)); </pre>
<p>This class is not intended to be used for very large amounts of data; for example, tens of millions of rows. For that, a JDBC-backed <kbd>DataModel</kbd> and a database are more appropriate.</p>
<p>In the real world, however, we cannot always ensure that the input data supplied to us contains only integer values for <kbd>userID</kbd> and <kbd>itemID</kbd>. For example, in our case, <kbd>itemID</kbd> corresponds to ISBN book numbers, which uniquely identify items, but these are not integers, and the <kbd>FileDataModel</kbd> default won't be suitable to process our data.</p>
<p>Now, let's consider how to deal with a case where our <kbd>itemID</kbd> is a string. We will define our custom data model by extending <kbd>FileDataModel</kbd> and overriding the long <kbd>readItemIDFromString(String)</kbd> method in order to read the <kbd>itemID</kbd> as a string and convert it into <kbd>long</kbd>, and return a unique <kbd>long</kbd> value. To convert a <kbd>String</kbd> into a unique <kbd>long</kbd>, we'll extend another Mahout <kbd>AbstractIDMigrator</kbd> helper class, which is designed exactly for this task.</p>
<p>Now, let's look at how <kbd>FileDataModel</kbd> is extended:</p>
<pre>class StringItemIdFileDataModel extends FileDataModel { 
 
  //initialize migrator to covert String to unique long 
  public ItemMemIDMigrator memIdMigtr; 
 
  public StringItemIdFileDataModel(File dataFile, String regex) <br/>     throws IOException { 
    super(dataFile, regex); 
  } 
 
  @Override 
  protected long readItemIDFromString(String value) { 
     
    if (memIdMigtr == null) { 
      memIdMigtr = new ItemMemIDMigrator(); 
    } 
     
    // convert to long 
    long retValue = memIdMigtr.toLongID(value); 
    //store it to cache  
    if (null == memIdMigtr.toStringID(retValue)) { 
      try { 
        memIdMigtr.singleInit(value); 
      } catch (TasteException e) { 
        e.printStackTrace(); 
      } 
    } 
    return retValue; 
  } 
   
  // convert long back to String 
  String getItemIDAsString(long itemId) { 
    return memIdMigtr.toStringID(itemId); 
  } 
} </pre>
<p>Other useful methods that can be overridden are as follows:</p>
<ul>
<li><kbd>readUserIDFromString(String value)</kbd>, if user IDs are not numeric</li>
<li><kbd>readTimestampFromString(String value)</kbd>, to change how <kbd>timestamp</kbd> is parsed</li>
</ul>
<p>Now, let's take a look at how <kbd>AbstractIDMIgrator</kbd> is extended:</p>
<pre>class ItemMemIDMigrator extends AbstractIDMigrator { 
 
  private FastByIDMap&lt;String&gt; longToString; 
 
  public ItemMemIDMigrator() { 
    this.longToString = new FastByIDMap&lt;String&gt;(10000); 
  } 
 
  public void storeMapping(long longID, String stringID) { 
    longToString.put(longID, stringID); 
  } 
 
  public void singleInit(String stringID) throws TasteException { 
    storeMapping(toLongID(stringID), stringID); 
  } 
 
  public String toStringID(long longID) { 
    return longToString.get(longID); 
  } 
} </pre>
<p>Now, we have everything in place, and we can load our dataset with the following code:</p>
<pre>StringItemIdFileDataModel model = new StringItemIdFileDataModel( 
  new File("datasets/chap6/BX-Book-Ratings.csv"), ";"); 
System.out.println( 
"Total items: " + model.getNumItems() +  
"\nTotal users: " +model.getNumUsers()); </pre>
<p>This provides the total number of users and items as output:</p>
<pre>    Total items: 340556
    Total users: 105283
  </pre>
<p>We are ready to move on and start making recommendations.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Loading data from a database</h1>
                </header>
            
            <article>
                
<p>Alternatively, we can load the data from a database using one of the JDBC data models. In this chapter, we will not dive into the detailed instructions of how to set up a database, connections, and so on, but we will give a sketch of how this can be done.</p>
<p>Database connectors have been moved to a separate package, <kbd>mahout-integration</kbd>; hence, we have to add the package to our <kbd>dependency</kbd> list. Open the <kbd>pom.xml</kbd> file and add the following <kbd>dependency</kbd>:</p>
<pre>&lt;dependency&gt; 
  &lt;groupId&gt;org.apache.mahout&lt;/groupId&gt; 
  &lt;artifactId&gt;mahout-integration&lt;/artifactId&gt; 
  &lt;version&gt;0.7&lt;/version&gt; 
&lt;/dependency&gt; </pre>
<p>Consider that we want to connect to a MySQL database. In this case, we will also need a package that handles database connections. Add the following to the <kbd>pom.xml</kbd> file:</p>
<pre>&lt;dependency&gt; 
  &lt;groupId&gt;mysql&lt;/groupId&gt; 
  &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; 
  &lt;version&gt;5.1.35&lt;/version&gt; 
&lt;/dependency&gt; </pre>
<p>Now, we have all of the packages, so we can create a connection. First, let's initialize a <kbd>DataSource</kbd> class with connection details, as follows:</p>
<pre>MysqlDataSource dbsource = new MysqlDataSource(); 
  dbsource.setUser("user"); 
  dbsource.setPassword("pass"); 
  dbsource.setServerName("hostname.com"); 
  dbsource.setDatabaseName("db"); </pre>
<p>Mahout integration implements <kbd>JDBCDataModel</kbd> to various databases that can be accessed via JDBC. By default, this class assumes that there is a <kbd>DataSource</kbd> available under the JNDI name, <kbd>jdbc/taste</kbd>, which gives access to a database with a<br/>
<kbd>taste_preferences</kbd> table, with the following schema:</p>
<pre>CREATE TABLE taste_preferences ( 
  user_id BIGINT NOT NULL, 
  item_id BIGINT NOT NULL, 
  preference REAL NOT NULL, 
  PRIMARY KEY (user_id, item_id) 
) 
CREATE INDEX taste_preferences_user_id_index ON taste_preferences <br/>   (user_id); 
CREATE INDEX taste_preferences_item_id_index ON taste_preferences <br/>   (item_id); </pre>
<p>A database-backed data model is initialized as follows. In addition to the DB connection object, we can specify the custom table name and the table column names, as follows:</p>
<pre>DataModel dataModel = new MySQLJDBCDataModel(dbsource, <br/>   "taste_preferences",  
  "user_id", "item_id", "preference", "timestamp"); </pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">In-memory databases</h1>
                </header>
            
            <article>
                
<p>Last, but not least, the data model can be created on the fly and held in memory. A database can be created from an array of preferences, which will hold user ratings for a set of items.</p>
<p>We can proceed as follows. First, we create a <kbd>FastByIdMap</kbd> hash map of preference arrays, <kbd>PreferenceArray</kbd>, which stores an array of preferences:</p>
<pre>FastByIDMap &lt;PreferenceArray&gt; preferences = new FastByIDMap <br/>   &lt;PreferenceArray&gt; ();  </pre>
<p>Next, we can create a new preference array for a user that will hold their ratings. The array must be initialized with a size parameter that reserves that many slots in the memory:</p>
<pre>PreferenceArray prefsForUser1 =  
  new GenericUserPreferenceArray (10);   </pre>
<p>Next, we set the user ID for the current preference at the position <kbd>0</kbd>. This will actually set the user ID for all preferences:</p>
<pre>prefsForUser1.setUserID (0, 1L);  </pre>
<p>Set an <kbd>itemID</kbd> for the current preference at the position <kbd>0</kbd>, as follows:</p>
<pre>prefsForUser1.setItemID (0, 101L);  </pre>
<p>Set the preference value for the preference at <kbd>0</kbd>, as follows:</p>
<pre>prefsForUser1.setValue (0, 3.0f);   </pre>
<p>Continue for other item ratings, as follows:</p>
<pre>prefsForUser1.setItemID (1, 102L);  
prefsForUser1.setValue (1, 4.5F);  </pre>
<p>Finally, add the user <kbd>preferences</kbd> to the hash map:</p>
<pre>preferences.put (1L, prefsForUser1); // use userID as the key  </pre>
<p>The preference hash map can now be used to initialize <kbd>GenericDataModel</kbd>:</p>
<pre>DataModel dataModel = new GenericDataModel(preferences); </pre>
<p>This code demonstrates how to add two preferences for a single user; in a practical application, you'll want to add multiple preferences for multiple users.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Collaborative filtering</h1>
                </header>
            
            <article>
                
<p>The recommendation engines in Mahout can be built with the <kbd>org.apache.mahout.cf.taste</kbd> package, which was formerly a separate project called <kbd>Taste</kbd>, and has continued to be developed in Mahout.</p>
<p>A Mahout-based collaborative filtering engine takes the users' preferences for items (tastes) and returns the estimated preferences for other items. For example, a site that sells books or CDs could easily use Mahout to figure out the CDs that a customer might be interested in listening to, with the help of previous purchase data.</p>
<p>Top-level packages define the Mahout interfaces to the following key abstractions:</p>
<ul>
<li><strong>DataModel</strong>: This represents a repository of information about users and their preferences for items</li>
<li><strong>UserSimilarity</strong>: This defines a notion of similarity between two users</li>
<li><strong>ItemSimilarity</strong>: This defines a notion of similarity between two items</li>
<li><strong>UserNeighborhood</strong>: This computes neighboring users for a given user
<ul>
<li><strong>Recommender</strong>: This recommends items for the user</li>
</ul>
</li>
</ul>
<p>A general structure of the preceding concepts is shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-671 image-border" src="Images/4e64495c-df83-4e76-84b8-0150cf124ea9.png" style="width:22.50em;height:53.92em;" width="442" height="1060"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">User-based filtering</h1>
                </header>
            
            <article>
                
<p>The most basic user-based collaborative filtering can be implemented by initializing the previously described components, as follows:</p>
<p>First, load the data model:</p>
<pre>StringItemIdFileDataModel model = new StringItemIdFileDataModel( 
    new File("/datasets/chap6/BX-Book-Ratings.csv", ";"); </pre>
<p>Next, define how to calculate how the users are correlated; for example, using the Pearson correlation:</p>
<pre>UserSimilarity similarity =  
  new PearsonCorrelationSimilarity(model); </pre>
<p>Next, define how to tell which users are similar, that is, the users that are close to each other, according to their ratings:</p>
<pre>UserNeighborhood neighborhood =  
  new ThresholdUserNeighborhood(0.1, similarity, model); </pre>
<p>Now, we can initialize a <kbd>GenericUserBasedRecommender</kbd> default engine with the data for <kbd>model</kbd>, <kbd>neighborhood</kbd>, and similar objects, as follows:</p>
<pre>UserBasedRecommender recommender =  
new GenericUserBasedRecommender(model, neighborhood, similarity); </pre>
<p>That's it. Our first basic recommendation engine is ready. Let's discuss how to invoke recommendations. First, let's print the items that the user has already rated, along with ten recommendations for that user:</p>
<pre>long userID = 80683; 
int noItems = 10; 
 
List&lt;RecommendedItem&gt; recommendations = recommender.recommend( 
  userID, noItems); 
 
System.out.println("Rated items by user:"); 
for(Preference preference : model.getPreferencesFromUser(userID)) { 
  // convert long itemID back to ISBN 
  String itemISBN = model.getItemIDAsString( 
  preference.getItemID()); 
  System.out.println("Item: " + books.get(itemISBN) +  
    " | Item id: " + itemISBN +  
    " | Value: " + preference.getValue()); 
} 
 
System.out.println("\nRecommended items:"); 
for (RecommendedItem item : recommendations) { 
  String itemISBN = model.getItemIDAsString(item.getItemID()); 
  System.out.println("Item: " + books.get(itemISBN) +  
    " | Item id: " + itemISBN +  
    " | Value: " + item.getValue()); 
} </pre>
<p>This will provide the following recommendations, along with their scores, as output:</p>
<pre>    Rated items:
    Item: The Handmaid's Tale | Item id: 0395404258 | Value: 0.0
    Item: Get Clark Smart : The Ultimate Guide for the Savvy Consumer | Item id: 1563526298 | Value: 9.0
    Item: Plum Island | Item id: 0446605409 | Value: 0.0
    Item: Blessings | Item id: 0440206529 | Value: 0.0
    Item: Edgar Cayce on the Akashic Records: The Book of Life | Item id: 0876044011 | Value: 0.0
    Item: Winter Moon | Item id: 0345386108 | Value: 6.0
    Item: Sarah Bishop | Item id: 059032120X | Value: 0.0
    Item: Case of Lucy Bending | Item id: 0425060772 | Value: 0.0
    Item: A Desert of Pure Feeling (Vintage Contemporaries) | Item id: 0679752714 | Value: 0.0
    Item: White Abacus | Item id: 0380796155 | Value: 5.0
    Item: The Land of Laughs : A Novel | Item id: 0312873115 | Value: 0.0
    Item: Nobody's Son | Item id: 0152022597 | Value: 0.0
    Item: Mirror Image | Item id: 0446353957 | Value: 0.0
    Item: All I Really Need to Know | Item id: 080410526X | Value: 0.0
    Item: Dreamcatcher | Item id: 0743211383 | Value: 7.0
    Item: Perplexing Lateral Thinking Puzzles: Scholastic Edition | Item id: 0806917695 | Value: 5.0
    Item: Obsidian Butterfly | Item id: 0441007813 | Value: 0.0
    
    Recommended items:
    Item: Keeper of the Heart | Item id: 0380774933 | Value: 10.0
    Item: Bleachers | Item id: 0385511612 | Value: 10.0
    Item: Salem's Lot | Item id: 0451125452 | Value: 10.0
    Item: The Girl Who Loved Tom Gordon | Item id: 0671042858 | Value: 10.0
    Item: Mind Prey | Item id: 0425152898 | Value: 10.0
    Item: It Came From The Far Side | Item id: 0836220730 | Value: 10.0
    Item: Faith of the Fallen (Sword of Truth, Book 6) | Item id: 081257639X | Value: 10.0
    Item: The Talisman | Item id: 0345444884 | Value: 9.86375
    Item: Hamlet | Item id: 067172262X | Value: 9.708363
    Item: Untamed | Item id: 0380769530 | Value: 9.708363
  </pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Item-based filtering</h1>
                </header>
            
            <article>
                
<p>The <kbd>ItemSimilarity</kbd> attribute is the most important point to discuss here. Item-based recommenders are useful, as they can take advantage of something very fast; they base their computations on item similarity, not user similarity, and item similarity is relatively static. It can be precomputed, instead of recomputed in real time.</p>
<p>Thus, it's strongly recommended that you use <kbd>GenericItemSimilarity</kbd> with precomputed similarities, if you're going to use this class. You can use <kbd>PearsonCorrelationSimilarity</kbd>, too, which computes similarities in real time, but you will probably find this painfully slow for large amounts of data:</p>
<pre>StringItemIdFileDataModel model = new StringItemIdFileDataModel( 
  new File("datasets/chap6/BX-Book-Ratings.csv"), ";"); 
 
ItemSimilarity itemSimilarity = new <br/>   PearsonCorrelationSimilarity(model); 
 
ItemBasedRecommender recommender = new <br/>   GenericItemBasedRecommender(model, itemSimilarity); 
 
String itemISBN = "0395272238"; 
long itemID = model.readItemIDFromString(itemISBN); 
int noItems = 10; 
List&lt;RecommendedItem&gt; recommendations = <br/>   recommender.mostSimilarItems(itemID, noItems); 
 
System.out.println("Recommendations for item: <br/>   "+books.get(itemISBN)); 
 
System.out.println("\nMost similar items:"); 
for (RecommendedItem item : recommendations) { 
  itemISBN = model.getItemIDAsString(item.getItemID()); 
  System.out.println("Item: " + books.get(itemISBN) + " | Item id: <br/>     " + itemISBN + " | Value: " + item.getValue()); 
} 
Recommendations for item: Close to the BoneMost similar items:Item: Private Screening | Item id: 0345311396 | Value: 1.0Item: Heartstone | Item id: 0553569783 | Value: 1.0Item: Clockers / Movie Tie In | Item id: 0380720817 | Value: 1.0Item: Rules of Prey | Item id: 0425121631 | Value: 1.0Item: The Next President | Item id: 0553576666 | Value: 1.0Item: Orchid Beach (Holly Barker Novels (Paperback)) | Item id: 0061013412 | Value: 1.0Item: Winter Prey | Item id: 0425141233 | Value: 1.0Item: Night Prey | Item id: 0425146413 | Value: 1.0Item: Presumed Innocent | Item id: 0446359866 | Value: 1.0Item: Dirty Work (Stone Barrington Novels (Paperback)) | Item id: <br/>   0451210158 | Value: 1.0</pre>
<p>The resulting list returns a set of items that are similar to a particular item that we selected.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Adding custom rules to recommendations</h1>
                </header>
            
            <article>
                
<p>It often happens that some business rules require us to boost the score of the selected items. In the book dataset, for example, if a book is recent, we want to give it a higher score. That's possible by using the <kbd>IDRescorer</kbd> interface, as follows:</p>
<ul>
<li><kbd>rescore(long, double)</kbd> takes the <kbd>itemId</kbd> and original score as an argument and returns a modified score</li>
<li><kbd>isFiltered(long)</kbd> returns <kbd>true</kbd> to exclude a specific item from the recommendations, or <kbd>false</kbd>, otherwise</li>
</ul>
<p>Our example can be implemented as follows:</p>
<pre>class MyRescorer implements IDRescorer { 
 
  public double rescore(long itemId, double originalScore) { 
    double newScore = originalScore; 
    if(bookIsNew(itemId)){ 
      originalScore *= 1.3; 
    } 
    return newScore; 
  } 
 
  public boolean isFiltered(long arg0) { 
    return false; 
  } 
 
} </pre>
<p>An instance of <kbd>IDRescorer</kbd> is provided when invoking <kbd>recommender.recommend</kbd>:</p>
<pre>IDRescorer rescorer = new MyRescorer(); 
List&lt;RecommendedItem&gt; recommendations =  
recommender.recommend(userID, noItems, rescorer); </pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Evaluation</h1>
                </header>
            
            <article>
                
<p>You might be wondering how to make sure that the returned recommendations make any sense. The only way to really be sure about how effective recommendations are is to use A/B testing in a live system, with real users. For example, the A group receives a random item as a recommendation, while the B group receives an item that's recommended by our engine.</p>
<p>As this is not always possible (nor practical), we can get an estimate with offline statistical evaluation. One way to proceed is to use k-fold cross-validation, which was introduced in <a href="11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml"><span class="ChapterrefPACKT">Chapter 1</span></a>, <em>Applied Machine Learning Quick Start</em>. We partition a dataset into multiple sets; some are used to train our recommendation engine, and the rest are used to test how well it recommends items to unknown users.</p>
<p>Mahout implements the <kbd>RecommenderEvaluator</kbd> class, which splits a dataset in two parts. The first part (90%, by default) is used to produce recommendations, while the rest of the data is compared against estimated preference values in order to test the match. The class does not accept a <kbd>recommender</kbd> object directly; you need to build a class that's implementing the <kbd>RecommenderBuilder</kbd> interface instead, which builds a <kbd>recommender</kbd> object for a given <kbd>DataModel</kbd> object that is then used for testing. Let's take a look at how this is implemented.</p>
<p>First, we create a class that implements the <kbd>RecommenderBuilder</kbd> interface. We need to implement the <kbd>buildRecommender</kbd> method, which will return a <kbd>recommender</kbd>, as follows:</p>
<pre>public class BookRecommender implements RecommenderBuilder  { 
  public Recommender buildRecommender(DataModel dataModel) { 
    UserSimilarity similarity =  
      new PearsonCorrelationSimilarity(model); 
    UserNeighborhood neighborhood =  
      new ThresholdUserNeighborhood(0.1, similarity, model); 
    UserBasedRecommender recommender =  
      new GenericUserBasedRecommender( 
        model, neighborhood, similarity); 
    return recommender; 
  } 
} </pre>
<p>Now that we have a class that returns a recommender object, we can initialize a <kbd>RecommenderEvaluator</kbd> instance. The default implementation of this class is the <kbd>AverageAbsoluteDifferenceRecommenderEvaluator</kbd> class, which computes the average absolute difference between the predicted and actual ratings for users. The following code shows how to put the pieces together and run a hold-out test:</p>
<p>First, load a data model, as follows:</p>
<pre>DataModel dataModel = new FileDataModel( 
  new File("/path/to/dataset.csv")); </pre>
<p>Next, initialize an <kbd>evaluator</kbd> instance, as follows:</p>
<pre>RecommenderEvaluator evaluator =  
  new AverageAbsoluteDifferenceRecommenderEvaluator(); </pre>
<p>Initialize the <kbd>BookRecommender</kbd> object, implementing the <kbd>RecommenderBuilder</kbd> interface, as follows:</p>
<pre>RecommenderBuilder builder = new MyRecommenderBuilder(); </pre>
<p>Finally, call the <kbd>evaluate()</kbd> method, which accepts the following parameters:</p>
<ul>
<li><kbd>RecommenderBuilder</kbd>: This is the object implementing the <kbd>RecommenderBuilder</kbd> that can build the <kbd>recommender</kbd> to test</li>
<li><kbd>DataModelBuilder</kbd>: This indicates the <kbd>DataModelBuilder</kbd> to use; if null, a default <kbd>DataModel</kbd> implementation will be used</li>
<li><kbd>DataModel</kbd>: This is the dataset that will be used for testing</li>
<li><kbd>trainingPercentage</kbd>: This indicates the percentage of each user's preferences to use to produce recommendations; the rest are compared to estimated preference values in order to evaluate the <span>performance of the</span> <kbd>recommender</kbd> </li>
<li><kbd>evaluationPercentage</kbd>: This is the percentage of users to be used in the evaluation</li>
</ul>
<p>The method is called as follows:</p>
<pre>double result = evaluator.evaluate(builder, null, model, 0.9, <br/>   1.0); 
System.out.println(result); </pre>
<p>The method returns a <kbd>double</kbd>, where <kbd>0</kbd> represents the best possible evaluation, meaning that the recommender perfectly matches user preferences. In general, the lower the value, the better the match.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Online learning engine</h1>
                </header>
            
            <article>
                
<p>In any online platform, the new users will continue increasing. The previously discussed approach works well for the existing user. It is expensive to create a recommendation instance for every new user that's added. We cannot ignore the users that have been added to the system after the recommendation engine is made. To cope with situations that are similar to this, Apache Mahout has the ability of adding a temporary user to a data model.<br/>
The general setup is as follows:</p>
<ul>
<li>Periodically recreate the whole recommendation using current data (for example, each day or hour, depending on how long it takes)</li>
<li>Always check whether the user exists in the system before going for a recommendation</li>
<li>If the user exists, then complete the recommendations</li>
<li>If the user does not exist, create a temporary user, fill in the preferences, and do the recommendation</li>
</ul>
<p>The first step seems to be tricky, in regards to how frequently the whole recommendation is to be generated using the current data. If the system is huge, memory constraints will be there, because when the new recommender is being generated, the old, working recommender should be held in memory, so the request is being served from the old copy until the new recommender is ready.</p>
<p>As for the temporary users, we can wrap our data model with a <kbd>PlusAnonymousConcurrentUserDataModel</kbd> instance. This class allows us to obtain a temporary user ID; the ID must later be released so that it can be reused (there's a limited number of such IDs). After obtaining the ID, we have to fill in the preferences, and then we can proceed with the recommendation, as always:</p>
<pre>class OnlineRecommendation{ 
 
  Recommender recommender; 
  int concurrentUsers = 100; 
  int noItems = 10; 
 
  public OnlineRecommendation() throws IOException { 
     
     
    DataModel model = new StringItemIdFileDataModel( 
      new File /chap6/BX-Book-Ratings.csv"), ";"); 
    PlusAnonymousConcurrentUserDataModel plusModel = new <br/>       PlusAnonymousConcurrentUserDataModel<br/>         (model, concurrentUsers); 
    recommender = ...; 
     
  } 
   
  public List&lt;RecommendedItem&gt; recommend(long userId, <br/>     PreferenceArray preferences){ 
     
    if(userExistsInDataModel(userId)){ 
      return recommender.recommend(userId, noItems); 
    } 
     
    else{ 
       
      PlusAnonymousConcurrentUserDataModel plusModel = 
        (PlusAnonymousConcurrentUserDataModel) <br/>           recommender.getDataModel(); 
       
      // Take an available anonymous user form the poll 
      Long anonymousUserID = plusModel.takeAvailableUser(); 
       
      // Set temporary preferences 
      PreferenceArray tempPrefs = preferences; 
      tempPrefs.setUserID(0, anonymousUserID); 
      tempPrefs.setItemID(0, itemID); 
       plusModel.setTempPrefs(tempPrefs, anonymousUserID); 
       
      List&lt;RecommendedItem&gt; results = <br/>         recommender.recommend(anonymousUserID, noItems); 
       
      // Release the user back to the poll 
      plusModel.releaseUser(anonymousUserID); 
       
      return results; 
 
    } 
     
  } 
} </pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Content-based filtering</h1>
                </header>
            
            <article>
                
<p>Content-based filtering is out of the scope of the Mahout framework, mainly because it is up to you to decide how to define similar items. If we want to do a content-based item similarity, we need to implement our own <kbd>ItemSimilarity</kbd>. For instance, in our book's dataset, we might want to make up the following rule for book similarity:</p>
<ul>
<li>If the genres are the same, add <kbd>0.15</kbd> to <kbd>similarity</kbd></li>
<li>If the author is the same, add <kbd>0.50</kbd> to <kbd>similarity</kbd></li>
</ul>
<p>We can now implement our own <kbd>similarity</kbd> measure, as follows:</p>
<pre>class MyItemSimilarity implements ItemSimilarity { 
 ... 
 public double itemSimilarity(long itemID1, long itemID2) { 
  MyBook book1 = lookupMyBook (itemID1); 
  MyBook book2 = lookupMyBook (itemID2); 
  double similarity = 0.0; 
  if (book1.getGenre().equals(book2.getGenre())  
   similarity += 0.15; 
  } 
  if (book1.getAuthor().equals(book2. getAuthor ())) { 
   similarity += 0.50; 
  } 
  return similarity; 
 } 
 ... 
} </pre>
<p>We can then use this <kbd>ItemSimilarity</kbd>, instead of something like <kbd>LogLikelihoodSimilarity</kbd>, or other implementations with a <kbd>GenericItemBasedRecommender</kbd>. That's about it. This is as far as we have to go to perform content-based recommendations in the Mahout framework.</p>
<p>What we saw here is one of the simplest forms of content-based recommendation. Another approach would be to create a content-based profile of users, based on a weighted vector of item features. The weights denote the importance of each feature to the user, and can be computed from individually-rated content vectors.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, you learned about the basic concept of recommendation engines, the differences between collaborative and content-based filtering, and how to use Apache Mahout, which is a great basis for creating recommenders, as it is very configurable and provides many extension points. We looked at how to pick the right configuration parameter values, set up rescoring, and evaluate the recommendation results.</p>
<p>With this chapter, we have completed our overview of the data science techniques that are used to analyze customer behavior, which started with customer relationship prediction in <a href="6ac8d4de-1e7f-4f60-9cf0-93ab2fe55e4d.xhtml"><span class="ChapterrefPACKT">Chapter 4</span></a>, <em>Customer Relationship Prediction with Ensembles</em>, and continued with affinity analytics in <a href="21e9de6d-720b-416a-bb9c-4c16541d97a9.xhtml"><span class="ChapterrefPACKT">Chapter 5</span></a>, <em>Affinity Analysis</em>. In the next chapter, we will move on to other topics, such as fraud and anomaly detection.</p>


            </article>

            
        </section>
    </div>



  </body></html>