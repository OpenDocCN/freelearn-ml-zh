["```py\n    import pandas as pd\n    import numpy as np\n    from imblearn.pipeline import make_pipeline\n    from sklearn.model_selection import RandomizedSearchCV,\\\n      RepeatedStratifiedKFold\n    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.feature_selection import SelectKBest, chi2\n    from scipy.stats import randint\n    import sklearn.metrics as skmet\n    from sklearn.model_selection import cross_validate\n    import os\n    import sys\n    sys.path.append(os.getcwd() + \"/helperfunctions\")\n    import healthinfo as hi\n    ```", "```py\n    X_train = hi.X_train\n    X_test = hi.X_test\n    y_train = hi.y_train\n    y_test = hi.y_test\n    new_cols = hi.new_cols\n    new_cols\n    array(['smoking_Yes', 'alcoholdrinkingheavy_Yes',\n           'stroke_Yes', 'walkingdifficult_Yes',\n           'physicalactivity_Yes', 'asthma_Yes',\n           'kidneydisease_Yes', 'skincancer_Yes',\n           'gender_Male', 'ethnicity_Asian',\n           'ethnicity_Black', 'ethnicity_Hispanic',\n           'ethnicity_Other', 'ethnicity_White',\n           'agecategory', 'genhealth', 'diabetic', 'bmi',\n           'physicalhealthbaddays', 'mentalhealthbaddays',\n           'sleeptimenightly'], dtype=object)\n    ```", "```py\nknn_example = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\nkf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=0)\npipe0 = make_pipeline(hi.coltrans, hi.smotenc, knn_example)\nscores = cross_validate(pipe0, X_train,\n  y_train.values.ravel(), \\\n  scoring=['accuracy','precision','recall','f1'], \\\n  cv=kf, n_jobs=-1)\nprint(\"accuracy: %.2f, sensitivity: %.2f, precision: %.2f, f1: %.2f\"  %\n  (np.mean(scores['test_accuracy']),\\\n  np.mean(scores['test_recall']),\\\n  np.mean(scores['test_precision']),\\\n  np.mean(scores['test_f1'])))\naccuracy: 0.73, sensitivity: 0.56, precision: 0.17, f1: 0.26\n```", "```py\n    knn = KNeighborsClassifier(n_jobs=-1)\n    pipe1 = make_pipeline(hi.coltrans, hi.smotenc,\n       SelectKBest(score_func=chi2), knn)\n    knn_params = {\n     'selectkbest__k':\n        randint(1, len(new_cols)),\n     'kneighborsclassifier__n_neighbors':\n        randint(5, 300),\n     'kneighborsclassifier__metric':\n        ['euclidean','manhattan','minkowski']\n    }\n    ```", "```py\n    rs = RandomizedSearchCV(pipe1, knn_params, cv=5, scoring=\"roc_auc\")\n    rs.fit(X_train, y_train.values.ravel())\n    ```", "```py\n    selected = rs.best_estimator_['selectkbest'].\\\n      get_support()\n    selected.sum()\n    11\n    new_cols[selected]\n    array(['smoking_Yes', 'alcoholdrinkingheavy_Yes',\n           'walkingdifficult_Yes', 'ethnicity_Black',\n           'ethnicity_Hispanic', 'agecategory',\n           'genhealth', 'diabetic', 'bmi',\n           'physicalhealthbaddays','mentalhealthbaddays'],\n          dtype=object)\n    ```", "```py\n    rs.best_params_\n    {'kneighborsclassifier__metric': 'manhattan',\n     'kneighborsclassifier__n_neighbors': 251,\n     'selectkbest__k': 11}\n    rs.best_score_\n    0.8030553205304845\n    ```", "```py\n    pred = rs.predict(X_test)\n    print(\"accuracy: %.2f, sensitivity: %.2f, specificity: %.2f, precision: %.2f\"  %\n      (skmet.accuracy_score(y_test.values.ravel(), pred),\n      skmet.recall_score(y_test.values.ravel(), pred),\n      skmet.recall_score(y_test.values.ravel(), pred, \n        pos_label=0),\n      skmet.precision_score(y_test.values.ravel(), pred)))\n    accuracy: 0.67, sensitivity: 0.82, specificity: 0.66, precision: 0.18\n    ```", "```py\n    cm = skmet.confusion_matrix(y_test, pred)\n    cmplot = skmet.ConfusionMatrixDisplay(\n      confusion_matrix=cm,\n      display_labels=['Negative', 'Positive'])\n    cmplot.plot()\n    cmplot.ax_.set(title='Heart Disease Prediction Confusion Matrix', \n      xlabel='Predicted Value', ylabel='Actual Value')\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n    from imblearn.pipeline import make_pipeline\n    from sklearn.impute import SimpleImputer\n    from sklearn.compose import ColumnTransformer\n    from sklearn.model_selection import RandomizedSearchCV\n    from sklearn.neighbors import KNeighborsClassifier\n    from imblearn.over_sampling import SMOTENC\n    from sklearn.feature_selection import SelectKBest, chi2\n    import sklearn.metrics as skmet\n    import os\n    import sys\n    sys.path.append(os.getcwd() + \"/helperfunctions\")\n    from preprocfunc import OutlierTrans\n    ```", "```py\n    machinefailuretype = pd.read_csv(\"data/machinefailuretype.csv\")\n    machinefailuretype.info()\n    <class 'pandas.core.frame.DataFrame'>\n    RangeIndex: 10000 entries, 0 to 9999\n    Data columns (total 10 columns):\n     #   Column               Non-Null Count  Dtype\n    ---  ------               --------------  -----  \n     0   udi                  10000 non-null  int64\n     1   product              10000 non-null  object \n     2   machinetype          10000 non-null  object \n     3   airtemp              10000 non-null  float64\n     4   processtemperature   10000 non-null  float64\n     5   rotationalspeed      10000 non-null  int64\n     6   torque               10000 non-null  float64\n     7   toolwear             10000 non-null  int64\n     8   fail                 10000 non-null  int64\n     9   failtype             10000 non-null  object \n    dtypes: float64(3), int64(4), object(3)\n    memory usage: 781.4+ KB\n    ```", "```py\n    machinefailuretype.head()\n       udi product machinetype airtemp processtemperature\\\n    0   1   M14860      M         298         309 \n    1   2   L47181      L         298         309 \n    2   3   L47182      L         298         308 \n    3   4   L47183      L         298         309 \n    4   5   L47184      L         298         309 \n     Rotationalspeed  Torque  toolwear  fail   failtype\n    0      1551         43         0      0    No Failure\n    1      1408         46         3      0    No Failure\n    2      1498         49         5      0    No Failure\n    3      1433         40         7      0    No Failure\n    4      1408         40         9      0    No Failure\n    ```", "```py\n    machinefailuretype.failtype.value_counts(dropna=False).sort_index()\n    Heat Dissipation Failure  112\n    No Failure                9652\n    Overstrain Failure        78\n    Power Failure             95\n    Random Failures           18\n    Tool Wear Failure         45\n    Name: failtype, dtype: int64\n    machinefailuretype.machinetype.\\\n      value_counts(dropna=False).sort_index()\n    H      1003\n    L      6000\n    M      2997\n    Name: machinetype, dtype: int64\n    ```", "```py\n    def setcode(typetext):\n      if (typetext==\"No Failure\"):\n        typecode = 1\n      elif (typetext==\"Heat Dissipation Failure\"):\n        typecode = 2\n      elif (typetext==\"Power Failure\"):\n        typecode = 3\n      elif (typetext==\"Overstrain Failure\"):\n        typecode = 4\n      else:\n        typecode = 5\n      return typecode\n    machinefailuretype[\"failtypecode\"] = \\\n      machinefailuretype.apply(lambda x: setcode(x.failtype), axis=1)\n    machinefailuretype.groupby(['failtypecode','failtype']).size().\\\n      reset_index()\n       failtypecode  failtype                   0\n    0   1            No Failure                 9652\n    1   2            Heat Dissipation Failure   112\n    2   3            Power Failure              95\n    3   4            Overstrain Failure         78\n    4   5            Random Failures            18\n    5   5            Tool Wear Failure          45\n    ```", "```py\n    num_cols = ['airtemp', 'processtemperature',\n      'rotationalspeed', 'torque', 'toolwear']\n    cat_cols = ['machinetype']\n    machinefailuretype[num_cols].agg(['min','median','max']).T\n                           min       median       max\n    airtemp                295       300          304\n    processtemperature     306       310          314\n    rotationalspeed        1,168     1,503        2,886\n    torque                 4         40           77\n    toolwear               0         108          253\n    ```", "```py\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(machinefailuretype[num_cols + cat_cols],\\\n      machinefailuretype[['failtypecode']], test_size=0.2, random_state=0)\n    ```", "```py\n    ohe = OneHotEncoder(drop='first', sparse=False)\n    cattrans = make_pipeline(ohe)\n    standtrans = make_pipeline(\n      OutlierTrans(3),SimpleImputer(strategy=\"median\"),\n      MinMaxScaler())\n    coltrans = ColumnTransformer(\n      transformers=[\n        (\"cat\", cattrans, cat_cols),\n        (\"stand\", standtrans, num_cols),\n      ]\n    )\n    ```", "```py\n    coltrans.fit(X_train.sample(1000))\n    new_cat_cols = \\\n      coltrans.\\\n      named_transformers_['cat'].\\\n      named_steps['onehotencoder'].\\\n      get_feature_names(cat_cols)\n    new_cols = np.concatenate((new_cat_cols, np.array(num_cols)))\n    print(new_cols)\n    ['machinetype_L' 'machinetype_M' 'airtemp' \n    'processtemperature' 'rotationalspeed' 'torque' \n    'toolwear']\n    ```", "```py\n    catcolscnt = new_cat_cols.shape[0]\n    smotenc = SMOTENC(categorical_features=np.arange(0,catcolscnt), random_state=0)\n    knn = KNeighborsClassifier(n_jobs=-1)\n    pipe1 = make_pipeline(coltrans, smotenc, SelectKBest(score_func=chi2), knn)\n    ```", "```py\n    knn_params = {\n     'selectkbest__k': np.arange(1, len(new_cols)),\n     'kneighborsclassifier__n_neighbors': np.arange(5, 175, 2),\n     'kneighborsclassifier__metric': ['euclidean','manhattan','minkowski']\n    }\n    rs = RandomizedSearchCV(pipe1, knn_params, cv=5, scoring=\"roc_auc_ovr_weighted\")\n    rs.fit(X_train, y_train.values.ravel())\n    ```", "```py\n    selected = rs.best_estimator_['selectkbest'].get_support()\n    selected.sum()\n    6\n    new_cols[selected]\n    array(['machinetype_L', 'machinetype_M', 'airtemp', \n           'rotationalspeed', 'torque', 'toolwear'], \n           dtype=object)\n    rs.best_params_\n    {'selectkbest__k': 6,\n     'kneighborsclassifier__n_neighbors': 125,\n     'kneighborsclassifier__metric': 'minkowski'}\n    rs.best_score_\n    0.899426752716227\n    ```", "```py\n    pred = rs.predict(X_test)\n    cm = skmet.confusion_matrix(y_test, pred)\n    cmplot = skmet.ConfusionMatrixDisplay(confusion_matrix=cm,\n       display_labels=['None', 'Heat','Power','Overstrain','Other'])\n    cmplot.plot()\n    cmplot.ax_.set(title='Machine Failure Type Confusion Matrix', \n      xlabel='Predicted Value', ylabel='Actual Value')\n    ```", "```py\n    print(skmet.classification_report(y_test, pred,\n      target_names=\\\n      ['None', 'Heat','Power','Overstrain','Other']))\n                  Precision  recall  f1-score  support\n            None  0.99       0.71    0.83      1927\n            Heat  0.11       0.90    0.20      21\n           Power  0.15       0.61    0.24      18\n      Overstrain  0.36       0.76    0.49      21\n           Other  0.01       0.31    0.02      13\n        accuracy                     0.71      2000\n       macro avg  0.33       0.66    0.36      2000\n    weighted avg  0.96       0.71    0.81      2000\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from sklearn.model_selection import StratifiedKFold, \\\n      GridSearchCV\n    from sklearn.neighbors import KNeighborsClassifier\n    import sklearn.metrics as skmet\n    from scipy.stats import randint\n    ```", "```py\n    letterrecognition = pd.read_csv(\"data/letterrecognition.csv\")\n    letterrecognition.shape\n    (20000, 17)\n    letterrecognition.head().T\n                0     1     2     3     4\n    letter      T     I     D     N     G\n    xbox        2     5     4     7     2\n    ybox        8     12    11    11    1\n    width       3     3     6     6     3\n    height      5     7     8     6     1\n    onpixels    1     2     6     3     1\n    xbar        8     10    10    5     8\n    ybar        13    5     6     9     6\n    x2bar       0     5     2     4     6\n    y2bar       6     4     6     6     6\n    xybar       6     13    10    4     6\n    x2ybar      10     3    3     4     5\n    xy2bar      8     9     7     10    9\n    x-ege       0     2     3     6     1\n    xegvy       8     8     7     10    7\n    y-ege       0     4     3     2     5\n    yegvx       8     10    9     8     10\n    ```", "```py\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(letterrecognition.iloc[:,1:],\\\n      letterrecognition.iloc[:,0:1], test_size=0.2, \n      random_state=0)\n    ```", "```py\n    knn = KNeighborsClassifier(n_jobs=-1)\n    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n    knn_params = {\n      'n_neighbors': np.arange(3, 41, 2),\n      'metric': ['euclidean','manhattan','minkowski']\n    }\n    ```", "```py\n    gs = GridSearchCV(knn, knn_params, cv=kf, scoring='accuracy')\n    gs.fit(X_train, y_train.values.ravel())\n    gs.best_params_\n    {'metric': 'euclidean', 'n_neighbors': 3}\n    gs.best_score_\n    0.9470625\n    ```", "```py\n    pred = gs.best_estimator_.predict(X_test)\n    letters = np.sort(letterrecognition.letter.unique())\n    cm = skmet.confusion_matrix(y_test, pred)\n    cmplot = \\\n      skmet.ConfusionMatrixDisplay(confusion_matrix=cm,\n      display_labels=letters)\n    cmplot.plot()\n    cmplot.ax_.set(title='Letters', \n      xlabel='Predicted Value', ylabel='Actual Value')\n    ```"]