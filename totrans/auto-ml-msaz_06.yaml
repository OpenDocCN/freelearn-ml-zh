- en: '*Chapter 4*: Building an AutoML Regression Solution'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You've taken the first step to becoming an Azure AutoML expert by building a
    solution with the AutoML guided user interface. Now, it's time to level up your
    skills by creating a solution with the **Azure Machine Learning Python Software
    Development Kit** (**AzureML Python SDK**). Using the Diabetes dataset that we
    built in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023), *Getting Started
    with Azure Machine Learning Service*, you will build a regression solution to
    predict how much a person's diabetes disease has advanced over the last year.
  prefs: []
  type: TYPE_NORMAL
- en: You will begin this chapter by opening up a Jupyter notebook from your compute
    instance, which will let you write Python code. First, you will load in the Diabetes
    data. Then, you will train an AutoML model and register your trained model to
    your **Azure Machine Learning Service (AMLS)** workspace. You will accomplish
    this by using easily reusable Python scripts. After examining your model's results,
    you will learn how to register your model so that it can be optimized for a variety
    of regression-specific metrics and fine-tune your solution to improve performance.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have full mastery and knowledge of Azure
    AutoML's regression capabilities and be able to train regression models using
    your own data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing data for AutoML regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training an AutoML regression model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Registering your trained regression model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning your AutoML regression model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the prerequisites for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Access to the internet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A web browser, preferably Google Chrome or Microsoft Edge Chromium
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Microsoft Azure account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Azure Machine Learning service workspace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `titanic-compute-instance` compute instance from [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `compute-cluster` compute cluster from [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Diabetes Sample` dataset from [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code for this chapter is available here: [https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Chapter04/Chapter-4-AutoML-on-Azure.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Chapter04/Chapter-4-AutoML-on-Azure.ipynb).'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing data for AutoML regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before you can train any model with AutoML, you must have a properly cleansed
    dataset. This section will walk you through how to prepare data for any AutoML
    regression solution. You will begin by using your compute instance to access Jupyter
    notebook, a code editor that will let you code in Python. Following that, you
    will cleanse, transform, and register your data as an Azure dataset. This will
    give you a dataset that's ready for training in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Some of you may be new to Python or even to coding in general, but don't worry.
    While scripting an AutoML solution may seem much more difficult than using the
    *GUI*, in reality, it's a matter of making slight changes to boilerplate code.
  prefs: []
  type: TYPE_NORMAL
- en: Using the code found in this book's GitHub repository, you only have to alter
    it slightly to adapt it to your own custom solution using your own custom data.
    Furthermore, for this exercise, you've already completed most of the prerequisites.
    You have your **compute instance**, **compute cluster**, and **dataset** ready,
    and you're only a few lines of code away from being ready to train an AutoML regression
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up your Jupyter environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To write code yourself, you must open a Jupyter notebook. **Jupyter notebook**
    is an environment where you can write, edit, and run Python code. **Python** is
    a general-purpose programming language that is extremely popular among machine
    learning practitioners and forms the basis of the Azure Machine Learning service.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will teach you how to access a Jupyter notebook environment
    through your Azure compute instance. You will then learn how to create a notebook
    within this environment that will allow you to script your AutoML regression solution:'
  prefs: []
  type: TYPE_NORMAL
- en: First, open Azure Machine Learning Studio by navigating to [http://ml.azure.com](http://ml.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you are in the studio, click **Compute** on the right-hand side of the
    studio, under **Manage**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If your compute instance is currently paused, check the circular checkbox next
    to `titanic-compute-instance` and click the **Start** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, click **Jupyter** under **Application URI**, as shown in *Figure 4.1*:![Figure
    4.1 – Accessing your Jupyter environment ](img/B16595_4_01.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 4.1 – Accessing your Jupyter environment
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once you have accessed your Jupyter environment, the next step is to create
    a Jupyter notebook. You can create as many Jupyter notebooks as you like, and
    you can also use this environment to upload and download files, create folder
    structures, and run both Python and R scripts. **R** is another programming language
    that is popular with machine learning practitioners, but we will not cover it
    in this book.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **New** in the upper right-hand corner of your screen to access the drop-down
    menu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Python 3.6 – AzureML** from the drop-down menu, as shown in the *Figure
    4.2*:![Figure 4.2 – Creating a Jupyter notebook ](img/B16595_4_02.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 4.2 – Creating a Jupyter notebook
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the new Jupyter notebook that appears in the top-left corner of your screen;
    that is, `Untitled.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Rename `Untitled.ipynb` to `Diabetes_Regression_AutoML` by clicking `Diabetes_Regression_AutoML`
    into the resulting textbox, and clicking **Rename**, as shown in *Figure 4.3*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Renaming your Jupyter notebook ](img/B16595_4_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – Renaming your Jupyter notebook
  prefs: []
  type: TYPE_NORMAL
- en: By creating and renaming your Jupyter notebook, you are now ready to begin coding
    in Python. This is also a step-by-step, repeatable process that consists of mostly
    boilerplate code. **Boilerplate** refers to code that can be reused from project
    to project and requires little to no customization. As such, you can write Azure
    AutoML scripts with next to no Python experience.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing your data for AutoML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every AutoML script begins exactly the same way. First, you load in your Python
    libraries. **Libraries** are simply collections of useful functions that let you
    complete complex tasks without having to write complicated code yourself. Then,
    you must set your **workspace, datastore, compute cluster,** and **dataset**.
    Once you've done this, manipulate your data if necessary and save it to a new
    dataset. If this is not necessary, simply move on to the *Training an AutoML regression
    model* section after loading your dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following steps, you will load all the necessary libraries you''ll need
    to run the entire notebook from start to finish. These libraries are sufficient
    to run the data preparation, model training, and model registration portions of
    this chapter. You will then load the Diabetes dataset you created previously in
    [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023)*, Getting Started with Azure
    Machine Learning Service*. After loading the data, you will make some slight data
    transformations before registering it as a new dataset. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load in all the libraries you will need to run everything in this chapter by
    using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`Workspace` lets you connect to your `Dataset` and `Datastore` let you access
    your previously created datasets and datastores, while `Experiment` lets you log
    the results of your AutoML.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`ComputeTarget` lets you use your compute cluster to run your AutoML job. On
    the other hand, `AutoMLConfig` enables you to configure your run, while `AutoMLRun`
    is necessary to train your model. Finally, `RunDetails` lets you track your job
    in real time.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Load in `pandas`, in particular, is necessary to view the data in your dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Connect your Jupyter notebook to your AMLS workspace by using the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your compute cluster to the one you created in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023)*,
    Getting Started with Azure Machine Learning Service*, by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your datastore by using the following code. For this exercise, we will
    use the `workspaceblobstore` with the name of your datastore:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your dataset by using the following code. Use the `Diabetes Sample` dataset
    you created in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023)*, Getting
    Started with Azure Machine Learning Service*, for this. You can reuse this code
    by replacing the name shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For this code, you will always need to use the latest version of your dataset.
    If you wish to use an earlier version of your dataset, you can replace `'latest'`
    with a number.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'View the first 10 rows of your data, as shown in the following screenshot,
    by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Whenever you view your data, it's important that you make sure the data looks
    correct. Verify that the columns have names that match what you expect. Make sure
    that the values are of the correct type, numeric or string, and that the values
    themselves look appropriate. If you see a number higher than 120 in the `AGE`
    column, for example, you may have problems in the dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you do find any inconsistencies within your data, it is important that you
    fix them before training a model with AutoML. Leaving string values in columns
    that should be numeric will cause AutoML to treat those columns as categorical.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In some cases, this will result in inferior performance. Likewise, leaving errors
    in your data may result in models that fail to make accurate predictions. As the
    old data science saying goes, "*Garbage in, garbage out*." Always inspect your
    data to make sure it's not garbage.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output should resemble *Figure 4.4*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Viewing your dataset ](img/B16595_4_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 4.4 – Viewing your dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If you wish to change anything about your data, use pandas to do so by converting
    your dataset into a pandas DataFrame using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'One common thing you may want to do is drop columns. You should drop any columns
    that are derived from the field that you are trying to predict that contain nearly
    all null values, or that will not be available when you''re processing new data.
    For example, if you don''t know the new patient''s `Sex` and `Age`, you can use
    the pandas `drop` function, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reregister your altered data and give the dataset a new name; that is, `Diabetes
    Sample Age/Sex Dropped`. Using the following code, you can save your altered pandas
    DataFrame to your datastore:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Another common transformation you may want to try is binning. `Age` column
    into three different groups: children younger than 18 years old, adults between
    the ages of 18 to 64, and seniors older than 64 years old. The following code
    illustrates this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Data scientists can also remove outliers. `Age` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'One last common data transformation is creating categorical columns from numeric
    columns based on cutoff points. Obesity is defined as having a BMI of 30 or greater.
    We can make a column, `Obesity_Flag`, that contains a `1` or `0` value to indicate
    whether an individual is obese with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once again, save your altered data to your datastore and register it as a dataset
    called `Diabetes Sample Full Transform` by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You have accomplished a lot in this section. Your libraries have been loaded
    in, your workspace has been set, and you have all the necessary resources coded
    to easily create an AutoML run. Additionally, you have multiple versions of your
    Diabetes data saved as different datasets that you will use to train three AutoML
    models in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Training an AutoML regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Compared to setting up your Jupyter environment and preparing your data, training
    an AutoML model involves fewer steps. First, you will need to set a name for your
    **experiment**. Remember that experiments automatically log information about
    your AutoML runs. Next, you will need to set your **Target** column, which is
    the column you wish to predict, and a few other settings. Finally, you will use
    AutoML to train a model and watch the results in real time.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, you will create an experiment, configure the various parameters
    and settings specific to AutoML regression tasks, and train three AutoML regression
    models using the datasets you created in the previous section. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Set `Experiment` and give it a name by using the following code. This is where
    all of the logs and metrics of your run will be stored in the AML studio:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your `Target` column with the following code. AutoML will train a model
    that predicts the value of this column – in this case, the `Y` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable for your `task` using the following code. `task` is the type
    of AutoML model you are trying to train, and the options for this are regression,
    forecasting, and classification. For predicting numeric values that do not have
    a time element, enter `regression`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you are trying to predict data that has a time element, use *forecasting*
    instead of *regression*. If `date` is one of your columns or you are trying to
    predict future values based on the current situation, use *forecasting*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a variable for your primary metric. This **primary metric** is how your
    model will be scored. You should use **normalized root mean squared error** here.
    This metric, referred to as **RSME**, takes the prediction and subtracts it from
    the actual value for each observation, squares it, and averages the score across
    all observations. The lower the score, the better your model. Other options for
    regression include **R2 score**, **Spearman correlation**, and **normalized mean
    absolute error**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following code creates a variable and sets it to normalized RMSE. This
    variable will be passed into your AutoML configuration settings later:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a variable for `featurization`. You can set featurization to `auto` or
    `off`. If you set featurization to `auto`, you will have to drop high-cardinality
    features, impute null values, one-hot encode your data, and generate additional
    features yourself.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Always set it to `auto` unless you are an expert data scientist and are comfortable
    doing everything yourself. The following code also creates a new variable that
    you will pass into your AutoML configuration settings:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To configure your AutoML, run the following code. Here, you will pass in your
    task, primary metric, featurization settings, compute target, dataset, and target
    column. You created all of these previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You must also pass in how long the experiment will run for, whether it will
    stop early if the model''s performance does not improve, the number of cross-validations,
    and whether your experiment will record model explanations. `5` and `20`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Train your model and watch the results in real time. The following code trains
    the AutoML model with your configuration settings and logs the results of the
    run to the experiment you created earlier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As it runs, this code will allow you to track the progress of your session
    in real time. Here, you can watch AutoML check the validity of your data, train
    models iteratively, and select the best model:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you''ve done everything correctly, your AutoML run will kick off and you
    can sit back, relax, and watch it train models. First, you will see it perform
    a **data guardrails** check, as shown in *Figure 4.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Data guardrails check ](img/B16595_4_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 – Data guardrails check
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, AutoML will start training your models. You will notice that AutoML will
    train different combinations of feature transformations and algorithms. In cases
    where an identical feature transformation/algorithm pair is replicated, AutoML
    tests different hyperparameter combinations for that algorithm. As it runs, you
    will be able to track how long each model took to train, how well it scored, and
    the score of the best-performing model, as shown in *Figure 4.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – AutoML results ](img/B16595_4_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 – AutoML results
  prefs: []
  type: TYPE_NORMAL
- en: Notice how the AutoML trained models do not progressively get better with each
    run. The first model that was trained has a normalized RMSE of `0.1808`. The third
    model trained has a score of `0.2027`. With normalized RMSE, the lower your score,
    the better.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the experiment, the best model has a score of `0.1682`. When you
    run the model, you should see similar, but not exact, results, depending on which
    models AutoML trains. While you can see which models and transformations are being
    used under the `PIPELINE` column, hyperparameters remain hidden due to their large
    number for some algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: You can also get a visualization of these results, as shown in the following
    graph. Given enough time, you will notice that AutoML gets better and better.
    This is because it's following its own internal logic of trying different feature
    engineering/algorithm pairs until it can no longer find a higher-performing model,
    upon which AutoML will finish with two ensemble algorithms and end the run.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, either `Diabetes Sample Age/Sex Dropped` dataset and another
    using the `Diabetes Sample Full Transform` dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 4.7* provides a visualization of the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – AutoML results visualized](img/B16595_4_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 – AutoML results visualized
  prefs: []
  type: TYPE_NORMAL
- en: In addition to these two charts, both of which can be found in your Jupyter
    notebook, there are two more visualizations you can access via AML studio. These
    are the **Predicted vs True** graph and your **Residuals** histogram. *Predicted
    vs True* shows you how well your model performed versus an ideal model, whereas
    *Residuals* gives you an idea of whether your errors are normally distributed
    or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can access these graphs by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the front page of AML studio.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Models** on the left-hand panel, under **Assets**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click `Diabetes-AllData-Regression-AutoML`. This is the name of the model you
    trained.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the blue link under **Run ID**. It should begin with AutoML, followed
    by a long string of letters and digits. This is the ID that your experiment was
    logged under.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Metrics**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the boxes for **predicted_true** and **residuals**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Predicted vs True* shows you how well your predictions performed against a
    model that predicts every data point perfectly. The horizontal axis represents
    your true values, whereas the vertical axis represents your predicted values.
    Likewise, the dotted green line represents the perfect model, while the solid
    blue line represents your actual model. There are also light-blue boundaries around
    your actual model, showing you the confidence interval. Confidence intervals estimate
    a range of how well your model would perform in the real world. Please carefully
    examine *Figure 4.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 – Predicted vs. True graph ](img/B16595_4_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 – Predicted vs. True graph
  prefs: []
  type: TYPE_NORMAL
- en: '*Residuals*, on the other hand, is a histogram that bins your error values
    and counts the number of data points in each bin. Error is simply how far off
    your predicted value was from the true value. For example, in *Figure 4.9*, we
    can see that there about 100 data points where the error fell between -38.5 and
    0, and about 115 data points where the error fell between 0 and 38.5\.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When examining this chart, you should make sure that it''s bell-shaped. If
    your chart isn''t bell-shaped, this means that something is causing a pattern
    in your errors and that you need to investigate the cause; usually, this means
    you are missing an important variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9 – Residuals ](img/B16595_4_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.9 – Residuals
  prefs: []
  type: TYPE_NORMAL
- en: Although you have trained a high-performing machine learning model with AutoML,
    your work is not over yet. Ultimately, a machine learning model is only useful
    if you can use it to predict new data points. The past is the past, after all,
    and business value always lies in future situations.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, you are trying to predict patient outcomes so that you can identify
    and preemptively treat patients whose disease will progress the most quickly.
    To do so, you must first register your model for future use. We will look at this
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Registering your trained regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AutoML lets you easily register your trained models for future use. In [*Chapter
    9*](B16595_09_ePub.xhtml#_idTextAnchor129)*, Implementing a Batch Scoring Solution*,
    and [*Chapter 11*](B16595_11_ePub.xhtml#_idTextAnchor172)*, Implementing a Real-Time
    Scoring Solution*, you will create batch execution inference pipelines and real-time
    scoring endpoints that will use your models. When registering your model, you
    can add tags and descriptions for easier tracking.
  prefs: []
  type: TYPE_NORMAL
- en: One especially useful feature is the ability to register models based on metrics
    other than the one you used to score your model. Thus, even though you trained
    a model using normalized RMSE, you can also register the model that had the best
    R2 score, even if that model is different.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, you will write a simple description of your model, tag it,
    and give it a name. After that, you will register the model to your AMLS workspace.
    It also contains code that will let you register different models based on other
    metrics. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, give your model a name, a description, and some tags. `tags` as you
    wish and feel free to be verbose in your description:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, register your model to your AMLS workspace, passing in your model''s
    name, tags, and description. Use the `AutoML_run` process you trained in the previous
    section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If time has elapsed since the time you trained your AutoML model, you can retrieve
    it by finding its `AutoML_run` using this ID, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`experiment_name = ''Diabetes-Sample-Regression''`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`exp = Experiment(workspace=ws, name=experiment_name)`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`AutoML_run = AutoMLRun(experiment = exp, run_id = ''your_run_id'')`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Try registering a different model based on R2 score. Give it a slightly different
    name, add an additional tag, and use an identical description:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With that, your model has been registered and is ready for use. You have created
    a regression model that can be used to identify how diabetes is likely to progress
    in a patient over a 1-year period based on their gender, age, blood pressure,
    BMI, and six blood serum measurements. Try registering other AutoML models you've
    trained using the other datasets you created in this chapter. Give them appropriate
    tags, names, and descriptions that differentiate them.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to emphasize the importance of a good tagging strategy and robust
    descriptions. As you are working on a machine learning project, it's not such
    a big deal, as you will remember which models you trained and what datasets you
    trained them with. However, as you move on to other projects and as time passes,
    your memory becomes less and less reliable. If you don't have good tags, locating
    your models becomes a difficult endeavor.
  prefs: []
  type: TYPE_NORMAL
- en: A proper tagging strategy will include the project name, the project creator,
    the metric the model was trained on, the dataset the model was trained with, and
    other pertinent information about the model. There is no need to include a version
    number, as AutoML includes one automatically. If you register a different model
    with the same name, a new version of the model will be registered and the old
    one can still be accessed by specifying its version number.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you''ve registered a few different models, try accessing one using the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Now, you know how to register and call models that you've trained with AutoML.
    With this accomplished, we can move on and look at some tips and tricks that will
    improve your regression models as you train them more in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning your AutoML regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will first review tips and tricks for improving your AutoML
    regression models and then review the algorithms used by AutoML for regression.
  prefs: []
  type: TYPE_NORMAL
- en: Improving AutoML regression models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While AutoML will handle most of the complicated data transformations and feature
    engineering for you, there are a few tips you can follow to increase the accuracy
    of your model. Some of these tips are true across all three AutoML tasks – *regression*,
    *classification*, and *forecasting* – while others are regression-specific. Following
    them will yield higher-performing models and, more importantly, hone your understanding
    of machine learning techniques. I have listed a few tips and tricks here for quick
    reference:'
  prefs: []
  type: TYPE_NORMAL
- en: Fill in null values before passing them on to AutoML. Alternatively, drop any
    rows that contain a null value. Just because AutoML will automatically fill your
    null values does not mean that it will do a great job.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In some situations, filling in null values with the mean of the column is appropriate.
    For example, if you''re missing the price of an item, it''s very likely that the
    mean price will approximate the missing value. For noisier columns, think deeply
    about how you should go about filling in missing values or whether you should
    include those datapoints at all. Here''s some Python code that will fill in null
    values for you:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Become familiar with all of the different AutoML configuration options. You
    can find them at this link: [https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `y_min` and `y_max` to take care of any outliers in your `Target` column.
    If you have values that are outliers, such as values that are `3` or more standard
    deviations away from the mean value of your `Target` column, setting `y_min` and
    `y_max` to `3` standard deviations below and above your mean, respectively, can
    yield better performing models. This only applies to regression models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code calculates the mean and standard deviation of the `Target`
    column and uses them to set `y_min` and `y_max`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Research the four different primary metrics to understand which metrics fit
    your problem best. Normalized RMSE will suffice for most regression problems,
    but many research papers exist on the pros and cons of using other metrics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml)
    to understand what a good regression model looks like. A good model will have
    unbiased residuals, meaning that your model over and under predicts equally. A
    good model will also more closely fit the ideal line in the *Predicted vs True*
    graph shown in *Figure 4.8*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Go to **Experiments** under **Assets** in AML studio, click your experiment's
    name, select your run ID, click the **Models** tab, select the highest-performing
    algorithm, and click the **Metrics** tab. This will provide you with all of the
    different metrics and charts necessary to evaluate your algorithm.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use the `weight_column_name` configuration option to assign a weight
    column to your dataset. If some observations are more important to get right than
    others, assign a higher weight to those observations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, you can assign a weight of 2 to an important observation while
    assigning a weight of 1 to normal observations, thus weighing important observations
    twice as heavily. For example, if you're building an algorithm that predicts electricity
    usage of a factory, you may want to peak usage times more heavily.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Enable longer experiment runtimes to obtain higher-performing models. Sometimes,
    this enables AutoML to find better hyperparameters for the models it trains. Other
    times, increasing the runtime doesn't help so much, but it's always worth giving
    it a try.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If AutoML does not provide a satisfactory model, try adding more data. You can
    add either more historical data (more rows) or additional information (more columns).
    Be careful not to add too many columns to a very small dataset, however, as this
    can lead to overfitting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overfitting** is where you produce a very good model that doesn''t generalize
    to new datapoints. If this happens to you, try adding more historical data or
    removing columns from your dataset.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the end, if, after applying all of these tips and tricks, your model is still
    unsatisfactory, try changing your regression problem to a classification problem.
    Generally, classification problems are easier to solve than regression problems.
    The way you achieve this is by binning your target column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Instead of trying to predict a specific number, your algorithm will try to
    predict a range of numbers instead. You have to be creative for this approach
    to work. For example, with the `Diabetes Sample` dataset, try binning the `Target`
    column using the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Whenever you employ the trick of turning a regression problem into a classification
    problem, keep in mind that the resulting target column must be meaningful. In
    the following screenshot, we can see the values of the `Target` column indicating
    the extent to which the disease has progressed in patients.
  prefs: []
  type: TYPE_NORMAL
- en: If there are substantial, meaningful differences between the four different
    bins, then this is a valid way to approach the problem. However, if the patients
    in each bin do not differ from each other in terms of medical outcome, then you
    should bin the data to make sure patients are lumped together correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 4.10*, we can see the values of the `Target` column indicating the
    extent to which the disease has progressed in patients:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.10 – Results of binning the Diabetes data](img/B16595_4_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.10 – Results of binning the Diabetes data
  prefs: []
  type: TYPE_NORMAL
- en: You are now familiar with many of the little techniques that data scientists
    employ to achieve higher-performing models and solve business problems. This list
    is far from exhaustive, and you will encounter more techniques as you build more
    models with AutoML. Anytime you find some interesting way to improve your model's
    performance, it is important to write it down somewhere and store the code in
    a repository.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever you encounter a difficult problem that seems impossible to solve, reread
    all of the tips in this section, then search your repository. Most of the time,
    with the right data and the right transformations, AutoML will be able to generate
    a solution on par with most data scientists. Other times, it's a matter of fine-tuning
    settings. Sometimes, the only thing you can do is try turning your regression
    problem into a classification problem and try again.
  prefs: []
  type: TYPE_NORMAL
- en: One last thing that will help you use AutoML more efficiently is developing
    an understanding of the algorithms underlying the technology.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding AutoML regression algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AutoML uses many state-of-the-art machine learning algorithms. While it isn't
    necessary for you to understand them in order to use AutoML, learning more about
    them will help you develop as a data scientist. Certain algorithms perform better
    in certain situations. Furthermore, you can group the algorithms into roughly
    five groups.
  prefs: []
  type: TYPE_NORMAL
- en: '**Standard regression algorithms** are those which assign coefficients to your
    explanatory variables in order to predict your target column. AutoML uses two
    of these techniques: **Elastic net** and **LARS** (**least angular regression**)
    **lasso**.'
  prefs: []
  type: TYPE_NORMAL
- en: Elastic net trains a regression model using both L1 and L2 regularization techniques.
    **L1**, also called **lasso**, reduces the coefficients on less important variables
    to 0, while **L2**, called **ridge**, reduces the value of coefficients of less
    important variables. Elastic net combines both techniques to create simpler models
    that are easier to explain while not dropping as many variables as lasso regression.
    LARS lasso is a technique for data with lots of columns that iteratively uses
    the most important columns, but doesn't perform well with noisy data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Tree algorithms** split data based on a series of if-then decision rules,
    resulting in a mapping that resembles a branching tree. As you go further down
    the tree, you eventually reach a point where the algorithm predicts a value based
    on the series of rules it creates. AutoML uses three of these techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Decision tree** is a simple algorithm which is easily explainable but prone
    to overfitting, performing well on training data at the expense of generalizing
    to new data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random forest** creates an ensemble of decision trees and averages them together.
    Each tree is created from a random sample of the training set and columns are
    randomly chosen to create decision rules.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extremely randomized trees** goes one step further by also randomizing the
    values chosen to make splits. This randomness reduces the variance of the models
    when generalized to new data, creating better models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gradient boosting algorithms** work by combining many weak performing decision
    tree models, called **weak learners**, together. These algorithms start by creating
    a single weak leaner, looking for data points on which it doesn''t perform well,
    and creating another weak learner on that subset of data. This process is repeated
    until a certain threshold is met. AutoML uses three of these algorithms: **XGBoost**,
    **LightGBM**, and **gradient boosting**. All three work similarly and were chosen
    based on their high performance, but must be carefully tuned to avoid overfitting.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Nearest neighbor algorithms** work by looking at each row of data and calculating
    the mean value of similar data points, called nearest neighbors. K-nearest neighbors
    are the sole type of nearest neighbor algorithm used by AutoML. K refers to the
    number of nearest neighbors the algorithm examines when making its prediction.
    KNN works well when your data has a low number of columns as it tends to overfit
    when you use many columns to predict your target column.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Optimization algorithms** are those that iteratively minimize an objective
    function to try to converge on the best prediction. AutoML uses three of these:
    **Stochastic gradient descent** (**SGD**), **online gradient descent regressor**,
    and **fast linear regressor**. Each of these algorithms work by finding the slope
    of an objective function for each column and working down the slope until it gets
    as close to 0 as possible by adjusting weights.'
  prefs: []
  type: TYPE_NORMAL
- en: This is a very slow process and SGD works by randomly picking datapoints along
    the slope to get to the minimum as fast as possible; online gradient descent regressor
    works similarly but with different weighting options. Fast linear regressor uses
    a new state-of-the-art optimization technique called **Stochastic Dual Coordinate
    Ascent** (**SDCA**) which optimizes a dual loss function instead of a single loss
    like the other algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: A summary of the 12 algorithms is provided in Figure 4.11.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11 – AutoML regression algorithms ](img/B16595_4_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.11 – AutoML regression algorithms
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the preceding 12 algorithms, AutoML also performs **model ensembling**
    at the end of each AutoML training run. Model ensembling is using the predictions
    of multiple machine learning models together to make a prediction. AutoML uses
    two ensembling techniques: voting and stacking.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Voting ensembles** take a weighted average of your regression models and
    use that to make a prediction. **Stack ensembles**, in contrast, train an elastic
    net model using the output of other models. AutoML will train one voting ensemble
    and one stack ensemble per training run. Usually, one of these two ensemble models
    will be your highest performing model.'
  prefs: []
  type: TYPE_NORMAL
- en: For more information on these models, please consult the AutoML documentation
    found at [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With this chapter, you have successfully constructed a regression model using
    the AzureML Python SDK. Regardless of whether you're a Python novice or expert,
    you have loaded data, transformed it extensively using pandas, and built a useful
    machine learning model with AutoML. You then registered your model to an AMLS
    workspace. You will use that same model in future chapters to create inference
    pipelines and real-time scoring endpoints using REST APIs.
  prefs: []
  type: TYPE_NORMAL
- en: By working through all the exercises in this chapter, you have obtained a level
    of mastery over Azure AutoML regression solutions. You can now take any set of
    data that's useful in predicting a number and use it to create a high-performing
    machine learning model. Furthermore, you can code all of this in Python and, if
    the model fails to perform, you know lots of little ways to improve performance,
    or, if worst comes to worst, change your regression problem to a classification
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 5*](B16595_05_ePub.xhtml#_idTextAnchor068), *Building an AutoML
    Classification Solution*, you will learn how to solve these classification problems
    using AutoML, and then build a machine learning model that predicts a class instead
    of a number.
  prefs: []
  type: TYPE_NORMAL
