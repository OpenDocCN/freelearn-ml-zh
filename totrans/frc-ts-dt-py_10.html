<html><head></head><body>
<div id="_idContainer227">
<h1 class="chapter-number" id="_idParaDest-108"><a id="_idTextAnchor641"/><a id="_idTextAnchor642"/><a id="_idTextAnchor643"/><span class="koboSpan" id="kobo.1.1">10</span></h1>
<h1 id="_idParaDest-109"><a id="_idTextAnchor644"/><span class="koboSpan" id="kobo.2.1">Accounting for Outliers and Special Events</span></h1>
<p><span class="koboSpan" id="kobo.3.1">An </span><strong class="bold"><span class="koboSpan" id="kobo.4.1">outlier</span></strong><span class="koboSpan" id="kobo.5.1"> is </span><a id="_idIndexMarker381"/><span class="koboSpan" id="kobo.6.1">any data point that lies significantly away from other data points along one or multiple different axes. </span><span class="koboSpan" id="kobo.6.2">Outliers may be incorrect data, resulting from a miscalibrated sensor producing invalid data, or even a finger slip on the keyboard during data entry, or they can be accurately recorded data that happens to wildly miss historical trends for various reasons, such as whether a tornado passed over a wind </span><span class="No-Break"><span class="koboSpan" id="kobo.7.1">speed sensor.</span></span></p>
<p><span class="koboSpan" id="kobo.8.1">These uncharacteristic measurements will sway any statistical or machine learning model, so correcting outliers is a challenge throughout data science and statistics. </span><span class="koboSpan" id="kobo.8.2">Fortunately, Prophet is generally robust at handling mild outliers. </span><span class="koboSpan" id="kobo.8.3">With extreme outliers though, there are two problems Prophet can experience – one problem with seasonality and another with </span><span class="No-Break"><span class="koboSpan" id="kobo.9.1">uncertainty intervals.</span></span></p>
<p><span class="koboSpan" id="kobo.10.1">In this chapter, you’ll see examples of both of these problems and learn how to alleviate their effects on your forecast. </span><span class="koboSpan" id="kobo.10.2">You’ll also learn a few techniques to automate outlier detection, and finally, you’ll apply a lesson learned in </span><a href="B19630_08.xhtml#_idTextAnchor537"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.11.1">Chapter 8</span></em></span></a><span class="koboSpan" id="kobo.12.1">, </span><em class="italic"><span class="koboSpan" id="kobo.13.1">Influencing Trend Changepoints</span></em><span class="koboSpan" id="kobo.14.1">, to keep the outliers in your model but instruct Prophet not to modify the trends or seasonalities to </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">fit them.</span></span></p>
<p><span class="koboSpan" id="kobo.16.1">This chapter will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.18.1">Correcting outliers that cause </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">seasonality swings</span></span></li>
<li><span class="koboSpan" id="kobo.20.1">Correcting outliers that cause wide </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">uncertainty intervals</span></span></li>
<li><span class="koboSpan" id="kobo.22.1">Detecting </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">outliers automatically</span></span></li>
<li><span class="koboSpan" id="kobo.24.1">Modeling outliers as </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">special events</span></span></li>
<li><span class="koboSpan" id="kobo.26.1">Modeling shocks, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">COVID-19 lockdowns</span></span><a id="_idTextAnchor645"/><a id="_idTextAnchor646"/></li>
</ul>
<h1 id="_idParaDest-110"><a id="_idTextAnchor647"/><span class="koboSpan" id="kobo.28.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.29.1">The data files and code for the examples in this chapter can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">at </span></span><a href="https://github.com/PacktPublishing/Forecasting-Time-Series-Data-with-Prophet-Second-Edition"><span class="No-Break"><span class="koboSpan" id="kobo.31.1">https://github.com/PacktPublishing/Forecasting-Time-Series-Data-with-Prophet-Second-Edition</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.32.1">.</span></span><a id="_idTextAnchor648"/><a id="_idTextAnchor649"/></p>
<h1 id="_idParaDest-111"><a id="_idTextAnchor650"/><span class="koboSpan" id="kobo.33.1">Correcting outliers that cause seasonality swings</span></h1>
<p><span class="koboSpan" id="kobo.34.1">We’ll be </span><a id="_idIndexMarker382"/><span class="koboSpan" id="kobo.35.1">using a ne</span><a id="_idTextAnchor651"/><span class="koboSpan" id="kobo.36.1">w dataset in this chapter to look at outliers – the average number of likes per day of posts on National Geographic’s Instagram account, </span><strong class="source-inline"><span class="koboSpan" id="kobo.37.1">@NatGeo</span></strong><span class="koboSpan" id="kobo.38.1">. </span><span class="koboSpan" id="kobo.38.2">This data was collected on November </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">21, 2019.</span></span></p>
<p><span class="koboSpan" id="kobo.40.1">I’ve chosen this dataset because it exhibits several significant outliers, which are marked in the </span><span class="No-Break"><span class="koboSpan" id="kobo.41.1">following plot:</span></span><a id="_idTextAnchor652"/></p>
<div>
<div class="IMG---Figure" id="_idContainer206">
<span class="koboSpan" id="kobo.42.1"><img alt="Figure 10.1 – Outliers on National Geographic’s Instagram account" src="image/Fig_10.1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.43.1">Figure 10.1 – Outliers on National Geographic’s Instagram account</span></p>
<p><span class="koboSpan" id="kobo.44.1">Each dashed vertical line indicates a moment where the time series deviated significantly. </span><span class="koboSpan" id="kobo.44.2">The second line from the left indicates a radical trend change in the summer of </span><strong class="bold"><span class="koboSpan" id="kobo.45.1">2015</span></strong><span class="koboSpan" id="kobo.46.1">, but the other four lines indicate outliers, with the last two outliers spanning across wide time ranges. </span><span class="koboSpan" id="kobo.46.2">We’ll specifically be looking at the line occurring in mid-</span><strong class="bold"><span class="koboSpan" id="kobo.47.1">2016</span></strong><span class="koboSpan" id="kobo.48.1">, in August to be precise. </span><span class="koboSpan" id="kobo.48.2">This represents the most extreme outliers. </span><span class="koboSpan" id="kobo.48.3">The </span><strong class="bold"><span class="koboSpan" id="kobo.49.1">2014</span></strong><span class="koboSpan" id="kobo.50.1"> set of outliers can be safely ignored, as they do not affect the forecast too much. </span><span class="koboSpan" id="kobo.50.2">The </span><strong class="bold"><span class="koboSpan" id="kobo.51.1">2017</span></strong><span class="koboSpan" id="kobo.52.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.53.1">2019</span></strong><span class="koboSpan" id="kobo.54.1"> outliers look like they may be seasonal effects, so we’ll let the yearly seasonality </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">capture them.</span></span></p>
<p><span class="koboSpan" id="kobo.56.1">As it turns out, in September 2016, National Geographic published a book, </span><em class="italic"><span class="koboSpan" id="kobo.57.1">@NatGeo: The Most Popular Instagram Photos</span></em><span class="koboSpan" id="kobo.58.1">. </span><span class="koboSpan" id="kobo.58.2">It seems that in the month prior to this, National</span><a id="_idTextAnchor653"/><span class="koboSpan" id="kobo.59.1"> Geographic undertook some marketing activities that boosted the number of likes on its </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">Instagram account.</span></span></p>
<p><span class="koboSpan" id="kobo.61.1">As we saw in </span><a href="B19630_08.xhtml#_idTextAnchor537"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.62.1">Chapter 8</span></em></span></a><span class="koboSpan" id="kobo.63.1">, </span><em class="italic"><span class="koboSpan" id="kobo.64.1">Influencing Trend Changepoints</span></em><span class="koboSpan" id="kobo.65.1">, James Rodríguez’s account also saw an increased number of likes during his World Cup appearances. </span><span class="koboSpan" id="kobo.65.2">However, in his case, these events were followed by higher baselines of likes at their conclusion – a significant trend change had occurred. </span><span class="koboSpan" id="kobo.65.3">In contrast, National Geographic’s August marketing work did not produce a lasting trend change, although it did increase the number </span><span class="No-Break"><span class="koboSpan" id="kobo.66.1">of likes.</span></span></p>
<p><span class="koboSpan" id="kobo.67.1">The spike </span><a id="_idIndexMarker383"/><span class="koboSpan" id="kobo.68.1">represents the first type of problem outliers can cause in Prophet – they can dominate a seasonality curve. </span><span class="koboSpan" id="kobo.68.2">Let me show you what I mean by plotting a Prophet forecast. </span><span class="koboSpan" id="kobo.68.3">Let’s make our imports, load the data, and plot the forecast. </span><span class="koboSpan" id="kobo.68.4">We’ll use multiplicative seasonality and dampen the Fourier order of the yearly seasonality down </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.70.1">6</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.72.1">
import pandas as pd
import matplotlib.pyplot as plt
from prophet import Prophet
from prophet.plot import add_changepoints_to_plot
df = pd.read_csv('instagram_natgeo.csv')
df['Date'] = pd.to_datetime(df['Date'])
df.columns = ['ds', 'y']
model = Prophet(seasonality_mode='multiplicative',
                yearly_seasonality=6)
model.fit(df)
future = model.make_future_dataframe(periods=365 * 2)
forecast = model.predict(future)
fig = model.plot(forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.73.1">Thes</span><a id="_idTextAnchor654"/><span class="koboSpan" id="kobo.74.1">e outliers </span><a id="_idIndexMarker384"/><span class="koboSpan" id="kobo.75.1">have caused Prophet to model a spike in likes </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">every August</span><a id="_idTextAnchor655"/><span class="koboSpan" id="kobo.77.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer207">
<span class="koboSpan" id="kobo.78.1"><img alt="Figure 10.2 – The NatGeo forecast with outliers" src="image/Fig_10.2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.79.1">Figure 10.2 – The NatGeo forecast with outliers</span></p>
<p><span class="koboSpan" id="kobo.80.1">It’s true that August in </span><strong class="bold"><span class="koboSpan" id="kobo.81.1">2013</span></strong><span class="koboSpan" id="kobo.82.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.83.1">2015</span></strong><span class="koboSpan" id="kobo.84.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.85.1">2017</span></strong><span class="koboSpan" id="kobo.86.1">, and </span><strong class="bold"><span class="koboSpan" id="kobo.87.1">2019</span></strong><span class="koboSpan" id="kobo.88.1"> also saw periods of increased likes, but the even years did not. </span><span class="koboSpan" id="kobo.88.2">Some seasonality would be expected but not this much. </span><span class="koboSpan" id="kobo.88.3">To make matters worse, this effect reverberates forever into the future. </span><span class="koboSpan" id="kobo.88.4">You can see how significant an effect this is by looking at the yearly </span><span class="No-Break"><span class="koboSpan" id="kobo.89.1">seasonality plot:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.90.1">
from prophet.plot import plot_yearly
plot_yearly(model, figsize=(10.5, 3.25))
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.91.1">Here, yo</span><a id="_idTextAnchor656"/><span class="koboSpan" id="kobo.92.1">u can see the August </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1">peak clearly:</span></span><a id="_idTextAnchor657"/></p>
<div>
<div class="IMG---Figure" id="_idContainer208">
<span class="koboSpan" id="kobo.94.1"><img alt="Figure 10.3 – Prophet’s yearly seasonality with outliers" src="image/Fig_10.3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.95.1">Figure 10.3 – Prophet’s yearly seasonality with outliers</span></p>
<p><span class="koboSpan" id="kobo.96.1">While</span><a id="_idIndexMarker385"/><span class="koboSpan" id="kobo.97.1"> attempting to fit a yearly seasonality to those outliers in </span><strong class="bold"><span class="koboSpan" id="kobo.98.1">2016</span></strong><span class="koboSpan" id="kobo.99.1">, Prophet has allowed </span><strong class="bold"><span class="koboSpan" id="kobo.100.1">August</span></strong><span class="koboSpan" id="kobo.101.1"> to contribute a boost of more than 20% to the number of expected likes. </span><span class="koboSpan" id="kobo.101.2">We see those frequent August boosts, so we do want Prophet to model them, but the </span><strong class="bold"><span class="koboSpan" id="kobo.102.1">2016</span></strong><span class="koboSpan" id="kobo.103.1"> anomaly </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">is dominating.</span></span></p>
<p><span class="koboSpan" id="kobo.105.1">The solution is simply to remove the points. </span><span class="koboSpan" id="kobo.105.2">Prophet handles missing data very well, so introducing a small gap won’t pose any issues. </span><span class="koboSpan" id="kobo.105.3">In </span><a href="B19630_04.xhtml#_idTextAnchor197"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.106.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.107.1">, </span><em class="italic"><span class="koboSpan" id="kobo.108.1">Handling Non-Daily Data</span></em><span class="koboSpan" id="kobo.109.1">, you learned how to handle regular gaps by removing those gaps from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.110.1">future</span></strong><span class="koboSpan" id="kobo.111.1"> DataFrame as well. </span><span class="koboSpan" id="kobo.111.2">In this case though, as long as we have </span><strong class="bold"><span class="koboSpan" id="kobo.112.1">August</span></strong><span class="koboSpan" id="kobo.113.1"> data for other years, we don’t need to take </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">that precaution.</span></span></p>
<p><span class="koboSpan" id="kobo.115.1">It seems that the first major outlier was on July 29 and the final one was on September 1, so we’ll exclude data between those dates using </span><strong class="source-inline"><span class="koboSpan" id="kobo.116.1">pandas</span></strong><span class="koboSpan" id="kobo.117.1">’ </span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">Boolean indexing:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.119.1">
df2 = df[(df['ds'] &lt; '2016-07-29') |
         (df['ds'] &gt; '2016-09-01')]</span></pre>
<p><span class="koboSpan" id="kobo.120.1">This new </span><strong class="source-inline"><span class="koboSpan" id="kobo.121.1">df2</span></strong><span class="koboSpan" id="kobo.122.1"> is identical t</span><a id="_idTextAnchor658"/><span class="koboSpan" id="kobo.123.1">o our original </span><strong class="source-inline"><span class="koboSpan" id="kobo.124.1">df</span></strong><span class="koboSpan" id="kobo.125.1">, just excluding those outliers. </span><span class="koboSpan" id="kobo.125.2">Let’s build the same Prophet model as before but just switch out the previous DataFrame, </span><strong class="source-inline"><span class="koboSpan" id="kobo.126.1">df</span></strong><span class="koboSpan" id="kobo.127.1">, for this new </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">one, </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.129.1">df2</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.131.1">
model = Prophet(seasonality_mode='multiplicative',
                yearly_seasonality=6)
model.fit(df2)
future = model.make_future_dataframe(periods=365 * 2)
forecast = model.predict(future)
fig = model.plot(forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.132.1">You can see the month-long gap in August 2016 in this plot. </span><span class="koboSpan" id="kobo.132.2">The forecast simply passes </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">through it:</span></span><a id="_idTextAnchor659"/></p>
<div>
<div class="IMG---Figure" id="_idContainer209">
<span class="koboSpan" id="kobo.134.1"><img alt="Figure 10.4 – The NatGeo forecast with outliers removed" src="image/Fig_10.4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.135.1">Figure 10.4 – The NatGeo forecast with outliers removed</span></p>
<p><span class="koboSpan" id="kobo.136.1">This new </span><a id="_idIndexMarker386"/><span class="koboSpan" id="kobo.137.1">forecas</span><a id="_idTextAnchor660"/><span class="koboSpan" id="kobo.138.1">t also shows significant seasonality, but we do expect this, as NatGeo’s likes are frequently higher in the summer. </span><span class="koboSpan" id="kobo.138.2">To quantify the difference between this forecast and the previous, let’s also plot the </span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">yearly seasonality:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.140.1">
plot_yearly(model, figsize=(10.5, 3.25))
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.141.1">It’s a very similar shape to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.142.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.143.1">.3</span></em><span class="koboSpan" id="kobo.144.1">, but with a less exaggerated </span><span class="No-Break"><span class="koboSpan" id="kobo.145.1">August peak:</span></span><a id="_idTextAnchor661"/></p>
<div>
<div class="IMG---Figure" id="_idContainer210">
<span class="koboSpan" id="kobo.146.1"><img alt="Figure 10.5 – Prophet’s yearly seasonality with outliers removed" src="image/Fig_10.5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.147.1">Figure 10.5 – Prophet’s yearly seasonality with outliers removed</span></p>
<p><span class="koboSpan" id="kobo.148.1">Now, the</span><a id="_idIndexMarker387"/><span class="koboSpan" id="kobo.149.1"> August peak has almost halved; it is just over 10% of a boost. </span><span class="koboSpan" id="kobo.149.2">This is much closer to what would be expected without the external (and non-repeating) shock of the marketing push before the release of National </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1">Geographic’s book.</span></span></p>
<p><span class="koboSpan" id="kobo.151.1">Now, let’s look at the second type of </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">outlier issue</span><a id="_idTextAnchor662"/><a id="_idTextAnchor663"/><span class="koboSpan" id="kobo.153.1">.</span></span></p>
<h1 id="_idParaDest-112"><a id="_idTextAnchor664"/><span class="koboSpan" id="kobo.154.1">Correcting outliers that cause wide uncertainty intervals</span></h1>
<p><span class="koboSpan" id="kobo.155.1">I</span><a id="_idTextAnchor665"/><span class="koboSpan" id="kobo.156.1">n the</span><a id="_idIndexMarker388"/><span class="koboSpan" id="kobo.157.1"> first type of outlier we looked at, the problem was that the seasonality was affected and forever changed </span><strong class="source-inline"><span class="koboSpan" id="kobo.158.1">yhat</span></strong><span class="koboSpan" id="kobo.159.1"> in the forecast (if you remember from </span><a href="B19630_02.xhtml#_idTextAnchor104"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.160.1">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.161.1">, </span><em class="italic"><span class="koboSpan" id="kobo.162.1">Getting Started with Prophet</span></em><span class="koboSpan" id="kobo.163.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.164.1">yhat</span></strong><span class="koboSpan" id="kobo.165.1"> is the predicted value for future dates contained in Prophet’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.166.1">forecast</span></strong><span class="koboSpan" id="kobo.167.1"> DataFrame). </span><span class="koboSpan" id="kobo.167.2">In this second problem, </span><strong class="source-inline"><span class="koboSpan" id="kobo.168.1">yhat</span></strong><span class="koboSpan" id="kobo.169.1"> is minimally affected, but the uncertainty intervals </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">widen dramatically.</span></span></p>
<p><span class="koboSpan" id="kobo.171.1">To simulate this issue, we need to modify our NatGeo data a bit. </span><span class="koboSpan" id="kobo.171.2">Let’s say that Instagram introduced a bug in their code that capped likes at 100,000 per post. </span><span class="koboSpan" id="kobo.171.3">It somehow went unnoticed for a year before being fixed, but unfortunately, all likes above 100,000 were lost. </span><span class="koboSpan" id="kobo.171.4">Such an error would look </span><span class="No-Break"><span class="koboSpan" id="kobo.172.1">like this</span><a id="_idTextAnchor666"/><span class="koboSpan" id="kobo.173.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer211">
<span class="koboSpan" id="kobo.174.1"><img alt="Figure 10.6 – Capped likes on National Geographic’s Instagram account" src="image/Fig_10.6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.175.1">Figure 10.6 – Capped likes on National Geographic’s Instagram account</span></p>
<p><span class="koboSpan" id="kobo.176.1">Yo</span><a id="_idTextAnchor667"/><span class="koboSpan" id="kobo.177.1">u can </span><a id="_idIndexMarker389"/><span class="koboSpan" id="kobo.178.1">simulate this new dataset yourself with the </span><span class="No-Break"><span class="koboSpan" id="kobo.179.1">following code:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.180.1">
df3 = df.copy()
df3.loc[df3['ds'].dt.year == 2016, 'y'] = 100000</span></pre>
<p><span class="koboSpan" id="kobo.181.1">This sets all the likes on all posts in 2016 to 100,000. </span><span class="koboSpan" id="kobo.181.2">To see what problem this causes, let’s again build the same model </span><span class="No-Break"><span class="koboSpan" id="kobo.182.1">as before:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.183.1">
model = Prophet(seasonality_mode='multiplicative',
                yearly_seasonality=6)
model.fit(df3)
future = model.make_future_dataframe(periods=365 * 2)
forecast = model.predict(future)
fig = model.plot(forecast)
add_changepoints_to_plot(fig.gca(), model, forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.184.1">We’re adding the changepoints to the plot in this example because that is exactly where t</span><a id="_idTextAnchor668"/><span class="koboSpan" id="kobo.185.1">he error is introduced, as seen in the </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">following graph</span><a id="_idTextAnchor669"/><span class="koboSpan" id="kobo.187.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer212">
<span class="koboSpan" id="kobo.188.1"><img alt="Figure 10.7 – The NatGeo forecast with outliers" src="image/Fig_10.7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.189.1">Figure 10.7 – The NatGeo forecast with outliers</span></p>
<p><span class="koboSpan" id="kobo.190.1">The future</span><a id="_idIndexMarker390"/><span class="koboSpan" id="kobo.191.1"> uncertainty explodes going forward. </span><span class="koboSpan" id="kobo.191.2">In the previous example, Prophet modeled the outliers with seasonality, adding extreme data to the yearly seasonality component. </span><span class="koboSpan" id="kobo.191.3">In this example though, Prophet models the outliers with trend changepoints. </span><span class="koboSpan" id="kobo.191.4">The seasonality </span><span class="No-Break"><span class="koboSpan" id="kobo.192.1">is unaffected.</span></span></p>
<p><span class="koboSpan" id="kobo.193.1">We’ll fully discuss uncertainty in </span><a href="B19630_11.xhtml#_idTextAnchor728"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.194.1">Chapter 11</span></em></span></a><span class="koboSpan" id="kobo.195.1">, </span><em class="italic"><span class="koboSpan" id="kobo.196.1">Managing Uncertainty Intervals</span></em><span class="koboSpan" id="kobo.197.1">, but briefly, what Prophet does is look at the frequency and magnitude of historical changepoints and model future uncertainty, assuming that future changepoints may occur with the same frequency and magnitude. </span><span class="koboSpan" id="kobo.197.2">So, dramatic historical changepoints, as you can see in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.198.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.199.1">.7</span></em><span class="koboSpan" id="kobo.200.1">, will cause dramatic future uncertainty, as Prophet is unsure whether they will </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">occur again.</span></span></p>
<p><span class="koboSpan" id="kobo.202.1">The solution, fortunately, is the same as in the previous situation – simply remove the bad data. </span><span class="koboSpan" id="kobo.202.2">In the previous example, we removed the rows from our DataFrame that contained bad data, but in this example, we’ll set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.203.1">'y'</span></strong><span class="koboSpan" id="kobo.204.1"> value </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.206.1">None</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.208.1">
df3.loc[df3['ds'].dt.year == 2016, 'y'] = None</span></pre>
<p><span class="koboSpan" id="kobo.209.1">Th</span><a id="_idTextAnchor670"/><span class="koboSpan" id="kobo.210.1">is makes </span><a id="_idIndexMarker391"/><span class="koboSpan" id="kobo.211.1">no difference to our trends or seasonalities. </span><span class="koboSpan" id="kobo.211.2">Where it does make a difference is that now, instead of skipping over those dates in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.212.1">forecast</span></strong><span class="koboSpan" id="kobo.213.1"> DataFrame, it predicts the values on those dates. </span><span class="koboSpan" id="kobo.213.2">You can see this in the forecast plot coming up in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.214.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.215.1">.8</span></em><span class="koboSpan" id="kobo.216.1">. </span><span class="koboSpan" id="kobo.216.2">Instead of a straight prediction line passing through the missing data, it follows </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1">the seasonality.</span></span></p>
<p><span class="koboSpan" id="kobo.218.1">Let’s rebuild our model again, using the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.219.1">df3</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.220.1"> DataFrame:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.221.1">
model = Prophet(seasonality_mode='multiplicative',
                yearly_seasonality=6)
model.fit(df3)
future = model.make_future_dataframe(periods=365 * 2)
forecast = model.predict(future)
fig = model.plot(forecast)
add_changepoints_to_plot(fig.gca(), model, forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.222.1">Compared to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.223.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.224.1">.7</span></em><span class="koboSpan" id="kobo.225.1">, we have now tamed that forecast uncertainty, as shown in the </span><span class="No-Break"><span class="koboSpan" id="kobo.226.1">following plo</span><a id="_idTextAnchor671"/><span class="koboSpan" id="kobo.227.1">t:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer213">
<span class="koboSpan" id="kobo.228.1"><img alt="Figure 10.8 – The NatGeo forecast with outliers removed" src="image/Fig_10.8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.229.1">Figure 10.8 – The NatGeo forecast with outliers removed</span></p>
<p><a id="_idTextAnchor672"/><span class="koboSpan" id="kobo.230.1">As mentioned before, we have missing data in 2016, but Prophet still made a prediction and plotted the predicted values. </span><span class="koboSpan" id="kobo.230.2">This is the result of setting those missing values to </span><strong class="source-inline"><span class="koboSpan" id="kobo.231.1">None</span></strong><span class="koboSpan" id="kobo.232.1"> instead of deleting them. </span><span class="koboSpan" id="kobo.232.2">Compare </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.233.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.234.1">.8</span></em><span class="koboSpan" id="kobo.235.1"> with </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.236.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.237.1">.4</span></em><span class="koboSpan" id="kobo.238.1">, where the missing data has no predicted values and the plot passes right through them in a </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">straight line.</span></span></p>
<p><span class="koboSpan" id="kobo.240.1">Mathematically, it makes</span><a id="_idIndexMarker392"/><span class="koboSpan" id="kobo.241.1"> no difference to your future forecast; it just applies predicted values to those that were missing. </span><span class="koboSpan" id="kobo.241.2">It is entirely up to you whether you want these missing values to be predicted in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.242.1">future</span></strong><span class="koboSpan" id="kobo.243.1"> DataFrame </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">or ignor</span><a id="_idTextAnchor673"/><a id="_idTextAnchor674"/><span class="koboSpan" id="kobo.245.1">ed.</span></span></p>
<h1 id="_idParaDest-113"><a id="_idTextAnchor675"/><span class="koboSpan" id="kobo.246.1">Detecting outliers automatically</span></h1>
<p><span class="koboSpan" id="kobo.247.1">In these examp</span><a id="_idTextAnchor676"/><span class="koboSpan" id="kobo.248.1">les so far, we detected outliers with a simple visual inspection of the data and applied common sense. </span><span class="koboSpan" id="kobo.248.2">In a fully automated setting, defining logical rules for what we as humans do intuitively can be difficult. </span><span class="koboSpan" id="kobo.248.3">Outlier detection</span><a id="_idIndexMarker393"/><span class="koboSpan" id="kobo.249.1"> is a good use of an analyst’s time, as we humans are able to use much more intuition, domain knowledge, and experience than a computer can. </span><span class="koboSpan" id="kobo.249.2">But as Prophet was developed to reduce the workload of analysts and automate as much as possible, we’ll examine a couple of techniques to identify </span><span class="No-Break"><span class="koboSpan" id="kobo.250.1">outliers automatica</span><a id="_idTextAnchor677"/><a id="_idTextAnchor678"/><span class="koboSpan" id="kobo.251.1">lly.</span></span></p>
<h2 id="_idParaDest-114"><a id="_idTextAnchor679"/><span class="koboSpan" id="kobo.252.1">Winsorizing</span></h2>
<p><span class="koboSpan" id="kobo.253.1">The f</span><a id="_idTextAnchor680"/><span class="koboSpan" id="kobo.254.1">irst technique is </span><a id="_idIndexMarker394"/><span class="koboSpan" id="kobo.255.1">called </span><strong class="bold"><span class="koboSpan" id="kobo.256.1">Winsorization</span></strong><span class="koboSpan" id="kobo.257.1">, named </span><a id="_idTextAnchor681"/><span class="koboSpan" id="kobo.258.1">after the statistician Charles P. </span><span class="koboSpan" id="kobo.258.2">Winsor. </span><span class="koboSpan" id="kobo.258.3">It is</span><a id="_idTextAnchor682"/> <a id="_idIndexMarker395"/><span class="koboSpan" id="kobo.259.1">also sometimes</span><a id="_idIndexMarker396"/><span class="koboSpan" id="kobo.260.1"> called </span><strong class="bold"><span class="koboSpan" id="kobo.261.1">clipping</span></strong><span class="koboSpan" id="kobo.262.1">. </span><span class="koboSpan" id="kobo.262.2">Winsorization is a blunt tool and tends not to work well with non-flat trends. </span><span class="koboSpan" id="kobo.262.3">Winsorization requires an analyst to specify a percentile; all data above or below that percentile is forced to remain at the value at </span><span class="No-Break"><span class="koboSpan" id="kobo.263.1">the percentile.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.264.1">Trimming</span></strong><span class="koboSpan" id="kobo.265.1"> is a </span><a id="_idTextAnchor683"/><a id="_idIndexMarker397"/><span class="koboSpan" id="kobo.266.1">similar technique, except that the extreme values are removed. </span><span class="koboSpan" id="kobo.266.2">The difference between these techniques can be seen in this simple example, in which the outliers are the two most extreme points on each side of the </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">three</span><a id="_idTextAnchor684"/><span class="koboSpan" id="kobo.268.1"> plots:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer214">
<span class="koboSpan" id="kobo.269.1"><img alt="Figure 10.9 – Winsorization versus trimming" src="image/Fig_10.9.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.270.1">Figure 10.9 – Winsorization versus trimming</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.271.1">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.272.1">In statistics, the word </span><em class="italic"><span class="koboSpan" id="kobo.273.1">stationary</span></em><span class="koboSpan" id="kobo.274.1"> means that the mean, variance, and autocorrelation structure do not change over time. </span><span class="koboSpan" id="kobo.274.2">In time series with a </span><em class="italic"><span class="koboSpan" id="kobo.275.1">flat trend</span></em><span class="koboSpan" id="kobo.276.1">, the mean does not change over time, and so one (and possibly each) requirement of stationarity is met. </span><span class="koboSpan" id="kobo.276.2">With stationary data, outliers may often be replaced by the mean value; however, this technique typically does not work with time series lacking a flat trend, due to the </span><span class="No-Break"><span class="koboSpan" id="kobo.277.1">stationarity requirement.</span></span></p>
<p class="callout"><span class="koboSpan" id="kobo.278.1">To take a concrete example, refer back to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.279.1">Figure 2</span></em></span><em class="italic"><span class="koboSpan" id="kobo.280.1">.2</span></em><span class="koboSpan" id="kobo.281.1"> from </span><a href="B19630_02.xhtml#_idTextAnchor104"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.282.1">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.283.1">, </span><em class="italic"><span class="koboSpan" id="kobo.284.1">Getting Started with Prophet</span></em><span class="koboSpan" id="kobo.285.1">, and look at the Keeling Curve of carbon dioxide levels at Mauna Loa and imagine replacing one of the final values – say, in 2015 – with the mean of the full dataset. </span><span class="koboSpan" id="kobo.285.2">This would result in an absurdly low value of about 360 in 2015, a value not seen in </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">20 years.</span></span></p>
<p><span class="koboSpan" id="kobo.287.1">Let’s </span><a id="_idTextAnchor685"/><span class="koboSpan" id="kobo.288.1">look at how to apply </span><a id="_idIndexMarker398"/><span class="koboSpan" id="kobo.289.1">Winsorizatio</span><a id="_idTextAnchor686"/><span class="koboSpan" id="kobo.290.1">n to our National Geographic data. </span><span class="koboSpan" id="kobo.290.2">The </span><strong class="bold"><span class="koboSpan" id="kobo.291.1">SciPy</span></strong> <strong class="source-inline"><span class="koboSpan" id="kobo.292.1">stats</span></strong><span class="koboSpan" id="kobo.293.1"> package has a Winsorization tool, so we’ll use that. </span><span class="koboSpan" id="kobo.293.2">Note that we are </span><a id="_idIndexMarker399"/><span class="koboSpan" id="kobo.294.1">dropping all null values, as those are not handled by this function. </span><span class="koboSpan" id="kobo.294.2">We are setting the lower limit to </span><strong class="source-inline"><span class="koboSpan" id="kobo.295.1">0</span></strong><span class="koboSpan" id="kobo.296.1">, so no values are affected at the lower bound, and the upper limit to </span><strong class="source-inline"><span class="koboSpan" id="kobo.297.1">.05</span></strong><span class="koboSpan" id="kobo.298.1">, so the upper fifth percentile </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">is affected:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.300.1">
from scipy import stats
df4 = df.copy().dropna()
df4['y'] = stats.mstats.winsorize(df4['y'],
                                  limits=(0, .05), axis=0)</span></pre>
<p><span class="koboSpan" id="kobo.301.1">The Winsorized National Geographic data appears thus, with affected data points marked wi</span><a id="_idTextAnchor687"/><span class="koboSpan" id="kobo.302.1">th </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">an </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.304.1">x</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer215">
<span class="koboSpan" id="kobo.306.1"><img alt="Figure 10.10 – Winsori﻿﻿zed data" src="image/Fig_10.10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.307.1">Figure 10.10 – Winsori</span><a id="_idTextAnchor688"/><a id="_idTextAnchor689"/><span class="koboSpan" id="kobo.308.1">zed data</span></p>
<h2 id="_idParaDest-115"><span class="koboSpan" id="kobo.309.1">Standard deviati</span><a id="_idTextAnchor690"/><span class="koboSpan" id="kobo.310.1">on</span></h2>
<p><span class="koboSpan" id="kobo.311.1">Since Winsorization </span><a id="_idIndexMarker400"/><span class="koboSpan" id="kobo.312.1">limits are</span><a id="_idTextAnchor691"/><span class="koboSpan" id="kobo.313.1"> set with </span><a id="_idIndexMarker401"/><span class="koboSpan" id="kobo.314.1">percentiles, there is no account taken of natural variance in the data – that is, some datasets are distributed very tightly around a mean value and some are very spread out. </span><span class="koboSpan" id="kobo.314.2">Setting a percentile limit would not take this into account. </span><span class="koboSpan" id="kobo.314.3">So, instead of using percentiles, sometimes using standard deviation makes more sense. </span><span class="koboSpan" id="kobo.314.4">This is very similar to Winsorization and can have identical effects if the limits are </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">set carefully.</span></span></p>
<p><span class="koboSpan" id="kobo.316.1">When we Winsorized in the previous section, we forced the outliers to take on the value at the upper limit. </span><span class="koboSpan" id="kobo.316.2">In this case, we will simply remove the outliers. </span><span class="koboSpan" id="kobo.316.3">We are using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.317.1">zscore</span></strong><span class="koboSpan" id="kobo.318.1"> function in the SciPy </span><strong class="source-inline"><span class="koboSpan" id="kobo.319.1">stats</span></strong><span class="koboSpan" id="kobo.320.1"> package to eliminate those data points lying </span><strong class="source-inline"><span class="koboSpan" id="kobo.321.1">1.65</span></strong><span class="koboSpan" id="kobo.322.1"> standard deviations above the mean; in a normal distribution, this upper value would demarcate 95% of the data, the same limit we </span><span class="No-Break"><span class="koboSpan" id="kobo.323.1">set previously:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.324.1">
df5 = df.copy().dropna()
df5 = df5[(stats.zscore(df5['y']) &lt;</span><a id="_idTextAnchor692"/><span class="koboSpan" id="kobo.325.1"> 1.65)]</span></pre>
<p><span class="koboSpan" id="kobo.326.1">In this case, the two techn</span><a id="_idTextAnchor693"/><span class="koboSpan" id="kobo.327.1">iques have nearly identical results, except that here, we are trimming </span><a id="_idTextAnchor694"/><span class="No-Break"><span class="koboSpan" id="kobo.328.1">the data:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer216">
<span class="koboSpan" id="kobo.329.1"><img alt="Figure 10.11 – Data trimmed with standard deviation" src="image/Fig_10.11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.330.1">Figure 10.11 – Data trimmed with standard deviation</span></p>
<p><span class="koboSpan" id="kobo.331.1">This method</span><a id="_idIndexMarker402"/><span class="koboSpan" id="kobo.332.1"> is also a poor fit when data features</span><a id="_idIndexMarker403"/><span class="koboSpan" id="kobo.333.1"> a trend. </span><span class="koboSpan" id="kobo.333.2">Obviously, points lying later in a time series with an upward trend are more likely to be trimmed than those lying earlier. </span><span class="koboSpan" id="kobo.333.3">The next technique takes this </span><span class="No-Break"><span class="koboSpan" id="kobo.334.1">in</span><a id="_idTextAnchor695"/><a id="_idTextAnchor696"/><span class="koboSpan" id="kobo.335.1">to account.</span></span></p>
<h2 id="_idParaDest-116"><span class="koboSpan" id="kobo.336.1">The moving</span><a id="_idTextAnchor697"/><span class="koboSpan" id="kobo.337.1"> average</span></h2>
<p><span class="koboSpan" id="kobo.338.1">We just looked at the</span><a id="_idIndexMarker404"/><span class="koboSpan" id="kobo.339.1"> number of </span><a id="_idIndexMarker405"/><span class="koboSpan" id="kobo.340.1">standa</span><a id="_idTextAnchor698"/><span class="koboSpan" id="kobo.341.1">rd deviations spread out away from the mean of the entire dataset and saw why it fails when there is a trend. </span><span class="koboSpan" id="kobo.341.2">In this method, we will use a moving average so that we’re essentially localizing our mean and standard deviation calculations, only applying them to data points that are temporally near </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">each other.</span></span></p>
<p><span class="koboSpan" id="kobo.343.1">In this example, we will trim both the upper and lower bounds of the data, again using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.344.1">1.65</span></strong><span class="koboSpan" id="kobo.345.1"> value for standard deviation as before. </span><span class="koboSpan" id="kobo.345.2">The analyst also needs to decide upon a window size. </span><span class="koboSpan" id="kobo.345.3">This is the number of surrounding data points to collect together for calculation. </span><span class="koboSpan" id="kobo.345.4">Set it too small and a group of outliers together will not be removed. </span><span class="koboSpan" id="kobo.345.5">Set it too large and we approach the previous technique of ignoring </span><span class="No-Break"><span class="koboSpan" id="kobo.346.1">the trend.</span></span></p>
<p><span class="koboSpan" id="kobo.347.1">Let’s use </span><strong class="source-inline"><span class="koboSpan" id="kobo.348.1">300</span></strong><span class="koboSpan" id="kobo.349.1"> here. </span><span class="koboSpan" id="kobo.349.2">We will use pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.350.1">rolling</span></strong><span class="koboSpan" id="kobo.351.1"> method to find the mean and standard deviation using a rolling window. </span><span class="koboSpan" id="kobo.351.2">Then, we calculate the upper and lower bounds using these values and filter our DataFrame with </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">those bounds:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.353.1">
df6 = df.copy().dropna()
df6['moving_average'] = df6.rolling(window=300,
                                    min_periods=1,
                                    center=True,
                                    on='ds')['y'].mean()
df6['std_dev'] = df6.rolling(window=300,
                             min_periods=1,
                             center=True,
                             on='ds')['y'].std()
df6['lower'] = df6['moving_average'] - 1.65 * \
               df6['std_dev']
df6['upper'] = df6['moving_average'] + 1.65 * \
               df6['std_dev']
df6 = df6[(df6['y'] &lt; df6['upper']) &amp; \
          (df6['y'] &gt; df6[</span><a id="_idTextAnchor699"/><span class="koboSpan" id="kobo.354.1">'lower'])]</span></pre>
<p><span class="koboSpan" id="kobo.355.1">We are now getting </span><a id="_idIndexMarker406"/><span class="koboSpan" id="kobo.356.1">more refined outli</span><a id="_idTextAnchor700"/><span class="koboSpan" id="kobo.357.1">er removal, as </span><a id="_idIndexMarker407"/><span class="koboSpan" id="kobo.358.1">can be seen in the </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">fo</span><a id="_idTextAnchor701"/><span class="koboSpan" id="kobo.360.1">llowing graph:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer217">
<span class="koboSpan" id="kobo.361.1"><img alt="Figure 10.12 – Data trimmed with the moving average" src="image/Fig_10.12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.362.1">Figure 10.12 – Data trimmed with the moving average</span></p>
<p><span class="koboSpan" id="kobo.363.1">The strong </span><a id="_idIndexMarker408"/><span class="koboSpan" id="kobo.364.1">advantage of this method is that it</span><a id="_idIndexMarker409"/><span class="koboSpan" id="kobo.365.1"> takes into ac</span><a id="_idTextAnchor702"/><a id="_idTextAnchor703"/><span class="koboSpan" id="kobo.366.1">count </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">the trend.</span></span></p>
<h2 id="_idParaDest-117"><a id="_idTextAnchor704"/><span class="koboSpan" id="kobo.368.1">Error standard deviation</span></h2>
<p><span class="koboSpan" id="kobo.369.1">The fina</span><a id="_idTextAnchor705"/><span class="koboSpan" id="kobo.370.1">l </span><a id="_idIndexMarker410"/><span class="koboSpan" id="kobo.371.1">method we will</span><a id="_idIndexMarker411"/><span class="koboSpan" id="kobo.372.1"> consider i</span><a id="_idTextAnchor706"/><span class="koboSpan" id="kobo.373.1">s the most precise of all. </span><span class="koboSpan" id="kobo.373.2">Let’s go back to the question of defining an outlier – it is a value that you don’t expect. </span><span class="koboSpan" id="kobo.373.3">Intuitively, we knew this when we visually inspected the data and removed points. </span><span class="koboSpan" id="kobo.373.4">So, how do you tell the computer what to expect? </span><span class="koboSpan" id="kobo.373.5">You build a forecast, </span><span class="No-Break"><span class="koboSpan" id="kobo.374.1">of course.</span></span></p>
<p><span class="koboSpan" id="kobo.375.1">Prophet’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.376.1">forecast</span></strong><span class="koboSpan" id="kobo.377.1"> DataFrame makes predictions in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.378.1">yhat</span></strong><span class="koboSpan" id="kobo.379.1"> column, but it also includes columns for </span><strong class="source-inline"><span class="koboSpan" id="kobo.380.1">yhat_upper</span></strong><span class="koboSpan" id="kobo.381.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.382.1">yhat_lower</span></strong><span class="koboSpan" id="kobo.383.1">. </span><span class="koboSpan" id="kobo.383.2">These uncertainty intervals are by default set to 80%, but you’ll learn in </span><a href="B19630_11.xhtml#_idTextAnchor728"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.384.1">Chapter 11</span></em></span></a><span class="koboSpan" id="kobo.385.1">, </span><em class="italic"><span class="koboSpan" id="kobo.386.1">Managing Uncertainty Intervals</span></em><span class="koboSpan" id="kobo.387.1">, how to modify them. </span><span class="koboSpan" id="kobo.387.2">If we accept any errors contained within the uncertainty intervals, we can declare an outlier to be anything that falls outside of these bounds, as it would </span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">be unexpected.</span></span></p>
<p><span class="koboSpan" id="kobo.389.1">In fact, the moving average is a crude forecasting technique; the previous method indeed removed outliers based upon deviation in the error term. </span><span class="koboSpan" id="kobo.389.2">By using Prophet to identify the error, we allow seasonality and other effects to be included in our </span><span class="No-Break"><span class="koboSpan" id="kobo.390.1">expected results.</span></span></p>
<p><span class="koboSpan" id="kobo.391.1">As the most precise method available, this is unfortunately also the most prone to overfitting. </span><span class="koboSpan" id="kobo.391.2">If you do wish to use this approach, be sure to tread carefully with new datasets and make sure you like the results before fully automating it. </span><span class="koboSpan" id="kobo.391.3">That said, let’s see how to </span><span class="No-Break"><span class="koboSpan" id="kobo.392.1">code it.</span></span></p>
<p><span class="koboSpan" id="kobo.393.1">Our approach will be to first remove null values to avoid downstream issues when comparing our </span><strong class="source-inline"><span class="koboSpan" id="kobo.394.1">forecast</span></strong><span class="koboSpan" id="kobo.395.1"> DataFrame to our </span><span class="No-Break"><span class="koboSpan" id="kobo.396.1">raw DataFrame:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.397.1">
df7 = df.copy().dropna().reset_index()</span></pre>
<p><span class="koboSpan" id="kobo.398.1">Next, we build a Prophet model on this data, including strong regularization to be sure we don’t overfit. </span><span class="koboSpan" id="kobo.398.2">Note that there is no need to predict the future. </span><span class="koboSpan" id="kobo.398.3">We include the </span><strong class="source-inline"><span class="koboSpan" id="kobo.399.1">inter</span><a id="_idTextAnchor707"/><span class="koboSpan" id="kobo.400.1">val_width</span></strong><span class="koboSpan" id="kobo.401.1"> argument he</span><a id="_idTextAnchor708"/><span class="koboSpan" id="kobo.402.1">re to increase the uncertainty interval to better align with our previous examples; we’ll</span><a id="_idIndexMarker412"/><span class="koboSpan" id="kobo.403.1"> cover this parameter</span><a id="_idIndexMarker413"/><span class="koboSpan" id="kobo.404.1"> in the </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">next chapter:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.406.1">
model = Prophet(seasonality_mode='multiplicative',
                yearly_seasonality=6,
                seasonality_prior_scale=.01,
                changepoint_prior_scale=.01,
                interval_width=.90)
model.fit(df7)
forecast = model.predict()</span></pre>
<p><span class="koboSpan" id="kobo.407.1">Finally, we create a DataFrame that excludes those values where the </span><strong class="source-inline"><span class="koboSpan" id="kobo.408.1">y</span></strong><span class="koboSpan" id="kobo.409.1"> value was either greater than </span><strong class="source-inline"><span class="koboSpan" id="kobo.410.1">yhat_upper</span></strong><span class="koboSpan" id="kobo.411.1"> or lower than </span><strong class="source-inline"><span class="koboSpan" id="kobo.412.1">yhat_lower</span></strong><span class="koboSpan" id="kobo.413.1">. </span><span class="koboSpan" id="kobo.413.2">These would be </span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">our outliers:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.415.1">
df8 = df7[(df7['y'] &gt; forecast['yhat_lower']) &amp;
          (df7['y'] &lt; forecast['yhat_upper'])]</span></pre>
<p><span class="koboSpan" id="kobo.416.1">The f</span><a id="_idTextAnchor709"/><span class="koboSpan" id="kobo.417.1">inal DataFrame would the</span><a id="_idTextAnchor710"/><span class="koboSpan" id="kobo.418.1">n be used to build a whole new Prophet model, without needing to worry about outliers. </span><span class="koboSpan" id="kobo.418.2">This is what our d</span><a id="_idTextAnchor711"/><span class="koboSpan" id="kobo.419.1">ata looks </span><span class="No-Break"><span class="koboSpan" id="kobo.420.1">like now:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer218">
<span class="koboSpan" id="kobo.421.1"><img alt="Figure 10.13 – Data trimmed with an error from the forecast" src="image/Fig_10.13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.422.1">Figure 10.13 – Data trimmed with an error from the forecast</span></p>
<p><span class="koboSpan" id="kobo.423.1">We have certainly removed what would plausibly be considered outliers. </span><span class="koboSpan" id="kobo.423.2">Had we used Prophet’s default uncertainty interval, then outlier removal may have been a bit too aggressive in this case. </span><span class="koboSpan" id="kobo.423.3">If you compare </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.424.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.425.1">.13</span></em><span class="koboSpan" id="kobo.426.1"> with the data plots of our other methods, this one appears to be the most surgical – for instance, by allowing high values that we would expect in the summer but removing those that are </span><span class="No-Break"><span class="koboSpan" id="kobo.427.1">uncharacteristically high.</span></span></p>
<p><span class="koboSpan" id="kobo.428.1">Using this method </span><a id="_idIndexMarker414"/><span class="koboSpan" id="kobo.429.1">makes the implicit assumption that the </span><a id="_idIndexMarker415"/><span class="koboSpan" id="kobo.430.1">data is stationary and has a constant varia</span><a id="_idTextAnchor712"/><span class="koboSpan" id="kobo.431.1">nce, which appears to</span><a id="_idTextAnchor713"/><span class="koboSpan" id="kobo.432.1"> be a poor assumption throughout the full National Geographic dataset but a fair assumption when considering only the data after 2016. </span><span class="koboSpan" id="kobo.432.2">The full data becomes more spread out as time advances. </span><span class="koboSpan" id="kobo.432.3">This is why more data points were dropped at later dates than earlier dates – just one more thing to consider when using </span><span class="No-Break"><span class="koboSpan" id="kobo.433.1">this method.</span></span></p>
<p><span class="koboSpan" id="kobo.434.1">Throughout this chapter, we have removed outliers from our data. </span><span class="koboSpan" id="kobo.434.2">However, there is one technique you can use to keep those outliers around if you believe they provide some valuable signal in your model but you want to control the effect. </span><span class="koboSpan" id="kobo.434.3">This technique uses the holiday functionality in Prophet. </span><span class="koboSpan" id="kobo.434.4">Let’s s</span><a id="_idTextAnchor714"/><a id="_idTextAnchor715"/><span class="koboSpan" id="kobo.435.1">ee how to do </span><span class="No-Break"><span class="koboSpan" id="kobo.436.1">it next.</span></span></p>
<h1 id="_idParaDest-118"><span class="koboSpan" id="kobo.437.1">Modeling outliers as special even</span><a id="_idTextAnchor716"/><span class="koboSpan" id="kobo.438.1">ts</span></h1>
<p><span class="koboSpan" id="kobo.439.1">There is one </span><a id="_idIndexMarker416"/><span class="koboSpan" id="kobo.440.1">final way to work with outliers in Prophet; it’s a technique we used with James Rodríguez’s data in </span><a href="B19630_08.xhtml#_idTextAnchor537"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.441.1">Chapter 8</span></em></span></a><span class="koboSpan" id="kobo.442.1">, </span><em class="italic"><span class="koboSpan" id="kobo.443.1">Influencing Trend Changepoints</span></em><span class="koboSpan" id="kobo.444.1"> – we can declare the outliers as a special event, essentially a holiday. </span><span class="koboSpan" id="kobo.444.2">By putting the outliers into the </span><strong class="source-inline"><span class="koboSpan" id="kobo.445.1">holidays</span></strong><span class="koboSpan" id="kobo.446.1"> DataFrame, we essentially instruct Prophet to apply trends and seasonality as if the data points were not outliers and capture the additional variation beyond trends and seasonality in the </span><span class="No-Break"><span class="koboSpan" id="kobo.447.1">holiday term.</span></span></p>
<p><span class="koboSpan" id="kobo.448.1">This can be useful if you know that the extreme observations are due to some external factor that you do not expect to repeat. </span><span class="koboSpan" id="kobo.448.2">Such external factors could be the World Cup or a large marketing campaign but may also be mysterious and unknown. </span><span class="koboSpan" id="kobo.448.3">You can keep the data in your model but essentially disregard it. </span><span class="koboSpan" id="kobo.448.4">An added benefit is that you can simulate what would happen if the </span><span class="No-Break"><span class="koboSpan" id="kobo.449.1">event repeated.</span></span></p>
<p><span class="koboSpan" id="kobo.450.1">We’ll again use the National Geographic data but, this time, label that August 2016 series of outliers as a holiday. </span><span class="koboSpan" id="kobo.450.2">If those additional likes were due to a marketing campaign surrounding the release of their book, we can predict what would happen if they repeated a similar marketing campaign at a </span><span class="No-Break"><span class="koboSpan" id="kobo.451.1">later date.</span></span></p>
<p><span class="koboSpan" id="kobo.452.1">We covered the creation of custom holidays in </span><a href="B19630_06.xhtml#_idTextAnchor375"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.453.1">Chapter 6</span></em></span></a><span class="koboSpan" id="kobo.454.1">, </span><em class="italic"><span class="koboSpan" id="kobo.455.1">Forecasting Holiday Effects</span></em><span class="koboSpan" id="kobo.456.1">, so this first step should be a review. </span><span class="koboSpan" id="kobo.456.2">We are simply creating two holidays for our August 2016 marketing event and an identical, hypothetical June 2020 </span><span class="No-Break"><span class="koboSpan" id="kobo.457.1">marketing event.</span></span></p>
<p><span class="koboSpan" id="kobo.458.1">Note that both events have the same name, </span><strong class="source-inline"><span class="koboSpan" id="kobo.459.1">'Promo event'</span></strong><span class="koboSpan" id="kobo.460.1">, so Prophet knows to apply the same effect to each. </span><span class="koboSpan" id="kobo.460.2">They’re both the same number of days long, although they needn’t be – the holiday effects for each day of the hypothetical event will match the effects for each day of the </span><span class="No-Break"><span class="koboSpan" id="kobo.461.1">measured event.</span></span></p>
<p><span class="koboSpan" id="kobo.462.1">If the hypothetical event is shorter, the effects will simply cease earl</span><a id="_idTextAnchor717"/><span class="koboSpan" id="kobo.463.1">y. </span><span class="koboSpan" id="kobo.463.2">If the hypothetical event is longer though, the effects will cease once the length of the measured event </span><span class="No-Break"><span class="koboSpan" id="kobo.464.1">is reached.</span></span></p>
<p><span class="koboSpan" id="kobo.465.1">We begin by defining the promotions the same way we </span><span class="No-Break"><span class="koboSpan" id="kobo.466.1">define holidays:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.467.1">
promo = pd.DataFrame({'holiday': 'Promo event',
                      'ds': pd.to_datetime(['2016-07-29']),
                      'lower_window': 0,
                      'upper_window': 34})
future_promo = pd.DataFrame({'holiday': 'Promo event',
                      'ds': pd.to_datetime(['2020-06-01']),
                      'lower_window': 0,
                      'upper_window': 34})
promos = pd.concat([promo, future_promo])</span></pre>
<p><span class="koboSpan" id="kobo.468.1">Next, we build </span><a id="_idIndexMarker417"/><span class="koboSpan" id="kobo.469.1">our model using the same parameters as throughout this chapter, except sending the first </span><strong class="source-inline"><span class="koboSpan" id="kobo.470.1">promo</span></strong><span class="koboSpan" id="kobo.471.1"> DataFrame to the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.472.1">holidays</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.473.1"> argument:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.474.1">
model = Prophet(seasonality_mode='multiplicative',
                holidays=promo,
                yearly_seasonality=6)
model.fit(df)
future = model.make_future_dataframe(periods=365 * 2)
forecast = model.predict(future)
fig = model.plot(forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.475.1">Our forecast perfectly models that spike of outliers, without either lett</span><a id="_idTextAnchor718"/><span class="koboSpan" id="kobo.476.1">ing seasonality get out of control (the first problem we looked at in this chapter) or the future uncertainty explode</span><a id="_idTextAnchor719"/><span class="koboSpan" id="kobo.477.1"> (the </span><span class="No-Break"><span class="koboSpan" id="kobo.478.1">second problem):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer219">
<span class="koboSpan" id="kobo.479.1"><img alt="Figure 10.14 – The NatGeo forecast with outliers modeled as special events" src="image/Fig_10.14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.480.1">Figure 10.14 – The NatGeo forecast with outliers modeled as special events</span></p>
<p><span class="koboSpan" id="kobo.481.1">To conclude this </span><a id="_idIndexMarker418"/><span class="koboSpan" id="kobo.482.1">example, let’s try one more model but, this time, include that hypothetical </span><span class="No-Break"><span class="koboSpan" id="kobo.483.1">promotional event:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.484.1">
model = Prophet(seasonality_mode='multiplicative',
                holidays=promos,
                yearly_seasonality=6)
model.fit(df)
future = model.make_future_dataframe(periods=365 * 2)
forecast = model.predict(future)
fig = model.plot(forecast)
plt.sh</span><a id="_idTextAnchor720"/><span class="koboSpan" id="kobo.485.1">ow()</span></pre>
<p><span class="koboSpan" id="kobo.486.1">This is the future forecast National Geographic could expect if they duplicated the promotion</span><a id="_idTextAnchor721"/><span class="koboSpan" id="kobo.487.1">al activities </span><span class="No-Break"><span class="koboSpan" id="kobo.488.1">in 2020:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer220">
<span class="koboSpan" id="kobo.489.1"><img alt="Figure 10.15 – The NatGeo forecast with a hypothetical promotional event" src="image/Fig_10.15.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.490.1">Figure 10.15 – The NatGeo forecast with a hypothetical promotional event</span></p>
<p><span class="koboSpan" id="kobo.491.1">With just one </span><a id="_idIndexMarker419"/><span class="koboSpan" id="kobo.492.1">instance of the holiday to train with, Proph</span><a id="_idTextAnchor722"/><span class="koboSpan" id="kobo.493.1">et has perfectly matched</span><a id="_idTextAnchor723"/><span class="koboSpan" id="kobo.494.1"> the holiday effects to the data, which is a good recipe for overfitting. </span><span class="koboSpan" id="kobo.494.2">If National Geographic had several similar marketing events, they could model all of them as the same holiday, which would average out </span><span class="No-Break"><span class="koboSpan" id="kobo.495.1">the effects.</span></span></p>
<p><span class="koboSpan" id="kobo.496.1">This technique of modeling outliers as special events can even be used to model dramatic shocks to an entire time series. </span><span class="koboSpan" id="kobo.496.2">In the next section, we’ll see how to apply these principles to model the effects of COVID-19 lockdowns </span><a id="_idTextAnchor724"/><a id="_idTextAnchor725"/><span class="koboSpan" id="kobo.497.1">on </span><span class="No-Break"><span class="koboSpan" id="kobo.498.1">pedestrian activity.</span></span></p>
<h1 id="_idParaDest-119"><a id="_idTextAnchor726"/><span class="koboSpan" id="kobo.499.1">Modeling shocks such as COVID-19 lockdowns</span></h1>
<p><span class="koboSpan" id="kobo.500.1">In mid-2020, forecasters the </span><a id="_idIndexMarker420"/><span class="koboSpan" id="kobo.501.1">world over were at a loss for what to predict in the coming months and years. </span><span class="koboSpan" id="kobo.501.2">The COVID-19 pandemic utterly transformed life around the world and, with it, many time series. </span><span class="koboSpan" id="kobo.501.3">Online purchases skyrocketed beyond anything anyone had predicted at the beginning of 2020; consumption of media such as Netflix and YouTube dramatically increased, while in-person event attendance </span><span class="No-Break"><span class="koboSpan" id="kobo.502.1">dramatically decreased.</span></span></p>
<p><span class="koboSpan" id="kobo.503.1">As brilliant as Prophet can be when it comes to forecasting, it cannot simply predict the future. </span><span class="koboSpan" id="kobo.503.2">In the midst of the pandemic, Prophet would have struggled just as much as the forecasting experts at predicting when the pandemic would end and how time series would behave both during and after the lockdowns. </span><span class="koboSpan" id="kobo.503.3">However, we can model such shocks to the system after the fact in order to understand what effect they had. </span><span class="koboSpan" id="kobo.503.4">And just like the NatGeo promotion we modeled in the previous section, we can predict what would result from a hypothetical repeat of such a shock. </span><span class="koboSpan" id="kobo.503.5">In this section, we’ll use a new dataset, the number of pedestrians in the Bourke Street Mall in </span><span class="No-Break"><span class="koboSpan" id="kobo.504.1">Melbourne, Australia.</span></span></p>
<p><span class="koboSpan" id="kobo.505.1">Since 2009, the city of Melbourne has counted pedestrians at several locations throughout the city through automated sensors. </span><span class="koboSpan" id="kobo.505.2">The data is shared on the city’s website, updated each month, and contains the hourly counts of pedestrians at each sensor. </span><span class="koboSpan" id="kobo.505.3">To make our analysis easier, the data we will use in this example has been pre-aggregated to daily counts, and we’ll only use the data from one sensor – the southern-most Bourke Street </span><span class="No-Break"><span class="koboSpan" id="kobo.506.1">Mall sensor.</span></span></p>
<p><span class="koboSpan" id="kobo.507.1">Bourke Street is one of Melbourne’s main streets, traditionally the entertainment hub of the city. </span><span class="koboSpan" id="kobo.507.2">It is a popular tourist destination and features many restaurants and major retail outlets. </span><span class="koboSpan" id="kobo.507.3">As the pandemic lockdowns most strongly affected tourism, restaurants, and in-person retail, this location seems like a prime spot to observe the effects of lockdown. </span><span class="koboSpan" id="kobo.507.4">Further, the government of the state of Victoria declared four official lockdown periods of varying lengths. </span><span class="koboSpan" id="kobo.507.5">We might expect these to mark clear and abrupt changes in behavior. </span><span class="koboSpan" id="kobo.507.6">Let’s load the</span><a id="_idIndexMarker421"/><span class="koboSpan" id="kobo.508.1"> dataset and take a look </span><span class="No-Break"><span class="koboSpan" id="kobo.509.1">at it:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.510.1">
df = pd.read_csv('pedestrian_counts.csv')
df['Date'] = pd.to_datetime(df['Date'])
plt.figure(figsize=(10, 6))
plt.scatter(x=df['Date'],
            y=df['Daily_Counts'],
            c='#0072B2')
plt.xlabel('Date')
plt.ylabel('Pedestrians per day')
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.511.1">The data shows a moderately flat trend with obvious seasonal effects and, of course, a severe anomaly continuing onward from the beginning </span><span class="No-Break"><span class="koboSpan" id="kobo.512.1">of 2020:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer221">
<span class="koboSpan" id="kobo.513.1"><img alt="Figure 10.16 – A daily count of pedestrians ﻿in the Bourke Street Mall" src="image/Fig_10.16.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.514.1">Figure 10.16 – A daily count of pedestrians in the Bourke Street Mall</span></p>
<p><span class="koboSpan" id="kobo.515.1">The dataset contains </span><a id="_idIndexMarker422"/><span class="koboSpan" id="kobo.516.1">several columns that aren’t of interest to us for this analysis, so before we can see how Prophet will handle a forecast, we need to extract only the </span><strong class="source-inline"><span class="koboSpan" id="kobo.517.1">Date</span></strong><span class="koboSpan" id="kobo.518.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.519.1">Daily_Counts</span></strong><span class="koboSpan" id="kobo.520.1"> columns and rename them in </span><span class="No-Break"><span class="koboSpan" id="kobo.521.1">Prophet’s format:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.522.1">
df = df[['Date', 'Daily_Counts']]
df.columns = ['ds', 'y']</span></pre>
<p><span class="koboSpan" id="kobo.523.1">Now, let’s build a basic forecast, looking ahead a </span><span class="No-Break"><span class="koboSpan" id="kobo.524.1">full year:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.525.1">
model = Prophet(seasonality_mode='multiplicative')
model.fit(df)
future = model.make_future_dataframe(periods=365)
forecast = model.predict(future)
fig = model.plot(forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.526.1">The forecast seems to be making an admirable effort to fit the trend around the </span><span class="No-Break"><span class="koboSpan" id="kobo.527.1">COVID shock:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer222">
<span class="koboSpan" id="kobo.528.1"><img alt="Figure 10.17 – A forecast with no special consideration of shock" src="image/Fig_10.17.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.529.1">Figure 10.17 – A forecast with no special consideration of shock</span></p>
<p><span class="koboSpan" id="kobo.530.1">This model provides us </span><a id="_idIndexMarker423"/><span class="koboSpan" id="kobo.531.1">no insight into what effect we can attribute to the lockdowns specifically. </span><span class="koboSpan" id="kobo.531.2">In order to model this lockdown shock, we will create holidays to represent days in lockdown and treat the shock similarly to how we treated NatGeo’s promotion in the previous section. </span><span class="koboSpan" id="kobo.531.3">To do this, we first need to define our lockdown holidays (a bit of an </span><span class="No-Break"><span class="koboSpan" id="kobo.532.1">ironic oxymoron!).</span></span></p>
<p><span class="koboSpan" id="kobo.533.1">In </span><a href="B19630_06.xhtml#_idTextAnchor375"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.534.1">Chapter 6</span></em></span></a><span class="koboSpan" id="kobo.535.1">, </span><em class="italic"><span class="koboSpan" id="kobo.536.1">Forecasting Holiday Effects</span></em><span class="koboSpan" id="kobo.537.1">, you learned how to create multi-day holidays using </span><strong class="source-inline"><span class="koboSpan" id="kobo.538.1">lower_window</span></strong><span class="koboSpan" id="kobo.539.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.540.1">upper_window</span></strong><span class="koboSpan" id="kobo.541.1">. </span><span class="koboSpan" id="kobo.541.2">We’ll do that again here, defining each of the four official lockdowns with a start date and using </span><strong class="source-inline"><span class="koboSpan" id="kobo.542.1">upper_window</span></strong><span class="koboSpan" id="kobo.543.1"> to set the length of </span><span class="No-Break"><span class="koboSpan" id="kobo.544.1">the lockdown:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.545.1">
lockdowns = pd.DataFrame([
    {'holiday':'lockdown1',
     'ds': pd.to_datetime('2020-03-21'),
     'lower_window': 0,
     'upper_window': 77},
    {'holiday':'lockdown2',
     'ds': pd.to_datetime('2020-07-09'),
     'lower_window': 0,
     'upper_window': 110},
    {'holiday':'lockdown3',
     'ds': pd.to_datetime('2021-02-13'),
     'lower_window': 0,
     'upper_window': 4},
    {'holiday':'lockdown4',
     'ds': pd.to_datetime('2021-05-28'),
     'lower_window': 0,
     'upper_window': 13}])</span></pre>
<p><span class="koboSpan" id="kobo.546.1">We don’t specify any future dates, so Prophet will not attempt to repeat these lockdowns at any </span><a id="_idIndexMarker424"/><span class="koboSpan" id="kobo.547.1">point in the future. </span><span class="koboSpan" id="kobo.547.2">When we create our next model, we pass this </span><strong class="source-inline"><span class="koboSpan" id="kobo.548.1">lockdown</span></strong><span class="koboSpan" id="kobo.549.1"> DataFrame to the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.550.1">holidays</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.551.1"> argument:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.552.1">
model = Prophet(seasonality_mode='multiplicative',
                holidays=lockdowns)
model.fit(df)
future = model.make_future_dataframe(periods=365)
forecast = model.predict(future)
fig = model.plot(forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.553.1">Our resulting forecast looks very similar to the one in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.554.1">Figure 10</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.555.1">.17</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.556.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer223">
<span class="koboSpan" id="kobo.557.1"><img alt="Figure 10.18 – A forecast with the lockdown modeled as holidays" src="image/Fig_10.18.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.558.1">Figure 10.18 – A forecast with the lockdown modeled as holidays</span></p>
<p><span class="koboSpan" id="kobo.559.1">Now, however, when </span><a id="_idIndexMarker425"/><span class="koboSpan" id="kobo.560.1">we look at the </span><strong class="source-inline"><span class="koboSpan" id="kobo.561.1">components</span></strong><span class="koboSpan" id="kobo.562.1"> plot, we’ll see the specific effect of </span><span class="No-Break"><span class="koboSpan" id="kobo.563.1">those lockdowns:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.564.1">
fig2 = model.plot_components(forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.565.1">We see a roughly 100% reduction in pedestrian numbers in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.566.1">holidays</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.567.1"> plot!</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer224">
<span class="koboSpan" id="kobo.568.1"><img alt="Figure 10.19 – The components plot showing the effect of COVID-19 lockdowns" src="image/Fig_10.19.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.569.1">Figure 10.19 – The components plot showing the effect of COVID-19 lockdowns</span></p>
<p><span class="koboSpan" id="kobo.570.1">The plot of holidays </span><a id="_idIndexMarker426"/><span class="koboSpan" id="kobo.571.1">in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.572.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.573.1">.19</span></em><span class="koboSpan" id="kobo.574.1"> demonstrates how effectively the lockdowns brought pedestrian traffic nearly to a standstill. </span><span class="koboSpan" id="kobo.574.2">Another, possibly even longer-lasting, effect of the lockdowns has been the transition to remote work. </span><span class="koboSpan" id="kobo.574.3">Many workers throughout the world have been able to perform their job duties from home, and are no longer as strictly chained to the Monday–Friday, 9:00–5:00 schedule. </span><span class="koboSpan" id="kobo.574.4">We can hypothesize that this might change the weekly seasonality to some degree. </span><span class="koboSpan" id="kobo.574.5">The weekly peak shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.575.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.576.1">.19</span></em><span class="koboSpan" id="kobo.577.1"> indicates that Friday is the most popular day on Bourke Street, followed by Saturday. </span><span class="koboSpan" id="kobo.577.2">Does this pattern remain </span><span class="No-Break"><span class="koboSpan" id="kobo.578.1">true post-COVID-19?</span></span></p>
<p><span class="koboSpan" id="kobo.579.1">You learned how to create conditional seasonalities in </span><a href="B19630_05.xhtml#_idTextAnchor254"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.580.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.581.1">, </span><em class="italic"><span class="koboSpan" id="kobo.582.1">Working with Seasonality</span></em><span class="koboSpan" id="kobo.583.1">; let’s use that same principle now to create a pre-COVID-19 weekly seasonality and a post-COVID-19 weekly seasonality. </span><span class="koboSpan" id="kobo.583.2">We will define a </span><strong class="source-inline"><span class="koboSpan" id="kobo.584.1">pre_covid</span></strong><span class="koboSpan" id="kobo.585.1"> seasonality for all dates before the first lockdown began and a </span><strong class="source-inline"><span class="koboSpan" id="kobo.586.1">post_covid</span></strong><span class="koboSpan" id="kobo.587.1"> seasonality for all dates after the final lockdown ended. </span><span class="koboSpan" id="kobo.587.2">We could also create a </span><strong class="source-inline"><span class="koboSpan" id="kobo.588.1">during_covid</span></strong><span class="koboSpan" id="kobo.589.1"> seasonality for those dates in between, but as pedestrian traffic ground to a halt with no data available, any insights gained from such a seasonality would be meaningless at best and potentially </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">even misleading:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.591.1">
df['pre_covid'] = df['ds'] &lt; '2020-03-21'
df['post_covid'] = df['ds'] &gt; '2021-06-10'</span></pre>
<p><span class="koboSpan" id="kobo.592.1">We’ll now make a third forecast of this data, but this time, we will turn off the default weekly seasonality and add our two conditional weekly seasonalities. </span><span class="koboSpan" id="kobo.592.2">Remember that we must add these conditions to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.593.1">future</span></strong><span class="koboSpan" id="kobo.594.1"> DataFrame </span><span class="No-Break"><span class="koboSpan" id="kobo.595.1">as well!</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.596.1">
model = Prophet(seasonality_mode='multiplicative',
                weekly_seasonality=False,
                holidays=lockdowns)
model.add_seasonality(
    name='weekly_pre_covid',
    period=7,
    fourier_order=3,
    condition_name='pre_covid',
)
model.add_seasonality(
    name='weekly_post_covid',
    period=7,
    fourier_order=3,
    condition_name='post_covid',
)
model.fit(df)
future = model.make_future_dataframe(periods=365)
future['pre_covid'] = future['ds'] &lt; '2020-03-21'
future['post_covid'] = future['ds'] &gt; '2021-06-10'
forecast = model.predict(future)
fig = model.plot(forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.597.1">Running this </span><a id="_idIndexMarker427"/><span class="koboSpan" id="kobo.598.1">code will produce the </span><span class="No-Break"><span class="koboSpan" id="kobo.599.1">following plot:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer225">
<span class="koboSpan" id="kobo.600.1"><img alt="Figure 10.20 – A forecast with conditional weekly seasonalities" src="image/Fig_10.20.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.601.1">Figure 10.20 – A forecast with conditional weekly seasonalities</span></p>
<p><span class="koboSpan" id="kobo.602.1">Finally, let’s take a </span><a id="_idIndexMarker428"/><span class="koboSpan" id="kobo.603.1">look at the </span><strong class="source-inline"><span class="koboSpan" id="kobo.604.1">components</span></strong><span class="koboSpan" id="kobo.605.1"> plot to see what lasting effect the </span><span class="No-Break"><span class="koboSpan" id="kobo.606.1">lockdowns produced:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.607.1">
fig2 = model.plot_components(forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.608.1">The trend, holidays, and yearly seasonality look much the same as in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.609.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.610.1">.19</span></em><span class="koboSpan" id="kobo.611.1">, so they have been cropped out of the following plot, which only shows the two weekly seasonalities for pre- and </span><span class="No-Break"><span class="koboSpan" id="kobo.612.1">post-COVID-19 lockdowns:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer226">
<span class="koboSpan" id="kobo.613.1"><img alt="Figure 10.21 – A cropped components plot showing the conditional seasonalities" src="image/Fig_10.21.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.614.1">Figure 10.21 – A cropped components plot showing the conditional seasonalities</span></p>
<p><span class="koboSpan" id="kobo.615.1">As we noted </span><a id="_idIndexMarker429"/><span class="koboSpan" id="kobo.616.1">in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.617.1">Figure 10</span></em></span><em class="italic"><span class="koboSpan" id="kobo.618.1">.19</span></em><span class="koboSpan" id="kobo.619.1">, Friday was the most popular day on Bourke Street pre-COVID-19. </span><span class="koboSpan" id="kobo.619.2">However, post-COVID-19, it appears that Saturday is the most popular day. </span><span class="koboSpan" id="kobo.619.3">With more people working from home, it seems that there might be fewer post-work happy hours on Friday, and instead, people are staying in! </span><span class="koboSpan" id="kobo.619.4">Perhaps Netflix is seeing a reverse pattern in its </span><span class="No-Break"><span class="koboSpan" id="kobo.620.1">consumption data…</span></span></p>
<h1 id="_idParaDest-120"><a id="_idTextAnchor727"/><span class="koboSpan" id="kobo.621.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.622.1">Outliers are a fact of any data analysis, but they do not always have to cause headaches. </span><span class="koboSpan" id="kobo.622.2">Prophet is very robust at handling most outliers without any special consideration, but sometimes problems can arise. </span><span class="koboSpan" id="kobo.622.3">In this chapter, you learned about the two problems most common with outliers in Prophet – uncontrolled seasonality and exploding </span><span class="No-Break"><span class="koboSpan" id="kobo.623.1">uncertainty intervals.</span></span></p>
<p><span class="koboSpan" id="kobo.624.1">In both cases, simply removing the data is the best approach to solving the problem. </span><span class="koboSpan" id="kobo.624.2">As long as data exists in other periods of the seasonality cycles for those gaps where data was removed, Prophet has no problem finding a </span><span class="No-Break"><span class="koboSpan" id="kobo.625.1">good fit.</span></span></p>
<p><span class="koboSpan" id="kobo.626.1">You also learned several automated outlier detection techniques, from the basic techniques of Winsorization and trimming, which tend not to work well on time series exhibiting a trend, to the more advanced technique of stacking forecasts and using errors in the first model to remove outliers for the </span><span class="No-Break"><span class="koboSpan" id="kobo.627.1">second model.</span></span></p>
<p><span class="koboSpan" id="kobo.628.1">Finally, you learned how to model both outliers and significant, lasting shocks such as COVID-19 lockdowns as special events, which has much the same effect as removing the data while retaining the information from that outlier. </span><span class="koboSpan" id="kobo.628.2">This technique has the advantage of allowing you to simulate a similar shock occurring in the future with your </span><span class="No-Break"><span class="koboSpan" id="kobo.629.1">time series.</span></span></p>
<p><span class="koboSpan" id="kobo.630.1">In the next chapter, we’ll look at a concept related to outliers – </span><span class="No-Break"><span class="koboSpan" id="kobo.631.1">uncertainty intervals.</span></span></p>
</div>
<div>
<div class="IMG---Figure" id="_idContainer228">
</div>
</div>
</body></html>