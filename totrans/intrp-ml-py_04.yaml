- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Global Model-Agnostic Interpretation Methods
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全球模型无关解释方法
- en: 'In the first part of this book, we introduced the concepts, challenges, and
    purpose of machine learning interpretation. This chapter kicks off the second
    part, which dives into a vast array of methods that are used to diagnose models
    and understand their underlying data. One of the biggest questions answered by
    interpretation methods is: *What matters most to the model and how does it matter?*
    Interpretation methods can shed light on the overall importance of features and
    how they—individually or combined—impact a model’s outcome. This chapter will
    provide a theoretical and practical foundation to approach these questions.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第一部分，我们介绍了机器学习解释的概念、挑战和目的。本章开启了第二部分，深入探讨用于诊断模型和理解其底层数据的各种方法。解释方法回答的最大问题之一是：*模型最关心的是什么，以及它是如何关心的？*
    解释方法可以揭示特征的整体重要性以及它们如何——单独或结合——影响模型的输出。本章将为回答这些问题提供理论和实践基础。
- en: Initially, we will explore the notion of feature importance by examining the
    model’s inherent parameters. Following that, we will study how to employ **permutation
    feature importance** in a model-agnostic manner to effectively, reliably, and
    autonomously rank features. Finally, we will outline how **SHapley Additive exPlanations**
    (**SHAP**) can rectify some of the shortcomings of permutation feature importance.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将通过检查模型的内在参数来探讨特征重要性的概念。随后，我们将研究如何以模型无关的方式使用**置换特征重要性**来有效地、可靠地、自主地对特征进行排序。最后，我们将概述**SHapley
    Additive exPlanations**（**SHAP**）如何纠正置换特征重要性的某些不足。
- en: This chapter will look at several ways to visualize global explanations, such
    as SHAP’s bar and beeswarm plots, and then dive into feature-specific visualizations
    like **Partial Dependence Plots** (**PDP**) and **Accumulated Local Effect** (**ALE**)
    plots. Lastly, feature interactions can enrich explanations because features often
    team up, so we will discuss 2-dimensional PDP and ALE plots.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨几种可视化全局解释的方法，例如SHAP的条形图和蜂群图，然后深入到特征特定的可视化，如**部分依赖图**（**PDP**）和**累积局部效应**（**ALE**）图。最后，特征交互可以丰富解释，因为特征通常会结成团队，所以我们将讨论二维PDP和ALE图。
- en: 'The following are the main topics we are going to cover in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖的主要内容包括：
- en: What is feature importance?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是特征重要性？
- en: Gauging feature importance with model-agnostic methods
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用模型无关方法衡量特征重要性
- en: 'Using SHAP, PDP, and ALE plots to visualize:'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SHAP、PDP和ALE图可视化：
- en: Global explanations
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全局解释
- en: Feature summary explanations
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征总结说明
- en: Feature interactions
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征交互
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter’s example uses the `pandas`, `numpy`, `sklearn`, `catboost`, `seaborn`,
    `matplotlib`, `shap`, `pdpbox`, and `pyale` libraries. Instructions on how to
    install all of these libraries are in the GitHub repository `README.md` file.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的示例使用了`pandas`、`numpy`、`sklearn`、`catboost`、`seaborn`、`matplotlib`、`shap`、`pdpbox`和`pyale`库。如何安装所有这些库的说明可以在GitHub仓库的`README.md`文件中找到。
- en: 'The code for this chapter is located here: [https://packt.link/Ty0Ev](https://packt.link/Ty0Ev)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码位于此处：[https://packt.link/Ty0Ev](https://packt.link/Ty0Ev)
- en: The mission
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务
- en: The used car market in the United States is a thriving and substantial industry
    with significant economic impact. In recent years, approximately 40 million used
    light vehicles have been sold yearly, representing over two-thirds of the overall
    yearly sales in the automotive sector. In addition, the market has witnessed consistent
    growth, driven by the rising cost of new vehicles, longer-lasting cars, and an
    increasing consumer preference for pre-owned vehicles due to the perception of
    value for money. As a result, this market segment has become increasingly important
    for businesses and consumers.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 美国的二手车市场是一个繁荣且规模庞大的行业，对经济有着显著的影响。近年来，每年大约有4000万辆二手车被售出，占汽车行业年度总销售的超过三分之二。此外，该市场一直保持着持续的增长，这得益于新车成本的上升、汽车使用寿命的延长以及消费者对性价比的感知不断增强。因此，这个市场细分对企业和消费者来说变得越来越重要。
- en: Given the market opportunity, a tech startup is currently working on a machine-learning-driven,
    two-sided marketplace for used car sales. It plans to work much like the e-commerce
    site eBay, except it’s focused on cars. For example, sellers can list their cars
    at a fixed price or auction them, and buyers can either pay the higher fixed price
    or participate in the auction, but how do you come up with a starting point for
    the price? Typically, sellers define the price, but the site can generate an optimal
    price that maximizes the overall value for all participants, ensuring that the
    platform remains attractive and sustainable in the long run.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于市场机会，一家技术初创公司目前正在开发一个基于机器学习的二手车销售双边市场。它计划与电子商务网站eBay类似，但专注于汽车。例如，卖家可以以固定价格列出他们的汽车或将其拍卖，买家可以选择支付更高的固定价格或参与拍卖，但你是如何确定价格起点的呢？通常，卖家定义价格，但网站可以生成一个最优价格，以最大化所有参与者的整体价值，确保平台在长期内保持有吸引力和可持续性。
- en: Optimal pricing is not a simple solution since it has to maintain a healthy
    balance between the number of buyers and sellers on the platform while being perceived
    as fair by both buyers and sellers. It remains competitive with other platforms
    while being profitable. However, it all starts with a price prediction model that
    can estimate the fair value, and then, from there, it can incorporate other models
    and constraints to adjust it. To that end, one of the startup’s data scientists
    has obtained a dataset of used car listings from Craigslist and merged it with
    other sources, such as the U.S. Census Bureau for demographic data and the **Environmental
    Protection Agency** (**EPA**) for emissions data. The idea is to train a model
    with this dataset, but we are unsure what features are helpful. And that’s where
    you come in!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳定价并非简单解决方案，因为它需要在平台上的买家和卖家数量之间保持健康平衡，同时确保买家和卖家都认为它是公平的。它需要与其他平台保持竞争力，同时实现盈利。然而，这一切都始于一个能够估算公平价值的定价预测模型，然后，在此基础上，它可以结合其他模型和约束条件进行调整。为此，这家初创公司的一位数据科学家已经从Craigslist获取了二手车列表数据集，并将其与其他来源合并，例如美国人口普查局的人口数据以及**环境保护署**（**EPA**）的排放数据。想法是使用这个数据集训练一个模型，但我们不确定哪些特征是有帮助的。这正是你需要介入的地方！
- en: You have been hired to explain which features are useful to the machine learning
    model and why. This is critical because the startup only wants to ask sellers
    to provide the bare minimum of details about their car before they get a price
    estimate. Of course, there are details like the car’s make and model and even
    the color that another machine learning model can automatically guess from the
    pictures. Still, some features like the transmission or cylinders may vary in
    the car model, and the seller may not know or be willing to disclose them. Limiting
    the questions asked produces the least friction and thus will lead to more sellers
    completing their listings successfully.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你被雇佣来解释哪些特征对机器学习模型有用以及为什么。这是至关重要的，因为初创公司只想要求卖家在获得价格估算之前提供关于他们汽车的最基本信息。当然，有一些细节，如汽车的制造商和型号，甚至颜色，另一个机器学习模型可以从图片中自动猜测。然而，一些特征，如变速器或汽缸数，可能在汽车型号中有所不同，卖家可能不知道或不愿意透露这些信息。限制提问可以减少摩擦，从而使得更多卖家能够成功完成他们的列表。
- en: The approach
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法
- en: 'You have decided to take the following steps:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经决定采取以下步骤：
- en: Train a couple of models.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练几个模型。
- en: Evaluate them.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估它们。
- en: Create feature importance values using several methods, both model-specific
    and model-agnostic.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用多种方法创建特征重要性值，包括模型特定的和非模型特定的。
- en: Plot global summaries, feature summaries, and feature interaction plots to understand
    how these features relate to the outcome and each other.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制全局摘要图、特征摘要图和特征交互图，以了解这些特征如何与结果以及彼此相关。
- en: The plots will help you communicate findings to the tech startup executives
    and your data science colleagues.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图表将帮助你向技术初创公司的管理层和数据科学同事传达发现。
- en: The preparations
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'You will find the code for this example here: [https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/main/04/UsedCars.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/main/04/UsedCars.ipynb)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到此示例的代码：[https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/main/04/UsedCars.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/main/04/UsedCars.ipynb)
- en: Loading the libraries
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载库
- en: 'To run this example, you need to install the following libraries:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此示例，您需要安装以下库：
- en: '`mldatasets` to load the dataset'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `mldatasets` 加载数据集
- en: '`pandas` and `numpy` to manipulate it'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `pandas` 和 `numpy` 进行操作
- en: '`sklearn` (scikit-learn) and `catboost` to load and configure the model'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `sklearn`（scikit-learn）和 `catboost` 加载和配置模型
- en: '`matplotlib`, `seaborn`, `shap`, `pdpbox`, and `pyale` to generate and visualize
    the model interpretations'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `matplotlib`、`seaborn`、`shap`、`pdpbox` 和 `pyale` 生成和可视化模型解释
- en: 'You should load all of them first:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该首先加载所有这些：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can inspect it using the `usedcars_df.info()` function and verify that there
    are indeed over 256,000 rows and 29 columns with no nulls. Some of them are `object`
    data types because they are categorical.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 `usedcars_df.info()` 函数进行检查，并验证确实有超过256,000行和29列，没有空值。其中一些是 `object` 数据类型，因为它们是分类数据。
- en: 'The data dictionary for the dataset is as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集的数据字典如下：
- en: 'Variables related to the listing:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与列表相关的变量：
- en: '`price`: target, continuous, the price posted for the vehicle'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`price`：目标，连续型，表示车辆发布的价格'
- en: '`region`: categorical, the region for the listing—usually this is a city, metropolitan
    area, or (for more rural areas) a portion of a state or a least populated state
    (out of 402)'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`region`：分类，表示列表的地区——通常这是一个城市、大都市区或（对于更乡村的地区）州的一部分或人口最少的州（共402个）'
- en: '`posting_date`: datetime, the date and time of the posting (all postings are
    for a single month period in 2021 so you cannot observe seasonal patterns with
    it)'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`posting_date`：日期时间，表示发布日期和时间（所有发布都是2021年单月期间的，因此您无法通过它观察到季节性模式）'
- en: '`lat`: continuous, the latitude in decimal format'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lat`：连续型，表示十进制度纬度'
- en: '`long`: continuous, the longitude in decimal format'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`long`：连续型，表示十进制度经度'
- en: '`state`: categorical, the two-letter state code (out of 51 including [DC])'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`state`：分类，表示两位州代码（共51个，包括[DC]）'
- en: '`city`: categorical, the name of the city (out of over 6,700)'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`city`：分类，表示城市名称（共超过6,700个）'
- en: '`zip`: nominal, the zip code (out of over 13,100)'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zip`：名义型，表示邮政编码（共超过13,100个）'
- en: 'Variables related to the vehicle:'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与车辆相关的变量：
- en: '`make`: categorical, the brand or manufacturer of the vehicle (out of 37)'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`make`：分类，表示车辆的品牌或制造商（共37个）'
- en: '`make_cat`: categorical, the category for the make (out of 5). It’s [obsolete]
    for makes no longer produced, such as “Saturn,” [luxury sports] for brands like
    “Ferrari,” and [luxury] for brands like “Mercedes-Benz.” Everything else is [regular]
    or [premium]. The only difference is that [premium] include brands like “Cadillac”
    and “Acura,” which are the high-end brands of car manufacturers in the [regular]
    category.'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`make_cat`：分类，表示制造商的类别（共5个）。对于不再生产的制造商，如“Saturn”，[豪华运动型]适用于“法拉利”等品牌，[豪华型]适用于“奔驰”等品牌。其他所有都是[常规型]或[高级型]。唯一的区别是[高级型]包括像“凯迪拉克”和“Acura”这样的品牌，它们是[常规型]类别中汽车制造商的高端品牌。'
- en: '`make_pop`: continuous, the relative popularity of the make in percentiles
    (0–1)'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`make_pop`：连续型，表示制造商的相对流行度（百分比，0-1）'
- en: '`model`: categorical, the model (out of over 17,000)'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`：分类，表示车型（共超过17,000个）'
- en: '`model_premier`: binary, whether the model is a luxury version/trim of a model
    (if the model itself is not already high-end such as those in the luxury, luxury
    sports, or premium categories)'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_premier`：二元型，表示该车型是否是豪华版本/修剪（如果该车型本身不是高端，例如豪华、豪华运动型或高级类别）'
- en: '`year`: ordinal, the year of the model (from 1984–2022)'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`year`：序数型，表示车型的年份（从1984-2022）'
- en: '`make_yr_pop`: continuous, the relative popularity of the make for the year
    it was made for in percentiles (0–1)'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`make_yr_pop`：连续型，表示制造商在其制造年份的相对流行度（百分比，0-1）'
- en: '`model_yr_pop`: continuous, the relative popularity of the model for the year
    it was made in percentiles (0–1)'
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_yr_pop`：连续型，表示该车型在其制造年份的相对流行度（百分比，0-1）'
- en: '`odometer`: continuous, the reading in the vehicle’s odometer'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`odometer`：连续型，表示车辆里程表上的读数'
- en: '`auto_trans`: binary, whether the car has automatic transmission—otherwise,
    it is manual'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auto_trans`：二元型，表示汽车是否有自动变速器——否则为手动变速'
- en: '`fuel`: categorical, the type of fuel used (out of 5: [gas], [diesel], [hybrid],
    [electric] and [other])'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fuel`：分类，表示使用的燃料类型（共5个：[gas]、[diesel]、[hybrid]、[electric] 和 [other]）'
- en: '`model_type`: categorical (out of 13: [sedan], [SUV], and [pickup] are the
    three most popular, by far)'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_type`：分类（共13个：[sedan]、[SUV] 和 [pickup] 是最受欢迎的三个，远远超过其他）'
- en: '`drive`: categorical, whether it’s four-wheel, front-wheel, or rear-wheel drive
    (out of 3: [4wd], [fwd] and [rwd])'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drive`：分类，表示是四轮驱动、前轮驱动还是后轮驱动（共3个：[4wd]、[fwd] 和 [rwd]）'
- en: '`cylinders`: nominal, the number of cylinders of the engine (from 2–16). Generally,
    the more cylinders, the higher the horsepower'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cylinders`：名义，发动机的汽缸数（从2到16）。一般来说，汽缸越多，马力越高'
- en: '`title_status`: categorical, what the title says about the status of the vehicle
    (out of 7 like [clean], [rebuilt], [unknown], [salvage], and [lien])'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`title_status`：分类，标题对车辆状态（在7个类别中，如[clean]、[rebuilt]、[unknown]、[salvage]和[lien]）的描述'
- en: '`condition`: categorical, what the owner reported the condition of the vehicle
    to be (out of 7 like [good], [unknown], [excellent] and [like new])'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`condition`：分类，车主报告的车辆状况（在7个类别中，如[good]、[unknown]、[excellent]和[like new]）'
- en: 'Variables related to the emissions of the vehicle:'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与车辆排放相关的变量：
- en: '`epa_co2`: continuous, tailpipe CO2 in grams/mile. For models after 2013, it
    is based on EPA tests. For previous years, CO2 is estimated using an EPA emission
    factor (`-1` = not vvailable)'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epa_co2`：连续，尾气排放的CO2（以克/英里计）。对于2013年之后的模型，它基于EPA测试。对于之前的年份，CO2使用EPA排放因子（`-1`
    =不可用）进行估算'
- en: '`epa_displ`: continuous, the engine displacement (in liters 0.6–8.4)'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epa_displ`：连续，发动机排量（以升计，0.6-8.4）'
- en: 'Variables related to the ZIP code of the listing:'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与列表的ZIP代码相关的变量：
- en: '`zip_population`: continuous, the population'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zip_population`：连续，人口'
- en: '`zip_density`: continuous, the density (residents per sq. mile)'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zip_density`：连续，密度（每平方英里的居民数）'
- en: '`est_households_medianincome_usd`: continuous, the median household income'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`est_households_medianincome_usd`：连续，家庭中位数收入'
- en: Data preparation
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'We should apply categorical encoding to them so that there’s one column per
    category, but only if the category has at least 500 records. We can do this with
    the `make_dummies_with_limits` utility function. But first, let’s back up the
    original dataset:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该对这些变量应用分类编码，以便每个类别有一个列，但只有当类别至少有500条记录时才这样做。我们可以使用`make_dummies_with_limits`实用函数来完成此操作。但首先，让我们备份原始数据集：
- en: '[PRE2]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We don’t need any of these columns since we have `latitude`, `longitude`, and
    some of the demographic features, which provide the model with some idea of where
    the car was being sold. As for the `make` and `model`, we have the `make` and
    `model` popularity and category features. We can remove the non-numerical features
    by simply only selecting the numerical ones like this:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要这些列，因为我们已经有了`latitude`、`longitude`以及一些人口统计特征，这些特征为模型提供了一些关于汽车销售地点的信息。至于`make`和`model`，我们有`make`和`model`的流行度和类别特征。我们可以通过仅选择数值特征来简单地删除非数值特征，如下所示：
- en: '[PRE4]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The final data preparation steps are to:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的数据准备步骤是：
- en: Define our random seed (`rand`) to ensure reproducibility.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义我们的随机种子（`rand`）以确保可重复性。
- en: Split data into `X` (features) and `y` (labels). The former has all columns
    except for the target variable (`target_col`). The latter is only the target.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为`X`（特征）和`y`（标签）。前者包含所有列，除了目标变量（`target_col`）。后者仅包含目标。
- en: 'Lastly, divide both `X` and `y` into train and test components randomly using
    scikit-learn’s `train_test_split` function:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用scikit-learn的`train_test_split`函数随机将`X`和`y`分为训练和测试组件：
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now we have everything to move forward so we will go ahead with some model training!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了继续前进所需的一切，所以我们将继续进行一些模型训练！
- en: Model training and evaluation
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练和评估
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we can evaluate the CatBoost model using a **regression plot**, and a
    few metrics. Run the following code, which will output *Figure 4.1*:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用**回归图**和一些指标来评估CatBoost模型。运行以下代码，将输出*图4.1*：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The CatBoost model produced a high R-squared of 0.94 and a test RMSE of nearly
    3,100\. The regression plot in *Figure 4.1* tells us that although there are quite
    a few cases that have an extremely high error, the vast majority of the 64,000
    test samples were predicted fairly well. You can confirm this by running the following
    code:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost模型产生了高达0.94的R-squared和近3,100的测试RMSE。*图4.1*中的回归图告诉我们，尽管有相当多的案例具有极高的误差，但64,000个测试样本中的绝大多数都被相当好地预测了。你可以通过运行以下代码来确认这一点：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'It says that the percentage of test samples with an absolute error in the $4,000
    range is nearly 90%. Granted it’s a large margin of error for cars that cost a
    few thousand, but we just want to get a sense of how accurate the model is. We
    will likely need to improve it for production, but for now, it will do for the
    exercise requested by the tech startup:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 它表示在$4,000范围内的绝对误差的测试样本百分比接近90%。当然，对于价值几千美元的汽车来说，这是一个很大的误差范围，但我们只是想了解模型的准确性。我们可能需要对其进行改进以用于生产，但现在它将满足技术初创公司要求的练习：
- en: '![](img/B18406_04_01.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_01.png)'
- en: 'Figure 4.1: CatBoost model predictive performance'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：CatBoost模型预测性能
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The Random Forest performs just as well for the test samples, and its metrics
    are remarkably similar to CatBoost, except it overfits much more in this case.
    This matters because we will now compare some feature importance methods on both
    and don’t want differences in predictive performance to be a reason to doubt any
    findings.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林对测试样本的表现同样出色，其指标与CatBoost非常相似，但在这个案例中它过度拟合得更多。这很重要，因为我们现在将在两者上比较一些特征重要性方法，并且不希望预测性能的差异成为怀疑任何发现的原因。
- en: What is feature importance?
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征重要性是什么？
- en: Feature importance refers to the extent to which each feature contributes to
    the final output of a model. For linear models, it’s easier to determine the importance
    since coefficients clearly indicate the contributions of each feature. However,
    this isn’t always the case for non-linear models.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 特征重要性指的是每个特征对模型最终输出的贡献程度。对于线性模型，由于系数明确指示了每个特征的贡献，因此确定其重要性较为容易。然而，对于非线性模型来说，情况并不总是如此。
- en: 'To simplify the concept, let’s compare model classes to various team sports.
    In some sports, it’s easy to identify the players who have the greatest impact
    on the outcome, while in others, it isn’t. Let’s consider two sports as examples:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化这个概念，让我们将模型类别与各种团队运动进行比较。在一些运动中，很容易识别出对比赛结果影响最大的球员，而在另一些运动中则不然。让我们以两项运动为例：
- en: '*Relay race*: In this sport, each runner covers equal distances, and the race’s
    outcome largely depends on the speed at which they complete their part. Thus,
    it’s easy to separate and quantify each racer’s contributions. A relay race is
    similar to a linear model since the race’s outcome is a linear combination of
    independent components.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*接力赛跑*：在这项运动中，每位运动员跑的距离相等，比赛的结局很大程度上取决于他们完成自己部分的速度。因此，很容易分离和量化每位运动员的贡献。接力赛跑与线性模型相似，因为比赛的结局是独立组件的线性组合。'
- en: '*Basketball*: In this game, players have distinct roles, and comparing them
    using the same metrics is not possible. Moreover, the varying game conditions
    and player interactions can significantly affect their contributions to the outcome.
    So, how can we measure and rank each player’s contributions?'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*篮球*：在这项游戏中，球员们有各自不同的角色，使用相同的指标来比较他们是不可能的。此外，不断变化的比赛条件和球员之间的互动可能会显著影响他们对比赛结果的影响。那么，我们如何衡量和排名每位球员的贡献呢？'
- en: Models possess inherent parameters that can occasionally aid in unraveling the
    contributions of each feature. We’ve trained two models. How have their intrinsic
    parameters been used to calculate feature importance?
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 模型具有固有的参数，有时可以帮助揭示每个特征的贡献。我们训练了两个模型。它们的内在参数是如何用来计算特征重要性的？
- en: 'Let’s begin with Random Forest. If you plot one of its estimators with the
    following code, it will generate *Figure 4.2*. Because each estimator is up to
    six levels deep, we will plot only up to the second level (`max_depth=2`) because,
    otherwise, the text would be too small. But feel free to increase the `max_depth`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从随机森林开始。如果你用以下代码绘制其估计器之一，它将生成*图4.2*。因为每个估计器最深可达六层，所以我们只绘制到第二层（`max_depth=2`），因为否则文本会太小。但你可以自由地增加`max_depth`：
- en: '[PRE11]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Notice the `squared_error` and `samples` in each node of the estimator in *Figure
    4.2*. By dividing these numbers, you can calculate the **Mean Squared Error**
    (**MSE**). Although for classifiers, it’s the **Gini coefficient**, for regressors,
    MSE is the impurity measure. It’s expected to decrease as you go deeper in the
    tree, so the sum of these weighted impurity decreases is calculated for each feature
    throughout the tree. How much a feature decreases node impurity indicates how
    much it contributes to the model’s outcome. This would be a **model-specific**
    method since it can’t be used with linear models or neural networks, but this
    is precisely how tree-based models compute feature importance. Random Forest is
    no different. However, it’s an ensemble, so it has a collection of estimators,
    so the feature importance is the mean decrease in impurity across all estimators.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 注意*图4.2*中每个节点估计器的`squared_error`和`samples`。通过将这些数字相除，你可以计算出**均方误差**（**MSE**）。虽然对于分类器来说，它是**基尼系数**，但对于回归器来说，MSE是不纯度度量。随着你深入树中，它预计会降低，因此计算每个特征在整个树中的加权不纯度之和。一个特征降低节点不纯度的程度表明它对模型结果的贡献有多大。这将是一个**特定于模型**的方法，因为它不能用于线性模型或神经网络，但这正是基于树的模型计算特征重要性的方式。随机森林也不例外。然而，它是一个集成，因此它有一系列估计器，所以特征重要性是所有估计器之间不纯度减少的平均值。
- en: '![](img/B18406_04_02.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_04_02.png)'
- en: 'Figure 4.2: First level for the first estimator of the Random Forest model'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2：随机森林模型第一个估计器的第一级
- en: 'We can obtain and print the feature importance values for the Random Forest
    model with the following snippet:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码片段获取并打印随机森林模型的特征重要性值：
- en: '[PRE12]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note that since they have been normalized, they add up to 1 (`sum(rf_feat_imp)`).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于它们已经被归一化，它们的总和为1（`sum(rf_feat_imp)`）。
- en: CatBoost uses a different method, by default, to compute feature importance,
    called `PredictionValuesChange`. It shows how much, on average, the model outcome
    changes if the feature value changes. It traverses the tree performing a weighted
    average of feature contributions according to the number of nodes in each branch
    (left or right). If it encounters a combination of features in a node, it evenly
    assigns contributions to each one. As a result, it can yield misleading feature
    importance values for features that usually interact with one another.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost默认使用一种不同的方法来计算特征重要性，称为`PredictionValuesChange`。它显示了如果特征值发生变化，模型结果平均变化了多少。它在树中遍历，根据每个分支（左或右）中的节点数量对特征贡献进行加权平均。如果它在节点中遇到特征组合，则将贡献平均分配给每个特征。因此，它可能会为通常相互作用的特征产生误导性的特征重要性值。
- en: 'You can also retrieve the CatBoost feature importances with `feature_importances_`
    like this, and unlike Random Forest, they add up to 100 and not 1:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用`feature_importances_`像这样检索CatBoost特征重要性，并且与随机森林不同，它们的总和为100而不是1：
- en: '[PRE13]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Notice that both models have the same most important feature in *Figure 4.3*.
    The top ten features are mostly the same but not in the same rank. In particular,
    `odometer` appears to be much more important for CatBoost than for Random Forest.
    Also, all the other features don’t match up in ranking except for the least important
    ones, for which there’s a consensus that they are indeed last:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在*图4.3*中，两个模型都有相同的最重要特征。前十位特征大多相同，但排名不同。特别是，`odometer`对于CatBoost似乎比对于随机森林更重要。此外，除了最不重要的特征外，其他所有特征在排名上都不匹配，而对于最不重要的特征，人们普遍认为它们确实是最后的：
- en: '![](img/B18406_04_03.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_04_03.png)'
- en: 'Figure 4.3: Compare both models’ feature importance values'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3：比较两个模型的特征重要性值
- en: How can we address these differences and employ a technique that consistently
    represents a feature’s importance? We will explore this using model-agnostic approaches.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何解决这些差异并采用一种始终如一地表示特征重要性的技术？我们将使用模型无关的方法来探讨这个问题。
- en: Assessing feature importance with model-agnostic methods
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用模型无关方法评估特征重要性
- en: '**Model-agnostic** methods imply that we will not depend on intrinsic model
    parameters to compute feature importance. Instead, we will consider the model
    as a black box, with only the inputs and output visible. So, how can we determine
    which inputs made a difference?'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型无关**的方法意味着我们将不会依赖于模型参数来计算特征重要性。相反，我们将把模型视为一个黑盒，只有输入和输出是可见的。那么，我们如何确定哪些输入产生了影响？'
- en: 'What if we altered the inputs randomly? Indeed, one of the most effective methods
    for evaluating feature importance is through simulations designed to measure a
    feature’s impact or lack thereof. In other words, let’s remove a random player
    from the game and observe the outcome! In this section, we will discuss two ways
    to achieve this: permutation feature importance and SHAP.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们随机改变输入呢？确实，评估特征重要性最有效的方法之一是通过设计用于衡量特征影响或缺乏影响的模拟。换句话说，让我们从游戏中随机移除一个玩家并观察结果！在本节中，我们将讨论两种实现方式：排列特征重要性和SHAP。
- en: Permutation feature importance
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 排列特征重要性
- en: 'Once we have a trained model, we cannot remove a feature to assess the impact
    of not using it. However, we can:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有一个训练好的模型，我们就不能移除一个特征来评估不使用它的影响。然而，我们可以：
- en: Replace the feature with a static value, such as the mean or median, rendering
    it devoid of useful information.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将特征替换为静态值，如平均值或中位数，使其失去有用的信息。
- en: Shuffle (permute) the feature values to disrupt the relationship between the
    feature and the outcome.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打乱（排列）特征值以破坏特征与结果之间的关系。
- en: 'Permutation feature importance (`permutation_importance`) uses the second strategy
    with a test dataset. Then it measures a change in the score (MSE, r2, f1, accuracy,
    etc.). In this case, a substantial decrease in the negative **Mean Absolute Error**
    (**MAE**) when the feature is shuffled would suggest that the feature has a high
    influence on the prediction. It would have to repeat the shuffling several times
    (`n_repeats`) to arrive at conclusive results by averaging out the decreases in
    accuracy. Please note the default scorer for Random Forest regressors is R-squared,
    while it’s RMSE for CatBoost, so we are making sure they both use the same scorer
    by setting the `scoring` parameter. The following code does all of this for both
    models:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 置换特征重要性(`permutation_importance`)使用测试数据集的第二种策略。然后它测量分数（MSE，r2，f1，准确度等）的变化。在这种情况下，当特征被打乱时，负**平均绝对误差**（**MAE**）的显著下降表明该特征对预测有很高的影响。它必须重复打乱几次（`n_repeats`），通过平均减少准确度来得出结论性的结果。请注意，随机森林回归器的默认评分器是R-squared，而CatBoost是RMSE，所以我们通过设置`scoring`参数确保它们都使用相同的评分器。以下代码为两个模型执行所有这些操作：
- en: '[PRE15]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The method outputs a mean score (`importances_mean`) and a standard deviation
    (`importances_std`) across all repeats for each model, which we can place in a
    `pandas` DataFrame, sort, and format, as we did before with feature importance.
    The following code generates the table in *Figure 4.4*:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法输出每个模型的平均分数（`importances_mean`）和标准差（`importances_std`），这些分数跨越所有重复，我们可以将其放入`pandas`
    DataFrame中，排序和格式化，就像我们之前对特征重要性所做的那样。以下代码生成了*图4.4*中的表格：
- en: '[PRE16]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The first four features for both models in *Figure 4.4* are much more consistent
    than *Figure 4.3*—not that they have to be because they are different models!
    However, it makes sense considering they were derived from the same method. There
    are considerable differences too. Random Forest seems to rely much more heavily
    on fewer features, but these features might not be as necessary if they achieve
    a very similar predictive performance as CatBoost:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图4.4*中，两个模型的前四个特征与*图4.3*相比要一致得多——并不是因为它们必须一致，因为它们是不同的模型！然而，考虑到它们是从相同的方法中得出的，这还是有意义的。也存在相当大的差异。随机森林似乎更依赖于少数特征，但如果它们达到与CatBoost非常相似的预测性能，这些特征可能并不那么必要：
- en: '![](img/B18406_04_04.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_04_04.png)'
- en: 'Figure 4.4: Compare both models’ permutation feature importance values'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4：比较两个模型的置换特征重要性值
- en: 'Permutation feature importance can be understood as the average increase in
    model error when a feature is made irrelevant, along with its interactions with
    other features. It is relatively fast to compute since models don’t need to be
    retrained, but its specific value should be taken with a grain of salt because
    there are some drawbacks to this shuffling technique:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 置换特征重要性可以理解为当特征变得无关紧要时，模型误差的平均增加，以及它与其他特征的交互。由于模型不需要重新训练，它相对快速地计算，但它的具体值应该谨慎对待，因为这种打乱技术有一些缺点：
- en: Shuffling a highly correlated feature with another unshuffled feature may not
    significantly affect predictive performance, as the unshuffled feature retains
    some information from the shuffled one. This means it cannot accurately assess
    the importance of multicollinear features.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将高度相关的特征与另一个未打乱的特征进行打乱可能不会显著影响预测性能，因为未打乱的特征保留了从打乱的特征中的一些信息。这意味着它不能准确评估多重共线性特征的重要性。
- en: Shuffling can lead to unrealistic observations, like predicting vehicle traffic
    with weather and ending up with winter temperatures during the summer. This will
    result in a higher predictive error for a model that has never encountered such
    examples, overstating the importance scores beyond their actual significance.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打乱可能导致不切实际的观察结果，例如用天气预测车辆流量，结果夏天预测出冬季温度。这将导致从未遇到过此类示例的模型预测误差更高，夸大了重要性评分的实际意义。
- en: Therefore, these importance values are only useful to rank the features and
    gauge their relative importance against other features in a particular model.
    We will now explore how Shapley values can help address these issues.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这些重要性值仅适用于对特征进行排序，并衡量它们在特定模型中相对于其他特征的相对重要性。我们现在将探讨Shapley值如何帮助解决这些问题。
- en: SHAP values
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SHAP值
- en: Before delving into SHAP values, we should discuss **Shapley values**. SHAP
    is an implementation of Shapley values that takes some liberties but maintains
    many of the same properties.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究SHAP值之前，我们应该讨论**Shapley值**。SHAP是Shapley值的实现，它采取了一些自由，但保持了许多相同的属性。
- en: It’s appropriate that we’ve been discussing feature importance within the context
    of games, as Shapley values are rooted in **cooperative game theory**. In this
    context, players form different sets called **coalitions**, and when they play,
    they get varying scores known as **marginal contributions**. The Shapley value
    is the average of these contributions across multiple simulations. In terms of
    feature importance, players represent features, sets of players symbolize sets
    of features, and marginal contribution is related to a decrease in predictive
    error.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在游戏的背景下讨论特征重要性是合适的，因为Shapley值植根于**合作博弈论**。在这种情况下，玩家形成不同的集合，称为**联盟**，当他们玩游戏时，他们会得到不同的分数，称为**边际贡献**。Shapley值是这些贡献在多次模拟中的平均值。在特征重要性的方面，玩家代表特征，玩家的集合代表特征的集合，边际贡献与预测误差的减少有关。
- en: 'This approach may seem similar to permutation feature importance, but its focus
    on feature combinations rather than individual features helps tackle the multicollinear
    issue. Moreover, the values obtained through this method satisfy several favorable
    mathematical properties, such as:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可能看起来与置换特征重要性相似，但它的重点是特征组合而不是单个特征，这有助于解决多重共线性问题。此外，通过这种方法获得的价值满足几个有利的数学属性，例如：
- en: '**Additivity**: the sum of the parts adds to the total value'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可加性**：部分的总和等于总价值'
- en: '**Symmetry**: consistent values for equal contributions'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对称性**：对等贡献的一致值'
- en: '**Efficiency**: equal to the difference between the prediction and expected
    value'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：等于预测值与期望值之间的差异'
- en: '**Dummy**: a value of zero for features with no impact on the outcome'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**虚拟值**：对不影响结果的特征的零值'
- en: In practice, this method demands substantial computational resources. For instance,
    five features yield ![](img/B18406_04_001.png) possible coalitions, while 15 features
    result in 32,768\. Therefore, most Shapley implementations use shortcuts like
    Monte Carlo sampling or leveraging the model’s intrinsic parameters (which makes
    them model-specific). The SHAP library employs various strategies to reduce computational
    load without sacrificing Shapley properties too much.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，这种方法需要大量的计算资源。例如，五个特征会产生![img/B18406_04_001.png](img/B18406_04_001.png)个可能的联盟，而15个特征则会产生32,768个。因此，大多数Shapley实现使用像蒙特卡洛采样或利用模型内在参数（这使得它们具有模型特定性）这样的捷径。SHAP库采用各种策略来减少计算负担，同时不会过多牺牲Shapley属性。
- en: Comprehensive explanations with KernelExplainer
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用KernelExplainer的综合解释
- en: Within SHAP, the most prevalent model-agnostic approach is `KernelExplainer`,
    which is based on **Local Interpretable Model-agnostic Explanations** (**LIME**).
    Don’t fret if you don’t understand the specifics since we will cover it in detail
    in *Chapter 5*, *Local Model-Agnostic Interpretation Methods*. To cut down on
    computation, it employs sample coalitions. In addition, it follows the same procedures
    as LIME, such as fitting weighted linear models, but employs Shapley sample coalitions
    and a different kernel that returns SHAP values as coefficients.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在SHAP中，最普遍的模型无关方法是`KernelExplainer`，它基于**局部可解释模型无关解释**（**LIME**）。如果你不理解具体细节，不要担心，我们将在第5章“局部模型无关解释方法”中详细讲解。为了减少计算量，它采用了样本联盟。此外，它遵循与LIME相同的程序，例如拟合加权线性模型，但使用Shapley样本联盟和不同的核函数，该核函数返回SHAP值作为系数。
- en: '`KernelExplainer` can be initialized with a `kmeans` background sample of the
    training dataset (`X_train_summary`), which helps it define the kernels. It can
    be still slow. Therefore, it’s better not to use large datasets to compute the
    `shap_values`. Instead, in the following code, we are using only 2% of the test
    dataset (`X_test_sample`):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`KernelExplainer`可以用训练数据集的`kmeans`背景样本（`X_train_summary`）初始化，这有助于它定义核函数。它可能仍然很慢。因此，最好不要使用大型数据集来计算`shap_values`。相反，在下面的代码中，我们只使用了测试数据集的2%（`X_test_sample`）：'
- en: '[PRE17]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: It might take a while to run the whole thing. Should it take too long, feel
    free to reduce the sample size from `0.02` to `0.005`. SHAP values will be less
    reliable but it’s just an example so you can get a taste of `KernelExplainer`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 运行整个过程可能需要一些时间。如果时间过长，请随意将样本大小从`0.02`减少到`0.005`。SHAP值将不太可靠，但这只是一个示例，你可以尝尝`KernelExplainer`的滋味。
- en: Once it completes, please run `print(rf_shap_values.shape)` to get an idea of
    the dimensions we’ll be dealing with. Note that it’s two dimensions! There’s one
    SHAP value per observation x feature. For this reason, SHAP values can be used
    for both global and local interpretation. Put a pin in that! We will cover the
    local interpretation in the next chapter. For now, we will look at another SHAP
    explainer.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成，请运行`print(rf_shap_values.shape)`来了解我们将要处理的维度。注意，它是二维的！每个观察值和特征都有一个SHAP值。因此，SHAP值可以用于全局和局部解释。记住这一点！我们将在下一章中介绍局部解释。现在，我们将查看另一个SHAP解释器。
- en: Faster explanations with TreeExplainer
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用TreeExplainer加速解释
- en: '`TreeExplainer` was designed to efficiently estimate SHAP values for tree-based
    models such as XGBoost, Random Forest, and CART decision trees. It can allocate
    non-zero values to non-influential features because it employs the conditional
    expectation value function rather than marginal expectation, violating the Shapley
    dummy property. This can have consequences when features are collinear, potentially
    making explanations less reliable. However, it adheres to other properties.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`TreeExplainer`被设计用来高效地估计基于树的模型（如XGBoost、随机森林和CART决策树）的SHAP值。因为它使用条件期望值函数而不是边缘期望值，所以它可以给非影响特征分配非零值，这违反了Shapley虚拟属性。当特征共线性时，这可能会使解释变得不那么可靠。然而，它遵循其他属性。'
- en: 'You can obtain the SHAP values with `TreeExplainer` like this:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`TreeExplainer`获取SHAP值，如下所示：
- en: '[PRE18]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can tell, it’s easier and much quicker. It also outputs a two-dimensional
    array like `KernelExplainer`. You can check with `print(cb_shap_values.shape)`.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这更容易，也更快。它还输出一个类似于`KernelExplainer`的两维数组。您可以使用`print(cb_shap_values.shape)`进行检查。
- en: 'For feature importance values, we can collapse two dimensions into one. All
    we need to do is average the absolute value per feature like this:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特征重要性值，我们可以将两个维度合并为一个。我们只需要像这样对每个特征的平均绝对值进行操作：
- en: '[PRE19]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: For Random Forest, just replace the `cb_` for `rf_` with the same code.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 对于随机森林，只需将`cb_`替换为`rf_`相同的代码。
- en: We can now compare both SHAP feature importances side-by-side using a formatted
    and sorted `pandas` DataFrame. The following code will generate the table in *Figure
    4.5*.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用格式化和排序的`pandas` DataFrame并排比较两个模型的SHAP特征重要性。以下代码将在*图4.5*中生成表格。
- en: '[PRE20]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '*Figure 4.5* not only compares feature importance for two different models
    but also for two different SHAP explainers. They aren’t necessarily perfect depictions,
    but they are both to be trusted more than permutation feature importance:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.5*不仅比较了两个不同模型的特征重要性，还比较了两个不同的SHAP解释器。它们不一定都是完美的描述，但它们都比排列特征重要性更值得信赖：'
- en: '![](img/B18406_04_05.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_05.png)'
- en: 'Figure 4.5: Compare both models’ SHAP feature importance values'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5：比较两个模型的SHAP特征重要性值
- en: SHAP for both models suggest that `loan_to_value_ratio` and `make_cat_va` importances
    were previously deflated. This makes sense because `loan_to_value_ratio` is highly
    correlated with several of the top features and `make_cat_va` with all the other
    product-type features.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于两个模型，SHAP分析表明`loan_to_value_ratio`和`make_cat_va`的重要性之前被低估了。这很有道理，因为`loan_to_value_ratio`与多个顶级特征高度相关，而`make_cat_va`与所有其他产品类型特征相关。
- en: Visualize global explanations
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化全局解释
- en: Previously, we covered the concept of global explanations and SHAP values. But
    we didn’t demonstrate the many ways we can visualize them. As you will learn,
    SHAP values are very versatile and can be used to examine much more than feature
    importance!
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们介绍了全局解释和SHAP值的概念。但我们没有展示我们可以用许多方式可视化它们。正如您将学到的，SHAP值非常灵活，可以用来检查比特征重要性更多的事情！
- en: 'But first, we must initialize a SHAP explainer. In the previous chapter, we
    generated the SHAP values using `shap.TreeExplainer` and `shap.KernelExplainer`.
    This time, we will use SHAP’s newer interface, which simplifies the process by
    saving SHAP values and corresponding data in a single object and much more! Instead
    of explicitly defining the type of explainer, you initialize it with `shap.Explainer(model)`,
    which returns the callable object. Then, you load your test dataset (`X_test`)
    into the callable `Explainer`, and it returns an `Explanation` object:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，我们必须初始化一个SHAP解释器。在前一章中，我们使用`shap.TreeExplainer`和`shap.KernelExplainer`生成SHAP值。这次，我们将使用SHAP的新接口，它通过将SHAP值和对应数据保存在单个对象中以及更多来简化过程！我们不需要显式定义解释器的类型，而是使用`shap.Explainer(model)`初始化它，这将返回可调用的对象。然后，您将测试数据集（`X_test`）加载到可调用的`Explainer`中，它将返回一个`Explanation`对象：
- en: '[PRE21]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In case you are wondering, how did it know what kind of explainer to create?
    Glad you asked! There’s an optional parameter called `algorithm` in the initialization
    function, and you can explicitly define `tree`, `linear`, `additive`, `kernel`,
    and others. But by default, it is set to `auto`, which means it will guess which
    kind of explainer is needed for the model. In this case, CatBoost is a tree ensemble,
    so `tree` is what makes sense. We can easily check that SHAP chose the right explainer
    with `cb_explainer.[dict]{custom-style="P - Italics"}[ or ]print(type(cb_explainer))`.
    It will return `<class ''shap.explainers._tree.Tree''>`, which is correct! As
    for the explanation stored in `cb_shap`, what is it exactly? It’s an object that
    contains pretty much everything that is needed to plot explanations, such as the
    SHAP values (`cb_shap.values`) and corresponding dataset (`cb_shap.data`). They
    should be exactly the same dimensions because there’s one SHAP value for every
    data point. It’s easy to verify this by checking their dimensions with the `shape`
    property:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在想，它是如何知道要创建哪种解释器的？很高兴你问了！初始化函数中有一个可选参数叫做 `algorithm`，你可以明确地定义 `tree`、`linear`、`additive`、`kernel`
    等等。但默认情况下，它设置为 `auto`，这意味着它会猜测模型需要哪种解释器。在这种情况下，CatBoost 是一个树集成，所以 `tree` 是有意义的。我们可以很容易地通过
    `cb_explainer.[dict]{custom-style="P - Italics"}[ 或 ]print(type(cb_explainer))`
    来检查 SHAP 是否选择了正确的解释器。它将返回 `<class 'shap.explainers._tree.Tree'>`，这是正确的！至于存储在 `cb_shap`
    中的解释，它究竟是什么呢？它是一个包含几乎用于绘制解释所需的一切的对象，例如 SHAP 值 (`cb_shap.values`) 和相应的数据集 (`cb_shap.data`)。它们的维度应该完全相同，因为每个数据点都有一个
    SHAP 值。我们可以通过使用 `shape` 属性来检查它们的维度来验证这一点：
- en: '[PRE22]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Now, let’s put these values to some use!
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来使用这些值吧！
- en: SHAP bar plot
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SHAP 条形图
- en: 'Let’s start with the most straightforward global explanation visualizations
    we can do, which is feature importance. You can do this with a bar chart (`shap.plots.bar`).
    All it needs is the explanation object (`cb_shap`), but by default, it will only
    display 10 bars. Fortunately, we can change this with `max_display`:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从最直接的全球解释可视化开始，那就是特征重要性。你可以用条形图 (`shap.plots.bar`) 来做这件事。它只需要解释对象 (`cb_shap`)，但默认情况下，它只会显示
    10 个条形。幸运的是，我们可以用 `max_display` 来改变这个：
- en: '[PRE23]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](img/B18406_04_06.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_06.png)'
- en: 'Figure 4.6: CatBoost model’s SHAP feature importance'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6：CatBoost 模型的 SHAP 特征重要性
- en: '*Figure 4.6* should look very familiar if you read the previous chapter. In
    fact, it should match the `cb_shap_imp` column in *Figure 4.5*.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4.6* 如果你阅读了上一章，应该看起来非常熟悉。事实上，它应该与 *图 4.5* 中的 `cb_shap_imp` 列相匹配。'
- en: SHAP feature importance offers considerable flexibility since it is simply the
    average of the absolute value of SHAP values for each feature. With the granularity
    of SHAP values, you can dissect them in the same way as the test dataset to obtain
    insights across various dimensions. This reveals more about feature importance
    than a single average for each feature.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 特征重要性提供了相当大的灵活性，因为它只是每个特征 SHAP 值绝对值的平均值。有了 SHAP 值的粒度，你可以像测试数据集一样剖析它们，从而在各个维度上获得洞察。这比每个特征的单一平均值揭示了更多关于特征重要性的信息。
- en: For example, you can compare feature importance across different groups. Suppose
    we want to explore how feature importance differs between `year` cohorts. First,
    we need a threshold to define. Let’s use 2014 because it’s the median `year` in
    our dataset. Values above that can be set in the “Newer Car” cohort and pre-2014
    values set to “Older Car.” Then, use `np.where` to create an array assigning the
    cohorts to each observation. To create the bar chart, repeat the previous process
    but use the cohorts function to split the explanation, applying the absolute value
    (`abs`) and `mean` operations to each cohort.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以比较不同组之间的特征重要性。假设我们想探索 `year` 群体之间特征重要性的差异。首先，我们需要一个阈值来定义。让我们用 2014 年来定义，因为它是我们数据集中的中位数
    `year`。高于该值的可以设置为“新车”群体，而 2014 年之前的值设置为“旧车”。然后，使用 `np.where` 创建一个数组，将群体分配给每个观测值。为了创建条形图，重复前面的过程，但使用群体函数来拆分解释，对每个群体应用绝对值
    (`abs`) 和 `mean` 操作。
- en: '[PRE24]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](img/B18406_04_07.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_07.png)'
- en: 'Figure 4.7: CatBoost model’s SHAP feature importance split by property value
    cohorts'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7：按属性值群体拆分的 CatBoost 模型 SHAP 特征重要性
- en: As you can see in *Figure 4.7*, all the top features matter less for “Older
    cars.” One of the biggest differences is with `year` itself. When a car is older,
    how much older doesn’t matter as much as when it’s in the “Newer Car” cohort.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在 *图 4.7* 中所见，对于“旧车”来说，所有顶级特征的重要性都较小。最大的不同之一是 `year` 本身。当一辆车变旧时，它变得有多旧并不像它在“新车”群体中那样重要。
- en: SHAP beeswarm plot
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SHAP蜜蜂群图
- en: 'Bar charts can obscure some aspects of how features affect model outcomes.
    Not only do different feature values have varying impacts, but their distribution
    across all observations can also exhibit considerable variation. The beeswarm
    plot aims to provide more insight by using dots to represent each observation
    for every individual feature, even though features are ordered by global feature
    importance:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 柱状图可能会掩盖某些方面特征如何影响模型结果的情况。不仅不同的特征值有不同的影响，而且它们在所有观测值中的分布也可能表现出相当大的变化。蜜蜂群图通过使用点来表示每个个体特征的所有观测值，旨在提供更多洞察，尽管特征是按全局特征重要性排序的：
- en: Dots are color-coded based on their position in the range of low to high values
    for each feature.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点根据它们在每个特征低到高值范围内的位置进行着色。
- en: Dots are arranged horizontally according to their impact on the outcome, centered
    on the line where SHAP value = 0, with negative impacts on the left and positive
    impacts on the right.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点根据它们对结果的影响水平横向排列，以SHAP值=0的线为中心，左侧为负面影响，右侧为正面影响。
- en: Dots accumulate vertically, creating a histogram-like visualization to display
    the number of observations influencing the outcome at every impact level for each
    feature.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点垂直累积，创建类似直方图的可视化，以显示每个特征在每个影响水平上影响结果观测值的数量。
- en: 'To better understand this, we’ll create a beeswarm plot. Generating the plot
    is easy with the `shap.plots.beeswarm` function. It only requires the explanation
    object (`cb_shap`), and, as with the bar plot, we’ll override the default `max_display`
    to show only 15 features:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这一点，我们将创建一个蜜蜂群图。使用`shap.plots.beeswarm`函数生成图表很容易。它只需要解释对象（`cb_shap`），并且，与柱状图一样，我们将覆盖默认的`max_display`以仅显示15个特征：
- en: '[PRE25]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The result of the preceding code is in *Figure 4.8*:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 前述代码的结果在 *图4.8* 中：
- en: '![](img/B18406_04_08.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_08.png)'
- en: 'Figure 4.8: The CatBoost model’s SHAP beeswarm plot'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8：CatBoost模型的SHAP蜜蜂群图
- en: '*Figure 4.8* can be read as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.8* 可以这样阅读：'
- en: The most important feature (of the 15) from top to bottom is `year` and the
    least is longitude (`long`). It should match the same order in the bar chart or
    if you take the average absolute values of the SHAP values across every feature.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从上到下，最重要的特征（15个中的）是`year`，最不重要的是经度（`long`）。它应该与柱状图中的顺序相同，或者如果你取每个特征的SHAP值的平均绝对值。
- en: Low values for `year` negatively impact the model outcome, while high values
    impact it positively. There’s a nice clean gradient in between, suggesting an
    increasing monotonic relationship between `year` and the predicted `price`. That
    is, the higher the `year`, the higher the `price` according to the CatBoost model.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`year`的较低值对模型结果有负面影响，而较高值则产生正面影响。中间有一个干净的梯度，表明`year`与预测的`price`之间存在递增的单调关系。也就是说，根据CatBoost模型，年份越高，价格越高。'
- en: '`odometer` has a negative or negligible impact on a sizable portion of the
    observations. However, it has a long tail of observations for which it has a sizable
    impact. You can tell this by looking at the density depicted vertically.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`odometer`对相当一部分观测值有负面影响或可忽略的影响。然而，它对有显著影响的观测值有一个长长的尾巴。你可以通过查看垂直密度来识别这一点。'
- en: If you scan the rest of the plot looking for other continuous features, you
    won’t find such a clean gradient anywhere else as you did for `year` and `odometer`
    but you’ll find some trends like higher values of `make_yr_pop` and `model_yr_pop`
    having mostly a negative impact.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你扫描图表的其余部分寻找其他连续特征，你不会在其他地方找到像`year`和`odometer`那样的干净梯度，但你将找到一些趋势，例如`make_yr_pop`和`model_yr_pop`的较高值主要产生负面影响。
- en: For binary features, it is easy to tell because you only have two colors, and
    they are sometimes neatly split, as with `model_premier`, `model_type_pickup`,
    `drive_fwd`, `make_cat_regular`, and `fuel_diesel`, demonstrating how a certain
    kind of vehicle might be a tell-tale sign for the model whether it is high priced
    or not. In this case, a pick-up model increases the price, whereas a vehicle with
    a regular make—that is, a brand that is not luxury—decreases the price.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于二元特征，很容易判断，因为你只有两种颜色，它们有时会整齐地分开，例如`model_premier`、`model_type_pickup`、`drive_fwd`、`make_cat_regular`和`fuel_diesel`，这展示了某种类型的车辆可能是模型高价的标志。在这种情况下，皮卡模型会增加价格，而具有常规制造的车辆（即非豪华品牌）会降低价格。
- en: While the beeswarm plot offers an excellent summary of many findings, it can
    sometimes be challenging to interpret, and it doesn’t capture everything. The
    color-coding is useful for illustrating the relationship between feature values
    and model output, but what if you want more detail? That’s where the partial dependence
    plot comes in. It’s among the many feature summary explanations that provide a
    global interpretation method specific to features.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然蜂群图提供了许多发现的出色总结，但它有时可能难以解释，并且无法捕捉到所有内容。颜色编码对于说明特征值与模型输出之间的关系很有用，但如果你想要更多细节呢？这就是部分依赖图发挥作用的地方。它是许多特征摘要说明之一，提供了针对特征的全局解释方法。
- en: Feature summary explanations
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征摘要说明
- en: This section will cover a number of methods used to visualize how an individual
    feature impacts the outcome.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍用于可视化单个特征如何影响结果的一些方法。
- en: Partial dependence plots
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部分依赖图
- en: '**Partial Dependence Plots** (**PDPs**) display a feature’s relationship with
    the outcome according to the model. In essence, the PDP illustrates the marginal
    effect of a feature on the model’s predicted output across all possible values
    of that feature.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**部分依赖图**（**PDPs**）根据模型显示特征与结果之间的关系。本质上，PDP说明了特征对模型预测输出的边际效应，该效应考虑了该特征的所有可能值。'
- en: 'The calculation involves two steps:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 计算涉及两个步骤：
- en: Initially, conduct a simulation where the feature value for each observation
    is altered to a range of different values, and predict the model using those values.
    For example, if the `year` varies between 1984 and 2022, create copies of each
    observation with `year` values ranging between these two numbers. Then, run the
    model using these values. This first step can be plotted as the **Individual Conditional
    Expectation** (**ICE**) plot, with simulated values for `year` on the X-axis and
    the model output on the Y-axis, and one line per simulated observation.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始时，进行一个模拟，其中每个观察值的特征值被改变为一系列不同的值，并使用这些值预测模型。例如，如果`year`在1984年和2022年之间变化，则创建每个观察值的`year`值介于这两个数字之间的副本。然后，使用这些值运行模型。这一步可以绘制为**个体条件期望**（**ICE**）图，其中模拟的`year`值位于X轴上，模型输出位于Y轴上，每个模拟观察值对应一条线。
- en: In the second step, simply average the ICE lines to obtain a general trend line.
    This line represents the PDP!
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二步中，只需简单地将ICE线平均，以获得一条总体趋势线。这条线代表PDP！
- en: PDPs can be created using scikit-learn but these only work well with scikit-learn
    models. They also can be generated with the SHAP library, as well as another library
    called PDPBox. Each has its advantages and disadvantages, which we will cover
    in this section.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用scikit-learn创建PDPs，但这些仅适用于scikit-learn模型。它们还可以使用SHAP库以及另一个名为PDPBox的库生成。每个都有其优点和缺点，我们将在本节中介绍。
- en: 'SHAP’s `partial_dependence` plot function takes the name of a feature (`year`),
    a `predict` function (`cb_mdl.predict`), and a dataset (`X_test`). There are some
    optional parameters such as whether to show the ICE lines (`ice`), a horizontal
    model expected value line (`model_expected_value`), and a vertical feature expected
    value line (`feature_expected_value`). It shows the `ice` lines by default, but
    there are so many observations in the test dataset it would take a long time to
    generate the plot, and would be “too busy” to appreciate the trends. The SHAP
    PDP can also incorporate SHAP values (`shap_values=True`) but it would take a
    very long time considering the size of the dataset. It’s best to sample your dataset
    to make it more plot-friendly:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP的`partial_dependence`图函数接受一个特征名称（`year`）、一个`predict`函数（`cb_mdl.predict`）和一个数据集（`X_test`）。还有一些可选参数，例如是否显示ICE线（`ice`）、一个水平模型期望值线（`model_expected_value`）和一个垂直特征期望值线（`feature_expected_value`）。默认情况下，它显示ICE线，但由于测试数据集中有如此多的观察值，生成该图将花费很长时间，并且会“过于繁忙”，无法欣赏趋势。SHAP
    PDP还可以包含SHAP值（`shap_values=True`），但考虑到数据集的大小，这将花费非常长的时间。最好对您的数据集进行采样，使其更适合绘图：
- en: '[PRE26]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The preceding code will produce the plot in *Figure 4.9*:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将在**图4.9**中生成该图：
- en: '![](img/B18406_04_09.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_09.png)'
- en: 'Figure 4.9: SHAP’s PDP for year'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9：SHAP的`year`部分依赖图
- en: As you can appreciate in *Figure 4.9*, there’s an upward trend for `year`. This
    finding shouldn’t be surprising considering the neat gradient in *Figure 4.8*
    for *year*. With the histogram, you can tell the bulk of observations have values
    for `year` over 2011, which is where it starts to have an above-verage impact
    on the model. This makes sense once you compare the location of the histogram
    to the location of the bulge in the beeswarm plot (*Figure 4.8*).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图4.9*中可以欣赏到的，`year`有一个上升趋势。考虑到*图4.8*中*year*的整洁梯度，这个发现并不令人惊讶。通过直方图，你可以看出大部分观察到的`year`值在2011年及以上，这是它开始对模型产生超过平均水平影响的地方。一旦你将直方图的位置与beeswarm图（*图4.8*）中突起的位置进行比较，这一点就变得有意义了。
- en: With PDPBox, we will make several variations of PDP plots. This library separates
    the potentially time-consuming process of making the simulations with the `PDPIsolate`
    function from the plotting with the `plot` function. We will only have to run
    `PDPIsolate` once but `plot` three times.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PDPBox，我们将制作几种PDP图表的变体。这个库将使用`PDPIsolate`函数进行模拟的耗时过程与使用`plot`函数进行绘图的过程分开。我们只需要运行一次`PDPIsolate`，但需要运行三次`plot`。
- en: For the first plot, we use `plot_pts_dist=True` to display a rug. The rug is
    a more concise way of conveying the distribution than the histogram.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个图表，我们使用`plot_pts_dist=True`来显示地毯图。地毯图是传达分布比直方图更简洁的方式。
- en: For the second one, we use `plot_lines=True` to plot the ICE lines, but we can
    only plot a fraction of them, so `frac_to_plot=0.01` randomly selects 1% of them.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个示例，我们使用`plot_lines=True`来绘制ICE线，但我们只能绘制其中的一部分，因此`frac_to_plot=0.01`随机选择其中的1%。
- en: 'For the third one, instead of showing a rug, we can construct the X-axis with
    quantiles (`to_bins=True`):'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第三个示例，我们不是显示地毯图，而是可以用分位数构建X轴（`to_bins=True`）：
- en: '[PRE27]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](img/B18406_04_10.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_04_10.png)'
- en: 'Figure 4.10: Three variations of PDPBox’s PDPs for year'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.10：PDPBox的PDP对于年份的三种变化
- en: The ICE lines enrich the PDP plots by showing the potential for variance. The
    last plot in *Figure 4.10* also shows how, even though rugs or histograms are
    useful guides, organizing the axis in quantiles better helps visualize distribution.
    In this case, two-thirds of `year` is distributed before 2017\. And the two decades
    between 1984 and 2005 only account for 11%. It’s only fair they get a corresponding
    portion of the plot.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ICE线通过展示方差潜力丰富了PDP图表。*图4.10*中的最后一个图表也展示了即使地毯图或直方图是有用的指南，将轴组织在分位数上更能帮助可视化分布。在这种情况下，三分之二的`year`分布在2017年之前。1984年至2005年之间的二十年只占11%。它们在图表中应该得到相应的一部分。
- en: 'We can now create a few lists we will use to iterate across different kinds
    of features, whether continuous (`cont_feature_l`), binary (`bin_feature_l`),
    or categorical (`cat_feature_l`):'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以创建几个列表，我们将使用这些列表遍历不同类型的特征，无论是连续的(`cont_feature_l`)、二元的(`bin_feature_l`)还是分类的(`cat_feature_l`)：
- en: '[PRE28]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To quickly get a sense of what PDPs look like for each feature, we can iterate
    across one of the lists of features producing PDP plots for each one. We will
    do continuous features (`cont_feature_l`) because it’s easiest to visualize, but
    you can try one of the other lists as well:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速了解每个特征的PDP看起来像什么，我们可以遍历一个特征列表，为每个特征生成PDP图表。我们将做连续特征(`cont_feature_l`)，因为它最容易可视化，但你也可以尝试其他列表之一：
- en: '[PRE29]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The preceding code will output eight plots, including the one in *Figure 4.11*:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将输出八个图表，包括*图4.11*中的那个：
- en: '![](img/B18406_04_11.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_04_11.png)'
- en: 'Figure 4.11: PDPBox’s PDP for odometer'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11：PDPBox的里程表PDP
- en: The beeswarm plot in *Figure 4.8* shows that a low value of `odometer` correlates
    with the model outputting a higher price. In *Figure 4.11*, it depicts how it’s
    mostly monotonically decreasing except in the extremes. It’s interesting that
    there are `odometer` values of zero and ten million in the extremes. While it
    makes sense that the model learned that `odometer` made no difference in prices
    when it’s zero, a value of ten million is an anomaly, and for this reason, you
    can tell that the ICE lines are going in different directions because the model
    is not sure what to make of such a value. We must also keep in mind that ICE plots,
    and thus PDPs, are generated with simulations that may create examples that wouldn’t
    exist in real life, such as a brand-new car with an extremely high `odometer`
    value.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.8*中的蜂群图显示，较低的里程表值与模型输出较高的价格相关。在*图4.11*中，它描绘了价格主要单调递减，除了极端情况。有趣的是，在极端情况下存在里程表值为零和一千万的情况。虽然模型学习到当里程表为零时，`里程表`对价格没有影响是有道理的，但一千万的值是一个异常值，因此你可以看出ICE线朝不同方向延伸，因为模型不确定如何处理这样的值。我们还必须记住，ICE图和因此PDP是通过模拟生成的，这些模拟可能会创建出在现实生活中不存在的例子，例如一个里程表值极高的全新车辆。'
- en: '[PRE30]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Fortunately, you can create a PDP with each one-hot encoded category side by
    side. All you need to do is plug in the list of product-type features in the `feature`
    attribute. PDPBox also has a “predict plot,” which can help provide context by
    showing prediction distribution across feature values. `PredictPlot` is easy to
    plot, having many of the same attributes as the `plot`.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，你可以创建一个PDP，其中每个类别的一元编码特征并排显示。你需要做的就是将产品类型特征的列表插入到`feature`属性中。PDPBox还有一个“预测绘图”功能，可以通过显示特征值范围内的预测分布来提供上下文。`PredictPlot`易于绘图，具有与`plot`许多相同的属性。
- en: '[PRE31]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![](img/B18406_04_12.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_04_12.png)'
- en: 'Figure 4.12: PDPBox’s actual plot for make categories'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.12*: PDPBox针对品牌类别的实际绘图'
- en: The PDP for `make_cat` in *Figure 4.12* shows the tendency of “luxury” and “premium”
    categories to lead to higher prices but only by about 3,000 dollars on average
    with a lot of variance depicted in the ICE lines. However, remember what was said
    about simulations not being necessarily representative of real-life scenarios?
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.12*中的`make_cat` PDP显示了“豪华”和“高级”类别倾向于导致更高的价格，但平均而言仅高出约3,000美元，ICE线图中显示了大量的变异性。然而，记得之前提到的模拟并不一定代表现实场景吗？'
- en: If we compare the PDP to the box and whiskers in the actual predictions in *Figure
    4.12*, we can tell that the difference in average prediction between regular and
    any of the “luxury” and “premium” categories is at least seven thousand dollars.
    Of course, the average doesn’t tell the whole story because even a premium car
    with too much mileage or that’s very old might cost less than a regular vehicle.
    The price depends on many factors besides the reputation of the make. Of course,
    just judging by how the boxes and whiskers align in *Figure 4.12*, “luxury sports”
    and “obsolete” categories are stronger indications of higher and lower prices,
    respectively.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将PDP与*图4.12*中实际预测的箱线和须线进行比较，我们可以发现，在常规车型与“豪华”和“高级”任何一类车型之间的平均预测差异至少有七千美元。当然，平均数并不能说明全部情况，因为即使是里程数过多或非常旧的豪华车，其价格也可能低于常规车辆。价格取决于许多因素，而不仅仅是品牌的声誉。当然，仅从*图4.12*中箱线和须线的排列来看，“豪华运动”和“过时”类别分别更强烈地表明了价格的高低。
- en: PDPs are often straightforward to interpret and relatively quick to generate.
    However, the simulation strategy it employs doesn’t account for feature distribution
    and heavily relies on the assumption of feature independence, which can lead to
    counterintuitive examples. We will now explore two alternatives.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: PDP通常易于解释且相对快速生成。然而，它所采用的模拟策略没有考虑特征分布，并且高度依赖于特征独立性的假设，这可能导致反直觉的例子。我们现在将探讨两种替代方案。
- en: SHAP scatter plot
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SHAP散点图
- en: SHAP values are available for every data point, enabling you to plot them against
    feature values, resulting in a PDP-like visualization with model impact (SHAP
    values) on the *y*-axis and feature values on the *x*-axis. Being a similar concept,
    the SHAP library initially called this a `dependence_plot`, but now it’s referred
    to as a scatter plot. Despite the similarities, PDP and SHAP values are calculated
    differently.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP值对每个数据点都可用，使您可以将它们与特征值进行绘图，从而在*y*轴上得到模型影响（SHAP值）和*x*轴上的特征值的PDP-like可视化。作为一个类似的概念，SHAP库最初将其称为`dependence_plot`，但现在它被称为散点图。尽管有相似之处，PDP和SHAP值的计算方式不同。
- en: 'Creating a SHAP scatter plot is simple, requiring only the explanation object.
    Optionally, you can color-code the dots according to another feature to understand
    potential interactions. You can also clip outliers from the *x*-axis using percentiles
    with `xmin` and `xmax` attributes and make dots 20% opaque (`alpha`) to identify
    sparser areas more easily:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 创建SHAP散点图很简单，只需要解释对象。可选地，你可以根据另一个特征对点进行颜色编码，以了解潜在的交互。你还可以使用`xmin`和`xmax`属性从*x*轴剪除异常值，并将点设置为20%不透明（`alpha`），以便更容易地识别稀疏区域：
- en: '[PRE32]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![](img/B18406_04_13.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_13.png)'
- en: 'Figure 4.13: SHAP’s scatter plots for odometer and long, color-coded for year
    and epa_displ respectively'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13：SHAP的里程表和长度的散点图，分别用颜色编码年份和epa_displ
- en: The first plot in *Figure 4.13* depicts how a higher `odometer` reading negatively
    impacts the model outcome. Also, the color coding shows that the SHAP values for
    higher years are even lower when the odometer reading is over ninety thousand.
    In other words, an old car with a high odometer reading is expected, but with
    a new car, it’s a red flag!
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.13*中的第一个图显示了较高的`里程表`读数如何对模型结果产生负面影响。此外，颜色编码显示，当里程表读数超过九万时，较高年份的SHAP值甚至更低。换句话说，一辆旧车有高里程表读数是可以预期的，但如果是新车，那就是一个红旗！'
- en: The second plot in *Figure 4.13* is very interesting; it shows how the west
    coast of the country (at about -120°) correlates with higher SHAP values and the
    further east it goes, the lower the SHAP values. Hawaii, Anchorage, and Alaska
    (at about -150°) are also higher than the east coast of the United States (at
    around -75°). The color coding shows how the more liters displaced of fuel mostly
    leads to higher SHAP values but it’s not as stark of a difference the further
    east you go.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.13*中的第二个图非常有趣；它显示了该国西海岸（大约在-120°）与较高的SHAP值相关联，并且越往东走，SHAP值越低。夏威夷、安克雷奇和阿拉斯加（大约在-150°）也高于美国的东海岸（大约在-75°）。颜色编码显示了燃料排量越多，SHAP值越高，但当你越往东走，这种差异就越不明显。'
- en: 'The `scatter` plot works well for continuous features, but can you use it for
    discrete ones? Yes! Let’s create one for `make_cat_luxury`. Since there are only
    two possible values on the *x*-axis, 0 and 1, what makes sense is to jitter them
    so that all the dots don’t get plotted on top of each other. For instance, `x_jitter=0.4`
    means they will be jittered horizontally up to 0.4, or 0.2 on each side of the
    original value. We can combine this with `alpha` to ensure that we can appreciate
    the density:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '`散点图`适用于连续特征，但你能否用它来表示离散特征？是的！让我们为`make_cat_luxury`创建一个散点图。由于*x*轴上只有两个可能的值，0和1，因此有意义的做法是使它们产生抖动，这样所有的点就不会重叠在一起。例如，`x_jitter=0.4`意味着它们将在水平方向上抖动最多0.4，或者原始值的每侧0.2。我们可以结合`alpha`来确保我们可以欣赏到密度：'
- en: '[PRE33]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![](img/B18406_04_14.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_14.png)'
- en: 'Figure 4.14: SHAP’s scatter plot for make_cat_luxury color-coded for year'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14：SHAP的`make_cat_luxury`散点图，用颜色编码年份
- en: '*Figure 4.14* shows that according to the SHAP values, `make_cat_fha=1` positively
    impacts the model outcome, whereas `make_cat_fha=1` has a mildly negative effect.
    The color coding suggests that lower years tempers the impact, making it smaller.
    This makes sense because older luxury cars have depreciated.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.14*显示，根据SHAP值，`make_cat_fha=1`对模型结果有积极影响，而`make_cat_fha=1`则有一个轻微的负面影响。颜色编码表明，较低的年份会减弱影响，使其变小。这很有道理，因为旧款豪华车已经贬值。'
- en: While SHAP scatter plots may be an improvement from PDP plots, SHAP’s tree explainers
    trade fidelity for speed, causing features that have no influence on the model
    to potentially have a SHAP value above zero. Fidelity refers to the accuracy of
    an explanation in representing the behavior of the model. To get higher fidelity,
    you need to use a method that makes fewer shortcuts in understanding what the
    model is doing, and even then, some adjustments to parameters like using a greater
    sample size will increase fidelity too because you are using more data to create
    the explanations. In this case, the solution is to use `KernelExplainer` instead
    because, as we previously discussed, it is more comprehensive, but it has issues
    with feature dependence. So there’s no free lunch! Next, we will cover ALE plots
    as a partial solution to these problems.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 SHAP 散点图可能比 PDP 图有所改进，但 SHAP 的树解释器以速度换取精确度，导致对模型没有影响的特征可能具有大于零的 SHAP 值。精确度指的是解释在表示模型行为方面的准确性。为了获得更高的精确度，您需要使用一种在理解模型做什么时采取较少捷径的方法，即使如此，对参数（如使用更大的样本量）的一些调整也会增加精确度，因为您正在使用更多数据来创建解释。在这种情况下，解决方案是使用
    `KernelExplainer`，因为我们之前讨论过的，它更全面，但存在特征依赖问题。所以没有免费的午餐！接下来，我们将介绍 ALE 图作为这些问题的部分解决方案。
- en: ALE plots
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ALE 图
- en: ALE plots are advantageous over PDPs because they are unbiased and faster. ALE
    accounts for data distributions when calculating feature effects, resulting in
    an unbiased representation. The algorithm divides the feature space into equally
    sized windows and computes how predictions change within these windows, resulting
    in the *local effects*. Summing the effects across all windows makes them *accumulated*.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ALE 图相对于 PDP 图的优势在于它们是无偏的且速度更快。ALE 在计算特征效应时考虑数据分布，从而实现无偏表示。该算法将特征空间划分为等大小的窗口，并计算这些窗口内的预测变化，从而产生
    *局部效应*。将所有窗口的效果相加，使它们成为 *累积的*。
- en: You can easily generate the ALE plot with the `ale` function. All you need is
    some data (`X_test_no_outliers`), the model (`cb_mdl`), and the feature(s) and
    feature type(s) to be plotted. Optionally, you can enter the `grid_size`, which
    will define the window size for local effects calculations. It is `20` by default,
    but we can increase it for higher fidelity, provided you have enough data. As
    mentioned previously, some adjustments to parameters can affect fidelity. For
    window size, it will break the data into smaller bins to compute values and thus
    make them more granular. Also, confidence intervals are shown by default. Incidentally,
    it’s best to remove outliers in this case because it’s hard to appreciate the
    plot when the maximum loan nearly reaches $8 million. You can try using `X_test`
    instead of `X_test_no_outliers` to see what I mean.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 `ale` 函数轻松生成 ALE 图。您需要的只是一些数据（`X_test_no_outliers`）、模型（`cb_mdl`）以及要绘制的特征和特征类型。可选地，您可以输入
    `grid_size`，这将定义局部效应计算的窗口大小。默认值为 `20`，但如果我们有足够的数据，我们可以将其增加以提高精确度。如前所述，一些参数的调整可能会影响精确度。对于窗口大小，它将数据分割成更小的区间以计算值，从而使它们更加细化。此外，默认情况下显示置信区间。顺便提一下，在这种情况下最好移除异常值，因为当最大贷款几乎达到
    800 万美元时，很难欣赏到图表。您可以通过尝试使用 `X_test` 而不是 `X_test_no_outliers` 来了解我的意思。
- en: 'Confidence intervals are shown by default. It’s preferable to exclude outliers
    in this case, as it’s difficult to appreciate the plot when only very few vehicles
    represent years before 1994 and after 2021 and have very low and very high odometer
    readings. You can use `X_test` instead of `X_test_no_outliers` in the `ale` function
    to see the difference:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下显示置信区间。在这种情况下，最好排除异常值，因为当只有极少数车辆代表1994年之前和2021年之后的年份，并且具有非常低和非常高的里程表读数时，很难欣赏到图表。您可以在
    `ale` 函数中使用 `X_test` 而不是 `X_test_no_outliers` 来查看差异：
- en: '[PRE34]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![](img/B18406_04_15.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_04_15.png)'
- en: 'Figure 4.15: ALE plots for odometer and make_cat_luxury'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15：里程表和 make_cat_luxury 的 ALE 图
- en: The first plot in *Figure 4.15* is the ALE plot for `odometer`. As portrayed
    in *Figure 4.13*, the effect on the model goes from positive to negative as the
    odometer reading increases. However, unlike SHAP, in the ALE plot, it goes negative
    long before the odometer reaches 90,000\. Please note the confidence interval
    is so thin it’s only visible somewhere under 10,000\. The second ALE plot shows
    a significant positive impact of the “luxury” category on the outcome and that
    luxury vehicles are not as represented as other ones.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.15*中的第一个图是`odometer`的ALE图。正如*图4.13*所示，随着里程表的读数增加，模型的影响从正面变为负面。然而，与SHAP不同，在ALE图中，它会在里程表达到90,000之前就变为负值。请注意，置信区间非常窄，只在10,000以下某处可见。第二个ALE图显示了“豪华”类别对结果有显著的正向影响，并且豪华车辆不像其他车辆那样有代表性。'
- en: So far, we’ve only discussed single-feature explanations. But we also can observe
    the interaction between features, which we will cover next.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只讨论了单特征解释。但我们也可以观察到特征之间的交互作用，这将在下一部分进行介绍。
- en: Feature interactions
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征交互
- en: Features may not influence predictions independently. For example, as discussed
    in *Chapter 2*, *Key Concepts of Interpretability*, determining obesity based
    solely on weight isn’t possible. A person’s height or body fat, muscle, and other
    percentages are needed. Models understand data through correlations, and features
    are often correlated because they are naturally related, even if they are not
    linearly related. Interactions are what the model may do with correlated features.
    For instance, a decision tree may put them in the same branch, or a neural network
    may arrange its parameters in such a way that it creates interaction effects.
    This also occurs in our case. Let’s explore this through several feature interaction
    visualizations.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 特征可能不会独立地影响预测。例如，如*第二章*中讨论的，仅根据体重确定肥胖是不可能的。一个人的身高或体脂、肌肉和其他百分比都是需要的。模型通过相关性理解数据，而特征通常是相关的，即使它们不是线性相关的。交互作用是模型可能对相关特征所做的。例如，决策树可能将它们放在同一个分支上，或者神经网络可能以某种方式安排其参数，从而产生交互效应。这种情况也出现在我们的案例中。让我们通过几个特征交互可视化来探讨这一点。
- en: SHAP bar plot with clustering
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有聚类的SHAP条形图
- en: 'SHAP comes with a hierarchical clustering method (`shap.utils.hclust`) that
    allows for the grouping of training features based on the “redundancy” between
    any given pair of features. This refers to the degree to which they depend on
    each other, on a scale from complete redundancy (0) to total independence (1).
    We won’t use the entire dataset for this task because it would take a very long
    time, so we will use a 10% `sample`:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP附带一个分层聚类方法(`shap.utils.hclust`)，可以根据任何给定特征对之间的“冗余”对训练特征进行分组。这指的是它们相互依赖的程度，从完全冗余（0）到完全独立（1）的范围内。我们不会使用整个数据集来完成这项任务，因为这会花费很长时间，所以我们将使用10%的`sample`：
- en: '[PRE35]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We can employ the same bar chart as in *Figure 4.6*, but this time, we input
    the `clustering` and clustering cutoff and voilá! We can visualize which features
    are most redundant. Our aim is to pinpoint relationships that are less than 0.7
    independent (`clustering_cutoff`):'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用与*图4.6*相同的条形图，但这次，我们输入`clustering`和聚类截止值，voilá！我们可以可视化哪些特征最为冗余。我们的目标是确定小于0.7独立性的关系（`clustering_cutoff`）：
- en: '[PRE36]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![](img/B18406_04_16.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_04_16.png)'
- en: 'Figure 4.16: SHAP bar plot with clustering'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.16：带有聚类的SHAP条形图
- en: The dendrogram on the right in *Figure 4.16* reveals which features rely on
    each other the most and at three tiers. For instance, `year` is dependent on `odometer`,
    and when combined, they both depend on `epa_co2`, which in turn depends indirectly
    on a number of features, including the fuel displacement (`epa_displ`) and `cylinders`
    features. Also, please note that all make category features depend on each other
    but also on the make’s relative popularity (`make_pop`). This finding makes sense
    because some categories are overall more popular than others. These insights can
    serve as a guide for subsequent investigations.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图4.16*的右侧树状图中，揭示了哪些特征之间相互依赖最多，以及三个层级。例如，`year`依赖于`odometer`，当它们结合在一起时，它们都依赖于`epa_co2`，而`epa_co2`又间接依赖于包括燃油排量(`epa_displ`)和`cylinders`在内的多个特征。此外，请注意，所有制造商类别特征不仅相互依赖，还依赖于制造商的相对普及度(`make_pop`)。这一发现是有意义的，因为有些类别比其他类别更受欢迎。这些见解可以作为后续调查的指南。
- en: 2D ALE plots
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2D ALE图
- en: The optimal way to visually inspect the impact of two variables on predictions
    is through 2D ALE plots, primarily because it’s unbiased when dealing with correlated
    features.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 通过二维ALE图来直观地检查两个变量对预测的影响是最优的方式，主要是因为它在处理相关特征时是无偏的。
- en: 'Let’s scrutinize the top features, `year` and `odometer`, which also have a
    clear dependency. We’ll utilize the test dataset minus the outliers so that the
    plot focuses on the core of the data—that is, the part containing approximately
    98% of the data points. This time, instead of a single feature, we’ll insert a
    list of two features:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细审查前几个特征，即`年份`和`里程表`，它们也有明显的依赖关系。我们将使用去除异常值的测试数据集，以便图表专注于数据的核心——即包含大约98%的数据点的部分。这次，我们不会插入单个特征，而是一个包含两个特征的列表：
- en: '[PRE37]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The above code produces the ALE plot in *Figure 4.17*:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码在*图4.17*中产生了ALE图：
- en: '![](img/B18406_04_17.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_17.png)'
- en: 'Figure 4.17: 2D ALE plot for odometer and year'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.17：里程表和年份的二维ALE图
- en: As seen in *Figure 4.17*, except for a slim range of extremely high `odometer`
    readings and areas where older cars and low `odometer` readings overlap, there’s
    a modest effect for most of the plot. Mostly, they seem to only have a larger
    negative effect in the corners.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图4.17*所示，除了极少数极端高的`里程表`读数和老旧汽车与低`里程表`读数重叠的区域外，大部分图表的效果都很适度。大多数情况下，它们似乎只在角落处有更大的负效应。
- en: 'An important point to remember is that SHAP’s clustering distance ranges from
    redundancy to independence. The issue with highly correlated features is that,
    at a certain point, they cease depending on each other and become entirely redundant.
    So, let’s examine how close to redundancy these two features are with the `clustering`
    array we created with `shap.utils.hclust`:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的一个重要观点是，SHAP的聚类距离范围从冗余到独立。高度相关特征的问题在于，在某个点上，它们停止相互依赖，变得完全冗余。因此，让我们通过使用`shap.utils.hclust`创建的`聚类`数组来检查这两个特征接近冗余的程度：
- en: '[PRE38]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The preceding snippet should output the below array:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段应该输出以下数组：
- en: '[PRE39]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The array consists of rows of edges. The columns represent node number 1, node
    number 2, their distance, and parent node number. At the top, there are a few
    pairs that are completely redundant such as `make_pop` (feature 2) and `make_cat_luxury_sports`
    (feature 21). Not a strange outcome considering luxury sports cars, like a Ferrari,
    are the least popular vehicles in the dataset because they aren’t sold as often
    as, say, a Ford:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 该数组由边缘的行组成。列代表节点编号1、节点编号2、它们的距离和父节点编号。在顶部，有一些完全冗余的配对，例如`make_pop`（特征2）和`make_cat_luxury_sports`（特征21）。考虑到豪华跑车，如法拉利，在数据集中是最不受欢迎的车辆，因为它们的销售频率不如福特等车型，所以这不是一个奇怪的结果：
- en: '[PRE40]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![](img/B18406_04_18.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_18.png)'
- en: 'Figure 4.18: 2D ALE plot for epa_displ and cylinders'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.18：epa_displ和汽缸数的二维ALE图
- en: '*Figure 4.18* distinctly illustrates higher interaction effects where `cylinders`
    is larger than 8 and where `epa_displ` is under 4\. This finding is counterintuitive
    considering vehicles with a lot of cylinders are unlikely to have low amounts
    of engine displacement. On the other hand, the higher interaction effects when
    there are over 4 cylinders and an engine displacement of at least 6 liters make
    more sense. Please note that there are other factors such as `year` and `model_type`
    that correlate with these two features, but ALE is great at separating the effects
    of `cylinders` and `epa_displ` from other highly correlated features.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.18*清楚地说明了当`汽缸数`大于8且`epa_displ`小于4时的高交互效应。考虑到拥有大量汽缸的车辆不太可能有低发动机排量，这个发现是反直觉的。另一方面，当汽缸数超过4且发动机排量至少为6升时，更高的交互效应更有意义。请注意，还有其他因素，如`年份`和`型号类型`，与这两个特征相关，但ALE擅长将`汽缸数`和`epa_displ`的效果与其他高度相关的特征分开。'
- en: PDP interactions plots
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PDP交互图
- en: 'I’m sure you’re wondering: Given the numerous limitations of PDP, when and
    where should we contemplate using 2D PDP?'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信你一定在想：鉴于PDP的众多局限性，我们应该在何时何地考虑使用二维PDP？
- en: Only when a proven relationship exists between two features, but they are not
    entirely redundant or independent, and ideally, when they perfectly complement
    each other. Even then, an ALE plot is advisable as it teases out higher-order
    effects.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当两个特征之间存在已证实的关联关系，但它们并不完全冗余或独立，并且理想情况下，它们完美互补时，才建议使用ALE图，因为它可以揭示更高阶的效应。
- en: 'Nonetheless, for illustrative purposes, we will generate a 2D PDP with `long`
    and `lat`, which are indirectly connected. The code for 2D is very similar to
    1D, with the exception that we use `PDPInteract` instead of `PDPIsolate`, and
    then for the plot function, designate the `plot_type` as `contour`, but `grid`
    could also be used:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了说明目的，我们将生成一个2D PDP，其中包含`long`和`lat`，它们是间接连接的。2D的代码与1D非常相似，只是我们使用`PDPInteract`而不是`PDPIsolate`，然后对于绘图函数，指定`plot_type`为`contour`，但也可以使用`grid`：
- en: '[PRE41]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![](img/B18406_04_19.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_19.png)'
- en: 'Figure 4.19: PDP interaction contour plot for long and lat'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.19：长和纬度的PDP交互等高线图
- en: '*Figure 4.19* serves as proof of how the features are related to the outcome:
    `long` seems to be responsible for most of the effect, but in some areas, `lat`
    seems to make a difference, especially in Alaska in the top-left corner. We can
    check the reliability of this result with a 2D predict plot (`InteractPredictPlot`).
    As with *Figure 4.12*, the objective is to display the distribution of the data
    and the predicted scores for that data, but this time, it features a grid of bins
    that are color-coded for average scores and size-coded for the number of test
    observations. We can contrast this with the corresponding 2D target plot (`InteractTargetPlot`),
    which does the same but for the labels (`target`) and not the predicted score:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.19*证明了特征与结果之间的关系：`long`似乎对大部分影响负责，但在某些地区，`lat`似乎有所影响，尤其是在左上角的阿拉斯加。我们可以通过2D预测图（`InteractPredictPlot`）来检查这个结果的可靠性。与*图4.12*一样，目标是显示数据的分布和该数据的预测分数，但这次，它以网格的形式显示，网格的颜色编码表示平均分数，大小编码表示测试观察的数量。我们可以将其与相应的2D目标图（`InteractTargetPlot`）进行对比，后者执行相同的操作，但针对的是标签（`target`）而不是预测分数：'
- en: '[PRE42]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![](img/B18406_04_20.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_04_20.png)'
- en: 'Figure 4.20: PDP actual plot for long and lat'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.20：长和纬度的PDP实际图
- en: From the initial plot, it’s evident that the median predictions are greatest
    on the western half (on the right side) and especially toward the southwest (on
    the bottom right), but not by much. The second plot affirms that the labels are
    indeed more likely to be high-priced in these sections of the plot. Therefore,
    it’s no surprise that the model learned this distribution to its degree of accuracy.
    These plots aid in affirming a relationship between both features.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 从初始图中可以看出，中值预测在西部（右侧）最大，尤其是西南部（右下角），但变化不大。第二个图证实了在这些图的这些部分，标签更有可能标价较高。因此，模型以这种精确度学习这种分布并不令人惊讶。这些图有助于证实这两个特征之间的关系。
- en: In the following chapter, we’ll delve deeper into local explanations!
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将更深入地探讨局部解释！
- en: Mission accomplished
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 任务完成
- en: We set out to uncover what features helped predict the used car price for the
    two-sided marketplace. Using the intrinsic parameters of the decision trees, permutation
    feature importance, and SHAP, we realized that at least 15 features have a negligible
    impact on either model. Also, about an equal amount of features holds the lion’s
    share of impact. Some of the most critical features, like engine displacement
    (`epa_displ`) and cylinders, are technical and can vary for the same make and
    model, so the user would have to know and enter them.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们着手揭示哪些特征有助于预测双边市场的二手车价格。使用决策树的内禀参数、排列特征重要性和SHAP，我们发现至少有15个特征对任何模型的影响可以忽略不计。此外，大约相等数量的特征占据了大部分影响。一些最重要的特征，如发动机排量（`epa_displ`）和汽缸数，是技术性的，并且对于同一款车型的不同版本可能会有所不同，因此用户必须知道并输入它们。
- en: We also found interesting and perfectly valid relationships between different
    features such as `year` and `odometer`, which help us understand how they interact
    in the model. We can share all of these findings with the tech startup.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还发现了不同特征之间有趣且完全有效的关联，例如`year`和`odometer`，这有助于我们了解它们在模型中的相互作用。我们可以将这些所有发现与科技初创公司分享。
- en: Summary
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: After reading this chapter, you should understand what model-specific methods
    to compute feature importance are and their shortcomings. Then, you should have
    learned how model-agnostic methods’ permutation feature importance and SHAP values
    are calculated and interpreted. You also learned the most common ways to visualize
    model explanations. You should know your way around global explanation methods
    like global summaries, feature summaries, and feature interaction plots and their
    advantages and disadvantages.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本章之后，你应该理解了计算特征重要性的模型特定方法及其不足。然后，你应该学习了模型无关方法中的排列特征重要性和SHAP值的计算和解释方法。你还学习了可视化模型解释的最常见方式。你应该熟悉全局解释方法，如全局摘要、特征摘要和特征交互图及其优缺点。
- en: In the next chapter, we will delve into local explanations.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨局部解释。
- en: Further reading
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Shapley, Lloyd S., 1953, *A value for n-person Games*. In Kuhn, H. W.; Tucker,
    A. W. (eds.). *Contributions to the Theory of Games. Annals of Mathematical Studies*.
    28\. Princeton University Press. pp. 307–317: [https://doi.org/10.1515/9781400881970-018](https://doi.org/10.1515/9781400881970-018)'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shapley, Lloyd S.，1953，*n人博弈的价值*. 在Kuhn, H. W.；Tucker, A. W.（编者）. *博弈论贡献. 数学研究年鉴*.
    28. 普林斯顿大学出版社. 第307-317页：[https://doi.org/10.1515/9781400881970-018](https://doi.org/10.1515/9781400881970-018)
- en: 'Lundberg, S., and Lee, S., 2017, *A Unified Approach to Interpreting Model
    Predictions*. Advances in Neural Information Processing Systems: [https://arxiv.org/abs/1705.07874](https://arxiv.org/abs/1705.07874)
    (documentation for SHAP: [https://github.com/slundberg/shap](https://github.com/slundberg/shap))'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lundberg, S. 和 Lee, S.，2017，*解释模型预测的统一方法*. 神经信息处理系统进展：[https://arxiv.org/abs/1705.07874](https://arxiv.org/abs/1705.07874)（SHAP的文档：[https://github.com/slundberg/shap](https://github.com/slundberg/shap)）
- en: 'Lundberg, S.M., Erion, G., and Lee, S., 2018, *Consistent Individualized Feature
    Attribution for Tree Ensembles*. ICML Workshop: [https://arxiv.org/abs/1802.03888](https://arxiv.org/abs/1802.03888)'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lundberg, S.M.，Erion, G. 和 Lee, S.，2018，*树集成的一致性个体化特征归因*. ICML研讨会：[https://arxiv.org/abs/1802.03888](https://arxiv.org/abs/1802.03888)
- en: 'Molnar, C., 2019, *Interpretable Machine Learning. A Guide for Making Black
    Box Models Explainable*: [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Molnar, C., 2019, *可解释机器学习：构建可解释黑盒模型的指南*: [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)'
- en: 'Documentation for SHAP plots: [https://shap.readthedocs.io/en/latest/api.html#plots](https://shap.readthedocs.io/en/latest/api.html#plots)'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP图的文档：[https://shap.readthedocs.io/en/latest/api.html#plots](https://shap.readthedocs.io/en/latest/api.html#plots)
- en: 'Original paper for PDP method: Friedman, J.H., 2001, *Greedy function approximation:
    A gradient boosting machine*. Annals of Statistics, 29, 1189-1232: [https://doi.org/10.1214/aos/1013203451](https://doi.org/10.1214/aos/1013203451)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'PDP方法的原始论文：Friedman, J.H., 2001, *贪婪函数逼近：梯度提升机*. 统计学年鉴，29，1189-1232: [https://doi.org/10.1214/aos/1013203451](https://doi.org/10.1214/aos/1013203451)'
- en: 'Documentation for PDPBox: [https://pdpbox.readthedocs.io/en/latest/](https://pdpbox.readthedocs.io/en/latest/)'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PDPBox的文档：[https://pdpbox.readthedocs.io/en/latest/](https://pdpbox.readthedocs.io/en/latest/)
- en: 'Original paper for ALE method: Apley, D.W., & Zhu, J., 2020, *Visualizing the
    effects of predictor variables in black box supervised learning models*. Journal
    of the Royal Statistical Society: Series B (Statistical Methodology), 82\. [https://arxiv.org/abs/1612.08468](https://arxiv.org/abs/1612.08468)'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ALE方法的原始论文：Apley, D.W., & Zhu, J., 2020, *可视化黑盒监督学习模型中预测变量的影响*. 英国皇家统计学会：系列B（统计方法），82\.
    [https://arxiv.org/abs/1612.08468](https://arxiv.org/abs/1612.08468)
- en: 'Repository for PyALE: [https://github.com/DanaJomar/PyALE](https://github.com/DanaJomar/PyALE)'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyALE的仓库：[https://github.com/DanaJomar/PyALE](https://github.com/DanaJomar/PyALE)
- en: 'Original paper for LIME method: Ribeiro, M., Singh, S., and Guestrin, C., 2016,
    *“Why Should I Trust You?”: Explaining the Predictions of Any Classifier*. Proceedings
    of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data
    Mining. [https://arxiv.org/abs/1602.04938](https://arxiv.org/abs/1602.04938)'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME方法的原始论文：Ribeiro, M., Singh, S., and Guestrin, C., 2016, *“我应该相信你吗？”：解释任何分类器的预测*.
    第22届ACM SIGKDD国际知识发现和数据挖掘会议论文集。 [https://arxiv.org/abs/1602.04938](https://arxiv.org/abs/1602.04938)
- en: 'Documentation for LIME: [https://lime-ml.readthedocs.io/en/latest/](https://lime-ml.readthedocs.io/en/latest/)'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME的文档：[https://lime-ml.readthedocs.io/en/latest/](https://lime-ml.readthedocs.io/en/latest/)
- en: Learn more on Discord
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Discord上了解更多
- en: 'To join the Discord community for this book – where you can share feedback,
    ask the author questions, and learn about new releases – follow the QR code below:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 要加入这本书的 Discord 社区——在那里您可以分享反馈、向作者提问，以及了解新书发布——请扫描下面的二维码：
- en: '[https://packt.link/inml](Chapter_4.xhtml)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/inml](Chapter_4.xhtml)'
- en: '![](img/QR_Code107161072033138125.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code107161072033138125.png)'
