- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Foundations
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础
- en: '**Emotions** play a key role in our daily lives. Some people define them as
    the reactions that we as human beings experience as a response to events or situations,
    some describe them simply as a class of feelings, and others say they describe
    physiological states and are generated subconsciously. Psychologists describe
    emotions as “*a complex state of feeling that results in physical and psychological
    changes that influence thought and behavior.*” So, it appears that although we
    feel emotions, they are much harder to describe.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**情绪**在我们的日常生活中起着关键作用。有些人将它们定义为人类对事件或情况的反应，有些人简单地描述它们为一种情感类别，而有些人说它们描述生理状态，并且是无意识地产生的。心理学家将情绪描述为“*一种复杂的情感状态，导致身体和心理变化，从而影响思维和行为。*”因此，尽管我们感受到情绪，但它们很难描述。'
- en: Our brains play a crucial role when creating and processing emotions. Historically,
    it was believed that each emotion was located in a specific part of the brain.
    However, research has shown that there is no single region of the brain that’s
    responsible for processing emotions – several brain regions are activated when
    emotions are being processed. Furthermore, different parts of the brain can generate
    the same emotion and different parts can also contribute to generating an emotion.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的大脑在创造和处理情绪时起着至关重要的作用。历史上，人们认为每种情绪都位于大脑的特定部分。然而，研究表明，没有单一的大脑区域负责处理情绪——当处理情绪时，多个大脑区域会被激活。此外，大脑的不同部分可以产生相同的情绪，不同的部分也可以有助于产生情绪。
- en: The reality may even be that *emotion* and *sentiment* are experiences that
    result from combined influences of biological, cognitive, and social aspects.
    Whatever the case, emotions matter because they help us decide what actions to
    do, how to negotiate tricky situations, and, at a basic level, how to survive.
    Different emotions rule our everyday lives; for example, we make decisions based
    on whether we are happy, angry, or sad, and we choose our daily pastimes and routines
    based on the emotions they facilitate. So, emotions are important, and understanding
    them may make our lives easier.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，*情绪*和*情感*可能是由于生物、认知和社会方面的综合影响而产生的体验。无论情况如何，情绪都很重要，因为它们帮助我们决定采取什么行动，如何谈判复杂的情况，以及在基本层面上如何生存。不同的情绪统治着我们的日常生活；例如，我们根据我们是快乐、愤怒还是悲伤来做出决定，我们根据它们促进的情绪选择我们的日常娱乐和例行公事。因此，情绪很重要，理解它们可能会让我们的生活变得更简单。
- en: In this chapter, you will learn about the main concepts and differences between
    sentiment analysis and emotion analysis, and also understand why emotion analysis
    is important in the modern world. By combining this with a basic introduction
    to **natural language processing** (**NLP**) and machine learning, we will lay
    the foundations for successfully using these techniques for emotion analysis.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解情感分析和情感分析之间的主要概念和区别，并了解为什么情感分析在现代世界中很重要。通过结合对**自然语言处理**（**NLP**）和机器学习的基本介绍，我们将为成功使用这些技术进行情感分析奠定基础。
- en: 'In this chapter, we’ll cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Emotions
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情绪
- en: Sentiment
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感
- en: Why is emotion analysis important?
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么情感分析很重要？
- en: Introduction to natural language processing
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言处理简介
- en: Introduction to machine learning
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: Emotions
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 情绪
- en: This book is about writing programs that can detect emotions expressed in texts,
    particularly informal texts. Emotions play a crucial role in our daily lives.
    They impact how we feel, how we think, and how we behave. Consequently, it stands
    to reason that they impact the decisions we make. If this is the case, then being
    able to detect emotions from written text (for example, social media posts) is
    a useful thing to do because the impact it would have on many practical everyday
    applications in sectors such as marketing, industry, health, and security would
    be huge.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书是关于编写能够检测文本中表达的情绪的程序，尤其是非正式文本。情绪在我们的日常生活中起着至关重要的作用。它们影响我们的感受、我们的思考和我们的行为。因此，可以合理地认为它们会影响我们的决策。如果情况是这样的话，那么能够从书面文本（例如社交媒体帖子）中检测情绪是有用的，因为它将对许多实际日常应用产生巨大影响，这些应用领域包括营销、工业、健康和安全。
- en: However, while it is clear that we all experience emotions and that they play
    a significant role in our plans and actions, it is much less clear what they *are*.
    Given that we are about to embark on a detailed study of how to write programs
    to detect them, it is perhaps worth beginning by investigating the notion of what
    an emotion is and looking at the various theories that attempt to pin them down.
    This is a topic that has fascinated philosophers and psychologists from antiquity
    to the present day, and it is still far from settled. We will briefly look at
    a number of the most prominent theories and approaches. This overview will not
    lead us to a definitive view, but before we start trying to identify them in written
    texts, we should at least become aware of the problems that people still have
    in pinning them down.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，虽然很清楚我们都会体验到情绪，并且它们在我们的计划和行动中起着重要作用，但它们究竟是什么却并不那么清楚。鉴于我们即将开始详细研究如何编写程序来检测它们，也许首先调查一下情绪是什么的概念，并看看试图将它们固定下来的各种理论是值得的。这是一个从古代到现代一直吸引着哲学家和心理学家的主题，而且至今仍未有定论。我们将简要地看看一些最突出的理论和方法。这个概述不会引导我们得出一个明确的观点，但在我们开始尝试在书面文本中识别它们之前，我们至少应该意识到人们在固定它们时仍然存在的问题。
- en: Darwin believed that emotions allowed humans and animals to survive and reproduce.
    He argued that they evolved, were adaptive, and that all humans, and even other
    animals, expressed emotion through similar behaviors. He believed that emotions
    had an evolutionary history that could be traced across cultures and species.
    Today, psychologists agree that emotions such as fear, surprise, disgust, happiness,
    and sadness can be regarded as universal regardless of culture.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 达尔文认为，情绪使人类和动物能够生存和繁衍。他论证说，情绪是进化的，具有适应性，所有人类，甚至其他动物，都通过类似的行为表达情绪。他相信情绪有一个可以跨越文化和物种追溯的进化历史。今天，心理学家们一致认为，恐惧、惊讶、厌恶、快乐和悲伤等情绪可以被视为普遍存在的，无论文化如何。
- en: The James-Lange theory proposes that it is our physical responses that are responsible
    for emotions. For example, if someone jumps out at you from behind a bush, your
    heart rate will increase, and it is this increase that causes the individual to
    feel fear. The facial-feedback theory builds on this idea and suggests that physical
    activity is responsible for influencing emotion, for example, if you smile, likely,
    you will automatically feel happier than if you did not smile. However, Cannon-Bard’s
    theory refutes James-Lange, instead suggesting that people experience emotional
    and physical responses simultaneously. The Schachter-Singer theory is a cognitive
    theory of emotion that suggests that it is our thoughts that are responsible for
    emotions, and similarly, cognitive appraisal theory suggests that thinking must
    come before experiencing an emotion. For instance, the brain might understand
    a situation as threatening, and hence fear is experienced.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 詹姆斯-兰格理论提出，情绪的产生是由我们的生理反应所负责的。例如，如果有人从灌木丛后突然跳出来吓你，你的心率会增加，正是这种增加导致了个体感到恐惧。面部反馈理论在此基础上进一步提出，身体活动是影响情绪的原因，例如，如果你微笑，你可能会自动感到比不微笑时更快乐。然而，坎农-巴德理论反驳了詹姆斯-兰格理论，反而提出人们同时体验到情绪和生理反应。沙赫特-辛格理论是一种情绪的认知理论，它认为情绪的产生是由我们的思想所负责的，同样，认知评估理论也提出，思考必须先于体验情绪。例如，大脑可能将某种情况理解为威胁，因此产生了恐惧感。
- en: 'To try to obtain a deeper understanding of emotions, let’s look at the three
    main theories of emotion:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尝试更深入地理解情绪，让我们来看看情绪的三个主要理论：
- en: '**Physiological**: Psychologists have the view that emotions are formed when
    a bodily response is triggered by a stimulus, so as the individual experiences
    physiological changes, this is also experienced as an emotion'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生理学**：心理学家认为，情绪是在生理反应被刺激触发时形成的，因此，当个体经历生理变化时，这也被体验为情绪。'
- en: '**Neurological**: Biologists claim that hormones (for example, estrogen, progesterone,
    and testosterone) that are produced by the body’s glands impact the chemistry
    and circuitry of the brain and these lead to emotional responses'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经学**：生物学家声称，由身体腺体产生的激素（例如，雌激素、孕酮和睾酮）会影响大脑的化学和电路，这些影响导致了情绪反应。'
- en: '**Cognitive**: Cognitive scientists believe that thoughts and other mental
    activities play a crucial role in forming emotions'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**认知**：认知科学家认为，思想和其他心理活动在形成情绪中起着至关重要的作用。'
- en: In all likelihood, all three theories are probably valid to some extent. It
    has also been postulated that instead of thinking of these as mutually exclusive,
    it is more likely that they are complementary and that each explains and accounts
    for a different aspect of what we think of as an emotion.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，这三个理论在某种程度上都是有效的。也有人提出，与其将这些理论视为相互排斥的，不如认为它们更可能是互补的，并且每个理论都解释和说明了我们认为是情感的不同方面。
- en: Although emotions have been studied for many decades, it is probably still true
    that we still do not fully understand emotions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管情感已经研究了几十年，但很可能我们仍然没有完全理解情感。
- en: Humans can experience a huge number of emotions, but only a handful are considered
    basic. However, the number of emotions considered in emotion analysis research
    is not always limited to just these basic emotions. Furthermore, it is not straightforward
    to demarcate emotions, and hence boundaries are very rarely clearly defined.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 人类可以体验到大量的情感，但只有少数被认为是基本的。然而，在情感分析研究中考虑的情感数量并不总是仅限于这些基本情感。此外，区分情感并不简单，因此边界很少被明确界定。
- en: 'We will now consider what are known as the *primary emotions*. These have been
    described as a reaction to an event or situation, or the immediate strong first
    reaction experienced when something happens. There has been much research on identifying
    these primary emotions, but there is still no general agreement, and different
    models have been suggested by eminent researchers such as Ekman, Plutchik, and
    Parrot. Some emotions such as anger, fear, joy, and surprise are universally agreed
    upon. However, the same is not true for other emotions, with disagreements on
    the emotions that constitute the basic emotions and the number of these emotions.
    Although there is, again, no consensus on which model is best at covering basic
    emotions, the models proposed by Ekman and Plutchik are most commonly used. There
    are two popular approaches: **categorical** and **dimensional**.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将考虑所谓的*基本情感*。这些情感被描述为对事件或情况的反应，或者当某事发生时立即强烈的第一反应。在识别这些基本情感方面已经进行了大量研究，但仍然没有达成普遍共识，杰出的研究人员如Ekman、Plutchik和Parrot提出了不同的模型。一些情感，如愤怒、恐惧、快乐和惊讶，是普遍认可的。然而，对于其他情感，关于构成基本情感的情感和这些情感的数量存在分歧。尽管再次没有关于哪个模型最适合涵盖基本情感的共识，但Ekman和Plutchik提出的模型最常被使用。有两种流行的方法：**类别**和**维度**。
- en: Categorical
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 类别
- en: Ekman is an advocate of the categorical theory, which suggests that emotions
    arise from separate neural systems. This approach also suggests that there are
    a limited number of primary, distinct emotions, such as anger, anxiety, joy, and
    sadness. Ekman suggested that primary emotions must have a distinct facial expression
    that is recognizable across all cultures. For example, the corners of the lips
    being turned down demonstrates sadness – and this facial expression is recognized
    universally as portraying sadness. Similarly, smiling with teeth exposed and the
    corners of the mouth pointing upwards is universally recognized as joy.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Ekman是类别理论的倡导者，该理论认为情感源于不同的神经网络系统。这种方法还表明，存在有限数量的基本、独特的情感，如愤怒、焦虑、快乐和悲伤。Ekman提出，基本情感必须具有在所有文化中都能识别的独特面部表情。例如，嘴唇角向下弯曲表示悲伤——这种面部表情被普遍认为是描绘悲伤的。同样，露出牙齿微笑，嘴角向上，被普遍认为是快乐。
- en: 'Amazingly, people blind from birth use the same facial expressions when expressing
    sadness and joy. They have never seen these facial expressions, so it is impossible
    that these expressions were learned. It is much more likely that these are an
    integral part of human nature. Using this understanding of distinct, universal
    facial expressions, Ekman proposed six primary emotions (Ekman, 1993):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，从出生就失明的人表达悲伤和快乐时使用相同的面部表情。他们从未见过这些表情，因此这些表情不可能被学习。更有可能的是，这些是人性的一部分。利用对独特、普遍面部表情的理解，Ekman提出了六种基本情感（Ekman，1993）：
- en: Anger
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 愤怒
- en: Disgust
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 厌恶
- en: Fear
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恐惧
- en: Joy
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快乐
- en: Sadness
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 悲伤
- en: Surprise
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 惊讶
- en: Ekman suggested that these *basic* emotions were biologically primitive and
    have evolved to increase the reproductive fitness of animals and that all other
    emotions were combinations of these eight primary emotions. Later, Eckman expanded
    this list to include other emotions that he considered basic, such as embarrassment,
    excitement, contempt, shame, pride, satisfaction, and amusement.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 艾克曼认为这些*基本*情绪在生物学上是原始的，并且已经进化以增加动物的繁殖适应性，而且所有其他情绪都是这八种基本情绪的组合。后来，艾克曼扩大了这个列表，包括他认为的基本情绪，如尴尬、兴奋、轻蔑、羞愧、自豪、满意和娱乐。
- en: 'Another of the most influential works in the area of emotions is Plutchik’s
    psychoevolutionary theory of emotion. Plutchik proposed eight primary emotions
    (Plutchik, 2001):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在情绪领域最具影响力的另一项工作是普鲁奇克的情绪心理进化理论。普鲁奇克提出了八种基本情绪（普鲁奇克，2001年）：
- en: Anger
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 愤怒
- en: Anticipation
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 期待
- en: Disgust
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 厌恶
- en: Fear
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恐惧
- en: Joy
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快乐
- en: Sadness
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 悲伤
- en: Surprise
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 惊讶
- en: Trust
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信任
- en: From this theory, Plutchik developed a Wheel of Emotions (see *Figure 1**.1*).
    This wheel was developed to help understand the nuances of emotion and how emotions
    contrast. It has eight sectors representing the eight emotions. Emotions intensify
    as they move from outside toward the center of the wheel. For example, annoyance
    increases to anger and then further increases to outright rage. Each sector of
    the circle has an opposite emotion that is placed directly opposite in the wheel.
    For example, the opposite of sadness is joy, and the opposite of anger is fear.
    It also shows how different emotions can be combined.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个理论出发，普鲁奇克发展了一个情绪轮（见图*1**.1*）。这个轮子是为了帮助理解情绪的细微差别以及情绪如何对比而开发的。它有八个区域代表八种情绪。情绪随着它们从轮子的外围向中心移动而增强。例如，烦恼增加到愤怒，然后进一步增加到彻底的愤怒。圆圈的每个区域都有一个直接相对的相反情绪，位于轮子的直接对面。例如，悲伤的对立面是快乐，愤怒的对立面是恐惧。它还显示了不同情绪如何结合。
- en: '![Figure 1.1 – Plutchik’s Wheel of Emotions](img/B18714_01_01.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1 – 普鲁奇克情绪轮](img/B18714_01_01.jpg)'
- en: Figure 1.1 – Plutchik’s Wheel of Emotions
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 普鲁奇克情绪轮
- en: Although Ekman and Plutchik’s theories are the most common, there are other
    works, but there is little agreement on what the basic emotions are. However,
    in the area of emotion analysis research, Ekman and Plutchik’s models are the
    most often used classification schemes.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然艾克曼和普鲁奇克的理论是最常见的，但还有其他作品，但对于基本情绪是什么并没有达成共识。然而，在情绪分析研究领域，艾克曼和普鲁奇克的模型是最常用的分类方案。
- en: Dimensional
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维度
- en: The dimensional approach posits that to understand emotional experiences, the
    fundamental dimensions of valence (the *goodness* and *badness* of the emotion)
    and arousal (the *intensity* of the emotion) are vital. This approach suggests
    that a common and interconnected neurophysiological system is responsible for
    all affective states. Every emotion can then be defined in terms of these two
    measures, so the plane can be viewed as a continuous two-dimensional space, with
    dimensions of valence and arousal, and each point in the place corresponds to
    a separate emotion state.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 维度方法认为，为了理解情绪体验，情绪的基本维度（情绪的*好坏*）和唤醒（情绪的*强度*）是至关重要的。这种方法表明，一个共同的、相互关联的神经生理系统负责所有情感状态。每个情绪都可以用这两个指标来定义，因此平面可以被视为一个连续的两维空间，其维度为情绪的好坏和唤醒，空间中的每个点都对应一个单独的情绪状态。
- en: '![Figure 1.2 – Russell’s circumplex model](img/B18714_01_02.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图1.2 – 拉塞尔的环状模型](img/B18714_01_02.jpg)'
- en: Figure 1.2 – Russell’s circumplex model
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – 拉塞尔的环状模型
- en: 'The most common dimensional model is Russell’s circumplex model ((Russell,
    1980): see *Figure 1**.2*). The model posits that emotions are made up of two
    core dimensions: valence and arousal. *Figure 1**.2* shows that valence ranges
    from −1 (unpleasant) to 1 (pleasant), and arousal also ranges from −1 (calm) to
    1 (excited). Each emotion is then a linear combination of these two dimensions.
    For example, anger is an unpleasant emotional state (a negative valence) with
    a high intensity (a positive arousal). Other basic emotions can be seen in *Figure
    1**.2* with their approximate positions in the two-dimensional space.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的维度模型是拉塞尔的环状模型（拉塞尔，1980年：见图*1**.2*）。该模型认为，情绪由两个核心维度组成：情绪的好坏和唤醒。*图1**.2*显示，情绪的好坏范围从-1（不愉快）到1（愉快），唤醒也范围从-1（平静）到1（兴奋）。然后每个情绪都是这两个维度的线性组合。例如，愤怒是一种不愉快的情绪状态（负面的情绪好坏）具有高强度（正面的唤醒）。其他基本情绪可以在*图1**.2*中看到，它们在二维空间中的大致位置。
- en: Some emotions have similar arousal and valence (for example, grief and rage).
    Hence, a third dimension (control) has also been suggested that can be used to
    distinguish between these. Control ranges from *no control* to *full control*.
    So, the entire range of human emotions can be represented as a set of points in
    the three-dimensional space using these three dimensions.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一些情感具有相似的唤醒和效价（例如，悲伤和愤怒）。因此，还提出了第三个维度（控制），可以用来区分这些情感。控制范围从*无控制*到*完全控制*。因此，使用这三个维度，整个人类情感的整个范围都可以表示为三维空间中的一组点。
- en: The dimensional model has a poorer resolution of emotions; that is, it is harder
    to distinguish between ambiguous emotions. The categorical model is simpler to
    understand, but some emotions are not part of the set of basic emotions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 维度模型在情感分辨率上较差；也就是说，区分模糊情感更困难。分类模型更容易理解，但有些情感并不属于基本情感集合。
- en: Most emotion analysis research uses a categorical perspective; there seems to
    be a lack of research using the dimensional approach.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情感分析研究都采用分类视角；似乎缺乏使用维度方法的研究。
- en: Sentiment
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 情感
- en: There is a second closely-related term known as **sentiment**. The terms sentiment
    and emotion seem to be used in an ad hoc manner, with different writers using
    them almost interchangeably. Given the difficulty we have found in working out
    what emotions are, and in deciding exactly how many emotions there are, having
    yet another ill-defined term is not exactly helpful. To try to clarify the situation,
    note that when people work on sentiment mining, they generally make use of a simple,
    limited system of classification using *positive*, *negative*, and *neutral* cases.
    This is a much simpler scheme to process and ascertain, and yields results that
    are also easier to understand. In some ways, emotion analysis may be regarded
    as an *upgrade* to sentiment analysis; a more complex solution that analyzes much
    more than the simple positive and negative markers and instead tries to determine
    specific emotions (anger, joy, sadness). This may be more useful but also involves
    much more effort, time, and cost. Emotion and sentiment are, thus, not the same.
    An emotion is a complex psychological state, whereas a sentiment is a mental attitude
    that is created through the very existence of the emotion.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个与之密切相关的术语，称为**情感**。情感和情绪这两个术语似乎是以一种临时的方式使用的，不同的作者几乎可以互换使用。鉴于我们在确定情感是什么以及确切有多少情感方面遇到的困难，再加上另一个定义不明确的术语并不完全有帮助。为了尝试澄清情况，请注意，当人们从事情感挖掘时，他们通常使用一个简单、有限的分类系统，包括*积极*、*消极*和*中性*案例。这是一个更简单的方案，更容易处理和确认，并且产生的结果也更容易理解。在某种程度上，情感分析可能被视为对情感分析的*升级*；一个更复杂的解决方案，它分析的内容远不止简单的积极和消极标记，而是试图确定特定的情感（愤怒、快乐、悲伤）。这可能更有用，但也需要更多的努力、时间和成本。因此，情感和情绪不是同一个概念。情感是一种复杂的心理状态，而情绪是通过情感的存在而产生的心理态度。
- en: For us, sentiment refers exclusively to an expressed opinion that is positive,
    negative, or neutral. There is some degree of overlap here because, for example,
    emotions such as joy and love could both be considered positive sentiments. It
    may be that the terms simply have different granularity – in the same way that
    ecstasy, joy, and contentment provide a fine-grained classification of a single
    generic emotion class that we might call happiness, happiness and love are a fine-grained
    classification of the general notion of feeling positive. Alternatively, it may
    be that sentiment is the name for one of the axes in the dimensional model – for
    example, the valence axis in Russell’s analysis. Given the range of theories of
    emotion, it seems best to just avoid having another term for much the same thing.
    In this book, we will stick to the term emotion; we will take an entirely pragmatic
    approach by accepting some set of labels from an existing theory such as Plutchik’s
    or Russell’s as denoting emotions, without worrying too much about what it is
    that they denote. We can all agree that *I hate the people who did that and I
    wish they were all dead* expresses hate and anger, and that it is overall negative,
    even if we’re not sure what hate and anger are or what the scale from negative
    to positive actually measures.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们来说，情感仅指表达出的正面、负面或中性的观点。在这里有一些重叠，因为例如快乐和爱都可以被视为积极的情感。可能这些术语只是具有不同的粒度——就像狂喜、快乐和满足提供了对单一通用情感类别（我们可能称之为快乐）的精细分类一样，快乐和爱是对积极感受这一普遍概念的精细分类。或者，情感可能是维度模型中的一个轴的名称——例如，在拉塞尔的分析中的效价轴。鉴于情感理论的多样性，似乎最好的做法是避免为几乎相同的事物使用另一个术语。在这本书中，我们将坚持使用“情感”这个术语；我们将采取完全实用主义的方法，接受来自现有理论（如普拉奇克或拉塞尔的理论）的一些标签，作为表示情感的标志，而不太关心它们究竟代表什么。我们都可以同意，“*我恨那些做那种事的人，我希望他们都死了*”表达了仇恨和愤怒，而且整体上是负面的，即使我们不确定仇恨和愤怒是什么，或者从负面到正面的尺度实际上衡量的是什么。
- en: Now that we know a bit more about what emotion is and how it is categorized
    and understood, it is essential to understand why emotion analysis is an important
    topic.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对情感有了更多的了解，知道了它是如何被分类和理解的，因此理解情感分析为何是一个重要的话题是至关重要的。
- en: Why emotion analysis is important
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 情感分析为何重要
- en: The amount of data generated daily from online sources such as social media
    and blogs is staggering. In 2019, Forbes estimated this to be around 2.5 quintillion
    bytes of data, though this figure is more
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 来自社交媒体和博客等在线来源的每日数据量令人震惊。2019年，《福布斯》估计这一数字约为2.5千兆字节的数据，尽管现在这个数字可能更高。
- en: than likely even higher now. Due to this, much research has focused on using
    this data for analysis and for gaining hitherto unknown insights (for example,
    predicting flu trends and disease outbreaks using Twitter (now known as “X”) data).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 更有可能的是现在这个数字甚至更高。因此，许多研究都集中在利用这些数据进行分析，以及获得迄今为止未知的新见解（例如，使用Twitter（现称为“X”）数据预测流感趋势和疾病爆发）。
- en: Similarly, people are also increasingly expressing their opinions online – and
    many of these opinions are, explicitly or implicitly, highly emotional (for example,
    *I love summer*). Nowadays, social network platforms such as Facebook, LinkedIn,
    and Twitter are at the hub of everything we do. Twitter is one of the most popular
    social network platforms, with more than 300 million users using Twitter actively
    every month. Twitter is used by people from all walks of life; celebrities, movie
    stars, politicians, sports stars, and everyday people. Users post short messages,
    known as **tweets**, and, every day, millions share their opinions about themselves,
    news, sports, movies, and other topics. Consequently, this makes platforms such
    as Twitter rich sources of data for public opinion mining and sentiment analysis.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，人们也越来越倾向于在网上表达自己的观点——其中许多观点，无论是明确还是隐晦，都充满了强烈的情感（例如，*我爱夏天*）。如今，像Facebook、LinkedIn和Twitter这样的社交网络平台已经成为我们所有活动的中心。Twitter是最受欢迎的社交网络平台之一，每月有超过3亿用户活跃使用Twitter。来自各行各业的人们都在使用Twitter；名人、电影明星、政治家、体育明星以及普通人。用户发布简短的消息，称为**推文**，每天数百万的人分享他们对自身、新闻、体育、电影和其他主题的看法。因此，这使得像Twitter这样的平台成为了公众舆论挖掘和情感分析的数据宝库。
- en: As we have seen, emotions play an important role in human intelligence, decision-making,
    social interaction, perception, memory, learning, creativity, and much much more.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，情感在人类智能、决策、社会互动、感知、记忆、学习、创造力以及更多方面发挥着重要作用。
- en: 'Emotion analysis is the process of recognizing the emotions that are expressed
    through texts (for example, social media posts). It is a complex task because
    user-generated content, such as tweets, is typically understood as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析是通过文本（例如，社交媒体帖子）识别表达出的情绪的过程。这是一个复杂的工作，因为用户生成的内容，如推文，通常被理解为如下：
- en: Written in natural language
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用自然语言书写
- en: Often unstructured, informal, and misspelled
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常是非结构化、非正式和拼错的
- en: Can contain slang and made-up words
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以包含俚语和虚构的单词
- en: Can contain emojis and emoticons where their usage does not always correspond
    to the reason for their original creation (for example, using the pizza emoji
    to express love)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以包含表情符号和表情符号，它们的用法并不总是与其原始创建的原因相对应（例如，使用披萨表情符号来表达爱）
- en: Furthermore, it is also entirely possible to express emotion without using any
    obvious emotion markers.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，完全有可能在不使用任何明显的情感标记的情况下表达情感。
- en: 'One of the big unsolved problems in emotion analysis is detecting emotions
    such as anticipation, pessimism, and sarcasm. Consider the following tweet:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析中尚未解决的重大问题之一是检测诸如期待、悲观和讽刺等情绪。考虑以下推文：
- en: '*We lost* *again. Great.*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们* *又输了*。太棒了。'
- en: We humans are fairly knowledgeable when it comes to drilling down to the true
    meaning implied, and would understand that the user was being sarcastic. We know
    that a team losing again is not a good thing. Hence, by making use of this understanding,
    we can easily identify the implied meaning.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们人类在深入挖掘隐含的真实意义方面相当有知识，会理解用户是在讽刺。我们知道一支球队再次输球不是好事。因此，通过利用这种理解，我们可以轻松地识别隐含的意义。
- en: The problem is that simply considering each word that has sentiment in isolation
    will not do a good job. Instead, further rules must be applied to understand the
    context of the word. These rules will help the analyzer differentiate between
    sentences that might contain similar words but have completely different meanings.
    However, even with these rules, analyzers will still make mistakes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，仅仅考虑具有情感色彩的每个单词而孤立地看待它们，并不能做好这项工作。相反，必须应用进一步的规则来理解单词的上下文。这些规则将帮助分析者区分可能包含相似单词但意义完全不同的句子。然而，即使有了这些规则，分析者仍然会犯错误。
- en: Social media is now viewed as a valuable resource, so organizations are showing
    an increased interest in social media monitoring to analyze massive, free-form,
    short, user-generated text from social
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 社交媒体现在被视为一项宝贵的资源，因此组织对社交媒体监控的兴趣日益增加，以分析来自社交媒体的大量、自由形式的简短、用户生成文本。
- en: media sites. Exploiting these allows organizations to gain insights into understanding
    their customer’s opinions, concerns, and needs about their products and services.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 媒体网站。利用这些网站可以让组织深入了解客户对其产品和服务意见、担忧和需求。
- en: Due to its real-time nature, governments are also interested in using social
    media to identify threats and monitor and analyze public responses to current
    events.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其实时性，政府也对使用社交媒体来识别威胁、监控和分析对当前事件的公众反应感兴趣。
- en: 'Emotion analysis has many interesting applications:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析有许多有趣的应用：
- en: '`#ShareACoke` by Coca-Cola, `#WantAnR8` by Audi, and `#BeTheFastest` by Virgin
    Media.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可口可乐的`#ShareACoke`，奥迪的`#WantAnR8`，以及维珍媒体的`#BeTheFastest`。
- en: '**Stock markets**: Academics have attempted to use Twitter to anticipate trends
    in financial markets. In 2013, the Associated Press Twitter account posted a (false)
    tweet stating that there had been explosions in the White House and that Obama
    was injured. The post was debunked very quickly but the stock markets still took
    a nosedive, resulting in hundreds of billions of dollars changing hands.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**股市**：学者们试图利用推特来预测金融市场趋势。2013年，美联社的推特账号发布了一条（虚假的）推文，称白宫发生了爆炸，奥巴马受伤。该帖子很快就被辟谣了，但股市仍然暴跌，导致数百亿美元易手。'
- en: '**Social studies**: Millions of people regularly interact with the world by
    tweeting, providing invaluable insights into their feelings, actions, routines,
    emotions, and behavior. This vast amount of public communication can be used to
    generate forecasts of various types of events. For example, large-scale data analysis
    of social media has demonstrated that not only did Brexit supporters have a more
    powerful, emotional message, but they were also more effective in the use of social
    media. They routinely outmuscled their rivals and had more vocal and active supporters
    across nearly all social media platforms. This led to the activation of a greater
    number of Leave supporters and enabled them to dominate social media platforms
    – thus influencing many undecided voters.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社会科学研究**：数百万的人通过发推文与世界互动，提供了关于他们的感受、行为、日常习惯、情绪和行为的有价值见解。如此大量的公共沟通可以用来预测各种类型的事件。例如，对社交媒体的大规模数据分析表明，不仅脱欧支持者有一个更有力、更具情感的信息，他们在社交媒体的使用上也非常有效。他们通常在几乎所有社交媒体平台上都压倒了对手，拥有更多声音和活跃的支持者。这导致了更多脱欧支持者的激活，并使他们能够主导社交媒体平台——从而影响了许多未决定投票的选民。'
- en: Gaining an understanding of emotions is also important for organizations to
    gain insights into public opinion about their products and services. However,
    it is also important to automate this process so that decisions can be made and
    actions can be taken in real-time. For example, analysis techniques can automatically
    analyze and process thousands of reviews about a particular product and extract
    insights that show whether consumers are satisfied with the product or service.
    This can be sentiment or emotion, although emotion may be more useful due to it
    being more granular.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 理解情感对于组织来说也很重要，以便深入了解公众对其产品和服务的态度。然而，自动化这一过程也很重要，以便能够实时做出决策并采取行动。例如，分析技术可以自动分析和处理关于特定产品的数千条评论，并提取出显示消费者是否对产品或服务满意的见解。这可能包括情感或情绪，尽管由于它更细致，情感可能更有用。
- en: Research has shown that tweets posted by dissatisfied users are shared more
    often and spread faster and wider than other types of tweets. Therefore, organizations
    have to provide customer services beyond the old-fashioned agent at the end of
    the phone line. Due to this, many organizations today also provide social media-based
    customer support in an attempt to head-off bad reviews and give a good impression.
    Nowadays, there is so much consumer choice, and it is so much easier for customers
    to switch to competitors, that it is vitally important for organizations to retain
    and increase their customer base. Hence, the quicker an organization reacts to
    a bad post, the better chance they have
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 研究表明，不满意的用户发布的推文比其他类型的推文更频繁地被分享，传播得更快、更广。因此，组织必须提供超越传统电话线末端的客服。因此，许多组织今天也提供基于社交媒体的客户支持，试图阻止负面评论并留下好印象。如今，消费者选择如此之多，客户转向竞争对手变得如此容易，因此，组织保留并增加其客户群至关重要。因此，组织对负面帖子的反应越快，他们获得的机会就越好。
- en: of retaining the customer. Furthermore, there is no better advertising than
    word of mouth – such as that generated by happy customers. Emotion analysis is
    one way to quickly analyze hundreds of tweets, find the ones where customers are
    unhappy, and use this to drive other processes that attempt to resolve the problem
    before the customer becomes too unhappy and decides to take their business elsewhere.
    Emotion analysis not only requires data – it also generates a lot of data. This
    data can be further analyzed to determine, for example, what the top items on
    user wishlists are, or what the top user gripes are. These can then be used to
    drive the next iteration or version of the product or service.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 保留客户的重要性。此外，没有比口碑更好的广告了——比如由满意的客户产生的口碑。情感分析是快速分析数百条推文、找出客户不满意的推文，并利用这些信息来推动其他试图在客户变得过于不高兴并决定将业务转移到其他地方之前解决问题的流程的一种方法。情感分析不仅需要数据——它还会生成大量数据。这些数据可以进一步分析，例如，确定用户愿望清单上的顶级项目，或者确定用户的主要抱怨。这些信息可以用来推动产品或服务的下一迭代或版本。
- en: Although sentiment analysis and emotion analysis are not mutually exclusive
    and can be used in conjunction, the consensus is that sentiment analysis is not
    adequate for classifying something as complex, multi-layered, and nuanced as emotion.
    Simply taking the whole range of emotions and considering them as only positive,
    negative, or neutral runs the considerable risk of missing out on deeper insights
    and understandings.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管情感分析和情绪分析并非相互排斥，并且可以结合使用，但普遍观点认为，情感分析不足以对像情感这样复杂、多层次、细微的事物进行分类。简单地将整个情感范围视为只有积极、消极或中性，存在很大的风险，可能会错过更深层次的洞察和理解。
- en: Emotion analysis also provides more in-depth insights. Understanding why someone
    ignored or liked a post needs more than just a sentiment score. Furthermore, gaining
    *actionable* insights also requires more than just a sentiment score.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 情绪分析也提供了更深入的洞察。理解为什么有人忽略或喜欢某个帖子，需要的不仅仅是情感分数。此外，获得*可操作的*洞察也需要不仅仅是情感分数。
- en: Emotion analysis is a sub-field of NLP, so it makes sense to gain a better understanding
    of that next.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 情绪分析是自然语言处理的一个子领域，因此，更好地理解这一点是有意义的。
- en: Introduction to NLP
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）简介
- en: 'Sentiment mining is about finding the sentiments that are expressed by natural
    language texts – often quite short texts such as tweets and online reviews, but
    also larger items such as newspaper articles. There are many other ways of getting
    computers to do useful things with natural language texts and spoken language:
    you can write programs that can have conversations (with people or with each other),
    you can write programs to extract facts and events from articles and stories,
    you can write programs to translate from one language to another, and so on. These
    applications all share some basic notions and techniques, but they each lay more
    emphasis on some topics and less on others. In [*Chapter 4*](B18714_04.xhtml#_idTextAnchor093),
    *Preprocessing – Stemming, Tagging, and Parsing*, we will look at the things that
    matter most for sentiment mining, but we will give a brief overview of the main
    principles of NLP here. As noted, not all of the stages outlined here are needed
    for every application, but it is nonetheless useful to have a picture of how everything
    fits together when considering specific subtasks later.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 情感挖掘是关于寻找自然语言文本中表达的情感——通常是相当简短的文本，如推文和在线评论，但也包括更长的内容，如报纸文章。还有许多其他方法可以让计算机对自然语言文本和口语进行有用的处理：你可以编写可以进行对话的程序（与人们或彼此对话），你可以编写从文章和故事中提取事实和事件的程序，你可以编写从一种语言翻译到另一种语言的程序，等等。这些应用都共享一些基本的概念和技术，但它们各自更侧重于某些主题，而较少关注其他主题。在[*第4章*](B18714_04.xhtml#_idTextAnchor093)“预处理——词干提取、词性标注和解析”中，我们将探讨情感挖掘中最重要的事情，但在这里我们将简要概述自然语言处理的主要原则。正如所提到的，这里概述的所有阶段并非每个应用都需要，但考虑后续的具体子任务时，了解一切如何相互关联仍然是有用的。
- en: 'We will start with a couple of basic observations:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从几个基本观察开始：
- en: Natural language is *linear*. The fundamental form of language is speech, which
    is necessarily linear. You make one sound, and then you make another, and then
    you make another. There may be some variation in the way you make each sound –
    louder or softer, with a higher pitch or a lower one, quicker or slower – and
    this may be used to overlay extra information on the basic message, but fundamentally,
    spoken language is made up of a *sequence* of identifiable units, namely sounds;
    and since written language is just a way of representing spoken language, it too
    must be made up of a sequence of identifiable units.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言是*线性的*。语言的基本形式是口语，它必然是线性的。你发出一个声音，然后发出另一个，再然后是另一个。你在发出每个声音的方式上可能会有一些变化——声音可能更响或更轻，音调可能更高或更低，速度可能更快或更慢——这些变化可能被用来在基本信息上叠加额外的信息，但本质上，口语是由一系列可识别的单位组成的序列，即声音；而书面语言只是口语的表示方式，它也必须由一系列可识别的单位组成。
- en: Natural language is hierarchical. Smaller units are grouped into larger units,
    which are grouped into larger units, which are grouped into larger units, and
    so on. Consider the sentence smaller units are grouped into larger units. In the
    written form of English, for instance, the smallest units are characters; these
    are grouped into morphemes (meaning-bearing word-parts), as small er unit s are
    group ed into large er unit s, which are grouped into words (small-er unit-s are
    group-ed into large-er unit-s), which are grouped into base-level phrases ([small-er
    unit-s] [are group-ed] [into] [large-er unit-s]), which are grouped into higher-level
    phrases ([[small-er unit-s] [[are group-ed] [[into] [large-er unit-s]]]]]).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言是分层的。较小的单位被组合成较大的单位，这些较大的单位又被组合成更大的单位，如此类推。以句子“较小的单位被组合成较大的单位”为例。在英语的书面形式中，例如，最小的单位是字符；这些字符被组合成语素（有意义的词部分），正如较小的单位被组合成较大的单位一样，这些较大的单位又被组合成单词（较小的单位被组合成较大的单位），这些单词又被组合成基础级别的短语（[较小的单位]
    [被组合] [成] [较大的单位]），这些短语又被组合成更高级别的短语（[[较小的单位] [[被组合] [[成] [较大的单位]]]]）。
- en: These two properties hold for all natural languages. All natural languages were
    spoken before they were written (some widely spoken languages have no universally
    accepted written form!), and hence are fundamentally linear. But they all express
    complex hierarchical relations, and hence to understand them, you have to be able
    to find the ways that smaller units are grouped into larger ones.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个特性适用于所有自然语言。所有自然语言在书写之前都是被说出来的（一些广泛使用的语言没有普遍接受的书写形式！），因此它们在本质上都是线性的。但它们都表达复杂的分层关系，因此要理解它们，你必须能够找到较小的单位组合成较大的单位的方式。
- en: 'What the bottom-level units are like, and how they are grouped, differs from
    language to language. The sounds of a language are made by moving your articulators
    (tongue, teeth, lips, vocal cords, and various other things) around while trying
    to expel air from your lungs. The sound that you get by closing and then opening
    your lips with your vocal cords tensed (/b/, as in the English word *bat*) is
    different from the sound you get by doing the same things with your lips while
    your vocal cords are relaxed (/p/, as in *pat*). Different languages use different
    combinations – Arabic doesn’t use /p/ and English doesn’t use the sound you get
    by closing the exit from the chamber containing the vocal cords (a **glottal stop**):
    the combinations that are used in a particular language are called its **phonemes**.
    Speakers of a language that don’t use a particular combination find it hard to
    distinguish words that use it from ones that use a very similar combination, and
    very hard to produce that combination when they learn a language that does.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 底层单位是什么样的，以及它们是如何组合的，因语言而异。一种语言的声音是通过移动你的发音器官（舌头、牙齿、嘴唇、声带以及各种其他东西）并试图从肺部排出空气来产生的。通过紧闭然后张开嘴唇并紧张声带得到的音（如在英语单词
    *bat* 中的 /b/）与通过放松声带并做同样的事情得到的音（如在 *pat* 中的 /p/）是不同的。不同的语言使用不同的组合——阿拉伯语不使用 /p/，而英语不使用通过关闭声带包含室的出口得到的音（一个**喉塞音**）：在特定语言中使用的组合被称为该语言的**音素**。不使用特定组合的语言使用者发现很难区分使用该组合的单词和非常相似的组合的单词，而且当他们学习使用该组合的语言时，很难产生那个组合。
- en: To make matters worse, the relationship between the bottom-level units in spoken
    language and written language can vary from language to language. The phonemes
    of a language can be represented in the written form of that language in a wide
    variety of ways. The written form may make use of **graphemes**, which are combinations
    of ways of making a shape out of strokes and marks (so, AAAAAA are all written
    by producing two near-vertical more-or-less-straight lines joined at the top with
    a cross-piece about half-way up), just as phonemes are combinations of ways of
    making a sound; a single phoneme may be represented by one grapheme (the short
    vowel /a/ from *pat* is represented in English by the character *a*) or by a combination
    of graphemes (the sound /sh/ from *should* is represented by the pair of graphemes
    *s* and *h*); a sound may have no representation in the written form (Arabic text
    omits short vowels and some other distinctions between phonemes); or there may
    simply be no connection between the written form and the way it is pronounced
    (written Chinese, Japanese kanji symbols). Given that we are going to be largely
    looking at text, we can at least partly ignore the wide variety of ways that written
    and spoken language are related, but we will still have to be aware that different
    languages combine the basic elements of the written forms in completely different
    ways to make up words.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，口语和书面语中底层单位之间的关系在不同的语言中可能会有所不同。一种语言的音素可以用该语言的书面形式以多种多样的方式来表示。书面形式可能会使用**图形符号**，这些是构成形状的笔画和标记的组合方式（因此，AAAAAA都是由两条几乎垂直的、或多或少直的线条组成，顶部相连，中间大约一半的位置有一个横杠），就像音素是构成声音的组合方式一样；一个音素可能由一个图形符号表示（来自
    *pat* 的短元音 /a/ 在英语中由字符 *a* 表示）或者由多个图形符号的组合表示（来自 *should* 的声音 /sh/ 由一对图形符号 *s*
    和 *h* 表示）；一个声音在书面形式中可能没有表示（阿拉伯文本省略了短元音和一些音素之间的其他区别）；或者书面形式和发音之间可能根本没有任何联系（书面汉语、日语的汉字符号）。鉴于我们将主要关注文本，我们至少可以部分地忽略书面语和口语之间关系的多样性，但我们仍然需要意识到，不同的语言以完全不同的方式组合书面形式的基本元素来构成单词。
- en: The bottom-level units of a language, then, are either identifiable sounds or
    identifiable marks. These are combined into groups that carry meaning – **morphemes**.
    A morpheme can carry quite a lot of meaning; for example, *cat* (made out of the
    graphemes *c*, *a*, and *t*) denotes a small mammal with pointy ears and an inscrutable
    outlook on life, whereas *s* just says that you’ve got more than one item of the
    kind you are thinking about, so *cats* denotes a group of several small mammals
    with pointy ears and an opaque view of the world. Morphemes of the first kind
    are sometimes called **lexemes**, with a single lexeme combining with one or more
    other morphemes to express a concept (so, the French lexeme *noir* (*black*) might
    combine with *e* (feminine) and *s* (plural) to make *noires* – several black
    female things). Morphemes that add information to a lexeme, such as about how
    many things were involved or when an event happened, are called **inflectional**
    morphemes, whereas ones that radically change their meaning (for example an *incomplete*
    solution to a problem is *not* complete) are called **derivational** morphemes,
    since they derive a new concept from the original. Again, most languages make
    use of inflectional and derivational morphemes to enrich the basic set of lexemes,
    but exactly how this works varies from language to language. We will revisit this
    at some length in [*Chapter 5*](B18714_05.xhtml#_idTextAnchor116) , *Sentiment
    Lexicons and Vector Space Models* since finding the core lexemes can be significant
    when we are trying to assign emotions to texts.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，语言的底层单位要么是可以识别的声音，要么是可以识别的标记。这些被组合成带有意义的组群——**词素**。一个词素可以承载相当多的意义；例如，“cat”（由词素“c”、“a”和“t”组成）表示一种长着尖耳朵和难以捉摸的生活态度的小型哺乳动物，而“s”只是表示你考虑的这类物品不止一个，所以“cats”表示一群有几个长着尖耳朵和世界观的哺乳动物。第一种类型的词素有时被称为**词素**，一个词素可以与一个或多个其他词素结合来表达一个概念（因此，法语词素“noir”（黑色）可以与“e”（阴性）和“s”（复数）结合形成“noires”——几个黑色的女性事物）。向词素添加信息的词素，如涉及的事物数量或事件发生的时间，被称为**屈折词素**，而那些根本改变其意义的词素（例如，一个问题的**不完整**解决方案不是完整的）被称为**派生词素**，因为它们从原始词素中派生出一个新概念。再次强调，大多数语言都使用屈折词素和派生词素来丰富基本的词素集，但具体如何操作因语言而异。我们将在[*第五章*](B18714_05.xhtml#_idTextAnchor116)，“情感词库和向量空间模型”中详细回顾这一点，因为当我们试图将情感分配给文本时，找到核心词素可能是重要的。
- en: A lexeme plus a suitable set of morphemes is often referred to as a **word**.
    Words are typically grouped into larger tree-like structures, with the way that
    they are grouped carrying a substantial part of the message conveyed by the text.
    In the sentence *John believes that Mary expects Peter to marry Susan*, for instance,
    *Peter to marry Susan* is a group that describes a particular kind of event, *Mary
    expects [Peter to marry Susan]* is a group that describes Mary’s attitude to this
    event, and *John believes [that Mary expected [Peter to marry Susan]]* is a group
    that describes John’s view of Mary’s expectation.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一个词素加上一个合适的词素集通常被称为**词**。词通常被分组成更大的树状结构，它们分组的方式承载了文本传达的大部分信息。例如，在句子“John believes
    that Mary expects Peter to marry Susan”中，“Peter to marry Susan”是一个描述特定事件的组群，“Mary
    expects [Peter to marry Susan]”是一个描述玛丽对此事件态度的组群，而“John believes [that Mary expected
    [Peter to marry Susan]]”是一个描述约翰对玛丽期望看法的组群。
- en: Yet again, different languages carry out this kind of grouping in different
    ways, and there are numerous ways of approaching the task of analyzing the grouping
    in particular cases. This is not the place for a review of all the grammatical
    theories that have ever been proposed to analyze the ways that words get grouped
    together or of all the algorithms that have ever been proposed for applying those
    theories to specific cases (**parsers**), but there are a few general observations
    that are worth making.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，不同的语言以不同的方式执行这种分组，针对特定情况分析分组的方法有很多。这不是对所有曾经提出的分析词语分组方式的语法理论（**解析器**）或所有曾经提出的将这些理论应用于特定情况的算法的综述之处，但有一些一般的观察值得提出。
- en: Phrase structure grammar versus dependency grammar
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 短语结构语法与依存语法
- en: 'In some languages, groups are mainly formed by merging adjacent groups. The
    previous sentence, for instance, can be analyzed if we group it as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些语言中，组群主要是通过合并相邻的组群形成的。例如，如果我们这样分组，上一句话就可以进行分析：
- en: '*In some languages groups are mainly formed by merging* *adjacent groups*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '*In [some languages]*np *groups are mainly formed by merging [**adjacent groups]*np'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '*[In [some languages]]*pp *groups are mainly formed by [merging [**adjacent
    groups]]*vp'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '*[In [some languages]]*pp *groups are mainly formed [by [merging [**adjacent
    groups]]]*pp'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '*[In [some languages]]*pp *groups are mainly [formed [by [merging [**adjacent
    groups]]]]*vp'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '*[In [some languages]]*pp *groups are [mainly [formed [by [merging [**adjacent
    groups]]]]]*vp'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '*[In [some languages]]*pp *groups [are [mainly [formed [by [merging [**adjacent
    groups]]]]]]*vp'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '*[In [some languages]]*pp *[groups [are [mainly [formed [by [merging [**adjacent
    groups]]]]]]]*s'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '*[[In [some languages]][groups [are [mainly [formed [by [merging [**adjacent
    groups]]]]]]]]*s'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: This tends to work well for languages where word order is largely fixed – no
    languages have completely fixed word order (for example, the preceding sentence
    could be rewritten as *Groups are mainly formed by merging adjacent groups in
    some languages* with very little change in meaning), but some languages allow
    more freedom than others. For languages such as English, analyzing the relationships
    between words in terms of adjacent phrases, such as using a **phrase structure
    grammar**, works quite well.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'For languages where words and phrases are allowed to move around fairly freely,
    it can be more convenient to record pairwise relationships between words. The
    following tree describes the same sentence using a **dependency grammar** – that
    is, by assigning a parent word to every word (apart from the full stop, which
    we are taking to be the root of the tree):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3 – Analysis of “In some languages, groups are mainly formed by
    merging adjacent groups” using a rule-based dependency parser](img/B18714_01_03.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
- en: Figure 1.3 – Analysis of “In some languages, groups are mainly formed by merging
    adjacent groups” using a rule-based dependency parser
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many variations of phrase structure grammar and many variations of
    dependency grammar. Roughly speaking, dependency grammar provides an easier handle
    on languages where words can move around very freely, while phrase structure grammar
    makes it easier to deal with *invisible* items such as the subject of *merging*
    in the preceding example. The difference between the two is, in any case, less
    clear than it might seem from the preceding figure: a dependency tree can easily
    be transformed into a phrase structure tree by treating each subtree as a phrase,
    and a phrase structure tree can be transformed into a dependency tree if you can
    specify which item in a phrase is its **head** – for example, in the preceding
    phrase structure tree, the head of a group labeled as **nn** is its noun and the
    head of a group labeled as **np** is the head of **nn**.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Rule-based parsers versus data-driven parsers
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As well as having a theory of how to describe the structure of a piece of text,
    you need a program that applies that theory to specific texts – a **parser**.
    There are two ways to approach the development of a parser:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 除了有一个描述文本结构的理论外，你还需要一个程序将这个理论应用到特定的文本上——一个**解析器**。开发解析器有两种方法：
- en: '**Rule-based**: You can try to devise a set of rules that describe the way
    that a particular language works (a **grammar**), and then implement a program
    that tries to apply these rules to the texts you want analyzed. Devising such
    rules is difficult and time-consuming, and programs that try to apply them tend
    to be slow and fail if the target text does not obey the rules.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于规则**：你可以尝试制定一套规则来描述特定语言的工作方式（一种**语法**），然后实现一个程序，尝试将这些规则应用到你想分析的文本上。制定这样的规则是困难的且耗时，而试图应用这些规则的程序往往运行缓慢，如果目标文本不遵循这些规则，则可能会失败。'
- en: '**Data-driven**: You can somehow produce a set of analyses of a large number
    of texts (a **treebank**), and then implement a program that extracts patterns
    from these analyses. Producing a treebank is difficult and time-consuming – you
    need hundreds of thousands of examples, and the trees all have to be consistently
    annotated, which means that if this is to be done by people, then they have to
    be given consistent guidelines that cover every example they will see (which is,
    in effect, a grammar) (and if it is not done by people then you must already have
    an automated way of doing it, that is, a parser!).'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据驱动**：你可以以某种方式产生大量文本的分析集（一个**树库**），然后实现一个程序，从这些分析中提取模式。制作树库是困难的且耗时——你需要数十万个例子，并且所有的树都必须一致性地标注，这意味着如果由人来完成，那么他们必须得到涵盖他们将会看到的每一个例子的统一指南（这在实际上是一种语法）（如果没有人来完成，那么你必须已经有一个自动化的方法来做这件事，即解析器！）。'
- en: 'Both approaches have advantages and disadvantages: when considering whether
    to use a dependency grammar or a phrase structure grammar and then when considering
    whether to follow a rule-based approach or a data-driven one, there are several
    criteria to be considered. Since *no* existing system optimizes all of these,
    you should think about which ones matter most for your application and then decide
    which way to go:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法都有优点和缺点：在考虑是否使用依存语法或短语结构语法，以及考虑是否遵循基于规则的方法或数据驱动的方法时，有几个标准需要考虑。由于**没有**现有系统优化所有这些，你应该考虑哪些对你的应用最重要，然后决定走哪条路：
- en: '**Speed**: The first criterion to consider is the speed at which the parser
    runs. Some parsers can become very slow when faced with long sentences. The worst-case
    complexity of the standard **chart-parsing** algorithm for rule-based approaches
    is O(N3), where *N* is the length of the sentence, which means that for long sentences,
    the algorithm can take a *very* long time. Some other algorithms have much better
    complexity than this (the MALT (Nivre et al., 2006) and MST (McDonald et al.,
    2005) parsers, for instance, are linear in the length of the sentence), while
    others have much worse. If two parsers are equally good according to all the other
    criteria, then the faster one will be preferable, but there will be situations
    where one (or more) of the other criteria is more important.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**：首先需要考虑的是解析器的运行速度。一些解析器在遇到长句时可能会变得非常慢。基于规则的标准的**图表解析**算法的复杂度最坏情况下是O(N^3)，其中*N*是句子的长度，这意味着对于长句，算法可能需要非常长的时间。有些其他算法的复杂度比这要好得多（例如，MALT（Nivre等，2006）和MST（McDonald等，2005）解析器，它们的复杂度与句子的长度成线性关系），而有些则更差。如果两个解析器在其他所有标准上都是一样的，那么更快的那个将被优先考虑，但也会有一些情况，其中一个（或多个）其他标准更为重要。'
- en: '**Robustness**: Some parsers, particularly rule-based ones, can fail to produce
    any analysis at all for some sentences. This will happen if the input is ungrammatical,
    but it will also happen if the rules are not a complete description of the language.
    A parser that fails to produce a perfectly grammatical input sentence is less
    useful than one that can analyze every grammatically correct sentence of the target
    language. It is less clear that parsers that will do something with every input
    sentence are necessarily more useful than ones that will reject some sentences
    as being ungrammatical. In some applications, detecting ungrammaticality is a
    crucial part of the task (for example, in language learning programs), but in
    any case, assigning an analysis to an ungrammatical sentence cannot be either
    right or wrong, and hence any program that makes use of such an analysis cannot
    be sure that it is doing the right thing.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**鲁棒性**：一些解析器，尤其是基于规则的解析器，可能无法对某些句子产生任何分析。如果输入是不合语法的，这将会发生，但如果规则不是对语言的完整描述，也会发生。无法产生完全合语法输入句子分析的解析器比能够分析目标语言中每个合语法句子的解析器更不有用。对于任何输入句子都进行某些操作的分析器是否比拒绝一些不合语法句子的分析器更有用，这一点并不明确。在某些应用中，检测不合语法性是任务的关键部分（例如，在语言学习程序中），但在任何情况下，将分析分配给不合语法句子既不能是正确的，也不能是错误的，因此任何利用这种分析的程序都不能确定它在做正确的事情。'
- en: '**Accuracy**: A parser that assigns the *right* analysis to every input text
    will generally be more useful than one that does not. This does, of course, beg
    the question of how to decide what the right analysis is. For data-driven parsers,
    it is impossible to say what the right analysis of a sentence that does not appear
    in the treebank is. For rule-based parsers, any analysis that is returned will
    be right in the sense that it obeys the rules. So, if an analysis looks odd, you
    have to work out how the rules led to it and revise them accordingly.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确性**：将正确分析分配给每个输入文本的解析器通常比没有这样做更有用。当然，这提出了一个问题，即如何决定正确的分析是什么。对于数据驱动解析器，不可能说出树库中未出现的句子的正确分析。对于基于规则的解析器，任何返回的分析都将符合规则，因此是正确的。所以，如果一个分析看起来很奇怪，你必须找出规则是如何导致它的，并相应地修改它们。'
- en: 'There is a trade-off between accuracy and robustness. A parser that fails to
    return any analysis at all in complex cases will produce fewer wrong analyses
    than one that tries to find some way of interpreting every input text: the one
    that simply rejects some sentences will have lower recall but may have higher
    precision, and that can be a good thing. It may be better to have a system that
    says *Sorry, I didn’t quite understand what you just said* than one that goes
    ahead with whatever it is supposed to be doing based on an incorrect interpretation.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '在准确性和鲁棒性之间存在权衡。在复杂情况下无法返回任何分析的解析器，其错误分析的数量将少于试图以某种方式解释每个输入文本的解析器：简单地拒绝一些句子的解析器将具有较低的召回率，但可能具有更高的精确率，这可能是好事。拥有一个系统说“抱歉，我没有完全理解你刚才说的话”可能比基于错误解释继续执行的系统要好。 '
- en: '**Sensitivity and consistency**: Sometimes, sentences that look superficially
    similar have different underlying structures. Consider the following examples:'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**敏感性和一致性**：有些句子表面上看起来相似，但具有不同的深层结构。考虑以下例子：'
- en: a) I want to see the queen b) I went to see the queen
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: a) 我想去看女王 b) 我去看了女王
- en: '1(a) is the answer to *What do you want?* and 2(b) is the answer to *Why did
    you go?* If the structures that are assigned to these two sentences do not reflect
    the different roles for *to see the queen*, then it will be impossible to make
    this distinction:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 1(a) 是对“你想要什么？”的回答，而 2(b) 是对“你为什么去？”的回答。如果分配给这两个句子的结构没有反映“去看女王”的不同角色，那么将无法做出这种区分：
- en: '![Figure 1.4 – Trees for 1(a) and 1(b) from the Stanford dependency parser
    (Dozat et al., 2017)](img/B18714_01_04.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.4 – 来自斯坦福依存句法分析器的 1(a) 和 1(b) 的树形图（Dozat 等人，2017）](img/B18714_01_04.jpg)'
- en: Figure 1.4 – Trees for 1(a) and 1(b) from the Stanford dependency parser (Dozat
    et al., 2017)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 – 来自斯坦福依存句法分析器的 1(a) 和 1(b) 的树形图（Dozat 等人，2017）
- en: a) One of my best friends is watching old movies b) One of my favorite pastimes
    is watching old movies
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: a) 我最好的朋友之一正在看老电影 b) 我最喜欢的消遣之一是看老电影
- en: '![Figure 1.5 – Trees for 2(a) and 2(b) from the Stanford dependency parser](img/B18714_01_05.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.5 – 来自斯坦福依存句法分析器的 2(a) 和 2(b) 的树形图](img/B18714_01_05.jpg)'
- en: Figure 1.5 – Trees for 2(a) and 2(b) from the Stanford dependency parser
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5 – 来自斯坦福依存句法分析器的 2(a) 和 2(b) 的树形图
- en: 'The **Stanford dependency parser** (**SDP**) trees both say that the subject
    (*One of my best friends*, *One of my favorite pastimes*) is carrying out the
    action of watching old movies – it is sitting in its most comfortable armchair
    with the curtains drawn and the TV on. The first of these makes sense, but the
    second doesn’t: pastimes don’t watch old movies. What we need is an equational
    analysis that says that *One of my favorite pastimes* and *watching old movies*
    are the same thing, as in *Figure 1**.6*:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6 – Equational analysis of “One of my favorite pastimes is watching
    old movies”](img/B18714_01_06.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
- en: Figure 1.6 – Equational analysis of “One of my favorite pastimes is watching
    old movies”
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Spotting that 2(b) requires an analysis like this, where my favorite pastime
    is the predication in an equational use of *be* rather than the agent of a watching-old-movies
    event, requires more detail about the words in question than is usually embodied
    in a treebank.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'It can also happen that sentences that look superficially different have very
    similar underlying structures:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: a) Few great tenors are poor b) Most great tenors are rich
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This time, the SDP assigns quite different structures to the two sentences:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.7 – Trees for 3(a) and 3(b) from the SDP](img/B18714_01_07.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
- en: Figure 1.7 – Trees for 3(a) and 3(b) from the SDP
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: The analysis of 3(a) assigns *most* as a modifier of *great*, whereas the analysis
    of 3(b) assigns *few* as a modifier of *tenors*. *Most* can indeed be used for
    modifying adjectives, as in *He is the most annoying person I know*, but in 3(a),
    it is acting as something more like a determiner, just as *few* is in 3(b).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: a) There are great tenors who are rich b) Are there great tenors who are rich?
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It is clear that 4(a) and 4(b) should have almost identical analyses – 4(b)
    is just 4(a) turned into a question. Again, this can cause problems for treebank-based
    parsers:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.8 – Trees for 4(a) and 4(b) from MALTParser](img/B18714_01_08.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
- en: Figure 1.8 – Trees for 4(a) and 4(b) from MALTParser
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: The analysis in *Figure 1**.8* for 4(a) makes *are* the head of the tree, with
    *there*, *great tenors who are rich*, and as daughters, whereas 4(b) is given
    *tenors* as its head and *are*, *there*, *great*, *who are rich*, and *?* as daughters.
    It would be difficult, given these analyses, to see that 4(a) is the answer to
    4(b)!
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Treebank-based parsers frequently fail to cope with issues of the kind raised
    by the examples given here. The problem is that the treebanks on which they are
    trained tend not to include detailed information about the words that appear in
    them – that *went* is an intransitive verb and *want* requires a sentential complement,
    that friends are human and can therefore watch old movies while pastimes are events,
    and can therefore be equated with the activity of watching something, or that
    *most* can be used in a wide variety of ways.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: It is not possible to say that all treebank-based parsers suffer from these
    problems, but several very widely used ones (the SDP, the version of MALT distributed
    with the NLTK, the EasyCCG parser (Lewis & Steedman, 2014), spaCy (Kitaev & Klein,
    2018)) do. Some of these issues are fairly widespread (the failure to distinguish
    1(a) and 1(b)), and some arise because of specific properties of either the treebank
    or the parsing algorithm. Most of the pre-trained models for parsers such as MALT
    and SPACY are trained on the well-known Wall Street Journal corpus, and since
    this treebank does not distinguish between sentences such as 1(a) and 1(b), it
    is impossible for parsers trained on it to do so. All the parsers listed previously
    assign different structures to 3(a) and 3(b), which may be a characteristic of
    the treebank or it may be some property of the training algorithms. It is worth
    evaluating the output of any such parser to check that it does give distinct analyses
    for obvious cases such as 1(a) and 1(b) and does give parallel analyses for obvious
    cases such as 4(a) and 4(b).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 并不能说所有基于树库的解析器都存在这些问题，但其中一些非常广泛使用的解析器（如SDP、与NLTK一起分发的MALT版本、EasyCCG解析器（Lewis
    & Steedman, 2014）、spaCy（Kitaev & Klein, 2018））确实存在。其中一些问题相当普遍（如无法区分1(a)和1(b)），而有些问题则是因为树库或解析算法的特定属性而产生的。大多数用于MALT和SPACY等解析器的预训练模型都是在著名的华尔街日报语料库上训练的，由于这个树库无法区分1(a)和1(b)这样的句子，因此在其上训练的解析器也无法做到这一点。之前列出的所有解析器都将3(a)和3(b)分配给不同的结构，这可能既可能是树库的特性，也可能是训练算法的某些属性。值得评估任何此类解析器的输出，以检查它是否确实为像1(a)和1(b)这样的明显情况提供了不同的分析，并且是否为像4(a)和4(b)这样的明显情况提供了并行分析。
- en: 'So, when choosing a parser, you have to weigh up a range of factors. Do you
    care if it sometimes makes mistakes? Do you want it to assign different trees
    to texts whose underlying representations are different (this isn’t quite the
    same as accuracy because it could happen that what the parser produces isn’t wrong,
    it just doesn’t contain all the information you need, as in 1(a) and 1(b))? Do
    you want it to always produce a tree, even for texts that don’t conform to any
    of the rules of normal language (should it produce a parse for *#anxious don’t
    know why ................. #worry* 😶 *slowly going #mad hahahahahahahahaha*)?
    Does it matter if it takes 10 or 20 seconds to parse some sentences? Whatever
    you do, *do not trust what anyone says about a parser*: try it for yourself, on
    the data that you are intending to use it on, and check that its output matches
    your needs.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，在选择解析器时，你必须权衡一系列因素。你是否关心它有时会犯错误？你是否希望它为具有不同底层表示的文本分配不同的树（这并不完全等同于准确性，因为可能发生的情况是解析器产生的结果并不错误，只是没有包含你需要的所有信息，就像1(a)和1(b)那样）？你是否希望它总是为文本生成树，即使对于不符合正常语言任何规则的文本（它应该为*#anxious
    don’t know why ................. #worry* 😶 *slowly going #mad hahahahahahahahaha*)生成解析吗？解析某些句子需要10秒或20秒是否重要？无论你做什么，*不要相信任何人关于解析器的说法*：自己尝试，在你打算使用它的数据上尝试，并检查其输出是否符合你的需求。'
- en: Semantics (the study of meaning)
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语义学（对意义的研究）
- en: As we’ve seen, finding words, assigning them to categories, and finding the
    relationships between them is quite hard work. There would be no point in doing
    this work unless you had some application in mind that could make use of it. The
    key here is that the choice of words and the relationships between them are what
    allow language to carry messages, to have meaning. That’s why language is important;
    because it carries messages. Almost all application programs that do anything
    with natural language are concerned with the message carried by the input text,
    so almost all such programs have to identify the words that are present and the
    way they are arranged.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，寻找单词、将它们分配到类别中，并找出它们之间的关系是非常困难的。除非你有一个打算使用它的应用，否则做这项工作是没有意义的。关键在于，单词的选择以及它们之间的关系是语言能够传达信息、具有意义的原因。这就是为什么语言很重要的原因；因为它能够传达信息。几乎所有的自然语言处理应用程序都关注输入文本所携带的信息，因此几乎所有这样的程序都必须识别出存在的单词以及它们的排列方式。
- en: 'The study of how language encodes messages is known as semantics. As just noted,
    the message is encoded by the words that are present (**lexical semantics**) and
    the way they are arranged (**compositional semantics**). They are both crucial:
    you can’t understand the difference between *John loves Mary* and *John hates
    Mary* if you don’t know what *loves* and *hates* mean, and you can’t understand
    the difference between *John loves Mary* and *Mary loves John* if you don’t know
    how being the subject or object of a verb encodes the relationship between the
    things denoted by *John* and *Mary* and the event denoted by *loves*.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'The key test for a theory of semantics is the ability to carry out inference
    between sets of natural language texts. If you can’t do the inferences in 1–7
    (where P1, …, Pn |- Q means that Q can be inferred from the premises P1, …, Pn),
    then you cannot be said to understand English:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: John hates Mary |- John dislikes Mary
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (a) John and Mary are divorced |- John and Mary are not married
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (b) John and Mary are divorced |- John and Mary used to be married
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I saw a man with a big nose |- I saw a man
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Every woman distrusts John, Mary is a woman |- Mary distrusts John
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I saw more than three pigeons |- I saw at least four birds
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I doubt that she saw anyone |- I do not believe she saw a fat man
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These are very simple inferences. If someone said that the conclusions didn’t
    follow from the premises, you would have to say that they just don’t understand
    English properly. They involve a range of different kinds of knowledge – simple
    entailment relationships between words (*hates* entails *dislikes* (1)); more
    complex relationships between words (getting divorced means canceling an existing
    marriage (2), so if John and Mary are divorced, then they are not now married
    but at one time they were); the fact that *a man with a big nose* is something
    that is a man and has a big nose plus the fact that *A and* *B* entails *A* (3);
    an understanding of how quantifiers work ((4) and (5)); combinations of all of
    these (6) – but they are all inferences that anyone who understands English would
    agree with.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Some of this information can be fairly straightforwardly extracted from corpora.
    There is a great deal of work, for instance, on calculating the similarity between
    pairs of words, though extending that to cover entailments between words has proved
    more difficult. Some of it is much more difficult to find using data-driven methods
    – the relationships between *more than* and *at least*, for instance, cannot easily
    be found in corpora, and the complex concepts that lie behind the word *divorce*
    would also be difficult to extract unsupervised from a corpus.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, some of it can be applied by using tree-matching algorithms of
    various kinds, from simple algorithms that just compute whether one tree is a
    subtree of another to more complex approaches that pay attention to polarity (that
    *doubt* flicks a switch that turns the direction of the matching algorithm round
    – *I know she loves him* |*- I know she likes him, I doubt she likes him* |- *I
    doubt she loves him*) and to the relationships between quantifiers (*the* |- *some,
    more than N* |- *at least N-1*) (Alabbas & Ramsay, 2013) (MacCartney & Manning,
    2014). Some of it requires more complex strategies, in particular examples with
    multiple premises (4), but all but the very simplest (for example, just treating
    a sentence as a bag of words) require accurate, or at least consistent, trees.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Exactly how much of this machinery you need depends on your ultimate application.
    Fortunately for us, sentiment mining can be done reasonably effectively with fairly
    shallow approaches, but it should not be forgotten that there is a great deal
    more to understanding a text than simply knowing lexical relationships such as
    similarity or subsumption between words.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Before wrapping up this chapter, we will spend some time learning about machine
    learning, looking at various machine learning models, and then working our way
    through a sample project using Python.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to machine learning
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before discussing machine learning, it makes sense to properly understand the
    term artificial intelligence. Broadly speaking, artificial intelligence is a branch
    of computer science and is the idea that machines can be made to think and act
    just like us humans, without explicit programming instructions.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a common misconception that artificial intelligence is a *new thing*.
    The term is widely considered to have been coined in 1956 by assistant Professor
    of Mathematics John McCarthy at the Dartmouth Summer Research Project on Artificial
    Intelligence. We are now in an AI boom – but it was not always so; artificial
    intelligence has a somewhat chequered history. Following on from the 1956 conference,
    funding flowed generously and rapid progress was made as researchers developed
    systems that could play chess and solve mathematical problems. Optimism was high,
    but progress stalled because promises made earlier about artificial intelligence
    were not able to be fulfilled, and hence the funding dried up; this cycle was
    repeated in the 1980s. The current boom we are experiencing is due to the timely
    advances and emergence of three key technologies:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '**Big data**: Giving us the amounts of data required to be able to do artificial
    intelligence'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High-speed high-capacity storage devices**: Giving us the ability to store
    the data'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GPUs**: Giving us the ability to process the data'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nowadays, AI is everywhere. Here are some examples of AI:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Chatbots (for example, customer service chatbots)
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Alexa, Apple’s Siri, and other smart assistants
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autonomous vehicles
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spam filters
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendation engines
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'According to experts, there are four types of AI:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '**Reactive**: This is the simplest type and involves machines programmed to
    always respond in the same predictable manner. They cannot learn.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Limited memory**: This is the most common type of AI in use today. It combines
    pre-programmed information with historical data to perform tasks.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Theory of mind**: This is a technology we may see in the future. The idea
    here is that a machine with a theory of mind AI will understand emotions, and
    then alter its own behavior accordingly as it interacts with humans.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Self-aware**: This is the most advanced type of AI. Machines that are self-aware
    of their own emotions, and the emotions of those around them, will have a level
    of intelligence like human beings and will be able to make assumptions, inferences,
    and deductions. This is certainly one for the future as the technology for this
    doesn’t exist just yet.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning is one way to exploit AI. Writing software programs to cater
    to all situations, occurrences, and eventualities is time-consuming, requires
    effort, and, in some cases, is not even possible. Consider the task of recognizing
    pictures of people. We humans can handle this task easily, but the same is not
    true for computers. Even more difficult is programming a computer to do this task.
    Machine learning tackles this problem by getting the machine to program itself
    by learning through experiences.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'There is no universally agreed-upon definition of machine learning that everyone
    subscribes to. Some attempts include the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: A branch of computer science that focuses on the use of data and algorithms
    to imitate the way that humans learn
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The capability of machines to imitate intelligent human behavior
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A subset of AI that allows machines to learn from data without being programmed
    explicitly
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning needs data – and sometimes lots and lots of it.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Lack of data is a significant weak spot in AI. Without a reasonable amount of
    data, machines cannot perform and generate sensible results. Indeed, in some ways,
    this is just like how we humans operate – we look and learn and then apply that
    knowledge in new, unknown situations.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'And, if we think about it, everyone has data. From the smallest sole trader
    to the largest organization, everyone will have sales data, purchase data, customer
    data, and more. The format of this data may differ between different organizations,
    but it is all useful data that can be used in machine learning. This data can
    be collected and processed and can be used to build machine learning models. Typically,
    this data is split into the following sets:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '**Training set**: This is always the largest of the datasets (typically 80%)
    and is the data that is used to train the machine learning models.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Development set**: This dataset (10%) is used to tweak and try new parameters
    to find the ones that work the best for the model.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test set**: This is used to test (validate) the model (10%). The model has
    already seen the training data, so it cannot be used to test the model, hence
    this dataset is required. This dataset also allows you to determine whether the
    model is working well or requires more training.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It is good practice to have both development and test datasets. The process
    of building models involves finding the best set of parameters that give the best
    results. These parameters are determined by making use of the development set.
    Without the development set, we would be reduced to using the same datasets for
    training, testing, and evaluation. This is undesirable, but it can also present
    further problems unless handled carefully. For example, the datasets should be
    constructed such that the original dataset class proportions are preserved across
    the test and training sets. Furthermore, as a general point, training data should
    be checked for the following:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: It is relevant to the problem
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is large enough such that all use cases of the model are covered
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is unbiased and contains no imbalance toward any particular category
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Modern toolkits such as `sklearn` (Pedregosa et al., 2011) provide ready-made
    functions that will easily split your dataset for you:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'However, there are times when the data scientist will not have enough data
    available to be able to warrant splitting it multiple ways – for example, there
    is no data relevant to the problem, or the process to collect the data is too
    difficult, expensive, or time-consuming. This is known as **data scarcity** and
    it can be responsible for poor model performance. In such cases, various solutions
    may help alleviate the problem:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '**Augmentation**: For example, taking an image and performing processing (for
    example, rotation, scaling, and modifying the colors) so that new instances are
    slightly different'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synthetic data**: Data that is artificially generated using computer programs'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To evaluate models where data is scarce, a technique known as k-fold cross-validation
    is used. This is discussed more fully in [*Chapter 2*](B18714_02.xhtml#_idTextAnchor061),
    briefly the dataset is split into a number (*k*) of groups; then, in turn, each
    group is taken as the test dataset with the remaining groups as the training dataset,
    and the model is fit and evaluated. This is repeated for each group, hence each
    member of the original dataset is used in the test dataset exactly once and in
    a training dataset k-1 times. Finally, the model accuracy is calculated by using
    the results from the individual evaluations.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 'This poses an interesting question about how much data is needed. There are
    no hard-and-fast rules but, generally speaking, the more the better. However,
    regardless of the amount of data, there are typically other issues that need to
    be addressed:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Missing values
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inconsistencies
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duplicate values
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ambiguity
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inaccuracies
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning is important. It has many real-world applications that can
    allow businesses and individuals to save time, money, and effort by, for example,
    automating business processes. Consider a customer service center where staff
    are required to take calls, answer queries, and help customers. In such a scenario,
    machine learning can be used to handle some of the more simple repetitive tasks,
    hence relieving burden from staff and getting things done more quickly and efficiently.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning has dramatically altered the traditional ways of doing things
    over the past few years. However, in many aspects, it still lags far behind human
    levels of performance. Often, the best solutions are hybrid human-in-the-loop
    solutions where humans are needed to perform final verification of the outcome.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several types of machine learning:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised learning
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinforcement learning
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Supervised learning models must be trained with **labeled** data. Hence, both
    the inputs and the outputs of the model are specified. For example, a machine
    learning model could be trained with human-labeled images of apples and other
    fruits, labeled as *apple* and *non-apple*. This would allow the machine to learn
    the best way to identify pictures of apples. Supervised machine learning is the
    most common type of machine learning used today. In some ways, this matches how
    we humans function; we look and learn from experiences and then apply that knowledge
    in unknown, new situations to work out an answer. Technically speaking, there
    are two main types of supervised learning problems:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification**: Problems that involve predicting labels (for example, *apple*)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regression**: Problems that involve predicting a numerical value (for example,
    a house price)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these types of problems can have any number of inputs of any type. These
    problems are known as **supervised** from the idea that the output is supplied
    by a teacher that shows the system what to do.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'Unsupervised learning is a type of machine learning that, opposite to supervised
    learning, involves training algorithms on data that is **unlabeled**. Unsupervised
    algorithms examine datasets looking for meaningful patterns or trends that would
    not otherwise be apparent – that is, the target is for the algorithm to find the
    structure in the data on its own. For example, unsupervised machine learning algorithms
    can examine sales data and pinpoint the different types of products being purchased.
    However, the problem with this is that although these models can perform more
    complex tasks than their supervised counterparts, they are also much more unpredictable.
    Some use cases that adopt this approach are as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '**Dimensionality reduction**: The process of reducing the number of inputs
    into a model by identifying the key (*principal*) components that capture the
    majority of the data without losing key information.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Association rules**: The process of finding associations between different
    inputs in the input dataset by discovering the probabilities of the co-occurrence
    of items. For example, when people buy ice cream, they also typically buy sunglasses.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustering**: Finds hidden patterns in a dataset based on similarities or
    differences and groups the data into clusters or groups. Unsupervised learning
    can be used to perform clustering when the exact details of the clusters are unknown.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning is, unsurprisingly, a combination of supervised and
    unsupervised learning. A small amount of labeled data and a large amount of unlabeled
    data is used. This has the benefits of both unsupervised and supervised learning
    but at the same time avoids the challenges of requiring large amounts of labeled
    data. Consequently, models can be trained to label data without requiring huge
    amounts of labeled training data.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning is about learning the best behavior so that the maximum
    reward is achieved. This behavior is learned by interacting with the environment
    and observing how it responds. In other words, the sequence of actions that maximize
    the reward must be independently discovered via a trial-and-error process. In
    this way, the model can learn the actions that result in success in an unseen
    environment.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'Briefly, here are the typical steps that are followed in a machine learning
    project:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '**Data collection**: Data can come from a database, Excel, or text file – essentially
    it can come from anywhere.'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data preparation**: The quality of the data used is crucial. Hence, time
    must be spent fixing issues such as missing data and duplicates. Initial **exploratory
    data analysis** (**EDA**) is performed on the data to discover patterns, spot
    anomalies, and test theories about the data by using visual techniques.'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model training**: An appropriate algorithm and model is chosen to represent
    the data. The data is split into training data for developing the model and test
    data for testing the model.'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Evaluation**: To test the accuracy, the test data is used.'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Improve performance**: Here, a different model may be chosen, or other inputs
    may be used.'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s start with the technical requirements.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This book describes a series of experiments with machine learning algorithms
    – some standard algorithms, some developed especially for this book. These algorithms,
    along with various worked examples, are available as Python programs at [https://github.com/PacktPublishing/Machine-Learning-for-Emotion-Analysis/tree/main](https://github.com/PacktPublishing/Machine-Learning-for-Emotion-Analysis/tree/main),
    split into directories corresponding to the chapters in which the specific algorithms
    will be discussed.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the reasons why we implemented these programs in Python is that there
    is a huge amount of useful material to build upon. In particular, there are good
    -quality, efficient implementations of several standard machine learning algorithms,
    and using these helps us be confident that where an algorithm doesn’t work as
    well as expected on some dataset, it is because the algorithm isn’t very well
    suited to that dataset, rather than that we just haven’t implemented it very well.
    Some of the programs in the repository use very particular libraries, but there
    are several packages that we will use throughout this book. These are listed here.
    If you are going to use the code in the repository – which we hope you will because
    looking at what actual programs do is one of the best ways of learning – you will
    need to install these libraries. Most of them can be installed very easily, either
    by using the built-in package installer `pip` or by following the directions on
    the relevant website:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '`pandas` structures as inputs. You can install it by typing the following command
    in the command prompt:'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Or you can go to [https://pandas.pydata.org/docs/getting_started/install.xhtml](https://pandas.pydata.org/docs/getting_started/install.xhtml)
    for other options.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NumPy**: This is used primarily for its support of *N*-dimensional arrays.
    It has functions for linear algebra and matrices and is also used by other libraries.
    Python provides several collection classes that can be used to represent arrays,
    notably as lists, but they are computationally slow to work with – NumPy provides
    objects that are up to 50 times faster than Python lists. To install it, run the
    following command in the command prompt:'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Alternatively, you can refer to the documentation for more options: [https://numpy.org/install/](https://numpy.org/install/).'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '**SciPy**: This provides a range of scientific functions built on top of NumPy,
    including ways of representing sparse arrays (arrays where most elements are 0)
    that can be manipulated thousands of times faster than standard NumPy arrays if
    the vast majority of elements are 0\. You can install it using the following command:'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can also refer to the SciPy documentation for more details: [https://scipy.org/install/](https://scipy.org/install/).'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '**scikit-learn (Pedregosa et al., 2011)**: This is used to build machine learning
    models as it has functions for building supervised and unsupervised machine learning
    models, analysis, and dimensionality reduction. A large part of this book is about
    investigating how well various standard machine learning algorithms work on particular
    datasets, and it is useful to have reliable good-quality implementations of the
    most widely used algorithms so that we are not distracted by issues due to the
    way we have implemented them.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'scikit-learn is also known as `sklearn` – when you want to import it into a
    program, you should refer to it as sklearn. You can install it as follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Refer to the documentation for more information: [https://scikit-learn.org/stable/install.xhtml](https://scikit-learn.org/stable/install.xhtml).'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: The `sklearn` implementations of the various algorithms generally make the internal
    representations of the data available to other programs. This can be particularly
    valuable when you are trying to understand the behavior of some algorithm on a
    given dataset and is something we will use extensively as we carry out our experiments.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '`pip`:'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For more information, refer to the TensorFlow documentation: [https://www.tensorflow.org/install](https://www.tensorflow.org/install).'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: You will not benefit from its use of parallelism unless you have a GPU or other
    hardware accelerator built into your machine, and training complex models is likely
    to be intolerably slow. We will consider how to use remote facilities such as
    Google Colab to obtain better performance in [*Chapter 9*](B18714_09.xhtml#_idTextAnchor172),
    *Exploring* *Transformers*. For now, just be aware that running `tensorflow` on
    a standard computer without any kind of hardware accelerator probably won’t do
    anything within a reasonable period.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '**Keras**: This is also used for building neural networks. It is built on top
    of TensorFlow. It creates computational graphs to represent machine learning algorithms,
    so it is slow compared to other libraries. Keras comes as part of TensorFlow,
    so there is no need to install anything beyond TensorFlow itself.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matplotlib`:'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Refer to the documentation for more information: [https://matplotlib.org/stable/users/installing/index.xhtml](https://matplotlib.org/stable/users/installing/index.xhtml).'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Matplotlib may install NumPy if you do not have it already installed, but it
    is more sensible to install them separately (NumPy first).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '**Seaborn**: This is built on the top of Matplotlib, and is another library
    for creating visualizations. It is useful for making attractive plots and helps
    users explore and understand data. Seaborn makes it easy for users to switch between
    different visualizations. You can easily install Seaborn by running the following
    command:'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For more installation options, please refer to [https://seaborn.pydata.org/installing.xhtml](https://seaborn.pydata.org/installing.xhtml).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: We will use these libraries throughout this book, so we advise you to install
    them now, before trying out any of the programs and examples that we’ll discuss
    as we go along. You only have to install them once so that they will be available
    whenever you need them. We will specify any other libraries that the examples
    depend on as we go along, but from now on, we will assume that you have at least
    these ones.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: A sample project
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The best way to learn is by doing! In this section, we will discover how to
    complete a small machine learning project in Python. Completing, and understanding,
    this project will allow you to become familiar with machine learning concepts
    and techniques.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, the first step in developing any Python program is to import the
    modules that are going to be needed using the `import` statement:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Other imports are needed for this exercise; these can be found in the GitHub
    repository.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to load the data that is needed to build the model. Like most
    tutorials, we will use the famous Iris dataset. The Iris dataset contains data
    on the length and width of sepals and petals. We will use `pandas` to load the
    dataset. The dataset can be downloaded from the internet and read from your local
    filesystem, as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Alternatively, `pandas` can read it directly from a URL:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `read_csv` command returns a DataFrame. It is probably the most commonly
    used `pandas` object and is simply a two-dimensional data structure with rows
    and columns, just like a spreadsheet.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we will be using `sklearn`, it is interesting to see that `sklearn` also
    makes it easy to access the dataset:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can now check that the dataset has been successfully loaded by using the
    `describe` function:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `describe` function returns a descriptive summary of a DataFrame reporting
    values such as the mean, count, and standard deviation:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This function is useful to check that the data has been loaded correctly but
    also to provide a first glance at some interesting attributes of the data.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'Some other useful commands tell us more about the DataFrame:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 'This shows the first five elements in the DataFrame:'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This shows the last five elements in the DataFrame:'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This describes the columns of the DataFrame:'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This describes the number of rows and columns in the DataFrame:'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: It is usually a good idea to use these functions to check that the dataset has
    been successfully and correctly loaded into the DataFrame and that everything
    looks as it should.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: It is also important to ensure that the dataset is balanced – that is, there
    are relatively equal numbers of each class.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: The majority of machine learning algorithms have been developed with the assumption
    that there are equal numbers of instances of each class. Consequently, imbalanced
    datasets present a big problem for machine learning models as this results in
    models with poor predictive performance.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Iris example, this means that we have to check that we have equal numbers
    of each type of flower. This can be verified by running the following command:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This prints the following output:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We can see that there are 50 examples of each variety. The next step is to create
    some visualizations. Although we used the `describe` function to get an idea of
    the statistical properties of the dataset, it is much easier to observe these
    in a visual form as opposed to in a table.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: 'Box plots (see *Figure 1**.9*) plot the distribution of data based on the sample
    minimum, the lower quartile, the median, the upper quartile, and the sample maximum.
    This helps us analyze the data to establish any outliers and the data variation
    to better understand each attribute:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This outputs the following plot:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.9 – Box plot](img/B18714_01_09.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
- en: Figure 1.9 – Box plot
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: Heatmaps are useful for understanding the relationships between attributes.
    Heatmaps are an important tool for data scientists to explore and visualize data.
    They represent the data in a two-dimensional format and allow the data to be summarized
    visually as a colored graph. Although we can use `matplotlib` to create heatmaps,
    it is much easier in `seaborn` and requires significantly fewer lines of code
    – something we like!
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This outputs the following heatmap:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.10 – Heatmap](img/B18714_01_10.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
- en: Figure 1.10 – Heatmap
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: 'The squares in the heatmap represent the correlation (a measure that shows
    how much two variables are related) between the variables. The correlation values
    range from -1 to +1:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: The closer the value is to 1, the more positively correlated they are – that
    is, as one increases, so does the other
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conversely, the closer the value is to -1, the more negatively correlated they
    are – that is, as one variable decreases, the other will increase
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Values close to 0 indicate that there is no linear trend between the variables
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In *Figure 1**.10*, the diagonals are all 1\. This is because, in those squares,
    the two variables are the same and hence the correlation is to itself. For the
    remainder, the scale shows that the lighter the color (toward the top of the scale),
    the higher the correlation. For example, the petal length and petal width are
    highly correlated, whereas petal length and sepal width are not. Finally, it can
    also be seen that the plot is symmetrical on both sides of the diagonal. This
    is because the same set of variables are paired in the squares that are the same.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now build a model using the data and estimate the accuracy of the model
    on data that it has not seen previously. Let’s start by separating the data and
    the labels from each other by using Python:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Before we can train a machine learning model, it is necessary to split the
    data and labels into testing and training data. As discussed previously, we can
    use the `train_test_split` function from `sklearn`:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The capital `X` and lowercase `y` are a nod to math notation, where it is common
    practice to write matrix variable names in uppercase and vector variable names
    using lowercase letters. This has no special Python function and these conventions
    can be ignored if desired. For now, note that `X` refers to data, and `y` refers
    to the associated labels. Hence, `X_train` can be understood to refer to an object
    that contains the training data.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can begin to work on the machine learning model, we must *normalize*
    the data. Normalization is a scaling technique that updates the numeric columns
    to use a common scale. This helps improve the performance, reliability, and accuracy
    of the model. The two most common normalization techniques are min-max scaling
    and standardization scaling:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '**Min-max scaling**: This method uses the minimum and maximum values for scaling
    and rescales the values so that they end up in the range 0 to 1 or -1 to 1\. It
    is most useful when the features are of different scales. It is typically used
    when the feature distribution is unknown, such as in k-NN or neural network models.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standardization scaling**: This method uses the mean and the standard deviation
    to rescale values so that they have a mean of 0 and a variance of 1\. The resultant
    scaled values are not confined to a specific range. It is typically used when
    the feature distribution is normal.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It is uncommon to come across datasets that perfectly follow a certain specific
    distribution. Typically, every dataset will need to be standardized. For the Iris
    dataset, we will use sklearn’s `StandardScaler` to scale the data by making the
    mean of the data 0 and the standard deviation 1:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Now that the data is ready, `sklearn` makes it easy for us to test and compare
    various machine learning models. A brief explanation of each model has been provided
    but don’t worry – we explain these models in more detail later in later chapters.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Logistic regression** is one of the most popular machine learning techniques.
    It is used to predict a categorical dependent variable using a set of independent
    variables and makes use of a *sigmoid* function. The sigmoid is a mathematical
    function that has values from 0 to 1 and asymptotes both values. This makes it
    useful for binary classification with 0 and 1 as potential output values:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: There is also a technique called linear regression but, as its name suggests,
    this is used for regression problems, whereas the current Iris problem is a classification
    problem.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: Support vector machines (SVMs)
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Support vector machine** (**SVM**) is one of the best “out-of-the-box” classification
    techniques. SVM constructs a hyperplane that can then be used for classification.
    It works by calculating the distance between two observations and then determining
    a hyperplane that maximizes the distance between the closest members of separate
    classes. The linear **support vector classifier** (**SVC**) method (as used in
    the following example) applies a linear kernel function to perform classification:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The following parameters are used:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: '`random_state`: This controls the random number generation that is used to
    shuffle the data. In this example, a value hasn’t been set, hence a randomly initialized
    state is used. This means that results will vary between runs.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gamma`: This controls how much influence a single data point has on the decision
    boundary. Low values mean “far” and high values mean “close.” In this example,
    gamma is set to “auto,” hence allowing it to automatically define its own value
    based on the characteristics of the dataset.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C`: This controls the trade-off between maximizing the distance between classes
    and correctly classifying the data.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: K-nearest neighbors (k-NN)
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**k-NN** is another widely used classification technique. k-NN classifies objects
    based on the closest training examples in the feature space. It is a simple algorithm
    that stores all available cases and classifies new cases by a majority vote of
    its *k* neighbors. The case being assigned to the class is the most common among
    its k-NNs measured by a distance function:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Decision trees
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Decision trees** attempt to create a tree-like model that predicts the value
    of a variable by learning simple decision rules that are inferred from the data
    features. Decision trees classify examples by sorting down the tree from the root
    to a leaf node, with the leaf node providing the classification for our example:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Random forest
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Random forest** builds decision trees using different samples and then takes
    the majority vote as the answer. In other words, random forest builds multiple
    decision trees and then merges them to get a more accurate prediction. Due to
    its simplicity, it is also one of the most commonly used algorithms:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Neural networks
  id: totrans-346
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Neural networks** (also referred to as deep learning) are algorithms that
    are inspired by how the human brain works, and are designed to recognize numerical
    patterns. Neural networks consist of input and output *layers* and (optionally)
    hidden layers. These layers contain units (*neurons*) that transform the inputs
    into something useful for the output layer. These neurons are connected and work
    together. We will look at these in more detail later in this book.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: Making predictions
  id: totrans-348
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we have chosen and fit a machine learning model, it can easily be used
    to make predictions on new, unseen data – that is, take the final model and one
    or more data instances and then predict the classes for each of the data instances.
    The model is needed because the result classes are not known for the new data.
    The class for the unseen data can be predicted using scikit-learn’s `predict()`
    function.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the unseen data must be transformed into a pandas DataFrame, along with
    the column names:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This DataFrame can then be passed to scikit-learn’s `predict()` function to
    predict the class value:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: A sample text classification problem
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given that this is a book on emotion classification and emotions are generally
    expressed in written form, it makes sense to take a look at how a text classification
    problem is tackled.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: We have all received spam emails. These are typically emails that are sent to
    huge numbers of email addresses, usually for marketing or phishing purposes. Often,
    these emails are sent by bots. They are of no interest to the recipients and have
    not been requested by them. Consequently, email servers will often automatically
    detect and remove these messages by looking for recognizable phrases and patterns,
    and sometimes placing them into special folders labeled *Junk* or *Spam*.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will build a spam detector and use the machine learning
    abilities of scikit-learn to train the spam detector to detect and classify text
    as spam and non-spam. There are many labeled datasets available online (for example,
    from Kaggle); we chose to use the dataset from [https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset?resource=download](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset?resource=download).
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: The dataset contains SMS messages that have been collected for spam research.
    It contains 5,574 SMS messages in English that are labeled as spam or non-spam
    (ham). The file contains one message per line, and each line has two columns;
    the label and the message text.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: 'We have seen some of the basic `pandas` commands already, so let’s load the
    file and split it into training and test sets, as we did previously:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: The file may have an encoding error; for now, we will ignore this as it is not
    relevant to the task at hand.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: 'A handy function called `CountVectorizer` is available in `sklearn`. This can
    be used to transform text into a vector of term-token counts. It is also able
    to preprocess the text data before generating the vector representations, hence
    it is an extremely useful function. `CountVectorizer` converts the raw text into
    a numerical vector representation, which makes it easy to use the text as inputs
    in machine learning tasks:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Essentially, it assigns a number, randomly, to each word and then counts the
    number of occurrences of each. For example, consider the following sentence:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: '*The quick brown fox jumps over the* *lazy dog.*'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: 'This would be converted as follows:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '| **word** | **the** | **quick** | **brown** | **fox** | **jumps** | **over**
    | **lazy** | **dog** |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
- en: '| **index** | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
- en: '| **count** | 2 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
- en: Notice that there are eight unique words, hence eight columns. Each column represents
    a unique word in the vocabulary. Each count row represents the item or row in
    the dataset. The values in the cells are the word counts. Armed with this knowledge
    about the types and counts of common words that appear in spam, the model will
    be able to classify text as spam or non-spam.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the simple k-NN model introduced earlier:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The `fit()` function, as we have seen earlier, trains the model with the vectorized
    counts from the training data and the training labels. It compares its predictions
    against the real answers in `y_train` and then tunes its hyperparameters until
    it achieves the best possible accuracy. Note how here, since this is a classification
    task, the labels must also be passed to the `fit()` function. The Iris example
    earlier was a regression task; there were no labels, so we did not pass them into
    the `fit()` function:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We now have a model that we can use on the test data to test for accuracy:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Note how this time, we use `transform()` instead of `fit_transform()`. The difference
    is subtle but important. The `fit_transform()` function does `fit()`, followed
    by `transform()` – that is, it calculates the initial parameters, uses these calculated
    values to modify the training data, and generates a term-count matrix. This is
    needed when a model is being trained. The `transform()` method, on the other hand,
    only generates and returns the term-count matrix. The `score()` function then
    scores the prediction of the test data term-count matrix against the actual labels
    in test data labels, `y_test`, and even using a simplistic model we can classify
    spam with high accuracy and obtain reasonable results.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-379
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started by examining emotion and sentiment, and their origins.
    Emotion is not the same as sentiment; emotion is more fine-grained and is much
    harder to quantify and work with. Hence, we learned about the three main theories
    of emotion, with psychologists, neurologists, and cognitive scientists each having
    slightly different views as to how emotions are formed. We explored the approaches
    of Ekman and Plutchik, and how the categorical and dimensional models are laid
    out.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: We also examined the reasons why emotion analysis is important but difficult
    due to the nuances and difficulty of working with content written in natural language,
    particularly the kind of informal language we are concerned with in this book.
    We looked at the basic issues in NLP and will return to the most relevant aspects
    of NLP in [*Chapter 4*](B18714_04.xhtml#_idTextAnchor093), *Preprocessing – Stemming,
    Tagging, and Parsing*. Finally, we introduced machine learning and worked through
    some sample projects.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore where to find suitable data, the steps
    needed to make it fit for purpose, and how to construct a dataset suitable for
    emotion analysis.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-383
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: Alabbas, M., & Ramsay, A. M. (2013). *Natural language inference for Arabic
    using extendedtree edit distance with subtrees*. Journal of Artificial Intelligence
    Research, 48, 1–22.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dozat, T., Qi, P., & Manning, C. D. (2017). *Stanford’s Graph-based Neural
    Dependency Parser at the CoNLL 2017 Shared Task*. Proceedings of the CoNLL 2017
    Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, 20–30\.
    [https://doi.org/10.18653/v1/K17-3002](https://doi.org/10.18653/v1/K17-3002).'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ekman, P. (1993). *Facial expression and emotion*. *American Psychologist*,
    *48(4)*, 384.
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kitaev, N., & Klein, D. (2018). *Constituency Parsing with a Self-Attentive
    Encoder*. Proceedings of the 56th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), 2,676–2,686\. [https://doi.org/10.18653/v1/P18-1249](https://doi.org/10.18653/v1/P18-1249).'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lewis, M., & Steedman, M. (2014). *A* CCG Parsing with a Supertag-factored Model*.
    Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing
    (EMNLP), 990–1,000\. [https://doi.org/10.3115/v1/D14-1107](https://doi.org/10.3115/v1/D14-1107).
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MacCartney, B., & Manning, C. D. (2014). *Natural logic and natural language
    inference*. In Computing Meaning (pp. 129–147). Springer.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: McDonald, R., Pereira, F., Ribarov, K., & Hajič, J. (2005). *Non-Projective
    Dependency Parsing using Spanning Tree Algorithms*. Proceedings of Human Language
    Technology Conference and Conference on Empirical Methods in Natural Language
    Processing, 523–530\. [https://aclanthology.org/H05-1066](https://aclanthology.org/H05-1066).
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nivre, J., Hall, J., & Nilsson, J. (2006). MaltParser: *A data-driven parser-generator
    for dependency parsing*. Proceedings of the International Conference on Language
    Resources and Evaluation (LREC), 6, 2,216–2,219.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
    O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos,
    A., Cournapeau, D., Brucher, M., Perrot, M., & Duchesnay, E. (2011). *Scikit-learn:
    Machine Learning in Python*. Journal of Machine Learning Research, 12, 2,825–2,830.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Plutchik, R. (2001). *The Nature of Emotions: Human emotions have deep evolutionary
    roots, a fact that may explain their complexity and provide tools for clinical
    practice*. *American Scientist*, 89(4), 344–350.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russell, J. A. (1980). *A circumplex model of affect*. Journal of Personality
    and Social Psychology, 39(6), 1,161–1,178\. [https://doi.org/10.1037/h0077714](https://doi.org/10.1037/h0077714).
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Part 2:Building and Using a Dataset
  id: totrans-396
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The process of collecting data (e.g., tweets and news articles) is described
    in this part, followed by the preprocessing steps that are required to get good
    results to create a corpus.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B18714_02.xhtml#_idTextAnchor061), *Building and Using a Dataset*'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B18714_03.xhtml#_idTextAnchor077), *Labeling Data*'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B18714_04.xhtml#_idTextAnchor093), *Preprocessing – Stemming,
    Tagging, and Parsing*'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
