<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Creating Clusters on AWS</h1>
                </header>
            
            <article>
                
<p>One of the key problems in machine learning is understanding how to scale and parallelize the learning across multiple machines. Whether you are training deep learning models, which are very heavy on hardware usage, or just launching machines for creating predictions it is essential that we select the appropriate hardware configuration, both for const considerations and runtime performance reasons. </p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Choosing your instance types</li>
<li>Distributed deep learning</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Choosing your instance types</h1>
                </header>
            
            <article>
                
<p>In the <a href="af506fc8-f482-453e-8162-93a676b2e737.xhtml">Chapter 4</a>, <em>Predicting User Behavior with Tree-Based Methods,</em> and other chapters, we had to launch EMR clusters and SageMaker instances (servers) for learning and model serving. In this section, we discuss the characteristics of the different instance types. In this chapter, you can find all supported instance types AWS provides at <a href=".">https://aws.amazon.com/ec2/instance-types/</a>.</p>
<p>Depending on the task at hand, we should use different instance types. For example, we may require an instance type with GPUs rather than CPUs <span>for deep learning</span>. When launching a large iterative <strong>Extract, Transform, and Load</strong> (<span><strong>ETL</strong>)</span> job (that is, a data transformation job) on Apache Spark, we might need large amounts of memory. To make it easier for the users, AWS has classified the instances into families that are catered for different use cases. Additionally, AWS constantly provides newer hardware configurations for each family. These are called <strong>generations</strong>. Typically, a new generation provides improved performance over the previous generation. However, older generations are usually still available. In turn, each family has machines of different sizes in terms of compute and memory capabilities.</p>
<p>The most commonly used families are as follows:</p>
<ul>
<li style="font-weight: 400">Compute optimized (C-family)</li>
<li style="font-weight: 400">Memory optimized (M-family)</li>
<li style="font-weight: 400">Accelerated computing (P-family)</li>
<li style="font-weight: 400">Storage optimized (I-family)</li>
<li style="font-weight: 400">General purpose (R-family)</li>
</ul>
<p>There are other families for each optimization objective, but in the previous list, we list the most commonly used family for each. Each family may have a different configuration. The following table shows a few configurations for the C and M families. Each configuration has a different price. For example, the fifth generation, xlarge, and C-family machine costs $0.085 at the time of this writing on the <span class="packt_screen">us-east-1</span> region of AWS. As you can see, at a given price level, the user can choose to pay for a configuration that has more memory power and less compute power or vice versa. The <strong>Memory (GB)</strong> column in the following table shows values in gigabytes and the vCPUs are units of processing power in virtual machines, as measured by AWS. The prices shown in the table are just reference prices that correspond to the Virginia data center region on AWS as priced in March, 2019. Currently, AWS charges for the use of the instances for each second the machine is up (that is, even though the price is shown as an hourly amount, a machine can be launched for 120 seconds and the user would only need to pay the corresponding fraction of the hourly price):</p>
<div>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr style="height: 61px">
<td style="width: 89px;height: 61px">
<p><strong>Model</strong></p>
</td>
<td style="width: 53px;height: 61px">
<p><strong>vCPU</strong></p>
</td>
<td style="width: 109px;height: 61px">
<p><strong>Memory (GB)</strong></p>
</td>
<td style="width: 302.608px;height: 61px">
<p><strong>On-demand price (us-east-1 region)</strong></p>
</td>
</tr>
<tr style="height: 52px">
<td style="width: 89px;height: 52px">
<p>c5.large</p>
</td>
<td style="width: 53px;height: 52px">
<p>2</p>
</td>
<td style="width: 109px;height: 52px">
<p>4</p>
</td>
<td style="width: 302.608px;height: 52px">
<p>$0.085 per hour</p>
</td>
</tr>
<tr style="height: 51.0209px">
<td style="width: 89px;height: 51.0209px">
<p>c5.xlarge</p>
</td>
<td style="width: 53px;height: 51.0209px">
<p>4</p>
</td>
<td style="width: 109px;height: 51.0209px">
<p>8</p>
</td>
<td style="width: 302.608px;height: 51.0209px">
<p>$0.17 per hour</p>
</td>
</tr>
<tr style="height: 61px">
<td style="width: 89px;height: 61px">
<p>c5.2xlarge</p>
</td>
<td style="width: 53px;height: 61px">
<p>8</p>
</td>
<td style="width: 109px;height: 61px">
<p>16</p>
</td>
<td style="width: 302.608px;height: 61px">
<p>$0.34 per hour</p>
</td>
</tr>
<tr style="height: 61px">
<td style="width: 89px;height: 61px">
<p>c5.4xlarge</p>
</td>
<td style="width: 53px;height: 61px">
<p>16</p>
</td>
<td style="width: 109px;height: 61px">
<p>32</p>
</td>
<td style="width: 302.608px;height: 61px">
<p>$0.68 per hour</p>
</td>
</tr>
<tr style="height: 61px">
<td style="width: 89px;height: 61px">
<p><span>m5.large</span></p>
</td>
<td style="width: 53px;height: 61px">
<p>2</p>
</td>
<td style="width: 109px;height: 61px">
<p>8</p>
</td>
<td style="width: 302.608px;height: 61px">
<p>$0.096 per hour</p>
</td>
</tr>
<tr style="height: 29px">
<td style="width: 89px;height: 29px"><span>m5.xlarge</span></td>
<td style="width: 53px;height: 29px">4</td>
<td style="width: 109px;height: 29px">16</td>
<td style="width: 302.608px;height: 29px">$0.192 per hour</td>
</tr>
<tr style="height: 34px">
<td style="width: 89px;height: 34px"><span>m5.2xlarge</span></td>
<td style="width: 53px;height: 34px">8</td>
<td style="width: 109px;height: 34px">32</td>
<td style="width: 302.608px;height: 34px">$0.384 per hour</td>
</tr>
</tbody>
</table>
</div>
<p class="mce-root"><br/>
The price for a given configuration can change due to a number of factors, namely, the following:</p>
<ul>
<li style="font-weight: 400">The region (data center) of the machine</li>
<li style="font-weight: 400">Whether the instance is requested as spot or on-demand</li>
<li style="font-weight: 400">The use of reserved pricing</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">On-demand versus spot instance pricing</h1>
                </header>
            
            <article>
                
<p>On-demand is the most flexible way to request machines from the cloud. Prices for on-demand instances are fixed and once you launch the machine, it is guaranteed to remain up (unless an error occurs or AWS is experimenting capacity issues, which is extremely rare). On the other hand, spot pricing is based on auctions. AWS has a set of excess capacity machines that are auctioned, typically at a lower price than on-demand. To obtain such machines, at launch time, the user needs to specify how much he or she is willing to spend on such an instance. If the current market price is below the bid value, the machine is successfully provisioned. As soon as the market price exceeds the bid, the machine can be taken away from the user. So, if you use spot pricing, you need to know that the machine can go down at any moment. That said, based on our experience, spot pricing can be reliably for large scale (thousands of machines) production workloads successfully. It is important to choose the bid price and machine configuration adequately and be ready to change these every so often upon the changes in the spot market prices.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In the following link, you can inspect the market value of each instance type in different regions and availability zones (these are distinct isolated data centers within a region) at <a href="https://console.aws.amazon.com/ec2sp/v1/spot/home?region=us-east-1#">https://console.aws.amazon.com/ec2sp/v1/spot/home?region=us-east-1#</a>:<a href="https://console.aws.amazon.com/ec2sp/v1/spot/home?region=us-east-1#"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-841 image-border" src="assets/d122e1e5-53bc-4ae6-b538-87ff52d1dac2.png" style="width:129.17em;height:69.67em;"/></p>
<p>The preceding diagram shows the market price for <strong>c5.4xlarge</strong> machines between March and February, 2019. The reader might observe that the region <strong>us-east-1d</strong> seems to have a lower market price than the rest of the regions. This means that whenever possible, you could request spot instances on that region at a lower bid price. </p>
<p>Currently, SageMaker does not support spot pricing, and only on-demand instances are allowed. Additionally, there is a different price chart for SageMaker-supported instances, which can be found via the following link: <a href="https://aws.amazon.com/sagemaker/pricing/">https://aws.amazon.com/sagemaker/pricing/</a>.  There are different prices for the different things you can do with SakeMaker (notebooks, training jobs, batch transform jobs, endpoints, and so on.).</p>
<p><a href="https://aws.amazon.com/sagemaker/pricing/"/></p>
<p>As for <span><strong>Elastic MapReduce</strong> (</span><strong>EMR</strong>), it does support spot instances. However, there is a minor additional cost added to the raw instance type cost when launched through EMR.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reserved pricing</h1>
                </header>
            
            <article>
                
<p>Costs can be reduced if you have an accurate estimate of you compute needs ahead. In that case, you can pay AWS upfront and get significant discounts for on-demand instances. For example, if you plan to spend USD 1,000 on m5.xlarge machines over the course of a year, you can opt to pay upfront the USD 1,000 amount and obtain a 40% saving. The more you pay upfront, the larger the savings rate.</p>
<p>Details can be found in the following link: <a href="https://aws.amazon.com/ec2/pricing/reserved-instances/pricing/">https://aws.amazon.com/ec2/pricing/reserved-instances/pricing/</a>.<a href="https://aws.amazon.com/ec2/pricing/reserved-instances/pricing/">   </a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Amazon Machine Images (AMIs)</h1>
                </header>
            
            <article>
                
<p>Machines can be launched outside EMR or SageMaker directly via the <strong>Elastic Compute</strong> service (<a href="https://aws.amazon.com/ec2">https://aws.amazon.com/ec2</a>). This is useful when you want to handle the deployment of your own application on the AWS cloud or want to custom-configure the packages that you have available on the instance. When you launch an instance through EC2, you can select an AMI and the machine will come up with all the libraries and packages necessary for your application. You can create your own AMI from a running instance for re-use at a later time or through Docker specs. However, AWS provides several pre-backed AMIs that are very useful for deep learning. We highly encourage you to take a look at the available AMIs via this link: <a href="https://aws.amazon.com/machine-learning/amis/">https://aws.amazon.com/machine-learning/amis/</a>. These AMIs include the most common machine learning packages (such as TensorFlow, Anaconda, and scikit-learn) installed in a way that ensures compatibility between the different library versions (typically, a tricky task). These <strong>Deep Learning AMIs</strong> are typically referred to as <strong>DLAMIs</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep learning hardware</h1>
                </header>
            
            <article>
                
<p>Most of the instance types in AWS are based on CPUs. CPU instances are typically optimal for performing various sequential tasks. However, the accelerated computing instance types (for example, the P or G families) are based on <strong>graphical processing units</strong> (<span><strong>GPUs</strong>)</span>. These kinds of instances, which were originally popular on gaming consoles, turned out to be ideal for deep learning. GPUs are characterized by having more cores than CPUs, but with less processing power. Thus, GPUs are capable of fast parallel processing of simpler instructions.</p>
<p>In particular, GPUs allow for the very fast and parallel multiplication of matrices. Recall from <a href="c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml"/><a href="c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml">Chapter 7</a>, <em>Implementing Deep Learning Algorithms</em>, that deep learning involves multiplying the weights by the signals on different layer inputs, much like a vector dot-product. In fact, matrix multiplications involve doing several dot products between several columns and rows simultaneously. Matrix multiplication is usually the main bottleneck in deep learning, and GPUs are extremely good at performing such operations as there is an opportunity to perform tons of calculations in parallel.</p>
<p>In the following table, we can see typical machine configurations used for deep learning and their relevant characteristics. The number of GPUs and networking performance are especially important when it comes to distributing the deep learning workloads, as we will discuss in the following sections:</p>
<div>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td style="width: 14%">
<p><strong>Model</strong></p>
</td>
<td style="width: 6%">
<p><strong>GPUs</strong></p>
</td>
<td style="width: 6%">
<p><strong>vCPU</strong></p>
</td>
<td style="width: 14%">
<p><strong>Mem (GiB)</strong></p>
</td>
<td style="width: 20%">
<p><strong>GPU Mem (GiB)</strong></p>
</td>
<td style="width: 28.4965%">
<p><strong>Networking performance</strong></p>
</td>
</tr>
<tr>
<td style="width: 14%">
<p>p3.2xlarge</p>
</td>
<td style="width: 6%">
<p>1</p>
</td>
<td style="width: 6%">
<p>8</p>
</td>
<td style="width: 14%">
<p>61</p>
</td>
<td style="width: 20%">
<p>16</p>
</td>
<td style="width: 28.4965%">
<p>Up to 10 gigabits</p>
</td>
</tr>
<tr>
<td style="width: 14%">
<p>p3.8xlarge</p>
</td>
<td style="width: 6%">
<p>4</p>
</td>
<td style="width: 6%">
<p>32</p>
</td>
<td style="width: 14%">
<p>244</p>
</td>
<td style="width: 20%">
<p>64</p>
</td>
<td style="width: 28.4965%">
<p>10 gigabits</p>
</td>
</tr>
<tr>
<td style="width: 14%">
<p>p3.16xlarge</p>
</td>
<td style="width: 6%">
<p>8</p>
</td>
<td style="width: 6%">
<p>64</p>
</td>
<td style="width: 14%">
<p>488</p>
</td>
<td style="width: 20%">
<p>128</p>
</td>
<td style="width: 28.4965%">
<p>25 gigabits</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="packt_infobox"><span><span class="packt_screen">Elastic Inference Acceleration</span><br/>
In 2018, AWS announced a new feature that allows us to combine regular instances attached through GPU-based accelerator devices via a network at a fraction of the having a GPU instance. Details can be found at </span><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/ei.htm">https://docs.aws.amazon.com/sagemaker/latest/dg/ei.htm</a>.<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/ei.htm"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Distributed deep learning</h1>
                </header>
            
            <article>
                
<p class="mce-root">Let's explore the <strong>distributed deep learning</strong> concept next.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model versus data parallelization</h1>
                </header>
            
            <article>
                
<p>When are training large amounts of data, or when the network structure is huge, we usually need to distribute the training across different machines/threads so that learning can be performed in parallel. This parallelization may happen within a single machine with several GPUs or across several machines synchronizing through a network. The two main strategies for distributing deep learning workloads are data parallelization and model parallelization.</p>
<p>In data parallelization, we run a number of mini-batches in parallel using the same weights (that is, the same model). This implies synchronizing the weights of the different mini-batches upon a series of runs. One strategy for combining the weights of the different parallel runs is to average the weights resulting of each parallel mini-batch. An efficient way to average out the gradients of each machine or thread is to use algorithms such as <strong>AllReduce</strong> that allow combining the gradients in a distributed fashion without the need of a central combiner. Other alternatives involve hosting a parameter server that acts as a central location for synchronizing weights.</p>
<p>Model parallelism, on the other hand, involves having different threads or machines processing the same mini-batch in parallel while distributing the actual processing. The algorithm being run needs to be able to distribute the work in different threads. This typically works well on machines with multiple GPUs that share a high-speed bus, because model parallelization typically only requires synchronizing the outputs of each layer after each forward pass. However, this synchronization might involve more or less data than the weights synchronization in data parallelism, depending on the structure of the network.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Distributed TensorFlow</h1>
                </header>
            
            <article>
                
<p><strong>TensorFlow</strong> natively supports data parallelization on a single machine with more than one GPU, using <strong>AllReduce</strong>. The algorithms for distributing the learning through TensorFlow is an active area of development within TensorFlow.</p>
<p>For example, we can launch a notebook instance with more than one GPU:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-736 image-border" src="assets/4eb27f1a-8cd7-40a0-840d-5d9d68369e73.png" style="width:44.92em;height:27.67em;"/></p>
<p>In this example, we have a four-GPU machine. Let's examine how we would change the code to our regressor estimator that we considered in <a href="a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml">Chapter 8</a>, <em>Implementing Deep Learning with TensorFlow on AWS</em>. Recall we used <kbd>LinearRegressor</kbd> for solving our house value estimation. To enable the distributed learning across GPUs, we need to define a distribution strategy.</p>
<p>The simplest is <kbd>MirroredStrategy</kbd>, which uses the AllReduce technique. This strategy is instantiated and submitted to the regressor as an input, as we show in the following code block:</p>
<pre class="mce-root">distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=4)<br/>config = tf.estimator.RunConfig(train_distribute=distribution)<br/><br/>tf_regressor = tf.estimator.LinearRegressor(<br/>  config=config,<br/>  optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0000001),<br/>  feature_columns=[tf.feature_column.numeric_column('inputs', <br/>                                  shape=(11,))],<br/>)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Currently, the distribution strategy supports <kbd>GradientDescentOptimizer</kbd> that accepts a learning rate as input. Also, the way to provide the input functions needs to change slightly compared to what we did in <a href="a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml">Chapter 8</a>, <em>Implementing Deep Learning with TensorFlow on AWS</em>. In distributed processing, the input function needs to return <kbd>tf.Dataset</kbd> that we create from tensors obtained through the <kbd>pandas</kbd> <kbd>as_matrix()</kbd> function:</p>
<pre class="mce-root">def training_input_fn():<br/>  return tf.data.Dataset.from_tensor_slices(<br/>        ({'inputs': training_df[training_features].as_matrix()},             <br/>         training_df[label].as_matrix())).repeat(50).batch(1)</pre>
<p>The training is done in the same way as we did in <a href="a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml"/><a href="a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml">Chapter 8</a>, <em>Implementing Deep Learning with TensorFlow on AWS</em>:</p>
<pre>tf_regressor.train(input_fn=training_input_fn)</pre>
<p>In the <kbd>train_distributed_tensorflow.ipynb</kbd><span> notebook, </span>you can see the full example. In this particular toy example, the distributed learning is not justifiable. However, it should serve the reader as a reference, as there is currently not much documentation and or many examples available regarding how to successfully perform the training on a multi-CPU environment.  </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Distributed learning through Apache Spark</h1>
                </header>
            
            <article>
                
<p>In previous chapters, we showed how to use Apache Spark for distributed machine learning though the Spark ML library. However, if you want to combine Apache Spark with deep learning libraries such as TensorFlow, it is possible to obtain significant benefits.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data parallelization</h1>
                </header>
            
            <article>
                
<p>In this scheme, the same mini-batches run in parallel throughout the Spark executors (in a map-like transformation) and the weights are averaged (in a reduce-like operation). Tools such as SparkFlow (<a href="https://github.com/lifeomic/sparkflow">https://github.com/lifeomic/sparkflow</a>) allow us to define a simple TensorFlow model (such as the one we developed in <a href="a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml">Chapter 8</a>, <em>Implementing Deep Learning with TensorFlow on AWS</em>) and perform parallel training by making the Spark driver act as a parameter server. Through this library, we can work with pipeline abstractions (estimators and transformers) that work as smart wrappers of TensorFlow graphs. Similarly, BigDL (<a href="https://bigdl-project.github.io/">https://bigdl-project.github.io</a>) allows us to distribute deep learning training using <kbd>allreduce</kbd> <strong>stochastic gradient descent</strong> (<strong>SGD</strong>) implementations.</p>
<p><a href="https://bigdl-project.github.io/"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model parallelization</h1>
                </header>
            
            <article>
                
<p>At the time of this chapter writing, there is no native library that allows us to do model parallelization with TensorFlow through Apache Spark. However, Apache Spark does come with an implementation of a <strong>multilayer perceptron classifier</strong> (<strong>MLPC</strong>) ( <a href="https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier">https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier</a>) that implements model parallelization through Apache Spark. This implementation is relatively simplistic compared to the power of libraries such as TensorFlow. For example, the network structure and the activation functions are fixed. You can only define the number of layers and a few other parameters. That said, it is a good way to get started with distributed deep learning, as your data pipelines are already in Spark.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Distributed hyperparameter tuning</h1>
                </header>
            
            <article>
                
<p>By having a Spark cluster, it is possible to train variants of the same neural network on different machines. Each of these variants could be different hyperparameters, or even slightly different network structures. For example, you might want to switch the activation functions on a particular layer. If we can predefine all these combinations of neural networks beforehand, a simple <kbd>map()</kbd> transformation can be performed through Spark. Each parallel training job can return the generated model, as well as the loss metric. Libraries such as <kbd>sparkdl</kbd> (<a href="https://github.com/databricks/spark-deep-learning">https://github.com/databricks/spark-deep-learning</a>) come with good tools for performing such tasks (especially if you're working with images). We'll cover hyperparameter tuning in more detail in <a href="691fc3d8-e4b8-4e3f-a8d9-e13f53f058c4.xhtml">Chapter 15</a>, <em>Tuning Clusters for Machine Learning</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Distributed predictions at scale</h1>
                </header>
            
            <article>
                
<p>Once we have a serialized model, it is possible to make predictions in parallel by sending the model to the different executors and applying it to the data distributed by Spark. The <kbd>sparkdl</kbd> library, for example, implements a Keras transformer that makes distributed predictions, given a Keras model such as the one we developed in <a href="a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml">Chapter 8</a>, <em>Implementing Deep Learning with TensorFlow on AWS</em>.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Parallelization in SageMaker</h1>
                </header>
            
            <article>
                
<p>Many of the use cases identified in the previous section can also easily be addressed just by using <strong>SageMaker</strong>. With SageMaker, we can launch several instances performing parallel training variants of different models. Many of SageMaker's built-in algorithms are designed to perform model parallelization, which is why we usually specify the number (and type) of machines to be used for training. Additionally, it comes with advanced parameter-tuning capabilities that we'll explore in <a href="691fc3d8-e4b8-4e3f-a8d9-e13f53f058c4.xhtml">Chapter 15</a>, <em>Tuning Clusters for Machine Learning</em>. Lastly, the distributed predictions are done through batch transform jobs such as the ones we showed in <a href="af506fc8-f482-453e-8162-93a676b2e737.xhtml">Chapter 4</a>, <em>Predicting User Behavior with Tree-Based Methods</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we covered the basic considerations regarding how to choose the kinds of machines for the training clusters. These involve making tradeoffs between costs, memory sizes, compute power, and provisioning limitations. As for deep learning, we provided a concrete example on how to run distributed TensorFlow on SageMaker notebooks and some guidelines on how to further distribute your deep learning pipelines through Apache Spark on EMR. In the next chapter, <em>Optimizing Models in Spark and SageMaker</em>, we will dive into the problem of tuning our models for optimal performance from the standpoint of model accuracy. </p>


            </article>

            
        </section>
    </body></html>