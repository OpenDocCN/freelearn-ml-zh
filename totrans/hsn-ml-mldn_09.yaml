- en: Matrix Factorization Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With anomaly detection models behind us, it is now time to dive into matrix
    factorization models. Matrix factorization is one of the newer additions to ML.NET,
    with a transform of the same name. In this chapter, we will dive into matrix factorization,
    as well as the various applications best suited to utilizing matrix factorization.
    In addition, we will build a new sample application to predict music recommendations
    based on the sample training data. Finally, we will explore how to evaluate a
    matrix factorization model with the properties that ML.NET exposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down matrix factorizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a matrix factorization application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating a matrix factorization model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breaking down matrix factorizations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in [Chapter 1](b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml), *Getting
    Started with Machine Learning and ML.NET*, matrix factorization, by definition,
    is an unsupervised learning algorithm. This means that the algorithm will train
    on data and build a matrix of patterns in user ratings, and during a prediction
    call, will attempt to find like ratings based on the data provided. In this section,
    we will dive into use cases for matrix factorization and have a look into the
    matrix factorization trainer in ML.NET.
  prefs: []
  type: TYPE_NORMAL
- en: Use cases for matrix factorizations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Matrix factorizations, as you might be starting to realize, have numerous applications
    where data is available, but the idea is to suggest other matches based on previously
    unselected data. Without needing to do manual spot-checking, matrix factorization
    algorithms train on this unselected data and determine patterns using a key-value
    pair combination. ML.NET provides various matrix factorization values to look
    at programmatically, inside of your application. We will review these values later on
    in this chapter, to better ensure the recommendation was not a false positive.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the potential applications best suited for matrix factorization are:'
  prefs: []
  type: TYPE_NORMAL
- en: Music recommendations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Product recommendations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Movie recommendations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Book recommendations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Effectively, anything where data can be traced back to a single user and then
    built upon as more data is entered can utilize matrix factorizations. This problem
    is called a **cold start** **problem**. Take, for instance, a new music platform
    geared toward helping you to find new bands to listen to. When you first reach
    the site and create a profile, there is no prior data available. You, as the end
    user, must tell the system what you like and don't like. Due to the nature of
    the algorithm, matrix factorization is better suited to this application than
    the straight regression or binary classification algorithms we explored in earlier
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Diving into the matrix factorization trainer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The matrix factorization trainer is the only traditional trainer found in ML.NET
    as of this writing. The matrix factorization trainer requires both normalization
    of the values and caching. In addition, to utilize matrix factorization in ML.NET, the `Microsoft.ML.Recommender` NuGet
    package is required if you are creating the project from scratch. The included
    sample from the GitHub repository includes this package.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to other algorithms, normalization is required, but matrix factorization
    is unique. Other algorithms, as we have seen with binary classification or regression
    algorithms, have multiple values that can be normalized. In matrix factorization, there
    are only three values involved: `Label`, `Row`, and `Column` values. The output
    is comprised of two properties: `Score `and `Label`. The `Score` value is of type `Float`,
    non-negative and unbounded.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that in July 2018's ML.NET 0.3 update, field-aware factorization
    machines were added. However, this type of trainer offered only binary recommendations
    (such as either like or dislike), as opposed to matrix factorization, which supports
    floating-point values of any range. This provides considerably better flexibility
    in usage, such as getting more granular predictions. If, for instance, a matrix
    factorization recommendation on a scale from 0 to 100 returned 30, the recommendation
    engine would more than likely return a negative recommendation. With simply a
    binary response, the application—and thereby the end-user—is not shown how strong
    the recommendation is either way.
  prefs: []
  type: TYPE_NORMAL
- en: We will demonstrate this trainer in the sample application later, in the next
    section, by providing music recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a matrix factorization application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier, the application we will be creating is for music prediction.
    Given a UserID, MusicID, and a rating, the algorithm will use that data to create
    recommendations. As with other applications, this is not meant to power the next
    Spotifyesque machine learning product; however, it will show you how to use matrix
    factorization in ML.NET.
  prefs: []
  type: TYPE_NORMAL
- en: As with previous chapters, the completed project code, sample dataset, and project
    files can be downloaded here: [https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter07](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter07).
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the project architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building on the project architecture and code we created in previous chapters,
    the bulk of the changes are in the training of the model, as matrix factorization requires
    a fairly significant paradigm shift from what we have reviewed in previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, you will find the Visual Studio Solution Explorer
    view of the project. The new additions to the solution are the `MusicRating`and `MusicPrediction`files,
    which we will review later in this section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d3568d52-b3fd-48a1-8630-72b8c1bebf0d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `sampledata.csv` file contains 10 rows of random music ratings. Feel free
    to adjust the data to fit your own observations, or to adjust the trained model.
    Here is a snippet of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Each of these rows contains the value for the properties in the newly created `MusicRating`class
    that we will review later on in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to this, we added the `testdata.csv` file that contains additional
    data points to test the newly trained model against and evaluate. Here is a snippet
    of the data inside of `testdata.csv`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Diving into the code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this application, as noted in the previous section, we are building on top
    of the work completed in [Chapter 6](4e2ca910-b4a8-4f00-b8e4-5f2cf7ee5222.xhtml), *Anomaly
    Detection Model*. For this deep dive, we are going to focus solely on the code
    that was changed for this application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Classes that were changed or added are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MusicRating`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MusicPrediction`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Predictor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Trainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Constants`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The MusicRating class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `MusicRating`class is the container class that contains the data to both
    predict and train our model. As described in previous chapters, the number in
    the `LoadColumn` decorator maps to the index in the CSV files. As noted in the
    earlier section, matrix factorization in ML.NET requires the use of normalization,
    as shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The MusicPrediction class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `MusicPrediction`class contains the properties mapped to our prediction
    output. The `Score` contains the likelihood the prediction is accurate. We will
    review these values later on in this section, but for now, they can be seen in
    the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The Predictor class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a couple of changes in this class to handle the music-prediction
    scenario, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create our prediction engine with the `MusicRating`and `MusicPrediction` types,
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we read the input file into a string object, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '3\. Next, we deserialize the string into an object of type `MusicRating`, like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we need to run the prediction, and then output the results of the model
    run, as follows:'
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With the transform only returning the three-element vector, the original row
    data is outputted to give context.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The Trainer class
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Inside the `Trainer` class, several modifications need to be made to support
    the matrix factorization. In many ways, a simplification is required due to the
    nature of only having three inputs:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The first addition is the two constant variables for the variable encoding,
    shown in the following code block:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then build the `MatrixFactorizationTrainer` options. The `Row` and `Column`
    properties are set to the column names previously defined. The `Quiet` flag displays
    additional model building information on every iteration, as illustrated in the
    following code block:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can then create the matrix factorization trainer, as follows:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we fit the model on the training data and save the model, as follows:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Lastly, we load the testing data and pass the data to the matrix factorization
    evaluator, like this:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The Constants class
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In addition, given the training only requires the training data, some modifications
    to the `Program` class need to be performed, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Running the application
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run the application, the process is nearly identical to Chapter 6''s sample
    application, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After preparing the data, we must then train the model by passing in the newly
    created `sampledata.csv` file, like this:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To run the model with this file, simply pass the `testdata.csv` filementioned
    earlier into the newly built application, and the predicted output will show the
    following:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Prior to running the prediction, create a JSON file in Notepad with the following
    text:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Then save the file to your output folder.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, run the prediction, like this:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Feel free to modify the values, and see how the prediction changes based on
    the dataset that the model was trained on. A few areas of experimentation from
    this point might be to:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Change the hyperparameters mentioned in the `Trainer` class deep dive.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Add diversification and more data points to the training and test data.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating a matrix factorization model
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in previous chapters, evaluating a model is a critical part of
    the overall model-building process. A poorly trained model will only provide inaccurate
    predictions. Fortunately, ML.NET provides many popular attributes to calculate
    model accuracy based on a test set at the time of training, to give you an idea
    of how well your model will perform in a production environment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'As noted earlier in the sample application, for matrix factorization model
    evaluation in ML.NET, there are five properties that comprise the `RegressionMetrics`class
    object. Let us dive into the properties exposed in the `RegressionMetrics`object
    here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Loss function
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mean Squared Error** (**MSE**)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mean Absolute Error** (**MAE**)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: R-squared
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Root Mean Squared Error** (**RMSE**)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next sections, we will break down how these values are calculated, and
    detail the ideal values to look for.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Loss function
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: This property uses the loss function set when the matrix factorization trainer
    was initialized. In the case of our matrix factorization example application,
    we used the default constructor, which defaults to the `SquaredLossRegression` class.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Other regression loss functions offered by ML.NET are:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Squared-loss one class
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Squared-loss regression
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The idea behind this property is to allow some flexibility when it comes to
    evaluating your model compared to the other four properties, which use fixed algorithms
    for evaluation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: MSE
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MSE is defined as the measure of the average of the squares of the errors.
    To put this simply, take the plot shown in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/f8a787c2-7855-4379-a5a3-8c40633dadf7.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: The dots correlate to data points for our model, while the blue line is the
    prediction line. The distance between the red dots and the prediction line is
    the error. For MSE, the value is calculated based on these points and their distances
    to the line. From that value, the mean is calculated. For MSE, the smaller the
    value, the better the fitting, and the more accurate the predictions you will
    have with your model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: MSE is best used to evaluate models when outliers are critical to the prediction
    output.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: MAE
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: MAE is similar to MSE, with the critical difference being that it sums the distances
    between the points and the prediction lines, as opposed to computing the mean.
    It should be noted that MAE does not take into account directions in calculating
    the sum. For instance, if you had two data points equal distance from the line,
    one above and the other below, in effect this would be balanced out with a positive
    and negative value. In machine learning, this is referred to as **Mean Bias Error**
    (**MBE**). However, ML.NET does not provide this as part of the `RegressionMetrics` class
    at the time of this writing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: MAE is best used to evaluate models when outliers are considered simply anomalies,
    and shouldn't be counted in evaluating a model's performance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: R-squared
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: R-squared, also called **the coefficient of determination**, is another method
    of representing how well the prediction compares to the test set. R-squared is
    calculated by taking the difference between each predicted value and its corresponding
    actual value, squaring that difference, then summing the squares for each pair
    of points.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: R-squared values generally range between 0 and 1, represented as a floating-point
    value. A negative value can occur when the fitted model is evaluated to be worse
    than an average fit. However, a low number does not always reflect that the model
    is bad. Predictions, such as the one we looked at in this chapter, that are based
    on predicting human actions are often found to be under 50%.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Conversely, higher values aren't necessarily a sure sign of the model's performance,
    as this could be considered as overfitting of the model. This happens in cases
    when there are a lot of features fed to the model, thereby making the model more
    complex as compared to the model we built in the *Creating your first ML.NET application* section
    of [Chapter 2](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml), *Setting Up the ML.NET
    Environment*, as there is simply not enough diversity in the training and test
    sets. For example, if all of the employees were roughly the same values, and then
    the test set holdout was comprised of the same ranges of values, this would be
    considered overfitting.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: RMSE
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: 'RMSE is arguably the easiest property to understand, given the previous methods.
    Take the plot shown in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/39c169e9-4a2f-4798-9e73-7dea68e45fbc.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: In the case of testing the model, as we did previously with the holdout set,
    the red dots are the actual values from the test set, while the blue dots are
    the predicted values. The X depicted is the distance between the predicted and
    actual values. RMSE simply takes a mean of all of those distances, squares that
    value, and then takes the square root.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A value under 180 is generally considered a good model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the course of this chapter, we have deep-dived into ML.NET's matrix factorization
    support. We have also created and trained our first matrix factorization application
    to predict music recommendations. Lastly, we also dove into how to evaluate a
    matrix factorization model and looked at the various properties that ML.NET exposes
    to achieve a proper evaluation of a matrix factorization model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With this chapter coming to a close, we have also completed our initial investigation
    of the various models ML.NET provides. In the next chapter, we will be creating
    full applications, building on the knowledge garnered over the last few chapters,
    with the first being a full .NET Core application providing stock forecasting.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
