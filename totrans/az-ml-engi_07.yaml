- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Deploying ML Models for Batch Scoring
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署用于批量评分的 ML 模型
- en: '**Deploying ML models for batch scoring** supports making predictions using
    a large volume of data. This solution supports use cases when you don’t need your
    model predictions immediately, but rather minutes or hours later. If you need
    to provide inferencing once a day, week, or month, using a large dataset, batch
    inferencing is ideal.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**部署用于批量评分的 ML 模型**支持使用大量数据进行预测。此解决方案支持您不需要立即获得模型预测，而是需要几分钟或几小时后的用例。如果您需要每天、每周或每月提供一次推理，使用大型数据集，批量推理是理想的。'
- en: Batch inferencing allows data scientists and ML professionals to leverage cloud
    compute when needed, rather than paying for compute resources to be available
    for real-time responses. This means that compute resources can be spun up to support
    batch inferencing and spun down after the results have been provided to the business
    users. We are going to show you how to leverage the Azure Machine Learning service
    to deploy trained models to managed endpoints, which are HTTPS REST APIs that
    clients can invoke to get the score results of a trained model for batch inferencing
    using the studio and the Python SDK.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 批量推理允许数据科学家和 ML 专业人员在需要时利用云计算，而不是为实时响应支付计算资源。这意味着计算资源可以启动以支持批量推理，在向业务用户提供结果后关闭。我们将向您展示如何利用
    Azure 机器学习服务将训练好的模型部署到管理端点，这些端点是客户端可以调用的 HTTPS REST API，用于使用 Studio 和 Python SDK
    对训练模型进行批量推理以获取评分结果。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Deploying a model for batch inferencing using the Studio
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Studio 部署用于批量推理的模型
- en: Deploying a model for batch inferencing through the Python SDK
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Python SDK 部署用于批量推理的模型
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In order to access your workspace, recall the steps from the previous chapter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了访问您的 workspace，回想一下上一章中的步骤：
- en: Go to [https://ml.azure.com](https://ml.azure.com).
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往[https://ml.azure.com](https://ml.azure.com)。
- en: Select your workspace.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您的 workspace。
- en: On the left side of the workspace’s UI, on click **Compute**.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在工作区 UI 的左侧，点击**计算**。
- en: On the compute screen, select your compute instance and select **Start**.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在计算屏幕上，选择您的计算实例并选择**启动**。
- en: '![Figure 7.1 – Start compute](img/B18003_07_001.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – 开始计算](img/B18003_07_001.jpg)'
- en: Figure 7.1 – Start compute
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – 开始计算
- en: Your compute instance will change from the **Stopped** to the **Starting** status.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的计算实例将从**停止**状态变为**启动**状态。
- en: In the previous chapter, we cloned the Git repository. If you have not done
    this, continue with this step. If you have already cloned the repository, skip
    to *step 7*.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上一章中，我们克隆了 Git 仓库。如果您还没有这样做，请继续此步骤。如果您已经克隆了仓库，请跳转到*步骤 7*。
- en: 'Open the terminal on your compute instance. Note that the path will include
    your user in the directory. Type the following into the terminal to clone the
    sample notebooks into your working directory:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的计算实例上打开终端。请注意，路径将包括您的用户目录。在终端中输入以下内容以将示例笔记本克隆到您的工作目录：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Clicking on the refresh icon shown in*Figure 7**.2* will update and refresh
    the notebooks displayed on your screen.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击*图 7.2*中显示的刷新图标将更新并刷新屏幕上显示的笔记本。
- en: '![Figure 7.2 – Refresh Icon](img/B18003_07_002.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.2 – 刷新图标](img/B18003_07_002.jpg)'
- en: Figure 7.2 – Refresh Icon
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – 刷新图标
- en: 'Review the notebooks in your `Azure-Machine-Learning-Engineering` directory.
    This will display the files cloned into your working directory, as shown in *Figure
    7**.3*:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看您`Azure-Machine-Learning-Engineering`目录中的笔记本。这将显示克隆到您工作目录中的文件，如图*图 7.3*所示：
- en: '![Figure 7.3 – Azure-Machine-Learning-Engineering](img/B18003_07_003.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3 – Azure-Machine-Learning-Engineering](img/B18003_07_003.jpg)'
- en: Figure 7.3 – Azure-Machine-Learning-Engineering
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3 – Azure-Machine-Learning-Engineering
- en: Let’s start with deploying a model for batch inferencing using the studio next.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们接下来使用 Studio 部署用于批量推理的模型。
- en: Deploying a model for batch inferencing using the Studio
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Studio 部署用于批量推理的模型
- en: 'In [*Chapter 3*](B18003_03.xhtml#_idTextAnchor053), *Training Machine Learning
    Models in AMLS*, we trained a model and registered it in an Azure Machine Learning
    workspace. We are going to deploy that model to a managed batch endpoint for batch
    scoring:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 3 章*](B18003_03.xhtml#_idTextAnchor053)“在 AMLS 中训练机器学习模型”中，我们训练了一个模型并将其注册到
    Azure 机器学习工作区。我们将部署该模型到管理的批量端点进行批量评分：
- en: 'Navigate to your Azure Machine Learning workspace, select **Models** from the
    left menu bar to see the models registered in your workspace, and select **titanic_servival_model_**,
    as shown in *Figure 7**.4*:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到你的Azure机器学习工作区，从左侧菜单栏选择**模型**以查看你工作区中注册的模型，并选择**titanic_survival_model_**，如图*图7**.4*所示：
- en: '![Figure 7.4 – List of models registered in the workspace](img/B18003_07_004.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图7.4 – 工作区中注册的模型列表](img/B18003_07_004.jpg)'
- en: Figure 7.4 – List of models registered in the workspace
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 – 工作区中注册的模型列表
- en: 'Click on **Deploy** and select **Deploy to batch endpoint**, as shown in *Figure
    7**.5*:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**部署**，然后选择**部署到批处理端点**，如图*图7**.5*所示：
- en: '![Figure 7.5 – Deploy the selected model to a batch endpoint](img/B18003_07_005.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图7.5 – 将所选模型部署到批处理端点](img/B18003_07_005.jpg)'
- en: Figure 7.5 – Deploy the selected model to a batch endpoint
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 – 将所选模型部署到批处理端点
- en: 'This opens the deployment wizard. Use the following values for the required
    fields:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打开部署向导。为所需的字段使用以下值：
- en: '`titanic-survival-batch-endpoint`'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`titanic-survival-batch-endpoint`'
- en: '**Model**: Retain the default of **titanic_survival_model_**'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：保留默认的**titanic_survival_model_**'
- en: '`titanic-deployment`'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`titanic-deployment`'
- en: '**Environment**: For the selected model, the scoring script and environment
    are auto-generated for you'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**环境**：对于所选模型，评分脚本和环境为你自动生成'
- en: '`cluster cpu-cluster`'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster cpu-cluster`'
- en: 'Review your batch deployment specs and click **Create deployment**, as shown
    in *Figure 7**.6*:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 审查你的批处理部署规范，并点击**创建部署**，如图*图7**.6*所示：
- en: '![Figure 7.6 – Create batch deployment](img/B18003_07_006.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图7.6 – 创建批处理部署](img/B18003_07_006.jpg)'
- en: Figure 7.6 – Create batch deployment
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 – 创建批处理部署
- en: 'After a minute or so, you should see a page that shows that your batch endpoint
    has been deployed successfully. It also has some information about your batch
    endpoint, as shown in *Figure 7**.7*:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一分钟左右，你应该会看到一个页面显示你的批处理端点已成功部署。它还包含有关你的批处理端点的一些信息，如图*图7**.7*所示：
- en: '![Figure 7.7 – Successful batch deployment](img/B18003_07_007.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图7.7 – 成功的批处理部署](img/B18003_07_007.jpg)'
- en: Figure 7.7 – Successful batch deployment
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 – 成功的批处理部署
- en: 'Now that you have a batch endpoint up and running, let’s create a scoring/inferencing
    job that invokes your endpoint. To do so, follow these steps:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有一个批处理端点正在运行，让我们创建一个调用你的端点的评分/推理作业。为此，请按照以下步骤操作：
- en: 'Click on **Endpoints** in the left menu bar and click on your recently created
    batch endpoint, as shown in *Figure 7**.8*:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧菜单栏中点击**端点**，然后点击你最近创建的批处理端点，如图*图7**.8*所示：
- en: '![Figure 7.8 – List of deployed batch endpoints](img/B18003_07_008.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图7.8 – 已部署批处理端点列表](img/B18003_07_008.jpg)'
- en: Figure 7.8 – List of deployed batch endpoints
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 – 已部署批处理端点列表
- en: 'On the **titanic-survival-batch-endpoint** page, select the **Jobs** tab, as
    shown in *Figure 7**.9*:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**titanic-survival-batch-endpoint**页面，选择**作业**标签，如图*图7**.9*所示：
- en: '![Figure 7.9 – titanic-survival-batch-endpoint Jobs tab](img/B18003_07_009.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图7.9 – titanic-survival-batch-endpoint作业标签](img/B18003_07_009.jpg)'
- en: Figure 7.9 – titanic-survival-batch-endpoint Jobs tab
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9 – titanic-survival-batch-endpoint作业标签
- en: Click **Create job** and pick the corresponding values for the fields in the
    wizard as shown in *Figure 7**.10*. Click **Create** once you’re done. Please
    note that the deployment is pre-selected for you, but make sure the correct deployment
    is pre-selected. You should also have a test dataset called **titanic-test-data**,
    which was created in [*Chapter 3*](B18003_03.xhtml#_idTextAnchor053)*, Training
    Machine Learning Models* *in AMLS*.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建作业**，并在向导中为字段选择相应的值，如图*图7**.10*所示。完成后点击**创建**。请注意，部署已为你预选，但请确保预选了正确的部署。你还应该有一个名为**titanic-test-data**的测试数据集，该数据集在[*第3章*](B18003_03.xhtml#_idTextAnchor053)*，在AMLS中训练机器学习模型*时创建。
- en: '![Figure 7.10 – Create a batch scoring job](img/B18003_07_010.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图7.10 – 创建批评分作业](img/B18003_07_010.jpg)'
- en: Figure 7.10 – Create a batch scoring job
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10 – 创建批评分作业
- en: 'Depending on the size of the test dataset that you selected in the last step,
    it will take some time for the job to complete. Once it is complete, you will
    see a pipeline representing the batch scoring job for **titanic-survival-batch-endpoint**,
    as shown in *Figure 7**.11*:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据你在上一步中选择的测试数据集的大小，作业完成可能需要一些时间。一旦完成，你将看到一个表示**titanic-survival-batch-endpoint**批评分作业的管道，如图*图7**.11*所示：
- en: '![Figure 7.11 – Batch scoring job for titanic-survival-batch-endpoint](img/B18003_07_011.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图7.11 – titanic-survival-batch-endpoint批评分作业](img/B18003_07_011.jpg)'
- en: Figure 7.11 – Batch scoring job for titanic-survival-batch-endpoint
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11 – titanic-survival-batch-endpoint 的批量评分作业
- en: 'Now, in order to view the scoring results, click on the **batchscoring** step
    of the pipeline, click on **Job overview** on the right, select the **Outputs
    + logs** tab, and finally, click on **Show data outputs**, as shown in *Figure
    7**.12*:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，为了查看评分结果，点击管道中的 **batchscoring** 步骤，在右侧点击 **作业概述**，选择 **输出 + 日志** 选项卡，最后点击
    **显示数据输出**，如图 *7.12* 所示：
- en: '![Figure 7.12 – Batch scoring results](img/B18003_07_012.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.12 – 批量评分结果](img/B18003_07_012.jpg)'
- en: Figure 7.12 – Batch scoring results
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12 – 批量评分结果
- en: 'After you click on `predictions.csv` file has been saved. Click on this file
    and select the **Edit** tab in order to view the scoring results, as shown in
    *Figure 7**.13*:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击后，`predictions.csv` 文件已被保存。点击此文件并选择 **编辑** 选项卡以查看评分结果，如图 *7.13* 所示：
- en: '![Figure 7.13 – Viewing batch scoring results](img/B18003_07_013.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.13 – 查看批量评分结果](img/B18003_07_013.jpg)'
- en: Figure 7.13 – Viewing batch scoring results
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13 – 查看批量评分结果
- en: In this section, you learned how to deploy an existing model to a managed endpoint
    for batch inferencing using the studio. In the next section, we will show you
    how to deploy a model to a managed endpoint for batch scoring using the Python
    SDK.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你学习了如何使用工作室将现有模型部署到管理端点进行批量推理。在下节中，我们将向你展示如何使用 Python SDK 将模型部署到管理端点进行批量评分。
- en: Deploying a model for batch inferencing through the Python SDK
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 Python SDK 部署用于批量推理的模型
- en: 'In this section, we are going to deploy an existing model to a managed endpoint
    for batch inferencing using the Python SDK by following these steps:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过以下步骤使用 Python SDK 将现有模型部署到管理端点进行批量推理：
- en: Go to [https://ml.azure.com](https://ml.azure.com).
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往 [https://ml.azure.com](https://ml.azure.com)。
- en: Select your workspace.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择你的工作区。
- en: 'On the workspace user interface on the left side, click **Compute**:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧的工作区用户界面中，点击 **计算**：
- en: '![Figure 7.14 –  Compute instance icon](img/B18003_07_014.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.14 – 计算实例图标](img/B18003_07_014.jpg)'
- en: Figure 7.14 – Compute instance icon
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14 – 计算实例图标
- en: 'On the **Compute** screen, select your compute instance and select **Start**:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **计算** 屏幕上，选择你的计算实例并选择 **启动**：
- en: '![Figure 7.15 – Start compute](img/B18003_07_015.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.15 – 开始计算](img/B18003_07_015.jpg)'
- en: Figure 7.15 – Start compute
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.15 – 开始计算
- en: Your compute instance will change from **Stopped** to **Starting**. Once the
    compute instance moves from **Starting** to **Running**, it is ready for use,
    so go ahead and clone our repository, which contains some sample notebooks to
    walk through.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你的计算实例将从 **停止** 变为 **启动**。一旦计算实例从 **启动** 变为 **运行**，它就准备好使用，因此继续克隆我们的仓库，其中包含一些示例笔记本以供学习。
- en: Click on the **Terminal** hyperlink under applications.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在应用程序下点击 **终端** 超链接。
- en: 'This will open the terminal on your compute instance. Note that the path will
    include your user in the directory path. Type the following into the terminal
    to clone the sample notebooks into your working directory:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在你的计算实例上打开终端。请注意，路径将包括你的用户在目录路径中。在终端中输入以下内容以将示例笔记本克隆到你的工作目录：
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Click on the Jupyter link under applications, and this will display the folders
    that were just cloned. Navigate to `chapter 7` and click on `Deploy_Model_for_Batch_Scoring.ipynb`
    to bring up the notebook for this section.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在应用程序下点击 Jupyter 链接，这将显示刚刚克隆的文件夹。导航到 `第 7 章` 并点击 `Deploy_Model_for_Batch_Scoring.ipynb`
    以打开本节的工作簿。
- en: 'The code snippet shown in *Figure 7**.16* shows the libraries that need to
    be imported and how to connect to the Azure ML workspace in your compute instance:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*图 7.16* 中显示的代码片段展示了需要导入的库以及如何在计算实例中连接到 Azure ML 工作区：'
- en: '![Figure 7.16 – Import required libraries and connecting to the Azure Machine
    Learning workspace](img/B18003_07_016.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.16 – 导入所需的库并连接到 Azure 机器学习工作区](img/B18003_07_016.jpg)'
- en: Figure 7.16 – Import required libraries and connecting to the Azure Machine
    Learning workspace
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.16 – 导入所需的库并连接到 Azure 机器学习工作区
- en: 'The code snippet shown in *Figure 7**.17* shows how to create a batch endpoint:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*图 7.17* 中显示的代码片段展示了如何创建批量端点：'
- en: '![Figure 7.17 – Creating a batch endpoint for inferencing](img/B18003_07_017.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.17 – 创建用于推理的批量端点](img/B18003_07_017.jpg)'
- en: Figure 7.17 – Creating a batch endpoint for inferencing
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.17 – 创建用于推理的批量端点
- en: 'The code snippet shown in *Figure 7**.18* shows how to retrieve an existing
    model from the workspace and how to create a batch deployment. The batch deployment
    must specify the batch endpoint, the trained model, and the compute cluster that
    is used for scoring, along with other deployment parameters:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*图7.18* 中所示的代码片段展示了如何从工作区检索现有模型以及如何创建批量部署。批量部署必须指定批量端点、训练模型以及用于评分的计算集群，以及其他部署参数：'
- en: '![Figure 7.18 – Creating a batch deployment](img/B18003_07_018.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图7.18 – 创建批量部署](img/B18003_07_018.jpg)'
- en: Figure 7.18 – Creating a batch deployment
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.18 – 创建批量部署
- en: 'Now, that your batch endpoint is ready to be invoked, you are going to pass
    some test data to the endpoint, as shown in *Figure 7**.19*:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您的批量端点已准备好调用，您将传递一些测试数据到端点，如图*图7.19*所示：
- en: '![Figure 7.19 – Creating a batch deployment](img/B18003_07_019.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图7.19 – 创建批量部署](img/B18003_07_019.jpg)'
- en: Figure 7.19 – Creating a batch deployment
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.19 – 创建批量部署
- en: 'The code snippet shown in *Figure 7**.20* shows the Python code required to
    monitor the batch scoring job that was submitted in the previous step:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*图7.20* 中所示的代码片段展示了在上一步骤中提交的批量评分作业所需的Python代码：'
- en: '![Figure 7.20 – Creating a batch deployment](img/B18003_07_020.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图7.20 – 创建批量部署](img/B18003_07_020.jpg)'
- en: Figure 7.20 – Creating a batch deployment
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.20 – 创建批量部署
- en: Clicking on the output link from the previous step will open the workspace displaying
    the batch scoring job, as shown in *Figure 7**.21*. You can follow *steps 9* and
    *10* from the last section to see the results.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击上一步骤的输出链接将打开显示批量评分作业的工作区，如图*图7.21*所示。您可以遵循上一节的*步骤9*和*步骤10*来查看结果。
- en: '![Figure 7.21 – Batch scoring results](img/B18003_07_021.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图7.21 – 批量评分结果](img/B18003_07_021.jpg)'
- en: Figure 7.21 – Batch scoring results
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.21 – 批量评分结果
- en: Let’s summarize the chapter next.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们接下来总结本章内容。
- en: Summary
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We have covered a lot of topics in this chapter. We have shown you how to deploy
    a model for batch scoring using the studio and through the Python SDK. We also
    showed you how to pass some test data to be scored by the deployed model by invoking
    the batch endpoint.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了众多主题。我们向您展示了如何使用工作室和Python SDK来部署模型进行批量评分。我们还向您展示了如何通过调用批量端点将一些测试数据传递给部署的模型进行评分。
- en: In the next chapter, you will learn about responsible AI and the capabilities
    within Azure Machine Learning that allow you to develop, assess, and deploy models
    more responsibly to minimize unwanted bias in your AI systems.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将了解负责任的AI以及Azure机器学习中的功能，这些功能允许您更负责任地开发、评估和部署模型，以最小化AI系统中的不希望出现的偏差。
