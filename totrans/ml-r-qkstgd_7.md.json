["```py\nlibrary(caTools)\n\nindex = sample.split(macroeconomic_data$RatingMayT1, SplitRatio = .75)\n\ntrain_macro<-subset(macroeconomic_data, index == TRUE)\ntest_macro<-subset(macroeconomic_data, index == FALSE)\n```", "```py\nprint(paste(\"The number of observations in the train sample is: \",nrow(train_macro),sep=\"\"))\n## [1] \"The number of observations in the train sample is: 168\"\nprint(paste(\"The number of observations in the test sample is: \",nrow(test_macro),sep=\"\"))\n## [1] \"The number of observations in the test sample is: 56\"\n```", "```py\nlibrary(caret)\n```", "```py\npreprocess <- preProcess(train_macro[,4:13], method=c(\"center\", \"scale\"))\n\nprint(preprocess)\n ## Created from 168 samples and 10 variables\n ## \n ## Pre-processing:\n ##   - centered (10)\n ##   - ignored (0)\n ##   - scaled (10)\n```", "```py\ntrain_macro_trn <- cbind(train_macro[,c(1:3,14)],predict(preprocess, train_macro[,4:13]))\ntest_macro_trn <- cbind(test_macro[,c(1:3,14)],predict(preprocess, test_macro[,4:13]))\n```", "```py\nlibrary(ggplot2)\nvariables<-colnames(train_macro_trn[,5:14])\n train_macro_trn$RatingMayT1<-as.factor(train_macro_trn$RatingMayT1)\n\n for (i in 5:14)\n{\n\n library(ggplot2)\n theme_set(theme_classic())\n\n var<-colnames(train_macro_trn)[i]\n\n data_aux<-train_macro_trn[,c(var,\"RatingMayT1\")]\n colnames(data_aux)<-c(\"variable\",\"RatingMayT1\")\n\n g <- ggplot(data_aux, aes(RatingMayT1,variable))\n plot(g + geom_boxplot(varwidth=T, fill=\"plum\") + \n     labs(title=\"Box plot\", \n          subtitle=var,\n          x=\"Rating Number\",\n          y=var))\n\n }\n```", "```py\nlibrary(dplyr)\nmeans_YPCA <- train_macro_trn %>% group_by(RatingMayT1) %>%\n         summarise(YPCA = mean(YPCA))\n\nggplot(train_macro_trn, aes(x = RatingMayT1, y = YPCA, color = RatingMayT1,          fill = RatingMayT1)) +\ngeom_bar(data = means_YPCA, stat = \"identity\", alpha = .3) + ggrepel::geom_text_repel(aes(label = CountryName), color = \"black\", size =      2.5, segment.color = \"grey\") + geom_point() + guides(color = \"none\", fill = \"none\") + theme_bw() +  labs(  x = \"Rating\", y = \"GDP per capita\")\n```", "```py\nlibrary(ggplot2)\n theme_set(theme_classic())\nggplot(train_macro_trn, aes((MEANWGI))) + geom_density(aes(fill=factor(RatingMayT1)),alpha=0.8) + \n     labs(title=\"Density plot\", \n          subtitle=\"Mean of the Worldwide Governance Indicators\",\n          x=paste(\"MeanWGI\",sep=''),\n          fill=\"RatingNum\")\n```", "```py\nggplot(train_macro_trn, aes((CARA))) + geom_density(aes(fill=factor(RatingMayT1)),alpha=0.8) +     labs(title=\"Density plot\", \n          subtitle=\"Current account balance/GDP\",\n          x=paste(\"CARA\",sep=''),\n          fill=\"RatingNum\")\n```", "```py\ncolnames(train_macro_trn)\n ##  [1] \"Year\"                 \"CountryISO\"           \"CountryName\"        \n ##  [4] \"RatingMayT1\"          \"CARA\"                 \"DCPI\"               \n ##  [7] \"DGDP\"                 \"ILMA\"                 \"PSBR\"               \n ## [10] \"PUDP\"                 \"TDRA\"                 \"YPCA\"               \n ## [13] \"MEANWGI\"              \"YearsFromLastDefault\"\nvariables<-colnames(train_macro_trn[,c(4:14)])\n```", "```py\naux<-train_macro_trn\naux$RatingMayT1<-as.numeric(as.character(aux$RatingMayT1)) \n # Correlation matrix\ncorrelations<-cor(aux[, variables], use=\"pairwise\", method=\"pearson\")\ncorrelations_with_Rating<-as.matrix(correlations[1,])\n```", "```py\nprint(correlations_with_Rating)\n ##                            [,1]\n ## RatingMayT1           1.0000000\n ## CARA                  0.3938594\n ## DCPI                  0.1517755\n ## DGDP                  0.1167254\n ## ILMA                  0.3130267\n ## PSBR                  0.2783237\n ## PUDP                 -0.4172153\n ## TDRA                  0.3854816\n ## YPCA                  0.6491449\n ## MEANWGI               0.8024756\n ## YearsFromLastDefault  0.5132374\n```", "```py\nrm(list=setdiff(ls(), c(\"macroeconomic_data\",\"train_macro\",\"test_macro\",\"correlations_with_Rating\",\"train_macro_trn\",\"test_macro_trn\")))\n\nsave.image(\"Backup3.RData\")\n```", "```py\nlibrary(rpart)\nlibrary(rpart.plot)\n```", "```py\nvariables<-names(train_macro_trn[,4:14])\nprint(variables)\n ##  [1] \"RatingMayT1\"          \"CARA\"                 \"DCPI\"                \n ##  [4] \"DGDP\"                 \"ILMA\"                 \"PSBR\"                \n ##  [7] \"PUDP\"                 \"TDRA\"                 \"YPCA\"                \n ## [10] \"MEANWGI\"              \"YearsFromLastDefault\"\n```", "```py\nset.seed(1234)\n\nDT<-rpart(formula = RatingMayT1 ~ ., data = train_macro_trn[,c(variables)], control=rpart.control(maxdepth=5,cp=0.001))\n```", "```py\n#summary(DT)\n```", "```py\nDT_pr_train <- data.frame(cbind(train_macro_trn$CountryName,train_macro_trn$Year,train_macro_trn$RatingMayT1,predict(DT, newdata=train_macro_trn, type=\"class\")))\ncolnames(DT_pr_train)<-c(\"Country\",\"year\",\"Observed\",\"Predicted\")\n\nDT_pr_test <- data.frame(cbind(test_macro_trn$CountryName,test_macro_trn$Year,test_macro_trn$RatingMayT1,predict(DT, newdata=test_macro_trn, type=\"class\")))\ncolnames(DT_pr_test)<-c(\"Country\",\"year\",\"Observed\",\"Predicted\")\n```", "```py\ntable(DT_pr_train$Observed,DT_pr_train$Predicted)\n ##      1  2  3  4  5  6\n ##   1  6  2  0  0  0  0\n ##   2  0 16  5  1  1  0\n ##   3  1  4 22  4  2  0\n ##   4  0  0  7 25  0  0\n ##   5  0  0  7  1 25  1\n ##   6  0  0  0  2  1 35\n```", "```py\ntable(DT_pr_test$Observed,DT_pr_test$Predicted)\n ##      1  2  3  4  5  6\n ##   1  2  0  0  1  0  0\n ##   2  0  3  5  0  0  0\n ##   3  0  1  8  2  0  0\n ##   4  0  0  1  8  1  0\n ##   5  0  0  2  2  7  1\n ##   6  0  0  0  1  1 10\n```", "```py\nmodel_assessment<-function(data,model)\n{\n data$Observed<-as.numeric(as.character(data$Observed))\n data$Predicted<-as.numeric(as.character(data$Predicted))\n data$df<-abs(as.numeric(data$Predicted)-as.numeric(data$Observed))\n comparison<-as.data.frame(table(data$df))\n comparison$perc<-comparison$Freq/nrow(data)\n colnames(comparison)<-c(\"notche\",\"N\",paste(\"perc_\",model,sep=''))\n comparison$N<-NULL\n comparison$cumulative<-cumsum(comparison[,ncol(comparison)]) \n return(comparison)\n }\n```", "```py\nmodel_assessment(DT_pr_train,\"DT\")\n ##   notche     perc_DT cumulative\n ## 1      0 0.767857143  0.7678571\n ## 2      1 0.148809524  0.9166667\n ## 3      2 0.077380952  0.9940476\n ## 4      3 0.005952381  1.0000000\n```", "```py\nmodel_assessment(DT_pr_test,\"DT\")\n ##   notche    perc_DT cumulative\n ## 1      0 0.67857143  0.6785714\n ## 2      1 0.25000000  0.9285714\n ## 3      2 0.05357143  0.9821429\n ## 4      3 0.01785714  1.0000000\n```", "```py\nprp(DT)\n```", "```py\nsave.image(\"Backup4.RData\")\n\n```", "```py\nlibrary(MASS)\nordered_logistic <- polr(RatingMayT1 ~ ., data = train_macro_trn[,c(variables)], Hess=TRUE)\n```", "```py\nsummary(ordered_logistic)\n ## Call:\n ## polr(formula = RatingMayT1 ~ ., data = train_macro_trn[, c(variables)],\n ##     Hess = TRUE)\n ##\n ## Coefficients:\n ##                        Value Std. Error t value\n ## CARA                 -0.3624     0.2520 -1.4381\n ## DCPI                  0.1432     0.1807  0.7924\n ## DGDP                 -0.2225     0.2129 -1.0452\n ## ILMA                  1.5587     0.2592  6.0126\n ## PSBR                  0.6929     0.2209  3.1371\n ## PUDP                 -2.8039     0.3886 -7.2145\n ## TDRA                  0.3070     0.2464  1.2461\n ## YPCA                  2.6988     0.7100  3.8011\n ## MEANWGI               2.2565     0.4707  4.7937\n ## YearsFromLastDefault  0.8091     0.2191  3.6919\n ##\n ## Intercepts:\n ##     Value    Std. Error t value\n ## 1|2 -10.0770   1.1157    -9.0321\n ## 2|3  -5.6306   0.6134    -9.1789\n ## 3|4  -2.4390   0.4011    -6.0810\n ## 4|5   0.4135   0.3615     1.1439\n ## 5|6   4.8940   0.5963     8.2070\n ##\n ## Residual Deviance: 236.9271\n ## AIC: 266.9271\n```", "```py\ncoefs <- coef(summary(ordered_logistic))\n print(coefs)\n ##                            Value Std. Error    t value\n ## CARA                  -0.3623788  0.2519888 -1.4380749\n ## DCPI                   0.1432174  0.1807448  0.7923737\n ## DGDP                  -0.2225049  0.2128768 -1.0452282\n ## ILMA                   1.5586713  0.2592360  6.0125575\n ## PSBR                   0.6928689  0.2208629  3.1371002\n ## PUDP                  -2.8038553  0.3886409 -7.2145133\n ## TDRA                   0.3069968  0.2463570  1.2461463\n ## YPCA                   2.6988066  0.7100112  3.8010760\n ## MEANWGI                2.2564849  0.4707199  4.7936888\n ## YearsFromLastDefault   0.8090669  0.2191455  3.6919175\n ## 1|2                  -10.0770197  1.1156894 -9.0321014\n ## 2|3                   -5.6306456  0.6134365 -9.1788566\n ## 3|4                   -2.4389936  0.4010815 -6.0810418\n ## 4|5                    0.4134912  0.3614860  1.1438653\n ## 5|6                    4.8940176  0.5963226  8.2069960\n```", "```py\nexp(coef(ordered_logistic))\n ##                 CARA                 DCPI                 DGDP\n ##           0.69601870           1.15398065           0.80051110\n ##                 ILMA                 PSBR                 PUDP\n ##           4.75250240           1.99944358           0.06057607\n ##                 TDRA                 YPCA              MEANWGI\n ##           1.35933662          14.86198455           9.54946258\n ## YearsFromLastDefault\n ##           2.24581149\n\n```", "```py\np_values <- pnorm(abs(coefs[, \"t value\"]), lower.tail = FALSE) * 2\ncoefs <- cbind(coefs, \"p value\" = p_values)\nprint(coefs)\n ##                            Value Std. Error    t value     p value\n ## CARA                  -0.3623788  0.2519888 -1.4380749 1.504128e-01\n ## DCPI                   0.1432174  0.1807448  0.7923737 4.281428e-01\n ## DGDP                  -0.2225049  0.2128768 -1.0452282 2.959175e-01\n ## ILMA                   1.5586713  0.2592360  6.0125575 1.826190e-09\n ## PSBR                   0.6928689  0.2208629  3.1371002 1.706278e-03\n ## PUDP                  -2.8038553  0.3886409 -7.2145133 5.412723e-13\n ## TDRA                   0.3069968  0.2463570  1.2461463 2.127107e-01\n ## YPCA                   2.6988066  0.7100112  3.8010760 1.440691e-04\n ## MEANWGI                2.2564849  0.4707199  4.7936888 1.637422e-06\n ## YearsFromLastDefault   0.8090669  0.2191455  3.6919175 2.225697e-04\n ## 1|2                  -10.0770197  1.1156894 -9.0321014 1.684062e-19\n ## 2|3                   -5.6306456  0.6134365 -9.1788566 4.356928e-20\n ## 3|4                   -2.4389936  0.4010815 -6.0810418 1.194042e-09\n ## 4|5                    0.4134912  0.3614860  1.1438653 2.526795e-01\n ## 5|6                    4.8940176  0.5963226  8.2069960 2.267912e-16\n```", "```py\nOrd_log_pr_train <- cbind(train_macro_trn[,c(\"CountryName\",\"Year\",\"RatingMayT1\")], predict(ordered_logistic, train_macro_trn, type = \"probs\"))\n\ncolnames(Ord_log_pr_train)<-c(\"Country\",\"year\",\"Observed\",\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\")\nhead(Ord_log_pr_train,1)\n##Country year Observed      X1           X2          X3         X4\n 1 Austria 2010   6      5.468638e-06 4.608843e-04 0.010757249 0.15316033\n\n ##      X5         X6\n ## 1 0.7811701 0.05444599\n```", "```py\nfor (j in 1:nrow(Ord_log_pr_train))\n{\nOrd_log_pr_train$maximaPD[j]<-max(Ord_log_pr_train$X1[j],Ord_log_pr_train$X2[j],Ord_log_pr_train$X3[j],Ord_log_pr_train$X4[j],Ord_log_pr_train$X5[j],Ord_log_pr_train$X6[j])\n}\n\nOrd_log_pr_train$Predicted<-ifelse(Ord_log_pr_train$X1==Ord_log_pr_train$maximaPD,1,ifelse(Ord_log_pr_train$X2==Ord_log_pr_train$maximaPD,2,ifelse(Ord_log_pr_train$X3==Ord_log_pr_train$maximaPD,3,ifelse(Ord_log_pr_train$X4==Ord_log_pr_train$maximaPD,4,ifelse(Ord_log_pr_train$X5==Ord_log_pr_train$maximaPD,5,6)))))\n```", "```py\nmodel_assessment(Ord_log_pr_train,\"Ordered_logistic\")\n ##   notche perc_Ordered_logistic cumulative\n ## 1      0            0.69047619  0.6904762\n ## 2      1            0.29761905  0.9880952\n ## 3      2            0.01190476  1.0000000\n```", "```py\nOrd_log_pr_test <- cbind(test_macro_trn[,c(\"CountryName\",\"Year\",\"RatingMayT1\")], predict(ordered_logistic, test_macro_trn, type = \"probs\"))\ncolnames(Ord_log_pr_test)<-c(\"Country\",\"year\",\"Observed\",\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\")\n```", "```py\nfor (j in 1:nrow(Ord_log_pr_test))\n{\n\n Ord_log_pr_test$maximaPD[j]<-max(Ord_log_pr_test$X1[j],Ord_log_pr_test$X2[j],Ord_log_pr_test$X3[j],Ord_log_pr_test$X4[j],Ord_log_pr_test$X5[j],Ord_log_pr_test$X6[j])\n\n }\n\nOrd_log_pr_test$Predicted<-ifelse(Ord_log_pr_test$X1==Ord_log_pr_test$maximaPD,1,ifelse(Ord_log_pr_test$X2==Ord_log_pr_test$maximaPD,2,ifelse(Ord_log_pr_test$X3==Ord_log_pr_test$maximaPD,3,ifelse(Ord_log_pr_test$X4==Ord_log_pr_test$maximaPD,4,ifelse(Ord_log_pr_test$X5==Ord_log_pr_test$maximaPD,5,6)))))\n```", "```py\nmodel_assessment(Ord_log_pr_test,\"Ordered_logistic\")\n ##   notche perc_Ordered_logistic cumulative\n ## 1      0            0.57142857  0.5714286\n ## 2      1            0.39285714  0.9642857\n ## 3      2            0.01785714  0.9821429\n ## 4      3            0.01785714  1.0000000\n```", "```py\nsave.image(\"Backup5.RData\")\n```", "```py\ndirectories <- list.files(path = \"../MachineLearning/CountryReports/\", pattern = \"201\", full.names = TRUE)\n\nprint(directories)\n ## [1] \"../MachineLearning/CountryReports/2011\"\n ## [2] \"../MachineLearning/CountryReports/2012\"\n ## [3] \"../MachineLearning/CountryReports/2013\"\n ## [4] \"../MachineLearning/CountryReports/2014\"\n ## [5] \"../MachineLearning/CountryReports/2015\"\n ## [6] \"../MachineLearning/CountryReports/2016\"\n ## [7] \"../MachineLearning/CountryReports/2017\"\n ## [8] \"../MachineLearning/CountryReports/2018\"\n```", "```py\ntxt_files2011<-list.files(path = directories[1], pattern = \".txt\",  recursive=TRUE,full.names = TRUE)\ntxt_files2012<-list.files(path = directories[2], pattern = \".txt\",  recursive=TRUE,full.names = TRUE)\ntxt_files2013<-list.files(path = directories[3], pattern = \".txt\",  recursive=TRUE,full.names = TRUE)\ntxt_files2014<-list.files(path = directories[4], pattern = \".txt\",  recursive=TRUE,full.names = TRUE)\ntxt_files2015<-list.files(path = directories[5], pattern = \".txt\",  recursive=TRUE,full.names = TRUE)\ntxt_files2016<-list.files(path = directories[6], pattern = \".txt\",  recursive=TRUE,full.names = TRUE)\ntxt_files2017<-list.files(path = directories[7], pattern = \".txt\",  recursive=TRUE,full.names = TRUE)\ntxt_files2018<-list.files(path = directories[8], pattern = \".txt\",  recursive=TRUE,full.names = TRUE)\n```", "```py\ncountry_reports_list<-do.call(c,list(txt_files2011,txt_files2012,txt_files2013,txt_files2014,txt_files2015,txt_files2016,txt_files2017,txt_files2018))\nhead(country_reports_list)\n ## [1] \"../MachineLearning/CountryReports/2011/swp_austria_en_0.txt\"      \n ## [2] \"../MachineLearning/CountryReports/2011/swp_belgium_en_0.txt\"      \n ## [3] \"../MachineLearning/CountryReports/2011/swp_bulgaria_en_0.txt\"     \n ## [4] \"../MachineLearning/CountryReports/2011/swp_cyprus_en_0.txt\"       \n ## [5] \"../MachineLearning/CountryReports/2011/swp_czechrepublic_en_0.txt\"\n ## [6] \"../MachineLearning/CountryReports/2011/swp_denmark_en_0.txt\"\n```", "```py\nlist<-data.frame(country_reports_list)\nlist<-data.frame(t(data.frame(strsplit(as.character(list$country_reports_list), \"/\"))))\nlist<-list[,(ncol(list)-1):ncol(list)]\nrow.names(list)<-NULL\nlist<-cbind(list,country_reports_list)\ncolnames(list)<-c(\"Year\",\"file\",\"root\")\nhead(list)\n ##   Year                       file\n ## 1 2011       swp_austria_en_0.txt\n ## 2 2011       swp_belgium_en_0.txt\n ## 3 2011      swp_bulgaria_en_0.txt\n ## 4 2011        swp_cyprus_en_0.txt\n ## 5 2011 swp_czechrepublic_en_0.txt\n ## 6 2011       swp_denmark_en_0.txt\n ##                                                                root\n ## 1       ../MachineLearning/CountryReports/2011/swp_austria_en_0.txt\n ## 2       ../MachineLearning/CountryReports/2011/swp_belgium_en_0.txt\n ## 3      ../MachineLearning/CountryReports/2011/swp_bulgaria_en_0.txt\n ## 4        ../MachineLearning/CountryReports/2011/swp_cyprus_en_0.txt\n ## 5 ../MachineLearning/CountryReports/2011/swp_czechrepublic_en_0.txt\n ## 6       ../MachineLearning/CountryReports/2011/swp_denmark_en_0.txt\n```", "```py\nlist$CountryMapping<-NA\n\n list[grep(\"austria\",list$file),\"CountryMapping\"]<-\"Austria\"\n list[grep(\"belgium\",list$file),\"CountryMapping\"]<-\"Belgium\"\n list[grep(\"bulgaria\",list$file),\"CountryMapping\"]<-\"Bulgaria\"\n list[grep(\"croatia\",list$file),\"CountryMapping\"]<-\"Croatia\"\n list[grep(\"cyprus\",list$file),\"CountryMapping\"]<-\"Cyprus\"\n list[grep(\"czech\",list$file),\"CountryMapping\"]<-\"Czech Republic\"\n list[grep(\"denmark\",list$file),\"CountryMapping\"]<-\"Denmark\"\n list[grep(\"estonia\",list$file),\"CountryMapping\"]<-\"Estonia\"\n list[grep(\"finland\",list$file),\"CountryMapping\"]<-\"Finland\"\n list[grep(\"france\",list$file),\"CountryMapping\"]<-\"France\"\n list[grep(\"germany\",list$file),\"CountryMapping\"]<-\"Germany\"\n list[grep(\"greece\",list$file),\"CountryMapping\"]<-\"Greece\"\n list[grep(\"hungary\",list$file),\"CountryMapping\"]<-\"Hungary\"\n list[grep(\"ireland\",list$file),\"CountryMapping\"]<-\"Ireland\"\n list[grep(\"italy\",list$file),\"CountryMapping\"]<-\"Italy\"\n list[grep(\"latvia\",list$file),\"CountryMapping\"]<-\"Latvia\"\n list[grep(\"lithuania\",list$file),\"CountryMapping\"]<-\"Lithuania\"\n list[grep(\"luxembourg\",list$file),\"CountryMapping\"]<-\"Luxembourg\"\n list[grep(\"malta\",list$file),\"CountryMapping\"]<-\"Malta\"\n list[grep(\"netherlands\",list$file),\"CountryMapping\"]<-\"Netherlands\"\n list[grep(\"poland\",list$file),\"CountryMapping\"]<-\"Poland\"\n list[grep(\"portugal\",list$file),\"CountryMapping\"]<-\"Portugal\"\n list[grep(\"romania\",list$file),\"CountryMapping\"]<-\"Romania\"\n list[grep(\"slovakia\",list$file),\"CountryMapping\"]<-\"Slovakia\"\n list[grep(\"slovenia\",list$file),\"CountryMapping\"]<-\"Slovenia\"\n list[grep(\"spain\",list$file),\"CountryMapping\"]<-\"Spain\"\n list[grep(\"sweden\",list$file),\"CountryMapping\"]<-\"Sweden\"\n list[grep(\"uk\",list$file),\"CountryMapping\"]<-\"United Kingdom\"\n list[grep(\"kingdom\",list$file),\"CountryMapping\"]<-\"United Kingdom\"\n list[grep(\"netherland\",list$file),\"CountryMapping\"]<-\"Netherlands\"\n```", "```py\ntable(list$CountryMapping)\n ## \n ## Austria         Belgium   Bulgaria   Croatia  Cyprus  \n ##    8               8         8         6         8 \n ## Czech Republic  Denmark   Estonia    Finland  France \n ##    8               8         8         8         8 \n ## Germany         Greece    Hungary    Ireland  Italy \n ##    8               4         8         8         8 \n ## Latvia          Lithuania Luxembourg Malta    Netherlands \n ##    8               8         8         8         8 \n ## Poland          Portugal  Romania    Slovakia Slovenia \n ##    8               8         8         8         8 \n ## Spain           Sweden    United Kingdom \n ##    8               8            8\n```", "```py\ntrain_list<-train_macro[,c(\"CountryName\",\"Year\")]\ntrain_list$year_report<-train_list$Year+1\n\ntrain_list<-merge(train_list,list,by.x=c(\"CountryName\",\"year_report\"),by.y=c(\"CountryMapping\",\"Year\"),all.x=TRUE)\n\ntrain_list<-train_list[complete.cases(train_list),]\n\nfiles_train<-as.vector(train_list$root)\n```", "```py\nprint(head(files_train))\n ## [1] \"../MachineLearning/CountryReports/2011/swp_austria_en_0.txt\"                       \n ## [2] \"../MachineLearning/CountryReports/2012/swd2012_austria_en.txt\"                                \n ## [3] \"../MachineLearning/CountryReports/2013/swd2013_austria_en.txt\"                                \n ## [4] \"../MachineLearning/CountryReports/2014/swd2014_austria_en_0.txt\"                              \n ## [5] \"../MachineLearning/CountryReports/2016/cr2016_austria_en.txt\"                                 \n ## [6] \"../MachineLearning/CountryReports/2017/2017-european-semester-country-report-austria-en_1.txt\"\n```", "```py\ntest_list<-test_macro[,c(\"CountryName\",\"Year\")]\ntest_list$year_report<-test_list$Year+1\n\ntest_list<-merge(test_list,list,by.x=c(\"CountryName\",\"year_report\"),by.y=c(\"CountryMapping\",\"Year\"),all.x=TRUE)\n\ntest_list<-test_list[complete.cases(test_list),]\n\nfiles_test<-as.vector(test_list$root)\n```", "```py\nprint(head(files_test))\n ## [1] \"../MachineLearning/CountryReports/2015/cr2015_austria_en.txt\"                               \n ## [2] \"../MachineLearning/CountryReports/2018/2018-european-semester-country-     report-austria-en.txt\"\n ## [3] \"../MachineLearning/CountryReports/2013/swd2013_belgium_en.txt\"                              \n ## [4] \"../MachineLearning/CountryReports/2011/swp_bulgaria_en_0.txt\"                               \n ## [5] \"../MachineLearning/CountryReports/2013/swd2013_bulgaria_en.txt\"                             \n ## [6] \"../MachineLearning/CountryReports/2014/swd2014_croatia_en.txt\"\n```", "```py\nprint(paste(\"The number of countries used to train previous model was formed by\",nrow(train_macro_trn), \"countries\",sep=\" \"))\n\n ## [1] \"The number of countries used to train previous model was formed by 168      countries\"\n```", "```py\nprint(paste(\"The number of countries which we will use to train this new model will be formed by\",nrow(train_list), \"countries\",sep=\" \"))\n\n ## [1] \"The number of countries which we will use to train this new model will      be formed by 165 countries\"\n```", "```py\nprint(paste(\"The number of countries used to validate previous model was formed by\",nrow(test_macro_trn), \"countries\",sep=\" \"))\n\n ## [1] \"The number of countries used to validate previous model was formed by      56 countries\"\n```", "```py\nprint(paste(\"The number of countries which we will use to train this new model will be formed by\",nrow(test_list), \"countries\",sep=\" \"))\n\n ## [1] \"The number of countries which we will use to train this new model will be formed by 53 countries\"\n```", "```py\nImport_txt <- function(txt) \n{\n x<-as.data.frame(read.delim(txt, header=FALSE, comment.char=\"#\", stringsAsFactors=FALSE))\n return(x)\n}\n```", "```py\nReports_train <- lapply(files_train, \n                  function(x) \n                  read.delim(x, \n                             header = FALSE, comment.char=\"#\",\n                             stringsAsFactors = FALSE))\nReports_test <-  lapply(files_test, \n                  function(x) \n                  read.delim(x, \n                             header = FALSE, comment.char=\"#\",\n                             stringsAsFactors = FALSE))\n```", "```py\nrm(list=setdiff(ls(), c(\"macroeconomic_data\",\"Reports_train\",\"Reports_test\",\"train_list\",\"test_list\")))\nsave.image(\"Backup6.RData\")\n```", "```py\nlibrary(tm)\ndocs_train <- as.VCorpus(Reports_train)\n\ndocs_test <- as.VCorpus(Reports_test)\n```", "```py\ncorpus_treatment<-function(corpus)\n{\n\n toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, \" \", x))})\n\n corpus <- tm_map(corpus,PlainTextDocument)\n corpus <- tm_map(corpus, toSpace, \"-\")\n corpus <- tm_map(corpus, toSpace, \":\")\n corpus <- tm_map(corpus, removePunctuation)\n corpus <- tm_map(corpus, toSpace, \"'\")\n corpus <- tm_map(corpus, toSpace, \"'\")\n corpus <- tm_map(corpus, toSpace, \" -\")\n corpus <- tm_map(corpus,content_transformer(tolower))\n corpus <- tm_map(corpus, removeNumbers)\n corpus <- tm_map(corpus, removeWords, stopwords(\"english\"))\n corpus <- tm_map(corpus, stripWhitespace)\n return(corpus)\n}\n```", "```py\ndocs_train<-corpus_treatment(docs_train)\ndocs_test<-corpus_treatment(docs_test)\n```", "```py\nlibrary(SnowballC)\ndocs_train <- tm_map(docs_train,stemDocument)\ndocs_test <- tm_map(docs_test,stemDocument)\n```", "```py\nlibrary(RWeka)\n```", "```py\noptions(mc.cores=4)\n\nBigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 2))\n```", "```py\ntdm2_train <- TermDocumentMatrix(docs_train, control = list(tokenize = BigramTokenizer,wordLengths = c(3,20)))\n```", "```py\ntdm2_test <- TermDocumentMatrix(docs_test, control = list(dictionary = Terms(tdm2_train),tokenize = BigramTokenizer,wordLengths = c(3,20)))\n```", "```py\ntdm2_train\n ## <<TermDocumentMatrix (terms: 609929, documents: 165)>>\n ## Non-/sparse entries: 2034690/98603595\n ## Sparsity           : 98%\n ## Maximal term length: 20\n ## Weighting          : term frequency (tf)\ntdm2_test\n ## <<TermDocumentMatrix (terms: 609929, documents: 53)>>\n ## Non-/sparse entries: 504543/31821694\n ## Sparsity           : 98%\n ## Maximal term length: 20\n ## Weighting          : term frequency (tf)\n```", "```py\ntdm2_train2 <- removeSparseTerms(tdm2_train, 0.75)\ntdm2_train2\n ## <<TermDocumentMatrix (terms: 6480, documents: 165)>>\n ## Non-/sparse entries: 589204/479996\n ## Sparsity           : 45%\n ## Maximal term length: 20\n ## Weighting          : term frequency (tf)\n```", "```py\nprint(as.matrix(tdm2_train2[1:10, 1:4]))\n ##             Docs\n ## Terms        character(0) character(0) character(0) character(0)\n ##   ­ gj                  0            0            0            0\n ##   ­ mwh                 0            0            0            0\n ##   ± ±                  0            0            0            0\n ##   à vis                1            1            1            5\n ##   abil                 0            1            1            2\n ##   abl                  0            1            1            0\n ##   abl afford           0            0            0            0\n ##   abolish              1            1            3            1\n ##   abroad               2            4            3            0\n ##   absenc               0            0            0            0\n```", "```py\nprint(head(as.character(train_list$root),4))\n## [1] \"../MachineLearning/CountryReports/2011/swp_austria_en_0.txt\"   \n## [2] \"../MachineLearning/CountryReports/2012/swd2012_austria_en.txt\" \n## [3] \"../MachineLearning/CountryReports/2013/swd2013_austria_en.txt\" \n## [4] \"../MachineLearning/CountryReports/2014/swd2014_austria_en_0.txt\"\n```", "```py\nfreq <- rowSums(as.matrix(tdm2_train2))\nord <- order(freq,decreasing=TRUE)\n```", "```py\nfreq[head(ord,20)]\n\n ##    gdp    rate increas  market  labour  sector     tax  growth  public\n ##  20566   16965   15795   15759   15751   15381   14582   14545   14515\n ##   year  employ  energi  invest  measur  govern    debt    bank    term\n ##  13118   12481   12330   12027   11341   10903   10854   10668   10470\n ##  averag  social\n ##  10059   10051\n```", "```py\nlibrary(wordcloud)\nset.seed(1234)\nwordcloud(row.names(tdm2_train2), freq = freq, max.words=200,min.freq=4000,scale=c(2,.4),\nrandom.order = FALSE,rot.per=.5,vfont=c(\"sans serif\",\"plain\"),colors=palette())\n```", "```py\ntdm2_train2 <- as.matrix(tdm2_train2)\ndim(tdm2_train2)\n## [1] 6480  165\ntdm2_train2 <- t(tdm2_train2)\ntdm2_test2<-as.matrix(tdm2_test)\ntdm2_test2 <- t(tdm2_test2)\n\nrm(tdm2_test)\n```", "```py\nrm(list=setdiff(ls(), c(\"macroeconomic_data\",\"train_list\",\"test_list\",\"tdm2_test2\",\"tdm2_train2\")))\n```", "```py\nsave.image(\"Backup7.RData\")\n```", "```py\ntrain_list<-merge(train_list[,c(\"Year\",\"CountryName\",\"year_report\")],macroeconomic_data[,c(\"CountryName\",\"Year\",\"RatingMayT1\")],by=c(\"CountryName\",\"Year\"),all.x=TRUE)\n\ntest_list<-merge(test_list[,c(\"Year\",\"CountryName\",\"year_report\")],macroeconomic_data[,c(\"CountryName\",\"Year\",\"RatingMayT1\")],by=c(\"CountryName\",\"Year\"),all.x=TRUE)\ntraining <- cbind(train_list,tdm2_train2)\n\nvalidation <- cbind(test_list,tdm2_test2)\n```", "```py\nhead(colnames(training),7)\n\n## [1] \"CountryName\" \"Year\"        \"year_report\" \"RatingMayT1\" \"­ gj\"       \n## [6] \"­ mwh\"       \"± ±\"\n```", "```py\ncorrelations<-data.frame(correlations)\ncolnames(correlations)<-c(\"word\",\"correlation\")\ncorrelations$abs_corr<-abs(as.numeric(as.character(correlations$correlation)))\ncorrelations<-correlations[order(correlations$abs_corr,decreasing = TRUE),]\ncorrelations = matrix(\"NA\",nrow=(ncol(training)-4),2) \nncolumns<-ncol(training)\n\n for (i in 5:ncolumns)\n{\n   correlations[i-4,1]<-colnames(training[i])\n   correlations[i-4,2]<-  as.numeric(cor(training[,i],as.numeric(as.character(training[,\"RatingMayT1\"]))))\n}\n```", "```py\nhead(correlations,10)\n ##               word        correlation  abs_corr\n ## 3245        judici -0.495216233392176 0.4952162\n ## 1175         court   -0.4939081009835 0.4939081\n ## 132      administr -0.470760214895828 0.4707602\n ## 3710       migrant  0.460837714113155 0.4608377\n ## 1343         delay  -0.46038844705712 0.4603884\n ## 468     background  0.455839970556903 0.4558400\n ## 116          adequ -0.445062248908142 0.4450622\n ## 2811        immigr  0.428818668867468 0.4288187\n ## 3246 judici system  -0.42745138771952 0.4274514\n ## 6106      undeclar -0.419206156830568 0.4192062\n```", "```py\nlist_vars<-dput(as.vector(correlations$word[1:1000]))\n```", "```py\nsave.image(\"Backup8.RData\")\n```", "```py\nlibrary(glmnet)\n```", "```py\ntraining$RatingMayT1<-as.factor(training$RatingMayT1)\nvalidation$RatingMayT1<-as.factor(validation$RatingMayT1)\n```", "```py\nxtrain<-training[,list_vars]\nytrain<-training$RatingMayT1\n```", "```py\nvalidation$RatingMayT1<-as.factor(validation$RatingMayT1)\nxtest<-validation[,list_vars]\nytest<-validation$RatingMayT1\n```", "```py\nset.seed(1234)\n\nModelLasso <- cv.glmnet(y =  ytrain, x=data.matrix(xtrain[,list_vars]), alpha=1,family='multinomial',type.multinomial = \"grouped\",parallel=TRUE)\n```", "```py\ntable(ytrain)\n ## ytrain\n ##  1  2  3  4  5  6 \n ##  5 23 33 32 34 38\n```", "```py\nytrain<-gsub(\"1\",\"2\",ytrain)\nytest<-gsub(\"1\",\"2\",ytest)\n```", "```py\ntable(ytrain)\n ## ytrain\n ##  2  3  4  5  6 \n ## 28 33 32 34 38\nset.seed(1234)\n\nModelLasso <- cv.glmnet(y =  ytrain, x=data.matrix(xtrain[,list_vars]), alpha=1,family='multinomial',type.multinomial = \"grouped\")\n```", "```py\nplot(ModelLasso)\n```", "```py\nlog(ModelLasso$lambda.min)\n## [1] -3.836699\n```", "```py\nbest_lambda <- ModelLasso$lambda.1se\nprint(best_lambda)\n## [1] 0.05727767\n```", "```py\npredictLASSO_train <- predict(ModelLasso, newx = data.matrix(xtrain[,list_vars]), \ntype = \"class\", s = ModelLasso$lambda.1se)\n\npredictLASSO_train<-as.data.frame(cbind(training[,1:2],ytrain ,predictLASSO_train))\ncolnames(predictLASSO_train)<-c(\"Country\",\"Year\",\"Rating\",\"Prediction\")\n```", "```py\ntable(predictLASSO_train$Rating,predictLASSO_train$Prediction)\n ##      2  3  4  5  6\n ##   2 27  0  0  0  1\n ##   3  1 32  0  0  0\n ##   4  0  1 30  0  1\n ##   5  0  0  0 33  1\n ##   6  0  0  0  1 37\n```", "```py\npredictLASSO_test <- predict(ModelLasso, newx = data.matrix(xtest), \ntype = \"class\", s = ModelLasso$lambda.1se)\n\npredictLASSO_test<-as.data.frame(cbind(validation[,1:2],ytest ,predictLASSO_test))\ncolnames(predictLASSO_test)<-c(\"Country\",\"Year\",\"Rating\",\"Prediction\")\n```", "```py\n\ntable(predictLASSO_test$Rating,predictLASSO_test$Prediction)\n ##      2  3  4  5  6\n ##   2  5  3  1  0  1\n ##   3  1  7  1  0  0\n ##   4  0  0  7  0  3\n ##   5  0  1  1  8  2\n ##   6  0  0  0  2 10\n```", "```py\nmodel_assessment<-function(data,model)\n {\n data$Observed<-as.numeric(as.character(data$Rating))\n data$Predicted<-as.numeric(as.character(data$Prediction))\n data$df<-abs(as.numeric(data$Predicted)-as.numeric(data$Observed))\n comparison<-as.data.frame(table(data$df))\n comparison$perc<-comparison$Freq/nrow(data)\n colnames(comparison)<-c(\"notch\",\"N\",paste(\"perc_\",model,sep=''))\n comparison$N<-NULL\n return(comparison)\n }\n```", "```py\nmodel_assessment(predictLASSO_train,\"Train_LASSO\")\n ##   notch perc_Train_LASSO\n ## 1     0      0.963636364\n ## 2     1      0.024242424\n ## 3     2      0.006060606\n ## 4     4      0.006060606\nmodel_assessment(predictLASSO_test,\"Test_LASSO\")\n ##   notch perc_Test_LASSO\n ## 1     0      0.69811321\n ## 2     1      0.18867925\n ## 3     2      0.09433962\n ## 4     4      0.01886792\n```", "```py\ncoefs<-coef(ModelLasso, s = \"lambda.1se\")\n```", "```py\ncoefs2<-coefs$`2`\n list_coefs2<-as.data.frame(coefs2@Dimnames)\n colnames(list_coefs2)<-c(\"variable\",\"id\")\n list_coefs2$id<-as.numeric(row.names(list_coefs2))-1\n aux_coefs2<-cbind(as.data.frame(coefs2@i),as.data.frame(coefs2@x))\n colnames(aux_coefs2)<-c(\"id\",\"coefficient\")\n list_coefs2<-merge(list_coefs2,aux_coefs2,by.x=\"id\")\n rm(coefs2,aux_coefs2)\n```", "```py\nhead(list_coefs2[order(list_coefs2$coefficient,decreasing = TRUE),],10)\n ##     id         variable coefficient\n ## 18  69      financ need  0.24991828\n ## 37 192        personnel  0.13635379\n ## 44 305          outflow  0.11243899\n ## 15  51    energi sector  0.06854058\n ## 24  97    minimum incom  0.05821313\n ## 39 216     gross extern  0.05237113\n ## 10  37          resolut  0.04807981\n ## 72 700           analyt  0.03036531\n ## 75 774 healthcar sector  0.02997181\n ## 26 102   social benefit  0.02572995\n```", "```py\ncoefs6<-coefs$`6`\n list_coefs6<-as.data.frame(coefs6@Dimnames)\n colnames(list_coefs6)<-c(\"variable\",\"id\")\n list_coefs6$id<-as.numeric(row.names(list_coefs6))-1\n aux_coefs6<-cbind(as.data.frame(coefs6@i),as.data.frame(coefs6@x))\n colnames(aux_coefs6)<-c(\"id\",\"coefficient\")\n list_coefs6<-merge(list_coefs6,aux_coefs6,by.x=\"id\")\n rm(coefs6,aux_coefs6)\n```", "```py\nhead(list_coefs6[order(list_coefs6$coefficient,decreasing = TRUE),],10)\n ##     id         variable coefficient\n ## 45 309          remaind  0.22800169\n ## 1    0      (Intercept)  0.20122381\n ## 7   20    govern balanc  0.15410796\n ## 81 899         stimulus  0.11734883\n ## 82 918   europ strategi  0.06968609\n ## 17  57 interest payment  0.05516403\n ## 49 367     fiscal posit  0.04272709\n ## 65 568   contribut rate  0.03101503\n ## 38 207            decad  0.03063200\n ## 2    6       background  0.03029957\n```", "```py\nsave.image(\"Backup9.RData\")\n```"]