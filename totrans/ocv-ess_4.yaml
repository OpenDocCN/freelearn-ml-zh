- en: Chapter 4. What's in the Image? Segmentation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章 图像中的内容？分割
- en: 'Segmentation is any process that partitions an image into multiple regions
    or segments. These will typically correspond to meaningful regions or objects,
    such as face, car, road, sky, grass, and so on. Segmentation is one of the most
    important stages in a computer vision system. In OpenCV, there is no specific
    module for segmentation, though a number of ready-to-use methods are available
    in other modules (most of them in `imgproc`). In this chapter, we will cover the
    most important and frequently used methods available in the library. In some cases,
    additional processing will have to be added to improve the results or obtain seeds
    (this refers to rough segments that allow an algorithm to perform a complete segmentation).
    In this chapter we will look at the following major segmentation methods: thresholding,
    contours and connected components, flood filling, watershed segmentation, and
    the GrabCut algorithm.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分割是将图像分割成多个区域或片段的任何过程。这些通常对应于有意义的区域或对象，例如人脸、汽车、道路、天空、草地等。分割是计算机视觉系统中最重要阶段之一。在
    OpenCV 中，没有专门的分割模块，尽管在其他模块（大多数在 `imgproc` 中）中提供了许多现成的方法。在本章中，我们将介绍库中最重要的和最常用的方法。在某些情况下，可能需要添加额外的处理来提高结果或获取种子（这指的是允许算法执行完整分割的粗略片段）。在本章中，我们将探讨以下主要的分割方法：阈值化、轮廓和连通组件、区域填充、分水岭分割和
    GrabCut 算法。
- en: Thresholding
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阈值化
- en: Thresholding is one of the simplest yet most useful segmentation operations.
    We can safely say that you will end up using some sort of thresholding in almost
    any image-processing application. We consider it a segmentation operation since
    it partitions an image into two regions, typically, an object and its background.
    In OpenCV, thresholding is performed with the function `double threshold(InputArray
    src, OutputArray dst, double thresh, double maxval, int type)`.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值化是一种简单但非常有用的分割操作。我们可以安全地说，你几乎会在任何图像处理应用中使用某种形式的阈值化。我们将其视为分割操作，因为它将图像分割成两个区域，通常是对象及其背景。在
    OpenCV 中，阈值化是通过函数 `double threshold(InputArray src, OutputArray dst, double thresh,
    double maxval, int type)` 来实现的。
- en: 'The first two parameters are the input and output images, respectively. The
    third input parameter is the threshold chosen. The meaning of `maxval` is controlled
    by the type of thresholding we want to perform. The following table shows the
    operation performed for each type:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个参数分别是输入和输出图像。第三个输入参数是选择的阈值。`maxval` 的含义取决于我们想要执行的阈值化类型。以下表格显示了每种类型执行的操作：
- en: '| Type | dst(x,y) |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | dst(x,y) |'
- en: '| --- | --- |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `THRESH_BINARY` | `maxval` if `src(x,y)` is greater than `thresh` and `0`
    if otherwise |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| `THRESH_BINARY` | 如果 `src(x,y)` 大于 `thresh`，则返回 `maxval`，否则返回 `0` |'
- en: '| `THRESH_BINARY_INV` | `0` if `src(x,y)` is greater than `thresh` and `maxval`
    if otherwise |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| `THRESH_BINARY_INV` | 如果 `src(x,y)` 大于 `thresh`，则返回 `0`，否则返回 `maxval` |'
- en: '| `THRESH_TRUNC` | `thresh` if `src(x,y)` is greater than `thresh` and `src(x,y)`
    if otherwise |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| `THRESH_TRUNC` | 如果 `src(x,y)` 大于 `thresh`，则返回 `thresh`，否则返回 `src(x,y)` |'
- en: '| `THRESH_TOZERO` | `src(x,y)` if `src(x,y)` is greater than `thresh` and `0`
    if otherwise |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| `THRESH_TOZERO` | 如果 `src(x,y)` 大于 `thresh`，则返回 `src(x,y)`，否则返回 `0` |'
- en: '| `THRESH_TOZERO_INV` | `0` if `src(x,y)` is greater than `thresh` and `src(x,y)`
    if otherwise |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| `THRESH_TOZERO_INV` | 如果 `src(x,y)` 大于 `thresh`，则返回 `0`，否则返回 `src(x,y)` |'
- en: 'While in previous OpenCV books (and the available reference manual) each type
    of thresholding is illustrated with the help of 1D signal plots, our experience
    shows that numbers and gray levels allow you to grasp the concept faster. The
    following table shows the effect of the different threshold types using a single-line
    image as an example input:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的 OpenCV 书籍（以及可用的参考手册）中，每种类型的阈值化都是通过 1D 信号图来展示的，但我们的经验表明，数字和灰度级别能让你更快地掌握概念。以下表格展示了使用单行图像作为示例输入时，不同阈值类型的效果：
- en: '![Thresholding](img/00021.jpeg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![阈值化](img/00021.jpeg)'
- en: The special value `THRESH_OTSU` may be combined with the previous values (with
    the OR operator). In such cases, the threshold value is automatically estimated
    by the function (using Otsu's algorithm). This function returns the estimated
    threshold value.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 特殊值 `THRESH_OTSU` 可以与前面的值（使用 OR 运算符）组合。在这种情况下，阈值值将由函数自动估计（使用 Otsu 算法）。此函数返回估计的阈值值。
- en: Note
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Otsu's method obtains a threshold that best separates the background from the
    foreground's pixels (in an interclass/intraclass variance ratio sense). See the
    full explanation and demos at [http://www.labbookpages.co.uk/software/imgProc/otsuThreshold.html](http://www.labbookpages.co.uk/software/imgProc/otsuThreshold.html).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大津法（Otsu's method）获得一个最佳阈值，该阈值能够最好地将背景与前景像素分开（从类间/类内方差比的角度来看）。有关完整解释和演示，请参阅[http://www.labbookpages.co.uk/software/imgProc/otsuThreshold.html](http://www.labbookpages.co.uk/software/imgProc/otsuThreshold.html)。
- en: 'While the function described uses a single threshold for the whole image, adaptive
    thresholding estimates a different threshold for each pixel. This produces a better
    result when the input image is less homogeneous (with unevenly illuminated regions,
    for example). The function to perform adaptive thresholding is as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然描述的函数使用单个阈值处理整个图像，但自适应阈值处理为每个像素估计不同的阈值。当输入图像不太均匀（例如，具有不均匀照亮的区域）时，这会产生更好的结果。执行自适应阈值处理的函数如下：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This function is similar to the previous one. The parameter `thresholdType`
    must be either `THRESH_BINARY` or `THRESH_BINARY_INV`. This function computes
    a threshold for each pixel by computing a weighted average of pixels in a neighborhood
    minus a constant (`C`). When `thresholdType` is ADAPTIVE_THRESH_MEAN_C, the threshold
    computed is the mean of the neighborhood (that is, all the elements are weighted
    equally).When `thresholdType` is ADAPTIVE_THRESH_GAUSSIAN_C, the pixels in the
    neighborhood are weighted according to a Gaussian function.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数与上一个函数类似。参数`thresholdType`必须是`THRESH_BINARY`或`THRESH_BINARY_INV`。此函数通过计算邻域内像素的加权平均值减去一个常数（`C`）来为每个像素计算一个阈值。当`thresholdType`是`ADAPTIVE_THRESH_MEAN_C`时，计算出的阈值是邻域的平均值（即所有元素都被同等加权）。当`thresholdType`是`ADAPTIVE_THRESH_GAUSSIAN_C`时，邻域内的像素根据高斯函数进行加权。
- en: 'The following `thresholding` example shows how to perform thresholding operations
    on an image:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下`阈值`示例展示了如何在图像上执行阈值操作：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The example in the preceding code creates three windows with the source image,
    which is loaded in grayscale, and the result of thresholding and adaptive thresholding.
    Then, it creates three trackbars: one associated to the thresholding result window
    (to handle the threshold value) and two associated to the adaptive thresholding
    result window (to handle the block''s size and the value of the constant `C`).
    Note that since two callback functions are necessary in this case, and we do not
    want to repeat code, the call to `adaptiveThreshold` is embedded in the function,
    `adaptThreshAndShow`.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码中的示例创建了一个包含源图像、灰度加载的源图像、阈值处理结果和自适应阈值处理结果的三个窗口。然后，它创建了三个滑块：一个与阈值处理结果窗口相关联（用于处理阈值值），另外两个与自适应阈值处理结果窗口相关联（用于处理块的尺寸和常数`C`的值）。请注意，由于在这种情况下需要两个回调函数，并且我们不希望重复代码，因此`adaptiveThreshold`的调用被嵌入到`adaptThreshAndShow`函数中。
- en: 'Next, a call is made to the functions that perform the operations using default
    parameter values. Finally, the `moveWindow` function from `highgui` is used to
    reposition the windows on the screen (otherwise they will be displayed on top
    of each other, and only the third one will be visible). Also, note that the first
    six lines in the function `adaptiveThresholding1` are needed to keep an odd value
    in the parameter `block_size`. The following screenshot shows the output of the
    example:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，调用执行操作的函数，使用默认参数值。最后，使用`highgui`中的`moveWindow`函数重新定位屏幕上的窗口（否则它们将重叠显示，并且只能看到第三个窗口）。此外，请注意，函数`adaptiveThresholding1`中的前六行是必要的，以保持`block_size`参数的奇数值。以下截图显示了示例的输出：
- en: '![Thresholding](img/00022.jpeg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![阈值](img/00022.jpeg)'
- en: Output of the thresholding example
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值示例的输出
- en: Note
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The function `inRange(InputArray src, InputArray lowerb, InputArray upperb,
    OutputArray dst)` is also useful for thresholding as it checks whether the pixels
    lie between lower and upper thresholds. Both `lowerb` and `upperb` must be provided
    using Scalar, as in `inRange(src, Scalar(bl,gl,rl), Scalar(bh,gh,rh), tgt);`.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`inRange(InputArray src, InputArray lowerb, InputArray upperb, OutputArray
    dst)`在阈值处理中也很有用，因为它检查像素是否位于下限和上限阈值之间。`lowerb`和`upperb`都必须使用Scalar提供，如`inRange(src,
    Scalar(bl,gl,rl), Scalar(bh,gh,rh), tgt);`。
- en: Contours and connected components
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘和连通组件
- en: Contour extraction operations can be considered halfway between feature extraction
    and segmentation, since a binary image is produced in which image contours are
    separated from other homogeneous regions. Contours will typically correspond to
    object boundaries.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 轮廓提取操作可以被认为是特征提取和分割之间的中间步骤，因为它产生了一个二值图像，其中图像轮廓与其他均匀区域分离。轮廓通常对应于物体边界。
- en: While a number of simple methods detect edges in images (for example, the Sobel
    and Laplace filters), the **Canny** method is a robust algorithm for doing this.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然许多简单的方法可以检测图像中的边缘（例如，Sobel和Laplace滤波器），但**Canny**方法是一种稳健的算法来完成这项任务。
- en: Note
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: This method uses two thresholds to decide whether a pixel is an edge. In what
    is called a hysteresis procedure, a lower and an upper threshold are used (see
    [http://docs.opencv.org/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.html](http://docs.opencv.org/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.html)).
    Since OpenCV already includes a good example of the Canny edge detector (in `[opencv_source_code]/samples/cpp/edge.cpp`),
    we do not include one here (but see the following `floodFill` example). Instead,
    we will go on to describe other highly useful functions based on detected edges.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用两个阈值来决定一个像素是否是边缘。在所谓的阈值过程（hysteresis procedure）中，使用一个下限和一个上限阈值（参见[http://docs.opencv.org/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.html](http://docs.opencv.org/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.html)）。由于OpenCV已经包含了一个好的Canny边缘检测器示例（在`[opencv_source_code]/samples/cpp/edge.cpp`中），我们这里没有包含一个（但请参见下面的`floodFill`示例）。相反，我们将继续描述基于检测到的边缘的其他非常有用的函数。
- en: To detect straight lines, the Hough transform is a classical method. While the
    Hough transform method is available in OpenCV (the functions `HoughLines` and
    `HoughLinesP`, for example, `[opencv_source_code]/samples/cpp/houghlines.cpp`),
    the more recent **Line Segment Detector** (**LSD**) method is generally a more
    robust one. LSD works by finding alignments of high-gradient magnitude pixels,
    given its alignment tolerance feature. This method has been shown to be more robust
    and faster than the best previous Hough-based detector (Progressive Probabilistic
    Hough Transform).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要检测直线，霍夫变换是一种经典方法。虽然霍夫变换方法在OpenCV中可用（例如，`HoughLines`和`HoughLinesP`函数，参见`[opencv_source_code]/samples/cpp/houghlines.cpp`），但较新的**线段检测器**（**LSD**）方法通常更稳健。LSD通过寻找高梯度幅度像素的对齐来实现，这得益于其对齐容差特性。这种方法已被证明比最好的基于霍夫的前期检测器（渐进概率霍夫变换）更稳健且更快。
- en: The LSD method is not available in the 2.4.9 release of OpenCV; although, at
    the time of this writing, it is already available in the code source's repository
    in GitHub. The method will be available in Version 3.0\. A short example (`[opencv_source_code]/samples/cpp/lsd_lines.cpp`)
    in the library covers this functionality. However, we will provide an additional
    example that shows different features.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: LSD方法在OpenCV的2.4.9版本中不可用；尽管如此，在撰写本文时，它已经在GitHub代码源仓库中可用。该方法将在版本3.0中提供。库中的一个简短示例（`[opencv_source_code]/samples/cpp/lsd_lines.cpp`）涵盖了这一功能。然而，我们将提供一个额外的示例，展示不同的特性。
- en: Note
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: To test the latest source code available in GitHub, go to [https://github.com/itseez/opencv](https://github.com/itseez/opencv)
    and download the library code as a ZIP file. Then, unzip it to a local folder
    and follow the same steps described in [Chapter 1](part0014_split_000.html#page
    "Chapter 1. Getting Started"), *Getting Started*, to compile and install the library.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试GitHub上可用的最新源代码，请访问[https://github.com/itseez/opencv](https://github.com/itseez/opencv)并下载库代码作为ZIP文件。然后，将其解压缩到本地文件夹，并按照[第1章](part0014_split_000.html#page
    "第1章。入门")中描述的相同步骤，*入门*，来编译和安装库。
- en: The LSD detector is a C++ class. The function `cv::Ptr<LineSegmentDetector>
    cv::createLineSegmentDetector (int _refine=LSD_REFINE_STD, double _scale=0.8,
    double_sigma_scale=0.6, double _quant=2.0, double _ang_th=22.5, double _log_eps=0,
    double _density_th=0.7, int _n_bins=1024)` creates an object of the class and
    returns a pointer to it. Note that several arguments define the detector created.
    The meaning of those parameters requires you to know the underlying algorithm,
    which is out of the scope of this book. Fortunately, the default values will suffice
    for most purposes, so we refer the reader to the reference manual (for Version
    3.0 of the library) for special cases. Having said that, the first parameter scale
    roughly controls the number of lines that are returned. The input image is automatically
    rescaled by this factor. At lower resolutions, fewer lines are detected.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: LSD检测器是一个C++类。函数`cv::Ptr<LineSegmentDetector> cv::createLineSegmentDetector
    (int _refine=LSD_REFINE_STD, double _scale=0.8, double_sigma_scale=0.6, double
    _quant=2.0, double _ang_th=22.5, double _log_eps=0, double _density_th=0.7, int
    _n_bins=1024)`创建了一个类的对象，并返回指向它的指针。请注意，几个参数定义了创建的检测器。这些参数的含义需要你了解底层算法，而这超出了本书的范围。幸运的是，默认值对于大多数用途已经足够，因此我们建议读者查阅参考手册（关于库的3.0版本）以了解特殊情况。在此说明之后，第一个参数scale大致控制返回的线条数量。输入图像会自动按此因子缩放。在较低分辨率下，检测到的线条较少。
- en: Note
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `cv::Ptr<>` type is a template class for wrapping pointers. This template
    is available in the 2.x API to facilitate automatic deallocation using reference
    counting. The `cv:: Ptr<>` type is analogous to `std::unique_ptr`.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv::Ptr<>`类型是一个用于包装指针的模板类。这个模板在2.x API中可用，以方便使用引用计数进行自动释放。`cv::Ptr<>`类型类似于`std::unique_ptr`。'
- en: Detection itself is accomplished with the method `LineSegmentDetector::detect(const
    InputArray _image, OutputArray _lines, OutputArray width=noArray(), OutputArray
    prec=noArray(), OutputArraynfa=noArray())`. The first parameter is the input image,
    while the `_lines` array will be filled with a (STL) vector of `Vec4i` objects
    that represent the (x, y) location of one end of the line followed by the location
    of the other end. The optional parameters `width`, `prec`, and `noArray` return
    additional information about the lines detected. The first one, `width`, contains
    the estimated line widths. Lines can be drawn with the convenient (yet simple)
    method called `LineSegmentDetector::drawSegments(InputOutputArray _image, InputArray
    lines)`. Lines will be drawn on top of the input, namely, `_image`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 检测本身是通过`LineSegmentDetector::detect(const InputArray _image, OutputArray _lines,
    OutputArray width=noArray(), OutputArray prec=noArray(), OutputArraynfa=noArray())`方法完成的。第一个参数是输入图像，而`_lines`数组将被填充为一个（STL）`Vec4i`对象的向量，该对象表示线条一端的（x,
    y）位置，然后是另一端的位置。可选参数`width`、`prec`和`noArray`返回有关检测到的线条的附加信息。第一个参数`width`包含估计的线条宽度。可以使用方便的（尽管简单）方法`LineSegmentDetector::drawSegments(InputOutputArray
    _image, InputArray lines)`绘制线条。线条将绘制在输入图像上，即`_image`。
- en: 'The following `lineSegmentDetector` example shows the detector in action:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下`lineSegmentDetector`示例显示了检测器的实际应用：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding example creates a window with the source image, which is loaded
    in grayscale, and shows the `drawSegments` method. However, it allows you to impose
    a segment length threshold and specify the line colors (`drawSegments` will draw
    all the lines in red). Besides, lines will be drawn with a thickness given by
    the widths estimated by the detector. A trackbar is associated with the main window
    to control the length of the threshold. The following screenshot shows an output
    of the example:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例创建了一个包含源图像的窗口，该图像以灰度加载，并显示了`drawSegments`方法。然而，它允许你施加段长度阈值并指定线条颜色（`drawSegments`将以红色绘制所有线条）。此外，线条将以检测器估计的宽度绘制。主窗口关联了一个滑块来控制阈值的长度。以下截图显示了示例的输出：
- en: '![Contours and connected components](img/00023.jpeg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![轮廓和连通组件](img/00023.jpeg)'
- en: Output of the lineSegmentDetector example
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 线段检测器示例输出
- en: Circles can be detected using the function `HoughCircles(InputArray image, OutputArray
    circles, int method, double dp, double minDist, double param1=100, double param2=100,
    intminRadius=0, int maxRadius=0)`. The first parameter is a grayscale input image.
    Output parameter circles will be filled with a vector of `Vec3f` objects. Each
    object represents the `(center_x, center_y, radius)` components of a circle. The
    last two parameters represent the minimum and maximum search radii, so they have
    an effect on the number of circles detected. OpenCV already contains a straightforward
    example of this function, `[opencv_source_code]/samples/cpp/houghcircles.cpp`.
    The example detects circles with a radius between 1 and 30 and displays them on
    top of the input image.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用函数 `HoughCircles(InputArray image, OutputArray circles, int method, double
    dp, double minDist, double param1=100, double param2=100, int minRadius=0, int
    maxRadius=0)` 来检测圆。第一个参数是一个灰度输入图像。输出参数 circles 将填充一个 `Vec3f` 对象的向量。每个对象代表一个圆的
    `(center_x, center_y, radius)` 组件。最后两个参数代表最小和最大搜索半径，因此它们会影响检测到的圆的数量。OpenCV 已经包含了这个函数的直接示例，`[opencv_source_code]/samples/cpp/houghcircles.cpp`。该示例检测半径在
    1 到 30 之间的圆，并将它们显示在输入图像上方。
- en: Segmentation algorithms typically form connected components, that is, the regions
    of connected pixels in a binary image. In the following section, we show how to
    obtain connected components and their contours from a binary image. Contours can
    be retrieved using the now classical function, `findContours`. Examples of this
    function are available in the reference manual (also see the `[opencv_source_code]/samples/cpp/contours2.cpp`
    and `[opencv_source_code]/samples/cpp/segment_objects.cpp` examples). Also note
    that in the 3.0 release of OpenCV (and in the code already available in the GitHub
    repository), the class `ShapeDistanceExtractor` allows you to compare the contours
    with the Shape Context descriptor (an example of this is available at `[opencv_source_code]/samples/cpp/shape_example.cpp`)
    and the Hausdorff distance. This class is in a new module of the library called
    `shape`. Shape transformations are also available through the class `ShapeTransformer`
    (example, `[opencv_source_code]/samples/cpp/shape_transformation.cpp`).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 分割算法通常形成连通组件，即在二值图像中的连接像素区域。在下一节中，我们将展示如何从二值图像中获取连通组件及其轮廓。轮廓可以通过现在经典的功能 `findContours`
    获取。该函数的示例可以在参考手册中找到（也请参阅 `[opencv_source_code]/samples/cpp/contours2.cpp` 和 `[opencv_source_code]/samples/cpp/segment_objects.cpp`
    示例）。此外，请注意，在 OpenCV 3.0 版本（以及在 GitHub 存储库中可用的代码）中，`ShapeDistanceExtractor` 类允许您将轮廓与形状上下文描述符（一个示例在
    `[opencv_source_code]/samples/cpp/shape_example.cpp`）和 Hausdorff 距离进行比较。这个类在库的新模块
    `shape` 中。形状变换也可以通过 `ShapeTransformer` 类（示例，`[opencv_source_code]/samples/cpp/shape_transformation.cpp`）进行。
- en: The new functions `connectedComponents` and `connectedComponentsWithStats` retrieve
    connected components. These functions will be part of the 3.0 release, and they
    are already available in the GitHub repository. An example of this is included
    in OpenCV that shows how to use the first one, `[opencv_source_code]/samples/cpp/connected_components.cpp`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 新的函数 `connectedComponents` 和 `connectedComponentsWithStats` 获取连通组件。这些函数将是 3.0
    版本的一部分，并且已经在 GitHub 存储库中可用。OpenCV 包含了一个示例，展示了如何使用第一个函数，`[opencv_source_code]/samples/cpp/connected_components.cpp`。
- en: Note
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The connected component that labels the functionality was actually removed in
    previous OpenCV 2.4.x versions and has now been added again.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，标记功能性的连通组件在之前的 OpenCV 2.4.x 版本中被移除，现在又重新添加。
- en: 'We provide another example (`connectedComponents`) that shows how to use the
    second function, `int connectedComponentsWithStats(InputArray image, OutputArray
    labels, OutputArray stats, OutputArray centroids, int connectivity=8, intltype=CV_32S)`,
    which provides useful statistics about each connected component. These statistics
    are accessed via `stats(label, column)` where the column can be the following
    table:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一个示例 (`connectedComponents`)，展示了如何使用第二个函数，`int connectedComponentsWithStats(InputArray
    image, OutputArray labels, OutputArray stats, OutputArray centroids, int connectivity=8,
    intltype=CV_32S)`，该函数提供了有关每个连通组件的有用统计信息。这些统计信息可以通过 `stats(label, column)` 访问，其中列可以是以下表格：
- en: '| `CC_STAT_LEFT ` | The leftmost (*x*) coordinate that is the inclusive start
    of the bounding box in the horizontal direction |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `CC_STAT_LEFT` | 在水平方向上，边界框的起始（x）坐标，即最左边的坐标 |'
- en: '| `CC_STAT_TOP ` | The topmost (y) coordinate that is the inclusive start of
    the bounding box in the vertical direction |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `CC_STAT_TOP` | 在垂直方向上，边界框的起始（y）坐标，即最顶部的坐标 |'
- en: '| `CC_STAT_WIDTH ` | The horizontal size of the bounding box |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| `CC_STAT_WIDTH ` | 矩形的水平尺寸 |'
- en: '| `CC_STAT_HEIGHT ` | The vertical size of the bounding box |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| `CC_STAT_HEIGHT ` | 矩形的垂直尺寸 |'
- en: '| `CC_STAT_AREA ` | The total area (in pixels) of the connected component |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| `CC_STAT_AREA ` | 连通组件的总面积（以像素为单位） |'
- en: 'The following is the code for the example:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为示例代码：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding example creates a window with an associated trackbar. The trackbar
    controls the threshold to apply to the source image. Inside the `on_trackbar`
    function, a call is made to `connectedComponentsWithStats` using the result of
    the thresholding. This is followed by two sections of the code. The first section
    fills the pixels that correspond to each connected component with a random color.
    The pixels that belong to each component are in `labelImage` (a `labelImage` output
    is also given by the function `connectedComponents`). The second part displays
    a text with the area of each component. This text is positioned at the centroid
    of each component. The following screenshot shows the output of the example:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的示例创建了一个带有相关滑块的窗口。滑块控制应用于源图像的阈值。在 `on_trackbar` 函数内部，使用阈值的结果调用 `connectedComponentsWithStats`。这之后是代码的两个部分。第一部分用随机颜色填充对应于每个连通组件的像素。属于每个组件的像素在
    `labelImage` 中（`labelImage` 输出也由 `connectedComponents` 函数提供）。第二部分显示每个组件的面积文本。此文本位于每个组件的重心上。以下截图显示了示例的输出：
- en: '![Contours and connected components](img/00024.jpeg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![轮廓和连通组件](img/00024.jpeg)'
- en: The output of the connectedComponents example
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 连通组件示例的输出
- en: Flood fill
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 洪水填充
- en: The flood fill operation fills the connected components with a given color.
    Starting from a seed point, the neighboring pixels are colored with a uniform
    color. The neighboring pixels can be within a specified range of the current pixel.
    The flood fill function is `int floodFill(InputOutputArray image, Point seedPoint,
    Scalar newVal, Rect* rect=0, Scalar loDiff=Scalar(), Scalar upDiff=Scalar(),int
    flags=4)`. The parameters `loDiff` and `upDiff` represent the range to check for
    every neighboring pixel (note that 3-channel difference thresholds can be specified).
    The parameter `newVal` is the color to apply to the pixels that are in range.
    The lower part of the parameter `flags` contains the pixel's connectivity value
    to use (`4` or `8`). The upper part defines the mode of the operation.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 洪水填充操作用给定的颜色填充连通组件。从种子点开始，相邻像素用统一颜色着色。相邻像素可以位于当前像素指定范围内。洪水填充函数为 `int floodFill(InputOutputArray
    image, Point seedPoint, Scalar newVal, Rect* rect=0, Scalar loDiff=Scalar(), Scalar
    upDiff=Scalar(),int flags=4)`。参数 `loDiff` 和 `upDiff` 表示检查每个相邻像素的范围（注意可以指定3通道的差异阈值）。参数
    `newVal` 是应用于范围内的像素的颜色。参数 `flags` 的较低部分包含要使用的像素连通性值（`4` 或 `8`）。较高部分定义了操作模式。
- en: Depending on this mode, the flood fill function will color a neighboring pixel
    in the input image if it is within the specified range (given by `loDiff` and
    `upDiff`) of either the current pixel or if the neighboring pixel is within the
    specified range of the original seed's value. The function can also be called
    with a mask image as the second parameter. If specified, the flood-filling operation
    will not go across non-zero pixels in the mask. Note that the mask should be a
    single-channel 8-bit image that is 2 pixels wider and 2 pixels taller than the
    input image.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 根据此模式，洪水填充函数将在输入图像中着色相邻像素，如果它位于当前像素或原始种子值的指定范围内（由 `loDiff` 和 `upDiff` 给出），或者如果相邻像素位于原始种子值的指定范围内。该函数还可以用掩码图像作为第二个参数调用。如果指定，则填充操作不会跨越掩码中的非零像素。请注意，掩码应是一个比输入图像宽2像素、高2像素的单通道8位图像。
- en: 'The upper bit of `flags` can be 0 or a combination of the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`flags` 的最高位可以是 0 或以下组合之一：'
- en: '`FLOODFILL_FIXED_RANGE`: If set, the difference between the current pixel and
    seed pixel is considered. Otherwise, the difference between neighbor pixels is
    considered.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FLOODFILL_FIXED_RANGE`: 如果设置，则考虑当前像素和种子像素之间的差异。否则，考虑相邻像素之间的差异。'
- en: '`FLOODFILL_MASK_ONLY`: If set, the function does not change the image (`newVal`
    is ignored) but fills the mask.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FLOODFILL_MASK_ONLY`: 如果设置，则函数不更改图像（忽略 `newVal`），但填充掩码。'
- en: 'In OpenCV''s flood fill example (`[opencv_source_code]/samples/cpp/ffilldemo.cpp`),
    the mask is used only as an output parameter. In our `floodFill` example, shown
    as the following code, we will use it as an input parameter in order to constrain
    the filling. The idea is to use the output of an edge detector as a mask. This
    should stop the filling process at the edges:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV的洪水填充示例（`[opencv_source_code]/samples/cpp/ffilldemo.cpp`）中，掩码仅用作输出参数。在我们的`floodFill`示例中，如下所示，我们将将其用作输入参数以限制填充。想法是使用边缘检测器的输出作为掩码。这应该在边缘处停止填充过程：
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding example reads and displays a color image and then creates four
    trackbars. The first two trackbars control `loDiff` and `upDiffvalues` for the
    `floodFill` function. The other two trackbars control the lower and upper threshold
    parameters for the Canny edge detector. In this example, the user can click anywhere
    on the input image. The click position will be used as a seed point to perform
    a flood fill operation. Actually, upon each click, two calls are made to the `floodFill`
    function. The first one simply fills a region using a random color. The second
    one uses a mask created from the output of the Canny edge detector. Note that
    the `copyMakeBorder` function is necessary to form a 1-pixel wide border around
    the mask. The following screenshot shows the output of this example:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例读取并显示一个彩色图像，然后创建四个滑块。前两个滑块控制`floodFill`函数的`loDiff`和`upDiff`值。其他两个滑块控制Canny边缘检测器的上下阈值参数。在这个示例中，用户可以在输入图像的任何地方点击。点击位置将被用作种子点以执行洪水填充操作。实际上，每次点击都会调用两次`floodFill`函数。第一个函数简单地使用随机颜色填充一个区域。第二个函数使用由Canny边缘检测器输出创建的掩码。请注意，`copyMakeBorder`函数是必要的，以便在掩码周围形成1像素宽的边界。以下截图显示了此示例的输出：
- en: '![Flood fill](img/00025.jpeg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![洪水填充](img/00025.jpeg)'
- en: Output of the floodFill example
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 洪水填充示例的输出
- en: Note that the output that uses Canny edges (right) has filled in less pixels
    than the standard operation (left).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，使用Canny边缘（右侧）的输出填充的像素比标准操作（左侧）少。
- en: Watershed segmentation
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流域分割
- en: Watershed is a segmentation method that is known for its efficiency. The method
    essentially starts from user-specified starting (seed) points from which regions
    grow. Assuming that good starting seeds can be provided, the resulting segmentations
    are useful for many purposes.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 流域分割是一种以其效率而闻名的分割方法。该方法本质上从用户指定的起始（种子）点开始，区域从这些点生长。假设可以提供良好的起始种子，则生成的分割对于许多用途都是有用的。
- en: Note
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more details and examples about the watershed transform for image segmentation,
    see [http://cmm.ensmp.fr/~beucher/wtshed.html](http://cmm.ensmp.fr/~beucher/wtshed.html).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 关于图像分割中流域变换的更多细节和示例，请参阅[http://cmm.ensmp.fr/~beucher/wtshed.html](http://cmm.ensmp.fr/~beucher/wtshed.html)。
- en: The function `watershed(InputArray image, InputOutputArray markers)` accepts
    a 3-channel input image and an image called `markers` with the seeds. The latter
    has to be a 32-bit single-channel image. Seeds may be specified in `markers` as
    connected components with positive values (0 cannot be used as a value for seeds).
    As an output argument, each pixel in `markers` will be set to a value of the seed
    components or `-1` at boundaries between the regions. OpenCV includes a watershed
    example (`[opencv_source_code]/samples/cpp/watershed.cpp`) in which the user has
    to draw the seed's regions.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`watershed(InputArray image, InputOutputArray markers)`接受一个3通道输入图像和一个带有种子的`markers`图像。后者必须是一个32位单通道图像。种子可以指定为`markers`中的正值连接组件（0不能用作种子的值）。作为输出参数，`markers`中的每个像素将被设置为种子组件的值或区域之间的边界处的`-1`。OpenCV包含一个流域示例（`[opencv_source_code]/samples/cpp/watershed.cpp`），其中用户需要绘制种子的区域。
- en: 'Obviously, the selection of the seed regions is important. Ideally, seeds will
    be selected automatically without user intervention. A typical use of watershed
    is to first threshold the image to separate the object from the background, apply
    the distance transform, and then use the local maxima of the distance transform
    image as seed points for segmentation. However, the first thresholding step is
    critical, as parts of the object may be considered as the background. In this
    case, the object seed region will be too small and segmentation will be poor.
    On the other hand, to perform a watershed segmentation, we need seeds for the
    background too. While we can use points over the corners of the image as seeds,
    this will not be sufficient. In this case, the background seed region is too small.
    If we use those seeds, the object region given by the segmentation will be generally
    much larger than the real object. In our following `watershed` example, a different
    approach is followed that produces better results:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，种子区域的选取很重要。理想情况下，种子应该自动选择，无需用户干预。水系分割的一个典型应用是首先对图像进行阈值处理，以将对象与背景分开，然后应用距离变换，最后使用距离变换图像的局部最大值作为分割的种子点。然而，第一个阈值步骤是关键的，因为对象的一部分可能被视为背景。在这种情况下，对象种子区域将太小，分割效果会较差。另一方面，为了执行水系分割，我们还需要背景的种子。虽然我们可以使用图像角落的点作为种子，但这将不足以满足需求。在这种情况下，背景种子区域太小。如果我们使用这些种子，分割得到的对象区域通常会比实际对象大得多。在我们接下来的
    `watershed` 示例中，采用了一种不同的方法，可以得到更好的结果：
- en: '[PRE5]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `Watershed` function in the preceding code performs three steps. First,
    a background seed region is obtained by performing a flood fill. The flood fill
    seed is the upper left corner of the image, that is, pixel (0, 0). Next, another
    flood fill is performed to obtain an object''s (hand in the sample image) seed
    region. The seed for this flood fill is taken as the center of the image. Then,
    a seed region image is formed by performing an `OR` operation between the previous
    two flood fill results. The resulting image is used as the seed image for the
    watershed operation. See the output of the example in the following screenshot
    where the seed image is shown at the center of the figure:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码中的 `Watershed` 函数执行了三个步骤。首先，通过执行淹没填充来获得背景种子区域。淹没填充的种子是图像的左上角，即像素 (0, 0)。接下来，执行另一个淹没填充来获得对象的（在示例图像中的手）种子区域。这个淹没填充的种子取为图像的中心。然后，通过执行前两个淹没填充结果的
    `OR` 操作来形成一个种子区域图像。这个结果图像被用作水系操作的种子图像。以下截图显示了种子图像位于图中心的输出示例：
- en: '![Watershed segmentation](img/00026.jpeg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![水系分割](img/00026.jpeg)'
- en: The output of the watershed example
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 水系分割示例的输出
- en: GrabCut
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GrabCut
- en: GrabCut is an excellent iterative background/foreground segmentation algorithm
    that is available since Version 2.1 of OpenCV. GrabCut is especially useful to
    separate objects from the background with minimal additional information (a bounding
    rectangle is sufficient in most cases). However, it is computationally intensive,
    and so it is only appropriate to segment still images.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: GrabCut 是自 OpenCV 2.1 版本以来可用的一种优秀的迭代背景/前景分割算法。GrabCut 特别适用于在最少额外信息（大多数情况下，一个边界矩形就足够了）的情况下将对象从背景中分离出来。然而，它计算量很大，因此仅适用于分割静态图像。
- en: Note
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: GrabCut is the underlying algorithm for the Background Removal tool in Microsoft
    Office 2010\. This algorithm was first proposed by researchers at Microsoft Research
    Cambridge. Starting with a user-provided bounding box of the object to segment,
    the algorithm estimates the color distributions of both the target object and
    the background. This estimate is further refined by minimizing an energy function
    in which connected regions that have the same label receive more weight.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: GrabCut 是 Microsoft Office 2010 中背景去除工具的底层算法。该算法最初由微软研究院剑桥的研究人员提出。该算法从用户提供的要分割的对象的边界框开始，估计目标对象和背景的颜色分布。这个估计通过最小化一个能量函数来进一步细化，其中具有相同标签的连接区域获得更多的权重。
- en: 'The main function is `grabCut(InputArray img, InputOutputArray mask, Rect rect,
    InputOutputArray bgdModel, InputOutputArray fgdModel, int iterCount, int mode=GC_EVAL)`.
    The parameters `bgdModel` and `fgdModel` are only used internally by the function
    (though they have to be declared). The `iterCount` variable is the number of iterations
    to be performed. In our experience, few iterations of the algorithm are required
    to produce good segmentations. The algorithm is aided by a bounding rectangle,
    a mask image, or both. The option chosen is indicated in the `mode` parameter,
    which can be `GC_INIT_WITH_RECT`, `GC_INIT_WITH_MASK`, or an `OR` combination
    of the two. In the former case, `rect` defines the rectangle. Pixels outside the
    rectangle are considered as the obvious background. In the latter case, the mask
    is an 8-bit image in which pixels may have the following values:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 主要功能是 `grabCut(InputArray img, InputOutputArray mask, Rect rect, InputOutputArray
    bgdModel, InputOutputArray fgdModel, int iterCount, int mode=GC_EVAL)`。参数 `bgdModel`
    和 `fgdModel` 仅由函数内部使用（尽管它们必须被声明）。`iterCount` 变量是要执行的迭代次数。根据我们的经验，算法的迭代次数很少就能产生良好的分割效果。算法由一个边界矩形、一个掩码图像或两者共同辅助。所选择的选项由
    `mode` 参数指示，可以是 `GC_INIT_WITH_RECT`、`GC_INIT_WITH_MASK` 或两者的 `OR` 组合。在前一种情况下，`rect`
    定义了矩形。矩形外的像素被视为明显的背景。在后一种情况下，掩码是一个 8 位图像，其中像素可能具有以下值：
- en: '`GC_BGD`: This defines an obvious background pixel'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GC_BGD`：这定义了一个明显的背景像素'
- en: '`GC_FGD`: This defines an obvious foreground (object) pixel'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GC_FGD`：这定义了一个明显的背景（对象）像素'
- en: '`GC_PR_BGD`: This defines a possible background pixel'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GC_PR_BGD`：这定义了一个可能的背景像素'
- en: '`GC_PR_FGD`: This defines a possible foreground pixel'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GC_PR_FGD`：这定义了一个可能的背景像素'
- en: The image mask is also the output image with the resulting segmentation, which
    is derived using those same previous values. OpenCV includes an example of GrabCut
    (`[opencv_source_code]/samples/cpp/grabcut.cpp`) in which the user can draw a
    bounding rectangle as well as foreground and background pixels.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图像掩码也是输出图像，其中包含使用那些相同的前值得到的分割结果。OpenCV 包含了一个 GrabCut 的示例（`[opencv_source_code]/samples/cpp/grabcut.cpp`），用户可以在其中绘制边界矩形以及前景和背景像素。
- en: 'The following `grabcut` example uses the algorithm with an initial bounding
    rectangle and then copies the resulting foreground onto another position in the
    same image:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的 `grabcut` 示例使用初始边界矩形算法，然后将结果前景复制到同一图像的另一个位置：
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The preceding example simply uses a fixed rectangle around the coin in the source
    image (see the fifth screenshot in this chapter) and performs the segmentation.
    The `result` image will contain values between 0 (`GC_BGD`) and 3 (`GC_PR_FGD`).
    The ensuing `AND` operation is needed to convert values other than `GC_FGD` to
    zero and thus get a binary foreground mask. Then, both the source image and the
    mask are translated by 50 pixels in the horizontal. An affine warping operation
    is used with an identity matrix in which only the x translation component is changed.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例简单地使用源图像中硬币周围的固定矩形（参见本章第五个截图）进行分割。`result` 图像将包含介于 0 (`GC_BGD`) 和 3 (`GC_PR_FGD`)
    之间的值。接下来的 `AND` 操作将非 `GC_FGD` 值转换为零，从而得到一个二值前景掩码。然后，源图像和掩码在水平方向上各移动 50 像素。使用一个仅改变
    x 平移组件的单位矩阵进行仿射变换操作。
- en: 'Finally, the translated image is copied onto the target image, using the (also
    translated) mask. Both source and target images are shown in the following screenshot.
    Increasing the number of iterations did not have any significant effect in this
    particular example:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将转换后的图像复制到目标图像上，使用（也转换过的）掩码。以下截图显示了源图像和目标图像。在这个特定示例中，增加迭代次数没有产生任何显著的影响：
- en: '![GrabCut](img/00027.jpeg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![GrabCut](img/00027.jpeg)'
- en: Source and target images in the GrabCut example
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: GrabCut 示例中的源图像和目标图像
- en: Summary
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter has covered one of the most important subjects in computer vision.
    Segmentation is often one of the first steps, and also, it is typically one of
    the trickiest. In this chapter, we have provided the reader with insight and samples
    to use the most useful segmentation methods in OpenCV, such as thresholding, contours
    and connected components, flood filling of regions, the watershed segmentation
    method, and the GrabCut method.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了计算机视觉中最重要的话题之一。分割通常是第一步，也是通常最棘手的一步。在本章中，我们向读者提供了洞察力和示例，以使用 OpenCV 中最有用的分割方法，例如阈值、轮廓和连通组件、区域填充、分水岭分割方法和
    GrabCut 方法。
- en: What else?
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有什么？
- en: The meanshift segmentation (the function `pyrMeanShiftFiltering`) has been omitted.
    OpenCV includes an example showing how to use this function (`[opencv_source_code]/samples/cpp/meanshift_segmentation.cpp`).This
    method is, however, relatively slow and tends to produce oversegmented results.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 均值漂移分割（函数`pyrMeanShiftFiltering`）已被省略。OpenCV 包含一个示例，展示了如何使用此函数（`[opencv_source_code]/samples/cpp/meanshift_segmentation.cpp`）。然而，这种方法相对较慢，并且倾向于产生过度分割的结果。
- en: Background/foreground segmentations can also be achieved using video, which
    will be covered in [Chapter 7](part0055_split_000.html#page "Chapter 7. What Is
    He Doing? Motion"), *What Is He Doing? Motion*.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 背景前景分割也可以通过视频实现，这将在第7章（[part0055_split_000.html#page "Chapter 7. What Is He
    Doing? Motion"](https://example.org/part0055_split_000.html#page "Chapter 7. What
    Is He Doing? Motion")）*他在做什么？运动*中介绍。
