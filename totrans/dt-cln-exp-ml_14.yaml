- en: '*Chapter 10*: Logistic Regression'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this and the next few chapters, we will explore models for classification.
    These involve targets with two or several class values, such as whether a student
    will pass a class or not or whether a customer will choose chicken, beef, or tofu
    at a restaurant with only these three choices. There are several machine learning
    algorithms for these kinds of classification problems. We will take a look at
    some of the most popular ones in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression has been used to build models with binary targets for decades.
    Traditionally, it has been used to generate estimates of the impact of an independent
    variable or variables on the odds of a dichotomous outcome. Since our focus is
    on prediction, rather than the effect of each feature, we will also explore regularization
    techniques, such as lasso regression. These techniques can improve the accuracy
    of our classification predictions. We will also examine strategies for predicting
    a multiclass target (when there are more than two possible target values).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Key concepts of logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary classification with logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regularization with logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multinomial logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will stick to the libraries that are available in most
    scientific distributions of Python: pandas, NumPy, and scikit-learn. All the code
    in this chapter will run fine with scikit-learn versions 0.24.2 and 1.0.2.'
  prefs: []
  type: TYPE_NORMAL
- en: Key concepts of logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are familiar with linear regression, or read [*Chapter 7*](B17978_07_ePub.xhtml#_idTextAnchor091),
    *Linear Regression Models*, of this book, you have probably anticipated some of
    the issues we will discuss in this chapter – regularization, linearity among regressors,
    and normally distributed residuals. If you have built supervised machine learning
    models in the past or worked through the last few chapters of this book, then
    you have also likely anticipated that we will spend some time discussing the bias-variance
    tradeoff and how that influences our choice of model.
  prefs: []
  type: TYPE_NORMAL
- en: I remember being introduced to logistic regression 35 years ago in a college
    course. It is often presented in undergraduate texts almost as a special case
    of linear regression; that is, linear regression with a binary dependent variable
    coupled with some transformation to keep predictions between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: It does share many similarities with linear regression of a numeric target variable.
    Logistic regression is relatively easy to train and interpret. Optimization techniques
    for both linear and logistic regression are efficient and can generate low bias
    predictors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also like linear regression, logistic regression predicts a target based on
    weights assigned to each feature. But to constrain the predicted probability to
    between 0 and 1, we use the sigmoid function. This function takes any value and
    maps it to a value between 0 and 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As *x* approaches infinity, ![](img/B17978_10_002.png) gets closer to 1\. As
    *x* approaches negative infinity, ![](img/B17978_10_003.png) gets closer to 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot illustrates a sigmoid function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Sigmoid function ](img/B17978_10_0011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Sigmoid function
  prefs: []
  type: TYPE_NORMAL
- en: 'We can plug the familiar equation for linear regression, ![](img/B17978_10_004.png),
    into the sigmoid function to predict the probability of class membership:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here ![](img/B17978_10_006.png) is the predicted probability of class membership
    in the binary case. The coefficients (the betas) can be converted into odds ratios
    for interpretation, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *r* is the odds ratio and β is the coefficient. A 1-unit increase in the
    value of a feature multiplies the odds of class membership by ![](img/B17978_10_008.png).
    Similarly, for a binary feature, a true value has ![](img/B17978_10_009.png) times
    the odds of class membership as does a false value for that feature, all else
    being equal.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression has several advantages as an algorithm for classification
    problems. Features can be dichotomous, categorical, or numeric, and do not need
    to be normally distributed. The target variable can have more than two possible
    values, as we will discuss later, and it can be nominal or ordinal. Another key
    advantage is that the relationship between features and the target is not assumed
    to be linear.
  prefs: []
  type: TYPE_NORMAL
- en: The nomenclature here is a tad confusing. Why are we using a regression algorithm
    for a classification problem? Well, logistic regression predicts the probability
    of class membership. We apply a decision rule to those probabilities to predict
    membership. The default threshold is often 0.5 with binary targets. Instances
    with predicted probabilities greater than or equal to 0.5 get a positive class
    or 1 or True; those less than 0.5 are assigned 0 or False.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression extensions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will consider two key extensions of logistic regression in this chapter.
    We will explore multiclass models – that is, those where the target has more than
    two values. We will also examine the regularization of logistic models to improve
    (lessen) variance.
  prefs: []
  type: TYPE_NORMAL
- en: 'A popular choice when constructing multiclass models is **multinomial logistic
    regression** (**MLR**). With MLR, the prediction probability distribution is a
    multinomial probability distribution. We can replace the equation we used for
    the binary classifier with a softmax function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/B17978_10_011.png). This calculates a probability for each class
    label, *j*, where *k* is the number of classes.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative to multinomial logistic regression when we have more than two
    classes is **one-versus-rest** (**OVR**) logistic regression. This extension to
    logistic regression turns the multiclass problem into a binary problem, estimating
    the probability of class membership versus membership in all of the other classes.
    The key assumption here is that membership in each class is independent. We will
    use MLR in an example in this chapter. One advantage it has over OVR is that the
    predicted probabilities are more reliable.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, logistic regression has some of the same challenges
    as linear regression, including that the low bias of our predictions comes with
    high variance. This is more likely to be a problem when several features are highly
    correlated. Fortunately, we can deal with this with regularization, just as we
    saw in [*Chapter 7*](B17978_07_ePub.xhtml#_idTextAnchor091), *Linear Regression
    Models*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regularization adds a penalty to the loss function. We still seek to minimize
    the error, but also constrain the size of our parameters. **L1** regularization,
    also referred to as lasso regression, penalizes the absolute value of the weights
    (or coefficients):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *p* is the number of features and λ determines the strength of the regularization.
    **L2** regularization, also referred to as ridge regression, penalizes the squared
    values of the weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Both L1 and L2 regularization push the weights toward 0, though L1 regularization
    is more likely to lead to sparse models. In scikit-learn, we use the *C* parameter
    to adjust the value of λ, where *C* is just the inverse of λ:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We can get a balance between L1 and L2 with elastic net regression. With elastic
    net regression, we adjust the L1 ratio. A value of 0.5 uses L1 and L2 equally.
    We can use hyperparameter tuning to choose the best value for the L1 ratio.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization can result in a model with lower variance, which is a good tradeoff
    when we are less concerned about our coefficients than we are with our predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Before building a model with regularization, we will construct a fairly straightforward
    logistic model with a binary target. We will also spend a good amount of time
    evaluating that model. This will be the first classification model we will build
    in this book and model evaluation looks very different for those models than it
    does for regression models.
  prefs: []
  type: TYPE_NORMAL
- en: Binary classification with logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression is often used to model health outcomes when the target is
    binary, such as whether the person gets a disease or not. We will go through an
    example of that in this section. We will build a model to predict if an individual
    will have heart disease based on personal characteristics such as smoking and
    alcohol drinking habits; health features, including BMI, asthma, diabetes, and
    skin cancer; and age.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will work exclusively with data on heart disease that’s
    available for public download at [https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease](https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease).
    This dataset is derived from the United States Center for Disease Control data
    on more than 400,000 individuals from 2020\. Data columns include whether respondents
    ever had heart disease, body mass index, ever smoked, heavy alcohol drinking,
    age, diabetes, and kidney disease. We will work with a 30,000 individual sample
    in this section to speed up the processing, but the full dataset is available
    in the same folder in this book’s GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also do a little more preprocessing in this chapter than we have in
    previous chapters. We will integrate much of this work with our pipeline. This
    will make it easier to reuse this code in the future and lessens the likelihood
    of data leakage. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by importing the same libraries we have worked with in the last
    few chapters. We will also import the `LogisticRegression` and `metrics` modules.
    We will use the `metrics` module from scikit-learn to evaluate each of our classification
    models in this part of this book. In addition to `matplotlib` for visualizations,
    we will also use `seaborn`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We are also going to need several custom classes to handle the preprocessing.
    We have already seen the `OutlierTrans` class. Here, we have added a couple of
    new classes – `MakeOrdinal` and `ReplaceVals`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `MakeOrdinal` class takes a character feature and assigns numeric values
    based on an alphanumeric sort. For example, a feature that has three possible
    values – not well, okay, and well – would be transformed into an ordinal feature
    with values of 0, 1, and 2, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that scikit-learn pipeline transformers must have `fit` and `transform`
    methods, and must inherit from `BaseEstimator`. They often also inherit from `TransformerMixin`,
    though there are other options.
  prefs: []
  type: TYPE_NORMAL
- en: 'All the action in the `MakeOrdinal` class happens in the `transform` method.
    We loop over all of the columns that are passed to it by the column transformer.
    For each column, we find all the unique values and sort them alphanumerically,
    storing the unique values in a NumPy array that we name `cats`. Then, we use a
    lambda function and NumPy’s `where` method to find the index of `cats` associated
    with each feature value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`MakeOrdinal` will work fine when the alphanumeric order matches a meaningful
    order, as with the previous example. When that is not true, we can use `ReplaceVals`
    to assign appropriate ordinal values. This class replaces values in any feature
    with alternative values based on a dictionary passed to it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We could have just used the pandas `replace` method without putting it in a
    pipeline, but this way, it is easier to integrate our recoding with other pipeline
    steps, such as feature scaling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Do not worry if you do not fully understand how we will use these classes yet.
    It will be clearer when we add them to our column transformations.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will load the heart disease data and take a look at a few rows. Several
    string features are conceptually binary, such as `alcoholdrinkingheavy`, which
    is `Yes` when the person is a heavy drinker and `No` otherwise. We will need to
    encode these features before running a model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `agecategory` feature is character data that represents the age interval.
    We will need to convert that feature into numeric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at the size of the DataFrame and how many missing values we have.
    There are 30,000 instances, but there are no missings for any of the 18 data columns.
    That’s great. We won’t have to worry about that when we construct our pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s change the `heartdisease` variable, which will be our target, into a
    `0` and `1` variable. This will give us one less thing to worry about later. One
    thing to notice right away is that the target’s values are quite imbalanced. Less
    than 10% of our observations have heart disease. That, of course, is good news,
    but it presents some challenges for modeling that we will need to handle:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We should organize our features by the preprocessing we will be doing with them.
    We will be scaling the numeric features and doing one-hot encoding with the categorical
    features. We want to make the `agecategory` and `genhealth` features, which are
    currently strings, into ordinal features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We need to do a specific cleanup of the `diabetic` feature. Some individuals
    indicate no, but that they were borderline. For our purposes, we will consider
    them a *no*. Some individuals had diabetes during their pregnancies only. We will
    consider them a *yes*. For both `genhealth` and `diabetic`, we will set up a dictionary
    that will indicate how feature values should be replaced. We will use that dictionary
    in the `ReplaceVals` transformer of our pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We should take a look at some frequencies for the binary features, as well
    as other categorical features. A large percentage of the individuals (42%) report
    that they have been smokers. 14% report that they have difficulty walking:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s also look at frequencies for the other categorical features. There are
    nearly equal numbers of men and women. Most people report excellent or very good
    health:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We should also look at some descriptive statistics for the numerical features. The
    median value for both bad physical health and mental health days is 0; that is,
    at least half of the observations report no bad physical health days, and at least
    half report no bad mental health days over the previous month:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will need to do some scaling. We will also need to do some encoding of the
    categorical features. There are also some extreme values for the numerical features.
    A `sleeptimenightly` value of 24 seems unlikely! It is probably a good idea to
    deal with them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are ready to build our pipeline. Let’s create the training and testing
    DataFrames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we will set up the column transformations. We will create a one-hot encoder
    instance that we will use for all of the categorical features. For the numeric
    columns, we will remove extreme values using the `OutlierTrans` object and then
    impute the median.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will convert the `agecategory` feature into an ordinal one using the `MakeOrdinal`
    transformer and code the `genhealth` and `diabetic` features using the `ReplaceVals`
    transformer.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will add the column transformation to our pipeline in the next step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Now, we are ready to set up and fit our pipeline. First, we will instantiate
    logistic regression and stratified k-fold objects, which we will use with recursive
    feature elimination. Recall that recursive feature elimination needs an estimator.
    We use stratified k-fold to get approximately the same target value distribution
    in each fold.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we must create another logistic regression instance for our model. We
    will set the `class_weight` parameter to `balanced`. This should improve the model’s
    ability to deal with the class imbalance. Then, we will add the column transformation,
    recursive feature elimination, and logistic regression instance to our pipeline,
    and then fit it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to do a little work to recover the column names from the pipeline after
    the fit. We can use the `get_feature_names` method of the one-hot encoder for
    the `bin` transformer and the `cat` transformer for this. This gives us the column
    names for the binary and categorical features after the encoding. The names of
    the numerical features remain unchanged. We will use the feature names later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, let’s look at the results from the recursive feature elimination. We can
    use the `ranking_` attribute of the `rfecv` object to get the ranking of each
    feature. Those with a *1* for ranking will be selected for our model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If we use the `get_support` method or the `support_` attribute of the `rfecv`
    object instead of the `ranking_` attribute, we get just those features that will
    be used in our model – that is, those with a ranking of 1\. We will do that in
    the next step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We can get the odds ratios from the coefficients from the logistic regression. Recall
    that the odds ratio is the exponentiated coefficient. There are 13 coefficients,
    which makes sense because we learned in the previous step that 13 features got
    a ranking of 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will use the `get_support` method of the `rfecv` step to get the names of
    the selected features and create a NumPy array with those names and the odds ratios,
    `oddswithlabs`. We then create a pandas DataFrame and sort by the odds ratio in
    descending order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Not surprisingly, those who had a stroke and older individuals are substantially
    more likely to have heart disease. If the individual had a stroke, they had three
    times the odds of having heart disease, controlling for everything else. The odds
    of having heart disease increase by 2.88 times for each increase in age category.
    On the other hand, the odds of having heart disease decline by about half (57%)
    for every increase in general health; from, say, fair to good. Surprisingly, heavy
    alcohol drinking is associated with lower odds of heart disease, controlling for
    everything else:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have fit our logistic regression model, we are ready to evaluate
    it. In the next section, we will spend some time looking into various performance
    measures, including accuracy and sensitivity. We will use many of the concepts
    that we introduced in [*Chapter 6*](B17978_06_ePub.xhtml#_idTextAnchor078), *Preparing
    for Model Evaluation*.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating a logistic regression model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most intuitive measure of a classification model’s performance is its accuracy
    – that is, how often our predictions are correct. In some cases, however, we might
    be at least as concerned about sensitivity – the percent of positive cases that
    we predict correctly – as accuracy; we may even be willing to lose a little accuracy
    to improve sensitivity. Predictive models of diseases often fall into that category.
    But whenever there is a class imbalance, measures such as accuracy and sensitivity
    can give us very different estimates of the performance of our model.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to being concerned about accuracy or sensitivity, we might be worried
    about our model’s **specificity** or **precision**. We may want a model that can
    identify negative cases with high reliability, even if that means it does not
    do as good a job of identifying positives. Specificity is a measure of the percentage
    of all negatives identified by the model.
  prefs: []
  type: TYPE_NORMAL
- en: Precision, which is the percentage of predicted positives that are positives,
    is another important measure. For some applications, it is important to limit
    false positives, even if we have to tolerate lower sensitivity. An apple grower,
    using image recognition to identify bad apples, may prefer a high-precision model
    to a more sensitive one, not wanting to discard apples unnecessarily.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be made more clear by looking at a confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Confusion matrix of actual by predicted values for a binary
    target ](img/B17978_10_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – Confusion matrix of actual by predicted values for a binary target
  prefs: []
  type: TYPE_NORMAL
- en: 'The confusion matrix helps us conceptualize accuracy, sensitivity, specificity,
    and precision. Accuracy is the percentage of observations for which our prediction
    was correct. This can be stated more precisely as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Sensitivity is the number of times we predicted positives correctly divided
    by the number of positives. It might be helpful to glance at the confusion matrix
    again and confirm that actual positive values can either be predicted positives
    (TP) or predicted negatives (FN). Sensitivity is also referred to as **recall**
    or the **true positive rate**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Specificity is the number of times we correctly predicted a negative value
    (TN) divided by the number of actual negative values (TN + FP). Specificity is
    also known as the **true negative rate**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Precision is the number of times we correctly predicted a positive value (TP)
    divided by the number of positive values predicted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We went over these concepts in more detail in [*Chapter 6*](B17978_06_ePub.xhtml#_idTextAnchor078),
    *Preparing for* *Model Evaluation*. In this section, we will examine the accuracy,
    sensitivity, specificity, and precision of our logistic regression model of heart
    disease:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `predict` method of the pipeline we fitted in the previous section
    to generate predictions from our logistic regression. Then, we can generate a
    confusion matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This produces the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – A confusion matrix for heart disease prediction ](img/B17978_10_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – A confusion matrix for heart disease prediction
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to notice here is that most of the action is in the top-left
    quadrant, where we correctly predict actual negative values in the testing data.
    That is going to help our accuracy a fair bit. Nonetheless, we have a fair number
    of false positives. We predict heart disease 1,430 times (out of 5,506 negative
    instances) when there is no heart disease. We do seem to do an okay job of identifying
    positive heart disease instances, correctly classifying 392 instances (out of
    494) that were positive.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s calculate the accuracy, sensitivity, specificity, and precision. The
    overall accuracy is not great, at 74%. Sensitivity is pretty decent though, at
    79%. (Of course, how *decent* the sensitivity is depends on the domain and judgment.
    For something such as heart disease, we likely want it to be higher.) This can
    be seen in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can do these calculations in a more straightforward way using the `metrics`
    module (I chose a more roundabout approach in the previous step to illustrate
    how the calculations are done):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The biggest problem with our model is the very low level of precision – that
    is, 22%. This is due to the large number of false positives. The majority of the
    time that our model predicts positive, it is wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the four measures that we have already calculated, it can also
    be helpful to get the false positive rate. The false positive rate is the propensity
    of our model to predict positive when the actual value is negative:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17978_10_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s calculate the false positive rate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So, 26% of the time that a person does not have heart disease, we predicted
    that they do. While we certainly want to limit the number of false positives,
    this often means sacrificing some sensitivity. We will demonstrate why this is
    true later in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should take a closer look at the prediction probabilities generated by our
    model. Here, the threshold for a positive class prediction is 0.5, which is often
    the default with logistic regression. (Recall that logistic regression predicts
    a probability of class membership. We need an accompanying decision rule, such
    as the 0.5 threshold, to predict the class.) This can be seen in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can use a **kernel density estimate** (**KDE**) plot to visualize these
    probabilities. We can also see how a different decision rule may impact our predictions.
    For example, we could move the threshold from 0.5 to 0.25\. At a glance, that
    has some advantages. The area between the two possible thresholds has somewhat
    more heart disease cases than no heart disease cases. We would be getting the
    brown area between the dashed lines right, predicting heart disease correctly
    where we would not have with the 0.5 threshold. That is a larger area than the
    green area between the lines, where we turn some of the true negative predictions
    at the 0.5 threshold into false positives at the 0.25 threshold:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This generates the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Heart disease predicted probability distribution ](img/B17978_10_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – Heart disease predicted probability distribution
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider the tradeoff between precision and sensitivity a little more
    carefully than we have so far. Remember that precision is the rate at which we
    are right when we predict a positive class value. Sensitivity, also referred to
    as recall or the true positive rate, is the rate at which we identify an actual
    positive as positive.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can plot precision and sensitivity curves as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This generates the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Precision and sensitivity at threshold values ](img/B17978_10_0051.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.5 – Precision and sensitivity at threshold values
  prefs: []
  type: TYPE_NORMAL
- en: As the threshold increases beyond 0.2, there is a sharper decrease in sensitivity
    than there is an increase in precision.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is often also helpful to look at the false positive rate with the sensitivity
    rate. The false positive rate is the propensity of our model to predict positive
    when the actual value is negative. One way to see that relationship is with a
    ROC curve:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This produces the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6 – ROC curve ](img/B17978_10_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – ROC curve
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that increasing the false positive rate buys us less increase
    in sensitivity the higher the false positive rate is. Beyond a false positive
    rate of 0.5, there is not much payoff at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'It may also be helpful to just plot the false positive rate and sensitivity
    by threshold:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This produces the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Sensitivity and false positive rate ](img/B17978_10_0071.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.7 – Sensitivity and false positive rate
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that as we lower the threshold below 0.25, the false positive
    rate increases more rapidly than sensitivity.
  prefs: []
  type: TYPE_NORMAL
- en: These last two visualizations hint at the possibility of finding an optimal
    threshold value – that is, one with the best tradeoff between sensitivity and
    the false positive rate; at least mathematically, ignoring domain knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will calculate the `argmax` function. We want the value of the threshold
    at that index. The optimal threshold according to this calculation is 0.46, which
    isn’t very different from the default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can redo the confusion matrix based on this alternative threshold:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This produces the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Confusion matrix of heart disease prediction  ](img/B17978_10_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.8 – Confusion matrix of heart disease prediction
  prefs: []
  type: TYPE_NORMAL
- en: 'This gives us a small improvement in sensitivity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The point here is not that we should change thresholds willy-nilly. This is
    often a bad idea. But we should keep two points in mind. First, when we have a
    highly imbalanced class, a 0.5 threshold may not make sense. Second, this is an
    important place to lean on domain knowledge. For some classification problems,
    a false positive is substantially less important than a false negative.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we focused on sensitivity, precision, and false positive rate
    as measures of model performance. That is partly because of space limitations,
    but also because of the issues with this particular target – imbalance classes
    and the likely preference for sensitivity. We will be emphasizing other measures,
    such as accuracy and specificity, in other models that we will be building in
    the next few chapters. In the rest of this chapter, we will look at a couple of
    extensions of logistic regression, regularization and multinomial logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization with logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you have already worked your way through [*Chapter 7*](B17978_07_ePub.xhtml#_idTextAnchor091),
    *Linear Regression Models*, and read the first section of this chapter, you already
    have a good idea of how regularization works. We add a penalty to the estimator
    that minimizes our parameter estimates. The size of that penalty is typically
    tuned based on a measure of model performance. We will work through that in this
    section. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will load the same modules that we worked with in the previous section,
    plus the modules we will need for the necessary hyperparameter tuning. We will
    use `RandomizedSearchCV` and `uniform` to find the best value for our penalty
    strength:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will load the heart disease data and do a little processing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will organize our features to facilitate the column transformation
    we will do in a couple of steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we must create testing and training DataFrames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we must set up the column transformations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, we are ready to run our model. We will instantiate logistic regression
    and repeated stratified k-fold objects. Then, we will create a pipeline with our
    column transformation from the previous step and the logistic regression.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After that, we will create a list of dictionaries for our hyperparameters, rather
    than just one dictionary, as we have done previously in this book. This is because
    not all hyperparameters work together. For example, we cannot use an L1 penalty
    with a `newton-cg` solver. The `logisticregression__` (note the double underscore)
    prefix to the dictionary key names indicates that we want the values to be passed
    to the logistic regression step of our pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will set the `n_iter` parameter to `20` for our randomized grid search to
    get it to sample hyperparameters 20 times. Each of those times, the grid search
    will select from the hyperparameters listed in one of the dictionaries. We will
    indicate that we want the grid search scoring to be based on the area under the
    ROC curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'After fitting the search, the `best_params` attribute gives us the parameters
    associated with the highest score. Elastic net regression, with an L1 ratio closer
    to L1 than to L2, performs the best:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Let’s look at some of the other top scores from the grid search. The best three
    models have pretty much the same score. One uses elastic net regression, another
    L1, and another L2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `cv_results_` dictionary of the grid search provides us with lots of information
    about the 20 models that were tried. The `params` list in that dictionary has
    a somewhat complicated structure because some keys are not present for some iterations,
    such as `L1_ratio`. We can use `json_normalize` to flatten the structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take a look at the confusion matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This generates the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.9 – Confusion matrix of heart disease prediction ](img/B17978_10_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.9 – Confusion matrix of heart disease prediction
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s also look at some metrics. Our scores are largely unchanged from our
    model without regularization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Even though regularization provided no obvious improvement in the performance
    of our model, there are many times when it does. It is also not as necessary to
    worry about feature selection when using L1 regularization, as the weights for
    less important features will be 0.
  prefs: []
  type: TYPE_NORMAL
- en: We still haven’t dealt with how to handle models where the target has more than
    two possible values, though almost all the discussion in the last two sections
    applies to multiclass models as well. In the next section, we will learn how to
    use multinomial logistic regression to model multiclass targets.
  prefs: []
  type: TYPE_NORMAL
- en: Multinomial logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression would not be as useful if it only worked for binary classification
    problems. Fortunately, we can use multinomial logistic regression when our target
    has more than two values.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will work with data on machine failures as a function of
    air and process temperature, torque, and rotational speed.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: This dataset on machine failure is available for public use at [https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification](https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification).
    There are 10,000 observations, 12 features, and two possible targets. One is binary
    – that is, the machine failed or didn’t. The other has types of failure. The instances
    in this dataset are synthetic, generated by a process designed to mimic machine
    failure rates and causes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s learn how to use multinomial logistic regression to model machine failure:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will import the now-familiar libraries. We will also import `cross_validate`,
    which we first used in [*Chapter 6*](B17978_06_ePub.xhtml#_idTextAnchor078), *Preparing
    for* *Model Evaluation*, to help us evaluate our model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will load the machine failure data and take a look at its structure. We
    do not have any missing data. That’s great news:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s look at a few rows. `machinetype` has values of `L`, `M`, and `H`. These
    values are proxies for machines of low, medium, and high quality, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should also generate some frequencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s collapse the `failtype` values and create numeric code for them. We will
    combine random failures and tool wear failures since the counts are so low for
    random failures:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should confirm that `failtypecode` does what we intended:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s also get some descriptive statistics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s create the testing and training DataFrames. We will also set up
    the column transformations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s set up a pipeline with our column transformations and our multinomial
    logistic regression model We just need to set the `multi_class` attribute to multinomial
    when we instantiate the logistic regression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can generate a confusion matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This produces the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.10 – Confusion matrix of predicted machine failure types ](img/B17978_10_0101.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.10 – Confusion matrix of predicted machine failure types
  prefs: []
  type: TYPE_NORMAL
- en: The confusion matrix shows that our model does not do a good job of predicting
    the failure type when there is a failure, particularly with power failures or
    other failures.
  prefs: []
  type: TYPE_NORMAL
- en: We can use `cross_validate` to evaluate this model. We mainly get excellent
    scores for accuracy, precision, and sensitivity (recall). However, this is misleading.
    The weighted scores when the classes are so imbalanced (almost all of the instances
    have `no failure`) are very heavily influenced by the class that contains almost
    all of the values. Our model gets `no failure` correct reliably.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we look at the `f1_macro` score (recall from [*Chapter 6*](B17978_06_ePub.xhtml#_idTextAnchor078),
    *Preparing for* *Model Evaluation*, that `f1` is the harmonic mean of precision
    and sensitivity), we will see that our model does not do very well for classes
    other than the `no failure` class. (The `macro` score is just a simple average.)
  prefs: []
  type: TYPE_NORMAL
- en: 'We could have just used a classification report here, as we did in [*Chapter
    6*](B17978_06_ePub.xhtml#_idTextAnchor078), *Preparing for* *Model Evaluation*,
    but I sometimes find it helpful to generate the stats I need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we explored how to construct a multinomial logistic regression
    model. This approach works regardless of whether the target is nominal or ordinal.
    In this case, it was nominal. We also saw how we can extend the model evaluation
    approaches we used for logistic regression with a binary target. We reviewed how
    to interpret the confusion matrix and scoring metrics when we have more than two
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression has been a go-to tool for me for many, many years when I
    have needed to predict a categorical target. It is an efficient algorithm with
    low bias. Some of its disadvantages, such as high variance and difficulty handling
    highly correlated predictors, can be addressed with regularization and feature
    selection. We went over examples of doing that in this chapter. We also examined
    how to handle imbalanced classes in terms of what such targets mean for modeling
    and interpretation of results.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at a very popular alternative to logistic
    regression for classification – decision trees. We will see that decision trees
    have many advantages that make them a particularly good option if we need to model
    complexity, without having to worry as much about how our features are specified
    as we do with logistic regression.
  prefs: []
  type: TYPE_NORMAL
