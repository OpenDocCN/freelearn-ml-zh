["```py\nimport numpy as np\n```", "```py\nfrom hyperopt import hp\n```", "```py\nhyperparameter_space = {\n```", "```py\n“criterion”: hp.choice(“criterion”, [“gini”, “entropy”]),\n```", "```py\n“n_estimators”: 5 + hp.randint(“n_estimators”, 195),\n```", "```py\n“min_samples_split” : hp.loguniform(“min_samples_split”, np.log(0.0001), np.log(0.5))\n```", "```py\n}\n```", "```py\nhyperparameter_space =\n```", "```py\nhp.choice(“class_weight_type”, [\n```", "```py\n{“class_weight”: None,\n```", "```py\n“n_estimators”: 5 + hp.randint(“none_n_estimators”, 45),\n```", "```py\n},\n```", "```py\n{“class_weight”: “balanced”,\n```", "```py\n“n_estimators”: 5 + hp.randint(“balanced_n_estimators”, 195),\n```", "```py\n}\n```", "```py\n])\n```", "```py\n    import numpy as np\n    from sklearn.base import clone\n    from sklearn.model_selection import cross_val_score\n    from hyperopt import STATUS_OK\n    def objective(space):\n        estimator_clone = clone(pipe).set_params(**space)\n        return {‘loss’: -1 * np.mean(cross_val_score(estimator_clone, X_train_full, y_train, cv=5, scoring=’f1’, n_jobs=-1)), \n                ‘status’: STATUS_OK}\n    ```", "```py\n    from hyperopt import hp\n    hyperparameter_space = { \n    “model__n_estimators”: 5 + hp.randint(“n_estimators”, 195), \n    “model__criterion”: hp.choice(“criterion”, [“gini”, “entropy”]),\n    “model__class_weight”: hp.choice(“class_weight”, [“balanced”,”balanced_subsample”]),\n    “model__min_samples_split”: hp.loguniform(“min_samples_split”, np.log(0.0001), np.log(0.5))\n    }\n    ```", "```py\n    from hyperopt import Trials\n    trials = Trials()\n    ```", "```py\n    from hyperopt import fmin, rand\n    best = fmin(objective,\n                space=hyperparameter_space,\n                algo=rand.suggest,\n                max_evals=100,\n                rstate=np.random.default_rng(0),\n                trials=trials\n               )\n    print(best)\n    ```", "```py\n{‘class_weight’: 0, ‘criterion’: 1, ‘min_samples_split’: 0.00047017001935242104, ‘n_estimators’: 186}\n```", "```py\n    pipe = pipe.set_params(**{‘model__class_weight’: “balanced”,\n    ‘model__criterion’: “entropy”,\n    ‘model__min_samples_split’: 0.00047017001935242104,\n    ‘model__n_estimators’: 186})\n    pipe.fit(X_train_full,y_train)\n    ```", "```py\n    from sklearn.metrics import f1_score\n    y_pred = pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    from hyperopt import plotting\n    ```", "```py\nplotting.main_plot_history(trials)\n```", "```py\nplotting.main_plot_histogram(trials)\n```", "```py\nPlotting.main_plot_vars(trials)\n```", "```py\nfrom hyperopt import fmin, tpe\n```", "```py\nbest = fmin(objective, \n```", "```py\n            space=hyperparameter_space, \n```", "```py\n            algo=tpe.suggest, \n```", "```py\n            max_evals=100, \n```", "```py\n            rstate=np.random.default_rng(0), \n```", "```py\n            trials=trials \n```", "```py\n           )\n```", "```py\nprint(best)\n```", "```py\n{‘class_weight’: 1, ‘criterion’: 1, ‘min_samples_split’: 0.0005245304932726025, ‘n_estimators’: 138}\n```", "```py\nfrom hyperopt import fmin, atpe\n```", "```py\nbest = fmin(objective, \n```", "```py\n            space=hyperparameter_space, \n```", "```py\n            algo=atpe.suggest, \n```", "```py\n            max_evals=100, \n```", "```py\n            rstate=np.random.default_rng(0), \n```", "```py\n            trials=trials \n```", "```py\n           )\n```", "```py\nprint(best)\n```", "```py\n{‘class_weight’: 1, ‘criterion’: 1, ‘min_samples_split’: 0.0005096354197481012, ‘n_estimators’: 157}\n```", "```py\nfrom hyperopt import fmin, anneal\n```", "```py\nbest = fmin(objective, \n```", "```py\n            space=hyperparameter_space, \n```", "```py\n            algo=anneal.suggest, \n```", "```py\n            max_evals=100, \n```", "```py\n            rstate=np.random.default_rng(0), \n```", "```py\n            trials=trials \n```", "```py\n           )\n```", "```py\nprint(best)\n```", "```py\n{‘class_weight’: 1, ‘criterion’: 1, ‘min_samples_split’: 0.00046660708302994583, ‘n_estimators’: 189}\n```", "```py\n    plotting_data = np.array([[x[‘result’][‘loss’],\n    x[‘misc’][‘vals’][‘class_weight’][0],\n    x[‘misc’][‘vals’][‘criterion’][0],\n    x[‘misc’][‘vals’][‘min_samples_split’][0],\n    x[‘misc’][‘vals’][‘n_estimators’][0],\n    ] for x in trials.trials])\n    ```", "```py\n    import pandas as pd\n    plotting_data = pd.DataFrame(plotting_data,\n    columns=[‘score’, ‘class_weight’, ‘criterion’, ‘min_samples_split’,’n_estimators’])\n    ```", "```py\n    import matplotlib.pyplot as plt\n    plotting_data.plot(subplots=True,figsize=(12, 12))\n    plt.xlabel(“Iterations”)\n    plt.show()\n    ```"]