- en: Association Rule Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关联规则算法
- en: Association rule learning, or association rule mining, is a relatively modern
    unsupervised learning technique originally used to discover associations between
    purchased items in grocery stores. The goal of association rule mining is to discover
    interesting relationships between sets of items, for instance, discovering that
    shoppers preparing for a hurricane often buy Pop-Tarts along with their bottled
    water, batteries, and flashlights.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则学习，或称关联规则挖掘，是一种相对较新的无监督学习技术，最初用于在杂货店发现购买商品之间的关联。关联规则挖掘的目标是发现商品集合之间的有趣关系，例如，发现为应对飓风做准备的人通常会购买Pop-Tarts、瓶装水、电池和手电筒。
- en: In [Chapter 5](8ba34275-43c8-4d0c-a8d3-8e0dd89dd2f9.xhtml), *Classification
    Algorithms*, we introduced the concept of conditional probability. In this chapter,
    we're going to take the concept a bit further and apply conditional probability
    to association rule learning. Recall that conditional probability asks (and answers)
    the question: given that we know something, what's the probability of something
    else happening? Or, what's the probability that someone will buy Pop-Tarts given
    that they also bought bottled water and batteries? The probability is high, as
    we will shortly see.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](8ba34275-43c8-4d0c-a8d3-8e0dd89dd2f9.xhtml)，“分类算法”中，我们介绍了条件概率的概念。在本章中，我们将把这一概念进一步拓展，并将其应用于关联规则学习。回想一下，条件概率询问（并回答）的问题是：如果我们知道某事，另一件事发生的概率是多少？或者，如果某人买了瓶装水和电池，他们购买Pop-Tarts的概率是多少？这个概率很高，正如我们很快就会看到的。
- en: In association rule learning, our goal is to look at a database of transactions
    or events and relate the most common subsets to each other through probabilities.
    This may be easier to understand with an example. Imagine you run an e-commerce
    store, and your task is to create a personalized widget on the homepage suggesting
    products to the shopper. You have the full database of their order history available
    to you, and you must use the shopper's browsing history to suggest items that
    have a high probability of being purchased by them.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在关联规则学习中，我们的目标是查看交易或事件数据库，并通过概率将最常见的子集相互关联。这可以通过一个例子更容易理解。想象你经营一家电子商务商店，你的任务是创建一个个性化的主页小部件，向购物者推荐产品。你可以使用他们完整的订单历史数据库，你必须使用购物者的浏览历史来推荐他们很可能购买的商品。
- en: Naturally, there are several ways to solve this problem. There's no reason you
    can't train a neural network on the entire order history of your store to suggest
    new products—except for time and complexity. Training the neural network on millions
    of transactions is both time-consuming and very difficult to inspect and understand
    intuitively. Association rule learning, on the other hand, gives us a simple and
    quick tool that's grounded in basic probability concepts.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，解决这个问题有几种方法。没有理由你不能在商店整个订单历史上训练一个神经网络来推荐新产品——除了时间和复杂性。在数百万笔交易上训练神经网络既耗时又非常难以直观地检查和理解。另一方面，关联规则学习为我们提供了一个简单快捷的工具，这个工具基于基本的概率概念。
- en: 'Let''s say your e-commerce store is a drop-shipping business that sells boutique,
    curated home decorations, and furniture. Your goal is to determine the sets of
    items that are most frequently bought together, for instance: 90% of people who
    bought the recliner chair and end table also bought the ottoman, and 80% of people
    who bought the giant wall clock also bought the drywall-mounting anchor set.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的电子商务商店是一家销售精品、精选家居装饰和家具的直邮业务。你的目标是确定最常一起购买的商品组合，例如：90%购买躺椅和茶几的人也购买了脚凳，80%购买巨型挂钟的人也购买了干墙安装锚固件套装。
- en: If you have a fast and efficient way to search through millions of previous
    orders to find these relationships, you can compare the current shopper's browsing
    history to other shoppers' purchase histories and display the items that the shopper
    is most likely to purchase.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一种快速有效的方法来搜索数百万笔以前的订单以找到这些关系，你可以将当前购物者的浏览历史与其他购物者的购买历史进行比较，并显示购物者最有可能购买的商品。
- en: 'Association rule learning is not limited to e-commerce. Another obvious application
    is physical stores, such as your local supermarket. If 90% of shoppers who buy
    milk and eggs also buy bread, it might be good to keep the bread close by so your
    shoppers can find it more easily. Alternatively, you might want to put bread on
    the *opposite* side of the store, because you know the shopper is going to have
    to walk through a bunch of aisles and probably pick up some more items along the
    way. How you use this data is up to you, and depends on what you want to optimize
    for: shopper convenience or total shopping basket value.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则学习不仅限于电子商务。另一个明显的应用是实体店，比如你当地的超市。如果90%购买牛奶和鸡蛋的购物者也会购买面包，那么把面包放在附近可能会让购物者更容易找到它。或者，你可能想把面包放在商店的*对面*，因为你知道购物者将不得不走过很多通道，并且可能在这个过程中购买更多商品。如何使用这些数据取决于你，这取决于你想要优化什么：购物者的便利性还是整个购物篮的价值。
- en: At first blush, it seems like this would be an easy algorithm to write—we're
    just counting probabilities, after all. However, with a large database and a large
    number of possible items to select from, it becomes very time-consuming to check
    every combination of items for their frequencies, and therefore we need something
    a little more involved than the brute-force, exhaustive-search approach.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 初看起来，这似乎是一个容易编写的算法——毕竟我们只是在计算概率。然而，在大型数据库和大量可能的商品选择中，检查每个商品组合的频率会变得非常耗时，因此我们需要比暴力穷举搜索方法更复杂一些的方法。
- en: 'In this chapter, we will discuss:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论：
- en: Association rule learning from a mathematical perspective
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数学角度的关联规则学习
- en: A description of the Apriori algorithm
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apriori算法的描述
- en: Various applications of association rule learning
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则学习的各种应用
- en: Worked examples of various association rule algorithms
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种关联规则算法的工作示例
- en: Let's get started by looking at association rule learning from a mathematical
    perspective.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从数学的角度来探讨关联规则学习。
- en: The mathematical perspective
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数学角度的描述
- en: Association rule learning assumes that you have a *transactional database* to
    learn from. This doesn't refer to any specific technology, but rather the concept
    of a database that stores transactions—the database can be an array in memory,
    an Excel file, or a table in your production MySQL or PostgreSQL instance. Since
    association rule learning was developed for products in supermarkets, the original
    transactional database was a list of items bought by each individual shopper on
    a given shopping trip—essentially an archive of receipts from the checkout aisle.
    However, a transactional database can be any list of items or events that occur
    during a single session, whether that session is a shopping trip, a website visit,
    or a trip to a doctor. For the time being, we'll consider the supermarket example.
    We'll discuss other uses of the association rule in a later section.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则学习假设你有一个*事务数据库*来学习。这并不指代任何特定的技术，而是指存储事务的数据库概念——数据库可以是内存中的数组、Excel文件，或者你生产环境中的MySQL或PostgreSQL实例中的表。由于关联规则学习最初是为超市中的产品开发的，原始的事务数据库是每个购物者在一次购物过程中购买的商品列表——本质上是一个收银通道的收据档案。然而，事务数据库可以是任何单次会话中发生的商品或事件的列表，无论这个会话是购物之旅、网站访问还是去看医生。目前，我们将考虑超市的例子。我们将在后面的章节中讨论关联规则的其他用途。
- en: 'A transactional database is a database where the rows are sessions and the
    columns are *items*. Consider the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 事务数据库是一个行代表会话、列代表*商品*的数据库。考虑以下：
- en: '| **Receipt ** | **Eggs** | **Milk** | **Bread** | **Cheese** | **Shampoo**
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| **收据** | **鸡蛋** | **牛奶** | **面包** | **奶酪** | **洗发水** |'
- en: '| 1 | Yes | Yes | No | Yes | No |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 是 | 是 | 否 | 是 | 否 |'
- en: '| 2 | No | No | Yes | Yes | No |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 否 | 否 | 是 | 是 | 否 |'
- en: '| 3 | No | No | No | No | Yes |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 否 | 否 | 否 | 否 | 是 |'
- en: '| 4 | Yes | Yes | Yes | Yes | No |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 是 | 是 | 是 | 是 | 否 |'
- en: '| 5 | Yes | Yes | No | Yes | No |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 是 | 是 | 否 | 是 | 否 |'
- en: 'Such a table can be considered a transactional database. Note that we are not
    recording the quantities of each item purchased, just whether or not the item
    was purchased. This is the case for most association rule learning: both the quantities
    and the ordering of items are typically ignored.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的表格可以被视为一个事务数据库。请注意，我们并没有记录每个商品购买的数量，只是记录商品是否被购买。在大多数关联规则学习中，通常忽略商品的数量和顺序。
- en: Based on the information in the table, we can put together probabilities for
    the occurrences of various events. For instance, the probability that a shopper
    buys `Shampoo`, or *P(E[Shampoo]),* is 20%. The probability that a shopper buys
    both `Cheese` and `Bread` is 40%, since two of the five shoppers bought both `Cheese`
    and `Bread`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 根据表中的信息，我们可以组合出各种事件发生的概率。例如，购物者购买洗发水的概率，或*P(E[Shampoo])*，是20%。购物者同时购买奶酪和面包的概率是40%，因为有两位购物者同时购买了奶酪和面包。
- en: Mathematically speaking, *milk* and *bread* is called an **itemset** and is
    typically written as `{milk, bread}`. Itemsets are similar to the concept of the
    probability *events* we introduced in [Chapter 5](8ba34275-43c8-4d0c-a8d3-8e0dd89dd2f9.xhtml), *Classification
    Algorithms*, except that itemsets are specifically used for situations such as
    this, and events are a more general concept in probability.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，*牛奶*和*面包*被称为**项集**，通常写作`{milk, bread}`。项集类似于我们在[第五章](8ba34275-43c8-4d0c-a8d3-8e0dd89dd2f9.xhtml)“分类算法”中引入的概率*事件*的概念，但项集专门用于这种情况，而事件是概率中更一般的概念。
- en: In association rule learning, the probability that an itemset appears as part
    of a transaction is called the **support** for that itemset. Just a moment ago,
    we mentioned that the probability of someone buying both milk and bread was 40%;
    this is another way of saying that the support for the `{milk, bread}` itemset
    is 40%. Noted mathematically, we can write `supp({milk, bread}) = 40%`.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在关联规则学习中，一个项集作为交易的一部分出现的概率被称为该项集的**支持度**。刚才我们提到，某人购买牛奶和面包的概率是40%；这是另一种说法，即`{milk,
    bread}`项集的支持度为40%。用数学表示，我们可以写成`supp({milk, bread}) = 40%`。
- en: Calculating the support of an itemset does not get us all the way to association
    rule learning, however. We first need to define what an association rule is. An
    association rule has the form X -> Y, where *X* and *Y* are both itemsets. Written
    out fully, an example association rule could be `{eggs, milk} -> {cheese}`, which
    relates the buying of eggs and milk to the buying of cheese. Association rules
    almost always only have a single item on the right-hand side, though the left-hand
    side can have any number of items. The association rule, by itself, tells us nothing
    about the association; we also need to look at various metrics, such as the association's
    *confidence* and *lift*, to understand how strong the association is.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，计算项集的支持度并不能让我们完全达到关联规则学习。我们首先需要定义什么是关联规则。关联规则的形式是X -> Y，其中*X*和*Y*都是项集。完整写出来，一个示例关联规则可以是`{eggs,
    milk} -> {cheese}`，这关联了购买鸡蛋和牛奶与购买奶酪。尽管左侧可以有任意数量的项目，但关联规则几乎总是只有右侧有一个项目。关联规则本身并不能告诉我们关于关联的信息；我们还需要查看各种指标，如关联的*置信度*和*提升度*，以了解关联有多强。
- en: The most important metric to consider for an association rule is its *confidence*,
    which is essentially how often the rule is found to be true. The *confidence*
    also happens to be the conditional probability of *P(E[Y]|E[X])*, or the probability
    that someone buys the items in itemset `Y` given that they bought the items in
    `X`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于关联规则来说，最重要的指标是其*置信度*，这本质上是指规则被发现为真的频率。置信度也恰好是条件概率*P(E[Y]|E[X])*，或给定某人购买了`X`中的项目，他们购买`Y`中项目的概率。
- en: Using our knowledge of conditional probability from Chapter 5, *Classification
    Algorithms*, and the new concepts of *support* and *confidence* in association
    rule learning, let's write a few equivalences that will help us solidify these
    mathematical concepts.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们在第五章“分类算法”中关于条件概率的知识，以及关联规则学习中的新概念“支持”和“置信度”，让我们写出一些等价式，这将帮助我们巩固这些数学概念。
- en: First, let's say that the itemset `X` is eggs and milk, or `X = {eggs, milk}`,
    and that `Y = {cheese}`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们假设项集`X`是鸡蛋和牛奶，或`X = {eggs, milk}`，而`Y = {cheese}`。
- en: The support of `X`, or `supp(X)`, is the same as the probability of finding
    the items in `X` in a transaction, or *P(E[X])*. In this case, eggs and milk appears
    in three out of five transactions, so its support is 60%. Similarly, the support
    of `Y` (just cheese) is 80%.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`X`的支持，或`supp(X)`，等同于在交易中找到`X`中项目的概率，或*P(E[X])*。在这种情况下，鸡蛋和牛奶出现在五笔交易中的三笔，因此其支持度为60%。同样，`Y`（仅奶酪）的支持度为80%。'
- en: The confidence of an association rule, `X -> Y`, is defined as `conf(X -> Y)
    = supp(X ∪ Y) / supp(X)`. Another way to say this is that the confidence of a
    rule is the support of all items in the rule divided by the support of the left-hand
    side. The ∪ symbol is used in probability theory to mean *union—*basically a Boolean
    OR operation. The *union* of the `X` and `Y` itemsets is therefore any item that
    appears in either X or Y. In our case, the union is eggs, milk, and cheese.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则 `X -> Y` 的置信度定义为 `conf(X -> Y) = supp(X ∪ Y) / supp(X)`。另一种说法是，规则的置信度是规则中所有项的支持度除以左侧的支持度。在概率论中，∪
    符号表示 *并集*——基本上是一个布尔 OR 操作。因此，`X` 和 `Y` 项集的 *并集* 是出现在 X 或 Y 中的任何项。在我们的例子中，并集是鸡蛋、牛奶和奶酪。
- en: 'If `supp(X) = P(EX)`, then `supp(X ∪ Y) = P(EX ∩ XY)`. Recall that ∩ is the
    symbol for *intersection*, or essentially a Boolean AND*.* This is one scenario
    in which the semantics of itemsets differ from the semantics of probability events—the
    *union* of two itemsets is related to the *intersection* of two events containing
    those itemsets. Despite the slightly confusing notations, what we''re getting
    at is this: this *confidence* formula is starting to look exactly like the formula
    for conditional probability, once we start translating the association rule notation
    into a standard probability notation.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `supp(X) = P(EX)`，那么 `supp(X ∪ Y) = P(EX ∩ XY)`。回想一下，∩ 是 *交集* 的符号，或者说本质上是一个布尔
    AND 操作。这是项集语义与概率事件语义不同的一种情况——两个项集的 *并集* 与包含这些项集的两个事件的 *交集* 有关。尽管符号有点令人困惑，但我们想要表达的是：当我们开始将关联规则符号翻译成标准的概率符号时，这个
    *置信度* 公式开始看起来非常像条件概率的公式。
- en: Since, in conditional probability, the *P(E[Y] | E[X]) = P(E[X] ∩ E[Y]) / P(E[X])* relation
    defines the conditional probability, and we know that `supp(X ∪ Y) = P(E[X] ∩
    E[Y])`, and we also know that *P(E[X]) = supp(X)*, we find that the confidence
    of an association rule is just its conditional probability.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在条件概率中，*P(E[Y] | E[X]) = P(E[X] ∩ E[Y]) / P(E[X])* 这个关系定义了条件概率，并且我们知道 `supp(X
    ∪ Y) = P(E[X] ∩ E[Y])`，我们还知道 *P(E[X]) = supp(X)*，我们发现关联规则的置信度就是它的条件概率。
- en: Returning to our example rule of `{eggs, milk} ⇒ {cheese}`, we find that the
    confidence of this rule is 1.0\. The union of *X* and *Y* (or `{eggs, milk, cheese}`)
    appears in three of the five transactions, and has a support of 0.6\. We divide
    that by the support of the left-hand side, or just `supp ({eggs, milk})`, which
    we also find in three of the five transactions. Dividing 0.6 by 0.6 gives us 1.0,
    which is the highest possible confidence value. Every time a shopper bought eggs
    and milk, they also bought cheese. Or, stated in terms of conditional probability,
    the probability that someone bought cheese given that they bought eggs and milk
    is 100%. Compare that to the probability of someone buying cheese, which is only
    80%. We clearly have a positive relationship between eggs, milk, and cheese.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的示例规则 `{eggs, milk} ⇒ {cheese}`，我们发现这个规则的置信度为 1.0。*X* 和 *Y*（或 `{eggs, milk,
    cheese}`）的并集在五笔交易中出现了三次，其支持度为 0.6。我们将这个支持度除以左侧的支持度，即 `supp ({eggs, milk})`，我们也在五笔交易中找到了它。将
    0.6 除以 0.6 得到 1.0，这是可能的最大置信值。每次购物者购买鸡蛋和牛奶时，他们也会购买奶酪。或者，用条件概率的说法，给定他们购买了鸡蛋和牛奶，购买奶酪的概率是
    100%。与购买奶酪的概率只有 80% 相比，我们明显看到鸡蛋、牛奶和奶酪之间存在正相关关系。
- en: This coincidental relationship can be further explored with a concept called
    **lift***.* Lift is defined as the support of the combined items, divided by the
    support for the left- and right-hand sides individually (that is, assuming they
    are independent). The formula is `lift(X -> Y) = supp(X ∪ Y) / ( supp(X) * supp(Y)
    )`. This formula essentially measures how dependent or independent `X` and `Y`
    are on each other. If the support of `X` and `Y` together is the same as the support
    of `X` and `Y` separately, the lift of the rule will be 1, and `X` and `Y` can
    be considered completely independent from one another. As the co-dependence of
    the two itemsets increases, the value of *lift* will increase as well. In our
    case, the support for `{eggs, milk, cheese}` is once again 0.6, the support for
    `{eggs, milk}` is 0.6, and the support for `{cheese}` is 0.8\. Combining these
    values with the lift equation gives us `lift(X -> Y) = 0.6 / (0.6 * 0.8) = 1.25`.
    This rule is said to have a lift of 25%, which indicates that there is some dependent
    relationship between `{eggs, milk}` and `{cheese}`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这种偶然关系可以通过一个称为**提升度**的概念进一步探索。提升度定义为组合项的支持度除以左侧和右侧各自的支持度（即，假设它们是独立的）。公式是 `提升度(X
    -> Y) = supp(X ∪ Y) / ( supp(X) * supp(Y) )`。这个公式本质上衡量了`X`和`Y`相互之间是依赖还是独立。如果`X`和`Y`一起的支持度与`X`和`Y`分别的支持度相同，那么规则的提升度将是1，`X`和`Y`可以被认为是完全相互独立的。随着两个项集的相互依赖性增加，提升度的值也会增加。在我们的例子中，`{鸡蛋，牛奶，奶酪}`的支持度再次是0.6，`{鸡蛋，牛奶}`的支持度是0.6，而`{奶酪}`的支持度是0.8。将这些值与提升度公式结合起来，我们得到
    `提升度(X -> Y) = 0.6 / (0.6 * 0.8) = 1.25`。这个规则据说有25%的提升度，这表明`{鸡蛋，牛奶}`和`{奶酪}`之间存在某种依赖关系。
- en: There are several other metrics that researchers can use when developing association
    rules, though we will not encounter any of these in our examples. There are metrics
    such as *conviction,* *leverage,* and *collective strength*, but for the most
    part, the familiar concepts of support, confidence, and lift will be all you need.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发关联规则时，研究人员可以使用几种其他指标，尽管在我们的示例中我们不会遇到这些指标。例如有*信念度*、*杠杆作用*和*集体力量*等指标，但大部分情况下，熟悉的支持度、置信度和提升度概念就足够了。
- en: 'If you take one thing away from this section, let it be this: many modern problems
    in computer science and machine learning can be solved with centuries-old probability
    theory. Association rule learning was developed in the 1990s, but the core concepts
    can be traced back hundreds of years. As we saw in [Chapter 5](8ba34275-43c8-4d0c-a8d3-8e0dd89dd2f9.xhtml), *Classification
    Algorithms*, we can use probability theory to develop powerful **machine learning**
    (**ML**) algorithms, and association rule learning is another argument for honing
    your knowledge of probability theory.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从这个部分学到了什么，让它成为这一点：许多计算机科学和机器学习中的现代问题都可以用几个世纪的概率理论来解决。关联规则学习是在20世纪90年代开发的，但其核心概念可以追溯到数百年前。正如我们在[第5章](8ba34275-43c8-4d0c-a8d3-8e0dd89dd2f9.xhtml)中看到的，*分类算法*，我们可以使用概率理论来开发强大的**机器学习**（**ML**）算法，关联规则学习也是提高你对概率理论知识的另一个论据。
- en: Let's now take a look at the challenges of analyzing a transactional database,
    and how an association rule algorithm might work.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来探讨分析事务型数据库的挑战，以及关联规则算法可能的工作方式。
- en: The algorithmic perspective
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法视角
- en: We now come to the much more difficult task of identifying frequent itemsets
    in a database. Once we know which itemsets and associations we want to generate
    rules for, calculating the support and confidence of the rules is quite easy.
    The difficulty, however, lies in automatically discovering the frequent and interesting
    itemsets in a database of millions of transactions among thousands of possible
    items.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在面临的是一个更加困难的任务，即在数据库中识别频繁项集。一旦我们知道我们想要为哪些项集和关联生成规则，计算规则的支持度和置信度就相当容易了。然而，困难在于自动发现数百万笔交易中数以千计的可能项的频繁且有趣的项集。
- en: Imagine that your e-commerce store only carries 100 unique items. Obviously,
    your customers can purchase any number of items during a session. Let's say a
    shopper buys only two items—there are 4,950 different combinations of two items
    from your catalog to consider. But you also must consider shoppers who buy three
    items, of which there are 161,700 combinations to search for. If your product
    catalog contains 1,000 items, there are a whopping 166 million combinations of
    three items that you'd have to consider when searching for frequent itemsets.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的电子商务商店只有100种独特的商品。显然，你的客户在会话期间可以购买任意数量的商品。让我们说一个购物者只买了两种商品——从你的目录中考虑两种商品的不同组合有4,950种。但你还需要考虑购买三种商品的购物者，这其中有161,700种组合需要搜索。如果你的产品目录包含1,000种商品，在搜索频繁项集时，你需要考虑的三个商品组合有1,660万种。
- en: Clearly, a more evolved algorithm is necessary to search the transactional database
    for frequent itemsets. Note that the frequent itemset search is only half of the
    solution; once you find frequent itemsets, you still must generate association
    rules from them. However, as the search for frequent itemsets is much more difficult
    than generating association rules, the itemset search becomes the key focus for
    most algorithms.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，需要一个更高级的算法来搜索事务数据库中的频繁项集。请注意，频繁项集搜索只是解决方案的一半；一旦找到频繁项集，你仍然必须从它们中生成关联规则。然而，由于频繁项集搜索比生成关联规则要困难得多，因此项集搜索成为大多数算法的关键焦点。
- en: 'In this section, we''ll describe one of the original frequent itemset search
    algorithms: the Apriori algorithm. We''re doing this for educational purposes
    only; it''s unlikely you''d ever need to implement your own version of the Apriori
    algorithm, as there are newer and faster frequent itemset search algorithms available.
    However, I think it''s important to study and understand these classic algorithms,
    especially algorithms that tackle a very large search space. Most algorithms that
    search a very large space use some kind of axiomatically or heuristically justified
    trick to drastically reduce the search space, and Apriori is no different.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述一种原始的频繁项集搜索算法：Apriori算法。我们这样做只是为了教育目的；你不太可能需要实现自己的Apriori算法版本，因为现在有更新、更快的频繁项集搜索算法可用。然而，我认为研究并理解这些经典算法很重要，特别是那些解决非常广大搜索空间的算法。大多数搜索非常广大空间的算法都使用某种公理化或启发式证明的技巧来极大地减少搜索空间，Apriori也不例外。
- en: The Apriori algorithm begins by scanning the database of transactions and recording
    the support (or frequency) of each individual item. The result of this is a list
    or hash table of items such as eggs = 0.6, milk = 0.6, shampoo = 0.2.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori算法首先扫描事务数据库，并记录每个单独物品的支持度（或频率）。结果是物品列表或哈希表，例如鸡蛋 = 0.6，牛奶 = 0.6，洗发水 =
    0.2。
- en: The next step is to find combinations of two items and determine their support
    (or frequency) in the database. The result of this step would be something like
    `{eggs, milk} = 0.6`, `{eggs, bread} = 0.2`, `{eggs, cheese} = 0.6`, `{eggs, shampoo}
    = 0.0`, and so on. The problem with the brute-force, exhaustive-search approach
    starts at this step. If you have 100 items in your catalog, you need to calculate
    the support for 4,950 pairs. If you have 1,000 items in your catalog, you must
    calculate the support for nearly 500,000 pairs. I don't know how many products
    Amazon ([https://www.amazon.com/](https://www.amazon.com/)) sells (the latest
    report from January 2017 states 368 million), but assuming they now have 400 million
    products, there are 8 x 10^(16) pairs of items to consider (that's eighty million
    billion pairs of items). And that's just *pairs* of items. We'd also need to look
    at every triplet of items, every quadruplet of items, and so on.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是找到两个物品的组合并确定它们在数据库中的支持度（或频率）。这一步骤的结果可能类似于 `{鸡蛋, 牛奶} = 0.6`，`{鸡蛋, 面包} = 0.2`，`{鸡蛋,
    奶酪} = 0.6`，`{鸡蛋, 洗发水} = 0.0`，等等。暴力搜索、穷举搜索方法的问题从这一步开始。如果你目录中有100个物品，你需要计算4,950对的支持度。如果你目录中有1,000个物品，你必须计算近500,000对的支持度。我不知道亚马逊（[https://www.amazon.com/](https://www.amazon.com/））卖了多少产品（2017年1月的最新报告称有3.68亿），但假设他们现在有4亿个产品，有8
    x 10^(16)对物品需要考虑（那是八十万亿对物品）。而且这只是物品的*对*。我们还需要查看每个物品的三元组、四元组，等等。
- en: The clever trick that Apriori uses to reduce the search space is to filter the
    list of unique products by a minimum support level, or minimum frequency of interest.
    If we set the minimum support to 0.25, for instance, we find that `{shampoo}`
    doesn't make the cut, and shampoo can never be part of our frequent itemset analysis
    because it's simply not purchased frequently enough.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori用来减少搜索空间的巧妙技巧是通过最小支持度或最小感兴趣频率来过滤唯一产品列表。例如，如果我们设定最小支持度为0.25，我们会发现`{洗发水}`不符合条件，因此洗发水永远不会成为我们的频繁项集分析的一部分，因为它简单地没有频繁购买。
- en: If shampoo, by itself, is not purchased frequently enough to be considered frequent,
    it also follows that any pair of items containing shampoo will *also* not be frequent
    enough for consideration. If shampoo appears in 20% of purchases, then the `{eggs,
    shampoo}` pair must appear *less* frequently than (or equal to) 20% of purchases.
    We cannot only eliminate shampoo from our search, we can also eliminate *any*
    set that contains shampoo from consideration. If shampoo by itself is infrequent
    enough that we can ignore it, then `{eggs, shampoo}`, `{bread, shampoo}`, and
    `{eggs, bread, shampoo}` will all also be so infrequent that we can ignore them.
    This cuts down on our search space *drastically*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果洗发水本身购买频率不够高，不足以被认为是频繁的，那么任何包含洗发水的项目对也将同样不足以被考虑。如果洗发水出现在20%的购买中，那么`{鸡蛋, 洗发水}`这对必须出现在（或等于）20%的购买中更少（或等于）的频率。我们不仅可以从搜索中排除洗发水，还可以从考虑中排除任何包含洗发水的集合。如果洗发水本身购买频率足够低以至于我们可以忽略它，那么`{鸡蛋,
    洗发水}`、`{面包, 洗发水}`和`{鸡蛋, 面包, 洗发水}`也将同样足够低以至于我们可以忽略它们。这大大减少了我们的搜索空间。
- en: We can take this approach a step further as we inspect larger combinations of
    items. In our example, `{eggs}` has a support of 60% and `{bread}` has a support
    of 40%. If we've set our minimum support to 25%, both of these items individually
    make the cut and should be considered in our frequent dataset analysis. However,
    the combination of `{eggs, bread}` has a support of only 20% and can be discarded.
    In the same way we were able to eliminate any combination containing `{shampoo}`
    from our second-degree search, we can now eliminate any combination containing
    `{eggs, bread}` from our third-degree search. Because eggs and bread together
    is rare, any combination of three or more items that contains both eggs and bread
    must also be rare. We can therefore eliminate combinations such as `{eggs, bread,
    cheese}`, `{eggs, bread, milk}`, and `{eggs, bread, shampoo}` from consideration,
    as they all contain the rare combination of `eggs` and `bread`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在检查更大组合的项目时将这种方法进一步深化。在我们的例子中，`{鸡蛋}`的支持度为60%，而`{面包}`的支持度为40%。如果我们设定的最小支持度为25%，这两个项目单独都符合条件，应该在我们的频繁数据集分析中考虑。然而，`{鸡蛋,
    面包}`的组合支持度仅为20%，可以被舍弃。同样地，我们能够从二级搜索中消除任何包含`{洗发水}`的组合，现在我们也可以从三级搜索中消除任何包含`{鸡蛋,
    面包}`的组合。因为鸡蛋和面包一起出现的频率很低，所以任何包含鸡蛋和面包的三个或更多项目的组合也必须很少见。因此，我们可以从考虑中排除像`{鸡蛋, 面包,
    奶酪}`、`{鸡蛋, 面包, 牛奶}`和`{鸡蛋, 面包, 洗发水}`这样的组合，因为它们都包含了罕见的`鸡蛋`和`面包`组合。
- en: While this approach drastically reduces the time required to find frequent itemsets,
    you should use this approach with caution as it's possible to accidentally skip
    over interesting, but somewhat rare, combinations. Most Apriori implementations
    will allow you to set both a minimum support and a minimum confidence for the
    resultant association rules. If you set the minimum support to a high value, your
    search will be faster but you may get more obvious or less interesting results;
    if you set the support lower, you're in danger of waiting for a very long time
    for the search to complete. Typically, association rules are generated after the
    frequent itemsets are found, so any minimum confidence level you set will not
    have an impact on the search time—only the minimum support variable will have
    a significant effect on search time.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种方法大大减少了寻找频繁项集所需的时间，但你应该谨慎使用这种方法，因为可能会意外地跳过一些有趣但相对罕见的组合。大多数Apriori实现都将允许你为生成的关联规则设置最小支持和最小置信度。如果你将最小支持度设定为高值，你的搜索将会更快，但你可能会得到更明显或不太有趣的结果；如果你将支持度设定得较低，你可能会在等待搜索完成上花费很长时间。通常，关联规则是在找到频繁项集之后生成的，所以你设定的任何最小置信度水平都不会影响搜索时间——只有最小支持度变量会对搜索时间产生重大影响。
- en: It should also be noted that there are more advanced and faster algorithms for
    frequent itemset searches. In particular, we will experiment with the FP-Growth
    algorithm later in this chapter. However, the Apriori algorithm is a great starting
    point for understanding how frequent itemset searches work in practice.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 还应注意的是，对于频繁项集搜索，存在更多高级且更快的算法。特别是，我们将在本章后面实验FP-Growth算法。然而，Apriori算法是理解实际中频繁项集搜索如何工作的绝佳起点。
- en: Before we implement libraries, let's take a look at a few situations in which
    association rules might be helpful.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们实现库之前，让我们看看一些可能有助于关联规则的场景。
- en: Association rule applications
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关联规则应用
- en: The original use of association rule algorithms was for market basket analysis,
    such as the grocery store example we've been using throughout this chapter. This
    is a clear-cut application for association rule mining. Market basket analysis
    can be used both in physical stores and in e-commerce stores, and different models
    can be maintained for different days of the week, seasons, or even for specific
    rare events, such as an upcoming concert or a hurricane.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则算法的原始用途是市场篮子分析，例如我们在本章中一直使用的杂货店示例。这是关联规则挖掘的一个明确应用。市场篮子分析可以用于实体店和电子商务店，并且可以根据不同的星期日、季节或甚至特定罕见事件（如即将到来的音乐会或飓风）维护不同的模型。
- en: In fact, in 2004, The New York Times (and others) reported that Walmart used
    association rule mining to figure out how to stock stores in advance of hurricanes.
    Walmart discovered that the association with the highest lift right before a hurricane
    wasn't bottled water or flashlights, but in fact strawberry Pop-Tarts. Another
    association with a high confidence was beer. I'm not too surprised about the beer,
    but the strawberry Pop-Tarts is the type of insight that you can really only get
    from ML!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，在2004年，《纽约时报》（以及其他媒体）报道说，沃尔玛使用关联规则挖掘来提前了解如何为飓风储备商店。沃尔玛发现，在飓风来临前的最高提升关联并不是瓶装水或手电筒，而是草莓Pop-Tarts。另一个具有高置信度的关联是啤酒。我对啤酒并不感到太惊讶，但草莓Pop-Tarts这种洞察力只能从机器学习中真正获得！
- en: Imagine you were a data scientist at Walmart back in 2004\. It would be easy
    to look up the individual sales volumes of various products during different time
    periods. It's possible that the strawberry Pop-Tarts, being a small-ticket item,
    only showed a very minor percentage change in the relative sales volume during
    hurricane periods. That's the kind of data point you might naturally ignore as
    being insignificant. Pop-Tarts get a slight bump, so what? But if you were to
    mine the data for frequent itemsets and association rules, you might have found
    that the `{bottled water, batteries} -> {Strawberry Pop-Tarts}` rule appeared
    with an unusually strong confidence, and a lift of around 8.0 (a very high value
    for lift) in the days before a hurricane. Outside of hurricane season, this association
    may have been nonexistent or too weak to make the cut. But when a hurricane is
    about to hit, strawberry Pop-Tarts become a necessary hurricane supply, almost
    certainly due to their long shelf life and their ability to make both children
    and adults happy. Seeing this association, you'd tell stores to stock up on strawberry
    Pop-Tarts and put them right at the front of the store—next to the bottled water
    and batteries—and make a killing on Pop-Tart sales.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果你在2004年的沃尔玛担任数据科学家。查看不同时间段各种产品的单个销售量很容易。可能草莓Pop-Tarts作为一种小额商品，在飓风期间相对销售量的百分比变化非常小。这就是你可能自然忽略的、看似不重要的数据点。Pop-Tarts销量略有上升，那又如何？但如果你挖掘频繁项集和关联规则的数据，你可能会发现`{瓶装水，电池}
    -> {草莓Pop-Tarts}`规则在飓风来临前的几天出现了异常强的置信度和大约8.0的提升（提升值非常高）。在飓风季节之外，这种关联可能不存在或太弱而无法被选中。但当飓风即将来临，草莓Pop-Tarts成为必需的飓风补给品，几乎肯定是因为它们的长期保质期以及它们能让孩子们和成年人快乐的特性。看到这个关联，你会告诉商店增加草莓Pop-Tarts的库存，并将它们放在商店最前面——紧挨着瓶装水和电池——从而在Pop-Tarts销售上大赚一笔。
- en: While this type of scenario is what association rules were designed for, you
    can apply frequent itemset mining and association rules to any transactional database.
    If you consider a website session to be a transaction, and if you can capture
    actions taken (such as *logged in*, *wishlisted item*, *downloaded case study*)
    as your items, you can apply the same algorithms and association rule mining to
    website visitor behaviors. You can develop association rules, such as `{downloaded
    case study, viewed pricing page} -> {entered credit card}`, to model your visitor
    behavior and optimize the layout and functionality of your site to encourage the
    behavior you want.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种类型的场景是关联规则设计的目的，但你可以将频繁项集挖掘和关联规则应用于任何事务数据库。如果你将网站会话视为一个事务，并且如果你可以捕获采取的行动（例如 *登录*，*加入愿望清单的商品*，*下载案例研究*）作为你的项目，你就可以将相同的算法和关联规则挖掘应用于网站访客行为。你可以开发关联规则，例如 `{下载案例研究,
    查看定价页面} -> {输入信用卡}`，来模拟访客行为并优化你网站的布局和功能，以鼓励你希望的行为。
- en: Keep in mind that association rules are not just valuable when they're positive.
    They're valuable when they're negative, too. Oftentimes you need cold, hard facts
    to change your mind about a stubborn belief that you previously held. Performing
    association rule mining on a dataset and *not* seeing an association you expected
    to see can be just as powerful as discovering an unexpected association. Seeing
    that the confidence for a rule you intuitively thought to be a strong association
    is actually very low, or below your cut-off, can help you let go of outdated thinking
    that might be holding you or your product back.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，关联规则不仅在它们为正时才有价值。当它们为负时，同样有价值。很多时候，你需要冷酷、硬性的事实来改变你对之前顽固信念的看法。在对数据集进行关联规则挖掘时，如果没有看到你预期看到的关联，这可以与发现意外的关联一样强大。看到你直觉上认为的强关联的置信度实际上非常低，或者低于你的阈值，这可以帮助你放弃可能阻碍你或你的产品的过时思维。
- en: There are stories of association rule mining being used in many and varied fields.
    Yes, association rules can be used to maximize Pop-Tarts profits before a hurricane,
    but association rules can also be used to characterize the hurricanes themselves
    in terms of their features and power output. Even though association rule learning
    was developed for market basket analysis, its foundation in conditional probability
    makes it applicable to nearly any statistical system that can be represented by
    items and transactions.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多关于关联规则挖掘在许多和不同领域被使用的例子。是的，关联规则可以用来在飓风来临之前最大化Pop-Tarts的利润，但关联规则也可以用来根据其特征和功率输出来描述飓风本身。尽管关联规则学习是为篮子分析开发的，但其基于条件概率的基础使其适用于几乎任何可以用项目和事务表示的统计系统。
- en: Consider, for instance, medical diagnoses. If each diagnosis by a doctor is
    considered a transaction, and every medical condition or environmental factor
    an item, we can apply association rule mining to find surprising associations
    between pre-existing conditions, environmental factors, and new diagnoses. You
    might find that the `{poor air quality, poor diet} -> {asthma}` rule has a high
    confidence or lift, and that can inform the way researchers and doctors treat
    asthma, perhaps by taking a closer look at diet.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 以医疗诊断为例。如果每位医生的诊断被视为一个事务，每种医疗状况或环境因素被视为一个项目，我们可以应用关联规则挖掘来发现现有条件、环境因素和新诊断之间的惊人关联。你可能会发现 `{空气质量差，饮食差}
    -> {哮喘}` 规则具有高置信度或提升，这可以告知研究人员和医生如何治疗哮喘，也许可以通过更仔细地关注饮食来实现。
- en: 'Association rules can be used in many other fields, such as genetics, bioinformatics,
    and IT security. Because these approaches can be used so broadly, it''s often
    difficult to recognize when association rules should be applied. A good rule of
    thumb to use is this: if your dataset contains transactions, or if you can see
    yourself calculating conditional probabilities for many combinations of events,
    you may want to consider association rule mining.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则可以应用于许多其他领域，如遗传学、生物信息学和IT安全。由于这些方法可以如此广泛地使用，因此很难认识到何时应该应用关联规则。一个很好的经验法则是：如果你的数据集包含事务，或者如果你可以看到自己计算许多事件组合的条件概率，你可能需要考虑关联规则挖掘。
- en: Let's take a look at a couple of JavaScript libraries for association rule mining.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看几个用于关联规则挖掘的JavaScript库。
- en: Example – retail data
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 – 零售数据
- en: 'In this example, we''ll use the Apriori algorithm to analyze a retail dataset.
    Start by creating a new folder for this project called `Ch6-Apriori`, and add
    the following `package.json` file:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用Apriori算法来分析一个零售数据集。首先，为这个项目创建一个名为`Ch6-Apriori`的新文件夹，并添加以下`package.json`文件：
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: After adding the `package.json` file, run `yarn install` from the command line
    to install the dependencies.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加`package.json`文件后，从命令行运行`yarn install`以安装依赖项。
- en: Next, create a `src` directory and download the required data file from this
    book's GitHub repository, `retail-data.json`, into the folder.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个`src`目录，并从本书的GitHub仓库下载所需的数据文件`retail-data.json`到文件夹中。
- en: 'Now add an `index.js` file to the `src` folder and add the following code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将`index.js`文件添加到`src`文件夹中，并添加以下代码：
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The preceding code imports the data and the Apriori library. It then initializes
    a new Apriori solver with a minimum support of `0.02` (2%) and a minimum rule
    confidence of 90%. We're also only analyzing the first 1,000 receipts in the dataset;
    the Apriori algorithm is a bit slow by nature, so you'll likely want to limit
    the dataset as you experiment initially.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码导入数据集和Apriori库。然后，使用最小支持度为`0.02`（2%）和最小规则置信度为90%初始化一个新的Apriori求解器。我们还在数据集中仅分析前1000张收据；由于Apriori算法本质上比较慢，所以在最初实验时你可能想要限制数据集的大小。
- en: 'Run the program with `yarn start` and you should see output similar to the
    following. The output will be longer than what I show here; take a minute to explore
    your own console output:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`yarn start`运行程序，你应该会看到类似以下输出的结果。输出将比这里显示的更长；花点时间探索你自己的控制台输出：
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: These association rules all have a confidence of 1.0, which means that the right-hand
    side (labeled `rhs`) appeared in a transaction 100% of the times that the left-hand
    side appeared.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这些关联规则都具有1.0的置信度，这意味着右侧（标记为`rhs`）在左侧出现时100%的情况下都会出现。
- en: 'Scroll down through the results a little more and you might find this rule:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在结果中向下滚动一点，你可能会找到以下规则：
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This rule essentially tells us that when a shopper buys the babushka and red
    retrospot design hand warmers, they have a 91% likelihood of also buying the bird
    design hand warmer. Have you ever wondered why, when shopping on Amazon, you often
    see suggestions similar to items you've just bought or added to your cart? This
    is why—apparently shoppers buy groups of similar items often enough that the association
    rule passes the various thresholds it needs to pass, despite the fact that the
    *average* shopper has no need for three differently designed hand warmers. But
    catering to the average shopper is not always the goal; you want to cater to the
    shopper who's going to spend more money, and you can find that shopper with statistics.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个规则实际上告诉我们，当购物者购买babushka和红色复古设计的手暖器时，他们有91%的可能性也会购买鸟形设计的手暖器。你有没有想过，当你在亚马逊购物时，为什么经常看到类似你刚刚购买或添加到购物车中的商品的建议？这就是原因——显然，购物者经常购买足够多的相似商品，以至于关联规则通过了它需要通过的各种阈值，尽管平均购物者可能不需要三个不同设计的手暖器。但迎合平均购物者并不总是目标；你想要迎合那些会花更多钱的购物者，而你可以通过统计数据找到这样的购物者。
- en: Experiment a little with the Apriori settings. What happens if you decrease
    the minimum confidence? What happens if you increase the minimum support?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试调整Apriori设置。如果你降低最小置信度会发生什么？如果你增加最小支持度会发生什么？
- en: Keeping the minimum support the same while decreasing the minimum confidence
    should give you more association rule results with no real impact on execution
    time. Most of the execution time is spent discovering frequent itemsets, where
    confidence is not yet a defined parameter; confidence only comes into play when
    composing rules, and does not affect individual itemsets.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在保持最小支持度不变的同时降低最小置信度应该会给你更多的关联规则结果，而不会对执行时间产生实际影响。大部分执行时间都花在发现频繁项集上，此时置信度尚未是一个定义好的参数；置信度只在组合规则时发挥作用，不会影响单个项集。
- en: Raising the minimum support will speed up the algorithm, however, you will find
    that you get less interesting results. As you raise the minimum support, you'll
    find that the left-hand side of the rules become simpler. Where you used to see
    rules with three and four items on the left-hand side, you'll now start seeing
    simpler left-hand itemsets, with only one or maybe two items. Itemsets with more
    than one item naturally tend toward having lower support values, so as you raise
    the minimum support, you will end up with simpler associations.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 提高最小支持度将加快算法的速度，然而，你会发现得到的结果不那么有趣。随着你提高最小支持度，你会发现规则的左侧变得更加简单。你以前会看到左侧有三个或四个项的规则，现在你将开始看到只有一项或可能两项的更简单的左侧项集。包含多个项的项集自然倾向于具有较低的支持值，所以随着你提高最小支持度，你最终会得到更简单的关联。
- en: Lowering the minimum support, on the other hand, will drastically increase execution
    time but also yield more interesting results. Note that it's possible to have
    rules with generally low support but very high confidence; these are rules that
    hold to be true often, but are rare in occurrence. As you lower the minimum support,
    you will find that the new rules that appear are evenly spread across a range
    of confidence values.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，降低最小支持度将大大增加执行时间，但也会产生更有趣的结果。请注意，可能存在支持度一般但置信度非常高的规则；这些规则通常成立，但发生频率较低。随着你降低最小支持度，你会发现新出现的规则在置信度值范围内均匀分布。
- en: Also try increasing the limit given to `receipts.slice`. Not only will the program
    become slower, but you'll also have *fewer* rules in the output if you keep the
    minimum support parameter constant. The reason for this is that the support value
    depends on the size of the dataset. An itemset that appeared in 2% of 1,000 transactions
    *might* only appear in 1% of 2,000 transactions, depending on the distribution
    of items. If you have a very large selection of items, or if your distribution
    of items is exponentially decaying (that is, the *long-tail distribution*), you
    will find that you need to scale the minimum support value as you scale the number
    of items considered.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以尝试增加`receipts.slice`所给的限制。如果你保持最小支持度参数不变，不仅程序会变慢，而且输出中的规则也会更少。原因在于支持值取决于数据集的大小。一个在1,000笔交易中出现在2%的项集*可能*只在2,000笔交易中的1%出现，这取决于项的分布。如果你有非常多的项选择，或者如果你的项分布是指数衰减的（即，*长尾分布*），你会发现你需要随着考虑的项的数量成比例地调整最小支持度值。
- en: To demonstrate this, I started with a minimum support of 0.02, a minimum confidence
    of 0.9, and a limit of 1,000 items from the receipts variable. With these parameters,
    the Apriori algorithm found 67 association rules. When I update the limit from
    1,000 to 2,000, the algorithm finds zero rules. The frequent itemsets in the first
    1,000 transactions are different enough from the itemsets in the second 1,000
    transactions that most itemsets' support values were reduced when I increased
    the limit.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示这一点，我从一个最小支持度为0.02、最小置信度为0.9以及从收据变量中选取1,000项的限制开始。在这些参数下，Apriori算法找到了67条关联规则。当我将限制从1,000增加到2,000时，算法没有找到任何规则。在前1,000笔交易中的频繁项集与后1,000笔交易中的项集差异足够大，以至于当我增加限制时，大多数项集的支持值都降低了。
- en: In order to find more results, I must decrease the minimum support. I first
    tried setting a minimum support of 0.01, however, I had to cancel that attempt
    after two hours of waiting for the program to complete. I tried again at 0.015\.
    This time, the program finished in 70 seconds and gave me 12 results. There must
    be some point between 0.010 and 0.015 where the number of itemsets dramatically
    increases—and indeed, the program found 584 rules with a minimum support of 0.0125.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到更多结果，我必须降低最小支持度。我首先尝试将最小支持度设置为0.01，然而，在等待程序完成两个小时后，我不得不取消那次尝试。我再次尝试设置为0.015。这次，程序在70秒内完成，并给了我12个结果。在0.010和0.015之间，必须存在某个点，使得项集的数量会急剧增加——确实，程序在最小支持度为0.0125时找到了584条规则。
- en: The support of an itemset is simply its frequency among all transactions. We
    can reframe everything related to support in terms of frequency. If we're considering
    2,000 transactions, a support of 0.0125 corresponds to 25 occurrences. Put another
    way, the list of 584 rules I just generated only includes items that were purchased
    at least 25 times in my 2,000-transaction dataset. In order to generate rules
    for products that were only purchased, say, 5 or more times, I'd need to set a
    minimum support of 0.0025—a value I'm pretty sure would set my laptop on fire.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 项集的支持简单是其所有交易中的频率。我们可以用频率来重新表述与支持相关的一切。如果我们考虑2,000笔交易，支持值为0.0125对应于25次出现。换句话说，我刚刚生成的584条规则列表只包括在我的2,000笔交易数据集中至少被购买25次的商品。为了生成只购买过，比如说5次或更多次的产品规则，我需要设置最小支持值为0.0025——一个我相当确信会烧毁我的笔记本电脑的值。
- en: Here, the need for an algorithm more refined than Apriori becomes apparent.
    Unfortunately, the JavaScript ecosystem is still lacking in this department. Another
    popular frequent itemset mining algorithm, ECLAT, seems not to have any JavaScript
    implementations.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，需要比Apriori更精细的算法变得明显。不幸的是，JavaScript生态系统在这方面仍然缺乏。另一个流行的频繁项集挖掘算法ECLAT似乎没有任何JavaScript实现。
- en: 'There is another frequent itemset mining algorithm available to us: the FP-Growth
    algorithm. This algorithm should be able to handle our task quite readily, however,
    the library available to us only does the frequent itemset search and does not
    generate association rules. It is much easier to generate association rules once
    the frequent itemsets have been discovered, however, I will leave this exercise
    up to the reader. For now, let''s take a look at the FP-Growth library.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有另一个可用的频繁项集挖掘算法：FP-Growth算法。这个算法应该能够轻松地处理我们的任务，然而，我们可用的库只执行频繁项集搜索，并不生成关联规则。一旦发现了频繁项集，生成关联规则就变得容易多了，但我将这个练习留给读者。现在，让我们看看FP-Growth库。
- en: 'In the `index.js` file, you may comment out the existing lines related to the
    Apriori solver and add the following code:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在`index.js`文件中，你可以取消与Apriori求解器相关的现有行的注释，并添加以下代码：
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The FP-Growth implementation does not generate association rules, therefore
    the only parameter it takes is the minimum support value. In this example, we
    are not truncating the `receipts` transaction database, since the algorithm should
    be able to handle the larger dataset. The full transaction database has approximately
    26,000 records, so a minimum support of `0.01` corresponds to products that were
    purchased `260` times or more.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: FP-Growth实现不生成关联规则，因此它只接受最小支持值作为参数。在这个例子中，我们没有截断`receipts`交易数据库，因为算法应该能够处理更大的数据集。完整的交易数据库大约有26,000条记录，所以最小支持值为`0.01`对应于被购买至少`260`次的产品。
- en: 'Run `yarn start` from the command line and you should see output similar to
    this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 从命令行运行`yarn start`，你应该看到类似以下输出的内容：
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Notice that the value for support is given as an absolute value, that is, the
    number of times the items were found in the database. While these are only frequent
    itemsets and not association rules, they are still useful. If you see a frequent
    itemset similar to the following, you might want to show the user the rose teapot
    if they''re browsing the sugar bowl page:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，支持值是以绝对值给出的，即项目在数据库中出现的次数。虽然这些只是频繁项集而不是关联规则，但它们仍然很有用。如果你看到以下类似的频繁项集，你可能想在用户浏览糖碗页面时展示玫瑰茶壶：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: While I think there is still some work to be done in terms of association rule
    learning in the JavaScript ecosystem, the Apriori and FP-Growth algorithms are
    both available and useful. The Apriori implementation in particular should be
    useful in most real-world use cases, which often contain fewer transactions and
    smaller item catalogs. While the FP-Growth implementation doesn't bother to generate
    association rules, there are still many things you can do by finding sets that
    an item frequently occurs in.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我认为在JavaScript生态系统中，关联规则学习方面还有一些工作要做，但Apriori和FP-Growth算法都是可用且有用的。特别是Apriori的实现，在大多数现实世界的用例中应该很有用，这些用例通常包含较少的交易和较小的商品目录。虽然FP-Growth的实现不生成关联规则，但通过找到频繁出现的商品集合，你仍然可以做很多事情。
- en: Summary
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed association rule learning, or the approach of
    finding frequent sets of items in a transactional database and relating them to
    one another via probabilities. We learned that association rule learning was invented
    for market basket analysis but has applications in many fields, since the underlying
    probability theory and the concept of transactional databases are both broadly
    applicable.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了关联规则学习，或是在事务数据库中寻找频繁项集的方法，并通过概率将它们相互关联。我们了解到，关联规则学习最初是为了市场篮子分析而发明的，但由于其背后的概率理论和事务数据库的概念都具有广泛的应用性，因此它在许多领域都有应用。
- en: 'We then discussed the mathematics of association rule learning in depth, and
    explored the canonical algorithmic approach to frequent itemset mining: the Apriori
    algorithm. We looked at other possible applications of association rule learning
    before trying out our own example on a retail dataset.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们深入探讨了关联规则学习的数学原理，并研究了频繁项集挖掘的典型算法方法：Apriori算法。在尝试我们自己零售数据集上的示例之前，我们探讨了关联规则学习的其他可能应用。
