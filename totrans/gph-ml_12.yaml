- en: 'Chapter 9: Building a Data-Driven Graph-Powered Application'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章：构建数据驱动的图驱动应用
- en: So far, we have provided you with both theoretical and practical ideas to allow
    you to design and implement machine learning models that leverage graph structures.
    Besides designing the algorithm, it is often very important to embed the modeling/analytical
    pipeline into a robust and reliable end-to-end application. This is especially
    true in industrial applications, where the end goal is usually to design and implement
    production systems that support data-driven decisions and/or provide users with
    timely information. However, creating a data-driven application that resorts to
    graph representation/modeling is indeed a challenging task that requires a proper
    design that is a lot more complicated than simply importing `networkx`. This chapter
    aims to provide you with a general overview of the key concepts and frameworks
    that are used when building graph-based, scalable, data-driven applications.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经向您提供了理论和实践上的想法，以便您设计并实现利用图结构进行机器学习模型的构建。除了设计算法之外，将建模/分析流程嵌入到一个强大且可靠的全端到端应用中通常也非常重要。这在工业应用中尤其如此，因为最终目标通常是设计和实现支持数据驱动决策和/或为用户提供及时信息的生产系统。然而，创建一个依赖图表示/建模的数据驱动应用确实是一项具有挑战性的任务，它需要适当的设计，这比简单地导入`networkx`要复杂得多。本章旨在向您提供构建基于图、可扩展、数据驱动的应用时所使用的核心概念和框架的一般概述。
- en: 'We will start by providing an overview of the so-called **Lambda architectures**,
    which provide a framework to structure scalable applications that require large-scale
    processing and real-time updates. We will then continue by applying this framework
    in the context of *graph-powered applications*, that is, applications that leverage
    graph structures using techniques such as the ones described in this book. We
    will describe their two main analytical components: **graph processing engines**
    and **graph querying engines**. We''ll present some of the technologies used,
    both in shared memory machines and distributed memory machines, outlining similarities
    and differences. The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先概述所谓的**Lambda架构**，它提供了一个框架来构建需要大规模处理和实时更新的可扩展应用。然后，我们将继续在*图驱动应用*的背景下应用这个框架，即利用本书中描述的技术等利用图结构的应用。我们将描述其两个主要分析组件：**图处理引擎**和**图查询引擎**。我们将介绍一些在共享内存机器和分布式内存机器上使用的技术，概述相似之处和不同之处。本章将涵盖以下主题：
- en: Overview of Lambda architectures
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda架构概述
- en: Lambda architectures for graph-powered applications
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于图驱动应用的Lambda架构
- en: Technologies and examples of graph processing engines
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图处理引擎的技术和示例
- en: Graph querying engines and graph databases
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图查询引擎和图数据库
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will be using Python 3.8 for all of our exercises. In the following code
    block, you can find a list of the Python libraries that need to be installed for
    this chapter using `pip`. For example, run `pip install networkx==2.5` on the
    command line, and so on:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在所有练习中使用Python 3.8。在下面的代码块中，您可以使用`pip`找到本章需要安装的Python库列表。例如，在命令行中运行`pip install
    networkx==2.5`，等等：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: All the code files relevant to this chapter are available at [https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter09](https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter09).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 所有与本章相关的代码文件可在[https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter09](https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter09)找到。
- en: Overview of Lambda architectures
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lambda架构概述
- en: In recent years, great focus has been given to designing scalable architectures
    that will allow, on the one hand, the *processing of a large amount of data*,
    and, on the other, *providing answers/alerts/actions in real time, using the latest
    available information*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，人们高度重视设计可扩展的架构，一方面可以处理大量数据，另一方面可以实时提供答案/警报/操作，使用最新可用的信息。
- en: Besides, these systems need to also be able to scale out seamlessly to a larger
    number of users or a larger amount of data by increasing resources horizontally
    (adding more servers) or vertically (using servers that are more powerful). **Lambda
    architecture** is a particular data-processing architecture that is designed to
    process massive quantities of data and ensure large throughput in a very efficient
    manner, preserving reduced latency and ensuring fault tolerance and negligible
    errors.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些系统还需要能够通过水平扩展（添加更多服务器）或垂直扩展（使用更强大的服务器）无缝地扩展到更多用户或更多数据。**Lambda架构**是一种特定的数据处理架构，旨在以非常高效的方式处理大量数据，并确保高吞吐量，同时保持低延迟并确保容错性和可忽略的错误。
- en: 'The Lambda architecture is composed of three different layers:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda架构由三个不同的层组成：
- en: '**The batch layer**: This layer sits on top of the (possibly distributed and
    scalable) storage system, and can handle and store all historical data, as well
    as performing **Online Analytical Processing** (**OLAP**) computation on the entire
    dataset. New data is continuously ingested and stored, as it would be traditionally
    done in data warehouse systems. Large-scale processing is generally achieved via
    massively parallel jobs, which aim at producing aggregation, structuring, and
    computation of relevant information. In the context of machine learning, model
    training that relies on historic information is generally done in this layer,
    thus producing a trained model to be used either in a batch prediction job or
    in real-time execution.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量层**：这一层位于（可能分布式和可扩展的）存储系统之上，可以处理和存储所有历史数据，并在整个数据集上执行**在线分析处理**（**OLAP**）计算。新数据会持续被摄取和存储，就像在传统数据仓库系统中那样。大规模处理通常通过大规模并行作业实现，旨在生成相关信息的汇总、结构和计算。在机器学习的背景下，依赖于历史信息的模型训练通常在这一层进行，从而产生一个用于批量预测作业或实时执行的训练模型。'
- en: '**The speed layer**: This is a low-latency layer that allows the real-time
    processing of the information to provide timely updates and information. It is
    generally fed by a streaming process, usually involving fast computation that
    does not require long computational time or load. It produces an output that is
    integrated with the data generated by the batch layer in (near) real time, providing
    support for **Online Transaction Processing** (**OLTP**) operations. The speed
    layer might also very well use some outputs of the OLAP computations, such as
    a trained model. Oftentimes, applications that use machine learning modeling in
    real time (for example, fraud detection engines used in credit card transactions)
    embed in their speed layers trained models that provide prompt predictions and
    trigger real-time alerts of potential fraud. Libraries may operate at an event
    level (such as Apache Storm) or over mini-batches (such as Spark Streaming), providing,
    depending on the use case, slightly different requirements for latency, fault
    tolerance, and computational speed.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度层**：这是一个低延迟层，允许实时处理信息，以提供及时更新和信息。它通常由流处理过程提供数据，通常涉及快速计算，不需要长时间的计算时间或负载。它产生的输出与批量层生成的数据（在（近）实时中）集成，为**在线事务处理**（**OLTP**）操作提供支持。速度层也可能很好地使用OLAP计算的一些输出，例如训练模型。通常，使用实时机器学习建模的应用程序（例如，在信用卡交易中使用的欺诈检测引擎）在其速度层中嵌入训练模型，以提供及时的预测并触发潜在的欺诈实时警报。库可以在事件级别（如Apache
    Storm）或微型批次（如Spark Streaming）上运行，根据用例，对延迟、容错性和计算速度有不同的要求。'
- en: '`flask`, `fastapi`, or `turbogear`), which provide the data via specifically
    designed endpoints:'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flask`、`fastapi`或`turbogear`），它们通过专门设计的端点提供数据：'
- en: '![Figure 9.1 – Functional diagram for an application based on Lambda architecture'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.1 – 基于 Lambda 架构的应用功能图'
- en: '](img/B16069_09_01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16069_09_01.jpg]'
- en: Figure 9.1 – Functional diagram for an application based on Lambda architecture
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 – 基于 Lambda 架构的应用功能图
- en: 'Lambda architectures have several benefits that have motivated and promoted
    their use, especially in the context of *big data* applications. In the following
    bullet points, we list some of the main pros of Lambda architectures:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda架构具有几个优点，这些优点推动了其使用，尤其是在**大数据**应用场景中。以下是一些Lambda架构的主要优点：
- en: '**No server management**: As the Lambda architectural design pattern typically
    abstracts the functional layers and does not require installing, maintaining,
    or administering any software/infrastructure'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无需服务器管理**：因为Lambda架构设计模式通常抽象了功能层，不需要安装、维护或管理任何软件/基础设施'
- en: '**Flexible scaling**: As the application can be either automatically scaled
    or scaled by controlling the number of processing units that are used in batch
    layers (for example, computing nodes) and/or in speed layers (for example, Kafka
    brokers) separately'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活扩展**：因为应用程序可以是自动扩展的，也可以通过控制批量层（例如计算节点）和/或在速度层（例如Kafka代理）中使用的处理单元的数量来扩展'
- en: '**Automated high availability**: Due to the fact that it represents a serverless
    design for which we already have built-in availability and fault tolerance'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动高可用性**：由于它代表了一种无服务器设计，我们已经有内置的可用性和容错性'
- en: '**Business agility**: Reacts in real time to changing business/market scenarios'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**业务敏捷性**：实时响应不断变化的业务/市场场景'
- en: 'Although very powerful and flexible, Lambda architectures come with some limitations
    mainly due to the presence of two interconnected processing flows: the **batch
    layer** and the **speed layer**. This may require developers to build and maintain
    separate code bases for batch and stream processes, resulting in more complexity
    and code overhead, which may lead to harder debugging, possible misalignment,
    and bug promotion.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管非常强大和灵活，但Lambda架构也存在一些限制，这主要归因于存在两个相互关联的处理流程：**批量层**和**速度层**。这可能要求开发人员为批量处理和流处理构建和维护单独的代码库，从而导致更多的复杂性和代码开销，这可能导致更困难的调试、可能的偏差和错误升级。
- en: Here, we have provided a short overview of Lambda architectures and their basic
    building blocks. For more details on how to design scalable architectures and
    the most commonly used architectural patterns, please refer to the book *Data
    Lake for Enterprises*, 2017, by Tomcy John and Pankaj Misra.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们提供了一个Lambda架构及其基本构建块的简要概述。有关如何设计可扩展架构和最常用的架构模式的更多详细信息，请参阅Tomcy John和Pankaj
    Misra于2017年出版的书籍《企业数据湖》。
- en: In the next section, we will show you how to implement a Lambda architecture
    for graph-powered applications. In particular, we will describe the main components
    and review the most common technologies.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将向您展示如何实现图驱动应用程序的Lambda架构。特别是，我们将描述主要组件并回顾最常用的技术。
- en: Lambda architectures for graph-powered applications
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图驱动应用程序的Lambda架构
- en: 'When dealing with scalable, graph-powered, data-driven applications, the design
    of Lambda architectures is also reflected in the separation of functionalities
    between two crucial components of the analytical pipeline, as shown in *Figure
    9.2*:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理可扩展的、基于图的数据驱动应用程序时，Lambda架构的设计也体现在分析管道两个关键组件之间的功能分离上，如图*9.2*所示：
- en: The **graph processing engine** executes computations on the graph structure
    in order to extract features (such as embeddings), compute statistics (such as
    degree distributions, the number of edges, and cliques), compute metrics and **Key
    Performance Indicators** (**KPIs**) (such as centrality measures and clustering
    coefficients), and identify relevant subgraphs (for example, communities) that
    often require OLAP.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图处理引擎**在图结构上执行计算以提取特征（例如嵌入），计算统计数据（例如度分布、边的数量和团），计算指标和**关键性能指标**（**KPIs**）（例如中心性度量聚类系数），并识别通常需要OLAP的相关子图（例如社区）。'
- en: 'The **graph querying engine** allows us to persist network data (usually done
    via a graph database) and provides fast information retrieval and efficient querying
    and graph traversal (usually via graph querying languages). All of the information
    is already persisted in some data storage (that may or may not be in memory) and
    no further computation is required apart from (possibly) some final aggregation
    results, for which indexing is crucial to achieving high performance and low latency:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图查询引擎**使我们能够持久化网络数据（通常通过图数据库完成）并提供了快速的信息检索和高效的查询以及图遍历（通常通过图查询语言完成）。所有信息都已持久化在某些数据存储中（可能或可能不在内存中），除了（可能）一些最终的聚合结果之外，不需要进一步的计算，对于这些结果，索引对于实现高性能和低延迟至关重要：'
- en: '![FigurFigure 9.2 – Graph-based architecture, with the main components'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.2 – 基于图的架构，主要组件'
- en: also reflected in a Lambda architectural pattern](img/B16069_09_02.jpg)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 也反映在Lambda架构模式中](img/B16069_09_02.jpg)
- en: Figure 9.2 – Graph-based architecture, with the main components also reflected
    in a Lambda architectural pattern
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 – 基于图的架构，主要组件也反映在Lambda架构模式中
- en: Graph processing engines sit on top of batch layers and produce outputs that
    may be stored and indexed in appropriate graph databases. These databases are
    the backend of graph querying engines, which allow relevant information to be
    easily and quickly retrieved, representing the operational views used by the serving
    layer. Depending on the use cases and/or the size of the graph, it often makes
    sense to run both the graph processing engine and the graph query engine on top
    of the same infrastructure.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图处理引擎位于批处理层之上，并生成可能存储和索引在适当图数据库中的输出。这些数据库是图查询引擎的后端，允许相关信息的轻松快速检索，代表服务层使用的操作视图。根据用例和/或图的大小，通常在相同的基础设施上同时运行图处理引擎和图查询引擎是有意义的。
- en: Instead of storing the graph on a low-level storage layer (for example, the
    filesystem, HDFS, or S3), there are graph database options that could support
    both OLAP and OLTP. These provide, at the same time, a backend persistence layer
    where historical information processed by batch layers, together with real-time
    updates from the speed layer, is stored, and information to be queried efficiently
    by the serving layer.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与在低级存储层（例如，文件系统、HDFS或S3）上存储图不同，有一些图数据库选项可以同时支持OLAP和OLTP。这些提供，同时，一个后端持久化层，其中存储了批处理层处理的历史信息，以及来自速度层的实时更新，并且信息可以被服务层高效查询。
- en: As compared to other use cases, this condition is indeed quite peculiar for
    graph-powered, data-driven applications. Historical data often provides a topology
    on top of which new, real-time updates and OLAP outputs (KPIs, data aggregations,
    embeddings, communities, and so on) can be stored. This data structure also represents
    the information that is later queried by the serving layer that traverses the
    enriched graph.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他用例相比，这种条件对于基于图、数据驱动的应用确实相当独特。历史数据通常提供了一种拓扑结构，新的实时更新和OLAP输出（KPI、数据聚合、嵌入、社区等）可以存储在其上。这种数据结构还代表了服务层随后查询的丰富图中的信息。
- en: Graph processing engines
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图处理引擎
- en: To select the right technology for a **graph processing engine**, it is crucial
    to estimate the size in memory of the network compared to the capacity of the
    target architecture. You can start by using simpler frameworks that allow fast
    prototyping during the first phases of a project when the goal is to quickly build
    a **Minimum Viable Product** (**MVP**).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要选择合适的**图处理引擎**技术，估计网络在内存中的大小与目标架构的容量相比至关重要。你可以从使用更简单的框架开始，这些框架在项目的早期阶段允许快速原型设计，当时的目标是快速构建**最小可行产品**（**MVP**）。
- en: Such frameworks can then be substituted by more advanced tools later on when
    performance and scalability become more crucial. A microservice modular approach
    and proper structuring of these components will allow the switching of technologies/libraries
    independently from the rest of the application to target specific issues, which
    will also guide the choice of the backend stack.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些框架可以在性能和可扩展性变得更为关键时，由更先进的工具所取代。微服务模块化方法和这些组件的正确结构将允许独立于应用程序的其他部分切换技术/库，以针对特定问题，这也会指导后端堆栈的选择。
- en: Graph processing engines require information on the whole graphs to be accessed
    quickly, that is, having all of the graph in memory, and depending on the context,
    you might or might not need *distributed architectures*. As we saw in [*Chapter
    1*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014), *Getting Started with Graphs*,
    `networkx` is a great example of a library to build a graph processing engine
    when dealing with reasonably small datasets. When datasets get larger, but they
    can still fit in single servers or shared memory machines, other libraries may
    help to reduce computational time. As seen in [*Chapter 1*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014),
    *Getting Started with Graphs*, using libraries other than `networkx` where graph
    algorithms are implemented in more performant languages, such as C++ or Julia,
    may dramatically speed up the computation by more than two orders of magnitude.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图处理引擎需要快速访问整个图的信息，即所有图都在内存中，并且根据上下文，你可能需要或不需要*分布式架构*。正如我们在[*第一章*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014)，“开始使用图”中看到的，`networkx`是一个在处理相对较小的数据集时构建图处理引擎的优秀库示例。当数据集变大，但仍可以适应单个服务器或共享内存机器时，其他库可能有助于减少计算时间。正如在[*第一章*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014)，“开始使用图”中看到的，使用除了`networkx`之外的其他库，其中图算法是用性能更好的语言（如C++或Julia）实现的，可能会将计算速度提高两个数量级以上。
- en: 'However, there are cases where datasets grow so much that it is no longer technologically
    or economically viable to use shared memory machines of increasing capacity (fat
    nodes). In such cases, it is rather necessary to distribute the data on clusters
    of tens or hundreds of computing nodes, allowing horizontal scaling. The two most
    popular frameworks that can support a graph processing engine in these cases are
    the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，数据集增长如此之大，以至于使用不断增加容量的共享内存机器（胖节点）在技术上或经济上不再可行。在这种情况下，将数据分布到由数十或数百个计算节点组成的集群上，实现水平扩展，变得更为必要。在这些情况下，可以支持图处理引擎的两个最流行的框架如下：
- en: '**Apache Spark GraphX**, which is the module of the Spark library that deals
    with graph structures ([https://spark.apache.org/graphx](https://spark.apache.org/graphx)).
    It involves a distributed representation of the graph using **Resilient Distributed
    Datasets** (**RDDs**) for both vertices and edges. The graph repartition throughout
    the computing nodes can be done either with an *edge-cut* strategy, which logically
    corresponds to dividing the nodes among multiple machines, or a *vertex-cut* strategy,
    which logically corresponds to assigning edges to different machines and allowing
    vertices to span multiple machines. Although written in Scala, GraphX features
    wrappers with both R and Python. GraphX already comes with some algorithms implemented,
    such as *PageRank*, *connected components*, and *triangle counting*. There are
    also other libraries that can be used on top of GraphX for other algorithms, such
    as **SparklingGraph**, which implements more centrality measures.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Spark GraphX**，这是Spark库中处理图结构的模块（[https://spark.apache.org/graphx](https://spark.apache.org/graphx)）。它涉及使用**弹性分布式数据集**（**RDDs**）对顶点和边进行分布式表示。图在整个计算节点上的重新分区可以通过*边切割*策略来完成，这在逻辑上相当于将节点分配到多台机器上，或者通过*顶点切割*策略，这在逻辑上相当于将边分配到不同的机器上，并允许顶点跨越多台机器。尽管是用Scala编写的，但GraphX提供了R和Python的包装器。GraphX已经内置了一些算法实现，例如*PageRank*、*连通分量*和*三角形计数*。还有其他库可以在GraphX之上使用，用于其他算法，例如**SparklingGraph**，它实现了更多的中心性度量。'
- en: '**Apache Giraph**, which is an iterative graph processing system built for
    high scalability ([https://giraph.apache.org/](https://giraph.apache.org/)). It
    was developed, and is currently used, by Facebook to analyze the social graph
    formed by users and their connections and is built on top of the Hadoop ecosystem
    for unleashing the potential of structured datasets at a massive scale. Giraph
    is natively written in Java and, similarly to GraphX, also provides a scalable
    implementation for some basic graph algorithms, such as *PageRank* and *shortest
    path*.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Giraph**，这是一个为高可扩展性而构建的迭代图处理系统（[https://giraph.apache.org/](https://giraph.apache.org/)）。它由Facebook开发和目前使用，用于分析由用户及其连接形成的社会图，并建立在Hadoop生态系统之上，以释放大规模结构化数据集的潜力。Giraph是用Java原生编写的，类似于GraphX，也提供了一些基本图算法的可扩展实现，例如*PageRank*和*最短路径*。'
- en: 'When we consider scale-out to a distributed ecosystem, we should always keep
    in mind that the available choice for algorithms is significantly smaller than
    in a shared machine context. This is generally due to two reasons:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑扩展到分布式生态系统时，我们应该始终牢记，可用的算法选择比在共享机器环境中要少得多。这通常有两个原因：
- en: First, implementing algorithms in a distributed way is a lot more complex than
    in a shared machine due to communication among nodes, which also reduces the overall
    efficiency.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，由于节点之间的通信，以分布式方式实现算法比在共享机器上要复杂得多，这也降低了整体效率。
- en: Secondly, and more importantly, one fundamental mantra of big data analytics
    is that only algorithms that (nearly) scale linearly with the number of data points
    should be implemented in order to ensure horizontal scalability of the solution,
    by increasing the computational nodes as the dataset increases.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，更重要的是，大数据分析的一个基本信条是，只有那些（几乎）与数据点数量成线性关系的算法才应该被实现，以确保解决方案的水平可扩展性，即随着数据集的增加而增加计算节点。
- en: In this respect, both Giraph and GraphX allow you to define scalable, vertex-centric,
    iterative algorithms using standard interfaces based on **Pregel**, which can
    be seen as a sort of equivalent of iterative map-reduce operations for graphs
    (actually, iterative map-reduce operations applied to triplet node-edge-node instances).
    A Pregel computation is composed of a sequence of iterations, each called a **superstep**,
    each involving a node and its neighbors.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，Giraph和GraphX都允许你使用基于**Pregel**的标准接口定义可扩展的、以顶点为中心的迭代算法，这可以被视为图（实际上，应用于三元组节点-边-节点实例的迭代map-reduce操作）的某种迭代map-reduce操作的等价物。Pregel计算由一系列迭代组成，每个迭代称为**超级步**，每个迭代都涉及一个节点及其邻居。
- en: 'During the superstep, *S*, a user-defined function is applied for each vertex,
    *V*. This function takes the messages sent to *V* in superstep *S – 1* as input
    and modifies the state of *V* and its outgoing edges. This function represents
    the mapping stage, which can be easily parallelized. Besides computing the new
    states of *V*, the function also sends messages to other vertices connected to
    *V*, which will receive this information at superstep *S + 1*. Messages are typically
    sent along outgoing edges, but a message may be sent to any vertex whose identifier
    is known. In *Figure 9.3*, we show a sketch of what a Pregel algorithm would look
    like when computing the maximum value over a network. For further details on this
    algorithm, please refer to the original paper, *Pregel: A System for Large-Scale
    Graph Processing*, written by Malewicz et al. in 2010:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在超级步S期间，对每个顶点V应用一个用户定义的函数。这个函数将超级步S-1中发送到V的消息作为输入，并修改V及其出度边的状态。这个函数代表映射阶段，可以很容易地进行并行化。除了计算V的新状态外，该函数还将消息发送到与V连接的其他顶点，这些顶点将在超级步S+1接收到这些信息。消息通常沿着出度边发送，但可以向任何已知标识符的顶点发送消息。在图9.3中，我们展示了Pregel算法在计算网络上的最大值时的草图。有关此算法的更多详细信息，请参阅Malewicz等人于2010年撰写的原始论文《Pregel：一个用于大规模图处理的系统》：
- en: '![Figure 9.3 – Example of calculating a maximum value over a node property
    using Pregel'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.3 – 使用Pregel计算节点属性最大值的示例]'
- en: '](img/B16069_09_03.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16069_09_03.jpg]'
- en: Figure 9.3 – Example of calculating a maximum value over a node property using
    Pregel
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 – 使用Pregel计算节点属性最大值的示例
- en: By using Pregel, you can easily implement other algorithms, such as *PageRank*
    or *connected components*, in a very efficient and general way, or even implement
    node embeddings' parallel variants (for an example, see *Distributed-Memory Vertex-Centric
    Network Embedding for Large-Scale Graphs*, Riazi and Norris, 2020).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用Pregel，你可以轻松地以非常高效和通用的方式实现其他算法，例如*PageRank*或*连通分量*，甚至可以并行实现节点嵌入的变体（例如，请参阅Riazi和Norris于2020年撰写的《用于大规模图的分布式内存顶点中心网络嵌入》，Riazi和Norris，2020）。
- en: Graph querying layer
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图查询层
- en: In the last decade, due to the large diffusion of non-structured data, NoSQL
    databases have started to gain considerable attention and importance. Among them,
    **graph databases** are indeed extremely powerful to store information based on
    a relation between entities. Indeed, in many applications, data can naturally
    be seen as entities, associated with metadata in the form of node properties,
    connected by edges that also have properties that further describe the relationship
    between entities.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，由于非结构化数据的大量扩散，NoSQL数据库开始获得相当大的关注和重要性。其中，**图数据库**确实非常强大，可以基于实体之间的关系存储信息。实际上，在许多应用中，数据可以自然地被视为实体，通过具有属性的边连接，这些边也具有进一步描述实体之间关系的属性。
- en: Examples of graph databases are libraries or tools such as Neo4j, OrientDB,
    ArangoDB, Amazon Neptune, Cassandra, and JanusGraph (previously named TitanDB).
    In the following sections, we will briefly describe some of them, together with
    the languages that allow us to query and traverse the underlying graphs, which
    are called **graph querying languages**.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图数据库的例子包括Neo4j、OrientDB、ArangoDB、Amazon Neptune、Cassandra和JanusGraph（之前称为TitanDB）。在接下来的章节中，我们将简要介绍其中的一些，以及允许我们查询和遍历底层图的语言，这些语言被称为**图查询语言**。
- en: Neo4j
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Neo4j
- en: 'At the time of writing, **Neo4J** ([https://neo4j.com/](https://neo4j.com/))
    is surely the most common graph database around, with a large community supporting
    its use and adoption. It features two editions:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，**Neo4J** ([https://neo4j.com/](https://neo4j.com/))无疑是周围最常见的图数据库，拥有一个支持其使用和采用的庞大社区。它有两个版本：
- en: '*Community Edition*, released under a GPL v3 license, which allows users/developers
    to openly include Neo4j in their applications'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*社区版*，在GPL v3许可下发布，允许用户/开发者公开将Neo4j包含在其应用程序中'
- en: '*Enterprise Edition*, designed for commercial deployments where scale and availability
    are crucial'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*企业版*，专为需要规模和可用性的商业部署设计'
- en: Neo4j can scale out to fairly large datasets via **sharding**, that is, distributing
    data over multiple nodes and parallelizing queries and aggregation over multiple
    instances of the database. Besides, the Neo4j federation also allows querying
    smaller separated graphs (sometimes even with a different schema) as if they were
    one large graph.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j可以通过**分片**扩展到相当大的数据集，即通过将数据分布到多个节点并在数据库的多个实例上并行查询和聚合来并行化查询。此外，Neo4j联邦还允许查询较小的分离图（有时甚至具有不同的模式），就像它们是一个大图一样。
- en: 'Some of Neo4j''s strong points are its flexibility (which allows the schema
    to be evolved) and its user-friendliness. In particular, many operations in Neo4j
    can be done through its query language, which is very intuitive and easy to learn:
    **Cypher**. Cypher can just be seen as the counterpart of SQL for graph databases.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j的一些优点是其灵活性（允许模式演变）和用户友好性。特别是，Neo4j中的许多操作都可以通过其查询语言完成，该语言非常直观且易于学习：**Cypher**。Cypher可以被视为图数据库的SQL对应物。
- en: Testing out Neo4j and Cypher is extremely easy. You could install the Community
    Edition (via Docker; see the next section) or play around with an online sandbox
    version ([https://neo4j.com/sandbox/](https://neo4j.com/sandbox/)).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 测试Neo4j和Cypher非常容易。您可以通过Docker安装社区版（见下一节）或尝试在线沙盒版本（[https://neo4j.com/sandbox/](https://neo4j.com/sandbox/))。
- en: 'By using the latter, you can import some built-in datasets, such as the Movie
    dataset, and start querying it using the Cypher query language. The Movie dataset
    is made up of 38 movies and 133 people that acted in, directed, wrote, reviewed,
    and produced them. Both the on-premises version and the online version are equipped
    with a user-friendly UI that allows the user to query and visualize the data (see
    *Figure 9.4*). We start by listing 10 actors in the Movie dataset, by simply querying
    the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用后者，您可以导入一些内置的数据集，例如电影数据集，并开始使用Cypher查询语言对其进行查询。电影数据集由38部电影和133位参与表演、导演、编写、评论和制作这些电影的人组成。无论是在场版本还是在线版本，都配备了用户友好的UI，允许用户查询和可视化数据（见*图9.4*）。我们首先列出电影数据集中的10位演员，只需查询以下内容：
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'But let''s now leverage the information about relations between data points.
    We see that one of the actors that appears in the database is Keanu Reeves. We
    may wonder who all the actors that he has acted with in the listed movies are.
    This information can be easily retrieved using the following query:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在让我们利用数据点之间关系的信息。我们看到数据库中出现的一个演员是基努·里维斯。我们可能会想知道他在列出的电影中与哪些演员合作过。此信息可以通过以下查询轻松检索：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As shown in the following figure, the query intuitively and graphically indicates
    in its syntax how to traverse the graph by declaring the path we are interested
    in:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下图所示，查询通过声明我们感兴趣的路径，直观地以语法形式指示如何遍历图：
- en: '![Figure 9.4 – Example of the Neo4j UI with the Cypher query to retrieve the
    co-actors of Keanu Reeves in the Movie dataset](img/B16069_09_04.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图9.4 – Neo4j UI的示例，使用Cypher查询检索电影数据集中基努·里维斯的合作演员](img/B16069_09_04.jpg)'
- en: Figure 9.4 – Example of the Neo4j UI with the Cypher query to retrieve the co-actors
    of Keanu Reeves in the Movie dataset
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 – Neo4j UI的示例，使用Cypher查询检索电影数据集中基努·里维斯的合作演员
- en: Besides Cypher, data can also be queried using Gremlin. This will be described
    shortly as a common interface for graph databases.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Cypher，数据也可以使用Gremlin进行查询。这将在描述图数据库的通用接口时简要介绍。
- en: 'Neo4j also provides bindings with several programming languages, such as Python,
    JavaScript, Java, Go, Spring, and .NET. For Python in particular, there are several
    libraries that implement connections with Neo4j, such as `neo4j`, `py2neo`, and
    `neomodel`, of which `neo4j` is the official and supported one and provides direct
    connections to the database via a binary protocol. Creating a connection to the
    database and running a query is just a matter of a few lines of code:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j还提供了与多种编程语言的绑定，例如Python、JavaScript、Java、Go、Spring和.NET。特别是对于Python，有几个库实现了与Neo4j的连接，如`neo4j`、`py2neo`和`neomodel`，其中`neo4j`是官方和支持的，通过二进制协议直接连接到数据库。创建数据库连接并运行查询只需几行代码：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: A query could be any Cypher query, for instance, the one written previously
    to retrieve the co-actors of Keanu Reeves.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 查询可以是任何Cypher查询，例如，之前编写的用于检索基努·里维斯合作演员的查询。
- en: JanusGraph – a graph database to scale out to very large datasets
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: JanusGraph – 一个可扩展的图数据库，可扩展到非常大的数据集
- en: Neo4j is an extremely great piece of software, unbeatable when you want to get
    things done quickly, thanks to its intuitive interface and query language. Neo4j
    is indeed a graph database suitable for production, but especially good in MVPs
    when agility is crucial. However, as data increases, its scalability based on
    sharding and breaking down large graphs into smaller subgraphs may not be the
    best option.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j是一款非常出色的软件，当你想要快速完成任务时，凭借其直观的界面和查询语言，无与伦比。Neo4j确实是一个适合生产的图数据库，但在敏捷性至关重要的MVP中尤其出色。然而，随着数据量的增加，基于分片和将大型图分解成较小子图的扩展性可能不是最佳选择。
- en: When the volume of the data increases substantially, you should probably start
    to consider other graph database options. Once again, this should be done only
    when the use case requirements start to hit the scalability limitation of Neo4j,
    as needs evolve from the MVP initial requirements.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据量显著增加时，你可能需要开始考虑其他图数据库选项。再次强调，这应该只在用例需求开始触及Neo4j的可扩展性限制时进行，因为需求从MVP的初始要求演变而来。
- en: In such cases, there are several options. Some of them are commercial products,
    such as Amazon Neptune or Cassandra. However, open source options are also available.
    Among them, we believe it is worth mentioning **JanusGraph** ([https://janusgraph.org/](https://janusgraph.org/)),
    which is a particularly interesting piece of software. JanusGraph is the evolution
    of a previously open source project that was called **TitanDB** and is now an
    official project under the Linux Foundation, also featuring support from top players
    in the tech landscape, such as IBM, Google, Hortonworks, Amazon, Expero, and Grakn
    Labs.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，有几种选择。其中一些是商业产品，例如Amazon Neptune或Cassandra。然而，开源选项也是可用的。其中，我们认为值得提及的是**JanusGraph**
    ([https://janusgraph.org/](https://janusgraph.org/))，这是一款特别有趣的软件。JanusGraph是之前名为**TitanDB**的开放源代码项目的演变，现在是Linux基金会的官方项目，同时也得到了技术领域顶级玩家的支持，如IBM、Google、Hortonworks、Amazon、Expero和Grakn
    Labs。
- en: 'JanusGraph is a scalable graph database designed for storing and querying graphs
    distributed across a multi-machine cluster with hundreds of billions of vertices
    and edges. As a matter of fact, JanusGraph does not have a storage layer on its
    own, but it is rather a component, written in Java, that sits on top of other
    data storage layers, such as the following:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: JanusGraph是一个可扩展的图数据库，专为存储和查询跨多机集群分布的图而设计，具有数百亿个顶点和边。实际上，JanusGraph本身没有存储层，而是一个组件，用Java编写，位于其他数据存储层之上，如下所示：
- en: '**Google Cloud Bigtable** ([https://cloud.google.com/bigtable](https://cloud.google.com/bigtable)),
    which is the cloud version of the proprietary data storage system built on Google
    File System, designed to scale a massive amount of data distributed across data
    centers (*Bigtable: A Distributed Storage System for Structured Data*, Fay Chang
    et al., 2006).'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Cloud Bigtable** ([https://cloud.google.com/bigtable](https://cloud.google.com/bigtable))，这是基于Google文件系统构建的专有数据存储系统的云版本，旨在扩展数据中心间分布的大量数据（*《Bigtable:
    A Distributed Storage System for Structured Data》，Fay Chang等人，2006年）。'
- en: '**Apache HBase** ([https://hbase.apache.org/](https://hbase.apache.org/)),
    which is a non-relational database that features Bigtable capabilities on top
    of Hadoop and HDFS, thus ensuring similar scalability and fault tolerance.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache HBase** ([https://hbase.apache.org/](https://hbase.apache.org/))，这是一个非关系型数据库，它基于Hadoop和HDFS提供了Bigtable功能，从而确保了类似的可扩展性和容错性。'
- en: '**Apache Cassandra** ([https://cassandra.apache.org/](https://cassandra.apache.org/)),
    which is an open source distributed NoSQL database that allows handling a large
    amount of data, spanning multiple data centers.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Cassandra** ([https://cassandra.apache.org/](https://cassandra.apache.org/))，这是一个开源的分布式NoSQL数据库，允许处理大量数据，跨越多个数据中心。'
- en: '**ScyllaDB** ([https://www.scylladb.com/](https://www.scylladb.com/)), which
    is specifically designed for real-time applications, is compatible with Apache
    Cassandra while achieving significantly higher throughputs and lower latencies.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ScyllaDB** ([https://www.scylladb.com/](https://www.scylladb.com/))，这是一种专门为实时应用设计的数据库，与Apache
    Cassandra兼容，同时实现了显著更高的吞吐量和更低的延迟。'
- en: Thus, JanusGraph inherits all the good features, such as scalability, high availability,
    and fault tolerance, from scalable solutions, abstracting a graph view on top
    of them.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，JanusGraph继承了可扩展解决方案的所有良好特性，如可扩展性、高可用性和容错性，并在其之上抽象出一个图视图。
- en: With its integration with ScyllaDB, JanusGraph handles extremely fast, scalable,
    and high-throughput applications. Besides, JanusGraph also integrates indexing
    layers that can be based on Apache Lucene, Apache Solr, and Elasticsearch in order
    to allow even faster information retrieval and search functionalities within the
    graph.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通过与ScyllaDB的集成，JanusGraph可以处理极快、可扩展和高吞吐量的应用。此外，JanusGraph还集成了基于Apache Lucene、Apache
    Solr和Elasticsearch的索引层，以便在图中实现更快的信息检索和搜索功能。
- en: The usage of highly distributed backends together with indexing layers allows
    JanusGraph to scale to enormous graphs, with hundreds of billions of nodes and
    edges, efficiently handling the so-called **supernodes**—in other words, nodes
    that have an extremely large degree, which often arise in real-world applications
    (remember that a very famous model for real networks is the *Barabasi-Albert*
    model, based on preferential attachments, which makes hubs naturally emerge within
    the graph).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 与索引层一起使用高度分布的后端，允许JanusGraph扩展到巨大的图，拥有数百亿个节点和边，有效地处理所谓的**超节点**——换句话说，具有极端大度数的节点，这些节点通常出现在现实世界应用中（记住，一个非常著名的真实网络模型是*Barabasi-Albert*模型，基于优先连接，这使得中心节点自然地出现在图中）。
- en: In large graphs, supernodes are often potential bottlenecks of the application,
    especially when the business logic requires traversing the graph passing through
    them. Having properties that can help with rapidly filtering only the relevant
    edges during a graph traversal can dramatically speed up the process and achieve
    better performance.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型图中，超节点往往是应用的潜在瓶颈，尤其是在业务逻辑需要通过它们遍历图时。具有在图遍历期间快速过滤相关边的属性可以帮助显著加快处理过程并提高性能。
- en: JanusGraph exposes a standard API to query and traverse the graph via the **Apache
    TinkerPop** library ([https://tinkerpop.apache.org/](https://tinkerpop.apache.org/)),
    which is an open source, vendor-agnostic graph computing framework. TinkerPop
    provides a standard interface for querying and analyzing the underlying graph
    using the **Gremlin** graph traversal language. All TinkerPop-compatible graph
    database systems can therefore integrate seamlessly with one another. TinkerPop
    thus allows you to build "standard" serving layers that do not depend on the backend
    technology, giving you the freedom to choose/change the appropriate graph technology
    for your application depending on your actual needs. As a matter of fact, most
    of the graph databases (even Neo4j as we have seen previously) nowadays feature
    integration with TinkerPop, making switching between backend graph databases seamless
    and avoiding any vendor lock-in.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: JanusGraph通过**Apache TinkerPop**库（[https://tinkerpop.apache.org/](https://tinkerpop.apache.org/)）提供了一个标准的API来查询和遍历图，这是一个开源的、供应商无关的图计算框架。TinkerPop提供了一个标准接口，用于使用**Gremlin**图遍历语言查询和分析底层图。因此，所有TinkerPop兼容的图数据库系统都可以无缝地相互集成。因此，TinkerPop允许你构建“标准”的服务层，这些服务层不依赖于后端技术，从而给你自由选择/更改适合你应用的实际需要的图技术。实际上，大多数图数据库（甚至包括我们之前提到的Neo4j）现在都具备与TinkerPop的集成功能，这使得在后台图数据库之间切换变得无缝，并避免了任何供应商锁定。
- en: 'Besides Java connectors, Gremlin also has direct Python bindings thanks to
    the `gremlinpython` library, which allows Python applications to connect to and
    traverse graphs. In order to query the graph structure, we first need to connect
    to the database, using the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Java连接器之外，Gremlin还通过`gremlinpython`库提供了直接的Python绑定，这使得Python应用能够连接和遍历图。为了查询图结构，我们首先需要连接到数据库，使用以下方法：
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the connection is created, we can then instantiate `GraphTraversalSource`,
    which is the basis for all Gremlin traversals, and bind it to the connection we
    just created:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦建立了连接，我们就可以实例化`GraphTraversalSource`，这是所有Gremlin遍历的基础，并将其绑定到我们刚刚创建的连接：
- en: '[PRE5]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once `GraphTraversalSource` is instantiated, we can reuse it across the application
    to query the graph database. Imagine that we have imported the Movie graph database
    we described previously into JanusGraph; we can re-write the Cypher query we used
    previously to find all the co-actors of Keanu Reeves using Gremlin:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦实例化了`GraphTraversalSource`，我们就可以在整个应用中重用它来查询图数据库。想象一下，我们将之前描述的Movie图数据库导入到JanusGraph中；我们可以重新编写之前用来查找基努·里维斯所有合演者的Cypher查询，使用Gremlin：
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As can be seen from the preceding code lines, Gremlin is a functional language
    whereby operators are grouped together to form path-like expressions.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码行所示，Gremlin是一种函数式语言，其中操作符被分组在一起形成类似路径的表达式。
- en: Selecting between Neo4j and GraphX
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择Neo4j和GraphX
- en: Neo4j or GraphX? This is a question that often gets asked. However, as we have
    described briefly, the two pieces of software are not really competitors, but
    they rather target different needs. Neo4j allows us to store information in a
    graph-like structure and query the data, whereas GraphX makes it possible to analytically
    process a graph (especially for large graph dimensions). Although you could also
    use Neo4j as a processing engine (and indeed the Neo4j ecosystem features a Graph
    Data Science library, which is an actual processing engine) and GraphX could also
    be used as an in-memory stored graph, such approaches should be discouraged.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j或GraphX？这是一个经常被问到的问题。然而，正如我们简要描述的，这两款软件并不是真正的竞争对手，而是针对不同的需求。Neo4j允许我们以图结构存储信息并查询数据，而GraphX使得分析图（特别是对于大型图维度）成为可能。虽然你也可以将Neo4j用作处理引擎（实际上Neo4j生态系统包含一个图数据科学库，它实际上是一个处理引擎），GraphX也可以用作内存存储的图，但应避免这种做法。
- en: Graph processing engines usually compute KPIs that get stored in the graph database
    layers (potentially indexed such that querying and sorting become efficient) for
    later use. Thus, technologies such as GraphX are not competing with graph databases
    such as Neo4j, and they can very well co-exist within the same application to
    serve different purposes. As we stressed in the introduction, even in MVPs and
    at early stages, it is best to separate the two components, the graph processing
    engine and the graph querying engine, and use appropriate technologies for each
    of them.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图处理引擎通常计算KPI，这些KPI存储在图数据库层（可能被索引，以便查询和排序变得高效）以供以后使用。因此，像GraphX这样的技术并不与像Neo4j这样的图数据库竞争，它们可以在同一应用程序中很好地共存，以服务于不同的目的。正如我们在引言中所强调的，即使在MVP和早期阶段，最好是将两个组件——图处理引擎和图查询引擎——分开，并为每个组件使用适当的技术。
- en: Simple and easy-to-use libraries and tools do exist in both cases and we strongly
    encourage you to use them wisely in order to build a solid and reliable application
    that can be scaled out seamlessly.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，都存在简单易用的库和工具，我们强烈建议你明智地使用它们，以构建一个坚实可靠的应用程序，它可以无缝扩展。
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this section, we have provided you with the basic concepts of how to design,
    implement, and deploy data-driven applications that resort to graph modeling and
    leverage graph structures. We have highlighted the importance of a modular approach,
    which is usually the key to seamlessly scaling any data-driven use case from early-stage
    MVPs to production systems that can handle a large amount of data and large computational
    performances.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们向您提供了如何设计、实现和部署依赖图建模并利用图结构的数据驱动应用程序的基本概念。我们强调了模块化方法的重要性，这通常是任何数据驱动用例从早期MVP到可以处理大量数据和大量计算性能的生产系统的无缝扩展的关键。
- en: 'We have outlined the main architectural pattern, which should provide you with
    a guide when designing the backbone structure of your data-driven applications.
    We then continued by describing the main components that are the basis of graph-powered
    applications: *graph processing engines*, *graph databases*, and *graph querying
    languages*. For each component, we have provided an overview of the most common
    tools and libraries, with practical examples that will help you to build and implement
    your solutions. You should thus have by now a good overview of what the main technologies
    out there are and what they should be used for.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们概述了主要的架构模式，这应该在你设计数据驱动应用程序的主干结构时为你提供指导。然后我们继续描述了构成基于图的应用程序基础的主要组件：*图处理引擎*、*图数据库*和*图查询语言*。对于每个组件，我们都提供了最常见工具和库的概述，以及实用的示例，这将帮助你构建和实施你的解决方案。因此，你现在应该对目前的主要技术和它们的应用有了很好的了解。
- en: In the next chapter, we will turn to some recent developments and the latest
    research that trends in machine learning that has been applied to graphs. In particular,
    we will describe some of the latest techniques (such as generative neural networks)
    and applications (such as graph theory applied in neuroscience) available in the
    scientific literature, providing some practical examples and possible applications.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将转向一些最近的发展和最新研究，这些研究将机器学习的趋势应用于图。特别是，我们将描述科学文献中可用的最新技术（如生成型神经网络）和应用程序（如神经科学中应用的图论），并提供一些实用示例和可能的应用。
