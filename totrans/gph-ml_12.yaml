- en: 'Chapter 9: Building a Data-Driven Graph-Powered Application'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have provided you with both theoretical and practical ideas to allow
    you to design and implement machine learning models that leverage graph structures.
    Besides designing the algorithm, it is often very important to embed the modeling/analytical
    pipeline into a robust and reliable end-to-end application. This is especially
    true in industrial applications, where the end goal is usually to design and implement
    production systems that support data-driven decisions and/or provide users with
    timely information. However, creating a data-driven application that resorts to
    graph representation/modeling is indeed a challenging task that requires a proper
    design that is a lot more complicated than simply importing `networkx`. This chapter
    aims to provide you with a general overview of the key concepts and frameworks
    that are used when building graph-based, scalable, data-driven applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by providing an overview of the so-called **Lambda architectures**,
    which provide a framework to structure scalable applications that require large-scale
    processing and real-time updates. We will then continue by applying this framework
    in the context of *graph-powered applications*, that is, applications that leverage
    graph structures using techniques such as the ones described in this book. We
    will describe their two main analytical components: **graph processing engines**
    and **graph querying engines**. We''ll present some of the technologies used,
    both in shared memory machines and distributed memory machines, outlining similarities
    and differences. The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of Lambda architectures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lambda architectures for graph-powered applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technologies and examples of graph processing engines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graph querying engines and graph databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will be using Python 3.8 for all of our exercises. In the following code
    block, you can find a list of the Python libraries that need to be installed for
    this chapter using `pip`. For example, run `pip install networkx==2.5` on the
    command line, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: All the code files relevant to this chapter are available at [https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter09](https://github.com/PacktPublishing/Graph-Machine-Learning/tree/main/Chapter09).
  prefs: []
  type: TYPE_NORMAL
- en: Overview of Lambda architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In recent years, great focus has been given to designing scalable architectures
    that will allow, on the one hand, the *processing of a large amount of data*,
    and, on the other, *providing answers/alerts/actions in real time, using the latest
    available information*.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, these systems need to also be able to scale out seamlessly to a larger
    number of users or a larger amount of data by increasing resources horizontally
    (adding more servers) or vertically (using servers that are more powerful). **Lambda
    architecture** is a particular data-processing architecture that is designed to
    process massive quantities of data and ensure large throughput in a very efficient
    manner, preserving reduced latency and ensuring fault tolerance and negligible
    errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Lambda architecture is composed of three different layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The batch layer**: This layer sits on top of the (possibly distributed and
    scalable) storage system, and can handle and store all historical data, as well
    as performing **Online Analytical Processing** (**OLAP**) computation on the entire
    dataset. New data is continuously ingested and stored, as it would be traditionally
    done in data warehouse systems. Large-scale processing is generally achieved via
    massively parallel jobs, which aim at producing aggregation, structuring, and
    computation of relevant information. In the context of machine learning, model
    training that relies on historic information is generally done in this layer,
    thus producing a trained model to be used either in a batch prediction job or
    in real-time execution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The speed layer**: This is a low-latency layer that allows the real-time
    processing of the information to provide timely updates and information. It is
    generally fed by a streaming process, usually involving fast computation that
    does not require long computational time or load. It produces an output that is
    integrated with the data generated by the batch layer in (near) real time, providing
    support for **Online Transaction Processing** (**OLTP**) operations. The speed
    layer might also very well use some outputs of the OLAP computations, such as
    a trained model. Oftentimes, applications that use machine learning modeling in
    real time (for example, fraud detection engines used in credit card transactions)
    embed in their speed layers trained models that provide prompt predictions and
    trigger real-time alerts of potential fraud. Libraries may operate at an event
    level (such as Apache Storm) or over mini-batches (such as Spark Streaming), providing,
    depending on the use case, slightly different requirements for latency, fault
    tolerance, and computational speed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flask`, `fastapi`, or `turbogear`), which provide the data via specifically
    designed endpoints:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Functional diagram for an application based on Lambda architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16069_09_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.1 – Functional diagram for an application based on Lambda architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Lambda architectures have several benefits that have motivated and promoted
    their use, especially in the context of *big data* applications. In the following
    bullet points, we list some of the main pros of Lambda architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**No server management**: As the Lambda architectural design pattern typically
    abstracts the functional layers and does not require installing, maintaining,
    or administering any software/infrastructure'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexible scaling**: As the application can be either automatically scaled
    or scaled by controlling the number of processing units that are used in batch
    layers (for example, computing nodes) and/or in speed layers (for example, Kafka
    brokers) separately'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automated high availability**: Due to the fact that it represents a serverless
    design for which we already have built-in availability and fault tolerance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Business agility**: Reacts in real time to changing business/market scenarios'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Although very powerful and flexible, Lambda architectures come with some limitations
    mainly due to the presence of two interconnected processing flows: the **batch
    layer** and the **speed layer**. This may require developers to build and maintain
    separate code bases for batch and stream processes, resulting in more complexity
    and code overhead, which may lead to harder debugging, possible misalignment,
    and bug promotion.'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we have provided a short overview of Lambda architectures and their basic
    building blocks. For more details on how to design scalable architectures and
    the most commonly used architectural patterns, please refer to the book *Data
    Lake for Enterprises*, 2017, by Tomcy John and Pankaj Misra.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will show you how to implement a Lambda architecture
    for graph-powered applications. In particular, we will describe the main components
    and review the most common technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Lambda architectures for graph-powered applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When dealing with scalable, graph-powered, data-driven applications, the design
    of Lambda architectures is also reflected in the separation of functionalities
    between two crucial components of the analytical pipeline, as shown in *Figure
    9.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: The **graph processing engine** executes computations on the graph structure
    in order to extract features (such as embeddings), compute statistics (such as
    degree distributions, the number of edges, and cliques), compute metrics and **Key
    Performance Indicators** (**KPIs**) (such as centrality measures and clustering
    coefficients), and identify relevant subgraphs (for example, communities) that
    often require OLAP.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The **graph querying engine** allows us to persist network data (usually done
    via a graph database) and provides fast information retrieval and efficient querying
    and graph traversal (usually via graph querying languages). All of the information
    is already persisted in some data storage (that may or may not be in memory) and
    no further computation is required apart from (possibly) some final aggregation
    results, for which indexing is crucial to achieving high performance and low latency:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![FigurFigure 9.2 – Graph-based architecture, with the main components'
  prefs: []
  type: TYPE_NORMAL
- en: also reflected in a Lambda architectural pattern](img/B16069_09_02.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.2 – Graph-based architecture, with the main components also reflected
    in a Lambda architectural pattern
  prefs: []
  type: TYPE_NORMAL
- en: Graph processing engines sit on top of batch layers and produce outputs that
    may be stored and indexed in appropriate graph databases. These databases are
    the backend of graph querying engines, which allow relevant information to be
    easily and quickly retrieved, representing the operational views used by the serving
    layer. Depending on the use cases and/or the size of the graph, it often makes
    sense to run both the graph processing engine and the graph query engine on top
    of the same infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of storing the graph on a low-level storage layer (for example, the
    filesystem, HDFS, or S3), there are graph database options that could support
    both OLAP and OLTP. These provide, at the same time, a backend persistence layer
    where historical information processed by batch layers, together with real-time
    updates from the speed layer, is stored, and information to be queried efficiently
    by the serving layer.
  prefs: []
  type: TYPE_NORMAL
- en: As compared to other use cases, this condition is indeed quite peculiar for
    graph-powered, data-driven applications. Historical data often provides a topology
    on top of which new, real-time updates and OLAP outputs (KPIs, data aggregations,
    embeddings, communities, and so on) can be stored. This data structure also represents
    the information that is later queried by the serving layer that traverses the
    enriched graph.
  prefs: []
  type: TYPE_NORMAL
- en: Graph processing engines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To select the right technology for a **graph processing engine**, it is crucial
    to estimate the size in memory of the network compared to the capacity of the
    target architecture. You can start by using simpler frameworks that allow fast
    prototyping during the first phases of a project when the goal is to quickly build
    a **Minimum Viable Product** (**MVP**).
  prefs: []
  type: TYPE_NORMAL
- en: Such frameworks can then be substituted by more advanced tools later on when
    performance and scalability become more crucial. A microservice modular approach
    and proper structuring of these components will allow the switching of technologies/libraries
    independently from the rest of the application to target specific issues, which
    will also guide the choice of the backend stack.
  prefs: []
  type: TYPE_NORMAL
- en: Graph processing engines require information on the whole graphs to be accessed
    quickly, that is, having all of the graph in memory, and depending on the context,
    you might or might not need *distributed architectures*. As we saw in [*Chapter
    1*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014), *Getting Started with Graphs*,
    `networkx` is a great example of a library to build a graph processing engine
    when dealing with reasonably small datasets. When datasets get larger, but they
    can still fit in single servers or shared memory machines, other libraries may
    help to reduce computational time. As seen in [*Chapter 1*](B16069_01_Final_JM_ePub.xhtml#_idTextAnchor014),
    *Getting Started with Graphs*, using libraries other than `networkx` where graph
    algorithms are implemented in more performant languages, such as C++ or Julia,
    may dramatically speed up the computation by more than two orders of magnitude.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, there are cases where datasets grow so much that it is no longer technologically
    or economically viable to use shared memory machines of increasing capacity (fat
    nodes). In such cases, it is rather necessary to distribute the data on clusters
    of tens or hundreds of computing nodes, allowing horizontal scaling. The two most
    popular frameworks that can support a graph processing engine in these cases are
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Apache Spark GraphX**, which is the module of the Spark library that deals
    with graph structures ([https://spark.apache.org/graphx](https://spark.apache.org/graphx)).
    It involves a distributed representation of the graph using **Resilient Distributed
    Datasets** (**RDDs**) for both vertices and edges. The graph repartition throughout
    the computing nodes can be done either with an *edge-cut* strategy, which logically
    corresponds to dividing the nodes among multiple machines, or a *vertex-cut* strategy,
    which logically corresponds to assigning edges to different machines and allowing
    vertices to span multiple machines. Although written in Scala, GraphX features
    wrappers with both R and Python. GraphX already comes with some algorithms implemented,
    such as *PageRank*, *connected components*, and *triangle counting*. There are
    also other libraries that can be used on top of GraphX for other algorithms, such
    as **SparklingGraph**, which implements more centrality measures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache Giraph**, which is an iterative graph processing system built for
    high scalability ([https://giraph.apache.org/](https://giraph.apache.org/)). It
    was developed, and is currently used, by Facebook to analyze the social graph
    formed by users and their connections and is built on top of the Hadoop ecosystem
    for unleashing the potential of structured datasets at a massive scale. Giraph
    is natively written in Java and, similarly to GraphX, also provides a scalable
    implementation for some basic graph algorithms, such as *PageRank* and *shortest
    path*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When we consider scale-out to a distributed ecosystem, we should always keep
    in mind that the available choice for algorithms is significantly smaller than
    in a shared machine context. This is generally due to two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: First, implementing algorithms in a distributed way is a lot more complex than
    in a shared machine due to communication among nodes, which also reduces the overall
    efficiency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secondly, and more importantly, one fundamental mantra of big data analytics
    is that only algorithms that (nearly) scale linearly with the number of data points
    should be implemented in order to ensure horizontal scalability of the solution,
    by increasing the computational nodes as the dataset increases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this respect, both Giraph and GraphX allow you to define scalable, vertex-centric,
    iterative algorithms using standard interfaces based on **Pregel**, which can
    be seen as a sort of equivalent of iterative map-reduce operations for graphs
    (actually, iterative map-reduce operations applied to triplet node-edge-node instances).
    A Pregel computation is composed of a sequence of iterations, each called a **superstep**,
    each involving a node and its neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: 'During the superstep, *S*, a user-defined function is applied for each vertex,
    *V*. This function takes the messages sent to *V* in superstep *S – 1* as input
    and modifies the state of *V* and its outgoing edges. This function represents
    the mapping stage, which can be easily parallelized. Besides computing the new
    states of *V*, the function also sends messages to other vertices connected to
    *V*, which will receive this information at superstep *S + 1*. Messages are typically
    sent along outgoing edges, but a message may be sent to any vertex whose identifier
    is known. In *Figure 9.3*, we show a sketch of what a Pregel algorithm would look
    like when computing the maximum value over a network. For further details on this
    algorithm, please refer to the original paper, *Pregel: A System for Large-Scale
    Graph Processing*, written by Malewicz et al. in 2010:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Example of calculating a maximum value over a node property
    using Pregel'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16069_09_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.3 – Example of calculating a maximum value over a node property using
    Pregel
  prefs: []
  type: TYPE_NORMAL
- en: By using Pregel, you can easily implement other algorithms, such as *PageRank*
    or *connected components*, in a very efficient and general way, or even implement
    node embeddings' parallel variants (for an example, see *Distributed-Memory Vertex-Centric
    Network Embedding for Large-Scale Graphs*, Riazi and Norris, 2020).
  prefs: []
  type: TYPE_NORMAL
- en: Graph querying layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the last decade, due to the large diffusion of non-structured data, NoSQL
    databases have started to gain considerable attention and importance. Among them,
    **graph databases** are indeed extremely powerful to store information based on
    a relation between entities. Indeed, in many applications, data can naturally
    be seen as entities, associated with metadata in the form of node properties,
    connected by edges that also have properties that further describe the relationship
    between entities.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of graph databases are libraries or tools such as Neo4j, OrientDB,
    ArangoDB, Amazon Neptune, Cassandra, and JanusGraph (previously named TitanDB).
    In the following sections, we will briefly describe some of them, together with
    the languages that allow us to query and traverse the underlying graphs, which
    are called **graph querying languages**.
  prefs: []
  type: TYPE_NORMAL
- en: Neo4j
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At the time of writing, **Neo4J** ([https://neo4j.com/](https://neo4j.com/))
    is surely the most common graph database around, with a large community supporting
    its use and adoption. It features two editions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Community Edition*, released under a GPL v3 license, which allows users/developers
    to openly include Neo4j in their applications'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Enterprise Edition*, designed for commercial deployments where scale and availability
    are crucial'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neo4j can scale out to fairly large datasets via **sharding**, that is, distributing
    data over multiple nodes and parallelizing queries and aggregation over multiple
    instances of the database. Besides, the Neo4j federation also allows querying
    smaller separated graphs (sometimes even with a different schema) as if they were
    one large graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of Neo4j''s strong points are its flexibility (which allows the schema
    to be evolved) and its user-friendliness. In particular, many operations in Neo4j
    can be done through its query language, which is very intuitive and easy to learn:
    **Cypher**. Cypher can just be seen as the counterpart of SQL for graph databases.'
  prefs: []
  type: TYPE_NORMAL
- en: Testing out Neo4j and Cypher is extremely easy. You could install the Community
    Edition (via Docker; see the next section) or play around with an online sandbox
    version ([https://neo4j.com/sandbox/](https://neo4j.com/sandbox/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'By using the latter, you can import some built-in datasets, such as the Movie
    dataset, and start querying it using the Cypher query language. The Movie dataset
    is made up of 38 movies and 133 people that acted in, directed, wrote, reviewed,
    and produced them. Both the on-premises version and the online version are equipped
    with a user-friendly UI that allows the user to query and visualize the data (see
    *Figure 9.4*). We start by listing 10 actors in the Movie dataset, by simply querying
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'But let''s now leverage the information about relations between data points.
    We see that one of the actors that appears in the database is Keanu Reeves. We
    may wonder who all the actors that he has acted with in the listed movies are.
    This information can be easily retrieved using the following query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in the following figure, the query intuitively and graphically indicates
    in its syntax how to traverse the graph by declaring the path we are interested
    in:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Example of the Neo4j UI with the Cypher query to retrieve the
    co-actors of Keanu Reeves in the Movie dataset](img/B16069_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Example of the Neo4j UI with the Cypher query to retrieve the co-actors
    of Keanu Reeves in the Movie dataset
  prefs: []
  type: TYPE_NORMAL
- en: Besides Cypher, data can also be queried using Gremlin. This will be described
    shortly as a common interface for graph databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Neo4j also provides bindings with several programming languages, such as Python,
    JavaScript, Java, Go, Spring, and .NET. For Python in particular, there are several
    libraries that implement connections with Neo4j, such as `neo4j`, `py2neo`, and
    `neomodel`, of which `neo4j` is the official and supported one and provides direct
    connections to the database via a binary protocol. Creating a connection to the
    database and running a query is just a matter of a few lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: A query could be any Cypher query, for instance, the one written previously
    to retrieve the co-actors of Keanu Reeves.
  prefs: []
  type: TYPE_NORMAL
- en: JanusGraph – a graph database to scale out to very large datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Neo4j is an extremely great piece of software, unbeatable when you want to get
    things done quickly, thanks to its intuitive interface and query language. Neo4j
    is indeed a graph database suitable for production, but especially good in MVPs
    when agility is crucial. However, as data increases, its scalability based on
    sharding and breaking down large graphs into smaller subgraphs may not be the
    best option.
  prefs: []
  type: TYPE_NORMAL
- en: When the volume of the data increases substantially, you should probably start
    to consider other graph database options. Once again, this should be done only
    when the use case requirements start to hit the scalability limitation of Neo4j,
    as needs evolve from the MVP initial requirements.
  prefs: []
  type: TYPE_NORMAL
- en: In such cases, there are several options. Some of them are commercial products,
    such as Amazon Neptune or Cassandra. However, open source options are also available.
    Among them, we believe it is worth mentioning **JanusGraph** ([https://janusgraph.org/](https://janusgraph.org/)),
    which is a particularly interesting piece of software. JanusGraph is the evolution
    of a previously open source project that was called **TitanDB** and is now an
    official project under the Linux Foundation, also featuring support from top players
    in the tech landscape, such as IBM, Google, Hortonworks, Amazon, Expero, and Grakn
    Labs.
  prefs: []
  type: TYPE_NORMAL
- en: 'JanusGraph is a scalable graph database designed for storing and querying graphs
    distributed across a multi-machine cluster with hundreds of billions of vertices
    and edges. As a matter of fact, JanusGraph does not have a storage layer on its
    own, but it is rather a component, written in Java, that sits on top of other
    data storage layers, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Google Cloud Bigtable** ([https://cloud.google.com/bigtable](https://cloud.google.com/bigtable)),
    which is the cloud version of the proprietary data storage system built on Google
    File System, designed to scale a massive amount of data distributed across data
    centers (*Bigtable: A Distributed Storage System for Structured Data*, Fay Chang
    et al., 2006).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache HBase** ([https://hbase.apache.org/](https://hbase.apache.org/)),
    which is a non-relational database that features Bigtable capabilities on top
    of Hadoop and HDFS, thus ensuring similar scalability and fault tolerance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache Cassandra** ([https://cassandra.apache.org/](https://cassandra.apache.org/)),
    which is an open source distributed NoSQL database that allows handling a large
    amount of data, spanning multiple data centers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ScyllaDB** ([https://www.scylladb.com/](https://www.scylladb.com/)), which
    is specifically designed for real-time applications, is compatible with Apache
    Cassandra while achieving significantly higher throughputs and lower latencies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thus, JanusGraph inherits all the good features, such as scalability, high availability,
    and fault tolerance, from scalable solutions, abstracting a graph view on top
    of them.
  prefs: []
  type: TYPE_NORMAL
- en: With its integration with ScyllaDB, JanusGraph handles extremely fast, scalable,
    and high-throughput applications. Besides, JanusGraph also integrates indexing
    layers that can be based on Apache Lucene, Apache Solr, and Elasticsearch in order
    to allow even faster information retrieval and search functionalities within the
    graph.
  prefs: []
  type: TYPE_NORMAL
- en: The usage of highly distributed backends together with indexing layers allows
    JanusGraph to scale to enormous graphs, with hundreds of billions of nodes and
    edges, efficiently handling the so-called **supernodes**—in other words, nodes
    that have an extremely large degree, which often arise in real-world applications
    (remember that a very famous model for real networks is the *Barabasi-Albert*
    model, based on preferential attachments, which makes hubs naturally emerge within
    the graph).
  prefs: []
  type: TYPE_NORMAL
- en: In large graphs, supernodes are often potential bottlenecks of the application,
    especially when the business logic requires traversing the graph passing through
    them. Having properties that can help with rapidly filtering only the relevant
    edges during a graph traversal can dramatically speed up the process and achieve
    better performance.
  prefs: []
  type: TYPE_NORMAL
- en: JanusGraph exposes a standard API to query and traverse the graph via the **Apache
    TinkerPop** library ([https://tinkerpop.apache.org/](https://tinkerpop.apache.org/)),
    which is an open source, vendor-agnostic graph computing framework. TinkerPop
    provides a standard interface for querying and analyzing the underlying graph
    using the **Gremlin** graph traversal language. All TinkerPop-compatible graph
    database systems can therefore integrate seamlessly with one another. TinkerPop
    thus allows you to build "standard" serving layers that do not depend on the backend
    technology, giving you the freedom to choose/change the appropriate graph technology
    for your application depending on your actual needs. As a matter of fact, most
    of the graph databases (even Neo4j as we have seen previously) nowadays feature
    integration with TinkerPop, making switching between backend graph databases seamless
    and avoiding any vendor lock-in.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides Java connectors, Gremlin also has direct Python bindings thanks to
    the `gremlinpython` library, which allows Python applications to connect to and
    traverse graphs. In order to query the graph structure, we first need to connect
    to the database, using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the connection is created, we can then instantiate `GraphTraversalSource`,
    which is the basis for all Gremlin traversals, and bind it to the connection we
    just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Once `GraphTraversalSource` is instantiated, we can reuse it across the application
    to query the graph database. Imagine that we have imported the Movie graph database
    we described previously into JanusGraph; we can re-write the Cypher query we used
    previously to find all the co-actors of Keanu Reeves using Gremlin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As can be seen from the preceding code lines, Gremlin is a functional language
    whereby operators are grouped together to form path-like expressions.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting between Neo4j and GraphX
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Neo4j or GraphX? This is a question that often gets asked. However, as we have
    described briefly, the two pieces of software are not really competitors, but
    they rather target different needs. Neo4j allows us to store information in a
    graph-like structure and query the data, whereas GraphX makes it possible to analytically
    process a graph (especially for large graph dimensions). Although you could also
    use Neo4j as a processing engine (and indeed the Neo4j ecosystem features a Graph
    Data Science library, which is an actual processing engine) and GraphX could also
    be used as an in-memory stored graph, such approaches should be discouraged.
  prefs: []
  type: TYPE_NORMAL
- en: Graph processing engines usually compute KPIs that get stored in the graph database
    layers (potentially indexed such that querying and sorting become efficient) for
    later use. Thus, technologies such as GraphX are not competing with graph databases
    such as Neo4j, and they can very well co-exist within the same application to
    serve different purposes. As we stressed in the introduction, even in MVPs and
    at early stages, it is best to separate the two components, the graph processing
    engine and the graph querying engine, and use appropriate technologies for each
    of them.
  prefs: []
  type: TYPE_NORMAL
- en: Simple and easy-to-use libraries and tools do exist in both cases and we strongly
    encourage you to use them wisely in order to build a solid and reliable application
    that can be scaled out seamlessly.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we have provided you with the basic concepts of how to design,
    implement, and deploy data-driven applications that resort to graph modeling and
    leverage graph structures. We have highlighted the importance of a modular approach,
    which is usually the key to seamlessly scaling any data-driven use case from early-stage
    MVPs to production systems that can handle a large amount of data and large computational
    performances.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have outlined the main architectural pattern, which should provide you with
    a guide when designing the backbone structure of your data-driven applications.
    We then continued by describing the main components that are the basis of graph-powered
    applications: *graph processing engines*, *graph databases*, and *graph querying
    languages*. For each component, we have provided an overview of the most common
    tools and libraries, with practical examples that will help you to build and implement
    your solutions. You should thus have by now a good overview of what the main technologies
    out there are and what they should be used for.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will turn to some recent developments and the latest
    research that trends in machine learning that has been applied to graphs. In particular,
    we will describe some of the latest techniques (such as generative neural networks)
    and applications (such as graph theory applied in neuroscience) available in the
    scientific literature, providing some practical examples and possible applications.
  prefs: []
  type: TYPE_NORMAL
