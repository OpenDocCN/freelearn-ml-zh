- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Understanding H2O AutoML Architecture and Training
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 H2O AutoML 架构和训练
- en: Model training is one of the core components of a **Machine Learning** (**ML**)
    pipeline. It is the step in the pipeline where the system reads and understands
    the patterns in the dataset. This learning outputs a mathematical representation
    of the relationship between the different features in the dataset and the target
    value. The way in which the system reads and analyzes data depends on the ML algorithm
    being used and its intricacies. This is where the primary complexity of ML lies.
    Every ML algorithm has its own way of interpreting the data and deriving information
    from it. Every ML algorithm aims to optimize certain metrics while trading off
    certain biases and variances. Automation done by H2O AutoML further complicates
    this concept. Trying to understand how that would work can be overwhelming for
    many engineers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练是机器学习（**ML**）管道的核心组件之一。它是管道中系统读取和理解数据集中模式的一步。这种学习输出数据集中不同特征与目标值之间关系的数学表示。系统读取和分析数据的方式取决于所使用的
    ML 算法和其复杂性。这就是 ML 的主要复杂性所在。每个 ML 算法都有其自己的方式来解释数据并从中提取信息。每个 ML 算法都旨在优化某些指标，同时权衡某些偏差和方差。H2O
    AutoML 所做的自动化进一步复杂化了这一概念。试图理解它是如何工作的可能会让许多工程师感到不知所措。
- en: Don’t be discouraged by this complexity. All sophisticated systems can be broken
    down into simple components. Understanding these components and their interaction
    with each other is what helps us understand the system as a whole. Similarly,
    in this chapter, we will open up the black box, that is, H2O’s AutoML service,
    and try to understand what kind of magic makes the automation of ML possible.
    We shall first understand the architecture of H2O. We shall break it down into
    simple components and then understand what interaction takes place between the
    various components of H2O. Later, we will come to understand how H2O AutoML trains
    so many models and is able to optimize their hyperparameters to get the best possible
    model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 不要因为这种复杂性而气馁。所有复杂的系统都可以分解成简单的组件。理解这些组件及其相互之间的交互有助于我们理解整个系统。同样，在本章中，我们将打开黑盒，即
    H2O 的 AutoML 服务，并尝试理解是什么魔法使得机器学习的自动化成为可能。我们首先将了解 H2O 的架构。我们将将其分解成简单的组件，然后理解 H2O
    的各个组件之间发生什么样的交互。稍后，我们将了解 H2O AutoML 如何训练如此多的模型，并能够优化它们的超参数以获得最佳模型。
- en: 'In this chapter, we are going to cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Observing the high-level architecture of H2O
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 H2O 的高级架构
- en: Knowing the flow of interaction between the client and the H2O service
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解客户端与 H2O 服务之间交互的流程
- en: Understanding how H2O AutoML performs hyperparameter optimization and training
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 H2O AutoML 如何进行超参数优化和训练
- en: So, let’s begin by first understanding the architecture of H2O.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们首先了解 H2O 的架构。
- en: Observing the high-level architecture of H2O
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 观察 H2O 的高级架构
- en: To deep dive into H2O technology, we first need to understand its high-level
    architecture. It will not only help us understand what the different software
    components that make up the H2O AI stack are, but it will also help us understand
    how the components interact with each other and their dependencies.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解 H2O 技术，我们首先需要了解其高级架构。这不仅有助于我们理解构成 H2O AI 堆栈的不同软件组件，还有助于我们理解这些组件之间如何相互交互以及它们的依赖关系。
- en: 'With this in mind, let’s have a look at the H2O AI high-level architecture,
    as shown in the following diagram:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个前提下，让我们看一下 H2O AI 的高级架构，如下所示：
- en: '![Figure 4.1 – H2O AI high-level architecture ](img/B17298_04_001.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – H2O AI 高级架构](img/B17298_04_001.jpg)'
- en: Figure 4.1 – H2O AI high-level architecture
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – H2O AI 高级架构
- en: 'The H2O AI architecture is conceptually divided into two parts, each serving
    a different purpose in the software stack. The parts are as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: H2O AI 架构在概念上分为两部分，每一部分在软件堆栈中都有不同的作用。这两部分如下：
- en: '**Client layer** – This layer points to the client code that communicates with
    the H2O server.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户端层** – 这一层指向与 H2O 服务器通信的客户端代码。'
- en: '**Java Virtual Machine** (**JVM**) **components** – This layer indicates the
    H2O server and all of its JVM components that are responsible for the different
    functionalities of H2O AI, including AutoML.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Java 虚拟机**（**JVM**）**组件** – 这一层表示 H2O 服务器及其所有负责 H2O AI 不同功能的 JVM 组件，包括 AutoML。'
- en: The client and the JVM component layers are separated by the **network layer**.
    The network layer is nothing but the general internet, which requests are sent
    over.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端和 JVM 组件层之间由 **网络层** 分隔。网络层不过是普通的互联网，请求就是通过它发送的。
- en: Let’s dive deep into every layer to better understand their functionalities,
    starting with the first layer, the client layer.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入到每一层，以更好地理解它们的职能，从第一层，客户端层开始。
- en: Observing the client layer
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 观察客户端层
- en: 'The client layer comprises all the client code that you install in your system.
    You use this software program to send requests to the H2O server to perform your
    ML activities. The following diagram shows you the client layer from the H2O high-level
    architecture:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端层包括您在系统中安装的所有客户端代码。您使用这个软件程序向 H2O 服务器发送请求以执行您的机器学习活动。以下图表显示了 H2O 高级架构中的客户端层：
- en: '![Figure 4.2 – The client layer of H2O high-level architecture ](img/B17298_04_002.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – H2O 高级架构的客户层](img/B17298_04_002.jpg)'
- en: Figure 4.2 – The client layer of H2O high-level architecture
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – H2O 高级架构的客户层
- en: Every supported language will have its own H2O client code that is installed
    and used in the respective language’s script. All client code internally communicates
    with the H2O server via a REST API over a socket connection.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 每种受支持的语言都将拥有自己的 H2O 客户端代码，这些代码将在相应语言的脚本中安装和使用。所有客户端代码内部通过套接字连接，通过 REST API 与
    H2O 服务器通信。
- en: 'The following H2O clients exist for the respective languages:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 H2O 客户端分别适用于相应的语言：
- en: '**JavaScript**: H2O’s embedded web UI is written in JavaScript. When you start
    the H2O server, it starts a JavaScript web client that is hosted on http://localhost:54321\.
    You can log into this client with your web browser and communicate with the H2O
    server to perform your ML activities. The JavaScript client communicates with
    the H2O server via a REST API.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**JavaScript**：H2O 的嵌入式 Web UI 是用 JavaScript 编写的。当您启动 H2O 服务器时，它启动一个托管在 http://localhost:54321
    的 JavaScript Web 客户端。您可以使用 Web 浏览器登录此客户端，并与 H2O 服务器通信以执行您的机器学习活动。JavaScript 客户端通过
    REST API 与 H2O 服务器通信。'
- en: '`library(h2o)` and then using the imported `H2O` variable to import the dataset
    and train models. This is the R client that is interacting with the initialized
    H2O server and it does so using a REST API.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`library(h2o)` 然后使用导入的 `H2O` 变量导入数据集并训练模型。这是与初始化的 H2O 服务器交互的 R 客户端，它使用 REST
    API 进行交互。'
- en: '`import h2o` and then using the imported `H2O` variable to command the H2O
    server. This is the Python client that is interacting with the H2O server using
    a REST API.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import h2o` 然后使用导入的 `H2O` 变量来指挥 H2O 服务器。这是使用 REST API 与 H2O 服务器交互的 Python
    客户端。'
- en: '**Excel**: Microsoft Excel is spreadsheet software developed by Microsoft for
    Windows, macOS, Android, and iOS. H2O has support for Microsoft Excel as well
    since it is the most widely used spreadsheet software that handles large amounts
    of two-dimensional data. This data is well suited for analytics and ML. There
    is an H2O client for Microsoft Excel as well that enables Excel users to use H2O
    for ML activities through the Excel client.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Excel**：Microsoft Excel 是微软为 Windows、macOS、Android 和 iOS 开发的电子表格软件。由于它是处理大量二维数据的最广泛使用的电子表格软件，因此
    H2O 也支持 Microsoft Excel。H2O 还有一个针对 Microsoft Excel 的客户端，它允许 Excel 用户通过 Excel 客户端使用
    H2O 进行机器学习活动。'
- en: '**Tableau**: Tableau is interactive data visualization software that helps
    data analysts and scientists visualize data in the form of graphs and charts that
    are interactive in nature. H2O has support for Tableau and, as such, has a dedicated
    client for Tableau that adds ML capabilities to the data ingested by Tableau.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tableau**：Tableau 是交互式数据可视化软件，它帮助数据分析师和科学家以图表和图形的形式可视化数据，这些图表和图形本质上是交互式的。H2O
    支持 Tableau，因此有一个专门的 Tableau 客户端，它为 Tableau 摄入的数据添加了机器学习功能。'
- en: '**Flow**: As seen in [*Chapter 2*](B17298_02.xhtml#_idTextAnchor038), *Working
    with H2O Flow (H2O’s Web UI)*, H2O Flow is H2O’s web user interface that has all
    the functional capabilities of setting up the entire ML lifecycle in a notebook-style
    interface. This interface internally runs on JavaScript and similarly communicates
    with the H2O server via a standard REST API.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Flow**：如 [第 2 章](B17298_02.xhtml#_idTextAnchor038) 中所述，*使用 H2O Flow (H2O
    的 Web UI)*，H2O Flow 是 H2O 的 Web 用户界面，它具有在笔记本式界面中设置整个机器学习生命周期的所有功能。该界面内部运行在 JavaScript
    上，并且同样通过标准 REST API 与 H2O 服务器通信。'
- en: 'The following diagram shows you the interactions of various H2O clients with
    the same H2O server:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了各种 H2O 客户端与同一 H2O 服务器的交互：
- en: '![Figure 4.3 – Different clients communicating with the same H2O server ](img/B17298_04_003.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图4.3 – 不同客户端与同一H2O服务器通信](img/B17298_04_003.jpg)'
- en: Figure 4.3 – Different clients communicating with the same H2O server
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 不同客户端与同一H2O服务器通信
- en: As you can see in the diagram, all the different clients can communicate with
    the same instance of the H2O server. This enables a single H2O server to service
    different software products written in different languages.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，所有不同的客户端都可以与同一实例的H2O服务器通信。这使得单个H2O服务器能够服务用不同语言编写的不同软件产品。
- en: This covers the contents of the client layer; let’s move down to the next layer
    in the H2O’s high-level architecture, that is, the JVM component layer.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这涵盖了客户端层的所有内容；让我们继续向下移动到H2O高级架构的下一层，即JVM组件层。
- en: Observing the JVM component layer
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 观察JVM组件层
- en: The JVM is a runtime engine that runs Java programs in your system. The H2O
    cloud server runs on multiple **JVM processes**, also called **JVM nodes**. Each
    JVM node runs specific components of the H2O software stack.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: JVM是一个运行时引擎，它在您的系统中运行Java程序。H2O云服务器在多个**JVM进程**上运行，也称为**JVM节点**。每个JVM节点运行H2O软件堆栈的特定组件。
- en: 'The following diagram shows you the various JVM components that make up the
    H2O server:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了构成H2O服务器的各种JVM组件：
- en: '![Figure 4.4 – H2O JVM component layer ](img/B17298_04_004.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图4.4 – H2O JVM组件层](img/B17298_04_004.jpg)'
- en: Figure 4.4 – H2O JVM component layer
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 – H2O JVM组件层
- en: 'As seen in the preceding diagram, the JVM nodes are further split into three
    different layers, which are as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，JVM节点进一步分为三个不同的层级，具体如下：
- en: '`Shalala Scala` library is a code library that accesses dedicated domain-specific
    language that users can use to write their own programs and algorithms that H2O
    can use.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Shalala Scala`库是一个代码库，它访问用户可以用来编写自己的程序和算法的专用领域特定语言，这些程序和算法H2O可以使用。'
- en: '**The** **algorithm layer**: This layer contains all the inbuilt ML algorithms
    that H2O provides. The JVM processes in this layer are responsible for performing
    all the ML activities, such as importing datasets, parsing, calculating the mathematics
    for the respective ML algorithms, and overall training of models. This layer also
    has the prediction engine whose processes perform prediction and scoring functions
    using the trained models. Any custom algorithms imported into H2O are also housed
    in this layer and the JVM processes handle the execution just like the other algorithms.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**算法层**：该层包含H2O提供的所有内置机器学习算法。该层的JVM进程负责执行所有机器学习活动，如导入数据集、解析、为相应的机器学习算法计算数学，以及整体训练模型。该层还包含预测引擎，其进程使用训练好的模型执行预测和评分功能。任何导入到H2O中的自定义算法也位于这一层，JVM进程的处理方式与其他算法相同。'
- en: '**The** **resource management layer**: This layer contains all the JVM processes
    responsible for the efficient management of system resources such as memory and
    CPU when performing ML activities.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源管理层**：该层包含所有负责在执行机器学习活动时高效管理系统资源（如内存和CPU）的JVM进程。'
- en: 'Some of the JVM processes in this layer are as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 该层中的一些JVM进程如下：
- en: '**Fluid Vector frame**: A frame, also called a DataFrame, is the basic data
    storage object in H2O. Fluid Vector is a term coined by engineers at H2O.ai that
    points to the efficient (or, in other words, fluid) way by which the columns in
    the DataFrame can be added, updated, or deleted, as compared to the DataFrames
    in the data engineering domain, where they are usually said to be immutable in
    nature.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流体向量框架**：框架，也称为DataFrame，是H2O中的基本数据存储对象。流体向量是H2O的工程师们创造的一个术语，它指的是DataFrame中的列可以通过高效（或者说，流动）的方式添加、更新或删除，与数据工程领域的DataFrame相比，后者通常被认为是不可变的。'
- en: '**Distributed key-value store**: A key-value store or database is a data storage
    system that is designed to retrieve data or values efficiently and quickly from
    a distributed storage system using indexed keys. H2O uses this distributed key-value
    in-memory storage across its cluster for quick storage and lookups.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式键值存储**：键值存储或数据库是一个数据存储系统，它通过使用索引键从分布式存储系统中高效快速地检索数据或值。H2O在其集群中使用这种分布式键值内存存储，以实现快速存储和查找。'
- en: '**NonBlockingHashMap**: Usually in a database to provide **Atomicity, Consistency,
    Isolation, and Durability** (**ACID**) properties, locking is used to lock data
    when updates are being performed on it. This stops multiple processes from accessing
    the same resource. H2O uses a NonBlockingHashMap, which is an implementation of
    ConcurrentHashMap with better scaling capabilities.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NonBlockingHashMap**：通常在数据库中，为了提供 **原子性、一致性、隔离性和持久性**（**ACID**）属性，当对数据进行更新时，会使用锁定来锁定数据。这阻止了多个进程访问同一资源。H2O
    使用一个 NonBlockingHashMap，这是 ConcurrentHashMap 的一个实现，具有更好的扩展能力。'
- en: '**Job**: In programming, a job is nothing but a large piece of work that is
    done by software that serves a single purpose. H2O uses a jobs manager that orchestrates
    various jobs that perform complex tasks such as mathematical computations with
    increased efficiency and less CPU resource consumption.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Job**：在编程中，一个工作就是一个大型的工作，由软件执行，服务于单一目的。H2O 使用一个作业管理器来协调执行各种复杂任务的作业，如高效的数学计算和减少
    CPU 资源消耗。'
- en: '**MRTask**: H2O uses its own in-memory MapReduce task to perform its ML activities.
    MapReduce is a programming model that is used to process large amounts of computation
    or data read and writes using parallel execution of tasks on a distributed cluster.
    MapReduce helps the system perform computational activities faster than sequential
    computing.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MRTask**：H2O 使用其自己的内存中 MapReduce 任务来执行其机器学习活动。MapReduce 是一种编程模型，用于通过在分布式集群上并行执行任务来处理大量计算或数据读取和写入。MapReduce
    有助于系统比顺序计算更快地执行计算活动。'
- en: '**Fork/Join**: H2O uses a modified Java concurrency library called **jsr166y**
    to perform the concurrent execution of tasks. jsr166y is a very lightweight task
    execution framework that uses **Fork**, where the process breaks down a task into
    smaller subtasks, and **Join**, where the process joins the results of the subtasks
    together to get the final output of the task.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fork/Join**：H2O 使用一个名为 **jsr166y** 的修改版 Java 并发库来执行任务的并发执行。jsr166y 是一个非常轻量级的任务执行框架，它使用
    **Fork**，其中进程将任务分解成更小的子任务，以及 **Join**，其中进程将子任务的输出结果合并以获得任务的最终输出。'
- en: The entire JVM component layer lies on top of **Spark** and **Hadoop** data
    processing systems. The components in the JVM layer leverage these data processing
    cluster management engines to support cluster computing.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 整个 JVM 组件层位于 **Spark** 和 **Hadoop** 数据处理系统之上。JVM 层的组件利用这些数据处理集群管理引擎来支持集群计算。
- en: This sums up the entire high-level architecture of H2O’s software technology.
    With this background in mind, let’s move to the next section, where we shall understand
    the flow of interaction between the client and H2O and how the client-server interaction
    helps us perform ML activities.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这总结了 H2O 软件技术的整个高级架构。考虑到这个背景，让我们进入下一节，我们将了解客户端与 H2O 之间的交互流程以及客户端-服务器交互如何帮助我们执行机器学习活动。
- en: Learning about the flow of interaction between the client and the H2O service
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解客户端与 H2O 服务之间交互的流程
- en: In [*Chapter 1*](B17298_01.xhtml#_idTextAnchor017), *Understanding H2O AutoML
    Basics*, and [*Chapter 2*](B17298_02.xhtml#_idTextAnchor038), *Working with H2O
    Flow (H2O’s Web UI)*, we saw how we can send a command to H2O to import a dataset
    or train a model. Let’s try to understand what happens behind the scenes when
    you send a request to the H2O server, beginning with data ingestion.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第一章*](B17298_01.xhtml#_idTextAnchor017)，*理解 H2O AutoML 基础*，以及[*第二章*](B17298_02.xhtml#_idTextAnchor038)，*使用
    H2O Flow (H2O 的 Web UI)*中，我们看到了如何向 H2O 发送命令来导入数据集或训练模型。让我们尝试理解当您向 H2O 服务器发送请求时幕后发生的事情，从数据摄取开始。
- en: Learning about H2O client-server interactions during the ingestion of data
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在数据摄取期间了解 H2O 客户端-服务器交互
- en: 'The process of a system ingesting data is the same as how we read a book in
    real life: we open the book and start reading one line at a time. Similarly, when
    you want your program to read a dataset stored in your system, you will first
    inform the program about the location of the dataset. The program will then open
    the file and start reading the bytes of the data line by line and store it in
    its RAM. However, the issue with the type of sequential data reading in ML is
    that datasets tend to be huge in ML. Such data is often termed big data and can
    span from gigabytes to terabytes of volume. Reading such huge volumes of data
    by a system, no matter how fast it may be, will need a significant amount of time.
    This is time that ML pipelines do not have, as the aim of an ML pipeline is to
    make predictions. These predictions won’t have any value if the time to make decisions
    has already passed. For example, if you design an ML system that is installed
    in a car that automatically stops the car if it detects a possibility of collision,
    then the ML system would be useless if it spent all its time reading data and
    was too late to make collision predictions before they happened.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 系统摄取数据的过程与我们在现实生活中读书的方式相同：我们打开书本，逐行阅读。同样，当你想让你的程序读取存储在系统中的数据集时，你首先需要通知程序数据集的位置。然后程序会打开文件，逐行读取数据的字节，并将其存储在其RAM中。然而，在机器学习（ML）中，这种顺序数据读取的问题在于数据集往往非常大。这类数据通常被称为大数据，其体积可以从千兆字节到太字节不等。无论系统有多快，读取如此大量的数据都需要相当长的时间。这是机器学习管道所没有的时间，因为机器学习管道的目标是做出预测。如果做出决策的时间已经过去，这些预测将没有任何价值。例如，如果你设计了一个安装在汽车中的机器学习系统，该系统能够在检测到碰撞的可能性时自动停车，那么如果该系统花费所有时间读取数据，并且无法在碰撞发生之前及时做出预测，那么这个机器学习系统将毫无用处。
- en: This is where **parallel computing** or **cluster computing** comes in. A **cluster**
    is nothing but multiple processes connected together over a network that performs
    like a single entity. The main aim of cluster computing is to parallelize long-running
    sequential tasks using these multiple processes to finish the task quickly. It
    is for this reason that cluster computing plays a very important role in ML pipelines.
    H2O also rightly uses clusters to ingest data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是**并行计算**或**集群计算**发挥作用的地方。一个**集群**不过是通过网络连接在一起，表现得像一个单一实体的多个进程。集群计算的主要目的是通过这些多个进程并行化长时间运行的顺序任务，以快速完成任务。这就是为什么集群计算在机器学习管道中扮演着非常重要的角色。H2O也正确地使用了集群来摄取数据。
- en: Let’s observe how a data ingestion interaction request flows from the H2O client
    to the H2O server and how H2O ingests data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们观察数据摄取交互请求是如何从H2O客户端流向H2O服务器，以及H2O是如何摄取数据的。
- en: 'Refer to the following diagram to understand the flow of data ingestion interaction:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 参考以下图表以了解数据摄取交互的流程：
- en: '![Figure 4.5 – H2O data ingestion request interaction flow ](img/B17298_04_005.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图4.5 – H2O数据摄取请求交互流程](img/B17298_04_005.jpg)'
- en: Figure 4.5 – H2O data ingestion request interaction flow
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 – H2O数据摄取请求交互流程
- en: 'The following sequence of steps describes how a client request to the H2O cluster
    server to ingest data is serviced by H2O using the **Hadoop Distributed File System**
    (**HDFS**):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤序列描述了客户端请求H2O集群服务器摄取数据的过程，H2O使用**Hadoop分布式文件系统**（**HDFS**）来提供服务：
- en: '**Making the request**: Once the H2O cluster server is up and running, the
    user using the H2O client makes a data ingestion function call pointing to the
    location of the dataset (see **Step 1** in *Figure 4.5*). The function call in
    Python would be as follows:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**发起请求**：一旦H2O集群服务器启动并运行，使用H2O客户端的用户将发起一个指向数据集位置的摄取数据函数调用（参见*图4.5*中的**步骤1**）。Python中的函数调用如下所示：'
- en: '[PRE0]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The H2O client will extract the dataset location from the function call and
    internally create a REST API request (see **Step 2** in *Figure 4.5*). The client
    will then send the request over the network to the IP address where the H2O server
    is hosted.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: H2O客户端将从函数调用中提取数据集位置，并在内部创建一个REST API请求（参见*图4.5*中的**步骤2**）。然后客户端将通过网络将请求发送到H2O服务器所在的IP地址。
- en: '**H2O server processing the request**: Once the H2O cluster server receives
    the HTTP request from the client, it will extract the dataset location path value
    from the request and initiate the distributed dataset ingestion process (see **Step
    3** in *Figure 4.5*). The cluster nodes will then coordinate and parallelize the
    task of reading the dataset from the given path (see **Step 4** in *Figure 4.5*).'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**H2O 服务器处理请求**：一旦 H2O 集群服务器从客户端接收到 HTTP 请求，它将提取请求中的数据集位置路径值并启动分布式数据集摄取过程（参见
    *图 4.5* 中的 **步骤 3**）。然后集群节点将协调并并行化从给定路径读取数据集的任务（参见 *图 4.5* 中的 **步骤 4**）。'
- en: Each node will read a section of the dataset and store it in its cluster memory.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点将读取数据集的一部分并将其存储在其集群内存中。
- en: '**Ingestion of data**: The data read from the dataset location path will be
    stored in blocks in the distributed H2OFrame cluster memory (see **Step 1** in
    *Figure 4.6*). The block of data is stored in a distributed key-value store (see
    **Step 2** in *Figure 4.6*). Once the data is fully ingested, the H2O server will
    create a pointer that points to the ingested dataset stored in the key-value store
    and return it to the requesting client (see **Step 3** in *Figure 4.6*).'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据摄取**：从数据集位置路径读取的数据将存储在分布式 H2OFrame 集群内存中的块中（参见 *图 4.6* 中的 **步骤 1**）。数据块存储在分布式键值存储中（参见
    *图 4.6* 中的 **步骤 2**）。一旦数据完全摄取，H2O 服务器将创建一个指针，该指针指向存储在键值存储中的摄取数据集，并将其返回给请求的客户端（参见
    *图 4.6* 中的 **步骤 3**）。'
- en: 'Refer to the following diagram to understand the flow of interaction once data
    is ingested and H2O returns a response:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 参考以下图表以了解数据摄取后 H2O 返回响应时的交互流程：
- en: '![Figure 4.6 – H2O data ingestion response interaction flow ](img/B17298_04_006.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – H2O 数据摄取响应交互流程](img/B17298_04_006.jpg)'
- en: Figure 4.6 – H2O data ingestion response interaction flow
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – H2O 数据摄取响应交互流程
- en: Once the client receives the response, it creates a DataFrame object that contains
    this pointer, which the user can then later use to run any further executions
    on the ingested dataset (see **Step 4** in *Figure 4.6*). In this way, with the
    use of pointers and the distributed key-value store, H2O can work on DataFrame
    manipulations and usage without needing to transfer the huge volume of data that
    it ingested between the server and client.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦客户端收到响应，它将创建一个包含此指针的 DataFrame 对象，用户随后可以使用该指针在摄取的数据集上运行任何进一步的执行（参见 *图 4.6*
    中的 **步骤 4**）。通过使用指针和分布式键值存储，H2O 可以在 DataFrame 操作和使用上工作，而无需在服务器和客户端之间传输它摄取的大量数据。
- en: Now that we understand how H2O ingests data, let us now look into how it handles
    model training requests.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 H2O 如何摄取数据，让我们现在看看它是如何处理模型训练请求的。
- en: Knowing the sequence of interactions in H2O during model training
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解 H2O 在模型训练期间的交互序列
- en: During model training, there are plenty of interactions that take place, right
    from the users making the model training request to the user getting the trained
    ML model. The various components of H2O perform the model training activity using
    a series of coordinated messages and scheduled jobs.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练过程中，有许多交互发生，从用户发起模型训练请求到用户获取训练好的机器学习模型。H2O 的各个组件通过一系列协调的消息和计划好的作业执行模型训练活动。
- en: To better understand what happens internally when a model training request is
    sent to the H2O server, we need to dive deep into the sequence of interactions
    that occur during model training.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解当模型训练请求发送到 H2O 服务器时内部发生的情况，我们需要深入了解模型训练期间发生的交互序列。
- en: 'We shall understand the sequences of interactions by categorizing them as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下方式对交互序列进行分类来理解它们：
- en: The client starts a model training job.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端启动模型训练作业。
- en: H2O runs the model training job.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: H2O 执行模型训练作业。
- en: The client polls for job completion status.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端轮询作业完成状态。
- en: The client queries for the model information.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端查询模型信息。
- en: So, let’s begin first by understanding what happens when the client starts a
    model training job.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们首先了解当客户端启动模型训练作业时会发生什么。
- en: The client starts a model training job
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 客户端启动模型训练作业
- en: The model training job starts when the client first sends a model training request
    to H2O.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练作业开始于客户端首次向 H2O 发送模型训练请求。
- en: 'The following sequence diagram shows you the sequence of interactions that
    take place inside H2O when a client sends a model training request:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 以下序列图显示了当客户端发送模型训练请求时在 H2O 内部发生的交互序列：
- en: '![Figure 4.7 – Sequence of interactions in the model training request ](img/B17298_04_007.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图4.7 – 模型训练请求中的交互序列](img/B17298_04_007.jpg)'
- en: Figure 4.7 – Sequence of interactions in the model training request
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7 – 模型训练请求中的交互序列
- en: 'The following set of sequences takes place during a model training request:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练请求期间发生以下一系列操作：
- en: The user first runs a script that contains all the instructions and function
    calls to make a model training request to H2O.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户首先运行一个包含所有指令和函数调用的脚本，以向H2O发出模型训练请求。
- en: The script contains a model training function call with its respective parameters.
    This also includes an H2O AutoML function call that performs in a similar manner.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 脚本包含一个模型训练函数调用及其相应的参数。这还包括一个H2O AutoML函数调用，其操作方式类似。
- en: The function call instructs the respective language-specific H2O client, which
    creates a **POST** request that contains all the parametric information needed
    to train the model correctly.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 函数调用指示相应的语言特定H2O客户端，该客户端创建一个包含所有正确训练模型所需参数信息的**POST**请求。
- en: The H2O client will then perform a **curl** operation that sends the HTTP POST
    request to the H2O web server at the host IP address that it is hosted on.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，H2O客户端将执行一个**curl**操作，将HTTP POST请求发送到它所在的主机IP地址上的H2O网络服务器。
- en: From this point onward, the flow of information is performed inside the H2O
    server. The H2O server dispatches the request to the appropriate model training
    endpoint based on the model that was chosen to be trained by the user.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这一点开始，信息流在H2O服务器内部执行。H2O服务器根据用户选择的要训练的模型将请求派遣到适当的模型训练端点。
- en: This model training endpoint extracts the parameter values from the request
    and schedules a job.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此模型训练端点从请求中提取参数值并安排一个作业。
- en: The job, once scheduled, starts training the model.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦作业被安排，它就开始训练模型。
- en: The `job_id` for the training job, which can be used to identify the progress
    of the job.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练作业的`job_id`，可用于识别作业的进度。
- en: The job manager then sends the `job_id` back to the training job, which assigns
    it to itself.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作业管理器随后将`job_id`发送回训练作业，该作业将其分配给自己。
- en: The training job in turn returns the same `job_id` to the model training endpoint.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练作业随后将相同的`job_id`返回给模型训练端点。
- en: The model training endpoint creates a JSON response that contains this `job_id`
    and instructs the web server to send it back as a response to the client making
    the request.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练端点创建一个包含此`job_id`的JSON响应，并指示网络服务器将其作为响应发送给发出请求的客户端。
- en: The web server accordingly makes an HTTP response that transfers over the network
    and reaches the H2O client.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络服务器相应地做出HTTP响应，通过网络传输并到达H2O客户端。
- en: The client then creates a model object that contains this `job_id`, which the
    user can further use to track the progress of the model training or perform predictions
    once training is finished.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端随后创建一个包含此`job_id`的模型对象，用户可以使用它进一步跟踪模型训练的进度或在训练完成后进行预测。
- en: This sums up the sequence of events that take place inside the H2O server when
    it receives a model training request.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这总结了当H2O服务器接收到模型训练请求时内部发生的事件序列。
- en: Now that we understand what happens to the training request, let’s understand
    what the events that take place are when the training job created in *step 6*
    is training the model.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了训练请求会发生什么，让我们了解在*第6步*中创建的训练作业在训练模型时发生的事件。
- en: H2O runs the model training job
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: H2O运行模型训练作业
- en: In H2O, the training of a model is carried out by an internal model training
    job that acts independently from the user’s API request. The user’s API request
    just initiates the job; the job manager does the actual execution of the job.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在H2O中，模型的训练由一个内部模型训练作业执行，该作业独立于用户的API请求。用户的API请求只是启动作业；作业管理器执行实际的作业执行。
- en: 'The following sequence diagram shows you the sequence of interactions that
    take place when a model training job is training a model:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下序列图显示了模型训练作业在训练模型时发生的交互序列：
- en: '![Figure 4.8 – Sequence of interactions in the model training job execution
    ](img/B17298_04_008.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图4.8 – 模型训练作业执行中的交互序列](img/B17298_04_008.jpg)'
- en: Figure 4.8 – Sequence of interactions in the model training job execution
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8 – 模型训练作业执行中的交互序列
- en: 'The following set of sequences takes place during model training:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练期间发生以下一系列操作：
- en: The model training job breaks down the model training into tasks.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练作业将模型训练分解为任务。
- en: The job then submits the tasks to the execution framework.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，作业将任务提交给执行框架。
- en: The execution framework uses the Java concurrency library `jsr166y` to perform
    the task in a concurrent manner using the Fork/Join processing framework.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行框架使用 Java 并发库 `jsr166y` 通过 Fork/Join 处理框架以并发方式执行任务。
- en: Once a forked task is successfully executed, the execution library sends back
    the completed task results.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦分叉任务成功执行，执行库将发送回完成的任务结果。
- en: Once all the tasks are completed, the model that is trained is sent back to
    the model training job.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦所有任务完成，训练好的模型将被发送回模型训练作业。
- en: The model training job then stores the model object in H2O’s distributed key-value
    storage and tags it with a unique model ID.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练作业随后将模型对象存储在 H2O 的分布式键值存储中，并为其分配一个唯一的模型 ID。
- en: The training job then informs the job manager that model training is completed
    and the job manager is then free to move on to other training jobs.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练作业随后通知作业管理器模型训练已完成，然后作业管理器可以自由地继续处理其他训练作业。
- en: Now that we understand what goes on behind the scenes when a model training
    job is training a model, let’s move on to understand what happens when a client
    polls for the model training status.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了模型训练作业在训练模型时幕后发生的事情，那么让我们继续了解当客户端轮询模型训练状态时会发生什么。
- en: Client polls for model training job completion status
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 客户端轮询模型训练作业完成状态
- en: As mentioned previously, the actual training of the model is processed independently
    from the client’s training request. In this case, once a training request is sent
    by the client, the client is in fact unaware of the progress of the model. The
    client will need to constantly poll for the status of the model training job.
    This could be done either via manually making a request using HTTP or via certain
    client software features, such as progress trackers polling the H2O server for
    the status of the model training at regular intervals.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，模型的实际训练是独立于客户端的训练请求处理的。在这种情况下，一旦客户端发送了训练请求，客户端实际上并不知道模型的进度。客户端需要不断轮询模型训练作业的状态。这可以通过手动使用
    HTTP 发出请求或通过某些客户端软件功能来完成，例如进度跟踪器定期轮询 H2O 服务器以获取模型训练状态。
- en: 'The following sequence diagram shows you the sequence of interactions that
    takes place when a client polls for the model training job completion:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下序列图展示了当客户端轮询模型训练作业完成情况时发生的交互序列：
- en: '![Figure 4.9 – User polling for the model status sequence of interactions ](img/B17298_04_009.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.9 – 用户轮询模型状态交互序列](img/B17298_04_009.jpg)'
- en: Figure 4.9 – User polling for the model status sequence of interactions
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – 用户轮询模型状态交互序列
- en: 'The following set of sequences takes place when the client polls for the model
    training job completion:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当客户端轮询模型训练作业完成情况时，会发生以下一系列操作：
- en: To get the status of the model training, the client will make a `GET` request,
    passing the `job_id` that it received as a response when it first made a request
    to train a model.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要获取模型训练的状态，客户端将发出 `GET` 请求，传递它在首次请求训练模型时收到的 `job_id`。
- en: The `GET` request transfers over the network and to the H2O web server at the
    host IP address.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`GET` 请求通过网络传输到主机 IP 地址的 H2O 网络服务器。'
- en: The H2O web server dispatches the request to the H2O jobs endpoint.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: H2O 网络服务器将请求调度到 H2O 作业端点。
- en: The H2O jobs endpoint will then query the jobs manager, requesting the status
    of the `job_id` that was passed in the `GET` request.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: H2O 作业端点随后将查询作业管理器，请求 `GET` 请求中传递的 `job_id` 的状态。
- en: The job manager will return the job info of the respective `job_id` that contains
    information about the progress of the model training.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作业管理器将返回相应 `job_id` 的作业信息，其中包含有关模型训练进度的信息。
- en: The H2O jobs endpoint will prepare a JSON response containing the job information
    for the `job_id` and send it to the H2O web server.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: H2O 作业端点将为 `job_id` 准备包含作业信息的 JSON 响应，并将其发送到 H2O 网络服务器。
- en: The H2O web server will in turn send the JSON as a response back to the client
    making the request.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: H2O 网络服务器随后将 JSON 作为响应发送回发起请求的客户端。
- en: Upon receiving the response, the client will unpack this JSON and update the
    user about the status of the model training based on the job information.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接收到响应后，客户端将解包此 JSON 并根据作业信息更新用户关于模型训练状态的了解。
- en: This sums up the various interactions that take place when a client polls for
    the status of model training. With this in mind, let’s now see what happens when
    a client requests for the model info once it is informed that the model training
    job has finished training the model.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这总结了当客户端轮询模型训练状态时发生的各种交互。考虑到这一点，现在让我们看看当客户端在得知模型训练作业已完成模型训练后请求模型信息时会发生什么。
- en: Client queries for model information
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 客户端查询模型信息
- en: Once a model is trained successfully, the user will most likely want to analyze
    the details of the model. An ML model has plenty of metadata associated with its
    performance and quality. This metadata is very useful even before a model is used
    for predictions. But as we saw in the previous section, the model training process
    was independent of the user’s request, and H2O did not return a model object once
    training was complete. However, the H2O server does provide an API, using which
    you can get the information about a model already stored in the server.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练成功，用户很可能会想要分析模型的详细信息。机器学习模型与其性能和质量相关联的元数据非常丰富。即使模型尚未用于预测，这些元数据也非常有用。但是，正如我们在上一节中看到的，模型训练过程与用户的请求无关，一旦训练完成，H2O
    不会返回模型对象。然而，H2O 服务器确实提供了一个 API，使用它可以获取服务器上已存储的模型信息。
- en: 'The following sequence diagram shows you the sequence of interactions that
    take place when a client requests information about a trained model:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下序列图显示了客户端请求有关已训练模型的信息时发生的交互序列：
- en: '![Figure 4.10 – User querying for model information ](img/B17298_04_010.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.10 – 用户查询模型信息](img/B17298_04_010.jpg)'
- en: Figure 4.10 – User querying for model information
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – 用户查询模型信息
- en: 'The following set of sequences takes place when the client polls for the model
    training job completion:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当客户端轮询模型训练作业完成时，会发生以下一系列操作：
- en: To get the model information, the client will make a `GET` request passing the
    unique `model_id` of the ML model.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要获取模型信息，客户端将发送一个 `GET` 请求，传递机器学习模型的唯一 `model_id`。
- en: The `GET` request transfers over the network and to the H2O web server at the
    host IP address.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`GET` 请求通过网络传输到主机 IP 地址的 H2O 网络服务器。'
- en: The H2O web server dispatches the request to the H2O model endpoint.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: H2O 网络服务器将请求调度到 H2O 模型端点。
- en: All the model information is stored in H2O’s distributed key-value storage when
    the model training job finishes training the model. The H2O model endpoint will
    query this distributed key-value storage with the `model_id` as the filter.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当模型训练作业完成模型训练时，所有模型信息都存储在 H2O 的分布式键值存储中。H2O 模型端点将使用 `model_id` 作为过滤器查询这个分布式键值存储。
- en: The distributed key-value storage will return all the model information for
    the `model_id` passed to it.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分布式键值存储将返回传递给它的 `model_id` 的所有模型信息。
- en: The H2O model endpoint will then prepare a JSON response containing the model
    information and send it to the H2O web server.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，H2O 模型端点将准备一个包含模型信息的 JSON 响应，并将其发送到 H2O 网络服务器。
- en: The H2O web server will in turn send the JSON as a response back to the client
    making the request.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: H2O 网络服务器将相应地将 JSON 作为响应发送回发起请求的客户端。
- en: Upon receiving the response, the client will extract all the model information
    and display it to the user.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在收到响应后，客户端将提取所有模型信息并显示给用户。
- en: A model, once trained, is stored directly in the H2O server itself for quick
    access whenever there are any prediction requests. You can download the H2O model
    as well; however, any model not imported into the H2O server cannot be used for
    predictions.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，它将直接存储在 H2O 服务器本身中，以便在有任何预测请求时快速访问。您还可以下载 H2O 模型；然而，任何未导入到 H2O 服务器的模型都不能用于预测。
- en: This sums up the entire sequence of interactions that takes place in various
    parts of the H2O client-server communication. Now that we understand how H2O trains
    models internally using jobs and the job manager, let’s dive deeper and try to
    understand what happens when H2O AutoML trains and optimizes hyperparameters,
    eventually selecting the best model.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这总结了 H2O 客户端-服务器通信中各个部分发生的整个交互序列。现在我们了解了 H2O 如何使用作业和作业管理器内部训练模型，让我们进一步深入，尝试理解当
    H2O AutoML 训练和优化超参数，最终选择最佳模型时会发生什么。
- en: Understanding how H2O AutoML performs hyperparameter optimization and training
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 H2O AutoML 如何执行超参数优化和训练
- en: Throughout the course of this book, we have marveled at how the AutoML process
    automates the sophisticated task of training and selecting the best model without
    us needing to lift a finger. Behind every automation, however, there is a series
    of simple steps that is executed in a sequential manner.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的整个过程中，我们惊叹于AutoML过程如何自动化训练和选择最佳模型这一复杂的任务，而无需我们动手。然而，在每一次自动化背后，都有一系列简单的步骤，这些步骤以顺序的方式执行。
- en: Now that we have a good understanding of H2O’s architecture and how to use H2O
    AutoML to train models, we are now ready to finally open the black box, that is,
    H2O AutoML. In this section, we shall understand what H2O AutoML does behind the
    scenes so that it automates the entire process of training and selecting the best
    ML models.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对H2O的架构以及如何使用H2O AutoML来训练模型有了很好的理解，我们现在终于可以打开黑盒，即H2O AutoML。在本节中，我们将了解H2O
    AutoML在幕后做了什么，以便它能够自动化整个训练和选择最佳机器学习模型的过程。
- en: The answer to this question is pretty simple. H2O AutoML automates the entire
    ML process using **grid search hyperparameter optimization**.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的答案相当简单。H2O AutoML通过使用**网格搜索超参数优化**自动完成整个机器学习过程。
- en: Grid search hyperparameter optimization sounds very intimidating to a lot of
    non-experts, but the concept in itself is actually very easy to understand, provided
    that you know some of the basic concepts in model training, especially the importance
    of **hyperparameters**.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 网格搜索超参数优化对于许多非专业人士来说听起来非常令人畏惧，但如果你了解一些模型训练的基本概念，特别是**超参数**的重要性，这个概念本身实际上是非常容易理解的。
- en: So, before we dive into grid search hyperparameter optimization, let’s first
    come to understand what hyperparameters are.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在我们深入探讨网格搜索超参数优化之前，让我们首先了解什么是超参数。
- en: Understanding hyperparameters
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解超参数
- en: 'Most software engineers are aware of what parameters are: certain variables
    containing certain user input data, or any system-calculated data that is fed
    to another function or process. In ML, however, this concept is slightly complicated
    due to the introduction of hyperparameters. In the field of ML, there are two
    types of parameters. One type we call the **model parameters**, or just parameters,
    and the other is **hyperparameters**. Even though they have a similar name, there
    are some important differences between them that all software engineers should
    keep in mind when working in the ML space.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数软件工程师都知道什么是参数：包含某些用户输入数据或任何系统计算数据，这些数据被馈送到另一个函数或过程中的某些变量。然而，在机器学习中，由于超参数的引入，这个概念稍微复杂一些。在机器学习领域，有两种类型的参数。一种我们称之为**模型参数**，或简称参数，另一种是**超参数**。尽管它们的名称相似，但它们之间有一些重要的区别，所有在机器学习领域工作的软件工程师都应该记住。
- en: 'So, let’s understand them by simple definition:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们通过简单的定义来理解它们：
- en: '**Model parameters**: A model parameter is a parameter value that is calculated
    or learned by the ML algorithm from the given dataset during model training. Some
    examples of basic model parameters are **mean** or **standard deviation**, **weights**,
    and **biases** of data in the dataset. These are elements that we learn from the
    training data when we are training the model and these are the parametric values
    that the ML algorithm uses to train the ML model. Model parameters are also called
    **internal parameters**. Model parameters are not adjustable in a given ML training
    scenario.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型参数**：模型参数是机器学习算法在模型训练过程中从给定数据集中计算或学习到的参数值。一些基本的模型参数示例包括数据集中的**均值**或**标准差**、**权重**和**偏差**。这些是我们从训练数据中学习到的元素，这些是我们机器学习算法用来训练机器学习模型的参数值。模型参数也称为**内部参数**。在给定的机器学习训练场景中，模型参数是不可调整的。'
- en: '**Hyperparameters**: Hyperparameters are configurations that are external to
    the model training and are not derived from the training dataset. These are parametric
    values that are set by the ML practitioner and are used to derive the model parameters.
    They are values that are heuristically discovered by the ML practitioner and input
    to the ML algorithm before model training begins. Some simple examples of hyperparameters
    are the **number of trees** in a random forest, or the **learning rate** in regression
    algorithms. Every type of ML algorithm will have its own required set of hyperparameters.
    Hyperparameters are adjustable and are often experimented with to get the optimal
    model in a given ML training scenario.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超参数**：超参数是模型训练之外的外部配置，不是从训练数据集中派生出来的。这些是由机器学习实践者设置的参数值，用于推导模型参数。它们是机器学习实践者通过启发式方法发现并输入到模型训练开始之前的值。一些简单的超参数例子包括随机森林中的**树的数量**，或者回归算法中的**学习率**。每种机器学习算法都将有其自己所需的一组超参数。超参数是可调整的，并且通常在给定的机器学习训练场景中通过实验来获得最优模型。'
- en: 'The aim of training an optimal model is simple:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 训练最优模型的目标很简单：
- en: You select the best combination of hyperparameters.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你选择最佳的超参数组合。
- en: These hyperparameters generate the ideal model parameters.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些超参数生成理想的模型参数。
- en: These model parameters train a model with the lowest possible error rate.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些模型参数训练出一个错误率最低的模型。
- en: Sounds simple enough. However, there is a catch. Hyperparameters are not intuitive
    in nature. One cannot simply just observe the data and decide *x* value for the
    hyperparameter will get us the best model. Finding the perfect hyperparameter
    is a trial-and-error process, where the aim is to find a combination that minimizes
    errors.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来很简单。然而，这里有一个问题。超参数在本质上并不直观。人们不能仅仅观察数据并决定超参数的*x*值将给我们带来最佳模型。找到完美的超参数是一个试错过程，其目的是找到最小化错误的一个组合。
- en: Now, the next question that arises is how you find the best hyperparameters
    for training a model. This is where hyperparameter optimization comes into the
    picture, which we will cover next.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，接下来出现的问题是，你如何找到训练模型的最佳超参数。这就是超参数优化出现的地方，我们将在下一章中介绍。
- en: Understanding hyperparameter optimization
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解超参数优化
- en: Hyperparameter optimization, also known as **hyperparameter tuning**, is the
    process of choosing the best set of hyperparameters for a given ML algorithm to
    train the most optimal model. The best combination of these values minimizes a
    predefined **loss function** of an ML algorithm. A loss function in simple terms
    is a function that measures some unit of error. The loss function is different
    for different ML algorithms. A model with the lowest possible amount of errors
    among a potential combination of hyperparameter values is said to have optimal
    hyperparameters.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数优化，也称为**超参数调整**，是指为给定的机器学习算法选择最佳超参数集的过程，以训练出最优模型。这些值的最佳组合可以最小化机器学习算法预定义的**损失函数**。简单来说，损失函数是一个衡量某些错误单位的函数。不同的机器学习算法有不同的损失函数。在潜在的超参数值组合中，具有最低错误量的模型被称为具有最优超参数。
- en: 'There are many approaches to implementing hyperparameter optimization. Some
    of the most common ones are **grid search**, **random grid search**, **Bayesian
    optimization**, and **gradient-based optimization**. Each is a very broad topic
    to cover; however, for this chapter, we shall focus on only two approaches: grid
    search and random grid search.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 实现超参数优化有许多方法。其中一些最常见的方法是**网格搜索**、**随机网格搜索**、**贝叶斯优化**和**基于梯度的优化**。每个都是一个非常广泛的话题；然而，对于本章，我们将只关注两种方法：网格搜索和随机网格搜索。
- en: Tip
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'If you want to explore more about the Bayesian optimization technique for hyperparameter
    tuning, then feel free to do so. You can get additional information on the topic
    at this link: [https://arxiv.org/abs/1807.02811](https://arxiv.org/abs/1807.02811).
    Similarly, you can get more details on gradient-based optimization at this link:
    [https://arxiv.org/abs/1502.03492](https://arxiv.org/abs/1502.03492).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于超参数调整的贝叶斯优化技术，那么请随意探索。你可以在以下链接中找到有关此主题的更多信息：[https://arxiv.org/abs/1807.02811](https://arxiv.org/abs/1807.02811)。同样，你可以在以下链接中找到更多关于基于梯度的优化的详细信息：[https://arxiv.org/abs/1502.03492](https://arxiv.org/abs/1502.03492)。
- en: It is actually the random grid search approach that is used by H2O’s AutoML
    for hyperparameter optimization, but you need to have an understanding of the
    original grid search approach to optimization in order to understand random grid
    search.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，H2O的AutoML用于超参数优化的方法是随机网格搜索方法，但你需要理解优化中的原始网格搜索方法，以便理解随机网格搜索。
- en: So, let’s begin with grid search hyperparameter optimization.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们从网格搜索超参数优化开始。
- en: Understanding grid search optimization
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解网格搜索优化
- en: Let’s take the example of the Iris Flower Dataset that we used in [*Chapter
    1*](B17298_01.xhtml#_idTextAnchor017), *Understanding H2O AutoML Basics*. In this
    dataset, we are training a model that is learning from the sepal width, sepal
    length, petal width, and petal length to predict the classification type of the
    flower.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以我们在[*第一章*](B17298_01.xhtml#_idTextAnchor017)中使用的例子，即*理解H2O AutoML基础*为例。在这个数据集中，我们正在训练一个模型，该模型通过学习花瓣宽度、花瓣长度、萼片宽度和萼片长度来预测花的分类类型。
- en: 'Now, the first question you are faced with is: which ML algorithm should be
    used to train a model? Assuming you do come up with an answer to that and choose
    an algorithm, the next question you will have is: which combination of hyperparameters
    will get me the optimal model?'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你面临的首要问题是：应该使用哪种机器学习算法来训练模型？假设你确实找到了答案并选择了一个算法，那么接下来的问题将是：哪个超参数组合将给我带来最优的模型？
- en: Traditionally, ML practitioners would train multiple models for a given ML algorithm
    with different combinations of hyperparameter values. They would then compare
    the performance of these models and find out which hyperparameter combination
    trained the model with the lowest possible error rate.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，机器学习从业者会为给定的机器学习算法训练多个模型，这些模型使用不同的超参数值组合。然后，他们会比较这些模型的性能，找出哪个超参数组合训练出的模型具有最低的可能错误率。
- en: 'The following diagram shows you how different combinations of hyperparameters
    train different models with varying performance:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表展示了不同的超参数组合如何训练出性能各异的模型：
- en: '![Figure 4.11 – Manual hyperparameter tuning ](img/B17298_04_011.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图4.11 – 手动超参数调整](img/B17298_04_011.jpg)'
- en: Figure 4.11 – Manual hyperparameter tuning
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11 – 手动超参数调整
- en: Let’s take an example where you are training a decision tree. Its hyperparameters
    are the number of trees, `ntrees`, and the maximum depth, `max_depth`. If you
    are performing a manual search for hyperparameter optimization, then you will
    initially start out with values like `50`, `100`, `150`, and `200` for `ntrees`
    and `5`, `10`, and `50` for `max_depth`, train the models, and measure their performance.
    When you find out which combination of those values gives you the best results,
    you set those values as the threshold and tweak them with smaller increments or
    decrements, retrain the models with these new hyperparameter values, and compare
    the performance again. You keep doing this until you find the best set of hyperparameter
    values that gives you the optimum performance.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以你正在训练决策树为例。它的超参数是树的数量`ntrees`和最大深度`max_depth`。如果你正在进行手动搜索以进行超参数优化，那么你将最初从`ntrees`的值`50`、`100`、`150`和`200`以及`max_depth`的值`5`、`10`和`50`开始，训练模型并测量它们的性能。当你发现哪个值的组合给你带来最佳结果时，你将这些值设置为阈值，并通过较小的增量或减量调整它们，使用这些新的超参数值重新训练模型，并再次比较性能。你一直这样做，直到找到最佳的超参数值组合，以获得最佳性能。
- en: This method, however, has a few drawbacks. Firstly, the range of values you
    can try out initially is limited since you can only train so many models manually.
    So, if you have a hyperparameter whose value can range between 1 and 10,000, then
    you need to make sure that you cover enough ground to not miss the ideal value
    by a huge margin. If you do, then you will end up constantly tweaking the value
    with smaller increments or decrements, spending lots of time optimizing. Secondly,
    as the number of hyperparameters increases and the number of possible values and
    combinations of values you want to use increases, it becomes tedious for the ML
    practitioner to manage and run optimization processes.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法有几个缺点。首先，你可以尝试的值范围有限，因为你只能手动训练这么多模型。所以，如果你有一个值介于1到10,000之间的超参数，那么你需要确保你覆盖足够的范围，以免因为巨大的误差而错过理想值。如果你这样做，那么你将不断以较小的增量或减量调整值，花费大量时间进行优化。其次，随着超参数数量的增加以及你想要使用的可能值和值组合数量的增加，机器学习从业者管理并运行优化过程变得繁琐。
- en: To manage and partially automate this process of training multiple models with
    different hyperparameters, grid search was invented. Grid search is also known
    as **Cartesian Hyperparameter Search** or **exhaustive search**.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 为了管理和部分自动化使用不同超参数训练多个模型的过程，发明了网格搜索。网格搜索也被称为**笛卡尔超参数搜索**或**穷举搜索**。
- en: 'Grid search basically maps all the values for given hyperparameters over a
    Cartesian grid and exhaustively searches combinations in the grid to train models.
    Refer to the following diagram, which shows you how a hyperparameter grid search
    translates to multiple models being trained:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 网格搜索基本上将给定超参数的所有值映射到笛卡尔网格上，并在网格中全面搜索组合以训练模型。参考以下图表，它展示了超参数网格搜索如何转化为训练多个模型：
- en: '![Figure 4.12 – Cartesian grid search hyperparameter tuning ](img/B17298_04_012.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图4.12 – 卡尔丹网格搜索超参数调整](img/B17298_04_012.jpg)'
- en: Figure 4.12 – Cartesian grid search hyperparameter tuning
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12 – 卡尔丹网格搜索超参数调整
- en: In the diagram, we can see that we have a two-dimensional grid that maps the
    two hyperparameters. Using this Cartesian grid, we can further expand the combination
    of hyperparameter values to 10 values per parameter, extending our search. The
    grid search approach exhaustively searches across different values of the two
    hyperparameters. So, it will have 100 different combinations and will train 100
    different models in total, all trained without needing much manual intervention.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，我们可以看到我们有一个二维网格，它映射了两个超参数。使用这个笛卡尔网格，我们可以进一步将超参数值的组合扩展到每个参数10个值，从而扩展我们的搜索。网格搜索方法会全面搜索两个超参数的不同值。因此，它将有100种不同的组合，总共训练100个不同的模型，所有这些模型都是在不需要太多手动干预的情况下训练的。
- en: H2O does have grid search capabilities that users can use to test out their
    own manually implemented grid search approach for hyperparameter optimization.
    When training models using grid search, H2O will map all models that it trains
    to the respective hyperparameter value combinations of the grid. H2O also allows
    you to sort all these models based on any supported model performance metrics.
    This sorting helps you quickly find the best-performing model based on the metric
    values. We shall explore more about performance metrics in [*Chapter 6*](B17298_06.xhtml#_idTextAnchor129),
    *Understanding H2O AutoML Leaderboard and Other Performance Metrics*.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: H2O确实具有网格搜索功能，用户可以使用它来测试他们自己手动实现的网格搜索方法进行超参数优化。当使用网格搜索训练模型时，H2O会将所有训练的模型映射到网格中相应的超参数值组合。H2O还允许你根据任何支持的模型性能指标对所有这些模型进行排序。这种排序可以帮助你根据指标值快速找到性能最佳的模型。我们将在[*第6章*](B17298_06.xhtml#_idTextAnchor129)中进一步探讨性能指标，*理解H2O
    AutoML排行榜和其他性能指标*。
- en: However, despite automating and introducing a quality-of-life improvement to
    manual searching, there are still some drawbacks to this approach. Grid search
    hyperparameter optimization suffers from what is called the **curse of dimensionality**.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管自动化并引入了提高生活质量的改进，这种方法仍然存在一些缺点。网格搜索超参数优化受到所谓的**维度诅咒**的影响。
- en: The curse of dimensionality was a term coined by **Richard E. Bellman** when
    considering problems in dynamic programming. From the point of view of ML, this
    concept states that as the number of hyperparameter combinations increases, the
    number of evaluations that the grid search will perform increases exponentially.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 维度诅咒这个术语是由**理查德·E·贝尔曼**在考虑动态规划问题时提出的。从机器学习的角度来看，这个概念表明，随着超参数组合数量的增加，网格搜索将执行的评估数量将以指数级增长。
- en: 'For example, let’s say you have a hyperparameter *x* and you want to try out
    integer values 1-20\. In this case, you will end up doing 20 evaluations, in other
    words, training 20 models. Now suppose that there is another hyperparameter *y*
    and you want to try out the values 1-20 in combination with the values for *x*.
    Your combinations will be as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你有一个超参数*x*，并且你想尝试1到20的整数值。在这种情况下，你将进行20次评估，换句话说，训练20个模型。现在假设还有一个超参数*y*，并且你想尝试与*x*的值相结合的1到20的值。你的组合将如下所示：
- en: '*(1,1), (1,2), (1,3), (1,4), (1,5), (1,6), (1,7)….(20,20) where (x, y)*'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '*(1,1), (1,2), (1,3), (1,4), (1,5), (1,6), (1,7)……(20,20)，其中(x, y)*'
- en: Now, there are 20x20=400 combinations in total in your grid, for which your
    grid search optimization will end up training 400 models. Add another hyperparameter
    *z* to it and your number of combinations will skyrocket beyond management. The
    more hyperparameters you have, the more combinations you would try and the more
    combinatorial explosion will occur.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你的网格中共有20x20=400种组合，你的网格搜索优化将最终训练400个模型。再添加一个超参数*z*，你的组合数量将激增，超出管理范围。你拥有的超参数越多，你尝试的组合就越多，组合爆炸现象就越严重。
- en: Given the time and resource sensitivity of ML, an exhaustive search is counterproductive
    to finding the best model. The real world has limitations, hence a random selection
    of hyperparameter values has often been proven to provide better results than
    an exhaustive grid search.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到机器学习对时间和资源敏感，穷举搜索对于找到最佳模型来说是没有效果的。现实世界有局限性，因此随机选择超参数值已被证明往往比穷举网格搜索提供更好的结果。
- en: This brings us to our next approach in hyperparameter optimization, random grid
    search.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这将我们引向超参数优化的下一个方法，即随机网格搜索。
- en: Understanding random grid search optimization
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解随机网格搜索优化
- en: Random grid search replaces the previous exhaustive grid search by choosing
    random values from the hyperparameter search space, rather than sequentially exhausting
    all of them.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 随机网格搜索通过从超参数搜索空间中选择随机值来替代之前的穷举网格搜索，而不是按顺序耗尽所有值。
- en: 'For example, refer to the following diagram, which shows you an example of
    random grid search optimization:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，参考以下图表，它展示了随机网格搜索优化的一个示例：
- en: '![Figure 4.13 – Random grid search hyperparameter tuning ](img/B17298_04_013.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![图4.13 – 随机网格搜索超参数调整](img/B17298_04_013.jpg)'
- en: Figure 4.13 – Random grid search hyperparameter tuning
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13 – 随机网格搜索超参数调整
- en: The preceding diagram is a hyperparameter space of 100 combinations of two hyperparameters,
    *X* and *Y*. Random grid search optimization will only choose a few at random
    and perform evaluations using those hyperparameter values.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表是两个超参数*X*和*Y*的100种组合的超参数空间。随机网格搜索优化将随机选择其中几个，并使用这些超参数值进行评估。
- en: The drawback of random grid search optimization is that it is a best effort
    approach to find the best combination of hyperparameter values with a limited
    number of evaluations. It may or may not find the best combination of hyperparameter
    values to train the optimal model, but given a large sample size, it can find
    the near-perfect combination to train a model with good-enough quality.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 随机网格搜索优化的缺点是它是一种在有限评估次数内寻找最佳超参数值组合的最佳努力方法。它可能或可能不会找到训练最佳模型的最佳超参数值组合，但给定一个大的样本量，它可以找到接近完美的组合来训练一个质量足够好的模型。
- en: H2O library functions support random grid search optimization. It provides users
    with the functionality to set their own hyperparameter search grid and set a search
    criteria parameter to control the type and extent of the search. The search criteria
    can be anything, such as maximum runtime, the maximum number of models to train,
    or any metric. H2O will choose different hyperparameter combinations from the
    grid at random sequentially without repeat and will keep searching and evaluating
    till the search criteria are met.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: H2O库函数支持随机网格搜索优化。它为用户提供设置自己的超参数搜索网格和设置搜索标准参数以控制搜索类型和范围的功能。搜索标准可以是任何东西，例如最大运行时间、最大训练模型数量或任何指标。H2O将随机无重复地从网格中选择不同的超参数组合进行评估，并持续搜索和评估，直到满足搜索标准。
- en: H2O AutoML works slightly differently from random grid search optimization.
    Instead of waiting for the user to input the hyperparameter search grid, H2O has
    automated this part as well by already having a list of hyperparameters with all
    potential values for specific algorithms spaced out in the grid as default values.
    H2O AutoML also has provisions to include non-default values in the hyperparameter
    search list set by the user. H2O AutoML has predetermined values already set for
    algorithms; we shall explore them in the next chapter, along with understanding
    how different algorithms work.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: H2O AutoML的工作方式与随机网格搜索优化略有不同。它不是等待用户输入超参数搜索网格，而是通过已经有一个包含所有潜在值的超参数列表，并在网格中默认值的形式自动完成这一部分。H2O
    AutoML还提供了将用户设置的超参数搜索列表中的非默认值包括在内的功能。H2O AutoML已经为算法预设了值；我们将在下一章中探讨这些值，同时了解不同算法的工作原理。
- en: Summary
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have come to understand the high-level architecture of H2O
    and what the different layers that comprise the overall architecture are. We then
    dived deep into the client and JVM layer of the architecture, where we understood
    the different components that make up the H2O software stack. Next, keeping the
    architecture of H2O in mind, we came to understand the flow of interactions that
    take place between the client and server, where we understood how exactly we command
    the H2O server to perform various ML activities. We also came to understand how
    the interactions flow down the architecture stack during model training.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了H2O的高级架构以及构成整体架构的不同层级。然后，我们深入到架构的客户端和JVM层，了解了构成H2O软件堆栈的不同组件。接下来，在心中牢记H2O的架构，我们了解了客户端和服务器之间发生的交互流程，了解了我们如何确切地命令H2O服务器执行各种机器学习活动。我们还了解了在模型训练过程中，交互如何在架构堆栈中流动。
- en: Building on this knowledge, we have investigated the sequence of interactions
    that take place inside the H2O server during model training. We also looked into
    how H2O trains models using the job manager to coordinate training jobs and how
    H2O communicates the status of model training with the user. And, finally, we
    unboxed H2O AutoML and came to understand how it trains the best model automatically.
    We have understood the concept of hyperparameter optimization and its various
    approaches and how H2O automates these approaches and mitigates their drawbacks
    to automatically train the best model.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 建立在现有知识的基础上，我们研究了在模型训练过程中H2O服务器内部发生的交互序列。我们还探讨了H2O如何使用作业管理器来协调训练作业，以及H2O如何与用户沟通模型训练的状态。最后，我们揭开了H2O
    AutoML的面纱，并了解了它是如何自动训练最佳模型的。我们已经理解了超参数优化的概念及其各种方法，以及H2O如何自动化这些方法并减轻它们的缺点以自动训练最佳模型。
- en: Now that we know the internal details of H2O AutoML and how it trains models,
    we are now ready to understand the various ML algorithms that H2O AutoML trains
    and how they manage to make predictions. In the next chapter, we shall explore
    these algorithms and have a better understanding of models, which will help us
    to justify which model would work best for a given ML problem.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了H2O AutoML的内部细节以及它是如何训练模型的，我们现在准备了解H2O AutoML训练的各种机器学习算法以及它们如何进行预测。在下一章中，我们将探索这些算法，并更好地理解模型，这将帮助我们证明哪种模型最适合给定的机器学习问题。
