- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Interpretation Challenges
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释性挑战
- en: In this chapter, we will discuss the traditional methods used for machine learning
    interpretation for both regression and classification. This includes model performance
    evaluation methods such as RMSE, R-squared, AUC, ROC curves, and the many metrics
    derived from confusion matrices. We will then examine the limitations of these
    performance metrics and explain what exactly makes “white-box” models intrinsically
    interpretable and why we cannot always use white-box models. To answer these questions,
    we’ll consider the trade-off between prediction performance and model interpretability.
    Finally, we will discover some new “glass-box” models such as **Explainable Boosting
    Machines** (**EBMs**) and GAMI-Net that attempt to not compromise on this trade-off
    between predictive performance and interpretability.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论用于机器学习解释的传统方法，包括回归和分类。这包括模型性能评估方法，如RMSE、R-squared、AUC、ROC曲线以及从混淆矩阵派生出的许多指标。然后，我们将检查这些性能指标的局限性，并解释“白盒”模型本质上可解释的原因以及为什么我们并不总是可以使用白盒模型。为了回答这些问题，我们将考虑预测性能和模型可解释性之间的权衡。最后，我们将发现一些新的“玻璃盒”模型，如**可解释提升机**（**EBMs**）和GAMI-Net，它们试图不在这两种性能之间做出妥协。
- en: 'The following are the main topics that will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要主题：
- en: Reviewing traditional model interpretation methods
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回顾传统的模型解释方法
- en: Understanding the limitations of traditional model interpretation methods
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解传统模型解释方法的局限性
- en: Studying intrinsically interpretable (white-box) models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究本质上可解释的（白盒）模型
- en: Recognizing the trade-off between performance and interpretability
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 认识到性能和可解释性之间的权衡
- en: Discovering newer interpretable (glass-box) models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现新的可解释（玻璃盒）模型
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: From *Chapter 2*, *Key Concepts of Interpretability*, onward, we are using a
    custom `mldatasets` library to load our datasets. Instructions on how to install
    this library can be found in the *Preface*. In addition to `mldatasets`, this
    chapter’s examples also use the `pandas`, `numpy`, `sklearn`, `rulefit`, `interpret`,
    `statsmodels`, `matplotlib`, and `gaminet` libraries.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从**第二章**，**可解释性关键概念**开始，我们使用自定义的`mldatasets`库来加载我们的数据集。有关如何安装此库的说明可以在**前言**中找到。除了`mldatasets`，本章的示例还使用了`pandas`、`numpy`、`sklearn`、`rulefit`、`interpret`、`statsmodels`、`matplotlib`和`gaminet`库。
- en: 'The code for this chapter is located here: [packt.link/swCyB](http://packt.link/swCyB).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码位于此处：[packt.link/swCyB](http://packt.link/swCyB)。
- en: The mission
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务
- en: Picture yourself, a data science consultant, in a conference room in Fort Worth,
    Texas, during early January 2019\. In this conference room, executives for one
    of the world’s largest airlines, **American Airlines** (**AA**), are briefing
    you on their **On-Time Performance** (**OTP**). OTP is a widely accepted **Key
    Performance Indicator** (**KPI**) for flight punctuality. It is measured as the
    percentage of flights that arrived within 15 minutes of the scheduled arrival.
    It turns out that AA has achieved an OTP of just over 80% for 3 years in a row,
    which is acceptable, and a significant improvement, but they are still ninth in
    the world and fifth in North America. To brag about it next year in their advertising,
    they aspire to achieve, at least, number one in North America for 2019, besting
    their biggest rivals.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你是一位数据科学顾问，在2019年1月初的德克萨斯州沃斯堡的一个会议室里。在这个会议室里，世界上最大航空公司之一的**美国航空公司**（**AA**）的行政人员正在向您介绍他们的**准时性能**（**OTP**）。OTP是衡量航班准时的一个广泛接受的**关键绩效指标**（**KPI**）。它被定义为在预定到达时间前后15分钟内到达的航班百分比。结果发现，AA连续3年实现了略高于80%的OTP，这是可以接受的，并且是一个显著的改进，但他们仍然在全球排名第九，在北美排名第五。为了在明年的广告中炫耀，他们渴望至少在2019年成为北美第一，超越他们最大的竞争对手。
- en: On the financial front, it is estimated that delays cost the airline close to
    $2 billion, so reducing this by 25–35% to be on parity with their competitors
    could produce sizable savings. And it is estimated that it costs passengers just
    as much due to tens of millions of lost hours. A reduction in delays would result
    in happier customers, which could lead to an increase in ticket sales.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在财务方面，预计延误将使航空公司损失近20亿美元，因此减少25-35%以与竞争对手持平可以产生可观的节省。而且，由于数千万小时的损失，乘客的损失也大致相同。减少延误将导致更满意的客户，这可能导致机票销售额的增加。
- en: 'Your task is to create models that can accurately predict delays for domestic
    flights only. What they hope to gain from the models is the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您的任务是创建可以准确预测国内航班延误的模型。他们希望从这些模型中获得以下信息：
- en: To understand what factors impacted domestic arrival delays the most in 2018
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解哪些因素在2018年对国内到达延误影响最大
- en: To anticipate a delay caused by the airline in midair with enough accuracy to
    mitigate some of these factors in 2019
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了在2019年足够准确地预测空中由航空公司造成的延误，以减轻这些因素中的一些
- en: But not all delays are made equal. The **International Air Transport Association**
    (**IATA**) has over 80 delay codes ranging from 14 (*oversales booking errors*)
    to 75 (*de-icing of aircraft, removal of ice/snow, frost prevention*). Some are
    preventable, and others unavoidable.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 但并非所有延误都是平等的。**国际航空运输协会**（**IATA**）有超过80个延误代码，从14（*超额预订错误*）到75（*飞机除冰、清除冰雪、防霜*）。有些是可以预防的，而有些则是不可避免的。
- en: The airline executives told you that the airline is not, for now, interested
    in predicting delays caused by events out of their control, such as extreme weather,
    security events, and air traffic control issues. They are also not interested
    in delays caused by late arrivals from previous flights using the same aircraft
    because this was not the root cause. Nevertheless, they would like to know the
    effect of a busy hub on avoidable delays even if this has to do with congestion
    because, after all, perhaps there’s something they can do with flight scheduling
    or flight speed, or even gate selection. And while they understand that international
    flights occasionally impact domestic flights, they hope to tackle the sizeable
    local market first.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 航空公司高管们告诉您，目前航空公司对预测由他们无法控制的事件（如极端天气、安全事件和空中交通管制问题）造成的延误不感兴趣。他们也不对由于使用同一架飞机的先前航班延误造成的延误感兴趣，因为这不是根本原因。尽管如此，他们仍然希望了解繁忙枢纽对可避免延误的影响，即使这与拥堵有关，因为毕竟，他们可能可以通过航班调度或航班速度，甚至登机口选择来做些什么。而且，虽然他们理解国际航班偶尔会影响国内航班，但他们希望首先解决庞大的本地市场。
- en: Executives have provided you with a dataset from the United States Department
    of Transportation *Bureau of Transportation Statistics* with all 2018 AA domestic
    flights.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 高管们向您提供了美国交通部*运输统计局*的所有2018年AA国内航班的数据库。
- en: The approach
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法
- en: 'Upon careful consideration, you have decided to approach this both as a regression
    problem and a classification problem. Therefore, you will produce models that
    predict minutes delayed as well as models that classify whether flights were delayed
    by more than 15 minutes. For interpretation, using both will enable you to use
    a wider variety of methods and expand your interpretation accordingly. So we will
    approach this example by taking the following steps:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 经过仔细考虑，您决定将此问题同时视为回归问题和分类问题。因此，您将创建预测延误分钟的模型以及分类航班是否延误超过15分钟的模型。为了解释，使用这两种方法将使您能够使用更广泛的方法，并相应地扩展解释。因此，我们将通过以下步骤来处理此示例：
- en: Predicting minutes delayed with various regression methods
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用各种回归方法预测延误的分钟数
- en: Classifying flights as delayed or not delayed with various classification methods
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用各种分类方法将航班分类为延误或未延误
- en: These steps in the *Reviewing traditional model interpretation methods* section
    are followed by conclusions spread out in the rest of the sections of this chapter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在“*回顾传统模型解释方法*”部分中，这些步骤后面是本章其余部分分散的结论。
- en: The preparations
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'You will find the code for this example here: [https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/blob/main/03/FlightDelays.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/blob/main/03/FlightDelays.ipynb).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下链接中找到此示例的代码：[https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/blob/main/03/FlightDelays.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/blob/main/03/FlightDelays.ipynb)。
- en: Loading the libraries
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载库
- en: 'To run this example, you need to install the following libraries:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此示例，您需要安装以下库：
- en: '`mldatasets` to load the dataset'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`mldatasets`来加载数据集
- en: '`pandas` and `numpy` to manipulate it'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas`和`numpy`来操作它'
- en: '`sklearn` (scikit-learn), `rulefit`, `statsmodels`, `interpret`, `tf`, and
    `gaminet` to fit models and calculate performance metrics'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn`（scikit-learn）、`rulefit`、`statsmodels`、`interpret`、`tf`和`gaminet`来拟合模型和计算性能指标'
- en: '`matplotlib` to create visualizations'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib`来创建可视化'
- en: 'Load these libraries as seen in the following snippet:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下代码片段加载这些库：
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Understanding and preparing the data
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解和准备数据
- en: 'We then load the data as shown:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后按如下方式加载数据：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'There should be nearly 900,000 records and 23 columns. We can take a peek at
    what was loaded like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 应该有近90万条记录和23列。我们可以这样查看加载的内容：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following is the output:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为输出结果：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Everything seems to be in order because all columns are there and there are
    no `null` values.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一切似乎都井然有序，因为所有列都在那里，并且没有`null`值。
- en: The data dictionary
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据字典
- en: Let’s examine the data dictionary.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查数据字典。
- en: 'General features are as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一般特征如下：
- en: '`FL_NUM`: Flight number.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FL_NUM`: 航班号。'
- en: '`ORIGIN`: Starting airport code (IATA).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ORIGIN`: 起始机场代码（IATA）。'
- en: '`DEST`: Destination airport code (IATA).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DEST`: 目的地机场代码（IATA）。'
- en: 'Departure features are as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 离开特征如下：
- en: '`PLANNED_DEP_DATETIME`: The planned date and time of the flight.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PLANNED_DEP_DATETIME`: 航班的计划日期和时间。'
- en: '`CRS_DEP_TIME`: The planned departure time.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CRS_DEP_TIME`: 计划离开时间。'
- en: '`DEP_TIME`: The actual departure time.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DEP_TIME`: 实际离开时间。'
- en: '`DEP_AFPH`: The number of actual flights per hour occurring during the interval
    in between the planned and actual departure from the origin airport (factoring
    in 30 minutes of padding). The feature tells you how busy the origin airport was
    during takeoff.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DEP_AFPH`: 在计划出发和实际出发之间的间隔内实际每小时航班数（考虑了30分钟的填充时间）。该特征告诉你出发机场在起飞时的繁忙程度。'
- en: '`DEP_RFPH`: The departure relative flights per hour is the ratio of actual
    flights per hour over the median number of flights per hour that occur at the
    origin airport at that time of day, day of the week, and month of the year. The
    feature tells you how *relatively* busy the origin airport was during takeoff.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DEP_RFPH`: 离开相对航班每小时数是实际每小时航班数与当天、星期和月份在出发机场发生的平均每小时航班数的比率。该特征告诉你出发机场在起飞时的相对繁忙程度。'
- en: '`TAXI_OUT`: The time duration elapsed between the departure from the origin
    airport gate and wheels off.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TAXI_OUT`: 从出发机场登机口出发到飞机轮子离地的持续时间。'
- en: '`WHEELS_OFF`: The point in time that the aircraft’s wheels leave the ground.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WHEELS_OFF`: 飞机轮子离地的时间点。'
- en: 'In-flight features are as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 飞行中的特征如下：
- en: '`CRS_ELAPSED_TIME`: The planned amount of time needed for the flight trip.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CRS_ELAPSED_TIME`: 飞行行程计划所需的时间。'
- en: '`PCT_ELAPSED_TIME`: The ratio of actual flight time over planned flight time
    to gauge the plane’s relative speed.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PCT_ELAPSED_TIME`: 实际飞行时间与计划飞行时间的比率，以衡量飞机的相对速度。'
- en: '`DISTANCE`: The distance between two airports.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DISTANCE`: 两个机场之间的距离。'
- en: 'Arrival features are as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 到达特征如下：
- en: '`CRS_ARR_TIME`: The planned arrival time.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CRS_ARR_TIME`: 计划到达时间。'
- en: '`ARR_AFPH`: The number of actual flights per hour occurring during the interval
    between the planned and actual arrival time at the destination airport (factoring
    in 30 minutes of padding). The feature tells you how busy the destination airport
    was during landing.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ARR_AFPH`: 在计划到达和实际到达时间之间的间隔内实际每小时航班数（考虑了30分钟的填充时间）。该特征告诉你目的地机场在着陆时的繁忙程度。'
- en: '`ARR_RFPH`: The arrival relative flights per hour is the ratio of actual flights
    per hour over the median number of flights per hour that occur at the destination
    airport at that time of day, day of the week, and month of the year. The feature
    tells you how *relatively* busy the destination airport was during landing.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ARR_RFPH`: 到达相对航班每小时数是实际每小时航班数与当天、星期和月份在该目的地机场发生的平均每小时航班数的比率。该特征告诉你目的地机场在着陆时的相对繁忙程度。'
- en: 'Delay features are as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 延误特征如下：
- en: '`DEP_DELAY`: The total delay on departure in minutes.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DEP_DELAY`: 离开延误的总分钟数。'
- en: '`ARR_DELAY`: The total delay on arrival in minutes can be subdivided into any
    or all of the following:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ARR_DELAY`: 到达延误的总分钟数可以细分为以下任何一个或所有：'
- en: '`CARRIER_DELAY`: The delay in minutes caused by circumstances within the airline’s
    control (for example, maintenance or crew problems, aircraft cleaning, baggage
    loading, fueling, and so on).'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`CARRIER_DELAY`: 由航空公司控制因素（例如，维护或机组人员问题、飞机清洁、行李装载、加油等）造成的延误分钟数。'
- en: '`WEATHER_DELAY`: The delay in minutes caused by significant meteorological
    conditions (actual or forecasted).'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WEATHER_DELAY`: 由重大气象条件（实际或预报）造成的延误分钟数。'
- en: '`NAS_DELAY`: The delay in minutes mandated by a national aviation system such
    as non-extreme weather conditions, airport operations, heavy traffic volume, and
    air traffic control.'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`NAS_DELAY`：由国家航空系统（如非极端天气条件、机场运营、交通量过大和空中交通管制）规定的延误分钟数。'
- en: '`SECURITY_DELAY`: The delay in minutes caused by the evacuation of a terminal
    or concourse, re-boarding of an aircraft because of a security breach, faulty
    screening equipment, or long lines above 29 minutes in screening areas.'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`SECURITY_DELAY`：由于疏散机场或候机楼、因安全漏洞重新登机、检查设备故障或安检区域超过29分钟的长时间排队等原因造成的延误分钟数。'
- en: '`LATE_AIRCRAFT_DELAY`: The delay in minutes caused by a previous flight with
    the same aircraft that arrived late.'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`LATE_AIRCRAFT_DELAY`：由于同一架飞机的先前航班延误而造成的延误分钟数。'
- en: Data preparation
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'For starters, `PLANNED_DEP_DATETIME` must be a datetime data type:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`PLANNED_DEP_DATETIME`必须是日期时间数据类型：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The exact day and time of a flight don’t matter, but maybe the month and day
    of the week do because of weather and seasonal patterns that can only be appreciated
    at this level of granularity. Also, the executives mentioned weekends and winters
    being especially bad for delays. Therefore, we will create features for the month
    and day of the week:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 飞行的确切日期和时间并不重要，但也许月份和星期几很重要，因为天气和季节性模式只能在这个粒度级别上得到欣赏。此外，提到的管理人员表示周末和冬季的延误尤其严重。因此，我们将为月份和星期几创建特征：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We don’t need the `PLANNED_DEP_DATETIME` column so let’s drop it like this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要`PLANNED_DEP_DATETIME`列，所以让我们像这样删除它：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'It is essential to record whether the arrival or destination airport is a hub.
    AA, in 2019, had 10 hubs: Charlotte, Chicago–O’Hare, Dallas/Fort Worth, Los Angeles,
    Miami, New York–JFK, New York–LaGuardia, Philadelphia, Phoenix–Sky Harbor, and
    Washington–National. Therefore, we can encode which `ORIGIN` and `DEST` airports
    are AA hubs using their IATA codes, and get rid of columns with codes since they
    are too specific (`FL_NUM`, `ORIGIN`, and `DEST`):'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 记录到达或目的地机场是否为枢纽机场是至关重要的。美国航空公司（AA）在2019年有10个枢纽机场：夏洛特、芝加哥-奥黑尔、达拉斯/沃斯堡、洛杉矶、迈阿密、纽约-肯尼迪、纽约-拉瓜迪亚、费城、凤凰城-天港和华盛顿-国家机场。因此，我们可以使用它们的IATA代码来编码哪些`ORIGIN`和`DEST`机场是AA的枢纽机场，并删除包含代码的列，因为它们过于具体（`FL_NUM`、`ORIGIN`和`DEST`）：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After all these operations, we have a fair number of useful features, but we
    are yet to determine the target feature. There are two columns that could serve
    this purpose. We have `ARR_DELAY`, which is the total number of minutes delayed
    regardless of the reason, and then there’s `CARRIER_DELAY`, which is just the
    total number of those minutes that can be attributed to the airline. For instance,
    look at the following sample of flights delayed over 15 minutes (which is considered
    late according to the airline’s definition):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行所有这些操作之后，我们拥有相当数量的有用特征，但我们尚未确定目标特征。有两列可以用于此目的。我们有`ARR_DELAY`，这是无论原因如何延迟的总分钟数，然后是`CARRIER_DELAY`，这只是可以归因于航空公司的那些分钟数的总和。例如，看看以下样本，这些航班延误超过15分钟（根据航空公司的定义，这被认为是延误）：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The preceding code outputs *Figure 3.1*:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码输出了**图3.1**：
- en: '![Table  Description automatically generated](img/B18406_03_01.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![表格描述自动生成](img/B18406_03_01.png)'
- en: 'Figure 3.1: Sample observations with arrival delays over 15 minutes'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**图3.1**：样本观察值，到达延误超过15分钟'
- en: 'Of all the delays in *Figure 3.1*, one of them (#26) wasn’t at all the responsibility
    of the airline because only 0 minutes could be attributed to the airline. Four
    of them were partially the responsibility of the airline (#8, #16, #33, and #40),
    two of which were over 15 minutes late due to the airline (#8 and #40). The rest
    of them were entirely the airline’s fault. We can tell that although the total
    delay is useful information, the airline executives were only interested in delays
    caused by the airline so `ARR_DELAY` can be discarded. Furthermore, there’s another
    more important reason it should be discarded, and it’s that if the task at hand
    is to predict a delay, we cannot use pretty much the very same delay (minus the
    portions not due to the airline) to predict it. For this very same reason, it
    is best to remove `ARR_DELAY`:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图3.1*的所有延误中，其中之一（#26）根本不是航空公司的责任，因为只有0分钟可以归因于航空公司。其中四个部分是航空公司的责任（#8、#16、#33和#40），其中两个由于航空公司而晚于15分钟（#8和#40）。其余的完全是航空公司的责任。我们可以看出，尽管总延误是有用的信息，但航空公司的高管们只对由航空公司造成的延误感兴趣，因此`ARR_DELAY`可以被丢弃。此外，还有一个更重要的原因应该丢弃它，那就是如果当前的任务是预测延误，我们不能使用几乎完全相同的延误（减去不是由于航空公司的部分）来预测它。出于这个原因，最好移除`ARR_DELAY`：
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, we can put the target feature alone as `y` and all the rest as `X`.
    After this, we split `y` and `X` into train and test datasets. Please note that
    the target feature (`y`) stays the same for regression, so we split it into `y_train_reg`
    and `y_test_reg`. However, for classification, we must make binary versions of
    these labels denoting whether it’s more than 15 minutes late or not, called `y_train_class`
    and `y_test_class`. Please note that we are setting a fixed `random_state` for
    reproducibility:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以将目标特征单独作为`y`，其余所有特征作为`X`。之后，我们将`y`和`X`分为训练集和测试集。请注意，对于回归，目标特征（`y`）保持不变，因此我们将其分为`y_train_reg`和`y_test_reg`。然而，对于分类，我们必须将这些标签的二进制版本表示为是否晚于15分钟以上，称为`y_train_class`和`y_test_class`。请注意，我们正在设置一个固定的`random_state`以确保可重复性：
- en: '[PRE10]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To examine how linearly correlated the features are to the target `CARRIER_DELAY`,
    we can compute Pearson’s correlation coefficient, turn coefficients to absolute
    values (because we aren’t interested in whether they are positively or negatively
    correlated), and sort them in descending order:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查特征与目标`CARRIER_DELAY`的线性相关性，我们可以计算皮尔逊相关系数，将系数转换为绝对值（因为我们不感兴趣它们是正相关还是负相关），并按降序排序：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As you can tell from the output, only one feature (`DEP_DELAY`) is highly correlated.
    The others aren’t:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从输出中可以看出，只有一个特征（`DEP_DELAY`）高度相关。其他特征则不然：
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: However, this is only *linearly* correlated and on a one-by-one basis. It doesn’t
    mean that they don’t have a non-linear relationship, or that several features
    interacting together wouldn’t impact the target. In the next section, we will
    discuss this further.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这仅仅是*线性*相关的，并且是逐个比较的。这并不意味着它们没有非线性关系，或者几个特征相互作用不会影响目标。在下一节中，我们将进一步讨论这个问题。
- en: Reviewing traditional model interpretation methods
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 审查传统的模型解释方法
- en: To explore as many model classes and interpretation methods as possible, we
    will fit the data into regression and classification models.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尽可能探索多种模型类别和解释方法，我们将数据拟合到回归和分类模型中。
- en: Predicting minutes delayed with various regression methods
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用各种回归方法预测延误的分钟数
- en: 'To compare and contrast regression methods, we will first create a dictionary
    named `reg_models`. Each model is its own dictionary and the function that creates
    it is the `model` attribute. This structure will be used later to neatly store
    the fitted model and its metrics. Model classes in this dictionary have been chosen
    to represent several model families and to illustrate important concepts that
    we will discuss later:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较和对比回归方法，我们首先创建一个名为`reg_models`的字典。每个模型都是其自己的字典，创建它的函数是`model`属性。这种结构将在以后用来整洁地存储拟合的模型及其指标。这个字典中的模型类别已被选择来代表几个模型家族，并展示我们将要讨论的重要概念：
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Before we start fitting the data to these models, we will briefly explain them
    one by one:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将数据拟合到这些模型之前，我们将逐一简要解释它们：
- en: '`linear`: **Linear regression** was the first model class we discussed. For
    better or for worse, it makes several assumptions about the data. Chief among
    them is the assumption that the prediction must be a linear combination of *X*
    features. This, naturally, limits the capacity to discover non-linear relationships
    and interactions among the features.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`linear`: **线性回归**是我们讨论的第一个模型类别。不管好坏，它对数据做出了一些假设。其中最重要的是假设预测必须是*X*特征的线性组合。这自然限制了发现特征之间非线性关系和交互的能力。'
- en: '`linear_poly`: **Polynomial regression** extends linear regression by adding
    polynomial features. In this case, as indicated by `degree=2`, the polynomial
    degree is two, so it’s quadratic. This means, in addition to having all features
    in their monomial form (for example, `DEP_FPH`), it also has them in a quadratic
    form (for example, `DEP_FPH²`), plus the many interaction terms for all of the
    21 features. In other words, for `DEP_FPH`, there would be interaction terms such
    as `DEP_FPH` ![](img/B18406_03_001.png) `DISTANCE`, `DEP_FPH` ![](img/B18406_03_001.png)
    `DELAY`, and so on for the rest of the features.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`linear_poly`: **多项式回归**通过添加多项式特征扩展了线性回归。在这种情况下，如`degree=2`所示，多项式度数为二，因此它是二次的。这意味着除了所有特征都以单变量形式（例如，`DEP_FPH`）存在之外，它们还以二次形式存在（例如，`DEP_FPH²`），以及所有21个特征的许多交互项。换句话说，对于`DEP_FPH`，会有如`DEP_FPH`
    ![](img/B18406_03_001.png) `DISTANCE`、`DEP_FPH` ![](img/B18406_03_001.png) `DELAY`等交互项，以及其他所有特征的类似项。'
- en: '`linear_interact`: This is just like the **polynomial regression** model but
    without the quadratic terms – in other words, only the interactions, as `interaction_only=True`
    would suggest. It’s useful because there is no reason to believe any of our features
    have a relationship that is better fitted with quadratic terms. Still, perhaps
    it’s the interaction with other features that makes an impact.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`linear_interact`: 这就像**多项式回归**模型，但没有二次项——换句话说，只有交互项，正如`interaction_only=True`所暗示的那样。它是有用的，因为我们没有理由相信我们的任何特征与二次项有更好的拟合关系。然而，也许正是与其他特征的交互产生了影响。'
- en: '`ridge`: **Ridge regression** is a variation of linear regression. However,
    even though the method behind linear regression, called **ordinary least squares**
    (**OLS**), does a pretty good job of reducing the error and fitting the model
    to the features, it does it without considering **overfitting**. The problem here
    is that OLS treats all features equally, so the model becomes more complex as
    each variable is added. As the word *overfitting* suggests, the resulting model
    fits the training data too well, resulting in the lowest bias but the highest
    variance. There’s a sweet spot in this **trade-off between bias and variance**,
    and one way of getting to this spot is by reducing the complexity added by the
    introduction of too many features. Linear regression is not equipped to do so
    on its own.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ridge`: **岭回归**是线性回归的一种变体。然而，尽管线性回归背后的方法，称为**普通最小二乘法**（**OLS**），在减少误差和将模型拟合到特征方面做得相当不错，但它并没有考虑**过拟合**。问题在于OLS平等地对待所有特征，因此随着每个变量的增加，模型变得更加复杂。正如单词*过拟合*所暗示的，结果模型对训练数据拟合得太好，导致最低的偏差但最高的方差。在这个**偏差和方差之间的权衡**中有一个甜蜜点，而到达这个点的一种方法是通过减少引入过多特征所增加的复杂性。线性回归本身并没有装备去做到这一点。'
- en: This is where ridge regression comes along, with our friend **regularization**.
    It does this by shrinking coefficients that don’t contribute to the outcome with
    a penalty term called the **L2 norm**. It penalizes complexity, thus constraining
    the algorithm from overfitting. In this example, we use a cross-validated version
    of `ridge` (`RidgeCV`) that tests several regularization strengths (`alphas`).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 正是在这里，岭回归伴随着我们的朋友**正则化**出现。它是通过引入一个称为**L2范数**的惩罚项来缩小对结果没有贡献的系数来做到这一点的。它惩罚复杂性，从而约束算法不过拟合。在这个例子中，我们使用了一个交叉验证版本的`ridge`（`RidgeCV`），它测试了几个正则化强度（`alphas`）。
- en: '`decision_tree`: A **decision tree** is precisely as the name suggests. Imagine
    a tree-like structure where at every point that branches subdivide to form more
    branches, there is a “test” performed on a feature, partitioning the datasets
    into each branch. When branches stop subdividing, they become leaves, and at every
    leaf, there’s *a decision*, be it to assign a *class* for classification or a
    fixed value for regression. We are limiting this tree to `max_depth=7` to prevent
    overfitting because the larger the tree, the better it will fit our training data,
    and the less likely the tree will generalize to non-training data.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decision_tree`: **决策树**正如其名所示。想象一个树状结构，在每一个分支点，数据集被细分以形成更多的分支，都会对某个特征进行“测试”，将数据集划分到每个分支。当分支停止细分时，它们变成叶子节点，在每一个叶子节点，都会做出一个“决策”，无论是为分类分配一个**类别**还是为回归提供一个固定值。我们将此树限制在
    `max_depth=7` 以防止过拟合，因为树越大，它将更好地拟合我们的训练数据，并且越不可能将树泛化到非训练数据。'
- en: '`rule_fit`: **RuleFit** is a regularized linear regression expanded to include
    feature interactions in the form of rules. The rules are formed by traversing
    a decision tree, except it discards the leaves and keeps the feature interactions
    found traversing the branches toward these leaves. It uses **LASSO Regression**,
    which, like ridge, uses regularization, but instead of using the **L2 norm**,
    it uses the **L1 norm**. The result is that useless features end up with a coefficient
    of zero and do not just converge to zero, as they do with L2, which makes it easy
    for the algorithm to filter them out. We are limiting the rules to 150 (`max_rules=150`)
    and the attribute `rfmode=''regress''` tells RuleFit that this is a regression
    problem, since it can also be used for classification. Unlike all other models
    used here, this isn’t a scikit-learn one but was created by Christoph Molnar adapting
    a paper called *Predictive learning via rule ensembles*.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rule_fit`: **RuleFit** 是一种正则化线性回归，扩展到包括以规则形式出现的特征交互。这些规则是通过遍历决策树形成的，除了它丢弃了叶子节点并保留了在向这些叶子节点分支过程中发现的特征交互。它使用
    **LASSO 回归**，与岭回归类似，使用正则化，但它使用的是 **L1 范数**而不是 **L2 范数**。结果是，无用的特征最终会得到零系数，并且不会像
    L2 那样简单地收敛到零，这使得算法可以轻松地将它们过滤掉。我们将规则限制在 150 条（`max_rules=150`），属性 `rfmode=''regress''`
    告诉 RuleFit 这是一个回归问题，因为它也可以用于分类。与这里使用的所有其他模型不同，这不是一个 scikit-learn 模型，而是由 Christoph
    Molnar 创建的，他改编了一篇名为 *Predictive learning via rule ensembles* 的论文。'
- en: '`knn`: **k-Nearest Neighbors** (**k-NN**) is a simple method based on the *locality*
    assumption, which is that data points that are close to each other are similar.
    In other words, they must have similar predicted values, and, in practice, this
    isn’t a bad guess, so it takes data points nearest to the point you want to predict
    and derives a prediction based on that. In this case, `n_neighbors=7` so k = 7\.
    It’s an **instance-based machine learning model**, also known as a **lazy learner**
    because it simply stores the training data. During inference, it employs training
    data to calculate the similarity with points and generate a prediction based on
    that. This is opposed to what model-based machine learning techniques, or **eager
    learners**, do, which is to use training data to learn formulas, parameters, coefficients,
    or bias/weights, which they then leverages to make a prediction during inference.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`knn`: **k-Nearest Neighbors** (**k-NN**) 是一种基于**局部性**假设的简单方法，该假设认为彼此靠近的数据点相似。换句话说，它们必须具有相似的预测值，而在实践中，这并不是一个糟糕的猜测，因此它选取离你想要预测的点最近的数据点，并根据这些点进行预测。在这种情况下，`n_neighbors=7`，所以
    k = 7。它是一个**基于实例的机器学习模型**，也称为**懒惰学习器**，因为它只是存储训练数据。在推理过程中，它使用训练数据来计算与点的相似性，并根据这些相似性生成预测。这与基于模型的机器学习技术，或**急切学习器**所做的方法相反，后者使用训练数据来学习公式、参数、系数或偏差/权重，然后利用这些信息在推理过程中进行预测。'
- en: '`random_forest`: Imagine not one but hundreds of decision trees trained on
    random combinations of the features and random samples of data. **Random forest**
    takes an average of these randomly generated decision trees to create the best
    tree. This concept of training less effective models in parallel and combining
    them using an averaging process is called **bagging**. It is an **ensemble** method
    because it combines more than one model (usually called **weak learners**) into
    a **strong learner**. In addition to *bagging*, there are two other ensemble techniques,
    called **boosting** and **stacking**. For bagging deeper, trees are better because
    they reduce variance, so this is why we are using `max_depth=7`.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`随机森林`：想象一下，不是一棵，而是成百上千棵决策树，这些决策树是在特征随机组合和数据随机样本上训练的。**随机森林**通过平均这些随机生成的决策树来创建最佳树。这种在并行训练较少有效模型并使用平均过程将它们组合起来的概念被称为**袋装法**。它是一种**集成**方法，因为它将多个模型（通常称为**弱学习器**）组合成一个**强学习器**。除了**袋装法**之外，还有两种其他集成技术，称为**提升法**和**堆叠法**。对于更深的袋装，树更好，因为它们减少了方差，这就是为什么我们使用`max_depth=7`的原因。'
- en: '`mlp`: **A multi-layer perceptron** is a “vanilla” feedforward (sequential)
    neural network, so it uses non-linear activation functions `(MLPRegressor` uses
    *ReLU* by default), stochastic gradient descent, and backpropagation. In this
    case, we are using 21 neurons in the first and only hidden layer, hence `hidden_layer_sizes=(21,)`,
    running training for 500 epochs (`max_iter=500`), and terminating training when
    the validation score is not improving (`early_stopping=True`).'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlp`：**多层感知器**是一个“普通”的前馈（顺序）神经网络，因此它使用非线性激活函数（`MLPRegressor`默认使用*ReLU*），随机梯度下降和反向传播。在这种情况下，我们在第一个也是唯一的隐藏层中使用21个神经元，因此`hidden_layer_sizes=(21,)`，运行500个训练周期（`max_iter=500`），并在验证分数不再提高时终止训练（`early_stopping=True`）。'
- en: If you are unfamiliar with some of these models, don’t fret! We will cover them
    in more detail later in this chapter and the book. Also, please note that some
    of these models have a random process somewhere. To ensure reproducibility, we
    have set `random_state`. It is best to always set this; otherwise, it will randomly
    set it every single time, which will make your results hard to reproduce.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对这些模型中的某些不熟悉，不要担心！我们将在本章和书中更详细地介绍它们。此外，请注意，这些模型中的某些模型在某个地方有一个随机过程。为了确保可重复性，我们已经设置了`random_state`。最好总是设置它；否则，它将每次随机设置，这将使你的结果难以重复。
- en: 'Now, let’s iterate over our dictionary of models (`reg_models`), fit them to
    the training data, and predict and compute two metrics based on the quality of
    these predictions. We’ll then save the fitted model, test predictions, and metrics
    in the dictionary for later use. Note that `rulefit` only accepts `numpy` arrays,
    so we can’t `fit` it in the same way. Also, note that `rulefit` and `mlp` take
    longer than the rest to train, so this can take a few minutes to run:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们遍历我们的模型字典（`reg_models`），将它们拟合到训练数据上，并根据这些预测的质量计算两个指标。然后我们将保存拟合的模型、测试预测和指标到字典中，以供以后使用。请注意，`rulefit`只接受`numpy`数组，所以我们不能以同样的方式`fit`它。另外，请注意，`rulefit`和`mlp`的训练时间比其他模型长，所以这可能需要几分钟才能运行：
- en: '[PRE14]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can now convert the dictionary to a `DataFrame` and display the metrics
    in a sorted and color-coded fashion:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以将字典转换为`DataFrame`，并以排序和彩色编码的方式显示指标：
- en: '[PRE15]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The preceding code outputs *Figure 3.2*. Please note that color-coding doesn’t
    work in all Jupyter Notebook implementations:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码输出了*图3.2*。请注意，彩色编码并不适用于所有Jupyter Notebook实现：
- en: '![Table  Description automatically generated](img/B18406_03_02.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![表格描述自动生成](img/B18406_03_02.png)'
- en: 'Figure 3.2: Regression metrics for our models'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2：我们模型的回归指标
- en: 'To interpret the metrics in *Figure 3.2*, we ought to first understand what
    they mean, both in general and in the context of this regression exercise:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释*图3.2*中的指标，我们首先应该了解它们在一般和回归练习的上下文中的含义：
- en: '**RMSE**: **Root Mean Square Error** is defined as the standard deviation of
    the residuals. It’s the square root of the squared residuals divided by the number
    of observations – in this case, flights. It tells you, on average, how far apart
    the predictions are from the actuals, and as you can probably tell from the color-coding,
    less is better because you want your predictions to be as close as possible to
    the actuals in the *test* (**hold-out**) dataset. We have also included this metric
    for the **train** dataset to see how well it’s generalizing. You expect the test
    error to be higher than the training error, but not by much. If it is, like it
    is for `random_forest`, you need to tune some of the parameters to reduce overfitting.
    In this case, reducing the trees’ maximum depth, increasing the number of trees
    (also called **estimators**), and reducing the maximum number of features to use
    should do the trick. On the other hand, with `knn`, you can adjust the number
    of neighbors, but it is expected, because of its **lazy learner** nature, to overperform
    on the training data.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In any case, these numbers are pretty good because even our worst performing
    model is below a test RMSE of 10 minutes, and about half of them have a test RMSE
    of less than 7.5, quite possibly predicting a delay effectively, on average, since
    the threshold for a delay is 15 minutes.
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that `linear_poly` is the second and `linear_interact` is the fourth most
    performant model, significantly ahead of `linear`, suggesting that non-linearity
    and interactivity are important factors to produce better predictive performance.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**R**²: **R-squared** is also known as the **coefficient of determination**.
    It’s defined as the proportion of the variance in the *y* (outcome) target that
    can be explained by the *X* (predictors) features in the model. It answers the
    question of what proportion of the model variability is explainable? And as you
    can probably tell from the color-coding, more is better. And our models appear
    to include significant *X* features, as evidenced by our *Pearson’s correlation
    coefficients*. So if this *R*² value was low, perhaps adding additional features
    would help, such as flight logs, terminal conditions, and even those things airline
    executives said they weren’t interested in exploring right now, such as *knock-off*
    effects and international flights. These could fill in the gaps in the unexplained
    variance.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s see if we can get good metrics with classification.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Classifying flights as delayed or not delayed with various classification methods
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Just as we did with regression, to compare and contrast classification methods,
    we will first create a dictionary for them named `class_models`. Each model is
    its own dictionary and the function that creates it is the `model` attribute.
    This structure will be used later to store the fitted model and its metrics. Model
    classes in this dictionary have been chosen to represent several model families
    and to illustrate important concepts that we will discuss later. Some of these
    will look familiar because they are the same methods used in regression but applied
    to classification:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Before we start fitting the data to these models, we will briefly explain them
    one by one:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '`logistic`: **logistic regression** was introduced in *Chapter 2*, *Key Concepts
    of Interpretability*. It has many of the same pros and cons as **linear regression**.
    For instance, feature interactions must be added manually. Like other classification
    models, it returns a probability between 0 and 1, which, when closer to 1, denotes
    a probable match to a **positive class** while, when closer to 0, it denotes an
    improbable match to the **positive class**, and therefore a probable match to
    the **negative class**. Naturally, 0.5 is the threshold used to decide between
    classes, but it doesn’t have to be. As we will examine later in the book, there
    are interpretation and performance reasons to adjust the threshold. Note that
    this is a binary classification problem, so we are only choosing between delayed
    (positive) and not delayed (negative), but this method could be extended to multi-class
    classification. It would then be called **multinomial classification**.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ridge`: **Ridge classification** leverages the same regularization technique
    used in **ridge regression** but applied to classification. It does this by converting
    the target values to -1 (for a negative class) and keeping 1 for a positive class
    and then performing ridge regression. At its heart, its regression in disguise
    will predict values between -1 and 1, and then convert them back to a 0–1 scale.
    Like with `RidgeCV` for regression, `RidgeClassifierCV` uses leave-one-out cross-validation,
    which means it first splits the data into different equal-size sets – in this
    case, we are using five sets (`cv=5`) – and then removes features one at a time
    to see how well the model performs without them, on average in all the five sets.
    Those features that don’t make much of a difference are penalized by testing several
    regularization strengths (`alphas`) to find the optimal strength. As with all
    *regularization* techniques, the point is to discourage learning from unnecessary
    complexity, minimizing the impact of less salient features.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decision_tree`: A standard **decision tree**, such as this one, is also known
    as a **CART** (**classification and regression tree**) because it can be used
    for regression or classification tasks. It has the same algorithm for both tasks
    but functions slightly differently, like the algorithm used to decide where to
    “split” a branch. In this case, we are only allowing our trees to have a depth
    of 7.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`knn`: **k-NN** can also be applied to classification tasks, except instead
    of averaging what the nearest neighbors’ target features (or labels) are, it chooses
    the most frequent one (also known as the **mode**). We are also using a k-value
    of 7 for classification (`n_neighbors`).'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`naive_bayes`: **Gaussian Naïve Bayes** is part of the family of *Naïve Bayes*
    classifiers, which are called naïve because they make the assumption that the
    features are independent of each other, which is usually not the case. This dramatically
    impedes its capacity to predict unless the assumption is correct. It’s called
    *Bayes* because it’s based on **Bayes’ theorem of conditional probabilities**,
    which is that the conditional probability of a class is the class probability
    times the feature probability given the class. *Gaussian Naïve Bayes* makes an
    additional assumption, which is that continuous values have a normal distribution,
    also known as a **Gaussian distribution**.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gradient_boosting`: Like **random forest**, **gradient-boosted trees** are
    also an ensemble method, but that leverages **boosting** instead of **bagging**.
    **Boosting** doesn’t work in parallel but in sequence, iteratively training weak
    learners and incorporating their strengths into a stronger learner, while adapting
    another weak learner to tackle their weaknesses. Although ensembles and boosting,
    in particular, can be done with a model class, this method uses decision trees.
    We have limited the number of trees to 210 (`n_estimators=210`).'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_forest`: The same **random forest** as with regression except it generates
    classification decision trees and not regression trees.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mlp`: The same **multi-layer perceptron** as with regression, but the output
    layer, by default, uses a **logistic** function in the output layer to yield probabilities,
    which it then converts to 1 or 0, based on the 0.5 threshold. Another difference
    is that we are using seven neurons in the first and only hidden layer (`hidden_layer_sizes=(7,)`)
    because binary classification tends to require fewer of them to achieve an optimal
    result.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Please note that some of these models use balanced weights for the classes
    (`class_weight=''balanced''`), which is very important because this happens to
    be an **imbalanced classification** task. By that, we mean that negative classes
    vastly outnumber positive classes. We can find out what this looks like for our
    training data:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As you can see, the output in our training data’s positive classes represents
    only 6% of the total. Models that account for this will achieve *more balanced*
    results. There are different ways of accounting for *class imbalance*, which we
    will discuss in further detail in *Chapter 11*, *Bias Mitigation and Causal Inference
    Methods*, but `class_weight='balanced'` applies a weight inversely proportional
    to class frequencies, giving the outnumbered *positive* class a leg up.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Training and evaluating the classification models
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can now convert the dictionary to a `DataFrame` and display the metrics
    in a sorted and color-coded fashion:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding code outputs *Figure 3.3*:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B18406_03_03.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.3: Classification metrics for our models'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'To interpret the metrics in *Figure 3.3*, we ought to first understand what
    they mean, both in general and in the context of this classification exercise:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '**Accuracy**: Accuracy is the simplest way to measure the effectiveness of
    a classification task, and it’s the percentage of correct predictions over all
    predictions. In other words, in a binary classification task, you can calculate
    this by adding the number of **True Positives** (**TPs**)and **True Negatives**
    (**TNs**) and dividing them by a tally of all predictions made. As with regression
    metrics, you can measure accuracy for both train and test to gauge overfitting.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recall**: Even though accuracy sounds like a great metric, recall is much
    better in this case and the reason is you could have an accuracy of 94%, which
    sounds pretty good, but it turns out you are always predicting no delay! In other
    words, even if you get high accuracy, it is meaningless unless you are predicting
    accurately for the least represented class, delays. We can find this number with
    recall (also known as **sensitivity** or **true positive rate**), which is ![](img/B18406_03_003.png)
    , and it can be interpreted as how much of the relevant results were returned
    – in other words, in this case, what percentage of the actual delays were predicted.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another good measure involving true positives is **precision**, which is how
    much our predicted samples are relevant, which is ![](img/B18406_03_004.png).
    In this case, that would be what percentage of predicted delays were actual delays.
    For imbalanced classes, it is recommended to use both, but depending on your preference
    for *FN* over *FP*, you will prefer recall over precision or vice versa.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**ROC-AUC**: **ROC** is an acronym for **Receiver Operating Characteristic**
    and was designed to separate signal from noise. What it does is plot the proportion
    of **true positive rate** (**recall**) on the *x* axis and the false positive
    rate on the *y* axis. **AUC** stands for **area under the curve**, which is a
    number between 0 and 1 that assesses the prediction ability of the classifier
    1 being perfect, 0.5 being as good as a random coin toss, and anything lower meaning
    that if we inverted the results of our prediction, we would have a better prediction.
    To illustrate this, let’s generate a ROC curve for our worst-performing model,
    Naïve Bayes, according to the AUC metric:'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The preceding code outputs *Figure 3.4*. Note that the diagonal line signifies
    half the area. In other words, the point where it has a coin-toss-like prediction
    quality:'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![A picture containing polygon  Description automatically generated](img/B18406_03_04.png)'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.4: ROC curve for Naïve Bayes'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**F1**: The **F1-score** is also called the harmonic average of precision and
    recall because it’s calculated like this: ![](img/B18406_03_005.png). Since it
    includes both precision and recall metrics, which pertain to the proportion of
    true positives, it’s a good metric choice to use when your dataset is imbalanced,
    and you don’t prefer either precision or recall.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MCC**: The **Matthews correlation coefficient** is a metric drawn from biostatistics.
    It’s gaining popularity in the broader data science community because it has the
    ability to produce high scores considering *TP*, *FN*, *TN*, and *FP* fairly,
    because it takes into account the proportions of classes. This makes it optimal
    for imbalanced classification tasks. Unlike all other metrics used so far, it
    doesn’t range from 0 to 1 but from -1, complete disagreement, to 1, a total agreement
    between predictions and actuals. The mid-point, 0, is equivalent to a random prediction:'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18406_03_006.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
- en: Our classification metrics are mostly very good, exceeding 96% accuracy and
    75% recall. However, even recall isn’t everything. For instance, `RandomForest`,
    due to its class balancing with weights, got the highest recall but did poorly
    in F1 and MCC, which suggests that precision is not very good.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Ridge classification also had the same setting and had such a poor F1 score
    that the precision must have been dismal. This doesn’t mean this weighting technique
    is inherently wrong, but it often requires more control. This book will cover
    techniques to achieve the right balance between fairness and accuracy, accuracy
    and reliability, reliability and validity, and so on. This is a balancing act
    that requires many metrics and visualizations. A key takeaway from this exercise
    should be that a **single metric will not tell you the whole story**, and interpretation
    is about **telling the most relevant and sufficiently complete story**.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Understanding limitations of traditional model interpretation methods
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a nutshell, traditional interpretation methods *only cover high-level questions
    about your models* such as the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: In aggregate, do they perform well?
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*What* changes in hyperparameters may impact predictive performance?'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*What* latent patterns can you find between the features and their predictive
    performance?'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These questions are very limiting if you are trying to understand not only whether
    your model works but *why* and *how*?
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: This gap in understanding can lead to unexpected issues with your model that
    won’t necessarily be immediately apparent. Let’s consider that models, once deployed,
    are not static but dynamic. They face different challenges than they did in the
    “lab” when you were training them. They may face not only performance issues but
    issues with bias, such as imbalance with underrepresented classes, or security
    vulnerabilities with adversarial attacks. Realizing that the features have changed
    in the real-world environment, we might have to add new features instead of merely
    retraining with the same feature set. And if there are some troubling assumptions
    made by your model, you might have to re-examine the whole pipeline. But how do
    you recognize that these problems exist in the first place? That’s when you will
    need a whole new set of interpretation tools that can help you dig deeper and
    answer more specific questions about your model. These tools provide interpretations
    that can truly account for **Fairness, Accountability, and Transparency** (**FAT**),
    which we discussed in *Chapter 1*, *Interpretation, Interpretability, and Explainability;
    and Why Does It All Matter?*
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Studying intrinsically interpretable (white-box) models
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, in this chapter, we have already fitted our training data to model classes
    representing each of these “white-box” model families. The purpose of this section
    is to show you exactly why they are *intrinsically interpretable*. We’ll do so
    by employing the models that were previously fitted.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Generalized Linear Models (GLMs)
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'GLMs are a large family of model classes that have a model for every statistical
    distribution. Just like **linear regression** assumes your target feature and
    residuals have a normal distribution, **logistic regression** assumes the Bernoulli
    distribution. There are GLMs for every distribution, such as **Poisson regression**
    for Poisson distribution and **multinomial response** for multinomial distribution.
    You choose which GLM to use based on the distribution of your target variable
    and whether your data meets the other assumptions of the GLM (they vary). In addition
    to an underlying distribution, what ties GLMs together into a single family is
    the fact that they all have a linear predictor. In other words, the ![](img/B18406_03_007.png)
    target variable (or predictor) can be expressed mathematically as a weighted sum
    of *X* features, where weights are called *b* coefficients. This is the simple
    formula, the linear predictor function, that all GLMs share:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_008.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
- en: However, although they share this same formula, they each have a different link
    function, which provides a link between the linear predictor function and the
    mean of the statistical distribution of the GLM. This can add some non-linearity
    to the resulting model formula while retaining the linear combination between
    the *b* coefficients and the *X* input data, which can be a source of confusion.
    Still, it’s linear because of the linear combination.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: There are also many variations for specific GLMs. For instance, **Polynomial
    regression** is *linear regression* with polynomials of its features, and **ridge
    regression** is *linear regression* with L2 regularization. We won’t cover all
    GLMs in this section because they aren’t needed for the example in this chapter,
    but all have plausible use cases.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Incidentally, there’s also a similar concept called **Generalized Additive Models**
    (**GAMs**), which are GLMs that don’t require linear combinations of features
    and coefficients and instead retain the addition part, but of arbitrary functions
    applied to the features. GAMs are also interpretable, but they are not as common,
    and are usually tailored to specific use cases *ad hoc*.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In *Chapter 1*, *Interpretation, Interpretability, and Explainability, and
    Why Does It All Matter?*, we covered the formula of simple linear regression,
    which only has a single *X* feature. Multiple linear regression extends this to
    have any number of features, so instead of being:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_009.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: 'it can be:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_010.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
- en: 'with *n* features, and where ![](img/B18406_03_011.png) is the intercept, and
    thanks to linear algebra this can be a simple matrix multiplication:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_008.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
- en: 'The method used to arrive at the optimal *b* coefficients, **OLS**, is well-studied
    and understood. Also, in addition to the coefficients, you can extract confidence
    intervals for each. The model’s correctness depends on whether the input data
    meets the assumptions: **linearity**, normality, independence, a lack of multicollinearity,
    and homoscedasticity. We’ve discussed linearity, so far, quite a bit so we will
    briefly explain the rest:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '**Normality** is the property that each feature is normally distributed. This
    can be tested with a **Q-Q plot**, histogram, or **Kolmogorov-Smirnov** test,
    and non-normality can be corrected with non-linear transformations. If a feature
    isn’t normally distributed, it will make its coefficient confidence intervals
    invalid.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Independence** is when your *observations* (the rows in your dataset) are
    independent of each other, like different and unrelated events. If your *observations*
    aren’t independent, it could affect your interpretation of the results. In this
    chapter’s example, if you had multiple rows about the same flight, that could
    violate this assumption and make results hard to understand. This can be tested
    by looking for duplicate flight numbers.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multicollinearity occurs when the features are highly correlated with each other.
    **Lack of multicollinearity** is desirable because otherwise, you’d have inaccurate
    coefficients. This can be tested with a **correlation matrix**, **tolerance measure**,
    or **Variance Inflation Factor** (**VIF**), and it can be fixed by removing one
    of each highly correlated feature.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Homoscedasticity** was briefly discussed in *Chapter 1*, *Interpretation,
    Interpretability, and Explainability; and Why Does It All Matter?* and it’s when
    the residuals (the errors) are more or less equal across the regression line.
    This can be tested with the **Goldfeld–Quandt test**, and heteroscedasticity (the
    lack of homoscedasticity) can be corrected with non-linear transformations. This
    assumption is often violated in practice.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Even though we haven’t done it for this chapter’s example, if you are going
    to rely on linear regression heavily, it’s always good to test these assumptions
    before you even begin to fit your data to a linear regression model. This book
    won’t detail how this is done because it’s more about model-agnostic and deep-learning
    interpretation methods than delving into how to meet the assumptions of a specific
    class of models, such as **normality** and **homoscedasticity**. However, we covered
    the characteristics that trump interpretation the most in *Chapter 2,* *Key Concepts
    of Interpretability*, and we will continue to look for these characteristics:
    **non-linearity**, **non-monotonicity**, and **interactivity**. We will do this
    mainly because the linearity and correlation of and between features are still
    relevant, regardless of the modeling class used to make predictions. And these
    are characteristics that can be easily tested in the methods used for linear regression.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation
  id: totrans-192
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'So how do we interpret a linear regression model? Easy! Just get the coefficients
    and the intercept. Our scikit-learn models have these attributes embedded in the
    fitted model:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The preceding code outputs the following:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'So now you know the formula, which looks something like this:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_013.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
- en: 'This formula should provide some intuition on how the model can be interpreted
    globally. Interpreting each coefficient in the model can be done for multiple
    linear regression, just as we did with the simple linear regression example in
    *Chapter 1*, *Interpretation, Interpretability, and Explainability; and Why Does
    It All Matter?*. The coefficients act as weights, but they also tell a story that
    varies depending on the kind of feature. To make interpretation more manageable,
    let’s put our coefficients in a `DataFrame` alongside the names of each feature:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The preceding code produces the DataFrame in *Figure 3.5*:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B18406_03_05.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.5: Coefficients of linear regression features'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how to interpret a feature using the coefficients in *Figure 3.5*:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '**Continuous**: Like `ARR_RFPH`, you know that for every one-unit increase
    (relative flights per hour), it increases the predicted delay by 0.373844 minutes,
    if all other features stay the same.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Binary**: Like `ORIGIN_HUB`, you know the difference between the origin airport
    being a hub or not is expressed by the coefficient -1.029088\. In other words,
    since it’s a negative number, the origin airport is a hub. It reduces the delay
    by just over 1 minute if all other features stay the same.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Categorical**: We don’t have categorical features, but we have ordinal features
    that could have been, and **actually should have been**, categorical features.
    For instance, `DEP_MONTH` and `DEP_DOW` are integers from 1–12 and 0–6, respectively.
    If they are treated as ordinals, we are assuming because of the linear nature
    of linear regression that an increase or decrease in months has an impact on the
    outcome. It’s the same with the day of the week. But the impact is tiny. Had we
    treated them as dummy or one-hot encoded features, we could measure whether Fridays
    are more prone to carrier delays than Saturdays and Wednesdays, or Julys more
    than Octobers and Junes. This couldn’t possibly be modeled with them in order,
    because they have no relation to this order (yep – it’s non-linear!). So, say
    we had a feature called `DEP_FRIDAY` and another called `DEP_JULY`. They are treated
    like binary features and can tell you precisely what effect a departure being
    on a Friday or in July has on the model. Some features were kept as ordinal or
    continuous on purpose, despite being good candidates for being categorical, to
    demonstrate how not making the right adjustments to your features can impact the
    **expressive power** of model interpretation. It would have been good to tell
    airline executives more about how the day and time of a departure impacted delays.
    Also, in some cases – not in this one – an oversight like this can grossly affect
    a linear regression model’s performance.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The intercept (-37.86) is not a feature, but it does have a meaning, which is,
    if all features were at 0, what would the prediction be? In practice, this doesn’t
    happen unless your features happen to all have a plausible reason to be 0\. Just
    as in *Chapter 1*, *Interpretation, Interpretability, and Explainability; and
    Why Does It All Matter?* you wouldn’t have expected anyone to have a height of
    0, in this example, you wouldn’t expect a flight to have a distance of 0\. However,
    if you standardized the features so that they had a mean of 0, then you would
    change the interpretation of the intercept to be the prediction you expect if
    all features are their mean value.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Feature importance
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The coefficients can also be leveraged to calculate feature importance. Unfortunately,
    scikit-learn’s linear regressor is ill-equipped to do this because it doesn’t
    output the standard error of the coefficients. According to their importance,
    all it takes to rank features is to divide the ![](img/B18406_03_014.png)s by
    their corresponding standard errors. This result is something called the **t-statistic**:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_015.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
- en: 'And then you take an absolute value of this and sort them from high to low.
    It’s easy enough to calculate, but you need the standard error. You could reverse-engineer
    the linear algebra involved to retrieve it using the intercept, and the coefficients
    returned by scikit-learn. However, it’s probably a lot easier to fit the linear
    regression model again, but this time using the `statsmodels` library, which has
    a summary with all the statistics included! By the way, `statsmodels` names its
    linear regressor `OLS`, which makes sense because `OLS` is the name of the mathematical
    method that fits the data:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: There’s quite a bit to unpack in the regression summary. This book won’t address
    everything except that the t-statistic can tell you how important features are
    in relation to each other. There’s another more pertinent statistical interpretation,
    which is that if you were to hypothesize that the *b* coefficient is 0 – in other
    words, that the feature has no impact on the model – the distance of the t-statistic
    from 0 helps reject that null hypothesis. This is what the **p-value** to the
    right of the t-statistic does. It’s no coincidence that the closest *t* to 0 (for
    `ARR_AFPH`) has the only p-value above 0.05\. This puts this feature at a level
    of insignificance since everything below 0.05 is statistically significant according
    to this method of hypothesis testing.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 'So to rank our features, let’s extract the DataFrame from the `statsmodels`
    summary. Then, we drop the `const` (the intercept) because this is not a feature.
    Then, we make a new column with the absolute value of the t-statistic and sort
    it accordingly. To demonstrate how the absolute value of the t-statistic and p-value
    are inversely related, we are also color-coding these columns:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The preceding code outputs *Figure 3.6*:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '![Table, Excel  Description automatically generated](img/B18406_03_06.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.6: Linear regression summary table sorted by the absolute value of
    the t-statistic'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'Something particularly interesting about the feature importance in *Figure
    3.6* is that different kinds of delays occupy five out of the top six positions.
    Of course, this could be because linear regression is confounding the different
    non-linear effects these have, or perhaps there’s something here we should look
    further into – especially since the `statsmodels` summary in the “**Warnings**”
    section cautions:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This is odd. Hold that thought. We will examine this further later.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Ridge regression
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ridge regression is part of a sub-family of **penalized** or **regularized**
    regression along with the likes of LASSO and ElasticNet because, as explained
    earlier in this chapter, it penalizes using the *L2 norm*. This sub-family is
    also called **sparse linear models** because, thanks to the regularization, it
    cuts out some of the noise by making irrelevant features less relevant. **Sparsity**
    in this context means less is more because reduced complexity will lead to lower
    variance and improved generalization.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this concept, look at the feature importance table (*Figure 3.6*)
    we output for linear regression. Something that should be immediately apparent
    is how the `t_abs` column starts with every row a different color, and then a
    whole bunch of them are the same shade of yellow. Because of the variation in
    confidence intervals, the absolute t-value is not something you can take proportionally
    and say that your top feature is hundreds of times more relevant than every one
    of your bottom 10 features. However, it should indicate that there are significantly
    more important features than others to the point of irrelevance, and possibly
    confoundment, hence creating noise. There’s ample research on how there’s a tendency
    for a small subset of features to have the most substantial effects on the outcome
    of the model. This is called the **bet on sparsity principle**. Whether it’s true
    or not for your data, it’s always good to test the theory by applying regularization,
    especially in cases where data is very wide (many features) or exhibits multicollinearity.
    These regularized regression techniques can be incorporated into feature selection
    processes or to inform your understanding of what features are essential.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: There is a technique to adapt ridge regression to classification problems. It
    was briefly discussed before. It converts the labels to a -1 to 1 scale for training
    to predict values between -1 and 1, and then turns them back to a 0–1 scale. However,
    it uses regularized linear regression to fit the data and can be interpreted in
    the same way.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation
  id: totrans-227
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Ridge regression can be interpreted in the same way as linear regression, both
    globally and locally, because once the model has been fitted, there’s no difference.
    The formula is the same:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_016.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
- en: Except ![](img/B18406_03_017.png) coefficients are different because they were
    penalized with a ![](img/B18406_03_018.png) parameter, which controls how much
    shrinkage to apply.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'We can quickly compare coefficients by extracting the ridge coefficients from
    their fitted model and placing them side by side in a `DataFrame` with the coefficients
    of the linear regression:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'As you can tell in the *Figure 3.7* output of the preceding code, the coefficients
    are always slightly different, but sometimes they are lower and sometimes higher:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B18406_03_07.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.7: Linear regression coefficients compared to ridge regression coefficients'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'We didn’t save the ![](img/B18406_03_018.png) parameter (which scikit-learn
    calls *alpha*) that the ridge regression cross-validation deemed optimal. However,
    we can run a little experiment of our own to figure out which parameter was the
    best. We do this by iterating through 100 possible alphas values between 100 (1)
    and 1013 (100,000,000,000,000), fitting the data to the ridge model, and then
    appending the coefficients to an array. We exclude the eight coefficient in the
    array because it’s so much larger than the rest, and it will make it harder to
    visualize the effects of shrinkage:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now that we have an array of coefficients, we can plot the progression of coefficients:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The preceding code generates *Figure 3.8*:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, line chart  Description automatically generated](img/B18406_03_08.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.8: Value of alpha hyperparameters versus the value of ridge regression
    coefficients'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Something to note in *Figure 3.8* is that the higher the alpha, the higher the
    regularization. This is why when alpha is 1012, all coefficients have converged
    to 0, and as the alpha becomes smaller, they get to a point where they have all
    diverged and more or less stabilized. In this case, this point is reached at about
    102\. Another way of seeing it is when all coefficients are around 0, it means
    that the regularization is so strong that all features are irrelevant. When they
    have sufficiently diverged and stabilized, the regularization makes them all relevant,
    which defeats the purpose.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'Now on that note, if we go back to our code, we will find that this is what
    we chose for alphas in our `RidgeCV`: `alphas=[1e-3, 1e-2, 1e-1, 1]`. As you can
    tell from the preceding plot, by the time the alphas have reached `1` and below,
    the coefficients have already stabilized even though they are still fluctuating
    slightly. This can explain why our ridge was not better performing than linear
    regression. Usually, you would expect a regularized model to perform better than
    one that isn’t – unless your hyperparameters are not right.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation and hyperparameters
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'Well-tuned regularization can help cut out the noise and thus increase interpretability,
    but the alphas chosen for `RidgeCV` were selected on purpose to be able to convey
    this point: *regularization can only work if you chose hyperparameters correctly*,
    or, when regularization hyperparameter tuning is automatic, the method must be
    optimal for your dataset.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Feature importance
  id: totrans-247
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This is precisely the same as with linear regression, but again we need the
    standard error of the coefficients, which is something that cannot be extracted
    from the scikit-learn model. You can use the `statsmodels fit_regularized` method
    to this effect.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Polynomial regression
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Polynomial regression is a special case of linear or logistic regression where
    the features have been expanded to have higher degree terms. We have only performed
    polynomial linear regression in this chapter’s exercise, so we will only discuss
    this variation. However, it is applied similarly.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 'A two-feature multiple linear regression would look like this:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_020.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
- en: 'However, in polynomial regression, every feature is expanded to have higher
    degree terms and interactions between all the features. So, if this two-feature
    example was expanded to a second-degree polynomial, the linear regression formula
    would look like this:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_021.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
- en: 'It’s still linear regression in every way except it has extra features, higher-degree
    terms, and interactions. While you can limit polynomial expansion to only one
    or a few features, we used `PolynomialFeatures`, which does this to all features.
    Therefore, 21 features were likely multiplied many times over. We can extract
    the coefficients from our fitted model and, using the `shape` property of the
    `numpy` array, return how many coefficients were generated. This amount corresponds
    to the number of features generated:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'It outputs `253`. We can do the same with the version of polynomial regression,
    which was with interaction terms only:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The above code outputs `232`. The reality is that most terms in a polynomial
    generated like this are interactions between all the features.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation and feature importance
  id: totrans-260
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Polynomial regression can be interpreted, both globally and locally, in precisely
    the same way as linear regression. In this case, it’s not practical to understand
    a formula with 253 linearly combined terms, so it loses what we defined in *Chapter
    2*, *Key Concepts of Interpretability*, as **global holistic interpretation**.
    However, it still can be interpreted in all other scopes and retains many of the
    properties of linear regression. For instance, since the model is additive, it
    is easy to separate the effects of the features. You can also use the same many
    peer-reviewed tried and tested statistical methods that are used for linear regression.
    For instance, you can use the t-statistic, p-value, confidence bounds, R-squared,
    as well as the many tests used to assess goodness of fit, residual analysis, linear
    correlation, and analysis of variance. This wealth of statistically proven methods
    to test and interpret models isn’t something most model classes can count on.
    Unfortunately, many of them are model-specific to linear regression and its special
    cases.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Also, we won’t do it here because there are so many terms. Still, you could
    undoubtedly rank features for polynomial regression in the same way we have for
    linear regression using the `statsmodels` library. The challenge is figuring out
    the order of the features generated by `PolynomialFeatures` to name them accordingly
    in the feature name column. Once this is done, you can tell if some second-degree
    terms or interactions are important. This could tell you if these features have
    a non-linear nature or highly depend on other features.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We discussed logistic regression as well as its interpretation and feature
    importance in *Chapter 2*, *Key Concepts of Interpretability*. We will only expand
    on that a bit here in the context of this chapter’s classification exercise and
    to underpin why exactly it is interpretable. The fitted logistic regression model
    has coefficients and intercepts just as the linear regression model does:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The preceding code outputs this:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'However, the way these coefficients appear in the formula for a specific prediction
    ![](img/B18406_03_022.png)is entirely different:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_023.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
- en: In other words, the probability that ![](img/B18406_03_024.png) (is a positive
    case) is expressed by a **logistic function** that involves exponentials of the
    linear combination of ![](img/B18406_03_014.png) coefficients and the *x* features.
    The presence of the exponentials explains why the coefficients extracted from
    the model are log odds because to isolate the coefficients, you should apply a
    logarithm to both sides of the equation.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation
  id: totrans-271
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To interpret each coefficient, you do it in precisely the same way as with linear
    regression, except with each unit increase in the features, you increase the odds
    of getting the positive case by a factor expressed by the exponential of the coefficient
    – all things being equal (remember the **ceteris paribus** assumption discussed
    in *Chapter 2*, *Key Concepts of Interpretability*). An exponential (![](img/B18406_03_026.png))
    has to be applied to each coefficient because they express an increase in log
    odds and not odds. Besides incorporating the log odds into the interpretation,
    the same that was said about continuous, binary, and categorical in linear regression
    interpretation applies to logistic regression.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: Feature importance
  id: totrans-273
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Frustrating as it is, there isn’t consensus yet from the statistical community
    on how to best get feature importance for logistic regression. There’s a standardize-all-features-first
    method, a pseudo R² method, a *one feature at a time* ROC AUC method, a partial
    chi-squared statistic method, and then the simplest one, which is multiplying
    the standard deviations of each feature times the coefficients. We won’t cover
    all these methods, but it has to be noted that computing feature importance consistently
    and reliably is a problem for most model classes, even white-box ones. We will
    dig deeper into this in *Chapter 4*, *Global Model-Agnostic Interpretation Methods*.
    For logistic regression, perhaps the most popular method is achieved by standardizing
    all the features before training – that is, making sure they are centered at zero
    and divided by their standard deviation. But we didn’t do this because although
    it has other benefits, it makes the interpretation of coefficients more difficult,
    so here we are using the rather crude method leveraged in *Chapter 2*, *Key Concepts
    of Interpretability*, which is to multiply the standard deviations of each feature
    times the coefficients:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The preceding code yields the following output:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: It can still approximate the importance of features quite well. And just like
    with linear regression, you can tell that delay features are ranking quite high.
    All five of them are among the top eight features. Indeed, it’s something we should
    look into. We will discuss more on that as we discuss some other white-box methods.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Decision trees have been used for the longest time, even before they were turned
    into algorithms. They hardly require any mathematical abilities to understand
    them, and this low barrier to comprehensibility makes them extremely interpretable
    in their simplest representations. However, in practice, there are many types
    of decision tree learning, and most of them are not very interpretable because
    they use **ensemble methods** (boosting, bagging, and stacking), or even leverage
    PCA or some other embedder. Even non-ensembled decision trees can get extremely
    complicated as they become deeper. Regardless of the complexity of a decision
    tree, they can always be mined for important insights about your data and expected
    predictions, and they can be fitted to both regression and classification tasks.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: CART decision trees
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **Classification and Regression Trees** (**CART**) algorithm is the “vanilla”
    no-frills decision tree of choice in most use cases. And as noted, most decision
    trees aren’t white-box models, but this one is because it is expressed as a mathematical
    formula, visualized, and printed as a set of rules that subdivides the tree into
    branches and eventually the leaves.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 'The mathematical formula:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_027.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
- en: And what this means is that if according to the identity function *I*, *x* is
    in the subset *R*[m], then it returns a 1, otherwise a 0\. This binary term is
    multiplicated by the averages of all elements in the subset *R*[m] denoted as
    ![](img/B18406_03_028.png). So if x[i] is in the subset belonging to the leaf
    node *R*[k] then the prediction ![](img/B18406_03_029.png). In other words, the
    prediction is the average of all elements in the subset*R*[k]. This is what happens
    to regression tasks, and in binary classification, there is simply no ![](img/B18406_03_028.png)
    to multiply the *I* identify function.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: At the heart of every decision tree algorithm, there’s a method to generate
    the *R*[m] subsets. For CART, this is achieved using something called the **Gini
    index**, recursively splitting on where the two branches are as different as possible.
    This concept will be explained in greater detail in *Chapter 4*, *Global Model-Agnostic
    Interpretation Methods*.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A decision tree can be globally and locally interpreted visually. Here, we
    have established a maximum depth of 2 (`max_depth=2`) because we could generate
    all 7 layers, but the text would be too small to appreciate. One of the limitations
    of this method is that it can get complicated to visualize with depths above 3
    or 4\. However, you can always programmatically traverse the branches of the tree
    and visualize only some branches at a time:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The preceding code prints out the tree in *Figure 3.9*. From the tree, you
    can tell that the very first branch splits the decision tree based on the value
    of `DEP_DELAY` being equal to or smaller than 20.5\. It tells you the Gini index
    that informed that decision and the number of `samples` (just another way of saying
    observations, data points, or rows) present. You can traverse these branches till
    they reach a leaf. There is one leaf node in this tree, and it is on the far left.
    This is a classification tree, so you can tell by the value =[629167, 0] that
    all 629,167 samples left in this node have been classified as a 0 (not delayed):'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_09.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9: Our models’ plotted decision tree'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way the tree can be better visualized but with fewer details, such
    as the Gini index and sample size, is by printing out the decisions made in every
    branch and the class in every node:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'And the preceding code outputs the following:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '![A close-up of a document  Description automatically generated with medium
    confidence](img/B18406_03_10.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.10: Our decision tree’s structure'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: There’s a lot more that can be done with a decision tree, and scikit-learn provides
    an API to explore the tree.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Feature importance
  id: totrans-299
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Calculating feature importance in a CART decision tree is reasonably straightforward.
    As you can appreciate from the visualizations, some features appear more often
    in the decisions, but their appearances are weighted by how much they contributed
    to the overall reduction in the Gini index compared to the previous node. All
    the sum of the relative decrease in the Gini index throughout the tree is tallied,
    and the contribution of each feature is a percentage of this reduction:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The `dt_imp_df` DataFrame output by the preceding code can be appreciated in
    *Figure 3.11*:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B18406_03_11.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.11: Our decision tree’s feature importance'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: This last feature importance table, *Figure 3.11*, increases suspicions about
    the delay features. They occupy, yet again, five of the top six positions. Is
    it possible that all five of them have such an outsized effect on the model?
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '**Interpretation and domain expertise**'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: The target `CARRIER_DELAY` is also called a dependent variable because it’s
    dependent on all the other features, the independent variables. Even though a
    statistical relationship doesn’t imply causation, we want to inform our feature
    selection based on our understanding of what independent variables could plausibly
    affect a dependent one.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: It makes sense that a departure delay (`DEPARTURE_DELAY`) affects the arrival
    delay (which we removed), and therefore, `CARRIER_DELAY`. Similarly, `LATE_AIRCRAFT_DELAY`
    makes sense as a predictor because it is known before the flight takes off if
    a previous aircraft was several minutes late, causing this flight to be at risk
    of arriving late, but not as a cause of the current flight (ruling this option
    out). However, even though the Bureau of Transportation Statistics website defines
    delays in such a way that they appear to be discrete categories, some may be determined
    well after a flight has departed. For instance, in predicting a delay mid-flight,
    could we use `WEATHER_DELAY` if the bad weather hasn’t yet happened? And could
    we use `SECURITY_DELAY` if the security breach hasn’t yet occurred? The answers
    to these questions are that we probably shouldn’t because the rationale for including
    them is they could serve to rule out `CARRIER_DELAY`, but this only works if they
    are discrete categories that pre-date the dependent variable! If they don’t they
    would be producing what is known as data leakage. Before coming to further conclusions,
    what you would need to do is talk to the airline executives to determine the timeline
    on which each delay category gets consistently set and (hypothetically) is accessible
    from the cockpit or the airline’s command center. Even if you are forced to remove
    them from the models, maybe other data can fill the void in a meaningful way,
    such as the first 30 minutes of flight logs and/or historical weather patterns.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation is not always directly inferred from the data and the machine
    learning models, but by working closely with domain experts. But sometimes domain
    experts can mislead you too. In fact, another insight is with all the time-based
    metrics and categorical features we engineered at the beginning of the chapter
    (`DEP_DOW`, `DEST_HUB`, `ORIGIN_HUB`, and so on). It turns out they have consistently
    had little to no effect on the models. Despite the airline executives hinting
    at the importance of days of the week, hubs, and congestion, we should have explored
    the data further, looking for correlations before engineering the data. But even
    if we do engineer some useless features, it also helps to use a white-box model
    to assess their impact, as we have. In data science, practitioners often will
    learn the same way that the most performant machine learning models do – by trial
    and error!
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: RuleFit
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**RuleFit** is a model-class family that is a hybrid between a LASSO linear
    regression to get regularized coefficients for every feature and decision rules,
    which also uses LASSO to regularize. These **decision** **rules** are extracted
    by traversing a decision tree, finding interaction effects between features, and
    assigning coefficients to them based on their impact on the model. The implementation
    used in this chapter uses gradient-boosted decision trees to perform this task.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: We haven’t covered decision rules explicitly in this chapter, but they are yet
    another family of **intrinsically interpretable models**. They weren’t included
    because, at the time of writing, the only Python library that supports decision
    rules, called **Bayesian Rule List** (**BRL**) by Skater, is still at an experimental
    stage. In any case, the concept behind decision rules is very similar. They extract
    the feature interactions from a decision tree but don’t discard the leaf node,
    and instead of assigning coefficients, they use the predictions in the leaf node
    to construct the rules. The last rule is a catch-all, like an *ELSE* statement.
    Unlike RuleFit, it can only be understood sequentially because it’s so similar
    to any *IF-THEN-ELSE* statement, but that’s its main advantage.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation and feature importance
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can put everything you need to know about RuleFit into a single DataFrame
    (`rulefit_df`). Then you remove the rules that have a coefficient of `0`. It has
    these because in LASSO, unlike ridge, coefficient estimates converge to zero.
    You can sort the DataFrame by importance in a descending manner to see what features
    or feature interactions (in the form of rules) are most important:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The rules in the `rulefit_df` DataFrame can be seen in *Figure 3.12*:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B18406_03_12.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.12: RuleFit’s rules'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: There’s a `type` for every RuleFit feature in *Figure 3.12*. Those that are
    `linear` are interpreted as you would any linear regression coefficient. Those
    that are `type=rule` are also to be treated like binary features in a linear regression
    model. For instance, if the rule `LATE_AIRCRAFT_DELAY <= 333.5 & DEP_DELAY > 477.5`
    is true, then the coefficient `172.103034` is applied to the prediction. The rules
    capture the interaction effects, so you don’t have to add interaction terms to
    the model manually or use some non-linear method to find them. Furthermore, it
    does this in an easy-to-understand manner. You can use RuleFit to guide your understanding
    of feature interactions even if you choose to productionize other models.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: Nearest neighbors
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Nearest neighbors is a family of models that even includes unsupervised methods.
    All of them use the closeness between data points to inform their predictions.
    Of all these methods, only the supervised k-NN and its cousin Radius Nearest Neighbors
    are somewhat interpretable.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: k-Nearest Neighbors
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The idea behind **k-NN** is straightforward. It takes the *k* closest points
    to a data point in the training data and uses their labels (`y_train`) to inform
    the predictions. If it’s a classification task, it’s the **mode** of all the labels,
    and if it’s a regression task, it’s the **mean**. It’s a **lazy learner** because
    the “fitted model” is not much more than the training data and the parameters,
    such as *k* and the list of classes (if it’s a classification). It doesn’t do
    much till inference. That’s when it leverages the training data, tapping into
    it directly rather than extracting parameters, weights/biases, or coefficients
    learned by the model as **eager learners** do.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation
  id: totrans-324
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**k-NN** only has local interpretability because since there’s no fitted model,
    you don’t have global modular or global holistic interpretability. For classification
    tasks, you could attempt to get a sense of this using the decision boundaries
    and regions we studied in *Chapter 2*, *Key Concepts of Interpretability*. Still,
    it’s always based on local instances.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: 'To interpret a local point from our test dataset, we query the `pandas` DataFrame
    using its index. We will be using flight #721043:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The preceding code outputs the following `pandas` series:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'In the `y_test_class` labels for flight #721043, we can tell that it was delayed
    because this code outputs 1:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'However, our k-NN model predicted that it was not because this code outputs
    0:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Please note that the predictions are output as a `numpy` array, so we can’t
    access the prediction for flight #721043 using its `pandas` index (721043). We
    have to use the sequential location of this index in the test dataset using `get_loc`
    to retrieve it.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: 'To find out why this was the case, we can use `kneighbors` on our model to
    find the seven nearest neighbors of this point. To this end, we have to `reshape`
    our data because `kneighbors` will only accept it in the same shape found in the
    training set, which is (n, 21) where n is the number of observations (rows). In
    this case, `n=1` because we only want the nearest neighbors for a single data
    point. And as you can tell from what was output by `X_test.loc[721043,:]`, the
    `pandas` series has a shape of (21,1), so we have to reverse this shape:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '`kneighbors` outputs two arrays:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The first is the distance of each of the seven closest training points to our
    test data point. And the second is the location of these data points in the training
    data:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The preceding code outputs the following `pandas` series:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We can tell that the prediction reflects the **mode** because the most common
    class in the seven nearest points was 0 (not delayed). You can increase or decrease
    the *k* to see if this holds. Incidentally, when using binary classification,
    it’s recommended to choose an odd-numbered *k* so that there are no ties. Another
    important aspect is the distance metric that was used to select the closest data
    points. You can easily find out which one it is using:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The output is Euclidean, which makes sense for this example. After all, Euclidean
    is optimal for a **real-valued vector space** because most features are continuous.
    You could also test alternative distance metrics such as `minkowski`, `seuclidean`,
    or `mahalanobis`. When most of your features are binary and categorical, you have
    an **integer-valued** **vector space**. So your distances ought to be calculated
    with algorithms suited for this space such as `hamming` or `canberra`.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: Feature importance
  id: totrans-346
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Feature importance is, after all, a global model interpretation method and k-NN
    has a hyper-local nature, so there’s no way of deriving feature importance from
    a k-NN model.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: Naïve Bayes
  id: totrans-348
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Like GLMs, Naïve Bayes is a family of model classes with a model tailored to
    different statistical distributions. However, unlike GLMs’ assumption that the
    target *y* feature has the chosen distribution, all Naïve Bayes models assume
    that your *X* features have this distribution. More importantly, they were based
    on Bayes’ theorem of conditional probability, so they output a probability and
    are, therefore, exclusively classifiers. But they treat the probability of each
    feature impacting the model independently, which is a strong assumption. This
    is why they are called naïve. There’s one for Bernoulli called Bernoulli Naïve
    Bayes, one for multinomial called **Multinomial Naïve Bayes**, and, of course,
    one for Gaussian, which is the most common.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian Naïve Bayes
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Bayes’ theorem is defined by this formula: ![](img/B18406_03_031.png)'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, to find the probability of *A* happening given that *B* is
    true, you take the conditional probability of *B* given *A* is true times the
    probability of *A* occurring, divided by the probability of *B*. In the context
    of a machine learning classifier, this formula can be rewritten as follows:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_032.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
- en: 'This is because what we want is the probability of *y* given *X* is true. But
    our *X* has more than one feature, so this can be expanded like this:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_033.png)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
- en: 'To compute ![](img/B18406_03_007.png) predictions, we have to consider that
    we have to calculate and compare probabilities for each *C*[k] class (the probability
    of a delay versus the probability of no delay) and choose the class with the highest
    probability:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_035.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
- en: 'Calculating the probability of each class ![](img/B18406_03_036.png) (also
    known as the class prior) is relatively trivial. In fact, the fitted model has
    stored this in an attribute called `class_prior_`:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'This outputs the following:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Naturally, since delays caused by the carrier only occur 6% of the time, there
    is a marginal probability of this occurring.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: 'Then the formula has a product ![](img/B18406_03_037.png) of conditional probabilities
    that each feature belongs to a class ![](img/B18406_03_038.png). Since this is
    binary there’s no need to calculate the probabilities of multiple classes because
    they are inversely proportional. Therefore, we can drop *C*[k] and replace it
    with a 1 like this:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_039.png)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
- en: 'This is because what we are trying to predict is the probability of a delay.
    Also, ![](img/B18406_03_040.png) is its own formula, which differs according to
    the assumed distribution of the model – in this case, Gaussian:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_041.png)'
  id: totrans-366
  prefs: []
  type: TYPE_IMG
- en: This formula is called the probability density of the Gaussian distribution.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation and feature importance
  id: totrans-368
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'So what are these **sigmas** (![](img/B18406_03_042.png)) and **thetas** (![](img/B18406_03_043.png))
    in the formula? They are, respectively, the variance and mean of the *x*[i] feature
    when ![](img/B18406_03_044.png). The concept behind this is that features have
    a different variance and mean in one class versus another, which can inform the
    classification. This is a binary classification task, but you could calculate
    ![](img/B18406_03_045.png)and ![](img/B18406_03_043.png) for both classes. Fortunately,
    the fitted model has this stored:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'There are two arrays output, the first one corresponding to the negative class
    and the second to the positive. The arrays contain the sigma (variance) for each
    of the 21 features given the class:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'You can also extract the thetas (means) from the model:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The preceding code also outputs two arrays, one for each class:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: These two arrays are all you need to debug and interpret Naïve Bayes results
    because you can use them to compute the conditional probability that the *x*[i]
    feature is given a positive class ![](img/B18406_03_047.png). You could use this
    probability to rank the features by importance on a global level, or interpret
    a specific prediction on a local level.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '*Naïve Bayes* is a fast algorithm with some good use cases, such as spam filtering
    and recommendation systems, but the independence assumption hinders its performance
    in most situations. Speaking of performance, let’s discuss this topic in the context
    of interpretability.'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing the trade-off between performance and interpretability
  id: totrans-379
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have briefly touched on this topic before, but high performance often requires
    complexity, and complexity inhibits interpretability. As studied in *Chapter 2*,
    *Key Concepts of Interpretability*, this complexity comes from primarily three
    sources: non-linearity, non-monotonicity, and interactivity. If the model adds
    any complexity, it is **compounded by the number and nature of features** in your
    dataset, which by itself is a source of complexity.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: Special model properties
  id: totrans-381
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These special properties can help make a model more interpretable.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: 'The key property: explainability'
  id: totrans-383
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In *Chapter 1*, *Interpretation, Interpretability, and Explainability; and Why
    Does It All Matter?*, we discussed why being able to look under the hood of the
    model and intuitively understand how all its moving parts derive its predictions
    in a consistent manner is, mostly, what separates *explainability* from *interpretability*.
    This property is also called **transparency** or **translucency**. A model can
    be interpretable without this, but in the same way as interpreting a person’s
    decisions because we can’t understand what is going on “under the hood.” This
    is often called **post-hoc interpretability** and this is the kind of interpretability
    this book primarily focuses on, with a few exceptions. That being said, we ought
    to recognize that if a model is understood by leveraging its mathematical formula
    (grounded in statistical and probability theory), as we’ve done with linear regression
    and Naïve Bayes, or by visualizing a human-interpretable structure, as with decision
    trees, or a set of rules as with RuleFit, it is much more interpretable than machine
    learning model classes where none of this is practically possible.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: White-box models will always have the upper hand in this regard, and as listed
    in *Chapter 1*, *Interpretation, Interpretability, and Explainability; and Why
    Does It All Matter?*, there are many use cases in which a white-box model is a
    must-have. But even if you don’t productionize white-box models, they can always
    serve a purpose in assisting with interpretation, if data dimensionality allows.
    Transparency is a key property because it wouldn’t matter if it didn’t comply
    with the other properties as long as it had explainability; it would still be
    more interpretable than those without it.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: 'The remedial property: regularization'
  id: totrans-386
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, we’ve learned that *regularization* limits the complexity added
    by the introduction of too many features, and this can make the model more interpretable,
    not to mention more performant. Some models incorporate regularization into the
    training algorithm, such as RuleFit and gradient-boosted trees; others have the
    ability to integrate it, such as multi-layer perceptron, or linear regression,
    and some cannot include it, such as k-NN. Regularization comes in many forms.
    Decision trees have a method called pruning, which can help reduce complexity
    by removing non-significant branches. Neural networks have a technique called
    dropout, which randomly drops neural network nodes from layers during training.
    Regularization is a remedial property because it can help even the least interpretable
    models lessen complexity and thus improve interpretability.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: Assessing performance
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By now, in this chapter, you have already assessed performance on all of the
    white-box models reviewed in the last section as well as a few black-box models.
    Maybe you’ve already noticed that black-box models have topped most metrics, and
    for most use cases, this is generally the case.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: Figuring out which model classes are more interpretable is not an exact science,
    but the following table (*Figure 3.17*) is sorted by those models with the most
    desirable properties – that is, they don’t introduce non-linearity, non-monotonicity,
    and interactivity. Of course, explainability on its own is a property that is
    a game-changer, regardless, and regularization can help. There are also cases
    in which it’s hard to assess properties. For instance, polynomial (linear) regression
    implements a linear model, but it fits non-linear relationships, which is why
    it is color-coded differently. As you will learn in *Chapter 12*, *Monotonic Constraints
    and Model Tuning for Interpretability*, some libraries support adding monotonic
    constraints to gradient-boosted trees and neural networks, which means it’s possible
    to make these monotonic. However, the black-box methods we used in this chapter
    do not support monotonic constraints.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: 'The task columns tell you whether they can be used for regression or classification.
    And the **Performance Rank** columns show you how well these models ranked in
    RMSE (for regression) and ROC AUC (for classification), where lower ranks are
    better. Please note that even though we have used only one metric to assess performance
    for this chart for simplicity’s sake, the discussion about performance should
    be more nuanced than that. Another thing to note is that ridge regression did
    poorly, but this is because we used the wrong hyperparameters, as explained in
    the previous section:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing chart  Description automatically generated](img/B18406_03_13.png)'
  id: totrans-392
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.13: A table assessing the interpretability and performance of several
    white-hat and black-box models we have explored in this chapter'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Because it’s compliant with all five properties, it’s easy to tell why **linear
    regression is the gold standard for interpretability**. Also, while recognizing
    that this is anecdotal evidence, it should be immediately apparent that most of
    the best ranks are with black-box models. This is no accident! The math behind
    neural networks and gradient-boosted trees is brutally efficient in achieving
    the best metrics. Still, as the red dots suggest, they have all the properties
    that make a model less interpretable, making their biggest strength (complexity)
    a potential weakness.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: 'This is precisely why black-box models are our primary interest in this book,
    although many of the methods you will learn to apply to white-box models. In *Part
    2*, which comprises *Chapters 4* to *9*, we will learn model-agnostic and deep-learning-specific
    methods that assist with interpretation. And in *Part 3*, which includes *Chapters
    10* to *14*, we will learn how to tune models and datasets to increase interpretability:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, funnel chart  Description automatically generated](img/B18406_03_14.png)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.14: A table comparing white-box, black-box, and glass-box models,
    or at least what is known so far about them'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: Discovering newer interpretable (glass-box) models
  id: totrans-398
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last decade, there have been significant efforts in both industry and
    in academia to create new models that can have enough complexity to find the sweet
    spot between underfitting and overfitting, known as the **bias-variance trade-off**,
    but retain an adequate level of explainability.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: Many models fit this description, but most of them are meant for specific use
    cases, haven’t been properly tested yet, or have released a library or open-sourced
    code. However, two general-purpose ones are already gaining traction, which we
    will look at now.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: Explainable Boosting Machine (EBM)
  id: totrans-401
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**EBM** is part of Microsoft’s InterpretML framework, which includes many of
    the model-agnostic methods we will use later in the book.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: 'EBM leverages the **GAMs** we mentioned earlier, which are like linear models
    but look like this:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_048.png)'
  id: totrans-404
  prefs: []
  type: TYPE_IMG
- en: 'Individual functions *f*[1] through *f*[p] are fitted to each feature using
    spline functions. Then a link function *g* adapts the GAM to perform different
    tasks such as classification or regression, or adjust predictions to different
    statistical distributions. GAMs are white-box models, so what makes EBM a glass-box
    model? It incorporates bagging and gradient boosting, which tend to make models
    more performant. The boosting is done one feature at a time using a low learning
    rate so as not to confound them. It also finds practical interaction terms automatically,
    which improves performance while maintaining interpretability:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_049.png)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
- en: Once fitted, this formula is made up of complicated non-linear formulas, so
    a global holistic interpretation isn’t likely feasible. However, since the effects
    of each feature or pairwise interaction terms are additive, they are easily separable,
    and global modular interpretation is entirely possible. Local interpretation is
    equally easy, given that a mathematical formula can assist in debugging any prediction.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: 'One drawback is that EBM can be much slower than gradient-boosted trees and
    neural networks because of the *one feature at a time* approach, a low learning
    rate not impacting the feature order, and spline fitting methods. However, it
    is parallelizable, so in environments with ample resources and multiple cores
    or machines, it will be much quicker. To avoid waiting for results for an hour
    or two, it is best to create abbreviated versions of `X_train` and `X_test` –
    that is, with fewer columns representing only the eight features white-box models
    found to be most important: `DEP_DELAY`, `LATE_AIRCRAFT_DELAY`, `PCT_ELAPSED_TIME`,
    `WEATHER_DELAY, NAS_DELAY`, `SECURITY_DELAY`, `DISTANCE`, `CRS_ELAPSED_TIME`,
    and `TAXI_OUT`. These are placed in a `feature_samp` array, and then the `X_train`
    and `X_test` DataFrames are subset to only include this feature. We are setting
    the `sample2_size` to 10%, but if you feel you have enough resources to handle
    it, adjust accordingly:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'To train your EBM, all you have to do is instantiate an `ExplainableBoostingClassifier()`
    and then fit your model to your training data. Note that we are using `sample_idx`
    to sample a portion of the data so that it takes less time:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Global interpretation
  id: totrans-412
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Global interpretation is dead simple. It comes with an `explain_global` dashboard
    you can explore. It loads with the feature importance plot first, and you can
    select individual features to graph what was learned from each one:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The preceding code generates a dashboard that looks like *Figure 3.15*:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, bar chart  Description automatically generated](img/B18406_03_15.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.15: EBM’s global interpretation dashboard'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: Local interpretation
  id: totrans-418
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Local interpretation uses a dashboard like global does, except you choose specific
    predictions to interpret with `explain_local`. In this case, we are selecting
    #76, which, as you can tell, was incorrectly predicted. But the LIME-like plot
    we will study in *Chapter 5*, *Local Model-Agnostic Interpretation Methods*, helps
    us make sense of it:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Similar to the global dashboard, the preceding code generates another one,
    depicted in *Figure 3.16*:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, bar chart  Description automatically generated](img/B18406_03_16.png)'
  id: totrans-422
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.16: EBM’s local interpretation dashboard'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  id: totrans-424
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: EBM performance, at least measured with the ROC AUC, is not far from what was
    achieved by the top two classification models, and we can only expect it to get
    better with 10 times more training and testing data!
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: You can appreciate the performance dashboard produced by the preceding code
    in *Figure 3.17*.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, line chart  Description automatically generated](img/B18406_03_17.png)'
  id: totrans-428
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.17: One of EBM’s performance dashboards'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: The performance dashboard can also compare several models at a time since its
    explainers are model-agnostic. And there’s even a fourth dashboard that can be
    used for data exploration. Next, we will cover another GAM-based model.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: GAMI-Net
  id: totrans-431
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There’s also a newer GAM-based method with similar properties to EBM but trained
    with neural networks. At the time of writing, this method has yet to get commercial
    traction but yields good interpretability and performance.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: As we have previously discussed, interpretability is decreased by each additional
    feature, especially those that don’t significantly impact model performance. In
    addition to too many features, it’s also trumped by the added complexity of non-linearities,
    non-monotonicity, and interactions. GAMI-Net tackles all these problems by fitting
    non-linear subnetworks for each feature in the main effects network first. Then,
    fitting a pairwise interaction network with subnetworks for each combination of
    features. The user provides a maximum number of interactions to keep, which are
    then fitted to the residuals of the main effects network. See *Figure 3.18* for
    a diagram.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_03_18.png)'
  id: totrans-434
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.18: Diagram of the GAMI-Net model'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: 'GAMI-Net has three interpretability constraints built in:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: '**Sparsity**: Only the top features and interactions are kept.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heredity**: A pairwise interaction can be included if at least one of its
    parent features is included.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Marginal clarity**: Non-orthogonality in interactions is penalized to approximate
    better marginal clarity.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The GAMI-Net implementation can also enforce monotonic constraints, which we
    will cover in more detail in *Chapter 12*, *Monotonic Constraints and Model Tuning
    for Interpretability*.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start, we must create a dictionary called `meta_info` with details
    about each feature and target, such as the type (continuous, categorical, and
    target) and the scaler used to scale each feature — since the library expects
    each feature to be scaled independently. All the features in the abbreviated dataset
    are continuous so we can leverage dictionary comprehension to this easily:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Next, we will create a copy of `X_train_abbrev` and `X_train_abbrev` and then
    scale them and store the scalers in the dictionary. Then, we will append information
    about the target variable to the dictionary. And lastly, we will convert all the
    data to `numpy` format:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Now that we have a `meta_info` dictionary and the dataset is ready, we can
    initialize and fit GAMI-Net to the training data. In addition to `meta_info`,
    it has a lot of parameters: `interact_num` defines how many top interactions it
    should consider, and `task_type` defines whether it’s a classification or regression
    task. Note that GAMI-Net trains three neural networks, so there are three epoch
    parameters to fill in (`main_effect_epochs`, `interaction_epochs`, and `tuning_epochs`).
    The learning rate (`lr_bp`) and early stopping thresholds (`early_stop_thres`)
    are entered as a list for each of the epoch parameters. You will also find lists
    for the architecture of the networks, where each item corresponds to a number
    of nodes per layer (`interact_arch` and `subnet_arch`). Furthermore, there are
    additional parameters for batch size, activation function, whether to enforce
    heredity constraint, a loss threshold for early stopping, and what percentage
    of the training data to use for validation (`val_ratio`). Finally, there are two
    optional parameters for monotonic constraints (`mono_increasing_list`, `mono_decreasing_list`):'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-446
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'We can plot the training loss for each epoch across all three trainings with
    `plot_trajectory`. Then, with `plot_regularization`, we can plot the outcome for
    the regularization of both the main effects and interaction networks. Both plotting
    functions can save the image in a folder but will do so in a folder called `results`
    by default, unless you change the path with the `folder` parameter:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '![Graphical user interface  Description automatically generated](img/B18406_03_19.png)Figure
    3.19: The trajectory and regularization plots for the GAMI-net training process'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.19* tells the story of how the three stages sequentially reduce loss
    while regularizing to only keep the fewest features and interactions as possible.'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: Global interpretation
  id: totrans-451
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Global explanations can be extracted in a dictionary with the `global_explain`
    function and then turned into a feature importance plot with `feature_importance_visualize`,
    like in the following snippet:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The preceding snippet outputs the following plot:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: '![Histogram  Description automatically generated with medium confidence](img/B18406_03_20.png)'
  id: totrans-455
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.20: A global explanation plot'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: As you can tell by *Figure 3.20*, the most important feature is, by far, `DEP_DELAY`
    and one interaction is among the top six features in the plot. We can also use
    the `global_visualize_density` plot to output partial dependence plots, which
    we will cover in *Chapter 4*, *Global Model-Agnostic Interpretation Methods*.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: Local interpretation
  id: totrans-458
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s examine an explanation for a single prediction using `local_explain`,
    followed by `local_visualize`. We are selecting test case #73:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The preceding code generates the plot in *Figure 3.21*:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application, Teams  Description automatically generated](img/B18406_03_21.png)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.21: A local explanation plot for test case #73'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.21* tells the story of how each feature weighs in the outcome. Note
    that `DEP_DELAY` is over 50 but that there’s an intercept that almost cancels
    it out. The intercept is a counterbalance – after all, the dataset is unbalanced
    toward it being less likely to be a `CARRIER_DELAY`. But all the subsequent features
    after the intercept are not enough to push the outcome positively.'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  id: totrans-465
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To determine the predictive performance of the GAMI-Net model, all we need
    to do is get the scores (`y_test_prob`) and predictions (`y_test_pred`) for the
    test dataset and then use scikit-learn’s `metrics` functions to compute them:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The preceding code yields the following metrics:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: The performance was not bad considering it was trained on 10% of the training
    data and evaluated on only 10% of the test data – especially the recall score,
    which was among the top three places.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: Mission accomplished
  id: totrans-471
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The mission was to train models that could predict preventable delays with enough
    accuracy to be useful, and then, to understand the factors that impacted these
    delays, according to these models, to improve OTP. The resulting regression models
    all predicted delays, on average, well below the 15-minute threshold according
    to the RMSE. And most of the classification models achieved an F1 score well above
    50% – one of them reached 98.8%! We also managed to find factors that impacted
    delays for all white-box models, some of which performed reasonably well. So,
    it seems like it was a resounding success!
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: Don’t celebrate just yet! Despite the high metrics, this mission was a failure.
    Through interpretation methods, we realized that the models were accurate mostly
    for the wrong reasons. This realization helps underpin the mission-critical lesson
    that a model can easily be right for the wrong reasons, so *the question “why?”
    is not a question to be asked only when it performs poorly but always*. And using
    interpretation methods is how we ask that question.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: But if the mission failed, why is this section called *Mission accomplished?*
    Good question!
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: 'It turns out there was a secret mission. Hint: it’s the title of this chapter.
    The point of it was to learn about common interpretation challenges through the
    failure of the overt mission. In case you missed them, here are the interpretation
    challenges we stumbled upon:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: Traditional model interpretation methods only cover surface-level questions
    about your models. Note that we had to resort to model-specific global interpretation
    methods to discover that the models were right for the wrong reasons.
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assumptions can derail any machine learning project since this is information
    that you suppose without evidence. Note that it is crucial to work closely with
    domain experts to inform decisions throughout the machine learning workflow, but
    sometimes they can also mislead you. Ensure you check for inconsistencies between
    the data and what you assume to be the truth about that data. Finding and correcting
    these problems is at the heart of what interpretability is about.
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many model classes, even white-box models, have issues with computing feature
    importance consistently and reliably.
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorrect model tuning can lead to a model that performs well enough but is
    less interpretable. Note that a regularized model overfits less but is also more
    interpretable. We will cover methods to address this challenge in *Chapter 12*,
    *Monotonic Constraints and Model Tuning for Interpretability*. Feature selection
    and engineering can also have the same effect, which you can read about in *Chapter
    10*, *Feature Selection and Engineering for Interpretability*.
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There’s a trade-off between predictive performance and interpretability. And
    this trade-off extends to execution speed. For these reasons, this book primarily
    focuses on black-box models, which have the predictive performance we want and
    a reasonable execution speed but could use some help on the interpretability side.
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you learned about these challenges, then congratulations! Mission accomplished!
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-482
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After reading this chapter, we covered some traditional methods for interpretability
    and what their limitations are. We learned about **intrinsically interpretable
    models** and how to both use them and interpret them, for both regression and
    classification. We also studied the **performance versus interpretability trade-off**
    and some models that attempt not to compromise in this trade-off. We also discovered
    many practical interpretation challenges involving the roles of feature selection
    and engineering, hyperparameters, domain experts, and execution speed.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn more about different interpretation methods
    to measure the effect of a feature on a model.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: Dataset sources
  id: totrans-485
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: United States Department of Transportation Bureau of Transportation Statistics.
    (2018). Airline On-Time Performance Data. Originally retrieved from [https://www.transtats.bts.gov](https://www.transtats.bts.gov).
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-487
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Friedman, J. and Popescu, B, 2008, *Predictive Learning via Rule Ensembles*.
    The Annals of Applied Statistics, 2(3), 916-954\. [http://doi.org/10.1214/07-AOAS148](http://doi.org/10.1214/07-AOAS148)
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hastie, T., Tibshirani, R., and Wainwright, M., 2015, *Statistical Learning
    with Sparsity: The Lasso and Generalizations*. Chapman & Hall/Crc Monographs on
    Statistics & Applied Probability, Taylor & Francis'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thomas, D.R., Hughes, E., and Zumbo, B.D., 1998, *On Variable Importance in
    Linear Regression.* Social Indicators Research 45, 253–275: [https://doi.org/10.1023/A:1006954016433](https://doi.org/10.1023/A:1006954016433)'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nori, H., Jenkins, S., Koch, P., and Caruana, R., 2019, *InterpretML: A Unified
    Framework for Machine Learning Interpretability*. arXiv preprint: [https://arxiv.org/pdf/1909.09223.pdf](https://arxiv.org/pdf/1909.09223.pdf)'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hastie, T., and Tibshirani, R., 1987, *Generalized Additive Models: Some Applications.*
    Journal of the American Statistical Association, 82(398):371–386: [http://doi.org/10.2307%2F2289439](http://doi.org/10.2307%2F2289439)'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn more on Discord
  id: totrans-493
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To join the Discord community for this book – where you can share feedback,
    ask the author questions, and learn about new releases – follow the QR code below:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/inml](Chapter_3.xhtml)'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code107161072033138125.png)'
  id: totrans-496
  prefs: []
  type: TYPE_IMG
