- en: 'Chapter 13: Governing the ML System for Continual Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 13 章：治理持续学习的机器学习系统
- en: In this chapter, we will reflect on the need for continual learning in **machine
    learning** (**ML**) solutions. Adaptation is at the core of machine intelligence.
    The better the adaptation, the better the system. Continual learning focuses on
    the external environment and adapts to it. Enabling continual learning for an
    ML system can reap great benefits. We will look at what is needed to successfully
    govern an ML system as we explore continuous learning and study the governance
    component of the Explainable Monitoring Framework, which helps us control and
    govern ML systems to achieve maximum value.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将反思机器学习（**ML**）解决方案中持续学习的必要性。适应是机器智能的核心。适应得越好，系统就越好。持续学习专注于外部环境并适应它。为机器学习系统启用持续学习可以带来巨大的好处。我们将探讨在探索持续学习和研究可解释监控框架的治理组件时，成功治理机器学习系统所需的内容，该框架帮助我们控制和治理机器学习系统以实现最大价值。
- en: We will delve into the hands-on implementation of governance by enabling alert
    and action features. Next, we will look into ways of assuring quality for models
    and controlling deployments, and we'll learn the best practices to generate model
    audits and reports. Lastly, we will learn about methods to enable model retraining
    and maintain CI/CD pipelines.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将深入探讨通过启用警报和操作功能来实现治理的实战实施。接下来，我们将探讨确保模型质量和控制部署的方法，以及我们将学习生成模型审计和报告的最佳实践。最后，我们将了解使模型重新训练和维护
    CI/CD 管道的方法。
- en: 'Let''s start by reflecting on the need for continual learning and go on to
    explore the following topics in the chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先反思一下持续学习的必要性，然后继续探讨本章中的以下主题：
- en: Understanding the need for continual learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解持续学习的必要性
- en: Governing an ML system using Explainable Monitoring
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用可解释监控来治理机器学习系统
- en: Enabling model retraining
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用模型重新训练
- en: Maintaining the CI/CD pipeline
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护 CI/CD 管道
- en: Understanding the need for continual learning
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解持续学习的必要性
- en: When we got started in [*Chapter 1*](B16572_01_Final_JM_ePub.xhtml#_idTextAnchor015),
    *Fundamentals of MLOps Workflow*, we learned about the reasons AI adoption is
    stunted in organizations. One of the reasons was the lack of continual learning
    in ML systems. Yes, continual learning! We will address this challenge in this
    chapter and make sure we learn how to enable this capability by the end of this
    chapter. Now, let's look into continual learning.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在[*第 1 章*](B16572_01_Final_JM_ePub.xhtml#_idTextAnchor015)，“MLOps 工作流程基础”中开始时，我们了解到为什么人工智能在组织中的采用受到阻碍。其中一个原因是机器学习系统中缺乏持续学习。是的，持续学习！我们将在本章中解决这个挑战，并确保我们能够在本章结束时学会如何启用这种功能。现在，让我们来看看持续学习。
- en: Continual learning
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持续学习
- en: 'Continual learning is built on the principle of continuously learning from
    data, human experts, and the external environment. Continual learning enables
    lifelong learning, with adaptation at its core. It enables ML systems to become
    intelligent over time to adapt to the task at hand. It does this by monitoring
    and learning from the environment and the human experts assisting the ML system.
    Continual learning can be a powerful add-on to an ML system. It can allow you
    to realize the maximum potential of an AI system over time. Continual learning
    is highly recommended. Let''s have a look at an example:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 持续学习建立在持续从数据、人类专家和外部环境中学习的原则之上。持续学习使终身学习成为可能，其核心是适应。它使机器学习系统能够随着时间的推移变得智能，以适应手头的任务。它是通过监控和学习环境和协助机器学习系统的人类专家来做到这一点的。持续学习可以是一个强大的机器学习系统附加功能。它可以让你随着时间的推移实现人工智能系统的最大潜力。持续学习非常值得推荐。让我们来看一个例子：
- en: '![Figure 13.1 – A loan issuing officer – a traditional system versus an ML
    system assisted by a human'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.1 – 贷款发放官员 – 传统系统与由人类辅助的机器学习系统'
- en: '](img/B16572_13_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16572_13_01.jpg](img/B16572_13_01.jpg)'
- en: Figure 13.1 – A loan issuing scenario – a traditional system versus an ML system
    assisted by a human
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.1 – 贷款发放场景 – 传统系统与由人类辅助的机器学习系统
- en: There are several advantages to deploying a model (enabled by continual learning)
    compared to having a traditional process in an organization that is fully dependent
    on human employees. For example, in the preceding diagram, we can see the steps
    of a bank's loan approval process in two cases. The first scenario is driven by
    human experts (such as in a traditional bank setup) only. The second scenario
    is where the process is automated or augmented using an ML system to screen applications,
    negotiate, provide loan application finalization (where a human expert reviews
    the ML system's decision and approves or rejects it), and approve the loan. The
    processing time of the traditional setup is 1 week, while the processing time
    of the ML system (working together with human experts) is 6 hours.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 与组织中的传统流程（完全依赖人类员工）相比，部署一个模型（由持续学习驱动）具有几个优势。例如，在前面的图表中，我们可以看到银行贷款审批流程的两个案例。第一种场景是由人类专家（例如在传统银行设置中）驱动的。第二种场景是使用机器学习系统自动化或增强流程，以筛选申请、谈判、提供贷款申请最终审批（在此过程中，人类专家审查机器学习系统的决策并批准或拒绝它），以及批准贷款。传统设置的审批时间为一周，而机器学习系统（与人类专家合作）的审批时间为6小时。
- en: The ML system is faster and more sustainable for the bank as it is continually
    learning and improving with a human assistant's help. Human employees have a fixed
    term of employment in a company or job. When they leave, their domain expertise
    is gone, and training a new employee or onboarding a new employee for the same
    task is costly. On the other hand, an ML model working together with or assisted
    by human experts that learns continually as time progresses manages to learn with
    time and retains that knowledge indefinitely (with regards to time). The continual
    learning that's acquired by the ML system (together with human experts) can be
    retained forever by the bank compared to the traditional approach, where human
    employees are constantly changing. Continual learning can unleash great value
    for an ML system and for the business in the long run.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器学习系统在人类助理的帮助下持续学习和改进，因此它对银行来说更快且更具可持续性。人类员工在公司或工作中有固定的雇佣期限。当他们离开时，他们的领域专业知识也随之消失，培训新员工或为同一任务招聘新员工是昂贵的。另一方面，随着时间推移，与人类专家合作或由人类专家辅助的机器学习模型能够随着时间的推移不断学习并保留知识（就时间而言）。与传统的、人类员工不断变化的方法相比，机器学习系统（与人类专家一起）获得的持续学习可以永久保留。从长远来看，持续学习可以为机器学习系统和业务释放巨大价值。
- en: The need for continual learning
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持续学习的需求
- en: 'The following diagram shows some of the reasons why continual learning is needed
    and how it will enhance your ML system to maximize your business value:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了为什么需要持续学习以及它如何增强您的机器学习系统以最大化您的商业价值：
- en: '![Figure 13.2 – Benefits of continual learning'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.2 – 持续学习的益处'
- en: '](img/B16572_13_02.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.2 – 持续学习的益处](img/B16572_13_02.jpg)'
- en: Figure 13.2 – Benefits of continual learning
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2 – 持续学习的益处
- en: 'Let''s go through the benefits of continual learning in detail:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细探讨持续学习的益处：
- en: '**Adaptation**: In most straightforward applications, data drift might stay
    the same as data keeps coming in. However, many applications have dynamically
    changed data drifts, such as recommendation or anomaly detection systems, where
    data keeps flowing. In these cases, continually learning is important for adapting
    and being accurate with predictions. Hence, adapting to the changing nature of
    data and the environment is important.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适应性**：在大多数直接应用中，数据漂移可能随着数据的持续流入而保持不变。然而，许多应用具有动态变化的数据漂移，例如推荐系统或异常检测系统，其中数据持续流动。在这些情况下，持续学习对于适应和准确预测至关重要。因此，适应数据和环境的不断变化性质是很重要的。'
- en: '**Scalability**: A white paper published by IDC ([https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-dataage-whitepaper.pdf](https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-dataage-whitepaper.pdf))
    suggests that by 2025, the rate of data generation will grow to 160 ZB/year, and
    that we will not be able to store all of it. The paper predicts that we will only
    be able to store between 3% and 12%. Data needs to be processed on the fly; otherwise,
    it will be lost since the storage infrastructure cannot keep up with the data
    that is produced. The main trick here is to process incoming data once, store
    only the essential information, and then get rid of the rest.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：由IDC发布的白皮书（[https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-dataage-whitepaper.pdf](https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-dataage-whitepaper.pdf)）指出，到2025年，数据生成的速度将增长到每年160
    ZB，我们将无法存储所有这些数据。该论文预测，我们只能存储3%到12%的数据。数据需要即时处理；否则，由于存储基础设施无法跟上产生的数据，数据将会丢失。这里的诀窍是只处理一次传入的数据，只存储必要的信息，然后丢弃其余部分。'
- en: '**Relevance**: Predictions from ML systems need to be relevant and need to
    adapt to changing contexts. Continual learning is needed to keep the ML systems
    highly relevant to and valuable in the changing contexts and environments.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相关性**：ML系统的预测需要具有相关性并适应不断变化的环境。持续学习是保持ML系统在变化的环境和环境中高度相关和有价值的必要条件。'
- en: '**Performance**: Continual learning will enable high performance for the ML
    system, since it powers the ML system to be relevant by adapting to the changing
    data and environment. In other words, being more relevant will improve the performance
    of the ML system, for example, in terms of accuracy or other metrics, by providing
    more meaningful or valuable predictions.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**：持续学习将使ML系统具有高性能，因为它通过适应不断变化的数据和环境来使ML系统保持相关性。换句话说，更具相关性将提高ML系统的性能，例如，在准确性或其他指标方面，通过提供更有意义或更有价值的预测。'
- en: 'For these reasons, continual learning is needed in an ML system, so without
    continual learning, we cannot reach the maximum value an ML system has to offer.
    In other words, projects are doomed to fail. Continual learning is the key to
    succeeding in AI projects. An efficient governance strategy as part of Explainable
    Monitoring can enable continual learning. An important part of continual learning
    is model retraining, so that we can cope with evolving data and make relevant
    decisions. To do this, we can fuse Explainable Monitoring and model retraining
    to enable continual learning:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些原因，在ML系统中需要持续学习，否则我们无法达到ML系统所能提供的最大价值。换句话说，项目注定会失败。持续学习是AI项目成功的关键。作为可解释监控的一部分，有效的治理策略可以促进持续学习。持续学习的一个重要部分是模型重新训练，这样我们才能应对不断变化的数据并做出相关决策。为此，我们可以将可解释监控和模型重新训练结合起来，以实现持续学习：
- en: '**Explainable Monitoring + Model Retraining = Continual Learning**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**可解释监控 + 模型重新训练 = 持续学习**'
- en: Going ahead we will see continual learning in depth. Now, let's explore how
    we can bring efficient governance to ML systems.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入探讨持续学习的应用。现在，让我们探讨如何将有效的管理制度引入ML系统。
- en: Explainable monitoring – governance
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释的监控 – 管理制度
- en: 'In this section, we will implement the governance mechanisms that we learned
    about previously in [*Chapter 11*](B16572_11_Final_JM_ePub.xhtml#_idTextAnchor206),
    *Key Principles of Monitoring Your ML System*, for the business use case we have
    been working on. We will delve into three of the components of governing an ML
    system, as shown in the following diagram:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现我们在[*第11章*](B16572_11_Final_JM_ePub.xhtml#_idTextAnchor206)“监控您的ML系统的关键原则”中学习到的治理机制，应用于我们一直在工作的业务案例。我们将深入研究管理ML系统的三个组成部分，如下面的图所示：
- en: '![Figure 13.3 – Components of governing your ML system'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.3 – 管理您的ML系统的组件'
- en: '](img/B16572_13_03.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_13_03.jpg)'
- en: Figure 13.3 – Components of governing your ML system
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3 – 管理您的ML系统的组件
- en: The effectiveness of ML systems results from how they are governed to maximize
    business value. To have end-to-end trackability and comply with legislation, system
    governance requires quality assurance and monitoring, model auditing, and reporting.
    We can regulate and rule ML systems by monitoring and analyzing model outputs.
    Smart warnings and behavior guide governance to optimize business value. Let's
    look at how the ML system's governance is orchestrated by warnings and behavior,
    model quality assurance and control, model auditing, and reports.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统的有效性取决于它们如何被管理以最大化商业价值。为了实现端到端的可追踪性和符合法规，系统治理需要质量保证和监控、模型审计和报告。我们可以通过监控和分析模型输出来规范和规则机器学习系统。智能警告和行为指导治理以优化商业价值。让我们看看机器学习系统的治理是如何通过警告和行为、模型质量保证和控制、模型审计和报告来编排的。
- en: Alerts and actions
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 警报和操作
- en: Alerts are generated by performing scheduled checks to detect conditions. Upon
    meeting a condition, an alert is generated. Based on the alert that's generated,
    we can perform actions. In this section, we will learn about these elements and
    how they are orchestrated to govern an ML system.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 警报是通过执行计划检查来检测条件生成的。一旦满足条件，就会生成警报。基于生成的警报，我们可以执行操作。在本节中，我们将了解这些元素以及它们是如何编排来管理机器学习系统的。
- en: What is an alert?
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是警报？
- en: 'An alert is a scheduled task running in the background to monitor an application
    to check if specific conditions are being detected. An alert is driven by three
    things:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 警报是一个在后台运行的计划任务，用于监控应用程序以检查是否检测到特定条件。警报由以下三个因素驱动：
- en: '**Schedule**: How often should we check for conditions?'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计划**：我们应该多久检查一次条件？'
- en: '**Conditions**: What needs to be detected?'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**条件**：需要检测什么？'
- en: '**Actions**: What should we do when a condition is detected?'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操作**：当检测到条件时，我们应该做什么？'
- en: 'We can create alerts based on application performance to monitor aspects such
    as the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据应用程序性能创建警报来监控以下方面：
- en: Alerts for availability based on a threshold
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于阈值的可用性警报
- en: Alerts for failed requests based on a threshold
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于阈值的失败请求警报
- en: Alerts for server response time based on a threshold
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于阈值的响应时间警报
- en: Alerts for server exceptions based on a threshold
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于阈值的服务器异常警报
- en: Alerts based on a threshold for data drift
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于数据漂移阈值的警报
- en: Alerts based on a threshold for model drift
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于模型漂移阈值的警报
- en: Alerts based on errors or exceptions
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于错误或异常的警报
- en: An important area of governing ML systems is dealing with errors, so let's turn
    our attention to error handling.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 管理机器学习系统的一个重要领域是处理错误，因此让我们将注意力转向错误处理。
- en: Dealing with errors
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理错误
- en: 'Potential errors are always possible in an application. We can foresee them
    by addressing all the possible edge cases for our ML application. Using the framework
    shown in the following diagram, we can address these errors. The purpose of this
    framework is to identify edge cases and automated debugging methods to tackle
    possible errors. This will keep the ML service up and running:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序中，潜在的错误总是可能的。我们可以通过解决我们机器学习应用程序的所有可能的边缘情况来预见它们。使用以下图表中显示的框架，我们可以解决这些错误。这个框架的目的是识别边缘情况和自动调试方法来处理可能的错误。这将使机器学习服务保持运行：
- en: '![Figure 13.4 – Framework for debugging and investigating errors'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.4 – 调试和调查错误的框架'
- en: '](img/B16572_13_04.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_13_04.jpg)'
- en: Figure 13.4 – Framework for debugging and investigating errors
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.4 – 调试和调查错误的框架
- en: As shown in the preceding diagram, we started by identifying resources where
    errors might be present and choosing a resource to address that error. Upon choosing
    a resource, we check for errors by checking for high utilization of resources
    and resource saturation (a resource is saturated when its capacity is fully utilized
    or its capacity is past a set threshold). In the case of either issue, we investigate
    the discovery by investigating logs and devising a solution to handle any errors.
    Eventually, we automate debugging by using premade scripts to handle any issues
    (blocking the system from functioning optimally), for example, by restarting the
    resource or reloading a function or file to get the resource up and running in
    a healthy state.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，我们首先识别可能存在错误的地方，并选择一个资源来处理该错误。选择资源后，我们通过检查资源的高利用率以及资源饱和度（资源饱和是指其容量已完全利用或超过设定的阈值）来检查错误。在出现任何问题的情况下，我们通过检查日志和制定解决方案来处理任何错误。最终，我们通过使用预先编写的脚本来处理任何问题（例如，通过重启资源或重新加载一个函数或文件，以使资源在健康状态下运行）来自动化调试。
- en: By addressing all the possible edge cases and devising automated error handling
    or debugging, we can make our applications failure-proof to serve our users. Having
    a failure-proof application enables robustness, making sure the users have a seamless
    experience and value from using the ML application. Once you have identified an
    error, address it by investigating or creating an automated debugging process
    and solving the error. After all, prevention is better than a cure. Hence, checking
    for all possible edge cases and addressing them beforehand can be rewarding.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解决所有可能的边缘情况并制定自动错误处理或调试，我们可以使我们的应用程序无故障，以服务于我们的用户。拥有无故障的应用程序可以确保用户在使用机器学习应用程序时获得无缝的体验和价值。一旦你识别出错误，通过调查或创建自动调试过程来解决它。毕竟，预防胜于治疗。因此，检查所有可能的边缘情况并在事先解决它们是有益的。
- en: 'We can handle potential errors by using exception handling functionalities.
    Exception handling is a programming technique that is used for dealing with rare
    situations that necessitate special care. Exception handling for a wide range
    of error types is easy to implement in Python. We can use the `try`, `except`,
    `else`, and `finally` functionalities to handle errors and exceptions, as shown
    in the following diagram:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用异常处理功能来处理潜在的错误。异常处理是一种编程技术，用于处理需要特殊关注的情况。在 Python 中，实现广泛的错误类型的异常处理很容易。我们可以使用
    `try`、`except`、`else` 和 `finally` 功能来处理错误和异常，如下图所示：
- en: '![Figure 13.5 – Handling exceptions and edge cases'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.5 – 处理异常和边缘情况'
- en: '](img/B16572_13_05.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16572_13_05.jpg)'
- en: Figure 13.5 – Handling exceptions and edge cases
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5 – 处理异常和边缘情况
- en: All the statements are executed before an exception is encountered in the `try`
    clause. The exception(s) that are found in the `try` clause are caught and treated
    with the `except` block. The `else` block allows you to write parts that can only
    run if there are no exceptions in the `try` clause. Using `finally`, with or without
    any previously experienced exceptions, you can run parts of code that should always
    run.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `try` 子句中遇到异常之前，所有语句都会被执行。在 `try` 子句中找到的异常会被 `except` 块捕获和处理。`else` 块允许你编写只有在
    `try` 子句中没有异常时才能运行的代码。使用 `finally`，无论之前是否遇到过异常，都可以运行应该始终运行的代码部分。
- en: 'Here is a list of some possible common exceptions or errors to look out for:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了一些可能常见的异常或错误，需要注意：
- en: '![](img/012.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/012.jpg)'
- en: These edge cases or errors are common and can be addressed in the application
    by using `try` and `exception` techniques. The strategy is to mitigate situations
    where your ML system will look very basic or naive for the user; for example,
    a chatbot that sends error messages in the chats. In such cases, the cost of errors
    is high, and the users will lose trust in the ML system.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这些边缘情况或错误很常见，可以通过在应用程序中使用 `try` 和 `exception` 技术来解决。策略是减轻用户可能会觉得你的机器学习系统非常基础或天真的情况；例如，一个在聊天中发送错误信息的聊天机器人。在这种情况下，错误的代价很高，用户可能会失去对机器学习系统的信任。
- en: 'We will implement some custom exception and error handling for the business
    use case we have been implementing and implement actions based on the alerts that
    are generated. Let''s get started:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为我们一直在实施的业务用例实现一些自定义异常和错误处理，并根据生成的警报执行操作。让我们开始吧：
- en: 'In your Azure DevOps project, go to our `13_Govenance_Continual_Learning`.
    From there, access the `score.py` file. We will begin by importing the required
    libraries. This time, we will use the `applicationinsights` library to track custom
    events or exceptions of Application Insights that are connected to the endpoint:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的 Azure DevOps 项目中，前往我们的 `13_Govenance_Continual_Learning`。从那里，访问 `score.py`
    文件。我们将首先导入所需的库。这次，我们将使用 `applicationinsights` 库来跟踪与端点连接的 Application Insights
    的自定义事件或异常：
- en: '[PRE0]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As shown in the preceding code, we have imported the `TelemetryClient` function
    from the `applicationinsights` library. We will use the `TelemetryClient` function
    to access the Application Insights that are connected to our endpoint. Provide
    your instrumentation key from Application Insights to the `TelemetryClient` function.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如前述代码所示，我们已经从 `applicationinsights` 库中导入了 `TelemetryClient` 函数。我们将使用 `TelemetryClient`
    函数来访问连接到我们端点的 Application Insights。将 Application Insights 的仪表化密钥提供给 `TelemetryClient`
    函数。
- en: This **Instrumentation Key** can be accessed from your Application Insights,
    which should be connected to the ML application, as shown in the following screenshot:![Figure
    13.6 – Fetching an instrumentation key from Application Insights
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此 **Instrumentation Key** 可从您的 Application Insights 访问，它应连接到机器学习应用程序，如下面的截图所示：![图
    13.6 – 从 Application Insights 获取仪表化密钥
- en: '](img/B16572_13_06.jpg)'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16572_13_06.jpg)'
- en: Figure 13.6 – Fetching an instrumentation key from Application Insights
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.6 – 从 Application Insights 获取仪表化密钥
- en: 'After fetching your `TelemetryClient` function, as shown in the following code.
    Here, we create a `TelemetryClient` object in the `tc` variable, which is used
    to track custom events:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在获取您的 `TelemetryClient` 函数后，如下述代码所示。在这里，我们在 `tc` 变量中创建了一个 `TelemetryClient`
    对象，用于跟踪自定义事件：
- en: '[PRE1]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Likewise, we will implement some other custom events – that is, `ValueNotFound`,
    `OutofBoundsException`, and `InferenceError` – in the `run` function:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，我们将在 `run` 函数中实现一些其他自定义事件 – 即，`ValueNotFound`、`OutofBoundsException` 和 `InferenceError`
    –：
- en: '[PRE2]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'try:'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'try:'
- en: '# scale incoming data'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '# 缩放传入数据'
- en: data = scaler.transform(data)
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: data = scaler.transform(data)
- en: 'except Exception as e:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'except Exception as e:'
- en: 'try and except can be handy in this case, since we are trying to scale the
    data using a scaler file that''s been loaded in the init function. If scaling
    the data is not successful, then an exception is raised. Here, we use the `track_event`
    function to track the exception on Application Insights. We generate a custom
    event named `ScalingError` in case an exception is generated. An exception message
    and an error code of `301` is logged on Application Insights. Likewise, the most
    important step of dealing with the scoring file – inferencing the model – needs
    to be done meticulously. Now, we will use `try` and `except` again to make sure
    the inference is successful without any exceptions. Let''s see how we can handle
    exceptions in this case. Note that we are accessing element number `2` for the
    `model.run` function. This causes an error in the model''s inference as we are
    referring to an incorrect or nonexistent element of the list:'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在此情况下，`try` 和 `except` 可能很有用，因为我们正在尝试使用在 `init` 函数中加载的缩放器文件来缩放数据。如果缩放数据不成功，则会引发异常。在这里，我们使用
    `track_event` 函数在 Application Insights 上跟踪异常。如果生成异常，我们将生成一个名为 `ScalingError` 的自定义事件。在
    Application Insights 上记录一个异常消息和错误代码 `301`。同样，处理评分文件的最重要步骤 – 模型推理 – 需要细致入微地进行。现在，我们将再次使用
    `try` 和 `except` 来确保推理成功且没有任何异常。让我们看看我们如何处理这种情况下的异常。请注意，我们正在访问 `model.run` 函数的元素编号
    `2`。这导致模型推理时出现错误，因为我们正在引用列表中的错误或不存在的元素：
- en: '[PRE3]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now, let's look at how to investigate these errors in Application Insights using
    the error logs and generate actions for it.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何使用错误日志在 Application Insights 中调查这些错误并为其生成操作。
- en: Setting up actions
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置操作
- en: We can set up alerts and actions based on the exception events that we created
    previously (in the *Dealing with errors* section). In this section, we will set
    up an action in the form of an email notification based on an alert that we've
    generated. Whenever an exception or alert is generated in Application Insights,
    we will be notified via an email. Then, we can investigate and solve it.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据之前创建的异常事件（在 *处理错误* 部分中）设置警报和操作。在本节中，我们将根据我们生成的警报设置一个电子邮件通知形式的操作。每当在 Application
    Insights 中生成异常或警报时，我们都会通过电子邮件收到通知。然后，我们可以进行调查并解决它。
- en: 'Let''s set up an action (email) upon receiving an alert by going to Application
    Insights, which should be connected to your ML system endpoint. You can access
    Application Insights via your Azure ML workspace. Let''s get started:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 通过访问应用洞察（Application Insights），我们可以设置一个动作（电子邮件）来接收警报，该应用洞察应连接到您的机器学习系统端点。您可以通过Azure
    ML工作区访问应用洞察。让我们开始吧：
- en: Go to `Endpoints` and check for Application Insights. Once you've accessed the
    Application Insights dashboard, click on `Transaction search`, as shown in the
    following screenshot, to check for your custom event logs (for example, inference
    exception):![Figure 13.7 – Checking the custom event logs
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往`端点`并检查应用洞察。一旦您访问了应用洞察仪表板，点击`事务搜索`，如下面的截图所示，以检查您的自定义事件日志（例如，推理异常）：![图13.7
    – 检查自定义事件日志
- en: '](img/B16572_13_07.jpg)'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.7 – 检查自定义事件日志](img/B16572_13_07.jpg)'
- en: Figure 13.7 – Checking the custom event logs
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.7 – 检查自定义事件日志
- en: You can check for custom events that have been generated upon exceptions and
    errors occurs via the logs, and then set up alerts and actions for these custom
    events. To set up an alert and action, go to the **Monitoring** > **Alerts** section
    and click on **New alert rule**, as shown in the following screenshot:![Figure
    13.8 – Setting up a new alert rule
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过日志检查在异常和错误发生时生成的自定义事件，然后为这些自定义事件设置警报和动作。要设置警报和动作，请转到**监控** > **警报**部分并点击**新建警报规则**，如下面的截图所示：![图13.8
    – 设置新的警报规则
- en: '](img/B16572_13_08.jpg)'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.8 – 设置新的警报规则](img/B16572_13_08.jpg)'
- en: Figure 13.8 – Setting up a new alert rule
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.8 – 设置新的警报规则
- en: Here, you can create conditions for actions based on alerting. To set up a condition,
    click on **Add condition**. You will be presented with a list of signals or log
    events you can use to make conditions. Select **InferenceError**, as shown in
    the following screenshot:![Figure 13.9 – Configuring a condition
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，您可以根据警报创建动作的条件。要设置条件，请点击**添加条件**。您将看到一个可以用来创建条件的信号或日志事件的列表。选择**InferenceError**，如下面的截图所示：![图13.9
    – 配置条件
- en: '](img/B16572_13_09.jpg)'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.10 – 配置条件逻辑和阈值](img/B16572_13_09.jpg)'
- en: Figure 13.9 – Configuring a condition
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.9 – 配置条件
- en: After selecting the signal or event of your choice, you will get to configure
    its condition logic, as shown in the following screenshot. Configure the condition
    by setting up a threshold for it. In this case, we will provide a threshold of
    `400` as the error raises a value of `401` (since we had provided a custom value
    of `401` for the `InferenceError` event). When an inference exception occurs,
    it raises an `InferenceError` with a value above `400` (`401`, to be precise):![Figure
    13.10 – Configuring the condition logic and threshold
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您选择的信号或事件后，您将可以配置其条件逻辑，如下面的截图所示。通过设置一个阈值来配置条件。在这种情况下，我们将提供一个阈值为`400`，因为错误会引发一个值为`401`（因为我们为`InferenceError`事件提供了一个自定义的值为`401`）。当发生推理异常时，它会引发一个值高于`400`的`InferenceError`（确切地说是`401`）：![图13.10
    – 配置条件逻辑和阈值
- en: '](img/B16572_13_010.jpg)'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.11 – 自动化调试的动作（可选）](img/B16572_13_010.jpg)'
- en: Figure 13.10 – Configuring the condition logic and threshold
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.10 – 配置条件逻辑和阈值
- en: After setting up the threshold, you will be asked to configure other actions,
    such as running an **Automation Runbook**, **Azure Function**, **Logic App,**
    or **Secure Webhook**, as shown in the following screenshot. For now, we will
    not prompt these actions, but it is good to know that we have them since we can
    run some scripts or applications as a backup mechanism to automate error debugging:![Figure
    13.11 – Actions to automate debugging (optional)
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置阈值后，您将需要配置其他动作，例如运行**自动化运行手册**、**Azure Function**、**逻辑应用**或**安全Webhook**，如下面的截图所示。目前，我们不会提示这些动作，但了解我们有这些动作是好的，因为我们可以运行一些脚本或应用程序作为备份机制来自动化错误调试：![图13.11
    – 自动化调试的动作（可选）
- en: '](img/B16572_13_011.jpg)'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.8 – 设置新的警报规则](img/B16572_13_011.jpg)'
- en: Figure 13.11 – Actions to automate debugging (optional)
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.11 – 自动化调试的动作（可选）
- en: This way, we can automate debugging by having pre-configured scripts or applications
    set up in case an error occurs or to prevent errors. Prevention is better than
    a cure, after all!
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这样，我们就可以通过预先配置的脚本或应用程序来自动化调试，以防发生错误或防止错误。毕竟，预防胜于治疗！
- en: Finally, we will create a condition. Click **Review and create** to create the
    condition, as shown in the preceding screenshot. Once you have created this condition,
    you will see it in the **Create alert rule** panel, as shown in the following
    screenshot. Next, set up an action by clicking on **Add action groups** and then
    **Create action group**:![Figure 13.12 – Creating an action group
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将创建一个条件。点击**审查和创建**以创建条件，如前面的截图所示。一旦创建了此条件，您将在**创建警报规则**面板中看到它，如下面的截图所示。接下来，通过点击**添加动作组**然后**创建动作组**来设置一个动作：![图13.12
    – 创建动作组
- en: '](img/B16572_13_012.jpg)'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B16572_13_012.jpg](img/B16572_13_012.jpg)'
- en: Figure 13.12 – Creating an action group
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.12 – 创建动作组
- en: Provide an email address so that you can receive notifications, as shown in
    the following screenshot. Here, you can name your notification (in the **Alert
    rule name** field) and provide the necessary information to set up an email alert
    action:![Figure 13.13 – Configuring email notifications
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供一个电子邮件地址，以便您可以接收通知，如下面的截图所示。在这里，您可以在**警报规则名称**字段中命名您的通知，并提供设置电子邮件警报动作所需的信息：![图13.13
    – 配置电子邮件通知
- en: '](img/B16572_13_013.jpg)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B16572_13_013.jpg](img/B16572_13_013.jpg)'
- en: Figure 13.13 – Configuring email notifications
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.13 – 配置电子邮件通知
- en: 'After providing all the necessary information, including an email, click on
    the **Review + Create** button to configure the action (an email based on an error).
    Finally, provide alert rule details such as **Alert rule name**, **Description**,
    and **Severity**, as shown in the following screenshot:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在提供所有必要信息，包括电子邮件后，点击**审查 + 创建**按钮来配置动作（基于错误的电子邮件）。最后，提供如**警报规则名称**、**描述**和**严重性**之类的警报规则详细信息，如下面的截图所示：
- en: '![Figure 13.14 – Configuring email notifications'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图13.14 – 配置电子邮件通知'
- en: '](img/B16572_13_014.jpg)'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B16572_13_014.jpg](img/B16572_13_014.jpg)'
- en: Figure 13.14 – Configuring email notifications
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.14 – 配置电子邮件通知
- en: 'Click on `InferenceError`). With that, you have created an alert, so now it''s
    time to test it. Go to the `13_Govenance_Continual_Learning` folder and access
    the `test_inference.py` script (replace the URL with your endpoint link). Then,
    run the script by running the following command:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`InferenceError`)。有了这个，您已经创建了一个警报，现在是时候测试它了。转到`13_Govenance_Continual_Learning`文件夹，访问`test_inference.py`脚本（将URL替换为您的端点链接）。然后，通过运行以下命令来运行脚本：
- en: '[PRE5]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Running the script will output an error. Stop the script after performing some
    inferences. Within 5-10 minutes of the error, you will be notified of the error
    via email, as shown in the following screenshot:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行脚本将输出错误。在执行一些推理后停止脚本。在错误发生后的5-10分钟内，您将通过电子邮件收到错误通知，如下面的截图所示：
- en: '![Figure 13.15 – Email notification of an error in production'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.15 – 生产中的错误电子邮件通知'
- en: '](img/B16572_13_015.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16572_13_015.jpg](img/B16572_13_015.jpg)'
- en: Figure 13.15 – Email notification of an error in production
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.15 – 生产中的错误电子邮件通知
- en: Congratulations – you have successfully set up an email action alert for an
    error! This way, you can investigate when an error has been discovered in order
    to resolve it and get the system up and running.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您 – 您已成功设置了一个错误的电子邮件动作警报！这样，您就可以在发现错误时进行调查，以便解决它并使系统恢复正常运行。
- en: Next, let's look at how to ensure we have quality assurance for models and can
    control them in order to maximize business value.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何确保我们有模型的质量保证，并且可以控制它们以最大化商业价值。
- en: Model QA and control
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型问答和控制
- en: 'Evolving or dynamically changing data leads to increased prediction error rates.
    This may result from data drift as the business and external environment change,
    or it may be due to data poisoning attacks. This increase in prediction error
    rates results in having to re-evaluate ML models as they are retrained (manually
    or automatically), leading to the discovery of new algorithms that are more accurate
    than the previous ones. Here are some guidelines for testing ML models with new
    data:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的演变或动态变化导致预测错误率增加。这可能是由于业务和外部环境的变化导致的数据漂移，或者可能是由于数据中毒攻击。预测错误率的增加导致在重新训练（手动或自动）时必须重新评估机器学习模型，从而发现比之前更准确的新算法。以下是一些使用新数据测试机器学习模型的指南：
- en: Enable continual learning by retraining your models and evaluating their performance.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过重新训练模型并评估其性能来启用持续学习。
- en: Evaluate the performance of all the models on a new dataset at periodic intervals.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在定期间隔内评估所有模型在新的数据集上的性能。
- en: Raise an alert when an alternative model starts giving better performance or
    greater accuracy than the existing model.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当替代模型开始提供比现有模型更好的性能或更高的准确性时，发出警报。
- en: Maintain a registry of models containing their latest performance details and
    reports.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护包含最新性能细节和报告的模型注册表。
- en: Maintain end-to-end lineages of all the models to reproduce them or explain
    their performance to stakeholders.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护所有模型的端到端血缘，以便重现它们或向利益相关者解释其性能。
- en: Model auditing and reports
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型审计和报告
- en: 'Establishing a periodic auditing and reporting system for MLOps is a healthy
    practice as it enables an organization to track its operations end to end, as
    well as comply with the law and enable them to explain its operations to stakeholders
    upon request. We can ensure that the ML system conforms to the conventions that
    have been established and deliberated at the societal and governmental levels.
    To audit and report MLOps, it is recommended for auditors to inspect the fundamentals
    of an audit, shown in the following image:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 建立MLOps的定期审计和报告系统是一种良好的做法，因为它使组织能够端到端地跟踪其运营，并遵守法律，在需要时向利益相关者解释其运营。我们可以确保机器学习系统符合在社会和政府层面已经建立和审议的惯例。为了审计和报告MLOps，建议审计员检查以下图像所示的审计基础：
- en: '![Figure 13.16 – Fundamentals of an audit report for ML Operations'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 13.16 – ML Operations审计报告的基本要素]'
- en: '](img/B16572_13_016.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16572_13_016.jpg]'
- en: Figure 13.16 – Fundamentals of an audit report for ML Operations
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 13.16 – ML Operations审计报告的基本要素
- en: Data audit
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据审计
- en: Data is what drives many of the decisions made by ML systems. Due to this, the
    auditors need to consider data for auditing and reporting, inspecting the training
    data, testing the data, inferring the data, and monitoring the data. This is essential
    and having end-to-end traceability to track the use of data (for example, which
    dataset was used to train which model) is needed for MLOps. Having a *Git for
    Data* type of mechanism that versions data can enable auditors to reference, examine,
    and document the data.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是驱动许多机器学习系统决策的因素。因此，审计员在审计和报告中需要考虑数据，检查训练数据，测试数据，推断数据，并监控数据。这是至关重要的，并且对于MLOps来说，拥有端到端的可追溯性以跟踪数据的使用（例如，哪个数据集用于训练哪个模型）是必要的。拥有类似“数据Git”的机制，可以对数据进行版本控制，可以使得审计员能够引用、检查和记录数据。
- en: Model audit (fairness and performance)
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型审计（公平性和性能）
- en: Auditors of ML systems need to have a hacker's mindset to identify the different
    ways in which a model could fail and not give fair predictions. First, the training
    data is inspected and compared to the inference data using Explainable AI techniques.
    This can help auditors make fair judgments about each model and each of its predictions
    on an individual level. To make fairness and performance assessments for each
    model, we can use data slicing techniques, which can reveal valuable information
    for making an assessment. Due to this, it is valuable for auditors to request
    the results of data slicing for the required demographics and slices of data.
    To make a collective assessment, we can compare models and assess their performance.
    This can reveal another angle of information for making fairness and performance
    assessments.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统的审计员需要具备黑客心态，以识别模型可能失败的不同方式以及无法给出公平预测的情况。首先，审计员会检查训练数据，并使用可解释人工智能技术将其与推理数据进行比较。这有助于审计员对每个模型及其每个预测在个体层面上做出公平的判断。为了对每个模型进行公平性和性能评估，我们可以使用数据切片技术，这可以揭示对评估有价值的宝贵信息。因此，审计员请求所需人口统计数据和数据切片的数据切片结果是有价值的。为了进行集体评估，我们可以比较模型并评估其性能。这可以揭示关于公平性和性能评估的另一个信息角度。
- en: If a model audit were to proceed, it would assess the model's inputs (training
    data), the model itself, and its outputs. Data consistency and possible biases
    in the training data will need to be assessed. For example, if a resume screening
    model had been trained on previous or historic decisions where candidates had
    received job offers and workers were promoted, we'd want to make sure that the
    training data hasn't been influenced by past recruiters' and managers' implicit
    biases. Benchmarking against competing models, performing statistical tests to
    ensure that the model generalizes from training to unknown results, and using
    state-of-the-art techniques to allow model interpretability are all parts of the
    model evaluation process.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果进行模型审计，它将评估模型的输入（训练数据）、模型本身及其输出。需要评估数据的一致性和训练数据中可能存在的偏差。例如，如果简历筛选模型是在候选人收到工作邀请和工人晋升的先前或历史决策上训练的，我们想确保训练数据没有受到过去招聘人员和经理的隐含偏见的影响。与竞争模型进行基准测试、执行统计测试以确保模型从训练推广到未知结果，以及使用最先进的技术以允许模型可解释性，都是模型评估过程的一部分。
- en: Project and governance audit
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 项目和治理审计
- en: Is it necessary to have a deep understanding of AI models to audit algorithms?
    Certainly not. An audit of an AI system's progress is like a project management
    audit. Is there a clear target for the desired achievement? This is a good and
    straightforward question to ask if a government entity has implemented AI in a
    particular environment. Furthermore, is there a viable framework to manage the
    model after the developers leave, if external developers have been applied to
    the AI system? To reduce the need for specialist expertise, the company must have
    extensive documentation of concept creation and the staff who are familiar with
    the model. Hence, auditing the development and governance practices can be rewarding
    in the long run.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 审计算法是否需要深入了解AI模型？当然不是。对AI系统进展的审计就像项目管理审计一样。是否有明确的期望成果目标？如果政府实体在特定环境中实施了AI，这是一个很好的、直接的问题。此外，如果外部开发者被应用于AI系统，在开发者离开后，是否有可行的框架来管理模型？为了减少对专业知识的需要，公司必须对概念创建有广泛的文档记录，并拥有熟悉该模型的员工。因此，审计开发和治理实践从长远来看是有益的。
- en: Auditing data considerations, model fairness and performance, and project management
    and governance of ML systems can provide a comprehensive view of MLOps. Using
    error alerts and actions, we can perform timely investigations into errors to
    get the system up and running and in some cases, we can even do automated debugging
    to automate error resolution and MLOps. Finally, by undertaking model quality
    assurance, control, and auditing, we can ensure efficient governance of our MLOps.
    Next, we will look at how to enable model retraining so that we have continual
    learning capabilities for our ML system.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 审计数据考虑因素、模型公平性和性能，以及ML系统的项目管理与治理，可以提供一个全面的MLOps视图。使用错误警报和操作，我们可以及时调查错误，使系统恢复正常运行，在某些情况下，我们甚至可以进行自动化调试以自动化错误解决和MLOps。最后，通过进行模型质量保证、控制和审计，我们可以确保MLOps的有效治理。接下来，我们将探讨如何启用模型重新训练，以便我们的ML系统具有持续学习的能力。
- en: Enabling model retraining
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用模型重新训练
- en: 'So far, we''ve talked about what model drift is and how to recognize it. So,
    the question is, what should we do about it? If a model''s predictive performance
    has deteriorated due to changes in the environment, the solution is to retrain
    the model using a new training set that represents the current situation. How
    much should your model be retrained by? And how can you choose your new workout
    routine? The following diagram shows the **Model retrain** function triggering
    the **Build** module based on the results of the **Monitor** module. There are
    two ways to trigger the model retrain function. One is manually and the other
    is by automating the model retraining function. Let''s see how we can enable both:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了什么是模型漂移以及如何识别它。那么，问题来了，我们应该如何应对它？如果一个模型的预测性能由于环境变化而下降，解决方案是使用代表当前情况的新训练集重新训练模型。你的模型应该重新训练多少次？你如何选择你的新训练计划？以下图表显示了基于**模型重新训练**功能触发的**构建**模块，该模块基于**监控**模块的结果。有两种方式可以触发模型重新训练功能。一种是通过手动操作，另一种是通过自动化模型重新训练功能。让我们看看我们如何启用这两种方式：
- en: '![Figure 13.17 – Model retraining enabled in an MLOps workflow'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '![图13.17 – 在MLOps工作流程中启用模型重新训练'
- en: '](img/B16572_13_017.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16572_13_017.jpg]'
- en: Figure 13.17 – Model retraining enabled in an MLOps workflow
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.17 – 在MLOps工作流程中启用模型重新训练
- en: Manual model retraining
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动模型重新训练
- en: The product owner or quality assurance manager has the responsibility of ensuring
    manual model retraining is successful. The manual model triggering step involves
    evaluating model drift and if it goes above a threshold (you need to determine
    a threshold for drift that will trigger model retraining), then they must trigger
    the model training process by training the model using a new dataset (this can
    be the previous training dataset and the latest inference data). This way, the
    product owner or quality assurance manager has full control over the process,
    and also knows when and how to trigger model retraining to deliver maximized value
    from the ML system.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 产品负责人或质量保证经理有责任确保手动模型重新训练成功。手动模型触发步骤包括评估模型漂移，如果它超过了一个阈值（你需要确定一个漂移阈值，以触发模型重新训练），那么他们必须通过使用新的数据集（这可以是之前的训练数据集和最新的推理数据）来训练模型来触发模型训练过程。这样，产品负责人或质量保证经理对整个过程有完全的控制权，并且知道何时以及如何触发模型重新训练，以从机器学习系统中获得最大价值。
- en: Automated model retraining
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动化模型重新训练
- en: If you want to fully automate the MLOps pipeline, automating model drift management
    can be an ideal approach to retraining the production model. Automating model
    drift management is done by configuring batch jobs that monitor application diagnostics
    and model performance. Then, you must activate model retraining. A key part of
    automating model drift management is setting the threshold that will automatically
    trigger the retraining model function. If the drift monitoring threshold is set
    too low, you run the risk of having to retrain too often, which will result in
    high compute costs. If the threshold is set too high, you risk not retraining
    often enough, resulting in suboptimal production models. Figuring out the right
    threshold is trickier than it seems because you have to figure out how much additional
    training data you'll need to reflect this new reality. Even if the environment
    has changed, replacing an existing model with one that has a very small training
    set is pointless. Once you have the threshold figured out, you could have jobs
    (for example, as part of the CI/CD pipeline) that compare the feature distributions
    of live datasets to those of training data on a regular basis (as we did in [*Chapter
    12*](B16572_12_Final_JM_ePub.xhtml#_idTextAnchor222), *Model Serving and Monitoring*).
    When a large deviation is detected (or above the defined threshold), the system
    can schedule model retraining and deploy a new model automatically. This can be
    done using a work scheduler such as Jenkins or Kubernetes Jobs or CI/CD pipeline
    cron jobs. This way, you can fully automate the MLOps pipeline and the model retraining
    part.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要完全自动化MLOps管道，自动化模型漂移管理可以是一个重新训练生产模型的理想方法。自动化模型漂移管理是通过配置监控应用程序诊断和模型性能的批量作业来完成的。然后，你必须激活模型重新训练。自动化模型漂移管理的关键部分是设置将自动触发重新训练模型功能的阈值。如果漂移监控阈值设置得太低，你可能会面临需要频繁重新训练的风险，这会导致高昂的计算成本。如果阈值设置得太高，你可能会面临不够频繁地重新训练的风险，导致生产模型次优。确定正确的阈值比看起来要复杂，因为你必须确定你需要多少额外的训练数据来反映这一新现实。即使环境已经改变，用一个非常小的训练集替换现有模型也是没有意义的。一旦你确定了阈值，你就可以有作业（例如，作为CI/CD管道的一部分）定期比较实时数据集的特征分布与训练数据上的特征分布（正如我们在[*第12章*](B16572_12_Final_JM_ePub.xhtml#_idTextAnchor222)，*模型服务和监控*中所做的那样）。当检测到大的偏差（或超过定义的阈值）时，系统可以安排模型重新训练并自动部署新模型。这可以通过使用工作调度程序（例如，Jenkins或Kubernetes作业或CI/CD管道cron作业）来完成。这样，你可以完全自动化MLOps管道和模型重新训练部分。
- en: Note that it doesn't make sense to retrain the model in cases where there is
    low new data coming in or if you are doing batch inference once in a blue moon
    (for example, every 6 months). You can train the model before inference or periodically
    whenever you need to.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在数据流入量低或你偶尔进行批量推理（例如，每6个月一次）的情况下重新训练模型是没有意义的。你可以在推理之前或在你需要的时候定期训练模型。
- en: Maintaining the CI/CD pipeline
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 维护CI/CD管道
- en: 'As you may recall, in [*Chapter 10*](B16572_10_Final_JM_ePub.xhtml#_idTextAnchor189)*,
    Essentials of Production Release*, we mentioned that *a model is not the product;
    the pipeline is the product*. Hence, after setting up automated or semi-automated
    CI/CD pipelines, it is critical to monitor the performance of our pipeline. We
    can do that by inspecting the releases in Azure DevOps, as shown in the following
    screenshot:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所忆，在[*第 10 章*](B16572_10_Final_JM_ePub.xhtml#_idTextAnchor189)“生产发布要素”中，我们提到*模型不是产品；管道才是产品*。因此，在设置自动化或半自动化
    CI/CD 管道后，监控我们管道的性能至关重要。我们可以通过检查 Azure DevOps 中的发布来实现这一点，如下面的截图所示：
- en: '![Figure 13.18 – Maintaining CI/CD pipeline releases'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 13.18 – 维护 CI/CD 管道发布'
- en: '](img/B16572_13_018.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16572_13_018.jpg]'
- en: Figure 13.18 – Maintaining CI/CD pipeline releases
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.18 – 维护 CI/CD 管道发布
- en: 'The goal of an inspection is to keep the CI/CD pipeline in a healthy and robust
    state. Here are some guidelines for keeping the CI/CD pipeline healthy and robust:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 检查的目标是保持 CI/CD 管道处于健康和稳健的状态。以下是一些保持 CI/CD 管道健康和稳健的指南：
- en: If a build is broken, a **fix it asap** policy from the team should be implemented.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果构建失败，团队应实施**立即修复**的政策。
- en: Integrate automated acceptance tests.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成自动化验收测试。
- en: Require pull requests.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要提交拉取请求。
- en: Peer code review each story or feature.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对每个故事或功能进行同行代码审查。
- en: Audit system logs and events periodically (recommended).
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期审计系统日志和事件（建议）。
- en: Regularly report metrics visibly to all the team members (for example, slackbot
    or email notifications).
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期向所有团队成员公开报告指标（例如，通过 slackbot 或电子邮件通知）。
- en: By implementing these practices, we can avoid high failure rates and make the
    CI/CD pipeline robust, scalable, and transparent for all the team members.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 通过实施这些实践，我们可以避免高失败率，并使 CI/CD 管道对所有团队成员来说都稳健、可扩展和透明。
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the key principles of continual learning in
    ML solutions. We learned about Explainable Monitoring (the governance component)
    by implementing hands-on error handling and configuring actions to alert developers
    of ML systems using email notifications. Lastly, we looked at ways to enable model
    retraining and how to maintain the CI/CD pipeline. With this, you have been equipped
    with the critical skills to automate and govern MLOps for your use cases.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了 ML 解决方案持续学习的核心原则。我们通过实际错误处理和配置使用电子邮件通知提醒开发者的操作，学习了可解释监控（治理组件）。最后，我们探讨了启用模型重新训练以及维护
    CI/CD 管道的方法。这样，您已经具备了自动化和治理 MLOps 的关键技能，以应对您的用例。
- en: Congratulations on finishing this book! The world of MLOps is constantly evolving
    for the better. You are now equipped to help your business thrive using MLOps.
    I hope you enjoyed reading and learning by completing the hands-on MLOps implementations.
    Go out there and be the change you wish to see. All the best with your MLOps endeavors!
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您完成这本书！MLOps 的世界正在不断进化，变得越来越好。您现在已经准备好利用 MLOps 来帮助您的业务繁荣。希望您在完成动手实践 MLOps
    实现的过程中享受阅读和学习。走出舒适区，成为您希望看到的改变。祝您在 MLOps 的努力中一切顺利！
