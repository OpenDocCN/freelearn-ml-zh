- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Advanced Deep Learning Techniques
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级深度学习技术
- en: In the previous chapter, we reviewed the concept of neural network modeling
    and deep learning while focusing on fully connected neural networks. In this chapter,
    we will discuss more advanced techniques that let you use deep learning models
    across different data types and structures, such as images, texts, and graphs.
    These techniques are behind the majority of advancements across industries through
    artificial intelligence, such as in chatbots, medical diagnosis, drug discovery,
    stock trading, and fraud detection. Although we will present some of the most
    famous deep learning models across different data types, this chapter aims to
    help you understand the concepts and practice with PyTorch, and not provide you
    with state-of-the-art models for each data type or subject domain.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们回顾了神经网络建模和深度学习的概念，同时关注全连接神经网络。在本章中，我们将讨论更多高级技术，这些技术让您能够使用深度学习模型跨越不同的数据类型和结构，例如图像、文本和图。这些技术是人工智能在各个行业取得进步的主要推动力，例如在聊天机器人、医疗诊断、药物发现、股票交易和欺诈检测等领域。尽管我们将介绍不同数据类型中最著名的深度学习模型，但本章旨在帮助您理解概念，并使用
    PyTorch 和 Python 进行实践，而不是为每个数据类型或主题领域提供最先进的模型。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Types of neural networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络类型
- en: Convolutional neural networks for image shape data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于图像形状数据的卷积神经网络
- en: Transformers for language modeling
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于语言建模的转换器
- en: Modeling graphs using deep neural networks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用深度神经网络建模图
- en: By the end of this chapter, you will have learned about **convolutional neural
    networks** (**CNNs**), transformers, and graph neural networks as the three important
    categories of deep learning modeling to develop high-performance models in your
    problems of interest. You will have also learned how to develop such models using
    PyTorch and Python.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将了解**卷积神经网络**（**CNNs**）、转换器和图神经网络作为深度学习建模的三个重要类别，以在您感兴趣的问题中开发高性能模型。您还将了解如何使用
    PyTorch 和 Python 开发此类模型。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following requirements should be considered for this chapter as they will
    help you better understand the concepts, use them in your projects, and practice
    with the provided code:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，以下要求应予以考虑，因为它们将帮助您更好地理解概念，在项目中使用它们，并使用提供的代码进行实践：
- en: 'Python library requirements:'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 库要求：
- en: '`torch` >= 2.0.0'
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch` >= 2.0.0'
- en: '`torchvision` >= 0.15.1'
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torchvision` >= 0.15.1'
- en: '`transformers` >= 4.28.0'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformers` >= 4.28.0'
- en: '`datasets` >= 2.12.0'
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`datasets` >= 2.12.0'
- en: '`torch_geometric` == 2.3.1'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch_geometric` == 2.3.1'
- en: 'You will require basic knowledge of the following:'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要具备以下基本知识：
- en: Deep learning modeling and fully connected neural networks
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习建模和全连接神经网络
- en: How to use PyTorch for deep learning modeling
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 PyTorch 进行深度学习建模
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter13](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter13).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 GitHub 上找到本章的代码文件，链接为 [https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter13](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter13)。
- en: Types of neural networks
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络类型
- en: The examples we have provided so far in this book have focused on tabular data
    either in machine learning or in deep learning modeling, as one category of machine
    learning modeling. However, machine learning, and especially deep learning, has
    been successful in tackling problems that deal with non-tabular, or unstructured,
    texts, images, and graphs. First, we’ll introduce different problems that involve
    such data types in this section; then, we’ll review deep learning techniques that
    can help you build reliable models for them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本书迄今为止提供的示例主要集中在表格数据上，无论是机器学习还是深度学习建模，作为机器学习建模的一个类别。然而，机器学习和特别是深度学习在处理非表格数据、非结构化文本、图像和图的问题上已经取得了成功。首先，在本节中，我们将介绍涉及此类数据类型的不同问题；然后，我们将回顾可以帮助您为这些问题构建可靠模型的深度学习技术。
- en: Categorization based on data type
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于数据类型的分类
- en: 'Structured data, which is also referred to as tabular data, is data that can
    be organized into spreadsheets and structured databases. As we have used this
    data type in this book, we usually have different features and even output in
    the columns of a table, matrix, or DataFrame. The rows of a DataFrame represent
    different data points in the dataset. However, we have other types of data that
    are not structured, and reformatting them into a DataFrame or matrix results in
    a loss of information. *Figure 13**.1* shows the three most important types of
    unstructured data – that is, sequence data such as text, image shape data such
    as family photos, and graphs such as social networks:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据，也称为表格数据，是指可以组织成电子表格和结构化数据库的数据。正如我们在本书中使用这种数据类型一样，我们通常在表格、矩阵或DataFrame的列中具有不同的特征，甚至输出。DataFrame的行代表数据集中的不同数据点。然而，我们还有其他类型的数据，它们不是结构化的，将它们重新格式化为DataFrame或矩阵会导致信息丢失。“图13.1”显示了三种最重要的非结构化数据类型——即文本等序列数据、家庭照片等图像形状数据以及社交网络等图数据：
- en: '![Figure 13.1 – Different data types that can be modeled using deep learning](img/B16369_13_01.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图13.1 – 使用深度学习可以建模的不同数据类型](img/B16369_13_01.jpg)'
- en: Figure 13.1 – Different data types that can be modeled using deep learning
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1 – 使用深度学习可以建模的不同数据类型
- en: '*Table 13.1* provides some examples of problems and how their corresponding
    data fits within each category mentioned in *Figure 13**.1*:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*表13.1* 提供了一些问题和它们对应的数据如何适合图13.1中提到的每个类别的一些示例：'
- en: '| **Data Type** | **Examples** |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| **数据类型** | **示例** |'
- en: '| Sequence data | TextTime-series data such as stock pricesAudio data as a
    sequence of sound wavesGeolocation data as a sequence of object movementEEG data
    as a sequence of electrical activity of the brainECG data as a sequence of electrical
    activity of the heart |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 序列数据 | 文本、股票价格等时间序列数据、声音波序列的音频数据、物体运动序列的地理位置数据、大脑电活动序列的EEG数据、心脏电活动序列的ECG数据
    |'
- en: '| Image shape data | PhotographsSecurity and surveillance imagesMedical images
    such as X-rays or CT scansVisual arts and images of drawings and paintingsImages
    captured by satellites, such as weather patternsImages captured using microscopes,
    such as images of cells |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 图像形状数据 | 照片、安全监控图像、X射线或CT扫描等医学图像、视觉艺术和绘画图像、卫星捕获的图像，如天气模式、显微镜捕获的图像，如细胞图像 |'
- en: '| Graphs | Road networksWeb graphs – connections between web pagesKnowledge
    graphs – relationships between conceptsSocial networks – connections between individuals
    and groupsBiological networks – connections between genes or other biological
    entities |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 图 | 道路网络、网页之间的连接（网络图）、概念之间的关系（知识图）、个人和群体之间的连接（社交网络）、基因或其他生物实体之间的连接（生物网络）
    |'
- en: Table 13.1 – Examples of problems for each data type
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 表13.1 – 每种数据类型的示例问题
- en: 'Some of the challenges and issues with reformatting different data types into
    tabular data are as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 将不同数据类型重新格式化为表格数据时的一些挑战和问题如下：
- en: Reformatting sequence data into a table shape data object results in a loss
    of information regarding the order of data, such as words
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将序列数据重新格式化为表格形状的数据对象会导致关于数据顺序（如单词）的信息丢失
- en: Reformatting images into tabular format results in a loss of local patterns,
    such as the relationship between pixels of two-dimensional images
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像重新格式化为表格格式会导致局部模式（如二维图像像素之间的关系）的丢失
- en: Reformatting graphs into tabular data will eliminate dependency between data
    points or features
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图重新格式化为表格数据将消除数据点或特征之间的依赖关系
- en: Now that we understand the importance of not reformatting all datasets and data
    types into tabular data, we can start working with different deep learning techniques
    to understand how we can build successful models for non-tabular data. We will
    start by looking at image shape data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经理解了不将所有数据集和数据类型重新格式化为表格数据的重要性，我们可以开始使用不同的深度学习技术来了解我们如何为非表格数据构建成功的模型。我们将从查看图像形状数据开始。
- en: Convolutional neural networks for image shape data
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于图像形状数据的卷积神经网络
- en: 'CNNs allow us to build deep learning models on image data without the need
    to reformat images into a tabular format. The name of this category of deep learning
    techniques comes from the concept of convolution, which in deep learning refers
    to applying a filter to image shape data to produce a secondary image shape feature
    map (shown in *Figure 13**.2*):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: CNNs允许我们在图像数据上构建深度学习模型，而无需将图像重新格式化为表格格式。这类深度学习技术的名称来源于卷积的概念，在深度学习中指的是将滤波器应用于图像形状数据以产生一个次级图像形状特征图（如*图13**.2*所示）：
- en: '![Figure 13.2 – A simple example of applying a predefined convolution filter
    to a 3x3 image shape data point](img/B16369_13_02.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图13.2 – 将预定义的卷积滤波器应用于3x3图像形状数据点的简单示例](img/B16369_13_02.jpg)'
- en: Figure 13.2 – A simple example of applying a predefined convolution filter to
    a 3x3 image shape data point
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2 – 将预定义的卷积滤波器应用于3x3图像形状数据点的简单示例
- en: When training a deep learning model, for example using PyTorch, a convolution
    filter or other filters that we will introduce later in this chapter will not
    be predefined but rather learned through the learning process. Convolution and
    other filters and processes in CNN modeling let us use the methods under this
    category of deep learning techniques for different image shape data (as we saw
    in *Figure 13**.1*).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练一个深度学习模型时，例如使用PyTorch，卷积滤波器或其他我们将在本章后面介绍的滤波器并不是预定义的，而是通过学习过程来学习的。卷积和其他CNN建模中的滤波器及过程使我们能够使用这类深度学习技术处理不同图像形状的数据（正如我们在*图13**.1*中看到的）。
- en: 'The application of CNNs is beyond supervised learning for image classification,
    for which it might be most famous. CNNs have been used for different problems,
    including **image segmentation**, **resolution enhancements**, **object detection**,
    and more (*Figure 13**.3*):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: CNNs的应用不仅限于图像分类的监督学习，这是它最著名的应用之一。CNNs已被用于不同的问题，包括**图像分割**、**分辨率增强**、**目标检测**等（*图13**.3*）：
- en: '![Figure 13.3 – Some of the successful applications of convolutional neural
    networks](img/B16369_13_03.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图13.3 – 卷积神经网络的一些成功应用](img/B16369_13_03.jpg)'
- en: Figure 13.3 – Some of the successful applications of convolutional neural networks
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3 – 卷积神经网络的一些成功应用
- en: '*Table 13.2* provides a list of high-performance models in different applications
    of CNNs that you can use in your projects or learn from to build even better models:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*表13.2*列出了CNN在不同应用中的高性能模型，您可以在项目中使用或在构建更好的模型时参考：'
- en: '| **Problem** | **Some of the Widely Used Models and** **Related Techniques**
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| **问题** | **一些广泛使用的模型和相关技术** |'
- en: '| Image classification | ResNet (He et al., 2016); EfficientNets (Tan and Le,
    2019); MobileNets (Howard et al., 2017; Sandler et al., 2018); Xception (Chollet,
    2017) |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | ResNet（He et al., 2016）；EfficientNets（Tan and Le, 2019）；MobileNets（Howard
    et al., 2017；Sandler et al., 2018）；Xception（Chollet, 2017）|'
- en: '| Image segmentation | U-Net (Ronneberger et al., 2015); Mask R-CNN (He et
    al., 2017); DeepLab (Chen et al., 2017); PSPNet (Chao et al., 2017) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 图像分割 | U-Net（Ronneberger et al., 2015）；Mask R-CNN（He et al., 2017）；DeepLab（Chen
    et al., 2017）；PSPNet（Chao et al., 2017）|'
- en: '| Object detection | Mask R-CNN (He et al., 2017); Faster R-CNN (Ren et al.,
    2015); YOLO (Redmon et al., 2016) |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 目标检测 | Mask R-CNN（He et al., 2017）；Faster R-CNN（Ren et al., 2015）；YOLO（Redmon
    et al., 2016）|'
- en: '| Image super-resolution | SRCNN (Dong et el., 2015); FSRCNN (Dong et al.,
    2016); EDSR (Lim et al., 2017) |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 图像超分辨率 | SRCNN（Dong et el., 2015）；FSRCNN（Dong et al., 2016）；EDSR（Lim et al.,
    2017）|'
- en: '| Image-to-image translation | Pix2Pix (Isola et al., 2017); CycleGAN (Zhu
    et al., 2017) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 图像到图像翻译 | Pix2Pix（Isola et al., 2017）；CycleGAN（Zhu et al., 2017）|'
- en: '| Style transfer | Neural Algorithm of Artistic Style (Gatys et al., 2016);
    AdaIN-Style (Huang et al., 2017) |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 风格迁移 | 艺术风格神经算法（Gatys et al., 2016）；AdaIN-Style（Huang et al., 2017）|'
- en: '| Anomaly detection | AnoGAN (Schlegl et al., 2017); RDA (Zhou et al., 2017);
    Deep SVDD (Ruff et al., 2018) |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 异常检测 | AnoGAN（Schlegl et al., 2017）；RDA（Zhou et al., 2017）；Deep SVDD（Ruff
    et al., 2018）|'
- en: '| Optical character recognition | EAST (Zhou et al., 2017); CRAFT (Bake et
    al., 2019) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 光学字符识别 | EAST（Zhou et al., 2017）；CRAFT（Bake et al., 2019）|'
- en: Table 13.2 – High-performance CNN models across different problems
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 表13.2 – 不同问题下的高性能CNN模型
- en: You can train CNN models on two-dimensional or three-dimensional image shape
    data. You can also build models that work on sequences of such data points, such
    as videos, as sequences of images. Some of the most famous models or approaches
    in terms of using CNNs on videos that you can play with are C3D (Tran et al.,
    2015), I3D (Carreira and Zisserman, 2017), and SlowFast (Feichtenhofer et al.,
    2019).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在二维或三维图像形状数据上训练CNN模型。你也可以构建处理此类数据点序列的模型，例如视频，作为图像序列。你可以玩的一些在视频上使用CNN的最著名模型或方法包括C3D（Tran等，2015年）、I3D（Carreira和Zisserman，2017年）和SlowFast（Feichtenhofer等，2019年）。
- en: Next, we will learn about some of the ways we can assess the performance of
    CNN models.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解一些评估CNN模型性能的方法。
- en: Performance assessment
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能评估
- en: 'You can use the performance measures presented in [*Chapter 4*](B16369_04.xhtml#_idTextAnchor159),
    *Detecting Performance and Efficiency Issues in Machine Learning Models*, such
    as ROC-AUC, PR-AUC, precision, and recall, for CNN classification models. However,
    there are other measures more specific to some of the problems presented in *Figure
    13**.3*, as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用在第[*第4章*](B16369_04.xhtml#_idTextAnchor159)中介绍的机器学习模型性能和效率问题检测的性能指标，例如ROC-AUC、PR-AUC、精确率和召回率，用于CNN分类模型。然而，对于*图13**.3*中提出的一些问题，还有其他更具体的指标，如下所示：
- en: '**Pixel accuracy**: This measure is defined as the ratio of correctly classified
    pixels to the total number of pixels. This measure works like accuracy and can
    be misleading when there is a class imbalance in the pixels.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**像素精度**：这个指标定义为正确分类的像素数与总像素数的比率。这个指标与准确度类似，当像素存在类别不平衡时可能会产生误导。'
- en: '**Jaccard index**: The Jaccard index is defined as the intersection over the
    union and can be used to calculate the overlap between the predicted segmentation
    and the ground truth normalized by their union.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jaccard指数**：Jaccard指数定义为交集与并集的比率，可以用来计算预测分割与真实分割的交集，并按它们的并集进行归一化。'
- en: CNN modeling using PyTorch
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PyTorch进行CNN建模
- en: 'The process of CNN modeling in PyTorch is very similar to building fully connected
    neural networks, as we covered in the previous chapter. It starts with specifying
    the architecture of the network, then initializing the optimizer, and finally
    going through different epochs and batches to learn from training data points.
    Here, we want to practice CNN modeling in PyTorch using the `torchvision` library.
    Examples of the images in this dataset are shown in *Figure 13**.4*:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch中的CNN建模过程与我们之前章节中介绍的构建全连接神经网络非常相似。它从指定网络架构开始，然后初始化优化器，最后通过不同的周期和批次从训练数据点中学习。在这里，我们想使用`torchvision`库在PyTorch中练习CNN建模。此数据集中图像的示例在*图13**.4*中显示：
- en: '![Figure 13.4 – Examples of images in the German Traffic Sign Recognition Benchmark
    (GTSRB) dataset from torchvision](img/B16369_13_04.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图13.4 – torchvision数据集中德国交通标志识别基准（GTSRB）数据集的图像示例](img/B16369_13_04.jpg)'
- en: Figure 13.4 – Examples of images in the German Traffic Sign Recognition Benchmark
    (GTSRB) dataset from torchvision
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4 – torchvision数据集中德国交通标志识别基准（GTSRB）数据集的图像示例
- en: There are other filters and layers besides the convolution filter (`torch.nn.Conv2d`)
    available in `torch.nn` that you can use to train high-performance CNN models.
    One of those filters that is widely used besides `torch.nn.Conv2d` is `torch.nn.MaxPool2d`,
    which can be used as a pooling layer in CNN modeling (LeCun et al., 1989). You
    can read about the required arguments for these two filters on the PyTorch website
    ([https://pytorch.org/docs/stable/nn.html](https://pytorch.org/docs/stable/nn.html)).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`torch.nn.Conv2d`卷积滤波器外，`torch.nn`模块中还有其他滤波器和层可供使用，你可以使用它们来训练高性能的CNN模型。除了`torch.nn.Conv2d`之外，广泛使用的另一个滤波器是`torch.nn.MaxPool2d`，它可以用作CNN建模中的池化层（LeCun等，1989年）。你可以在PyTorch网站上阅读这两个滤波器所需的参数（[https://pytorch.org/docs/stable/nn.html](https://pytorch.org/docs/stable/nn.html)）。
- en: 'Let’s start practicing CNN modeling using the GTSRB dataset. First, we must
    load the data for model training and testing, and then specify the number of classes
    in the classification model:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始使用GTSRB数据集练习CNN建模。首先，我们必须加载用于模型训练和测试的数据，然后指定分类模型中的类别数：
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we must define a neural network class, called `Net`, which determines
    the architecture of the network, including two layers of convolutional plus pooling
    filters, followed by ReLU activation functions, and then three layers of fully
    connected neural networks with ReLU activation functions:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须定义一个名为`Net`的神经网络类，它决定了网络的架构，包括两层卷积加上池化滤波器，然后是ReLU激活函数，接着是三层具有ReLU激活函数的全连接神经网络：
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, we must initialize the network and optimizer, as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须初始化网络和优化器，如下所示：
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we are ready to train the network using the initialized architecture and
    the optimizer. Here, we will use three epochs to train the network. The batch
    sizes don’t need to be specified here as they were determined when the data was
    loaded from `torchvision`, which was specified as `6` in this case (this can be
    found in this book’s GitHub repository):'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好使用初始化的架构和优化器来训练网络。在这里，我们将使用三个epoch来训练网络。批大小不需要在这里指定，因为它们在从`torchvision`加载数据时就已经确定，在这个例子中指定为`6`（这可以在本书的GitHub仓库中找到）：
- en: '[PRE3]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The final calculated loss after 3 epochs is 0.00008.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 经过3个epoch后的最终计算损失为0.00008。
- en: This was a simple example of using PyTorch for CNN modeling. There are other
    functionalities in PyTorch that you can benefit from while building CNN models,
    such as data augmentation. We will discuss this next.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个使用PyTorch进行CNN建模的简单示例。在构建CNN模型时，PyTorch还有其他你可以从中受益的功能，例如数据增强。我们将在下一节讨论这个问题。
- en: Image data transformation and augmentation for CNNs
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CNN的图像数据转换和增强
- en: 'As part of the pre-training stages of a machine learning life cycle, you might
    need to transform your images, such as by cropping them, or implement data augmentation
    as a series of techniques for synthetic data generation to improve the performance
    of your models, as explained in [*Chapter 5*](B16369_05.xhtml#_idTextAnchor183),
    *Improving the Performance of Machine Learning Models*. *Figure 13**.5* shows
    some simple examples of data augmentation, including rotation and scaling, that
    help you in generating synthetic but highly relevant data points to help your
    models:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 作为机器学习生命周期预训练阶段的一部分，你可能需要转换你的图像，例如通过裁剪它们，或者实现数据增强作为一系列用于合成数据生成的技术，以提高你模型的性能，如[第5章](B16369_05.xhtml#_idTextAnchor183)中所述，*提高机器学习模型的性能*。*图13.5*展示了数据增强的一些简单示例，包括旋转和缩放，这些可以帮助你生成合成但高度相关的数据点，以帮助你的模型：
- en: "![Figure 13.5 – Examples of rule-based data augmentation – (A) original image\uFEFF\
    ,\uFEFF (B) rotated image\uFEFF, and\uFEFF (C) scaled image](img/B16369_13_05.jpg)"
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图13.5 – 基于规则的图像数据增强示例 – (A) 原始图像，(B) 旋转图像，和(C) 缩放图像](img/B16369_13_05.jpg)'
- en: Figure 13.5 – Examples of rule-based data augmentation – (A) original image,
    (B) rotated image, and (C) scaled image
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5 – 基于规则的图像数据增强示例 – (A) 原始图像，(B) 旋转图像，和(C) 缩放图像
- en: Although there are simple examples of rules for data augmentation that you can
    implement in Python, there are many classes in PyTorch that you can use for both
    data transformation and augmentation, as explained at [https://pytorch.org/vision/stable/transforms.html](https://pytorch.org/vision/stable/transforms.html).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可以实现数据增强的简单规则示例，但在PyTorch中有许多类可以用于数据转换和增强，如[https://pytorch.org/vision/stable/transforms.html](https://pytorch.org/vision/stable/transforms.html)中所述。
- en: Using pre-trained models
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用预训练模型
- en: In a deep learning setting, often, we rely on pre-trained models either for
    inference or to further fine-tune for a specific problem we have at hand. CNNs
    are not an exception and you can find many pre-trained models in PyTorch for image
    classification or other applications of CNNs ([https://pytorch.org/vision/stable/models.html](https://pytorch.org/vision/stable/models.html)).
    You can also find code examples at the same URL on how to use these models. You
    can find the necessary code to teach you how to fine-tune these models using new
    data at [https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习环境中，我们通常依赖于预训练模型来进行推理或进一步微调以解决我们手头的特定问题。卷积神经网络（CNNs）也不例外，你可以在PyTorch中找到许多用于图像分类或其他CNN应用的预训练模型（[https://pytorch.org/vision/stable/models.html](https://pytorch.org/vision/stable/models.html)）。你还可以在相同的URL上找到如何使用这些模型的代码示例。你可以在[https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)找到必要的代码，教你如何使用新数据微调这些模型。
- en: Although we’ve focused on applying CNNs to image data so far, they can be used
    to model any image shape data. For example, audio data can be transformed from
    the time domain into the frequency domain, resulting in image shape data that
    can be modeled using CNNs in combination with sequence modeling algorithms, as
    introduced later in this chapter ([https://pytorch.org/audio/main/models.html](https://pytorch.org/audio/main/models.html)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们迄今为止一直专注于将 CNN 应用于图像数据，但它们可以用来建模任何图像形状数据。例如，音频数据可以从时域转换到频域，从而产生可以结合序列建模算法使用
    CNN 来建模的图像形状数据，正如本章后面所介绍的 ([https://pytorch.org/audio/main/models.html](https://pytorch.org/audio/main/models.html))。
- en: In addition to images and image shape data, deep learning models and algorithms
    have been developed to properly model sequence data in a variety of applications,
    such as in **natural language processing** (**NLP**), which we will refer to as
    language modeling here for simplicity. In the next section, we will review transformers
    for language modeling to help you start benefiting from such models if you have
    a relevant idea or project at hand.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 除了图像和图像形状数据之外，深度学习模型和算法已经被开发出来，以在多种应用中正确地建模序列数据，例如在**自然语言处理**（**NLP**）中，为了简便起见，我们在这里将其称为语言建模。在下一节中，我们将回顾用于语言建模的
    Transformer，以帮助您在手中有一个相关想法或项目时开始从这些模型中受益。
- en: Transformers for language modeling
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于语言建模的 Transformer
- en: Transformers were introduced in a famous paper called *Attention is All You
    Need* (Vaswani et al., 2017) as a new approach for sequence-to-sequence data modeling
    tasks such as translating statements from one language into another (that is,
    machine translation). These models are built on top of the idea of self-attention,
    which helps the model pay attention to other important parts of a sentence or
    sequence of information in the learning process during training. This attention
    mechanism helps the models better understand the relationships between the elements
    of input sequences – for example, between the words in the input sequences in
    language modeling. Models built using transformers usually work better than ones
    built using predecessor techniques such as **Long Short Term Memory** (**LSTM**)
    and **Recurrent Neural Networks** (**RNNs**) (Vaswani et al., 2017; Devlin et
    al., 2018).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 在一篇名为 *Attention is All You Need* 的著名论文（Vaswani et al., 2017）中被引入，作为一种新的序列到序列数据建模任务的方法，例如将一种语言的陈述翻译成另一种语言（即机器翻译）。这些模型建立在自注意力概念之上，该概念有助于模型在训练过程中关注句子或信息序列中的其他重要部分。这种注意力机制有助于模型更好地理解输入序列元素之间的关系——例如，在语言建模中输入序列中的单词之间的关系。使用
    Transformer 构建的模型通常比使用如 **长短期记忆**（**LSTM**）和 **循环神经网络**（**RNNs**）（Vaswani et al.,
    2017; Devlin et al., 2018）等前辈技术构建的模型表现更好。
- en: '*Figure 13**.6* shows four traditional problems in language modeling that have
    been tackled successfully by transformer models:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 13.6* 展示了通过 Transformer 模型成功解决的四个传统语言建模问题：'
- en: '![Figure 13.6 – Four traditional problems in language modeling for which deep
    learning techniques have been used successfully](img/B16369_13_06.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.6 – 深度学习技术在语言建模中成功应用的四个传统问题](img/B16369_13_06.jpg)'
- en: Figure 13.6 – Four traditional problems in language modeling for which deep
    learning techniques have been used successfully
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 – 深度学习技术在语言建模中成功应用的四个传统问题
- en: 'Some famous models have been used either directly or with some modifications
    across these or other language modeling tasks. Here are some examples:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一些著名的模型已经在这些或其他语言建模任务中直接使用或经过一些修改。以下是一些例子：
- en: BERT (Devlin et al., 2018; [https://github.com/google-research/bert](https://github.com/google-research/bert))
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BERT (Devlin et al., 2018; [https://github.com/google-research/bert](https://github.com/google-research/bert))
- en: GPT (Radford et al., 2018) and its more recent versions ([https://openai.com/product/gpt-4](https://openai.com/product/gpt-4))
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT (Radford et al., 2018) 及其更近的版本 ([https://openai.com/product/gpt-4](https://openai.com/product/gpt-4))
- en: DistilBERT (Sanh et al., 2019; [https://huggingface.co/docs/transformers/model_doc/distilbert](https://huggingface.co/docs/transformers/model_doc/distilbert))
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DistilBERT (Sanh et al., 2019; [https://huggingface.co/docs/transformers/model_doc/distilbert](https://huggingface.co/docs/transformers/model_doc/distilbert))
- en: RoBERTa (Liu et al., 2019; [https://github.com/facebookresearch/fairseq/tree/main/examples/roberta](https://github.com/facebookresearch/fairseq/tree/main/examples/roberta))
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RoBERTa (Liu et al., 2019; [https://github.com/facebookresearch/fairseq/tree/main/examples/roberta](https://github.com/facebookresearch/fairseq/tree/main/examples/roberta))
- en: BART (Lewis et al., 2019; [https://github.com/huggingface/transformers/tree/main/src/transformers/models/bart](https://github.com/huggingface/transformers/tree/main/src/transformers/models/bart))
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BART（Lewis et al., 2019；[https://github.com/huggingface/transformers/tree/main/src/transformers/models/bart](https://github.com/huggingface/transformers/tree/main/src/transformers/models/bart))
- en: XLNet (Yang et al., 2019; [https://github.com/zihangdai/xlnet/](https://github.com/zihangdai/xlnet/))
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XLNet（Yang et al., 2019；[https://github.com/zihangdai/xlnet/](https://github.com/zihangdai/xlnet/))
- en: T5 (Raffel et al., 2020; [https://github.com/google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer))
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T5（Raffel et al., 2020；[https://github.com/google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer))
- en: LLaMA (Touvron et al., 2023; [https://github.com/facebookresearch/llama](https://github.com/facebookresearch/llama))
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLaMA（Touvron et al., 2023；[https://github.com/facebookresearch/llama](https://github.com/facebookresearch/llama))
- en: Transformer models have also been used in other fields and sequence data, such
    as for electronic health records (Li et al., 2020), protein structure prediction
    (Jumpter et al., 2021), and time-series anomaly detection (Xu et al., 2021).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器模型也被用于其他领域和序列数据，例如电子健康记录（Li et al., 2020）、蛋白质结构预测（Jumpter et al., 2021）和时间序列异常检测（Xu
    et al., 2021）。
- en: Generative modeling is another important concept in machine learning modeling
    for which transformers and CNNs have been successfully used. Examples of such
    models are different versions of GPT, such as GPT-4 ([https://openai.com/product/gpt-4](https://openai.com/product/gpt-4)).
    You will learn about generative modeling in [*Chapter 14*](B16369_14.xhtml#_idTextAnchor379),
    *Introduction to* *Recent Advancements in Machine Learning*. There is an open
    **Large Language Model** (**LLM**) leaderboard that provides a list of up-to-date
    open source LLM models ([https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)).
    You can also check the list of practical guide resources for LLMs at [https://github.com/Mooler0410/LLMsPracticalGuide](https://github.com/Mooler0410/LLMsPracticalGuide).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型是机器学习建模中另一个重要的概念，变压器和CNNs已经成功地被用于此类模型。此类模型的例子包括GPT的不同版本，如GPT-4 ([https://openai.com/product/gpt-4](https://openai.com/product/gpt-4))。你将在[*第14章*](B16369_14.xhtml#_idTextAnchor379)，“机器学习最新进展导论”中了解生成模型。有一个公开的**大型语言模型**（**LLM**）排行榜，提供了最新的开源LLM模型列表([https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard))。你还可以查看LLMs的实用指南资源列表[https://github.com/Mooler0410/LLMsPracticalGuide](https://github.com/Mooler0410/LLMsPracticalGuide)。
- en: 'We don’t want to get into the theoretical details behind transformers, but
    you will learn about the components of a transformer architecture while building
    one in PyTorch. However, other widely used performance measures are used in sequence
    data and language modeling, such as the following:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不想深入探讨变压器背后的理论细节，但你在用PyTorch构建一个变压器架构的过程中，将会了解其组成部分。然而，其他广泛使用的性能指标也被用于序列数据和语言模型，例如以下内容：
- en: '**Perplexity** ([https://torchmetrics.readthedocs.io/en/stable/text/perplexity.html](https://torchmetrics.readthedocs.io/en/stable/text/perplexity.html))'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**困惑度** ([https://torchmetrics.readthedocs.io/en/stable/text/perplexity.html](https://torchmetrics.readthedocs.io/en/stable/text/perplexity.html))'
- en: '**Bilingual Evaluation Understudy** (**BLEU**)**score** ([https://torchmetrics.readthedocs.io/en/stable/text/bleu_score.html](https://torchmetrics.readthedocs.io/en/stable/text/bleu_score.html))'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BLEU**评分（**Bilingual Evaluation Understudy**）([https://torchmetrics.readthedocs.io/en/stable/text/bleu_score.html](https://torchmetrics.readthedocs.io/en/stable/text/bleu_score.html))'
- en: '**Recall-Oriented Understudy for Gisting Evaluation** (**ROUGE**)**score**
    ([https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html](https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html))'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ROUGE**评分（**Recall-Oriented Understudy for Gisting Evaluation**）([https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html](https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html))'
- en: These measures help you in evaluating your sequence models.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标可以帮助你评估你的序列模型。
- en: Tokenization
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分词
- en: Before training and testing transformer models, we need to transform the data
    into the right format through a process called tokenization. Tokenization is about
    chunking data into smaller pieces such as words, as in **word tokenization**,
    or characters, as in **character tokenization**. For example, the sentence “I
    like reading books” can be transformed into its contained words – that is, [“I,”
    “like,” “reading,” “books”]. When building a tokenizer, the maximum number of
    allowed tokens needs to be specified. For example, for a tokenizer with 1,000
    tokens, the most frequent 1,000 words get used as tokens from a text provided
    to build the tokenizer. Then, each token will be one of those 1,000 most frequent
    tokens. After this, these tokens each get an ID; these numbers will be used later
    by neural network models for training and testing. The words and characters outside
    of the tokens of a tokenizer get a common value of, for example, 0 or 1\. Another
    challenge in text tokenization is the different lengths of statements and sequences
    of words. To handle this challenge, a common ID, such as 0, is used before or
    after the IDs of tokens of words in each sequence of words or sentences in a process
    called padding.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练和测试 transformer 模型之前，我们需要通过一个称为分词的过程将数据转换成正确的格式。分词是将数据分成更小的片段，如单词，如在**单词分词**中，或者字符，如在**字符分词**中。例如，句子“我喜欢读书”可以被转换成其包含的单词——即[“我”，“喜欢”，“读书”，“书籍”]。在构建分词器时，需要指定允许的最大标记数。例如，对于一个有
    1,000 个标记的分词器，最频繁的 1,000 个单词将从提供给构建分词器的文本中用作标记。然后，每个标记将是这 1,000 个最频繁标记中的一个。之后，这些标记每个都会得到一个
    ID；这些数字将在之后的神经网络模型训练和测试中使用。分词器标记之外的字词和字符会得到一个共同的值，例如，0 或 1。在文本分词中，另一个挑战是语句和单词序列的不同长度。为了应对这一挑战，在称为填充的过程中，通常会在每个单词序列或句子中的标记
    ID 之前或之后使用一个共同的 ID，例如 0。
- en: The recent LLMs have different numbers of tokens in their tokenization process.
    For example, the **gpt-4-32k** model by OpenAI offers 32,000 tokens ([https://help.openai.com/en/articles/7127966-what-is-the-difference-between-the-gpt-4-models](https://help.openai.com/en/articles/7127966-what-is-the-difference-between-the-gpt-4-models)),
    while Claude’s LLM offers 100k tokens ([https://www.anthropic.com/index/100k-context-windows](https://www.anthropic.com/index/100k-context-windows)).
    The difference in the number of tokens could impact the performance of the models
    in terms of the corresponding text-related tasks.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 近期的大型语言模型（LLM）在分词过程中的标记数不同。例如，OpenAI 的 **gpt-4-32k** 模型提供 32,000 个标记 ([https://help.openai.com/en/articles/7127966-what-is-the-difference-between-the-gpt-4-models](https://help.openai.com/en/articles/7127966-what-is-the-difference-between-the-gpt-4-models))，而
    Claude 的 LLM 提供 100k 个标记 ([https://www.anthropic.com/index/100k-context-windows](https://www.anthropic.com/index/100k-context-windows))。标记数的差异可能会影响模型在相应文本相关任务中的性能。
- en: There are commonly used libraries for tokenization, such as Hugging Face’s transformer
    ([https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html](https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html)),
    SpaCy ([https://spacy.io/](https://spacy.io/)), and NLTK ([https://www.nltk.org/api/nltk.tokenize.html](https://www.nltk.org/api/nltk.tokenize.html)).
    Let’s practice with Hugging Face’s transformer library to better understand how
    tokenization works.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的分词库包括 Hugging Face 的 transformer ([https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html](https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html))、SpaCy
    ([https://spacy.io/](https://spacy.io/)) 和 NLTK ([https://www.nltk.org/api/nltk.tokenize.html](https://www.nltk.org/api/nltk.tokenize.html))。让我们通过练习
    Hugging Face 的 transformer 库来更好地理解分词是如何工作的。
- en: 'First, let’s import `transformers.AutoTokenizer()` and then load the `bert-base-cased`
    and `gpt2` pre-trained tokenizers:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入 `transformers.AutoTokenizer()` 并加载 `bert-base-cased` 和 `gpt2` 预训练的分词器：
- en: '[PRE4]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To practice with these two tokenizers, we must make a list of two statements
    to use in the tokenization process:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了练习这两个分词器，我们必须制作一个包含两个语句的列表，用于分词过程：
- en: '[PRE5]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then, we must use each of the loaded tokenizers to tokenize and encode these
    two statements to the corresponding lists of IDs. First, let’s use `gpt2`, as
    follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须使用每个加载的分词器对这两个语句进行分词和编码，以得到相应的 ID 列表。首先，让我们使用 `gpt2`，如下所示：
- en: '[PRE6]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The preceding code converts these two statements into the following two-dimensional
    lists, which include IDs for each of the tokens in each statement. For example,
    as both statements start with “I,” the first ID for both of them is 40, which
    is the token for “I” in the `gpt2` tokenizer:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将这些两个语句转换成以下二维列表，其中包含每个语句中每个标记的ID。例如，由于这两个语句都以“I”开头，因此它们的第一ID都是40，这是`gpt2`分词器中“I”的标记：
- en: '[PRE7]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, we will use `bert-base-cased`, but this time, we will ask the tokenizer
    to also use padding to generate lists of IDs of the same length and return the
    generated IDs in tensor format, which is suitable for use later in neural network
    modeling, such as using PyTorch:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用`bert-base-cased`，但这次，我们将要求分词器也使用填充来生成相同长度的ID列表，并以张量格式返回生成的ID，这对于后续在神经网络建模中使用，例如使用PyTorch，是合适的：
- en: '[PRE8]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following tensor shows the same length for the generated IDs for both sentences:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下张量显示了生成的两个句子ID的长度相同：
- en: '[PRE9]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can also use decoding functionality from each of these tokenizers to convert
    the IDs back into the original statements. First, we must decode the generated
    IDs using `gpt2`:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用这些分词器的解码功能将ID转换回原始语句。首先，我们必须使用`gpt2`解码生成的ID：
- en: '[PRE10]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This generates the following statements, which match the original input statements:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了以下语句，这些语句与原始输入语句相匹配：
- en: '[PRE11]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'However, let’s say we use the `bert-base-cased` tokenizer for decoding the
    IDs, as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，假设我们使用`bert-base-cased`分词器进行ID解码，如下所示：
- en: '[PRE12]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The resulting statements not only contain the original statements but also
    show how a padding token is decoded. This is shown as `[PAD]`, `[CLS]`, which
    is equivalent to the start of a sentence, and `[SEP]`, which shows where another
    second sentence starts:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的语句不仅包含原始语句，还显示了填充标记的解码方式。这显示为`[PAD]`、`[CLS]`，这相当于句子的开始，以及`[SEP]`，它显示了另一个句子开始的位置：
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Language embedding
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言嵌入
- en: We can transform the identified IDs per word, or sentence if we tokenize sentences
    and statements, into more information-rich embeddings. The IDs themselves can
    be used as one-hot encodings, as discussed in [*Chapter 4*](B16369_04.xhtml#_idTextAnchor159),
    *Detecting Performance and Efficiency Issues in Machine Learning Models*, where
    each word gets a long vector with zeros for all elements and one for the token
    dedicated to the corresponding word. But these one-hot encodings don’t provide
    us with any relationship between the words that work like data points in language
    modeling at the word level.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将每个单词的识别ID转换成更信息丰富的嵌入。这些ID本身可以用作one-hot编码，如在第[*第4章*](B16369_04.xhtml#_idTextAnchor159)中讨论的，*检测机器学习模型的性能和效率问题*，其中每个单词都得到一个所有元素为零、对应单词的标记为1的长向量。但这些one-hot编码并没有提供任何关于单词之间关系的信息，这些关系在语言建模的单词级别上类似于数据点。
- en: We can transform the words in a vocabulary into embeddings that can be used
    to capture semantic relationships between them and help our machine learning and
    deep learning models benefit from the new information-rich features across different
    language modeling tasks. Although models such as BERT and GPT-2 are not designed
    solely for embedding extraction for text, they can be used to generate embeddings
    for each word in a corpus of text. But there are other older methods such as Word2Vec
    (Mikolov et al., 2013), GloVe (Pennington et al., 2014), and fast-text (Bojanowski
    et al., 2017) that are designed for embedding generation. There are also more
    recent and more comprehensive models for word embedding such as Cohere ([https://txt.cohere.com/embedding-archives-wikipedia/](https://txt.cohere.com/embedding-archives-wikipedia/))
    that you can use to generate embeddings for text, in different languages, that
    you aim to embed and use for modeling.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将词汇表中的单词转换为嵌入，这些嵌入可以用来捕捉它们之间的语义关系，并帮助我们的机器学习和深度学习模型从不同语言建模任务中的新信息丰富的特征中受益。尽管BERT和GPT-2等模型并非专为文本嵌入提取而设计，但它们可以用来为文本语料库中的每个单词生成嵌入。但还有其他一些较老的方法，如Word2Vec（Mikolov等人，2013年）、GloVe（Pennington等人，2014年）和fast-text（Bojanowski等人，2017年），它们是为嵌入生成而设计的。还有更多最近且更全面的词嵌入模型，如Cohere（[https://txt.cohere.com/embedding-archives-wikipedia/](https://txt.cohere.com/embedding-archives-wikipedia/)），您可以使用它来生成文本嵌入，用于嵌入和建模的不同语言。
- en: Language modeling using pre-trained models
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用预训练模型进行语言建模
- en: There are pre-trained models that we can import into different deep learning
    frameworks, such as PyTorch, to use solely for inference or further fine-tuning
    with new data. Here, we want to practice this process with DistilBERT (Sanh et
    al., 2019), which is a faster and lighter version of BERT (Devlin et al., 2018).
    Specifically, we want to use `DistilBertForSequenceClassification()`, a model
    based on the DistilBERT architecture, that’s been adapted for sequence classification
    tasks. In such processes, the model gets trained and can be used for inference
    for the task of assigning a label to a given sentence or statement. Examples of
    such label assignments are spam detection or semantic labeling, such as positive,
    negative, and neutral.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将预训练模型导入到不同的深度学习框架中，例如PyTorch，仅用于推理或使用新数据进行进一步的微调。在这里，我们想用DistilBERT（Sanh
    et al., 2019）来练习这个过程，它是BERT（Devlin et al., 2018）的一个更快、更轻量级的版本。具体来说，我们想使用基于DistilBERT架构的`DistilBertForSequenceClassification()`模型，该模型已被调整为用于序列分类任务。在这些过程中，模型会被训练并可用于对给定句子或陈述分配标签的任务的推理。此类标签分配的例子包括垃圾邮件检测或语义标记，如正面、负面和中立。
- en: 'First, we will import the necessary libraries and classes from `torch` and
    `transformers`:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将从`torch`和`transformers`库中导入必要的库和类：
- en: '[PRE14]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, we will load the `imdb` dataset so that we can use it to train a model,
    as a fine-tuned version of `DistilBertForSequenceClassification()`:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将加载`imdb`数据集，以便我们可以使用它来训练一个模型，作为一个微调版本的`DistilBertForSequenceClassification()`：
- en: '[PRE15]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, we can define a tokenizer function on top of the `DistilBertTokenizerFast()`
    tokenizer with `distilbert-base-uncased` as the pre-trained tokenizer:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在`DistilBertTokenizerFast()`分词器的基础上定义一个分词器函数，其中使用`distilbert-base-uncased`作为预训练的分词器：
- en: '[PRE16]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'After, we can separate a small percentage (1%) of the `imdb` data for training
    and testing as we want to solely practice with this process, and using the whole
    dataset takes a long time in terms of training and testing:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将`imdb`数据集的一小部分（1%）分离出来用于训练和测试，因为我们只想练习这个过程，而使用整个数据集在训练和测试方面需要花费很长时间：
- en: '[PRE17]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we can initialize the `DistilBertForSequenceClassification()` model while
    specifying the number of labels in the classification process. Here, this is `2`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在分类过程中指定标签的数量来初始化`DistilBertForSequenceClassification()`模型。这里，这是`2`：
- en: '[PRE18]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, we can train the model using separate training data from the `imdb` dataset
    for `3` epochs:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`imdb`数据集的独立训练数据来训练模型，进行`3`个epoch的训练：
- en: '[PRE19]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'With that, the model has been trained and we can evaluate it on the separate
    test set from the `imdb` dataset:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，模型就已经训练好了，我们可以使用`imdb`数据集的独立测试集来评估它：
- en: '[PRE20]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This results in a 0.35 evaluation loss.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了0.35的评估损失。
- en: 'There are many other available models you can use in your language modeling
    or inference tasks (for example, the PyTorch Transformers library: [https://pytorch.org/hub/huggingface_pytorch-transformers/](https://pytorch.org/hub/huggingface_pytorch-transformers/)).
    There are also other sequence models, outside of language modeling, for areas
    such as the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的语言建模或推理任务中，有许多其他可用的模型可以使用（例如，PyTorch Transformers库：[https://pytorch.org/hub/huggingface_pytorch-transformers/](https://pytorch.org/hub/huggingface_pytorch-transformers/)）。还有其他序列模型，除了语言建模之外，适用于以下领域：
- en: 'Audio modeling: [https://pytorch.org/audio/main/models.html](https://pytorch.org/audio/main/models.html)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频建模：[https://pytorch.org/audio/main/models.html](https://pytorch.org/audio/main/models.html)
- en: 'Time-series modeling: [https://huggingface.co/docs/transformers/model_doc/time_series_transformer](https://huggingface.co/docs/transformers/model_doc/time_series_transformer)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列建模：[https://huggingface.co/docs/transformers/model_doc/time_series_transformer](https://huggingface.co/docs/transformers/model_doc/time_series_transformer)
- en: 'Forecasting: [https://pytorch-forecasting.readthedocs.io/en/stable/models.html](https://pytorch-forecasting.readthedocs.io/en/stable/models.html)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测：[https://pytorch-forecasting.readthedocs.io/en/stable/models.html](https://pytorch-forecasting.readthedocs.io/en/stable/models.html)
- en: 'Video modeling: [https://pytorchvideo.org/](https://pytorchvideo.org/))'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频建模：[https://pytorchvideo.org/](https://pytorchvideo.org/))
- en: You can learn more about transformer modeling and how to make new architectures
    from scratch instead of using pre-trained models in PyTorch at [https://pytorch.org/tutorials/beginner/transformer_tutorial.html](https://pytorch.org/tutorials/beginner/transformer_tutorial.html).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://pytorch.org/tutorials/beginner/transformer_tutorial.html](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)了解更多关于transformer建模以及如何在PyTorch中从头开始构建新架构，而不是使用预训练模型。
- en: In this section, you learned about modeling text as one type of sequence data.
    Next, we will cover modeling graphs, which are more complex data structures.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你学习了将文本建模为一种序列数据类型。接下来，我们将介绍建模图，这是一种更复杂的数据结构。
- en: Modeling graphs using deep neural networks
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度神经网络建模图
- en: 'We can consider graphs as a more general structure of almost all non-tabular
    data we use for machine learning and deep learning modeling. Sequences can be
    considered **one-dimensional** (**1D**), while images or image shape data can
    be considered **two-dimensional** (**2D**) (see *Figure 13**.7*). Earlier in this
    chapter, you learned how to start benefiting from CNNs and transformers in Python
    and PyTorch for sequence and image shape data. But more general graphs don’t fit
    into these two graphs, which have predefined structures (see *Figure 13**.7*),
    and we cannot simply model them using CNNs or sequence models:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将图视为我们用于机器学习和深度学习建模的几乎所有非表格数据的更通用结构。序列可以被认为是**一维的**（1D），而图像或图像形状数据可以被认为是**二维的**（2D）（参见*图
    13.7*）。在本章的早期，你学习了如何在 Python 和 PyTorch 中开始从 CNN 和变压器中受益，用于序列和图像形状数据。但更通用的图不适用于这些两个图，它们具有预定义的结构（参见*图
    13.7*），我们不能简单地使用 CNN 或序列模型来建模它们：
- en: '![Figure 13.7 – Graph representation of different unstructured data types](img/B16369_13_07.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.7 – 不同非结构化数据的图表示](img/B16369_13_07.jpg)'
- en: Figure 13.7 – Graph representation of different unstructured data types
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 – 不同非结构化数据的图表示
- en: 'Graphs have two important elements, called nodes and edges. The edges connect
    the nodes. The nodes and edges of graphs can have different characteristics that
    differentiate them from each other (see *Figure 13**.8*):'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图有两个重要的元素，称为节点和边。边连接节点。图中的节点和边可以具有不同的特征，这些特征将它们彼此区分开来（参见*图 13.8*）：
- en: '![Figure 13.8 – Graph types according to their node and edge characteristics](img/B16369_13_08.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.8 – 根据节点和边特征分类的图类型](img/B16369_13_08.jpg)'
- en: Figure 13.8 – Graph types according to their node and edge characteristics
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.8 – 根据节点和边特征分类的图类型
- en: We can have graphs where nodes have features, edges have weights or features,
    or edges have directions. Undirected graphs (graphs with undirected edges), for
    example, are useful for many applications, such as social media networks. Assuming
    each node in the graph of social media is a node, then the edges can determine
    which people are connected. The features of nodes in such graphs could be different
    characteristics of people in the social media network, such as their age, field
    of study or job title, city of residence, and so on. Directed graphs can be used
    in different applications, such as for causal modeling, which we’ll discuss in
    [*Chapter 15*](B16369_15.xhtml#_idTextAnchor406), *Correlation* *versus Causality*.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以有节点具有特征、边具有权重或特征，或者边具有方向的图。无向图（具有无向边的图）在许多应用中很有用，例如社交媒体网络。假设社交媒体图中的每个节点都是一个节点，那么边可以确定哪些人相连。此类图中的节点特征可以是社交媒体网络中人们的不同特征，例如他们的年龄、研究领域或职称、居住城市等。有向图可用于不同的应用，例如因果建模，我们将在[*第
    15 章*](B16369_15.xhtml#_idTextAnchor406) *相关性* *与因果关系* 中讨论。
- en: As mentioned at the beginning of this section, techniques such as CNNs and transformers
    cannot be used directly on graphs. Due to this, we’ll review other neural network
    techniques that can help you in modeling graphs in your projects.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如本节开头所述，CNN 和变压器等技术不能直接应用于图。因此，我们将回顾其他神经网络技术，这些技术可以帮助你在项目中建模图。
- en: Graph neural networks
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图神经网络
- en: Graphs may have complicated structures as opposed to 2D images and 1D sequence
    data. However, we can model them using deep neural networks with the same idea
    as in CNNs and transformer models to rely on local patterns and relationships
    in the data. We can rely on local patterns in graphs and let the neural network
    learn from neighboring nodes instead of trying to learn information about the
    whole graph, which might contain thousands of nodes and millions of edges all
    at once. This is the idea behind **graph neural** **networks** (**GNNs**).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 与 2D 图像和 1D 序列数据相比，图可能具有更复杂的结构。然而，我们可以使用与 CNN 和变压器模型相同的理念，通过依赖数据中的局部模式和关系来建模它们。我们可以在图中依赖局部模式，让神经网络从相邻节点中学习，而不是试图学习关于整个图的信息，这个图可能包含成千上万的节点和数百万的边。这就是**图神经网络**（GNNs）背后的理念。
- en: 'We can use GNNs for different tasks, such as the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 GNNs（图神经网络）来完成不同的任务，例如以下内容：
- en: '**Node classification**: We can aim to predict the class of each node in a
    graph using GNNs. For example, if you consider a graph of hotels in a city with
    edges being the shortest route between them, you can aim to predict which one
    gets filled in during the holidays. Or if you have a background in chemistry,
    you can use node classification to annotate amino acids in proteins using the
    3D structure of proteins (Abdollahi et al., 2023).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点分类**：我们可以通过使用图神经网络（GNNs）来预测图中每个节点的类别。例如，如果你考虑一个城市中酒店的图，其中边是它们之间的最短路径，你可以预测在假期期间哪个酒店会被预订。或者如果你有化学背景，你可以使用节点分类来注释蛋白质中的氨基酸，使用蛋白质的3D结构（Abdollahi等人，2023年）。'
- en: '**Node selection**: Node selection for GNNs is a similar task to object detection
    for CNNs. We can design GNNs to identify and select nodes with specific characteristics,
    such as choosing people to suggest a product to in a graph of products and consumers.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点选择**：对于GNNs的节点选择与CNNs的对象检测任务类似。我们可以设计GNNs来识别和选择具有特定特征的节点，例如在产品与消费者图中选择推荐产品的人。'
- en: '**Link prediction**: We can aim to predict unknown edges between already existing
    nodes or new nodes in a graph. For example, in a graph that’s representative of
    a social media network, link prediction could be about predicting connections
    between people. Then, those individuals could be suggested to each other so that
    they can add each other to their networks of connections.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**链接预测**：我们可以旨在预测已存在节点或图中新节点之间的未知边。例如，在一个代表社交媒体网络的图中，链接预测可能是预测人与人之间的联系。然后，这些个人可以被推荐给对方，以便他们可以将彼此添加到他们的联系网络中。'
- en: '**Graph classification**: Instead of aiming to predict or select nodes or edges,
    we can design GNNs to predict the characteristics of whole graphs ([https://chrsmrrs.github.io/datasets/](https://chrsmrrs.github.io/datasets/)).
    In such cases, there could be graphs where each represents a data point, such
    as a drug molecule to be used in a GNN model for graph classification.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图分类**：我们不是旨在预测或选择节点或边，而是可以设计GNNs来预测整个图的特征（[https://chrsmrrs.github.io/datasets/](https://chrsmrrs.github.io/datasets/)）。在这种情况下，可能会有代表数据点的图，例如用于图分类GNN模型的药物分子。'
- en: There are general taxonomies of different GNNs, such as the one suggested by
    Wu et al. (2020). But here, we want to focus on examples of widely used methods
    instead of getting too technical regarding the different categories of GNNs. Examples
    of methodologies that have been used successfully for modeling graphs are **Graph
    Convolutional Networks** (**GCNs**) (Kipf and Welling in 2016), **Graph Sample
    and Aggregation** (**GraphSAGE**) (Hamilton et al. in 2017), and **Graph Attention
    Networks** (**GATs**) (Veličković et al. in 2018). While most GNN techniques consider
    features for nodes, not all of them consider edge features. **Message Passing
    Neural Networks** (**MPNNs**) is an example of a technique that considers both
    node and edge features and was initially designed for producing graphs of drug
    molecules (Gilmer et al. in 2017).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 存在着不同GNNs的一般分类法，例如Wu等人（2020年）提出的分类法。但在这里，我们想专注于广泛使用的方法的例子，而不是过于技术性地涉及GNNs的不同类别。成功用于建模图的方
    法的例子包括**图卷积网络**（**GCNs**）（Kipf和Welling在2016年），**图样本和聚合**（**GraphSAGE**）（Hamilton等人，2017年），以及**图注意力网络**（**GATs**）（Veličković等人，2018年）。虽然大多数GNN技术考虑节点的特征，但并非所有都考虑边特征。**消息传递神经网络**（**MPNNs**）是一种考虑节点和边特征的技术示例，最初是为生成药物分子的图而设计的（Gilmer等人，2017年）。
- en: You can build graphs from the data you have at hand or use publicly available
    datasets such as **Stanford Large Network Dataset Collection** (**SNAP**) to practice
    with different GNN techniques. SNAP has one of the largest collections of graph
    datasets you can download and start practicing with ([https://snap.stanford.edu/data/](https://snap.stanford.edu/data/)).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从手头的数据构建图，或者使用公开可用的数据集，如**斯坦福大型网络数据集收集**（**SNAP**）来练习不同的GNN技术。SNAP拥有你可以下载并开始练习的最大的图数据集之一（[https://snap.stanford.edu/data/](https://snap.stanford.edu/data/)）。
- en: Next, we will practice GNN modeling using PyTorch to help you better understand
    how to build such models in Python.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用PyTorch练习GNN建模，以帮助你更好地理解如何在Python中构建此类模型。
- en: GNNs with PyTorch Geometric
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyTorch Geometric中的GNNs
- en: 'PyTorch Geometric is a Python library built upon PyTorch that helps you train
    and test GNNs. There is a series of tutorials you can benefit from to learn about
    GNN modeling using PyTorch Geometric ([https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html](https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html)).
    Here, we will practice the problem of node classification with code adapted from
    one of these tutorials ([https://colab.research.google.com/drive/14OvFnAXgg     xB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=0YgHcLXMLk4o](https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=0YgHcLXMLk4o)).'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Geometric 是一个基于 PyTorch 的 Python 库，它帮助您训练和测试 GNN。有一系列教程您可以从中受益，了解如何使用
    PyTorch Geometric 进行 GNN 建模（[https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html](https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html)）。在这里，我们将通过改编自这些教程之一的代码来练习节点分类问题（[https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=0YgHcLXMLk4o](https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=0YgHcLXMLk4o)）。
- en: 'First, let’s import the *CiteSeer* citation network dataset from `Planetoid`
    in PyTorch Geometric (Yang et al., 2016):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们从 PyTorch Geometric 中的 `Planetoid` 导入 *CiteSeer* 引用网络数据集（Yang et al.,
    2016）：
- en: '[PRE21]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, similar to initializing neural networks for FCNNs and CNNs, we must initialize
    a `GCNet` class for GNN modeling, but instead of using linear and convolutional
    layers, we will use `GCNConv` graph convolutional layers:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，类似于初始化 FCNN 和 CNN 的神经网络，我们必须为 GNN 建模初始化一个 `GCNet` 类，但我们将使用 `GCNConv` 图卷积层而不是线性层和卷积层：
- en: '[PRE22]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In the previous class, we used three `GCNConv` layers in combination with the
    ReLU activation function and dropout for regularization.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节课中，我们使用了三个 `GCNConv` 层，结合 ReLU 激活函数和 dropout 进行正则化。
- en: 'Now, we can use the defined `GCNet` class to initialize our model with hidden
    layers whose sizes are 128 and 16, both of which are arbitrary in this practice
    code. We must also initialize an optimizer while specifying the algorithm, which
    in this case is `Adam`, and a learning rate of `0.01` and a weight decay of `1e-4`
    for regularization:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用定义的 `GCNet` 类来初始化我们的模型，其隐藏层的大小为 128 和 16，在这段实践代码中都是任意的。我们还需要在指定算法的同时初始化一个优化器，在这个例子中是
    `Adam`，学习率为 `0.01`，权重衰减为 `1e-4` 以进行正则化：
- en: '[PRE23]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, we can define our training function, which will be used for one-epoch
    training:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以定义我们的训练函数，它将被用于单 epoch 训练：
- en: '[PRE24]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'With that, we are ready to go through a series of epochs and train the model.
    Please note that the following loop for training the model for 400 epochs might
    take a long time:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就准备好了一系列的 epoch 并开始训练模型。请注意，以下用于训练模型 400 个 epoch 的循环可能需要很长时间：
- en: '[PRE25]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following plot shows the learning curve (loss versus epoch) in the training
    process:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图显示了训练过程中的学习曲线（损失与 epoch 的关系）：
- en: '![Figure 13.9 – The learning curve for the example GCN model on the CiteSeer
    dataset](img/B16369_13_09.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.9 – 在 CiteSeer 数据集上示例 GCN 模型的学习曲线](img/B16369_13_09.jpg)'
- en: Figure 13.9 – The learning curve for the example GCN model on the CiteSeer dataset
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.9 – 在 CiteSeer 数据集上示例 GCN 模型的学习曲线
- en: 'We can also test the model on the test portion of the dataset, as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在数据集的测试部分测试模型，如下所示：
- en: '[PRE26]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This results in an accuracy of 0.655\. We can also generate a confusion matrix
    of the predictions on the test set:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致准确率为 0.655。我们还可以生成测试集上预测的混淆矩阵：
- en: '[PRE27]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This results in the following matrix, shown as a heatmap. Although most of
    the predictions and true classes of data points match, many of them are misclassified
    and summarized outside of the diagonal elements of the confusion matrix:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下矩阵，以热图的形式展示。尽管大多数数据点的预测和真实类别匹配，但其中许多被错误分类，并且总结在混淆矩阵的对角线元素之外：
- en: '![Figure 13.10 – Confusion matrix of the predictions over the test set for
    the example GCN model on the CiteSeer dataset](img/B16369_13_010.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.10 – 在 CiteSeer 数据集上示例 GCN 模型的测试集预测混淆矩阵](img/B16369_13_010.jpg)'
- en: Figure 13.10 – Confusion matrix of the predictions over the test set for the
    example GCN model on the CiteSeer dataset
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.10 – 在 CiteSeer 数据集上示例 GCN 模型的测试集预测混淆矩阵
- en: In this section, we talked about techniques for modeling different data types
    and problems using deep learning. Now, you are ready to learn more about these
    advanced techniques and use them in your projects.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了使用深度学习建模不同数据类型和问题的技术。现在，你准备好学习更多关于这些高级技术并在你的项目中使用它们了。
- en: Summary
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about advanced deep learning techniques, including
    CNNs, transformers, and GNNs. You were provided with some of the widely used or
    famous models that have been developed using each of these techniques. You also
    practiced building these advanced models either from scratch or fine-tuning them
    using Python and PyTorch. This knowledge helped you learn more about these techniques
    and start using them in your projects so that you can model images and image shape
    data, text and sequence data, and graphs.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了高级深度学习技术，包括卷积神经网络（CNNs）、转换器（transformers）和图神经网络（GNNs）。你了解了一些使用这些技术开发的广泛使用或著名的模型。你还练习了使用Python和PyTorch从头开始构建这些高级模型或微调它们。这些知识帮助你更深入地了解这些技术，并在你的项目中开始使用它们，以便你可以对图像和图像形状数据进行建模，对文本和序列数据进行建模，以及对图进行建模。
- en: In the next chapter, you will learn how recent advancements in generative modeling
    and prompt engineering, as well as self-supervised learning, can either help you
    in developing your projects or provide you with opportunities to develop interesting
    and useful tools and applications.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习到最近在生成建模和提示工程以及自监督学习方面的进展，这些进展将帮助你开发项目或为你提供开发有趣和有用的工具和应用程序的机会。
- en: Questions
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are some examples of problems you can use CNNs and GNNs for?
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用CNNs和GNNs解决哪些问题的示例？
- en: Does applying convolution preserve local patterns in images?
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用卷积是否可以保留图像中的局部模式？
- en: Could decreasing the number of tokens result in more mistakes in language models?
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 减少标记数是否会导致语言模型中的错误更多？
- en: What is padding in the text tokenization process?
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本标记过程中的填充（padding）是什么？
- en: Are the network architecture classes we build for CNNs and GNNs in PyTorch similar?
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在PyTorch中为CNNs和GNNs构建的网络架构类是否相似？
- en: When do you need edge features to build GNNs?
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在构建GNNs时，何时需要边缘特征？
- en: References
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: He, Kaiming, et al. *Deep residual learning for image recognition*. Proceedings
    of the IEEE conference on computer vision and pattern recognition. 2016.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He, Kaiming等人。*用于图像识别的深度残差学习*。IEEE计算机视觉和模式识别会议论文集。2016年。
- en: 'Tan, Mingxing, and Quoc Le. *Efficientnet: Rethinking model scaling for convolutional
    neural networks*. International conference on machine learning. PMLR, 2019.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan, Mingxing和Quoc Le. *Efficientnet：重新思考卷积神经网络的模型缩放*。机器学习国际会议。PMLR，2019年。
- en: 'Howard, Andrew G., et al. *Mobilenets: Efficient convolutional neural networks
    for mobile vision applications*. arXiv preprint arXiv:1704.04861 (2017).'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Howard, Andrew G.等人。*Mobilenets：用于移动视觉应用的效率卷积神经网络*。arXiv预印本arXiv:1704.04861（2017年）。
- en: 'Sandler, Mark, et al. *Mobilenetv2: Inverted residuals and linear bottlenecks*.
    Proceedings of the IEEE conference on computer vision and pattern recognition.
    2018.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sandler, Mark等人。*Mobilenetv2：倒置残差和线性瓶颈*。IEEE计算机视觉和模式识别会议论文集。2018年。
- en: 'Chollet, François. *Xception: Deep learning with depthwise separable convolutions*.
    Proceedings of the IEEE conference on computer vision and pattern recognition.
    2017.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chollet, François。*Xception：使用深度可分离卷积的深度学习*。IEEE计算机视觉和模式识别会议论文集。2017年。
- en: 'Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. *U-net: Convolutional
    networks for biomedical image segmentation*. Medical Image Computing and Computer-Assisted
    Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October
    5-9, 2015, Proceedings, Part III 18\. Springer International Publishing, 2015.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ronneberger, Olaf，Philipp Fischer和Thomas Brox. *U-net：用于生物医学图像分割的卷积网络*。医学图像计算和计算机辅助干预（MICCAI
    2015）：第18届国际会议，德国慕尼黑，2015年10月5-9日，第III部分18。Springer国际出版社，2015年。
- en: He, Kaiming, et al. *Mask r-cnn*. Proceedings of the IEEE international conference
    on computer vision. 2017.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He, Kaiming等人。*Mask r-cnn*。IEEE国际计算机视觉会议。2017年。
- en: 'Chen, Liang-Chieh, et al. *Deeplab: Semantic image segmentation with deep convolutional
    nets, atrous convolution, and fully connected crfs*. IEEE transactions on pattern
    analysis and machine intelligence 40.4 (2017): 834-848.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen, Liang-Chieh等人。*Deeplab：使用深度卷积网络、扩张卷积和全连接crfs进行语义图像分割*。IEEE模式分析杂志第40卷第4期（2017年）：834-848。
- en: Zhao, Hengshuang, et al. *Pyramid scene parsing network*. Proceedings of the
    IEEE conference on computer vision and pattern recognition. 2017.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao, Hengshuang等人。*金字塔场景解析网络*。IEEE计算机视觉和模式识别会议论文集。2017年。
- en: 'Ren, Shaoqing, et al. *Faster r-cnn: Towards real-time object detection with
    region proposal networks*. Advances in neural information processing systems 28
    (2015).'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ren, Shaoqing等人。*Faster r-cnn：使用区域提议网络的实时目标检测*。神经信息处理系统进展第28卷（2015年）。
- en: 'Redmon, Joseph, et al. *You only look once: Unified, real-time object detection*.
    Proceedings of the IEEE conference on computer vision and pattern recognition.
    2016.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redmon, Joseph, et al. *一次检测：统一、实时目标检测*. IEEE计算机视觉与模式识别会议论文集。2016.
- en: 'Dong, Chao, et al. *Image super-resolution using deep convolutional networks*.
    IEEE transactions on pattern analysis and machine intelligence 38.2 (2015): 295-307.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dong, Chao, et al. *使用深度卷积网络进行图像超分辨率*. IEEE模式分析杂志 38.2 (2015): 295-307.'
- en: 'Dong, Chao, Chen Change Loy, and Xiaoou Tang. *Accelerating the super-resolution
    convolutional neural network*. Computer Vision–ECCV 2016: 14th European Conference,
    Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14\. Springer
    International Publishing, 2016.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong, Chao, Chen Change Loy, 和 Xiaoou Tang. *加速超分辨率卷积神经网络*. 计算机视觉–ECCV 2016：第14届欧洲会议，荷兰阿姆斯特丹，2016年10月11-14日，会议论文集第II部分
    14\. Springer International Publishing, 2016.
- en: Lim, Bee, et al. *Enhanced deep residual networks for single image super-resolution*.
    Proceedings of the IEEE conference on computer vision and pattern recognition
    workshops. 2017.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lim, Bee, et al. *用于单图像超分辨率的增强深度残差网络*. IEEE计算机视觉与模式识别会议论文集 workshops。2017.
- en: Isola, Phillip, et al. *Image-to-image translation with conditional adversarial
    networks*. Proceedings of the IEEE conference on computer vision and pattern recognition.
    2017.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Isola, Phillip, et al. *使用条件对抗网络进行图像到图像翻译*. IEEE计算机视觉与模式识别会议论文集。2017.
- en: Zhu, Jun-Yan, et al. *Unpaired image-to-image translation using cycle-consistent
    adversarial networks*. Proceedings of the IEEE international conference on computer
    vision. 2017.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu, Jun-Yan, et al. *使用循环一致对抗网络的无配对图像到图像翻译*. IEEE国际计算机视觉会议论文集。2017.
- en: Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. *Image style transfer
    using convolutional neural networks*. Proceedings of the IEEE conference on computer
    vision and pattern recognition. 2016.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gatys, Leon A., Alexander S. Ecker, 和 Matthias Bethge. *使用卷积神经网络进行图像风格迁移*. IEEE计算机视觉与模式识别会议论文集。2016.
- en: Huang, Xun, and Serge Belongie. *Arbitrary style transfer in real-time with
    adaptive instance normalization*. Proceedings of the IEEE international conference
    on computer vision. 2017.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang, Xun, 和 Serge Belongie. *实时自适应实例归一化在任意风格转换中的应用*. IEEE国际计算机视觉会议论文集。2017.
- en: 'Schlegl, Thomas, et al. *Unsupervised anomaly detection with generative adversarial
    networks to guide marker discovery*. Information Processing in Medical Imaging:
    25th International Conference, IPMI 2017, Boone, NC, USA, June 25-30, 2017, Proceedings.
    Cham: Springer International Publishing, 2017.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schlegl, Thomas, et al. *无监督异常检测与生成对抗网络引导标记发现*. 医学图像处理：第25届国际会议，IPMI 2017，美国北卡罗来纳州博恩，2017年6月25-30日，会议论文集。Cham:
    Springer International Publishing, 2017.'
- en: Ruff, Lukas, et al. *Deep one-class classification*. International conference
    on machine learning. PMLR, 2018.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ruff, Lukas, et al. *深度单类分类*. 国际机器学习会议。PMLR，2018.
- en: Zhou, Chong, and Randy C. Paffenroth. *Anomaly detection with robust deep autoencoders*.
    Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery
    and data mining. 2017.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou, Chong, 和 Randy C. Paffenroth. *使用鲁棒深度自编码器的异常检测*. 第23届ACM SIGKDD国际知识发现和数据挖掘会议论文集。2017.
- en: Baek, Youngmin, et al. *Character region awareness for text detection*. Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition. 2019.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baek, Youngmin, et al. *文本检测中的字符区域感知*. IEEE/CVF计算机视觉与模式识别会议论文集。2019.
- en: 'Zhou, Xinyu, et al. *East: an efficient and accurate scene text detector*.
    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.
    2017.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou, Xinyu, et al. *East：一种高效准确的场景文本检测器*. IEEE计算机视觉与模式识别会议论文集。2017.
- en: Tran, Du, et al. *Learning spatiotemporal features with 3d convolutional networks*.
    Proceedings of the IEEE international conference on computer vision. 2015.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tran, Du, et al. *使用3D卷积网络学习时空特征*. IEEE国际计算机视觉会议论文集。2015.
- en: Carreira, Joao, and Andrew Zisserman. *Quo vadis, action recognition? a new
    model and the kinetics dataset*. Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition. 2017.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carreira, Joao, 和 Andrew Zisserman. *动作识别何去何从？一个新的模型和Kinetics数据集*. IEEE计算机视觉与模式识别会议论文集。2017.
- en: Feichtenhofer, Christoph, et al. *Slowfast networks for video recognition*.
    Proceedings of the IEEE/CVF international conference on computer vision. 2019.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feichtenhofer, Christoph, et al. *用于视频识别的Slowfast网络*. IEEE/CVF国际计算机视觉会议论文集。2019.
- en: LeCun, Yann, et al. *Handwritten digit recognition with a back-propagation network*.
    Advances in neural information processing systems 2 (1989).
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun, Yann, 等人. *使用反向传播网络进行手写数字识别*. 神经信息处理系统进展 2 (1989).
- en: Vaswani, Ashish, et al. *Attention is all you need*. Advances in neural information
    processing systems 30 (2017).
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani, Ashish, 等人. *注意力即一切*. 神经信息处理系统进展 30 (2017).
- en: 'Devlin, Jacob, et al. *Bert: Pre-training of deep bidirectional transformers
    for language understanding*. arXiv preprint arXiv:1810.04805 (2018).'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Devlin, Jacob, 等人. *BERT: 用于语言理解的深度双向变换器预训练*. arXiv预印本 arXiv:1810.04805 (2018).'
- en: 'Touvron, Hugo, et al. *Llama: Open and efficient foundation language models*.
    arXiv preprint arXiv:2302.13971 (2023).'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron, Hugo, 等人. *Llama: 开放且高效的通用语言模型*. arXiv预印本 arXiv:2302.13971 (2023).'
- en: 'Li, Yikuan, et al. *BEHRT: transformer for electronic health records*. Scientific
    reports 10.1 (2020): 1-12.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li, Yikuan, 等人. *BEHRT: 用于电子健康记录的变换器*. 科学报告 10.1 (2020): 1-12.'
- en: 'Jumper, John, et al. *Highly accurate protein structure prediction with AlphaFold*.
    Nature 596.7873 (2021): 583-589.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jumper, John, 等人. *使用AlphaFold进行高度精确的蛋白质结构预测*. 自然 596.7873 (2021): 583-589.'
- en: 'Xu, Jiehui, et al. *Anomaly transformer: Time series anomaly detection with
    association discrepancy*. arXiv preprint arXiv:2110.02642 (2021).'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu, Jiehui, 等人. *异常变换器：基于关联差异的时间序列异常检测*. arXiv预印本 arXiv:2110.02642 (2021).
- en: 'Yuan, Li, et al. *Tokens-to-token vit: Training vision transformers from scratch
    on imagenet*. Proceedings of the IEEE/CVF international conference on computer
    vision. 2021.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan, Li, 等人. *从零开始训练图像Net上的视觉变换器：tokens-to-token vit*. 2021年IEEE/CVF国际计算机视觉会议论文集.
    2021.
- en: 'Liu, Yinhan, et al. *Roberta: A robustly optimized bert pretraining approach*.
    arXiv preprint arXiv:1907.11692 (2019).'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu, Yinhan, 等人. *Roberta: 一种鲁棒优化的BERT预训练方法*. arXiv预印本 arXiv:1907.11692 (2019).'
- en: 'Lewis, Mike, et al. *Bart: Denoising sequence-to-sequence pre-training for
    natural language generation, translation, and comprehension*. arXiv preprint arXiv:1910.13461
    (2019).'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lewis, Mike, 等人. *Bart: 用于自然语言生成、翻译和理解的去噪序列到序列预训练*. arXiv预印本 arXiv:1910.13461
    (2019).'
- en: Radford, Alec, et al. *Improving language understanding by generative* *pre-training*.
    (2018).
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford, Alec, 等人. *通过生成预训练改进语言理解*. (2018).
- en: 'Raffel, Colin, et al. *Exploring the limits of transfer learning with a unified
    text-to-text transformer*. The Journal of Machine Learning Research 21.1 (2020):
    5485-5551.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Raffel, Colin, 等人. *通过统一的文本到文本变换器探索迁移学习的极限*. 机器学习研究杂志 21.1 (2020): 5485-5551.'
- en: 'Sanh, Victor, et al. *DistilBERT, a distilled version of BERT: smaller, faster,
    cheaper and lighter*. arXiv preprint arXiv:1910.01108 (2019).'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sanh, Victor, 等人. *DistilBERT，BERT的精炼版本：更小、更快、更便宜、更轻*. arXiv预印本 arXiv:1910.01108
    (2019).
- en: 'Yang, Zhilin, et al. *Xlnet: Generalized autoregressive pretraining for language
    understanding*. Advances in neural information processing systems 32 (2019).'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang, Zhilin, 等人. *Xlnet: 用于语言理解的广义自回归预训练*. 神经信息处理系统进展 32 (2019).'
- en: Mikolov, Tomas, et al. *Efficient estimation of word representations in vector
    space*. arXiv preprint arXiv:1301.3781 (2013).
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mikolov, Tomas, 等人. *在向量空间中高效估计词表示*. arXiv预印本 arXiv:1301.3781 (2013).
- en: 'Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. *Glove: Global
    vectors for word representation*. Proceedings of the 2014 conference on empirical
    methods in natural language processing (EMNLP). 2014.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pennington, Jeffrey, Richard Socher, 和 Christopher D. Manning. *Glove: 用于词表示的全局向量*.
    2014年自然语言处理实证方法会议论文集 (EMNLP). 2014.'
- en: 'Bojanowski, Piotr, et al. *Enriching word vectors with subword information*.
    Transactions of the association for computational linguistics 5 (2017): 135-146.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bojanowski, Piotr, 等人. *通过子词信息丰富词向量*. 计算语言学协会会刊 5 (2017): 135-146.'
- en: 'Wu, Zonghan, et al. *A comprehensive survey on graph neural networks*. IEEE
    transactions on neural networks and learning systems 32.1 (2020): 4-24.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu, Zonghan, 等人. *图神经网络综述*. 电气和电子工程师协会神经网络和机器学习系统交易 32.1 (2020): 4-24.'
- en: 'Abdollahi, Nasim, et al. *NodeCoder: a graph-based machine learning platform
    to predict active sites of modeled protein structures*. arXiv preprint arXiv:2302.03590
    (2023).'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Abdollahi, Nasim, 等人. *NodeCoder: 一种基于图的机器学习平台，用于预测建模蛋白质结构的活性位点*. arXiv预印本
    arXiv:2302.03590 (2023).'
- en: Kipf, Thomas N., and Max Welling. *Semi-supervised classification with graph
    convolutional networks*. arXiv preprint arXiv:1609.02907 (2016).
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kipf, Thomas N., 和 Max Welling. *使用图卷积网络进行半监督分类*. arXiv预印本 arXiv:1609.02907
    (2016).
- en: Hamilton, Will, Zhitao Ying, and Jure Leskovec. *Inductive representation learning
    on large graphs*. Advances in neural information processing systems 30 (2017).
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hamilton, Will, Zhitao Ying, and Jure Leskovec. *在大图上进行归纳表示学习*. 神经信息处理系统进展 30
    (2017).
- en: 'Velickovic, Petar, et al. *Graph attention networks*. stat 1050.20 (2017):
    10-48550.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Velickovic, Petar, et al. *图注意力网络*. stat 1050.20 (2017): 10-48550.'
- en: Gilmer, Justin, et al. *Neural message passing for quantum chemistry*. International
    conference on machine learning. PMLR, 2017.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gilmer, Justin, et al. *神经消息传递在量子化学中的应用*. 机器学习国际会议. PMLR, 2017.
- en: Yang, Zhilin, William Cohen, and Ruslan Salakhudinov. *Revisiting semi-supervised
    learning with graph embeddings*. International conference on machine learning.
    PMLR, 2016.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang, Zhilin, William Cohen, and Ruslan Salakhudinov. *重新审视使用图嵌入的半监督学习*. 机器学习国际会议.
    PMLR, 2016.
