- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Advanced Deep Learning Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we reviewed the concept of neural network modeling
    and deep learning while focusing on fully connected neural networks. In this chapter,
    we will discuss more advanced techniques that let you use deep learning models
    across different data types and structures, such as images, texts, and graphs.
    These techniques are behind the majority of advancements across industries through
    artificial intelligence, such as in chatbots, medical diagnosis, drug discovery,
    stock trading, and fraud detection. Although we will present some of the most
    famous deep learning models across different data types, this chapter aims to
    help you understand the concepts and practice with PyTorch, and not provide you
    with state-of-the-art models for each data type or subject domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Types of neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convolutional neural networks for image shape data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformers for language modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling graphs using deep neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have learned about **convolutional neural
    networks** (**CNNs**), transformers, and graph neural networks as the three important
    categories of deep learning modeling to develop high-performance models in your
    problems of interest. You will have also learned how to develop such models using
    PyTorch and Python.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following requirements should be considered for this chapter as they will
    help you better understand the concepts, use them in your projects, and practice
    with the provided code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Python library requirements:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`torch` >= 2.0.0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`torchvision` >= 0.15.1'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`transformers` >= 4.28.0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`datasets` >= 2.12.0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`torch_geometric` == 2.3.1'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You will require basic knowledge of the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning modeling and fully connected neural networks
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use PyTorch for deep learning modeling
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter13](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter13).
  prefs: []
  type: TYPE_NORMAL
- en: Types of neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The examples we have provided so far in this book have focused on tabular data
    either in machine learning or in deep learning modeling, as one category of machine
    learning modeling. However, machine learning, and especially deep learning, has
    been successful in tackling problems that deal with non-tabular, or unstructured,
    texts, images, and graphs. First, we’ll introduce different problems that involve
    such data types in this section; then, we’ll review deep learning techniques that
    can help you build reliable models for them.
  prefs: []
  type: TYPE_NORMAL
- en: Categorization based on data type
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Structured data, which is also referred to as tabular data, is data that can
    be organized into spreadsheets and structured databases. As we have used this
    data type in this book, we usually have different features and even output in
    the columns of a table, matrix, or DataFrame. The rows of a DataFrame represent
    different data points in the dataset. However, we have other types of data that
    are not structured, and reformatting them into a DataFrame or matrix results in
    a loss of information. *Figure 13**.1* shows the three most important types of
    unstructured data – that is, sequence data such as text, image shape data such
    as family photos, and graphs such as social networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1 – Different data types that can be modeled using deep learning](img/B16369_13_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – Different data types that can be modeled using deep learning
  prefs: []
  type: TYPE_NORMAL
- en: '*Table 13.1* provides some examples of problems and how their corresponding
    data fits within each category mentioned in *Figure 13**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Data Type** | **Examples** |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence data | TextTime-series data such as stock pricesAudio data as a
    sequence of sound wavesGeolocation data as a sequence of object movementEEG data
    as a sequence of electrical activity of the brainECG data as a sequence of electrical
    activity of the heart |'
  prefs: []
  type: TYPE_TB
- en: '| Image shape data | PhotographsSecurity and surveillance imagesMedical images
    such as X-rays or CT scansVisual arts and images of drawings and paintingsImages
    captured by satellites, such as weather patternsImages captured using microscopes,
    such as images of cells |'
  prefs: []
  type: TYPE_TB
- en: '| Graphs | Road networksWeb graphs – connections between web pagesKnowledge
    graphs – relationships between conceptsSocial networks – connections between individuals
    and groupsBiological networks – connections between genes or other biological
    entities |'
  prefs: []
  type: TYPE_TB
- en: Table 13.1 – Examples of problems for each data type
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the challenges and issues with reformatting different data types into
    tabular data are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Reformatting sequence data into a table shape data object results in a loss
    of information regarding the order of data, such as words
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reformatting images into tabular format results in a loss of local patterns,
    such as the relationship between pixels of two-dimensional images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reformatting graphs into tabular data will eliminate dependency between data
    points or features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we understand the importance of not reformatting all datasets and data
    types into tabular data, we can start working with different deep learning techniques
    to understand how we can build successful models for non-tabular data. We will
    start by looking at image shape data.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional neural networks for image shape data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CNNs allow us to build deep learning models on image data without the need
    to reformat images into a tabular format. The name of this category of deep learning
    techniques comes from the concept of convolution, which in deep learning refers
    to applying a filter to image shape data to produce a secondary image shape feature
    map (shown in *Figure 13**.2*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.2 – A simple example of applying a predefined convolution filter
    to a 3x3 image shape data point](img/B16369_13_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – A simple example of applying a predefined convolution filter to
    a 3x3 image shape data point
  prefs: []
  type: TYPE_NORMAL
- en: When training a deep learning model, for example using PyTorch, a convolution
    filter or other filters that we will introduce later in this chapter will not
    be predefined but rather learned through the learning process. Convolution and
    other filters and processes in CNN modeling let us use the methods under this
    category of deep learning techniques for different image shape data (as we saw
    in *Figure 13**.1*).
  prefs: []
  type: TYPE_NORMAL
- en: 'The application of CNNs is beyond supervised learning for image classification,
    for which it might be most famous. CNNs have been used for different problems,
    including **image segmentation**, **resolution enhancements**, **object detection**,
    and more (*Figure 13**.3*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – Some of the successful applications of convolutional neural
    networks](img/B16369_13_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – Some of the successful applications of convolutional neural networks
  prefs: []
  type: TYPE_NORMAL
- en: '*Table 13.2* provides a list of high-performance models in different applications
    of CNNs that you can use in your projects or learn from to build even better models:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Problem** | **Some of the Widely Used Models and** **Related Techniques**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Image classification | ResNet (He et al., 2016); EfficientNets (Tan and Le,
    2019); MobileNets (Howard et al., 2017; Sandler et al., 2018); Xception (Chollet,
    2017) |'
  prefs: []
  type: TYPE_TB
- en: '| Image segmentation | U-Net (Ronneberger et al., 2015); Mask R-CNN (He et
    al., 2017); DeepLab (Chen et al., 2017); PSPNet (Chao et al., 2017) |'
  prefs: []
  type: TYPE_TB
- en: '| Object detection | Mask R-CNN (He et al., 2017); Faster R-CNN (Ren et al.,
    2015); YOLO (Redmon et al., 2016) |'
  prefs: []
  type: TYPE_TB
- en: '| Image super-resolution | SRCNN (Dong et el., 2015); FSRCNN (Dong et al.,
    2016); EDSR (Lim et al., 2017) |'
  prefs: []
  type: TYPE_TB
- en: '| Image-to-image translation | Pix2Pix (Isola et al., 2017); CycleGAN (Zhu
    et al., 2017) |'
  prefs: []
  type: TYPE_TB
- en: '| Style transfer | Neural Algorithm of Artistic Style (Gatys et al., 2016);
    AdaIN-Style (Huang et al., 2017) |'
  prefs: []
  type: TYPE_TB
- en: '| Anomaly detection | AnoGAN (Schlegl et al., 2017); RDA (Zhou et al., 2017);
    Deep SVDD (Ruff et al., 2018) |'
  prefs: []
  type: TYPE_TB
- en: '| Optical character recognition | EAST (Zhou et al., 2017); CRAFT (Bake et
    al., 2019) |'
  prefs: []
  type: TYPE_TB
- en: Table 13.2 – High-performance CNN models across different problems
  prefs: []
  type: TYPE_NORMAL
- en: You can train CNN models on two-dimensional or three-dimensional image shape
    data. You can also build models that work on sequences of such data points, such
    as videos, as sequences of images. Some of the most famous models or approaches
    in terms of using CNNs on videos that you can play with are C3D (Tran et al.,
    2015), I3D (Carreira and Zisserman, 2017), and SlowFast (Feichtenhofer et al.,
    2019).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will learn about some of the ways we can assess the performance of
    CNN models.
  prefs: []
  type: TYPE_NORMAL
- en: Performance assessment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can use the performance measures presented in [*Chapter 4*](B16369_04.xhtml#_idTextAnchor159),
    *Detecting Performance and Efficiency Issues in Machine Learning Models*, such
    as ROC-AUC, PR-AUC, precision, and recall, for CNN classification models. However,
    there are other measures more specific to some of the problems presented in *Figure
    13**.3*, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pixel accuracy**: This measure is defined as the ratio of correctly classified
    pixels to the total number of pixels. This measure works like accuracy and can
    be misleading when there is a class imbalance in the pixels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Jaccard index**: The Jaccard index is defined as the intersection over the
    union and can be used to calculate the overlap between the predicted segmentation
    and the ground truth normalized by their union.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CNN modeling using PyTorch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The process of CNN modeling in PyTorch is very similar to building fully connected
    neural networks, as we covered in the previous chapter. It starts with specifying
    the architecture of the network, then initializing the optimizer, and finally
    going through different epochs and batches to learn from training data points.
    Here, we want to practice CNN modeling in PyTorch using the `torchvision` library.
    Examples of the images in this dataset are shown in *Figure 13**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – Examples of images in the German Traffic Sign Recognition Benchmark
    (GTSRB) dataset from torchvision](img/B16369_13_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – Examples of images in the German Traffic Sign Recognition Benchmark
    (GTSRB) dataset from torchvision
  prefs: []
  type: TYPE_NORMAL
- en: There are other filters and layers besides the convolution filter (`torch.nn.Conv2d`)
    available in `torch.nn` that you can use to train high-performance CNN models.
    One of those filters that is widely used besides `torch.nn.Conv2d` is `torch.nn.MaxPool2d`,
    which can be used as a pooling layer in CNN modeling (LeCun et al., 1989). You
    can read about the required arguments for these two filters on the PyTorch website
    ([https://pytorch.org/docs/stable/nn.html](https://pytorch.org/docs/stable/nn.html)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start practicing CNN modeling using the GTSRB dataset. First, we must
    load the data for model training and testing, and then specify the number of classes
    in the classification model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we must define a neural network class, called `Net`, which determines
    the architecture of the network, including two layers of convolutional plus pooling
    filters, followed by ReLU activation functions, and then three layers of fully
    connected neural networks with ReLU activation functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we must initialize the network and optimizer, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to train the network using the initialized architecture and
    the optimizer. Here, we will use three epochs to train the network. The batch
    sizes don’t need to be specified here as they were determined when the data was
    loaded from `torchvision`, which was specified as `6` in this case (this can be
    found in this book’s GitHub repository):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The final calculated loss after 3 epochs is 0.00008.
  prefs: []
  type: TYPE_NORMAL
- en: This was a simple example of using PyTorch for CNN modeling. There are other
    functionalities in PyTorch that you can benefit from while building CNN models,
    such as data augmentation. We will discuss this next.
  prefs: []
  type: TYPE_NORMAL
- en: Image data transformation and augmentation for CNNs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As part of the pre-training stages of a machine learning life cycle, you might
    need to transform your images, such as by cropping them, or implement data augmentation
    as a series of techniques for synthetic data generation to improve the performance
    of your models, as explained in [*Chapter 5*](B16369_05.xhtml#_idTextAnchor183),
    *Improving the Performance of Machine Learning Models*. *Figure 13**.5* shows
    some simple examples of data augmentation, including rotation and scaling, that
    help you in generating synthetic but highly relevant data points to help your
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 13.5 – Examples of rule-based data augmentation – (A) original image\uFEFF\
    ,\uFEFF (B) rotated image\uFEFF, and\uFEFF (C) scaled image](img/B16369_13_05.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 13.5 – Examples of rule-based data augmentation – (A) original image,
    (B) rotated image, and (C) scaled image
  prefs: []
  type: TYPE_NORMAL
- en: Although there are simple examples of rules for data augmentation that you can
    implement in Python, there are many classes in PyTorch that you can use for both
    data transformation and augmentation, as explained at [https://pytorch.org/vision/stable/transforms.html](https://pytorch.org/vision/stable/transforms.html).
  prefs: []
  type: TYPE_NORMAL
- en: Using pre-trained models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a deep learning setting, often, we rely on pre-trained models either for
    inference or to further fine-tune for a specific problem we have at hand. CNNs
    are not an exception and you can find many pre-trained models in PyTorch for image
    classification or other applications of CNNs ([https://pytorch.org/vision/stable/models.html](https://pytorch.org/vision/stable/models.html)).
    You can also find code examples at the same URL on how to use these models. You
    can find the necessary code to teach you how to fine-tune these models using new
    data at [https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html).
  prefs: []
  type: TYPE_NORMAL
- en: Although we’ve focused on applying CNNs to image data so far, they can be used
    to model any image shape data. For example, audio data can be transformed from
    the time domain into the frequency domain, resulting in image shape data that
    can be modeled using CNNs in combination with sequence modeling algorithms, as
    introduced later in this chapter ([https://pytorch.org/audio/main/models.html](https://pytorch.org/audio/main/models.html)).
  prefs: []
  type: TYPE_NORMAL
- en: In addition to images and image shape data, deep learning models and algorithms
    have been developed to properly model sequence data in a variety of applications,
    such as in **natural language processing** (**NLP**), which we will refer to as
    language modeling here for simplicity. In the next section, we will review transformers
    for language modeling to help you start benefiting from such models if you have
    a relevant idea or project at hand.
  prefs: []
  type: TYPE_NORMAL
- en: Transformers for language modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Transformers were introduced in a famous paper called *Attention is All You
    Need* (Vaswani et al., 2017) as a new approach for sequence-to-sequence data modeling
    tasks such as translating statements from one language into another (that is,
    machine translation). These models are built on top of the idea of self-attention,
    which helps the model pay attention to other important parts of a sentence or
    sequence of information in the learning process during training. This attention
    mechanism helps the models better understand the relationships between the elements
    of input sequences – for example, between the words in the input sequences in
    language modeling. Models built using transformers usually work better than ones
    built using predecessor techniques such as **Long Short Term Memory** (**LSTM**)
    and **Recurrent Neural Networks** (**RNNs**) (Vaswani et al., 2017; Devlin et
    al., 2018).
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 13**.6* shows four traditional problems in language modeling that have
    been tackled successfully by transformer models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.6 – Four traditional problems in language modeling for which deep
    learning techniques have been used successfully](img/B16369_13_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.6 – Four traditional problems in language modeling for which deep
    learning techniques have been used successfully
  prefs: []
  type: TYPE_NORMAL
- en: 'Some famous models have been used either directly or with some modifications
    across these or other language modeling tasks. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: BERT (Devlin et al., 2018; [https://github.com/google-research/bert](https://github.com/google-research/bert))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT (Radford et al., 2018) and its more recent versions ([https://openai.com/product/gpt-4](https://openai.com/product/gpt-4))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DistilBERT (Sanh et al., 2019; [https://huggingface.co/docs/transformers/model_doc/distilbert](https://huggingface.co/docs/transformers/model_doc/distilbert))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RoBERTa (Liu et al., 2019; [https://github.com/facebookresearch/fairseq/tree/main/examples/roberta](https://github.com/facebookresearch/fairseq/tree/main/examples/roberta))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BART (Lewis et al., 2019; [https://github.com/huggingface/transformers/tree/main/src/transformers/models/bart](https://github.com/huggingface/transformers/tree/main/src/transformers/models/bart))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XLNet (Yang et al., 2019; [https://github.com/zihangdai/xlnet/](https://github.com/zihangdai/xlnet/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: T5 (Raffel et al., 2020; [https://github.com/google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLaMA (Touvron et al., 2023; [https://github.com/facebookresearch/llama](https://github.com/facebookresearch/llama))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformer models have also been used in other fields and sequence data, such
    as for electronic health records (Li et al., 2020), protein structure prediction
    (Jumpter et al., 2021), and time-series anomaly detection (Xu et al., 2021).
  prefs: []
  type: TYPE_NORMAL
- en: Generative modeling is another important concept in machine learning modeling
    for which transformers and CNNs have been successfully used. Examples of such
    models are different versions of GPT, such as GPT-4 ([https://openai.com/product/gpt-4](https://openai.com/product/gpt-4)).
    You will learn about generative modeling in [*Chapter 14*](B16369_14.xhtml#_idTextAnchor379),
    *Introduction to* *Recent Advancements in Machine Learning*. There is an open
    **Large Language Model** (**LLM**) leaderboard that provides a list of up-to-date
    open source LLM models ([https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)).
    You can also check the list of practical guide resources for LLMs at [https://github.com/Mooler0410/LLMsPracticalGuide](https://github.com/Mooler0410/LLMsPracticalGuide).
  prefs: []
  type: TYPE_NORMAL
- en: 'We don’t want to get into the theoretical details behind transformers, but
    you will learn about the components of a transformer architecture while building
    one in PyTorch. However, other widely used performance measures are used in sequence
    data and language modeling, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Perplexity** ([https://torchmetrics.readthedocs.io/en/stable/text/perplexity.html](https://torchmetrics.readthedocs.io/en/stable/text/perplexity.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bilingual Evaluation Understudy** (**BLEU**)**score** ([https://torchmetrics.readthedocs.io/en/stable/text/bleu_score.html](https://torchmetrics.readthedocs.io/en/stable/text/bleu_score.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recall-Oriented Understudy for Gisting Evaluation** (**ROUGE**)**score**
    ([https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html](https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These measures help you in evaluating your sequence models.
  prefs: []
  type: TYPE_NORMAL
- en: Tokenization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before training and testing transformer models, we need to transform the data
    into the right format through a process called tokenization. Tokenization is about
    chunking data into smaller pieces such as words, as in **word tokenization**,
    or characters, as in **character tokenization**. For example, the sentence “I
    like reading books” can be transformed into its contained words – that is, [“I,”
    “like,” “reading,” “books”]. When building a tokenizer, the maximum number of
    allowed tokens needs to be specified. For example, for a tokenizer with 1,000
    tokens, the most frequent 1,000 words get used as tokens from a text provided
    to build the tokenizer. Then, each token will be one of those 1,000 most frequent
    tokens. After this, these tokens each get an ID; these numbers will be used later
    by neural network models for training and testing. The words and characters outside
    of the tokens of a tokenizer get a common value of, for example, 0 or 1\. Another
    challenge in text tokenization is the different lengths of statements and sequences
    of words. To handle this challenge, a common ID, such as 0, is used before or
    after the IDs of tokens of words in each sequence of words or sentences in a process
    called padding.
  prefs: []
  type: TYPE_NORMAL
- en: The recent LLMs have different numbers of tokens in their tokenization process.
    For example, the **gpt-4-32k** model by OpenAI offers 32,000 tokens ([https://help.openai.com/en/articles/7127966-what-is-the-difference-between-the-gpt-4-models](https://help.openai.com/en/articles/7127966-what-is-the-difference-between-the-gpt-4-models)),
    while Claude’s LLM offers 100k tokens ([https://www.anthropic.com/index/100k-context-windows](https://www.anthropic.com/index/100k-context-windows)).
    The difference in the number of tokens could impact the performance of the models
    in terms of the corresponding text-related tasks.
  prefs: []
  type: TYPE_NORMAL
- en: There are commonly used libraries for tokenization, such as Hugging Face’s transformer
    ([https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html](https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html)),
    SpaCy ([https://spacy.io/](https://spacy.io/)), and NLTK ([https://www.nltk.org/api/nltk.tokenize.html](https://www.nltk.org/api/nltk.tokenize.html)).
    Let’s practice with Hugging Face’s transformer library to better understand how
    tokenization works.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s import `transformers.AutoTokenizer()` and then load the `bert-base-cased`
    and `gpt2` pre-trained tokenizers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To practice with these two tokenizers, we must make a list of two statements
    to use in the tokenization process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we must use each of the loaded tokenizers to tokenize and encode these
    two statements to the corresponding lists of IDs. First, let’s use `gpt2`, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code converts these two statements into the following two-dimensional
    lists, which include IDs for each of the tokens in each statement. For example,
    as both statements start with “I,” the first ID for both of them is 40, which
    is the token for “I” in the `gpt2` tokenizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will use `bert-base-cased`, but this time, we will ask the tokenizer
    to also use padding to generate lists of IDs of the same length and return the
    generated IDs in tensor format, which is suitable for use later in neural network
    modeling, such as using PyTorch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following tensor shows the same length for the generated IDs for both sentences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also use decoding functionality from each of these tokenizers to convert
    the IDs back into the original statements. First, we must decode the generated
    IDs using `gpt2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This generates the following statements, which match the original input statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'However, let’s say we use the `bert-base-cased` tokenizer for decoding the
    IDs, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting statements not only contain the original statements but also
    show how a padding token is decoded. This is shown as `[PAD]`, `[CLS]`, which
    is equivalent to the start of a sentence, and `[SEP]`, which shows where another
    second sentence starts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Language embedding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can transform the identified IDs per word, or sentence if we tokenize sentences
    and statements, into more information-rich embeddings. The IDs themselves can
    be used as one-hot encodings, as discussed in [*Chapter 4*](B16369_04.xhtml#_idTextAnchor159),
    *Detecting Performance and Efficiency Issues in Machine Learning Models*, where
    each word gets a long vector with zeros for all elements and one for the token
    dedicated to the corresponding word. But these one-hot encodings don’t provide
    us with any relationship between the words that work like data points in language
    modeling at the word level.
  prefs: []
  type: TYPE_NORMAL
- en: We can transform the words in a vocabulary into embeddings that can be used
    to capture semantic relationships between them and help our machine learning and
    deep learning models benefit from the new information-rich features across different
    language modeling tasks. Although models such as BERT and GPT-2 are not designed
    solely for embedding extraction for text, they can be used to generate embeddings
    for each word in a corpus of text. But there are other older methods such as Word2Vec
    (Mikolov et al., 2013), GloVe (Pennington et al., 2014), and fast-text (Bojanowski
    et al., 2017) that are designed for embedding generation. There are also more
    recent and more comprehensive models for word embedding such as Cohere ([https://txt.cohere.com/embedding-archives-wikipedia/](https://txt.cohere.com/embedding-archives-wikipedia/))
    that you can use to generate embeddings for text, in different languages, that
    you aim to embed and use for modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Language modeling using pre-trained models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are pre-trained models that we can import into different deep learning
    frameworks, such as PyTorch, to use solely for inference or further fine-tuning
    with new data. Here, we want to practice this process with DistilBERT (Sanh et
    al., 2019), which is a faster and lighter version of BERT (Devlin et al., 2018).
    Specifically, we want to use `DistilBertForSequenceClassification()`, a model
    based on the DistilBERT architecture, that’s been adapted for sequence classification
    tasks. In such processes, the model gets trained and can be used for inference
    for the task of assigning a label to a given sentence or statement. Examples of
    such label assignments are spam detection or semantic labeling, such as positive,
    negative, and neutral.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will import the necessary libraries and classes from `torch` and
    `transformers`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will load the `imdb` dataset so that we can use it to train a model,
    as a fine-tuned version of `DistilBertForSequenceClassification()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can define a tokenizer function on top of the `DistilBertTokenizerFast()`
    tokenizer with `distilbert-base-uncased` as the pre-trained tokenizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'After, we can separate a small percentage (1%) of the `imdb` data for training
    and testing as we want to solely practice with this process, and using the whole
    dataset takes a long time in terms of training and testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can initialize the `DistilBertForSequenceClassification()` model while
    specifying the number of labels in the classification process. Here, this is `2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can train the model using separate training data from the `imdb` dataset
    for `3` epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'With that, the model has been trained and we can evaluate it on the separate
    test set from the `imdb` dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This results in a 0.35 evaluation loss.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many other available models you can use in your language modeling
    or inference tasks (for example, the PyTorch Transformers library: [https://pytorch.org/hub/huggingface_pytorch-transformers/](https://pytorch.org/hub/huggingface_pytorch-transformers/)).
    There are also other sequence models, outside of language modeling, for areas
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Audio modeling: [https://pytorch.org/audio/main/models.html](https://pytorch.org/audio/main/models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Time-series modeling: [https://huggingface.co/docs/transformers/model_doc/time_series_transformer](https://huggingface.co/docs/transformers/model_doc/time_series_transformer)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Forecasting: [https://pytorch-forecasting.readthedocs.io/en/stable/models.html](https://pytorch-forecasting.readthedocs.io/en/stable/models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Video modeling: [https://pytorchvideo.org/](https://pytorchvideo.org/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can learn more about transformer modeling and how to make new architectures
    from scratch instead of using pre-trained models in PyTorch at [https://pytorch.org/tutorials/beginner/transformer_tutorial.html](https://pytorch.org/tutorials/beginner/transformer_tutorial.html).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you learned about modeling text as one type of sequence data.
    Next, we will cover modeling graphs, which are more complex data structures.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling graphs using deep neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can consider graphs as a more general structure of almost all non-tabular
    data we use for machine learning and deep learning modeling. Sequences can be
    considered **one-dimensional** (**1D**), while images or image shape data can
    be considered **two-dimensional** (**2D**) (see *Figure 13**.7*). Earlier in this
    chapter, you learned how to start benefiting from CNNs and transformers in Python
    and PyTorch for sequence and image shape data. But more general graphs don’t fit
    into these two graphs, which have predefined structures (see *Figure 13**.7*),
    and we cannot simply model them using CNNs or sequence models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.7 – Graph representation of different unstructured data types](img/B16369_13_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.7 – Graph representation of different unstructured data types
  prefs: []
  type: TYPE_NORMAL
- en: 'Graphs have two important elements, called nodes and edges. The edges connect
    the nodes. The nodes and edges of graphs can have different characteristics that
    differentiate them from each other (see *Figure 13**.8*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.8 – Graph types according to their node and edge characteristics](img/B16369_13_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.8 – Graph types according to their node and edge characteristics
  prefs: []
  type: TYPE_NORMAL
- en: We can have graphs where nodes have features, edges have weights or features,
    or edges have directions. Undirected graphs (graphs with undirected edges), for
    example, are useful for many applications, such as social media networks. Assuming
    each node in the graph of social media is a node, then the edges can determine
    which people are connected. The features of nodes in such graphs could be different
    characteristics of people in the social media network, such as their age, field
    of study or job title, city of residence, and so on. Directed graphs can be used
    in different applications, such as for causal modeling, which we’ll discuss in
    [*Chapter 15*](B16369_15.xhtml#_idTextAnchor406), *Correlation* *versus Causality*.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned at the beginning of this section, techniques such as CNNs and transformers
    cannot be used directly on graphs. Due to this, we’ll review other neural network
    techniques that can help you in modeling graphs in your projects.
  prefs: []
  type: TYPE_NORMAL
- en: Graph neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Graphs may have complicated structures as opposed to 2D images and 1D sequence
    data. However, we can model them using deep neural networks with the same idea
    as in CNNs and transformer models to rely on local patterns and relationships
    in the data. We can rely on local patterns in graphs and let the neural network
    learn from neighboring nodes instead of trying to learn information about the
    whole graph, which might contain thousands of nodes and millions of edges all
    at once. This is the idea behind **graph neural** **networks** (**GNNs**).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use GNNs for different tasks, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Node classification**: We can aim to predict the class of each node in a
    graph using GNNs. For example, if you consider a graph of hotels in a city with
    edges being the shortest route between them, you can aim to predict which one
    gets filled in during the holidays. Or if you have a background in chemistry,
    you can use node classification to annotate amino acids in proteins using the
    3D structure of proteins (Abdollahi et al., 2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Node selection**: Node selection for GNNs is a similar task to object detection
    for CNNs. We can design GNNs to identify and select nodes with specific characteristics,
    such as choosing people to suggest a product to in a graph of products and consumers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Link prediction**: We can aim to predict unknown edges between already existing
    nodes or new nodes in a graph. For example, in a graph that’s representative of
    a social media network, link prediction could be about predicting connections
    between people. Then, those individuals could be suggested to each other so that
    they can add each other to their networks of connections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph classification**: Instead of aiming to predict or select nodes or edges,
    we can design GNNs to predict the characteristics of whole graphs ([https://chrsmrrs.github.io/datasets/](https://chrsmrrs.github.io/datasets/)).
    In such cases, there could be graphs where each represents a data point, such
    as a drug molecule to be used in a GNN model for graph classification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are general taxonomies of different GNNs, such as the one suggested by
    Wu et al. (2020). But here, we want to focus on examples of widely used methods
    instead of getting too technical regarding the different categories of GNNs. Examples
    of methodologies that have been used successfully for modeling graphs are **Graph
    Convolutional Networks** (**GCNs**) (Kipf and Welling in 2016), **Graph Sample
    and Aggregation** (**GraphSAGE**) (Hamilton et al. in 2017), and **Graph Attention
    Networks** (**GATs**) (Veličković et al. in 2018). While most GNN techniques consider
    features for nodes, not all of them consider edge features. **Message Passing
    Neural Networks** (**MPNNs**) is an example of a technique that considers both
    node and edge features and was initially designed for producing graphs of drug
    molecules (Gilmer et al. in 2017).
  prefs: []
  type: TYPE_NORMAL
- en: You can build graphs from the data you have at hand or use publicly available
    datasets such as **Stanford Large Network Dataset Collection** (**SNAP**) to practice
    with different GNN techniques. SNAP has one of the largest collections of graph
    datasets you can download and start practicing with ([https://snap.stanford.edu/data/](https://snap.stanford.edu/data/)).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will practice GNN modeling using PyTorch to help you better understand
    how to build such models in Python.
  prefs: []
  type: TYPE_NORMAL
- en: GNNs with PyTorch Geometric
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'PyTorch Geometric is a Python library built upon PyTorch that helps you train
    and test GNNs. There is a series of tutorials you can benefit from to learn about
    GNN modeling using PyTorch Geometric ([https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html](https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html)).
    Here, we will practice the problem of node classification with code adapted from
    one of these tutorials ([https://colab.research.google.com/drive/14OvFnAXgg     xB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=0YgHcLXMLk4o](https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=0YgHcLXMLk4o)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s import the *CiteSeer* citation network dataset from `Planetoid`
    in PyTorch Geometric (Yang et al., 2016):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, similar to initializing neural networks for FCNNs and CNNs, we must initialize
    a `GCNet` class for GNN modeling, but instead of using linear and convolutional
    layers, we will use `GCNConv` graph convolutional layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the previous class, we used three `GCNConv` layers in combination with the
    ReLU activation function and dropout for regularization.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can use the defined `GCNet` class to initialize our model with hidden
    layers whose sizes are 128 and 16, both of which are arbitrary in this practice
    code. We must also initialize an optimizer while specifying the algorithm, which
    in this case is `Adam`, and a learning rate of `0.01` and a weight decay of `1e-4`
    for regularization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can define our training function, which will be used for one-epoch
    training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'With that, we are ready to go through a series of epochs and train the model.
    Please note that the following loop for training the model for 400 epochs might
    take a long time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The following plot shows the learning curve (loss versus epoch) in the training
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.9 – The learning curve for the example GCN model on the CiteSeer
    dataset](img/B16369_13_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.9 – The learning curve for the example GCN model on the CiteSeer dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also test the model on the test portion of the dataset, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in an accuracy of 0.655\. We can also generate a confusion matrix
    of the predictions on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following matrix, shown as a heatmap. Although most of
    the predictions and true classes of data points match, many of them are misclassified
    and summarized outside of the diagonal elements of the confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.10 – Confusion matrix of the predictions over the test set for
    the example GCN model on the CiteSeer dataset](img/B16369_13_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.10 – Confusion matrix of the predictions over the test set for the
    example GCN model on the CiteSeer dataset
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we talked about techniques for modeling different data types
    and problems using deep learning. Now, you are ready to learn more about these
    advanced techniques and use them in your projects.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about advanced deep learning techniques, including
    CNNs, transformers, and GNNs. You were provided with some of the widely used or
    famous models that have been developed using each of these techniques. You also
    practiced building these advanced models either from scratch or fine-tuning them
    using Python and PyTorch. This knowledge helped you learn more about these techniques
    and start using them in your projects so that you can model images and image shape
    data, text and sequence data, and graphs.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how recent advancements in generative modeling
    and prompt engineering, as well as self-supervised learning, can either help you
    in developing your projects or provide you with opportunities to develop interesting
    and useful tools and applications.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are some examples of problems you can use CNNs and GNNs for?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does applying convolution preserve local patterns in images?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Could decreasing the number of tokens result in more mistakes in language models?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is padding in the text tokenization process?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are the network architecture classes we build for CNNs and GNNs in PyTorch similar?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When do you need edge features to build GNNs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: He, Kaiming, et al. *Deep residual learning for image recognition*. Proceedings
    of the IEEE conference on computer vision and pattern recognition. 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan, Mingxing, and Quoc Le. *Efficientnet: Rethinking model scaling for convolutional
    neural networks*. International conference on machine learning. PMLR, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Howard, Andrew G., et al. *Mobilenets: Efficient convolutional neural networks
    for mobile vision applications*. arXiv preprint arXiv:1704.04861 (2017).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sandler, Mark, et al. *Mobilenetv2: Inverted residuals and linear bottlenecks*.
    Proceedings of the IEEE conference on computer vision and pattern recognition.
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chollet, François. *Xception: Deep learning with depthwise separable convolutions*.
    Proceedings of the IEEE conference on computer vision and pattern recognition.
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. *U-net: Convolutional
    networks for biomedical image segmentation*. Medical Image Computing and Computer-Assisted
    Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October
    5-9, 2015, Proceedings, Part III 18\. Springer International Publishing, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He, Kaiming, et al. *Mask r-cnn*. Proceedings of the IEEE international conference
    on computer vision. 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen, Liang-Chieh, et al. *Deeplab: Semantic image segmentation with deep convolutional
    nets, atrous convolution, and fully connected crfs*. IEEE transactions on pattern
    analysis and machine intelligence 40.4 (2017): 834-848.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao, Hengshuang, et al. *Pyramid scene parsing network*. Proceedings of the
    IEEE conference on computer vision and pattern recognition. 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren, Shaoqing, et al. *Faster r-cnn: Towards real-time object detection with
    region proposal networks*. Advances in neural information processing systems 28
    (2015).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Redmon, Joseph, et al. *You only look once: Unified, real-time object detection*.
    Proceedings of the IEEE conference on computer vision and pattern recognition.
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dong, Chao, et al. *Image super-resolution using deep convolutional networks*.
    IEEE transactions on pattern analysis and machine intelligence 38.2 (2015): 295-307.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dong, Chao, Chen Change Loy, and Xiaoou Tang. *Accelerating the super-resolution
    convolutional neural network*. Computer Vision–ECCV 2016: 14th European Conference,
    Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14\. Springer
    International Publishing, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lim, Bee, et al. *Enhanced deep residual networks for single image super-resolution*.
    Proceedings of the IEEE conference on computer vision and pattern recognition
    workshops. 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Isola, Phillip, et al. *Image-to-image translation with conditional adversarial
    networks*. Proceedings of the IEEE conference on computer vision and pattern recognition.
    2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu, Jun-Yan, et al. *Unpaired image-to-image translation using cycle-consistent
    adversarial networks*. Proceedings of the IEEE international conference on computer
    vision. 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. *Image style transfer
    using convolutional neural networks*. Proceedings of the IEEE conference on computer
    vision and pattern recognition. 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang, Xun, and Serge Belongie. *Arbitrary style transfer in real-time with
    adaptive instance normalization*. Proceedings of the IEEE international conference
    on computer vision. 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schlegl, Thomas, et al. *Unsupervised anomaly detection with generative adversarial
    networks to guide marker discovery*. Information Processing in Medical Imaging:
    25th International Conference, IPMI 2017, Boone, NC, USA, June 25-30, 2017, Proceedings.
    Cham: Springer International Publishing, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ruff, Lukas, et al. *Deep one-class classification*. International conference
    on machine learning. PMLR, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou, Chong, and Randy C. Paffenroth. *Anomaly detection with robust deep autoencoders*.
    Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery
    and data mining. 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baek, Youngmin, et al. *Character region awareness for text detection*. Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition. 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou, Xinyu, et al. *East: an efficient and accurate scene text detector*.
    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tran, Du, et al. *Learning spatiotemporal features with 3d convolutional networks*.
    Proceedings of the IEEE international conference on computer vision. 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Carreira, Joao, and Andrew Zisserman. *Quo vadis, action recognition? a new
    model and the kinetics dataset*. Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition. 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feichtenhofer, Christoph, et al. *Slowfast networks for video recognition*.
    Proceedings of the IEEE/CVF international conference on computer vision. 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun, Yann, et al. *Handwritten digit recognition with a back-propagation network*.
    Advances in neural information processing systems 2 (1989).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani, Ashish, et al. *Attention is all you need*. Advances in neural information
    processing systems 30 (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin, Jacob, et al. *Bert: Pre-training of deep bidirectional transformers
    for language understanding*. arXiv preprint arXiv:1810.04805 (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron, Hugo, et al. *Llama: Open and efficient foundation language models*.
    arXiv preprint arXiv:2302.13971 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li, Yikuan, et al. *BEHRT: transformer for electronic health records*. Scientific
    reports 10.1 (2020): 1-12.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jumper, John, et al. *Highly accurate protein structure prediction with AlphaFold*.
    Nature 596.7873 (2021): 583-589.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu, Jiehui, et al. *Anomaly transformer: Time series anomaly detection with
    association discrepancy*. arXiv preprint arXiv:2110.02642 (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yuan, Li, et al. *Tokens-to-token vit: Training vision transformers from scratch
    on imagenet*. Proceedings of the IEEE/CVF international conference on computer
    vision. 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu, Yinhan, et al. *Roberta: A robustly optimized bert pretraining approach*.
    arXiv preprint arXiv:1907.11692 (2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lewis, Mike, et al. *Bart: Denoising sequence-to-sequence pre-training for
    natural language generation, translation, and comprehension*. arXiv preprint arXiv:1910.13461
    (2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford, Alec, et al. *Improving language understanding by generative* *pre-training*.
    (2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Raffel, Colin, et al. *Exploring the limits of transfer learning with a unified
    text-to-text transformer*. The Journal of Machine Learning Research 21.1 (2020):
    5485-5551.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sanh, Victor, et al. *DistilBERT, a distilled version of BERT: smaller, faster,
    cheaper and lighter*. arXiv preprint arXiv:1910.01108 (2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang, Zhilin, et al. *Xlnet: Generalized autoregressive pretraining for language
    understanding*. Advances in neural information processing systems 32 (2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mikolov, Tomas, et al. *Efficient estimation of word representations in vector
    space*. arXiv preprint arXiv:1301.3781 (2013).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. *Glove: Global
    vectors for word representation*. Proceedings of the 2014 conference on empirical
    methods in natural language processing (EMNLP). 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bojanowski, Piotr, et al. *Enriching word vectors with subword information*.
    Transactions of the association for computational linguistics 5 (2017): 135-146.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu, Zonghan, et al. *A comprehensive survey on graph neural networks*. IEEE
    transactions on neural networks and learning systems 32.1 (2020): 4-24.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abdollahi, Nasim, et al. *NodeCoder: a graph-based machine learning platform
    to predict active sites of modeled protein structures*. arXiv preprint arXiv:2302.03590
    (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kipf, Thomas N., and Max Welling. *Semi-supervised classification with graph
    convolutional networks*. arXiv preprint arXiv:1609.02907 (2016).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hamilton, Will, Zhitao Ying, and Jure Leskovec. *Inductive representation learning
    on large graphs*. Advances in neural information processing systems 30 (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Velickovic, Petar, et al. *Graph attention networks*. stat 1050.20 (2017):
    10-48550.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gilmer, Justin, et al. *Neural message passing for quantum chemistry*. International
    conference on machine learning. PMLR, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang, Zhilin, William Cohen, and Ruslan Salakhudinov. *Revisiting semi-supervised
    learning with graph embeddings*. International conference on machine learning.
    PMLR, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
