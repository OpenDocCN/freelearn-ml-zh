- en: '*Chapter 5*: Automated Machine Learning with Microsoft Azure'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"By far, the greatest danger of artificial intelligence is that people conclude
    too early that they understand it."'
  prefs: []
  type: TYPE_NORMAL
- en: – Eliezer Yudkowsky
  prefs: []
  type: TYPE_NORMAL
- en: The Microsoft Azure platform and its associated toolset are diverse and part
    of a larger enterprise ecosystem that is a force to be reckoned with. It enables
    businesses to focus on what they do best by accelerating growth via improved communication,
    resource management, and facilitating advance actionable analytics. In the previous
    chapter, you were introduced to the Azure Machine Learning platform and its services.
    You learned how to get started with Azure machine learning, and you took a glimpse
    at the end-to-end machine learning life cycle using the power of the Microsoft
    Azure platform and its services. That was quite literally (in the non-literal
    sense of the word) the tip of the iceberg.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will get started by looking at **Automated Machine Learning**
    (**AutoML**) in Microsoft Azure. You will build a classification model and perform
    time series prediction using Azure's AutoML capabilities. This chapter will equip
    you with the skills you'll need to build and deploy AutoML solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: AutoML in Microsoft Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series prediction using Azure AutoML and JupyterLab
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: AutoML in Microsoft Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AutoML is treated as a first-class citizen in the Azure platform. The fundamental
    ideas behind feature engineering, network architecture search, and hyperparameter
    tuning are the same as what we discussed in [*Chapter 2*](B16890_02_Final_VK_ePub.xhtml#_idTextAnchor049),
    *Automated Machine Learning, Algorithms, and Techniques*, and [*Chapter 3*](B16890_03_Final_VK_ePub.xhtml#_idTextAnchor058),
    *Automated Machine Learning with Open Source Tools and Libraries*. However, the
    layer of abstraction that's used to democratize these skills makes them much more
    appealing to non-machine learning experts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key principles of AutoML in the Azure platform are shown in the following
    diagram. User input such as datasets target metrics, and constraints (how long
    to run the job, what the allocated budget is for compute, and so on) drive the
    AutoML "engine", which completes iterations to find the best model and rank it
    according to the score of **Training Success**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Azure AutoML workflow – how AutoML works'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.1_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.1 – Azure AutoML workflow – how AutoML works
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we''ll provide a step-by-step walkthrough of the AutoML approach.
    In [*Chapter 4*](B16890_04_Final_VK_ePub.xhtml#_idTextAnchor076), *Getting Started
    with Azure Machine Learning*, you saw the main page for Azure machine learning.
    There, we created a classification model and tested it using a notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Azure Machine Learning portal'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.2_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.2 – Azure Machine Learning portal
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s explore how AutoML-based model development works when it comes
    to training and tuning a model:'
  prefs: []
  type: TYPE_NORMAL
- en: From the Azure portal, click on **Automated ML** | **Start now**. You will be
    taken to the following screen, where you can create a new Automated ML run:![Figure
    5.3 – Azure Machine Learning – Creating an Automated ML run
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.3_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.3 – Azure Machine Learning – Creating an Automated ML run
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The first step of creating an automated ML run is selecting a dataset to work
    with. Here, you can either create your own dataset or – better yet – select an
    existing one from the repository of public datasets that Azure provides:![Figure
    5.4 – AutoML dataset selection page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.4_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.4 – AutoML dataset selection page
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A dataset can be created from open datasets. In this case, we will use our
    tried and tested MNIST dataset to create the AutoML run, as shown in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: MNIST dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Yann LeCun (Courant Institute, NYU) and Corinna Cortes (Google Labs, New York)
    hold the copyright for MNIST dataset, which is a derivative work from the original
    NIST datasets. The MNIST dataset has been made available under the terms of the
    Creative Commons Attribution-Share Alike 3.0 license.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.5 – The Create dataset from Open Datasets page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.5_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.5 – The Create dataset from Open Datasets page
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have selected the dataset, it will appear as part of your run, and
    you can also preview it. Apart from specifying the dataset''s version, you can
    also specify if you would like to use the entire dataset, or whether it should
    be registered as a tabular data source or a file type data source:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Dataset from the Azure Machine Learning dataset repository of
    curated datasets'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.6_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.6 – Dataset from the Azure Machine Learning dataset repository of curated
    datasets
  prefs: []
  type: TYPE_NORMAL
- en: 'Upon selecting **Create**, you will see the following screen as the dataset
    becomes part of your run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Dataset from the Azure Machine Learning dataset repository of
    curated datasets'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.7_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.7 – Dataset from the Azure Machine Learning dataset repository of curated
    datasets
  prefs: []
  type: TYPE_NORMAL
- en: 'The MNIST dataset can also be seen as part of the data preview if you click
    on the dataset''s name, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Preview of the dataset from the Azure Machine Learning dataset
    repository of curated datasets'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.8_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.8 – Preview of the dataset from the Azure Machine Learning dataset
    repository of curated datasets
  prefs: []
  type: TYPE_NORMAL
- en: Let's face it – this preview of the MNIST pixel dataset isn't that exciting,
    but if you had some more representative data (healthcare, retail, or financial
    data, and so on), the preview would help us understand that the ingestion process
    went well and that we are not running the risk of a delimiter fiasco.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, the data statistics are shown in the following screenshot. If you
    are pandas-inclined, think of it as the `describe()` feature. Due to its image-based
    nature, this isn''t quite as relevant, but when it comes to some of the other
    datasets we will use later in this chapter, it comes in quite handy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9 – Preview of the data statistics in Azure AutoML'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.9_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.9 – Preview of the data statistics in Azure AutoML
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have selected the dataset, we can configure the run by providing
    the experiment's name, target column (the labeled feature to train on and classify),
    and the compute cluster, as shown in the following screenshot:![Figure 5.10 –
    Configuring an AutoML run
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.10_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.10 – Configuring an AutoML run
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The third and final step is to select the task type – classification, regression,
    or time series forecasting. In this case, we are classifying digits based on their
    associated labels. You will learn how to use the other task types in future examples:![Figure
    5.11 – Selecting the task type for the AutoML run
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.11_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.11 – Selecting the task type for the AutoML run
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It is important to consider the additional configurations. Here, you can select
    a primary metric, its explainability, any allowed algorithms (by default, all
    of them are allowed), the exit criteria, and any validation split information,
    as shown in the following screenshot:![Figure 5.12 – Additional configuration
    for the task type of the AutoML run
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.12_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.12 – Additional configuration for the task type of the AutoML run
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Additional configuration varies based on the task''s type. The following screenshot
    shows the regression configuration elements:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Additional configuration for the task type of the AutoML run'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.13_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.13 – Additional configuration for the task type of the AutoML run
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Featurization** – that is, selecting and transforming features – is an important
    factor to keep in mind as you move forward with the dataset. When you click on
    the **View Featurization Settings** link, Azure machine learning provides you
    with the following screen. From here, you can select the feature''s type, assign
    a specific data type, and specify what you wish to impute the feature with:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.14 – Featurization of the AutoML run'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.14_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.14 – Featurization of the AutoML run
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Automatic featurization** – that is, turning different data types into numerical
    vectors – is a typical part of any data science workflow. The following diagram
    shows the techniques that are applied automatically to the datasets when featurization
    is turned on (see the blue toggle at the top of the preceding screenshot). The
    following diagram shows some of the key steps that are taken during auto-featurization.
    You can find out more about enumerated featurization techniques at [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.15 – Featurization approaches for the AutoML run'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.15_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.15 – Featurization approaches for the AutoML run
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Scaling** and **normalization** (also sometimes referred to as **regularization**
    and **standaridization**) are two important ways of featurization that deal with
    transforming data into a common range of values. The scaling and normalization
    techniques that are used in the automatic featurization algorithms can be seen
    in the following diagram. You can find out more about various enumerated scaling
    and featurization techniques at [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.16 – Azure AutoML – scaling and featurization'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.16_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.16 – Azure AutoML – scaling and featurization
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The topic of featurization is not complete without the mention of guardrails.
    Data guardrails are part of the AutoML engine which helps identify and address
    issues with the dataset such as missing feature values, handling high cardinality
    features (lots of unique values), class imbalance (minority classes and outliers)
    and so on. The following figure outlines these guardrails you should make yourself
    familiar with. You can read further details about these guardrails here in the
    Azure documentation ([https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features)):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.17 – Data guardrails for the AutoML run'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.17_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.17 – Data guardrails for the AutoML run
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, when you click the **Finish** button, as shown in *Figure 5.10*, after
    setting up the given parameters for the task type and any additional configuration
    items, you will see the following screen, which validates the run:![Figure 5.18
    – Data guardrails for the AutoML run
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.18_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.18 – Data guardrails for the AutoML run
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'One important point to keep in mind is that you need to have good compute resources
    to run an experiment; otherwise, it will fail. For example, in this experiment,
    I have set the training time to 0.25 hours; that is, 15 minutes. This is not enough
    time for the given compute, which means the run is bound to fail, as shown in
    the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.19 – AutoML experiment run settings'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.19_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.19 – AutoML experiment run settings
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following screenshot shows that since we didn''t allocate the right computing
    resources to run the AutoML experiment, it failed:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.20 – AutoML experiment run failure message'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.20_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.20 – AutoML experiment run failure message
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following error message explains the user error in detail, along with potential
    solutions, such as adding compute resources, applying an experiment timeout, and
    making dataset sampling changes:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.21 – AutoML experiment run failure message'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.21_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.21 – AutoML experiment run failure message
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Increasing the time limit to 5 hours will help, as you will see in the following
    steps. Azure AutoML has now had enough time and enough resources to execute multiple
    experiments. This has taught you that cheapening out on time and/or resources
    isn't a good AutoML strategy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The following screen in the AutoML child run shows individual iterations. It
    clearly demonstrates how different data preprocessing methods, such as `StandardScalerWrapper`,
    `RobustScaler`, and `MaxAbsScaler`/`MinMaxScaler`, and forecasting algorithms,
    such as `RandomForest`, `LightGB`, `ElasticNet`, `DecisionTree`, and `LassoLars`,
    were used. Runs `54` and `53` in the following screenshot show how ensemble algorithms
    and their weights can be viewed by clicking on their associated tags:![Figure
    5.22 – AutoML experiment run details
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.22_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.22 – AutoML experiment run details
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Click on the **Models** tab to see which model provided what degree of accuracy
    and what run it is associated with, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.23 – AutoML experiment run details'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.23_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.23 – AutoML experiment run details
  prefs: []
  type: TYPE_NORMAL
- en: 'The run metrics are also a great way to get more detailed information about
    the associated run. For example, you can see the algorithm''s name, the associated
    accuracy, AUC scores, precision, F1 score, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.24 – AutoML experiment run details'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.24_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.24 – AutoML experiment run details
  prefs: []
  type: TYPE_NORMAL
- en: 'The data guardrail measures that are taken to protect the quality of the data
    can be seen by clicking on the corresponding tab, as shown in the following screenshot.
    This page shows what guardrail techniques have been used to ensure that the input
    data used to train the model was high quality:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.25 – AutoML experiment data guardrails'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.25_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.25 – AutoML experiment data guardrails
  prefs: []
  type: TYPE_NORMAL
- en: 'From the main run summary page, you can view the best model and its summarized
    outcome. In this case, the soft voting-based `VotingEnsemble()` method was the
    clear winner. It is among two of the ensemble methods currently supported in Azure
    AutoML. The other one is `StackEnsemble`, which creates collections from previously
    run iterations. Ensemble methods are techniques that are used to combine multiple
    models to get the best results; voting, stacking, bagging, and boosting are some
    of the categories available for ensemble methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.26 – AutoML experiment summary page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.26_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.26 – AutoML experiment summary page
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming you have followed these experiments so far and tried these steps by
    yourself, it should be evident that each run has several child runs – that is,
    individual iterations that each model has. So, when we look at the **Metrics**
    tab of the **Run** summary page, we not only see the different metrices, but also
    a precision recall plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.27 – AutoML experiment accuracy metrics and PR curve'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.27_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.27 – AutoML experiment accuracy metrics and PR curve
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at the explanations for the models. The explainability of
    machine learning models is super important, especially for AutoML. This is because
    you would like to know, as a subject matter expert, which features played a critical
    role in the result. In the following screenshot, you can see a tabular explanation
    of feature importance for the top *k* features, along with a breakdown of how
    they are used to predict digits from 0-9:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.28 – AutoML experiment explanation of features'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.28_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.28 – AutoML experiment explanation of features
  prefs: []
  type: TYPE_NORMAL
- en: The preceding screenshot shows which feature played what part in predicting
    the digits. Feature 377 was significant in predicting digit 7, features 379 and
    434 were significant in predicting 9, and so on and so forth. This MNIST dataset
    might not appear to be relevant to you, but let's imagine you are looking at an
    HR hiring dataset and gender, race, or age become an important feature. This would
    raise an alarm since this would go against your corporate policies of sexual bias,
    racism, or age-related discrimination. It would also likely be against the law
    and you could get in serious trouble in terms of compliance and reputational damage
    for having a bigot in the machine. Not to mention, it's unethical (and honestly
    nonsensical) to discriminate based on attributes that have nothing to do with
    an employee's capability to get the job done.
  prefs: []
  type: TYPE_NORMAL
- en: 'This explainability also provides summary importance for features where you
    can visualize the importance of individual k-features for both global and local
    features. The swarm chart, shown in the following screenshot, visualizes the same
    data at a very granular level. It shows a one-to-one mapping between the number
    of elements in the MNIST dataset and the features they correspond to, similar
    to what''s shown in the tabular representation in the preceding screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.29 – Azure Machine Learning top k features summary importance chart'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.29_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.29 – Azure Machine Learning top k features summary importance chart
  prefs: []
  type: TYPE_NORMAL
- en: With this overview of automated ML for classification, let's move on and apply
    the same techniques to time series forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Time series prediction using AutoML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Forecasting energy demand is a real problem in the industry where energy providers
    like to predict the consumer's expected needs in advance. In this example, we
    will use the New York City energy demand dataset, which is available in the public
    domain. We will use historic time series data and apply AutoML for forecasting;
    that is, predicting energy demand for the next 48 hours.
  prefs: []
  type: TYPE_NORMAL
- en: 'The machine learning notebook is part of the Azure model repository, which
    can be accessed on GitHub at [https://github.com/Azure/MachineLearningNotebooks/](https://github.com/Azure/MachineLearningNotebooks/).
    Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Clone the aforementioned GitHub repository on your local disk and navigate to
    the `forecasting-energy-demand` folder:![Figure 5.30 – Azure Machine Learning
    notebooks GitHub repository
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.30_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.30 – Azure Machine Learning notebooks GitHub repository
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the `forecasting-energy-demand` folder to the Azure notebook repository,
    as shown in the following screenshot:![Figure 5.31 – Uploading a folder in the
    Azure Machine Learning notebook workspace
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.31_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.31 – Uploading a folder in the Azure Machine Learning notebook workspace
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once the folder has been uploaded (see the files in left-hand pane of the following
    screenshot), double-click on the, `ipynb` (notebook) file and open it. You will
    see the following screen:![Figure 5.32 – Uploading files in the AutoML notebook
    workspace
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.32_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.32 – Uploading files in the AutoML notebook workspace
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, open this in JupyterLab by clicking on the respective dropdown, as shown
    in the following screenshot. It is important to remember that even though you
    are running the files in JupyterLab, an automated ML experiment is being run in
    the Azure Machine Learning workspace, and you can always track and view every
    experiment there. This shows the power of seamless integration with third-party
    tools:![Figure 5.33 – Uploading files in the AutoML notebook workspace and opening
    them in JupyterLab
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.33_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.33 – Uploading files in the AutoML notebook workspace and opening them
    in JupyterLab
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, the file is running in a very familiar environment, with the kernel being
    Python 3.6 – the Azure Machine Learning runtime. This seamless integration with
    notebooks is a powerful feature of Azure Machine Learning:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.34 – Uploading files in the AutoML notebook workspace and opening
    them in JupyterLab'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.34_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.34 – Uploading files in the AutoML notebook workspace and opening them
    in JupyterLab
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Since we are working with time series data, it is useful to note that Azure
    AutoML offers a variety of native time series as well as deep learning models
    to support time series-related analytical workloads. The following screenshot
    shows a list of these algorithms:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.35 – Azure AutoML time series capabilities'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.35_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.35 – Azure AutoML time series capabilities
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Azure automated ML comes with a variety of regression, classification, and
    time series forecasting algorithms and scoring mechanisms, and you can always
    add custom metrics. The following screenshot shows a list of Azure AutoML classification,
    regression, and time series forecasting algorithms and measures:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![ Figure 5.36 – Azure AutoML classification, regression, and time series forecasting
    algorithms'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.36_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.36 – Azure AutoML classification, regression, and time series forecasting
    algorithms
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following is a list of metrics that are used to measure the accuracy of
    the aforementioned methods:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.37 – Azure AutoML measures for classification, regression, and time
    series forecasting'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.37_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.37 – Azure AutoML measures for classification, regression, and time
    series forecasting
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Skimming over the boilerplate setup code, we can set up the experiment by setting
    the target column to demand and the time column's name to be the timestamp. Once
    we've done this, the data is downloaded and made part of the pandas DataFrame,
    as shown in the following screenshot:![Figure 5.38 – Azure AutoML data loading
    for the NYC power supply in the notebook
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.38_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.38 – Azure AutoML data loading for the NYC power supply in the notebook
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, let's split up the data into training and testing sets:![Figure 5.39 –
    Data split for the NYC power supply in the notebook
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.39_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.39 – Data split for the NYC power supply in the notebook
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: One of the key parameters you will have to set as part of this exercise is the
    forecast horizon; that is, how far in the future you would like to predict for.
    The automated ML algorithm is smart enough to know what unit to use (hour, days,
    or months) based on the time series frequency of your dataset. Based on our business
    problem, we will set the forecast horizon to `48` (hours) and submit the job,
    as shown in the following screenshot:![Figure 5.40 – Creating the AutoML configuration
    for the forecasting job
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.40_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.40 – Creating the AutoML configuration for the forecasting job
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now that we have created the configuration, let's submit the experiment, as
    shown in the following screenshot:![Figure 5.41 – Submitting the AutoML experiment
    to the remote server for execution
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.41_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.41 – Submitting the AutoML experiment to the remote server for execution
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To demonstrate the integration of Jupyterlab with the Azure Machine Learning
    service, click on the **Experiments** tab in the ML service portal, as shown in
    the following screenshot. Here, you can see that the experiment has been submitted
    and is now prepared to run with the associated config for the AutoML parameters:![Figure
    5.42 – The experiment pane views for the AutoML experiment on the remote server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.42_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.42 – The experiment pane views for the AutoML experiment on the remote
    server
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The AutoML config elements can also be observed as part of the notebook as
    you wait for the job to complete:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.43 – The notebook running the wait_for_completion() method after
    submitting the job'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.43_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.43 – The notebook running the wait_for_completion() method after submitting
    the job
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This inherent integration between the notebook and the corresponding experiment
    can also be seen in the following screenshot. Here, we can see how the **Experiment**
    notebook is reflected in the experiment console:![Figure 5.44 – The experiment
    from the notebook shown in the Experiments pane  in Azure Machine Learning](img/Figure_5.44_B16890.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 5.44 – The experiment from the notebook shown in the Experiments pane
    in Azure Machine Learning
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The algorithm''s name and error details are outlined for each run and shows
    a consistent reduction in the error rate. Normalized RMSE and accuracy metrics
    for MNIST classification are shown int he following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.45 – The experiment from the notebook shown in the Experiments pane
    in Azure Machine Learning'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.45_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.45 – The experiment from the notebook shown in the Experiments pane
    in Azure Machine Learning
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The data guardrails types are also notable. In the following screenshot, you
    can see that they are different from the guardrails we had in the classification
    exercise. In this case, the data is validated against frequency detection and
    missing feature value imputation. The AutoML engine is smart enough to learn what
    types of guardrails need to be applied for different types of experiments and
    datasets:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.46 – The guardrails for the Experiments pane in Azure Machine Learning'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.46_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.46 – The guardrails for the Experiments pane in Azure Machine Learning
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now that the experiment is complete, we can retrieve the best model in the notebook,
    as shown in the following screenshot (or in the machine learning service console,
    if you are visually inclined):![Figure 5.47 – Model retrieval in the notebook
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.47_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.47 – Model retrieval in the notebook
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You might recall deep feature search or automated feature engineering being
    introduced in the previous chapters. You can access and retrieve the engineered
    features from the notebook with the help of the following steps by calling the
    `get_engineered_feature_names()` method on the model:![Figure 5.48 – Retrieving
    engineered features via get_engineered_feature_names
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/Figure_5.48_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.48 – Retrieving engineered features via get_engineered_feature_names
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Viewing the featurization summary for these features, both engineered and organic,
    provides you with the rationale that was used to build these features, as shown
    in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.49 – Viewing the engineered features summary via get_featurization_summary()'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_5.49_B16890.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.49 – Viewing the engineered features summary via get_featurization_summary()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Using the scoring method, we can create the test scores and plot the predicted
    points on a chart, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.50 – Building a scatter plot for test data scores'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.50_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.50 – Building a scatter plot for test data scores
  prefs: []
  type: TYPE_NORMAL
- en: 'The predicted data test scores are in blue, while the actual score is in green:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: This image may be black and white to you. You will understand the color reference
    better when practically working on the example.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.51 – The test data scores and the associated plot'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.51_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.51 – The test data scores and the associated plot
  prefs: []
  type: TYPE_NORMAL
- en: '`X_trans` captures the featurization, including the automatic feature engineering
    changes in the dataset, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.52 – X_trans showing the time series features for energy forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.52_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.52 – X_trans showing the time series features for energy forecasting
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though the explainability of the MNIST dataset wasn''t quite as intuitive,
    in terms of exploring the energy demand dataset, you can visualize different models
    and see which features have the most impact on the predicted usage. It is quite
    intuitive that temperature would have a positive correlation with the global importance
    of power usage. A higher temperature leads to a heavier usage of air conditioning,
    and hence higher power usage. The time of day and day of the week are also deemed
    important by the model, as shown in the following chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.53 – Global importance explainability graph'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.53_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.53 – Global importance explainability graph
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, different explanation models (engineered features
    versus raw) map the result against the different predicted values of Y. Model
    explanation views help us understand which features directly impact the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.54 – Global importance explainability graph'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.54_B16890.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.54 – Global importance explainability graph
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our demonstration of time series prediction using AutoML in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to apply AutoML in Azure to a classification
    problem and a time series prediction problem. You were able to build a model within
    the Azure Machine Learning environment with an Azure notebook and via JupyterLab.
    You then understood how the entire workspace relates to the experiments and runs.
    You also see the visualization during these automated runs; this is where feature
    importance, the global and local impact of features, and explanations based on
    raw and engineered features provide an intuitive understanding. Besides your affinity
    with a tool, it is also important that the platform aligns with your enterprise
    roadmap. Azure is an overall great platform with a comprehensive set of tools,
    and we hope you enjoyed exploring its automated ML capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information on the topics that were covered in this chapter, please
    take a look at the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure AutoML:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml](https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Practical AutoML on Azure:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/PracticalAutomatedMachineLearning/Azure](https://github.com/PracticalAutomatedMachineLearning/Azure)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
