<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Proactive Measures with vSAN Advanced Analytics</h1>
                </header>
            
            <article>
                
<p>This chapter will brief you on <strong>virtual storage area network</strong> (<strong>vSAN</strong>) design recommendations, as well as all of the monitoring options through which your customers can assess, recommend, and design their environment. This will help them achieve different business objectives by automating their operations with smart policies.</p>
<p><span>We will learn to configure policy-based operations as per ML algorithms and we'll learn how the end user experience is improved by the proactive resolving of customer issues. We'll also learn to optimize a <strong>hyperconverged infrastructure</strong> (<strong>HCI</strong>) to achieve customer business objectives.</span></p>
<p> The following topics will be covered in this chapter:</p>
<ul>
<li class="CDPAlignLeft CDPAlign">Application scalability on vSAN</li>
<li class="mce-root CDPAlignLeft CDPAlign">Intelligent monitoring</li>
<li class="mce-root CDPAlignLeft CDPAlign"><strong>High availability</strong> (<strong>HA</strong>) configuration in stretched clusters</li>
<li class="mce-root CDPAlignLeft CDPAlign">vSAN policy design with <strong>Storage Policy-Based Management</strong> (<strong>SPBM</strong>)</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>You can download VMware vCenter Server 6.5 U1 from the site at <a href="https://my.vmware.com/web/vmware/details?downloadGroup=VC65U1&amp;productId=676&amp;rPId=28154" target="_blank">https://my.vmware.com/web/vmware/details?downloadGroup=VC65U1&amp;amp;productId=676&amp;amp;rPId=28154</a><a href="https://my.vmware.com/web/vmware/details?downloadGroup=VC65U1&amp;productId=676&amp;rPId=28154" target="_blank">.</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Application scalability on vSAN</h1>
                </header>
            
            <article>
                
<p>VMware vSAN can support containers and a next-generation application based on an updated vSphere Docker volume driver with native support directly through Docker APIs. This allows Docker to be built on top of vSAN and take advantage of the proven, persistent storage capabilities of vSAN. This driver update has new features, including support for multi-tenancy, SPBM, cloning, and snapshots. <span><span>VMware</span></span> has a principle of <em>APIs first</em>, and all management features are available through APIs, which are extensions of the vSphere APIs that tens of thousands of enterprise customers use to automate their operations.</p>
<p><span>The following parameters should be taken into consideration to detain the storage tier where application data should be stored:</span></p>
<ul>
<li><strong>I/O operations per second</strong> (<strong>IOPS</strong>) requirements</li>
<li>MBps requirements</li>
<li>Capacity requirements</li>
<li>Availability requirements</li>
<li>Latency requirements</li>
<li>Consider any existing SLAs</li>
<li>Consider whether data might move between storage tiers during the information life cycle</li>
</ul>
<p>These details can be used to move applications and services to the storage tier that's been designed with matching characteristics.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Storage and network assessment</h1>
                </header>
            
            <article>
                
<p>A holistic approach to vSAN management can have a significantly positive impact on the infrastructure. It integrates with vRealize Operation and complements it by providing more in-depth information about resources. The following VMware recommendations view the business challenges from three different perspectives:</p>
<ul>
<li><strong>Organizational recommendations</strong>: Develop a virtualization policy with a service-centered approach such as a menu of offerings and service levels.</li>
</ul>
<ul>
<li><strong>Operational recommendations</strong>: Focus on process definition and improvement, specifically in the areas of provisioning, systems monitoring, and problem management. Research and evaluate virtual infrastructure monitoring tools.</li>
<li><strong>Technical recommendations</strong>: Implement consistent configurations across similar systems, perform minor network adjustments to greatly improve network performance during contention and backup windows, and configure virtual machines to exploit the benefits of virtualization.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Storage design policy</h1>
                </header>
            
            <article>
                
<p>The assessment summaries are based on the <strong>VMware Health Analyzer</strong> (<strong>vHA</strong>) checkpoints and documented vSAN best practices. We will take a look at some of the recommendations in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">VMware best practices recommendations </h1>
                </header>
            
            <article>
                
<p>The following are VMware's best practices, along with recommendations for the storage design policies:</p>
<ul>
<li>Verify that we have set up storage policies correctly in vCenter console:
<ul>
<li>Default rule settings should be modified by default. The policy should be applied as per your requirements.</li>
<li><strong>Policy settings</strong>: <span class="packt_screen">Force provisioning</span> should be set to true during configuration.</li>
<li><span class="packt_screen">Object space reservation (%)</span> should be set to 100%.</li>
</ul>
</li>
</ul>
<p style="padding-left: 60px"><strong>Justification</strong>: The VM storage policies in vSAN can affect the performance of VMs running on the vSAN datastore. These include the <span><span class="packt_screen">Number of disk stripes per object</span>,</span> <span class="packt_screen"><span>F</span>lash read cache reservation (%)</span>, <span class="packt_screen">Number of failures to tolerate</span>, and <span class="packt_screen">Object space reservation (%)</span> parameters.</p>
<p style="padding-left: 60px">VMware recommends that you go with the default policy of one failure to tolerate and one disk stripe. We can change the policy as per customer requirements and also change the configuration. We have to update the policy for each additional failure to tolerate. <em>2n+1</em> hosts are required to fulfill the policy, where <em>n</em> is number of failure to tolerate.</p>
<ul>
<li>Verify that VMs are distributed evenly across vSAN nodes. Just as disk resources should generally be distributed evenly across vSAN hosts, for the best performance, virtual machines should also be distributed relatively evenly across those hosts.</li>
</ul>
<p style="padding-left: 60px"><span><strong>Justification</strong>:</span> This reduces the chances of performance being impacted due to an imbalance of virtual machines on a single host, which could saturate the vSAN network. vSphere's <strong>Distributed Resource Scheduler</strong> (<strong>DRS</strong>) can help with disk resource distribution by monitoring and balancing the virtual machines as needed.</p>
<ul>
<li>The storage controller's settings should be configured correctly for best performance.</li>
</ul>
<p style="padding-left: 60px"><span><strong>Justification</strong>:</span> The VM storage policies in vSAN can affect the performance of VMs running on the vSAN datastore. A low controller queue depth may impact the availability of production VMs during rebuild/resync, so a minimum queue depth of 256 is required in vSAN. The VMware Compatibility Guide for vSAN has been updated to include only adapters with this requirement. However, certain adapters with older firmware might still have the queue depth artificially limited. The controller should have caching disabled. If this is not possible, set read caching to 100%. If the controller is not set to pass-through, present each disk as its own device. Do not configure drives as one large RAID volume.</p>
<ul>
<li>Avoid using the flash read cache policy reservations unless absolutely necessary.</li>
</ul>
<p style="padding-left: 60px"><span><strong>Justification</strong>:</span> vSAN allows for the customization of policies for use with virtual machines. One of the policy options, <span class="packt_screen">Flash read cache reservation (%)</span>, allows for the reservation of read cache. Do not set this policy option unless absolutely necessary. These reservations reserve a portion of the read cache for objects based on the percentage of capacity disk size (10% of a 250 GB disk is 25 GB.) If they are not used sparingly, cache reservations quickly reduce the available cache and the effectiveness of vSAN.</p>
<ul>
<li>We should upgrade the on-disk file format to 3.0.</li>
</ul>
<p style="padding-left: 60px"><span><strong>Justification</strong>:</span> To use the full set of vSAN capabilities in vSphere, be sure to upgrade the on-disk file format. During the vSAN upgrade from version 5.5 to version 6.7, it is possible to keep the on-disk format version, that is, 1.0, but you cannot use many of the new features. vSAN supports both on-disk formats.</p>
<ul>
<li>vSAN should be using optimal <span><strong>non-volatile memory express</strong> (</span><strong>NVMe</strong>) CLASS E disks. Verify that you are using supported and high-performing <strong>solid state drives</strong> (<strong>SSDs</strong>) for best performance.</li>
</ul>
<p style="padding-left: 60px"><span><strong>Justification</strong>: </span>All writes hit SSDs in vSAN first. vSAN read cache hits come from SSDs, so the performance of the SSDs is a critical factor in the overall performance of vSAN.</p>
<p style="padding-left: 60px">We can use SSDs instead of magnetic disks for the capacity tier as well. The VMware Compatibility Guide helps customers in selecting the right SSDs by segregating them into different groups based on their performance, as follows:</p>
<ul>
<li><strong>Class A</strong>: 2,500–5,000 writes per second</li>
<li><strong>Class B</strong>: 5,000–10,000 writes per second</li>
<li><strong>Class C</strong>: 10,000–20,000 writes per second</li>
<li><strong>Class D</strong>: 20,000–30,000 writes per second</li>
<li><strong>Class E</strong>: 30,000+ writes per second</li>
</ul>
<p>VMware always recommends using flash drives that meet application performance needs for optimal performance. As per best practices, we have to consider 10 percent of projected used <strong>hard disk drive</strong> (<strong>HDD</strong>) capacity before the failures-to-tolerate policy is applied for a minimum flash drive.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Network design policy</h1>
                </header>
            
            <article>
                
<p>vSAN requires a VMkernel network configuration for synchronization and replication activities. This port group should generally be dedicated and isolated to vSAN traffic. However, if a 10 gigabits network interface is being used, it can be shared. 1 gigabit networks require a dedicated <strong>network inte</strong><span><strong>rface card</strong> (</span><strong>NIC</strong>) to be assigned to the port group.</p>
<p>The following are the major decision points regarding vSAN network configuration:</p>
<ul>
<li><strong>Network speed requirements</strong>: All-flash vSAN configurations (with Advanced and Enterprise Edition) will only work with 10 gigabits Ethernet network uplinks. A 10 gigabits network is required to achieve the highest performance (IOPS). VMware recommends a 10 gigabits Ethernet connection (MTU 9000) for use with vSAN in all configurations.</li>
</ul>
<ul>
<li><strong>Type of virtual switch to be used</strong>:<strong> </strong>vSAN supports both vSphere standard virtual switch configurations and distributed switch configurations. A distributed switch allows network I/O control to be used for the prioritization of bandwidth. It allows the interface to be shared and prioritizes performance levels in contention scenarios. VMware recommends using a <strong>vSphere Distributed Switch</strong> (<strong>VDS</strong>) for the vSAN port group.</li>
<li><strong>Jumbo frame</strong>:<strong> </strong>vSAN supports using jumbo frames for vSAN network transmissions. VMware recommends using jumbo frames for vSAN, but only if the underlying physical environment is already configured to support them.</li>
<li class="mce-root"><strong><span> Business continuity and disaster recovery</span></strong> (<span><strong>BC/DR</strong></span>) <span><strong>and teaming considerations</strong>:</span><strong><span> </span></strong>BC/DR is critical in any environment in case of a network failure. vSAN supports teaming configurations for network cards to enhance the availability and redundancy of the network. VMware recommends that configurations use an active/active redundancy with a route based on physical adapter load for the teaming in the environment. Idle network cards do not wait for a failure to occur and aggregate bandwidth in this configuration.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">VMware best practices recommendations </h1>
                </header>
            
            <article>
                
<p><span>The following are VMware's best practices with recommendations for the network design policies:</span></p>
<ul>
<li>We should distribute VMNICs for a port group across various <span><strong>Peripheral Component Interconnect</strong> (</span><strong>PCI</strong>) buses for enhancing availability</li>
</ul>
<p style="color: black;padding-left: 60px"><span><strong>Justification</strong>:</span> Distributing VMNICs for a port group across different PCI buses provides protection from failures related to a specific PCI bus. You need to team VMNICs from different PCI buses to improve fault resiliency from component failures.</p>
<ul>
<li>Configure NICs, physical switch speed, and duplex settings consistently</li>
</ul>
<p style="color: black;padding-left: 60px"><span><strong>Justification</strong>: </span>Incorrect network speed and duplex settings can impact performance. The network adapter (VMNIC) and physical switch settings must be checked and set correctly. If your physical switch is configured for a specific speed and duplex setting, we must force the network driver to use the same speed and duplex setting. Network settings should be set to auto-negotiate and not forced for gigabits links. We can set network adapter speed and duplex settings from the vSphere client, but a reboot is required for the changes to take effect.</p>
<ul>
<li>It is always recommended to use 10 gigabits or faster networks with vSAN</li>
</ul>
<p style="color: black;padding-left: 60px"><span><strong>Justification</strong>:</span> Small vSAN deployments can perform well with 1 gigabit Ethernet links between the ESXi hosts in the vSAN cluster, but most deployments will require 10 gigabits or faster links. VMware recommends using a minimum of 10 gigabits links for best datastore performance.</p>
<ul>
<li><strong>Network I/O control</strong> (<strong>NIOC</strong>) shares are configured to ensure at least 8 gigabits are available for vSAN traffic to avoid contention. We will use vSAN reservations while using<span> NIOC</span>. </li>
</ul>
<p style="color: black;padding-left: 60px"><span><strong>Justification</strong>:</span> VMware suggests reservations with vSAN for specific use cases but primarily for environmental conditions in the physical network, thus reducing the actual bandwidth. This can be scheduled between the physical NIC and the physical network. Reservations ensure that the vSAN network traffic is not consumed by other traffic types. NIOC can redistribute reserved bandwidth to other system traffic types (management, <strong>i</strong><span><strong>nternet small computer system interface</strong></span> <span>(</span><strong>iSCSI</strong>), <strong>fault tolerance</strong> (<strong>FT</strong>), vMotion, and so on), but not to VM traffic. VM traffic is limited without any congestion even with minimal management traffic.</p>
<ul>
<li style="color: black">Multicast networking is enabled for efficient operation as one multicast group contains no network partitions</li>
</ul>
<p style="color: black;padding-left: 60px"><span><strong>Justification</strong>:</span> Multicast networking using <strong>internet group management protocol</strong> (<strong>IGMP</strong>) snooping is required for vSAN. We should validate that the networking infrastructure supports this requirement by running network discovery commands. The infrastructure will require either a snooper carrier configured for the vSAN network, or IGMP snooping to be disabled explicitly on the VLAN or ports which are used by default in many environments. All of the physical switches and routers handling vSAN traffic, along with the layer 2 path and the layer 3 (optional) path, should be enabled with multicast. VMware recommends using layer 2 multicast for the simplicity of configuration and operations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">VMware's Customer Experience Improvement Program/vSAN ReadyCare</h1>
                </header>
            
            <article>
                
<p><span>We have enhancements that have been added to and developed by an engineering team based on customer feedback from the past 6 – 12 months. </span>VMware retrieves technical data regarding VMware solutions that are deployed in the customer's environment and other services that are integrated with the customer's VMware license keys.</p>
<p>Depending on the nature of the VMware product or service and the level of participation the customer selects, the technical data that's accumulated is comprised of all or some of the following data:</p>
<ul>
<li>Configuration data providing information about the configuration of VMware solutions, along with associated products that are deployed in the customer's environment, like the version of VMware products, configuration details, and applications/hardware configuration with VMware products/services</li>
<li>Product feature-specific data, which provides information about how VMware tools are utilized in a customer's data center, including user interface activity and integration with third-party tools</li>
<li>Performance data helps with the different metrics to measure the performance of various VMware product features, like availability/scalability/security, along with response times for user interfaces and API integrations</li>
<li>Product log data that's fostered from the initial deployment to the production stage by VMware products, such as the logs of past system events and different system states for a specific time period, without having a customer's application data/content</li>
</ul>
<p>VMware updates all of this information at regular intervals to reflect changes in its products/services through the <strong>Customer Experience Improvement Program</strong> (<strong>CEIP</strong>), and we always suggest that our customers browse this web page (CEIP) regularly so that they're always updated: <a href="https://www.vmware.com/in/solutions/trustvmware/ceip.html" target="_blank">https://www.vmware.com/in/solutions/trustvmware/ceip.html</a>.</p>
<p>We will now see how we can use machine learning techniques to collect logs and for monitoring purposes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Intelligent monitoring</h1>
                </header>
            
            <article>
                
<p>vSAN environment monitoring is critical for a successful deployment. We have to follow the following monitoring practices:</p>
<ul>
<li>General monitoring practices</li>
<li>vSAN Health Check plugin</li>
<li>vSAN Observer</li>
<li>VMware vRealize Operations Manager Monitoring</li>
<li>Monitoring design</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">General monitoring practices</h1>
                </header>
            
            <article>
                
<p>vSAN supports monitoring datastores through the VMware vSphere Web Client, the HTML 5 client, and the vSAN Management API. The vSphere Web Client monitors different objects, like clusters and datastores.</p>
<p>Without effective control over the infrastructure, a VM or ESXi host sprawl can quickly diminish the return of investment from virtualization. Areas for improvement include assessing workloads to determine performance metrics that can then be used to create VM-specific vSAN policies to better suit the workload. A stripe policy of two nodes for write-intensive workloads that are bigger than the cache disk size may lead to performance improvements. We can minimize the troubleshooting time that is spent by the operations teams on VMs that have performance-related issues.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">vSAN Health Check plugin</h1>
                </header>
            
            <article>
                
<p>The vSAN Health Check plugin is a simple way to check the health of the vSAN cluster. It is included by default in the installation. The health check technical recommendations are as follows:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p><strong>Priority</strong></p>
</td>
<td>
<p><strong>Component</strong></p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign"><strong>Recommended action item</strong></p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">P1</p>
</td>
<td>
<p>vSAN</p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign">Verify vSAN firmware and driver versions.</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">P2</p>
</td>
<td>
<p>vSAN network</p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign">Distribute VMNICs for a port group across different PCI buses for greater redundancy.</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">P3</p>
</td>
<td>
<p>vSAN network</p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign">Configure NICs, physical switch speed, and duplex settings consistently. Set to auto negotiation for 1 gigabit NICs.</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">P3</p>
</td>
<td>
<p>vSAN</p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign">Verify that you have set up the storage policies correctly.</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">P3</p>
</td>
<td>
<p>vSAN</p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign">Verify that the VMs are distributed evenly across vSAN nodes.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>VMware recommends using the Health Check plugin to allow for easy monitoring of the vSAN clusters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">vSAN Observer</h1>
                </header>
            
            <article>
                
<p>vSAN Observer does in-depth monitoring of disk groups, shows an aggregate view for the group and disk layers, and also monitors vSAN physical disk layer latencies. It reads cache hit rate, evictions and performance, and other parameters, such as size, disk type, manufacturers, model, local/non-local, and so on. vSAN Observer is part of the <strong>Ruby vSphere Console</strong> (<strong>RVC</strong>), which supports the use of the vCenter Server certificate on Windows platforms and provides network, a <span><strong>Content-Based Read Cache</strong> (</span><strong>CRBC</strong>), and vSANSparse statistics. The following tools/data can help your customers troubleshoot vSAN-related issues:<br/></p>
<ul>
<li>vSAN configuration</li>
<li>vSAN health monitoring</li>
<li>vSAN disks statistics</li>
<li>vSAN performance statistics</li>
<li>Observer</li>
</ul>
<p>vSAN Observer recommends that you deploy a vCenter Server appliance and run the observer session on the newly deployed or remote vCenter Server appliance to increase the data gathering time beyond the default (2 hours).</p>
<p>The vSAN Observer user interface displays the following performance details:</p>
<ul>
<li>Statistics of the physical disk layer</li>
<li>Extensive physical disk group details</li>
<li>CPU usage statistics</li>
<li>Consumption of vSAN memory pools</li>
<li>Physical and in-memory object distribution across vSAN clusters</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">vRealize Operations Manager monitoring</h1>
                </header>
            
            <article>
                
<p>A business can be heavily impacted when service interruptions continue to rise and IT teams become more eager to find interruption issues in a small time period. <span>Logs have become a critical source of information and are required to troubleshoot IT operations issues. However, the amount and size of logs have grown due to increasingly complex IT environments.</span></p>
<p><span>As customers become more cost-sensitive, Log Intelligence, one of the VMware Cloud services, helps customers overcome these challenges by providing valuable insights into public and private cloud infrastructure. Log Intelligence offers rapid IT troubleshooting, deep operational visibility across multiple clouds, including VMware Cloud on AWS, and centralized log management. VMware recommends installing and monitoring vSAN with vRealize Operations Manager, which helps in the comprehensive monitoring of vSAN in the environment.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Challenges affecting business outcomes</h1>
                </header>
            
            <article>
                
<p>The following are the challenges that affect business outcomes:</p>
<ul>
<li><strong>Lack of visibility</strong>: IT teams that don't have system-wide visibility through a single pane of glass spend an ample amount of time manually reviewing logs, preventing them from spending time on more strategic tasks</li>
<li><strong>Reactive troubleshooting</strong>: IT teams spend too much time identifying and solving issues due to isolated metrics that trigger alarms, increasing time spent, cost, and downtime</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Business benefits</h1>
                </header>
            
            <article>
                
<p>Log Intelligence is a service that offers rapid IT troubleshooting, deep operational visibility across public and private cloud environments, and centralized log management, making it easier for IT teams to decipher and solve issues more efficiently.</p>
<p>Following are the benefits:</p>
<ul>
<li><strong>Minimize costs</strong>: Help customers improve performance and create a faster problem resolution that raises savings at a company's top and bottom line</li>
<li><strong>Prevent downtime</strong>: Move away from a reactive mechanism to spot potential problems and track infrastructure whose log values were out of normal operation, preventing future downtime</li>
<li><strong>Saving time</strong>: Use a centralized log management tool to automatically collect and organize information</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical Issues</h1>
                </header>
            
            <article>
                
<p>The technical issues such as monitoring and proactive support to reduce resolution time are as follows:</p>
<ul>
<li><strong>Lack of insight into the SDDC environment</strong>: IT administrators generally don't have good visibility into their organization's cloud environment, especially the workloads that are deployed by their application teams in public clouds.</li>
<li><strong>Reactive performance troubleshooting</strong>: Traditional log management tools rely on raw performance metrics and typically do not go beyond alerting administrators when performance thresholds are exceeded. In addition, they do not provide additional insights from log files for troubleshooting and root cause analysis.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical solution</h1>
                </header>
            
            <article>
                
<p>Log Intelligence, a SaaS offering, is easy to onboard and use. IT administrators can use it to collect and analyze various types of machine-generated log data. Log Intelligence can be connected to infrastructure and applications for enterprise-wide visibility via log analytics.</p>
<p>Log Intelligence offers an intuitive GUI-based interface, making it easy for IT administrators to run simple interactive searches, as well as deep analytical queries for quick insights that provide immediate value and improved IT efficiency.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Log Intelligence advantages</h1>
                </header>
            
            <article>
                
<p>Let's take a look at some of the advantages of Log Intelligence:</p>
<ul>
<li><strong>Immediate time to value</strong>: Log Intelligence provides automated data collection from public and private cloud environments and provides immediate time to value by helping customers ingest universal log collection and analytics efficiently, while delivering intuitive, interesting events</li>
<li><strong>Cost savings</strong>: It helps customers in reducing the resolution time of escalated support requests with its innovative approach of indexing and grouping in rapid troubleshooting across virtual and cloud deployments</li>
<li><strong>Increased productivity</strong>: It has a single log management console with all of the relevant information, which helps users to innovate new things in the organization</li>
</ul>
<p>We will now learn about the different configuration parameters that you can use during a stretched clusters deployment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">HA configuration in stretched clusters</h1>
                </header>
            
            <article>
                
<p class="mce-root">VMware vSAN has the option to deploy two ESXi hosts in a cluster with a remote witness appliance. We can define specific vSphere HA behaviors for vSAN to validate the VM's individual state. vSphere HA can dictate a particular VM failover action if the virtual machine's components are accessible from a defined partition.</p>
<p>The following is a screenshot of the cluster settings:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/05f2f519-c6a6-43cb-9ffb-18b74a6839bf.png" style="width:55.25em;height:26.17em;"/></p>
<p class="mce-root">vSAN stretched cluster-enabled HA has the following configurations in the cluster's settings:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td class="CDPAlignLeft CDPAlign" style="width: 52.7217%">
<p><strong>vSphere HA</strong></p>
</td>
<td class="CDPAlignLeft CDPAlign" style="width: 45.2783%">
<p>Configuration<strong> parameters</strong></p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign" style="width: 52.7217%">
<p><span class="packt_screen">Host Monitoring</span></p>
</td>
<td class="CDPAlignLeft CDPAlign" style="width: 45.2783%">Yes</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign" style="width: 52.7217%">
<p><span class="packt_screen">Host Hardware Monitoring </span>—<span class="packt_screen">VM Component Protection</span>: <span class="packt_screen">Protect against Storage Connectivity Loss</span></p>
</td>
<td class="CDPAlignLeft CDPAlign" style="width: 45.2783%">
<p> No, default</p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign" style="width: 52.7217%">
<p><span class="packt_screen">Virtual Machine Monitoring</span></p>
</td>
<td class="CDPAlignLeft CDPAlign" style="width: 45.2783%">
<p>No, default</p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign" style="width: 52.7217%">
<p><span class="packt_screen">Admission Control</span></p>
</td>
<td class="CDPAlignLeft CDPAlign" style="width: 45.2783%">
<p><span><span>Enabled</span></span></p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign" style="width: 52.7217%">
<p><span class="packt_screen">Datastore Heartbeats</span></p>
</td>
<td class="CDPAlignLeft CDPAlign" style="width: 45.2783%">
<p>Datastore Heartbeat will be disabled by using datastores from the defined list, but without choosing any datastores from this list</p>
</td>
</tr>
</tbody>
</table>
<p>To configure the policy to enable HA, follow these steps:</p>
<ol>
<li>Go to the HA Settings (HA enabled) and configure the static routes on the host servers and witness host</li>
<li>Add static routes to the witness VM's vSAN VLAN to the vSAN network of the ESXi hosts in the data centers</li>
<li>The traffic for the vSAN is enabled for the VMkernel port groups</li>
<li>Static routes are added by executing the <kbd>esxcfg-route –a</kbd> command on all the ESXi hosts in the cluster across data sites and the witness host</li>
<li>The <kbd>esxcli</kbd> command is used to add a static route, as follows:</li>
</ol>
<pre>esxcli network ip route ipv4 add –n &lt;remote network&gt; -g &lt;gateway to use&gt;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Two-node clusters</h1>
                </header>
            
            <article>
                
<p>Two-node clusters aren't possible with vSAN as a minimum of three hosts are required to make sure that all of the components are protected. </p>
<p>A two-node cluster can be configured from the configuration wizard with a witness. This is good for smaller environments. VMware introduced <strong>witness traffic separation</strong> (<strong>WTS</strong>) for two-node configurations and also supports this feature for stretched clusters. Most of the stretched vSAN customers leverage this feature by configuring (witness) through the CLI (<kbd>esxcli</kbd>). All we have to do is tag a <span><strong>VMKernel NIC</strong> (</span><strong>vmknic</strong>) for witness traffic with the following command:</p>
<pre><strong>esxcli vsan network ip set -i vmk&lt;X&gt; -T=witness</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Witness appliance for the vSAN cluster</h1>
                </header>
            
            <article>
                
<p>VMware has a vSAN witness appliance, which is basically an ESXi instance running in a VM to act as a witness. A witness host needs less capacity, bandwidth, and performance compared to hosts in normal vSAN clusters, or hosts in data center parts of the vSAN stretched cluster. A witness appliance stores the VM's witness components and is responsible for object quorums in the case of failure or a split-brain situation to make the required VM available.</p>
<p>The configuration of the witness appliance for a tiny environment are as follows:</p>
<ul>
<li>Tiny (10 VMs or less: application/domain controller/file and print server)</li>
<li>Two vCPUs, 8 GB vRAM</li>
<li>8 GB ESXi Boot Disk, one 10 GB SSD, one 15 GB HDD</li>
<li>Supports a maximum of 750 witness components</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuring the vSAN cluster</h1>
                </header>
            
            <article>
                
<p>All VMware vSAN certified servers that are mentioned in the VMware HCL can be considered to be a part of the vSAN cluster, which utilizes both magnetic disks and flash disks for capacity and cache tiers. 70% of the available cache is allocated for storing frequently read disk blocks by reducing accesses to the slower magnetic disks, while the remaining 30% of the available cache is allocated to writes. Multiple writes should be coalesced and written sequentially to enhance magnetic disk performance:</p>
<ol>
<li>Choose the cluster that the host servers are added on.</li>
<li>Click the <span class="packt_screen">Configure...</span> option on the right-hand side to manage all the datastores powered by vSAN:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c23cd23b-1a2e-408a-ac7a-fc44ac3c525a.png" style="width:36.75em;height:12.33em;"/></p>
<ol start="3">
<li>Find the option to configure the vSAN under <span class="packt_screen">Virtual SAN</span>.</li>
<li>Go to the configuration page.</li>
</ol>
<ol start="5">
<li>Then, go to <span class="packt_screen">Claim disks</span> from datastore, and then choose <strong>Manual</strong>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/0b134d98-ab25-433b-b64f-9423ff4fd03c.png" style="width:38.58em;height:21.50em;"/></p>
<p class="mce-root"/>
<ol start="6">
<li><span class="packt_screen">Fault Domains &amp; Stretched Cluster</span>: Configure two host vSAN clusters.</li>
<li>Confirm that the networking is valid on the vSAN VMkernel adapters.</li>
<li>Verify that all of the disks show up for each server.</li>
<li>Collapse the disks to their logical drives. Then, set the SSDs to the <span class="packt_screen">Cache tier</span> and the HDDs to the <span class="packt_screen">Capacity tier.</span></li>
<li>Choose the fault domains and the <span class="packt_screen">Preferred fault domain</span> and <span class="packt_screen">Secondary fault domain.</span></li>
<li>Click <span class="packt_screen">Next</span> and continue.</li>
<li>Select the option to choose the witness VM.</li>
</ol>
<ol start="13">
<li>Map the capacity and the <strong>Cache tier</strong> for the witness VM host. Then, deploy the witness VM to monitor the vSAN cluster:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d69ca947-6440-4421-87ae-e8148df4b004.png" style="width:46.92em;height:43.00em;"/></p>
<p class="mce-root"/>
<ol start="14">
<li>Click on <span class="packt_screen">Finish</span> to complete the vSAN configuration. The disks should now be visible.</li>
<li> Log on to a host server and type the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>localcli vsan cluster get</strong></pre>
<ol start="16">
<li> Verify that the cluster shows up as healthy.</li>
<li> Under <span class="packt_screen">Cluster</span> | <span class="packt_screen">Monitor</span> | <span class="packt_screen">VSAN</span> |, run the health check to confirm that the configuration is correct.</li>
</ol>
<p>We have gone through how to configure a vSAN cluster, as well as how to perform health check monitoring. Now, we will learn about the various policies that we can configure through SPBM.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">vSAN policy design with SPBM</h1>
                </header>
            
            <article>
                
<p>The storage class definition in vSphere maps to policies that are defined through vSAN SPBM to achieve different levels of <strong>service level agreements</strong> (<strong>SLAs</strong>) and <strong>quality of service</strong> (<strong>QoS</strong>), and can leverage these benefits from advanced vSAN data service functionalities such as de-duplication, compression, and checksums. Using general policies is advisable if no specific use cases exist.</p>
<p>Start by assessing the following different application requirements:</p>
<ul>
<li>I/O performance and the profile of your workloads on a per-virtual-disk basis</li>
<li>Working sets of your workloads</li>
<li>Hot-add (feature of vSphere) of additional cache requires re-population of the cache</li>
<li>Specific application best practices, such as block size</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining a policy based on business objectives</h1>
                </header>
            
            <article>
                
<p>vSAN integrates storage parameters into vCenter Server by using vSphere APIs for storage awareness. SPBM further helps in defining VM-centric policies, which are basically constructs that store VM storage provisioning needs based on the available storage features with various policies (with configuration parameters).</p>
<p>These are given here:</p>
<ul>
<li><span class="packt_screen">Number of disk stripes per object</span> (performance): Default value = 01, maximum value = 12</li>
</ul>
<p style="padding-left: 60px"><strong>Remarks</strong>: VM disk performance gets enhanced with RAID 0 stripe configuration by defining the HDD's number.</p>
<ul>
<li><span class="packt_screen">Flash read cache reservation (%)</span> (performance): Default % = 0, maximum % = 100</li>
</ul>
<p style="padding-left: 60px"><strong>Remarks</strong>: We can leverage this configuration exclusively for VMs, which must have read IOPS issues. This needs to be sorted out, but reservations should be not recommended as per VMware best practices.</p>
<ul>
<li><span class="packt_screen">Number of failures to tolerate</span>, FTT (redundancy): Default value= 01, maximum value = 03</li>
</ul>
<p style="padding-left: 60px"><strong>Remarks</strong>: The FTT number decides the number of host, disk, or network failures a storage object can tolerate. We can tolerate <em>n (0, 1, 2, 3)</em> failures when <em>n+1</em> copies of the disk are created and <em>2n+1</em> hosts or fault domains need to contribute to the storage alongside mirroring. We can tolerate one failure, with minimum four nodes or fault domains and subsequent can tolerate two failures with minimum six hosts or fault domains along with erasure coding. The maximum value is 1 if the disk size is greater than 16 TB.</p>
<p style="padding-left: 60px">These parameters are configured in the <span class="packt_screen">Configure</span> interface:</p>
<ul>
<li><span class="packt_screen">Failure tolerance method</span> (<span class="packt_screen">Performance</span>/<span class="packt_screen">Capacity</span>): Default = <span class="packt_screen">RAID 1 (Mirroring)-Performance</span></li>
</ul>
<p style="padding-left: 60px"><strong>Remarks</strong>: RAID 1 can tackle failure tolerance using mirrors with good performance, while RAID 5/6 helps with failure tolerance by using parity blocks with great space efficiency. RAID 5/6 is only available on all-flash vSAN clusters, and when the <span class="packt_screen">N</span><span class="packt_screen">umber of failures to tolerate</span> (<span class="packt_screen">FTT</span>) is set to <kbd>1</kbd> or <kbd>2</kbd>. A value of <kbd>1</kbd> FTT implies a RAID 5 configuration, and a value of 2 FTT implies a RAID 6 configuration.</p>
<ul>
<li><span class="packt_screen">IOPS limit for object</span> (performance): Default = 0</li>
</ul>
<p style="padding-left: 60px"><strong>Remarks</strong>: The IOPS limit for a disk IOPS is calculated as the number of I/Os using a defined size. It uses a base size of 32 KB by default, so a 64 KB I/O will represent 2 I/O. No limit policy is defined by setting the limit equal to <kbd>0</kbd>.</p>
<ul>
<li><span class="packt_screen">Disable object checksum</span> (override policy): Default = No</li>
</ul>
<p style="padding-left: 60px"><strong>Remarks</strong>: This setting determines whether checksums will be calculated for the data being written to the volume or not. Checksum calculation and error-correction are executed in the background. </p>
<ul>
<li><span class="packt_screen">Force provisioning</span> (override policy): Default = No</li>
</ul>
<p style="padding-left: 60px"><strong>Remarks:</strong> Force provisioning overrides the current policy if it won't comply with the available resources.</p>
<ul>
<li><span class="packt_screen">Object space reservation</span> (thick provisioning %): Default value = 0, maximum = 100</li>
</ul>
<p style="padding-left: 60px"><strong>Remarks</strong>: It will help with a percentage of thick-provisioned storage objects upon VM creation, while the rest of the storage objects are thin-provisioned. When the expected amount of storage is already filled with objects, then it will help in reducing repeatable disk growth operation tasks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">FTT policy with RAID configurations</h1>
                </header>
            
            <article>
                
<p>Policies are configured based on application requirements and are applied based on the objects that are available. The following table lists the FTT policy options that are applied in different scenarios:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/699b2416-8bcb-4065-bae3-d691616a9d56.png" style="width:26.17em;height:8.17em;"/><br/></p>
<p><strong>RAID-1</strong> will be used for the <strong>Fault Tolerance Method</strong> on the host servers. If we are not using the HBA mode for the hosts, then we will have to RAID the individual disks as RAID 0. Sometimes, RAID 5 and RAID 6 over the network are also referred to as erasure coding. This is done inline so that no post-processing is needed. Erasure coding distributes the <strong>RAID5/6</strong> stripe across multiple hosts without any overhead or need of data locality. <strong>RAID-5</strong> needs a minimum of <strong>4</strong> host clusters, with 3+1 logic, and has to sustain one node failure without data loss. This reduces disk capacity consumption. Erasure coding can guarantee capacity reduction. This policy can be executed on a per <strong>v</strong><span><strong>irtual machine disk</strong> (</span><strong>VMDK</strong>) file/disk using the SPDM system.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p><span>The vSAN performance and health service helps with updated health checks for known issues and provides visibility to the end user. It will not help users collect the logs from a customer's site and send them in for support so that the development team will get the incident after the end user has logged a support ticket with issues. Instead, it helps with data that assists the engineering team in enhancing VMware products and related services, resolving issues, and recommend best practices to follow while implementing VMware solutions.</span></p>
<p>In the next chapter, <a href="6e95024c-c15b-43b6-80e8-7975b6bde0af.xhtml" target="_blank">Chapter 3</a>, <em>Security with Workspace One Intelligence</em>, we will learn about how customers are becoming increasingly pressured to provide more intelligent insights about their organizations and user behavior to deliver the best IT service possible. Having different tools and systems that house this insightful data across <strong>mobile device management</strong> (<strong>MDM</strong>), PC, and other third-party systems causes fragmentation of this data and inconsistency in the process of training, as well as the end user experience.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li><em>VMware Virtual SAN Design and Sizing Guide</em>, at<span> </span><a href="https://docs.vmware.com/en/VMware-vSphere/6.7/vsan-671-planning-deployment-guide.pdf">https://www.vmware.com/files/pdf/products/vsan/VSAN_Design_and_Sizing_Guide.pdf</a></li>
<li><em>VMware Virtual SAN Health Check Plugin Guide</em>, at<span> </span><a href="http://www.vmware.com/files/pdf/products/vsan/VMW-GDL-VSAN-Health-Check.pdf">http://www.vmware.com/files/pdf/products/vsan/VMW-GDL-VSAN-Health-Check.pdf</a></li>
<li><em>vSphere 6.0 Configuration Maximums guide</em>, at <a href="https://www.vmware.com/pdf/vsphere6/r60/vsphere-60-configuration-maximums.pdf">https://www.vmware.com/pdf/vsphere6/r60/vsphere-60-configuration-maximums.pdf</a></li>
<li><em>Virtual SAN documentation from the vSphere Storage guide in the VMware vSphere Documentation</em>, at<span> </span><a href="https://www.vmware.com/support/pubs/vsphere-esxi-vcenter-server-pubs.html">https://www.vmware.com/support/pubs/vsphere-esxi-vcenter-server-pubs.html</a></li>
<li><em>VMware Virtual SAN section of Performance Best Practices for VMware vSphere 6.0</em>, at<span> </span><a href="http://www.vmware.com/files/pdf/techpaper/VMware-PerfBest-Practices-vSphere6-0.pdf">http://www.vmware.com/files/pdf/techpaper/VMware-PerfBest-Practices-vSphere6-0.pdf</a></li>
<li><em>Solutions for Poor Network Performance section of vSphere Monitoring and Performance vSphere 6.0</em>, at <a href="https://pubs.vmware.com/vsphere-60/topic/com.vmware.ICbase/PDF/vsphere-esxi-vcenter-server-60-monitoring-performance-guide.pdf" target="_blank">https://pubs.vmware.com/vsphere-60/topic/com.vmware.ICbase/PDF/vsphere-esxi-vcenter-server-60-monitoring-performance-guide.pdf</a></li>
</ul>


            </article>

            
        </section>
    </body></html>