- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Designing Query Strategy Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Query strategies** act as the engine that drives active ML and determines
    which data points get selected for labeling. In this chapter, we aim to provide
    a comprehensive and detailed explanation of the most widely used and highly effective
    query strategy frameworks that are employed in active ML. These frameworks play
    a crucial role in the field of active ML, aiding in selecting informative and
    representative data points for labeling. The strategies that we will delve into
    include uncertainty sampling, query-by-committee, **expected model change** (**EMC**),
    **expected error reduction** (**EER**), and density-weighted methods. By thoroughly
    understanding these frameworks and the underlying principles, you can make informed
    decisions when designing and implementing active ML algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will gain skills that will equip you to design and deploy
    query strategies that extract maximum value from labeling efforts. You will gain
    intuition for matching strategies to datasets and use cases when building active
    ML systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring uncertainty sampling methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding query-by-committee approaches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labeling with EMC sampling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sampling with EER
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding density-weighted sampling methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the code examples demonstrated in this chapter, we have used Python 3.9.6
    with the following packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '`numpy` (version 1.23.5)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scikit-learn` (version 1.2.2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matplotlib` (version 3.7.1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring uncertainty sampling methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Uncertainty sampling** refers to querying data points for which the model
    is least certain about their prediction. These are samples the model finds most
    ambiguous and cannot confidently label on its own. Getting these high-uncertainty
    points labeled allows the model to clarify where its knowledge is lacking.'
  prefs: []
  type: TYPE_NORMAL
- en: In uncertainty sampling, the active ML system queries instances for which the
    current model’s predictions exhibit *high uncertainty*. The goal is to select
    data points that are *near the decision boundary* between classes. Labeling these
    ambiguous examples helps the model gain confidence in areas where its knowledge
    is weakest.
  prefs: []
  type: TYPE_NORMAL
- en: Uncertainty sampling methods select data points close to the **decision boundary**
    because points near this boundary exhibit the highest prediction ambiguity. The
    decision boundary is defined as the point where the model shows the most uncertainty
    in distinguishing between different classes for a given input. Points on the boundary
    represent the most ambiguous, uncertain cases for a model.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2**.1* illustrates the difference between uncertainty sampling and
    random sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21789_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – Uncertainty sampling versus random sampling
  prefs: []
  type: TYPE_NORMAL
- en: For data points that are located far away from the decision boundary (*Figure
    2**.1*) within a class region (labeled as A or B), the model will exhibit a high
    level of confidence in assigning them to that class (for example, >95%). These
    points are considered certain and will not be selected when employing uncertainty
    sampling. However, there is a possibility that some of these points may be chosen
    when using random sampling. For data points that are extremely close to or directly
    on the decision boundary, the model will struggle to distinguish between the classes.
    The predicted class probabilities will be more evenly distributed, with the top
    predictions being very close to each other. Therefore, these points are considered
    uncertain and will be selected when using uncertainty sampling. These important
    data points might have been overlooked when using random sampling. As a result,
    the distance to the boundary correlates to uncertainty – the closest points will
    have the lowest max confidence, the smallest margin between top classes, and the
    highest entropy over the class probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, by selecting points based on metrics such as low confidence, low
    margin, and high entropy, uncertainty sampling queries the instances nearest to
    the decision boundary. We will discuss these metrics in detail in the upcoming
    sections of this chapter. Labeling these provides information to help clarify
    class regions and refine the boundary. The model is unlikely to gain much information
    from examples it can already predict correctly with high confidence. However,
    querying data points that the model is very uncertain about directly provides
    useful information about its gaps. Uncertainty sampling takes advantage of this
    by targeting points with high prediction ambiguity.
  prefs: []
  type: TYPE_NORMAL
- en: For example, an image classifier’s least confident predictions likely correspond
    to challenging out-of-distribution examples that traditional sampling would miss.
    By querying these unusual cases for labels, the model rapidly improves at classifying
    edge cases. Now, let’s discuss some of the common methods that are used for uncertainty
    sampling.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will talk about **least-confidence sampling**, where the data points
    are ranked according to their least-confidence score. This score is obtained by
    subtracting the most confident prediction label for each item from 1, which represents
    100% confidence. To facilitate understanding, it is beneficial to convert the
    uncertainty scores into a range of 0-1, where 1 signifies the highest level of
    uncertainty. The magnitude of the score that’s assigned to each data point lies
    in its association with the uncertainty of the model’s prediction. Consequently,
    data samples with the highest least-confident scores should be given priority
    for annotation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most informative sample, x, can be computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi
    mathvariant="normal">argmax</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>](img/1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi
    mathvariant="normal">argmax</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>](img/2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For instance, let’s say we have a model that classifies samples into three
    different classes. Now, we are trying to rank two samples using least-confidence
    sampling. The predicted probabilities of the two samples are `[0.05, 0.85, 0.10]`
    for sample 1 and `[0.35, 0.15, 0.50]` for sample 2\. Let’s find out which sample
    is the most informative when using the least-confidence sampling method by using
    the following Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code snippet is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Thus, the most informative sample is sample 2.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we can see that sample 2 is chosen when using the least-confidence
    sampling approach because the model’s predictions were the least confident for
    that sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will discuss **margin sampling**. This method is designed to identify
    and select data points that have the smallest disparity in probability between
    the top two predicted classes. By focusing on data points with minimal margin
    between classes, we can effectively prioritize the annotation of data samples
    that result in a higher level of confusion for the model. Therefore, the model’s
    level of uncertainty is higher when it encounters data points with a lower margin
    score, making them ideal candidates for annotation. The formula to calculate the
    score of the most informative data point with the margin sampling method is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi
    mathvariant="normal">argmin</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>](img/3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s use the samples from our previous example again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding script is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: With the margin sampling method, sample 2 is selected as well because it has
    the smallest disparity in probability between the top two predicted classes.
  prefs: []
  type: TYPE_NORMAL
- en: In the **ratio of confidence** method, the data points that have the smallest
    ratio between the probability of the top predicted class and the probability of
    the second most likely class are selected. This targets examples where the model’s
    top two predictions are closest in likelihood. A lower ratio indicates that the
    model is less confident in the top class relative to the second class. By querying
    points with the minimum ratio between the top two class probabilities, this technique
    focuses on cases where the model is nearly equivocal between two classes. Getting
    these boundary points labeled will push the model to gain greater confidence in
    the true class. A lower ratio means higher ambiguity, so the ratio of confidence
    sampling finds points where the model is most unsure of which class is correct.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can calculate the score of the most informative data point using the ratio
    of confidence sampling method via the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi
    mathvariant="normal">argmin</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>](img/4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once again, we’ll utilize the samples that we used previously for this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this script is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: So, sample 2 is selected when using the ratio of confidence sampling method
    as it has the smallest ratio between the probability of the top predicted class
    and the probability of the second most likely class.
  prefs: []
  type: TYPE_NORMAL
- en: Another method is **entropy sampling**. This method selects data points that
    have the highest entropy across the probability distribution over classes. Entropy
    represents the overall uncertainty in the predicted class probabilities. Higher
    entropy means the model is more uncertain, with a more uniform probability spread
    over classes. Lower entropy indicates confidence, with probability concentrated
    on one class.
  prefs: []
  type: TYPE_NORMAL
- en: 'By querying points with maximum entropy, this technique targets instances where
    the model’s predicted class probabilities are most evenly distributed. These highly
    uncertain points provide the most information gain since the model cannot strongly
    favor one class – its predictions are maximally unsure. Getting these high entropy
    points labeled enables the model to gain more confidence in areas in which it
    is the most uncertain. Overall, entropy sampling finds points with the highest
    total ambiguity. The formula to calculate the score of the most informative data
    point with the entropy sampling method is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi
    mathvariant="normal">argmax</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mo>-</mml:mo><mml:mrow><mml:munder><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mi
    mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi
    mathvariant="normal">g</mml:mi><mml:mo>⁡</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>](img/5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s use our sample examples again with this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This script outputs the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Using entropy sampling, sample 2 was chosen as it has the highest entropy across
    the probability distribution over classes.
  prefs: []
  type: TYPE_NORMAL
- en: These common uncertainty sampling techniques provide simple but effective strategies
    to identify highly ambiguous points to query.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s explore the key benefits that uncertainty sampling provides for
    active ML:'
  prefs: []
  type: TYPE_NORMAL
- en: Uncertainty sampling is a conceptually intuitive query strategy that is efficient
    to compute. Metrics such as confidence, margin, ratio, and entropy have clear
    uncertainty interpretations and can be calculated quickly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It actively enhances model confidence in areas where it is uncertain, expanding
    knowledge boundaries. For example, a sentiment classifier can gain more certainty
    on ambiguous reviews containing rare phrases by querying the most uncertain cases
    for their true sentiment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uncertainty sampling is widely applicable across classification tasks and model
    types such as **support vector machines** (**SVMs**), logistic regression, random
    forests, and **neural networks** (**NNs**). Uncertainty applies broadly to classification
    tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uncertainty sampling is useful for anomaly detection by finding ambiguous outliers
    the model cannot explain. Uncertainty highlights unusual cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can identify labeling errors by seeking points with inconsistent predictions
    between models. High uncertainty may indicate noisy data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, uncertainty sampling is a highly effective and versatile active ML
    method. It can be used in various domains and is intuitive and efficient. It helps
    expand a model’s capabilities and discover unknown points. Whether it’s used for
    classification, regression, or other ML tasks, uncertainty sampling consistently
    improves model performance. By selecting uncertain data points for annotation,
    the model learns from informative examples and improves predictions. It has proven
    useful in natural language processing, computer vision, and data mining. Uncertainty
    sampling actively acquires new knowledge and enhances ML models. While uncertainty
    sampling focuses on points the model is individually unsure of, query-by-committee
    approaches aim to add diversity by identifying points where an ensemble of models
    disagrees. We will discuss query-by-committee approaches in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding query-by-committee approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Query-by-committee** aims to add diversity by querying points where an ensemble
    of models disagrees the most. Different models will disagree where the data is
    most uncertain or ambiguous.'
  prefs: []
  type: TYPE_NORMAL
- en: In the query-by-committee approach, a group of models is trained using a labeled
    set of data. By doing so, the ensemble can work together and provide a more robust
    and accurate prediction.
  prefs: []
  type: TYPE_NORMAL
- en: One interesting aspect of this approach is that it identifies the data point
    that causes the most disagreement among the ensemble members. This data point
    is then chosen to be queried to obtain a label.
  prefs: []
  type: TYPE_NORMAL
- en: 'The reason why this method works well is because different models tend to have
    the most disagreement on difficult and boundary examples, as depicted in *Figure
    2**.2*. These are the instances where there is ambiguity or uncertainty, and by
    focusing on these points of maximal disagreement, the ensemble can gain consensus
    and make more confident predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Query-by-committee sampling with five unlabeled data points](img/B21789_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – Query-by-committee sampling with five unlabeled data points
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2**.2* reveals a disagreement between models 1 and 4, as opposed to
    models 2 and 3, regarding data point 2\. A similar pattern can be observed with
    data point 4\. Therefore, data points 2 and 4 have been chosen to be sent to the
    oracle for labeling.'
  prefs: []
  type: TYPE_NORMAL
- en: Query-by-committee is a widely used and effective active ML strategy that addresses
    the limitations of uncertainty sampling. While uncertainty sampling can be biased
    toward the current learner and may overlook crucial examples that are not within
    its estimator’s focus, query-by-committee overcomes these challenges. This approach
    involves maintaining multiple hypotheses simultaneously and selecting queries
    that lead to disagreements among these hypotheses. By doing so, it ensures a more
    comprehensive and diverse exploration of the data, ultimately enhancing the learning
    process. For instance, a committee of image classifiers may heavily disagree on
    ambiguous images that traditional sampling fails to capture. By querying labels
    for images with maximal disagreement, such as varied predictions for an unusual
    object, the committee collectively improves.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the common techniques for query-by-committee sampling include **maximum
    disagreement**, **vote entropy**, and **average KL divergence**, all of which
    we will discuss now.
  prefs: []
  type: TYPE_NORMAL
- en: Maximum disagreement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This simple approach looks at direct disagreement in the predicted labels between
    committee members. The data points where most ensemble members disagree on the
    label are queried. For example, if a three-model committee’s label votes for a
    point are (1, 2, 3), this exemplifies maximum disagreement as each model predicts
    a different class. Querying the points with the most label conflicts helps us
    focus only on cases that divide the committee. Maximum disagreement target instances
    create the largest rifts within the ensemble. Getting these high disagreement
    points labeled will aim to resolve the core differences between models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s explore a numerical example of the query-by-committee maximum disagreement
    method in active ML. For this example, we will consider a pool of 10 unlabeled
    data points, as shown in *Figure 2**.3*, that we want to label to train a classifier.
    We create two committee members (models) called M1 and M2\. We evaluate each unlabeled
    data point using M1 and M2 to get the following predicted labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – A numerical example to illustrate the query-by-committee maximum
    disagreement method](img/B21789_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – A numerical example to illustrate the query-by-committee maximum
    disagreement method
  prefs: []
  type: TYPE_NORMAL
- en: Then, we select the data point with the maximum disagreement between the two
    committee members. Here, data points 1, 4, 5, 8, and 9 have different predicted
    labels by M1 and M2\. We select one of these points, say point 4, to query the
    true label from an oracle. We then add the newly labeled point to retrain the
    committee members.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can do this with a simple Python script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This process is then repeated, querying points with maximum disagreement in
    labels predicted by the committee, until we reach sufficient performance. The
    most informative points surface through the maximum disagreement of the committee
    members.
  prefs: []
  type: TYPE_NORMAL
- en: Vote entropy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This technique calculates the entropy over the label votes from each model
    in the ensemble committee. **Entropy** represents the overall uncertainty, where
    higher entropy means the models have a wider spread of predictions. Lower entropy
    indicates the models largely agree on the label. Querying the data points with
    maximum entropy in the vote distribution helps target the instances where the
    committee displays the highest collective uncertainty and disagreement. Getting
    these maximally entropic points labeled will push the ensemble toward greater
    consensus. Overall, vote entropy identifies cases that divide the committee the
    most, focusing labeling on their disagreements. If we go back to using a numerical
    example to better understand how the query-by-committee vote entropy method works,
    we can once again use a pool of 10 unlabeled data points, as shown in *Figure
    2**.4*, and a committee of two models, M1 and M2\. We get the following predicted
    probabilities for each class on the data points:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – A numerical example to illustrate the query-by-committee vote
    entropy method](img/B21789_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – A numerical example to illustrate the query-by-committee vote entropy
    method
  prefs: []
  type: TYPE_NORMAL
- en: 'We calculate the vote entropy for each point as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>H</mi><mfenced
    open="(" close=")"><mi>x</mi></mfenced><mo>=</mo><mo>−</mo><mrow><munder><mo>∑</mo><mi>i</mi></munder><mrow><mi>P</mi><mfenced
    open="(" close=")"><mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></mfenced><mi mathvariant="normal">l</mi><mi
    mathvariant="normal">o</mi><mi mathvariant="normal">g</mi><mo>(</mo><mi>y</mi><mo>|</mo><mi>x</mi><mo>)</mo></mrow></mrow></mrow></mrow></math>](img/6.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>P</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/7.png)
    is averaged over the committee members.
  prefs: []
  type: TYPE_NORMAL
- en: 'The probabilities from the committee members are averaged when calculating
    the vote entropy because we want to measure the total uncertainty or disagreement
    of the entire committee on a data point. By averaging, we essentially get the
    *vote* of the full committee on the probabilities of each class, rather than just
    considering individual members’ predictions. This allows us to select the data
    points where the committee has the most uncertainty or disagrees the most with
    its predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – A numerical example to illustrate the query-by-committee vote
    entropy method with averages per class and entropy calculated](img/B21789_02_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 – A numerical example to illustrate the query-by-committee vote entropy
    method with averages per class and entropy calculated
  prefs: []
  type: TYPE_NORMAL
- en: The points with maximum entropy will have the most disagreement among models.
    In *Figure 2**.5*, points 1, 4, 5, 8, and 9 have the highest entropy, so we query
    their labels. The next step would be to retrain the models and repeat the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can write this with some Python code as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this script is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will move our focus to computing predictions using the KL divergence
    method.
  prefs: []
  type: TYPE_NORMAL
- en: Average KL divergence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This method measures the **Kullback-Leibler divergence** (**KL divergence**)
    between each committee member’s predicted label distribution and the average predicted
    distribution across all members.
  prefs: []
  type: TYPE_NORMAL
- en: 'KL divergence is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><msub><mi>D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo>(</mo><mi>P</mi><mo>|</mo><mfenced
    open="|" close=")"><mi>Q</mi></mfenced><mo>=</mo><mo>−</mo><mrow><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></munder><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>)</mo><mi
    mathvariant="normal">l</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">g</mi><mo>(</mo><mfrac><mrow><mi>Q</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac><mo>)</mo></mrow></mrow></mrow></mrow></mrow></math>](img/8.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, P and Q are two probability distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data points with the highest average KL divergence are then queried. A
    higher KL divergence indicates a larger difference between a model’s predictions
    and the committee consensus. Querying points with maximum divergence targets instances
    where individual models strongly disagree with the overall ensemble. Labeling
    these high-divergence points will bring the individual models closer to the committee
    average. Average KL divergence identifies cases with outlying model predictions
    to focus labeling on reconciliation. Let’s take a look at our numerical example
    for the query-by-committee average KL divergence method. Again, we’re using the
    pool of 10 unlabeled data points, as shown in *Figure 2**.6*, and a committee
    of two models, M1 and M2\. We get the predicted class probabilities on each data
    point from M1 and M2 and calculate the KL divergence between M1’s and M2’s predictions
    for each point:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – A numerical example to illustrate the query-by-committee average
    KL divergence method](img/B21789_02_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 – A numerical example to illustrate the query-by-committee average
    KL divergence method
  prefs: []
  type: TYPE_NORMAL
- en: We average the KL divergence between M1 and M2, and M2 and M1\. We calculate
    the KL divergence in both directions (KL(M1||M2) and KL(M2||M1)) – because KL
    divergence is asymmetric, it will give different values depending on the direction.
  prefs: []
  type: TYPE_NORMAL
- en: The KL divergence from M1 to M2, KL(M1||M2), measures how well M2’s distribution
    approximates M1’s. On the other hand, KL(M2||M1) measures how well M1’s distribution
    approximates M2’s.
  prefs: []
  type: TYPE_NORMAL
- en: In query-by-committee, we want to measure the total disagreement between the
    two committee members’ distributions. Just using KL(M1||M2) or just using KL(M2||M1)
    will not capture the full divergence. By taking the average of KL(M1||M2) and
    KL(M2||M1), we get a symmetric measure of the total divergence between the two
    distributions. This gives a better indication of the overall disagreement between
    the two committee members on a data point.
  prefs: []
  type: TYPE_NORMAL
- en: Taking the average KL in both directions ensures we select the points with maximum
    mutual divergence between the two models’ predictions. This surfaces the most
    informative points for labeling to resolve the committee’s uncertainty. The point
    with maximum average KL divergence has the most disagreement. So, here, points
    1, 4, 5, and 9 have the highest average KL divergence. We would then query these
    labels, retrain the models, and repeat the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can write this with some Python code as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon exploring different methods that are used to perform query-by-committee
    sampling, we’ve noticed that it can be quite computationally intensive. Indeed,
    as shown in *Figure 2**.7*, the query-by-committee technique is an iterative approach
    that requires retraining the models from the committee every time new labeled
    data is added to the training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – The iteration process in the query-by-committee sampling technique](img/B21789_02_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 – The iteration process in the query-by-committee sampling technique
  prefs: []
  type: TYPE_NORMAL
- en: 'In conclusion, this technique is designed to identify informative query points
    by quantifying the level of disagreement among the ensemble models and offers
    several key advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: It promotes diversity by finding points that various models interpret differently.
    The techniques can effectively prioritize query points that are likely to provide
    valuable information, thus improving the overall quality of the query-based learning
    process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It encourages exploration by actively seeking out query points that are less
    predictable or commonly known, allowing for a more comprehensive understanding
    of the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides the ability to construct committees with an array of distinct models
    such as SVMs, NNs, and many others. This versatility allows for a diverse range
    of strategies and approaches to be employed when making important decisions. By
    leveraging these various models, you can gain deeper insights and improve the
    overall performance of your committee. The query-by-committee approach differs
    from traditional techniques such as bagging and boosting. Its main objective is
    to choose the most informative unlabeled data points for labeling and inclusion
    in the training set. On the other hand, traditional ensemble methods such as bagging
    and boosting focus on combining multiple models to enhance overall predictive
    performance. Indeed, query-by-committee methods calculate disagreement between
    committee members to find optimal queries for labeling, as we have seen previously.
    Traditional ensembles combine predictions through voting or averaging to produce
    a unified prediction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is very useful in situations where the unlabeled data pool contains a limited
    representation of the underlying distribution. By combining the opinions and predictions
    of different committee members, query-by-committee methods can effectively address
    the challenges posed by poorly covered distributions in unlabeled data pools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By leveraging the varying opinions of the committee, query-by-committee enhances
    the overall performance of the learning system.
  prefs: []
  type: TYPE_NORMAL
- en: We will now delve deeper into the implementation of EMC strategies and explore
    their potential benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Labeling with EMC sampling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: EMC aims to query points that will induce the greatest change in the current
    model when labeled and trained on. This focuses labeling on points with the highest
    expected impact.
  prefs: []
  type: TYPE_NORMAL
- en: EMC techniques involve selecting a specific data point to label and learn from
    to cause the most significant alteration to the current model’s parameters and
    predictions. The core idea is to query the point that would impact the maximum
    change to the model’s parameters if we knew its label. By carefully identifying
    this particular data point, the EMC method aims to maximize the impact on the
    model and improve its overall performance. The process involves assessing various
    factors and analyzing the potential effects of each data point, ultimately choosing
    the one that is expected to yield the most substantial changes to the model, as
    depicted in *Figure 2**.8*. The goal is to enhance the model’s accuracy and make
    it more effective in making predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we refer to querying points that lead to larger updates in the model targets,
    what we are discussing is identifying highly informative examples located in uncertain
    areas of the input space. These examples play a crucial role in influencing and
    enhancing the model’s performance. By paying attention to these specific instances,
    we can gain deeper insights into the complexities and subtleties of the input
    space, resulting in a more thorough understanding and improved overall outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – EMC sampling](img/B21789_02_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 – EMC sampling
  prefs: []
  type: TYPE_NORMAL
- en: The initial model is trained using the training dataset. Then, the unlabeled
    samples are evaluated based on the changes in model outputs after including them
    in the training set. In *Figure 2**.8*, the graphs show the resulting **model
    output change** (**MOC**) for three example samples. The sample that leads to
    the largest output change, when considering all data, is chosen to be labeled
    next.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, in EMC sampling, the process begins by ranking the unlabeled
    examples. This ranking is determined by estimating the expected change that would
    occur in the model’s predictions if each example were to be labeled. This estimation
    takes into account various factors and considerations, ultimately providing a
    basis for the prioritization of labeling.
  prefs: []
  type: TYPE_NORMAL
- en: 'This estimation is typically based on calculating the **expected gradient length**
    (**EGL**). The EGL method estimates the expected length of the gradient of the
    loss function if the model was trained on the newly labeled point. When training
    discriminative probabilistic models, gradient-based optimization is commonly used.
    To assess the *change* in the model, we can examine the size of the training gradient.
    This gradient refers to the vector that is employed to update the parameter values
    during the training process. In simpler terms, the learner should choose the instance,
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>G</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup></mml:math>](img/9.png),
    that, when labeled and included in the labeled dataset, (![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi mathvariant="script">L</mml:mi></mml:math>](img/10.png)),
    would result in the greatest magnitude for the new training gradient:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msubsup><mi>x</mi><mrow><mi>E</mi><mi>G</mi><mi>L</mi></mrow><mi
    mathvariant="normal">*</mi></msubsup><mo>=</mo><munder><mi>argmax</mi><mi>x</mi></munder><mrow><munder><mo>∑</mo><mi>i</mi></munder><mrow><mi>P</mi><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>|</mo><mi>x</mi><mo>;</mo><mi>θ</mi></mrow></mfenced><mfenced
    open="‖" close="‖"><mrow><mo>∇</mo><mi mathvariant="script">l</mi><mo>(</mo><mi
    mathvariant="script">L</mi><mo>∪</mo><mfenced open="〈" close="〉"><mrow><mi>x</mi><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub></mrow></mfenced><mo>;</mo><mi>θ</mi><mo>)</mo></mrow></mfenced></mrow></mrow></mrow></mrow></math>](img/11.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ||.|| is the Euclidean norm of each resulting gradient vector, θ is the
    model parameters, x is an unlabeled point, y is the predicted label for x, and
    ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mo>∇</mo><mi
    mathvariant="script">l</mi><mo>(</mo><mi mathvariant="script">L</mi><mo>∪</mo><mfenced
    open="〈" close="〉"><mrow><mi>x</mi><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub></mrow></mfenced><mo>;</mo><mi>θ</mi><mo>)</mo></mrow></mrow></mrow></math>](img/12.png)
    is the new gradient that would be obtained by adding the training tuple, ![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mfenced
    open="⟨" close="⟩" separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/13.png),
    to the labeled dataset, (![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi mathvariant="script">L</mml:mi></mml:math>](img/14.png)).
    Data points that result in a longer expected gradient are prioritized for querying.
    A longer gradient indicates a greater expected change in the model parameters
    during training. By selecting points with high expected gradient length, the model
    focuses on samples that will highly influence the model once labeled. This targets
    points in uncertain regions that will have an outsized impact on updating model
    predictions. In short, EGL identifies data points that are likely to substantially
    reshape the decision boundary.
  prefs: []
  type: TYPE_NORMAL
- en: By employing this technique, the algorithm can pinpoint and identify the specific
    data points that are anticipated to yield substantial alterations in the model’s
    predictions. The selected examples are subsequently sent for labeling as they
    are believed to possess the most value in terms of training the model effectively.
    Once designated, these informative samples are seamlessly integrated into the
    existing training data, thereby facilitating the necessary updates and improvements
    to the model’s overall performance and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several key advantages of the EMC method:'
  prefs: []
  type: TYPE_NORMAL
- en: Its ability to actively seek out influential and under-represented regions within
    the input space. This means that it can effectively identify areas that may have
    been overlooked or not given enough attention in a traditional modeling approach.
    Suppose we are training a model to predict housing prices. The input features
    are things such as square footage, number of bedrooms, location, and so on. Using
    a traditional modeling approach, we may collect a random sample of houses to train
    the model on. However, this could lead to certain neighborhoods or house styles
    being under-represented if they are less common. The EMC method would analyze
    the current model and identify areas where new training data would likely lead
    to the largest change in the model predictions. For example, it may find that
    adding more samples from older houses could better calibrate the model’s understanding
    of how age affects price, or gathering data from a new suburban development that
    is under-represented could improve the performance of houses in that area. By
    actively seeking these influential regions, EMC can make the model more robust
    with fewer overall training examples. It reduces the risk of underfitting certain
    areas of the input space compared to passive or random data collection. It can
    help uncover hidden patterns or relationships that may not be immediately apparent,
    further enhancing the overall understanding of the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is compatible with probabilistic and kernel-based models. By leveraging the
    probabilistic nature of these models, the EMC method can provide insightful and
    accurate predictions. Additionally, its compatibility with kernel-based models
    allows for an enhanced understanding of complex data patterns and relationships.
    This combination of features makes the EMC method a powerful tool for analyzing
    and interpreting data in a wide range of domains.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It allows for estimation without the need for full retraining at each step.
    This means that the process can be more efficient and less time-consuming as it
    eliminates the need to repeatedly train the model from scratch. Instead, the method
    enables model changes to be estimated by focusing on the expected changes in the
    model’s parameters. By utilizing this approach, you can save valuable time and
    resources while still obtaining accurate and reliable estimations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, EMC queries aim to identify points with the highest potential impact
    on the model. It selects those with the maximum expected impact. This method is
    widely discussed in literature but not implemented in practice due to its high
    computational cost.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll explore EER sampling. This technique reduces the model’s error by
    selecting points that are expected to contribute the most to error reduction.
    By strategically sampling these points, we can improve overall model accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling with EER
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'EER focuses on measuring the potential decrease in generalization error instead
    of the expected change in the model, as seen in the previous approach. The goal
    is to estimate the anticipated future error of a model by training it with the
    current labeled set and the remaining unlabeled samples. EER can be defined as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><msub><mi>E</mi><msub><mover><mi>P</mi><mo
    stretchy="true">ˆ</mo></mover><mi mathvariant="script">L</mi></msub></msub><mo>=</mo><mrow><msub><mo>∫</mo><mi>x</mi></msub><mrow><mi>L</mi><mfenced
    open="(" close=")"><mrow><mi>P</mi><mfenced open="(" close=")"><mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></mfenced><mo>,</mo><mover><mi>P</mi><mo
    stretchy="true">ˆ</mo></mover><mfenced open="(" close=")"><mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></mfenced></mrow></mfenced><mi>P</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow></mrow></mrow></math>](img/15.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi
    mathvariant="script">L</mml:mi></mml:math>](img/16.png) is the pool of paired
    labeled data, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mi>P</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/17.png),
    and ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi
    mathvariant="script">L</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/18.png)
    is the estimated output distribution. L is a chosen loss function that measures
    the error between the true distribution, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>P</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/19.png),
    and the learner’s prediction, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mover
    accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi
    mathvariant="script">L</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/20.png).
  prefs: []
  type: TYPE_NORMAL
- en: This involves selecting the instance that is expected to have the lowest future
    error (referred to as *risk*) for querying. This focuses active ML on reducing
    long-term generalization errors rather than just immediate training performance.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, EER selects unlabeled data points that, when queried and learned
    from, are expected to significantly reduce the model’s errors on new data points
    from the same distribution. By focusing on points that minimize future expected
    errors, as shown in *Figure 2**.9*, EER aims to identify valuable training examples
    that will enhance the model’s ability to generalize effectively. This technique
    targets high-value training examples that will improve the model’s performance
    by minimizing incorrect predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach helps prevent short-term overfitting by avoiding the inclusion
    of redundant similar examples and instead focusing on diverse edge cases that
    better span the feature space. For instance, in the case of an image classifier,
    the technique may prioritize the inclusion of diverse edge cases that capture
    a wide range of features rather than including redundant similar examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – EER sampling](img/B21789_02_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.9 – EER sampling
  prefs: []
  type: TYPE_NORMAL
- en: Computing the expected model’s prediction error can be done using various loss
    functions, such as the log loss, which is defined as ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>L</mi><mo>=</mo><mrow><msub><mo>∑</mo><mrow><mi>y</mi><mo>∈</mo><mi>Y</mi></mrow></msub><mrow><mi>P</mi><mfenced
    open="(" close=")"><mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></mfenced><mi mathvariant="normal">l</mi><mi
    mathvariant="normal">o</mi><mi mathvariant="normal">g</mi><mo>(</mo><msub><mover><mi>P</mi><mo
    stretchy="true">ˆ</mo></mover><mi mathvariant="script">L</mi></msub><mfenced open="("
    close=")"><mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></mfenced><mo>)</mo></mrow></mrow></mrow></mrow></math>](img/21.png),
    or the 0/1 loss, which is defined as ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>L</mi><mo>=</mo><mn>1</mn><mo>−</mo><munder><mi>max</mi><mrow><mi>y</mi><mo>∈</mo><mi>Y</mi></mrow></munder><msub><mover><mi>P</mi><mo
    stretchy="true">ˆ</mo></mover><mi mathvariant="script">L</mi></msub><mfenced open="("
    close=")"><mrow><mi>y</mi><mo>|</mo><mi>x</mi></mrow></mfenced></mrow></mrow></math>](img/22.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'EER incurs a significant time cost due to the estimation of error reduction.
    To calculate the expected generalization error, the classifier must be re-optimized
    for each data point, considering its possible labels. Additionally, it is necessary
    to re-infer the labels of other data points. However, this technique offers a
    couple of key advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: It allows direct optimization of the true objective of reducing the generalization
    error instead of solely focusing on improving training performance. By prioritizing
    the reduction of the generalization error, EER allows for more accurate and reliable
    predictions in real-world scenarios. This not only enhances the overall performance
    of the model but also ensures that it can effectively generalize to unseen data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It considers the impact on unseen data points, going beyond just the training
    set. By doing so, EER helps to mitigate overfitting, which is a common challenge
    in ML and statistical modeling. Overfitting occurs when a model performs exceedingly
    well on the training data but fails to generalize well to new, unseen data. EER
    tackles this issue head-on by incorporating a comprehensive evaluation of potential
    errors and their reduction. This ensures that the model’s performance is not limited
    to the training set and instead extends to real-world scenarios, making it a valuable
    tool in data-driven decision-making.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EER is a predictive and robust query framework that focuses on maximally reducing
    the model’s generalization error. Similar to the EMC method, the EER method is
    a topic of extensive discussion in literature. However, it has not been widely
    adopted in practical applications primarily because of the significant computational
    resources it demands.
  prefs: []
  type: TYPE_NORMAL
- en: The next sampling method that we will explore, density-weighted sampling, aims
    to improve diversity by selecting representative points from all density regions.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding density-weighted sampling methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Density-weighted methods** are approaches that aim to carefully choose points
    that accurately represent the densities of their respective local neighborhoods.
    By doing so, these methods prioritize the labeling of diverse cluster centers,
    ensuring a comprehensive and inclusive representation of the data.'
  prefs: []
  type: TYPE_NORMAL
- en: Density-weighted techniques are highly beneficial and effective when it comes
    to querying points. These techniques utilize a clever combination of an informativeness
    measure and a density weight. An **informativeness measure** provides a score
    of how useful a data point would be for improving the model if we queried its
    label. Higher informativeness indicates the point is more valuable to label and
    add to the training set. In this chapter, we have explored several informativeness
    measures, such as uncertainty and disagreement. In density-weighted methods, the
    informativeness score is combined with a density weight to ensure we select representative
    and diverse queries across different regions of the input space. This is done
    by assigning a weight to each data point based on both its density and its informativeness.
    Data points with higher informativeness and lower density will be given a higher
    weight, and will therefore be more likely to be selected for labeling. Points
    in dense clusters receive lower weights. The density and informativeness are combined
    through multiplicative, exponential, or additive formulations. This balances informativeness
    with density to achieve diversity.
  prefs: []
  type: TYPE_NORMAL
- en: 'The density weight represents the density of the local neighborhood surrounding
    each point, allowing for a more comprehensive and accurate sampling of points
    from different densities, as shown in *Figure 2**.10*. This approach avoids the
    pitfall of solely focusing on dense clusters, which could result in redundant
    points. By taking into account the density weight, these techniques guarantee
    that the selected points effectively capture the overall distribution of the dataset.
    As a result, the obtained results are more meaningful and provide deeper insights
    into the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – Density-weighted sampling](img/B21789_02_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.10 – Density-weighted sampling
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 2**.10*, we can observe the significance of sample density in the
    active ML process. With instance 1 being positioned near the decision boundary,
    this makes it a prime candidate for being chosen as the most uncertain one. However,
    if we analyze the situation more closely, it becomes apparent that selecting instance
    2 would be more advantageous in terms of enhancing the overall quality of the
    model. This is because instance 2 not only represents itself accurately but also
    acts as a representative for other instances within the data distribution. Therefore,
    its inclusion in the active ML process can lead to more comprehensive and reliable
    model improvements.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing queries that would select instance 2 in the preceding example can
    be done with various density-weighted sampling methods, such as kNN density, **kernel
    density estimation** (**KDE**), K-means clustering, and **maximum mean** **discrepancy**
    (**MMD**).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with the imports and generating the dummy data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s understand and apply different density-based techniques for our
    `X` sample data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**kNN density** calculates the local density around each data point using its
    *k-nearest neighbors*. The density is estimated by taking the inverse of the average
    distance to the k-closest points. Denser points have higher density, while isolated
    points have lower density. The estimated density is then used as a weight. When
    combined with informativeness criteria such as uncertainty, points in sparser
    neighborhoods get higher density weights, increasing their priority. kNN density
    weighting provides an efficient way to increase sample diversity and avoid over-sampling
    clusters when querying:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**KDE** estimates the local density around each point using a kernel function
    centered on the point. Typically, a Gaussian kernel is used. The densities from
    the kernels of nearby points are summed to get the overall estimated density.
    As with kNN density, points in sparser regions will have lower kernel density
    compared to crowded areas. These density values can be used as weights when combined
    with informativeness criteria. Points in isolated clusters will be up-weighted,
    increasing their query priority. KDE provides a smooth, probabilistic estimate
    of local density, as opposed to the discrete clusters of kNN. It is more computationally
    expensive than kNN but can be implemented efficiently in high dimensions. KDE
    weighting focuses sampling on representative low-density points:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**K-means density** clusters the unlabeled data points using k-means into k
    clusters. The size of each cluster indicates its density – smaller clusters correspond
    to sparser regions. This cluster density can be used as a weight when combined
    with informativeness criteria. Points in smaller, tighter clusters get increased
    weight, making them more likely to be queried. This balances sampling across varying
    densities. K-means provides a simple way to estimate density and identify representative
    points from all densities. It is fast and scales well to large datasets. One limitation
    is determining the number of clusters, k, upfront. K-means density weighting focuses
    active ML on diverse cases from all densities equally:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**MMD** measures the *distance* between distributions to identify points in
    low-density regions. The MMD between a point’s neighborhood distribution and the
    overall data distribution is calculated. A higher MMD indicates that the local
    region is very different from the overall distribution, so it is likely a low-density
    area. These MMD density scores are then used as weights when combined with informativeness
    measures. Points in sparse, isolated regions with high MMD get increased priority
    for querying. This results in balanced sampling across varying densities, thereby
    avoiding cluster oversampling. MMD provides a principled way to estimate density
    that captures useful nonlinear variations. MMD density weighting focuses active
    ML on representative low-density areas:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s visualize these density-weight sampling methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting graph is presented in *Figure 2**.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – A comparison of different density-weighted sampling methods](img/B21789_02_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.11 – A comparison of different density-weighted sampling methods
  prefs: []
  type: TYPE_NORMAL
- en: 'Density-weighted sampling methods, including the ones mentioned previously,
    offer diverse advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: They can help improve the performance of the ML model by selecting samples that
    are more likely to be informative. This is because samples that are in high-density
    regions of the data are more likely to be representative of the underlying distribution
    and therefore more likely to be informative for the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They help reduce the number of labeled samples needed to train the model. This
    is because density-weighted sampling can help focus the labeling effort on the
    most informative samples, which can lead to faster convergence of the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They can be used with any type of data. Density-weighted sampling does not make
    any assumptions about the data distribution, so it can be used with any type of
    data, including structured and unstructured data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To conclude, density weighting, which is a technique that’s used to increase
    the diversity and coverage of samples, offers an effective and efficient approach.
    By assigning weights to each sample based on their density, this method ensures
    that the resulting sample set represents the underlying population more accurately.
    With this approach, you can obtain a more comprehensive understanding of the data,
    allowing for better decision-making and analysis. Overall, density weighting is
    a valuable tool in research and statistical analysis, allowing you to highlight
    hidden patterns and trends that might otherwise be overlooked.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have discussed several query strategies, let’s compare them to
    understand how they fare against each other:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Comparison chart for query strategies](img/B21789_02_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.12 – Comparison chart for query strategies
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2**.12* summarizes and compares various query strategies that have
    been discussed in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered key techniques such as uncertainty sampling, query-by-committee,
    EMC, EER, and density weighting for designing effective active ML query strategies.
    Moving forward, in the next chapter, our focus will shift toward exploring strategies
    for managing the human in the loop. It is essential to optimize the interactions
    with the oracle labeler to ensure maximum efficiency in the active ML process.
    By understanding the intricacies of human interaction and leveraging this knowledge
    to streamline the labeling process, we can significantly enhance the efficiency
    and effectiveness of active ML algorithms.In the next chapter we will discuss
    how to manage the role of human labelers in active ML.
  prefs: []
  type: TYPE_NORMAL
