- en: Sovereign Crisis - NLP and Topic Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuing with the detection of economic problems in European countries, in
    this chapter, we will try to replicate country ratings, provided by Standard &
    Poor's, using both quantitative and qualitative information.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is an interesting real-case application, because we will use some
    basic text-mining techniques to replicate Standard & Poor's credit ratings. For
    this purpose, we will use the country reports issued by the European Commission
    for the European member states.
  prefs: []
  type: TYPE_NORMAL
- en: We will perform a text-mining process to extract combinations of words or useful
    terms to predict sovereign ratings.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Predicting country ratings using macroeconomic information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing decision trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting sovereign ratings using European country reports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting country ratings using macroeconomic information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our clustering model, discussed in [Chapter 6](5c1b431c-46f9-42b6-b3e7-e583b1996cd5.xhtml),
    *Visualizing Economic Problems in the European Union*, using self-organizing maps,
    all the available data was used. Now, in order to train a model to be able to
    predict sovereign ratings, we need to split the data into two samples: train and
    test.'
  prefs: []
  type: TYPE_NORMAL
- en: That's not new for us. When we tried to develop different models to predict
    a bank's failures, we used the `caTools` package to split the data, while considering
    our target variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same procedure is used again here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you can print the following statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Thus, the test sample represents 25% of the total data. Moreover, the relative
    ratios of different credit ratings are preserved in both the train and test samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Both samples will be standardized. Again, the `caret` package is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The transformation should be carried out considering only the training sample,
    and then applied on the test sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are two additional train and test samples, replacing the original variables
    into transformed variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see how variables are related to the target variable (rating). For this
    purpose, we first convert the target variable into a `factor` variable, and then
    we will create different box plots by rating the category for each variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output for the current account balance of a country (**CARA**)
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3e3ef41a-0d33-49b7-a76d-1c9e213f0a01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is the output for the consumer prices growth rate (**DCPI**)
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e3cf52a4-bf5c-47a0-b3ed-d3359a2e070b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is the output for the GDP growth (**DGPD**) variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/621b6cc6-2722-4d9b-bcdb-32576d9809f4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is the output for the international reserves (**ILMA**) variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72fda116-00c0-489f-9911-6244ae3bc836.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is the output for the mean of the six worldwide governance indicators
    (**MEANWGI**) variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f6736dcf-60cf-439d-877b-02febf226b48.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is the output for the budget balance as a percentage of the GDP
    (**PSBR**) variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e16a2559-9660-457a-89a5-df019eed4584.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is the output for the public debt ratio (**PUDP**) variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/523d46cf-1797-4170-9f4a-a151dffa17ec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is output for the total imports less total exports of goods and
    services as a percentage of the GDP (**TDRA**) variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9dfa7f0f-8679-4fd7-99ef-0e9a92b4a17b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is the output for the GDP per head (**YPCA**) variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/212e3c8e-257e-4561-b4aa-4ee6e87577c6.png)'
  prefs: []
  type: TYPE_IMG
- en: These graphs are useful to see certain patterns in the data and how variables
    can help to predict credit ratings.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the box plot for variable public debt (% of GDP), or the `PUDP`,
    shows that countries with the lowest ratings display higher variables on average
    in this variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, let''s use the last previous plot, but this time give
    more detail about the countries included in each rating category:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the more detailed YPCA plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8c31d980-eb81-46c4-8b29-555132d3fd02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s look at another alternative:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the Density plot for MeanWGI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/66d9bf6a-505b-4af0-b19a-9cd00af92010.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s implement a `Density plot` for `CARA`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for the Density plot on CARA will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/32c7b25e-9e24-4eb4-bdbb-51e6f96efc89.png)'
  prefs: []
  type: TYPE_IMG
- en: As a target value, we have a variable that takes six different values. In this
    problem, it is not possible to calculate six, unlike in the previous problem,
    in which we were predicting failed banks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to assess the ability of each variable to predict credit ratings,
    we can calculate the correlations of each variable with the target variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: With the following code, we first create a copy of our training sample, and
    then convert the target variable into a numeric format. This is because it is
    not possible to calculate correlations with a non-numeric variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we will calculate correlations using the `cor` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, print these correlations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The most correlated variable with credit ratings is the mean of the governance
    indicators (`MEANWGI`), followed by the GDP per head (`YPCA`). In both cases,
    the higher the value of the variables, the higher the solvency or the credit rating
    value.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the least correlated variable is the change of consumer prices
    (`DCPI`). All variables have a positive correlation, except the `PUDP`. It means
    that the higher the indebtedness of a country, the lower the credit rating.
  prefs: []
  type: TYPE_NORMAL
- en: All the variables have an expected sign with credit ratings according to the
    literature and the methodological guidelines provided by the credit rating agencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we should save our workspace and remove any unnecessary objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As shown, the numbers of observations and variables are quite different than
    in the dataset of banks which we obtained in [Chapter 2](33b2f02e-58fd-41af-89a1-27947515b379.xhtml),
    *Predicting Failures of Banks - Data Collection*.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try some algorithms to predict credit ratings. Specifically, in the next
    section, we will train a decision tree and an ordered logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we looked at random forests in the *Testing a random forest model* section
    of chapter 5 (*Predicting the Failures of Banks - Multivariate Analysis*) previously,
    decision trees were briefly introduced. In a decision tree, the training sample
    is split into two or more homogeneous sets based on the most significant independent
    variables. In a decision tree, the best variable to split the data into the different
    categories is found. Information gain and the Gini index are the most common ways
    to find this variable. Then, data is recursively split, expanding the leaf nodes
    of the tree until the stopping criterion is reached.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how a decision tree can be implemented in R and how this algorithm
    is able to predict credit ratings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Decision trees are implemented in the `rpart` package. Moreover, the `rpart.plot`
    package will be useful to visualize our trained model later on. Implement the
    packages by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'To create a tree, we will use the `rpart` function. Four parameters have to
    be specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Formula**: In the format target: `~ predictor1+predictor2+…+predictorN`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data**: Specifies the data frame'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Method**: `class` for a classification tree or `anova` for a regression tree'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Control**: Optional parameters for controlling tree growth'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In our case, the following control parameters are specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '`maxdepth`: Refers to the maximum depth of any node of the final tree. It defines
    the number of splits or, in other words, how much the trees can grow, considering
    the root node depth 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complexity parameter** (or `cp`): This parameter is also used to control
    the size of the decision tree. This parameter can be considered the minimum gain
    required to increase the growth or the complexity of our decision tree. If adding
    a new node in a tree does not increase our fit, the algorithms will stop growing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s train the model. First a list of our variables is created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, a decision tree is trained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the model is trained, it is possible to print all the information given
    by the model with the `summary` function, although this time it is not printed
    due the large size of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now predict credit ratings with our decision tree, for both the train
    and test samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the confusion table for the training sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The trained model is able to predict almost all the credit ratings in the training
    sample. Let''s now print its accuracy in the test sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In order to assess the accuracy of the decision tree, we could calculate different
    metrics. Specifically, we can calculate which is the difference between the real
    rating value and the predicted one. Calculating these differences we can measure
    in which grade our model differs from the real rating levels.
  prefs: []
  type: TYPE_NORMAL
- en: 'For that, a function is created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the different results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: According to the preceding table, almost 77% of countries are correctly classified.
    On the other hand, the predictions of 14.88% of countries are not correctly classified
    but the difference with the real observed rating is only of one notch. On the
    other hand, the 7.74% of countries have a wrong predicted rating and this prediction
    differs in two notches from the real value, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same function is now applied using the test sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: These results are considered good enough. Credit ratings provided by external
    rating agencies are based on quantitative and qualitative information, the latter
    being most relevant. In our case, we are able to predict 68% of ratings only using
    quantitative public information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the decision tree is drawn using the `rpart.plot` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The **YPCA** decision tree will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ffd9c3da-bb8d-422c-82a2-9ab09df569da.png)'
  prefs: []
  type: TYPE_IMG
- en: Isn't the model easy to interpret?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s save the decision tree before starting the next section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will use another interesting approach, ordered logistic
    regression, which will be able to improve the results obtained within the decision
    tree.
  prefs: []
  type: TYPE_NORMAL
- en: Ordered logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen, decision trees perform well in multi-classification problems.
    There are other approaches we could follow too. One of them is logistic regression,
    which gives six possible outcomes to a problem. Nevertheless, this approach has
    some limitations. For example, we are assuming that there is no order to the categories
    in the target variable. It means that different categories or classes in the target
    variable are nominal. In the case of ratings, this assumption is not necessarily
    true, because ratings assign a ranking. Moreover, differences between credit ratings
    are not the same, which means that the difference between AAA and AA+ ratings
    is not necessarily equal to the difference between BBB and BBB- ratings.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, in this part of the book, we are going to implement an ordered logistic
    regression, which assumes an order in our target variable and a non-constant difference
    between ratings.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model can be deployed using the `polr` function from the `MASS` package.
    This function only needs the formula of the model, the dataset and, in our case,
    the `Hess=TRUE` option. This option will allow us to calculate and visualize the
    standard errors of the variables in our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'A summary of the model is then printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The preceding table provided us with the regression coefficient table. Moreover,
    it shows the estimates for the different intercepts, which are sometimes called
    **cutpoints**. The intercepts indicate where the predicted result should be cut,
    to make the different credit ratings observed in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the model provides us with the residual deviance and the `AIC` metrics,
    which are useful metrics to compare different models.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding results, we cannot see any `p_values` indicating whether a
    variable is significant, as it is not usually displayed in any regression. So,
    we need to calculate them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `p_values` can be approximately calculated by comparing the `t value` against
    the standard normal distribution. First, we will store our coefficients using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If we observe the sign of the coefficients, there are some negative values.
    Apparently, some variables display a non-intuitive or unexpected sign, but we
    don't need to be concerned about it in this example.
  prefs: []
  type: TYPE_NORMAL
- en: Coefficients of the model can be somewhat difficult to interpret, because they
    are scaled in terms of logs. Thus, it is common to convert previous raw coefficients
    into odds ratios.
  prefs: []
  type: TYPE_NORMAL
- en: 'Odds ratios will be obtained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the `p_values` of the different variables are calculated and merged
    with our obtained coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we develop our model, we are going to predict the outcome of our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The model gives a different probability for each rating. The predicted rating
    is the one with the highest predicted probability. For example, for Austria in
    2010, the model assigns the highest probability to the 5 (`X5`) rating, so the
    predicted rating is a 5.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the following code, we assign the predicted rating to the highest probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the accuracy of the model in the train sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the model is able to correctly predict 69.05% of credit ratings
    using the training sample. These results were better when using a decision tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see the performance of the model in the test sample. The following code
    gives us the predicted probabilities of each country for each of the rating levels.
    The predicted rating is given by the category with the highest probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code finds the rating category with the highest probability and
    assigns this rating as the predicted rating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The accuracy of the model in the test sample is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The results are also slightly worse than in the decision tree model.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now save the workspace before starting the next section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will use macroeconomic data to predict country ratings.
    All the variables we used are quantitative variables. In the following section,
    we will use country reports for the same purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting sovereign ratings using European country reports
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: According to the model based on macroeconomic information described in the *Predicting
    country ratings using macroeconomic information* section, decision trees can be
    considered a good alternative approach to predicting sovereign ratings.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, qualitative information represents an important and low transparent
    part of the rating assignment. In this section, we propose a model using only
    qualitative information based on the so-called country reports, published by the
    European Commission.
  prefs: []
  type: TYPE_NORMAL
- en: These reports, mainly published at the end of February, contain an annual analysis
    of the economic and social challenges for the EU member states.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, at the following link, we can download the country reports published
    in 2018, [https://ec.europa.eu/info/publications/2018-european-semester-country-reports_en](https://ec.europa.eu/info/publications/2018-european-semester-country-reports_en).
    For all of the 28 EU countries, we have downloaded their country reports from
    2011 to 2018, and converted them into a text format. We stored them in different
    folders, one for each year:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create a list that contains the names of different reports for each
    folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the names of the text files are stored in a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The name of files contains the roots and the filenames. Let''s try to separate
    the country name and the year of the report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s try to create a column with the country name, taking into consideration
    each filename. For example, if the word `czech` appears in the name of a file,
    a new column will be created that contains `Czech Republic`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the number of reports we have for each country in the European Union:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: We have eight different reports for all the countries in the European Union,
    except for Croatia (with only `6` reports) and Greece (with only `4`). Croatia's
    accession to the EU as a full member took place on July 1, 2013\. Thus, there
    are no reports for 2011 and 2012\. In the case of Greece, there were not specific
    reports for Greece after 2014.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we are going to train a model to predict credit ratings using the European
    reports, we need to select some reports to train the model and other reports to
    test it. The same countries we used in the model using macroeconomic information
    in [Chapter 6](5c1b431c-46f9-42b6-b3e7-e583b1996cd5.xhtml), *Visualizing Economic
    Problems in the European Union* (P*redicting country ratings using macroeconomic
    information* section) will be used here again. First, we need to select the countries
    we previously used to train the model. Then we merge the selected countries with
    the name and the root where the corresponding report is located:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s an example of the reports we will use to train our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The same procedure is carried out to obtain the validation or test sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s see the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'There are some differences in the size of samples with regard to the samples
    used in the previous model, because there are no reports for some countries. This
    is shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the number of countries that we will use to train the new model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the number of countries used to validate the previous model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the number of countries used to train the new model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the difference is not significant. Before reading files into
    R, we will create a function to read the files.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the following function is run, we can read the different reports iteratively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Two lists will be created. In each element of the lists, we can find each country
    report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Before continuing, some unnecessary objects can be removed and the workspace
    should be saved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Reports need to be preprocessed. Data preprocessing is necessary before extracting
    useful information or features to build our model.
  prefs: []
  type: TYPE_NORMAL
- en: Data cleaning, or preprocessing data, involves converting the data into plain
    text, and then removing formatting, whitespace, numbers, uppercase characters,
    and stopwords.
  prefs: []
  type: TYPE_NORMAL
- en: '**Stopwords** are defined as words in a language that are so common that their
    information value is practically null. As all the country reports are available
    in English, some examples of these stopwords are prepositions, determinants, and
    conjunctions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to make these preprocessing steps, the `tm` package is loaded and
    reports have to be converted into a corpus format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The following function is created to clean our reports one by one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'These reports are transformed by applying the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: An additional analysis will be done, called **stemming**. The stemming process
    refers to erasing suffixes to retrieve the root (or stem) of the word, which reduces
    the complexity of the data without significant loss of information.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, the verb *argue* will be reduce to the stem *argu*, regardless of the
    form or complexity of the word in the text. Thus, other forms such as *argued*,
    *argues*, *arguing*, and *argus* are also reduced to the same stem. The stemming
    procedure reduces the number of words to consider and provides a better frequency
    representation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The stemming process is done using the `SnowballC` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: After the preprocessing process, a matrix (document-term matrix) is built considering
    the country reports. Each row of this matrix represents each of the country reports,
    and each column represents all the words observed on them.
  prefs: []
  type: TYPE_NORMAL
- en: If a word occurs in a particular country report, the matrix entry corresponding
    to that row and column is 1, otherwise it is 0\. When multiple occurrences within
    a document are recorded, that is, if a word occurs twice in a report, it is recorded
    as 2 in the relevant matrix entry.
  prefs: []
  type: TYPE_NORMAL
- en: However, some extracted single words might lack important information that was
    included in the original text, such as word-to-word dependencies and the contexts
    around high-frequency words.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the extraction of the word *unemployment* in a report can't provide
    enough information to interpret whether the term is positive or negative. Thus,
    combinations of two words are extracted from the reports instead of individual
    words.
  prefs: []
  type: TYPE_NORMAL
- en: In this way, it is possible to find some combinations, such as *high unemployment*,
    that could appear more frequently in countries with lower creditworthiness.
  prefs: []
  type: TYPE_NORMAL
- en: 'The package we will use to extract combinations of words is named `Rweka`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The following function is created to obtain the combinations of `1` and `2`
    words in the reports:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Document-term matrices are now obtained for the train and test samples of the
    reports. Only words more than `3` and less than `20` characters long will be considered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: In the case of the validation sample, we will calculate the matrix considering
    the dictionary of words previously found in the training sample. New words found
    in the test sample will not be considered. Remember to take into consideration
    that we cannot use words found in the test sample to develop the model, which
    means that, right now, we should act as if the test sample does not exist to train
    the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, we should add a new parameter in our function when the document-term
    matrix is calculated on the test sample of reports: `dictionary = Terms(tdm2_train)`.
    This is shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s analyze the resultant matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: The first line indicates the number of different terms and the number of reports
    in each sample. The number of columns or terms in each matrix is the same and
    belongs to the total list of words found in our training sample.
  prefs: []
  type: TYPE_NORMAL
- en: A total of 609,929 terms have appeared at least once in the training sample
    of country reports.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, in the training matrix, there are 98,603,595 cells with frequencies
    of 0 and 2,034,690 cells that have non zero values. Thus, 98% of all cells are
    zero. This situation is very common in text-mining problems. When a matrix contains
    many cells with zero values, it is considered a sparse matrix.
  prefs: []
  type: TYPE_NORMAL
- en: The `removeSparseTerms` function will remove the infrequently used words, leaving
    only the most used words in the corpus.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, we will reduce the matrix to keep a maximum of 75% empty space.
    This process has to be applied only on the data we will later use to train the
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Our matrix to train the model now has 6,480 terms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s observe what our matrix looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: For example, the word `abroad` appears `2` times in the first report and `4`
    times in the second. Just remember that words were stemmed in a previous step,
    so only the roots of words are displayed. Single words and combinations of two
    words are also available in the matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'The names of the reports displayed in the preceding code are ordered according
    to the list we originally used to import the reports. Specifically, the first
    four documents belong to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to obtain the complete list of terms and their frequency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the list of the most repeated terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'For visualization, it is possible to create a word cloud plot with the most
    frequent words in our documents. To do this, we can use the `wordcloud` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'This is how the result looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6889a888-e48a-47da-b41a-95180134c96a.png)'
  prefs: []
  type: TYPE_IMG
- en: It looks pretty, right?
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to convert the previous matrix to have countries in rows and terms
    in columns. In summary, we need to transpose both the train and test matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, some irrelevant objects are removed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'And the workspace is again saved as a backup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we have processed our reports and we have extracted some features,
    terms, and combinations of words. Nevertheless, the target variable, the country
    rating, is not present in our new dataset. The credit rating is only present in
    the `macroeconomic_data` sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we will add credit ratings to our recently created training
    and validation matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: As the number of features to train in our model is quite high (more than 6,000),
    we will assess how correlated our features are with the credit ratings, to help
    discard some of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will create a data frame that contains our list of terms and the
    correlation with the credit ratings. The first three variables have to be excluded.
    This is shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the correlations, let''s put them in descending order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the top 10 most correlated variables with credit ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Apparently, the `judici` root, which comes from words such as *judicial*, is
    very correlated with credit ratings. The negative sign indicates that countries
    in which the specific words appear very frequently in the country report have
    a lower credit quality.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will only use the top 1,000 words to train our model. A list with the top
    1,000 terms is created here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Before training the model, let''s save the workspace one more time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: It is time to train the model. The selected model is a pure Lasso model, because
    it is demonstrated that this kind of model works well where the number of columns
    or features is high, acting as an approach to variable selection.
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach was already used in *chapter 5: Predicting the Failures of Banks
    - Multivariate Analysis* with the `h2o` package. This time, we will use the `glmnet`
    package only for academic purposes and with the aim that the reader can apply
    different solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: The `glmnet` package needs a matrix with variables and a vector with the class
    labels or the target values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s make sure that our target variable is a `factor`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Dependent and independent variables are stored in different objects to train
    the model, shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Like the preceding code, the same steps are carried out in the validation sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: We will also use the `cv.glmnet` function in the training process, which automatically
    performs a grid search to find the optimal value of λ, needed in the Lasso algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most important parameters in this function are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`y`: Our target variable, in our case, the credit rating.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x`: A matrix that contains all the independent variables of our features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alpha`: In our case, with a value of `1` to indicate that the model is a Lasso.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`family`: The type of our response variable. If target variable has only two
    levels, family should be defined as `binomial`. In our case, as our target variable
    displays more than two levels, the family should be specified as `multinomial`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`type.multinomial`: If `grouped`, a grouped Lasso penalty is used on the `multinomial`
    coefficients for a variable. The default is `ungrouped`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`parallel`: If `TRUE`, the algorithm is processed in parallel. This means the
    algorithm splits the different tasks and executes them simultaneously, significantly
    reducing the training time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is the application of this function with the current data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'During the execution of this code, a warning message arises: `one multinomial
    or binomial class has fewer than 8 observations; dangerous ground`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem is that we don''t have enough observations for all the categories
    in our target variable. We can check the number of different categories in the
    target variable by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: For rating `1`, there are only `5` observations. As a consequence, it is probably
    not expected to have any stable estimates for this category.
  prefs: []
  type: TYPE_NORMAL
- en: 'One solution could be to merge ratings `1` and `2` into the same rating category:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the problem should not appear:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the model is trained, the following plot helps to find the `lambda` parameter,
    which reduces the model''s error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'The optimal log value is approximately `-3`, according to the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a48280b9-1bc5-4432-9405-908bdad2286f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The exact value can be viewed by examining the `lambda_min` variable in the
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: The objective of regularization methods is to find a trade-off between accuracy
    and simplicity, which means to obtain a model with the smallest number of coefficients
    that also gives a good accuracy. In this vein, the `cv.glmnet` function also helps
    to find the model in which the error is within one standard error of the minimum.
  prefs: []
  type: TYPE_NORMAL
- en: 'This value of `lambda` can be found in the `lambda.1se` variable. This value
    will be selected as the resultant `lambda` of our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, it is time to assess the accuracy of our model. First, let''s look at
    the training sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the table of results for the training sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s look at the accuracy of the validation sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the table of results for the validation sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'The results seem to be good enough, considering that we used country reports.
    As we did when models were trained using macroeconomic data, we will calculate
    the percentage of correctly classified countries with the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s run the assessment for this model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: The Lasso model is able to predict 69.81% of countries correctly on the validation
    sample. The resultant model slightly improves the results obtained using only
    macroeconomic data, with an accuracy level attained of 67.86%.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it is very interesting to assess the most relevant terms that appear
    in country reports and that determine the credit rating of a country.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following function is useful to extract the coefficients of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is a list with the different coefficients for each rating level.
    For example, the coefficients for the credit ratings 1 and 2 (these categories
    were merged previously in this section) are obtained. This is shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Some of the most relevant terms are shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: A positive sign indicates that the more a term appears in the country report,
    the lower the credit quality of the country.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check whether this is observed properly. For example, the model checked
    some of the sentences that contain `financ need` in the country report of Cyprus
    in 2018\. Here are three sections of the report:'
  prefs: []
  type: TYPE_NORMAL
- en: Cyprus does not appear to face immediate risks of fiscal stress, owing to its
    favorable fiscal position. This is mainly thanks to the improvement of the general
    government fiscal balance and primary balance, low gross financing needs, and
    relatively low short-term general government debt. These more than offset the
    still-sizeable public debt. However, short-term risks on the macro-financial side
    remain significant.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limited access to finance and the need to reduce debt still restrain private-sector
    investment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Public debt has decreased significantly, but remains high, at around 99 % of
    GDP in 2017\. High public debt makes Cyprus vulnerable to financial or economic
    shocks. However, the large proportion of long-term low-interest debt provided
    by external creditors during the economic adjustment program, the current low
    sovereign bond yields, and relatively low medium-term financing needs mitigate
    refinancing risks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In these three sections, stopwords were removed, which is the reason for finding
    `financ need`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Different coefficients can be obtained for the best rating category as well.
    This can be done through the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are some of the most relevant terms we found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'Some sentences are also obtained for an example report. For example, for Germany
    in 2018, the following sentences contain the combination `govern balanc`:'
  prefs: []
  type: TYPE_NORMAL
- en: Germany has consistently improved its government balance, turning it into a
    surplus from 2014 onward.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The positive government balance is also reflected in falling government debt,
    which reached 70.9% in 2015, falling further to 68.1% in 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To conclude, keep a backup of all your models in case you want to use them
    later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned some introductory concepts of text-mining and topic
    extraction. You should now know how to read text files and process raw text to
    obtain useful common words. Also, you are now able to use the information collected
    in a text format in your own problems.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the amount of data and the type of problem you want to solve, you
    could now apply a variety of techniques, both simple and complex, used previously
    in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, and taking into account this chapter, you are ready to dive into other
    more recent and promising techniques, such as `word2vec` and `doc2vec`, which
    are both advanced techniques that allow you to discover relevant information or
    topics in a piece of text and documents. If you're curious, you can research these
    topics further.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you got an in-depth view of machine learning and that this book has helped
    you get started with solving problems using machine learning. Thanks for reading,
    and all the best!
  prefs: []
  type: TYPE_NORMAL
