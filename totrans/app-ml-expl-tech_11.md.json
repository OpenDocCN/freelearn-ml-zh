["```py\npip install dalex -U\n```", "```py\npip install dalex[full]\n```", "```py\nimport dalex as dx\n```", "```py\nx_train,x_valid,y_train,y_valid = train_test_split(\n```", "```py\n  df_train,labels,test_size=0.2,random_state=123)\n```", "```py\nmodel = RandomForestRegressor(\n```", "```py\n  n_estimators=790, min_samples_split = 3, \n```", "```py\n  random_state=123).fit(x_train, y_train)\n```", "```py\n# Create DALEX Explainer object \n```", "```py\nexplainer = dx.Explainer(model, \n```", "```py\n                         x_valid, y_valid, \n```", "```py\n                         model_type = 'regression',\n```", "```py\n                         label='Random Forest')\n```", "```py\nmodel_performance = explainer.model_performance(\"regression\")\n```", "```py\nVar_Importance = explainer.model_parts(\n```", "```py\n  variable_groups=variable_groups, B=15, random_state=123)\n```", "```py\nVar_Importance.plot(max_vars=10, \n```", "```py\n                    rounding_function=np.rint, \n```", "```py\n                    digits=None, \n```", "```py\n                    vertical_spacing=0.15,\n```", "```py\n                    title = 'Feature Importance')\n```", "```py\npdp = explainer.model_profile(type = 'partial', N=800)\n```", "```py\npdp.plot(variables = ['age', 'potential'])\n```", "```py\nald = explainer.model_profile(type = 'accumulated', N=800)\n```", "```py\nald.plot(variables = ['age', 'movement_reactions'])\n```", "```py\nprediction_level = {'interactive_breakdown':[], 'shap':[]}\n```", "```py\nibd = explainer.predict_parts(\n```", "```py\n  player, type='break_down_interactions', label=name)\n```", "```py\nprediction_level['interactive_breakdown'].append(ibd)\n```", "```py\nprediction_level['interactive_breakdown'][0].plot(\n```", "```py\n  prediction_level['interactive_breakdown'][1:3],\n```", "```py\n  rounding_function=lambda x, \n```", "```py\n  digits: np.rint(x, digits).astype(np.int),\n```", "```py\n  digits=None, \n```", "```py\n  max_vars=15)\n```", "```py\nsh = explainer.predict_parts(player, type='shap', B=10, \n```", "```py\n                             label=name)\n```", "```py\nprediction_level['shap'].append(sh)\n```", "```py\nprediction_level['shap'][0].plot(\n```", "```py\n  prediction_level['shap'][1:3],\n```", "```py\n  rounding_function=lambda x, \n```", "```py\n  digits: np.rint(x, digits).astype(np.int),\n```", "```py\n  digits=None, \n```", "```py\n  max_vars=15)\n```", "```py\nceteris_paribus_profile = explainer.predict_profile(\n```", "```py\n    player, \n```", "```py\n    variables=['age', 'potential'],\n```", "```py\n    label=name) # variables to calculate \n```", "```py\nceteris_paribus_profile.plot(size=3, \n```", "```py\n                             title= f\"What If? {name}\")\n```", "```py\nprotected = np.where(x_valid.age < 30, np.where(x_valid.age < 20, 'youth', 'developing'), 'developed')\n```", "```py\nprivileged = 'youth'\n```", "```py\nfairness = explainer.model_fairness(protected=protected,\n```", "```py\n                                    privileged=privileged)\n```", "```py\nfairness.fairness_check(epsilon = 0.7)\n```", "```py\nNo bias was detected! Conclusion: your model is fair in terms of checked fairness criteria.\n```", "```py\nfairness.result\n```", "```py\nfairness.plot()\n```", "```py\narena_dataset = df_test[:400].set_index('short_name')\n```", "```py\narena = dx.Arena()\n```", "```py\n# push DALEX explainer object\n```", "```py\narena.push_model(explainer)\n```", "```py\n# push whole test dataset (including target column)\n```", "```py\narena.push_observations(arena_dataset)\n```", "```py\n# run server on port 9294\n```", "```py\narena.run_server(port=9294)\n```", "```py\n!pip install explainerdashboard\n```", "```py\n!pip install graphviz==0.18\n```", "```py\nimport explainerdashboard\n```", "```py\nfrom explainerdashboard import RegressionExplainer, ExplainerDashboard\n```", "```py\nexplainer = RegressionExplainer(model_skl, x_valid, y_valid)\n```", "```py\nExplainerDashboard(explainer).run()\n```", "```py\npip install interpret\n```", "```py\nimport interpret as iml\n```", "```py\nx_train, x_test, y_train, y_test = train_test_split(\n```", "```py\n  encoded, label, test_size=0.3, random_state=123)\n```", "```py\nmodel = RandomForestClassifier(\n```", "```py\n  n_estimators=500, min_samples_split = 3,\n```", "```py\n  random_state=123).fit(x_train, y_train)\n```", "```py\nfrom interpret.glassbox import ExplainableBoostingClassifier\n```", "```py\nebm = ExplainableBoostingClassifier(feature_types=feature_types)\n```", "```py\nebm.fit(x_train, y_train)\n```", "```py\n# Showing Global Explanations\n```", "```py\nebm_global = ebm.explain_global()\n```", "```py\niml.show(ebm_global)\n```", "```py\n# Local explanation using EBM\n```", "```py\nebm_local = ebm.explain_local(x_test[5:6], y_test[5:6], \n```", "```py\n                              name = 'Local Explanation')\n```", "```py\niml.show(ebm_local)\n```", "```py\nfrom interpret.glassbox import DecisionListClassifier\n```", "```py\ndlc = DecisionListClassifier(feature_types=feature_types)\n```", "```py\ndlc.fit(x_train, y_train)\n```", "```py\n# Showing Global Explanations\n```", "```py\ndlc_global = dlc.explain_global()\n```", "```py\niml.show(dlc_global)\n```", "```py\nfrom interpret.glassbox import ClassificationTree\n```", "```py\ndtc = ClassificationTree(feature_types=feature_types)\n```", "```py\ndtc.fit(x_train, y_train)\n```", "```py\n# Showing Global Explanations\n```", "```py\ndtc_global = dtc.explain_global()\n```", "```py\niml.show(dtc_global)\n```", "```py\niml.show([ebm_global, ebm_local, dlc_global, dtc_global])\n```", "```py\nfrom interpret.blackbox import LimeTabular, ShapKernel, MorrisSensitivity, PartialDependence\n```", "```py\n#The InterpretML Blackbox explainers need a predict function, and optionally a dataset\n```", "```py\nlime = LimeTabular(predict_fn=model.predict_proba, data=x_train.astype('float').values, random_state=123)\n```", "```py\n#Select the instances to explain, optionally pass in labels if you have them\n```", "```py\nlime_local = lime.explain_local(\n```", "```py\n  x_test[:5].astype('float').values, \n```", "```py\n  y_test[:5], name='LIME')\n```", "```py\n# SHAP explanation\n```", "```py\nbackground_val = np.median(\n```", "```py\n  x_train.astype('float').values, axis=0).reshape(1, -1)\n```", "```py\nshap = ShapKernel(predict_fn=model.predict_proba, \n```", "```py\n                  data=background_val, \n```", "```py\n                  feature_names=list(x_train.columns))\n```", "```py\nshap_local = shap.explain_local(\n```", "```py\n  x_test[:5].astype('float').values, \n```", "```py\n  y_test[:5], name='SHAP')\n```", "```py\n# Morris Sensitivity\n```", "```py\nsensitivity = MorrisSensitivity(\n```", "```py\n  predict_fn=model.predict_proba, \n```", "```py\n  data=x_train.astype('float').values,                                \n```", "```py\n  feature_names=list(x_train.columns),                                \n```", "```py\n  feature_types=feature_types)\n```", "```py\nsensitivity_global = sensitivity.explain_global(name=\"Global Sensitivity\")\n```", "```py\n# Partial Dependence\n```", "```py\npdp = PartialDependence(\n```", "```py\n  predict_fn=model.predict_proba, \n```", "```py\n  data=x_train.astype('float').values,                        \n```", "```py\n  feature_names=list(x_train.columns),\n```", "```py\n  feature_types=feature_types)\n```", "```py\npdp_global = pdp.explain_global(name='Partial Dependence')\n```", "```py\niml.show([lime_local, shap_local, sensitivity_global, \n```", "```py\n          pdp_global])\n```", "```py\nimport alibi\n```", "```py\nfrom alibi.explainers import AnchorTabular, CEM, CounterfactualProto, ale \n```", "```py\nexplainer = AnchorTabular(\n```", "```py\n  predict_fn, \n```", "```py\n  feature_names=list(df_train.columns), \n```", "```py\n  seed=123)\n```", "```py\nexplainer.fit(df_train.values, disc_perc=[25, 50, 75])\n```", "```py\nclass_names = ['not_occupied', 'occupied']\n```", "```py\nprint('Prediction: ', \n```", "```py\n      class_names[explainer.predictor(\n```", "```py\n        df_test.values[5].reshape(1, -1))[0]])\n```", "```py\nexplanation = explainer.explain(df_test.values[5], \n```", "```py\n                                threshold=0.8)\n```", "```py\nprint('Anchor: %s' % (' AND '.join(explanation.anchor)))\n```", "```py\nprint('Prediction: ', \n```", "```py\n      class_names[explainer.predictor(\n```", "```py\n        df_test.values[100].reshape(1, -1))[0]])\n```", "```py\nexplanation = explainer.explain(df_test.values[100], \n```", "```py\n                                threshold=0.8)\n```", "```py\nprint('Anchor: %s' % (' AND '.join(explanation.anchor)))\n```", "```py\ncem = CEM(predict_fn, mode, shape, kappa=kappa, \n```", "```py\n          beta=beta, feature_range=feature_range, \n```", "```py\n          max_iterations=max_iterations, c_init=c_init, \n```", "```py\n          c_steps=c_steps, \n```", "```py\n          learning_rate_init=lr_init, clip=clip)\n```", "```py\ncem.fit(df_train.values, no_info_type='median')\n```", "```py\nexplanation = cem.explain(X, verbose=False)\n```", "```py\ncfe = CounterfactualProto(predict_fn,\n```", "```py\n                          shape,\n```", "```py\n                          use_kdtree=True, \n```", "```py\n                          theta=10., \n```", "```py\n                          max_iterations=1000,\n```", "```py\n                          c_init=1., \n```", "```py\n                          c_steps=10\n```", "```py\n                         )\n```", "```py\ncfe.fit(df_train.values, d_type='abdm', \n```", "```py\n        disc_perc=[25, 50, 75])\n```", "```py\nexplanation = cfe.explain(X)\n```", "```py\nproba_ale = ale.ALE(predict_fn, feature_names=numeric,\n```", "```py\n                    target_names=class_names)\n```", "```py\nproba_explain = proba_ale.explain(df_test.values)\n```", "```py\nale.plot_ale(proba_explain, n_cols=3, \n```", "```py\n             fig_kw={'figwidth': 12, 'figheight': 8})\n```", "```py\ndata_object = dice_ml.Data(\n```", "```py\n  dataframe = df_train[numeric + [target_variable]],\n```", "```py\n  continuous_features = numeric,\n```", "```py\n  outcome_name = target_variable\n```", "```py\n)\n```", "```py\nmodel_object = dice_ml.Model(model=model,backend='sklearn')\n```", "```py\nexplainer = dice_ml.Dice(data_object, model_object, \n```", "```py\n                         method = 'random')\n```", "```py\ntest_query = df_test[400:401][numeric]\n```", "```py\ncfe = explainer.generate_counterfactuals(\n```", "```py\n    test_query, \n```", "```py\n    total_CFs=4, \n```", "```py\n    desired_range=None,\n```", "```py\n    desired_class=\"opposite\",\n```", "```py\n    features_to_vary= numeric,\n```", "```py\n    permitted_range = { 'CO2' : [400, 1000]}, # Adding a constraint for CO2 feature\n```", "```py\n    random_seed = 123,\n```", "```py\n    verbose=True)\n```", "```py\ncfe.visualize_as_dataframe(show_only_changes=True)\n```", "```py\nlocal_importance = explainer.local_feature_importance(test_query)\n```", "```py\nprint(local_importance.local_importance)\n```", "```py\nplt.figure(figsize=(10,5))\n```", "```py\nplt.bar(range(len(local_importance.local_importance[0])), \n```", "```py\n        list(local_importance.local_importance[0].values())/(np.sum(list(local_importance.local_importance[0].values()))), \n```", "```py\n        tick_label=list(local_importance.local_importance[0].keys()),\n```", "```py\n        color = list('byrgmc')\n```", "```py\n       )\n```", "```py\nplt.show()\n```", "```py\npip install eli5\n```", "```py\nimport eli5\n```", "```py\neli5.show_weights(model, vec = DictVectorizer(), \n```", "```py\n                  feature_names = list(encoded.columns))\n```", "```py\nno_missing = lambda feature_name, feature_value: not np.isnan(feature_value) # filter missing values\n```", "```py\neli5.show_prediction(model, \n```", "```py\n                     x_test.iloc[1:2].astype('float'), \n```", "```py\n                     feature_names = list(encoded.columns), \n```", "```py\n                     show_feature_values=True, \n```", "```py\n                     feature_filter=no_missing,\n```", "```py\n                     target_names = {1:'Die', 2:'Live'},\n```", "```py\n                     top = 10,\n```", "```py\n                     show = ['feature_importances', \n```", "```py\n                             'targets', 'decision_tree', \n```", "```py\n                             'description'])\n```", "```py\npip install h2o\n```", "```py\nimport h2o\n```", "```py\nfrom h2o.automl import H2OAutoML\n```", "```py\n# Start the H2O cluster (locally) - Don't forget this step\n```", "```py\nh2o.init()\n```", "```py\naml = H2OAutoML(max_models=20, seed=1)\n```", "```py\ntrain = x_train.copy()\n```", "```py\nvalid = x_valid.copy()\n```", "```py\ntrain[\"position\"] = y_train\n```", "```py\nvalid[\"position\"] = y_valid\n```", "```py\nx = list(train.columns)\n```", "```py\ny = \"position\"\n```", "```py\ntraining_frame = h2o.H2OFrame(train)\n```", "```py\nvalidation_frame=h2o.H2OFrame(valid) \n```", "```py\n# training the automl model\n```", "```py\naml.train(x=x, y=y, training_frame=training_frame, \n```", "```py\n          validation_frame=validation_frame)\n```", "```py\nmodel = aml.get_best_model()\n```", "```py\naml.explain(validation_frame)\n```"]