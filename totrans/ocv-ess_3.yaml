- en: Chapter 3. First Things First – Image Processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image processing refers to digital processing of any two-dimensional data (a
    picture) by a computer by applying signal processing methods. Image processing
    has a broad spectrum of applications, such as image representation, image enhancement
    or sharpening, image restoration by means of filtering, and geometrical correction.
    These applications are usually the first stage and input to the following stages
    in a computer vision system. In OpenCV, there is a specific module, `imgproc`,
    for image processing. In this chapter, we will cover the most important and frequently
    used methods available in the library, that is, pixel-level access, histogram
    manipulation, image equalization, brightness and contracts modeling, color spaces,
    filtering, and arithmetic and geometrical transforms.
  prefs: []
  type: TYPE_NORMAL
- en: Pixel-level access and common operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the most fundamental operations in image processing is pixel-level access.
    Since an image is contained in the `Mat` matrix type, there is a generic access
    form that uses the `at<>` template function. In order to use it, we have to specify
    the type of matrix cells, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note that color images use the `Vec3b` type, which is an array of three unsigned
    chars. Images with a fourth alpha (transparency) channel would be accessed using
    the type `Vec4b`. The `Scalar` type represents a 1 to 4-element vector and can
    also be used in all these cases. Note that `at<>` can be also used to change pixel
    values (that is, on the left-hand side of an assignment).
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from pixel access, there are a number of common operations for which
    we should know the corresponding snippets. The following table shows these common
    operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Code example |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Obtain size of matrix |'
  prefs: []
  type: TYPE_TB
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Obtain number of channels |'
  prefs: []
  type: TYPE_TB
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Obtain pixel data type |'
  prefs: []
  type: TYPE_TB
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Set matrix values |'
  prefs: []
  type: TYPE_TB
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Or
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Create a copy of the matrix |'
  prefs: []
  type: TYPE_TB
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Create a copy of the matrix (with optional mask) |'
  prefs: []
  type: TYPE_TB
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference a submatrix |'
  prefs: []
  type: TYPE_TB
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Create a new matrix from a submatrix (that is, image crop) |'
  prefs: []
  type: TYPE_TB
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note the difference in the last two rows: in the last row, a new matrix is
    created. The case of the penultimate row only creates a reference to a submatrix
    within `src`, but data is not actually copied.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The most common operations, including additional iterator-based pixel access
    methods, are summarized in the *OpenCV 2.4 Cheat Sheet*, which can be downloaded
    from [http://docs.opencv.org/trunk/opencv_cheatsheet.pdf](http://docs.opencv.org/trunk/opencv_cheatsheet.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Image histogram
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An image histogram represents the frequency of the occurrence of the various
    gray levels or colors in the image, in case of 2D and 3D histograms respectively.
    Therefore, the histogram is similar to the probability density function of the
    different pixel values, that is, the gray levels, present in the image. In OpenCV,
    the image histogram may be calculated with the function `void calcHist(const Mat*
    images, int nimages, const int* channels, InputArray mask, OutputArray hist, int
    dims, const int* histSize, const float** ranges, bool uniform=true, bool accumulate=false)`.
    The first parameter is a pointer to the input image. It is possible to calculate
    the histogram of more than one input image. This allows you to compare image histograms
    and calculate the joint histogram of several images. The second parameter is the
    number of source images. The third input parameter is the list of the channels
    used to compute the histogram. It is possible to calculate the histogram of more
    than one channel of the same color image. Thus, in this case, the `nimages` value
    will be 1 and the `const int* channels` parameter will be an array with the list
    of channel numbers.
  prefs: []
  type: TYPE_NORMAL
- en: The number of channels goes from zero to two. The parameter `InputArray mask`
    is an optional mask to indicate the array elements (image pixels) counted in the
    histogram. The fifth parameter is the output histogram. The parameter `int dims`
    is the histogram dimensionality that must be positive and not greater than 32
    (`CV_MAX_DIMS`). A histogram can be *n*-dimensional according to the number of
    bins used to quantize the pixel values of the image. The parameter `const int*
    histSize` is the array of histogram sizes in each dimension. It allows us to compute
    histograms with non-uniform binning (or quantification). The `const float** ranges`
    parameter is the array of the `dims` arrays of the histogram bin boundaries in
    each dimension. The last two parameters have Boolean values and by default are
    `true` and `false` respectively. They indicate that the histogram is uniform and
    non-accumulative.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `ImgHisto` example shows how to calculate and display the one-dimensional
    histogram of a 2D image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is given here: the example creates three windows with
    the source image, the grayscale image, and the result of the 1D histogram. The
    1D histogram is shown as a bar diagram for the 255 gray values. Thus, first the
    color pixels are converted into gray values using the `cvtColor` function. The
    gray values are then normalized using the `normalize` function between 0 and the
    maximum gray level value. Then the 1D histogram is calculated by discretizing
    the colors in the image into a number of bins and counting the number of image
    pixels in each bin. The following screenshot shows the output of the example.
    Note that a new include file, `imgproc.hpp`, dedicated to image processing is
    needed.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image histogram](img/00013.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Output of the histogram example
  prefs: []
  type: TYPE_NORMAL
- en: Histogram equalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the image histogram is calculated, it can be modelled so that the image
    is modified and the histogram has a different shape. This is useful to change
    the low-contrast levels of images with narrow histograms, since this will spread
    out the gray levels and thus enhance the contrast. Histogram modeling, also known
    as histogram transfer, is a powerful technique for image enhancement. In histogram
    equalization, the goal is to obtain a uniform histogram for the output image.
    That is, a flat histogram where each pixel value has the same probability. In
    OpenCV, histogram equalization is performed with the function `void equalizeHist(InputArray
    src, OutputArray dst)`. The first parameter is the input image and the second
    one is the output image with the histogram equalized.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `EqualizeHist_Demo` example shows how to calculate and display
    the histogram equalized and the effect on the two-dimensional image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is given as follows. The example first reads the original
    image and converts it to grayscale. Then, histogram equalization is performed
    using the `equalizeHist` function. Finally, the histogram of the equalized image
    is shown together with the two previous images. The following screenshot shows
    the output of the example, where three windows are created with the grayscale
    image, the equalized image, and its histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Histogram equalization](img/00014.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Output of the histogram equalization example
  prefs: []
  type: TYPE_NORMAL
- en: Brightness and contrast modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The brightness of an object is the perceived luminance or intensity and depends
    on the luminance of the environment. Two objects in different environments could
    have the same luminance but different brightness. The reason is that the human
    visual perception is sensitive to luminance contrast rather than absolute luminance.
    Contrast is the difference in luminance and/or color that makes an object distinguishable
    compared to other objects within the same field of view. The maximum contrast
    of an image is known as the contrast ratio or dynamic range.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to modify the brightness and contrast of an image by means of
    point-wise operations. Point operations map a given gray pixel value into a different
    gray level according to a transform previously defined. In OpenCV, point operations
    may be performed with the function `void Mat::convertTo(OutputArray m, int rtype,
    double alpha=1, double beta=0)`. The `convertTo` function converts an image array
    to another data type with optional scaling. The first parameter is the output
    image and the second parameter is the output matrix type, that is, the depth,
    since the number of channels is the same as the input image. Thus, the source
    pixel values `I(x,y)` are converted to the target data type with the new value
    `(I(x,y) * alpha + beta)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `BrightnessContrast` example shows how to perform an image pixel
    (point) operation to modify brightness and contrast:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is given here: the example creates two windows with the
    grayscale image and its histogram. The new values for the brightness and contrast
    are selected by the user using the function `createTrackbar`. This function attaches
    two sliders or range controls to the image for brightness and contrast. The following
    screenshot shows the output of the `BrightnessContrast` example for a value of
    148 for brightness and 81 for contrast:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Brightness and contrast modeling](img/00015.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Output of the brightness and contrast image modification
  prefs: []
  type: TYPE_NORMAL
- en: Histogram matching and LUT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The histogram may also be used to modify the color of an image. Histogram matching
    is a method of color adjustment between two color images. Given a reference image
    and a target image, the result (destination image) will be equal to the target
    image except that its (three) histograms will look like those of the reference
    image. This effect is known as **color mapping** or **color transfer**.
  prefs: []
  type: TYPE_NORMAL
- en: The histogram matching algorithm is run over each of the three color histograms
    independently. For each channel, the **cumulative distribution function** (**cdf**)
    has to be calculated. For a given channel, let `Fr` be the cdf of the reference
    image and `Ft` be the cdf of the target image. Then, for each pixel `v` in the
    reference image, we find the gray level `w`, for which `Fr(v)=Ft(w)`. The pixel
    with value `v` is thus changed to `w`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we provide another example of histograms in which we use a technique called
    histogram matching. The example also uses **look-up tables** (**LUT**). A look-up
    table transformation assigns a new pixel value to each pixel in the input image
    (there is a good explanation and example of an LUT at [http://docs.opencv.org/doc/tutorials/core/how_to_scan_images/how_to_scan_images.html](http://docs.opencv.org/doc/tutorials/core/how_to_scan_images/how_to_scan_images.html)).
    The new values are given by a table. Thus, the first entry in this table gives
    the new value for pixel value 0, the second the new value for pixel value 1, and
    so on. Assuming we use a source and destination image, the transform is then given
    by `Dst(x,y)=LUT(Src(x,y))`.
  prefs: []
  type: TYPE_NORMAL
- en: The OpenCV function for performing a look-up table transformation is `LUT(InputArray
    src, InputArray lut, OutputArray dst, int interpolation=0)`. The parameter `src`
    is an 8-bit image. The table is given in the parameter `lut`, which has 256 elements.
    The table has either one channel or the same number of channels as the source
    image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the `histMatching` example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is given here: the example first reads the reference and
    target images. The output image is also allocated. The main function is `histMatch`.
    In it, the reference and target images are first split into the three color channels.
    Then, for every channel, we obtain the normalized histograms of reference and
    target images, followed by the respective cdfs. Next, the histogram matching transformation
    is performed.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we apply the new pixel values using the look-up table. Note that the
    transformation could also be applied by iterating over every pixel in the result
    image. The look-up table option is, however, much faster. The following screenshot
    shows the output of the sample. The color palette of the reference image (the
    `baboon.jpg` image) is transferred to the target image.
  prefs: []
  type: TYPE_NORMAL
- en: '![Histogram matching and LUT](img/00016.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Output of the histMatching example
  prefs: []
  type: TYPE_NORMAL
- en: Conversion from RGB to other color spaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The color of an image may also be modified by changing the color space. In OpenCV,
    six color models are available and it is possible to convert from one to another
    by using the `cvtColor` function.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The default color format in OpenCV is often referred to as RGB but it is actually
    BGR (the channels are reversed).
  prefs: []
  type: TYPE_NORMAL
- en: The function `void cvtColor(InputArray src, OutputArray dst, int code, int dstCn=0)`
    has the input and output images as the first and second parameters. The third
    parameter is the color space conversion code and the last parameter is the number
    of channels in the output image; if this parameter is 0, the number of channels
    is obtained automatically from the input image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `color_channels` example shows how to convert from RGB to HSV,
    Luv, Lab, YCrCb, and XYZ color spaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is given here: the first example reads the original image
    and makes the conversion into five different color models. The original image
    in RGB and the results are then displayed. The following screenshot shows the
    output of the sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Conversion from RGB to other color spaces](img/00017.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Output of the different color spaces
  prefs: []
  type: TYPE_NORMAL
- en: Filtering with the retina model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image restoration is concerned with filtering the digital image to minimize
    the effect of degradations. Degradation is produced by the sensing environment
    during image acquisition by optical or electronic devices. The effectiveness of
    image filtering depends on the extent and the accuracy of the knowledge of the
    degradation process as well as on the filter design.
  prefs: []
  type: TYPE_NORMAL
- en: In OpenCV, there are several isotropic and anisotropic filters available operating
    on both spatial and frequency domains. One of the most recent filters is the retina
    filter, which is based on a model of the human visual system. There is a class
    named `Retina` to perform spatio-temporal filtering modeling the two main retina
    information channels, which are **parvocellular** (`parvo`) due to foveal vision
    and **magnocellular** (`magno`) due to peripheral vision. The `parvo` channel
    is related to detail extraction while the `magno` channel is dedicated to motion
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Retina` class may be applied on still images, images sequences, and video
    sequences to perform motion analysis. Here we present a simplified version of
    the `retinademo` algorithm provided in OpenCV. The algorithm `Filter_Retina.cpp`
    presented here demonstrates the use of the retina model images, which can be used
    to perform texture analysis with enhanced signal-to-noise ratio and enhanced details
    that are robust against input image luminance ranges. The main properties of the
    human retina model are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Spectral whitening (mid-frequency detail enhancement)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-frequency spatio-temporal noise reduction (temporal noise and high-frequency
    spatial noise are minimized)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Low-frequency luminance reduction (luminance range compression): High-luminance
    regions do not hide details in darker regions anymore'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Local logarithmic luminance compression allows details to be enhanced even in
    low-light conditions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more information, refer to *Using Human Visual System Modeling for bio-inspired
    low level image processing, Benoit A., Caplier A., Durette B., Herault J.,* Elsevier,
    Computer Vision and Image Understanding 114 (2010), pp. 758-773\. DOI at [http://dx.doi.org/10.1016/j.cviu.2010.01.011](http://dx.doi.org/10.1016/j.cviu.2010.01.011).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the code for the example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is given here: the example first reads the input image
    and obtains the retina model of the image using classical parameters for the model.
    The retina can be settled up with various parameters; by default, the retina cancels
    mean luminance and enforces all details of the visual scene. The filter is then
    run five times and the `parvo` and `magno` images and its details are shown. The
    following screenshot shows the output of the retina model filter after the five
    iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Filtering with the retina model](img/00018.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Output of the retina filter after five iterations
  prefs: []
  type: TYPE_NORMAL
- en: Arithmetic and geometrical transforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An arithmetic transform changes the value of an image pixel and it is applied
    point to point, whereas a geometrical transform changes the position of the image
    pixels. Thus, points in an image get a new position in the output image without
    changing their intensity values. Examples of arithmetic transforms may be addition,
    subtraction, and division between images. Examples of geometrical transforms are
    scaling, translation, and rotation of images. More complex transformations are
    to solve the barrel and cushion deformations of an image produced by an optical
    lens.
  prefs: []
  type: TYPE_NORMAL
- en: In OpenCV, there are several functions to perform arithmetic and geometrical
    transforms. Here we show two examples for image addition and perspective transformation
    by means of the functions `addWeighted` and `warpPerspective` respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Arithmetic transform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The function `addWeighted` performs a linear combination of two images, that
    is, addition of two weighted images to carry out a linear blending. The function
    `void addWeighted(InputArray src1, double alpha, InputArray src2, double beta,
    double gamma, OutputArray dst, int dtype=-1)` has two input images as the first
    and third parameters with their weights (second and fourth parameter). Then, the
    output image is the sixth parameter. The fifth parameter, `gamma`, is a scalar
    added to each sum. The last parameter `dtype` is optional and refers to the depth
    of the output image; when both input images have the same depth, it can be set
    to `-1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `LinearBlend` example shows how to perform a linear blending
    between two images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is given here: the example first reads two images, `src1=
    baboon.jpg` and `src2= lena.jpg`, and then performs a total of 101 linear combinations
    with different values of the weights `alpha` and `beta`. The first linear combination
    or blend is with `alpha` equal to zero, and therefore it is the `src1` image.
    The value of `alpha` increases in the loop while the value of `beta` decreases.
    Therefore, the `src2` image is combined and superimposed onto the `src1` image.
    This produces a morphing effect and the `baboon.jpg` image gradually changes into
    a different image, that is, into `lena.jpg`. The following screenshot shows the
    output of several linear blending steps at iterations `1`, `10`, `20`, `30`, `40`,
    `50`, `70`, `85`, and `100`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Arithmetic transform](img/00019.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Output of different lineal blending between two images
  prefs: []
  type: TYPE_NORMAL
- en: Geometrical transforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The function `warpPerspective, void ocl::warpPerspective(const oclMat& src,
    oclMat& dst, const Mat& M, Size dsize, int flags=INTER_LINEAR)` performs a perspective
    transformation on an image. It has the input or source image `src` as the first
    parameter and the output or destination image `dst` as the second parameter. Then,
    the third parameter is a 2 x 3 transformation matrix obtained from the `getPerspectiveTransform`
    function, which calculates a perspective transform from the positions of four
    points in the two images in four pairs of corresponding points. The fourth parameter
    of `warpPerspective` is the size of the output image and the last parameter is
    the interpolation method. By default, the interpolation method is linear, `INTER_LINEAR`;
    other methods supported are nearest neighbor `INTER_NEAREST` and cubic `INTER_CUBIC`.
  prefs: []
  type: TYPE_NORMAL
- en: The following `Geometrical_Transform` example performs a perspective transformation
    to the input image `img.jpg`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For full details of the example, refer to *N. Amin*, *Automatic perspective
    correction for quadrilateral objects*, at [https://opencv-code.com/tutorials/automatic-perspective-correction-for-quadrilateral-objects/](https://opencv-code.com/tutorials/automatic-perspective-correction-for-quadrilateral-objects/).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The code explanation is given here: the example first reads the input image
    (`img.jpg`) and calculates the key points of the region of interest or object
    to perform the perspective transformation. The key points are the corner points
    of the object. The algorithm only works for quadrilateral objects. The methods
    to calculate corners (Canny operator and Hough transforms) are explained in [Chapter
    4](part0035_split_000.html#page "Chapter 4. What''s in the Image? Segmentation"),
    *What''s in the Image, Segmentation*. The points corresponding to the object corners
    are the corners of the output image. These points are shown with circles on the
    original image. The dimension of the output image is set to the same height and
    half the width of the input image. Finally, the image with the corrected object
    is visualized. The perspective correction uses a linear transform, `INTER_LINEAR`.
    The following screenshot shows the output of the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Geometrical transforms](img/00020.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Output of the geometrical transform performed to correct the perspective
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has covered the most common image processing methods used in computer
    vision. Image processing is often the step performed just before further computer
    vision applications. It has many methods and is usually applied for image corrections
    and enhancement such as image histograms, image equalization, brightness and contrast
    modeling, image color conversion by means of histogram matching and color space
    transformations, filtering using the model of the human retina, and arithmetic
    and geometrical transforms.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will cover the next stage in a computer vision system, that
    is, the segmentation process. We will see how to extract regions of interest within
    an image.
  prefs: []
  type: TYPE_NORMAL
- en: What else?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Other important functions in OpenCV for image processing are related to filtering.
    These functions have been omitted in the chapter since they are straightforward.
    OpenCV includes an example that shows how to use the main filters `([opencv_source_code]/samples/cpp/filter2D_demo.cpp`).
    The main filter functions are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`GaussianBlur` for a Gaussian filter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`medianBlur` for a median filter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bilateralFilter` for anisotropic filtering'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`blur` for a homogeneous blur'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
