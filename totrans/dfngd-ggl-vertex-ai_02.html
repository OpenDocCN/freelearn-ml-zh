<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer027">
			<h1 id="_idParaDest-32" class="chapter-number"><a id="_idTextAnchor031"/>2</h1>
			<h1 id="_idParaDest-33"><a id="_idTextAnchor032"/>What Is MLOps, and Why Is It So Important for Every ML Team?</h1>
			<p><strong class="bold">Machine learning operations</strong> (<strong class="bold">MLOps</strong>) is a pivotal practice for modern ML teams, encompassing the blend of technological and operational best practices. At its heart, MLOps seeks <a id="_idIndexMarker048"/>to address the challenges of productionizing ML models and fostering better collaboration between data scientists and IT teams. With the rapid advancements in technology and increasing reliance on ML solutions, MLOps is becoming the backbone of a sustainable and scalable ML strategy. This chapter will delve deep into the essence of MLOps, detailing its significance, its various maturity levels, and the role of Google’s Vertex AI in facilitating MLOps. By the end of this chapter, you will be equipped with a robust understanding of MLOps principles and what tools in Vertex AI can be used to implement <span class="No-Break">those principles.</span></p>
			<p>In this chapter, we will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Why is <span class="No-Break">MLOps important?</span></li>
				<li>MLOps <span class="No-Break">maturity levels</span></li>
				<li>How can Vertex AI help with implementing <span class="No-Break">ML Ops?</span></li>
			</ul>
			<p>Let’s embark on this enlightening journey to master MLOps on <span class="No-Break">Vertex AI.</span></p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor033"/>Why is MLOps important?</h1>
			<p>As the <a id="_idIndexMarker049"/>development and integration of ML models become more and more common in today’s world, the need for a robust operational framework has become more critical than ever. MLOps aims to address this requirement by streamlining the entire process of developing, deploying, and monitoring ML models. In this section, we will discuss the importance of MLOps due to the <span class="No-Break">following aspects:</span></p>
			<ul>
				<li><strong class="bold">Standardizing and automating </strong><span class="No-Break"><strong class="bold">ML workflows</strong></span><p class="list-inset">MLOps aims to standardize and automate various stages of the ML life cycle, from data <a id="_idIndexMarker050"/>ingestion and preprocessing to model training, evaluation, and deployment. By doing so, it minimizes the likelihood of human errors, facilitates reproducibility, and improves overall efficiency. Google’s Vertex AI offers managed services for each stage of the ML workflow, which helps organizations achieve consistency, automate processes, and reduce <span class="No-Break">operational overhead.</span></p></li>
				<li><strong class="bold">Monitoring and managing </strong><span class="No-Break"><strong class="bold">model performance</strong></span><p class="list-inset">One of the key aspects of MLOps is continuously monitoring and managing the performance of deployed models. This is crucial, as the effectiveness of ML models may degrade over time due to changes in data distribution, unforeseen edge cases, or evolving user behaviors. Google’s Vertex AI supports MLOps by providing tools for monitoring model performance and generating alerts when performance thresholds are breached. Furthermore, it enables seamless integration with other monitoring and logging services in the Google <span class="No-Break">Cloud ecosystem.</span></p></li>
				<li><strong class="bold">Ensuring scalability </strong><span class="No-Break"><strong class="bold">and flexibility</strong></span><p class="list-inset">MLOps facilitates the scaling of ML solutions by providing a framework that can easily accommodate increased data volumes, more complex models, and additional infrastructure requirements. Google’s Vertex AI is built to handle these demands, offering a range of services and tools that scale automatically, support distributed training and prediction, and allow users to choose the optimal hardware configurations for their specific <span class="No-Break">use cases.</span></p></li>
				<li><strong class="bold">Security </strong><span class="No-Break"><strong class="bold">and compliance</strong></span><p class="list-inset">MLOps emphasizes the importance of security and compliance in ML workflows, ensuring that data privacy and regulatory requirements are met. Google’s Vertex AI supports these objectives by providing a secure environment for model training, storage, and deployment. Its integration with Google Cloud’s <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) enables fine-grained control over access <a id="_idIndexMarker051"/>to resources, while encryption options protect data both at rest and <span class="No-Break">in transit.</span></p></li>
			</ul>
			<p>While developing ML models, there can be many shortcuts taken or complexities overlooked that accumulate “debt” over time, leading to system maintenance difficulties or failures in the future. As an ML solution deployed in production evolves, developers <a id="_idIndexMarker052"/>might add more features to improve accuracy and add overall value for users. Each feature often has its own specific way of preprocessing, normalizing, and configuring parameters. Over time, managing these configurations and related changes can become increasingly complex and the solutions might accumulate significant technical debt. MLOps provides the necessary practices and tooling to manage and mitigate these debts, ensuring sustainable and scalable <span class="No-Break">ML deployments.</span></p>
			<p>In summary, MLOps plays a vital role in streamlining ML workflows, enhancing collaboration, and ensuring that models are secure, scalable, and well maintained. Google’s Vertex AI, with its comprehensive suite of tools and services, empowers organizations to embrace MLOps and unlock the full potential of their <span class="No-Break">ML solutions.</span></p>
			<p>Now, let’s look at the different levels of maturity or complexity of typical MLOps implementations seen in the industry. Keep in mind that the architectures we will discuss are just representative samples of different levels of complexity. In the real world, you will see many different variations of these implementations, and each implementation is as unique as the organization <span class="No-Break">using it.</span></p>
			<h1 id="_idParaDest-35"><a id="_idTextAnchor034"/>Implementing different MLOps maturity levels</h1>
			<p>Most new ML teams and organizations go through a phased MLOps journey as they build and <a id="_idIndexMarker053"/>refine their MLOps strategy. They usually start with a fully manual step-by-step process where data science/data engineering teams take an extremely manual, ad hoc approach to building and deploying models. Once a few models have been deployed and stabilized in production, it slowly becomes apparent that this manual process is not very scalable and that the team needs to put some processes and automation <span class="No-Break">in place.</span></p>
			<p>At this point, as issues arise in production, it also becomes apparent that this ad hoc approach is not easily auditable or reproducible. As the usage of the ML solution grows, it graduates from being just an experiment to something the organization becomes increasingly dependent on. Compliance teams and leadership also start making requests to make the model deployment process more well organized and auditable to ensure compliance <a id="_idIndexMarker054"/>with the company’s IT policies. At this stage, the team leadership will need to put together a high-level MLOps strategy and implementation roadmap based on the resources they have at their disposal and the solution roadmap of projects they are working on. Some organizations decide to spend their time building the entire MLOps stack upfront, while others might decide to step through the different maturity levels one step at <span class="No-Break">a time.</span></p>
			<p>Now, let’s look at the different maturity levels most ML organizations typically <span class="No-Break">progress through.</span></p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor035"/>MLOps maturity level 0</h2>
			<p>This is the phase where an organization has just started experimenting with ML solutions <a id="_idIndexMarker055"/>and has not prepared a well-baked MLOps strategy in terms of what the standard process and tooling would look like as <a id="_idIndexMarker056"/>they scale up their ML adoptions. At this stage, the landscape looks like <span class="No-Break">the following:</span></p>
			<ul>
				<li>The organization has just 1-2 models deployed in production for each <span class="No-Break">business unit</span></li>
				<li>AI/ML development is handled by a small centralized team of <span class="No-Break">data scientists</span></li>
				<li>The focus is on deployment speed instead of <span class="No-Break">consistent processes</span></li>
				<li>The choice of ML tools is unclear, and the leadership wants to figure out what works and what doesn’t before committing to a particular <span class="No-Break">ML platform</span></li>
				<li>Most, if not all, steps <span class="No-Break">are manual</span></li>
			</ul>
			<p>The following diagram shows different key components of an MLOps solution at maturity <span class="No-Break">level 0:</span></p>
			<div>
				<div id="_idContainer014" class="IMG---Figure">
					<img src="image/B17792_02_1.jpg" alt=" Figure 2.1 – MLOps solution: maturity level 0" width="1650" height="736"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> Figure 2.1 – MLOps solution: maturity level 0</p>
			<p>As you can see in the preceding diagram, at MLOps maturity level 0, most of the handovers <a id="_idIndexMarker057"/>from one process to the next are manual. This ensures <a id="_idIndexMarker058"/>a short path to production deployment (when needed) by not requiring a build and test of extensive automation processes. The downside is obviously the significant time the team needs to spend every time the pipeline needs to be run. So, the ML engineering teams need to have a roadmap/strategy in place to add automation <span class="No-Break">over time.</span></p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor036"/>MLOps maturity level 1 – automating basic ML steps</h2>
			<p>A key characteristic of maturity level 1 in MLOps is fully automated data and ML model training <a id="_idIndexMarker059"/>pipelines. At this stage, full data acquisition and model retraining can be triggered with a single click of a button or an <span class="No-Break">API call.</span></p>
			<p>One of the <a id="_idIndexMarker060"/>most significant bottlenecks that are most apparent to the team closest to the solution development is the data acquisition and model training process. In the <em class="italic">MLOps maturity level 0</em> section, most of the steps around data ingestion and model builds were done manually and are prone to errors even when repeating similar steps with slightly modified parameters. So, the data and ML model training pipelines end up being the very first components to get automated. It also helps that most of the data and ML pipelining work is being done within the same teams; that is, data pipeline work is done by the data team and the ML model design and building is done by the data science/ML team. This reduces the cross-team dependency on automation. There is obviously still a dependence on the IT team to ensure the availability of the right orchestration and <span class="No-Break">automation tools.</span></p>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/B17792_02_2.jpg" alt="Figure 2.2 – MLOps maturity level 1" width="1636" height="1021"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.2 – MLOps maturity level 1</p>
			<p>As shown <a id="_idIndexMarker061"/>in the preceding diagram, most <a id="_idIndexMarker062"/>components in the MLOps pipeline are automated at this <span class="No-Break">maturity level.</span></p>
			<p>The components <a id="_idIndexMarker063"/>of the ML pipeline that are automated are <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Data imports</strong>: The process of importing the latest data is almost entirely automated and started through external triggers that indicate the availability of <span class="No-Break">newer data.</span></li>
				<li><strong class="bold">Feature/data engineering</strong>: Automatically triggered as soon as preceding data transfer steps <span class="No-Break">are completed.</span></li>
				<li><strong class="bold">Data validation</strong>: At this stage, data validation is primarily handled through the orchestrated scripts triggered at the end of data/feature <span class="No-Break">engineering steps.</span></li>
				<li><strong class="bold">Model training</strong>: Once the data validation is successfully completed, the orchestration layer triggers the model training step, to rebuild the model with newly <span class="No-Break">available data.</span></li>
				<li><strong class="bold">Model validation</strong>: Automated benchmarking of the model’s predictive performance, done through orchestrated scripts to ensure the model meets the business and <a id="_idIndexMarker064"/>technical requirements before being approved for <span class="No-Break">production deployment.</span></li>
				<li><strong class="bold">Registration of new model in the centralized model registry</strong>: Once the model has been validated, it gets pushed to a centralized model registry that keeps a catalog of all <span class="No-Break">approved models.</span></li>
			</ul>
			<p>The other new components that get introduced at this stage to support the automation are <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Code Repository</strong>: To ensure consistency in the data and pipeline executions, creating a centralized repository to host the pipeline code/logic is important. For this, enterprises use their in-house Git implementations, tools such as GitHub or GitLab, or cloud-based <a id="_idIndexMarker065"/>code repository tools such as <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) Cloud Source Repositories. (It’s beyond the scope of this book to cover these tools <span class="No-Break">in detail.)</span></li>
				<li><strong class="bold">Feature Store</strong>: Centralized catalog/repository of features that can make experiment automation/reproducibility easier and more consistent. This can be done using standalone specialized tools, such as <strong class="bold">FEAST</strong> or Vertex AI Feature Store, or a custom implementation using standard data warehouse tools. Vertex AI Feature Store is discussed in detail in <a href="B17792_11.xhtml#_idTextAnchor153"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, <em class="italic">MLOps Governance with </em><span class="No-Break"><em class="italic">Vertex AI</em></span><span class="No-Break">.</span></li>
			</ul>
			<p>With these fundamental MLOps components in place, your solution would be a lot more efficient and a lot less prone to <span class="No-Break">human errors.</span></p>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor037"/>MLOps maturity level 2 – automated model deployments</h2>
			<p>Key characteristics <a id="_idIndexMarker066"/>of MLOps maturity level 2 are continuous <a id="_idIndexMarker067"/>deployment capabilities, which can automatically deploy any new ML models in the production environment, and triggering the creation of new ML models based on the triggers from monitoring services when shifts are detected in <span class="No-Break">model accuracy.</span></p>
			<p>The following <a id="_idIndexMarker068"/>diagram depicts a representative MLOps implementation with maturity <span class="No-Break">level 2.</span></p>
			<div>
				<div id="_idContainer016" class="IMG---Figure">
					<img src="image/B17792_02_3.jpg" alt="Figure 2.3 – MLOps maturity level 2" width="1536" height="1196"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.3 – MLOps maturity level 2</p>
			<p>Once the <a id="_idIndexMarker069"/>data acquisition and ML modeling portion have been automated in the maturity level 2 architecture, the next bottleneck that becomes apparent is the integration of the model build side with the model deployment side. This has <span class="No-Break">two components:</span></p>
			<ul>
				<li>The process of taking a newly trained model that has passed the validation step and deploying it in production. For example, a new model that passes the validation tests should automatically get deployed <span class="No-Break">in production.</span></li>
				<li>Taking the data collected by the monitoring service, turning it into actionable insights, and triggering updates to models. For example, a drift in incoming feature values in production can trigger the retraining of the ML model with <span class="No-Break">newer data.</span></li>
			</ul>
			<p>The other new component that gets introduced at this stage to support the automation is Metadata Store. This is the repository of all metadata that gets generated during every step of data acquisition, feature generation, model development, and deployment. This becomes important during automated deployments and retraining as the source <a id="_idIndexMarker070"/>of the model development history. For example, to monitor the model in production for data drift or training skew, the monitoring <a id="_idIndexMarker071"/>process needs access to the model’s history to get the dataset on which it was trained. The other use case not related to automation is that Metadata Store can enable model auditing. If during the model development process all key parameters around the data and model are being logged in to Metadata Store, then it can provide end-to-end visibility around the model to the model auditors. An example of this is shown in the following figure, where you can see the journey of <span class="No-Break">the model:</span></p>
			<div>
				<div id="_idContainer017" class="IMG---Figure">
					<img src="image/B17792_02_4.jpg" alt="Figure 2.4 – Vertex AI Metadata Store" width="1077" height="407"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.4 – Vertex AI Metadata Store</p>
			<p>Now let us see how you can use Vertex AI to implement end-to-end <span class="No-Break">MLOps solutions.</span></p>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor038"/>How can Vertex AI help with implementing MLOps?</h1>
			<p>Google Cloud Vertex AI is a platform that provides tools and resources for the end-to-end implementation of the ML development <span class="No-Break">life cycle.</span></p>
			<p>Vertex AI <a id="_idIndexMarker072"/>can help with MLOps by providing features such as automated model building and deployment, model versioning <a id="_idIndexMarker073"/>and tracking, and monitoring and managing models in production. Additionally, it provides tools for collaboration and shared access to resources, allowing teams to work together on large and distributed <span class="No-Break">ML projects.</span></p>
			<p>Vertex AI <a id="_idIndexMarker074"/>can also help with other aspects of MLOps, such as <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Data management</strong>: Vertex AI can help with data preparation, labeling, and management, which are crucial for building accurate <span class="No-Break">ML models</span></li>
				<li><strong class="bold">Experimentation</strong>: Vertex AI can help track and manage experiments, including comparing and selecting the <span class="No-Break">best models</span></li>
				<li><strong class="bold">Model governance</strong>: Vertex AI can help manage model access and permissions and monitor models for drift <span class="No-Break">and compliance</span></li>
				<li><strong class="bold">Continuous integration and continuous delivery</strong> (<strong class="bold">CI/CD</strong>): Vertex AI can help with automating the process of building, testing, and deploying models, which is important for keeping models updated and making sure they are always running smoothly <span class="No-Break">in production</span></li>
				<li><strong class="bold">Scalability</strong>: Vertex AI can help with scaling ML models to handle large amounts of data and traffic, which is essential for maintaining the performance of models <span class="No-Break">in production</span></li>
				<li><strong class="bold">Monitoring</strong>: Vertex AI can help with monitoring and measuring the performance of ML models in production, which is vital for understanding how well models are working and identifying areas <span class="No-Break">for improvement</span></li>
			</ul>
			<p>Overall, Vertex AI can help with MLOps by providing a comprehensive platform for managing the entire ML life cycle on GCP, from development to deployment and maintenance, making it easier to build, deploy, and manage ML models <span class="No-Break">in production.</span></p>
			<p>This table <a id="_idIndexMarker075"/>shows which Vertex <a id="_idIndexMarker076"/>AI tools or features can help you implement which components of a typical <span class="No-Break">MLOps pipeline:</span></p>
			<table id="table001-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">MLOps Components</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Vertex </strong><span class="No-Break"><strong class="bold">AI Tool</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Other </strong><span class="No-Break"><strong class="bold">GCP Tools</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Feature Management</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Vertex AI <span class="No-Break">Feature Store</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">N/A</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Data Management</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Vertex <span class="No-Break">AI Datasets</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">BigQuery</span></p>
							<p>Google <span class="No-Break">Cloud Storage</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Data Exploration &amp; <span class="No-Break">Analysis</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Vertex <span class="No-Break">AI Workbench</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Data Fusion</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Metadata Store</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Vertex AI <span class="No-Break">Metadata Store</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">N/A</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Workflow Orchestration</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Vertex <span class="No-Break">AI Pipelines</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Kubeflow on <strong class="bold">Google Kubernetes </strong><span class="No-Break"><strong class="bold">Engine </strong></span><span class="No-Break">(</span><span class="No-Break"><strong class="bold">GKE</strong></span><span class="No-Break">)</span></p>
							<p><span class="No-Break">Composer (Airflow)</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Model Registry</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Vertex AI <span class="No-Break">Model Registry</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">N/A</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Model Development</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Vertex <span class="No-Break">AI Training</span></p>
							<p>Vertex <span class="No-Break">AI Experiments</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">N/A</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Model <span class="No-Break">Serving/Prediction Service</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Vertex AI <span class="No-Break">Batch Predictions</span></p>
							<p>Vertex <span class="No-Break">AI Endpoints</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Custom deployments on GCE <span class="No-Break">or GKE</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Monitoring</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Vertex <span class="No-Break">AI Monitoring</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">N/A</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 2.1 – MLOps to GCP product mapping</p>
			<p>Let’s <a id="_idIndexMarker077"/>look at these Vertex AI tools <span class="No-Break">in detail.</span></p>
			<p><strong class="bold">Vertex AI Workbench</strong> is a fully <a id="_idIndexMarker078"/>managed Jupyter Notebook-based <a id="_idIndexMarker079"/>development environment that supports the entire data science workflow. The key features include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Integration with most Google Cloud data sources, such as BigQuery and Google <span class="No-Break">Cloud Storage</span></li>
				<li>The ability to <a id="_idIndexMarker080"/>create and use highly scalable Jupyter <strong class="bold">virtual machine</strong> (<span class="No-Break"><strong class="bold">VM</strong></span><span class="No-Break">) instances</span></li>
				<li>The ability <a id="_idIndexMarker081"/>to trigger and utilize most GCP services through a <strong class="bold">software development </strong><span class="No-Break"><strong class="bold">kit</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">SDK</strong></span><span class="No-Break">)</span></li>
				<li>The ability to kick off cluster and job creation in Dataproc (managed <span class="No-Break">Spark service)</span></li>
				<li><span class="No-Break">Notebook scheduling</span></li>
			</ul>
			<p>The following screenshot shows the Vertex AI Workbench dashboard with a list of all deployed Jupyter <span class="No-Break">Notebook instances:</span></p>
			<div>
				<div id="_idContainer018" class="IMG---Figure">
					<img src="image/B17792_02_5.jpg" alt="Figure 2.5 – Vertex AI Workbench dashboard" width="1650" height="881"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.5 – Vertex AI Workbench dashboard</p>
			<p><strong class="bold">Vertex AI Data Management</strong> is, as the <a id="_idIndexMarker082"/>name suggests, Vertex AI’s native dataset management service. It allows users to do <span class="No-Break">the following:</span></p>
			<ul>
				<li>Import data into Vertex AI and manage <span class="No-Break">the datasets</span></li>
				<li>Manage labels and multiple <span class="No-Break">annotation sets</span></li>
				<li>When used in conjunction with Metadata Store, it helps track data lineage to models for troubleshooting <span class="No-Break">and audits</span></li>
				<li>Generate data statistics <span class="No-Break">and visualizations</span></li>
			</ul>
			<p>The following screenshot shows the Vertex AI Datasets dashboard with a list of all datasets created with <span class="No-Break">the tool:</span></p>
			<div>
				<div id="_idContainer019" class="IMG---Figure">
					<img src="image/B17792_02_6.jpg" alt="Figure 2.6 – Vertex AI Datasets dashboard" width="1021" height="603"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.6 – Vertex AI Datasets dashboard</p>
			<p><strong class="bold">Vertex AI Feature Store</strong> is a managed <a id="_idIndexMarker083"/>feature catalog service, part of <a id="_idIndexMarker084"/>Vertex AI. Key features include <span class="No-Break">the following:</span></p>
			<ul>
				<li>The ability to import and organize the <span class="No-Break">feature values</span></li>
				<li>The ability to serve the feature values in batch or <span class="No-Break">real-time modes</span></li>
				<li>The ability to monitor the change over time in feature values and <span class="No-Break">generate alerts</span></li>
			</ul>
			<p>The following screenshot shows the Vertex AI Feature Store dashboard with a list of all the features <a id="_idIndexMarker085"/>and entities present in <span class="No-Break">the tool.</span></p>
			<div>
				<div id="_idContainer020" class="IMG---Figure">
					<img src="image/B17792_02_7.jpg" alt="Figure 2.7 – Vertex AI Feature Store dashboard" width="864" height="514"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.7 – Vertex AI Feature Store dashboard</p>
			<p><strong class="bold">Vertex AI Pipelines</strong> is a <a id="_idIndexMarker086"/>managed Kubeflow service in the Vertex AI platform, which helps you orchestrate complex data and ML workflows. Key features <a id="_idIndexMarker087"/>include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Support for the Kubeflow <span class="No-Break">Pipelines SDK</span></li>
				<li>Support <a id="_idIndexMarker088"/>for <strong class="bold">TensorFlow </strong><span class="No-Break"><strong class="bold">Extended</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">TFX</strong></span><span class="No-Break">)</span></li>
				<li>The ability to deploy vertically scalable components <span class="No-Break">as containers</span></li>
				<li>Native integration with all Vertex AI tools and most Google <span class="No-Break">Cloud services</span></li>
			</ul>
			<p>The following screenshot shows the Vertex AI Pipelines dashboard with a list of all recently <span class="No-Break">executed pipelines.</span></p>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="image/B17792_02_8.jpg" alt="Figure 2.8 – Vertex AI Pipelines dashboard" width="948" height="526"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.8 – Vertex AI Pipelines dashboard</p>
			<p><strong class="bold">Vertex ML Metadata Store</strong> can store <a id="_idIndexMarker089"/>key parameters/artifacts <a id="_idIndexMarker090"/>from the ML pipelines to enable <span class="No-Break">the following:</span></p>
			<ul>
				<li>Lineage tracking and auditing for <span class="No-Break">ML models</span></li>
				<li><span class="No-Break">Model reproducibility</span></li>
				<li>Analysis <span class="No-Break">of experiments</span></li>
				<li>Tracking downstream usage of ML artifacts for better governance <span class="No-Break">and compliance</span></li>
			</ul>
			<p>The following screenshot shows a Vertex AI Metadata Store dashboard. The following figure shows a sample Metadata Store artifact depicting the lineage of an <span class="No-Break">ML pipeline.</span></p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/B17792_02_9.jpg" alt="Figure 2.9 – Vertex AI Metadata Store" width="905" height="424"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.9 – Vertex AI Metadata Store</p>
			<p><strong class="bold">Vertex AI Model Registry</strong> is a centralized registry for all ML models regardless of whether <a id="_idIndexMarker091"/>they were custom models or models generated by using AutoML capabilities. Key features include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Fully managed <span class="No-Break">model registry</span></li>
				<li>Seamless <a id="_idIndexMarker092"/>model deployments for a batch or real-time <span class="No-Break">prediction service</span></li>
				<li>The ability to <span class="No-Break">compare models</span></li>
			</ul>
			<p>The following figure shows the Vertex AI Model Registry dashboard with a list of <span class="No-Break">registered models.</span></p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B17792_02_10.jpg" alt="Figure 2.10 – Vertex AI Model Registry" width="1020" height="516"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.10 – Vertex AI Model Registry</p>
			<p><strong class="bold">Vertex AI Training</strong> is the <a id="_idIndexMarker093"/>core managed training service in Vertex AI that enables users to run complex ML model training jobs without managing the underlying <a id="_idIndexMarker094"/>infrastructure. Key capabilities include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Native support for TensorFlow, XGBoost, and scikit-learn <span class="No-Break">custom models</span></li>
				<li>The ability to deploy training jobs using <span class="No-Break">custom containers</span></li>
				<li>Automate ML for a variety of <span class="No-Break">use cases</span></li>
				<li>The ability <a id="_idIndexMarker095"/>to deploy models on extremely scalable <span class="No-Break">on-demand clusters</span></li>
				<li><span class="No-Break">Managed TensorBoard</span></li>
			</ul>
			<p><strong class="bold">Vertex AI Experiments</strong> is a managed experiment orchestration feature that enables the data <a id="_idIndexMarker096"/>science team to kick off a number of similar training jobs with slightly differing hyperparameters as part of <span class="No-Break">model design.</span></p>
			<p>The following figure shows the Vertex AI Experiments dashboard with a list of executed <span class="No-Break">training experiments.</span></p>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/B17792_02_11.jpg" alt="Figure 2.11 – Vertex AI Experiments dashboard" width="879" height="646"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.11 – Vertex AI Experiments dashboard</p>
			<p><strong class="bold">Vertex AI Batch Predictions</strong> provides fully managed batch predictions for models, uploaded <a id="_idIndexMarker097"/>to the <span class="No-Break">model registry.</span></p>
			<p>The following figure shows the Vertex AI Batch Predictions dashboard with a list of batch prediction jobs run on <span class="No-Break">the platform.</span></p>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="image/B17792_02_12.jpg" alt="Figure 2.12 – Vertex AI Batch Predictions dashboard" width="1159" height="578"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.12 – Vertex AI Batch Predictions dashboard</p>
			<p><strong class="bold">Vertex AI Endpoints</strong> is a <a id="_idIndexMarker098"/>managed model serving capability for <a id="_idIndexMarker099"/>real-time prediction use cases. Key features include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Configurable <span class="No-Break">serving infrastructure</span></li>
				<li><span class="No-Break">Autoscaling capabilities</span></li>
				<li>The ability to detect the number of performance issues relating to increased prediction latency, capacity bottlenecks, and <span class="No-Break">so on</span></li>
			</ul>
			<p>The following figure shows the dashboard for Vertex <span class="No-Break">AI Endpoints.</span></p>
			<div>
				<div id="_idContainer026" class="IMG---Figure">
					<img src="image/B17792_02_13.jpg" alt="Figure 2.13 – Vertex AI monitoring dashboard" width="1030" height="825"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.13 – Vertex AI monitoring dashboard</p>
			<p><strong class="bold">Vertex AI Monitoring</strong> helps <a id="_idIndexMarker100"/>automate the monitoring of deployed <a id="_idIndexMarker101"/>models in production to identify performance issues proactively. Key features include <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break">Drift detection</span></li>
				<li>Training-serving <span class="No-Break">skew detection</span></li>
			</ul>
			<p>As you can see, Google Cloud Vertex AI offers a comprehensive and robust set of tools that can help you streamline the entire ML development life cycle, from data management to model deployment <span class="No-Break">and monitoring.</span></p>
			<h1 id="_idParaDest-40"><a id="_idTextAnchor039"/>Summary</h1>
			<p>In this chapter, we delved into the core concepts of MLOps and explored the various levels of maturity that MLOps solutions exhibit in real-world scenarios. We also discussed the various tools and resources that are available as part of the Vertex AI platform, which are designed to help streamline and automate the process of building, deploying, and maintaining <span class="No-Break">ML models.</span></p>
			<p>After reading this chapter, we hope you are able to better articulate the fundamentals of MLOps practices and develop a high-level MLOps strategy for your organization, taking into consideration your organization’s unique requirements and goals, and understand how Vertex AI, as a part of GCP, can play a crucial role in your organization’s <span class="No-Break">MLOps strategy.</span></p>
			<p>In the next chapter, we cover the options available in Google Cloud to store data in order to support your ML solution’s training needs. We also discuss the tools available to you to help you transform large-scale datasets as part of feature <span class="No-Break">engineering activities.</span></p>
		</div>
	</div>
</div>


<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer028" class="Content">
			<h1 id="_idParaDest-41" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor040"/>Part 2: Machine Learning Tools for Custom Models on  Google Cloud</h1>
		</div>
		<div id="_idContainer029">
			<p>In this part, you will get an overview of the key ML tools that Google Cloud offers. You will learn about the different options in Google Vertex AI for storing and transforming data, training ML models, model optimization, model explainability, and so on. In addition to this, you will learn about the deployment tools, automation tools, and governance tools that Vertex AI offers for <span class="No-Break">ML orchestration.</span></p>
			<p>This part has the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B17792_03.xhtml#_idTextAnchor041"><em class="italic">Chapter 3</em></a>, <em class="italic">It’s All about Data – Options to Store and Transform ML Datasets</em></li>
				<li><a href="B17792_04.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Vertex AI Workbench – a One-Stop Tool for </em><em class="italic">AI/ML</em><em class="italic"> Development Needs</em></li>
				<li><a href="B17792_05.xhtml#_idTextAnchor066"><em class="italic">Chapter 5</em></a>, <em class="italic">No-Code Options for Building ML Models</em></li>
				<li><a href="B17792_06.xhtml#_idTextAnchor079"><em class="italic">Chapter 6</em></a>, <em class="italic">Low-Code Options for Building ML Models</em></li>
				<li><a href="B17792_07.xhtml#_idTextAnchor093"><em class="italic">Chapter 7</em></a>, <em class="italic">Training Fully Custom ML Models with Vertex AI</em></li>
				<li><a href="B17792_08.xhtml#_idTextAnchor102"><em class="italic">Chapter 8</em></a>, <em class="italic">ML Model Explainability</em></li>
				<li><a href="B17792_09.xhtml#_idTextAnchor121"><em class="italic">Chapter 9</em></a>, <em class="italic">Model Optimizations – Hyperparameter Tuning and NAS</em></li>
				<li><a href="B17792_10.xhtml#_idTextAnchor136"><em class="italic">Chapter 10</em></a>, <em class="italic">Vertex AI Deployment and Automation Tools – Orchestration through Managed Kubeflow Pipelines</em></li>
				<li><a href="B17792_11.xhtml#_idTextAnchor153"><em class="italic">Chapter 11</em></a>, <em class="italic">MLOps Governance with Vertex AI</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer030">
			</div>
		</div>
		<div>
			<div id="_idContainer031" class="Basic-Graphics-Frame">
			</div>
		</div>
	</div>
</div>
</body></html>