["```py\n# import packages we need for exploratory data analysis (EDA)\nimport pandas as pd # to store tabular data\nimport numpy as np # to do some math\nimport matplotlib.pyplot as plt # a popular data visualization tool\nimport seaborn as sns  # another popular data visualization tool\n%matplotlib inline \nplt.style.use('fivethirtyeight') # a popular data visualization theme\n```", "```py\n# load in our dataset using pandas\npima = pd.read_csv('../data/pima.data')\n\npima.head()\n\n```", "```py\npima_column_names = ['times_pregnant', 'plasma_glucose_concentration', 'diastolic_blood_pressure', 'triceps_thickness', 'serum_insulin', 'bmi', 'pedigree_function', 'age', 'onset_diabetes']\n\npima = pd.read_csv('../data/pima.data', names=pima_column_names)\n\npima.head()\n\n```", "```py\npima['onset_diabetes'].value_counts(normalize=True) \n# get null accuracy, 65% did not develop diabetes\n\n0    0.651042\n1    0.348958\nName: onset_diabetes, dtype: float64\n```", "```py\n# get a histogram of the plasma_glucose_concentration column for\n# both classes\n\ncol = 'plasma_glucose_concentration'\nplt.hist(pima[pima['onset_diabetes']==0][col], 10, alpha=0.5, label='non-diabetes')\nplt.hist(pima[pima['onset_diabetes']==1][col], 10, alpha=0.5, label='diabetes')\nplt.legend(loc='upper right')\nplt.xlabel(col)\nplt.ylabel('Frequency')\nplt.title('Histogram of {}'.format(col))\nplt.show()\n```", "```py\nfor col in ['bmi', 'diastolic_blood_pressure', 'plasma_glucose_concentration']:\n    plt.hist(pima[pima['onset_diabetes']==0][col], 10, alpha=0.5, label='non-diabetes')\n    plt.hist(pima[pima['onset_diabetes']==1][col], 10, alpha=0.5, label='diabetes')\n    plt.legend(loc='upper right')\n    plt.xlabel(col)\n    plt.ylabel('Frequency')\n    plt.title('Histogram of {}'.format(col))\n    plt.show()\n```", "```py\n# look at the heatmap of the correlation matrix of our dataset\nsns.heatmap(pima.corr())\n# plasma_glucose_concentration definitely seems to be an interesting feature here\n```", "```py\npima.corr()['onset_diabetes'] # numerical correlation matrix\n# plasma_glucose_concentration definitely seems to be an interesting feature here\n\ntimes_pregnant                  0.221898\nplasma_glucose_concentration    0.466581 diastolic_blood_pressure        0.065068\ntriceps_thickness               0.074752\nserum_insulin                   0.130548\nbmi                             0.292695\npedigree_function               0.173844\nage                             0.238356\nonset_diabetes                  1.000000\nName: onset_diabetes, dtype: float64\n```", "```py\npima.isnull().sum()\n>>>>\ntimes_pregnant                  0\nplasma_glucose_concentration    0\ndiastolic_blood_pressure        0\ntriceps_thickness               0\nserum_insulin                   0\nbmi                             0\npedigree_function               0\nage                             0\nonset_diabetes                  0\ndtype: int64\n```", "```py\npima.shape . # (# rows, # cols)\n(768, 9)\n```", "```py\npima['onset_diabetes'].value_counts(normalize=True) \n# get null accuracy, 65% did not develop diabetes\n\n0    0.651042\n1    0.348958\nName: onset_diabetes, dtype: float64\n```", "```py\npima.describe()  # get some basic descriptive statistics\n\n```", "```py\n# Our number of missing values is (incorrectly) 0\npima['serum_insulin'].isnull().sum()\n\n0\n\npima['serum_insulin'] = pima['serum_insulin'].map(lambda x:x if x != 0 else None)\n# manually replace all 0's with a None value\n\npima['serum_insulin'].isnull().sum()\n# check the number of missing values again\n\n374\n```", "```py\n# A little faster now for all columns\n\ncolumns = ['serum_insulin', 'bmi', 'plasma_glucose_concentration', 'diastolic_blood_pressure', 'triceps_thickness']\n\nfor col in columns:\n    pima[col].replace([0], [None], inplace=True)\n```", "```py\npima.isnull().sum()  # this makes more sense now!\n\ntimes_pregnant                    0\nplasma_glucose_concentration      5\ndiastolic_blood_pressure         35\ntriceps_thickness               227\nserum_insulin                   374\nbmi                              11\npedigree_function                 0\nage                               0\nonset_diabetes                    0\ndtype: int64\n\npima.head()\n```", "```py\npima.describe()  # grab some descriptive statistics\n```", "```py\npima['plasma_glucose_concentration'].mean(), pima['plasma_glucose_concentration'].std()\n\n(121.68676277850589, 30.53564107280403)\n```", "```py\n# drop the rows with missing values\npima_dropped = pima.dropna()\n```", "```py\nnum_rows_lost = round(100*(pima.shape[0] - pima_dropped.shape[0])/float(pima.shape[0]))\n\nprint \"retained {}% of rows\".format(num_rows_lost)\n# lost over half of the rows!\n\nretained 49.0% of rows\n```", "```py\n# some EDA of the dataset before it was dropped and after\n\n# split of trues and falses before rows dropped\npima['onset_diabetes'].value_counts(normalize=True)\n\n0    0.651042\n1    0.348958\nName: onset_diabetes, dtype: float64\n```", "```py\npima_dropped['onset_diabetes'].value_counts(normalize=True)  \n\n0    0.668367\n1    0.331633\nName: onset_diabetes, dtype: float64\n\n# the split of trues and falses stay relatively the same\n```", "```py\n# the mean values of each column (excluding missing values)\npima.mean()\n\ntimes_pregnant                    3.845052\nplasma_glucose_concentration    121.686763\ndiastolic_blood_pressure         72.405184\ntriceps_thickness                29.153420\nserum_insulin                   155.548223\nbmi                              32.457464\npedigree_function                 0.471876\nage                              33.240885\nonset_diabetes                    0.348958\ndtype: float64\n```", "```py\n# the mean values of each column (with missing values rows dropped)\npima_dropped.mean()\n\ntimes_pregnant                    3.301020\nplasma_glucose_concentration    122.627551\ndiastolic_blood_pressure         70.663265\ntriceps_thickness                29.145408\nserum_insulin                   156.056122\nbmi                              33.086224\npedigree_function                 0.523046\nage                              30.864796\nonset_diabetes                    0.331633\ndtype: float64\n```", "```py\n# % change in means\n(pima_dropped.mean() - pima.mean()) / pima.mean()\n\ntimes_pregnant                 -0.141489\nplasma_glucose_concentration    0.007731\ndiastolic_blood_pressure       -0.024058\ntriceps_thickness              -0.000275\nserum_insulin                   0.003265\nbmi                             0.019372\npedigree_function               0.108439\nage                            -0.071481\nonset_diabetes                 -0.049650\ndtype: float64\n```", "```py\n# % change in means as a bar chart\nax = ((pima_dropped.mean() - pima.mean()) / pima.mean()).plot(kind='bar', title='% change in average column values')\nax.set_ylabel('% change')\n```", "```py\n# now lets do some machine learning\n\n# note we are using the dataset with the dropped rows\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nX_dropped = pima_dropped.drop('onset_diabetes', axis=1)\n# create our feature matrix by removing the response variable\nprint \"learning from {} rows\".format(X_dropped.shape[0])\ny_dropped = pima_dropped['onset_diabetes']\n\n# our grid search variables and instances\n\n# KNN parameters to try\nknn_params = {'n_neighbors':[1, 2, 3, 4, 5, 6, 7]}\n\nknn = KNeighborsClassifier() . # instantiate a KNN model\n\ngrid = GridSearchCV(knn, knn_params)\ngrid.fit(X_dropped, y_dropped)\n\nprint grid.best_score_, grid.best_params_\n# but we are learning from way fewer rows..\n```", "```py\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n```", "```py\nX_dropped = pima_dropped.drop('onset_diabetes', axis=1) \n# create our feature matrix by removing the response variable\nprint \"learning from {} rows\".format(X_dropped.shape[0])\n\nlearning from 392 rows\n```", "```py\ny_dropped = pima_dropped['onset_diabetes']\n```", "```py\n# our grid search variables and instances\n\n# KNN parameters to try\n\nknn_params = {'n_neighbors':[1, 2, 3, 4, 5, 6, 7]}\n```", "```py\ngrid = GridSearchCV(knn, knn_params)\ngrid.fit(X_dropped, y_dropped)\n\nprint grid.best_score_, grid.best_params_\n# but we are learning from way fewer rows..\n\n0.744897959184 {'n_neighbors': 7}\n```", "```py\npima.isnull().sum()  # let's fill in the plasma column\n\ntimes_pregnant                    0\nplasma_glucose_concentration      5 diastolic_blood_pressure         35\ntriceps_thickness               227\nserum_insulin                   374\nbmi                              11\npedigree_function                 0\nage                               0\nonset_diabetes                    0\ndtype: int64\n```", "```py\nempty_plasma_index = pima[pima['plasma_glucose_concentration'].isnull()].index\npima.loc[empty_plasma_index]['plasma_glucose_concentration']\n\n75     None\n182    None\n342    None\n349    None\n502    None\nName: plasma_glucose_concentration, dtype: object\n```", "```py\npima['plasma_glucose_concentration'].fillna(pima['plasma_glucose_concentration'].mean(), inplace=True)\n# fill the column's missing values with the mean of the rest of the column\n\npima.isnull().sum()  # the column should now have 0 missing values\n\ntimes_pregnant                    0\nplasma_glucose_concentration      0 diastolic_blood_pressure         35\ntriceps_thickness               227\nserum_insulin                   374\nbmi                              11\npedigree_function                 0\nage                               0\nonset_diabetes                    0\ndtype: int64\n```", "```py\npima.loc[empty_plasma_index]['plasma_glucose_concentration']\n\n75     121.686763\n182    121.686763\n342    121.686763\n349    121.686763\n502    121.686763\nName: plasma_glucose_concentration, dtype: float64\n```", "```py\nfrom sklearn.preprocessing import Imputer\n```", "```py\nimputer = Imputer(strategy='mean')\n```", "```py\npima_imputed = imputer.fit_transform(pima)\n```", "```py\ntype(pima_imputed)  # comes out as an array\n\nnumpy.ndarray\n```", "```py\npima_imputed = pd.DataFrame(pima_imputed, columns=pima_column_names)\n# turn our numpy array back into a pandas DataFrame object\n```", "```py\npima_imputed.head()  # notice for example the triceps_thickness missing values were replaced with 29.15342\n```", "```py\npima_imputed.loc[empty_plasma_index]['plasma_glucose_concentration'] \n# same values as we obtained with fillna\n\n75     121.686763\n182    121.686763\n342    121.686763\n349    121.686763\n502    121.686763\nName: plasma_glucose_concentration, dtype: float64\n```", "```py\npima_imputed.isnull().sum()  # no missing values\n\ntimes_pregnant                  0\nplasma_glucose_concentration    0\ndiastolic_blood_pressure        0\ntriceps_thickness               0\nserum_insulin                   0\nbmi                             0\npedigree_function               0\nage                             0\nonset_diabetes                  0\ndtype: int64\n```", "```py\npima_zero = pima.fillna(0) # impute values with 0\n\nX_zero = pima_zero.drop('onset_diabetes', axis=1)\nprint \"learning from {} rows\".format(X_zero.shape[0])\ny_zero = pima_zero['onset_diabetes']\n\nknn_params = {'n_neighbors':[1, 2, 3, 4, 5, 6, 7]}\ngrid = GridSearchCV(knn, knn_params)\ngrid.fit(X_zero, y_zero)\n\nprint grid.best_score_, grid.best_params_ \n# if the values stayed at 0, our accuracy goes down\n\nlearning from 768 rows\n0.73046875 {'n_neighbors': 6}\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nX = pima[['serum_insulin']].copy()\ny = pima['onset_diabetes'].copy()\n\nX.isnull().sum()\n\nserum_insulin    374\ndtype: int64\n```", "```py\n# the improper way.. imputing values BEFORE splitting\n\nentire_data_set_mean = X.mean()    # take the entire datasets mean\nX = X.fillna(entire_data_set_mean) # and use it to fill in the missing spots\nprint entire_data_set_mean\n\nserum_insulin    155.548223\ndtype: float64\n\n# Take the split using a random state so that we can examine the same split.\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)\n```", "```py\nknn = KNeighborsClassifier()\n\nknn.fit(X_train, y_train)\n\nknn.score(X_test, y_test)\n\n0.65625  # the accuracy of the improper split\n```", "```py\n# the proper way.. imputing values AFTER splitting\nfrom sklearn.model_selection import train_test_split\n\nX = pima[['serum_insulin']].copy()\ny = pima['onset_diabetes'].copy()\n\n# using the same random state to obtain the same split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)\n\nX.isnull().sum()\n\nserum_insulin    374\ndtype: int64\n```", "```py\ntraining_mean = X_train.mean()\nX_train = X_train.fillna(training_mean)\nX_test = X_test.fillna(training_mean)\n\nprint training_mean \n\nserum_insulin    158.546053\ndtype: float64\n\n# not the entire dataset's mean, it's much higher!!\n```", "```py\nknn = KNeighborsClassifier()\n\nknn.fit(X_train, y_train)\n\nprint knn.score(X_test, y_test)\n\n0.4895\n\n# lower accuracy, but much more honest in the mode's ability to generalize a pattern to outside data\n```", "```py\nfrom sklearn.pipeline import Pipeline\n\nknn_params = {'classify__n_neighbors':[1, 2, 3, 4, 5, 6, 7]}\n# must redefine params to fit the pipeline\n\nknn = KNeighborsClassifier() . # instantiate a KNN model\n\nmean_impute = Pipeline([('imputer', Imputer(strategy='mean')), ('classify', knn)])\n\nX = pima.drop('onset_diabetes', axis=1)\ny = pima['onset_diabetes']\n\ngrid = GridSearchCV(mean_impute, knn_params)\ngrid.fit(X, y)\n\nprint grid.best_score_, grid.best_params_\n\n0.731770833333 {'classify__n_neighbors': 6}\nmean_impute = Pipeline([('imputer', Imputer(strategy='mean')), ('classify', knn)])\n```", "```py\nknn_params = {'classify__n_neighbors':[1, 2, 3, 4, 5, 6, 7]}\n```", "```py\nknn_params = {'classify__n_neighbors':[1, 2, 3, 4, 5, 6, 7]}\n\nknn = KNeighborsClassifier() . # instantiate a KNN model\n\nmedian_impute = Pipeline([('imputer', Imputer(strategy='median')), ('classify', knn)])\nX = pima.drop('onset_diabetes', axis=1)\ny = pima['onset_diabetes']\n\ngrid = GridSearchCV(median_impute, knn_params)\ngrid.fit(X, y)\n\nprint grid.best_score_, grid.best_params_\n\n0.735677083333 {'classify__n_neighbors': 6}\n```", "```py\nimpute = Imputer(strategy='mean')\n# we will want to fill in missing values to see all 9 columns\n\npima_imputed_mean = pd.DataFrame(impute.fit_transform(pima), columns=pima_column_names)\n```", "```py\npima_imputed_mean.hist(figsize=(15, 15))\n```", "```py\npima_imputed_mean.describe()\n```", "```py\npima_imputed_mean.hist(figsize=(15, 15), sharex=True)\n# with the same x axis (the y axis is not as important here)\n```", "```py\nprint pima['plasma_glucose_concentration'].head()\n\n0    148.0\n1     85.0\n2    183.0\n3     89.0\n4    137.0\nName: plasma_glucose_concentration, dtype: float64\n```", "```py\n# get the mean of the column\nmu = pima['plasma_glucose_concentration'].mean()\n\n# get the standard deviation of the column\nsigma = pima['plasma_glucose_concentration'].std()\n\n# calculate z scores for every value in the column.\nprint ((pima['plasma_glucose_concentration'] - mu) / sigma).head()\n\n0    0.864545\n1   -1.205376\n2    2.014501\n3   -1.073952\n4    0.503130\nName: plasma_glucose_concentration, dtype: float64\n```", "```py\n# built in z-score normalizer\nfrom sklearn.preprocessing import StandardScaler\n```", "```py\n# mean and std before z score standardizing\npima['plasma_glucose_concentration'].mean(), pima['plasma_glucose_concentration'].std()\n\n(121.68676277850591, 30.435948867207657)\n\nax = pima['plasma_glucose_concentration'].hist()\nax.set_title('Distribution of plasma_glucose_concentration')\n```", "```py\nscaler = StandardScaler()\n\nglucose_z_score_standardized = scaler.fit_transform(pima[['plasma_glucose_concentration']])\n# note we use the double bracket notation [[ ]] because the transformer requires a dataframe\n\n# mean of 0 (floating point error) and standard deviation of 1\nglucose_z_score_standardized.mean(), glucose_z_score_standardized.std()\n\n(-3.5619655373390441e-16, 1.0)\n```", "```py\nax = pd.Series(glucose_z_score_standardized.reshape(-1,)).hist()\nax.set_title('Distribution of plasma_glucose_concentration after Z Score Scaling')\n```", "```py\nscale = StandardScaler() # instantiate a z-scaler object\n\npima_imputed_mean_scaled = pd.DataFrame(scale.fit_transform(pima_imputed_mean), columns=pima_column_names)\npima_imputed_mean_scaled.hist(figsize=(15, 15), sharex=True)\n# now all share the same \"space\"\n```", "```py\nknn_params = {'imputer__strategy':['mean', 'median'], 'classify__n_neighbors':[1, 2, 3, 4, 5, 6, 7]}\n\nmean_impute_standardize = Pipeline([('imputer', Imputer()), ('standardize', StandardScaler()), ('classify', knn)])\nX = pima.drop('onset_diabetes', axis=1)\ny = pima['onset_diabetes']\n\ngrid = GridSearchCV(mean_impute_standardize, knn_params)\ngrid.fit(X, y)\n\nprint grid.best_score_, grid.best_params_\n\n0.7421875 {'imputer__strategy': 'median', 'classify__n_neighbors': 7}\n```", "```py\n# import the sklearn module\nfrom sklearn.preprocessing import MinMaxScaler\n\n#instantiate the class\nmin_max = MinMaxScaler()\n\n# apply the Min Max Scaling\npima_min_maxed = pd.DataFrame(min_max.fit_transform(pima_imputed), columns=pima_column_names)\n\n# spit out some descriptive statistics\npima_min_maxed.describe()\n```", "```py\nknn_params = {'imputer__strategy': ['mean', 'median'], 'classify__n_neighbors':[1, 2, 3, 4, 5, 6, 7]}\n\nmean_impute_standardize = Pipeline([('imputer', Imputer()), ('standardize', MinMaxScaler()), ('classify', knn)])\nX = pima.drop('onset_diabetes', axis=1)\ny = pima['onset_diabetes']\n\ngrid = GridSearchCV(mean_impute_standardize, knn_params)\ngrid.fit(X, y)\n\nprint grid.best_score_, grid.best_params_\n\n0.74609375 {'imputer__strategy': 'mean', 'classify__n_neighbors': 4}\n```", "```py\nnp.sqrt((pima_imputed**2).sum(axis=1)).mean() \n# average vector length of imputed matrix\n\n223.36222025823744\n```", "```py\nfrom sklearn.preprocessing import Normalizer # our row normalizer\n\nnormalize = Normalizer()\n\npima_normalized = pd.DataFrame(normalize.fit_transform(pima_imputed), columns=pima_column_names)\n\nnp.sqrt((pima_normalized**2).sum(axis=1)).mean()\n# average vector length of row normalized imputed matrix\n\n1.0\n```", "```py\nknn_params = {'imputer__strategy': ['mean', 'median'], 'classify__n_neighbors':[1, 2, 3, 4, 5, 6, 7]}\n\nmean_impute_normalize = Pipeline([('imputer', Imputer()), ('normalize', Normalizer()), ('classify', knn)])\nX = pima.drop('onset_diabetes', axis=1)\ny = pima['onset_diabetes']\n\ngrid = GridSearchCV(mean_impute_normalize, knn_params)\ngrid.fit(X, y)\n\nprint grid.best_score_, grid.best_params_\n\n0.682291666667 {'imputer__strategy': 'mean', 'classify__n_neighbors': 6}\n```"]