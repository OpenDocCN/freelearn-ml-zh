<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer095">
<h1 class="chapter-number" id="_idParaDest-244"><a id="_idTextAnchor247"/>15</h1>
<h1 id="_idParaDest-245"><a id="_idTextAnchor248"/>Diversity Issues in Synthetic Data</h1>
<p>This chapter introduces you to a well-known issue in the field of synthetic data, which is generating diverse synthetic datasets. It discusses different approaches to ensure high diversity in large-scale datasets. Then, it highlights some issues and challenges in achieving diversity for <span class="No-Break">synthetic data.</span></p>
<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>The need for diverse data <span class="No-Break">in ML</span></li>
<li>Generating diverse <span class="No-Break">synthetic datasets</span></li>
<li>Diversity issues in the synthetic <span class="No-Break">data realm</span></li>
</ul>
<h1 id="_idParaDest-246"><a id="_idTextAnchor249"/>The need for diverse data in ML</h1>
<p>As we have<a id="_idIndexMarker620"/> discussed and seen in previous chapters, diverse training data improves the generalizability of ML models to new domains and contexts. In fact, diversity helps your ML-based solution to be more accurate and better applicable to real-world scenarios. Additionally, it makes it more robust to noise and anomalies, which are usually unavoidable in practice. For more information, please refer to <em class="italic">Diversity in Machine Learning</em> (<a href="https://arxiv.org/abs/1807.01477">https://arxiv.org/abs/1807.01477</a>) and <em class="italic">Performance of Machine Learning Algorithms and Diversity in </em><span class="No-Break"><em class="italic">Data</em></span><span class="No-Break"> (</span><a href="https://doi.org/10.1051/MATECCONF%2F201821004019"><span class="No-Break">https://doi.org/10.1051/MATECCONF%2F201821004019</span></a><span class="No-Break">).</span></p>
<p>Next, let’s highlight some of the main advantages of using diverse training data in ML. In general, training and validating your ML model on diverse datasets improve <span class="No-Break">the following:</span></p>
<ul>
<li><span class="No-Break">Transferability</span></li>
<li><span class="No-Break">Problem modeling</span></li>
<li><span class="No-Break">Security</span></li>
<li>The process <span class="No-Break">of debugging</span></li>
<li>Robustness <span class="No-Break">to anomalies</span></li>
<li><span class="No-Break">Creativity</span></li>
<li><span class="No-Break">Customer satisfaction</span></li>
</ul>
<p>Now, let’s delve into each of these elements in <span class="No-Break">more detail.</span></p>
<h2 id="_idParaDest-247"><a id="_idTextAnchor250"/>Transferability</h2>
<p>When you train your ML model on <a id="_idIndexMarker621"/>diverse data covering a variety of scenarios, contexts, and environments, you boost the transferability of your ML solution to other applications and domains. The reason for this is that when the model learns how to deal with more diverse situations in the training stage, it becomes more capable of adapting to new, unseen contexts. For more information, please refer to <em class="italic">Can Data Diversity Enhance Learning </em><span class="No-Break"><em class="italic">Generalization?</em></span><span class="No-Break"> (</span><a href="https://aclanthology.org/2022.coling-1.437"><span class="No-Break">https://aclanthology.org/2022.coling-1.437</span></a><span class="No-Break">).</span></p>
<h2 id="_idParaDest-248"><a id="_idTextAnchor251"/>Better problem modeling</h2>
<p>Diverse training data<a id="_idIndexMarker622"/> enables the ML model to look at the problem from different perspectives. For example, let’s consider that our ML model is learning a semantic segmentation task. Training the model under adverse weather conditions and with objects of various colors, textures, and shapes will help the model to better learn the mapping from the RGB images to the semantic segmentation ones. Thus, it will significantly enhance the performance as the model has already learned how to capture a wider range of patterns under various variations. These patterns and associations between input features and output labels may not be easily identified given a less diverse <span class="No-Break">training dataset.</span></p>
<h2 id="_idParaDest-249"><a id="_idTextAnchor252"/>Security</h2>
<p>Research has recently shown <a id="_idIndexMarker623"/>that training your ML model on diverse training data can improve the robustness of your model to adversarial attacks. Thus, your model becomes even more reliable and secure with diverse training data. For example, training your ML model on a diverse set of adversarial training samples significantly boosts your ML model’s robustness to adversarial attacks. These attacks primarily involve manipulating images with noise to fool the ML model while still making them recognizable to the human eye. For instance, a slight change in some pixels’ intensity such as the color of a traffic sign may cause ML models to wrongly classify<a id="_idIndexMarker624"/> it under a different class with a high confidence. For more information, please refer to <em class="italic">Diversity Adversarial Training against Adversarial Attack on Deep Neural Networks</em> (<a href="http://www.mdpi.com/2073-8994/13/3/428">http://www.mdpi.com/2073-8994/13/3/428</a>) and <em class="italic">Adversarial Attacks on Traffic Sign Recognition: A </em><span class="No-Break"><em class="italic">Survey</em></span><span class="No-Break"> (</span><a href="https://arxiv.org/pdf/2307.08278.pdf"><span class="No-Break">https://arxiv.org/pdf/2307.08278.pdf</span></a><span class="No-Break">).</span></p>
<h2 id="_idParaDest-250"><a id="_idTextAnchor253"/>Process of debugging</h2>
<p>Leveraging diverse data in the <a id="_idIndexMarker625"/>validation and evaluation stages helps ML practitioners identify the weaknesses and limitations of their ML models and algorithms. Thus, they can avoid costly failures under challenging scenarios. Furthermore, they can iterate on their solutions and mitigate any potential issues and problems. For instance, suppose we are proposing a new person identification ML model. To clearly understand the limitations of our model, we need to evaluate the model on diverse datasets that cover various illumination conditions, camera viewpoints, indoor and outdoor scenes, and other relevant attributes. This will help us to spot the weaknesses of our approach. By returning to our example, we may see that our model is struggling to identify people at nighttime or when the camera is very close to the person. This sort of observation is essential for improving the model and preventing costly failures, which cannot be achieved without using appropriate diverse validation or <span class="No-Break">evaluation datasets.</span></p>
<h2 id="_idParaDest-251"><a id="_idTextAnchor254"/>Robustness to anomalies</h2>
<p>Training your ML model on diverse<a id="_idIndexMarker626"/> training data that includes anomalies helps the model learn how to deal with similar situations. Thus, it makes your ML-based solution more robust against outliers and unexpected situations. For instance, let’s suppose you trained your ML model for depth estimation on standard data collected by an industry-standard sensor under normal conditions. Your model may fail if the camera sensor was partially damaged, or some dust or raindrops accumulated on the camera lens. Therefore, training your ML model on similar scenarios improves the robustness and reliability of your ML system. Please refer to <em class="italic">A Novel Cross-Perturbation for Single Domain Generalization</em> (<a href="https://arxiv.org/pdf/2308.00918.pdf">https://arxiv.org/pdf/2308.00918.pdf</a>) for more <span class="No-Break">in-depth details.</span></p>
<h2 id="_idParaDest-252"><a id="_idTextAnchor255"/>Creativity</h2>
<p>In problems where creativity<a id="_idIndexMarker627"/> is a key requirement, training generative models on diverse training data is necessary to fuel this need. For instance, an LLM or image generator will significantly benefit from being trained on textual or visual data collected from different sources. This will help these generative models to be exposed to various topics, styles, ideas, and opinions, which will provide sufficient knowledge and urge the model to be more creative at various tasks and<a id="_idIndexMarker628"/> applications. For <a id="_idIndexMarker629"/>some interesting<a id="_idIndexMarker630"/> examples, please <a id="_idIndexMarker631"/>refer to <em class="italic">Deep Dream Generator</em> (<a href="https://deepdreamgenerator.com">https://deepdreamgenerator.com</a>), <em class="italic">AutoDraw</em> (<a href="https://www.autodraw.com">https://www.autodraw.com</a>), <em class="italic">Stablecog</em> (<a href="https://stablecog.com">https://stablecog.com</a>), and <em class="italic">DALL-E </em><span class="No-Break"><em class="italic">2</em></span><span class="No-Break"> (</span><a href="https://openai.com/dall-e-2"><span class="No-Break">https://openai.com/dall-e-2</span></a><span class="No-Break">).</span></p>
<h2 id="_idParaDest-253"><a id="_idTextAnchor256"/>Inclusivity</h2>
<p>Deploying diverse training data <a id="_idIndexMarker632"/>that appropriately represents the real world helps customers to feel that your ML-based solution is inclusive and does not discriminate against any characteristics of the population worldwide. Therefore, it is essential to ensure that your ML model works as intended for all customers regardless of their age, race, gender, geography, language, and religion. If customers feel that they are disadvantaged because of any of the previous factors, they will develop a negative impression of your business, not just the application itself. Additionally, it may cause legal issues and unwanted consequences to organizations. On the other hand, it helps decision-makers to make more appropriate decisions that take into careful consideration the unique needs of each demographic group of the <span class="No-Break">target audience.</span></p>
<p>Now that we understand the importance of training our ML models on diverse training data, let’s examine how to generate diverse <span class="No-Break">synthetic data.</span></p>
<h1 id="_idParaDest-254"><a id="_idTextAnchor257"/>Generating diverse synthetic datasets</h1>
<p>In this section, you will learn<a id="_idIndexMarker633"/> different methods of generating diverse synthetic datasets. We will discuss <span class="No-Break">the following:</span></p>
<ul>
<li>Latent <span class="No-Break">space variations</span></li>
<li>Ensemble synthetic <span class="No-Break">data generation</span></li>
<li><span class="No-Break">Diversity regularization</span></li>
<li>Incorporating <span class="No-Break">external knowledge</span></li>
<li><span class="No-Break">Progressive training</span></li>
<li>Procedural <a id="_idIndexMarker634"/>content generation with <span class="No-Break">game engines</span></li>
</ul>
<h2 id="_idParaDest-255"><a id="_idTextAnchor258"/>Latent space variations</h2>
<p>Latent space usually refers<a id="_idIndexMarker635"/> to a high-dimensional space where the training data is represented in a more abstract or compact way. Deep learning with many layers is designed to make the features in the latent space capture more semantic and conceptual information. For more details, please refer to <a href="B18494_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>. Thus, these features, in that space, convey encoded information about the problem through the ML model during the training stage. We may not be able to directly link the changes in the latent space to the changes that will happen on the generated images in models such as GANs. However, it was shown in <em class="italic">Interpreting the Latent Space of GANs for Semantic Face Editing</em> (<a href="https://arxiv.org/abs/1907.10786">https://arxiv.org/abs/1907.10786</a>) and <em class="italic">Closed-Form Factorization of Latent Semantics in GANs</em> (<a href="https://arxiv.org/abs/2007.06600">https://arxiv.org/abs/2007.06600</a>) that changing certain attributes in the latent space can generate unique and diverse synthetic samples. For instance, if you carefully change certain features in the latent space, you may generate new samples with different poses, backgrounds, lighting, and <span class="No-Break">weather conditions.</span></p>
<h2 id="_idParaDest-256"><a id="_idTextAnchor259"/>Ensemble synthetic data generation</h2>
<p>One of the approaches that is<a id="_idIndexMarker636"/> usually deployed to improve the diversity of the generated synthetic data is using multiple generative models to ensure that they capture the intended data distribution. This is especially applicable if the distribution is complex and cannot be modeled using a single generative model. For more information, please refer to <em class="italic">Ensembles of GANs for Synthetic Training Data Generation</em> (<a href="https://arxiv.org/pdf/2104.11797.pdf">https://arxiv.org/pdf/2104.11797.pdf</a>). In this work, multiple GANs were used to improve the generated synthetic data diversity. The researchers focused specifically on the effectiveness of this approach for synthesizing digital pathology patches. GANs were trained independently and in isolation from each other on the training dataset. This work shows that the stochasticity of the optimization process is fundamental to better represent the training data<a id="_idIndexMarker637"/> distribution and enrich the generated data diversity <span class="No-Break">for GANs.</span></p>
<h2 id="_idParaDest-257"><a id="_idTextAnchor260"/>Diversity regularization</h2>
<p>Another approach to encourage <a id="_idIndexMarker638"/>generative models to generate diverse synthetic samples is to utilize a regularization term in the training objective or loss. In other words, you can penalize the generative model for generating similar synthetic samples. Thus, your model will tend to generate more diverse samples to minimize the training loss. For example, this approach was utilized in <em class="italic">Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis</em> (<a href="https://arxiv.org/pdf/1903.05628.pdf">https://arxiv.org/pdf/1903.05628.pdf</a>) to address the mode collapse issue in GANs and improve the diversity of the generated synthetic images. For more details about the mode collapse issue in GANs, please refer to <a href="B18494_07.xhtml#_idTextAnchor120"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>. This approach does not require any modification to the architecture of the GAN. It simply changes the loss to encourage the generator to generate dissimilar images. Thus, the generator is urged to better cover the training data distribution and consequently generate more diverse synthetic images. For a survey of the regularization approaches in GANs, please refer to <em class="italic">A Systematic Survey of Regularization and Normalization in </em><span class="No-Break"><em class="italic">GANs</em></span><span class="No-Break"> (</span><a href="https://arxiv.org/abs/2008.08930"><span class="No-Break">https://arxiv.org/abs/2008.08930</span></a><span class="No-Break">).</span></p>
<h2 id="_idParaDest-258"><a id="_idTextAnchor261"/>Incorporating external knowledge</h2>
<p>You can also condition the <a id="_idIndexMarker639"/>generation process to encourage the generative models to generate synthetic data with certain attributes and under specific scenarios. For example, if your data has fewer training samples taken in rainy conditions, you can explicitly condition the GAN model to generate more examples under this weather condition. Additionally, you may prevent generative models from generating examples that are not relevant to your problem. For example, if you are generating cat images in an indoor environment, you may prevent your GAN from generating examples under adverse weather conditions as they are not valid in this particular environment. This can be achieved through various means, such as modifying the loss function to impose penalties on these irrelevant or unwanted predictions. In this scenario, the discriminator would need to make at least two distinct predictions: one for assessing whether the sample is real or<a id="_idIndexMarker640"/> fake and another for determining <span class="No-Break">its relevance.</span></p>
<h2 id="_idParaDest-259"><a id="_idTextAnchor262"/>Progressive training</h2>
<p>Another interesting approach to<a id="_idIndexMarker641"/> increase the diversity of the generated synthetic samples is to gradually introduce more complex patterns, add more layers to the generator and discriminator throughout the training process, and penalize for less diverse examples during the training stage. This encourages the synthetic data generation model to generate more diverse and variant data. For example, researchers in <em class="italic">Progressive Growing of GANs for Improved Quality, Stability, and Variation</em> (<a href="https://arxiv.org/pdf/1710.10196.pdf">https://arxiv.org/pdf/1710.10196.pdf</a>) showed that growing the generator and discriminator by adding new layers and training on more detailed and higher-resolution images as the training progresses significantly improves the stability of the training process of the GAN and the diversity of the generated <span class="No-Break">synthetic images.</span></p>
<h2 id="_idParaDest-260"><a id="_idTextAnchor263"/>Procedural content generation with game engines</h2>
<p><strong class="bold">Procedural Content Generation</strong> (<strong class="bold">PCG</strong>) is a<a id="_idIndexMarker642"/> widely used approach in video games to make the virtual world diverse and <a id="_idIndexMarker643"/>rich, resulting in a better player experience. The same concept can be utilized in game engines and simulators to create diverse 3D virtual worlds and thus generate diverse synthetic data. PCG can be utilized to generate textures, objects, maps, animations, and other scene elements. For a specific example, please refer to <em class="italic">ProcSy: Procedural Synthetic Dataset Generation Towards Influence Factor Studies Of Semantic Segmentation </em><span class="No-Break"><em class="italic">Networks</em></span><span class="No-Break"> (</span><a href="https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/procsy"><span class="No-Break">https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/procsy</span></a><span class="No-Break">).</span></p>
<p>So far, we have learned the main approaches usually utilized to improve the diversity of the generated synthetic data. Next, let’s learn the main issues and limitations of <span class="No-Break">these approaches.</span></p>
<h1 id="_idParaDest-261"><a id="_idTextAnchor264"/>Diversity issues in the synthetic data realm</h1>
<p>As we have seen, diversity <a id="_idIndexMarker644"/>helps us to build robust, accurate, and general-purpose ML models. Additionally, we learned many approaches to improve synthetic data diversity in practice. In this section, we will examine three main issues we usually encounter when we try to generate diverse <span class="No-Break">synthetic data:</span></p>
<ul>
<li>Balancing diversity <span class="No-Break">and realism</span></li>
<li>Privacy and <span class="No-Break">confidentiality concerns</span></li>
<li>Validation and <span class="No-Break">evaluation challenges</span></li>
</ul>
<h2 id="_idParaDest-262"><a id="_idTextAnchor265"/>Balancing diversity and realism</h2>
<p>There is usually a trade-off <a id="_idIndexMarker645"/>between diversity and realism. Generating diverse synthetic examples without considering the realism of these generated samples may introduce or increase the domain gap between synthetic and real domains. For more details, please refer to <em class="italic">Chapters 13</em> and <em class="italic">14</em>. For example, let’s suppose that we want to generate images with sports cars for a particular computer vision task or application. While it is crucial to generate diverse sports cars that cover most of the available real sports car samples in the real world, we do not want to generate sports cars that are unlikely to be observed in our problem context. Thus, our aim should always be to generate synthetic data that accurately represents the distribution in the real world. It should be diverse but also realistic to be useful for training and testing ML models <span class="No-Break">in practice.</span></p>
<h2 id="_idParaDest-263"><a id="_idTextAnchor266"/>Privacy and confidentiality concerns</h2>
<p>When generating synthetic <a id="_idIndexMarker646"/>data for applications that have restrictions on the real data because of privacy or confidentiality concerns, it becomes rather hard to generate diverse synthetic data. The reason behind this is the limited understanding of the attributes, patterns, and correlations of the real data, which cannot be learned by generative models given a small-scale training dataset. Thus, it becomes extremely hard for generative models to generate diverse synthetic data for such applications. Please refer to <a href="B18494_03.xhtml#_idTextAnchor049"><span class="No-Break"><em class="italic">Chapter 3</em></span></a> for an in-depth discussion about privacy issues with large-scale <span class="No-Break">real datasets.</span></p>
<h2 id="_idParaDest-264"><a id="_idTextAnchor267"/>Validation and evaluation challenges</h2>
<p>One of the main issues in<a id="_idIndexMarker647"/> this area is assessing the diversity of the generated synthetic data, and thus the usability of this data in practice. Developing a robust, reliable, and universal diversity evaluation metric would be highly beneficial in practice. State-of-the-art metrics are usually problem dependent and experimental and lack the appropriate theoretical framework. For <a id="_idIndexMarker648"/>more information, please refer to <em class="italic">Reliable Fidelity and Diversity Metrics for Generative </em><span class="No-Break"><em class="italic">Models</em></span><span class="No-Break"> (</span><a href="https://arxiv.org/abs/2002.09797"><span class="No-Break">https://arxiv.org/abs/2002.09797</span></a><span class="No-Break">).</span></p>
<h1 id="_idParaDest-265"><a id="_idTextAnchor268"/>Summary</h1>
<p>In this chapter, we have discussed the main reasons why the diversity of data is crucial for ML-based solutions. We also examined the key approaches to generating diverse synthetic data. Then, we highlighted the main issues and challenges. In the next chapter, we will focus on another relevant and interesting issue in synthetic data, which <span class="No-Break">is photorealism.</span></p>
</div>
</div></body></html>