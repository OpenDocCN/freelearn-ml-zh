- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Key Concepts of Interpretability
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释性的关键概念
- en: This book covers many model interpretation methods. Some produce metrics, others
    create visuals, and some do both; some depict models broadly and others granularly.
    In this chapter, we will learn about two methods, feature importance and decision
    regions, as well as the taxonomies used to describe these methods. We will also
    detail what elements hinder machine learning interpretability as a primer to what
    lies ahead.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书涵盖了多种模型解释方法。有些产生指标，有些创建可视化，有些两者都有；有些广泛描述模型，有些则细致描述。在本章中，我们将学习两种方法：特征重要性和决策区域，以及用于描述这些方法的分类法。我们还将详细说明阻碍机器学习可解释性的因素，作为对接下来内容的入门。
- en: 'The following are the main topics we are going to cover in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们将在本章中讨论的主要主题：
- en: Learning about interpretation method types and scopes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解解释方法类型和范围
- en: Appreciating what hinders machine learning interpretability
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欣赏阻碍机器学习可解释性的因素
- en: Let’s start with our technical requirements.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从我们的技术要求开始。
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Although we began the book with a “toy example,” we will be leveraging real
    datasets throughout this book to be used in specific interpretation use cases.
    These come from many different sources and are often used only once.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们以一个“玩具示例”开始了本书，但我们将利用本书中的真实数据集，用于特定的解释用例。这些数据来自许多不同的来源，并且通常只使用一次。
- en: To avoid that, readers spend a lot of time downloading, loading, and preparing
    datasets for single examples; there’s a library called `mldatasets` that takes
    care of most of this. Instructions on how to install this library are located
    in the *Preface*. In addition to `mldatasets`, this chapter’s examples also use
    the `pandas`, `numpy`, `statsmodel`, `sklearn`, `seaborn`, and `matplotlib` libraries.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，读者需要花费大量时间下载、加载和准备数据集以供单个示例使用；有一个名为 `mldatasets` 的库可以处理大部分这些工作。关于如何安装此库的说明位于**序言**中。除了
    `mldatasets`，本章的示例还使用了 `pandas`、`numpy`、`statsmodel`、`sklearn`、`seaborn` 和 `matplotlib`
    库。
- en: 'The code for this chapter is located here: [https://packt.link/DgnVj](https://packt.link/DgnVj).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码位于此处：[https://packt.link/DgnVj](https://packt.link/DgnVj)。
- en: The mission
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务
- en: 'Imagine you are an analyst for a national health ministry, and there’s a **Cardiovascular
    Diseases** (**CVDs**) epidemic. The minister has made it a priority to reverse
    the growth and reduce the caseload to a 20-year low. To this end, a task force
    has been created to find clues in the data to ascertain the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你是一名国家卫生部的分析师，那里爆发了一场**心血管疾病**（**CVDs**）疫情。部长已将其列为优先事项，以扭转增长趋势并降低病例数至20年来的最低水平。为此，已成立一个特别工作组，以在数据中寻找线索，以确定以下内容：
- en: What risk factors can be addressed.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以解决哪些风险因素。
- en: If future cases can be predicted, interpret predictions on a case-by-case basis.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可以预测未来的案例，则可以逐个案例解释预测。
- en: You are part of this task force!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你是这支任务小组的一员！
- en: Details about CVD
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于心血管疾病的详细信息
- en: 'Before we dive into the data, we must gather some important details about CVD
    in order to do the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入数据之前，我们必须收集一些关于心血管疾病的重要细节，以便完成以下工作：
- en: Understand the problem’s context and relevance.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解问题的背景和相关性。
- en: Extract domain knowledge information that can inform our data analysis and model
    interpretation.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取可以告知我们的数据分析及模型解释的领域知识信息。
- en: Relate an expert-informed background to a dataset’s features.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将专家背景与数据集的特征联系起来。
- en: 'CVDs are a group of disorders, the most common of which is coronary heart disease
    (also known as *Ischaemic Heart Disease*). According to the World Health Organization,
    CVD is the leading cause of death globally, killing close to 18 million people
    annually. Coronary heart disease and strokes (which are, for the most part, a
    byproduct of CVD) are the most significant contributors to that. It is estimated
    that 80% of CVD is made up of modifiable risk factors. In other words, some of
    the preventable factors that cause CVD include the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 心血管疾病（CVDs）是一组疾病，其中最常见的是冠心病（也称为**缺血性心脏病**）。根据世界卫生组织的数据，心血管疾病是全球死亡的主要原因，每年导致近1800万人死亡。冠心病和中风（大部分是心血管疾病的副产品）是导致这一情况的最重要因素。据估计，80%的心血管疾病是由可改变的风险因素引起的。换句话说，一些可以预防导致心血管疾病的风险因素包括以下内容：
- en: Poor diet
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 饮食不良
- en: Smoking and alcohol consumption habits
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吸烟和饮酒习惯
- en: Obesity
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 肥胖
- en: Lack of physical activity
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏体育锻炼
- en: Poor sleep
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 睡眠质量差
- en: 'Also, many of the risk factors are non-modifiable and, therefore, known to
    be unavoidable, including the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Genetic predisposition
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Old age
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Male (varies with age)
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We won’t go into more domain-specific details about CVD because it is not required
    to make sense of the example. However, *it can’t be stressed enough how central
    domain knowledge is to model interpretation*. So, if this example was your job
    and many lives depended on your analysis, it would be advisable to read the latest
    scientific research on the subject and consult with domain experts to inform your
    interpretations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: The approach
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression is one common way to rank risk factors in medical use cases.
    Unlike linear regression, it doesn’t try to predict a continuous value for each
    of our observations, but it predicts a probability score that an observation belongs
    to a particular class. In this case, what we are trying to predict is, given *x*
    data for each patient, what is the *y* probability, from 0 to 1, that they have
    CVD?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Preparations
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will find the code for this example here: [https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/main/02/CVD.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/main/02/CVD.ipynb).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Loading the libraries
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To run this example, we need to install the following libraries:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '`mldatasets` to load the dataset'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas` and `numpy` to manipulate it'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`statsmodels` to fit the logistic regression model'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sklearn` (scikit-learn) to split the data'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matplotlib` and `seaborn` to visualize the interpretations'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We should load all of them first:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Understanding and preparing the data
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The data to be used in this example should then be loaded into a DataFrame
    we call `cvd_df`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'From this, we should get 70,000 records and 12 columns. We can take a peek
    at what was loaded with `info()`:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding command will output the names of each column with its type and
    how many non-null records it contains:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The data dictionary
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To understand what was loaded, the following is the data dictionary, as described
    in the source:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '`age`: Of the patient in days (objective feature)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`height`: In centimeters (objective feature)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`weight`: In kg (objective feature)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gender`: A binary where 1: female, 2: male (objective feature)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ap_hi`: Systolic blood pressure, which is the arterial pressure exerted when
    blood is ejected during ventricular contraction. Normal value: < 120 mmHg (objective
    feature)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ap_lo`: Diastolic blood pressure, which is the arterial pressure in between
    heartbeats. Normal value: < 80 mmHg (objective feature)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cholesterol`: An ordinal where 1: normal, 2: above normal, and 3: well above
    normal (objective feature)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gluc`: An ordinal where 1: normal, 2: above normal, and 3: well above normal
    (objective feature)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`smoke`: A binary where 0: non-smoker and 1: smoker (subjective feature)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alco`: A binary where 0: non-drinker and 1: drinker (subjective feature)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`active`: A binary where 0: non-active and 1: active (subjective feature)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`active`: 这是一个二进制值，其中0表示非活跃，1表示活跃（主观特征）'
- en: '`cardio`: A binary where 0: no CVD and 1: has CVD (objective and target feature)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cardio`: 这是一个二进制值，其中0表示没有心血管疾病，1表示有心血管疾病（客观和目标特征）'
- en: 'It’s essential to understand the data generation process of a dataset, which
    is why the features are split into two categories:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 理解数据集的数据生成过程至关重要，这就是为什么特征被分为两类：
- en: '**Objective**: A feature that is a product of official documents or a clinical
    examination. It is expected to have a rather insignificant margin of error due
    to clerical or machine errors.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客观**: 是官方文件或临床检查的结果。由于文书或机器错误，预计其误差范围相当小。'
- en: '**Subjective**: Reported by the patient and not verified (or unverifiable).
    In this case, due to lapses of memory, differences in understanding, or dishonesty,
    it is expected to be less reliable than objective features.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主观**: 由患者报告且未经验证（或无法验证）。在这种情况下，由于记忆失误、理解差异或不诚实，预计其可靠性不如客观特征。'
- en: At the end of the day, trusting the model is often about trusting the data used
    to train it, so how much patients lie about smoking can make a difference.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，信任模型通常意味着信任用于训练它的数据，因此患者关于吸烟的谎言程度可能会产生影响。
- en: Data preparation
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'For the sake of interpretability and model performance, there are several data
    preparation tasks that we can perform, but the one that stands out right now is
    `age`. Age is not something we usually measure in days. In fact, for health-related
    predictions like this one, we might even want to bucket them into **age groups**
    since health differences observed between individual year-of-birth cohorts aren’t
    as evident as those observed between generational cohorts, especially when cross
    tabulating with other features like lifestyle differences. For now, we will convert
    all ages into years:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可解释性和模型性能，我们可以执行几个数据准备任务，但目前最突出的是`age`。年龄不是我们通常按天数衡量的东西。实际上，对于像这样的健康相关预测，我们甚至可能希望将它们分入**年龄组**，因为观察到的个体出生年份群体之间的健康差异不如代际群体之间明显，尤其是在与其他特征（如生活方式差异）交叉制表时。目前，我们将所有年龄转换为年份：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The result is a more understandable column because we expect age values to be
    between 0 and 120\. We took existing data and transformed it. This is an example
    of **feature engineering**, which is when we use the domain knowledge of our data
    to create features that better represent our problem, thereby improving our models.
    We will discuss this further in *Chapter 11*, *Bias Mitigation and Causal Inference
    Methods*. There’s value in performing feature engineering simply to make model
    outcomes more *interpretable* as long as this doesn’t significantly hurt model
    performance. In fact, it might improve predictive performance. Note that there
    was no loss in data in the feature engineering performed on the age column, as
    the decimal value for years is maintained.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个更易于理解的列，因为我们期望年龄值在0到120之间。我们使用了现有数据并对其进行了转换。这是一个**特征工程**的例子，即我们利用数据的领域知识来创建更好地代表我们问题的特征，从而提高我们的模型。我们将在*第11章*，*偏差缓解和因果推断方法*中进一步讨论这一点。只要这不会显著损害模型性能，仅仅为了使模型结果更*可解释*而进行特征工程是有价值的。实际上，它可能会提高预测性能。请注意，在年龄列上进行的特征工程没有损失数据，因为年份的小数值得到了保留。
- en: 'Now we are going to take a peek at what the summary statistics are for each
    one of our features using the `describe()` method:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用`describe()`方法查看每个特征的摘要统计信息：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '*Figure 2.1* shows the summary statistics outputted by the preceding code.
    It includes the 1% and 99% percentiles, which tell us what are among the highest
    and lowest values for each feature:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2.1*显示了前述代码输出的摘要统计信息。它包括1%和99%的分位数，这些分位数告诉我们每个特征的最高和最低值：'
- en: '![](img/B18406_02_01.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_02_01.png)'
- en: 'Figure 2.1: Summary statistics for the dataset'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1：数据集的摘要统计
- en: In *Figure 2.1*, `age` appears valid because it ranges between 29 and 65 years,
    which is not out of the ordinary, but there are some anomalous outliers for `ap_hi`
    and `ap_lo`. Blood pressure can’t be negative, and the highest ever recorded was
    `370`. Keeping these outliers in there can lead to poor model performance and
    interpretability. Given that the 1% and 99% percentiles still show values in normal
    ranges according to *Figure 2.1*, there’s close to 2% of records with invalid
    values. If you dig deeper, you’ll realize it’s closer to 1.8%.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图2.1*中，`age`值有效，因为它介于29至65岁之间，这并不罕见，但`ap_hi`和`ap_lo`存在一些异常的异常值。血压不能为负，最高记录值为`370`。保留这些异常值可能导致模型性能和可解释性变差。根据*图2.1*，1%和99%的分位数仍然显示正常范围内的值，因此大约有2%的记录具有无效值。如果你进一步挖掘，你会发现这个比例更接近1.8%。
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'There are many ways we could handle these incorrect values, but because they
    are relatively few records and we lack the domain expertise to guess if they were
    mistyped (and correct them accordingly), we will delete them:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有处理这些错误值的方法，但由于这些记录相对较少，并且我们缺乏领域专业知识来猜测它们是否被误输入（并相应地更正），我们将删除它们：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'For good measure, we ought to make sure that `ap_hi` is always higher than
    `ap_lo`, so any record with that discrepancy should also be dropped:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保万无一失，我们应该确保`ap_hi`始终高于`ap_lo`，因此任何存在这种差异的记录也应被删除：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, in order to fit a logistic regression model, we must put all objective,
    examination, and subjective features together as *X* and the target feature alone
    as *y*. After this, we split *X* and *y* into training and test datasets, but
    make sure to include `random_state` for reproducibility:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了拟合逻辑回归模型，我们必须将所有客观、考试和主观特征组合在一起作为*X*，并将目标特征单独作为*y*。之后，我们将*X*和*y*分为训练和测试数据集，但请确保包括`random_state`以实现可重复性：
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The scikit-learn `train_test_split` function puts 15% of the observations in
    the test dataset and the remainder in the train dataset, so you end up with *X*
    and *y* pairs for both.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn的`train_test_split`函数将15%的观测值放入测试数据集，其余的放入训练数据集，因此你最终会得到*X*和*y*对。
- en: Now that we have our data ready for training, let’s train a model and interpret
    it.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了用于训练的数据，让我们训练一个模型并对其进行解释。
- en: Interpretation method types and scopes
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释方法类型和范围
- en: 'Now that we have prepared our data and split it into training/test datasets,
    we can fit the model using the training data and print a summary of the results:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了数据，并将其分为训练/测试数据集，我们可以使用训练数据来拟合模型，并打印结果摘要：
- en: '[PRE10]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Printing `summary2` on the fitted model produces the following output:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在拟合的模型上打印`summary2`会产生以下输出：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The preceding summary helps us to understand which *X* features contributed
    the most to the *y* CVD diagnosis using the model coefficients (labeled `Coef.`
    in the table). Much like with linear regression, the coefficients are weights
    applied to the predictors. However, the linear combination exponent is a **logistic
    function**. This makes the interpretation more difficult. We explain this function
    further in *Chapter 3*, *Interpretation Challenges*.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 上述摘要帮助我们理解哪些*X*特征对模型系数（在表中标记为`Coef.`）对*y* CVD诊断的贡献最大。与线性回归类似，系数是应用于预测器的权重。然而，线性组合指数是一个**逻辑函数**。这使得解释变得更加困难。我们将在*第3章*，*解释挑战*中进一步解释这个函数。
- en: 'We can tell by looking at it that the features with the absolute highest values
    are `cholesterol` and `active`, but it’s not very intuitive in terms of what this
    means. A more interpretable way of looking at these values is revealed once we
    calculate the exponential of these coefficients:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察我们可以看出，具有绝对最高值的特征是`cholesterol`和`active`，但在理解这意味着什么方面并不直观。一旦我们计算了这些系数的指数，就会揭示一种更可解释的方式来查看这些值：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding code outputs the following:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码输出以下内容：
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Why the exponential? The coefficients are the **log odds**, which are the logarithms
    of the *odds*. Also, *odds* are the probability of a positive case over the probability
    of a negative case, where the **positive case** is the label we are trying to
    predict. It doesn’t necessarily indicate what is favored by anyone. For instance,
    if we are trying to predict the odds of a rival team winning the championship
    today, the positive case would be that they own, regardless of whether we favor
    them or not. Odds are often expressed as a ratio. The news could say the probability
    of them winning today is 60% or say the odds are 3:2 or 3/2 = 1.5\. In log odds
    form, this would be 0.176, which is the logarithm of 1.5\. They are basically
    the same thing but expressed differently. An exponential function is the inverse
    of a logarithm, so it can take any *log odds* and return the *odds*, as we have
    done.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么是指数函数？系数是**对数概率**，即概率的对数。概率是指正例发生的概率与负例发生的概率之比，其中**正例**是我们试图预测的标签。它并不一定表明任何人的偏好。例如，如果我们试图预测一个竞争对手今天赢得冠军的概率，正例就是他们赢了，无论我们是否支持他们。概率通常以比率的形式表示。新闻可能会说他们今天赢得比赛的概率是60%，或者可能会说赔率是3:2或3/2
    = 1.5。在对数概率形式中，这将等于0.176，即1.5的对数。它们基本上是同一件事，但表达方式不同。指数函数是对数函数的逆函数，因此它可以接受任何**对数概率**并返回**概率**，正如我们所做的那样。
- en: Back to our CVD case. Now that we have the odds, we can interpret what it means.
    For example, what do the odds mean in the case of cholesterol? It means that the
    odds of CVD increase by a factor of 1.64 for each additional unit of cholesterol,
    provided every other feature stays unchanged. Being able to explain the impact
    of a feature on the model in such tangible terms is one of the advantages of an
    *intrinsically interpretable* model such as logistic regression.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的CVD案例。现在我们有了概率，我们可以解释它意味着什么。例如，胆固醇的情况下的概率意味着什么？这意味着，在所有其他特征保持不变的情况下，每增加一个单位的胆固醇，CVD的概率会增加1.64倍。能够用如此具体的方式来解释一个特征对模型的影响，是像逻辑回归这样的**内在可解释**模型的一个优点。
- en: Although the *odds* provide us with useful information, they don’t tell us what
    matters the most and, therefore, by themselves, cannot be used to measure feature
    importance. But how could that be? If something has higher odds, then it must
    matter more, right? Well, for starters, they all have different scales, so that
    makes a huge difference. This is because if we measure the odds of how much something
    increases, we have to know by how much it typically increases because that provides
    context. For example, we could say that the odds of a specific species of butterfly
    living one day more are 0.66 after their first eggs hatch. This statement is meaningless
    unless we know the lifespan and reproductive cycle of this species.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然概率为我们提供了有用的信息，但它们并没有告诉我们什么最重要，因此，仅凭它们自身，不能用来衡量特征的重要性。但怎么会这样呢？如果某物的概率更高，那么它肯定更重要，对吧？好吧，首先，它们都有不同的尺度，这造成了巨大的差异。这是因为如果我们测量某物增加的概率，我们必须知道它通常增加多少，因为这提供了上下文。例如，我们可以说，在蝴蝶的第一批卵孵化后，这种特定蝴蝶多活一天的几率是0.66。除非我们知道这个物种的寿命和繁殖周期，否则这个陈述是没有意义的。
- en: 'To provide context to our odds, we can easily calculate the standard deviation
    of our features using the `np.std` function:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为我们提供的概率提供上下文，我们可以轻松地使用`np.std`函数计算特征的方差：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following series is what is outputted by the `np.std` function:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是由`np.std`函数输出的序列：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As we can tell by the output, binary and ordinal features only typically vary
    by one at most, but continuous features, such as `weight` or `ap_hi`, can vary
    10–20 times more, as evidenced by the standard deviation of the features.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们从输出中可以看出，二元和有序特征通常最多只变化一次，但连续特征，如`weight`或`ap_hi`，可以变化10-20倍，正如特征的方差所证明的那样。
- en: Another reason why *odds* cannot be used to measure feature importance is that
    despite favorable odds, sometimes features are not statistically significant.
    They are entangled with other features in such a way they might appear to be significant,
    but we can prove that they aren’t. This can be seen in the summary table for the
    model, under the `P>|z|` column. This value is called the **p-value**, and when
    it’s less than 0.05, we reject the null hypothesis that states that the coefficient
    is equal to zero. In other words, the corresponding feature is statistically significant.
    However, when it’s above this number, especially by a large margin, there’s no
    statistical evidence that it affects the predicted score. Such is the case with
    `gender`, at least in this dataset.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个原因是不可以用**几率**来衡量特征重要性，是因为尽管几率有利，但有时特征并不具有统计学意义。它们与其他特征纠缠在一起，以至于它们可能看起来很重要，但我们能证明它们并不重要。这可以在模型的摘要表中看到，在`P>|z|`列下。这个值被称为**p值**，当它小于0.05时，我们拒绝系数等于零的零假设。换句话说，相应的特征具有统计学意义。然而，当它高于这个数值，尤其是大幅高于时，没有统计证据表明它会影响预测分数。至少在这个数据集中，`性别`就是这种情况。
- en: 'If we are trying to obtain what features matter most, one way to approximate
    this is to multiply the coefficients by the standard deviations of the features.
    Incorporating the standard deviations accounts for differences in variances between
    features. Hence, it is better if we get `gender` out of the way too while we are
    at it:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们试图获得最重要的特征，一种近似方法是将系数乘以特征的标准差。引入标准差考虑了特征之间方差的不同。因此，如果我们在这个过程中把`性别`排除在外会更好：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The preceding code produced this output:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The preceding table can be interpreted as an **approximation of risk factors**
    from high to low according to the model. It is also a **model-specific** feature
    importance method, in other words, a **global model** (**modular**) **interpretation
    method**. There are a lot of new concepts to unpack here, so let’s break them
    down.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的表格可以解释为根据模型从高到低的风险因素**近似**。它也是一个**特定模型**的**特征重要性**方法，换句话说，是一个**全局模型**（**模块化**）**解释方法**。这里有很多新的概念需要解释，所以让我们逐一分析。
- en: Model interpretability method types
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型可解释性方法类型
- en: 'There are two model interpretability method types:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可解释性方法类型有两种：
- en: '**Model-specific**: When the method can only be used for a specific model class,
    then it’s model-specific. The method detailed in the previous example can only
    work with logistic regression because it uses its coefficients.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特定模型**：当方法只能用于特定模型类别时，那么它就是特定模型的。前一个例子中详细说明的方法只能与逻辑回归一起工作，因为它使用了其系数。'
- en: '**Model-agnostic**: These are methods that can work with any model class. We
    cover these in *Chapter 4*, *Global Model-Agnostic Interpretation Methods*, and
    the next two chapters.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型无关**：这些是可以与任何模型类别一起工作的方法。我们在*第四章*，*全局模型无关解释方法*以及接下来的两章中介绍了这些方法。'
- en: Model interpretability scopes
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型可解释性范围
- en: 'There are several model interpretability scopes:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可解释性的几个范围：
- en: '**Global holistic interpretation**: We can explain how a model makes predictions
    simply because we can comprehend the entire model at once with a complete understanding
    of the data, and it’s a trained model. For instance, the simple linear regression
    example in *Chapter 1*, *Interpretation, Interpretability, and Explainability;
    and Why Does It All Matter?*, can be visualized in a two-dimensional graph. We
    can conceptualize this in memory, but this is only possible because the simplicity
    of the model allows us to do so, and it’s not very common nor expected.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局整体解释**：我们可以解释模型是如何做出预测的，因为我们能够一次性完全理解数据并理解整个模型，并且这是一个训练好的模型。例如，*第一章*中的简单线性回归示例，在*解释、可解释性和可解释性；以及为什么这一切都很重要？*中，可以在二维图中可视化。我们可以在记忆中构想这一点，但这仅因为模型的简单性允许我们这样做，而且这种情况并不常见，也不被期望。'
- en: '**Global modular interpretation**: In the same way that we can explain the
    role of *parts* of an internal combustion engine in the *whole* process of turning
    fuel into movement, we can also do so with a model. For instance, in the CVD risk
    factor example, our feature importance method tells us that `ap_hi` (systolic
    blood pressure), `age`, `cholesterol`, and `weight` are the *parts* that impact
    the *whole* the most. Feature importance is only one of many global modular interpretation
    methods but arguably the most important one. *Chapter 4*, *Global Model-Agnostic
    Interpretation Methods*, goes into more detail on feature importance.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局模块化解释**：正如我们可以解释内燃机中**部分**在将燃料转化为运动的全过程中的作用一样，我们也可以用模型来做这样的解释。例如，在CVD风险因素示例中，我们的特征重要性方法告诉我们`ap_hi`（收缩压）、`age`（年龄）、`cholesterol`（胆固醇）和`weight`（体重）是影响**整体**最多的**部分**。特征重要性只是众多全局模块化解释方法中的一种，但可以说是最重要的方法之一。*第四章*，*全局模型无关解释方法*，将更详细地介绍特征重要性。'
- en: '**Local single-prediction interpretation**: We can explain why a single prediction
    was made. The next example will illustrate this concept and *Chapter 5*, *Local
    Model-Agnostic Interpretation Methods*, will go into more detail.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局部单预测解释**：我们可以解释为什么做出了单个预测。下一个例子将说明这个概念，而*第五章*，*局部模型无关解释方法*，将更详细地介绍。'
- en: '**Local group-prediction interpretation**: The same as single-prediction, except
    that it applies to groups of predictions.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局部组预测解释**：与单预测相同，但适用于预测组。'
- en: Congratulations! You’ve already determined the risk factors with a **global
    model interpretation method**, but the health minister also wants to know whether
    the model can be used to interpret individual cases. So, let’s look into that.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经使用**全局模型解释方法**确定了风险因素，但卫生部长还想知道模型是否可以用来解释单个案例。所以，让我们来看看这一点。
- en: Interpreting individual predictions with logistic regression
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用逻辑回归解释单个预测
- en: 'What if we used the model to predict CVD for the entire test dataset? We could
    do so like this:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用模型来预测整个测试数据集的CVD，我们可以这样做：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The resulting array is the probabilities that each test case is positive for
    CVD:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 结果数组是每个测试用例对CVD呈阳性的概率：
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Let’s take one of the positive cases; test case #2872:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们以一个阳性案例为例；测试用例 #2872：'
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We know that it predicted positive for CVD because the score exceeds 0.5.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道它预测CVD为阳性，因为得分超过了0.5。
- en: 'And these are the details for test case #2872:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '这是测试用例 #2872 的详细信息：'
- en: '[PRE21]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following is the output:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为输出结果：
- en: '[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'So, by the looks of the preceding series, we know that the following applies
    to this individual:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，根据前面的序列，我们知道以下适用于这个个体：
- en: A borderline high `ap_hi` (systolic blood pressure) since anything above or
    equal to 130 is considered high according to the **American Heart Association**
    (**AHA**).
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 临界高的`ap_hi`（收缩压），因为根据**美国心脏协会**（**AHA**）的标准，任何等于或高于130的都是高的。
- en: Normal `ap_lo` (diastolic blood pressure) also according to AHA. Having high
    systolic blood pressure and normal diastolic blood pressure is what is known as
    *isolated systolic hypertension*. It could be causing a positive prediction, but
    `ap_hi` is borderline; therefore, the condition of *isolated systolic hypertension*
    is borderline.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正常的`ap_lo`（舒张压）也符合AHA（美国心脏协会）的标准。收缩压高而舒张压正常的情况被称为**孤立性收缩压**。这可能导致预测结果为阳性，但`ap_hi`处于临界值；因此，**孤立性收缩压**的状态是临界性的。
- en: '`age` is not too old, but among the oldest in the dataset.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`age`（年龄）不算太老，但在数据集中是最老的。'
- en: '`cholesterol` is normal.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cholesterol`（胆固醇）是正常的。'
- en: '`weight` also appears to be in the healthy range.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight`（体重）似乎也在健康范围内。'
- en: 'There are also no other risk factors: glucose is normal, the individual does
    not smoke nor drink alcohol, and does not live a sedentary lifestyle, as the individual
    is active. It is not clear exactly why it’s positive. Are the age and borderline
    *isolated systolic hypertension* enough to tip the scales? It’s tough to understand
    the reasons for the prediction without putting all the predictions into context,
    so let’s try to do that!'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 没有其他风险因素：葡萄糖正常，个体不吸烟也不喝酒，并且不采取久坐的生活方式，因为个体很活跃。不清楚为什么它是阳性的。年龄和临界性的**孤立性收缩压**是否足以使结果为阳性？没有将所有预测放入上下文中，很难理解预测的原因，所以让我们尝试这样做！
- en: But how do we put everything in context at the same time? We can’t possibly
    visualize how one prediction compares with the other 10,000 for every single feature
    and their respective predicted CVD diagnosis. Unfortunately, humans can’t process
    that level of dimensionality, even if it were possible to visualize a ten-dimensional
    hyperplane!
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: However, we can do it for two features at a time, resulting in a graph that
    conveys where the decision boundary for the model lies for those features. On
    top of that, we can overlay what the predictions were for the test dataset based
    on all the features. This is to visualize the discrepancy between the effect of
    two features and all eleven features.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: This graphical interpretation method is what is termed a **decision boundary**.
    It draws boundaries for the classes, leaving areas that belong to one class or
    another. Such areas are called **decision regions**. In this case, we have two
    classes, so we will see a graph with a single boundary between `cardio=0` and
    `cardio=1`, only concerning the two features we are comparing.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: We have managed to visualize the two decision-based features at a time, with
    one big assumption that if all the other features are held constant, we can observe
    only two in isolation. This is also known as the **ceteris paribus** assumption
    and is critical in a scientific inquiry, allowing us to *control* some variables
    in order to *observe* others. One way to do this is to fill them with a value
    that won’t affect the outcome. Using the table of odds we produced, we can tell
    whether a feature increases as it will increase the odds of CVD. So, in aggregates,
    a lower value is less risky for CVD.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, `age=30` is the least risky value of those present in the dataset
    for `age`. It can also go in the opposite direction, so `active=1` is known to
    be less risky than `active=0`. We can come up with optimal values for the remainder
    of the features:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '`height=165`.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`weight=57` (optimal for that `height`).'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ap_hi=110`.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ap_lo=70`.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`smoke=0`.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cholesterol=1` (this means normal).'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gender` can be coded for male or female, which doesn’t matter because the
    odds for gender (`0.977519`) are so close to 1.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following `filler_feature_values` dictionary exemplifies what should be
    done with the features matching their index to their least risky values:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The next thing to do is to create a `(1,12)` shaped NumPy array with test case
    #2872 so that the plotting function can highlight it. To this end, we first convert
    it into NumPy and then prepend the *constant* of `1`, which must be the first
    feature, and then reshape it so that it meets the `(1,12)` dimensions. The reason
    for the constant is that in `statsmodels`, we must explicitly define the **intercept**.
    For this reason, the logistic model has an additional `0` feature, which always
    equals `1`.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following is the output:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We are good to go now! Let’s visualize some decision region plots! We will
    compare the feature that is thought to be the highest *risk factor*, `ap_hi`,
    with the following four most important risk factors: `age`, `cholesterol`, `weight`,
    and `ap_lo`.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code will generate the plots in *Figure 2.2*:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In the plot in *Figure 2.2*, the circle represents test case #2872\. In all
    the plots bar one, this test case is on the negative (left-hand side) decision
    region, representing `cardio=0` classification. The borderline high `ap_hi` (systolic
    blood pressure) and the relatively high `age` are barely enough for a positive
    prediction in the top-left chart. Still, in any case, for test case #2872, we
    have predicted a 57% score for CVD, so this could very well explain most of it.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'Not surprisingly, by themselves, `ap_hi` and a healthy `cholesterol` value
    are not enough to tip the scales in favor of a definitive CVD diagnosis according
    to the model because it’s decidedly in the negative decision region, and neither
    is a normal `ap_lo` (diastolic blood pressure). You can tell from these three
    charts that although there’s some overlap in the distribution of squares and triangles,
    there is a tendency for more triangles to gravitate toward the positive side as
    the *y*-axis increases, while fewer squares populate this region:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '![Calendar  Description automatically generated](img/B18406_02_02.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: The decision regions for ap_hi and other top risk factors, with
    test case #2872'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: The overlap across the decision boundary is expected because, after all, these
    squares and triangles are based on the effects of **all** features. Still, you
    expect to find a somewhat consistent pattern. The chart with `ap_hi` versus `weight`
    doesn’t have this pattern vertically as `weight` increases, which suggests something
    is missing in this story… Hold that thought because we are going to investigate
    that in the next section!
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have completed the second part of the minister’s request.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'Decision region plotting, a **local model interpretation method**, provided
    the health ministry with a tool to interpret individual case predictions. You
    could now extend this to explain several cases at a time, or plot all-important
    feature combinations to find the ones where the circle is decidedly in the positive
    decision region. You can also change some of the filler variables one at a time
    to see how they make a difference. For instance, what if you increase the filler
    age to the median age of 54 or even to the age of test case #2872? Would a borderline
    high `ap_hi` and healthy `cholesterol` now be enough to tip the scales? We will
    answer this question later, but first, let’s understand what can make machine
    learning interpretation so difficult.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Appreciating what hinders machine learning interpretability
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last section, we were wondering why the chart with `ap_hi` versus `weight`
    didn’t have a conclusive pattern. It could very well be that although `weight`
    is a risk factor, there are other critical *mediating variables* that could explain
    the increased risk of CVD. A **mediating variable** is one that influences the
    strength between the independent and target (*dependent*) variable. We probably
    don’t have to think too hard to find what is missing. In *Chapter 1*, *Interpretation,
    Interpretability, and Explainability; and Why Does It All Matter?*, we performed
    linear regression on `weight` and `height` because there’s a linear relationship
    between these variables. In the context of human health, `weight` is not nearly
    as *meaningful* without `height`, so you need to look at both.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps if we plot the decision regions for these two variables, we will get
    some clues. We can plot them with the following code:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![Chart, scatter chart  Description automatically generated](img/B18406_02_03.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: The decision regions for weight and height, with test case #2872'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: No decision boundary was ascertained in *Figure 2.3* because if all other variables
    are held constant (at a less risky value), no `height` and `weight` combination
    is enough to predict CVD. However, we can tell that there is a pattern for the
    orange triangles, mostly located in one ovular area. This provides exciting insight
    that even though we expect `weight` to increase when `height` increases, the concept
    of an inherently unhealthy `weight` value is not one that increases linearly with
    `height`.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, for almost two centuries, this relationship has been mathematically
    understood by the name **body mass index** (**BMI**):'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_02_001.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
- en: 'Before we discuss BMI further, you must consider complexity. Dimensionality
    aside, there are chiefly three things that introduce complexity that makes interpretation
    difficult:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Non-linearity
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Interactivity
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Non-monotonicity
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Non-linearity
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Linear equations such as ![](img/B18406_02_002.png) are easy to understand.
    They are additive, so it is easy to separate and quantify the effects of each
    of its terms (*a*, *bx*, and *cz*) from the outcome of the model (*y*). Many model
    classes have linear equations incorporated in the math. These equations can both
    be used to fit the data to the model and describe the model.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: However, there are model classes that are inherently non-linear because they
    introduce non-linearity in their training. Such is the case for *deep learning*
    models because they have non-linear activation functions such as *sigmoid*. However,
    logistic regression is considered a **Generalized Linear Model** (**GLM**) because
    it’s additive. In other words, the outcome is a sum of weighted inputs and parameters.
    We will discuss GLMs further in *Chapter 3*, *Interpretation Challenges*.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: 'However, even if your model is linear, the relationships between the variables
    may not be linear, which can lead to poor performance and interpretability. What
    you can do in these cases is adopt either of the following approaches:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '*Use a non-linear model class*, which will fit these non-linear feature relationships
    much better, possibly improving model performance. Nevertheless, as we will explore
    in more detail in the next chapter, this can make the model less interpretable.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Use domain knowledge to engineer a feature that can help “linearize” it*.
    For instance, if you had a feature that increased exponentially against another,
    you can engineer a new variable with the logarithm of that feature. In the case
    of our CVD prediction, we know BMI is a better way to understand weight in the
    company of height. Best of all, it’s not an *arbitrary* made-up feature, so it’s
    easier to interpret. We can prove this point by making a copy of the dataset,
    engineering the BMI feature in it, training the model with this extra feature,
    and performing local model interpretation. The following code snippet does just
    that:'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To illustrate this new feature, let’s plot `bmi` against both `weight` and
    `height` using the following code:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '*Figure 2.4* is produced with the preceding code:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_02_04.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Bivariate comparison between weight, height, and bmi'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: As you can appreciate by the plots in *Figure 2.4*, there is a more definite
    linear relationship between `bmi` and `weight` than between `height` and `weight`
    and, even, between `bmi` and `height`.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s fit the new model with the extra feature using the following code snippet:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, let’s see whether test case #2872 is in the positive decision region when
    comparing `ap_hi` to `bmi` if we keep `age` constant at `60`:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The preceding code plots decision regions in *Figure 2.5*:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B18406_02_05.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: The decision regions for ap_hi and bmi, with test case #2872'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.5* shows that controlling for `age`, `ap_hi`, and `bmi` can help
    explain the positive prediction for CVD because the circle is in the positive
    decision region. Please note that there are some likely anomalous `bmi` outliers
    (the highest BMI ever recorded was 204), so there are probably some incorrect
    weights or heights in the dataset.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: WHAT’S THE PROBLEM WITH OUTLIERS?
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Outliers can be **influential** or **high leverage** and, therefore, affect
    the model when trained with these included. Even if they don’t, they can make
    interpretation more difficult. If they are **anomalous**, then you should remove
    them, as we did with blood pressure at the beginning of this chapter. And sometimes,
    they can hide in plain sight because they are only perceived as *anomalous* in
    the context of other features. In any case, there are practical reasons why outliers
    are problematic, such as making plots like the preceding one “zoom out” to be
    able to fit them while not letting you appreciate the decision boundary where
    it matters. And there are also more profound reasons, such as losing trust in
    the data, thereby tainting trust in the models that were trained on that data,
    or making the model perform worse. This sort of problem is to be expected with
    real-world data. Even though we haven’t done it in this chapter for the sake of
    expediency, it’s essential to begin every project by thoroughly exploring the
    data, treating missing values and outliers, and doing other data housekeeping
    tasks.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Interactivity
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we created `bmi`, we didn’t only linearize a non-linear relationship, but
    we also created interactions between two features. `bmi` is, therefore, an **interaction
    feature**, but this was informed by domain knowledge. However, many model classes
    do this automatically by permutating all kinds of operations between features.
    After all, features have *latent* relationships between one another, much like
    `height` and `width`, and `ap_hi` and `ap_lo`. Therefore, automating the process
    of looking for them is not always a bad thing. In fact, it can even be absolutely
    necessary. This is the case for many deep learning problems where the data is
    unstructured and, therefore, part of the task of training the model is looking
    for the latent relationships to make sense of it.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: However, for structured data, even though interactions can be significant for
    model performance, they can hurt interpretability by adding potentially unnecessary
    complexity to the model and also finding latent relationships that *don’t mean
    anything* (which is called a **spurious relationship** or **correlation**).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Non-monotonicity
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Often, a variable has a meaningful and consistent relationship between a feature
    and the target variable. So, we know that as `age` increases, the risk of CVD
    (`cardio`) must increase. There is no point at which you reach a certain age and
    this risk drops. Maybe the risk slows down, but it does not drop. We call this
    **monotonicity**, and functions that are *monotonic* are either always increasing
    or decreasing throughout their entire domain.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Please note that **all** linear relationships are monotonic, but not all monotonic
    relationships are necessarily linear. This is because they don’t have to be a
    straight line. A common problem in machine learning is that a model doesn’t know
    about a monotonic relationship that we expect because of our domain expertise.
    Then, because of noise and omissions in the data, the model is trained in such
    a way in which there are ups and downs where you don’t expect them.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s propose a hypothetical example. Let’s imagine that due to a lack of availability
    of data for 57–60-year-olds, and because the few cases we did have for this range
    were negative for CVD, the model could learn that this is where you would expect
    a drop in CVD risk. Some model classes are inherently monotonic, such as logistic
    regression, so they can’t have this problem, but many others do. We will examine
    this in more detail in *Chapter 12*, *Monotonic Constraints and Model Tuning for
    Interpretability*:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – A partial dependence plot between a target variable (yhat) and
    a predictor with monotonic and non-monotonic models ](img/B18406_02_06.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: A partial dependence plot between a target variable (yhat) and
    a predictor with monotonic and non-monotonic models'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.6* is what is called a **Partial Dependence Plot** (**PDP**), from
    an unrelated example. PDPs are a concept we will study in further detail in *Chapter
    4*, *Global Model-Agnostic Interpretation Methods*, but what is important to grasp
    from it is that the prediction `yhat` is supposed to decrease as the feature `quantity_indexes_for_real_gdp_by_state`
    increases. As you can tell by the lines, in the monotonic model, it consistently
    decreases, but in the non-monotonic one, it has jagged peaks as it decreases,
    and then increases at the very end.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Mission accomplished
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first part of the mission was to understand risk factors for cardiovascular
    disease, and you’ve determined that the top four risk factors are systolic blood
    pressure (`ap_hi`), `age`, `cholesterol`, and `weight` according to the logistic
    regression model, of which only `age` is non-modifiable. However, you also realized
    that systolic blood pressure (`ap_hi`) is not as meaningful on its own since it
    relies on diastolic blood pressure (`ap_lo`) for interpretation. The same goes
    for `weight` and `height`. We learned that the interaction of features plays a
    crucial role in interpretation, and so does their relationship with each other
    and the target variable, whether linear or monotonic. Furthermore, the data is
    only a representation of the truth, which can be wrong. After all, we found *anomalies*
    that, left unchecked, can bias our model.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Another source of bias is how the data was collected. After all, you can wonder
    why the model’s top features were all objective and examination features. Why
    isn’t smoking or drinking a larger factor? To verify whether there was *sample*
    *bias* involved, you would have to compare with other more trustworthy datasets
    to check whether your dataset is underrepresenting drinkers and smokers. Or maybe
    the bias was introduced by the question that asked whether they smoked now, and
    not whether they had ever smoked for an extended period.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Another type of bias that we could address is *exclusion bias*—our data might
    be missing information that explains the truth that the model is trying to depict.
    For instance, we know through medical research that blood pressure issues such
    as isolated systolic hypertension, which increases CVD risk, are caused by underlying
    conditions such as diabetes, hyperthyroidism, arterial stiffness, and obesity,
    to name a few. The only one of these conditions that we can derive from the data
    is obesity and not the other ones. If we want to be able to interpret a model’s
    predictions well, we need to have all relevant features. Otherwise, there will
    be gaps we cannot explain. Maybe once we add them, they won’t make much of a difference,
    but that’s what the methods we will learn in *Chapter 10*, *Feature Selection
    and Engineering for Interpretability*, are for.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: The second part of the mission was to be able to interpret individual model
    predictions. We can do this well enough by plotting decision regions. It’s a simple
    method, but it has many limitations, especially in situations where there are
    more than a handful of features, and they tend to interact a lot with each other.
    *Chapter 5*, *Local Model-Agnostic Interpretation Methods*, and *Chapter 6*, *Anchors
    and Counterfactual Explanations*, will cover local interpretation methods in more
    detail. However, the decision region plot method helps illustrate many of the
    concepts surrounding decision boundaries, which we will discuss in those chapters.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we covered two model interpretation methods: feature importance
    and decision boundaries. We also learned about model interpretation method types
    and scopes and the three elements that impact interpretability in machine learning.
    We will keep mentioning these fundamental concepts in subsequent chapters. For
    a machine learning practitioner, it is paramount to be able to spot them so that
    we can know what tools to leverage to overcome interpretation challenges. In the
    next chapter, we will dive deeper into this topic.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Molnar, Christoph. *Interpretable Machine Learning. A Guide for Making Black
    Box Models Explainable*. 2019: [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mlextend Documentation. Plotting Decision Regions*: [http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn more on Discord
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To join the Discord community for this book – where you can share feedback,
    ask the author questions, and learn about new releases – follow the QR code below:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/inml](Chapter_2.xhtml)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code107161072033138125.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
