- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Key Concepts of Interpretability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book covers many model interpretation methods. Some produce metrics, others
    create visuals, and some do both; some depict models broadly and others granularly.
    In this chapter, we will learn about two methods, feature importance and decision
    regions, as well as the taxonomies used to describe these methods. We will also
    detail what elements hinder machine learning interpretability as a primer to what
    lies ahead.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the main topics we are going to cover in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Learning about interpretation method types and scopes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appreciating what hinders machine learning interpretability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start with our technical requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although we began the book with a “toy example,” we will be leveraging real
    datasets throughout this book to be used in specific interpretation use cases.
    These come from many different sources and are often used only once.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid that, readers spend a lot of time downloading, loading, and preparing
    datasets for single examples; there’s a library called `mldatasets` that takes
    care of most of this. Instructions on how to install this library are located
    in the *Preface*. In addition to `mldatasets`, this chapter’s examples also use
    the `pandas`, `numpy`, `statsmodel`, `sklearn`, `seaborn`, and `matplotlib` libraries.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this chapter is located here: [https://packt.link/DgnVj](https://packt.link/DgnVj).'
  prefs: []
  type: TYPE_NORMAL
- en: The mission
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imagine you are an analyst for a national health ministry, and there’s a **Cardiovascular
    Diseases** (**CVDs**) epidemic. The minister has made it a priority to reverse
    the growth and reduce the caseload to a 20-year low. To this end, a task force
    has been created to find clues in the data to ascertain the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What risk factors can be addressed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If future cases can be predicted, interpret predictions on a case-by-case basis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You are part of this task force!
  prefs: []
  type: TYPE_NORMAL
- en: Details about CVD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we dive into the data, we must gather some important details about CVD
    in order to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Understand the problem’s context and relevance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extract domain knowledge information that can inform our data analysis and model
    interpretation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relate an expert-informed background to a dataset’s features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CVDs are a group of disorders, the most common of which is coronary heart disease
    (also known as *Ischaemic Heart Disease*). According to the World Health Organization,
    CVD is the leading cause of death globally, killing close to 18 million people
    annually. Coronary heart disease and strokes (which are, for the most part, a
    byproduct of CVD) are the most significant contributors to that. It is estimated
    that 80% of CVD is made up of modifiable risk factors. In other words, some of
    the preventable factors that cause CVD include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Poor diet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Smoking and alcohol consumption habits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obesity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack of physical activity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Poor sleep
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Also, many of the risk factors are non-modifiable and, therefore, known to
    be unavoidable, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Genetic predisposition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Old age
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Male (varies with age)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We won’t go into more domain-specific details about CVD because it is not required
    to make sense of the example. However, *it can’t be stressed enough how central
    domain knowledge is to model interpretation*. So, if this example was your job
    and many lives depended on your analysis, it would be advisable to read the latest
    scientific research on the subject and consult with domain experts to inform your
    interpretations.
  prefs: []
  type: TYPE_NORMAL
- en: The approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression is one common way to rank risk factors in medical use cases.
    Unlike linear regression, it doesn’t try to predict a continuous value for each
    of our observations, but it predicts a probability score that an observation belongs
    to a particular class. In this case, what we are trying to predict is, given *x*
    data for each patient, what is the *y* probability, from 0 to 1, that they have
    CVD?
  prefs: []
  type: TYPE_NORMAL
- en: Preparations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will find the code for this example here: [https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/main/02/CVD.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/main/02/CVD.ipynb).'
  prefs: []
  type: TYPE_NORMAL
- en: Loading the libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To run this example, we need to install the following libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '`mldatasets` to load the dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas` and `numpy` to manipulate it'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`statsmodels` to fit the logistic regression model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sklearn` (scikit-learn) to split the data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matplotlib` and `seaborn` to visualize the interpretations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We should load all of them first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Understanding and preparing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The data to be used in this example should then be loaded into a DataFrame
    we call `cvd_df`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'From this, we should get 70,000 records and 12 columns. We can take a peek
    at what was loaded with `info()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command will output the names of each column with its type and
    how many non-null records it contains:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The data dictionary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To understand what was loaded, the following is the data dictionary, as described
    in the source:'
  prefs: []
  type: TYPE_NORMAL
- en: '`age`: Of the patient in days (objective feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`height`: In centimeters (objective feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`weight`: In kg (objective feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gender`: A binary where 1: female, 2: male (objective feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ap_hi`: Systolic blood pressure, which is the arterial pressure exerted when
    blood is ejected during ventricular contraction. Normal value: < 120 mmHg (objective
    feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ap_lo`: Diastolic blood pressure, which is the arterial pressure in between
    heartbeats. Normal value: < 80 mmHg (objective feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cholesterol`: An ordinal where 1: normal, 2: above normal, and 3: well above
    normal (objective feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gluc`: An ordinal where 1: normal, 2: above normal, and 3: well above normal
    (objective feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`smoke`: A binary where 0: non-smoker and 1: smoker (subjective feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alco`: A binary where 0: non-drinker and 1: drinker (subjective feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`active`: A binary where 0: non-active and 1: active (subjective feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cardio`: A binary where 0: no CVD and 1: has CVD (objective and target feature)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It’s essential to understand the data generation process of a dataset, which
    is why the features are split into two categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Objective**: A feature that is a product of official documents or a clinical
    examination. It is expected to have a rather insignificant margin of error due
    to clerical or machine errors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Subjective**: Reported by the patient and not verified (or unverifiable).
    In this case, due to lapses of memory, differences in understanding, or dishonesty,
    it is expected to be less reliable than objective features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the end of the day, trusting the model is often about trusting the data used
    to train it, so how much patients lie about smoking can make a difference.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For the sake of interpretability and model performance, there are several data
    preparation tasks that we can perform, but the one that stands out right now is
    `age`. Age is not something we usually measure in days. In fact, for health-related
    predictions like this one, we might even want to bucket them into **age groups**
    since health differences observed between individual year-of-birth cohorts aren’t
    as evident as those observed between generational cohorts, especially when cross
    tabulating with other features like lifestyle differences. For now, we will convert
    all ages into years:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The result is a more understandable column because we expect age values to be
    between 0 and 120\. We took existing data and transformed it. This is an example
    of **feature engineering**, which is when we use the domain knowledge of our data
    to create features that better represent our problem, thereby improving our models.
    We will discuss this further in *Chapter 11*, *Bias Mitigation and Causal Inference
    Methods*. There’s value in performing feature engineering simply to make model
    outcomes more *interpretable* as long as this doesn’t significantly hurt model
    performance. In fact, it might improve predictive performance. Note that there
    was no loss in data in the feature engineering performed on the age column, as
    the decimal value for years is maintained.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are going to take a peek at what the summary statistics are for each
    one of our features using the `describe()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 2.1* shows the summary statistics outputted by the preceding code.
    It includes the 1% and 99% percentiles, which tell us what are among the highest
    and lowest values for each feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_02_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: Summary statistics for the dataset'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 2.1*, `age` appears valid because it ranges between 29 and 65 years,
    which is not out of the ordinary, but there are some anomalous outliers for `ap_hi`
    and `ap_lo`. Blood pressure can’t be negative, and the highest ever recorded was
    `370`. Keeping these outliers in there can lead to poor model performance and
    interpretability. Given that the 1% and 99% percentiles still show values in normal
    ranges according to *Figure 2.1*, there’s close to 2% of records with invalid
    values. If you dig deeper, you’ll realize it’s closer to 1.8%.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'There are many ways we could handle these incorrect values, but because they
    are relatively few records and we lack the domain expertise to guess if they were
    mistyped (and correct them accordingly), we will delete them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'For good measure, we ought to make sure that `ap_hi` is always higher than
    `ap_lo`, so any record with that discrepancy should also be dropped:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, in order to fit a logistic regression model, we must put all objective,
    examination, and subjective features together as *X* and the target feature alone
    as *y*. After this, we split *X* and *y* into training and test datasets, but
    make sure to include `random_state` for reproducibility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The scikit-learn `train_test_split` function puts 15% of the observations in
    the test dataset and the remainder in the train dataset, so you end up with *X*
    and *y* pairs for both.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our data ready for training, let’s train a model and interpret
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation method types and scopes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have prepared our data and split it into training/test datasets,
    we can fit the model using the training data and print a summary of the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Printing `summary2` on the fitted model produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The preceding summary helps us to understand which *X* features contributed
    the most to the *y* CVD diagnosis using the model coefficients (labeled `Coef.`
    in the table). Much like with linear regression, the coefficients are weights
    applied to the predictors. However, the linear combination exponent is a **logistic
    function**. This makes the interpretation more difficult. We explain this function
    further in *Chapter 3*, *Interpretation Challenges*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can tell by looking at it that the features with the absolute highest values
    are `cholesterol` and `active`, but it’s not very intuitive in terms of what this
    means. A more interpretable way of looking at these values is revealed once we
    calculate the exponential of these coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code outputs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Why the exponential? The coefficients are the **log odds**, which are the logarithms
    of the *odds*. Also, *odds* are the probability of a positive case over the probability
    of a negative case, where the **positive case** is the label we are trying to
    predict. It doesn’t necessarily indicate what is favored by anyone. For instance,
    if we are trying to predict the odds of a rival team winning the championship
    today, the positive case would be that they own, regardless of whether we favor
    them or not. Odds are often expressed as a ratio. The news could say the probability
    of them winning today is 60% or say the odds are 3:2 or 3/2 = 1.5\. In log odds
    form, this would be 0.176, which is the logarithm of 1.5\. They are basically
    the same thing but expressed differently. An exponential function is the inverse
    of a logarithm, so it can take any *log odds* and return the *odds*, as we have
    done.
  prefs: []
  type: TYPE_NORMAL
- en: Back to our CVD case. Now that we have the odds, we can interpret what it means.
    For example, what do the odds mean in the case of cholesterol? It means that the
    odds of CVD increase by a factor of 1.64 for each additional unit of cholesterol,
    provided every other feature stays unchanged. Being able to explain the impact
    of a feature on the model in such tangible terms is one of the advantages of an
    *intrinsically interpretable* model such as logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: Although the *odds* provide us with useful information, they don’t tell us what
    matters the most and, therefore, by themselves, cannot be used to measure feature
    importance. But how could that be? If something has higher odds, then it must
    matter more, right? Well, for starters, they all have different scales, so that
    makes a huge difference. This is because if we measure the odds of how much something
    increases, we have to know by how much it typically increases because that provides
    context. For example, we could say that the odds of a specific species of butterfly
    living one day more are 0.66 after their first eggs hatch. This statement is meaningless
    unless we know the lifespan and reproductive cycle of this species.
  prefs: []
  type: TYPE_NORMAL
- en: 'To provide context to our odds, we can easily calculate the standard deviation
    of our features using the `np.std` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The following series is what is outputted by the `np.std` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As we can tell by the output, binary and ordinal features only typically vary
    by one at most, but continuous features, such as `weight` or `ap_hi`, can vary
    10–20 times more, as evidenced by the standard deviation of the features.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason why *odds* cannot be used to measure feature importance is that
    despite favorable odds, sometimes features are not statistically significant.
    They are entangled with other features in such a way they might appear to be significant,
    but we can prove that they aren’t. This can be seen in the summary table for the
    model, under the `P>|z|` column. This value is called the **p-value**, and when
    it’s less than 0.05, we reject the null hypothesis that states that the coefficient
    is equal to zero. In other words, the corresponding feature is statistically significant.
    However, when it’s above this number, especially by a large margin, there’s no
    statistical evidence that it affects the predicted score. Such is the case with
    `gender`, at least in this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we are trying to obtain what features matter most, one way to approximate
    this is to multiply the coefficients by the standard deviations of the features.
    Incorporating the standard deviations accounts for differences in variances between
    features. Hence, it is better if we get `gender` out of the way too while we are
    at it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code produced this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The preceding table can be interpreted as an **approximation of risk factors**
    from high to low according to the model. It is also a **model-specific** feature
    importance method, in other words, a **global model** (**modular**) **interpretation
    method**. There are a lot of new concepts to unpack here, so let’s break them
    down.
  prefs: []
  type: TYPE_NORMAL
- en: Model interpretability method types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two model interpretability method types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model-specific**: When the method can only be used for a specific model class,
    then it’s model-specific. The method detailed in the previous example can only
    work with logistic regression because it uses its coefficients.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model-agnostic**: These are methods that can work with any model class. We
    cover these in *Chapter 4*, *Global Model-Agnostic Interpretation Methods*, and
    the next two chapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model interpretability scopes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several model interpretability scopes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Global holistic interpretation**: We can explain how a model makes predictions
    simply because we can comprehend the entire model at once with a complete understanding
    of the data, and it’s a trained model. For instance, the simple linear regression
    example in *Chapter 1*, *Interpretation, Interpretability, and Explainability;
    and Why Does It All Matter?*, can be visualized in a two-dimensional graph. We
    can conceptualize this in memory, but this is only possible because the simplicity
    of the model allows us to do so, and it’s not very common nor expected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Global modular interpretation**: In the same way that we can explain the
    role of *parts* of an internal combustion engine in the *whole* process of turning
    fuel into movement, we can also do so with a model. For instance, in the CVD risk
    factor example, our feature importance method tells us that `ap_hi` (systolic
    blood pressure), `age`, `cholesterol`, and `weight` are the *parts* that impact
    the *whole* the most. Feature importance is only one of many global modular interpretation
    methods but arguably the most important one. *Chapter 4*, *Global Model-Agnostic
    Interpretation Methods*, goes into more detail on feature importance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local single-prediction interpretation**: We can explain why a single prediction
    was made. The next example will illustrate this concept and *Chapter 5*, *Local
    Model-Agnostic Interpretation Methods*, will go into more detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local group-prediction interpretation**: The same as single-prediction, except
    that it applies to groups of predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Congratulations! You’ve already determined the risk factors with a **global
    model interpretation method**, but the health minister also wants to know whether
    the model can be used to interpret individual cases. So, let’s look into that.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting individual predictions with logistic regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'What if we used the model to predict CVD for the entire test dataset? We could
    do so like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting array is the probabilities that each test case is positive for
    CVD:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take one of the positive cases; test case #2872:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We know that it predicted positive for CVD because the score exceeds 0.5.
  prefs: []
  type: TYPE_NORMAL
- en: 'And these are the details for test case #2872:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'So, by the looks of the preceding series, we know that the following applies
    to this individual:'
  prefs: []
  type: TYPE_NORMAL
- en: A borderline high `ap_hi` (systolic blood pressure) since anything above or
    equal to 130 is considered high according to the **American Heart Association**
    (**AHA**).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normal `ap_lo` (diastolic blood pressure) also according to AHA. Having high
    systolic blood pressure and normal diastolic blood pressure is what is known as
    *isolated systolic hypertension*. It could be causing a positive prediction, but
    `ap_hi` is borderline; therefore, the condition of *isolated systolic hypertension*
    is borderline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`age` is not too old, but among the oldest in the dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cholesterol` is normal.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`weight` also appears to be in the healthy range.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are also no other risk factors: glucose is normal, the individual does
    not smoke nor drink alcohol, and does not live a sedentary lifestyle, as the individual
    is active. It is not clear exactly why it’s positive. Are the age and borderline
    *isolated systolic hypertension* enough to tip the scales? It’s tough to understand
    the reasons for the prediction without putting all the predictions into context,
    so let’s try to do that!'
  prefs: []
  type: TYPE_NORMAL
- en: But how do we put everything in context at the same time? We can’t possibly
    visualize how one prediction compares with the other 10,000 for every single feature
    and their respective predicted CVD diagnosis. Unfortunately, humans can’t process
    that level of dimensionality, even if it were possible to visualize a ten-dimensional
    hyperplane!
  prefs: []
  type: TYPE_NORMAL
- en: However, we can do it for two features at a time, resulting in a graph that
    conveys where the decision boundary for the model lies for those features. On
    top of that, we can overlay what the predictions were for the test dataset based
    on all the features. This is to visualize the discrepancy between the effect of
    two features and all eleven features.
  prefs: []
  type: TYPE_NORMAL
- en: This graphical interpretation method is what is termed a **decision boundary**.
    It draws boundaries for the classes, leaving areas that belong to one class or
    another. Such areas are called **decision regions**. In this case, we have two
    classes, so we will see a graph with a single boundary between `cardio=0` and
    `cardio=1`, only concerning the two features we are comparing.
  prefs: []
  type: TYPE_NORMAL
- en: We have managed to visualize the two decision-based features at a time, with
    one big assumption that if all the other features are held constant, we can observe
    only two in isolation. This is also known as the **ceteris paribus** assumption
    and is critical in a scientific inquiry, allowing us to *control* some variables
    in order to *observe* others. One way to do this is to fill them with a value
    that won’t affect the outcome. Using the table of odds we produced, we can tell
    whether a feature increases as it will increase the odds of CVD. So, in aggregates,
    a lower value is less risky for CVD.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, `age=30` is the least risky value of those present in the dataset
    for `age`. It can also go in the opposite direction, so `active=1` is known to
    be less risky than `active=0`. We can come up with optimal values for the remainder
    of the features:'
  prefs: []
  type: TYPE_NORMAL
- en: '`height=165`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`weight=57` (optimal for that `height`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ap_hi=110`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ap_lo=70`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`smoke=0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cholesterol=1` (this means normal).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gender` can be coded for male or female, which doesn’t matter because the
    odds for gender (`0.977519`) are so close to 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following `filler_feature_values` dictionary exemplifies what should be
    done with the features matching their index to their least risky values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The next thing to do is to create a `(1,12)` shaped NumPy array with test case
    #2872 so that the plotting function can highlight it. To this end, we first convert
    it into NumPy and then prepend the *constant* of `1`, which must be the first
    feature, and then reshape it so that it meets the `(1,12)` dimensions. The reason
    for the constant is that in `statsmodels`, we must explicitly define the **intercept**.
    For this reason, the logistic model has an additional `0` feature, which always
    equals `1`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We are good to go now! Let’s visualize some decision region plots! We will
    compare the feature that is thought to be the highest *risk factor*, `ap_hi`,
    with the following four most important risk factors: `age`, `cholesterol`, `weight`,
    and `ap_lo`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code will generate the plots in *Figure 2.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'In the plot in *Figure 2.2*, the circle represents test case #2872\. In all
    the plots bar one, this test case is on the negative (left-hand side) decision
    region, representing `cardio=0` classification. The borderline high `ap_hi` (systolic
    blood pressure) and the relatively high `age` are barely enough for a positive
    prediction in the top-left chart. Still, in any case, for test case #2872, we
    have predicted a 57% score for CVD, so this could very well explain most of it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Not surprisingly, by themselves, `ap_hi` and a healthy `cholesterol` value
    are not enough to tip the scales in favor of a definitive CVD diagnosis according
    to the model because it’s decidedly in the negative decision region, and neither
    is a normal `ap_lo` (diastolic blood pressure). You can tell from these three
    charts that although there’s some overlap in the distribution of squares and triangles,
    there is a tendency for more triangles to gravitate toward the positive side as
    the *y*-axis increases, while fewer squares populate this region:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Calendar  Description automatically generated](img/B18406_02_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: The decision regions for ap_hi and other top risk factors, with
    test case #2872'
  prefs: []
  type: TYPE_NORMAL
- en: The overlap across the decision boundary is expected because, after all, these
    squares and triangles are based on the effects of **all** features. Still, you
    expect to find a somewhat consistent pattern. The chart with `ap_hi` versus `weight`
    doesn’t have this pattern vertically as `weight` increases, which suggests something
    is missing in this story… Hold that thought because we are going to investigate
    that in the next section!
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have completed the second part of the minister’s request.
  prefs: []
  type: TYPE_NORMAL
- en: 'Decision region plotting, a **local model interpretation method**, provided
    the health ministry with a tool to interpret individual case predictions. You
    could now extend this to explain several cases at a time, or plot all-important
    feature combinations to find the ones where the circle is decidedly in the positive
    decision region. You can also change some of the filler variables one at a time
    to see how they make a difference. For instance, what if you increase the filler
    age to the median age of 54 or even to the age of test case #2872? Would a borderline
    high `ap_hi` and healthy `cholesterol` now be enough to tip the scales? We will
    answer this question later, but first, let’s understand what can make machine
    learning interpretation so difficult.'
  prefs: []
  type: TYPE_NORMAL
- en: Appreciating what hinders machine learning interpretability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last section, we were wondering why the chart with `ap_hi` versus `weight`
    didn’t have a conclusive pattern. It could very well be that although `weight`
    is a risk factor, there are other critical *mediating variables* that could explain
    the increased risk of CVD. A **mediating variable** is one that influences the
    strength between the independent and target (*dependent*) variable. We probably
    don’t have to think too hard to find what is missing. In *Chapter 1*, *Interpretation,
    Interpretability, and Explainability; and Why Does It All Matter?*, we performed
    linear regression on `weight` and `height` because there’s a linear relationship
    between these variables. In the context of human health, `weight` is not nearly
    as *meaningful* without `height`, so you need to look at both.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps if we plot the decision regions for these two variables, we will get
    some clues. We can plot them with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![Chart, scatter chart  Description automatically generated](img/B18406_02_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: The decision regions for weight and height, with test case #2872'
  prefs: []
  type: TYPE_NORMAL
- en: No decision boundary was ascertained in *Figure 2.3* because if all other variables
    are held constant (at a less risky value), no `height` and `weight` combination
    is enough to predict CVD. However, we can tell that there is a pattern for the
    orange triangles, mostly located in one ovular area. This provides exciting insight
    that even though we expect `weight` to increase when `height` increases, the concept
    of an inherently unhealthy `weight` value is not one that increases linearly with
    `height`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, for almost two centuries, this relationship has been mathematically
    understood by the name **body mass index** (**BMI**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_02_001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Before we discuss BMI further, you must consider complexity. Dimensionality
    aside, there are chiefly three things that introduce complexity that makes interpretation
    difficult:'
  prefs: []
  type: TYPE_NORMAL
- en: Non-linearity
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Interactivity
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Non-monotonicity
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Non-linearity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Linear equations such as ![](img/B18406_02_002.png) are easy to understand.
    They are additive, so it is easy to separate and quantify the effects of each
    of its terms (*a*, *bx*, and *cz*) from the outcome of the model (*y*). Many model
    classes have linear equations incorporated in the math. These equations can both
    be used to fit the data to the model and describe the model.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are model classes that are inherently non-linear because they
    introduce non-linearity in their training. Such is the case for *deep learning*
    models because they have non-linear activation functions such as *sigmoid*. However,
    logistic regression is considered a **Generalized Linear Model** (**GLM**) because
    it’s additive. In other words, the outcome is a sum of weighted inputs and parameters.
    We will discuss GLMs further in *Chapter 3*, *Interpretation Challenges*.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, even if your model is linear, the relationships between the variables
    may not be linear, which can lead to poor performance and interpretability. What
    you can do in these cases is adopt either of the following approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Use a non-linear model class*, which will fit these non-linear feature relationships
    much better, possibly improving model performance. Nevertheless, as we will explore
    in more detail in the next chapter, this can make the model less interpretable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Use domain knowledge to engineer a feature that can help “linearize” it*.
    For instance, if you had a feature that increased exponentially against another,
    you can engineer a new variable with the logarithm of that feature. In the case
    of our CVD prediction, we know BMI is a better way to understand weight in the
    company of height. Best of all, it’s not an *arbitrary* made-up feature, so it’s
    easier to interpret. We can prove this point by making a copy of the dataset,
    engineering the BMI feature in it, training the model with this extra feature,
    and performing local model interpretation. The following code snippet does just
    that:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To illustrate this new feature, let’s plot `bmi` against both `weight` and
    `height` using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 2.4* is produced with the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18406_02_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Bivariate comparison between weight, height, and bmi'
  prefs: []
  type: TYPE_NORMAL
- en: As you can appreciate by the plots in *Figure 2.4*, there is a more definite
    linear relationship between `bmi` and `weight` than between `height` and `weight`
    and, even, between `bmi` and `height`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s fit the new model with the extra feature using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s see whether test case #2872 is in the positive decision region when
    comparing `ap_hi` to `bmi` if we keep `age` constant at `60`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code plots decision regions in *Figure 2.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B18406_02_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: The decision regions for ap_hi and bmi, with test case #2872'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.5* shows that controlling for `age`, `ap_hi`, and `bmi` can help
    explain the positive prediction for CVD because the circle is in the positive
    decision region. Please note that there are some likely anomalous `bmi` outliers
    (the highest BMI ever recorded was 204), so there are probably some incorrect
    weights or heights in the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: WHAT’S THE PROBLEM WITH OUTLIERS?
  prefs: []
  type: TYPE_NORMAL
- en: Outliers can be **influential** or **high leverage** and, therefore, affect
    the model when trained with these included. Even if they don’t, they can make
    interpretation more difficult. If they are **anomalous**, then you should remove
    them, as we did with blood pressure at the beginning of this chapter. And sometimes,
    they can hide in plain sight because they are only perceived as *anomalous* in
    the context of other features. In any case, there are practical reasons why outliers
    are problematic, such as making plots like the preceding one “zoom out” to be
    able to fit them while not letting you appreciate the decision boundary where
    it matters. And there are also more profound reasons, such as losing trust in
    the data, thereby tainting trust in the models that were trained on that data,
    or making the model perform worse. This sort of problem is to be expected with
    real-world data. Even though we haven’t done it in this chapter for the sake of
    expediency, it’s essential to begin every project by thoroughly exploring the
    data, treating missing values and outliers, and doing other data housekeeping
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Interactivity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we created `bmi`, we didn’t only linearize a non-linear relationship, but
    we also created interactions between two features. `bmi` is, therefore, an **interaction
    feature**, but this was informed by domain knowledge. However, many model classes
    do this automatically by permutating all kinds of operations between features.
    After all, features have *latent* relationships between one another, much like
    `height` and `width`, and `ap_hi` and `ap_lo`. Therefore, automating the process
    of looking for them is not always a bad thing. In fact, it can even be absolutely
    necessary. This is the case for many deep learning problems where the data is
    unstructured and, therefore, part of the task of training the model is looking
    for the latent relationships to make sense of it.
  prefs: []
  type: TYPE_NORMAL
- en: However, for structured data, even though interactions can be significant for
    model performance, they can hurt interpretability by adding potentially unnecessary
    complexity to the model and also finding latent relationships that *don’t mean
    anything* (which is called a **spurious relationship** or **correlation**).
  prefs: []
  type: TYPE_NORMAL
- en: Non-monotonicity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Often, a variable has a meaningful and consistent relationship between a feature
    and the target variable. So, we know that as `age` increases, the risk of CVD
    (`cardio`) must increase. There is no point at which you reach a certain age and
    this risk drops. Maybe the risk slows down, but it does not drop. We call this
    **monotonicity**, and functions that are *monotonic* are either always increasing
    or decreasing throughout their entire domain.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that **all** linear relationships are monotonic, but not all monotonic
    relationships are necessarily linear. This is because they don’t have to be a
    straight line. A common problem in machine learning is that a model doesn’t know
    about a monotonic relationship that we expect because of our domain expertise.
    Then, because of noise and omissions in the data, the model is trained in such
    a way in which there are ups and downs where you don’t expect them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s propose a hypothetical example. Let’s imagine that due to a lack of availability
    of data for 57–60-year-olds, and because the few cases we did have for this range
    were negative for CVD, the model could learn that this is where you would expect
    a drop in CVD risk. Some model classes are inherently monotonic, such as logistic
    regression, so they can’t have this problem, but many others do. We will examine
    this in more detail in *Chapter 12*, *Monotonic Constraints and Model Tuning for
    Interpretability*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – A partial dependence plot between a target variable (yhat) and
    a predictor with monotonic and non-monotonic models ](img/B18406_02_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: A partial dependence plot between a target variable (yhat) and
    a predictor with monotonic and non-monotonic models'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.6* is what is called a **Partial Dependence Plot** (**PDP**), from
    an unrelated example. PDPs are a concept we will study in further detail in *Chapter
    4*, *Global Model-Agnostic Interpretation Methods*, but what is important to grasp
    from it is that the prediction `yhat` is supposed to decrease as the feature `quantity_indexes_for_real_gdp_by_state`
    increases. As you can tell by the lines, in the monotonic model, it consistently
    decreases, but in the non-monotonic one, it has jagged peaks as it decreases,
    and then increases at the very end.'
  prefs: []
  type: TYPE_NORMAL
- en: Mission accomplished
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first part of the mission was to understand risk factors for cardiovascular
    disease, and you’ve determined that the top four risk factors are systolic blood
    pressure (`ap_hi`), `age`, `cholesterol`, and `weight` according to the logistic
    regression model, of which only `age` is non-modifiable. However, you also realized
    that systolic blood pressure (`ap_hi`) is not as meaningful on its own since it
    relies on diastolic blood pressure (`ap_lo`) for interpretation. The same goes
    for `weight` and `height`. We learned that the interaction of features plays a
    crucial role in interpretation, and so does their relationship with each other
    and the target variable, whether linear or monotonic. Furthermore, the data is
    only a representation of the truth, which can be wrong. After all, we found *anomalies*
    that, left unchecked, can bias our model.
  prefs: []
  type: TYPE_NORMAL
- en: Another source of bias is how the data was collected. After all, you can wonder
    why the model’s top features were all objective and examination features. Why
    isn’t smoking or drinking a larger factor? To verify whether there was *sample*
    *bias* involved, you would have to compare with other more trustworthy datasets
    to check whether your dataset is underrepresenting drinkers and smokers. Or maybe
    the bias was introduced by the question that asked whether they smoked now, and
    not whether they had ever smoked for an extended period.
  prefs: []
  type: TYPE_NORMAL
- en: Another type of bias that we could address is *exclusion bias*—our data might
    be missing information that explains the truth that the model is trying to depict.
    For instance, we know through medical research that blood pressure issues such
    as isolated systolic hypertension, which increases CVD risk, are caused by underlying
    conditions such as diabetes, hyperthyroidism, arterial stiffness, and obesity,
    to name a few. The only one of these conditions that we can derive from the data
    is obesity and not the other ones. If we want to be able to interpret a model’s
    predictions well, we need to have all relevant features. Otherwise, there will
    be gaps we cannot explain. Maybe once we add them, they won’t make much of a difference,
    but that’s what the methods we will learn in *Chapter 10*, *Feature Selection
    and Engineering for Interpretability*, are for.
  prefs: []
  type: TYPE_NORMAL
- en: The second part of the mission was to be able to interpret individual model
    predictions. We can do this well enough by plotting decision regions. It’s a simple
    method, but it has many limitations, especially in situations where there are
    more than a handful of features, and they tend to interact a lot with each other.
    *Chapter 5*, *Local Model-Agnostic Interpretation Methods*, and *Chapter 6*, *Anchors
    and Counterfactual Explanations*, will cover local interpretation methods in more
    detail. However, the decision region plot method helps illustrate many of the
    concepts surrounding decision boundaries, which we will discuss in those chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we covered two model interpretation methods: feature importance
    and decision boundaries. We also learned about model interpretation method types
    and scopes and the three elements that impact interpretability in machine learning.
    We will keep mentioning these fundamental concepts in subsequent chapters. For
    a machine learning practitioner, it is paramount to be able to spot them so that
    we can know what tools to leverage to overcome interpretation challenges. In the
    next chapter, we will dive deeper into this topic.'
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Molnar, Christoph. *Interpretable Machine Learning. A Guide for Making Black
    Box Models Explainable*. 2019: [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mlextend Documentation. Plotting Decision Regions*: [http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn more on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To join the Discord community for this book – where you can share feedback,
    ask the author questions, and learn about new releases – follow the QR code below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/inml](Chapter_2.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code107161072033138125.png)'
  prefs: []
  type: TYPE_IMG
