- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Model Monitoring and Management Solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B18638_06.xhtml#_idTextAnchor132), *SageMaker Training and
    Debugging Solutions*, and [*Chapter 7*](B18638_07.xhtml#_idTextAnchor151), *SageMaker
    Deployment Solutions*, we focused on training and deploying **machine learning**
    (**ML**) models using **SageMaker**. If you were able to complete the hands-on
    solutions presented in those chapters, you should be able to perform similar types
    of experiments and deployments using other algorithms and datasets. These two
    chapters are good starting points, especially when getting started with the managed
    service. At some point, however, you will have to use its other capabilities to
    manage, troubleshoot, and monitor different types of resources in production ML
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: One of the clear advantages of using SageMaker is that a lot of the commonly
    performed tasks of data scientists and ML practitioners have already been automated
    as part of this fully managed service. This means that we generally do not need
    to build a custom solution, especially if SageMaker already has that capability
    or feature. Examples of these capabilities include **SageMaker Debugger**, **SageMaker
    Feature Store**, **SageMaker Training Compiler**, **SageMaker Inference Recommender**,
    **SageMaker Clarify**, **SageMaker Processing**, and more! If we need to use one
    or more of these capabilities, all we need to do is use **boto3**, along with
    the **SageMaker Python SDK**, to run a few lines of code to obtain the desired
    functionality and results in just a matter of hours (or even minutes!).
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will focus on using the built-in **model registry** of SageMaker,
    which we will use to register and manage trained ML models. We will also show
    a quick demonstration of how to deploy models from the model registry into an
    ML inference endpoint. In addition to the model registry, we will work with **SageMaker
    Model Monitor**, which is another built-in capability that we will use to capture
    and analyze the data that passes through an ML inference endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Registering models to SageMaker Model Registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying models from SageMaker Model Registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enabling data capture and simulating predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scheduled monitoring with SageMaker Model Monitor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing the captured data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deleting an endpoint with a monitoring schedule
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cleaning up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you have completed the hands-on solutions in this chapter, you will have
    an easier time understanding, using, and configuring the other built-in features
    of SageMaker. With this in mind, let’s begin!
  prefs: []
  type: TYPE_NORMAL
- en: Technical prerequisites
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we start, we must have the following ready:'
  prefs: []
  type: TYPE_NORMAL
- en: A web browser (preferably Chrome or Firefox)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to the AWS account and **SageMaker Studio** domain that was used in the
    first chapter of this book
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Jupyter notebooks, source code, and other files used for each chapter are
    available in this book’s GitHub repository: [https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS](https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS).'
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended to use an IAM user with limited permissions instead of the
    root account when running the examples in this book. We will discuss this, along
    with other security best practices, in detail in [*Chapter 9*](B18638_09.xhtml#_idTextAnchor187),
    *Security, Governance, and Compliance Strategies*. If you are just starting to
    use AWS, you may proceed with using the root account in the meantime.
  prefs: []
  type: TYPE_NORMAL
- en: Registering models to SageMaker Model Registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B18638_06.xhtml#_idTextAnchor132), *SageMaker Training and
    Debugging Solutions*, we used the `deploy()` method of the `Estimator` instance
    to immediately deploy our ML model to an inference endpoint right after using
    the `fit()` method to train the model. When performing ML experiments and deployments
    in production, a model may have to be analyzed and evaluated first before proceeding
    with the deployment step. The individual or team performing the analysis would
    review the input configuration parameters, the training data, and the algorithm
    used to train the model, along with other relevant information available. Once
    the data science team has to work with multiple models, managing and organizing
    all of these would be much easier using a **model registry**.
  prefs: []
  type: TYPE_NORMAL
- en: 'What’s a model registry? A model registry is simply a repository that focuses
    on helping data scientists and ML practitioners manage, organize, and catalog
    ML models. After the training step, the data science team may store the trained
    ML model in the model registry and tag its status as *For Review* or *Pending
    Approval*. This will allow the reviewing team to easily locate the models for
    review, along with the history and information linked to these models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Working with a model registry ](img/B18638_08_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Working with a model registry
  prefs: []
  type: TYPE_NORMAL
- en: Once the reviewing team has finished the review process and has approved a model
    for deployment, the status of the model can now be changed to *Approved*, similar
    to what is shown in the preceding diagram. Once the status of the ML model has
    been changed to *Approved*, it can be deployed manually or even automatically
    using an **MLOps pipeline**. In addition to these, other automated actions such
    as automated reports and notifications can be triggered.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For more information on MLOps pipelines, feel free to check out [*Chapter 10*](B18638_10.xhtml#_idTextAnchor215),
    *Machine Learning Pipelines with Kubeflow on Amazon EKS*, and [*Chapter 11*](B18638_11.xhtml#_idTextAnchor231),
    *Machine Learning Pipelines with SageMaker Pipelines*.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have a better idea of how data science teams can make their lives
    easier using a model registry, you may already be planning on coding a model registry
    from scratch! Hold it right there – SageMaker already provides one for us! In
    the succeeding pages of this chapter, we will use the **boto3** library and the
    **SageMaker Python SDK** to utilize the model registry available in SageMaker.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new notebook in SageMaker Studio
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will start the hands-on portion of this section by opening SageMaker Studio
    and creating a new Jupyter Notebook inside a new directory.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that you have completed the hands-on solutions in the *Getting Started
    with SageMaker and SageMaker Studio* section of *Chapter 1*, *Introduction to
    ML Engineering on AWS* before proceeding. Note that the hands-on section in this
    chapter is *NOT* a continuation of what we completed in [*Chapter 6*](B18638_06.xhtml#_idTextAnchor132),
    *SageMaker Training and Debugging Solutions*, and [*Chapter 7*](B18638_07.xhtml#_idTextAnchor151),
    *SageMaker Deployment Solutions*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to launch SageMaker Studio and then create a new Notebook
    that will be used to run the Python scripts in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to `sagemaker studio` in the search bar of the AWS Management Console
    and selecting **SageMaker Studio** from the list of results under **Features**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: This chapter assumes that we are using the `us-west-2`) region when using services
    to manage and create different types of resources. You may use a different region
    but make sure to make any adjustments needed in case certain resources need to
    be transferred to your region of choice.
  prefs: []
  type: TYPE_NORMAL
- en: Next, click **Studio** under **SageMaker Domain** in the sidebar.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click **Launch app**, as highlighted in the following screenshot. Select **Studio**
    from the list of drop-down options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Opening SageMaker Studio ](img/B18638_08_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – Opening SageMaker Studio
  prefs: []
  type: TYPE_NORMAL
- en: This will redirect you to SageMaker Studio. Wait a few seconds for the interface
    to load.
  prefs: []
  type: TYPE_NORMAL
- en: 'Right-click on the empty space in the **File Browser** sidebar pane to open
    a context menu similar to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Creating a new folder ](img/B18638_08_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – Creating a new folder
  prefs: []
  type: TYPE_NORMAL
- en: Select `CH08`.
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the **CH08** directory by double-clicking the corresponding folder
    name in the sidebar.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a new Notebook by clicking the **File** menu and choosing **Notebook**
    from the list of options under the **New** submenu:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Creating a new Notebook ](img/B18638_08_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – Creating a new Notebook
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, we can see other options as well, including creating
    a new `.ipynb` Notebook files, which will be used to run the different blocks
    of code.
  prefs: []
  type: TYPE_NORMAL
- en: In the `Data Science` (option found under **SageMaker image**)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Python 3`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`No script`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Select** button afterward.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Wait for the kernel to start. This step may take around 3 to 5 minutes while
    an ML instance is being provisioned to run the Jupyter notebook cells.
  prefs: []
  type: TYPE_NORMAL
- en: 'Right-click on the tab’s name, as highlighted in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Renaming a notebook ](img/B18638_08_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – Renaming a notebook
  prefs: []
  type: TYPE_NORMAL
- en: Select **Rename Notebook…** from the list of options in the context menu.
  prefs: []
  type: TYPE_NORMAL
- en: In the `01 - Registering Models to the SageMaker Model Registry.ipynb` under
    **New Name**. Click the **Rename** button afterward.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that our notebook is ready, we can proceed with registering pre-trained
    models to SageMaker Model Registry!
  prefs: []
  type: TYPE_NORMAL
- en: Registering models to SageMaker Model Registry using the boto3 library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will be working with two pre-trained models stored inside
    `.tar.gz` files. We will store and register these models in `.tar.gz` files were
    generated by performing two separate ML training jobs using the **K-Nearest Neighbor**
    and **Linear Learner** built-in algorithms of SageMaker. These models accept *x*
    and *y* values as input and return a predicted *label* value as output. What do
    these *x* and *y* values represent? Let’s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Predicting the preferred vaccination site ](img/B18638_08_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – Predicting the preferred vaccination site
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding screenshot, these *x* and *y* values correspond to
    transformed and scaled coordinate values where certain members of the population
    reside using a specified point in the map as a reference. During the first vaccination
    run, several of these members selected their preferred vaccination site. These
    vaccination sites are tagged with the appropriate *label* value – *0*, *1*, and
    *2*. Using previous vaccination site data as our training data, we were able to
    generate two models that can automatically predict the preferred vaccination site
    for unvaccinated members, given a set of coordinate values – that is, *x* and
    *y*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to download the artifacts of the two pre-trained models
    mentioned and register these in SageMaker Model Registry in the `01 - Registering
    Models to the SageMaker Model Registry.ipynb` Notebook we prepared in the previous
    section:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by downloading the pre-trained model artifacts to the `tmp` directory
    using the `wget` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we downloaded two `.tar.gz` files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`knn.model.tar.gz`: This contains the model artifacts for the pre-trained **K-Nearest
    Neighbor** model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ll.model.tar.gz`: This contains the model artifacts for the pre-trained **Linear
    Learner** model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Specify a unique S3 bucket name and prefix. Make sure that you replace the
    value of `<INSERT S3 BUCKET HERE>` with a unique S3 bucket name before running
    the following block of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Make sure that you specify a bucket name for an S3 bucket that does *NOT* exist
    yet. If you want to reuse one of the buckets you created in the previous chapters,
    you may do so, but make sure to use an S3 bucket in the same region where **SageMaker
    Studio** is set up and configured.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create the S3 bucket where we will upload the `ll.model.tar.gz` and `knn.model.tar.gz`
    files we downloaded earlier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can skip this step if you are planning to reuse one of the existing S3 buckets
    you created in the previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that our S3 bucket is ready, let’s prepare the S3 paths so that they point
    to where we will upload the pre-trained model artifacts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that at this point, the `ll.model.tar.gz` and `knn.model.tar.gz` files
    do not exist yet in the specified S3 paths stored in the `ll_model_data` and `knn_model_data`
    variables. Here, we are simply preparing the S3 location paths (string) where
    the `.tar.gz` files will be uploaded.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s use the `aws s3 cp` command to copy and upload the `.tar.gz` files
    to their corresponding S3 locations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will upload the `ll.model.tar.gz` and `knn.model.tar.gz` files from the
    `tmp` directory to the S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the pre-trained model artifacts already in S3, let’s proceed with getting
    the ECR container image URI of the ML algorithms used to train these models. We’ll
    use the `retrieve()` function to get the image URIs for the **Linear Learner**
    and **K-Nearest Neighbor** algorithms:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize the `boto3` client for SageMaker. We will use this client to call
    several SageMaker APIs, which will help us create model packages and model package
    groups in the succeeding set of steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, define the `generate_random_string()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*What’s this for?* We will use the `generate_random_string()` function when
    creating new resources (in the succeeding set of steps). This will help us generate
    a random identifier or label for each of the resources we will create.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With the `generate_random_string()` function ready, let’s generate a random
    `group_id` value. This will be used to generate a *package group name* (`package_group_name`)
    and a *package group description* (`package_group_desc`). Then, we will create
    the *model package group* using the `create_model_package_group()` method of the
    boto3 client:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let’s define the `prepare_inference_specs()` function, which we will
    use to configure and set up our model package in the next step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we created a function that prepares and returns the necessary nested configuration
    structure using the *ECR container image URI* and the *model artifact S3 path*
    as input parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s define a custom function called `create_model_package()`. This
    function accepts several input parameter values, such as the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **Amazon Resource Name** (**ARN**) *of the model package group*
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The *inference specification configuration*
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '(Optional) The `boto3` client for SageMaker:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE58]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE64]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE67]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE68]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE70]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: Here, we automatically set the `ModelApprovalStatus` value to `Approved` upon
    creating the model package. Note that we have the option to set the value to `PendingManualApproval`
    first before transitioning it to `Approved`. However, we will simplify things
    a bit and directly set the value to `Approved`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The approval status of the model can be used to tag and identify which models
    are ready to be deployed to a production endpoint. Ideally, ML models are evaluated
    and manually approved first before being deployed. If the model passes the evaluation
    step, we can set the approval status to `Approved`. Otherwise, we set the status
    to `Rejected`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `prepare_inference_specs()` function to prepare the prerequisite inference
    specification configuration for both the **K-Nearest Neighbor** and **Linear Learner**
    model packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the inference specification configurations ready, let’s use `create_model_package()`
    to create the model packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, let’s use the `%store` magic from IPython to store the variable values
    for `knn_package_arn`, `ll_package_arn`, `s3_bucket`, and `prefix`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will use these stored variable values in the succeeding sections of this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, two model packages have been created and are ready for use.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You may use `client.list_model_package_groups()` and `client.list_model_packages(ModelPackageGroupName='<INSERT
    GROUP NAME>')` to check the list of registered model package groups and model
    packages. We will leave this to you as an exercise!
  prefs: []
  type: TYPE_NORMAL
- en: Deploying models from SageMaker Model Registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many possible next steps available after an ML model has been registered
    to a model registry. In this section, we will focus on deploying the first registered
    ML model (pre-trained **K-Nearest Neighbor** model) manually to a new inference
    endpoint. After the first registered ML model has been deployed, we will proceed
    with deploying the second registered model (pre-trained **Linear Learner** model)
    in the same endpoint where the first ML model has been deployed, similar to what’s
    shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Deploying models from the model registry   ](img/B18638_08_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – Deploying models from the model registry
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that we can directly replace the deployed ML model inside a
    running ML inference endpoint without creating a new separate inference endpoint.
    This means that we do not need to worry about changing the “target infrastructure
    server” in our setup since the model replacement operation is happening behind
    the scenes. At the same time, SageMaker has already automated this process for
    us, so all we need to do is call the right APIs to initiate this process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will continue where we left off in the *Registering models to SageMaker
    Model Registry* section and deploy the two registered models to an ML inference
    endpoint. That said, we will perform the following set of steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new Notebook by clicking the **File** menu and choosing **Notebook**
    from the list of options under the **New** submenu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Note that we will be creating the new notebook inside the `CH08` directory beside
    the `01 - Registering Models to the SageMaker Model Registry.ipynb` notebook file
    we worked with in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: In the `Data Science` (option found under **SageMaker image**)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Python 3`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`No script`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Select** button afterward.
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on the tab name of the new Notebook and select `02 - Deploying Models
    from the SageMaker Model Registry.ipynb` under **New Name**. Click the **Rename**
    button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we have the new notebook ready, let’s continue by loading the values
    of the stored variables for `knn_package_arn` and `ll_package_arn` using the `%store`
    magic from IPython:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s initialize a `ModelPackage` instance using the following block of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we passed the *IAM execution role*, *K-Nearest Neighbor model package
    ARN*, and the `Session` instance when initializing the `ModelPackage` instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have initialized the `ModelPackage` instance, we will call its
    `deploy()` method to deploy the pre-trained model to a real-time inference endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Since we set the `predictor_class` attribute in the previous step to `Predictor`,
    the `deploy()` method will return a `Predictor` instance instead of `None`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Model deployment should take around 5 to 10 minutes to complete. Feel free to
    grab a cup of coffee or tea!
  prefs: []
  type: TYPE_NORMAL
- en: 'Once our ML inference endpoint is ready, we will perform a sample prediction
    using the `predict()` method of the `Predictor` instance to test our setup:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should yield an output value equal or similar to `{''predictions'': [{''predicted_label'':
    2.0}]}`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s define the `process_prediction_result()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will extract the `label` value from the nested structure returned by the
    `predict()` method of the `Predictor` instance. Of course, the code in the function
    assumes that we will only be passing one payload at a time when calling the `predict()`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s define a custom `predict()` function that accepts the input `x` and `y`
    values, along with an optional `Predictor` instance parameter value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s test our custom `predict()` function using a set of sample values for
    `x` and `y`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This should return the predicted `label` value equal to or similar to `1.0`.
    *How do we interpret this result?* The customer who lives in a location represented
    with the specified input `x` and `y` values would probably go to the vaccination
    site tagged with the label `1` (that is, the second vaccination site).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to modify the `process_prediction_result()` function to convert the
    type of the resulting predicted `label` value into an *integer* instead of a *float*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s define the `test_different_values()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE146]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE147]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we just call our custom `predict()` function multiple times (with a 200-millisecond
    delay between each prediction request) using different combinations of values
    for *x* and *y*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before proceeding, let’s check if our `test_different_values()` function is
    working as expected:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This should show us the predicted `label` values given the different combinations
    of *x* and *y*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s define a custom `create_model()` function that makes use of the
    `create_model()` method of the boto3 client to work with the SageMaker API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE150]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE151]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE152]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE153]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE154]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE155]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE156]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE157]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE158]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE159]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE160]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE161]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE162]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE163]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s define the `generate_random_string()` function, which we will use to
    generate a random model name. After that, we will call the custom `create_model()`
    function we defined in the previous step, passing the model package ARN of our
    **Linear Learner** model along with the generated model name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE165]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE166]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE167]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE168]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE169]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE170]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE171]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE172]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE173]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE174]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE175]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let’s define the `create_endpoint_config()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE176]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE177]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE178]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE179]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE180]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE181]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE182]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE183]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE184]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE185]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE186]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE187]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE188]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE189]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE190]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This function simply makes use of the `create_endpoint_config()` method of the
    boto3 client for SageMaker to prepare the desired endpoint configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `create_endpoint_config()` function we defined in the previous step,
    let’s create a SageMaker ML inference endpoint configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE191]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE192]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE193]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE194]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE195]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s update the endpoint configuration using the `update_endpoint()`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE196]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE197]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE198]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE199]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we used the endpoint configuration we created in the previous step.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: '*What’s going to happen here?* Once we call the `update_endpoint()` method,
    SageMaker will perform the needed steps behind the scenes to update the endpoint
    and replace the old, deployed model (**K-Nearest Neighbor**) with the new model
    (**Linear Learner**) specified in the latest endpoint configuration. Note that
    this is just one of the possible solutions we can implement using the **SageMaker
    Python SDK** and the **boto3** library. Other possible deployment solutions include
    **multi-model endpoints**, **A/B testing** endpoint setups, endpoints using an
    **inference pipeline model**, and more! We won’t dive deep into these other variations
    and solutions, so feel free to check the deployment recipes found in the book
    *Machine Learning with Amazon SageMaker Cookbook*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before proceeding with the next set of steps, let’s wait 5 minutes using the
    following block of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE200]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE201]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we used the `sleep()` function, which accepts an input value equal to
    the number of seconds we want our code to wait or sleep.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We use the `sleep()` function to wait for 5 minutes to ensure that the update
    endpoint operation has been completed already (assuming that it takes approximately
    5 minutes or less to complete).
  prefs: []
  type: TYPE_NORMAL
- en: 'Initialize a `Predictor` object and attach it to the existing ML inference
    endpoint we prepared earlier in this section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE202]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE203]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE204]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE205]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE206]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE207]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s test our setup by making a prediction using a sample payload:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE208]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE209]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE210]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE211]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE212]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE213]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE214]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE215]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should yield an output value with a structure similar to `{''predictions'':
    [{''score'': [0.04544410854578018, 0.3947080075740814, 0.5598478317260742], ''predicted_label'':
    2}]}`.'
  prefs: []
  type: TYPE_NORMAL
- en: '*How do we interpret this result?* The customer who lives in a location represented
    with the specified input `x` and `y` values (that is, *x* = `1.5` and *y* = `2`)
    has the following probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '`4.5%` probability of going to the first vaccination site (label = 0)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`39.5%` probability of going to the second vaccination site (label = 1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`56%` probability of going to the third vaccination site (label = 2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given that the third vaccination site has the highest probability value, the
    model sets the `predicted_label` value to `2` (given that counting starts at 0).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Note that the deployed **Linear Learner** model returned the *probability scores
    for each class*, along with the *predicted label*, while the **k-nearest neighbor**
    model that we deployed at the start of this section only returned the *predicted
    label*. We need to be careful when replacing a deployed model with a model from
    a different instance family (which may require using a different algorithm container
    image for inference) since the new model may involve a different set of input
    and output structures and values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to what we performed earlier on the ML inference endpoint hosting our
    **K-Nearest Neighbor** model, we will perform multiple sample predictions using
    different values of *x* and *y*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE216]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `%store` magic to store the variable value for `endpoint_name`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE217]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE218]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you are wondering why we haven’t deleted the ML inference endpoint yet… we
    will reuse this endpoint and use it to demonstrate how to use the model monitoring
    capabilities and features of SageMaker in the very next section!
  prefs: []
  type: TYPE_NORMAL
- en: Enabling data capture and simulating predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After an ML model has been deployed to an inference endpoint, its quality needs
    to be monitored and checked so that we can easily perform corrective actions whenever
    quality issues or deviations are detected. This is similar to web application
    development, where even if the quality assurance team has already spent days (or
    weeks) testing the final build of the application, there can still be other issues
    that would only be detected once the web application is running already:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Capturing the request and response data of the ML inference
    endpoint ](img/B18638_08_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 – Capturing the request and response data of the ML inference endpoint
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding diagram, model monitoring starts by capturing the
    request and response data, which passes through a running ML inference endpoint.
    This collected data is processed and analyzed in a later step using a separate
    automated task or job that can generate reports and flag issues or anomalies.
    If we deployed our ML model in a custom-built web application endpoint, we may
    need to build this data capturing and model monitoring setup ourselves. However,
    if we are using SageMaker, there is no need for us to code anything from scratch
    since we can just utilize the built-in model monitoring capabilities, which just
    need to be enabled and configured.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In our “preferred vaccination site prediction” example, the captured data (ideally)
    includes both the input (the *x* and *y* values) and output values (predicted
    *label* value).
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to enable data capture in a running ML inference endpoint
    and simulate inference requests using randomly generated payload values:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new Notebook by clicking the **File** menu and choosing **Notebook**
    from the list of options under the **New** submenu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Note that we will be creating the new notebook inside the `CH08` directory beside
    the `01 - Registering Models to the SageMaker Model Registry.ipynb` and `02 -
    Deploying Models from the SageMaker Model Registry.ipynb` notebook files we worked
    with in the previous sections in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the `Data Science` (option found under **SageMaker image**)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Python 3`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`No script`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Select** button afterward.
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on the tab name of the new Notebook and select `03 - Enabling Data
    Capture and Simulating Predictions.ipynb` under **New Name**. Click the **Rename**
    button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we have our new notebook ready, let’s use the `%store` magic from
    IPython to load the values of the stored variables for `s3_bucket`, `prefix`,
    `ll_package_arn`, and `endpoint_name`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE219]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE220]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE221]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE222]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize a `Predictor` object and attach it to the ML inference endpoint
    we prepared in the *Deploying models from SageMaker Model Registry* section of
    this chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE223]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE224]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE225]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE226]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE227]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE228]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE229]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE230]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE231]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE232]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE233]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE234]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE235]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE236]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let’s prepare and initialize the `DataCaptureConfig` instance using the
    following block of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE237]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE238]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE239]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE240]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE241]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE242]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE243]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE244]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE245]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE246]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE247]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE248]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE249]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE250]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE251]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we specified a `sampling_percentage` value of `100`, which means that
    all of the data will be captured. We also specified, through the `capture_options`
    configuration value, that we are planning to capture both the request and response
    data that passes through the ML inference endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that our configuration is ready, let’s call the `update_data_capture_config()`
    method of the `Predictor` instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE252]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE253]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE254]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE255]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: This should take around 5 to 15 minutes to complete. Feel free to grab a cup
    of coffee or tea!
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `%store` magic to store the variable value for `capture_upload_path`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE256]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `generate_random_payload()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE257]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE258]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE259]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE260]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE261]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `perform_good_input()` and `perform_bad_input()` functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE262]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE263]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE264]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE265]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE266]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE267]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE268]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE269]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE270]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE271]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you might be wondering why we are considering floating-point
    values for the *y* input payload as *bad input*. Note that this is just for demonstration
    purposes since we are planning to configure **SageMaker Model Monitor** to tag
    floating-point input values for *x* and *y* as invalid values while configuring
    the constraints in the *Scheduled Monitoring with SageMaker Model Monitor* section.
  prefs: []
  type: TYPE_NORMAL
- en: Use the `perform_good_input()` function to run a sample inference request containing
    “valid values:”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE272]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use the `perform_bad_input()` function to run a sample inference request containing
    “invalid values:”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE273]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `generate_sample_requests()` function, which will alternate between
    calling the `perform_good_input()` and `perform_bad_input()` functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE274]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE275]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE276]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE277]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE278]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE279]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE280]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE281]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With everything ready, let’s continuously send sample requests to our ML inference
    endpoint using the `generate_sample_requests()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE282]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Note that the last step in this section will continuously send sample inference
    requests every 30 seconds and loop 480 times. We will leave this running and proceed
    with the next section. We should only stop the execution of the `generate_sample_requests()`
    function after completing the *Scheduled monitoring with SageMaker Model Monitor*
    section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you might be wondering where the data is stored and how this
    data would be used for analysis. In the next few sections, we will answer these
    questions and provide more details on how model monitoring works in SageMaker.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduled monitoring with SageMaker Model Monitor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you have been working in the data science and ML industry for quite some
    time, you probably know that an ML model’s performance after deployment is not
    guaranteed. Deployed models in production must be monitored in real time (or near-real
    time) so that we can potentially replace the deployed model and fix any issues
    once any **drift** or deviation from the expected set of values is detected:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Analyzing captured data and detecting violations using Model
    Monitor    ](img/B18638_08_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 – Analyzing captured data and detecting violations using Model Monitor
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, we can see that we can process and analyze the captured
    data through a monitoring (processing) job. This job is expected to generate an
    automated report that can be used to analyze the deployed model and the data.
    At the same time, any detected violations are flagged and reported as part of
    the report.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say that we have trained an ML model that predicts a professional’s *salary*
    given the professional’s *age*, *number of years of work experience*, *role*,
    and *number of children*. Once the ML model has been deployed to an inference
    endpoint, a variety of applications would then send request data to the ML inference
    endpoint to get the predicted salary value. *What if one of the applications starts
    sending erroneous values?* For example, the value specified for the *number of
    children* in the input payload is negative. Given that it is impossible to have
    a negative number for this field, a monitoring job should flag this violation
    as a **data quality issue**.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will configure **SageMaker Model Monitor** to analyze the
    captured data using a scheduled hourly processing job. Once the processing job
    results are ready, we will see that the monitoring job has flagged a violation
    caused by sending “bad input” as part of the payload to the ML inference endpoint
    in the previous section. Model Monitor can be configured to detect violations
    concerning **data quality**, **model quality**, **bias drift**, and **feature
    attribution drift**. In the hands-on solutions in this section, we will only focus
    on detecting violations concerning data quality. However, detecting the other
    types of drifts and violations should follow a similar set of steps, which will
    be presented in a bit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to configure **SageMaker Model Monitor** to run a monitoring
    job every hour and analyze the captured data that passed through the ML inference
    endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new Notebook by clicking the **File** menu and choosing **Notebook**
    from the list of options under the **New** submenu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Note that we will be creating the new notebook inside the `CH08` directory beside
    the other notebook files we created in the previous sections of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the `Data Science` (option found under **SageMaker image**)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Python 3`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`No script`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Select** button afterward.
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on the tab name of the new Notebook and select `04 - Scheduled Monitoring
    with SageMaker Model Monitor.ipynb` under **New Name**. Click the **Rename** button
    afterward.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we have our new notebook ready, let’s use the `%store` magic from
    IPython to load the values of the stored variables for `s3_bucket`, `prefix`,
    `ll_package_arn`, `endpoint_name`, and `ll_package_arn`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE283]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE284]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE285]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE286]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE287]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize a `Predictor` object and attach it to the ML inference endpoint
    we deployed in the *Deploying models from SageMaker Model Registry* section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE288]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE289]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE290]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE291]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE292]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE293]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE294]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE295]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE296]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE297]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Download the `baseline.csv` file using the `wget` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE298]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE299]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE300]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: What’s the `baseline.csv` file for? This CSV file will later serve as the **baseline
    dataset** that will be used by **SageMaker Model Monitor** as a “reference” to
    check for drifts and issues with the captured data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s also prepare the S3 path location where we will store the baseline analysis
    output files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE301]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE302]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE303]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `aws s3 cp` command to upload the `baseline.csv` file from the `tmp`
    directory to the S3 target location stored in `baseline_source_uri`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE304]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize and configure the `DefaultModelMonitor` instance using the following
    block of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE305]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE306]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE307]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE308]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE309]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE310]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE311]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE312]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE313]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE314]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE315]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we configured `ml.m5.large` instance when processing the captured data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To monitor the deployed ML model and the data passing through the inference
    endpoint, `monitor_dict` correspond to the configuration of the SageMaker Processing
    jobs for monitoring the ML model and the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run the baselining job using the following block of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE316]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE317]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE318]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE319]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE320]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE321]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE322]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE323]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE324]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE325]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE326]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE327]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE328]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE329]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we used the `baseline.csv` file as a reference for the expected properties
    of the data that will pass through the ML inference endpoint. Let’s say that one
    of the columns in the `baseline.csv` file only contains positive integers. Using
    this CSV file as the baseline, we would be able to configure **SageMaker Model
    Monitor** to flag negative or floating-point input values (for the said column
    or feature) as “bad input.”
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Of course, detecting the violations and issues is only half the story. Fixing
    the issue would be the other half.
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a custom `flatten()` function, which will help us inspect and view a
    dictionary object in a DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE330]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE331]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE332]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE333]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s the check statistics report generated by the baselining job:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE334]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE335]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE336]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE337]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should yield a DataFrame similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10 – DataFrame containing the baseline statistics ](img/B18638_08_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 – DataFrame containing the baseline statistics
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see the `inferred_type` values for each of the columns of the `baseline.csv`
    file, along with the other statistics values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s review the suggested constraints prepared by the baselining job:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE338]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE339]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE340]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should give us a DataFrame of values similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.11 – DataFrame with the suggested constraints of each of the features
    ](img/B18638_08_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.11 – DataFrame with the suggested constraints of each of the features
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see the constraints recommended by the baselining job after analyzing
    the baseline dataset used.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: These (suggested) constraints will be used later by the `a` in the baseline
    dataset has a constraint where it should contain integer values only, then the
    processing jobs will flag if the captured data contains records, where the column
    `a` value is a floating-point number.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will modify the constraints for columns `a` and `b` (containing the
    input *x* and *y* values) and assume that the valid values for these are of the
    integer type instead of float or decimal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE341]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE342]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE343]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once the hourly processing job analyzes the captured data, **SageMaker Model
    Monitor** will flag the payloads containing floating-point *y* values as “bad
    input.”
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: What happens if we change the `inferred_type` values for columns `a` and `b`
    (containing the *x* and *y* values, respectively) of the suggested constraints
    to `'Fractional'` instead of `'Integral'`? Since the payload values generated
    by the `generate_sample_requests()` function in the *Enabling data capture and
    simulating predictions* section involve a combination of integer and floating-point
    values, **SageMaker Model Monitor** will tag all input request payloads as “good
    input” and it will not report any detected violations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s define the `generate_label()` function, which will help us generate a
    random string label for the monitoring schedule name in a later step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE344]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE345]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE346]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE347]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE348]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE349]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE350]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE351]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE352]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s load the baseline statistics and suggested constraints using the `baseline_statistics()`
    and `suggested_constraints()` methods, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE353]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE354]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE355]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s prepare the **cron expression** that we will use to configure the monitoring
    job to run once every hour in a later step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE356]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For more details on other supported **cron expressions**, feel free to check
    out [https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-schedule-expression.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-schedule-expression.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: 'With the prerequisites ready, let’s create the monitoring schedule using the
    `create_monitoring_schedule()` method of the `DefaultModelMonitor` instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE357]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE358]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE359]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE360]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE361]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE362]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE363]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE364]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE365]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE366]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE367]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE368]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After running this block of code, `schedule` that runs a **SageMaker Processing**
    job (once every hour) that processes and monitors the data that’s been captured.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If you encounter deprecation warnings or issues when using `predictor.endpoint`,
    you may replace it with `predictor.endpoint_name` instead. For more information
    on deprecations (along with breaking and non-breaking changes) when using version
    2.x of the **SageMaker Python SDK**, feel free to check out [https://sagemaker.readthedocs.io/en/stable/v2.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-schedule-expression.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s quickly inspect the monitor’s schedule properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE369]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should yield a DataFrame similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12 – DataFrame describing the properties of the monitoring schedule
    ](img/B18638_08_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.12 – DataFrame describing the properties of the monitoring schedule
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the `MonitoringScheduleStatus` value is still `Pending`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `sleep()` function to wait for 5 minutes before executing the next
    cell:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE370]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE371]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Here, we wait for a few minutes while the monitoring schedule is being created
    (assuming it is created in 5 minutes).
  prefs: []
  type: TYPE_NORMAL
- en: 'Test and load the initial set of values for the monitor’s constraint violations
    and statistics using the `latest_monitoring_constraint_violations()` and `latest_monitoring_statistics()`
    methods of the `DefaultModelMonitor` instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE372]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE373]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE374]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE375]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE376]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `get_violations()` and `load_and_load_violations()` functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE377]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE378]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE379]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE380]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE381]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE382]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE383]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE384]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE385]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE386]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE387]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE388]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE389]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE390]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE391]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE392]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE393]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE394]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE395]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Invoke the `load_and_load_violations()` function we defined in the previous
    step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE396]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should yield a set of logs similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13 – Logs generated while running the loop_and_load_violations()
    function ](img/B18638_08_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.13 – Logs generated while running the loop_and_load_violations() function
  prefs: []
  type: TYPE_NORMAL
- en: Here, we simply iterated and waited for the scheduled Model Monitor processing
    job to yield the generated analysis report containing the detected violations,
    along with the other statistical values computed from the captured data.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: This step may take an hour or more to complete. Feel free to grab a (larger)
    cup of coffee or tea! While waiting for this step to complete, you may continue
    with the hands-on solutions of the next section of this chapter, *Analyzing the
    captured data*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the `loop_and_load_violations()` function has finished running, you can
    proceed with loading and inspecting the detected violations using the `latest_monitoring_constraint_violations()`
    method of the `DefaultModelMonitor` instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE397]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE398]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should give us a nested dictionary of values, similar to what we have
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE399]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that we have several detected violations for feature `b` (corresponding
    to the *y* input values). To have a better idea of what these detected violations
    are, we can check the available description – `Data type match requirement is
    not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only
    50.0% of data is Integral`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load and inspect the statistics data using the `latest_monitoring_statistics()`
    method of the `DefaultModelMonitor` instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE400]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE401]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should give us a nested structure of values similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE402]'
  prefs: []
  type: TYPE_PRE
- en: '*Wasn’t that easy?* Imagine trying to build this yourself! It would have taken
    you a few days to code and build this yourself from scratch.'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you should have a better idea of how to configure and use **SageMaker
    Model Monitor** to detect violations and potential issues in the model and data.
    Before cleaning up the resources we created and used in this chapter, we will
    look at another approach regarding how to analyze and process the data captured
    and collected by Model Monitor in the S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the captured data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of course, there are other ways to process the data that’s been captured and
    stored inside the S3 bucket. Instead of using the built-in model monitoring capabilities
    and features discussed in the previous section, we can also download the collected
    ML inference endpoint data from the S3 bucket and analyze it directly in a notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: It is still recommended to utilize the built-in model monitoring capabilities
    and features of SageMaker. However, knowing this approach would help us troubleshoot
    any issues we may encounter while using and running the automated solutions available
    in SageMaker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to use a variety of Python libraries to process, clean,
    and analyze the collected ML inference data in S3:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new Notebook by clicking the **File** menu and choosing **Notebook**
    from the list of options under the **New** submenu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Note that we will be creating the new notebook inside the `CH08` directory beside
    the other notebook files we created in the previous sections of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the `Data Science` (option found under **SageMaker image**)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Python 3`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`No script`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Select** button afterward.
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on the tab name of the new Notebook and select `05 - Analyzing the
    Captured Data.ipynb` under **New Name**. Click the **Rename** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we have created our new notebook, let’s use the `%store` magic from
    `s3_bucket` and `capture_upload_path`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE403]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE404]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Wait! Where did `capture_upload_path` come from? In the *Enabling data capture
    and simulating predictions* section, we initialized `capture_upload_path` and
    set its value to the S3 path where the captured data (of **SageMaker Model Monitor**)
    will be stored.
  prefs: []
  type: TYPE_NORMAL
- en: 'Get the S3 path of each of the generated `jsonl` files containing the input
    and output data of the inference requests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE405]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE406]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE407]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE408]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE409]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE410]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE411]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `captured` directory using the `mkdir` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE412]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, use the `aws s3 cp` command to copy each of the generated `jsonl` files
    to the `captured` directory we just created in the previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE413]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE414]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE415]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `load_json_file()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE416]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE417]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE418]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE419]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE420]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE421]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the JSON values from each of the downloaded `jsonl` files inside the
    `captured` directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE422]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE423]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE424]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE425]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE426]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE427]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE428]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE429]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `pip` to install the `flatten-dict` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE430]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we will see in the succeeding set of steps, the `flatten-dict` package is
    useful in “flattening” any nested dictionary structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Test the `flatten()` function from the `flatten-dict` library on the first
    entry stored in the `all_json` list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE431]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE432]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE433]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should give us a flattened structure similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE434]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We will use `flatten()` shortly to convert the nested JSON values stored in
    `all_json` into “flattened” JSON values. This list of “flattened” JSON values
    will then be converted into a **pandas** **DataFrame** (which we will process
    and analyze in later steps).
  prefs: []
  type: TYPE_NORMAL
- en: 'Flatten each of the JSON values stored in the `all_json` list using the following
    block of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE435]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE436]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE437]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE438]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE439]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, load the flattened structure into a pandas DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE440]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE441]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE442]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should yield a DataFrame similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.14 – DataFrame containing the collected monitoring data  ](img/B18638_08_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.14 – DataFrame containing the collected monitoring data
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see the collected endpoint data flattened inside a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s clean things up a bit by extracting the *x* and *y* values from
    the DataFrame column, `captureData.endpointInput.data`, which contains the input
    request data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE443]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After that, let’s extract the `label` value from the DataFrame column, `captureData.endpointOutput.data`,
    which contains the output response data. Store the `label` values inside a new
    column called `predicted_label`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE444]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s prepare the `clean_df` DataFrame, which only contains three columns from
    the original `DataFrame` – `predicted_label`, `x`, and `y`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE445]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE446]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should give us a DataFrame similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.15 – DataFrame containing the values for predicted_label, x, and
    y ](img/B18638_08_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.15 – DataFrame containing the values for predicted_label, x, and y
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that some values of the `y` column are integers, while some
    values are in floating-point format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s typecast the values stored in the `clean_df` DataFrame using the
    `astype` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE447]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE448]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE449]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE450]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE451]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE452]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should give us a DataFrame similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.16 – Values for x and y cast into floating-point values ](img/B18638_08_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.16 – Values for x and y cast into floating-point values
  prefs: []
  type: TYPE_NORMAL
- en: Now, everything is in floating-point format under the `x` and `y` columns.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we can run different types of analysis, such as computing different
    types of statistics manually, similar to what is performed automatically by **SageMaker
    Model Monitor**. We can also use this approach to troubleshoot data encoding issues
    encountered by the Model Monitor processing job when analyzing the collected data,
    similar to what we have at [https://github.com/aws/sagemaker-python-sdk/issues/1896](https://github.com/aws/sagemaker-python-sdk/issues/1896).
  prefs: []
  type: TYPE_NORMAL
- en: Deleting an endpoint with a monitoring schedule
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we are done using our ML inference endpoint, let’s delete it, along
    with the attached monitors and monitoring schedules.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to list all the attached monitors of our ML inference endpoint
    and delete any attached monitoring schedules, along with the endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new Notebook by clicking the **File** menu and choosing **Notebook**
    from the list of options under the **New** submenu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Note that we will be creating the new notebook inside the `CH08` directory beside
    the other notebook files we created in the previous sections of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the `Data Science` (option found under **SageMaker image**)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Python 3`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`No script`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Select** button afterward.
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on the tab name of the new Notebook and select `06 - Deleting an
    Endpoint with a Monitoring Schedule.ipynb` under **New Name**. Click the **Rename**
    button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we have our new notebook ready, let’s use the `%store` magic from
    IPython to load the stored variable value for `endpoint_name`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE453]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize the `Predictor` instance and attach it to an existing ML inference
    endpoint using the following block of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE454]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE455]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE456]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE457]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE458]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE459]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE460]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE461]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE462]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE463]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s quickly list any attached monitors before deleting them in the next step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE464]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE465]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE466]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we used the `__dict__` attribute to inspect the properties of the monitor
    instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use the `delete_monitoring_schedule()` method to delete each of the monitors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE467]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE468]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should yield an output similar to `Deleting Monitoring Schedule with name:
    monitor-HWFEL`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s delete the inference endpoint using the `delete_endpoint()`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE469]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Make sure that you also stop the execution of any running cells in the notebooks
    that were used in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have finished working on the hands-on solutions of this chapter,
    it is time we clean up and turn off any resources we will no longer use. Follow
    these steps to locate and turn off any remaining running instances in **SageMaker
    Studio**:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the **Running Instances and Kernels** icon in the sidebar, as highlighted
    in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.17 – Turning off the running instance ](img/B18638_08_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.17 – Turning off the running instance
  prefs: []
  type: TYPE_NORMAL
- en: Clicking the **Running Instances and Kernels** icon should open and show the
    running instances, apps, and terminals in SageMaker Studio.
  prefs: []
  type: TYPE_NORMAL
- en: Turn off all running instances under **RUNNING INSTANCES** by clicking the **Shutdown**
    button for each of the instances, as highlighted in the preceding screenshot.
    Clicking the **Shutdown** button will open a popup window verifying the instance
    shutdown operation. Click the **Shut down all** button to proceed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that you close the open notebook tabs in the **Editor** pane. In some
    cases, SageMaker will automatically turn on an instance when it detects that there
    are open notebook tabs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure that you check and delete all running inference endpoints under **SageMaker
    resources** as well (if any):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.18 – Checking the list of running inference endpoints ](img/B18638_08_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.18 – Checking the list of running inference endpoints
  prefs: []
  type: TYPE_NORMAL
- en: To check if there are running inference endpoints, click the **SageMaker resources**
    icon, as highlighted in the preceding screenshot, and then select **Endpoints**
    from the list of options in the drop-down menu.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, open the **File** menu and select **Shut down** from the list of options
    available. This should ensure that all running instances inside SageMaker Studio
    have been turned off as well.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that this cleanup operation needs to be performed after using **SageMaker
    Studio**. These resources are not turned off automatically by SageMaker, even
    during periods of inactivity.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we utilized the model registry available in SageMaker to register,
    organize, and manage our ML models. After deploying ML models stored in the registry,
    we used **SageMaker Model Monitor** to capture data and run processing jobs that
    analyze the collected data and flag any detected issues or deviations.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will focus on securing ML environments and systems using
    a variety of strategies and solutions. If you are serious about designing and
    building secure ML systems and environments, then the next chapter is for you!
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information on the topics that were covered in this chapter, feel
    free to check out the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*SageMaker Model Registry – Viewing the Deployment History* ([https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-deploy-history.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-deploy-history.xhtml))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*SageMaker Model Monitor – Monitor models for data and model quality, bias,
    and explainability* ([https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.xhtml))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*SageMaker Python SDK — Amazon SageMaker Model Monitor* ([https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.xhtml](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.xhtml))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
