["```py\n> sms_raw <- read.csv(\"sms_spam.csv\") \n```", "```py\n> str(sms_raw) \n```", "```py\n'data.frame':    5559 obs. of  2 variables:\n $ type: chr  \"ham\" \"ham\" \"ham\" \"spam\" ...\n $ text: chr  \"Hope you are having a good week. Just checking in\"\n\"K..give back my thanks.\" \"Am also doing in cbe only. But have to\npay.\" \"complimentary 4 STAR Ibiza Holiday or £10,000 cash needs your\nURGENT collection. 09066364349 NOW from Landline not to lose out\"|\n__truncated__ ... \n```", "```py\n> sms_raw$type <- factor(sms_raw$type) \n```", "```py\n> str(sms_raw$type) \n```", "```py\n Factor w/ 2 levels \"ham\",\"spam\": 1 1 1 2 2 1 1 1 2 1 ... \n```", "```py\n> table(sms_raw$type) \n```", "```py\n ham spam\n4812 747 \n```", "```py\n> sms_corpus <- VCorpus(VectorSource(sms_raw$text)) \n```", "```py\n> print(sms_corpus) \n```", "```py\n<<VCorpus>>\nMetadata:  corpus specific: 0, document level (indexed): 0\nContent:  documents: 5559 \n```", "```py\n> inspect(sms_corpus[1:2]) \n```", "```py\n<<VCorpus>>\nMetadata:  corpus specific: 0, document level (indexed): 0\nContent:  documents: 2\n[[1]]\n<<PlainTextDocument>>\nMetadata:  7\nContent:  chars: 49\n[[2]]\n<<PlainTextDocument>>\nMetadata:  7\nContent:  chars: 23 \n```", "```py\n> as.character(sms_corpus[[1]]) \n```", "```py\n[1] \"Hope you are having a good week. Just checking in\" \n```", "```py\n> lapply(sms_corpus[1:2], as.character) \n```", "```py\n$'1'\n[1] \"Hope you are having a good week. Just checking in\"\n$'2'\n[1] \"K..give back my thanks.\" \n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus,\n    content_transformer(tolower)) \n```", "```py\n> as.character(sms_corpus[[1]]) \n```", "```py\n[1] \"Hope you are having a good week. Just checking in\" \n```", "```py\n> as.character(sms_corpus_clean[[1]]) \n```", "```py\n[1] \"hope you are having a good week. just checking in\" \n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) \n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus_clean,\n    removeWords, stopwords()) \n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation) \n```", "```py\n> removePunctuation(\"hello...world\") \n```", "```py\n[1] \"helloworld\" \n```", "```py\n> replacePunctuation <- function(x) {\n    gsub(\"[[:punct:]]+\", \" \", x)\n  } \n```", "```py\n> library(SnowballC)\n> wordStem(c(\"learn\", \"learned\", \"learning\", \"learns\")) \n```", "```py\n[1] \"learn\"   \"learn\"   \"learn\"   \"learn\" \n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument) \n```", "```py\n> sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) \n```", "```py\n> sms_dtm <- DocumentTermMatrix(sms_corpus_clean) \n```", "```py\n> sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(\n    tolower = TRUE,\n    removeNumbers = TRUE,\n    stopwords = TRUE,\n    removePunctuation = TRUE,\n    stemming = TRUE\n)) \n```", "```py\n> sms_dtm \n```", "```py\n<<DocumentTermMatrix (documents: 5559, terms: 6559)>>\nNon-/sparse entries: 42147/36419334\nSparsity           : 100%\nMaximal term length: 40\nWeighting          : term frequency (tf) \n```", "```py\n> sms_dtm2 \n```", "```py\n<<DocumentTermMatrix (documents: 5559, terms: 6961)>>\nNon-/sparse entries: 43221/38652978\nSparsity           : 100%\nMaximal term length: 40\nWeighting          : term frequency (tf) \n```", "```py\nstopwords = function(x) { removeWords(x, stopwords()) } \n```", "```py\n> sms_dtm_train <- sms_dtm[1:4169, ]\n> sms_dtm_test  <- sms_dtm[4170:5559, ] \n```", "```py\n> sms_train_labels <- sms_raw[1:4169, ]$type\n> sms_test_labels  <- sms_raw[4170:5559, ]$type \n```", "```py\n> prop.table(table(sms_train_labels)) \n```", "```py\n ham      spam\n0.8647158 0.1352842 \n```", "```py\n> prop.table(table(sms_test_labels)) \n```", "```py\n ham      spam\n0.8683453 0.1316547 \n```", "```py\n> wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE) \n```", "```py\n> spam <- subset(sms_raw, type == \"spam\") \n```", "```py\n> ham <- subset(sms_raw, type == \"ham\") \n```", "```py\n> wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))\n> wordcloud(ham$text, max.words = 40, scale = c(3, 0.5)) \n```", "```py\n> findFreqTerms(sms_dtm_train, 5) \n```", "```py\n> sms_freq_words <- findFreqTerms(sms_dtm_train, 5) \n```", "```py\n> str(sms_freq_words) \n```", "```py\n chr [1:1137] \"£wk\" \"abiola\" \"abl\" \"abt\" \"accept\" \"access\" \"account\" \"across\" \"act\" \"activ\" ... \n```", "```py\n> sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]\n> sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words] \n```", "```py\n> convert_counts <- function(x) {\n    x <- ifelse(x > 0, \"Yes\", \"No\")\n} \n```", "```py\n> sms_train <- apply(sms_dtm_freq_train, MARGIN = 2,\n    convert_counts)\n> sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2,\n    convert_counts) \n```", "```py\n> sms_classifier <- naiveBayes(sms_train, sms_train_labels) \n```", "```py\nThere were 50 or more warnings (use warnings() to see the first 50) \n```", "```py\n> warnings() \n```", "```py\nWarning messages:\n1: naive_bayes(): Feature £wk – zero probabilities are present. Consider Laplace smoothing.\n2: naive_bayes(): Feature 60 biola – zero probabilities are present. Consider Laplace smoothing.\n3: naive_bayes(): Feature abl – zero probabilities are present. Consider Laplace smoothing.\n4: naive_bayes(): Feature abt – zero probabilities are present. Consider Laplace smoothing.\n5: naive_bayes(): Feature accept – zero probabilities are present. Consider Laplace smoothing. \n```", "```py\n> sms_test_pred <- predict(sms_classifier, sms_test) \n```", "```py\n> library(gmodels)\n> CrossTable(sms_test_pred, sms_test_labels,\n    prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,\n    dnn = c('predicted', 'actual')) \n```", "```py\nTotal Observations in Table:  1390 \n\n             | actual \n   predicted |       ham |      spam | Row Total |\n-------------|-----------|-----------|-----------|\n         ham |      1201 |        30 |      1231 |\n             |     0.864 |     0.022 |           |\n-------------|-----------|-----------|-----------|\n        spam |         6 |       153 |       159 |\n             |     0.004 |     0.110 |           |\n-------------|-----------|-----------|-----------|\nColumn Total |      1207 |       183 |      1390 |\n-------------|-----------|-----------|-----------| \n```", "```py\n> sms_classifier2 <- naiveBayes(sms_train, sms_train_labels,\n    laplace = 1) \n```", "```py\n> sms_test_pred2 <- predict(sms_classifier2, sms_test) \n```", "```py\n> CrossTable(sms_test_pred2, sms_test_labels,\n    prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,\n    dnn = c('predicted', 'actual')) \n```", "```py\nTotal Observations in Table:  1390 \n             | actual \n   predicted |       ham |      spam | Row Total |\n-------------|-----------|-----------|-----------|\n         ham |      1202 |        28 |      1230 |\n             |     0.865 |     0.020 |           |\n-------------|-----------|-----------|-----------|\n        spam |         5 |       155 |       160 |\n             |     0.004 |     0.112 |           |\n-------------|-----------|-----------|-----------|\nColumn Total |      1207 |       183 |      1390 |\n-------------|-----------|-----------|-----------| \n```"]