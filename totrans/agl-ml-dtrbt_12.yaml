- en: '*Chapter 9*: Forecasting and Time Series Modeling'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will understand what time series are and will see how DataRobot
    can be used to model them. Time series modeling is becoming increasingly useful
    in businesses. However, the challenges associated with forecasting make it quite
    challenging for many skilled data scientists to successfully carry out time series
    modeling, and this form of modeling could also be extremely time-consuming. DataRobot
    provides an automated process that enables data scientists to carry out time series
    projects in an effective and efficient fashion. In this chapter, we will introduce
    the concept of forecasting, stressing its commercial importance and inherent challenges,
    and illustrate how DataRobot can be used to build its models.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will have learned how to utilize DataRobot
    in building time series forecasting models. In addition, we will look at making
    predictions with these models. We go further by building models for multi-series
    time series as part of the advanced topics. Here are the main topics to be covered
    in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Conceptual introduction to time series forecasting and modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining and setting up time series projects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building time series forecasting models and understanding their model outcomes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making predictions with time series models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced topics in time series modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some parts of this chapter require access to the DataRobot software and some
    tools for data manipulation. Most of the examples deal with small datasets and
    therefore can be handled via Excel. The dataset that we will be using in this
    chapter is described next.
  prefs: []
  type: TYPE_NORMAL
- en: Appliances energy prediction dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This dataset can be accessed at the *University of California Irvine* (*UCI*)
    Machine Learning Repository ([https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction#](https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction#)).
  prefs: []
  type: TYPE_NORMAL
- en: Dataset citation
  prefs: []
  type: TYPE_NORMAL
- en: '*Luis M. Candanedo*, *Véronique Feldheim*, *Dominique Deramaix*, *Data driven
    prediction models of energy use of appliances in a low-energy house*, *Energy
    and Buildings*, *Volume 140*, *1 April 2017*, *Pages 81-97*, *ISSN 0378-7788*.'
  prefs: []
  type: TYPE_NORMAL
- en: This dataset captures temperature and humidity in various rooms in a house and
    in the outside environment, along with energy consumption by various devices over
    time. The data is captured every 10 minutes. This is a typical example of a time
    series dataset. Data is provided in `.csv` format and the site also provides descriptions
    of the various features. All features in this dataset are numeric features. The
    dataset also includes two random variables to make the problem interesting.
  prefs: []
  type: TYPE_NORMAL
- en: Conceptual introduction to time series forecasting modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The dynamic nature of the commercial environment makes time a pivot resource
    for business success. As a result, businesses need to account for the time factor
    in their decision-making. Changes occur within commercial settings at a high pace,
    which makes it pertinent for organizations to take rapid yet considered actions.
    Analytic technology provides organizations with tools that enable forecasting
    of the future so that decision-makers have crucial time in hand to ensure their
    decision aligns with their organizational objectives. Organizations use time-specific
    data to predict the volume of sales in a future period. Other writers have differentiated
    time series modeling from forecasting models. In this chapter, we have used the
    term interchangeably and consider **time series forecasting** to involve the use
    of advanced analytics to gain insights that guide business decisions leveraging
    time-based data.
  prefs: []
  type: TYPE_NORMAL
- en: Time series forecasting supports numerous aspects of business planning. With
    forecasting, human and other forms of resource planning can be optimized to ensure
    that expected outcomes are realized. Through forecasting, cash flow, profit, and
    budgeting projections are more rigorously established, thereby mitigating human
    bias. Forecasting sales could be influenced by several factors that are controllable
    and non-controllable. Certain consumer factors that change with time tend to affect
    the volume of sales. These factors include changes in population, customer taste,
    and interests. In addition, demand is sensitive to broader economic variables,
    such as inflation, that also change with time. As a result, it becomes pertinent
    to use some features that could act as proxies for these consumer and economic
    variables in addition to **lagged** or historic sales. Because some of these variables
    are challenging to acquire, analysts tend to be limited to a few historic values
    and volumes in modeling future outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Although a detailed discussion on time series is out of the scope of this book,
    it is, however, pertinent to appreciate that the properties of modeling time series
    make them more challenging to work with. In addition to difficulties with other
    forms of predictive modeling discussed in previous chapters of this book, time
    series modeling comes with additional challenges. One of the assumptions of linear
    regression modeling is that of independence of observations, that is, that observations
    or data rows are independent. However, this assumption is inevitably broken with
    time series modeling. Within time series, **autocorrelation** occurs naturally,
    as observations are similar across different time periods. It is also possible
    that highly corrected observations don't occur successively, in which case **seasonality**
    occurs. Series are considered seasonal when observations across a fixed time frame
    have higher levels of correlation. Indeed, these are periodic fluctuations in
    observations. A similar volume of sales of flight tickets during holiday periods
    brings this to life. Seasonality could indeed occur yet fails to follow a fixed
    time frame, described as **cyclicity**. Qualifying cycles generally require considerably
    larger datasets than other properties of series as cyclicity is mostly related
    to external factors such as macroeconomic or political changes within the business
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: Autocorrelation also gives rise to **linearity**, a concept that describes an
    overarching trend where consecutive observations are similar, albeit changing
    in such a way that they follow a linear trend. Due to this linear trend, albeit
    sometimes with some integrated fluctuations, the mean of specific time frames
    will follow a pattern but is unlikely to be the same, hence the use of **moving
    average** (**MA**) and **autoregression** approaches to represent time series.
    However, series can still be characterized by the extent to which their statistical
    properties change over time. They are considered **stationary** when they have
    a constant mean and variance that are independent of time. What is most interesting,
    albeit problematic statistically, is that some time series data has a combination
    of these properties. A good example is the volume of flights. Though gradually
    increasing over time, being seasonal, during an economic downturn this falls generally.
    In this example, we can see elements of seasonality, cyclicity, and linearity.
  prefs: []
  type: TYPE_NORMAL
- en: Another concept that sometimes gets lost in the details is that of **actionability**.
    Actionability being the ability of stakeholders to act because of an analysis
    or a model's outcome, it is very common for data scientists to focus on the accuracy
    of predictions. While accuracy is important, what is more important is to provide
    actionable guidance to decision-makers. A forecast that enables you to take action
    today is more valuable than a forecast that is more accurate but not actionable.
    Care must be taken while defining the forecasting problem to ensure the actionability
    of the model being developed.
  prefs: []
  type: TYPE_NORMAL
- en: The foregone conversation in this section highlights the properties that make
    time series modeling more challenging for typical data scientists. DataRobot has
    developed unique processes that enable data scientists, including those with limited
    statistical exposure, to create complex yet robust time series models. In the
    subsequent section, we will look at how to define and set up time series problems
    in DataRobot.
  prefs: []
  type: TYPE_NORMAL
- en: Defining and setting up time series projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 4*](B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087), *Preparing
    Data for DataRobot*, through to [*Chapter 8*](B17159_08_Final_NM_ePub.xhtml#_idTextAnchor116),
    *Model Scoring and Deployment*, we explored the creation, understanding, scoring,
    and deployment of basic models in DataRobot. We saw that DataRobot automatically
    built several models for us and we could then score a dataset using these built
    models. Further, after we have chosen a model that best aligns with our needs,
    DataRobot provides us a process to deploy our selected model. Due to the difference
    between time series modeling and other forms of predictive modeling, we will explore
    in this section how to mitigate problems by effectively defining and setting up
    time series projects in DataRobot.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset we will use to explore the use of time series modeling with DataRobot
    is the Appliances energy prediction dataset that we explored in [*Chapter 4*](B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087),
    *Preparing Data for DataRobot*. The goal of the project is to predict energy usage.
    This energy usage time series dataset has 4 and a half months' worth of 10-minute
    readings from differing data sources. First, the data involved room temperature
    and humidity in a house. These were monitored using a wireless sensor network
    and the data was stored every 10 minutes. Each of the nine rooms in the house
    had their readings for temperature and humidity stored for the time frame. Second,
    there was external data that provided a nearby airport (public source) detailed
    information pertaining to weather information outside the house, again with a
    10-minute interval. This included wind speed, visibility, dew point, pressure,
    and humidity. This information was merged with the data using date and time. In
    addition, appliances and light usage aligned to date and time were attached to
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within this dataset, it is easy to see that the goal of this time series prediction
    is predicting energy usage. The immediate influencing variables are the temperature
    and atmospheric pressure within the house; however, the external data from the
    weather outside the house is important. We created features calculating the average
    conditions across the nine rooms in the house. In addition, we engineered features
    that captured the difference between the mean room and the external temperature,
    as well as the difference between the mean room and external pressure. Since we
    have two time series (appliance usage and light usage), we will approach this
    problem in two ways. First, as a `.csv` file, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Choosing a target variable for time series'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.1 – Choosing a target variable for time series
  prefs: []
  type: TYPE_NORMAL
- en: 'The project is named `Energy_Prediction` and the target variable selected is
    `total_energy` (the sum of light and appliance usage). We proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: After selecting a target variable, we select a time variable and the nature
    of the time-based modeling. Clicking the `date` feature, which specifies the date
    and times of all readings, as illustrated in the following screenshot:![Figure
    9.2 – Choosing a time-aware function and time variable
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17159_09_02.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 9.2 – Choosing a time-aware function and time variable
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once the **Set up time-aware modeling** button is clicked and the time feature
    is selected, the platform requests the type of time-awareness model to be built.
    There are two options—**Automated time series forecasting with backtesting** and
    **Automated machine learning with backtesting**, as described next:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Automated time series forecasting with backtesting**—This option considers
    previous data in predicting future data. With time series, there is a need to
    forecast multiple future points. A case in point for this type of time-aware project
    could be estimating departmental stores'' daily sales for the next month using
    data from their last year''s sales.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automated machine learning with backtesting**—The automated machine learning
    option, sometimes referred to as **out-of-time validation**, basically creates
    time-based features in a row and then uses a typical predictive model that predicts
    a target variable for that row. Here, we do not use the typical cross-validation
    scheme; instead, this approach employs older data for training and holds back
    newer data for backtesting. Our project''s context problem falls within the forecasting
    category type, so this option is selected, as seen in the following screenshot:'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Time-aware modeling options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.3 – Time-aware modeling options
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have selected the **Automated time series forecasting with backtesting**
    option, we are presented with a **Time-Aware Modeling** options tab (see *Figure
    9.3*). Here, a few options are to be carefully selected. We express how far back
    the model draws data to make predictions and also how far forward the model makes
    predictions for. Let''s first consider the **Feature Derivation Window** option.
    This **rolling window** highlights a lag upon which features and statistics for
    time series models are derived in relation to the time from which a forecast is
    made (**forecast point**). The rolling window is expressed in relation to the
    forecast point and automatically moves forward with the passage of time. In an
    ideal situation, this window should cover a seasonal period in your data. Essentially,
    this window typically answers the question: *How far back does the data our model
    uses to make predictions stretch?* Also, there should be enough time between the
    end of the window and your forecasting time to cater for any data ingest delays
    still limiting this time gap, ensuring the data is recent enough. This period
    is known as the **blind history**. In our case, we have assumed that an hour would
    be enough time to allow any blind history, so set the gap before the forecasting
    point to 60 minutes. Considering our data is limited to 4 and a half months, seasonality
    within the context of our problem would be day and night usage. Accordingly, we
    have set our rolling window to 2 days (2,880 minutes), which, when accounting
    for the initial 60-minute forecast point gap, amounts to 2,940 minute'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second consideration is for the **Forecast Window** option. This defines,
    in relation to the forecast point, how far in the future we are predicting. This
    has two elements; first, when the prediction starts. The predictions should provide
    enough time for actions to be taken yet not be too far in the future to ensure
    these predictions are accurate enough. Secondly, we select our prediction end.
    This is dependent on the start point as well as the nature of our problem. So,
    this aspect answers the question: *How far forward should predictions be made?*
    For the problem at hand, we have selected an **operationalization gap**, a gap
    between the forecast point and the start of the prediction window of 1 day (1,440
    minutes). Also, the rolling window is set at 1 day, which in consideration of
    our operationalization gap becomes 2,880 minutes.'
  prefs: []
  type: TYPE_NORMAL
- en: Having set up the time series forecasting project in this section, we will now
    explore the processes around building the models, from understanding feature lists
    and their distributions to looking at their impacts on evaluating models.
  prefs: []
  type: TYPE_NORMAL
- en: Building time series forecasting models and understanding their model outcomes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to projects we looked at in [*Chapter 4*](B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087),
    *Preparing Data for DataRobot*, through to [*Chapter 8*](B17159_08_Final_NM_ePub.xhtml#_idTextAnchor116),
    *Model Scoring and Deployment*, once we have finished with the initial configurations,
    we scroll up and click on the **Start** button. By doing this, DataRobot automatically
    builds time series models for this project. Before we evaluate the models, it
    would be useful to understand the nature of the features the platform extracts.
    DataRobot extracts features from the data that differ considerably from those
    of other prediction models, as is evident in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Feature lists'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.4 – Feature lists
  prefs: []
  type: TYPE_NORMAL
- en: 'The lists shown under the **Feature Lists** tab are constructed as part of
    **exploratory data analysis** (**EDA**) and itemize differing lists of features
    that DataRobot employs in creating models. Many of the feature lists involve **derived
    features**, which are created automatically based on properties of time series.
    A further discussion on derived features will be carried out later in this section.
    It is easy to see that some of the lists involve features that are extracted from
    the original data (for example, **Time Series Extracted Features**). Others involve
    features created solely from dates, while some are assessed as informative. Most
    lists appear to be combinations of differing types (for example, **Time Series
    Informative Features**). Importantly, the feature lists provide the descriptions
    as well as the number of features for each feature list name. Feature lists that
    could be pivotal are presented as part of the **Leaderboard** feature, as illustrated
    in the following screenshot, which guides our final model choice:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Model leaderboard'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.5 – Model leaderboard
  prefs: []
  type: TYPE_NORMAL
- en: The **Leaderboard** feature offers insights into models that have been built
    for a DataRobot project. It provides information regarding model names and **identifiers**
    (**IDs**), their accuracy metrics, and their types, versions, and sample sizes
    for the model development. With time series modeling, however, there are some
    differences, as noted next. Firstly, the sample size is present in data ranges.
    This is due to the time-based nature of time series datasets. Unlike other modeling
    forms, the time order of the data does affect outcomes; as a result, data is selected
    in time ranges. In this case, as can be seen in *Figure 9.5*, our models were
    built using 3 months', 21 hours', and 51 minutes' worth of data. Secondly, instead
    of the **Validation** and **Cross-Validation** columns, we have the **Backtest
    1** and **All Backtests** columns. The backtests follow logically from the discussion
    regarding the sample size (see [*Chapter 6*](B17159_06_Final_NM_ePub.xhtml#_idTextAnchor104),
    *Model Building with DataRobot*). The backtests provide an evaluation of the model
    performance on a subset of the data. However, unlike a typical validation, the
    data is time-ordered, and the size and number of backtests can be altered as needed.
    We have used the default backtest setting for this example project so that the
    data was partitioned in such a way that only one backtest partition was available
    for modeling. Finally, with time series modeling projects, there appear to be
    more feature lists. As with other predictive project types, the models could be
    ordered or selected using any of the columns on the **Leaderboard** feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a number of metrics against which time series forecasting models
    could be assessed. This, of course, depends on the model. For regression-type
    outcomes, some advocate the use of **Root Mean Square Error** (**RMSE**). The
    nature of the problem remains critical in determining the metrics for assessment.
    That said, the role of the **baseline model** on the leaderboard is crucial to
    evaluating other models. The baseline model employs the most recent value in making
    its predictions. As such, comparing models with the baseline prediction blueprint
    plays a pivotal role in the model evaluation as it somewhat answers the question:
    *To what extent are our models better than a naïve prediction from the most recent
    data?* DataRobot provides the **Mean Absolute Scaled Error** (**MASE**), which
    compares the **Mean Absolute Error** (**MAE**) of models of interest with those
    of the baseline model. For instance, the **Eureqa Generalized Additive Model (250
    Generations)** model, as presented in the following screenshot, has a comparative
    ratio of about 0.76 for **Backtest 1**. This suggests that the Eureqa model is
    about 24% better than the baseline. Since the **Holdout** metric could highlight
    considerable changes within the data, it should be included in model evaluation
    but not used in isolation. Other indications when evaluating models are covered
    within the *Advanced topics in time series modeling* section of this chapter.
    Model names could be clicked to provide elaborate insights about the data and
    its processes. We now turn to those we consider unique to time series forecasting,
    using the **Eureqa Generalized Additive Model (250 Generations)** example here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6 – Impact of original features'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.6 – Impact of original features
  prefs: []
  type: TYPE_NORMAL
- en: The **Understand** tab presents us with **Feature Impact**, **Feature Effects**,
    **Prediction Explanations**, and **Word Cloud** capabilities, which we have already
    encountered in [*Chapter 7*](B17159_07_Final_NM_ePub.xhtml#_idTextAnchor110),
    *Model Understanding and Explainability*. **Feature Impact** shows the relative
    extent to which features contribute to a model's overall accuracy. A click on
    the **Feature Impact** tab opens the **Original features** page (see *Figure 9.6*).
    The original features are features as they were in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other tab within `total_energy (1440 minute average baseline)`) is seen
    to be a feature constructed based on the stationary nature of the time series,
    as illustrated in the following screenshot. This is because it highlights the
    importance of the average 1,440-minute baseline energy on the accuracy of the
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7 – Impact of derived features'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.7 – Impact of derived features
  prefs: []
  type: TYPE_NORMAL
- en: It is reasonable, as is evident in *Figure 9.7*, that a considerable number
    of derived features appear to be created from the stationary property of time
    series, which on its own could be indicative of this time series being quite stationary.
    That said, caution needs to be exercised on reaching this conclusion because our
    dataset only entails 4 and a half months' worth of data; for instance, our dataset
    only covers January 2016 to May 2016, so does not account for the late Summer,
    Autumn, and early Winter months. As such, seasonality could occur if we were using
    a dataset covering a longer time frame.
  prefs: []
  type: TYPE_NORMAL
- en: DataRobot creates features that capitalize on the properties of time series
    to improve the accuracy of its models. Although not evident in this project, with
    seasonality or cyclicity, DataRobot establishes when periodic variations occur
    and creates features accordingly. Based on this information, it next detects patterns
    of seasonality—for instance, a seasonality that occurs during a time frame could
    be defined either by counting up from the beginning of the time frame or counting
    down from the end of the time frame. As such, the platform could detect and build
    features that, for instance, use energy usage on the last Saturday of March to
    predict energy usage on the last Saturday of April. In a similar fashion, DataRobot
    uses features built on **differencing** to improve model performance. It could
    utilize the average usage during the first week in March as a feature to predict
    usage during the first week of April.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving on to the **Describe** tab, upon opening the **Blueprint** tab, we are
    exposed to the stages involved in the modeling process of time series projects.
    As detailed in the following screenshot, we can quickly appreciate that this is
    not very different from those of other predictive projects encountered in preceding
    chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.8 – Model blueprint'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.8 – Model blueprint
  prefs: []
  type: TYPE_NORMAL
- en: We have now spent time building and understanding time series forecasting models.
    The next logical step is to use our selected model to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Making predictions with time series models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DataRobot provides us with tools to make predictions pain-free. There are two
    approaches to making predictions for time series. For small datasets under 1 **gigabyte**
    (**GB**), predictions could be made using the **Make Predictions** tab on the
    **Leaderboard** feature. This involves setting up and uploading a prediction dataset,
    then scoring it within the **Drag and drop a new dataset** **user interface**
    (**UI**) functionality. For significantly larger datasets, models need to be deployed
    and predictions are made using an **application programming interface** (**API**).
    In this chapter, we will cover the first approach to making predictions. With
    DataRobot, general model deployments and working with APIs are extensively discussed
    in [*Chapter 12*](B17159_12_Final_NM_ePub.xhtml#_idTextAnchor176), *DataRobot
    Python API*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The leaderboard''s drag-and-drop approach to scoring models for time series
    models somewhat differs from those of traditional models, as seen in [*Chapter
    8*](B17159_08_Final_NM_ePub.xhtml#_idTextAnchor116), *Model Scoring and Deployment*.
    When the **Make Predictions** tab is opened, DataRobot briefly outlines the recency
    and quantity of the data needed to make predictions. This outline is mostly consistent
    with the forecasting windows established as part of the configuration during the
    model development, as well as features derived. As the prediction process shows
    in the following screenshot, the prediction dataset requires a minimum of 4,320
    minutes of historic data outside of the 60 minutes prior to the forecasting point.
    In addition, when models include derived features that involve features in earlier
    time periods, the earlier time period is also included in the dataset requirement.
    Because the model in question has 24-hours''-difference derived features, this
    increases the requirement to 5,820 minutes. This 5,820-minute requirement includes
    an initial 60-minute forecast point gap window, 4,320-minute base prediction requirement
    data, and 1,440 minutes added on for the derived differencing features. This enables
    the model to predict 2,880 minutes in advance of the forecasting point after the
    1,440-minute operationalization gap. Some of these features are presented here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.9 – Make Predictions window'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.9 – Make Predictions window
  prefs: []
  type: TYPE_NORMAL
- en: 'To make predictions, if the data format is consistent with the training data,
    proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Import data**, which allows the data to be ingested from a local
    source, a **Uniform Resource Locator** (**URL**), оnе оf уоur еxіѕtіng dаtа ѕоurсеѕ,
    оr AI Catalog. If no row is found after the default forecast point, DataRobot
    generates a template. For this to be done, there must be no empty row within the
    forecast window and the template file must meet the upload size limit conditions.
    After the file has been uploaded, DataRobot sets the forecast points and includes
    the rows required to meet the forecast window expectations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Compute predictions** button after uploading the data, as illustrated
    in the following screenshot, since the uploaded prediction file is the most recent,
    without gaps and the fill number of rows expected:![Figure 9.10 – Computing time
    series predictions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17159_09_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 9.10 – Computing time series predictions
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The **Forecast settings** button in *Figure 9.10* provides options for predictions
    where either the forecasting point is not expected to be the most recent or changes
    the range for which predictions are to be made.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To make changes of this nature, click on the **Forecast settings** button,
    which opens the **Forecast Point Predictions** tab by default, as illustrated
    in the following screenshot. This window offers a forecast point slide tab selector,
    which can be configured by either a slide or entering the actual time value. Invalid
    dates are, however, disabled:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.11 – Forecast Point Predictions settings'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.11 – Forecast Point Predictions settings
  prefs: []
  type: TYPE_NORMAL
- en: As alluded to earlier, there is a limit to times that can be selected as a forecast
    point. The forecast point must be less than or equal to the most recent one. In
    the case of this project, this is **2016-05-27 19:00:00:00**, which is the most
    recent data row time, with an operationalization gap of **1440** minutes. A similar
    operation could be carried out to alter the prediction date ranges. The **Forecast
    Range Predictions** feature would ideally be used to validate models as opposed
    to making future predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we highlighted the importance of ensuring our prediction dataset
    for time series models is like that for training models. We went on to make predictions
    and interpreted other outcomes from the model. Next, we will explore more advanced
    topics involving time series modeling with DataRobot.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced topics in time series modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned how to configure, build and make predictions
    with basic time series forecasting models in DataRobot. In the preceding section,
    our attention was focused on building models that have one-time series. However,
    you could have a situation where you might have to make multi-time series predictions.
    Within the context of our energy utilization problem, we might want to forecast
    the usage of lights and appliances. Elsewhere, an energy company might want to
    forecast energy usage for differing cities or households within the same model.
    We will now take a deep dive into solving problems of this nature. Also, we will
    explore future ways other advanced approaches may be used in assessing our time
    series models. Finally, we will acknowledge the role of scheduled events on time
    series and highlight the provisions made by DataRobot to handle this possibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset used for this project highlights the energy usage of lights and
    other appliances. For the earlier project, we totaled up all usage as our target
    variable, but in this project (named `Energy_Prediction_2`), models will be built
    to predict usage for each device type. This dataset now has two series, implying
    timestamps could recur, yet timestamps within each series must be unique. The
    differentiating column, `Device_type`, is the ID for the device type that the
    usage is attributed to. After qualifying the project as being time-aware and choosing
    its type as `Device_type`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.12 – Multi-series time series forecasting setup'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.12 – Multi-series time series forecasting setup
  prefs: []
  type: TYPE_NORMAL
- en: 'For this project, we are interested in further evaluating our models. So, the
    sequel to customizing our forecasting window, within the `5 + Holdout`. The following
    screenshot details the setup for this configuration, and we can see how the training,
    validation, and holdout data is partitioned from the initial data. It is important
    to highlight that to set up the backtests, we must consider any form of seasonality,
    periodicity, and/or cyclicity within the data and ensure that every fold has at
    least one instance of these. This is because every backtest should be a complete
    dataset on its own, so seasonality, periodicity, and cyclicity need to be accounted
    for within each backtest. The validation and gap lengths can also be altered.
    The default length for this project is set to over 13 hours and 9 minutes. You
    can see the configuration here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.13 – Backtest configuration'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.13 – Backtest configuration
  prefs: []
  type: TYPE_NORMAL
- en: 'Having configured backtesting, we then click on **Start** to train the models.
    When models are created, the process of evaluation is like that for single time
    series models. As evident in the following screenshot, we can see the **All Backtests**
    metric, which measures the average performance of a model across all backtests.
    As such, it provides an interesting way to quickly assess not only the model performance
    but also the consistency of the data pattern over time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.14 – Accuracy over time'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.14 – Accuracy over time
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Accuracy Over Time** feature within the model **Evaluate** tab enables
    users to have a visual yet in-depth assessment of their models over time (see
    *Figure 9.14*). Here, the predicted and actual are visually presented. Within
    this window, you can choose a **Series to plot** setting and alter the **Backtest**
    and the **Forecast distance** settings. This view, within the context of a business,
    helps understand if there are periods of poor performance that could imply an
    aspect of a business not represented in the data. The **Forecasting Accuracy**
    window, as shown in the following screenshot, is another important representation
    that suggests how model performance changes as the forecast distance changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.15 – Forecasting Accuracy window'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17159_09_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.15 – Forecasting Accuracy window
  prefs: []
  type: TYPE_NORMAL
- en: The **Forecasting Accuracy** window highlights alterations in models' performance
    as forecasts are made into the future. This view allows us to assess where models'
    performance is similar across time, which is indicative of when models could be
    used within the business. Furthermore, it highlights when the models' performance
    considerably exceeds those of the baseline model when the MASE performance metric
    is used. As illustrated in *Figure 9.15*, the model's performance on **Backtest
    1** seems to begin to be considerably better than the baseline model around the
    +1,960-minute mark. The stability view presents users with the measure of scores
    across time ranges.
  prefs: []
  type: TYPE_NORMAL
- en: With the quest for better-performing models comes a need to adopt some changes
    to modeling paradigms. The default models available for time series modeling might
    just not provide the required performance. In that case, the model repository,
    as explained in [*Chapter 6*](B17159_06_Final_NM_ePub.xhtml#_idTextAnchor104),
    *Model Building with DataRobot*, presents us with options to select traditional
    time series models such as **AutoRegressive Integrated Moving Average** (**ARIMA**)
    and more recent models such as Keras **Long Short-Term Memory** (**LSTM**) and
    **XGBoost** (**XGB**). Depending on the nature of the time series under investigation,
    these modeling approaches sometimes present better performance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have extensively examined how DataRobot could be used to
    build time series models. We briefly discussed the unique opportunities time series
    modeling presents businesses, as well as the challenges it presents for analysts
    and data scientists. We used DataRobot to create both single and multiple time
    series models. We also described how predictions could be made using models built
    by DataRobot. This was followed by a discussion on advanced aspects of DataRobot's
    time series capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting is extremely important to business because of its ability to foretell
    what is likely to occur in the future considering time-dependent variables. Another
    commercially valuable area is the ability to suggest the interest that differing
    clients would have for a wide array of products. This is where recommender systems
    come in.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, [*Chapter 10*](B17159_10_Final_NM_ePub.xhtml#_idTextAnchor139),
    *Recommender Systems*, we look at how DataRobot could be used to build recommender
    engines.
  prefs: []
  type: TYPE_NORMAL
