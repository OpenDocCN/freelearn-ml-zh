- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Power Service Interruptions
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 电力服务中断
- en: In this chapter, we’ll again be looking at a scenario modeled after a real-life
    use case. The examples in this chapter will focus on the post-production maintenance
    and ML model deployment activities that are important for continued IA solution
    operation. The goal of this chapter is to become familiar with model deployments,
    rollbacks, and exporting audit data through SQL.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将再次查看一个基于真实用例的场景。本章中的示例将重点关注对持续IA解决方案操作重要的事后维护和机器学习模型部署活动。本章的目标是熟悉模型部署、回滚和通过SQL导出审计数据。
- en: In this scenario, we’re a power utility company that has an existing ML model
    that’s already in production. This model predicts whether certain regions of the
    power grid will have an outage based on weather indicators, date and time indicators,
    measurements from current power infrastructure, and historical data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个场景中，我们是一家拥有现有机器学习模型并已投入生产的电力公司。该模型根据天气指标、日期和时间指标、当前电力基础设施的测量值和历史数据，预测电力网格的某些区域是否会发生停电。
- en: The IA team wants to use this existing model and build a new model for new automation.
    First, the outage ML model will be regularly called to predict whether heavily
    populated regions will have an outage. If a potential outage is detected, we want
    to then predict which customers are most likely to call the customer service hotline.
    The model to predict customer complaints will be developed as part of this project.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: IA团队希望使用这个现有模型并构建一个新的模型用于新的自动化。首先，停电机器学习模型将定期调用以预测人口密集区域是否会发生停电。如果检测到潜在的停电，我们希望预测哪些客户最有可能拨打客户服务热线。客户投诉预测模型将作为本项目的部分开发。
- en: Once we’ve predicted which customers are likely to call customer service, we
    will send them an SMS informing them of a potential power outage ahead of time.
    The aim of this IA project is to reduce the number of calls to customer service,
    which saves money, reduces phone queue wait times, and improves customer satisfaction.
    The proposal to build this new model and automation has been approved by the governance
    board.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们预测出哪些客户可能会拨打客户服务电话，我们将提前通过短信通知他们可能发生的停电情况。这个IA项目的目标是减少客户服务电话的数量，从而节省资金，减少电话排队等待时间，并提高客户满意度。建立这个新模型和自动化的提案已经得到了治理委员会的批准。
- en: The outage prediction model is maintained by a separate, internal ML team. The
    decision is made to develop and maintain the customer complaints prediction model
    within the IA function as the necessary expertise is present.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 停电预测模型由一个独立的内部机器学习团队维护。决定在IA功能内部开发和维护客户投诉预测模型，因为必要的专业知识已经存在。
- en: 'In this chapter, we’re going to cover the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下主题：
- en: ML model background information
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型背景信息
- en: Solution design
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决方案设计
- en: Handling model deployments
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理模型部署
- en: Exporting data for audit
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导出数据以供审计
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Install SQL Server Management Studio [https://aka.ms/ssmsfullsetup](https://aka.ms/ssmsfullsetup)
    so that you can execute queries against the BP database. SQL Server Management
    Studio is used in *Example 4* and *Example 5*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 安装SQL Server Management Studio [https://aka.ms/ssmsfullsetup](https://aka.ms/ssmsfullsetup)
    以便您可以对BP数据库执行查询。SQL Server Management Studio在*示例4*和*示例5*中使用。
- en: ML model background information
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型背景信息
- en: Let’s analyze the requirements and characteristics of the two ML models (outage
    prediction and customer complaints). This information will help us understand
    the procedure needed to deploy and roll back the models. It will also help us
    determine what options we have to capture ML auditing data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析两个机器学习模型（停电预测和客户投诉）的需求和特征。这些信息将帮助我们了解部署和回滚模型所需的程序。它还将帮助我们确定我们有哪些选项来捕获机器学习审计数据。
- en: Outage prediction model
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 停电预测模型
- en: The **outage prediction** (**OP**) model is already being used elsewhere in
    the utility and is managed by a different internal team. We’ve received the necessary
    approvals to use their ML endpoint for the IA solution.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**停电预测**（**OP**）模型已经在其他地方得到了应用，并由不同的内部团队管理。我们已经获得了使用他们机器学习端点进行IA解决方案的必要批准。'
- en: Consumption and deployment method
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消费和部署方法
- en: The model is hosted on the intranet and is called using an HTTP API. As this
    is a pre-existing model, the deployment method is already determined. A *replacement*
    deployment methodology that requires downtime is used. The ML team will notify
    us when the model will be taken offline for maintenance. For model updates, the
    API endpoint is *overwritten*, meaning that only the latest version of the model
    can ever be called. This means that rolling back by changing the endpoint URL
    is not possible.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 模型托管在内网中，并通过HTTP API调用。由于这是一个预存在的模型，部署方法已经确定。使用需要停机的**替换**部署方法。ML团队将在模型维护时下线时通知我们。对于模型更新，API端点将被**覆盖**，这意味着只能调用模型的最新版本。这意味着通过更改端点URL来回滚是不可能的。
- en: Prediction volumes
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测量
- en: After discussing with project stakeholders, we decide to focus the automation
    on four regions. This will be expanded in further phases of the project. We decide
    on a prediction interval of 30 minutes for every region, from 6:00 AM to 10:00
    PM. Sending SMSs to customers outside of this time frame won’t be effective. This
    adds up to 112 calls to the API per day, which is an acceptable volume for the
    ML team.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在与项目利益相关者讨论后，我们决定将自动化重点放在四个区域。这将在项目的进一步阶段中扩展。我们决定每个区域的预测间隔为30分钟，从早上6:00到晚上10:00。在这个时间范围之外向客户发送短信将不会有效。这总计每天对API的112次调用，这对ML团队来说是可接受的量。
- en: HITL reviews, interface, and SLAs
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: HITL审查、界面和SLA
- en: It’s not possible for anyone outside of experts to review predictions, so it’s
    decided that reviews aren’t needed. There are also no SLAs to meet since this
    isn’t an already existing (nor critical) process. Customers currently aren’t being
    notified ahead of time if there might be an outage. However, we’ve set a target
    to notify customers within 30 minutes of receiving a *potential outage* prediction
    from the OP model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于专家之外的人无法审查预测，因此决定不需要审查。也没有SLA需要满足，因为这不是一个已经存在（也不是关键）的过程。目前，如果可能发生故障，客户不会被提前通知。然而，我们已经设定了一个目标，在从OP模型收到**潜在故障**预测后的30分钟内通知客户。
- en: ML auditing
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ML审计
- en: While server logs can be requested from the ML team, the lead time to receive
    them is undefined because it isn’t something that they have an existing procedure
    or SLA for. Because of this, the IA team decides to retain a copy of the API calls
    to the model in BP. Since they work for public service, the IA team is conscious
    of maintaining an audit trail for their ML calls.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以从ML团队请求服务器日志，但收到它们的提前期是未定义的，因为他们没有现有的程序或SLA。因此，IA团队决定在BP中保留对模型的API调用的副本。由于他们为公共服务工作，IA团队意识到需要维护他们ML调用的审计跟踪。
- en: We’ve finished gathering information about the OP model that’s relevant to the
    IA solution. Let’s look at the customer complaints model next.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经收集了与IA解决方案相关的OP模型的相关信息。让我们接下来看看客户投诉模型。
- en: Customer complaints model
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 客户投诉模型
- en: The **customer complaints** (**CC**) model predicts whether a customer is likely
    to call the customer support hotline based on demographic information, billing
    data, time of day, past calling behavior, and so on. The model will be developed
    and maintained by the IA team. The team decides to build a *binary classification*
    model that predicts between *will call* and *won’t call* using either regression
    or tree-based techniques. These techniques are favored because they have some
    degree of interpretability inherent to them.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**客户投诉**（**CC**）模型根据人口统计信息、账单数据、一天中的时间、过去的通话行为等预测客户是否可能拨打客户支持热线。该模型将由IA团队开发和维护。团队决定构建一个**二元分类**模型，使用回归或基于树的技巧来预测客户是**会拨打**还是**不会拨打**。这些技巧受到青睐，因为它们具有固有的某种程度可解释性。'
- en: Consumption and deployment method
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消耗和部署方法
- en: The IA team decides to deploy the CC ML solution as a native Code Stage that
    will run directly on the Digital Workers themselves. This will be possible because
    of the type of algorithm that is chosen.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: IA团队决定将CC ML解决方案作为原生代码阶段部署，它将直接在数字工作者本身上运行。这将是由于所选算法的类型。
- en: Prediction volumes
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测量
- en: The number of predictions needed depends on the number of residential electrical
    meters (customers) in the region. The largest region has roughly 10,000 customers.
    Assuming that it takes one minute to gather the model’s input data from various
    systems and make the prediction, it would require 334 digital workers to process
    10,000 predictions within 30 minutes, which is unacceptable.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 需要的预测数量取决于该地区住宅电表（客户）的数量。最大的地区大约有10,000名客户。假设从各个系统中收集模型输入数据并做出预测需要一分钟，那么在30分钟内处理10,000个预测将需要334名数字工作者，这是不可接受的。
- en: To bring the amount of time needed to make predictions down to a manageable
    level, the IA team decides to have a completely separate BP Process that gathers
    the necessary input data. This Process will generate predictions for each customer
    in the target regions on a weekly basis. Using a weekly prediction (and not a
    live prediction) is deemed to be a reasonable compromise as the customer data
    that is input to the model doesn’t change regularly.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将预测所需的时间降低到可管理的水平，IA团队决定采用一个完全独立的BP流程来收集必要的数据输入。该流程将每周为目标区域内的每位客户生成预测。使用每周预测（而不是实时预测）被认为是一个合理的折衷方案，因为输入到模型中的客户数据并不经常改变。
- en: The weekly customer complaint prediction results will be saved into a database.
    The saved prediction result can be used by the Process that sends SMSs if an outage
    is predicted for a region.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 每周的客户投诉预测结果将被保存到数据库中。如果预测到某个地区将出现故障，则保存的预测结果可以被发送短信的流程使用。
- en: Let’s assume that there are 20,000 residences in total in the four regions,
    each taking one minute to process. If we run the customer complaints prediction
    Process during off-peak hours, from 9:00 PM to 5:00 AM, it would require 6 digital
    workers to process 20,000 cases per week. After discussing with the business users,
    we are given the green light to run this CC prediction on six digital workers
    that are idle during off-peak hours, improving the overall utilization of the
    workforce.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 假设四个地区总共有20,000个住宅，每个地区处理需要一分钟。如果我们选择在非高峰时段（晚上9:00到早上5:00）运行客户投诉预测流程，那么每周处理20,000个案例将需要6名数字工作者。在与业务用户讨论后，我们获得了在非高峰时段空闲的六名数字工作者上运行此CC预测的绿灯，从而提高了劳动力的整体利用率。
- en: HITL reviews, interface, and SLAs
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: HITL审查、界面和SLA
- en: Human review of predictions is not needed as no one really knows how to predict
    whether someone is apt to call the hotline. There are also no SLAs to complete
    the prediction by, although we have self-imposed criteria of updating a customer’s
    prediction weekly.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有人真正知道如何预测某人是否可能拨打热线电话，因此不需要对预测进行人工审查。尽管我们自行设定了每周更新客户预测的标准，但也没有SLA来完成任务预测。
- en: ML auditing
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ML审计
- en: Auditing is required. Since the ML model is run from Code Stages, the logs must
    be saved into BP.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 需要进行审计。由于ML模型是从代码阶段运行的，因此日志必须保存到BP中。
- en: We’ve finished looking at the two ML models. Let’s summarize the details that
    are relevant to the IA solution. This will inform us of how we can deploy, roll
    back, and retrieve ML logs for auditing.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了对两个ML模型的审查。让我们总结与IA解决方案相关的细节。这将告诉我们如何部署、回滚和检索ML日志以进行审计。
- en: ML model summary
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML模型总结
- en: 'A summary of the ML model characteristics that are relevant to the design and
    operation of the solution is provided in the following table:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格提供了与解决方案设计和操作相关的ML模型特性的总结：
- en: '| **Model** | **Deployment method** | **HITL** **review criteria** | **HITL**
    **review interface** | **HITL** **review SLA** | **ML Auditing** |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **部署方法** | **HITL审查标准** | **HITL审查界面** | **HITL审查SLA** | **ML审计**
    |'
- en: '| OP | Replacement API | N/A | N/A | N/A | In the IA solution |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| OP | 替换API | N/A | N/A | N/A | 在IA解决方案中 |'
- en: '| CC | Code Stage | N/A | N/A | N/A | In the IA solution |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| CC | 代码阶段 | N/A | N/A | N/A | 在IA解决方案中 |'
- en: 'Table 12.1: A summary of the ML model characteristics'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 表12.1：ML模型特性的总结
- en: Solution design
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案设计
- en: We don’t need to consider designing separate Processes and Work Queues for *reviews*
    since reviews aren’t possible for either of the ML models. There’s also no need
    to *link* Work Queue Items between the two ML models as they are independent and
    *communicate* by saving the customer complaint prediction results in a database.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于两种ML模型都不可能进行**审查**，因此我们不需要考虑为**审查**设计单独的流程和工作队列。同样，由于两个ML模型是独立的，并且通过将客户投诉预测结果保存到数据库中**通信**，因此也不需要在两个ML模型之间**链接**工作队列项。
- en: Two main candidates for high-level solution design are possible. The first potential
    design is shown in the following diagram. In this design, we keep the Processes
    and Work Queues separate for the ML portions of the solution. This results in
    a four Process, four Work Queue design. It allows for independent scaling and
    targeted auditing of the ML models directly from the BP user interface. The major
    downsides of this first design are the number of licenses needed and the increased
    complexity of scheduling.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 高级解决方案设计有两个主要候选方案。第一个潜在的设计如下所示图。在这个设计中，我们将解决方案的机器学习部分中的流程和工作队列分开。这导致了一个四流程、四个工作队列的设计。它允许独立扩展并对ML模型直接从BP用户界面进行针对性审计。这种第一个设计的缺点是需要大量的许可证和调度复杂性的增加。
- en: '![Figure 12.1: Potential design 1: Separate Processes and Work Queues for the
    ML portions](img/B18416_12_1.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图12.1：潜在设计1：将ML部分中的流程和工作队列分开](img/B18416_12_1.jpg)'
- en: 'Figure 12.1: Potential design 1: Separate Processes and Work Queues for the
    ML portions'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1：潜在设计1：将ML部分中的流程和工作队列分开
- en: The next potential design is to not separate the ML into separate Processes
    and Work Queues. An example of this second design is shown in the following screenshot.
    With this design, we will need to either query the database manually to extract
    ML audit information or export the Session Logs as CSV and filter them from there.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个潜在的设计是不将ML分成单独的流程和工作队列。以下截图展示了这种第二个设计的例子。使用这种设计，我们可能需要手动查询数据库以提取ML审计信息，或者将会话日志作为CSV导出并从那里过滤。
- en: '![Figure 12.2: Potential design 2: Don’t separate Processes and Work Queues
    for the ML portions](img/B18416_12_2.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图12.2：潜在设计2：不要将ML部分中的流程和工作队列分开](img/B18416_12_2.jpg)'
- en: 'Figure 12.2: Potential design 2: Don’t separate Processes and Work Queues for
    the ML portions'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2：潜在设计2：不要将ML部分中的流程和工作队列分开
- en: Let’s consider the need to *scale* ML predictions separately from its main Process.
    For the OP model, the prediction volumes are low, so there isn’t any reason to
    scale ML independently from the main Process. For the CC model, the bottleneck
    will likely be in retrieving all of the necessary input data from the various
    CRM, customer support, and billing systems. The ML portion only contributes to
    a fraction of the total execution time, and there’s a one-to-one relationship
    between a customer and a prediction, so it isn’t necessary to scale the CC model
    predictions separately.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑需要单独*扩展*ML预测的需求。对于OP模型，预测量很低，所以没有必要从主流程中独立扩展ML。对于CC模型，瓶颈可能在于从各种CRM、客户支持系统和计费系统中检索所有必要的输入数据。ML部分只占总执行时间的很小一部分，并且客户与预测之间存在一对一的关系，因此没有必要单独扩展CC模型的预测。
- en: Next, let’s consider the *auditability* needs. There’s no need to give feedback
    on any reviewed results since reviews aren’t possible in this use case. While
    it would be possible for the customer support team to inform the IA team whether
    someone has actually called following a service interruption, this is something
    that will happen outside of BP.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们考虑*可审计性*需求。在这种情况下，没有必要对任何已审查的结果提供反馈，因为审查是不可能的。虽然客户支持团队可以通知IA团队是否有人在实际服务中断后打电话，但这是在BP之外发生的事情。
- en: There may be a need to allow parties external to the IA team to access Session
    Logs for export. An alternative to exporting data from BP is to query the DB directly.
    The IA team doesn’t anticipate needing to export Session Log data regularly for
    the purpose of ML auditing, or to check the ML logs for specific Sessions or Items,
    so the likelihood of needing to perform exporting actions from the BP user interface
    is low. The IA team decides to perform ML auditing through the BP database. The
    solution design chosen is the simpler one in *Figure 12**.2*.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 可能需要允许IA团队外部的人员访问会话日志以进行导出。从BP导出数据的替代方案是直接查询数据库。IA团队预计不需要定期导出会话日志数据以进行ML审计，或检查特定会话或项目的ML日志，因此从BP用户界面执行导出操作的可能性很低。IA团队决定通过BP数据库执行ML审计。选择的解决方案设计是*图12.2*中更简单的一个。
- en: Handling model deployments
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理模型部署
- en: Imagine that the IA solution has been implemented and is running in production
    already. We receive word from the ML team that the OP model, which is maintained
    by a different internal team, will be updated, and that downtime will occur. Recall
    that only one version of the OP model is live and that previous versions cannot
    be called. Let’s go through an example of what the IA team needs to do on the
    day that the OP model gets updated.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 想象IA解决方案已经实施并已在生产中运行。我们收到来自ML团队的消息，表示由不同内部团队维护的OP模型将进行更新，并且将出现停机时间。回想一下，只有OP模型的一个版本是活跃的，并且不能调用以前的版本。让我们通过一个例子来看看在OP模型更新的那天，IA团队需要做什么。
- en: Example 1 – Outage prediction model deployment
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例1 – 故障预测模型部署
- en: 'In this example, we will go through the steps needed to deploy a new version
    of the OP model for use in BP. Recall that the OP model uses a *replacement* deployment
    strategy. This example has seven high-level steps:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们将通过部署OP模型的新版本到BP中所需的步骤。回想一下，OP模型使用*替换*部署策略。此示例有七个高级步骤：
- en: Importing the `.bprelease` sample (created from the Synchronous Review template).
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入.bprelease样本（从同步审查模板创建）。
- en: Running the Process once to create Session Logs.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行流程一次以创建会话日志。
- en: Retiring the Schedule.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 退役计划。
- en: Waiting for the Sessions to complete.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待会话完成。
- en: Changing the Environment Variable that stores the model version.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更改存储模型版本的环境变量。
- en: Unretiring the Schedule.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 恢复计划。
- en: Running the Process with the new model to create Session Logs.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用新模型运行流程以创建会话日志。
- en: Import the Release
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入发布版本
- en: Let’s import a Release that has been developed based on the design in *Figure
    12**.2*.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们导入基于*图12.2*中设计开发的发布版本。
- en: 'Download the Release from GitHub: [https://github.com/PacktPublishing/Intelligent-Automation-with-Blue-Prism/blob/main/ch12/Ex_1_Outage_Prediction_Model_Deployment.bprelease](https://github.com/PacktPublishing/Intelligent-Automation-with-Blue-Prism/blob/main/ch12/Ex_1_Outage_Prediction_Model_Deployment.bprelease).'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从GitHub下载发布版本：[https://github.com/PacktPublishing/Intelligent-Automation-with-Blue-Prism/blob/main/ch12/Ex_1_Outage_Prediction_Model_Deployment.bprelease](https://github.com/PacktPublishing/Intelligent-Automation-with-Blue-Prism/blob/main/ch12/Ex_1_Outage_Prediction_Model_Deployment.bprelease)。
- en: Import the Release into BP..
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将发布版本导入BP。
- en: Ensure that two Processes, one Object, two Work Queues, two Schedules, three
    Environment Variables, and two Credentials have been imported.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保已导入两个流程、一个对象、两个工作队列、两个计划、三个环境变量和两个凭证。
- en: '![Figure 12.3 – The contents of .bprelease](img/B18416_12_3.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图12.3 – .bprelease的内容](img/B18416_12_3.jpg)'
- en: Figure 12.3 – The contents of .bprelease
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 – .bprelease的内容
- en: Visit *System* | *Security* | *Credentials*. Open the **Ch12 OP Prediction Kill
    Switch** Credential and ensure that the *Access Rights* are granted to the **01
    – Outage Prediction Notification** Process, in addition to the correct Roles and
    Resources.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 *系统* | *安全* | *凭证*。打开**Ch12 OP预测关闭开关**凭证，并确保**01 – 故障预测通知**流程的*访问权限*已授予，以及正确的角色和资源。
- en: Visit *System* | *Security* | *Credentials*. Open the **Ch12 CC Prediction Kill
    Switch** Credential and ensure that the *Access Rights* are granted to the **02
    – Customer Complaint Prediction** Process, in addition to the correct Roles and
    Resources.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 *系统* | *安全* | *凭证*。打开**Ch12 CC预测关闭开关**凭证，并确保**02 – 客户投诉预测**流程的*访问权限*已授予，以及正确的角色和资源。
- en: After importing, we need to run the Process once to generate some Session Log
    data.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 导入后，我们需要运行流程一次以生成一些会话日志数据。
- en: Run the Process
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行流程
- en: 'Execute the Process once from the Control Room so that Session Logs are generated.
    While the Session Logs aren’t needed for this example, they are needed for *Example
    4*:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制室执行流程一次以生成会话日志。虽然会话日志在此示例中不需要，但它们对于*示例4*是必需的：
- en: Run the **01 – Outage Prediction Notification** Process once from the Control
    Room. Wait for the Session to complete.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从控制室运行**01 – 故障预测通知**流程一次。等待会话完成。
- en: Open *Control* | *Queue Management* | *Ch12* | *01 – Outage Prediction Notification*.
    See that four Items, each representing one of the four regions, have been created.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 *控制* | *队列管理* | *Ch12* | *01 – 故障预测通知*。查看已创建四个项目，每个项目代表四个区域之一。
- en: Next, let’s begin deploying the new OP ML model. The first step is to retire
    the Schedule that runs the Process that calls the OP model prediction, *01 – Outage*
    *Prediction Notification*.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们开始部署新的OP ML模型。第一步是退役运行OP模型预测流程的计划，即*01 – 故障预测通知*。
- en: Retire the Schedule
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 退役计划
- en: Two Schedules were imported in the Release. We only need to retire the *Ch12
    Outage Prediction Notification* Schedule, since that’s the one that runs the Process
    which calls the OP prediction model.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在发布中导入了两个计划。我们只需要退役*Ch12停电预测通知*计划，因为那是运行调用OP预测模型的进程的计划。
- en: Under *Control* | *Scheduler*, right-click on the *Ch12 Outage Prediction Notification*
    Schedule and choose *Retire*. You should be able to retire even if there are Sessions
    that are still executing.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在*控制* | *调度器*下，右键单击*Ch12停电预测通知*计划并选择*退役*。即使有会话仍在执行，也应该能够退役。
- en: '![Figure 12.4: Retire the Ch12 Outage Prediction Notification Schedule](img/B18416_12_4.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图12.4：退役Ch12停电预测通知计划](img/B18416_12_4.jpg)'
- en: 'Figure 12.4: Retire the Ch12 Outage Prediction Notification Schedule'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4：退役Ch12停电预测通知计划
- en: After retiring the Schedule, we need to ensure that no active Sessions are running
    the **01 - Outage Prediction** **Notification** Process.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在退役计划后，我们需要确保没有活跃的会话正在运行**01 - 停电预测****通知**进程。
- en: Wait for the Sessions to stop
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 等待会话停止
- en: 'There are a few things we can do here, and they depend on how much time we
    have before the ML model is taken offline. If the ML model will be taken offline
    very shortly, we can trigger the OP Model’s kill switch. This will halt execution
    just prior to calling the ML algorithm. If the Choice Stage on the Main Page is
    correctly designed, we can retry the Work Queue Items that are marked as Exceptions
    due to activating the kill switch. Upon retrying, execution should resume to the
    point right before the ML prediction is called. If the amount of time that we
    have is greater than the expected amount of time for the current Item to complete,
    we can *Request Stop* on all of the in-flight Sessions. Finally, if we have lots
    of time, we can wait for all of the Sessions to complete:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们可以做几件事情，这取决于在ML模型下线之前我们有多少时间。如果ML模型很快就要下线，我们可以触发OP模型的关闭开关。这将阻止在调用ML算法之前执行。如果主页上的选择阶段设计正确，我们可以重试因触发关闭开关而被标记为异常的工作队列项。重试后，执行应恢复到ML预测被调用之前的点。如果我们拥有的时间超过当前项完成预期的时长，我们可以在所有正在进行的会话上请求停止。最后，如果我们有很多时间，我们可以等待所有会话完成：
- en: Under *Control* | *Session Management*, select **01 – Outage Prediction Notification**
    as the *Process* filter. Ensure that all of the other filters are set to **All**.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*控制* | *会话管理*下，选择**01 – 停电预测通知**作为*进程*过滤器。确保所有其他过滤器都设置为**全部**。
- en: '![Figure 12.5 – Filter Session Management to see the 01 – Outage Prediction
    Notification Process](img/B18416_12_5.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图12.5 – 过滤会话管理以查看01 – 停电预测通知进程](img/B18416_12_5.jpg)'
- en: Figure 12.5 – Filter Session Management to see the 01 – Outage Prediction Notification
    Process
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 – 过滤会话管理以查看01 – 停电预测通知进程
- en: Wait until all Sessions have finished running, Request Stop on the Sessions,
    or trigger the **Ch12 OP Prediction Kill Switch**. The one that should be used
    will depend on the expected execution time for one Work Queue Item, and how much
    time there is before the model is taken offline.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待直到所有会话都运行完成，请求停止会话，或触发**Ch12 OP预测关闭开关**。应该使用哪一个将取决于一个工作队列项的预期执行时间以及模型下线前的剩余时间。
- en: Now, let’s assume that some time has passed, and we’ve been notified that the
    ML deployment has completed. The next steps are to modify the **Ch12 OP Model
    Version** Environment Variable and to unretire the Schedule.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们假设已经过去了一些时间，并且我们已经收到通知，ML部署已完成。下一步是修改**Ch12 OP模型版本**环境变量，并取消退役计划。
- en: Update the Environment Variable to the new ML model version
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将环境变量更新为新ML模型版本
- en: Since the OP model only has one version, we need to keep track of when it’s
    updated manually. In this case, we need to update a `DateTime` Environment Variable.
    Once the model version is updated, we can allow Schedules to resume. Under *System*
    | *Processes* | *Environment Variables*, edit the value of the **Ch12 OP Model
    Version** Environment Variable so that it uses the current date and time.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 由于OP模型只有一个版本，我们需要手动跟踪其更新时间。在这种情况下，我们需要更新一个`DateTime`环境变量。一旦模型版本更新，我们可以允许计划恢复。在*系统*
    | *进程* | *环境变量*下，编辑**Ch12 OP模型版本**环境变量的值，使其使用当前日期和时间。
- en: Unretire the Schedules
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 取消退役计划
- en: Now we wait for the ML team to inform us that the new model is ready to use.
    Once we’ve been notified, we can unretire the schedules so that processing can
    begin again. Under *Control* | *Retired Schedules*, right-click on the *Ch12 Outage
    Prediction Notification* Schedule, and *Unretire* it.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们等待ML团队通知我们新模型已准备好使用。一旦我们收到通知，我们可以取消退休计划，以便再次开始处理。在*Control* | *Retired Schedules*下，右键单击*Ch12
    Outage Prediction Notification*计划，并*取消退休*它。
- en: Run the Process with the new model
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用新模型运行流程
- en: Run the **01 – Outage Prediction Notification** Process from the Control Room
    again. This step is only needed to generate Session Logs for a future example.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 再次从控制室运行**01 – 停电预测通知**流程。此步骤仅用于为未来的示例生成会话日志。
- en: We’ve completed the steps needed to deploy a new version of the OP model, which
    required downtime, into our IA solution. Now let’s look at how we can deploy a
    new version of the CC model which uses a Code Stage.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了将新版本的OP模型部署到我们的IA解决方案中所需的步骤，这需要停机。现在让我们看看我们如何部署使用代码阶段的CC模型的新版本。
- en: Example 2 – Customer complaint model deployment
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例2 – 客户投诉模型部署
- en: Let’s suppose that the CC ML model Object has been updated and that this deployment
    doesn’t require any new DLLs. Note that the model version (1.5.3) before deployment
    can be found as a Data Item on the `Initialise` Page of the **Customer Complaints
    ML Model** Object. Also, note that the Action that returns the predicted result
    also returns the model version as well. This means that we don’t need to use an
    Environment Variable to store the model version.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 假设CC ML模型对象已更新，并且这次部署不需要任何新的DLL。请注意，部署前的模型版本（1.5.3）可以在**客户投诉ML模型**对象的`初始化`页面作为数据项找到。此外，请注意，返回预测结果的操作也返回了模型版本。这意味着我们不需要使用环境变量来存储模型版本。
- en: '![Figure 12.6: The CC ML Object Action returns the model version.](img/B18416_12_6.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图12.6：CC ML对象操作返回模型版本。](img/B18416_12_6.jpg)'
- en: 'Figure 12.6: The CC ML Object Action returns the model version.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6：CC ML对象操作返回模型版本。
- en: 'This example has three high-level steps:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例有三个高级步骤：
- en: Running the **02 – Customer Complaints Prediction** Process once to create Session
    Logs.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行**02 – 客户投诉预测**流程一次以创建会话日志。
- en: Deploying the new model by importing an Object.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过导入对象来部署新模型。
- en: Running the Process again to create Session Logs.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次运行流程以创建会话日志。
- en: Our first step is to run the existing Process once to generate some Session
    Log data. This data will be used in *Example 5*.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是运行现有的流程一次以生成一些会话日志数据。这些数据将在*示例5*中使用。
- en: Run the Process
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行流程
- en: Execute the Process once from the Control Room so that Session Logs are generated.
    From the Control Room, run the **02 – Customer Complaints Prediction** Process
    once. This will create 20 Items (customers), who belong to one of the four regions.
    Next, we need to download the Object and verify that the model version has been
    updated.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制室运行流程一次以生成会话日志。从控制室运行**02 – 客户投诉预测**流程一次。这将创建20个项目（客户），他们属于四个区域之一。接下来，我们需要下载对象并验证模型版本已更新。
- en: Download, check the model version, and import the Object
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下载、检查模型版本并导入对象
- en: 'In this case, the updated model is provided as a `.bpobject` file. We need
    to download it and verify that the model version is not the same as the previous
    version (1.5.3):'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，更新的模型以`.bpobject`文件的形式提供。我们需要下载它并验证模型版本与之前的版本（1.5.3）不同：
- en: 'Download the Object from GitHub: [https://github.com/PacktPublishing/Intelligent-Automation-with-Blue-Prism/blob/main/ch12/Ex_2_BPA_Object_Customer_Complaints_ML_Model.bpobject](https://github.com/PacktPublishing/Intelligent-Automation-with-Blue-Prism/blob/main/ch12/Ex_2_BPA_Object_Customer_Complaints_ML_Model.bpobject).'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从GitHub下载对象：[https://github.com/PacktPublishing/Intelligent-Automation-with-Blue-Prism/blob/main/ch12/Ex_2_BPA_Object_Customer_Complaints_ML_Model.bpobject](https://github.com/PacktPublishing/Intelligent-Automation-with-Blue-Prism/blob/main/ch12/Ex_2_BPA_Object_Customer_Complaints_ML_Model.bpobject)。
- en: Import the downloaded Object into BP.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将下载的对象导入BP。
- en: Under *Studio | Objects |* *Ch12*, open the **Customer Complaints ML Model**
    Object in the Object Studio.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*Studio | Objects |* *Ch12*下，在对象工作室中打开**客户投诉ML模型**对象。
- en: On the `Initialise` Page, verify that the **Model Version** Data Item has been
    updated by the developers from the previous version (1.5.3).
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`初始化`页面，验证开发人员已将**模型版本**数据项从之前的版本（1.5.3）更新。
- en: '![Figure 12.7: Verify that the Model Version Data Item has been changed from
    1.5.3](img/B18416_12_7.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图12.7：验证模型版本数据项已从1.5.3更改](img/B18416_12_7.jpg)'
- en: 'Figure 12.7: Verify that the Model Version Data Item has been changed from
    1.5.3'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7：验证模型版本数据项已从1.5.3更改
- en: We’ve confirmed that the model version has changed. Since this is a Code Stage
    deployment, without any new DLLs, importing the new Object is all that we need
    to do. In-flight Sessions from before the Object import will still be using the
    old Object definition with the previous model version. New Sessions that start
    after the Object import will use the updated Object and model version.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已确认模型版本已更改。由于这是一个代码阶段部署，没有新的DLL文件，我们只需要导入新的对象文件。在对象导入之前进行的会话仍将使用旧的对象定义和先前的模型版本。在对象导入之后开始的新会话将使用更新的对象和模型版本。
- en: If you want to be safer, you can check if the model version has been updated
    before importing it into BP. If the file is a `.bpobject` file, you can open it
    in any text editor and search for *Model Version*. You can also perform a similar
    search if the file is a `.``bprelease` file.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想更安全，可以在将其导入BP之前检查模型版本是否已更新。如果文件是`.bpobject`文件，您可以在任何文本编辑器中打开它并搜索*模型版本*。如果文件是`.bprelease`文件，您也可以执行类似的搜索。
- en: '![Figure 12.8: The model version can be viewed by opening the .bpobject file
    in Notepad](img/B18416_12_8.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图12.8：可以通过在记事本中打开.bpobject文件来查看模型版本](img/B18416_12_8.jpg)'
- en: 'Figure 12.8: The model version can be viewed by opening the .bpobject file
    in Notepad'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8：可以通过在记事本中打开.bpobject文件来查看模型版本
- en: Finally, let’s run the Process again, to generate Session Logs with the updated
    model version.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们再次运行流程，以生成带有更新模型版本的会话日志。
- en: Use the new ML model
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用新的机器学习模型
- en: Execute the Process again from the Control Room. These Session Logs are required
    for *Example 5*. From the Control Room, run the **02 – Customer Complaints Prediction**
    Process again.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制室再次执行流程。这些会话日志对于*示例5*是必需的。从控制室再次运行**02 – 客户投诉预测**流程。
- en: We’ve completed the steps required to deploy a Code Stage-based model that didn’t
    require any new `.dll` files to be copied. This was straightforward and only required
    importing the new Object file. Next, let’s look at the steps needed to roll back
    this ML model deployment.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了部署基于代码阶段的模型所需的步骤，该模型不需要复制任何新的`.dll`文件。这很简单，只需导入新的对象文件。接下来，让我们看看回滚此机器学习模型部署所需的步骤。
- en: Example 3 – Rollback customer complaint model deployment
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例3 – 回滚客户投诉模型部署
- en: 'Suppose that we’ve found an issue with the new CC model. Let’s go through the
    exercise of rolling back to the previous version. This example has three high-level
    steps:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们发现新的CC模型存在问题。让我们通过回滚到上一个版本进行练习。此示例有三个高级步骤：
- en: Activating the kill switch (optional).
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 激活终止开关（可选）。
- en: Finding and importing the previous version of the Object.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找并导入对象的前一个版本。
- en: Running the **02 – Customer Complaints Prediction** Process once to create Session
    Logs.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行一次**02 – 客户投诉预测**流程以创建会话日志。
- en: If there are Sessions that are underway, we can consider turning on the kill
    switch, to prevent any further calls to the CC ML model.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有正在进行的会话，我们可以考虑打开终止开关，以防止对CC机器学习模型的任何进一步调用。
- en: Activate the customer complaint model kill switch (optional)
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 激活客户投诉模型终止开关（可选）
- en: If the issue with the model is critical, we can optionally trigger the kill
    switch, so that further predictions won’t be made using the CC model. We can activate
    the kill switch by invalidating the Credential.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型问题至关重要，我们可以选择性地触发终止开关，这样就不会再使用CC模型进行进一步预测。我们可以通过使凭证无效来激活终止开关。
- en: Visit *System* | *Security* | *Credentials*. Double-click on the **Ch12 CC Prediction
    Kill** **Switch** Credential.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问*系统* | *安全* | *凭证*。双击**Ch12 CC预测终止****开关**凭证。
- en: Tick the *Marked as invalid* box and press *OK*.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打勾选择*标记为无效*复选框并按*确定*。
- en: Now that Sessions can no longer use the CC model any further, we can begin the
    rollback procedure. First, let’s get a copy of the previous Object.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 由于会话现在无法再使用CC模型，我们可以开始回滚程序。首先，让我们获取上一个对象的副本。
- en: Obtain and import the previous Object
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取并导入上一个对象。
- en: There are a few ways to obtain an old version of an Object. You can retrieve
    it from a previous Release, and only re-import the Object. You might also have
    a copy in a shared location or version control system. If you don’t have a readily
    available copy of the previous Object, we can export it through the *Compare*
    function in BP.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 获取对象旧版本的方法有很多。您可以从以前的版本中检索它，并且只重新导入对象。您也可能在共享位置或版本控制系统中有一个副本。如果您没有以前对象的可用副本，我们可以通过
    BP 中的*比较*功能将其导出。
- en: Important note
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: BP Customer Support will often provide customers with database maintenance scripts.
    One of these scripts deletes historical versions of Objects and Processes in the
    `BPAAuditEvents` table if they’re older than a certain number of days. This could
    prevent you from using the *Compare* function. Please check with your database
    team to determine whether this maintenance script is in use.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: BP 客户支持通常会向客户提供数据库维护脚本。其中一些脚本会在对象和流程的历史版本超过一定天数时从`BPAAuditEvents`表中删除。这可能会阻止您使用*比较*功能。请与您的数据库团队联系，以确定是否正在使用此维护脚本。
- en: Click once on the **Customer Complaints ML Model** Object under *Studio* | *Objects*
    | *Ch12*. The Object’s version history will appear on the right.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*工作室* | *对象* | *Ch12*下，单击一次**客户投诉 ML 模型**对象。对象的版本历史将显示在右侧。
- en: Hold down the *Ctrl* button and select the two latest versions of the Object.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按住*Ctrl*按钮并选择对象的两个最新版本。
- en: '![Figure 12.9: Select the two latest versions of the Object](img/B18416_12_9.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.9：选择对象的两个最新版本](img/B18416_12_9.jpg)'
- en: 'Figure 12.9: Select the two latest versions of the Object'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.9：选择对象的两个最新版本
- en: Right-click and choose *Compare*. This opens the Business Object Comparison
    window. See that the two Objects have different model versions.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击并选择*比较*。这会打开业务对象比较窗口。请注意，两个对象具有不同的模型版本。
- en: '![Figure 12.10: Open the Object Comparison window](img/B18416_12_10.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.10：打开对象比较窗口](img/B18416_12_10.jpg)'
- en: 'Figure 12.10: Open the Object Comparison window'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.10：打开对象比较窗口
- en: Click on *File* | *Export Left Side* in the *Business Object* *Comparison* window.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*业务对象* *比较*窗口中，单击*文件* | *导出左侧*。
- en: '![Figure 12.11: Export the previous version of the Object](img/B18416_12_11.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.11：导出对象的上一版本](img/B18416_12_11.jpg)'
- en: 'Figure 12.11: Export the previous version of the Object'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.11：导出对象的上一版本
- en: Save the exported Object to a location of your choice.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将导出的对象保存到您选择的位置。
- en: Import the saved Object back into BP and overwrite the latest version.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将保存的对象重新导入 BP 并覆盖最新版本。
- en: Next, let’s run the Process to generate Session Logs with the old model.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们运行流程以生成使用旧模型的会话日志。
- en: Use the old ML model
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用旧 ML 模型
- en: Execute the Process again from the Control Room. This data will be used in *Example
    5*. From the Control Room, run the **02 – Customer Complaints Prediction** Process
    again.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制室再次执行流程。这些数据将在*示例 5*中使用。从控制室再次运行**02 – 客户投诉预测**流程。
- en: We’ve finished looking at examples of how to deploy new versions of the OP and
    CC models. We also went through an example of how to roll back the CC model, which
    used a Code Stage. Next, let’s look at the next major ongoing task that is needed
    for IA, which is exporting data for ML auditing.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了查看如何部署 OP 和 CC 模型新版本的示例。我们还通过一个示例了解了如何使用代码阶段回滚 CC 模型。接下来，让我们看看 IA 需要的下一个主要持续任务，即导出数据以供
    ML 审计。
- en: Exporting data for audit
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导出数据以供审计
- en: Based on the solution design, the easiest way to extract ML-related logs is
    to query the Session Logs database tables directly. Let’s go through an example
    of what query to use and what we should expect to see after requesting for the
    ML logs to be extracted from the database. In production, it’s expected that these
    steps would be performed by a database administrator.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 根据解决方案设计，提取与 ML 相关日志的最简单方法是从会话日志数据库表直接查询。让我们通过一个示例来看看应该使用什么查询以及请求从数据库提取 ML 日志后我们应该期望看到什么。在生产环境中，预计这些步骤将由数据库管理员执行。
- en: Important note
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The SQL query in the following example assumes that you are using the `BPASessionLog_NonUnicode`
    table to store your logs. Replace that table with `BPASessionLog_Unicode` in the
    query if you’re using Unicode logging.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的 SQL 查询假设您正在使用`BPASessionLog_NonUnicode`表来存储您的日志。如果您使用 Unicode 日志，请在查询中将该表替换为`BPASessionLog_Unicode`。
- en: Example 4 – Exporting OP model data through SQL
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 4 – 通过 SQL 导出 OP 模型数据
- en: In this example, we’ll be querying the inputs, outputs, and model version used
    for every call to the *OP model* through SQL Server Management Studio. This example
    relies on having completed *Example 1*, where we executed the **01 – Outage Prediction
    Notification** Process twice, once before deployment and once after.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'We expect to see *four* Session Log records with an older `DateTime` model
    version and *four* Session Log records with a newer `DateTime` model version:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Open SQL Server Management Studio and connect to your BP database server.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click on your database in the *Object Explorer* (IA in the following image).
    Choose *New Query*. An empty query editor window will appear.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.12: Open a new Query window](img/B18416_12_12.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.12: Open a new Query window'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'Copy and paste the following query into the editor window and *execute* it:
    `SELECT * FROM (SELECT logid, stagename, LAG(result, 1, 0) OVER(ORDER BY logid)
    as modelversion, attributexml, startdatetime from BPASessionLog_NonUnicode WHERE
    stagename in (''Log [Model Version]'', ''Set [Prediction] and [Confidence Score]'')
    AND processname = ''01 - Outage Prediction Notification'') as tbl WHERE stagename
    = ''Set [Prediction] and [``Confidence Score]'';`.'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify that your result looks similar to the result shown in *Figure 12**.13*.
    The *modelversion* column shows the value of the **Ch12 OP Model Version** Environment
    Variable. Notice that the *modelversion* of the first four rows differs from the
    last four rows. The *attributexml* column shows the values of any other input
    and output parameters of the model that you want to store in the *Set [Prediction]
    and [Confidence Score]* Multi Calc Stage.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.13: The query result for extracting the ML Session Logs for audit](img/B18416_12_13.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.13: The query result for extracting the ML Session Logs for audit'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: We’ve finished exporting the Session Logs that tell us the model version, inputs,
    and outputs of the OP ML model. The query that we used was taken from [*Chapter
    9*](B18416_09.xhtml#_idTextAnchor146), and it can be used by any Process that’s
    developed using the IA template from [*Chapter 7*](B18416_07.xhtml#_idTextAnchor114),
    with just a few modifications. The only change that we made here is to modify
    the name of the Process.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Now, suppose that we want to also export the ML audit logs for the CC model
    that’s called using an Object and Code Stage. We’ll see that the steps and the
    query are almost exactly the same.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Example 5 – Exporting customer complaint model data through SQL
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this example, we’ll be querying the inputs, outputs, and model version used
    for every call to the *CC model* through SQL Server Management Studio. This example
    makes use of the Session Logs generated from *Example 2* and *Example 3*, so make
    sure to go through those examples first.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: 'We expect to see 60 rows returned, where each row represents a customer. The
    first 20 rows are from before the ML model is updated and should show model version
    *1.5.3*. The next 20 rows are from after updating the ML model and should show
    model version *1.6.0*. The last 20 rows are from after rolling back the model
    and should show model version *1.5.3*:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望看到返回60行数据，其中每一行代表一个客户。前20行是在机器学习模型更新之前的数据，应该显示模型版本*1.5.3*。接下来的20行是在更新机器学习模型之后的数据，应该显示模型版本*1.6.0*。最后的20行是在回滚模型之后的数据，应该显示模型版本*1.5.3*：
- en: Open SQL Server Management Studio and connect to your BP database server.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开SQL Server Management Studio并连接到你的BP数据库服务器。
- en: Right-click on your database in the *Object Explorer*. Choose *New Query*. An
    empty query editor window will appear.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*对象资源管理器*中右键点击你的数据库。选择*新建查询*。一个空的查询编辑器窗口将出现。
- en: 'Copy and paste the following query into the editor window and *execute* it:
    `SELECT * FROM (SELECT logid, stagename, LAG(result, 1, 0) OVER(ORDER BY logid)
    as modelversion, attributexml, startdatetime from BPASessionLog_NonUnicode WHERE
    stagename in (''Log [Model Version]'', ''Set [Prediction] and [Confidence Score]'')
    AND processname = ''02 - Customer Complaints Prediction'') as tbl WHERE stagename
    = ''Set [Prediction] and [Confidence Score]'';`. The only difference between this
    query and the query in *Example 4* is that the name of the Process has changed.'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下查询复制粘贴到编辑器窗口中，并*执行*它：`SELECT * FROM (SELECT logid, stagename, LAG(result,
    1, 0) OVER(ORDER BY logid) as modelversion, attributexml, startdatetime from BPASessionLog_NonUnicode
    WHERE stagename in ('Log [Model Version]', 'Set [Prediction] and [Confidence Score]')
    AND processname = '02 - Customer Complaints Prediction') as tbl WHERE stagename
    = 'Set [Prediction] and [Confidence Score]';`。这个查询与*示例4*中的查询唯一的区别是流程的名称已更改。
- en: Verify that 60 rows are returned by the query, with the first 20 rows having
    *modelversion* 1.5.3, the next 20 rows having *modelversion* 1.6.0, and the final
    20 rows having *modelversion* 1.5.3.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证查询返回了60行数据，其中前20行具有*modelversion* 1.5.3，接下来的20行具有*modelversion* 1.6.0，最后的20行再次具有*modelversion*
    1.5.3。
- en: We’ve completed exporting the ML audit logs for the CC model. Since it uses
    the IA template, we only needed to change the name of the Process in the query.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了CC模型的机器学习审计日志的导出。由于它使用IA模板，我们只需要在查询中更改流程的名称。
- en: Summary
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we went through a scenario-based example of a power utility
    company that used two different ML models. The first model predicts grid outages.
    It’s API-hosted and maintained by an internal ML team. The second model predicts
    whether customers will call the customer support hotline and is developed and
    maintained by the IA team. This customer complaint model is deployed through a
    Code Stage. From analyzing the characteristics and requirements of both ML models,
    we came up with a solution design that did not separate ML into individual Processes
    and Work Queues.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们通过一个基于场景的例子，介绍了一家电力公用事业公司使用了两种不同的机器学习模型。第一个模型预测电网故障，它的API由内部机器学习团队托管和维护。第二个模型预测客户是否会拨打客户支持热线，由IA团队开发和维护。这个客户投诉模型通过代码阶段部署。通过分析两个机器学习模型的特点和需求，我们提出了一个解决方案设计，该设计没有将机器学习分割成单独的流程和工作队列。
- en: Next, we focused on two critical tasks that are needed for IA. These are deploying
    new ML models and extracting ML-specific data for audit purposes. We went through
    examples of deploying both the OP and CC models and rolling back the CC one. Finally,
    we looked at how ML Session Log data can be extracted directly through SQL for
    auditing purposes.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们专注于IA所需的两个关键任务。这些任务是部署新的机器学习模型和提取用于审计目的的机器学习特定数据。我们通过部署OP和CC模型的示例以及回滚CC模型进行了说明。最后，我们探讨了如何直接通过SQL提取机器学习会话日志数据用于审计目的。
- en: While mechanically simple, thinking through the steps needed, and practicing
    how to deploy and rollback ML models is a must for mature IA teams. ML will only
    receive more and more scrutiny in the future, not just from management, but the
    legal system as well. If an issue with a model is found, we need to be able to
    quickly roll back and figure out which customers have been affected by the ML
    prediction.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在机械上很简单，但思考所需的步骤，并练习如何部署和回滚机器学习模型，对于成熟的IA团队来说是必须的。机器学习在未来将受到越来越多的审查，不仅来自管理层，还包括法律系统。如果发现模型存在问题，我们需要能够快速回滚并找出哪些客户受到了机器学习预测的影响。
- en: In the next and final chapter, we’ll take a look at the wider BP product ecosystem.
    We’ll discuss four additional IA-related products, and how they can contribute
    to your firm’s IA program. Finally, we’ll also discuss three important IA trends.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章和最后一章中，我们将探讨更广泛的BP产品生态系统。我们将讨论四个额外的与IA相关的产品，以及它们如何为您的公司IA项目做出贡献。最后，我们还将讨论三个重要的IA趋势。
