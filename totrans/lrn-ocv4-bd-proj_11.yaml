- en: Text Recognition with Tesseract
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Tesseract 进行文本识别
- en: In [Chapter 10](31f3c15b-57fb-42c6-b67b-5552dfdfa3ac.xhtml), *Developing Segmentation
    Algorithms for Text Recognition*, we covered the very basic OCR processing functions.
    Although they are quite useful for scanned or photographed documents, they are
    almost useless when dealing with text that casually appears in a picture.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 10 章](31f3c15b-57fb-42c6-b67b-5552dfdfa3ac.xhtml)，*为文本识别开发分割算法*中，我们介绍了非常基础的
    OCR 处理函数。虽然它们对于扫描或拍摄的文档非常有用，但当处理图片中随意出现的文本时，它们几乎毫无用处。
- en: In this chapter, we'll explore the OpenCV 4.0 text module, which deals specifically
    with scene text detection. Using this API, it is possible to detect the text that
    appears in a webcam video, or to analyze photographed images (like the ones in
    Street View or taken by a surveillance camera) to extract text information in
    real time. This allows for a wide range of applications to be created, from accessibility,
    to marketing, and even robotics fields.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨 OpenCV 4.0 文本模块，该模块专门用于场景文本检测。使用此 API，可以检测出现在网络摄像头视频中的文本，或分析照片图像（如街景或监控摄像头拍摄的图像）以实时提取文本信息。这允许创建广泛的应用程序，从无障碍、营销甚至机器人领域。
- en: 'By the end of this chapter, you will be able to do the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够做到以下几件事情：
- en: Understand what scene text recognition is
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解场景文本识别是什么
- en: Understand how the text API works
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解文本 API 的工作原理
- en: Use the OpenCV 4.0 text API to detect text
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenCV 4.0 文本 API 检测文本
- en: Extract the detected text into an image
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将检测到的文本提取到图像中
- en: Use the text API and Tesseract integration to identify letters
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用文本 API 和 Tesseract 集成来识别字母
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires familiarity with the basic C++ programming language.
    All of the code used in this chapter can be downloaded from the following GitHub
    link: [https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_11](https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_11).
    The code can be executed on any operating system, though it is only tested on
    Ubuntu.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要熟悉基本的 C++ 编程语言。本章中使用的所有代码都可以从以下 GitHub 链接下载：[https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_11](https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_11)。代码可以在任何操作系统上执行，尽管它仅在
    Ubuntu 上进行了测试。
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，看看代码的实际应用：
- en: '[http://bit.ly/2Slht5A](http://bit.ly/2Slht5A)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2Slht5A](http://bit.ly/2Slht5A)'
- en: How the text API works
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本 API 的工作原理
- en: The text API implements the algorithm that was proposed by *Lukás Neumann* and
    *Jiri Matas* in the article *Real*-*Time Scene Text Localization and Recognition*
    during the **computer vision and pattern recognition** (**CVPR**) conference in
    2012\. This algorithm represented a significant increase in scene text detection,
    performing state-of-the art detection both in the CVPR database, as well as in
    the Google Street View database. Before using the API, let's take a look at how
    this algorithm works under to hood, and how it addresses the scene text detection
    problem.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 文本 API 实现了在 2012 年 **计算机视觉和模式识别**（**CVPR**）会议期间由 *Lukás Neumann* 和 *Jiri Matas*
    在文章 *Real*-*Time Scene Text Localization and Recognition* 中提出的算法。该算法在场景文本检测方面取得了显著进步，在
    CVPR 数据库以及 Google Street View 数据库中都实现了最先进的检测。在使用 API 之前，让我们看看这个算法在幕后是如何工作的，以及它是如何解决场景文本检测问题的。
- en: '**Remember**: The OpenCV 4.0 text API does not come with the standard OpenCV
    modules. It''s an additional module that''s present in the OpenCV `contrib` package.
    If you installed OpenCV using the Windows Installer, you should take a look back
    at [Chapter 1](96b225d4-84bc-4d49-b8b3-079b15f05cf0.xhtml), *Getting Started with
    OpenCV;* this will guide you on how to install these modules.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**记住**：OpenCV 4.0 文本 API 不包含在标准 OpenCV 模块中。它是一个存在于 OpenCV `contrib` 包中的附加模块。如果你使用
    Windows 安装程序安装了 OpenCV，你应该回顾一下[第 1 章](96b225d4-84bc-4d49-b8b3-079b15f05cf0.xhtml)，*开始使用
    OpenCV；*这将指导你如何安装这些模块。'
- en: The scene detection problem
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 场景检测问题
- en: 'Detecting text that randomly appears in a scene is a problem that''s harder
    than it looks. There are several new variables that you need to take into account
    when you''re comparing to identified scanned text, such as the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 检测场景中随机出现的文本是一个比看上去更难的问题。当你将检测到的文本与已识别的扫描文本进行比较时，需要考虑以下几个新变量：
- en: '**Tridimensionality**: The text may be in any scale, orientation, or perspective.
    Also, the text may be partially occluded or interrupted. There are literally thousands
    of possible regions where it may appear in the image.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**三维性**：文本可以以任何比例、方向或透视出现。此外，文本可能部分遮挡或中断。实际上有成千上万的可能性，文本可能出现在图像中的任何区域。'
- en: '**Variety**: Text can be in several different fonts and colors. The font may
    have outline borders. The background can be dark, light, or a complex image.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样性**：文本可以有多种不同的字体和颜色。字体可能有轮廓边框。背景可以是深色、浅色或复杂的图像。'
- en: '**Illumination and shadows**: The sunlight''s position and apparent color changes
    over time. Different weather conditions like fog or rain can generate noise. Illumination
    may be a problem even in closed spaces, since light reflects over colored objects
    and hits the text.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**光照和阴影**：阳光的位置和外观颜色会随时间变化。不同的天气条件，如雾或雨，可以产生噪声。即使在封闭空间中，光照也可能成为问题，因为光线会在彩色物体上反射并击中文本。'
- en: '**Blurring**: Text may appear in a region that''s not prioritized by lens auto-focus.
    Blurring is also common in moving cameras, in perspective text, or in the presence
    of fog.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模糊**：文本可能出现在镜头自动对焦不优先考虑的区域。在移动相机、透视文本或雾的存在下，模糊也很常见。'
- en: 'The following picture, taken from Google Street View, illustrates these problems.
    Note how several of these situations occur simultaneously in just a single image:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片，来自谷歌街景，说明了这些问题。注意这些情况如何在单一图像中同时发生：
- en: '![](img/5692ac93-9c3f-4ac5-a8bb-c8510e741663.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5692ac93-9c3f-4ac5-a8bb-c8510e741663.png)'
- en: Performing text detection to deal with such situations may prove computationally
    expensive, since there are **2*^n*** subsets of pixels, ***n*** being the number
    of pixels in the image.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对此类情况进行文本检测可能计算成本高昂，因为有 **2*^n*** 个像素子集，其中 ***n*** 是图像中的像素数量。
- en: 'To reduce complexity, two strategies are commonly applied:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了降低复杂性，通常采用两种策略：
- en: '**Use a sliding window to search just a subset of image rectangles**: This
    strategy just reduces the number of subsets to a smaller amount. The amount of
    regions varies according to the complexity of text being considered. Algorithms
    that deal just with text rotation may use small values, compared to the ones that
    also deal with rotation, skewing, perspective, and so on. The advantage of this
    approach is its simplicity, but they are usually limited to a narrow range of
    fonts and often to a lexicon of specific words.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用滑动窗口搜索图像矩形的子集**：这种策略只是将子集的数量减少到更小的数量。区域的数量根据考虑的文本复杂性而变化。仅处理文本旋转的算法可能使用较小的值，而同时处理旋转、倾斜、透视等的算法则可能使用较大的值。这种方法的优点在于其简单性，但它们通常仅限于较窄的字体范围，并且通常限于特定单词的词汇表。'
- en: '**Use of connected component analysis**: This approach assumes that pixels
    can be grouped into regions, where pixels have similar properties. These regions
    are supposed to have higher chances to be identified as characters. The advantage
    of this approach is that it does not depend on several text properties (orientation,
    scale, fonts, and so on), and they also provide a segmentation region that can
    be used to crop text to the OCR. This was the approach that we used in [Chapter
    10](31f3c15b-57fb-42c6-b67b-5552dfdfa3ac.xhtml), *Developing Segmentation Algorithms
    for Text Recognition*. Lighting could also affect the result, for example, if
    a shadow is cast over the letters, creating two distinct regions. However, since
    scene detection is commonly used in moving vehicles (for example, drones or cars)
    and with videos, the text will end up being detected eventually, since these lighting
    conditions will differ from frame to frame.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用连通分量分析**：这种方法假设像素可以分组到具有相似属性的区域内。这些区域更有可能被识别为字符。这种方法的优点是它不依赖于多个文本属性（方向、缩放、字体等），并且它们还提供了一个可以用于裁剪文本到OCR的分割区域。这是我们[第10章](31f3c15b-57fb-42c6-b67b-5552dfdfa3ac.xhtml)中使用的方法，*开发文本识别的分割算法*。光照也可能影响结果，例如，如果字母上投下阴影，会形成两个不同的区域。然而，由于场景检测通常用于移动车辆（例如，无人机或汽车）和视频中，由于这些光照条件会逐帧变化，文本最终会被检测到。'
- en: The OpenCV 4.0 algorithm uses the second strategy by performing connected component
    analysis and searching for extremal regions.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 4.0算法通过执行连通分量分析和搜索极端区域来使用第二种策略。
- en: Extremal regions
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 极端区域
- en: 'Extremal regions are connected areas that are characterized by almost uniform
    intensity, which is surrounded by a contrasted background. The stability of a
    region can be measured by calculating how resistant to thresholding variance the
    region is. This variance can be measured with a simple algorithm:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 极端区域是具有几乎均匀强度且被对比度背景包围的连通区域。一个区域的不变性可以通过计算该区域对阈值变化的抵抗程度来衡量。这种变化可以通过一个简单的算法来测量：
- en: Apply the threshold, generating an image, *A*. Detect its connected pixels regions
    (extremal regions).
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用阈值，生成一个图像，*A*。检测其连通像素区域（极端区域）。
- en: Increase the threshold by a delta amount, generating an image, *B*. Detect its
    connected pixels regions (extremal regions).
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将阈值增加一个 delta 数量，生成一个图像，*B*。检测其连通像素区域（极端区域）。
- en: Compare image *B* with *A*. If a region in image A is similar to the same region
    in image *B*, add it to the same branch in the tree. The criteria of similarity
    may vary from implementation to implementation, but it's usually related to the
    image area or general shape. If a region in image *A* appears to be split in image
    *B*, create two new branches in the tree for the new regions and associate it
    with the previous branch.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像 *B* 与 *A* 进行比较。如果图像 A 中的区域与图像 *B* 中相同的区域相似，则将其添加到树中的同一分支。相似性的标准可能因实现而异，但通常与图像面积或一般形状有关。如果图像
    *A* 中的区域在图像 *B* 中看起来被分割，则在树中为新的区域创建两个新的分支，并将其与上一个分支关联。
- en: Set *A* = *B* and go back to step 2, until the maximum threshold is applied.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将集合 *A* 设置为 *B* 并返回步骤 2，直到应用最大阈值。
- en: 'This will assemble a tree of regions, as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这将按照以下方式组装一个区域树：
- en: '![](img/c9442351-9576-48c7-b6c7-46bf4361eb11.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c9442351-9576-48c7-b6c7-46bf4361eb11.png)'
- en: The resistance to variance is determined by counting how many nodes are in the
    same level. By analyzing this tree, it's also possible to determine the **maximally
    stable extremal regions** (**MSER**s), that is, the regions where the area remains
    stable in a wide variety of thresholds. In the previous diagram, it is clear that
    these areas would contain the letters ***O***, ***N***, and ***Y***. The main
    disadvantage of maximally extremal regions is that they are weak in the presence
    of blur. OpenCV provides a MSER feature detector in the **feature2d** module.
    Extremal regions are interesting because they are strongly invariant to illumination,
    scale, and orientation. They are good candidates for text as well, since they
    are also invariant, with regards to the type of font used, even when the font
    is styled. Each region can also be analyzed to determine its boundary ellipsis,
    and can have properties like affine transformation and area numerically determined.
    Finally, it's worth mentioning that this entire process is fast, which makes it
    a very good candidate for real-time applications.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗变化的能力是通过计算同一级别的节点数量来确定的。通过分析这个树，还可以确定**最大稳定极端区域**（**MSER**s），即在广泛的各种阈值下面积保持稳定的区域。在之前的图中，很明显这些区域将包含字母
    ***O***、***N*** 和 ***Y***。最大极端区域的缺点是它们在模糊存在时较弱。OpenCV 在 **feature2d** 模块中提供了一个
    MSER 特征检测器。极端区域很有趣，因为它们对光照、尺度和方向具有很强的不变性。它们也是文本的良好候选者，因为它们对字体类型也不敏感，即使字体有样式。每个区域也可以进行分析以确定其边界椭圆，并具有如仿射变换和面积等数值确定的属性。最后，值得一提的是，整个过程非常快，这使得它非常适合实时应用。
- en: Extremal region filtering
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 极端区域过滤
- en: 'Although MSERs are a common approach to define which extremal regions are worth
    working with, the *Neumann* and *Matas* algorithm uses a different approach, by
    submitting all extremal regions to a sequential classifier that''s been trained
    for character detection. This classifier works in two different stages:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然MSERs是定义哪些极端区域值得工作的常见方法，但*Neumann*和*Matas*算法采用不同的方法，通过将所有极端区域提交给一个为字符检测而训练的顺序分类器。这个分类器在两个不同的阶段工作：
- en: The first stage incrementally computes descriptors (bounding box, perimeter,
    area, and Euler number) for each region. These descriptors are submitted to a
    classifier that estimates how probable the region is to be a character in the
    alphabet. Then, only the regions of high probability are selected for stage 2.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一阶段逐步计算每个区域的描述符（边界框、周长、面积和欧拉数）。这些描述符被提交给一个分类器，该分类器估计该区域成为字母表中字符的可能性。然后，只选择高概率的区域进入第二阶段。
- en: In this stage, the features of the whole area ratio, convex hull ratio, and
    the number of outer boundary inflexion points are calculated. This provides more
    detailed information that allows the classifier to discard non-text characters,
    but they are also much slower to calculate.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个阶段，计算整个区域比率、凸包比率和外部边界拐点数量。这提供了更多详细的信息，使分类器能够丢弃非文本字符，但它们的计算速度也慢得多。
- en: 'Under OpenCV, this process is implemented in a class called `ERFilter`. It
    is also possible to use different image single channel projections, such as *R*,
    *G*, *B*, Luminance, or gray scale conversion to increase the character recognition
    rates. Finally, all of the characters must be grouped into text blocks (such as
    words or paragraphs). OpenCV 3.0 provides two algorithms for this purpose:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中，这个过程是通过一个名为`ERFilter`的类实现的。也可以使用不同的图像单通道投影，例如*R*、*G*、*B*、亮度或灰度转换来提高字符识别率。最后，所有字符都必须被分组到文本块中（如单词或段落）。OpenCV
    3.0为此提供了两个算法：
- en: '**Prune exhaustive search**: Also proposed by *Mattas* in 2011, this algorithm
    does not need any previous training or classification, but is limited to horizontally
    aligned text'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**剪枝穷举搜索**：2011年由*Mattas*提出，这个算法不需要任何先前的训练或分类，但仅限于水平对齐的文本'
- en: '**Hierarchical method for oriented text**: This deals with text in any orientation,
    but needs a trained classifier'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**面向文本的分层方法**：这处理任何方向的文本，但需要一个训练好的分类器'
- en: 'Note that since these operations require classifiers, it is also necessary
    to provide a trained set as input. OpenCV 4.0 provides some of these trained sets
    in the following sample package: [https://github.com/opencv/opencv_contrib/tree/master/modules/text/samples](https://github.com/opencv/opencv_contrib/tree/master/modules/text/samples).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于这些操作需要分类器，因此还需要提供训练集作为输入。OpenCV 4.0在以下示例包中提供了一些这些训练集：[https://github.com/opencv/opencv_contrib/tree/master/modules/text/samples](https://github.com/opencv/opencv_contrib/tree/master/modules/text/samples)。
- en: This also means that this algorithm is sensitive to the fonts used in classifier
    training.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这也意味着这个算法对分类器训练中使用的字体敏感。
- en: 'A demonstration of this algorithm can be seen in the following video, which
    is provided by Neumann himself: [https://www.youtube.com/watch?v=ejd5gGea2Fo&feature=youtu.be](https://www.youtube.com/watch?v=ejd5gGea2Fo&feature=youtu.be).
    Once the text is segmented, it just needs to be sent to an OCR like Tesseract,
    similarly to what we did in [Chapter 10](31f3c15b-57fb-42c6-b67b-5552dfdfa3ac.xhtml),
    *Developing Segmentation Algorithms for Text Recognition*. The only difference
    is that now we will use OpenCV text module classes to interface with Tesseract,
    since they provide a way to encapsulate the specific OCR engine we are using.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以下视频展示了该算法的演示，由Neumann本人提供：[https://www.youtube.com/watch?v=ejd5gGea2Fo&feature=youtu.be](https://www.youtube.com/watch?v=ejd5gGea2Fo&feature=youtu.be)。一旦文本被分割，只需将其发送到OCR如Tesseract，类似于我们在[第10章](31f3c15b-57fb-42c6-b67b-5552dfdfa3ac.xhtml)，*开发用于文本识别的分割算法*中所做的那样。唯一的区别是现在我们将使用OpenCV文本模块类与Tesseract接口，因为它们提供了一种封装我们使用特定OCR引擎的方法。
- en: Using the text API
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用文本API
- en: Enough theory. It's time to see how the text module works in practice. Let's
    study how we can use it to perform text detection, extraction, and identification.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 理论已经足够。现在是时候看看文本模块在实际中是如何工作的了。让我们研究一下我们如何使用它来进行文本检测、提取和识别。
- en: Text detection
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本检测
- en: Let's start by creating a simple program so that we can perform text segmentation
    using **ERFilters**. In this program, we will use the trained classifiers from
    text API samples. You may download this from the OpenCV repository, but they are
    also available in this book's companion code.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先创建一个简单的程序，这样我们就可以使用**ERFilters**进行文本分割。在这个程序中，我们将使用文本API示例中的训练分类器。您可以从OpenCV仓库中下载这些示例，但它们也包含在这本书的配套代码中。
- en: 'First, we start by including all of the necessary `libs` and `usings`:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们开始包括所有必要的`libs`和`usings`：
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Recall from the *Extremal region filtering* section that the `ERFilter` works
    separately in each image channel. Therefore, we must provide a way to separate
    each desired channel in a different single channel, `cv::Mat`. This is done by
    the `separateChannels` function:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 从*极值区域过滤*部分回忆起，`ERFilter`在每个图像通道中独立工作。因此，我们必须提供一种方法来分别在每个不同的单通道`cv::Mat`中分离每个所需的通道。这是通过`separateChannels`函数实现的：
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'First, we verify whether the image is already a single channel image (grayscale
    image). If that''s the case, we just add this image – it does not need to be processed.
    Otherwise, we check if it''s an **RGB** image. For colored images, we call the
    `computeNMChannels` function to split the image into several channels. This function
    is defined as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们验证图像是否已经是单通道图像（灰度图像）。如果是这种情况，我们只需添加此图像——它不需要处理。否则，我们检查它是否是**RGB**图像。对于彩色图像，我们调用`computeNMChannels`函数将图像分割成几个通道。此函数定义如下：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following are its parameters:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是其参数：
- en: '`src`: The source input array. It must be a colored image of type 8UC3.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`src`: 源输入数组。它必须是一个8UC3类型的彩色图像。'
- en: '`channels`: A vector of `Mats` that will be filled with the resulting channels.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`channels`: 一个`Mats`向量，其中将填充结果通道。'
- en: '`mode`: Defines which channels will be computed. Two possible values can be
    used:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mode`: 定义将计算哪些通道。可以使用两个可能的值：'
- en: '`ERFILTER_NM_RGBLGrad`: Indicates whether the algorithm will use RGB color,
    lightness, and gradient magnitude as channels (default)'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERFILTER_NM_RGBLGrad`: 表示算法是否将使用RGB颜色、亮度和梯度幅度作为通道（默认）'
- en: '`ERFILTER_NM_IHSGrad`: Indicates whether the image will be split by its intensity,
    hue, saturation, and gradient magnitude'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERFILTER_NM_IHSGrad`: 表示图像是否将根据其强度、色调、饱和度和梯度幅度进行分割'
- en: We also append the negative of all color components in the vector. Since the
    image will have three distinct channels (*R*, *G*, and *B*), this is usually enough.
    It's also possible to add the non-flipped channels, just like we did with the
    de-grayscaled image, but we'll end up with six channels, and this could be computer-intensive.
    Of course, you're free to test with your images if this leads to a better result.
    Finally, if another kind of image is provided, the function will terminate the
    program with an error message.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还添加了向量中所有颜色成分的负值。由于图像将具有三个不同的通道（*R*、*G*和*B*），这通常就足够了。也可以添加非反转通道，就像我们处理去灰度图像时做的那样，但最终我们会得到六个通道，这可能会很费计算机资源。当然，您可以自由地测试您的图像，看看这是否能带来更好的结果。最后，如果提供了另一种类型的图像，函数将以错误消息终止程序。
- en: Negatives are appended, so the algorithms will cover both bright text in a dark
    background and dark text in a bright background. There is no sense in adding a
    negative for the gradient magnitude.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 负值被添加，因此算法将覆盖暗背景中的亮文本和亮背景中的暗文本。添加梯度幅度的负值没有意义。
- en: 'Let''s proceed to the main method. We''ll use this program to segment the `easel.png`
    image, which is provided with the source code:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续主方法。我们将使用此程序来分割`easel.png`图像，该图像与源代码一起提供：
- en: '![](img/c102affb-0070-4cab-9e5d-b8a0527490dd.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c102affb-0070-4cab-9e5d-b8a0527490dd.png)'
- en: 'This picture was taken by a mobile phone camera while I was walking on the
    street. Let''s code this so that you may also use a different image easily by
    providing its name in the first program argument:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这张照片是在我走在街上时用手机摄像头拍摄的。让我们编写代码，以便您也可以通过在第一个程序参数中提供其名称来轻松地使用不同的图像：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we''ll convert the image to grayscale and separate its channels by calling
    the `separateChannels` function:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将调用`separateChannels`函数将图像转换为灰度并分离其通道：
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If you want to work with all of the channels in a colored image, just replace
    the two first lines of this code extract to the following:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想处理彩色图像中的所有通道，只需将此代码片段的前两行替换为以下内容：
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will need to analyze six channels (RGB and inverted) instead of two (gray
    and inverted). Actually, the processing times will increase much more than the
    improvements that we can get. With the channels in hand, we need to create `ERFilters`
    for both stages of the algorithm. Luckily, the OpenCV text contribution module
    provides functions for this:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要分析六个通道（RGB和反转），而不是两个（灰度和反转）。实际上，处理时间将增加得比我们可以获得的改进更多。有了这些通道，我们需要为算法的两个阶段创建`ERFilters`。幸运的是，OpenCV文本贡献模块提供了相应的函数：
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For the first stage, we call the `loadClassifierNM1` function to load a previously
    trained classification model. The .xml containing the training data is its only
    argument. Then, we call `createERFilterNM1` to create an instance of the `ERFilter`
    class that will perform the classification. The function has the following signature:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一阶段，我们调用`loadClassifierNM1`函数来加载先前训练的分类模型。包含训练数据的.xml文件是其唯一参数。然后，我们调用`createERFilterNM1`来创建一个`ERFilter`类的实例，该实例将执行分类。该函数具有以下签名：
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The parameters for this function are as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数的参数如下：
- en: '`cb`: The classification model. This is the same model we loaded with the `loadCassifierNM1`
    function.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cb`：分类模型。这是与`loadCassifierNM1`函数一起加载的相同模型。'
- en: '`thresholdDelta`: The amount to be summed to the threshold in each algorithm
    iteration. The default value is `1`, but we''ll use `15` in our example.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`thresholdDelta`：在每次算法迭代中要加到阈值上的量。默认值是`1`，但我们在示例中会使用`15`。'
- en: '`minArea`: The minimum area of the **extremal region** (**ER**), where text
    may be found. This is measured by the percentage of the image''s size. ERs with
    areas smaller than this are immediately discarded.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minArea`：可能找到文本的**极端区域**（**ER**）的最小面积。这是按图像大小的百分比来衡量的。面积小于此的ER将被立即丢弃。'
- en: '`maxArea`: The maximum area of the ER where text may be found. This is also
    measured by the percentage of the image''s size. ERs with areas greater than this
    are immediately discarded.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxArea`：可能找到文本的ER的最大面积。这也按图像大小的百分比来衡量。面积大于此的ER将被立即丢弃。'
- en: '`minProbability`: The minimum probability that a region must have to be a character
    in order to remain for the next stage.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minProbability`：一个区域必须具有的最小概率，才能作为字符保留到下一阶段。'
- en: '`nonMaxSupression`: This is used to indicate if non-maximum suppression will
    be done in each branch probability.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nonMaxSupression`：用于指示是否在每个分支概率中执行非最大抑制。'
- en: '`minProbabilityDiff`: The minimum probability difference between the minimum
    and maximum extreme region.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minProbabilityDiff`：最小和最大极端区域之间的最小概率差异。'
- en: 'The process for the second stage is similar. We call `loadClassifierNM2` to
    load the classifier model for the second stage and `createERFilterNM2` to create
    the second stage classifier. This function only takes the input parameters of
    the loaded classification model and a minimum probability that a region must achieve
    to be considered as a character. So, let''s call these algorithms in each channel
    to identify all possible text regions:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 第二阶段的处理过程类似。我们调用`loadClassifierNM2`来加载第二阶段的分类器模型，并调用`createERFilterNM2`来创建第二阶段的分类器。此函数仅接受加载的分类模型的输入参数以及一个区域必须达到的最小概率，才能被认为是字符。因此，让我们在每个通道中调用这些算法来识别所有可能的文本区域：
- en: '[PRE8]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the previous code, we used the `run` function of the `ERFilter` class. This
    function takes two arguments:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用了`ERFilter`类的`run`函数。此函数接受两个参数：
- en: '**The input channel**: This includes the image to be processed.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入通道**：这包括要处理的图像。'
- en: '**The regions**: In the first stage algorithm, this argument will be filled
    with the detected regions. In the second stage (performed by `filter2`), this
    argument must contain the regions selected in stage 1\. These will be processed
    and filtered by stage 2.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**区域**：在第一阶段算法中，此参数将被填充为检测到的区域。在第二阶段（由`filter2`执行），此参数必须包含第一阶段选定的区域。这些区域将在第二阶段进行处理和过滤。'
- en: 'Finally, we release both filters, since they will not be needed in the program
    anymore. The final segmentation step is grouping all ERRegions into possible words
    and defining their bounding boxes. This is done by calling the `erGrouping` function:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们释放这两个过滤器，因为程序中不再需要它们。最终的分割步骤是将所有ER区域分组到可能的单词中，并定义它们的边界框。这是通过调用`erGrouping`函数来完成的：
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This function has the following signature:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数具有以下签名：
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s take a look at the meaning of each parameter:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看每个参数的含义：
- en: '`img`: Input image, also called the original image.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`img`：输入图像，也称为原始图像。'
- en: '`regions`: Vector of single channel images where regions were extracted.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regions`：提取区域的单通道图像向量。'
- en: '`groups`: An output vector of indexes of grouped regions. Each group region
    contains all extremal regions of a single word.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groups`：分组区域的索引输出向量。每个组区域包含单个单词的所有极端区域。'
- en: '`groupRects`: A list of rectangles with the detected text regions.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupRects`：一个包含检测到的文本区域的矩形列表。'
- en: '`method`: This is the method of grouping. It can be any of the following:'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`method`：这是分组的方法。它可以是指定的以下任何一种：'
- en: '`ERGROUPING_ORIENTATION_HORIZ`: The default value. This only generates groups
    with horizontally oriented text by doing an exhaustive search, as proposed originally
    by *Neumann* and *Matas*.'
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERGROUPING_ORIENTATION_HORIZ`：默认值。这仅通过穷举搜索生成具有水平方向文本的组，正如最初由*Neumann*和*Matas*提出的。'
- en: '`ERGROUPING_ORIENTATION_ANY`: This generates groups with text in any orientation,
    using single linkage clustering and classifiers. If you use this method, the filename
    of the classifier model must be provided in the next parameter.'
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERGROUPING_ORIENTATION_ANY`: 这会生成包含任意方向文本的组，使用单链接聚类和分类器。如果你使用这种方法，必须在下一个参数中提供分类器模型的文件名。'
- en: '`Filename`: The name of the classifier model. This is only needed if `ERGROUPING_ORIENTATION_ANY`
    is selected.'
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Filename`: 分类器模型的名称。这仅在选择了`ERGROUPING_ORIENTATION_ANY`时需要。'
- en: '`minProbability`: The minimum detected probability of accepting a group. This
    is also only needed if `ERGROUPING_ORIENTATION_ANY` is selected.'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minProbability`: 接受一个组的最低检测概率。这也仅在选择了`ERGROUPING_ORIENTATION_ANY`时需要。'
- en: 'The code also provides a call to the second method, but it''s commented out.
    You may switch between the two to test this out. Just comment the previous call
    and uncomment this one:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 代码还提供了一个对第二个方法的调用，但已被注释掉。你可以在这两个之间切换以测试这个功能。只需注释掉上一个调用并取消注释这个调用：
- en: '[PRE11]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'For this call, we also used the default trained classifier that''s provided
    in the text module sample package. Finally, we draw the region boxes and show
    the results:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个调用，我们还使用了文本模块示例包中提供的默认训练好的分类器。最后，我们绘制区域框并显示结果：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This program outputs the following result:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序输出以下结果：
- en: '![](img/a069ed42-9847-4e8d-a6e9-f662b1f80337.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a069ed42-9847-4e8d-a6e9-f662b1f80337.png)'
- en: You may check the entire source code in the `detection.cpp` file.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在`detection.cpp`文件中查看整个源代码。
- en: 'While most OpenCV text module functions are written to support both grayscale
    and colored images as its input parameter, at the time of writing this book, there
    were bugs preventing us from using grayscale images in functions such as `erGrouping`.
    For more information, take a look at the following GitHub link: [https://github.com/Itseez/opencv_contrib/issues/309](https://github.com/Itseez/opencv_contrib/issues/309).
    [](https://github.com/Itseez/opencv_contrib/issues/309) Always remember that the
    OpenCV contrib modules package is not as stable as the default OpenCV packages.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大多数OpenCV文本模块函数都编写为支持灰度和彩色图像作为其输入参数，但在撰写本书时，存在一些错误阻止我们在`erGrouping`等函数中使用灰度图像。有关更多信息，请查看以下GitHub链接：[https://github.com/Itseez/opencv_contrib/issues/309](https://github.com/Itseez/opencv_contrib/issues/309)。[总是记住，OpenCV
    contrib模块包不如默认的OpenCV包稳定。](https://github.com/Itseez/opencv_contrib/issues/309)
- en: Text extraction
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本提取
- en: 'Now that we have detected the regions, we must crop the text before submitting
    it to the OCR. We could simply use a function like `getRectSubpix` or `Mat::copy`,
    using each region rectangle as a **region of interest** (**ROI**) but, since the
    letters are skewed, some undesired text may be cropped as well. For example, this
    is what one of the regions would look like if we just extract the ROI based on
    its given rectangle:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经检测到了区域，我们必须在提交给OCR之前裁剪文本。我们可以简单地使用像`getRectSubpix`或`Mat::copy`这样的函数，使用每个区域矩形作为**感兴趣区域**（**ROI**），但由于字母是倾斜的，一些不需要的文本也可能被裁剪掉。例如，如果我们只是基于给定的矩形提取ROI，以下是一个区域的外观：
- en: '![](img/f227149d-3d30-4a84-9a38-4af84e3ead02.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f227149d-3d30-4a84-9a38-4af84e3ead02.png)'
- en: 'Fortunately, `ERFilter` provides us with an object called `ERStat`, which contains
    pixels inside each extremal region. With these pixels, we could use OpenCV''s
    `floodFill` function to reconstruct each letter. This function is capable of painting
    similar colored pixels based on a seed point, just like the **bucket** tool of
    most drawing applications. This is what the function signature looks like:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，`ERFilter`为我们提供了一个名为`ERStat`的对象，它包含每个极值区域内的像素。有了这些像素，我们可以使用OpenCV的`floodFill`函数来重建每个字母。这个函数能够根据种子点绘制类似颜色的像素，就像大多数绘图应用程序中的**水桶**工具一样。这个函数的签名如下：
- en: '[PRE13]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s understand these parameters and how they will be used:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解这些参数以及它们将如何被使用：
- en: '`image`: The input image. We''ll use the channel image where the extremal region
    was taken. This is where the function normally does the flood fill, unless `FLOODFILL_MASK_ONLY`
    is supplied. In this case, the image remains untouched and the drawing occurs
    in the mask. That''s exactly what we will do.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`: 输入图像。我们将使用包含极值区域的通道图像。这是函数通常执行洪水填充的地方，除非提供了`FLOODFILL_MASK_ONLY`。在这种情况下，图像保持不变，绘制发生在遮罩中。这正是我们将要做的。'
- en: '`mask`: The mask must be an image with two rows and two columns greater than
    the input image. When the flood fill draws a pixel, it verifies if the corresponding
    pixel in the mask is zero. In that case, it will draw and mark this pixel as one
    (or another value that''s passed into the flags). If the pixel is not zero, the
    flood fill does not paint the pixel. In our case, we''ll provide a blank mask
    so that every letter will get painted in the mask.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask`：掩码必须是一个比输入图像大两行两列的图像。当洪水填充绘制像素时，它会验证掩码中相应的像素是否为零。如果是这样，它将绘制并标记此像素为1（或传递到标志中的另一个值）。如果像素不是零，则洪水填充不会绘制像素。在我们的情况下，我们将提供一个空白掩码，以便在掩码中绘制每个字母。'
- en: '`seedPoint`: The starting point. It''s similar to the place you click when
    you want to use the **bucket** tool of a graphic application.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seedPoint`：起始点。它类似于你想要使用图形应用程序的**桶**工具时点击的位置。'
- en: '`newVal`: The new value of the repainted pixels.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`newVal`：重新绘制像素的新值。'
- en: '`loDiff` and `upDiff`: These parameters represent the lower and upper differences
    between the pixel being processed and its neighbors. The neighbor will be painted
    if it falls into this range. If the `FLOODFILL_FIXED_RANGE` flag is used, the
    difference between the seed point and the pixels being processed will be used
    instead.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loDiff` 和 `upDiff`：这些参数表示正在处理的像素与其邻居之间的上下差异。如果邻居落在这个范围内，它将被着色。如果使用了 `FLOODFILL_FIXED_RANGE`
    标志，则将使用种子点和正在处理的像素之间的差异。'
- en: '`rect`: This is an optional parameter that limits the region where the flood
    fill will be applied.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rect`：这是一个可选参数，它限制了洪水填充将应用到的区域。'
- en: '`flags`: This value is represented by a bit mask:'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flags`：这个值由一个位掩码表示：'
- en: The least significant 8 bits of the flag contains a connectivity value. A value
    of `4` indicates that all four edge pixels will be used, and a value of `8` will
    indicate that the diagonal pixels must also be taken into account. We'll use `4`
    for this parameter.
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '标志的最低8位包含一个连通性值。`4` 的值表示将使用所有四个边缘像素，而 `8` 的值将表示必须考虑对角像素。我们将为此参数使用 `4`。 '
- en: The next 8 to 16 bits contains a value from `1` to `255`, which is used to fill
    the mask. Since we want to fill the mask with white, we'll use `255 << 8` for
    this value.
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来的8到16位包含一个从 `1` 到 `255` 的值，用于填充掩码。由于我们想要用白色填充掩码，我们将使用 `255 << 8` 来表示这个值。
- en: There are two more bits that can be set by adding the `FLOODFILL_FIXED_RANGE`
    and `FLOODFILL_MASK_ONLY` flags, as we already described.
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有两个额外的位可以通过添加 `FLOODFILL_FIXED_RANGE` 和 `FLOODFILL_MASK_ONLY` 标志来设置，正如我们之前描述的那样。
- en: 'We''ll create a function called `drawER`. This function will receive four parameters:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个名为 `drawER` 的函数。这个函数将接收四个参数：
- en: A vector with all of the processed channels
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含所有处理通道的向量
- en: The `ERStat` region
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERStat` 区域'
- en: The group that must be drawn
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须绘制的组
- en: The group rectangle
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组矩形
- en: 'This function will return an image with the word represented by this group.
    Let''s start this function by creating the mask image and defining the flags:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将返回一个包含该组表示的单词的图像。让我们从这个函数开始，创建掩码图像并定义标志：
- en: '[PRE14]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, we''ll loop through each group. It''s necessary to find the region index
    and its status. There''s a chance of this extreme region being the root, which
    does not contain any points. In this case, we''ll just ignore it:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将遍历每个组。找到区域索引及其状态是必要的。这个极端区域可能是根，它不包含任何点。在这种情况下，我们将忽略它：
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, we can read the pixel coordinate from the `ERStat` object. It''s represented
    by the pixel number, counting from top to bottom, left to right. This linear index
    must be converted to a row (*y*) and column (*z*) notation, using a formula similar
    to the one we saw in [Chapter 2](37cf2702-b8c6-41ff-a935-fd4030f8ce64.xhtml),
    *An Introduction to the Basics of OpenCV*:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以从 `ERStat` 对象中读取像素坐标。它由像素编号表示，从上到下，从左到右计数。这个线性索引必须使用类似于我们在[第2章](37cf2702-b8c6-41ff-a935-fd4030f8ce64.xhtml)中看到的公式转换为行（*y*）和列（*z*）表示法，*《OpenCV基础知识简介》*：
- en: '[PRE16]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then, we can call the `floodFill` function. The `ERStat` object gives us the
    value to use in the `loDiff` parameter:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以调用 `floodFill` 函数。`ERStat` 对象为我们提供了 `loDiff` 参数中使用的值：
- en: '[PRE17]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After we do this for all of the regions in the group, we''ll end with an image
    that''s a little bigger than the original one, with a black background and the
    word in white letters. Now, let''s crop just the area of the letters. Since the
    region rectangle was given, we start by defining it as our region of interest:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在对组中的所有区域都这样做之后，我们将得到一个比原始图像略大的图像，背景为黑色，文字为白色。现在，让我们只裁剪字母的区域。由于已经给出了区域矩形，我们首先将其定义为我们的感兴趣区域：
- en: '[PRE18]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, we''ll find all non-zero pixels. This is the value we''ll use in the
    `minAreaRect` function to get the rotated rectangle around the letters. Finally,
    we will borrow the previous chapter''s `deskewAndCrop` function to crop and rotate
    the image for us:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将找到所有非零像素。这是我们在`minAreaRect`函数中将用于获取围绕字母的旋转矩形的值。最后，我们将借用上一章的`deskewAndCrop`函数来为我们裁剪和旋转图像：
- en: '[PRE19]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This is the result of the process for the easel image:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这是画布图像处理过程的结果：
- en: '![](img/ae3ff958-8639-4052-aa97-c6474f119b77.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ae3ff958-8639-4052-aa97-c6474f119b77.png)'
- en: Text recognition
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本识别
- en: In [Chapter 10](31f3c15b-57fb-42c6-b67b-5552dfdfa3ac.xhtml), *Developing Segmentation
    Algorithms for Text Recognition,* we used the Tesseract API directly to recognize
    the text regions. This time, we'll use OpenCV classes to accomplish the same goal.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第10章](31f3c15b-57fb-42c6-b67b-5552dfdfa3ac.xhtml)《开发文本识别的分割算法》中，我们直接使用Tesseract
    API来识别文本区域。这次，我们将使用OpenCV类来完成同样的目标。
- en: 'In OpenCV, all OCR-specific classes derive from the **BaseOCR** virtual class.
    This class provides a common interface for the OCR execution method itself. Specific
    implementations must inherit from this class. By default, the text module provides
    three different implementations: **OCRTesseract**, **OCRHMMDecoder**, and **OCRBeamSearchDecoder**.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中，所有OCR特定的类都从**BaseOCR**虚拟类派生。这个类为OCR执行方法本身提供了一个通用接口。具体的实现必须从这个类继承。默认情况下，文本模块提供了三种不同的实现：**OCRTesseract**、**OCRHMMDecoder**和**OCRBeamSearchDecoder**。
- en: 'This hierarchy is depicted in the following class diagram:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个类图，展示了这个层次结构：
- en: '![](img/463bba5c-a8d2-4b38-b981-7c4d7e23b74f.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/463bba5c-a8d2-4b38-b981-7c4d7e23b74f.png)'
- en: With this approach, we can separate the part of the code where the OCR mechanism
    is created from the execution itself. This makes it easier to change the OCR implementation
    in the future.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法，我们可以将创建OCR机制的部分与执行本身分开。这使得将来更改OCR实现变得更加容易。
- en: 'So, let''s start by creating a method that decides which implementation we''ll
    use based on a string. We currently support just Tesseract, but you may take a
    look in this chapter''s code, where a demonstration with **HMMDecoder** is also
    provided. Also, we are accepting the OCR engine name in a string parameter, but
    we could improve our application''s flexibility by reading it from an external
    JSON or XML configuration file:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们首先创建一个方法，根据字符串决定我们将使用哪种实现。我们目前只支持Tesseract，但您可以在本章的代码中查看，其中还提供了一个使用**HMMDecoder**的演示。此外，我们接受OCR引擎名称作为字符串参数，但我们可以通过从外部JSON或XML配置文件中读取它来提高我们应用程序的灵活性：
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'As you may have noticed, the function returns `Ptr<BaseOCR>`. Now, take a look
    at the highlighted code. It calls the `create` method to initialize a Tesseract
    OCR instance. Let''s take a look at its official signature, since it allows several
    specific parameters:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经注意到的，函数返回`Ptr<BaseOCR>`。现在，让我们看看高亮显示的代码。它调用`create`方法来初始化一个Tesseract OCR实例。让我们看看它的官方签名，因为它允许设置几个特定的参数：
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s dissect each of these parameters:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一分析这些参数：
- en: '`datapath`: This is the path to the root directory''s `tessdata` files. The
    path must end with a backslash `/` character. The `tessdata` directory contains
    the language files you installed. Passing `nullptr` to this parameter will make
    Tesseract search in its installation directory, which is the location where this
    folder is normally present. It''s common to change this value to `args[0]` when
    deploying an application and include the `tessdata` folder in your application
    path.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`datapath`：这是根目录的`tessdata`文件的路径。路径必须以反斜杠`/`字符结尾。`tessdata`目录包含您安装的语言文件。将`nullptr`传递给此参数将使Tesseract在其安装目录中搜索，这是该文件夹通常所在的位置。在部署应用程序时，通常会将此值更改为`args[0]`，并将`tessdata`文件夹包含在应用程序路径中。'
- en: '`language`: This is a three letter word with the language code (for example,
    eng for English, por for Portuguese, or hin for Hindi). Tesseract supports the
    loading of multiple language codes by using the `+` sign. Therefore, passing `eng+por`
    will load both English and Portuguese languages. Of course, you can only use languages
    that you have previously installed, otherwise the loading will fail. A language
    `config` file may specify that two or more languages must be loaded together.
    To prevent that, you may use a tilde `~`. For example, you can use `hin+~eng`
    to guarantee that English is not loaded with Hindi, even if it is configured to
    do so.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language`: 这是一个三个字母的单词，包含语言代码（例如，eng 代表英语，por 代表葡萄牙语，或 hin 代表印地语）。Tesseract
    通过使用 `+` 符号支持加载多个语言代码。因此，传递 `eng+por` 将加载英语和葡萄牙语。当然，您只能使用之前已安装的语言，否则加载将失败。语言 `config`
    文件可能指定必须一起加载两个或多个语言。为了防止这种情况，您可以使用波浪号 `~`。例如，您可以使用 `hin+~eng` 来确保即使配置了这样做，也不会将英语与印地语一起加载。'
- en: '`whitelist`: This is the character that''s set to be considered for recognition.
    In the case that `nullptr` is passed, the characters will be `0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ`.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whitelist`: 这是设置为考虑识别的字符。如果传递 `nullptr`，则字符将是 `0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ`。'
- en: '`oem`: These are the OCR algorithms that will be used. It can have one of the
    following values:'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oem`: 这些是将要使用的 OCR 算法。它可以有以下其中一个值：'
- en: '`OEM_TESSERACT_ONLY`: Uses just Tesseract. It''s the fastest method, but it
    also has less precision.'
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OEM_TESSERACT_ONLY`: 仅使用 Tesseract。这是最快的方法，但精度较低。'
- en: '`OEM_CUBE_ONLY`: Uses Cube engine. It''s slower, but more precise. This will
    only work if your language was trained to support this engine mode. To check if
    that''s the case, look for `.cube` files for your language in the `tessdata` folder.
    The support for English language is guaranteed.'
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OEM_CUBE_ONLY`: 使用 Cube 引擎。它较慢，但更精确。这仅在您的语言被训练以支持此引擎模式时才会工作。要检查是否如此，请查看 `tessdata`
    文件夹中您语言的 `.cube` 文件。对英语语言的支持是保证的。'
- en: '`OEM_TESSERACT_CUBE_COMBINED`: Combines both Tesseract and Cube to achieve
    the best possible OCR classification. This engine has the best accuracy and the
    slowest execution time.'
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OEM_TESSERACT_CUBE_COMBINED`: 将 Tesseract 和 Cube 结合起来以实现最佳的 OCR 分类。此引擎具有最高的准确性和最慢的执行时间。'
- en: '`OEM_DEFAULT`: Infers the strategy based in the language config file, command-line
    config file or, in the absence of both, use `OEM_TESSERACT_ONLY`.'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OEM_DEFAULT`: 根据语言配置文件、命令行配置文件推断策略，如果两者都不存在，则使用 `OEM_TESSERACT_ONLY`。'
- en: '`psmode`: This is the segmentation mode. It can be any of the following:'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`psmode`: 这是分割模式。它可以有以下任何一个：'
- en: '`PSM_OSD_ONLY:` Using this mode, Tesseract will just run its preprocessing
    algorithms to detect orientation and script detection.'
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_OSD_ONLY:` 使用此模式，Tesseract 将仅运行其预处理算法以检测方向和脚本检测。'
- en: '`PSM_AUTO_OSD`: This tells Tesseract to do automatic page segmentation with
    orientation and script detection.'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_AUTO_OSD`: 这告诉 Tesseract 进行自动页面分割，包括方向和脚本检测。'
- en: '`PSM_AUTO_ONLY`: Does page segmentation, but avoids doing orientation, script
    detection, or OCR. This is the default value.'
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_AUTO_ONLY`: 进行页面分割，但避免进行方向、脚本检测或 OCR。这是默认值。'
- en: '`PSM_AUTO`: Does page segmentation and OCR, but avoids doing orientation or
    script detection.'
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_AUTO`: 进行页面分割和 OCR，但避免进行方向或脚本检测。'
- en: '`PSM_SINGLE_COLUMN`: Assumes that the text of variable sizes is displayed in
    a single column.'
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_COLUMN`: 假设文本以单列显示。'
- en: '`PSM_SINGLE_BLOCK_VERT_TEXT`: Treats the image as a single uniform block of
    vertically aligned text.'
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_BLOCK_VERT_TEXT`: 将图像视为一个垂直对齐的单个统一文本块。'
- en: '`PSM_SINGLE_BLOCK`: Assumes a single block of text. This is the default configuration.
    We will use this flag since our preprocessing phase guarantees this condition.'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_BLOCK`: 假设一个文本块。这是默认配置。我们将使用此标志，因为我们的预处理阶段保证了这种条件。'
- en: '`PSM_SINGLE_LINE`: Indicates that the image contains only one line of text.'
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_LINE`: 表示图像中只包含一行文本。'
- en: '`PSM_SINGLE_WORD`: Indicates that the image contains just one word.'
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_WORD`: 表示图像中只包含一个单词。'
- en: '`PSM_SINGLE_WORD_CIRCLE`: Indicates that the image is a just one word disposed
    in a circle.'
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_WORD_CIRCLE`: 表示图像是一个单词，以圆形排列。'
- en: '`PSM_SINGLE_CHAR`: Indicates that the image contains a single character.'
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_CHAR`: 表示图像中只包含一个字符。'
- en: 'For the last two parameters, it''s recommended that you use the `#include`
    Tesseract directory to use the constant names instead of directly inserting their
    values. The last step is to add text detection in our main function. To do this,
    just add the following code to the end of the main method:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 对于最后两个参数，建议使用`#include` Tesseract目录来使用常量名称，而不是直接插入它们的值。最后一步是在我们的主函数中添加文本检测。为此，只需将以下代码添加到主方法的末尾：
- en: '[PRE22]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In this code, we started by calling our `initOCR` method to create a Tesseract
    instance. Note that the remaining code will not change if we chose a different
    OCR engine, since the run method signature is guaranteed by the `BaseOCR` class.
    Next, we iterate over each detected `ERFilter` group. Since each group represents
    a different word, we will do the following:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们首先调用我们的`initOCR`方法来创建一个Tesseract实例。请注意，如果我们选择不同的OCR引擎，剩余的代码将不会改变，因为`BaseOCR`类保证了运行方法的签名。接下来，我们遍历每个检测到的`ERFilter`组。由于每个组代表不同的单词，我们将执行以下操作：
- en: Call the previously created `drawER` function to create an image with the word.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用之前创建的`drawER`函数来创建包含单词的图像。
- en: Create a text string called `word`, and call the `run` function to recognize
    the word image. The recognized word will be stored in the string.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`word`的文本字符串，并调用`run`函数来识别单词图像。识别出的单词将被存储在字符串中。
- en: Print the text string in the screen.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在屏幕上打印文本字符串。
- en: 'Let''s take a look at the `run` method signature. This method is defined in
    the `BaseOCR` class, and will be equal for all specific OCR implementations –
    even the ones that might be implemented in the future:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看`run`方法的签名。这个方法定义在`BaseOCR`类中，对于所有特定的OCR实现都将相同——即使是在未来可能实现的那一些：
- en: '[PRE23]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Of course, this is a pure virtual function that must be implemented by each
    specific class (such as the `OCRTesseract` class we just used):'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是一个纯虚函数，必须由每个特定的类（如我们刚刚使用的`OCRTesseract`类）实现：
- en: '`image`: The input image. It must be a RGB or a grayscale image.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`：输入图像。它必须是RGB或灰度图像。'
- en: '`component_rects`: We can provide a vector to be filled with the bounding box
    of each component (words or text lines) that''s detected by the OCR engine.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`component_rects`：我们可以提供一个向量，用于填充由OCR引擎检测到的每个组件（单词或文本行）的边界框。'
- en: '`component_texts`: If given, this vector will be filled with the text strings
    of each component detected by the OCR.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`component_texts`：如果提供，这个向量将被填充为检测到的每个组件的文本字符串。'
- en: '`component_confidences`: If given, the vector will be filled with floats, with
    the confidence values of each component.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`component_confidences`：如果提供，该向量将被填充为浮点数，包含每个组件的置信度值。'
- en: '`component_level`: Defines what a component is. It may have the values `OCR_LEVEL_WORD`
    (by default), or `OCR_LEVEL_TEXT_LINE`.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`component_level`：定义了一个组件是什么。它可能有`OCR_LEVEL_WORD`（默认值）或`OCR_LEVEL_TEXT_LINE`的值。'
- en: If necessary, you may prefer changing the component level to a word or line
    in the `run()` method instead of doing the same thing in the `psmode` parameter
    of the `create()` function. This is preferable since the `run` method will be
    supported by any OCR engine that decides to implement the `BaseOCR` class. Always
    remember that the `create()` method is where vendor-specific configurations are
    set.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，你可能会更喜欢在`run()`方法中将组件级别更改为单词或行，而不是在`create()`函数的`psmode`参数中做同样的事情。这是更可取的，因为`run`方法将由任何决定实现`BaseOCR`类的OCR引擎支持。始终记住，`create()`方法是在设置供应商特定配置的地方。
- en: 'This is the program''s final output:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这是程序的最终输出：
- en: '![](img/2899645e-f4e4-416c-95f9-eca150d92aa0.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2899645e-f4e4-416c-95f9-eca150d92aa0.png)'
- en: Despite a minor confusion with the `&` symbol, every word was perfectly recognized.
    You may check the entire source code in the `ocr.cpp` file, in this chapter's
    code file.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管与`&`符号有些小混淆，但每个单词都被完美识别。你可以检查本章代码文件中的`ocr.cpp`文件中的整个源代码。
- en: Summary
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we saw that scene text recognition is a far more difficult
    OCR situation than working with scanned texts. We studied how the text module
    addresses this problem with extremal region identification using the *Newmann*
    and *Matas* algorithm. We also saw how to use this API with the `floodFill` function
    to extract the text in to an image and submit it to Tesseract OCR. Finally, we
    studied how the OpenCV text module integrates with Tesseract and other OCR engines,
    and how can we use its classes to identify what's written in an image.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解到场景文本识别比处理扫描文本的 OCR 情况要困难得多。我们研究了文本模块如何使用 *Newmann* 和 *Matas* 算法通过极值区域识别来解决这个问题。我们还看到了如何使用这个
    API 和 `floodFill` 函数来从图像中提取文本并将其提交给 Tesseract OCR。最后，我们研究了 OpenCV 文本模块如何与 Tesseract
    和其他 OCR 引擎集成，以及我们如何使用其类来识别图像中的文字。
- en: In the next chapter, you will be introduced to deep learning in OpenCV. You
    will learn about object detection and classification by using the **you only look
    once** (**YOLO**) algorithm.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将了解 OpenCV 中的深度学习。您将通过使用 **你只看一次**（**YOLO**）算法来学习物体检测和分类。
