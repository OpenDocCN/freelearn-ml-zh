- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Accounting for Outliers and Special Events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An **outlier** is any data point that lies significantly away from other data
    points along one or multiple different axes. Outliers may be incorrect data, resulting
    from a miscalibrated sensor producing invalid data, or even a finger slip on the
    keyboard during data entry, or they can be accurately recorded data that happens
    to wildly miss historical trends for various reasons, such as whether a tornado
    passed over a wind speed sensor.
  prefs: []
  type: TYPE_NORMAL
- en: These uncharacteristic measurements will sway any statistical or machine learning
    model, so correcting outliers is a challenge throughout data science and statistics.
    Fortunately, Prophet is generally robust at handling mild outliers. With extreme
    outliers though, there are two problems Prophet can experience – one problem with
    seasonality and another with uncertainty intervals.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you’ll see examples of both of these problems and learn how
    to alleviate their effects on your forecast. You’ll also learn a few techniques
    to automate outlier detection, and finally, you’ll apply a lesson learned in [*Chapter
    8*](B19630_08.xhtml#_idTextAnchor537), *Influencing Trend Changepoints*, to keep
    the outliers in your model but instruct Prophet not to modify the trends or seasonalities
    to fit them.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Correcting outliers that cause seasonality swings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Correcting outliers that cause wide uncertainty intervals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting outliers automatically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling outliers as special events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling shocks, such as COVID-19 lockdowns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data files and code for the examples in this chapter can be found at [https://github.com/PacktPublishing/Forecasting-Time-Series-Data-with-Prophet-Second-Edition](https://github.com/PacktPublishing/Forecasting-Time-Series-Data-with-Prophet-Second-Edition).
  prefs: []
  type: TYPE_NORMAL
- en: Correcting outliers that cause seasonality swings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ll be using a new dataset in this chapter to look at outliers – the average
    number of likes per day of posts on National Geographic’s Instagram account, `@NatGeo`.
    This data was collected on November 21, 2019.
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ve chosen this dataset because it exhibits several significant outliers,
    which are marked in the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Outliers on National Geographic’s Instagram account](img/Fig_10.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Outliers on National Geographic’s Instagram account
  prefs: []
  type: TYPE_NORMAL
- en: Each dashed vertical line indicates a moment where the time series deviated
    significantly. The second line from the left indicates a radical trend change
    in the summer of **2015**, but the other four lines indicate outliers, with the
    last two outliers spanning across wide time ranges. We’ll specifically be looking
    at the line occurring in mid-**2016**, in August to be precise. This represents
    the most extreme outliers. The **2014** set of outliers can be safely ignored,
    as they do not affect the forecast too much. The **2017** and **2019** outliers
    look like they may be seasonal effects, so we’ll let the yearly seasonality capture
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 'As it turns out, in September 2016, National Geographic published a book, *@NatGeo:
    The Most Popular Instagram Photos*. It seems that in the month prior to this,
    National Geographic undertook some marketing activities that boosted the number
    of likes on its Instagram account.'
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in [*Chapter 8*](B19630_08.xhtml#_idTextAnchor537), *Influencing Trend
    Changepoints*, James Rodríguez’s account also saw an increased number of likes
    during his World Cup appearances. However, in his case, these events were followed
    by higher baselines of likes at their conclusion – a significant trend change
    had occurred. In contrast, National Geographic’s August marketing work did not
    produce a lasting trend change, although it did increase the number of likes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The spike represents the first type of problem outliers can cause in Prophet
    – they can dominate a seasonality curve. Let me show you what I mean by plotting
    a Prophet forecast. Let’s make our imports, load the data, and plot the forecast.
    We’ll use multiplicative seasonality and dampen the Fourier order of the yearly
    seasonality down to `6`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'These outliers have caused Prophet to model a spike in likes every August:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – The NatGeo forecast with outliers](img/Fig_10.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – The NatGeo forecast with outliers
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s true that August in **2013**, **2015**, **2017**, and **2019** also saw
    periods of increased likes, but the even years did not. Some seasonality would
    be expected but not this much. To make matters worse, this effect reverberates
    forever into the future. You can see how significant an effect this is by looking
    at the yearly seasonality plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, you can see the August peak clearly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Prophet’s yearly seasonality with outliers](img/Fig_10.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – Prophet’s yearly seasonality with outliers
  prefs: []
  type: TYPE_NORMAL
- en: While attempting to fit a yearly seasonality to those outliers in **2016**,
    Prophet has allowed **August** to contribute a boost of more than 20% to the number
    of expected likes. We see those frequent August boosts, so we do want Prophet
    to model them, but the **2016** anomaly is dominating.
  prefs: []
  type: TYPE_NORMAL
- en: The solution is simply to remove the points. Prophet handles missing data very
    well, so introducing a small gap won’t pose any issues. In [*Chapter 4*](B19630_04.xhtml#_idTextAnchor197),
    *Handling Non-Daily Data*, you learned how to handle regular gaps by removing
    those gaps from the `future` DataFrame as well. In this case though, as long as
    we have **August** data for other years, we don’t need to take that precaution.
  prefs: []
  type: TYPE_NORMAL
- en: 'It seems that the first major outlier was on July 29 and the final one was
    on September 1, so we’ll exclude data between those dates using `pandas`’ Boolean
    indexing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This new `df2` is identical to our original `df`, just excluding those outliers.
    Let’s build the same Prophet model as before but just switch out the previous
    DataFrame, `df`, for this new one, `df2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see the month-long gap in August 2016 in this plot. The forecast simply
    passes through it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – The NatGeo forecast with outliers removed](img/Fig_10.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – The NatGeo forecast with outliers removed
  prefs: []
  type: TYPE_NORMAL
- en: 'This new forecast also shows significant seasonality, but we do expect this,
    as NatGeo’s likes are frequently higher in the summer. To quantify the difference
    between this forecast and the previous, let’s also plot the yearly seasonality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'It’s a very similar shape to *Figure 10**.3*, but with a less exaggerated August
    peak:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Prophet’s yearly seasonality with outliers removed](img/Fig_10.5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.5 – Prophet’s yearly seasonality with outliers removed
  prefs: []
  type: TYPE_NORMAL
- en: Now, the August peak has almost halved; it is just over 10% of a boost. This
    is much closer to what would be expected without the external (and non-repeating)
    shock of the marketing push before the release of National Geographic’s book.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at the second type of outlier issue.
  prefs: []
  type: TYPE_NORMAL
- en: Correcting outliers that cause wide uncertainty intervals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first type of outlier we looked at, the problem was that the seasonality
    was affected and forever changed `yhat` in the forecast (if you remember from
    [*Chapter 2*](B19630_02.xhtml#_idTextAnchor104), *Getting Started with Prophet*,
    `yhat` is the predicted value for future dates contained in Prophet’s `forecast`
    DataFrame). In this second problem, `yhat` is minimally affected, but the uncertainty
    intervals widen dramatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'To simulate this issue, we need to modify our NatGeo data a bit. Let’s say
    that Instagram introduced a bug in their code that capped likes at 100,000 per
    post. It somehow went unnoticed for a year before being fixed, but unfortunately,
    all likes above 100,000 were lost. Such an error would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6 – Capped likes on National Geographic’s Instagram account](img/Fig_10.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – Capped likes on National Geographic’s Instagram account
  prefs: []
  type: TYPE_NORMAL
- en: 'You can simulate this new dataset yourself with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This sets all the likes on all posts in 2016 to 100,000\. To see what problem
    this causes, let’s again build the same model as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We’re adding the changepoints to the plot in this example because that is exactly
    where the error is introduced, as seen in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7 – The NatGeo forecast with outliers](img/Fig_10.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.7 – The NatGeo forecast with outliers
  prefs: []
  type: TYPE_NORMAL
- en: The future uncertainty explodes going forward. In the previous example, Prophet
    modeled the outliers with seasonality, adding extreme data to the yearly seasonality
    component. In this example though, Prophet models the outliers with trend changepoints.
    The seasonality is unaffected.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll fully discuss uncertainty in [*Chapter 11*](B19630_11.xhtml#_idTextAnchor728),
    *Managing Uncertainty Intervals*, but briefly, what Prophet does is look at the
    frequency and magnitude of historical changepoints and model future uncertainty,
    assuming that future changepoints may occur with the same frequency and magnitude.
    So, dramatic historical changepoints, as you can see in *Figure 10**.7*, will
    cause dramatic future uncertainty, as Prophet is unsure whether they will occur
    again.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution, fortunately, is the same as in the previous situation – simply
    remove the bad data. In the previous example, we removed the rows from our DataFrame
    that contained bad data, but in this example, we’ll set the `''y''` value to `None`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This makes no difference to our trends or seasonalities. Where it does make
    a difference is that now, instead of skipping over those dates in the `forecast`
    DataFrame, it predicts the values on those dates. You can see this in the forecast
    plot coming up in *Figure 10**.8*. Instead of a straight prediction line passing
    through the missing data, it follows the seasonality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s rebuild our model again, using the `df3` DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Compared to *Figure 10**.7*, we have now tamed that forecast uncertainty, as
    shown in the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8 – The NatGeo forecast with outliers removed](img/Fig_10.8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.8 – The NatGeo forecast with outliers removed
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned before, we have missing data in 2016, but Prophet still made a
    prediction and plotted the predicted values. This is the result of setting those
    missing values to `None` instead of deleting them. Compare *Figure 10**.8* with
    *Figure 10**.4*, where the missing data has no predicted values and the plot passes
    right through them in a straight line.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematically, it makes no difference to your future forecast; it just applies
    predicted values to those that were missing. It is entirely up to you whether
    you want these missing values to be predicted in the `future` DataFrame or ignored.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting outliers automatically
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In these examples so far, we detected outliers with a simple visual inspection
    of the data and applied common sense. In a fully automated setting, defining logical
    rules for what we as humans do intuitively can be difficult. Outlier detection
    is a good use of an analyst’s time, as we humans are able to use much more intuition,
    domain knowledge, and experience than a computer can. But as Prophet was developed
    to reduce the workload of analysts and automate as much as possible, we’ll examine
    a couple of techniques to identify outliers automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Winsorizing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first technique is called **Winsorization**, named after the statistician
    Charles P. Winsor. It is also sometimes called **clipping**. Winsorization is
    a blunt tool and tends not to work well with non-flat trends. Winsorization requires
    an analyst to specify a percentile; all data above or below that percentile is
    forced to remain at the value at the percentile.
  prefs: []
  type: TYPE_NORMAL
- en: '**Trimming** is a similar technique, except that the extreme values are removed.
    The difference between these techniques can be seen in this simple example, in
    which the outliers are the two most extreme points on each side of the three plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.9 – Winsorization versus trimming](img/Fig_10.9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.9 – Winsorization versus trimming
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: In statistics, the word *stationary* means that the mean, variance, and autocorrelation
    structure do not change over time. In time series with a *flat trend*, the mean
    does not change over time, and so one (and possibly each) requirement of stationarity
    is met. With stationary data, outliers may often be replaced by the mean value;
    however, this technique typically does not work with time series lacking a flat
    trend, due to the stationarity requirement.
  prefs: []
  type: TYPE_NORMAL
- en: To take a concrete example, refer back to *Figure 2**.2* from [*Chapter 2*](B19630_02.xhtml#_idTextAnchor104),
    *Getting Started with Prophet*, and look at the Keeling Curve of carbon dioxide
    levels at Mauna Loa and imagine replacing one of the final values – say, in 2015
    – with the mean of the full dataset. This would result in an absurdly low value
    of about 360 in 2015, a value not seen in 20 years.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at how to apply Winsorization to our National Geographic data. The
    `stats` package has a Winsorization tool, so we’ll use that. Note that we are
    dropping all null values, as those are not handled by this function. We are setting
    the lower limit to `0`, so no values are affected at the lower bound, and the
    upper limit to `.05`, so the upper fifth percentile is affected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The Winsorized National Geographic data appears thus, with affected data points
    marked with an **x**:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 10.10 – Winsori\uFEFF\uFEFFzed data](img/Fig_10.10.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 10.10 – Winsorized data
  prefs: []
  type: TYPE_NORMAL
- en: Standard deviation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since Winsorization limits are set with percentiles, there is no account taken
    of natural variance in the data – that is, some datasets are distributed very
    tightly around a mean value and some are very spread out. Setting a percentile
    limit would not take this into account. So, instead of using percentiles, sometimes
    using standard deviation makes more sense. This is very similar to Winsorization
    and can have identical effects if the limits are set carefully.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we Winsorized in the previous section, we forced the outliers to take
    on the value at the upper limit. In this case, we will simply remove the outliers.
    We are using the `zscore` function in the SciPy `stats` package to eliminate those
    data points lying `1.65` standard deviations above the mean; in a normal distribution,
    this upper value would demarcate 95% of the data, the same limit we set previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the two techniques have nearly identical results, except that
    here, we are trimming the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.11 – Data trimmed with standard deviation](img/Fig_10.11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.11 – Data trimmed with standard deviation
  prefs: []
  type: TYPE_NORMAL
- en: This method is also a poor fit when data features a trend. Obviously, points
    lying later in a time series with an upward trend are more likely to be trimmed
    than those lying earlier. The next technique takes this into account.
  prefs: []
  type: TYPE_NORMAL
- en: The moving average
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We just looked at the number of standard deviations spread out away from the
    mean of the entire dataset and saw why it fails when there is a trend. In this
    method, we will use a moving average so that we’re essentially localizing our
    mean and standard deviation calculations, only applying them to data points that
    are temporally near each other.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will trim both the upper and lower bounds of the data, again
    using the `1.65` value for standard deviation as before. The analyst also needs
    to decide upon a window size. This is the number of surrounding data points to
    collect together for calculation. Set it too small and a group of outliers together
    will not be removed. Set it too large and we approach the previous technique of
    ignoring the trend.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use `300` here. We will use pandas’ `rolling` method to find the mean
    and standard deviation using a rolling window. Then, we calculate the upper and
    lower bounds using these values and filter our DataFrame with those bounds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now getting more refined outlier removal, as can be seen in the following
    graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Data trimmed with the moving average](img/Fig_10.12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.12 – Data trimmed with the moving average
  prefs: []
  type: TYPE_NORMAL
- en: The strong advantage of this method is that it takes into account the trend.
  prefs: []
  type: TYPE_NORMAL
- en: Error standard deviation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final method we will consider is the most precise of all. Let’s go back
    to the question of defining an outlier – it is a value that you don’t expect.
    Intuitively, we knew this when we visually inspected the data and removed points.
    So, how do you tell the computer what to expect? You build a forecast, of course.
  prefs: []
  type: TYPE_NORMAL
- en: Prophet’s `forecast` DataFrame makes predictions in the `yhat` column, but it
    also includes columns for `yhat_upper` and `yhat_lower`. These uncertainty intervals
    are by default set to 80%, but you’ll learn in [*Chapter 11*](B19630_11.xhtml#_idTextAnchor728),
    *Managing Uncertainty Intervals*, how to modify them. If we accept any errors
    contained within the uncertainty intervals, we can declare an outlier to be anything
    that falls outside of these bounds, as it would be unexpected.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, the moving average is a crude forecasting technique; the previous method
    indeed removed outliers based upon deviation in the error term. By using Prophet
    to identify the error, we allow seasonality and other effects to be included in
    our expected results.
  prefs: []
  type: TYPE_NORMAL
- en: As the most precise method available, this is unfortunately also the most prone
    to overfitting. If you do wish to use this approach, be sure to tread carefully
    with new datasets and make sure you like the results before fully automating it.
    That said, let’s see how to code it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our approach will be to first remove null values to avoid downstream issues
    when comparing our `forecast` DataFrame to our raw DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we build a Prophet model on this data, including strong regularization
    to be sure we don’t overfit. Note that there is no need to predict the future.
    We include the `interval_width` argument here to increase the uncertainty interval
    to better align with our previous examples; we’ll cover this parameter in the
    next chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we create a DataFrame that excludes those values where the `y` value
    was either greater than `yhat_upper` or lower than `yhat_lower`. These would be
    our outliers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The final DataFrame would then be used to build a whole new Prophet model,
    without needing to worry about outliers. This is what our data looks like now:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.13 – Data trimmed with an error from the forecast](img/Fig_10.13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.13 – Data trimmed with an error from the forecast
  prefs: []
  type: TYPE_NORMAL
- en: We have certainly removed what would plausibly be considered outliers. Had we
    used Prophet’s default uncertainty interval, then outlier removal may have been
    a bit too aggressive in this case. If you compare *Figure 10**.13* with the data
    plots of our other methods, this one appears to be the most surgical – for instance,
    by allowing high values that we would expect in the summer but removing those
    that are uncharacteristically high.
  prefs: []
  type: TYPE_NORMAL
- en: Using this method makes the implicit assumption that the data is stationary
    and has a constant variance, which appears to be a poor assumption throughout
    the full National Geographic dataset but a fair assumption when considering only
    the data after 2016\. The full data becomes more spread out as time advances.
    This is why more data points were dropped at later dates than earlier dates –
    just one more thing to consider when using this method.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, we have removed outliers from our data. However, there
    is one technique you can use to keep those outliers around if you believe they
    provide some valuable signal in your model but you want to control the effect.
    This technique uses the holiday functionality in Prophet. Let’s see how to do
    it next.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling outliers as special events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is one final way to work with outliers in Prophet; it’s a technique we
    used with James Rodríguez’s data in [*Chapter 8*](B19630_08.xhtml#_idTextAnchor537),
    *Influencing Trend Changepoints* – we can declare the outliers as a special event,
    essentially a holiday. By putting the outliers into the `holidays` DataFrame,
    we essentially instruct Prophet to apply trends and seasonality as if the data
    points were not outliers and capture the additional variation beyond trends and
    seasonality in the holiday term.
  prefs: []
  type: TYPE_NORMAL
- en: This can be useful if you know that the extreme observations are due to some
    external factor that you do not expect to repeat. Such external factors could
    be the World Cup or a large marketing campaign but may also be mysterious and
    unknown. You can keep the data in your model but essentially disregard it. An
    added benefit is that you can simulate what would happen if the event repeated.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll again use the National Geographic data but, this time, label that August
    2016 series of outliers as a holiday. If those additional likes were due to a
    marketing campaign surrounding the release of their book, we can predict what
    would happen if they repeated a similar marketing campaign at a later date.
  prefs: []
  type: TYPE_NORMAL
- en: We covered the creation of custom holidays in [*Chapter 6*](B19630_06.xhtml#_idTextAnchor375),
    *Forecasting Holiday Effects*, so this first step should be a review. We are simply
    creating two holidays for our August 2016 marketing event and an identical, hypothetical
    June 2020 marketing event.
  prefs: []
  type: TYPE_NORMAL
- en: Note that both events have the same name, `'Promo event'`, so Prophet knows
    to apply the same effect to each. They’re both the same number of days long, although
    they needn’t be – the holiday effects for each day of the hypothetical event will
    match the effects for each day of the measured event.
  prefs: []
  type: TYPE_NORMAL
- en: If the hypothetical event is shorter, the effects will simply cease early. If
    the hypothetical event is longer though, the effects will cease once the length
    of the measured event is reached.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by defining the promotions the same way we define holidays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we build our model using the same parameters as throughout this chapter,
    except sending the first `promo` DataFrame to the `holidays` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Our forecast perfectly models that spike of outliers, without either letting
    seasonality get out of control (the first problem we looked at in this chapter)
    or the future uncertainty explode (the second problem):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.14 – The NatGeo forecast with outliers modeled as special events](img/Fig_10.14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.14 – The NatGeo forecast with outliers modeled as special events
  prefs: []
  type: TYPE_NORMAL
- en: 'To conclude this example, let’s try one more model but, this time, include
    that hypothetical promotional event:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the future forecast National Geographic could expect if they duplicated
    the promotional activities in 2020:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.15 – The NatGeo forecast with a hypothetical promotional event](img/Fig_10.15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.15 – The NatGeo forecast with a hypothetical promotional event
  prefs: []
  type: TYPE_NORMAL
- en: With just one instance of the holiday to train with, Prophet has perfectly matched
    the holiday effects to the data, which is a good recipe for overfitting. If National
    Geographic had several similar marketing events, they could model all of them
    as the same holiday, which would average out the effects.
  prefs: []
  type: TYPE_NORMAL
- en: This technique of modeling outliers as special events can even be used to model
    dramatic shocks to an entire time series. In the next section, we’ll see how to
    apply these principles to model the effects of COVID-19 lockdowns on pedestrian
    activity.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling shocks such as COVID-19 lockdowns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In mid-2020, forecasters the world over were at a loss for what to predict in
    the coming months and years. The COVID-19 pandemic utterly transformed life around
    the world and, with it, many time series. Online purchases skyrocketed beyond
    anything anyone had predicted at the beginning of 2020; consumption of media such
    as Netflix and YouTube dramatically increased, while in-person event attendance
    dramatically decreased.
  prefs: []
  type: TYPE_NORMAL
- en: As brilliant as Prophet can be when it comes to forecasting, it cannot simply
    predict the future. In the midst of the pandemic, Prophet would have struggled
    just as much as the forecasting experts at predicting when the pandemic would
    end and how time series would behave both during and after the lockdowns. However,
    we can model such shocks to the system after the fact in order to understand what
    effect they had. And just like the NatGeo promotion we modeled in the previous
    section, we can predict what would result from a hypothetical repeat of such a
    shock. In this section, we’ll use a new dataset, the number of pedestrians in
    the Bourke Street Mall in Melbourne, Australia.
  prefs: []
  type: TYPE_NORMAL
- en: Since 2009, the city of Melbourne has counted pedestrians at several locations
    throughout the city through automated sensors. The data is shared on the city’s
    website, updated each month, and contains the hourly counts of pedestrians at
    each sensor. To make our analysis easier, the data we will use in this example
    has been pre-aggregated to daily counts, and we’ll only use the data from one
    sensor – the southern-most Bourke Street Mall sensor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bourke Street is one of Melbourne’s main streets, traditionally the entertainment
    hub of the city. It is a popular tourist destination and features many restaurants
    and major retail outlets. As the pandemic lockdowns most strongly affected tourism,
    restaurants, and in-person retail, this location seems like a prime spot to observe
    the effects of lockdown. Further, the government of the state of Victoria declared
    four official lockdown periods of varying lengths. We might expect these to mark
    clear and abrupt changes in behavior. Let’s load the dataset and take a look at
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The data shows a moderately flat trend with obvious seasonal effects and, of
    course, a severe anomaly continuing onward from the beginning of 2020:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 10.16 – A daily count of pedestrians \uFEFFin the Bourke Street Mall](img/Fig_10.16.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 10.16 – A daily count of pedestrians in the Bourke Street Mall
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset contains several columns that aren’t of interest to us for this
    analysis, so before we can see how Prophet will handle a forecast, we need to
    extract only the `Date` and `Daily_Counts` columns and rename them in Prophet’s
    format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s build a basic forecast, looking ahead a full year:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The forecast seems to be making an admirable effort to fit the trend around
    the COVID shock:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.17 – A forecast with no special consideration of shock](img/Fig_10.17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.17 – A forecast with no special consideration of shock
  prefs: []
  type: TYPE_NORMAL
- en: This model provides us no insight into what effect we can attribute to the lockdowns
    specifically. In order to model this lockdown shock, we will create holidays to
    represent days in lockdown and treat the shock similarly to how we treated NatGeo’s
    promotion in the previous section. To do this, we first need to define our lockdown
    holidays (a bit of an ironic oxymoron!).
  prefs: []
  type: TYPE_NORMAL
- en: 'In [*Chapter 6*](B19630_06.xhtml#_idTextAnchor375), *Forecasting Holiday Effects*,
    you learned how to create multi-day holidays using `lower_window` and `upper_window`.
    We’ll do that again here, defining each of the four official lockdowns with a
    start date and using `upper_window` to set the length of the lockdown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We don’t specify any future dates, so Prophet will not attempt to repeat these
    lockdowns at any point in the future. When we create our next model, we pass this
    `lockdown` DataFrame to the `holidays` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Our resulting forecast looks very similar to the one in *Figure 10**.17*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.18 – A forecast with the lockdown modeled as holidays](img/Fig_10.18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.18 – A forecast with the lockdown modeled as holidays
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, however, when we look at the `components` plot, we’ll see the specific
    effect of those lockdowns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We see a roughly 100% reduction in pedestrian numbers in the `holidays` plot!
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.19 – The components plot showing the effect of COVID-19 lockdowns](img/Fig_10.19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.19 – The components plot showing the effect of COVID-19 lockdowns
  prefs: []
  type: TYPE_NORMAL
- en: The plot of holidays in *Figure 10**.19* demonstrates how effectively the lockdowns
    brought pedestrian traffic nearly to a standstill. Another, possibly even longer-lasting,
    effect of the lockdowns has been the transition to remote work. Many workers throughout
    the world have been able to perform their job duties from home, and are no longer
    as strictly chained to the Monday–Friday, 9:00–5:00 schedule. We can hypothesize
    that this might change the weekly seasonality to some degree. The weekly peak
    shown in *Figure 10**.19* indicates that Friday is the most popular day on Bourke
    Street, followed by Saturday. Does this pattern remain true post-COVID-19?
  prefs: []
  type: TYPE_NORMAL
- en: 'You learned how to create conditional seasonalities in [*Chapter 5*](B19630_05.xhtml#_idTextAnchor254),
    *Working with Seasonality*; let’s use that same principle now to create a pre-COVID-19
    weekly seasonality and a post-COVID-19 weekly seasonality. We will define a `pre_covid`
    seasonality for all dates before the first lockdown began and a `post_covid` seasonality
    for all dates after the final lockdown ended. We could also create a `during_covid`
    seasonality for those dates in between, but as pedestrian traffic ground to a
    halt with no data available, any insights gained from such a seasonality would
    be meaningless at best and potentially even misleading:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We’ll now make a third forecast of this data, but this time, we will turn off
    the default weekly seasonality and add our two conditional weekly seasonalities.
    Remember that we must add these conditions to the `future` DataFrame as well!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this code will produce the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.20 – A forecast with conditional weekly seasonalities](img/Fig_10.20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.20 – A forecast with conditional weekly seasonalities
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s take a look at the `components` plot to see what lasting effect
    the lockdowns produced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The trend, holidays, and yearly seasonality look much the same as in *Figure
    10**.19*, so they have been cropped out of the following plot, which only shows
    the two weekly seasonalities for pre- and post-COVID-19 lockdowns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.21 – A cropped components plot showing the conditional seasonalities](img/Fig_10.21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.21 – A cropped components plot showing the conditional seasonalities
  prefs: []
  type: TYPE_NORMAL
- en: As we noted in *Figure 10**.19*, Friday was the most popular day on Bourke Street
    pre-COVID-19\. However, post-COVID-19, it appears that Saturday is the most popular
    day. With more people working from home, it seems that there might be fewer post-work
    happy hours on Friday, and instead, people are staying in! Perhaps Netflix is
    seeing a reverse pattern in its consumption data…
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Outliers are a fact of any data analysis, but they do not always have to cause
    headaches. Prophet is very robust at handling most outliers without any special
    consideration, but sometimes problems can arise. In this chapter, you learned
    about the two problems most common with outliers in Prophet – uncontrolled seasonality
    and exploding uncertainty intervals.
  prefs: []
  type: TYPE_NORMAL
- en: In both cases, simply removing the data is the best approach to solving the
    problem. As long as data exists in other periods of the seasonality cycles for
    those gaps where data was removed, Prophet has no problem finding a good fit.
  prefs: []
  type: TYPE_NORMAL
- en: You also learned several automated outlier detection techniques, from the basic
    techniques of Winsorization and trimming, which tend not to work well on time
    series exhibiting a trend, to the more advanced technique of stacking forecasts
    and using errors in the first model to remove outliers for the second model.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you learned how to model both outliers and significant, lasting shocks
    such as COVID-19 lockdowns as special events, which has much the same effect as
    removing the data while retaining the information from that outlier. This technique
    has the advantage of allowing you to simulate a similar shock occurring in the
    future with your time series.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll look at a concept related to outliers – uncertainty
    intervals.
  prefs: []
  type: TYPE_NORMAL
