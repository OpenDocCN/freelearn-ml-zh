<html><head></head><body>
		<div id="_idContainer072">
			<h1 id="_idParaDest-75" class="chapter-number"><a id="_idTextAnchor074"/>4</h1>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor075"/>Data Storage</h1>
			<p>Data storage in the cloud has become very common, not just for personal usage but also for business, computational, and application purposes as well. On the personal side, cloud storage is provided by well-known companies, ranging from a free usage tier of a few <strong class="bold">Gigabytes</strong> (<strong class="bold">GBs</strong>), to pay monthly or yearly plans for <strong class="bold">Terabytes</strong> (<strong class="bold">TBs</strong>) of data. These services are well integrated with applications on mobile devices, enabling users to store thousands of pictures, videos, songs, and other types <span class="No-Break">of files.</span></p>
			<p>For applications requiring high-performance computations, cloud data storage plays an even bigger role. For example, training <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) models over large datasets generally requires algorithms to run in a distributed fashion. If data is stored on the cloud, then it makes it much easier and more efficient for the ML platform to partition the data stored in the cloud and make these separate partitions available to the distributed components of the model training job. Similarly, for several other applications requiring large data amounts and high throughput, it makes much more sense to use cloud data storage to avoid throttling local storage. In addition, cloud data storage almost always has built-in redundancy to avoid hardware failures, accidental deletes, and hence loss of data. There are also several security and governance tools and features that are always provided with cloud data storage services. Furthermore, the true cost of ownership of data storage in the cloud is significantly reduced due to scale and infrastructure maintenance being managed by the storage <span class="No-Break">service provider.</span></p>
			<p>AWS provides several options for cloud data storage. In this chapter, we will learn about the various AWS data storage services, along with the security, access management, and governance aspects of these services. In addition, we will also learn about the tiered storage options to save cloud data <span class="No-Break">storage costs.</span></p>
			<p>We will cover the following topics in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>AWS services for <span class="No-Break">storing data</span></li>
				<li>Data security <span class="No-Break">and governance</span></li>
				<li>Tiered storage for <span class="No-Break">cost optimization</span></li>
				<li>Choosing the right storage option for <strong class="bold">High-Performance Computing</strong> (<span class="No-Break"><strong class="bold">HPC</strong></span><span class="No-Break">) workloads</span></li>
			</ul>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor076"/>Technical requirements</h1>
			<p>The main technical requirements for being able to work with the various AWS storage options in this chapter are to have an AWS account and the appropriate permissions to use these <span class="No-Break">storage services.</span></p>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor077"/>AWS services for storing data</h1>
			<p>AWS offers three different types of data storage services: object, file, and block. Depending <a id="_idIndexMarker303"/>on the need for the application, one or more of these types of services can be used. We will go through the AWS services spanning these storage categories in this section. The various AWS data storage services are shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/B18493_04_001.jpg" alt="Figure 4.1 – AWS data storage services"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – AWS data storage services</p>
			<p>In the next section, we will discuss the various storage options provided <span class="No-Break">by AWS.</span></p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor078"/>Amazon Simple Storage Service (S3)</h2>
			<p><strong class="bold">Amazon S3</strong> is one <a id="_idIndexMarker304"/>of the most commonly used cloud data storage services for web applications, and high-performance compute use <a id="_idIndexMarker305"/>cases. It is Amazon’s object storage service providing virtually unlimited data storage. Some of the advantages of using Amazon S3 include very high scalability, durability, data availability, security, and performance. Amazon S3 can be used for a variety of cloud-native applications, ranging from simple data storage to very large data lakes to web hosting and high-performance applications, such as training very advanced and compute-intensive ML models. Amazon S3 offers several classes of storage options with differences in terms of data access, resiliency, archival needs, and cost. We can choose the storage class that best suits our use case and business needs. There is also an option for cost saving when the access pattern is unknown or changes over time (S3 Intelligent-Tiering). We will discuss these different S3 storage classes in detail in the <em class="italic">Tiered storage for cost optimization</em> section of <span class="No-Break">this chapter.</span></p>
			<h3>Key capabilities and features of Amazon S3</h3>
			<p>In Amazon S3, data is stored as objects in <em class="italic">buckets</em>. An object is a file and any metadata that <a id="_idIndexMarker306"/>describes the file, and buckets are the resources (containers) for the objects. Some of the key capabilities of Amazon S3 are <span class="No-Break">discussed next.</span></p>
			<h4>Data durability</h4>
			<p>Amazon S3 is designed to provide very high levels of durability to the data, up to 99.999999999%. This means that the chances of data objects stored in Amazon S3 getting lost <a id="_idIndexMarker307"/>are extremely low (average expected loss of approximately 0.000000001% of objects, or 1 out of 10,000 objects every 10 million years). For HPC applications, data durability is of the utmost importance. For example, for training an ML model, data scientists need to carry out various experiments on the same dataset in order to fine-tune the model parameters to get the best performance. If the data storage from which training and validation data is read is not durable for these experiments, then the results of the trained model will not be consistent and hence can lead to incorrect insights, as well as bad inference results. For this reason, Amazon S3 is used in many ML and other data-dependent HPC applications for storing very large amounts <span class="No-Break">of data.</span></p>
			<h4>Object size</h4>
			<p>In Amazon S3, we can store objects up to 5 TB in size. This is especially useful for applications <a id="_idIndexMarker308"/>that require processing large files, such as videos (for example, high-definition movies or security footage), large logs, or other similar files. Many high-performance compute applications, such as training ML models for a video classification example, require processing thousands of such large files to come up with a model that makes inferences on unseen data well. A deep learning model can read these large files from Amazon S3 one (or more) at a time, store them temporarily on the model training virtual machine, compute and optimize model parameters, and then move on to the next object (file). This way, even machines with smaller disk space and memory can be used to train these computationally intensive models over large data files. Similarly, at the time of model inference, if there is a need to store the data, it can be stored in Amazon S3 for up to 5 TB of <span class="No-Break">object size.</span></p>
			<h4>Storage classes</h4>
			<p>Amazon S3 has various storage classes. We can store data in any of these classes and can also <a id="_idIndexMarker309"/>move the data across the classes. The right storage class to pick for storing data depends on our data storage, cost, and retention needs. The different S3 storage classes are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><span class="No-Break">S3 Standard</span></li>
				<li>S3 <span class="No-Break">Standard-Infrequent Access</span></li>
				<li>S3 One <span class="No-Break">Zone-Infrequent Access</span></li>
				<li><span class="No-Break">S3 Intelligent-Tiering</span></li>
				<li>S3 Glacier <span class="No-Break">Instant Retrieval</span></li>
				<li>S3 Glacier <span class="No-Break">Flexible Retrieval</span></li>
				<li>S3 Glacier <span class="No-Break">Deep Archive</span></li>
				<li><span class="No-Break">S3 Outposts</span></li>
			</ul>
			<p>We will <a id="_idIndexMarker310"/>learn about these storage classes in the <em class="italic">Tiered storage for cost optimization</em> section of <span class="No-Break">this chapter.</span></p>
			<h4>Storage management</h4>
			<p>Amazon S3 also has various advanced storage management options, such as data replication, prevention of accidental deletion of data, and data version control. Data in Amazon S3 <a id="_idIndexMarker311"/>can be replicated into destination buckets in the same or different AWS Regions. This can be done to add redundancy and hence reliability and also improve performance and latency. This is quite important for HPC applications as well since real-time HPC applications that need access to data stored in Amazon S3 will benefit from accessing data from a geographically closer AWS Region. Performance is generally accelerated by up to 60% when datasets are replicated across multiple AWS Regions. Amazon S3 also supports batch operations for data access, enabling various S3 operations to be carried out on billions of objects with a single API call. In addition, lifecycle policies can be configured for objects stored in Amazon S3. Using these policies, S3 objects can be moved automatically to different storage classes depending on access need, resulting in <span class="No-Break">cost optimization.</span></p>
			<h4>Storage monitoring</h4>
			<p>Amazon S3 <a id="_idIndexMarker312"/>also has several monitoring capabilities. For example, tags can be assigned to S3 buckets, and AWS cost allocation reports can be used to view aggregated usage and cost using these tags. Amazon CloudWatch can also be used to view the health of S3 buckets. In addition, bucket- and object-level activities can also be tracked using AWS CloudTrail. <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.2</em> shows an example of various storage monitoring tools working with an Amazon <span class="No-Break">S3 bucket:</span></p>
			<div>
				<div id="_idContainer054" class="IMG---Figure">
					<img src="image/B18493_04_002.jpg" alt="Figure 4.2 – S3 storage monitoring and management"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – S3 storage monitoring and management</p>
			<p>The <a id="_idIndexMarker313"/>preceding figure shows that <a id="_idIndexMarker314"/>we can also configure Amazon <strong class="bold">Simple Notification Service</strong> (<strong class="bold">SNS</strong>) to trigger AWS Lambda to carry out various tasks in the case of certain events, such as new file uploads and <span class="No-Break">so on.</span></p>
			<h4>Data transfer</h4>
			<p>For any <a id="_idIndexMarker315"/>application built upon large amounts of data and using S3, the data first needs to be transferred to S3. There are various services provided by AWS that work with S3 for different data transfer needs, including hybrid (premises/cloud) storage and online and offline data transfer. For example, if we <a id="_idIndexMarker316"/>want to extend our on-premise storage with cloud AWS storage, we can use <strong class="bold">AWS Storage Gateway</strong> (<span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.3</em>). Some of the commonly implemented use cases for AWS Storage Gateway are the replacement of tape libraries, cloud storage backend file shares, and low-latency caching of data for <span class="No-Break">on-premise applications.</span></p>
			<div>
				<div id="_idContainer055" class="IMG---Figure">
					<img src="image/B18493_04_003.jpg" alt="Figure 4.3 – Data transfer example using AWS Storage Gateway"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.3 – Data transfer example using AWS Storage Gateway</p>
			<p>For use <a id="_idIndexMarker317"/>cases requiring online data transfer, AWS DataSync can be used to efficiently transfer hundreds of terabytes into Amazon S3. In addition, AWS Transfer Family can also be used to transfer data to S3 using SFTP, FTPS, and FTP. For offline data transfer use cases, AWS Snow Family has a few options available, including AWS Snowcone, AWS Snowball, and AWS Snowmobile. For more details about the AWS Snow Family, refer to the <em class="italic">Further </em><span class="No-Break"><em class="italic">reading</em></span><span class="No-Break"> section.</span></p>
			<h4>Performance</h4>
			<p>One big <a id="_idIndexMarker318"/>advantage of S3 for HPC applications is that it supports parallel requests. Each S3 prefix supports 3,500 requests per second to add data and 5,500 requests per second to retrieve data. Prefixes are used to organize data in S3 buckets. These are a sequence of characters at the beginning of an object’s key name. We can have as many prefixes as we need in parallel, and each prefix will support this throughput. This way, we can achieve the desired throughput for our application by adding prefixes. In addition, if there is a long geographic separation between the client and the S3 bucket, we can use Amazon S3 Transfer Acceleration to transfer data. Amazon CloudFront is a globally distributed network of <span class="No-Break">edge locations.</span></p>
			<p>Using S3 Transfer Allocation, data is first transferred to an edge location in Amazon CloudFront. From the edge location, an optimized high-bandwidth and low-latency network path is then used to transfer the data to the S3 bucket. Furthermore, data can also be <a id="_idIndexMarker319"/>cached in CloudFront edge locations for frequently accessed requests, further optimizing performance. These performance-related features help in improving throughput and reducing latency for data access, especially suited to various <span class="No-Break">HPC applications.</span></p>
			<h4>Consistency</h4>
			<p>Data storage <a id="_idIndexMarker320"/>requests to Amazon S3 have strong read-after-write consistency. This means that any data written (new or an overwrite) to S3 is <span class="No-Break">available immediately.</span></p>
			<h4>Analytics</h4>
			<p>Amazon S3 also has analytics capabilities, including S3 Storage Lens and S3 Storage Class Analysis. S3 Storage Lens can be used to improve storage cost efficiency, as well as to provide <a id="_idIndexMarker321"/>best practices for data protection. In addition, it can be used to look into object storage usage and activity trends. It can provide a single view across thousands of accounts in an organization and can generate insights on various levels, such as account, bucket, and prefix. Using S3 Storage Class, we can optimize cost by deciding on when to move data to the right storage class. This information can be used to configure the lifecycle policy to make the data transfer for the S3 bucket. Amazon S3 Inventory is another S3 feature that generates daily or weekly reports, including bucket names, key names, last modification dates, object size, class, replication, encryption status, and a few <span class="No-Break">additional properties.</span></p>
			<h4>Data security</h4>
			<p>Amazon S3 has various security measures and features. These features include blocking unauthorized <a id="_idIndexMarker322"/>users from accessing data, locking objects to prevent deletions, modifying object ownership for access control, identity and access management, discovery and protection of sensitive data, server-side and client-side encryption, the inspection of an AWS environment, and connection to S3 from on-premise or in the cloud using private IP addresses. We will learn about these data security and access management features in detail in the <em class="italic">Data security and </em><span class="No-Break"><em class="italic">governance</em></span><span class="No-Break"> section.</span></p>
			<h3>Amazon S3 example</h3>
			<p>To be able to store data in an S3 bucket, we first need to create the bucket. Once the bucket <a id="_idIndexMarker323"/>is created, we can upload objects to the bucket. After uploading the object, we can download, move, open, or delete it. In order to create an S3 bucket, there are certain prerequisites listed <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Signing up for an <span class="No-Break">AWS account</span></li>
				<li>Creating <a id="_idIndexMarker324"/>an <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) user or a federated user assuming an <span class="No-Break">IAM role</span></li>
				<li>Signing in as an <span class="No-Break">IAM user</span></li>
			</ul>
			<p>Details of how to carry out these prerequisite steps can be found on Amazon S3’s documentation web page (see the <em class="italic">Further </em><span class="No-Break"><em class="italic">reading</em></span><span class="No-Break"> section).</span></p>
			<h3>S3 bucket creation</h3>
			<p>We can <a id="_idIndexMarker325"/>create an S3 bucket by logging into the AWS management console and selecting S3 in the services. Once in the S3 console, we will see a screen like that shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer056" class="IMG---Figure">
					<img src="image/B18493_04_004.jpg" alt="Figure 4.4 – Amazon S3 console"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.4 – Amazon S3 console</p>
			<p>As <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.4</em> shows, we <a id="_idIndexMarker326"/>do not have any S3 buckets so far in our account. To create an S3 bucket, perform the <span class="No-Break">following steps:</span></p>
			<ol>
				<li>Click on one of the <strong class="bold">Create bucket</strong> buttons shown on this page. <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.5</em> shows the <strong class="bold">Create bucket</strong> page on the <span class="No-Break">S3 console.</span></li>
				<li>Next, we need to specify <strong class="bold">Bucket name</strong> and <strong class="bold">AWS Region</strong>. Note that the S3 bucket name needs to be <span class="No-Break">globally unique:</span></li>
			</ol>
			<div>
				<div id="_idContainer057" class="IMG---Figure">
					<img src="image/B18493_04_005.jpg" alt="Figure 4.5 – Amazon S3 bucket creation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.5 – Amazon S3 bucket creation</p>
			<ol>
				<li value="3">We can also select certain bucket settings from one of our existing S3 buckets. On the S3 <strong class="bold">Create bucket</strong> page, we can also define whether the objects in the bucket <a id="_idIndexMarker327"/>are owned by the account creating the bucket or not, as other AWS accounts can also own the objects in the bucket. In addition, we can also select whether we want to block all public access to the bucket (as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.6</em>). There are also other options that we can select on the S3 bucket creation page, such as versioning, tags, encryption, and <span class="No-Break">object locking:</span></li>
			</ol>
			<div>
				<div id="_idContainer058" class="IMG---Figure">
					<img src="image/B18493_04_006.jpg" alt="Figure 4.6 – Public access options for the S3 bucket"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.6 – Public access options for the S3 bucket</p>
			<ol>
				<li value="4">Once <a id="_idIndexMarker328"/>the bucket has been created, it will show up in the S3 console as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.7</em>, where we have created a bucket named <strong class="source-inline">myhpcbucket</strong>. We can add objects to it using <a id="_idIndexMarker329"/>the console, AWS <strong class="bold">Command Line Interface</strong> (<strong class="bold">CLI</strong>), AWS SDK, or Amazon S3 <span class="No-Break">Rest API:</span></li>
			</ol>
			<div>
				<div id="_idContainer059" class="IMG---Figure">
					<img src="image/B18493_04_007.jpg" alt="Figure 4.7 – Amazon S3 console showing myhpcbucket"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.7 – Amazon S3 console showing myhpcbucket</p>
			<p>We <a id="_idIndexMarker330"/>can click on the bucket name and view objects stored in it along with bucket properties, permissions, metrics, management options, and <span class="No-Break">access points.</span></p>
			<p>In this section, we have learned about the Amazon S3 storage class, its key features and capabilities, and how to create an Amazon S3 bucket. In the next section, we are going to discuss Amazon Elastic File System, which is the file system for Amazon Elastic Compute <span class="No-Break">Cloud instances.</span></p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor079"/>Amazon Elastic File System (EFS)</h2>
			<p><strong class="bold">Amazon Elastic File System</strong> (<strong class="bold">EFS</strong>) is a fully managed serverless elastic NFS file system <a id="_idIndexMarker331"/>specifically designed for Linux workloads. It <a id="_idIndexMarker332"/>can quickly scale up to petabytes of data automatically and is well suited to work with on-premise resources as well as with various AWS services. Amazon EFS is designed such that <a id="_idIndexMarker333"/>thousands of <strong class="bold">Amazon Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>) instances can be provided with parallel shared access. In addition <a id="_idIndexMarker334"/>to EC2, EFS file systems can also be <a id="_idIndexMarker335"/>accessed by <strong class="bold">Amazon Elastic Container Service</strong> (<strong class="bold">ECS</strong>), <strong class="bold">Amazon Elastic Kubernetes Service</strong> (<strong class="bold">EKS</strong>), <strong class="bold">AWS Fargate</strong>, and <strong class="bold">AWS Lambda</strong> functions <a id="_idIndexMarker336"/>through a file system interface. The <a id="_idIndexMarker337"/>following are some of the common EFS <span class="No-Break">use cases:</span></p>
			<ul>
				<li><strong class="bold">High-performance compute</strong>: Since Amazon EFS is a shared file system, it is ideal <a id="_idIndexMarker338"/>for applications that require distributed workload across many instances. Applications and use cases requiring high-performance computes, such as image and video processing, content management, and ML applications, such as feature engineering, data processing, model training, numerical optimization, big data analytics, and similar applications, can benefit from <span class="No-Break">Amazon EFS.</span></li>
				<li><strong class="bold">Containerized applications</strong>: Amazon EFS is a very good fit for containerized applications <a id="_idIndexMarker339"/>because of its durability, which is a very important requirement of these applications. EFS integrates with Amazon container-based services such as Amazon ECS, Amazon EKS, and <span class="No-Break">AWS Fargate.</span></li>
				<li><strong class="bold">DevOps</strong>: Amazon <a id="_idIndexMarker340"/>EFS can be used for DevOps because of its capability to share code. This helps with code modification and the application of bug fixes and enhancements in a fast, agile, and secure manner, resulting in quick turnaround time based on <span class="No-Break">customer feedback.</span></li>
				<li><strong class="bold">Database backup</strong>: Amazon EFS is also often used as a database backup. This is because <a id="_idIndexMarker341"/>of the very high durability and reliability of EFS, and its low cost, along with being a POSIX-compliant file storage system – all of these often being requirements for a database backup from which the main database can be restored quickly in case of a loss <span class="No-Break">or emergency.</span></li>
			</ul>
			<p>In the next section, we will discuss the key capabilities of <span class="No-Break">Amazon EFS.</span></p>
			<h3>Key capabilities and features of Amazon EFS</h3>
			<p>In this <a id="_idIndexMarker342"/>section, we will discuss some of the key capabilities and features of Amazon EFS. Some of the key capabilities of Amazon S3 also apply to <span class="No-Break">Amazon EFS.</span></p>
			<h4>Durability</h4>
			<p>Like Amazon S3, Amazon EFS is also very highly durable and reliable, offering 99.999999999% durability. EFS achieves this high level of durability and redundancy by storing <a id="_idIndexMarker343"/>everything across multiple <strong class="bold">Availability Zones</strong> (<strong class="bold">AZs</strong>) within <a id="_idIndexMarker344"/>the same AWS Region (unless we select EFS One Zone storage class for the EFS storage). Because data is available across multiple AZs, EFS has the ability to recover and repair very quickly from concurrent <span class="No-Break">device failures.</span></p>
			<h4>Storage classes</h4>
			<p>Amazon EFS <a id="_idIndexMarker345"/>also offers multiple options for storage via storage classes. These storage classes are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Amazon <span class="No-Break">EFS Standard</span></li>
				<li>Amazon EFS <span class="No-Break">One Zone</span></li>
				<li>Amazon EFS <span class="No-Break">Standard-Infrequent Access</span></li>
				<li>Amazon EFS One <span class="No-Break">Zone-Infrequent Access</span></li>
			</ul>
			<p>We will discuss these classes in the <em class="italic">Tiered storage for cost optimization</em> section. We can easily move files between storage classes for cost and performance optimization <span class="No-Break">using policies.</span></p>
			<h4>Performance and throughput</h4>
			<p>Amazon <a id="_idIndexMarker346"/>EFS has two modes each for performance and throughput. For performance modes, it has <strong class="bold">General Purpose</strong> and <strong class="bold">Max I/O</strong>. General Purpose mode <a id="_idIndexMarker347"/>provides low latency for random as well as sequential input-output file system operations. Max I/O, on <a id="_idIndexMarker348"/>the other hand, is designed for very high throughput and operations per second. It is, therefore, very well suited for high-performance and highly parallelized <span class="No-Break">compute applications.</span></p>
			<p>For throughput, EFS has Bursting (default) and Provisioned modes. In Bursting mode, the <a id="_idIndexMarker349"/>throughput scales with the size of the file system and can burst dynamically depending on the nature of the workload. In Provisioned mode, throughput can be provisioned depending on the dedicated throughput needed by the application. It does not depend on the size of the <span class="No-Break">file system.</span></p>
			<h4>Scalability</h4>
			<p>Amazon <a id="_idIndexMarker350"/>EFS is highly elastic and scalable. It grows up and down in size as more data is added or removed and is designed <a id="_idIndexMarker351"/>for high throughput, <strong class="bold">Input/Output Operations Per Second</strong> (<strong class="bold">IOPS</strong>), and low latency for a wide variety of workloads and use cases. It also has the capability to provide very high burst throughput for unpredictable and spiky workloads, supporting up to 10 GB/second and 500,000 IOPS at the time <span class="No-Break">of writing.</span></p>
			<h4>AWS Backup</h4>
			<p>Amazon <a id="_idIndexMarker352"/>EFS works with AWS Backup, which is a fully managed backup service. It automates and enables us to centrally manage the EFS file systems, removing costly and tedious <span class="No-Break">manual processes.</span></p>
			<h4>Data transfer</h4>
			<p>Like <a id="_idIndexMarker353"/>Amazon S3, Amazon EFS also works with various AWS data transfer services, such as AWS DataSync and AWS Transfer Family, for transferring data in and out of EFS for one-time migration, as well as for periodic synchronization, replication, and <span class="No-Break">data recovery.</span></p>
			<h3>An Amazon EFS example</h3>
			<p>We can <a id="_idIndexMarker354"/>create an Amazon EFS file system either using the AWS Management Console or the AWS CLI. In this section, we will see an example of creating an EFS file system using the AWS <span class="No-Break">Management Console:</span></p>
			<ol>
				<li value="1">When we log into AWS Management Console and browse to Amazon EFS service, we will see the main page like the one shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.8</em>. It also lists all the EFS <a id="_idIndexMarker355"/>file systems that we have created in the AWS Region that we are <span class="No-Break">looking at:</span></li>
			</ol>
			<div>
				<div id="_idContainer060" class="IMG---Figure">
					<img src="image/B18493_04_008.jpg" alt="Figure 4.8 – Amazon EFS landing page"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.8 – Amazon EFS landing page</p>
			<ol>
				<li value="2">To create an Amazon EFS file system, we click on the <strong class="bold">Create file system</strong> button. When we click this button, we are shown a screen as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.9</em>. Here, we can pick any name for our <span class="No-Break">file system.</span></li>
			</ol>
			<div>
				<div id="_idContainer061" class="IMG---Figure">
					<img src="image/B18493_04_009.jpg" alt="Figure 4.9 – Creating an Amazon EFS file system"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.9 – Creating an Amazon EFS file system</p>
			<ol>
				<li value="3">For the <a id="_idIndexMarker356"/>file system, select a <strong class="bold">Virtual Private Cloud</strong> (<strong class="bold">VPC</strong>), and also select <a id="_idIndexMarker357"/>whether we want it across all AZs in our region or just <span class="No-Break">one AZ.</span></li>
				<li>We can also click on the <strong class="bold">Customize</strong> button to configure other options, such as <strong class="bold">Lifecycle management</strong> (<span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.10</em>), <strong class="bold">Performance mode</strong> and <strong class="bold">Throughput mode</strong> (<span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.11</em>), <strong class="bold">Encryption</strong>, <strong class="bold">Tags</strong>, network options, and the <strong class="bold">File </strong><span class="No-Break"><strong class="bold">system</strong></span><span class="No-Break"> policy.</span></li>
			</ol>
			<div>
				<div id="_idContainer062" class="IMG---Figure">
					<img src="image/B18493_04_010.jpg" alt="Figure 4.10 – Selecting options for an Amazon EFS file system"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.10 – Selecting options for an Amazon EFS file system</p>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="image/B18493_04_011.jpg" alt="Figure 4.11 – Selecting additional options for Amazon EFS"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.11 – Selecting additional options for Amazon EFS</p>
			<ol>
				<li value="5">Clicking on <strong class="bold">Next</strong> and then <strong class="bold">Create</strong> will create the Amazon EFS file system. The EFS file <a id="_idIndexMarker358"/>system we have created is shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.12</em></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="image/B18493_04_012.jpg" alt="Figure 4.12 – Created EFS file system"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.12 – Created EFS file system</p>
			<ol>
				<li value="6">We can click on the file system to view its various properties as well as to get the command to mount it to a Linux instance as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.13</em>. Once the EFS file <a id="_idIndexMarker359"/>system is mounted, we can use it just like a regular <span class="No-Break">file system.</span></li>
			</ol>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="image/B18493_04_013.jpg" alt="Figure 4.13 – Mounting options and commands for the EFS file system"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.13 – Mounting options and commands for the EFS file system</p>
			<p>Let’s discuss Amazon <strong class="bold">Elastic Block Store</strong> (<strong class="bold">EBS</strong>) and its key features and capabilities in the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor080"/>Amazon EBS</h2>
			<p><strong class="bold">Amazon EBS</strong> is a scalable, high-performance block storage service that can be used to create storage <a id="_idIndexMarker360"/>volumes that attach to EC2 instances. These volumes can be used for various purposes, such as a regular block storage <a id="_idIndexMarker361"/>volume, creating file systems on top of these, or even running databases. The following are some of the <a id="_idIndexMarker362"/>common use cases where Amazon EBS <span class="No-Break">is used:</span></p>
			<ul>
				<li>EBS can be used for big data analytics, where frequent resizing of clusters is needed, especially for Hadoop <span class="No-Break">and Spark.</span></li>
				<li>Several types of databases can be deployed using Amazon EBS. Some examples include MySQL, Oracle, Microsoft SQL Server, Cassandra, <span class="No-Break">and MongoDB.</span></li>
				<li>If we are running a computation job on an EC2 instance and need storage volume <a id="_idIndexMarker363"/>attached to it to read the data and write results without the need to scale across multiple instances, then EBS serves as a <span class="No-Break">good option.</span></li>
			</ul>
			<p>Next, let’s look at some of the key features and capabilities of <span class="No-Break">Amazon EBS.</span></p>
			<h3>Key features and capabilities of Amazon EBS</h3>
			<p>In this <a id="_idIndexMarker364"/>section, we discuss the key features and capabilities of Amazon EBS, such as volume types, snapshots, elastic volumes, EBS-optimized instances, <span class="No-Break">and durability.</span></p>
			<h4>Volume types</h4>
			<p>EBS <a id="_idIndexMarker365"/>volumes are divided into two main categories: <strong class="bold">SSD-backed storage</strong> and <strong class="bold">HDD-backed storage</strong>. We discuss these <span class="No-Break">categories here:</span></p>
			<ul>
				<li><strong class="bold">SSD-backed storage</strong>: In <a id="_idIndexMarker366"/>SSD-backed storage, performance depends mostly on IOPS and is best suited for transactional workloads, for example, databases and boot volumes. There are two main types of SSD-backed <span class="No-Break">storage volumes:</span><ul><li><strong class="bold">Provisioned IOPS SSD volumes</strong>: They are very high throughput volumes <a id="_idIndexMarker367"/>and are designed to provide single-digit millisecond latencies while delivering the provisioned performance 99.9% of the time. They are especially suited for critical applications that require very <span class="No-Break">high uptime.</span></li><li><strong class="bold">General purpose SSD volumes</strong>: These storage volumes also offer single-digit <a id="_idIndexMarker368"/>millisecond latency while delivering the provisioned performance 99% of the time. They are especially suited for transactional workloads, virtual desktops, boot volumes, and <span class="No-Break">similar applications.</span></li></ul></li>
				<li><strong class="bold">HDD-backed storage</strong>: In HDD-backed storage, performance depends mostly on MB/s and is best suited <a id="_idIndexMarker369"/>for throughput-intensive workloads, for example, MapReduce and log processing. There are also two main types of HDD-backed <span class="No-Break">storage volumes:</span><ul><li><strong class="bold">Throughput optimized HDD volumes</strong>: These volumes deliver performance <a id="_idIndexMarker370"/>measured in MB/s and are best suited for applications such as MapReduce, Kafka, log processing, and <span class="No-Break">ETL workloads.</span></li><li><strong class="bold">Cold HDD volumes</strong>: They provide the lowest cost of all EBS volumes and are <a id="_idIndexMarker371"/>backed by hard disk drives. These volumes are best suited for infrequently accessed workloads, such as <span class="No-Break">cold datasets.</span></li></ul></li>
			</ul>
			<p>The option of picking the appropriate category for EBS volume provides user flexibility depending on the <span class="No-Break">use case.</span></p>
			<h4>Snapshots</h4>
			<p>Amazon EBS has the ability to store the volume snapshots to Amazon S3. This is done incrementally, adding only the blocks of data that have been changed since the last snapshot. The <a id="_idIndexMarker372"/>data life cycle for EBS snapshots can be used to schedule the automated creation and deletion of EBS. These snapshots can be used not just for data recovery but also for initiating new volumes, expanding volume sizes, and moving EBS volumes across AZs in an <span class="No-Break">AWS Region.</span></p>
			<h4>Elastic volumes</h4>
			<p>Using <a id="_idIndexMarker373"/>Amazon EBS Elastic Volumes, we can increase the capacity of the volume dynamically at a later point and can also change the type of volume without <span class="No-Break">any downtime.</span></p>
			<h4>EBS-optimized instances</h4>
			<p>To fully <a id="_idIndexMarker374"/>utilize the IOPS configured for an EBS volume and provide maximum performance, some EC2 instances can be launched as EBS-optimized instances. This ensures dedicated throughput between Amazon EC2 instance and Amazon <span class="No-Break">EBS volume.</span></p>
			<h3>Durability</h3>
			<p>Like Amazon <a id="_idIndexMarker375"/>S3 and Amazon EFS, Amazon EBS is also highly durable and reliable. Data in Amazon EBS is replicated on multiple servers in an AZ to provide redundancy and recovery in case any single component in the volume <span class="No-Break">storage fails.</span></p>
			<h3>EBS volume creation</h3>
			<p>When creating <a id="_idIndexMarker376"/>an EC2 instance, we can add additional EBS volumes to it, as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.14</em> in the <strong class="bold">Add Storage</strong> step. In addition, we can also add new volumes from the EC2 management console after the instance has been launched. In the EC2 management console, we can review our existing volumes and snapshots along with lifecycle <span class="No-Break">management policies.</span></p>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="image/B18493_04_014.jpg" alt="Figure 4.14 – Adding an EBS volume during the EC2 instance creation process"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.14 – Adding an EBS volume during the EC2 instance creation process</p>
			<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.15</em> shows an example where we have two EBS volumes, along with their various <span class="No-Break">configuration parameters:</span></p>
			<div>
				<div id="_idContainer067" class="IMG---Figure">
					<img src="image/B18493_04_015.jpg" alt="Figure 4.15 – Volumes page in EC2 management console showing two EBS volumes that were created"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.15 – Volumes page in EC2 management console showing two EBS volumes that were created</p>
			<p>So far, in this <a id="_idIndexMarker377"/>chapter, we have learned about Amazon S3, Amazon EFS, and Amazon EBS. In the next section, we discuss the Amazon FSx family of <span class="No-Break">file systems.</span></p>
			<h2 id="_idParaDest-82"><a id="_idTextAnchor081"/>Amazon FSx</h2>
			<p>Amazon FSx is a <a id="_idIndexMarker378"/>feature-rich, scalable, high-performance, and cost-effective <a id="_idIndexMarker379"/>family of file systems. It consists of the following commonly used four <span class="No-Break">file systems:</span></p>
			<ul>
				<li>Amazon FSx for <span class="No-Break">NetApp ONTAP</span></li>
				<li>Amazon FSx for Windows <span class="No-Break">File Server</span></li>
				<li>Amazon FSx <span class="No-Break">for Lustre</span></li>
				<li>Amazon FSx <span class="No-Break">for OpenZFS</span></li>
			</ul>
			<p>Some of the <a id="_idIndexMarker380"/>common examples where the FSx family of file systems is used are <span class="No-Break">the following:</span></p>
			<ul>
				<li>FSx can deliver very low latency (sub-millisecond) and millions of IOPS and is highly scalable, making it ideal for high-performance compute applications, such as ML, numerical optimization, big data analytics, and <span class="No-Break">similar applications</span></li>
				<li>Data can be migrated without breaking or modifying existing code and workflows to FSx by matching the FSx file system to that of the <span class="No-Break">on-premise one</span></li>
				<li>Media and entertainment is another example where FSx is very commonly used because of it being a high-performance <span class="No-Break">file system</span></li>
			</ul>
			<h3>Key features of Amazon FSx</h3>
			<p>In this <a id="_idIndexMarker381"/>section, we will discuss the key features of Amazon FSx, such as management, durability, <span class="No-Break">and cost.</span></p>
			<h4>Fully managed</h4>
			<p>Amazon FSx is <a id="_idIndexMarker382"/>fully managed, making it very easy to migrate applications built on commonly used file systems in the industry to AWS. Linux, Windows, and macOS applications requiring very low latency and high performance work very well with Amazon FSx because of its <span class="No-Break">sub-millisecond latencies.</span></p>
			<h4>Durability</h4>
			<p>The data in <a id="_idIndexMarker383"/>Amazon FSx is replicated across or within AZs, in addition to having the option to replicate data across AWS Regions. It also integrates with AWS Backup for backup management and protection. These features make Amazon FSx a highly available and durable family of <span class="No-Break">file systems.</span></p>
			<h3>Cost</h3>
			<p>The cost and <a id="_idIndexMarker384"/>performance of Amazon FSx can be optimized depending on the need. It can be used for small as well as very compute-intensive workloads, such as ML and big data analytics. Like Amazon EBS, it also offers SSD and HDD storage options that can be configured for performance and storage <span class="No-Break">capacity separately.</span></p>
			<h3>Creating an FSx file system</h3>
			<p>We can <a id="_idIndexMarker385"/>create an FSx file system by logging into the AWS management console. In the console, upon pressing the <strong class="bold">Create file system</strong> button, we get the option of selecting the type of FSx file system (<span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.16</em></span><span class="No-Break">).</span></p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B18493_04_016.jpg" alt="Figure 4.16 – FSx file system types"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.16 – FSx file system types</p>
			<p>Upon selecting the type that we want to create, we are also prompted with additional options, some of which are specific to that particular FSx system being created. Some of these options, such as deployment and storage types, network and security, and Windows <a id="_idIndexMarker386"/>authentication, are shown in <em class="italic">Figures 4.17</em>–<em class="italic">4.19</em> for FSx for Windows File Server. These options will vary depending on the type of file system that we are creating. After creating the file system, we can mount it to our <span class="No-Break">EC2 instance.</span></p>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/B18493_04_017.jpg" alt="Figure 4.17 – Creating FSx for Windows File Server"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.17 – Creating FSx for Windows File Server</p>
			<div>
				<div id="_idContainer070" class="IMG---Figure">
					<img src="image/B18493_04_018.jpg" alt="Figure 4.18 – Network and security options for FSx for Windows File Server"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.18 – Network and security options for FSx for Windows File Server</p>
			<div>
				<div id="_idContainer071" class="IMG---Figure">
					<img src="image/B18493_04_019.jpg" alt="Figure 4.19 – Authentication and encryption options for FSx for Windows File Server"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.19 – Authentication and encryption options for FSx for Windows File Server</p>
			<p>This concludes our discussion on the various data storage options provided by AWS. We have learned about Amazon S3, Amazon EFS, Amazon EBS, and the Amazon FSx family, along with <a id="_idIndexMarker387"/>their key capabilities and features. In the next section, we will learn about the data security and governance aspects of cloud data storage <span class="No-Break">on AWS.</span></p>
			<h1 id="_idParaDest-83"><a id="_idTextAnchor082"/>Data security and governance</h1>
			<p>Data security and governance are very important aspects of cloud storage solutions and applications, whether they are web pages, file storage, ML applications, or any other application <a id="_idIndexMarker388"/>utilizing cloud data storage. It is of absolute importance that the data is protected while being at rest in storage or in transit. In addition, access controls should be applied to different users based on the privileges needed for data access. All the AWS data storage services mentioned previously have various security, protection, access management, and governance features. We will discuss these features in the <span class="No-Break">following sections.</span></p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor083"/>IAM</h2>
			<p>In order to be able to access AWS resources, we need an AWS account and to authenticate <a id="_idIndexMarker389"/>every time we log in. Once we have logged into AWS, we need permission to access <a id="_idIndexMarker390"/>the AWS resources. AWS IAM is used to attach permission policies to users, groups, and roles. These permission policies govern and control the access to AWS resources. We can specify who can access which resource and what actions they can take for that resource (for example, creating an S3 bucket, adding objects, listing objects, deleting objects, and so on). All AWS data storage services described in the previous section are integrated with AWS IAM, and access to these services and associated resources can be governed and controlled <span class="No-Break">using IAM.</span></p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor084"/>Data protection</h2>
			<p>All AWS <a id="_idIndexMarker391"/>data storage and file system <a id="_idIndexMarker392"/>services have various data protection features. We should always protect AWS account credentials and create individual user accounts using AWS IAM, giving each user the least privileges to access AWS resources that are needed for their job duties. A few additional security recommendations that help with data protection in AWS are the use of <strong class="bold">Multi-Factor Authentication</strong> (<strong class="bold">MFA</strong>), <strong class="bold">Secure Socket Layer</strong> (<strong class="bold">SSL</strong>), <strong class="bold">Transport Layer Security</strong> (<strong class="bold">TLS</strong>), activity <a id="_idIndexMarker393"/>logging via <strong class="bold">AWS CloudTrail</strong>, AWS <a id="_idIndexMarker394"/>encryption solutions, and <strong class="bold">Amazon Macie</strong> for Amazon <a id="_idIndexMarker395"/>S3 for securing personal and <span class="No-Break">sensitive data.</span></p>
			<p>The various <a id="_idIndexMarker396"/>tiers of Amazon S3 (except One Zone-IA) store all data <a id="_idIndexMarker397"/>objects across at least three AZs in an AWS Region. The One Zone-IA storage class provides redundancy and protection by storing data on multiple devices within the same AZ. In addition, with the help of versioning, different versions of data objects can be preserved and recovered <span class="No-Break">as needed.</span></p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor085"/>Data encryption</h2>
			<p>AWS provides <a id="_idIndexMarker398"/>data encryption at rest as well as in transit. Encryption in transit can be carried out by enabling SSL/TLS. Also, all data <a id="_idIndexMarker399"/>across AWS Regions flowing over the AWS global network is automatically encrypted. In Amazon S3, data can also be encrypted using client-side encryption. Data at rest on Amazon S3 can be encrypted using either server-side <a id="_idIndexMarker400"/>encryption or client-side encryption. For server-side encryption, we can either use <strong class="bold">AWS Key Management Service</strong> (<strong class="bold">KMS</strong>) or Amazon S3-managed encryption. For client-side encryption, we need to take care of the encryption process and upload objects to S3 after encrypting them. We can also create encrypted Amazon EFS file systems, Amazon EBS volumes, and the Amazon FSx family of <span class="No-Break">file systems.</span></p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor086"/>Logging and monitoring</h2>
			<p>Logging and monitoring are two very essential components of any storage solution since we need <a id="_idIndexMarker401"/>to keep track of who is accessing the data and what they are doing with it. Often this logging is also necessary <a id="_idIndexMarker402"/>to satisfy audits and build analytics and reports for usage and threat analysis. AWS data storage services have several logging and monitoring tools available. Amazon CloudWatch alarms can be used to monitor metrics, triggering alarms to Amazon SNS to send notifications. We can also use Amazon CloudTrail to view actions taken by a user, IAM roles, and AWS services in our data storage and file systems. In addition, there are other logging and monitoring features, such as Amazon CloudWatch Logs to access log files and Amazon CloudWatch Events to capture state information and take <span class="No-Break">corrective actions.</span></p>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor087"/>Resilience</h2>
			<p>AWS infrastructure <a id="_idIndexMarker403"/>consists of AWS Regions, which in turn consist of multiple physically separated AZs. These AZs have high throughput and low latency connectivity. By default, S3, EFS, EBS, and FSx resources are backed up and replicated either across multiple AZs across an AWS Region or within the same AZ, depending on the configuration picked by the user. In addition, there are also several other <a id="_idIndexMarker404"/>resilience features specific to these data storage and file systems, such as lifecycle configuration, versioning, S3 object lock, EBS snapshots, and so on. All these features make the data stored on AWS highly resilient to failures <span class="No-Break">and loss.</span></p>
			<p>In addition to the aforementioned mentioned security and governance features of data storage services on AWS, there are several other options available as well, such as the configuration of VPCs, network isolation, and a few additional options. With the combination of these tools and resources, AWS data storage services are among the most secure cloud storage <span class="No-Break">services available.</span></p>
			<p>AWS provides the option of using tiered storage for Amazon S3 and Amazon EFS. This helps with optimizing the data storage cost for <span class="No-Break">the user.</span></p>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor088"/>Tiered storage for cost optimization</h1>
			<p>AWS provides options for configuring its data storage services with various different tiers of <a id="_idIndexMarker405"/>storage types. This significantly helps with optimizing cost and performance depending on the use case requirements. In this section, we will discuss the tiered storage options for Amazon S3 and <span class="No-Break">Amazon EFS.</span></p>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor089"/>Amazon S3 storage classes</h2>
			<p>As mentioned <a id="_idIndexMarker406"/>in the <em class="italic">Amazon Simple Storage Service (S3)</em> section, there are various storage classes depending on the use <a id="_idIndexMarker407"/>case, access pattern, and cost requirements. We can configure S3 storage classes at the object level. We will discuss these storage classes in the <span class="No-Break">following sections.</span></p>
			<h3>Amazon S3 Standard</h3>
			<p>Amazon S3 <a id="_idIndexMarker408"/>Standard is the general-purpose S3 object storage commonly used for frequently accessed data. It provides <a id="_idIndexMarker409"/>high throughput and low latency. Some of the common applications of S3 Standard are online gaming, big data analytics, ML model training and data storage, an offline feature store for ML applications, content storage, and distribution, and websites with <span class="No-Break">dynamic content.</span></p>
			<h3>Amazon S3 Intelligent-Tiering</h3>
			<p><strong class="bold">Amazon S3 Intelligent-Tiering</strong> is the storage class for unknown, unpredictable, and changing <a id="_idIndexMarker410"/>access patterns. There are three access tiers in S3 Intelligent-Tiering –  frequent, infrequent, and archive tiers. S3 Intelligent-Tiering <a id="_idIndexMarker411"/>monitors access patterns and moves data to the appropriate tiers accordingly in order to save costs without impacting performance, retrieval fees, or creating operational overhead. In addition, we can also set up S3 Intelligent-Tiering to move data to the Deep Archive Access tier for data that is accessed very rarely (180 days or more). This can result in further additional <span class="No-Break">cost savings.</span></p>
			<h3>Amazon S3 Standard-Infrequent Access</h3>
			<p><strong class="bold">Amazon S3 Standard-Infrequent Access</strong> is for use cases where data is generally accessed <a id="_idIndexMarker412"/>less frequently, but rapid access may be required. It offers a low per GB storage price and retrieval <a id="_idIndexMarker413"/>charge but the same performance and durability as S3 Standard. Some of the common use cases for this tier are backups, a data store for disaster recovery, and long-term storage. For high-performance compute applications, such as ML, this storage tier can be used to store historical data on which models have already been trained or analytics have already been carried out and is not needed for model retraining for <span class="No-Break">a while.</span></p>
			<h3>Amazon S3 One Zone-Infrequent Access</h3>
			<p><strong class="bold">Amazon S3 One Zone-Infrequent Access</strong> is very similar to Amazon S3 Standard-Infrequent <a id="_idIndexMarker414"/>Access, but the data is stored in only <a id="_idIndexMarker415"/>one AZ (multiple devices) instead of the default three AZs within the same AWS Region as for other S3 storage classes. This is even more cost-effective than the S3 Standard-Infrequent <a id="_idIndexMarker416"/>Access storage class and is commonly used for storing secondary backups or easily re-creatable <a id="_idIndexMarker417"/>data, for example, engineered features no longer used for active ML <span class="No-Break">model training.</span></p>
			<h3>Amazon S3 Glacier</h3>
			<p><strong class="bold">Amazon S3 Glacier</strong> storage classes are highly flexible, low-cost, and high-performance <a id="_idIndexMarker418"/>data archival storage classes. In <a id="_idIndexMarker419"/>Amazon S3 Glacier, there are three storage classes. Amazon S3 Glacier Instant Retrieval is generally used where data is accessed very rarely, but the retrieval is required with latency in milliseconds, for example, news media assets and genomics data. Amazon S3 Flexible Retrieval is for use cases where large datasets such as backup recovery data need to be retrieved at no additional cost, but instant retrieval is not a requirement. The usual retrieval times for such use cases are a few minutes to a few hours. Amazon S3 Glacier Deep Archive is for use cases that require very infrequent retrieval, such as preserved digital media and compliance archives, for example. It is the lowest-cost storage of all the options discussed previously, and the typical retrieval time is 12 hours to <span class="No-Break">2 days.</span></p>
			<h3>S3 on Outposts</h3>
			<p>For on-premise AWS Outposts environments, object storage can be configured using <strong class="bold">Amazon S3 on Outposts</strong>. It stores data reliably and redundantly across multiple devices <a id="_idIndexMarker420"/>and servers on AWS Outposts, especially <a id="_idIndexMarker421"/>suited for use cases with local data <span class="No-Break">residency requirements.</span></p>
			<p>In the following section, we will discuss the different storage classes for <span class="No-Break">Amazon EFS.</span></p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor090"/>Amazon EFS storage classes</h2>
			<p>Amazon EFS <a id="_idIndexMarker422"/>provides the option of different storage classes <a id="_idIndexMarker423"/>for access based on how frequently the data needs to be accessed, as <span class="No-Break">discussed here.</span></p>
			<h3>Amazon EFS Standard and EFS Standard-Infrequent Access classes</h3>
			<p>Amazon <a id="_idIndexMarker424"/>EFS Standard and EFS Standard-Infrequent Access classes are highly available, durable, and elastic <a id="_idIndexMarker425"/>file system storage classes. They are both replicated across multiple geographically separated AZs within an AWS Region. EFS Standard <a id="_idIndexMarker426"/>is for use cases where our data needs frequent access, whereas the EFS Standard-Infrequent <a id="_idIndexMarker427"/>Access class is for use cases where frequent data access is not required. Using EFS Standard-Infrequent Access, we can reduce the storage <span class="No-Break">cost significantly.</span></p>
			<h3>Amazon EFS One Zone and EFS One Zone-Infrequent Access classes</h3>
			<p>Amazon <a id="_idIndexMarker428"/>EFS One Zone and EFS One Zone-Infrequent Access classes store data within a single <a id="_idIndexMarker429"/>AZ across multiple devices, reducing the storage cost compared to Amazon EFS Standard and EFS Standard-Infrequent <a id="_idIndexMarker430"/>Access classes, respectively. For frequently accessed files, EFS One Zone is recommended, whereas <a id="_idIndexMarker431"/>for infrequently accessed files, EFS One Zone-Infrequent Access class <span class="No-Break">is recommended.</span></p>
			<p>With multiple options available for Amazon S3 and Amazon EFS, the right approach is to first determine performance, access, and retrieval needs for a use case and then pick the storage class that satisfies these requirements while minimizing the total cost. Significant amounts of savings can be achieved if we pick the right storage class, especially for very big datasets and use cases where data scales significantly <span class="No-Break">over time.</span></p>
			<p>So far, we have discussed various AWS storage options for HPC along with their capabilities and cost optimization options. In the next section, we will learn about how to pick the right storage option for our HPC <span class="No-Break">use cases.</span></p>
			<h1 id="_idParaDest-92"><a id="_idTextAnchor091"/>Choosing the right storage option for HPC workloads</h1>
			<p>With so many <a id="_idIndexMarker432"/>choices available for cloud data storage, it becomes challenging to decide which storage option to pick for HPC workloads. The choice of data storage depends heavily on the use case and performance, throughput, latency, scaling, archival, and <span class="No-Break">retrieval requirements.</span></p>
			<p>For use cases where we need to archive our object data for a very long time, Amazon S3 should be considered. In addition, Amazon S3 can be very well suited to several HPC applications since it can be accessed by other AWS services. For example, in Amazon SageMaker, we can carry out feature engineering using data stored in Amazon S3 and then ingest those features in the SageMaker offline feature store, which is, again, stored in Amazon S3. Amazon SageMaker uses Amazon S3 for ML model training. It reads data from Amazon S3 and carries out model fitting, hyperparameter optimization, and validation using this data. The model artifacts created as a result are then stored in Amazon S3 as well, which can be used for real-time or batch inference. In addition to ML, Amazon S3 is also a good choice of storage for carrying out data analytics, for storing data on which we want to run complex queries, data archiving, <span class="No-Break">and backups.</span></p>
			<p>Amazon EFS <a id="_idIndexMarker433"/>is a shared file system for Amazon EC2 instances. Thousands of EC2 instances can share the same EFS file system. This makes it ideal for applications where high-performance scaling is needed. High-performance compute applications such as content management systems, distributed applications running on various instances needing access to the same data in the file system, and very large-scale data analysis are a few examples where EFS should <span class="No-Break">be used.</span></p>
			<p>Amazon EBS is a block storage service for single EC2 instances (except EBS Multi-Attach), so the main use case for EBS is when we need high-performance storage for an EC2 instance. For high-performance compute applications such as ML and numerical optimization, often we need to access data for training and tuning our algorithms. The size of the data is often very large to be stored in memory during the process (for example, several thousand videos). In such cases, we may store data temporarily on EBS drives attached to the EC2 instances on which we are running our algorithms, making it much faster to swap and read between data files to carry out the <span class="No-Break">compute operations.</span></p>
			<p>Amazon FSx should be used when we have a similar file system running on-premise and we want to migrate our applications to the cloud while also designing new applications on a similar file system without worrying about underlying infrastructure and tools and <span class="No-Break">process changes.</span></p>
			<p>These are some of the examples we have discussed here where high-performance compute applications can benefit from various AWS data storage options. At the time of designing the architecture, it is very important that we pick the right selection of storage options to make our application give the best performance while also making sure that we do not incur <span class="No-Break">unneeded costs.</span></p>
			<h1 id="_idParaDest-93"><a id="_idTextAnchor092"/>Summary</h1>
			<p>In this chapter, we have discussed the different data storage options available on AWS, along with their main features and capabilities. We have introduced Amazon S3 – a highly scalable and reliable object storage service, Amazon EFS – a shared file system for EC2 instances, Amazon EBS – block storage for EC2 instances, and the Amazon FSx family of file systems. We have also talked about the data protection and governance capabilities of these services and how they integrate with various other data protection, access management, encryption, logging, and monitoring services. We have also explored the various tiers of storage available for Amazon S3 and Amazon EFS and how we can use these tiers to optimize cost for our use cases. Finally, we have discussed a few examples of when to use which data storage service for high-performance <span class="No-Break">compute applications.</span></p>
			<p>Now that we have a good understanding of various AWS data storage services, we are ready to move on to the next part of the book, <a href="B18493_05.xhtml#_idTextAnchor095"><span class="No-Break"><em class="italic">Chapter 5</em></span></a><em class="italic">, Data Analysis</em>, which begins with how to carry out data analysis using <span class="No-Break">AWS services.</span></p>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor093"/>Further reading</h1>
			<p>For further reading on the material we learned in this chapter, please refer to the <span class="No-Break">following articles:</span></p>
			<ul>
				<li><em class="italic">Amazon S3 </em><span class="No-Break"><em class="italic">Features</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/s3/features/"><span class="No-Break">https://aws.amazon.com/s3/features/</span></a></li>
				<li><em class="italic">Amazon Regions and Availability </em><span class="No-Break"><em class="italic">Zones</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/about-aws/global-infrastructure/regions_az/"><span class="No-Break">https://aws.amazon.com/about-aws/global-infrastructure/regions_az/</span></a></li>
				<li><em class="italic">AWS Snow </em><span class="No-Break"><em class="italic">Family</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/snow/"><span class="No-Break">https://aws.amazon.com/snow/</span></a></li>
				<li><em class="italic">Getting started with Amazon </em><span class="No-Break"><em class="italic">S3</em></span><span class="No-Break">: </span><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/GetStartedWithS3.html"><span class="No-Break">https://docs.aws.amazon.com/AmazonS3/latest/userguide/GetStartedWithS3.html</span></a></li>
				<li><em class="italic">Prerequisite: Setting up Amazon </em><span class="No-Break"><em class="italic">S3</em></span><span class="No-Break">: </span><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/setting-up-s3.html"><span class="No-Break">https://docs.aws.amazon.com/AmazonS3/latest/userguide/setting-up-s3.html</span></a></li>
				<li><em class="italic">AWS EFS Deep Dive: What is it and when to use </em><span class="No-Break"><em class="italic">it</em></span><span class="No-Break">: </span><a href="https://www.learnaws.org/2021/01/23/aws-efs-deep-dive/"><span class="No-Break">https://www.learnaws.org/2021/01/23/aws-efs-deep-dive/</span></a></li>
				<li><em class="italic">Achieve highly available and durable database backup workflows with Amazon </em><span class="No-Break"><em class="italic">EFS</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/blogs/storage/using-amazon-efs-to-cost-optimize-highly-available-durable-database-backup-workflows/"><span class="No-Break">https://aws.amazon.com/blogs/storage/using-amazon-efs-to-cost-optimize-highly-available-durable-database-backup-workflows/</span></a></li>
				<li><em class="italic">Amazon EFS </em><span class="No-Break"><em class="italic">features</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/efs/features/"><span class="No-Break">https://aws.amazon.com/efs/features/</span></a></li>
				<li><em class="italic">AWS </em><span class="No-Break"><em class="italic">Backup</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/backup/"><span class="No-Break">https://aws.amazon.com/backup/</span></a></li>
				<li><em class="italic">Amazon EBS </em><span class="No-Break"><em class="italic">features</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/ebs/features/"><span class="No-Break">https://aws.amazon.com/ebs/features/</span></a></li>
				<li><em class="italic">Amazon FSx </em><span class="No-Break"><em class="italic">Documentation</em></span><span class="No-Break">: </span><a href="https://docs.aws.amazon.com/fsx/index.html"><span class="No-Break">https://docs.aws.amazon.com/fsx/index.html</span></a></li>
				<li><em class="italic">Amazon S3 Glacier storage </em><span class="No-Break"><em class="italic">classes</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/s3/storage-classes/glacier/"><span class="No-Break">https://aws.amazon.com/s3/storage-classes/glacier/</span></a></li>
			</ul>
		</div>
	

		<div id="_idContainer073" class="Content">
			<h1 id="_idParaDest-95"><a id="_idTextAnchor094"/>Part 2: Applied Modeling</h1>
		</div>
		<div id="_idContainer074">
			<p><em class="italic">Part 2</em> focuses on the application of <strong class="bold">high-performance computing</strong> (<strong class="bold">HPC</strong>) for machine learning. It includes a hands-on implementation of an end-to-end solution starting with analyzing large amounts of data and then covering distributed training and deploying models at scale, including performance optimization and machine learning at <span class="No-Break">the edge.</span></p>
			<p>This part comprises the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B18493_05.xhtml#_idTextAnchor095"><em class="italic">Chapter 5</em></a>, <em class="italic">Data Analysis</em></li>
				<li><a href="B18493_06.xhtml#_idTextAnchor116"><em class="italic">Chapter 6</em></a>, <em class="italic">Distributed Training of Machine Learning Models</em></li>
				<li><a href="B18493_07.xhtml#_idTextAnchor128"><em class="italic">Chapter 7</em></a>, <em class="italic">Deploying Machine Learning Models at Scale</em></li>
				<li><a href="B18493_08.xhtml#_idTextAnchor161"><em class="italic">Chapter 8</em></a>, <em class="italic">Optimizing and Managing Machine Learning Models for Edge Deployment</em></li>
				<li><a href="B18493_09.xhtml#_idTextAnchor175"><em class="italic">Chapter 9</em></a>, <em class="italic">Performance Optimization for Real-Time Inference</em></li>
				<li><a href="B18493_10.xhtml#_idTextAnchor186"><em class="italic">Chapter 10</em></a>, <em class="italic">Data Visualization</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer075">
			</div>
		</div>
		<div>
			<div id="_idContainer076">
			</div>
		</div>
	</body></html>