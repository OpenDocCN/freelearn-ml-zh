<html><head></head><body>
		<div id="_idContainer199">
			<h1 id="_idParaDest-123"><a id="_idTextAnchor124"/><a id="_idTextAnchor125"/><em class="italic">Chapter 9</em>: Forecasting and Time Series Modeling</h1>
			<p>In this chapter, we will understand what time series are and will see how DataRobot can be used to model them. Time series modeling is becoming increasingly useful in businesses. However, the challenges associated with forecasting make it quite challenging for many skilled data scientists to successfully carry out time series modeling, and this form of modeling could also be extremely time-consuming. DataRobot provides an automated process that enables data scientists to carry out time series projects in an effective and efficient fashion. In this chapter, we will introduce the concept of forecasting, stressing its commercial importance and inherent challenges, and illustrate how DataRobot can be used to build its models.</p>
			<p>By the end of this chapter, you will have learned how to utilize DataRobot in building time series forecasting models. In addition, we will look at making predictions with these models. We go further by building models for multi-series time series as part of the advanced topics. Here are the main topics to be covered in this chapter:</p>
			<ul>
				<li>Conceptual introduction to time series forecasting and modeling</li>
				<li>Defining and setting up time series projects </li>
				<li><a id="_idTextAnchor126"/><a id="_idTextAnchor127"/>Building time series forecasting models <a id="_idTextAnchor128"/>and understanding their model outcomes</li>
				<li><a id="_idTextAnchor129"/><a id="_idTextAnchor130"/>Making predictions with time series models</li>
				<li>Advanced topics in time series modeling</li>
			</ul>
			<h1 id="_idParaDest-124"><a id="_idTextAnchor131"/>Technical requirements</h1>
			<p>Some parts of this chapter require access to the DataRobot software and some tools for data manipulation. Most of the examples deal with small datasets and therefore can be handled via Excel. The dataset that we will be using in this chapter is described next.</p>
			<h2 id="_idParaDest-125"><a id="_idTextAnchor132"/>Appliances energy prediction dataset</h2>
			<p>This <a id="_idIndexMarker415"/>dataset can be accessed at the <em class="italic">University of California Irvine</em> (<em class="italic">UCI</em>) Machine Learning Repository (<a href="https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction#">https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction#</a>). </p>
			<p class="callout-heading">Dataset citation</p>
			<p class="callout"><em class="italic">Luis M. Candanedo</em>, <em class="italic">Véronique Feldheim</em>, <em class="italic">Dominique Deramaix</em>, <em class="italic">Data driven prediction models of energy use of appliances in a low-energy house</em>, <em class="italic">Energy and Buildings</em>, <em class="italic">Volume 140</em>, <em class="italic">1 April 2017</em>, <em class="italic">Pages 81-97</em>, <em class="italic">ISSN 0378-7788</em>.</p>
			<p>This dataset captures temperature and humidity in various rooms in a house and in the outside environment, along with energy consumption by various devices over time. The data is captured every 10 minutes. This is a typical example of a time series dataset. Data is provided in <strong class="source-inline">.csv</strong> format and the site also provides descriptions of the various features. All features in this dataset are numeric features. The dataset also includes two random variables to make the problem interesting.</p>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor133"/>Conceptual introduction to time series forecasting modeling</h1>
			<p>The dynamic nature of the commercial environment makes time a pivot resource for business success. As a result, businesses need to account for the time factor in their decision-making. Changes occur within commercial settings at a high pace, which makes it pertinent <a id="_idIndexMarker416"/>for organizations to take rapid yet considered actions. Analytic technology provides organizations with tools that enable forecasting of the future so <a id="_idIndexMarker417"/>that decision-makers have crucial time in hand to ensure their decision aligns with their organizational objectives. Organizations use time-specific data to predict the volume of sales in a future period. Other writers have differentiated time series modeling from forecasting models. In this chapter, we have used the term interchangeably and consider <strong class="bold">time series forecasting</strong> to involve the use of advanced analytics to gain insights that guide business decisions leveraging time-based data.</p>
			<p>Time series forecasting supports numerous aspects of business planning. With forecasting, human and other forms of resource planning can be optimized to ensure that expected outcomes are realized. Through forecasting, cash flow, profit, and budgeting projections are more rigorously established, thereby mitigating human bias. Forecasting sales could be influenced by several factors that are controllable and non-controllable. Certain consumer factors that change with time tend to affect the volume of sales. These factors include changes in population, customer taste, and interests. In addition, demand is sensitive to broader economic variables, such as inflation, that also change with time. As a result, it becomes pertinent to use some features that could act as proxies for these consumer and economic variables in addition to <strong class="bold">lagged</strong> or historic sales. Because some of these variables are challenging to acquire, analysts tend to be limited to a few historic values and volumes in modeling future outcomes.</p>
			<p>Although a <a id="_idIndexMarker418"/>detailed discussion on time series is out of the scope of this book, it is, however, pertinent to appreciate that the properties of modeling time series make them more challenging to work with. In addition to difficulties <a id="_idIndexMarker419"/>with other forms of predictive modeling discussed in previous chapters of this book, time series modeling comes with additional challenges. One of the assumptions of linear regression modeling is that of independence of observations, that is, that observations or data rows are independent. However, this assumption is inevitably broken with time series modeling. Within time series, <strong class="bold">autocorrelation</strong> occurs naturally, as observations are similar across different time periods. It is also possible that highly corrected observations don't occur successively, in which case <strong class="bold">seasonality</strong> occurs. Series are considered seasonal when observations across a fixed time frame have higher levels of correlation. Indeed, these are periodic fluctuations in observations. A similar volume of sales of flight tickets during holiday periods brings this to life. Seasonality could indeed occur yet fails to follow a fixed time frame, described as <strong class="bold">cyclicity</strong>. Qualifying cycles generally require considerably larger datasets than other properties of series as cyclicity is mostly related to external factors such as macroeconomic or political changes within the business environment.</p>
			<p>Autocorrelation also gives rise to <strong class="bold">linearity</strong>, a concept that describes an overarching trend where consecutive observations are similar, albeit changing in such a way that they follow a linear trend. Due to this linear trend, albeit sometimes with some integrated fluctuations, the mean of specific time frames will follow a pattern but is unlikely to be the same, hence the use of <strong class="bold">moving average</strong> (<strong class="bold">MA</strong>) and <strong class="bold">autoregression</strong> approaches to represent time series. However, series can still be characterized by the extent to which their statistical properties change over time. They are considered <strong class="bold">stationary</strong> when they have a constant mean and variance that are independent of time. What is most interesting, albeit problematic statistically, is that some time series data has a combination of these properties. A good example is the volume of flights. Though gradually increasing over time, being seasonal, during an economic downturn this falls generally. In this example, we can see elements of seasonality, cyclicity, and linearity.</p>
			<p>Another concept that sometimes gets lost in the details is that of <strong class="bold">actionability</strong>. Actionability being the ability of stakeholders to act because of an analysis or a model's outcome, it is very <a id="_idIndexMarker420"/>common for data scientists to focus on the accuracy <a id="_idIndexMarker421"/>of predictions. While accuracy is important, what is more important is to provide actionable guidance to decision-makers. A forecast that enables you to take action today is more valuable than a forecast that is more accurate but not actionable. Care must be taken while defining the forecasting problem to ensure the actionability of the model being developed.</p>
			<p>The foregone conversation in this section highlights the properties that make time series modeling more challenging for typical data scientists. DataRobot has developed unique processes that enable data scientists, including those with limited statistical exposure, to create complex yet robust time series models. In the subsequent section, we will look at how to define and set up time series problems in DataRobot.</p>
			<h1 id="_idParaDest-127"><a id="_idTextAnchor134"/>Defining and setting up time series projects</h1>
			<p>In <a href="B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087"><em class="italic">Chapter 4</em></a>, <em class="italic">Preparing Data for DataRobot</em>, through to <a href="B17159_08_Final_NM_ePub.xhtml#_idTextAnchor116"><em class="italic">Chapter 8</em></a>, <em class="italic">Model Scoring and Deployment</em>, we explored the creation, understanding, scoring, and deployment of basic models in DataRobot. We saw that DataRobot automatically built several models for us and <a id="_idIndexMarker422"/>we could then score a dataset using these built models. Further, after we have chosen a model that best aligns with our needs, DataRobot provides <a id="_idIndexMarker423"/>us a process to deploy our selected model. Due to the difference between time series modeling and other forms of predictive modeling, we will explore in this section how to mitigate problems by effectively defining and setting up time series projects in DataRobot. </p>
			<p>The dataset we will use to explore the use of time series modeling with DataRobot is the Appliances energy prediction dataset that we explored in <a href="B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087"><em class="italic">Chapter 4</em></a>, <em class="italic">Preparing Data for DataRobot</em>. The goal of the project is to predict energy usage. This energy usage time series dataset has 4 and a half months' worth of 10-minute readings from differing data sources. First, the data involved room temperature and humidity in a house. These were monitored using a wireless sensor network and the data was stored every 10 minutes. Each of the nine rooms in the house had their readings for temperature and humidity stored for the time frame. Second, there was external data that provided a nearby airport (public source) detailed information pertaining to weather information outside the house, again with a 10-minute interval. This included wind speed, visibility, dew point, pressure, and humidity. This information was merged with the data using date and time. In addition, appliances and light usage aligned to date and time were attached to the dataset. </p>
			<p>Within this dataset, it is easy to see that the goal of this time series prediction is predicting energy usage. The immediate <a id="_idIndexMarker424"/>influencing variables are the temperature <a id="_idIndexMarker425"/>and atmospheric pressure within the house; however, the external data from the weather outside the house is important. We created features calculating the average conditions across the nine rooms in the house. In addition, we engineered features that captured the difference between the mean room and the external temperature, as well as the difference between the mean room and external pressure. Since we have two time series (appliance usage and light usage), we will approach this problem in two ways. First, as a <strong class="bold">single time series</strong>, we will <a id="_idIndexMarker426"/>look at the sum of both appliance and light usage. Subsequently, within the advanced section, we will examine the <strong class="bold">multiple time series</strong> approach, with <a id="_idIndexMarker427"/>which we will be making predictions for each usage type. As with other prediction projects on DataRobot, we ingest the data as a <strong class="source-inline">.csv</strong> file, as seen in the following screenshot: </p>
			<div>
				<div id="_idContainer184" class="IMG---Figure">
					<img src="image/B17159_09_01.jpg" alt="Figure 9.1 – Choosing a target variable for time series&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1 – Choosing a target variable for time series</p>
			<p>The project is named <strong class="source-inline">Energy_Prediction</strong> and the target variable selected is <strong class="source-inline">total_energy</strong> (the sum of light and appliance usage). We proceed as follows:</p>
			<ol>
				<li>After selecting a target variable, we select a time variable and the nature of the time-based modeling. Clicking the <strong class="bold">Set up time-aware modeling</strong> button, as shown in <em class="italic">Figure 9.1</em>, highlights the importance of time as a dimension and provides an <a id="_idIndexMarker428"/>opportunity to choose a time variable. In this <a id="_idIndexMarker429"/>case, we choose the <strong class="source-inline">date</strong> feature, which specifies the date and times of all readings, as illustrated in the following screenshot: <div id="_idContainer185" class="IMG---Figure"><img src="image/B17159_09_02.jpg" alt="Figure 9.2 – Choosing a time-aware function and time variable&#13;&#10;"/></div><p class="figure-caption">Figure 9.2 – Choosing a time-aware function and time variable</p></li>
				<li>Once the <strong class="bold">Set up time-aware modeling</strong> button is clicked and the time feature is selected, the platform requests the type of time-awareness model to be built. There are two options—<strong class="bold">Automated time series forecasting with backtesting</strong> and <strong class="bold">Automated machine learning with backtesting</strong>, as described next: <ul><li><strong class="bold">Automated time series forecasting with backtesting</strong>—This option considers previous data in predicting future data. With time series, there is a need to forecast multiple future points. A case in point for this type of time-aware project could be estimating departmental stores' daily sales for the next month using data from their last year's sales. <p><strong class="bold">Automated machine learning with backtesting</strong>—The automated machine learning option, sometimes referred to as <strong class="bold">out-of-time validation</strong>, basically <a id="_idIndexMarker430"/>creates time-based features in a row <a id="_idIndexMarker431"/>and then uses a typical predictive model that predicts <a id="_idIndexMarker432"/>a target variable for that row. Here, we do <a id="_idIndexMarker433"/>not use the typical cross-validation scheme; instead, this approach employs older data for training and holds back newer data for backtesting. Our project's context problem falls within the forecasting category type, so this option is selected, as seen in the following screenshot: </p></li></ul></li>
			</ol>
			<div>
				<div id="_idContainer186" class="IMG---Figure">
					<img src="image/B17159_09_03.jpg" alt="Figure 9.3 – Time-aware modeling options&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3 – Time-aware modeling options</p>
			<p>Once we have selected the <strong class="bold">Automated time series forecasting with backtesting</strong> option, we are presented with a <strong class="bold">Time-Aware Modeling</strong> options tab (see <em class="italic">Figure 9.3</em>). Here, a few options are to be carefully selected. We express how far back the model <a id="_idIndexMarker434"/>draws data to make predictions and also how far forward the model makes predictions for. Let's first consider the <strong class="bold">Feature Derivation Window</strong> option. This <strong class="bold">rolling window</strong> highlights a lag upon which features and statistics for time series models are derived in relation to the time from which a forecast is made (<strong class="bold">forecast point</strong>). The rolling window is expressed in relation to the forecast point and automatically moves forward with the passage of time. In an ideal situation, this window should cover a seasonal period in your data. Essentially, this window typically answers the question: <em class="italic">How far back does the data our model uses to make predictions stretch?</em> Also, there should be enough time between the end of the window and your forecasting time to cater for any data ingest delays still limiting this time gap, ensuring <a id="_idIndexMarker435"/>the data is recent enough. This period is known as the <strong class="bold">blind history</strong>. In our case, we have assumed that an hour would be enough time to allow any blind history, so set the gap before the forecasting point to 60 minutes. Considering our data is limited to 4 and a half months, seasonality within the context of our problem <a id="_idIndexMarker436"/>would be day and night usage. Accordingly, we have <a id="_idIndexMarker437"/>set our rolling window to 2 days (2,880 minutes), which, when accounting for the initial 60-minute forecast point gap, amounts to 2,940 minute</p>
			<p>The second consideration is for the <strong class="bold">Forecast Window</strong> option. This defines, in relation to the forecast point, how far in the future we are predicting. This has two elements; first, when the prediction starts. The predictions should provide enough time for actions to be taken yet not be too far in the future to ensure these predictions are accurate enough. Secondly, we select our prediction end. This is dependent on the start point as well as the nature of our problem. So, this aspect answers the question: <em class="italic">How far forward should predictions be made?</em> For the problem at hand, we have selected an <strong class="bold">operationalization gap</strong>, a gap between the forecast point and the start of the prediction window of 1 day (1,440 minutes). Also, the rolling window is set at 1 day, which in consideration of our operationalization gap becomes 2,880 minutes.</p>
			<p>Having set up the time series forecasting project in this section, we will now explore the processes around building the models, from understanding feature lists and their distributions to looking at their impacts on evaluating models.</p>
			<h1 id="_idParaDest-128"><a id="_idTextAnchor135"/>Building time series forecasting models and understanding their model outcomes</h1>
			<p>Similar to projects we looked at in <a href="B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087"><em class="italic">Chapter 4</em></a>, <em class="italic">Preparing Data for DataRobot</em>, through to <a href="B17159_08_Final_NM_ePub.xhtml#_idTextAnchor116"><em class="italic">Chapter 8</em></a>, <em class="italic">Model Scoring and Deployment</em>, once we have finished with <a id="_idIndexMarker438"/>the initial configurations, we scroll up and click on the <strong class="bold">Start</strong> button. By doing this, DataRobot automatically builds time series <a id="_idIndexMarker439"/>models for this project. Before we evaluate the models, it would be useful to understand the nature of the features the platform extracts. DataRobot extracts features from the data that differ considerably from those of other prediction models, as is evident in the following screenshot:</p>
			<div>
				<div id="_idContainer187" class="IMG---Figure">
					<img src="image/B17159_09_04.jpg" alt="Figure 9.4 – Feature lists&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.4 – Feature lists</p>
			<p>The lists <a id="_idIndexMarker440"/>shown under the <strong class="bold">Feature Lists</strong> tab are constructed as part of <strong class="bold">exploratory data analysis</strong> (<strong class="bold">EDA</strong>) and itemize differing lists of features that DataRobot employs in creating models. Many of the feature lists involve <strong class="bold">derived features</strong>, which are created automatically based on properties of time series. A further discussion on derived features will be carried out later in this section. It is easy to see that some of the lists involve features that are extracted from the original data (for example, <strong class="bold">Time Series Extracted Features</strong>). Others involve features created solely from dates, while some are assessed as informative. Most lists appear to be combinations of differing types (for example, <strong class="bold">Time Series Informative Features</strong>). Importantly, the feature lists provide the descriptions as well as the number of features for each <a id="_idIndexMarker441"/>feature list name. Feature lists that could be <a id="_idIndexMarker442"/>pivotal are presented as part of the <strong class="bold">Leaderboard</strong> feature, as illustrated in the following screenshot, which guides our final model choice: </p>
			<div>
				<div id="_idContainer188" class="IMG---Figure">
					<img src="image/B17159_09_05.jpg" alt="Figure 9.5 – Model leaderboard&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.5 – Model leaderboard</p>
			<p>The <strong class="bold">Leaderboard</strong> feature offers insights into models that have been built for a DataRobot project. It provides information regarding model names and <strong class="bold">identifiers</strong> (<strong class="bold">IDs</strong>), their accuracy metrics, and their types, versions, and sample sizes for the model development. With time series modeling, however, there are some differences, as noted next. Firstly, the sample size is present in data ranges. This is due to the time-based nature of time series datasets. Unlike other modeling forms, the time order of the data does affect outcomes; as a result, data is selected in time ranges. In this case, as can be seen in <em class="italic">Figure 9.5</em>, our models were built using 3 months', 21 hours', and 51 minutes' worth of data. Secondly, instead of the <strong class="bold">Validation</strong> and <strong class="bold">Cross-Validation</strong> columns, we have the <strong class="bold">Backtest 1</strong> and <strong class="bold">All Backtests</strong> columns. The backtests follow logically from the discussion regarding the sample size (see <a href="B17159_06_Final_NM_ePub.xhtml#_idTextAnchor104"><em class="italic">Chapter 6</em></a>, <em class="italic">Model Building with DataRobot</em>). The backtests provide an evaluation of the model performance on a subset of the data. However, unlike a typical validation, the data is time-ordered, and the size and number of backtests can be altered as needed. We have used the default backtest setting for this example project so that the data was partitioned in such a way that only one backtest partition was available for modeling. Finally, with time series modeling projects, there appear to be more feature lists. As with other predictive project types, the models could be ordered or selected using any of the columns on the <strong class="bold">Leaderboard</strong> feature. </p>
			<p>There are a <a id="_idIndexMarker443"/>number of metrics against which time <a id="_idIndexMarker444"/>series forecasting models could be assessed. This, of course, depends on the model. For regression-type outcomes, some <a id="_idIndexMarker445"/>advocate the use of <strong class="bold">Root Mean Square Error</strong> (<strong class="bold">RMSE</strong>). The nature of the problem remains critical in determining the metrics for assessment. That said, the role of the <strong class="bold">baseline model</strong> on the leaderboard is <a id="_idIndexMarker446"/>crucial to evaluating other models. The baseline model employs the most recent value in making its predictions. As such, comparing models with the baseline prediction blueprint plays a pivotal role in the model <a id="_idIndexMarker447"/>evaluation as it somewhat answers the question: <em class="italic">To what extent are our models better than a naïve prediction from the most recent data?</em> DataRobot provides the <strong class="bold">Mean Absolute Scaled Error</strong> (<strong class="bold">MASE</strong>), which compares the <strong class="bold">Mean Absolute Error</strong> (<strong class="bold">MAE</strong>) of models of interest with those <a id="_idIndexMarker448"/>of the baseline model. For instance, the <strong class="bold">Eureqa Generalized Additive Model (250 Generations)</strong> model, as presented in the following screenshot, has a comparative ratio of about 0.76 for <strong class="bold">Backtest 1</strong>. This suggests that the Eureqa model is about 24% better than the baseline. Since the <strong class="bold">Holdout</strong> metric could highlight considerable changes within the data, it should be included in model evaluation but not used in isolation. Other indications when evaluating models are covered within the <em class="italic">Advanced topics in time series modeling</em> section of this chapter. Model names could be clicked to provide elaborate insights about the data and its processes. We now turn to those we consider unique to time series forecasting, using the <strong class="bold">Eureqa Generalized Additive Model (250 Generations)</strong> example here:</p>
			<div>
				<div id="_idContainer189" class="IMG---Figure">
					<img src="image/B17159_09_06.jpg" alt="Figure 9.6 – Impact of original features&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.6 – Impact of original features</p>
			<p>The <strong class="bold">Understand</strong> tab presents us with <strong class="bold">Feature Impact</strong>, <strong class="bold">Feature Effects</strong>, <strong class="bold">Prediction Explanations</strong>, and <strong class="bold">Word Cloud</strong> capabilities, which we have already encountered in <a href="B17159_07_Final_NM_ePub.xhtml#_idTextAnchor110"><em class="italic">Chapter 7</em></a>, <em class="italic">Model Understanding and Explainability</em>. <strong class="bold">Feature Impact</strong> shows <a id="_idIndexMarker449"/>the relative extent to which features <a id="_idIndexMarker450"/>contribute to a model's overall accuracy. A click on the <strong class="bold">Feature Impact</strong> tab opens the <strong class="bold">Original features</strong> page (see <em class="italic">Figure 9.6</em>). The original features are features as they were in the dataset. </p>
			<p>The other tab within <strong class="bold">Feature Impact</strong> depicts the effect of derived features on the accuracy of the model. As alluded to earlier, derived features are those constructed based on the characteristics of time series. For instance, the stationary nature of some time series suggests that their statistical properties do not change over time. In the case of our model, the most impactful derived feature (<strong class="source-inline">total_energy (1440 minute average baseline)</strong>) is seen to be a feature constructed based on the stationary nature of the time series, as illustrated in the following screenshot. This is because it highlights the importance of the average 1,440-minute baseline energy on the accuracy of the model:</p>
			<div>
				<div id="_idContainer190" class="IMG---Figure">
					<img src="image/B17159_09_07.jpg" alt="Figure 9.7 – Impact of derived features&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.7 – Impact of derived features</p>
			<p>It is reasonable, as is evident in <em class="italic">Figure 9.7</em>, that a considerable number of derived features appear to be created from the stationary property of time series, which on its own could be indicative of this time series being quite stationary. That said, caution needs to be <a id="_idIndexMarker451"/>exercised on reaching this conclusion <a id="_idIndexMarker452"/>because our dataset only entails 4 and a half months' worth of data; for instance, our dataset only covers January 2016 to May 2016, so does not account for the late Summer, Autumn, and early Winter months. As such, seasonality could occur if we were using a dataset covering a longer time frame.</p>
			<p>DataRobot creates features that capitalize on the properties of time series to improve the accuracy of its models. Although not evident in this project, with seasonality or cyclicity, DataRobot establishes when periodic variations occur and creates features accordingly. Based on this information, it next detects patterns of seasonality—for instance, a seasonality that occurs during a time frame could be defined either by counting up from the beginning of the time frame or counting down from the end of the time frame. As such, the platform could detect and build features that, for instance, use energy usage on the last Saturday of March to predict energy usage on the last Saturday of April. In a similar fashion, DataRobot uses features built on <strong class="bold">differencing</strong> to improve model performance. It could utilize the average usage during the first week in March as a feature to predict usage during the first week of April. </p>
			<p>Moving on to the <strong class="bold">Describe</strong> tab, upon opening the <strong class="bold">Blueprint</strong> tab, we are exposed to the stages involved in the modeling process of time series projects. As detailed in the following <a id="_idIndexMarker453"/>screenshot, we can quickly appreciate <a id="_idIndexMarker454"/>that this is not very different from those of other predictive projects encountered in preceding chapters: </p>
			<div>
				<div id="_idContainer191" class="IMG---Figure">
					<img src="image/B17159_09_08.jpg" alt="Figure 9.8 – Model blueprint&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.8 – Model blueprint</p>
			<p>We have now spent time building and understanding time series forecasting models. The next logical step is to use our selected model to make predictions.</p>
			<h1 id="_idParaDest-129"><a id="_idTextAnchor136"/>Making predictions with time series models</h1>
			<p>DataRobot provides us with tools to make predictions pain-free. There are two approaches <a id="_idIndexMarker455"/>to making predictions for time series. For small datasets under 1 <strong class="bold">gigabyte</strong> (<strong class="bold">GB</strong>), predictions could be made using the <strong class="bold">Make Predictions</strong> tab on the <strong class="bold">Leaderboard</strong> feature. This involves setting up and uploading a prediction dataset, then scoring it within the <strong class="bold">Drag and drop a new dataset</strong> <strong class="bold">user interface</strong> (<strong class="bold">UI</strong>) functionality. For significantly larger datasets, models need to be deployed and predictions are made using an <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>). In this chapter, we will cover the first approach to making predictions. With DataRobot, general model deployments and working with APIs are extensively discussed in <a href="B17159_12_Final_NM_ePub.xhtml#_idTextAnchor176"><em class="italic">Chapter 12</em></a>, <em class="italic">DataRobot Python API</em>.</p>
			<p>The leaderboard's drag-and-drop approach to scoring models for time series models somewhat differs from those of traditional models, as seen in <a href="B17159_08_Final_NM_ePub.xhtml#_idTextAnchor116"><em class="italic">Chapter 8</em></a>, <em class="italic">Model Scoring and Deployment</em>. When the <strong class="bold">Make Predictions</strong> tab is opened, DataRobot briefly outlines the recency and quantity of the data needed to make predictions. This outline is mostly consistent with the forecasting windows established as part of the configuration during the model development, as well as features derived. As the prediction process shows in the following screenshot, the prediction dataset requires a minimum of 4,320 minutes of historic data outside of the 60 minutes prior to the forecasting point. In addition, when models include derived features that involve features in <a id="_idIndexMarker456"/>earlier time periods, the earlier time period is also included in the dataset requirement. Because the model in question has 24-hours'-difference derived features, this increases the requirement to 5,820 minutes. This 5,820-minute requirement includes an initial 60-minute forecast point gap window, 4,320-minute base prediction requirement data, and 1,440 minutes added on for the derived differencing features. This enables the model to predict 2,880 minutes in advance of the forecasting point after the 1,440-minute operationalization gap. Some of these features are presented here: </p>
			<div>
				<div id="_idContainer192" class="IMG---Figure">
					<img src="image/B17159_09_09.jpg" alt="Figure 9.9 – Make Predictions window&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.9 – Make Predictions window</p>
			<p>To make <a id="_idIndexMarker457"/>predictions, if the data format is consistent with the training data, proceed as follows: </p>
			<ol>
				<li value="1">Click on <strong class="bold">Import data</strong>, which allows the data to be ingested from a local source, a <strong class="bold">Uniform Resource Locator</strong> (<strong class="bold">URL</strong>), оnе оf уоur еxіѕtіng dаtа ѕоurсеѕ, оr AI Catalog. If no <a id="_idIndexMarker458"/>row is found after the default forecast point, DataRobot generates a template. For this to be done, there must be no empty row within the forecast window and the template file must meet the upload size limit conditions. After the file has been uploaded, DataRobot sets the forecast points and includes the rows required to meet the forecast window expectations. </li>
				<li>Click on the <strong class="bold">Compute predictions</strong> button after uploading the data, as illustrated in the following screenshot, since the uploaded prediction file is the most recent, without gaps and the fill number of rows expected:<div id="_idContainer193" class="IMG---Figure"><img src="image/B17159_09_10.jpg" alt="Figure 9.10 – Computing time series predictions&#13;&#10;"/></div><p class="figure-caption">Figure 9.10 – Computing time series predictions</p><p>The <strong class="bold">Forecast settings</strong> button in <em class="italic">Figure 9.10</em> provides options for predictions where <a id="_idIndexMarker459"/>either the forecasting point is not expected to be the most recent or changes the range for which predictions are to be made. </p></li>
				<li>To make changes of this nature, click on the <strong class="bold">Forecast settings</strong> button, which opens the <strong class="bold">Forecast Point Predictions</strong> tab by default, as illustrated in the following screenshot. This window offers a forecast point slide tab selector, which can be configured by either a slide or entering the actual time value. Invalid dates are, however, disabled:</li>
			</ol>
			<div>
				<div id="_idContainer194" class="IMG---Figure">
					<img src="image/B17159_09_11.jpg" alt="Figure 9.11 – Forecast Point Predictions settings&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.11 – Forecast Point Predictions settings</p>
			<p>As alluded to earlier, there is a limit to times that can be selected as a forecast point. The forecast point must be less than or equal to the most recent one. In the case of this project, this is <strong class="bold">2016-05-27 19:00:00:00</strong>, which is the most recent data row time, with an operationalization gap of <strong class="bold">1440</strong> minutes. A similar operation could be carried out to alter the <a id="_idIndexMarker460"/>prediction date ranges. The <strong class="bold">Forecast Range Predictions</strong> feature would ideally be used to validate models as opposed to making future predictions. </p>
			<p>In this section, we highlighted the importance of ensuring our prediction dataset for time series models is like that for training models. We went on to make predictions and interpreted other outcomes from the model. Next, we will explore more advanced topics involving time series modeling with DataRobot.</p>
			<h1 id="_idParaDest-130"><a id="_idTextAnchor137"/>Advanced topics in time series modeling</h1>
			<p>In this chapter, we have learned how to configure, build and make predictions with basic time series forecasting models in DataRobot. In the preceding section, our attention was focused on building models that have one-time series. However, you could have <a id="_idIndexMarker461"/>a situation where you might have to make multi-time series predictions. Within the context of our energy utilization problem, we might want to forecast the usage of lights and appliances. Elsewhere, an energy company might want to forecast energy usage for differing cities or households within the same model. We will now take a deep dive into solving problems of this nature. Also, we will explore future ways other advanced approaches may be used in assessing our time series models. Finally, we will acknowledge the role of scheduled events on time series and highlight the provisions made by DataRobot to handle this possibility.</p>
			<p>The dataset used for this project highlights the energy usage of lights and other appliances. For the earlier project, we totaled up all usage as our target variable, but in this project (named <strong class="source-inline">Energy_Prediction_2</strong>), models will be built to predict usage for each device type. This dataset now has two series, implying timestamps could recur, yet timestamps within each series must be unique. The differentiating column, <strong class="source-inline">Device_type</strong>, is the ID for the device type that the usage is attributed to. After qualifying the project as being time-aware and choosing its type as <strong class="bold">Automated time series forecasting with backtesting</strong> (see <em class="italic">Figure 9.2</em> for more information on the setup of a time series project), due to the data having multiple rows with the same timestamp, the multiple time series is automatically selected. The next step, as shown in the following screenshot, is to select the series ID, which in this case is <strong class="source-inline">Device_type</strong>:</p>
			<div>
				<div id="_idContainer195" class="IMG---Figure">
					<img src="image/B17159_09_12.jpg" alt="Figure 9.12 – Multi-series time series forecasting setup&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.12 – Multi-series time series forecasting setup</p>
			<p>For this project, we are interested in further evaluating our models. So, the sequel to customizing <a id="_idIndexMarker462"/>our forecasting window, within the <strong class="bold">Partitioning</strong> tab of the <strong class="bold">Advanced Options</strong> window, is to configure our backtests to help us manage validation folds (for more on validation folds, see <a href="B17159_06_Final_NM_ePub.xhtml#_idTextAnchor104"><em class="italic">Chapter 6</em></a>, <em class="italic">Model Building with DataRobot</em>). Here, we simplistically set the number of backtests to <strong class="source-inline">5 + Holdout</strong>. The following screenshot details the setup for this configuration, and we can see how the training, validation, and holdout data is partitioned from the initial data. It is important to highlight that to set up the backtests, we must consider any form of seasonality, periodicity, and/or cyclicity within the data and ensure that every fold has at least one instance of these. This is because every backtest should be a complete dataset on its own, so seasonality, periodicity, and cyclicity need to be accounted for within each backtest. The validation and gap lengths can also be altered. The default length for this project is set to over 13 hours and 9 minutes. You can see the configuration here:</p>
			<div>
				<div id="_idContainer196" class="IMG---Figure">
					<img src="image/B17159_09_13.jpg" alt="Figure 9.13 – Backtest configuration&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.13 – Backtest configuration</p>
			<p>Having configured <a id="_idIndexMarker463"/>backtesting, we then click on <strong class="bold">Start</strong> to train the models. When models are created, the process of evaluation is like that for single time series models. As evident in the following screenshot, we can see the <strong class="bold">All Backtests</strong> metric, which measures the average performance of a model across all backtests. As such, it provides an interesting way to quickly assess not only the model performance but also the consistency of the data pattern over time:</p>
			<div>
				<div id="_idContainer197" class="IMG---Figure">
					<img src="image/B17159_09_14.jpg" alt="Figure 9.14 – Accuracy over time&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.14 – Accuracy over time</p>
			<p>The <strong class="bold">Accuracy Over Time</strong> feature within the model <strong class="bold">Evaluate</strong> tab enables users to have a visual <a id="_idIndexMarker464"/>yet in-depth assessment of their models over time (see <em class="italic">Figure 9.14</em>). Here, the predicted and actual are visually presented. Within this window, you can choose a <strong class="bold">Series to plot</strong> setting and alter the <strong class="bold">Backtest</strong> and the <strong class="bold">Forecast distance</strong> settings. This view, within the context of a business, helps understand if there are periods of poor performance that could imply an aspect of a business not represented in the data. The <strong class="bold">Forecasting Accuracy</strong> window, as shown in the following screenshot, is another important representation that suggests how model performance changes as the forecast distance changes: </p>
			<div>
				<div id="_idContainer198" class="IMG---Figure">
					<img src="image/B17159_09_15.jpg" alt="Figure 9.15 – Forecasting Accuracy window&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.15 – Forecasting Accuracy window</p>
			<p>The <strong class="bold">Forecasting Accuracy</strong> window highlights alterations in models' performance as forecasts are made into the future. This view allows us to assess where models' performance <a id="_idIndexMarker465"/>is similar across time, which is indicative of when models could be used within the business. Furthermore, it highlights when the models' performance considerably exceeds those of the baseline model when the MASE performance metric is used. As illustrated in <em class="italic">Figure 9.15</em>, the model's performance on <strong class="bold">Backtest 1</strong> seems to begin to be considerably better than the baseline model around the +1,960-minute mark. The stability view presents users with the measure of scores across time ranges. </p>
			<p>With the quest for better-performing models comes a need to adopt some changes to modeling paradigms. The default models available for time series modeling might just not provide the required performance. In that case, the model repository, as explained in <a href="B17159_06_Final_NM_ePub.xhtml#_idTextAnchor104"><em class="italic">Chapter 6</em></a>, <em class="italic">Model Building with DataRobot</em>, presents us with options to select traditional <a id="_idIndexMarker466"/>time series models such as <strong class="bold">AutoRegressive Integrated Moving Average</strong> (<strong class="bold">ARIMA</strong>) and more recent <a id="_idIndexMarker467"/>models such as Keras <strong class="bold">Long Short-Term Memory</strong> (<strong class="bold">LSTM</strong>) and <strong class="bold">XGBoost</strong> (<strong class="bold">XGB</strong>). Depending on the nature of the time series <a id="_idIndexMarker468"/>under investigation, these modeling approaches sometimes present better performance.</p>
			<h1 id="_idParaDest-131"><a id="_idTextAnchor138"/>Summary</h1>
			<p>In this chapter, we have extensively examined how DataRobot could be used to build time series models. We briefly discussed the unique opportunities time series modeling presents businesses, as well as the challenges it presents for analysts and data scientists. We used DataRobot to create both single and multiple time series models. We also described how predictions could be made using models built by DataRobot. This was followed by a discussion on advanced aspects of DataRobot's time series capabilities. </p>
			<p>Forecasting is extremely important to business because of its ability to foretell what is likely to occur in the future considering time-dependent variables. Another commercially valuable area is the ability to suggest the interest that differing clients would have for a wide array of products. This is where recommender systems come in. </p>
			<p>In the next chapter, <a href="B17159_10_Final_NM_ePub.xhtml#_idTextAnchor139"><em class="italic">Chapter 10</em></a>, <em class="italic">Recommender Systems</em>, we look at how DataRobot could be used to build recommender engines. </p>
		</div>
	</body></html>