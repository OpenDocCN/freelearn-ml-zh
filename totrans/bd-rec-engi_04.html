<html><head></head><body><div class="chapter" title="Chapter&#xA0;4.&#xA0;Data Mining Techniques Used in Recommendation Engines"><div class="titlepage" id="aid-RL0A2"><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Data Mining Techniques Used in Recommendation Engines</h1></div></div></div><p>Data mining techniques lie at the heart of recommendation engines. These data mining techniques help us extract patterns, group users, calculate similarities, predict preferences, handle sparse input data, evaluate recommendation models, and so on. In the previous chapter, we have learned about recommendation engines in detail. Though we did not get into the implementation of recommendation engines, we learned the theory behind the different types of recommendations engines, such as neighborhood-based, personalized, contextual recommenders, hybrids, and so on. In this chapter, we shall look into the popular data mining techniques currently used in building recommendation engines. The reason for dedicating a separate chapter to this is that we will come across many techniques while implementing recommendation engines in the subsequent chapters.</p><p>This chapter is broadly divided into the following sections:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Neighbourhood-based techniques<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Euclidean distance</li><li class="listitem">Cosine similarity</li><li class="listitem">Jaccard similarity</li><li class="listitem">Pearson correlation coefficient</li></ul></div></li><li class="listitem">Mathematical modelling techniques<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Matrix factorization</li><li class="listitem">Alternating Least Squares</li><li class="listitem">Singular value decomposition</li></ul></div></li><li class="listitem">Machine learning techniques <div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Linear regression</li><li class="listitem">Classification models</li></ul></div></li><li class="listitem">Clustering techniques<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">K-means clustering</li></ul></div></li><li class="listitem">Dimensionality reduction<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Principal component analysis</li></ul></div></li><li class="listitem">Vector space models<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Term frequency</li><li class="listitem">Term frequency-inverse document frequency</li></ul></div></li><li class="listitem">Evaluation techniques<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Root-mean-square error</li><li class="listitem">Mean absolute error</li><li class="listitem">Precision and recall</li></ul></div></li></ul></div><p>Each section is explained with the basic technique and its implementation in R.</p><p>Let's start refreshing the basics that are mostly commonly used in recommendation engines.</p><div class="section" title="Neighbourhood-based techniques"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec22"/>Neighbourhood-based techniques</h1></div></div></div><p>As introduced in the previous chapters, the neighbourhood methods are very simple techniques, which are used right from the beginning of building recommendation engines. These are the oldest yet most widely used approaches, even today. The popularity of these widely used approaches is because of their accuracy in generating recommendations. We know that almost every recommender system works on the concept of similarity between items or users. These neighbourhood methods consider the available information between two users or items as two vectors, and simple mathematic calculation is applied between these two vectors to see how close they are. In this section, we will discuss the following neighbourhood techniques:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Euclidean distance</li><li class="listitem">Cosine similarity</li><li class="listitem">Jaccard Similarity</li><li class="listitem">Pearson correlation coefficient</li></ul></div><div class="section" title="Euclidean distance"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec36"/>Euclidean distance</h2></div></div></div><p>Euclidean distance similarity is one of the most common similarity measures used to calculate the distance between two points or two vectors. It is the path distance between two points or vectors in vector space.</p><p>In the following diagram, we see the path distance between the two vectors, a and b, as Euclidean distance:</p><div class="mediaobject"><img src="../Images/image00256.jpeg" alt="Euclidean distance"/></div><p style="clear:both; height: 1em;"> </p><p>Euclidean distance is based on the Pythagoras's theorem to calculate the distance between two points.</p><p>The <span class="strong"><strong>Euclidean distance</strong></span> between two points or objects (point <span class="emphasis"><em>x</em></span> and point <span class="emphasis"><em>y</em></span>) in a dataset is defined by the following equation:</p><div class="mediaobject"><img src="../Images/image00257.jpeg" alt="Euclidean distance"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> are two consecutive data points, and n is the number of attributes for the dataset.</p><p>How is Euclidean distance applied in recommendation engines?</p><p>Consider a rating matrix containing user IDs as rows, item IDs as columns, and the preference values as cell values. The Euclidean distance between two rows gives us the user similarity, and the Euclidean distance between two columns gives us the item similarity. This measure is used when the data is comprised of continuous values.</p><p>The R script for calculating the Euclidean distance is as follows:</p><pre class="programlisting">x1 &lt;- rnorm(30) &#13;
x2 &lt;- rnorm(30) &#13;
Euc_dist = dist(rbind(x1,x2) ,method="euclidean") &#13;
</pre><div class="mediaobject"><img src="../Images/image00258.jpeg" alt="Euclidean distance"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Cosine similarity"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec37"/>Cosine similarity</h2></div></div></div><p><span class="strong"><strong>Cosine similarity</strong></span> is a measure of similarity between two vectors of an inner product space that measures the cosine of the angle between them; it's given by the following equation:</p><div class="mediaobject"><img src="../Images/image00259.jpeg" alt="Cosine similarity"/></div><p style="clear:both; height: 1em;"> </p><p>Let <span class="emphasis"><em>a</em></span> be a vector (<span class="emphasis"><em>a1</em></span>, <span class="emphasis"><em>a2</em></span>, <span class="emphasis"><em>a3</em></span>, <span class="emphasis"><em>a4</em></span>) and <span class="emphasis"><em>b</em></span> be another vector (<span class="emphasis"><em>b1</em></span>, <span class="emphasis"><em>b2</em></span>, <span class="emphasis"><em>b3</em></span>, <span class="emphasis"><em>b4</em></span>). The dot product between these vectors <span class="emphasis"><em>a</em></span> and <span class="emphasis"><em>b</em></span> is as follows:</p><p><span class="emphasis"><em>a.b = a1b1 + a2b2 + a3b3 + a4b4</em></span></p><p>The resultant will be a single value, a scalar constant. What does it mean to take the dot product between two vectors? To answer this question, let's define the geometric definition of dot product between two vectors:</p><div class="mediaobject"><img src="../Images/image00260.jpeg" alt="Cosine similarity"/></div><p style="clear:both; height: 1em;"> </p><p>On rearranging the preceding equation, we get the following:</p><div class="mediaobject"><img src="../Images/image00261.jpeg" alt="Cosine similarity"/></div><p style="clear:both; height: 1em;"> </p><p>In the earlier equation, <span class="emphasis"><em>cosθ</em></span> is the angle between two vectors, and <span class="emphasis"><em>acosθ</em></span> is the projection of vector A onto vector B.</p><p>The visual vector space representation of the dot product between two vectors can be shown as follows:</p><div class="mediaobject"><img src="../Images/image00262.jpeg" alt="Cosine similarity"/></div><p style="clear:both; height: 1em;"> </p><p>When cos angle between the two vectors is 90 degrees, the <span class="emphasis"><em>cos 90</em></span> will become zero, and the whole dot product will be zero, that is, they will be orthogonal to each other. The logical conclusion we can infer is that they are very far from each other:</p><div class="mediaobject"><img src="../Images/image00263.jpeg" alt="Cosine similarity"/></div><p style="clear:both; height: 1em;"> </p><p>When we reduce the cosine angle between the two vectors, their orientation will look very similar to each other's.</p><p>When the angle between the two vectors is zero, <span class="emphasis"><em>cos 0</em></span> will be 1, and both the vectors will lie on each other, as shown in the following image. Thus, we can say that the two vectors are similar to each other in terms of their orientation:</p><div class="mediaobject"><img src="../Images/image00264.jpeg" alt="Cosine similarity"/></div><p style="clear:both; height: 1em;"> </p><p>So on summarizing, we can conclude that when we compute the cosine angle between two vectors, the resultant scalar value will indicate how close the two vectors are with each other in terms of orientation:</p><div class="mediaobject"><img src="../Images/image00265.jpeg" alt="Cosine similarity"/></div><p style="clear:both; height: 1em;"> </p><p>Now let's revisit our original question: what does the dot product mean? When we take the dot product between two vectors, the resultant scalar value represents the cosine angle between them. If the scalar is zero, the two vectors are orthogonal and unrelated. If the scalar is 1, the two vectors are similar.</p><p>Now, how is this applied in recommendation engines?</p><p>As mentioned earlier, consider a rating matrix containing user IDs as rows and item IDs as columns. We can assume each row as user vectors and each column as item vectors.</p><p>The cosine angle between row vectors will give the user similarity, and cosine angle between column vectors give the item similarity.</p><p>The R script for calculating the cosine distance is as follows:</p><pre class="programlisting">vec1 = <a class="ulink" href="http://inside-r.org/r-doc/base/c">c</a>( 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0 ) &#13;
vec2 = <a class="ulink" href="http://inside-r.org/r-doc/base/c">c</a>( 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0 ) &#13;
library(lsa) &#13;
cosine(vec1,vec2) &#13;
</pre><p>Here, <span class="emphasis"><em>x</em></span> is matrix containing all the variables in a dataset; the cosine function is available in the <code class="literal">lsa</code> package. The <code class="literal">lsa</code> is a text mining package available in r used for discovering latent features or topics within the text. This package provides <code class="literal">cosine()</code> method to calculate cosine angle between two vectors.</p></div><div class="section" title="Jaccard similarity"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec38"/>Jaccard similarity</h2></div></div></div><p>Jaccard simlarity is another type of similarity measure used in recommendation engines. The <span class="strong"><strong>Jaccard similarity</strong></span> coefficient is calculated as the ratio of the intersection of features to the union of features between two users or items.</p><p>Mathematically speaking, if <span class="emphasis"><em>A</em></span> and <span class="emphasis"><em>B</em></span> are two vectors, the Jaccard similarity is given by the following equation:</p><div class="mediaobject"><img src="../Images/image00266.jpeg" alt="Jaccard similarity"/></div><p style="clear:both; height: 1em;"> </p><p>The Jaccard similarity coefficient metric is a statistic used to find the similarity and diversity in sample sets. Since users and items can be represented as vectors or sets, we can easily apply the Jaccard coefficient to recommender systems in order to find similarity between users or items.</p><p>The R script for calculating the Jaccard similarity is as follows:</p><pre class="programlisting">vec1 = c( 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0 ) &#13;
vec2 = c( 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0 ) &#13;
library('clusteval') &#13;
cluster_similarity(vec1, vec2, similarity = "jaccard") &#13;
</pre><p>The <code class="literal">clusteval</code> package in r is a popular package for evaluating clustering techniques. <code class="literal">Cluster_similarity()</code> method provides a very good implementation for calculating Jaccard similarity.</p></div><div class="section" title="Pearson correlation coefficient"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec39"/>Pearson correlation coefficient</h2></div></div></div><p>Another way of finding the aforementioned similarity is to find the correlation between two vectors. Instead of using the distance measures as a way of finding similarity among vectors, we use the correlation between vectors in this approach.</p><p>The Pearson correlation coefficient can be computed as follows:</p><div class="mediaobject"><img src="../Images/image00267.jpeg" alt="Pearson correlation coefficient"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>r</em></span> is the correlation coefficient,<span class="emphasis"><em> n</em></span> is the total number of data points,<span class="emphasis"><em> x<sub>i</sub></em></span> is the <span class="emphasis"><em>i<sup>th</sup></em></span> vector point of the x vector,<span class="emphasis"><em> y<sub>i</sub></em></span> is the <span class="emphasis"><em>i<sup>th</sup></em></span> vector point of the y vector<span class="emphasis"><em>, x-bar</em></span> is the mean of vector x<span class="emphasis"><em>, y-bar</em></span> is the mean of vector y<span class="emphasis"><em>, s<sub>x</sub></em></span> is the standard deviation of vector x<span class="emphasis"><em>, and s<sub>y</sub></em></span> is the standard deviation of vector y.</p><p>Another way of computing the correlation coefficient between two variables is by dividing the covariance of the two variables by the product of their standard deviations,</p><p>given by <span class="inlinemediaobject"><img src="../Images/image00268.jpeg" alt="Pearson correlation coefficient"/></span>(rho):</p><div class="mediaobject"><img src="../Images/image00269.jpeg" alt="Pearson correlation coefficient"/></div><p style="clear:both; height: 1em;"> </p><p>Let's understand this with an example, as shown in the following image. We plot the values of two vectors a, b; it is natural to assume that if all the points of the vectors vary together, there exists a positive relation among them. This tendency to vary together, or covariance, in simple terms, can be called correlation. Take a look at the following diagram:</p><div class="mediaobject"><img src="../Images/image00270.jpeg" alt="Pearson correlation coefficient"/></div><p style="clear:both; height: 1em;"> </p><p>Let's now examine the following image. We can observe that the vectors are not varying together, and the corresponding points are scattered randomly. So the tendency to vary together, or covariance, is less or in other less correlation:</p><div class="mediaobject"><img src="../Images/image00271.jpeg" alt="Pearson correlation coefficient"/></div><p style="clear:both; height: 1em;"> </p><p>From the similarity calculation aspect, we can conclude that the more the correlation between two vectors, the more similar they are.</p><p>Now, how is the Pearson correlation coefficient applied in recommendation engines?</p><p>As mentioned earlier, consider a rating matrix containing user IDs as rows and item IDs as columns. We can assume each row as user vectors and each column as item vectors.</p><p>The correlation coefficient between the row vectors will give the user similarity, and the correlation coefficient between the column vectors will give the item similarity using the following equation.</p><p>The R script is given by the following equation:</p><pre class="programlisting">Coef = cor(mtcars, method="pearson") &#13;
</pre><p>Here, <code class="literal">mtcars</code> is the dataset.</p></div></div></div>
<div class="section" title="Mathematic model techniques"><div class="titlepage" id="aid-SJGS2"><div><div><h1 class="title"><a id="ch04lvl1sec23"/>Mathematic model techniques</h1></div></div></div><p>Mathematical models such as matrix factorization and SVD have proved to be very accurate when it comes to building recommendation engines over the similarity calculation measures. Another advantage is their ability to scale down easily also allowed to design the systems easily. In this chapter, we will learn about the mathematical models as explained next.</p><div class="section" title="Matrix factorization"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec40"/>Matrix factorization</h2></div></div></div><p>A matrix can be decomposed into two low rank matrices, which when multiplied back will result in a single matrix approximately equal to the original matrix.</p><p>Let's say that <span class="emphasis"><em>R</em></span>, a rating matrix of size <span class="emphasis"><em>U X M</em></span> can be decomposed into two low rank matrices, <span class="emphasis"><em>P</em></span> and <span class="emphasis"><em>Q</em></span>, of size <span class="emphasis"><em>U X K</em></span> and <span class="emphasis"><em>M X K</em></span> respectively, where <span class="emphasis"><em>K</em></span> is called the rank of the matrix.</p><p>In the following example, the original matrix of size <span class="emphasis"><em>4 X 4</em></span> is decomposed into two matrices, <span class="emphasis"><em>P (4 X 2)</em></span> and <span class="emphasis"><em>Q (4 X 2)</em></span>; multiplying back <span class="emphasis"><em>P</em></span> and <span class="emphasis"><em>Q</em></span> will bring me the original matrix of size <span class="emphasis"><em>4 X 4</em></span> and values approximately equal to those of the original matrix:</p><div class="mediaobject"><img src="../Images/image00272.jpeg" alt="Matrix factorization"/></div><p style="clear:both; height: 1em;"> </p><p>One of the major advantages of the matrix factorization method is that we can compute the empty cells in the original matrix, <span class="emphasis"><em>R</em></span>, using the dot product between the low-rank matrices <span class="emphasis"><em>P</em></span>, <span class="emphasis"><em>Q</em></span>. This is given by the following equation:</p><div class="mediaobject"><img src="../Images/image00273.jpeg" alt="Matrix factorization"/></div><p style="clear:both; height: 1em;"> </p><p>When we apply the previous equation, we can reproduce the original matrix, <span class="emphasis"><em>R</em></span>, with all the empty cells filled.</p><p>In order to make the predicted values as close as to the original matrix as possible, we have to minimize the difference between the original values and the predicted values, which is also also known as error. The error between the original value and predicted value can be given by the following equation:</p><div class="mediaobject"><img src="../Images/image00274.jpeg" alt="Matrix factorization"/></div><p style="clear:both; height: 1em;"> </p><p>In order to minimize the aforementioned error term and reproduce the original matrix as closely as possible, we have to use gradient descend technique-an algorithm to find out optimal parameters of an objective function and minimize the function in an iterative manner, introduce Regularization term to the equation.</p><p>How is matrix factorization applied to recommendation engines?</p><p>This is core question, which we are more interested in rather than the mathematics involved in matrix factorization. We will see how we can apply matrix factorization techniques in building recommendation engines.</p><p>Recall the core tasks in building recommendation engines: finding similar users or items, then predicting the non-rated preferences, and finally recommending new items to active users. In short, we are predicting the non-rated item preferences. Recall this is what matrix factorization does: predicting the empty cells in the original rating matrix.</p><p>Now, how do we justify our approach of applying matrix decomposition to low-rank matrices to recommendation engines? To answer this question, we will discuss how users rate movies. People rate movies because of the story or actors or the genre of the movie, that is, users rate items because of the features of the items. When given a rating matrix containing user IDs, item IDs, and rating values, we can make an assumption that users will have some inherent preferences toward rating items, and the items will also have inherent features that help users rate them. These features of users and items are called <span class="strong"><strong>latent features</strong></span>.</p><p>Considering the earlier assumption, we apply the matrix factorization technique to the rating matrix the two low-rank matrices, which are assumed to be the user latent feature matrix and item latent feature matrix:</p><div class="mediaobject"><img src="../Images/image00275.jpeg" alt="Matrix factorization"/></div><p style="clear:both; height: 1em;"> </p><p>Considering these assumptions, researchers started applying matrix factorization techniques in building recommender systems. The advantage of the matrix factorization methods is that since it is a machine-learning model, the feature weightages are learned overtime, improving the model accuracy:</p><p>The following code explains the implementation of Matrix Factorization using <code class="literal">nmf</code> package in R:</p><pre class="programlisting">#MF &#13;
library(recommenderlab) &#13;
data("MovieLense") &#13;
dim(MovieLense) &#13;
 &#13;
#applying MF using NMF &#13;
mat  = as(MovieLense,"matrix") &#13;
mat[is.na(mat)] = 0 &#13;
res = nmf(mat,10) &#13;
res &#13;
 &#13;
#fitted values &#13;
r.hat &lt;- fitted(res) &#13;
dim(r.hat) &#13;
 &#13;
p &lt;- basis(res) &#13;
dim(p) &#13;
q &lt;- coef(res) &#13;
dim(q) &#13;
</pre></div><div class="section" title="Alternating least squares"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec41"/>Alternating least squares</h2></div></div></div><p>Recall the error minimization equation in the previous section. Upon introducing a regularization term to avoid over fitting, the final error term would look like the following equation:</p><div class="mediaobject"><img src="../Images/image00276.jpeg" alt="Alternating least squares"/></div><p style="clear:both; height: 1em;"> </p><p>In order to optimize the preceding equation, there are two popular techniques:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Stochastic gradient descent</strong></span> (<span class="strong"><strong>SGD</strong></span>): A mini-batch optimizing technique, similar to gradient descend, for finding optimal parameters in large-scale data or sparse data.</li><li class="listitem"><span class="strong"><strong>Alternating least squares</strong></span>(<span class="strong"><strong>ALS</strong></span>): The main advantage of ALS method over SGD is that it can be easily parallelized on distributed platforms.</li></ul></div><p>In this section, we will look into the ALS method.</p><p>The preceding equation involves two unknowns, which we need to solve. Since two unknowns are involved, the aforementioned equation is a non-convex problem. If we fix one of the unknown term constants, this optimization problem will become quadratic and can be solved optimally.</p><p>Alternating least squares is an iterative method, which involves computing one feature vector term using the least squares function by fixing the other feature vector term constant until we solve the preceding equation optimally.</p><p>In order to compute the user feature vector, we fix the item feature vector as a constant and solve for least squares. Similarly, while computing the item feature vector, we fix the user feature vector as a constant and solve for least squares.</p><p>Following this approach, we are able to convert a non-convex problem into a quadratic one, which can be solved optimally.</p><p>Most of the open source distributed platforms such as Mahout and Spark use the ALS method to implement scalable recommender systems for their ability to be parallelized.</p></div><div class="section" title="Singular value decomposition"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec42"/>Singular value decomposition</h2></div></div></div><p><span class="strong"><strong>Singular value decomposition</strong></span> (<span class="strong"><strong>SVD</strong></span>) is another very popular matrix factorization method. In simple terms, an SVD method decomposes a real matrix A of size m x n into three matrices, U,<span class="inlinemediaobject"><img src="../Images/image00277.jpeg" alt="Singular value decomposition"/></span>,V, which satisfy the following equation:</p><div class="mediaobject"><img src="../Images/image00278.jpeg" alt="Singular value decomposition"/></div><p style="clear:both; height: 1em;"> </p><p>In the previous equation, <span class="emphasis"><em>r</em></span> is called the rank of the matrix, <span class="emphasis"><em>A</em></span>. <span class="emphasis"><em>U</em></span>, <span class="emphasis"><em>V</em></span> are orthogonal matrices, and <span class="inlinemediaobject"><img src="../Images/image00277.jpeg" alt="Singular value decomposition"/></span> is a diagonal matrix having all singular values of the matrix <span class="emphasis"><em>A</em></span>. The values of the <span class="emphasis"><em>U</em></span> and <span class="emphasis"><em>V</em></span> are real if <span class="emphasis"><em>A</em></span> is a real matrix. The values of matrix <span class="inlinemediaobject"><img src="../Images/image00277.jpeg" alt="Singular value decomposition"/></span> are positive and real and are available in a decreasing order.</p><p>SVD can also be used as a dimensionality reduction technique, following two steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Choose a rank <span class="emphasis"><em>k</em></span> that is less than <span class="emphasis"><em>r.</em></span></li><li class="listitem">Recompute or subsize the <span class="emphasis"><em>U</em></span>, <span class="inlinemediaobject"><img src="../Images/image00277.jpeg" alt="Singular value decomposition"/></span> ,<span class="emphasis"><em>V</em></span> matrices to <span class="emphasis"><em>(m x k)</em></span>, <span class="emphasis"><em>(k x k)</em></span>, <span class="emphasis"><em>(k x n)</em></span>.</li></ul></div><div class="mediaobject"><img src="../Images/image00279.jpeg" alt="Singular value decomposition"/></div><p style="clear:both; height: 1em;"> </p><p>The matrices obtained by applying SVD are very much applicable to recommender systems as they provide the best low-rank approximations of the original matrix. How do we apply the SVD approach to recommendation? Let's take a rating matrix R of size m x n containing many empty cells. Similar to matrix factorization, our objective is to compute an approximate rating matrix as close as possible o the original matrix with the missing values being predicted.</p><p>Applying SVD on R will produce three matrices, <span class="emphasis"><em>U</em></span>, <span class="inlinemediaobject"><img src="../Images/image00277.jpeg" alt="Singular value decomposition"/></span>, <span class="emphasis"><em>V</em></span>, of sizes, let's say, <span class="emphasis"><em>m x r</em></span>, <span class="emphasis"><em>r x r</em></span>, <span class="emphasis"><em>r x n</em></span>. Here, <span class="emphasis"><em>U</em></span> represents the user latent feature vector representations, <span class="emphasis"><em>V</em></span> represents the item latent feature vector representations, and <span class="inlinemediaobject"><img src="../Images/image00277.jpeg" alt="Singular value decomposition"/></span> represents the independent feature representation, r, of user and items. By setting the value of the independent feature representation to a value <span class="emphasis"><em>k</em></span> less than <span class="emphasis"><em>r</em></span>, we are choosing the k optimal latent features, thereby reducing the size of the matrix. The k-value can be chosen using the cross-validation approach as the value of <span class="emphasis"><em>k</em></span> defines the performance of the model.</p><div class="note" title="Note"><h3 class="title"><a id="note6"/>Note</h3><p>A simpler method for choosing the value <span class="emphasis"><em>k</em></span> as <span class="inlinemediaobject"><img src="../Images/image00277.jpeg" alt="Singular value decomposition"/></span> is to take a diagonal matrix that contains singular values in a descending order, choose the values in the diagonal that have higher values, and eliminate very less diagonal values.</p></div><p>After choosing the k-value, we now resize or choose the first k-column in each of the matrices <span class="emphasis"><em>U</em></span>,<span class="inlinemediaobject"><img src="../Images/image00277.jpeg" alt="Singular value decomposition"/></span>,<span class="emphasis"><em>V</em></span>. This step will render matrices <span class="emphasis"><em>U</em></span>,<span class="inlinemediaobject"><img src="../Images/image00277.jpeg" alt="Singular value decomposition"/></span>,<span class="emphasis"><em>V</em></span> of size <span class="emphasis"><em>m x k</em></span>, <span class="emphasis"><em>k x k</em></span>, and <span class="emphasis"><em>k x n</em></span> respectively, please refer to the below image. After we resize the matrices, we move ahead to the final step.</p><p>In the final step, we will compute the dot products of the following series of matrices in order to calculate the approximate rating matrix <span class="inlinemediaobject"><img src="../Images/image00280.jpeg" alt="Singular value decomposition"/></span></p><div class="mediaobject"><img src="../Images/image00281.jpeg" alt="Singular value decomposition"/></div><p style="clear:both; height: 1em;"> </p><p>Below code snippet shows SVD implementations in R, the following code creates a sample matrix and then SVD is applied, using <code class="literal">svd()</code> available in base package in r, on the sample data to create 3 matrices, dot product between three matrices will get back our approximate original matrix.</p><pre class="programlisting">sampleMat &lt;- function(n) { i &lt;- 1:n; 1 / outer(i - 1, i, "+") } &#13;
original.mat &lt;- sampleMat(9)[, 1:6] &#13;
(s &lt;- svd(original.mat)) &#13;
D &lt;- diag(s$d) &#13;
#  X = U D V' &#13;
s$u %*% D %*% t(s$v) &#13;
</pre><div class="note" title="Note"><h3 class="title"><a id="note7"/>Note</h3><p>Please refer to <a class="link" title="Chapter 7. Building Real-Time Recommendation Engines with Spark" href="part0051.xhtml#aid-1GKCM2">Chapter 7</a>, <span class="emphasis"><em>Building Real-Time Recommendation Engines with Spark</em></span> for ALS implementation in Spark-python.</p></div></div></div>
<div class="section" title="Machine learning techniques"><div class="titlepage" id="aid-TI1E2"><div><div><h1 class="title"><a id="ch04lvl1sec24"/>Machine learning techniques</h1></div></div></div><p>In this section, we will learn about the most important or the most frequently used machine learning techniques, which are widely used in building recommendation engines.</p><div class="section" title="Linear regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec43"/>Linear regression</h2></div></div></div><p><span class="strong"><strong>Linear regression</strong></span> may be treated as a simple, popular, and the foremost approach for solving prediction problems. We employ linear regression where our objective is to predict the future outcomes, given input features and the output label is a continuous variable.</p><p>In linear regression, given historical input and output data, the model will try to find out the relation between independent feature variables and the dependent output variable given by the following equation and diagram:</p><div class="mediaobject"><img src="../Images/image00282.jpeg" alt="Linear regression"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>y </em></span>represents the output continuous dependent variable,<span class="emphasis"><em> x</em></span> represents independent feature variables, <span class="emphasis"><em>β0</em></span> and <span class="emphasis"><em>β1</em></span> are the unknowns or feature weights, <span class="emphasis"><em>e</em></span> represents the error.</p><p>Using the <span class="strong"><strong>ordinary least squares (OLS)</strong></span> approach, we will estimate the unknowns in the preceding equation. We shall not go deep into the linear regression approach, but here we will discuss how we can use linear regression in recommendation engines.</p><p>One of the core tasks in recommendation engines is to make predictions for non-rated items for users. For example, in case of item-based recommendation engines, the prediction for item <span class="emphasis"><em>i</em></span> by user <span class="emphasis"><em>u</em></span> is done by computing the sum of ratings given by user <span class="emphasis"><em>u</em></span> to items similar to item <span class="emphasis"><em>i</em></span>. Then each rating is weighted by its similarity value:</p><div class="mediaobject"><img src="../Images/image00283.jpeg" alt="Linear regression"/></div><p style="clear:both; height: 1em;"> </p><p>Instead of using this weighted average approach to make the predictions, we can use the linear regression approach to calculate the preference values for user <span class="emphasis"><em>u</em></span> for item <span class="emphasis"><em>i</em></span>. While using regression approach, instead of using the original rating values of similar items, we use their approximate rating values based on the linear regression model. For example, to predict the rating for item <span class="emphasis"><em>i</em></span> by user <span class="emphasis"><em>u</em></span>, we can use the following equation:</p><div class="mediaobject"><img src="../Images/image00284.jpeg" alt="Linear regression"/></div><p style="clear:both; height: 1em;"> </p><p>Linear regression using R is given by the following code:</p><pre class="programlisting">library(MASS) &#13;
data("Boston") &#13;
set.seed(0) &#13;
which_train &lt;- sample(x = c(TRUE, FALSE), size = nrow(Boston), &#13;
                      replace = TRUE, prob = c(0.8, 0.2)) &#13;
train &lt;- Boston[which_train, ] &#13;
test &lt;- Boston[!which_train, ] &#13;
lm.fit =lm(medv~. ,data=train ) &#13;
summary(lm.fit) &#13;
 &#13;
Call: &#13;
lm(formula = medv ~ ., data = train) &#13;
 &#13;
Residuals: &#13;
     Min       1Q   Median       3Q      Max  &#13;
-15.2631  -2.7614  -0.5243   1.7867  24.6306  &#13;
 &#13;
Coefficients: &#13;
              Estimate Std. Error t value Pr(&gt;|t|)     &#13;
(Intercept)  39.549376   5.814446   6.802 3.82e-11 *** &#13;
crim         -0.090720   0.040872  -2.220  0.02701 *   &#13;
zn            0.050080   0.015307   3.272  0.00116 **  &#13;
indus         0.032339   0.070343   0.460  0.64596     &#13;
chas          2.451235   0.992848   2.469  0.01397 *   &#13;
nox         -18.517205   4.407645  -4.201 3.28e-05 *** &#13;
rm            3.480574   0.469970   7.406 7.91e-13 *** &#13;
age           0.012625   0.015786   0.800  0.42434     &#13;
dis          -1.470081   0.223349  -6.582 1.48e-10 *** &#13;
rad           0.322494   0.077050   4.186 3.51e-05 *** &#13;
tax          -0.012839   0.004339  -2.959  0.00327 **  &#13;
ptratio      -0.972700   0.148454  -6.552 1.77e-10 *** &#13;
black         0.008399   0.003153   2.663  0.00805 **  &#13;
lstat        -0.592906   0.058214 -10.185  &lt; 2e-16 *** &#13;
--- &#13;
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 &#13;
 &#13;
Residual standard error: 4.92 on 396 degrees of freedom &#13;
Multiple R-squared:  0.7321,     Adjusted R-squared:  0.7233  &#13;
F-statistic: 83.26 on 13 and 396 DF,  p-value: &lt; 2.2e-16 &#13;
 &#13;
#predict new values &#13;
pred = predict(lm.fit,test[,-14]) &#13;
</pre><p>The <code class="literal">lm()</code> function, available in <code class="literal">stats</code> package I R, usually used to fit linear regression models.</p></div><div class="section" title="Classification models"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec44"/>Classification models</h2></div></div></div><p>Classification models fall into the category of the supervised form of machine learning. These models are usually employed in prediction problems, where the response is binary or multiclass labels. In this chapter, we will discuss many types of classification models, such as logistic regression, KNN classification, SVM, decision trees, random forests, bagging, and boosting. Classification models play a very crucial role in recommender systems. Though classification models don't play a great role in neighbourhood methods, they play a very important role in building personalized recommendations, contextual aware systems, and hybrid recommenders. Also, we can apply classification models to the feedback information about the recommendations, which can further be used for calculating the weightages for user features.</p><div class="section" title="Linear classification"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec1"/>Linear classification</h3></div></div></div><p>Logistic regression is the most common among classification models. <span class="strong"><strong>Logistic regression</strong></span> is also known as <span class="strong"><strong>linear classification</strong></span> as it is very similar to linear regression, except that in regression, the output label is continuous, whereas in linear classification, the output label is class variable. In regression, the model is a least squares function, whereas in logistic regression, the prediction model is a logit function given by the following equation:</p><div class="mediaobject"><img src="../Images/image00285.jpeg" alt="Linear classification"/></div><p style="clear:both; height: 1em;"> </p><p>In the preceding equation, <span class="emphasis"><em>e</em></span> is the natural logarithm, <span class="emphasis"><em>x</em></span> is the input variable, <span class="emphasis"><em>β<sub>0</sub></em></span> is the intercept, and <span class="emphasis"><em>β<sub>1</sub></em></span> is the weight of variable x.</p><p>We may interpret the preceding equation as the conditional probability of response variable against the linear combination of input variables. The logit function allows to take any continuous variable and gives response in the range of <span class="emphasis"><em>(0,1)</em></span>, as illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image00286.jpeg" alt="Linear classification"/></div><p style="clear:both; height: 1em;"> </p><p>The logistic regression using R is given as follows:</p><pre class="programlisting">set.seed(1) &#13;
x1 = rnorm(1000)           # sample continuous variables  &#13;
x2 = rnorm(1000) &#13;
z = 1 + 4*x1 + 3*x2        # data creation &#13;
pr = 1/(1+exp(-z))         # applying logit function &#13;
y = rbinom(1000,1,pr)      # bernoulli response variable &#13;
 &#13;
  #now feed it to glm: &#13;
df = data.frame(y=y,x1=x1,x2=x2)   &#13;
glm( y~x1+x2,data=df,family="binomial") &#13;
</pre><p>The <code class="literal">glm()</code> function in R is used to fit generalized linear models, popularly employed for classification problems.</p></div><div class="section" title="KNN classification"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec2"/>KNN classification</h3></div></div></div><p>The k nearest neighbors classification is popularly known as the KNN classification. This is one of the most popular classification techniques. The basic concept in KNN classification is that the algorithm considers k nearest items surrounding a particular data point and tries to classify this data point into one of the output labels based on its k-nearest data points. Unlike other classification techniques such as logistic regression, SVM, or any other classification algorithms, KNN classification is a non-parametric model, which doesn't involves any parameter estimation. The k in KNN is the number of nearest neighbors to be considered:</p><div class="mediaobject"><img src="../Images/image00287.jpeg" alt="KNN classification"/></div><p style="clear:both; height: 1em;"> </p><p>Consider 10 data points. We need to classify a test data point, highlighted in the preceding diagram, into one of two classes, blue or orange. In this example, we classify the test data point using the KNN classification. Let's say k is 4; it means that by considering four data points surrounding the active data point, we need to classify it by performing the following steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">As a first step, we need to calculate the distance of each point from the test data point.</li><li class="listitem">Identify the top four closest data points to the test data point.</li><li class="listitem">Using the voting mechanism, assign the majority class label count to the test data point.</li></ul></div><p>The KNN classification works well in case of highly non-linear problems. Though this method works well in most cases, this method being a non-parametric approach cannot find the feature importance or weightages.</p><p>Similar to the KNN classification, there is a regression version of KNN, which can be used to predict the continuous output labels.</p><p>Both the KNN classification and egression methods find their wide applicability in collaborative filtering recommender systems.</p><p>The following code snippet shows KNN classification using R, in the below code snippet we are using <code class="literal">knn3()</code> available in <code class="literal">caret</code> package for fitting KNN classification and <code class="literal">sample_n()</code> available in <code class="literal">dplyr</code> package to select random rows from a dataframe.</p><pre class="programlisting">data("iris") &#13;
library(dplyr) &#13;
iris2 = sample_n(iris, 150) &#13;
train = iris2[1:120,] &#13;
test = iris2[121:150,] &#13;
cl = train$Species &#13;
library(caret) &#13;
fit &lt;- knn3(Species~., data=train, k=3) &#13;
predictions &lt;- predict(fit, test[,-5], type="class") &#13;
table(predictions, test$Species) &#13;
</pre></div><div class="section" title="Support vector machines"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec3"/>Support vector machines</h3></div></div></div><p><span class="strong"><strong>Support vector machines</strong></span> algorithms are a form of supervised learning algorithms employed for solving classification problems. SVM is generally treated as one of the best algorithms for dealing with classification problems. Given a set of training examples, where each of the data points falls into one of two categories, an SVM training algorithm builds a model that assigns new data points into one category or the other. This model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a margin that is as wide as possible, as shown in the following figure. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall on. In this section, we will go through an overview and implementation of SVMs without going into mathematical details.</p><p>When SVM is applied to a p-dimensional dataset, the data is mapped to a p-1 dimensional hyper plane, and the algorithm finds a clear boundary with sufficient margin between classes. Unlike other classification algorithms that also create a separating boundary for classifying data points, SVM tries to choose a boundary that has maximum margin for separating the classes, as shown in the following figure:</p><div class="mediaobject"><img src="../Images/image00288.jpeg" alt="Support vector machines"/></div><p style="clear:both; height: 1em;"> </p><p>Consider a two-dimensional dataset having two classes, as shown in the previous figure. Now, when the SVM algorithm is applied, firstly it checks whether a one-dimensional hyper plane exists to map all the data points. If the hyper plane exists, the linear classifier creates a decision boundary with a margin to separate the classes. In the preceding figure, the thick redline is the decision boundary, and the thinner blue and red lines are the margins of each class from the boundary. When new test data is used to predict the class, the new data falls into one of the two classes.</p><p>The following are a few key points to be noted:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Though an infinite number of hyper planes can be created, SVM chooses only one hyper plane that has maximum margin, that is, the separating hyper plane that is farthest from the training observations.</li><li class="listitem">This classifier is only dependent on the data points that lie on the margins of the hyper plane, that is, on thin margins in the figure but not on other observations in the dataset. These points are called support vectors.</li><li class="listitem">The decision boundary is affected only by the support vectors but not by other observations located away from the boundaries, that is, if we change the data points other than the support vectors, there will not be any effect on the decision boundary, but if the support vectors are changed, the decision boundary changes.</li><li class="listitem">A large margin on the training data will also have a large margin on the test data so as to classify the test data correctly.</li><li class="listitem">Support vector machines also perform well with non-linear datasets. In this case, we use radial kernel functions.</li></ul></div><p>See below for R implementation of SVM on the <code class="literal">iris</code> dataset. We use the <code class="literal">e1071</code> package to run SVM. In R, the <code class="literal">SVM()</code> function contains the implementation of Support Vector Machines present in the <code class="literal">e1071</code> package.</p><div class="note" title="Note"><h3 class="title"><a id="note8"/>Note</h3><p>The cross-validation method is used to evaluate the accuracy of predictive models before testing future unseen data.</p></div><p>We can see that the SVM method is called with the <code class="literal">tune()</code> method, which performs cross validation and runs the model on different values of the cost parameters:</p><pre class="programlisting">library(e1071) &#13;
data(iris) &#13;
sample = iris[sample(nrow(iris)),] &#13;
train = sample[1:105,] &#13;
test = sample[106:150,] &#13;
tune =tune(svm,Species~.,data=train,kernel ="radial",scale=FALSE,ranges =list(cost=c(0.001,0.01,0.1,1,5,10,100))) &#13;
tune$best.model &#13;
 &#13;
Call: &#13;
best.tune(method = svm, train.x = Species ~ ., data = train, ranges = list(cost = c(0.001,  &#13;
    0.01, 0.1, 1, 5, 10, 100)), kernel = "radial", scale = FALSE) &#13;
 &#13;
Parameters: &#13;
   SVM-Type:  C-classification  &#13;
 SVM-Kernel:  radial  &#13;
       cost:  10  &#13;
      gamma:  0.25  &#13;
 &#13;
Number of Support Vectors:  25 &#13;
 &#13;
summary(tune) &#13;
 &#13;
Parameter tuning of 'svm': &#13;
- sampling method: 10-fold cross validation  &#13;
- best parameters: &#13;
 cost &#13;
   10 &#13;
- best performance: 0.02909091  &#13;
- Detailed performance results: &#13;
   cost      error dispersion &#13;
1 1e-03 0.72909091 0.20358585 &#13;
2 1e-02 0.72909091 0.20358585 &#13;
3 1e-01 0.04636364 0.08891242 &#13;
4 1e+00 0.04818182 0.06653568 &#13;
5 5e+00 0.03818182 0.06538717 &#13;
6 1e+01 0.02909091 0.04690612 &#13;
7 1e+02 0.07636364 0.08679584 &#13;
 &#13;
cost =10 is chosen from summary result of tune variable &#13;
model =svm(Species~.,data=train,kernel ="radial",cost=10,scale=FALSE) &#13;
</pre><p>The <code class="literal">tune$best.model</code>tells us that the model works best with cost parameter as <code class="literal">10</code> and the total number of support vectors as <code class="literal">25</code>:</p><pre class="programlisting">pred = predict(model,test) &#13;
</pre></div><div class="section" title="Decision trees"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec4"/>Decision trees</h3></div></div></div><p><code class="literal">Decision trees</code> is a simple, fast, and tree-based supervised learning algorithm for solving classification problems. Though not very accurate when compared to other logistic regression methods, this algorithm comes in handy while dealing with recommender systems.</p><p>Let's define the decision trees with an example. Imagine a situation where you have to predict the class of flower based on its features such as petal length, petal width, sepal length and sepal width. We apply the decision trees methodology to solve this problem:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">We consider the entire data at the start of the algorithm.</li><li class="listitem">Now we choose a proper question/variable to divide the data into two parts. In our case, we choose to divide the data based on petal length &gt; 2.45 and &lt;= 2.45. This separates flower class <code class="literal">setosa</code> from the rest of the classes.</li><li class="listitem">We further divide the data having petal length &gt; 2.45, based on same variable with petal length &lt; 4.5 and &gt;= 4.5 as shown in the following diagram.</li><li class="listitem">This splitting of the data will be further divided by narrowing down the data space until we reach a point where all the bottom points represent the response variables or where further logical split cannot be done on the data.</li></ol><div style="height:10px; width: 1px"/></div><p>In the following decision tree diagram, we have one root node, four internal nodes where data split occurred, five terminal nodes where data split cannot be done further, and they are defined as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Petal Length &lt; 2.5 as root node</li><li class="listitem">Petal length &lt; 2.5, petal length &lt; 4.85, sepal length &lt; 5.15, and petal width &lt; 1.75 are called internal nodes</li><li class="listitem">Final nodes having the class of the flowers are called terminal nodes</li><li class="listitem">The lines connecting the nodes are called the branches of the tree</li></ul></div><p>While predicting responses on new data using the aforementioned built model, each of the new data points is taken through each of the nodes, a question is asked, and a logical path is taken to reach its logical class:</p><div class="mediaobject"><img src="../Images/image00289.jpeg" alt="Decision trees"/></div><p style="clear:both; height: 1em;"> </p><p>Take a look at the decision tree implementation in R on the <code class="literal">iris</code> dataset using tree package available from CRAN.</p><p>The summary of the mode given next tells us that the misclassification rate is 0.0381, indicating that the model is very accurate:</p><pre class="programlisting">library(tree) &#13;
data(iris) &#13;
sample = iris[sample(nrow(iris)),] &#13;
train = sample[1:105,] &#13;
test = sample[106:150,] &#13;
model = tree(Species~.,train) &#13;
summary(model) &#13;
</pre><div class="mediaobject"><img src="../Images/image00290.jpeg" alt="Decision trees"/></div><p style="clear:both; height: 1em;"> </p><p>Below code shows plotting the decision tree:</p><pre class="programlisting">plot(model) #plot trees &#13;
text(model) #apply text &#13;
</pre><p>The following code displays the decision tree model:</p><div class="mediaobject"><img src="../Images/image00291.jpeg" alt="Decision trees"/></div><p style="clear:both; height: 1em;"> </p><pre class="programlisting">pred = predict(model,test[,-5],type="class") &#13;
</pre><p>The following image displays the prediction values made using <code class="literal">pred()</code> method:</p><div class="mediaobject"><img src="../Images/image00292.jpeg" alt="Decision trees"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Ensemble methods"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5"/>Ensemble methods</h3></div></div></div><p>In data mining, we use ensemble methods, which refer to using multiple learning algorithms to obtain better predictive results than applying any single learning algorithm on any statistical problem. This section deals with an overview of popular ensemble methods such as bagging, boosting, and random forests.</p><div class="section" title="Random forests"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec0"/>Random forests</h4></div></div></div><p>Random forests refer to improvised supervised algorithm than bootstrap aggregation or bagging method though built on a similar approach. Unlike selecting all the variables in all the B samples generated using the bootstrap technique in bagging, we select only a few predictor variables randomly from total variables for each of the B samples, and then these samples are trained with the models. Predictions are made by averaging the result of each model. The number of predictors in each sample is decided using the formula <span class="inlinemediaobject"><img src="../Images/image00293.jpeg" alt="Random forests"/></span>, where <span class="emphasis"><em>p</em></span> is the total variable count in the original dataset.</p><div class="note" title="Note"><h3 class="title"><a id="note9"/>Note</h3><p>This approach removes the condition of dependency of strong predictor in the dataset as we intentionally select fewer variables than all the variables for every iteration.</p></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">This approach also decorrelates variables resulting in less variability in the model, hence more reliability.</li></ul></div><p>Take a look at the following R implementation of random forests on the iris dataset using the <code class="literal">randomForest</code> package available from CRAN:</p><pre class="programlisting">library(randomForest) &#13;
data(iris) &#13;
sample = iris[sample(nrow(iris)),] &#13;
train = sample[1:105,] &#13;
test = sample[106:150,] &#13;
model =randomForest(Species~.,data=train,mtry=2,importance =TRUE,proximity=TRUE) &#13;
</pre><p>The following image will display the model details for random forest built above:</p><div class="mediaobject"><img src="../Images/image00294.jpeg" alt="Random forests"/></div><p style="clear:both; height: 1em;"> </p><pre class="programlisting">pred = predict(model,newdata=test[,-5]) &#13;
</pre><div class="mediaobject"><img src="../Images/image00295.jpeg" alt="Random forests"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Bagging"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec1"/>Bagging</h4></div></div></div><p><span class="strong"><strong>Bagging</strong></span> is also known as <span class="strong"><strong>bootstrap aggregating</strong></span>. It is designed to improve the stability and accuracy of machine learning algorithms. It helps in avoiding overfitting and reduces variance. This is mostly used with decision trees.</p><p>Bagging involves randomly generating bootstrap samples, random sample with replacement, from the dataset and training the models individually. Predictions are then made by aggregating or averaging all the response variables.</p><p>For example, consider a dataset (<span class="emphasis"><em>Xi</em></span>, <span class="emphasis"><em>Yi</em></span>) where <span class="emphasis"><em>i</em></span>=1 ...n, contains n data points. The following are the steps to perform bagging on this dataset:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Now randomly select B samples with replacement from the original dataset using the bootstrap technique.</li><li class="listitem">Next, train the B samples with regression/classification models independently, and then predictions are made on the test set by averaging the responses from all the B models generated in case of regression or selecting the most-occurring class among B samples in case of classification.</li></ul></div></div><div class="section" title="Boosting"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec2"/>Boosting</h4></div></div></div><p>Unlike in bagging where multiple copies of bootstrap samples are created and a new model is fitted for each copy of dataset and all the individual models are combined to create a single predictive model, in boosting, each new model is built using information from previously built models. Boosting can be understood as an iterative method involving two steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">A new model is built on the residuals of the previous models instead of response variable.</li><li class="listitem">Now the residuals are calculated from this model and updated to the residuals used in previous step.</li></ol><div style="height:10px; width: 1px"/></div><p>The preceding two steps are repeated multiple iterations allowing each new model to learn from its previous mistakes, thereby improving the model accuracy.</p><p>The following code snippet shows us gradient boosting using R, <code class="literal">gbm()</code> package in r generally used to perform various regression tasks:</p><pre class="programlisting">library(gbm) &#13;
data(iris) &#13;
sample = iris[sample(nrow(iris)),] &#13;
train = sample[1:105,] &#13;
test = sample[106:150,] &#13;
model = gbm(Species~.,data=train,distribution="multinomial",n.trees=5000,interaction.depth=4) &#13;
summary(model) &#13;
</pre><div class="mediaobject"><img src="../Images/image00296.jpeg" alt="Boosting"/></div><p style="clear:both; height: 1em;"> </p><p>The following image shows them model summary visually, showing the relative importance of each feature:</p><div class="mediaobject"><img src="../Images/image00297.jpeg" alt="Boosting"/></div><p style="clear:both; height: 1em;"> </p><p>The preceding summary states the relative importance of the variables of the model.</p><pre class="programlisting">pred = predict(model,newdata=test[,-5],n.trees=5000) &#13;
</pre><div class="mediaobject"><img src="../Images/image00298.jpeg" alt="Boosting"/></div><p style="clear:both; height: 1em;"> </p><p>Pick the response with the highest probability from the resulting <code class="literal">pred</code> matrix, by doing <code class="literal">apply(pred, 1, which.max)</code> on the vector output from prediction.</p><pre class="programlisting">p.pred &lt;- apply(pred,1,which.max) &#13;
</pre><div class="mediaobject"><img src="../Images/image00299.jpeg" alt="Boosting"/></div><p style="clear:both; height: 1em;"> </p><p>In the preceding code snippet, the output value for the <code class="literal">predict()</code> function is used in the <code class="literal">apply()</code> function to pick the response with highest probability among each row in the pred matrix, and the resultant output from the <code class="literal">apply()</code> function is the prediction for the response variable.</p></div></div></div></div>
<div class="section" title="Clustering techniques"><div class="titlepage" id="aid-UGI02"><div><div><h1 class="title"><a id="ch04lvl1sec25"/>Clustering techniques</h1></div></div></div><p><span class="strong"><strong>Cluster analysis</strong></span> is the process of grouping objects together in a way that objects in one group are more similar than objects in other groups.</p><p>For example, identifying and grouping clients with similar booking activities on travel portal, as shown in the following figure.</p><p>In the preceding example, each group is called a <span class="strong"><strong>cluster</strong></span>, and each member (data point) of the cluster behaves similar to its group members:</p><div class="mediaobject"><img src="../Images/image00300.jpeg" alt="Clustering techniques"/></div><p style="clear:both; height: 1em;"> </p><p>Cluster analysis is an unsupervised learning method. In supervised methods such as regression analysis, we have input variables and response variables; we fit a statistical model to the input variables to predict the response variable, whereas in unsupervised learning methods, we do not have any response variable to predict; we only have input variables. Instead of fitting a model to the input variables to predict the response variable, we just try to find patterns within the dataset. There are three popular clustering algorithms: hierarchical cluster analysis, k-means cluster analysis, and two-step cluster analysis. In this section, we will learn about k-means clustering.</p><div class="section" title="K-means clustering"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec45"/>K-means clustering</h2></div></div></div><p>K-means is an unsupervised, iterative algorithm where k is the number of clusters to formed from the data. Clustering is achieved in two steps, as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>The cluster assignment step</strong></span>: In this step, we randomly choose two cluster points (red dot &amp; green dot) and assign each data point to one of the two cluster points, whichever is closer to it (Take a look at the top part of the following figure).</li><li class="listitem"><span class="strong"><strong>The move centroid step:</strong></span> In this step, we take the average of the points of all the examples in each group and move the centroid to the new position, that is, the mean position calculated (Take a look at the bottom part of the following image).</li></ul></div><p>The preceding steps are repeated until all the data points are grouped into two groups and the mean of the data points at the end of the move centroid step doesn't change:</p><div class="mediaobject"><img src="../Images/image00301.jpeg" alt="K-means clustering"/></div><p style="clear:both; height: 1em;"> </p><p>The previous figure shows how a clustering algorithm works on data to form clusters. Take a look at the following R implementation of k-means clustering on the iris dataset.</p><p>The k-means clustering using R is as follows:</p><pre class="programlisting">library(cluster) 
data(iris) 
iris$Species = as.numeric(iris$Species) 
kmeans&lt;- kmeans(x=iris, centers=5) 
clusplot(iris,kmeans$cluster, color=TRUE, shade=TRUE,labels=13, lines=0) 
</pre><p>The <code class="literal">Clustplot()</code> method available in <code class="literal">cluster</code> package is used to plot the clusters formed for the IRIS dataset and is shown in the following image:</p><div class="mediaobject"><img src="../Images/image00302.jpeg" alt="K-means clustering"/></div><p style="clear:both; height: 1em;"> </p><p>The previous figure shows the formation of clusters on the iris data, and the clusters account for 95% of the data. In the previous example, the number of clusters k value is selected using the elbow method.</p><p>The following code snippet explains implementation of k-means clustering, which is shown in the next screenshot:</p><pre class="programlisting">library(cluster) 
library(ggplot2) 
data(iris) 
iris$Species = as.numeric(iris$Species) 
cost_df &lt;- data.frame() 
for(i in 1:100){ 
kmeans&lt;- kmeans(x=iris, centers=i, iter.max=50) 
cost_df&lt;- rbind(cost_df, cbind(i, kmeans$tot.withinss)) 
} 
names(cost_df) &lt;- c("cluster", "cost") 
#Elbow method to identify the idle number of Cluster 
#Cost plot 
ggplot(data=cost_df, aes(x=cluster, y=cost, group=1)) + 
theme_bw(base_family="Garamond") + 
geom_line(colour = "darkgreen") + 
theme(text = element_text(size=20)) + 
ggtitle("Reduction In Cost For Values of 'k'\n") + 
xlab("\nClusters") + ylab("Within-Cluster Sum of Squares\n") 
</pre><div class="mediaobject"><img src="../Images/image00303.jpeg" alt="K-means clustering"/></div><p style="clear:both; height: 1em;"> </p><p>From the previous figure, we can observe that the direction of the cost function is changed at cluster number 5, hence we choose 5 as our number of clusters k. Since the number of optimal clusters is found at elbow of the graph, we call it the <span class="strong"><strong>elbow method</strong></span>.</p></div></div>
<div class="section" title="Dimensionality reduction"><div class="titlepage" id="aid-VF2I2"><div><div><h1 class="title"><a id="ch04lvl1sec26"/>Dimensionality reduction</h1></div></div></div><p>One of the most commonly faced problems while building recommender systems is high dimensional and sparse data. Many times, we face a situation where we have a large set of features and less number of data points. In such situations, when we fit a model to the dataset, the predictive power of the model would be lower. This scenario is often termed as the curse of dimensionality. In general, adding more data points or decreasing the feature space, also known as dimensionality reduction, often reduces the effects of curse of dimensionality. In this section, we will discuss principal component analysis, a popular dimensionality reduction technique to reduce the effects of the curse of dimensionality.</p><div class="section" title="Principal component analysis"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec46"/>Principal component analysis</h2></div></div></div><p><span class="strong"><strong>Principal component analysis</strong></span> (<span class="strong"><strong>PCA</strong></span>) is a classical statistical technique for dimensionality reduction. PCA algorithm transforms the data with high dimensional space to a space with fewer dimensions. The algorithm linearly transforms m-dimensional input space to n-dimensional (n&lt;m) output space, with the objective of minimizing the amount of information/variance lost by discarding (m-n) dimensions. PCA allows us to discard the variables/features that have less variance.</p><p>Technically speaking, PCA uses orthogonal projection of highly correlated variables to a set of values of linearly uncorrelated variables called principal components. The number of principal components is less than or equal to the number of original variables. This linear transformation is defined in such a way that the first principal component has the largest possible variance, that is, it accounts for as much of the variability in the data as possible by considering highly correlated features, and each succeeding component, in turn, has the highest variance by using the features that are less correlated with the first principal component, which is orthogonal to the preceding component.</p><p>Let's understand this in simple terms. Assume that we have a three-dimensional data space with two features more correlated with each other than with the third. We now want to reduce the data to a two-dimensional space using PCA.</p><p>The first principal component is created in such a way that it explains maximum variance using the two correlated variables along the data. In the following figure, the first principal component (the bigger line) is along the data explaining most variance. To choose the second principal component, we need to choose another line that has the highest variance, is uncorrelated, and is orthogonal to the first principal component, The implementation and technical details of PCA is out of scope of this book, so we will discuss how it used in R.</p><p>The following image explains the spatial representation of principal components:</p><div class="mediaobject"><img src="../Images/image00304.jpeg" alt="Principal component analysis"/></div><p style="clear:both; height: 1em;"> </p><p>We illustrate PCA using the <code class="literal">USArrests</code> dataset. The <code class="literal">USArrests</code> dataset contains crime related statistics, such as <code class="literal">Assault</code>, <code class="literal">Murder</code>, <code class="literal">Rape</code>, <code class="literal">UrbanPop</code> per 100,000 residents in 50 states in the U.S..</p><p>PCA implementation in R is as follows:</p><pre class="programlisting">data(USArrests) 
head(states) 
[1] "Alabama"    "Alaska"     "Arizona"    "Arkansas"   "California" "Colorado"  
 
names(USArrests) 
[1] "Murder"   "Assault"  "UrbanPop" "Rape"  
</pre><p>Let's use the <code class="literal">apply()</code> function to the <code class="literal">USArrests</code> dataset row-wise to calculate the variance to see how each variable is varying:</p><pre class="programlisting">apply(USArrests , 2, var) 
 
Murder    Assault   UrbanPop       Rape  
  18.97047 6945.16571  209.51878   87.72916  
</pre><p>We observe that <code class="literal">Assault</code> has the most variance. It is important to note at this point that scaling the features is a very important step while applying PCA.</p><p>Apply PCA after scaling the feature, as follows:</p><pre class="programlisting">pca =prcomp(USArrests , scale =TRUE) 
 
pca 
Standard deviations: 
[1] 1.5748783 0.9948694 0.5971291 0.4164494 
 
Rotation: 
                PC1        PC2        PC3         PC4 
Murder   -0.5358995  0.4181809 -0.3412327  0.64922780 
Assault  -0.5831836  0.1879856 -0.2681484 -0.74340748 
UrbanPop -0.2781909 -0.8728062 -0.3780158  0.13387773 
Rape     -0.5434321 -0.1673186  0.8177779  0.08902432 
</pre><p>Now let's understand the components of PCA output:</p><pre class="programlisting">names(pca) 
[1] "sdev"     "rotation" "center"   "scale"    "x" 
</pre><p><code class="literal">Pca$rotation</code> contains the principal component loadings matrix, which explains the proportion of each variable along each principal component.</p><p>Now let's learn how to interpret the results of PCA using a biplot graph. Biplot is used to show the proportions of each variable along the two principal components.</p><p>The following code changes the directions of the biplot; if we don't include the following two lines, the plot will be a mirror image of the following one:</p><pre class="programlisting">pca$rotation=-pca$rotation 
pca$x=-pca$x 
biplot (pca , scale =0) 
</pre><p>The following image shows a plot showing principal components for the dataset:</p><div class="mediaobject"><img src="../Images/image00305.jpeg" alt="Principal component analysis"/></div><p style="clear:both; height: 1em;"> </p><p>In the previous figure, known as biplot, we can see the two principal components (PC1, PC2) of the <code class="literal">USArrests</code> dataset. The red arrows represent the loading vectors, which shows how the feature space varies along the principal component vectors.</p><p>From the plot, we observe that the first principal component vector, PC1, more or less places equal weight to three features: rape, assault, and murder. This means that these three features are more correlated with each other than with the UrbanPop feature. The second principal component, PC2, places more weight on UrbanPop than and is less correlated with the remaining three features.</p></div></div>
<div class="section" title="Vector space models"><div class="titlepage" id="aid-10DJ42"><div><div><h1 class="title"><a id="ch04lvl1sec27"/>Vector space models</h1></div></div></div><p><span class="strong"><strong>Vector space models</strong></span> are algebraic models most commonly used in text analysis applications for representing text documents using the words as vectors. This is widely used in information retrieval applications. In text analysis, let's say we want to find the similarity between two sentences. How do we go about this? We know that to compute similarity measure metric, the data should be all numeric. When it comes to a sentence we have words rather than numerals. Vectors space models allow us to represent the words present in the sentences in numeric form so that we can apply any of the similarity calculation metrics, such as cosine similarity.</p><p>This representation of sentences of words in numeric form can be done in two popular ways:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Term frequency</li><li class="listitem">Term frequency inverse document frequency</li></ul></div><p>Let's understand the previously mentioned approaches with an example:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Sentence 1</strong></span>: THE CAT CHASES RAT.</li><li class="listitem"><span class="strong"><strong>Sentence 2</strong></span>: THE DOG CHASES CAT.</li><li class="listitem"><span class="strong"><strong>Sentence 3</strong></span>: THE MAN WALKS ON MAT.</li></ul></div><p>Given three sentences, our objective is to find the similarity between the sentences. It is clear that we cannot directly apply similarity metrics such as cosine directly. So now let's learn how to represent them in numeric format.</p><div class="note" title="Note"><h3 class="title"><a id="note10"/>Note</h3><p>As a general notation, each sentence in vector space model is known as a <span class="strong"><strong>document</strong></span>.</p></div><div class="section" title="Term frequency"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec47"/>Term frequency</h2></div></div></div><p><span class="strong"><strong>Term frequency</strong></span> simply means the frequency of the word in a document. To find the frequency, we need to perform the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The first step is to find all the unique keywords present in all the documents, represented as V:<p>V = {THE, CAT, CHASES, RAT, DOG, MAN, WALKS, ON, MAT}</p></li><li class="listitem">The next step is to create vectors of documents, shown as follows:<p>D1 = {THE, CAT, CHASES, RAT}</p><p>D2 = {THE, DOG, CHASES, CAT}</p><p>D3 = {THE, MAN, WALKS, ON, MAT}</p></li><li class="listitem">In this step, we have to count the term frequency of all the terms in each document:<p>D1 = {(THE,1),(CAT,1),(CHASES,1),(RAT,1)}</p><p>D2 = {(THE,1),(DOG,1),(CHASES,1),(CAT,1)}</p><p>D3 = {(THE,1),(MAN,1),(WALKS,1),(ON,1),(MAT,1)}</p></li><li class="listitem">Now we will create a term-document matrix with document IDs as rows, unique terms as columns, and term frequency as cell values, as follows:<div class="mediaobject"><img src="../Images/image00306.jpeg" alt="Term frequency"/></div><p style="clear:both; height: 1em;"> </p></li></ol><div style="height:10px; width: 1px"/></div><p>Take a while and understand what is happening here: we have put 1 in places where the word occurs in the sentences and 0 where the word does not.</p><p>Now observe that we have represented our documents in the form of a numerical matrix using the term frequency in each document.</p><p>Now, in this term-matrix document, also known as TDM, we can directly apply similarity metrics such as cosine similarity.</p><div class="mediaobject"><img src="../Images/image00307.jpeg" alt="Term frequency"/></div><p style="clear:both; height: 1em;"> </p><p>The previous figure visually represents the similarity between the documents after calculating the cosine angle. From the figure, we can infer that the angle between D1 and D2 is less and that between D1 and D3 is more, indicating that D1 is more similar to D2 than D3.</p></div><div class="section" title="Term frequency inverse document frequency"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec48"/>Term frequency inverse document frequency</h2></div></div></div><p>The earlier approach is also known as the bag of words approach where we just have to find the frequency of each term in each document and numerically represent it in a TDM. But inherently, there is a flaw in this approach. This approach gives more weightage or importance to the terms that occur more frequently and less importance to the rarely occurring terms. It is important to understand that if a term occurs more frequently in most document collections, that term will not contribute as a differentiator in identifying a document. Similarly, a term which occurs more frequently in a document and less frequently in the whole of the document collection will contribute as a differentiator in identifying a particular document. This scaling down of weightage to more frequently occurring terms in the document collection and scaling up the weightage to more frequently occurring terms in document but less frequently in all of the document collection can be achieved using <span class="strong"><strong>term frequency inverse document frequency</strong></span> (<span class="strong"><strong>tf-idf</strong></span>).</p><p>The <span class="emphasis"><em>tf-idf</em></span> can be computed as a product of term frequency of document and inverse document frequency of the term:</p><p><span class="emphasis"><em>tf-idf = tf X idf</em></span></p><p>Here, <span class="emphasis"><em>idf</em></span> is defined as follows:</p><p><span class="emphasis"><em>idf = log(D/(1+ n(d,t)))</em></span></p><p>Here, <span class="emphasis"><em>D</em></span> is the total number of document collections, and <span class="emphasis"><em>n(d,t)</em></span> is the number of times a term <span class="emphasis"><em>t</em></span> occurs in all the documents.</p><p>Let's compute TDM in terms of <span class="emphasis"><em>tf-idf</em></span> for the previous set of documents (<span class="emphasis"><em>D1</em></span>, <span class="emphasis"><em>D2</em></span>, <span class="emphasis"><em>D3</em></span>):</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Take the TDM and calculate the term frequency of each term in each of the documents. This is the same as what we have done in the TF section:<div class="mediaobject"><img src="../Images/image00308.jpeg" alt="Term frequency inverse document frequency"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">In this step, we need to calculate the <span class="strong"><strong>document frequency</strong></span> (<span class="strong"><strong>DF</strong></span>), that is, how many times a term occurred in all the document collection. For example, let's calculate the DF for the term THE. The term is present in all the three documents, hence its DF will be 3. Similarly, for the term CAT the DF is 2:<div class="mediaobject"><img src="../Images/image00309.jpeg" alt="Term frequency inverse document frequency"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">In this step, we shall calculate the inverse of document frequency (IDF) using the aforementioned formula for IDF.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">So for the term THE, the idf will be given by: idf(THE) = log(3/(1+3)) = -0.12494</li></ul></div><div class="mediaobject"><img src="../Images/image00310.jpeg" alt="Term frequency inverse document frequency"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">Compute tf-idf as the product of tf and idf for each of the terms in the whole document collection, as follows:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">For example, for the term RAT in D1, the tf-idf will be computed as <span class="emphasis"><em>1 X 0.4777121 = 0.4777121</em></span></li></ul></div><div class="mediaobject"><img src="../Images/image00311.jpeg" alt="Term frequency inverse document frequency"/></div><p style="clear:both; height: 1em;"> </p></li></ol><div style="height:10px; width: 1px"/></div><p>Now that we have calculated the <span class="emphasis"><em>tf-idf</em></span>, we can compare the previous TDM based on <span class="emphasis"><em>tf-df</em></span> with the TDM with <span class="emphasis"><em>tf</em></span>. The main comparisons we can draw are in the differences in weightages for each of the terms in TDM. More frequent words across the document collection have got less weightage compared to the rarely occurred words in the document.</p><p>Now, on top of this TDM based on <span class="emphasis"><em>tf-idf</em></span> representation, we can directly apply the similarity metric measurements.</p><p>In this section, we learned about the vector space models and <span class="emphasis"><em>tf</em></span>, <span class="emphasis"><em>tf-idf</em></span> concepts, which are widely used in text analysis. Now the real question is: how do we apply these techniques in recommendation engines?</p><p>Many a time, while building content-based recommendation engines, we will be getting the user preference data in text format or the features of the items as text. In such cases we might able to apply the aforementioned techniques to represent the text data as numerical vectors.</p><p>Also many times we need to find the feature importance or feature weightage to the item features while building personalized content-based recommendation engines. In such cases, vector space models concepts are very useful.</p><p>The following code snippet shows how to calculate <code class="literal">tfidf</code> in R. In the code, we use <code class="literal">TermDocumentMatrix()</code> and <code class="literal">weightTFidf()</code> to calculate the term document matrix and <code class="literal">tfidf</code> respectively available in the <code class="literal">tm</code> package in R. The <code class="literal">inspect()</code> method is used to attain the results:</p><pre class="programlisting">library(tm) 
data(crude) 
tdm &lt;- TermDocumentMatrix(crude,control=list(weighting =   function(x) weightTfIdf(x, normalize =TRUE), stopwords = TRUE)) 
inspect(tdm) 
</pre><p>The following screenshot just shows a very small portion of the large document term:</p><div class="mediaobject"><img src="../Images/image00312.jpeg" alt="Term frequency inverse document frequency"/></div><p style="clear:both; height: 1em;"> </p></div></div>
<div class="section" title="Evaluation techniques" id="aid-11C3M1"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec28"/>Evaluation techniques</h1></div></div></div><p>In the previous sections, we saw various data mining techniques used in recommender systems. In this section, we will learn how to evaluate models built using data mining techniques. The ultimate goal for any data analytics model is to perform well on future data. This objective can be achieved only if we build a model, which is efficient and robust during the development stage.</p><p>While evaluating any model, the most important things we need to consider are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Whether the model is overfitting or underfitting</li><li class="listitem">How well the model fits the future data or the test data</li></ul></div><p>Underfitting, also known as bias, is a scenario in which the model doesn't even perform well on training data; this means that we are fitting a less robust model to the data; for example, letting the data be distributed non-linearly and fitting it with a linear model. From the following image, we see that data is non-linearly distributed. Assume that we have fitted a linear model (orange line). In this case, during the model-building stage itself, the prediction power will be low.</p><p>Overfitting is a scenario in which the model performs well on training data but does really bad on test data. This scenario arises when the model memorizes the data pattern rather than learning from the data; for example, letting the data be distributed non-linearly and fitting a complex model (green line). In this case, we observe that the model is fitted very close to the data distribution, taking care of every up and down. In this case, the model is most likely to fail on previously unseen data:</p><div class="mediaobject"><img src="../Images/image00313.jpeg" alt="Evaluation techniques"/></div><p style="clear:both; height: 1em;"> </p><p>The preceding figure shows simple, complex, and appropriately fitted models training data. The green fit represents overfitting, the orange line represents underfitting, the black and blue lines represent the appropriate model, which is a trade-off between the underfit and the overfit.</p><p>Any fitted model is evaluated to avoid the aforementioned scenarios using cross-validation, regularization, pruning, model comparisons, ROC curves, confusion matrix, and so on.</p><div class="section" title="Cross-validation"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec49"/>Cross-validation</h2></div></div></div><p>This is very popular technique for model evaluation for almost all models. In this technique, we divide the original data into multiple folds/sets (say 5) of training dataset and test dataset. At each fold iteration the model is built using the training dataset and evaluated using the test dataset. This process is repeated for all the folds. The test errors are calculated for very iteration. The average test error is calculated to generalize the model accuracy at the end of all the iterations.</p><p>Cross-validation implementation is explained in <a class="link" title="Chapter 5. Building Collaborative Filtering Recommendation Engines" href="part0037.xhtml#aid-1394Q1">Chapter 5</a>, <span class="emphasis"><em>Building Collaborative Filtering Recommendation Engines</em></span>.</p></div><div class="section" title="Regularization"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec50"/>Regularization</h2></div></div></div><p>In this technique, the data variables are penalized to reduce the complexity of the model with the objective of minimizing the cost function. There are the two most popular regularization techniques: Ridge Regression and Lasso Regression. In both the techniques, we try to reduce the variable coefficients to zero so less number of variables will fit the data optimally.</p><p>The popular evaluation metrics for recommendation engines are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Root-mean-square error (RMSE)</li><li class="listitem">Mean absolute error (MAE)</li><li class="listitem">Precision and recall</li></ul></div><div class="section" title="Root-mean-square error (RMSE)"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec6"/>Root-mean-square error (RMSE)</h3></div></div></div><p><span class="strong"><strong>Root-mean-square error</strong></span> is one of the most popular, frequently used, simple measures to find the accuracy of a model. In a general sense, it is the difference between the actual and predicted values. By definition, it is the squared root of mean square error, as given by the following equation:</p><div class="mediaobject"><img src="../Images/image00314.jpeg" alt="Root-mean-square error (RMSE)"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>X<sub>act</sub></em></span> refers to the observed values, and <span class="emphasis"><em>X<sub>pred</sub></em></span> refers to the predicted values.</p><p>How is RMSE applicable to recommendation engines?</p><p>One of the core tasks in recommendation engines is to predict the preference values for non-rated items for particular users. We use many approaches discussed in previous sections to predict these non-rated preference values. Consider the following rating matrix used for building a recommendation model. Assume that our recommendation engine model has predicted all the empty cells in the following figure let they be represented as r hat. Also assume that we know the actual values of these predicted empty cells; let they be represented as r.</p><div class="mediaobject"><img src="../Images/image00315.jpeg" alt="Root-mean-square error (RMSE)"/></div><p style="clear:both; height: 1em;"> </p><p>Now use the values of <span class="emphasis"><em>r hat</em></span> and <span class="emphasis"><em>r</em></span> in the preceding equation to calculate the model accuracy of the predictive power of the recommendation engine.</p></div><div class="section" title="Mean absolute error (MAE)"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec7"/>Mean absolute error (MAE)</h3></div></div></div><p>Another popular evaluation technique for the data-mining model is <span class="strong"><strong>mean absolute error</strong></span> (<span class="strong"><strong>MAE</strong></span>). This evaluation metric is very similar to RMSE and is given by the following equation:</p><div class="mediaobject"><img src="../Images/image00316.jpeg" alt="Mean absolute error (MAE)"/></div><p style="clear:both; height: 1em;"> </p><p>This is a very simple measure computed as mean error between predicted and actual values. MAE is applied in recommendation engines as a way to evaluate the model.</p></div><div class="section" title="Precision and recall"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec8"/>Precision and recall</h3></div></div></div><p>After we have deployed a recommendation engine in production, we will be interested only if the suggested recommendations are accepted by the users. How do we measure the effectiveness of the recommendation engine in terms of whether the model is generating valid recommendations? To measure the effectiveness, we can borrow the precision-recall evaluation technique, a popular technique in evaluating a classification model. The preceding discussion about whether a served recommendation is useful or not for a user can be treated as the binary class label of a classification model, and then we can calculate the precision-recall.</p><p>To understand precision-recall, we should understand a few more metrics that go together with precision-recall, such as true positive, true negative, false positive, and true negative.</p><p>To build what is popularly known as a confusion matrix, as shown next, let's take an example of online news recommending site, which contains 50 web pages.</p><p>Let's say we have generated 35 recommendations to user A. Of these, A has clicked on 25 suggested web pages, and 10 web pages are non-clicked. Now with this information, we create a table with the number of clicks, as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">In the top-left column, enter the count of suggested links that A has clicked on</li><li class="listitem">In the top-right column, enter the count of suggested links that A has not clicked on</li><li class="listitem">In the bottom-left column, enter the count of links that A has clicked on but have not been suggested</li><li class="listitem">In the bottom-right column, enter the count of links that A has not clicked on and have not been suggested:<div class="mediaobject"><img src="../Images/image00317.jpeg" alt="Precision and recall"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">The top-left count is called <span class="strong"><strong>true positive</strong></span> (<span class="strong"><strong>tf</strong></span>), which indicates the count of all the responses where the actual response is positive and the model predicted as positive</li><li class="listitem">The top-right count is called <span class="strong"><strong>false positive</strong></span> (<span class="strong"><strong>fp</strong></span>), which indicates the count of all the responses where the actual response is negative but the model predicted as positive, in other words, a <span class="strong"><strong>FALSE ALARM</strong></span></li><li class="listitem">The bottom-left count is called <span class="strong"><strong>false negative</strong></span> (<span class="strong"><strong>fn</strong></span>), which indicates the count of all the responses where the actual response is positive but the model predicted as negative; in general, we call it <span class="strong"><strong>A MISS</strong></span></li><li class="listitem">The bottom-right count is called <span class="strong"><strong>true negative</strong></span> (<span class="strong"><strong>tn</strong></span>), which indicates the count of all the responses where the actual response is negative and the model predicted negative.</li></ul></div><p>Take a look at the following table:</p><div class="mediaobject"><img src="../Images/image00318.jpeg" alt="Precision and recall"/></div><p style="clear:both; height: 1em;"> </p><p>Using the preceding information, we shall compute precision-recall metrics, as follows:</p><div class="mediaobject"><img src="../Images/image00319.jpeg" alt="Precision and recall"/></div><p style="clear:both; height: 1em;"> </p><p><span class="strong"><strong>Precision</strong></span> is calculated by true-positive divided by the sum of true-positive and false-positive. Precision indicates what per cent of the total recommendations are useful.</p><p><span class="strong"><strong>Recall</strong></span> is calculated by true-positive divided by the sum of true positive and false negative. Recall indicates of the total recommendations what percentage of recommendations is useful.</p><p>Precision and recall are both required while evaluating a recommendation model. Sometimes we would be interested in generating good recommendations with high precision, and other times we would be interested in generating recommendations with high recall. But the problem with these two is that if we focus on improving one metric, the other metric suffers. We need to choose an optimal trade-off between precision and recall based on our requirements. The implementations for precision-recall is covered in <a class="link" title="Chapter 5. Building Collaborative Filtering Recommendation Engines" href="part0037.xhtml#aid-1394Q1">Chapter 5</a>, <span class="emphasis"><em>Building Collaborative Filtering Recommendation Engines</em></span>.</p></div></div></div>
<div class="section" title="Summary" id="aid-12AK81"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec29"/>Summary</h1></div></div></div><p>In this chapter, we saw various data-mining steps that are popularly used in building recommendation engines. We started by learning similarity calculations, such as Euclidean distance measures, followed by mathematical models, such as matrix factorization techniques. Then we covered supervised and unsupervised machine learning techniques, such as regression, classification, clustering techniques, and dimensionality reduction techniques. In the last sections of the chapter, we covered how information retrieval methods from natural language processing, such as vector space models, can be used in recommendation engines. We concluded the chapter by covering popular evaluating metrics. Till now we have covered theoretical background required for building recommendation engines. In the next chapter, we will learn building collaborative filtering recommendation engines in R and Python.</p></div></body></html>