- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Time-Series Forecasting in Your Data Warehouse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we discussed how you can use Amazon Redshift **Machine
    Learning** (**ML**) to easily create, train, and apply ML models using familiar
    SQL commands. We talked about how we can use supervised learning algorithms for
    classification or regression problems to predict a certain outcome. In this chapter,
    we will talk about how you can use your data in Amazon Redshift to forecast a
    certain future event using Amazon Forecast.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will introduce you to time-series forecasting on Amazon Redshift
    using Amazon Forecast ([https://aws.amazon.com/forecast/](https://aws.amazon.com/forecast/)),
    a fully managed time-series forecasting service, using SQL, and without moving
    your data or learning new skills. We will guide you through the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting and time-series data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is Amazon Forecast?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration and security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating forecasting models using Redshift ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter requires a web browser and access to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An AWS account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Redshift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Redshift query editor v2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can find the code used in this chapter here: [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter12/chapter-12.sql](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter12/chapter-12.sql).'
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting and time-series data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Forecasting is a way of estimating future events, which involves analyzing historical
    data and past patterns to derive a possible outcome in the future. For example,
    based on historical data, a business can predict their sales revenue or identify
    what will happen in the next time period.
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting plays a valuable role in guiding businesses to make informed decisions
    about their operations and priorities. Many organizations rely on data warehouses
    such as Amazon Redshift to perform deep analytics on vast amounts of historical
    and current data, enabling them to drive their business goals and gauge future
    success. Acting as a planning tool, forecasting helps enterprises prepare for
    future uncertainties by leveraging past patterns, with the underlying principle
    that what happened in the past will likely recur in the future. These predictions
    are based on analyzing observations over time within the given timeframe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of how organizations use forecasting:'
  prefs: []
  type: TYPE_NORMAL
- en: Financial planning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supply and demand planning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Timing the launch of new products or services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resource planning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting future events, such as sales and revenue earnings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing management decisions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking at a trend graph helps us predict the trend, but a time-series forecast
    gives us a better estimate of how it may continue. We can also model data that
    doesn’t show any clear pattern or trend over time. When there is a pattern, we
    can look at the entire history of the data to see how it happened before. If there
    is no pattern, we can rely more on recent data for forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Types of forecasting methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two types of forecasting methods: qualitative and quantitative.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at what qualitative and quantitative methods are, as defined
    at [https://aws.amazon.com/what-is/forecast/](https://aws.amazon.com/what-is/forecast/):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Qualitative forecasting** is subjective and relies on marketing experts’
    opinions to make predictions. You can use these methods when there is not enough
    historical data. Some examples of qualitative forecasting methods are market research
    such as polls and surveys, and the Delphi method to collect informed opinions
    and predict trends.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quantitative forecasting** is objective in nature and is used to predict
    long-term future trends. It uses historical and current data to forecast future
    trends. Some examples of quantitative forecasting methods are *time-series forecasting*,
    *econometric modeling*, and the *indicator approach*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will focus on quantitative forecasting using time series
    for data, also known as time-series forecasting. Now, let’s look into what time-series
    forecasting is.
  prefs: []
  type: TYPE_NORMAL
- en: What is time-series forecasting?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Time-series forecasting** is a data science technique that uses ML to study
    historical data and predict future trends or behavior in time-series data. Time-series
    data is used in many situations, such as weather forecasting, financial studies,
    statistics, resource planning, and econometrics. In the previous chapter, we looked
    into regression models to predict values using cross-sectional data, where your
    input variables are used to determine the relationship between the variables so
    that you can predict the unknown target on sets of data without the target variables.'
  prefs: []
  type: TYPE_NORMAL
- en: This data is unique because it arranges data points by time. Time-series data
    can be plotted on a graph and these graphs are valuable tools for visualizing
    and analyzing the data. In many organizations, data scientists or data analysts
    use these graphs to identify forecasting data features or attributes. Let us look
    into some examples of time-series data characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: Time trending data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In trending data, the observations are captured at equal time intervals. In
    time-series graphs, the *y* axis is always a unit of time, such as quarter, year,
    month, day, hour, minute, or second. In *Figure 12**.1*, we have an example of
    the trend of total subscribers by year:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1 – Trend of total subscribers per year](img/B19071_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – Trend of total subscribers per year
  prefs: []
  type: TYPE_NORMAL
- en: Seasonality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In seasonality observations, we can see periodic fluctuations over time, and
    these fluctuations are predictable because we understand the behavior and the
    cause based on historical patterns. For example, retailers know that sales will
    increase during certain holiday periods. In *Figure 12**.2*, we see an upward
    spike in sales for November and December, which is expected because of the holiday
    season:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2 – Upward spike due to holiday season](img/B19071_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Upward spike due to holiday season
  prefs: []
  type: TYPE_NORMAL
- en: Structural breaks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In structural breaks, we have fluctuations that are less predictable and can
    occur at any point in time. For example, during a recession or geo-political disturbances,
    the economic situation of a country might show structural breaks. In *Figure 12**.3*,
    we can see a visualization of economic growth over time. The dips indicate an
    event that occurred at certain data points; for example, the one in 2009 correlates
    to the mortgage crisis in the US.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – Economic growth over time](img/B19071_12_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – Economic growth over time
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look into how Amazon Redshift ML uses Amazon Forecast to generate
    models using time-series datasets.
  prefs: []
  type: TYPE_NORMAL
- en: What is Amazon Forecast?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Amazon Forecast**, like Amazon Redshift ML, requires no ML experience to
    use. Time-series forecasts are generated using various ML and statistical algorithms
    based on historical data. As a user, you simply send data to Amazon Forecast and
    it will examine the data and automatically identify what is meaningful and produces
    a forecasting model.'
  prefs: []
  type: TYPE_NORMAL
- en: With Amazon Redshift ML, you can leverage Amazon Forecast to create and train
    forecasting models from your time-series data and use these models to generate
    forecasts. For forecasting, we require a target time-series dataset. In target
    time-series forecasting, we predict the future value of a variable using the past
    data or previous values, which is often called univariate time series because
    the data is sequential over equal time increments. Currently, Redshift ML supports
    target time-series datasets with a custom domain. The dataset in your data warehouse
    must contain the frequency or interval at which you capture your data. For example,
    you might record and aggregate the average temperature every hour.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon Forecast automatically trains your model based on an algorithm using
    Auto ML and provides six built-in algorithms (to learn more about the built-in
    algorithms, please check out this resource: [https://docs.aws.amazon.com/forecast/latest/dg/aws-forecast-choosing-recipes.html#forecast-algos](https://docs.aws.amazon.com/forecast/latest/dg/aws-forecast-choosing-recipes.html#forecast-algos)).
    These forecasting models, known as predictors, are created using an optimal combination
    of these algorithms from your time-series data in Amazon Redshift.'
  prefs: []
  type: TYPE_NORMAL
- en: Configuration and security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As Amazon Forecast is a separate fully managed service, you will need to create
    or modify your IAM role to include access permissions for your serverless endpoint
    or Redshift cluster. Additionally, you should configure a trust relationship for
    Amazon Forecast ([forecast.amazonaws.com](http://forecast.amazonaws.com)) in the
    IAM role to enable the necessary permissions.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the **AmazonForecastFullAccess** managed policy, which grants full
    access to Amazon Forecast and all of the supported operations. You can attach
    this policy to your default role but, in your production environments, you must
    follow the principle of least-privilege permissions. You may use more restrictive
    permissions, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Creating forecasting models using Redshift ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Currently, if you have to perform forecasting in your data warehouse, you need
    to export the dataset into external systems and then apply forecasting algorithms
    to create output datasets and then import them back into the data warehouse for
    your presentation layer or further analysis. With Redshift ML’s integration with
    Amazon Forecast, you don’t have to perform all these steps. You can now create
    the forecasting models right on your dataset within your data warehouse.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [*Chapter 5*](B19071_05.xhtml#_idTextAnchor068), we talked about the basic
    `CREATE MODEL` syntax and its constructs. Let’s take a look at the `CREATE MODEL`
    syntax for forecasting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: There are a few things to notice with the `CREATE MODEL` statement for forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: First, forecast models do not create inference functions. The reason for this
    is that when we train a predictor on Amazon Forecast, we specify in the training
    request the number (`HORIZON`) and frequency of predictions (`FREQUENCY`) we want
    to make in the future. Because of this, a trained model has a fixed forecast,
    so there isn’t a physical model to compile and execute. A custom CTAS command
    (which will be discussed later) is used to extract a forecast from the training
    output location in S3 into a table locally in Redshift.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can specify the *optional* objective or optimization metric, which
    is used to optimize the predictor for under-forecasting and over-forecasting.
    Amazon Forecast provides different model accuracy metrics for you to assess the
    strength of your forecasting models, which are listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`AverageWeightedQuantileLoss` – measures the accuracy of a model at a specified
    quantile'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`WAPE` (weighted absolute percentage error) – measures the overall deviation
    of forecasted values from the observed value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RMSE` (root mean square error) – the square root of the average of squared
    errors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MASE` (mean absolute scaled error) – calculated by dividing the average error
    by a scaling factor'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MAPE` (mean absolute percentage error) – takes the absolute value of the percentage
    error between observed and predicted values for each unit of time, then averages
    those values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lastly, it is important to note that `FORECAST` does not support any hyperparameters.
    Instead, any `FORECAST`-specific settings for training will be specified using
    the `SETTINGS` clause. Currently, the supported settings are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`FREQUENCY`: Granularity of predictions in a forecast. Valid values are `Y`
    (year), `M` (month), `W` (week), `D` (day), `H` (hour), and `min` (minute), for
    example, `H` for hourly forecasts or `1min` for forecasts every minute).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`HORIZON`: The number of time steps in the future to forecast (e.g., `24`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: '`FREQUENCY` `H` and `HORIZON` `24` mean you want hourly forecasts for the next
    day.'
  prefs: []
  type: TYPE_NORMAL
- en: '`PERCENTILES` (optional): The forecast types are used to train a predictor.
    Up to five forecast types or percentiles can be specified. These types can be
    quantiles `[0.01 to 0.99]` or `mean`. A forecast at the `0.50` quantile will estimate
    a lower value 50% of the time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s take a look at one use case where we can use the target time-series
    dataset for predicting the target forecast value.
  prefs: []
  type: TYPE_NORMAL
- en: Business problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this use case, let’s take the example of an online retail store to forecast
    the future demand for certain products in the store. This dataset is taken from
    the UCI ML repository and is available here: [https://archive.ics.uci.edu/dataset/352/online+retail](https://archive.ics.uci.edu/dataset/352/online+retail).
    For this exercise, we have modified the data to resemble more of a target time-series
    dataset, containing `item_id`, `date`, and `target_value` fields. The data spans
    a two-year time period starting from December 2018 to November 2020\. The modified
    data contains the item name, date products were sold, and total number of products
    sold.'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset citation
  prefs: []
  type: TYPE_NORMAL
- en: Online Retail. (2015). UCI Machine Learning Repository. [https://doi.org/10.24432/C5BW33](https://doi.org/10.24432/C5BW33).
  prefs: []
  type: TYPE_NORMAL
- en: Uploading and analyzing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After successfully connecting to Redshift as an admin or database developer,
    load data into Amazon Redshift and follow the steps outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to query editor v2, connect to **Serverless** endpoint, and connect
    to the **dev** database:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.4 – Connecting to the dev database](img/B19071_12_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – Connecting to the dev database
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following steps to create the schema and the trade details table
    and load the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following query to examine some sample data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result will be similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5 – Query results](img/B19071_12_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.5 – Query results
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in the preceding figure, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`invoice_date` (date when the item was sold)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`item_id` (name of the product sold)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`quantity` (number of items sold for that product for each day)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using this dataset, we will create a model in Amazon Forecast and predict the
    demand for the future for the given products. The goal is to analyze what a particular
    product’s demand is going to look like in the coming five days. For accuracy and
    validation, we will create the model using the data until October 2020\. Once
    we have the predictor ready, we will then compare the output values with the actual
    values in November 2020 to determine the accuracy of our model. We will also take
    a look at different accuracy metrics, such as the average **weighted quantile
    loss** (**wQL**), WAPE, MAPE, MASE, and RMSE.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s create the model using the `CREATE MODEL` statement we discussed at the
    beginning of the *Creating forecasting models using Redshift* *ML* section.
  prefs: []
  type: TYPE_NORMAL
- en: '`Objective` is set to `AverageWeightedQuantileLoss` (mean of wQL), which is
    the accuracy metric for `optimization_metric`. `Frequency` is set to `D` (Days),
    `Horizon` is set to `5`, and `Percentiles` is set to `0.25`, `0.50`, `0.75`, `0.90`,
    and `mean`.'
  prefs: []
  type: TYPE_NORMAL
- en: If you do not specify the percentiles settings, then Forecast generates the
    predictions on `p10`, `p50`, and `p90` (0.10, 0.50, and 0.90).
  prefs: []
  type: TYPE_NORMAL
- en: Run the following command in query editor v2 to create the model. Note this
    will take approximately 90 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the `SHOW MODEL` command to see whether model training is complete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6 – Result of model training](img/B19071_12_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 – Result of model training
  prefs: []
  type: TYPE_NORMAL
- en: You can also view the status of the predictor using the value of `Amazon Forecast`.
  prefs: []
  type: TYPE_NORMAL
- en: Click on **View dataset groups** and find the dataset group name by pasting
    **redshiftml_****20221224001451333090**.
  prefs: []
  type: TYPE_NORMAL
- en: Click on this dataset group name and verify whether **Target time series data**
    is **Active**, as shown in *Figure 12**.7*.
  prefs: []
  type: TYPE_NORMAL
- en: You can also view the details about your time-series data by clicking **View**
    and seeing the schema, frequency of data registered in your data file, dataset
    import details, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.7 – Verify the status of target time-series data](img/B19071_12_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.7 – Verify the status of target time-series data
  prefs: []
  type: TYPE_NORMAL
- en: 'Once active, you can view the predictor by clicking **View predictors**. The
    **Predictors** dialog box will show the training status, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.8 – Training status in View predictors](img/B19071_12_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.8 – Training status in View predictors
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the `SHOW MODEL` command again to see if model training is complete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.9 – Status of model training completion](img/B19071_12_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.9 – Status of model training completion
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the model training is finished and ready, you can then view the outputs
    by creating a table on your forecast:'
  prefs: []
  type: TYPE_NORMAL
- en: For a retail store, the company needs to ensure that they do not over-forecast
    or under-forecast the predicted quantity required in order to effectively manage
    inventory and enhance profits. As mentioned earlier, Redshift ML with Amazon Forecast
    provides different optimization metrics that can be used in order to measure the
    accuracy of a model specified at different quantiles. For this use case, we have
    created the model for `0.25`, `0.50`, `0.75`, `0.90`, and `mean`. If the emphasis
    is on over-forecasting, then for a retailer, choosing a higher quantile (`0.90`)
    captures the spike in demand in a much better way for a high-demand item or product.
    This suggests that there is a 90% probability of success for the product to meet
    the forecasted demand. Now, let’s see how to get our forecasted results.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a table with output results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After the model has finished training and is ready, we now create a table in
    our schema to hold all the forecast results using a simple CTAS command, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In this command, `forecast()` is a pseudo table function that takes the name
    of your model as an input parameter. The data is then pulled from the S3 bucket
    location where your model results are stored.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at the output from the preceding table by running the following
    SQL command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Looking at *Figure 12**.10*, you can see that for each day, Forecast has generated
    the output predictions for each distribution point or quantile that we provided
    and the mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.10 – Output of the table](img/B19071_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.10 – Output of the table
  prefs: []
  type: TYPE_NORMAL
- en: For products in high demand, the retailer can choose a higher quantile, such
    as `0.90` (`p90`), which better captures spikes in demand, rather than forecasting
    at the mean or `0.50` quantile.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s take a look at the data of a popular product: **JUMBO BAG** **RED
    RETROSPOT**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following SQL query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.11 – Forecast data](img/B19071_12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.11 – Forecast data
  prefs: []
  type: TYPE_NORMAL
- en: 'To visualize the data, select `invoice_date` attribute, and for the *y* axis,
    choose `p90_forecast`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.12 – Forecast chart](img/B19071_12_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.12 – Forecast chart
  prefs: []
  type: TYPE_NORMAL
- en: If we closely examine the preceding data in *Figure 12**.11*, we can observe
    that Line 1 was under-forecasted, while Lines 2 and 3 were very close to the actual
    values, and Line 4 was just slightly over-forecasted. In order to test the forecasting,
    you can further perform tests with different sets of data or even on different
    quantiles. Additionally, a retailer can use this data for different products,
    such as products with low demand, and make use of other quantiles, such as `p50`
    or `mean`.
  prefs: []
  type: TYPE_NORMAL
- en: The wQL is used to calculate the `AverageWeightedQuantileLoss` metric. The wQL
    can be used to manage the costs of over- and under-forecasting. These metrics
    will be available to you in the Amazon Forecast console for your predictor. Generally,
    to calculate the wQL at `0.90`, sum the values of the positive values in above
    `p90` error field and multiply them by a smaller weight of `0.10`, and sum the
    absolute values of the negative values in `p90` error and multiply them by `0.90`.
  prefs: []
  type: TYPE_NORMAL
- en: To align with your business outcomes, you can create the forecasting models
    at different quantiles (**Percentiles**) in your Amazon Redshift data warehouse.
    This gives you the flexibility to measure your business goals and keep the impacts
    on cost on the lower side.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed how you can use Redshift ML to generate forecasting
    models using Amazon Forecast by creating the model for Forecast `Model_Type`.
    You learned about what forecasting is and how time-series data is used to generate
    different models for different quantiles. We also looked at different quantiles
    and talked briefly about different optimization metrics.
  prefs: []
  type: TYPE_NORMAL
- en: We showed how forecast models can be used to predict the future quantity sale
    for a retailer use case and how they can be used to balance the effect of over-forecasting
    and under-forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at operational and optimization considerations.
  prefs: []
  type: TYPE_NORMAL
