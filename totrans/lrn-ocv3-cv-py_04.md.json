["```py\nimport numpy\n```", "```py\nimport numpy\nimport utils\n```", "```py\nimport depth\n```", "```py\n# Devices.CAP_OPENNI = 900 # OpenNI (for Microsoft Kinect)CAP_OPENNI_ASUS = 910 # OpenNI (for Asus Xtion)\n# Channels of an OpenNI-compatible depth generator.CAP_OPENNI_DEPTH_MAP = 0 # Depth values in mm (16UC1)CAP_OPENNI_POINT_CLOUD_MAP = 1 # XYZ in meters (32FC3)CAP_OPENNI_DISPARITY_MAP = 2 # Disparity in pixels (8UC1)CAP_OPENNI_DISPARITY_MAP_32F = 3 # Disparity in pixels (32FC1)CAP_OPENNI_VALID_DEPTH_MASK = 4 # 8UC1\n# Channels of an OpenNI-compatible RGB image generator.CAP_OPENNI_BGR_IMAGE = 5CAP_OPENNI_GRAY_IMAGE = 6\n```", "```py\ndef createMedianMask(disparityMap, validDepthMask, rect = None):\n    \"\"\"Return a mask selecting the median layer, plus shadows.\"\"\"\n    if rect is not None:\n        x, y, w, h = rect\n        disparityMap = disparityMap[y:y+h, x:x+w]\n        validDepthMask = validDepthMask[y:y+h, x:x+w]\n    median = numpy.median(disparityMap)\n    return numpy.where((validDepthMask == 0) | \\\n                       (abs(disparityMap - median) < 12),\n                       1.0, 0.0)\n```", "```py\ndef copyRect(src, dst, srcRect, dstRect, mask = None,\n             interpolation = cv2.INTER_LINEAR):\n    \"\"\"Copy part of the source to part of the destination.\"\"\"\n\n    x0, y0, w0, h0 = srcRect\n    x1, y1, w1, h1 = dstRect\n\n    # Resize the contents of the source sub-rectangle.\n    # Put the result in the destination sub-rectangle.\n    if mask is None:\n        dst[y1:y1+h1, x1:x1+w1] = \\\n            cv2.resize(src[y0:y0+h0, x0:x0+w0], (w1, h1),\n                       interpolation = interpolation)\n    else:\n        if not utils.isGray(src):\n            # Convert the mask to 3 channels, like the image.\n            mask = mask.repeat(3).reshape(h0, w0, 3)\n        # Perform the copy, with the mask applied.\n        dst[y1:y1+h1, x1:x1+w1] = \\\n            numpy.where(cv2.resize(mask, (w1, h1),\n                                   interpolation = \\\n                                   cv2.INTER_NEAREST),\n                        cv2.resize(src[y0:y0+h0, x0:x0+w0], (w1, h1),\n                                   interpolation = interpolation),\n                        dst[y1:y1+h1, x1:x1+w1])\n```", "```py\ndef swapRects(src, dst, rects, masks = None,\n              interpolation = cv2.INTER_LINEAR):\n    \"\"\"Copy the source with two or more sub-rectangles swapped.\"\"\"\n\n    if dst is not src:\n        dst[:] = src\n\n    numRects = len(rects)\n    if numRects < 2:\n        return\n\n    if masks is None:\n        masks = [None] * numRects\n\n    # Copy the contents of the last rectangle into temporary storage.\n    x, y, w, h = rects[numRects - 1]\n    temp = src[y:y+h, x:x+w].copy()\n\n    # Copy the contents of each rectangle into the next.\n    i = numRects - 2\n    while i >= 0:\n        copyRect(src, dst, rects[i], rects[i+1], masks[i],\n                 interpolation)\n        i -= 1\n\n    # Copy the temporarily stored content into the first rectangle.\n    copyRect(temp, dst, (0, 0, w, h), rects[0], masks[numRects - 1],\n             interpolation)\n```", "```py\nimport numpy as np\nimport cv2\n\ndef update(val = 0):\n    # disparity range is tuned for 'aloe' image pair\n    stereo.setBlockSize(cv2.getTrackbarPos('window_size', 'disparity'))\n    stereo.setUniquenessRatio(cv2.getTrackbarPos('uniquenessRatio', 'disparity'))\n    stereo.setSpeckleWindowSize(cv2.getTrackbarPos('speckleWindowSize', 'disparity'))\n    stereo.setSpeckleRange(cv2.getTrackbarPos('speckleRange', 'disparity'))\n    stereo.setDisp12MaxDiff(cv2.getTrackbarPos('disp12MaxDiff', 'disparity'))\n\n    print 'computing disparity...'\n    disp = stereo.compute(imgL, imgR).astype(np.float32) / 16.0\n\n    cv2.imshow('left', imgL)\n    cv2.imshow('disparity', (disp-min_disp)/num_disp)\n\nif __name__ == \"__main__\":\n    window_size = 5\n    min_disp = 16\n    num_disp = 192-min_disp\n    blockSize = window_size\n    uniquenessRatio = 1\n    speckleRange = 3\n    speckleWindowSize = 3\n    disp12MaxDiff = 200\n    P1 = 600\n    P2 = 2400\n    imgL = cv2.imread('images/color1_small.jpg')\n    imgR = cv2.imread('images/color2_small.jpg')    \n    cv2.namedWindow('disparity')\n    cv2.createTrackbar('speckleRange', 'disparity', speckleRange, 50, update)    \n    cv2.createTrackbar('window_size', 'disparity', window_size, 21, update)\n    cv2.createTrackbar('speckleWindowSize', 'disparity', speckleWindowSize, 200, update)\n    cv2.createTrackbar('uniquenessRatio', 'disparity', uniquenessRatio, 50, update)\n    cv2.createTrackbar('disp12MaxDiff', 'disparity', disp12MaxDiff, 250, update)\n    stereo = cv2.StereoSGBM_create(\n        minDisparity = min_disp,\n        numDisparities = num_disp,\n        blockSize = window_size,\n        uniquenessRatio = uniquenessRatio,\n        speckleRange = speckleRange,\n        speckleWindowSize = speckleWindowSize,\n        disp12MaxDiff = disp12MaxDiff,\n        P1 = P1,\n        P2 = P2\n    )\n    update()\n    cv2.waitKey()\n```", "```py\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('images/statue_small.jpg')\nmask = np.zeros(img.shape[:2],np.uint8)\n\nbgdModel = np.zeros((1,65),np.float64)\nfgdModel = np.zeros((1,65),np.float64)\n\nrect = (100,50,421,378)\ncv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n\nmask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\nimg = img*mask2[:,:,np.newaxis]\n\nplt.subplot(121), plt.imshow(img)\nplt.title(\"grabcut\"), plt.xticks([]), plt.yticks([])\nplt.subplot(122), plt.imshow(cv2.cvtColor(cv2.imread('images/statue_small.jpg'), cv2.COLOR_BGR2RGB))\nplt.title(\"original\"), plt.xticks([]), plt.yticks([])\nplt.show()\n```", "```py\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('images/statue_small.jpg')\nmask = np.zeros(img.shape[:2],np.uint8)\n```", "```py\nbgdModel = np.zeros((1,65),np.float64)\nfgdModel = np.zeros((1,65),np.float64)\n```", "```py\nrect = (100,50,421,378)\n```", "```py\ncv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n```", "```py\nmask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\nimg = img*mask2[:,:,np.newaxis]\n```", "```py\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\nimg = cv2.imread('images/basil.jpg')\ngray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n```", "```py\nret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n```", "```py\nkernel = np.ones((3,3),np.uint8)\nopening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n```", "```py\nsure_bg = cv2.dilate(opening,kernel,iterations=3)\n```", "```py\ndist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\nret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n```", "```py\nsure_fg = np.uint8(sure_fg)\nunknown = cv2.subtract(sure_bg,sure_fg)\n```", "```py\nret, markers = cv2.connectedComponents(sure_fg)\n```", "```py\nmarkers = markers+1\nmarkers[unknown==255] = 0\n```", "```py\nmarkers = cv2.watershed(img,markers)\nimg[markers == -1] = [255,0,0]\nplt.imshow(img)\nplt.show()\n```"]