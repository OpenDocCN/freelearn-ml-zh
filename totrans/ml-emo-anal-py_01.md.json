["```py\nres = train_test_split(data, labels,    train_size=0.8,\n    test_size=0.2,\n    random_state=42,\n    stratify=labels)\n```", "```py\n    pip install pandas\n    ```", "```py\n    pip install numpy\n    ```", "```py\n    pip install scipy\n    ```", "```py\npip install scikit-learn\n```", "```py\n    pip install tensorflow\n    ```", "```py\n    pip install matplotlib\n    ```", "```py\n    pip install seaborn\n    ```", "```py\nimport sklearnimport pandas as pd\n```", "```py\ndf = pd.read_csv(\"c:\\iris.csv\")\n```", "```py\ndf = pd.read_csv(\"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\")\n```", "```py\nfrom sklearn import datasetsiris = datasets.load_iris()\ndf = iris.data\n```", "```py\ndf.describe()\n```", "```py\nsepal.length sepal.width petal.length petal.widthcount 150.000000 150.000000 150.000000 150.000000\nmean 5.843333 3.057333 3.758000 1.199333\nstd 0.828066 0.435866 1.765298 0.762238\nmin 4.300000 2.000000 1.000000 0.100000\n25% 5.100000 2.800000 1.600000 0.300000\n50% 5.800000 3.000000 4.350000 1.300000\n75% 6.400000 3.300000 5.100000 1.800000\nmax 7.900000 4.400000 6.900000 2.500000\n```", "```py\n    df.head(5)\n    ```", "```py\n    df.tail(5)\n    ```", "```py\n    df.columns\n    ```", "```py\n    df.shape\n    ```", "```py\ndf['variety'].value_counts()\n```", "```py\nSetosa 50Versicolor 50\nVirginica 50\nName: variety, dtype: int64\n```", "```py\nimport matplotlib.pyplot as pltattributes = df[['sepal.length', 'sepal.width',\n    'petal.length', 'petal.width']]\nattributes.boxplot()\nplt.show()\n```", "```py\nimport seaborn as snssns.heatmap(iris.corr(), annot=True)\nplt.show()\n```", "```py\ndata = df.iloc[:, 0:4]labels = df.iloc[:, 4]\n```", "```py\nfrom sklearn.model_selection import train_test_splitX_train,X_test,y_train,y_test = train_test_split(data,\n    labels, test_size=0.2)\n```", "```py\nfrom sklearn.preprocessing import StandardScalerfrom sklearn.model_selection import cross_val_score\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n```", "```py\nfrom sklearn.linear_model import LogisticRegressionlr = LogisticRegression()\nlr.fit(X_train, y_train)\nscore = lr.score(X_train, y_train)\nprint(f\"Training data accuracy {score}\")\nscore = lr.score(X_test, y_test)\nprint(f\"Testing data accuracy {score}\")\nTraining data accuracy 0.9666666666666667\nTesting data accuracy 0.9666666666666667\n```", "```py\nfrom sklearn.svm import SVCsvm = SVC(random_state=0, gamma='auto', C=1.0)\nsvm.fit(X_train, y_train)\nscore = svm.score(X_train, y_train)\nprint(f\"Training data accuracy {score}\")\nscore = svm.score(X_test, y_test)\nprint(f\"Testing data accuracy {score}\")\ndata accuracy 0.9666666666666667\nTesting data accuracy 0.9666666666666667\n```", "```py\nfrom sklearn.neighbors import KNeighborsClassifierknn = KNeighborsClassifier(n_neighbors = 5)\nknn.fit(X_train,y_train)\nscore = knn.score(X_train, y_train)\nprint(f\"Training data accuracy {score}\")\nscore = knn.score(X_test, y_test)\nprint(f\"Testing data accuracy {score}\")\nTraining data accuracy 0.9583333333333334\nTesting data accuracy 0.9333333333333333\n```", "```py\nfrom sklearn import treedt = tree.DecisionTreeClassifier()\ndt.fit(X_train, y_train)\nscore = dt.score(X_train, y_train)\nprint(f\"Training data accuracy {score}\")\nscore = dt.score(X_test, y_test)\nprint(f\"Testing data accuracy {score}\")\nTraining data accuracy 1.0\nTesting data accuracy 0.9333333333333333\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifierrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nscore = rf.score(X_train, y_train)\nprint(f\"Training data accuracy {score}\")\nscore = rf.score(X_test, y_test)\nprint(f\"Testing data accuracy {score}\")\nTraining data accuracy 1.0\nTesting data accuracy 0.9666666666666667\n```", "```py\ndf_predict = pd.DataFrame([[5.9, 3.0, 5.1, 1.8]],    columns = ['sepal.length', 'sepal.width',\n    'petal.length', 'petal.width'])\n```", "```py\nprint (dt.predict(df_predict))['Virginica']\n```", "```py\nimport pandas as pdfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nspam = pd.read_csv(\"spam.csv\", encoding_errors=\"ignore\")\nlabels = spam[\"v1\"]\ndata = spam[\"v2\"]\nX_train,X_test,y_train,y_test = train_test_split(data,\n    labels, test_size = 0.2)\n```", "```py\ncount_vectorizer = CountVectorizer()X_train_features = count_vectorizer.fit_transform(X_train)\n```", "```py\nknn = KNeighborsClassifier(n_neighbors = 5)\n```", "```py\nknn.fit(X_train_features, y_train)\n```", "```py\nX_test_features = count_vectorizer.transform(X_test)score = knn.score(X_test_features, y_test)\nprint(f\"Training data accuracy {score}\")\nTraining data accuracy 0.9255605381165919\n```"]