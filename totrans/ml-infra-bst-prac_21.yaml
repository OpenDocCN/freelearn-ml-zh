- en: '17'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '17'
- en: Summary and Where to Go Next
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要及下一步行动
- en: This is the last chapter of this book. We’ve learned a lot – starting with understanding
    the differences between traditional and machine learning-based software. We’ve
    learned how to handle data and how to work with algorithms. We’ve also looked
    at how to deploy models and how to work ethically with machine learning. In this
    chapter, we’ll summarize the best practices and try to get a glimpse of future
    developments in the area of machine learning overlapped with software engineering.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本书的最后一章。我们学到了很多——从理解传统软件和基于机器学习的软件之间的区别开始。我们学习了如何处理数据，如何与算法合作。我们还探讨了如何部署模型，以及如何与机器学习进行道德合作。在本章中，我们将总结最佳实践，并试图一窥机器学习与软件工程交叉领域的未来发展趋势。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: To know where we are going, we need to know where we’ve been
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要知道我们将走向何方，我们需要知道我们曾经在哪里
- en: Best practices
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳实践
- en: Current developments
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前的发展
- en: My view on the future
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我对未来看法
- en: "To know where we’re going, we need to know where \Lwe’ve been"
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要知道我们将走向何方，我们需要知道我们曾经在哪里
- en: 'My journey with computers started in the early 1990s, with Atari 800XL. Once
    I got my hands on that computer, I was amazed by the sheer fact that it could
    do what I told it to do. My first program was, of course, a program in BASIC:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我的计算机之旅始于20世纪90年代初，那时我拥有Atari 800XL。一旦我接触到这台电脑，我就被它能够执行我所指示的事情的事实所震惊。我的第一个程序当然是BASIC语言编写的程序：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It’s neither well-formed nor a very useful program, but that was all I could
    do at the time. This first program shaped my entire career as it sparked my interest
    in software development. Later on, during my professional career, I realized that
    professional software engineering is much more than just writing source code and
    compiling it. The programs need to be well-formed, well-documented, well-designed,
    and well-tested (among many other things). This observation, in turn, shaped my
    view on software engineering as a discipline that can turn homebrewed software
    into a piece of art that can be used over long periods if well maintained. That
    was in the early 2000s. Around 2015, I saw a potential in machine learning that
    also sparked my interest. The first project that I took part in was done by a
    colleague of mine who showed me how a random forest classifier can interpret programming
    language code and make inferences about defects. Fast forward to today, we have
    transformers, diffusers, autoencoders, and hybrid networks that can do amazing
    things with data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这既不是一个结构良好的程序，也不是一个非常有用的程序，但那是我当时能做的所有事情。这个第一个程序塑造了我整个职业生涯，因为它激发了我对软件开发的兴趣。后来，在我的职业生涯中，我意识到专业的软件工程远不止是编写源代码和编译它。程序需要结构良好、文档齐全、设计合理、测试充分（以及其他许多事情）。这个观察结果反过来又塑造了我对软件工程作为一门学科的见解，它可以将自制的软件变成一件艺术品，如果维护得当，可以在很长时间内使用。那是在2000年代初。大约在2015年，我看到了机器学习的潜力，这也激发了我的兴趣。我参与的第一个项目是由我的一个同事完成的，他向我展示了如何使用随机森林分类器来解释编程语言代码并推断出缺陷。快进到今天，我们有变压器、扩散器、自动编码器和混合网络，它们可以用数据做惊人的事情。
- en: However, we need to move from AI development to AI engineering, as we did from
    software development to software engineering. That brings us to this book, where
    I showed over 70 best practices in AI engineering. This book has taken us from
    the basic concepts of machine learning and AI in *Part I*, through handling data
    in *Part II* to algorithms and models in *Part III*. We also explored the ethical
    and legal aspects of designing, using, and deploying machine learning systems
    in *Part IV*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们需要从人工智能开发转向人工智能工程，就像我们从软件开发转向软件工程一样。这把我们带到了这本书，我在书中展示了超过70个人工智能工程的最佳实践。这本书带领我们从机器学习和人工智能的基本概念（第一部分），通过处理数据（第二部分）到算法和模型（第三部分）。我们还探讨了设计、使用和部署机器学习系统的伦理和法律方面（第四部分）。
- en: Best practices
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最佳实践
- en: The first part of this book contains significantly more best practices, which
    is because these best practices relate to engineering software, designing it,
    and making crucial decisions about machine learning – for example, the first best
    practice tells us when to use (and not to use) machine learning.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的第一部分包含了许多最佳实践，这是因为这些最佳实践与软件工程、设计以及关于机器学习的关键决策有关——例如，第一个最佳实践告诉我们何时使用（以及何时不使用）机器学习。
- en: As this part of this book was about the *machine learning landscape in software
    engineering*, we’ll discuss different types of models and data and show how they
    come together.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这本书的这一部分是关于软件工程中的*机器学习景观*，我们将讨论不同类型的模型和数据，并展示它们是如何结合在一起的。
- en: 'The list of best practices from the first part of this book is presented in
    *Table 17.1*:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本书第一部分的最佳实践列表在*表17.1*中呈现：
- en: '| **ID** | **Best Practice** |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| **ID** | **最佳实践** |'
- en: '| --- | --- |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | Use machine learning algorithms when your problem is focused on data,
    not on the algorithm. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 当你的问题关注数据而不是算法时，使用机器学习算法。|'
- en: '| 2 | Before you start developing a machine learning system, do due diligence
    and identify the right group of algorithms to use. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 在开始开发机器学习系统之前，进行尽职调查，并确定要使用的正确算法组。|'
- en: '| 3 | If your software is safety-critical, make sure that you can design mechanisms
    to prevent hazards caused by the probabilistic nature of machine learning. |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 如果你的软件是安全关键的，确保你可以设计机制来防止由机器学习的概率性质引起的安全隐患。|'
- en: '| 4 | Test the machine learning software as an addition to the typical train-validation-evaluation
    process of machine learning model development. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 将机器学习软件作为机器学习模型开发典型训练-验证-评估流程的补充进行测试。|'
- en: '| 5 | When designing machine learning software, focus on your data and the
    problem to solve first and on the algorithm second. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 在设计机器学习软件时，首先关注你的数据和要解决的问题，其次才是算法。|'
- en: '| 6 | Use data imputation only when you know which properties of data you need
    to strengthen. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 只有在你知道需要加强哪些数据属性时，才使用数据插补。|'
- en: '| 7 | Once you have explored the problem to solve and understood the data available,
    decide whether you want to use supervised, self-supervised, unsupervised, or reinforcement
    learning algorithms. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 一旦你探索了要解决的问题并理解了可用的数据，决定你是否想使用监督学习、自监督学习、无监督学习或强化学习算法。|'
- en: '| 8 | Choose the data validation attributes that are the most relevant for
    your system. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 选择对你系统最相关的数据验证属性。|'
- en: '| 9 | Use GridSearch and other algorithms after you have explored the parameter
    search space manually. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 在手动探索参数搜索空间之后，使用GridSearch和其他算法。|'
- en: '| 10 | Always include monitoring mechanisms in your machine learning systems.
    |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 总是在你的机器学习系统中包含监控机制。|'
- en: '| 11 | Choose the right database for your data – look at this from the perspective
    of the data, not the system. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 根据数据的视角选择正确的数据库，而不是从系统的角度考虑。|'
- en: '| 12 | Use cloud infrastructure if you can as it saves resources and reduces
    the need for specialized competence. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 如果可能，使用云基础设施，因为它可以节省资源并减少对专业知识的需要。|'
- en: '| 13 | Decide on your production environment early and align your process with
    that environment. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 早期决定你的生产环境，并将你的流程与该环境对齐。|'
- en: '| 14 | Design the entire software system based on the task that you need to
    solve, not only the machine learning model. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 根据你需要解决的问题来设计整个软件系统，而不仅仅是机器学习模型。|'
- en: '| 15 | Downsize the size of your images and use as few colors as possible to
    reduce the computational complexity of your system. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 尽可能减小图像的大小，并尽可能少地使用颜色，以减少系统的计算复杂度。|'
- en: '| 16 | Use a reference dataset for benchmarking whenever you can. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 16 | 在可能的情况下，使用参考数据集进行基准测试。|'
- en: '| 17 | Whenever possible, use models that are already pre-trained for specific
    tasks. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 17 | 在可能的情况下，使用为特定任务预训练的模型。|'
- en: '| 18 | Visualize your raw data to get an understanding of patterns in your
    data. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 18 | 可视化你的原始数据，以了解你的数据中的模式。|'
- en: '| 19 | Visualize your data when it has been turned into features to monitor
    if the same patterns are still observable. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 19 | 当数据被转换为特征以进行监控时，可视化你的数据，以检查是否仍然可以观察到相同的模式。|'
- en: '| 20 | Only use the necessary information as input to machine learning models.
    Too much information may require additional processing and pose unnecessary requirements
    on the system. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 只使用必要的输入信息作为机器学习模型的输入。过多的信息可能需要额外的处理，并对系统提出不必要的性能要求。|'
- en: '| 21 | Use bounding boxes in the data when the task requires detecting and
    tracking objects. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 21 | 当任务需要检测和跟踪对象时，在数据中使用边界框。|'
- en: '| 22 | Use semantic maps when you need to get the context of the image or you
    need details of a specific area. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 22 | 当你需要获取图像的上下文或需要特定区域的详细信息时，请使用语义图。|'
- en: '| 23 | Use a pre-trained embedding model such as GPT-3 or an existing BERT
    model to vectorize your text. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 23 | 使用预训练的嵌入模型，如GPT-3或现有的BERT模型，来向量化你的文本。|'
- en: '| 24 | Use role labels when designing software that needs to provide grounded
    decisions. |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 24 | 在设计需要提供基于事实的决策的软件时，请使用角色标签。|'
- en: '| 25 | Identify the origin of the data used in your software and create your
    data processing pipeline accordingly. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 确定您软件中使用的数据的来源，并据此创建您的数据处理管道。|'
- en: '| 26 | Extract as much data as you need and store it locally to reduce the
    disturbances for the software engineers who will use the tool for their work.
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 26 | 提取您所需的所有数据，并将其存储在本地以减少使用该工具进行工作的软件工程师的干扰。|'
- en: '| 27 | When accessing data from public repositories, please check the licenses
    and ensure you acknowledge the contribution of the community that created the
    analyzed code. |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 27 | 当从公共存储库访问数据时，请检查许可证，并确保您承认创建了分析代码的社区的贡献。|'
- en: '| 28 | The best strategy to reduce the impact of noise on machine learning
    classifiers is to remove the noisy data points. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 28 | 减少噪声对机器学习分类器影响的最佳策略是移除噪声数据点。|'
- en: '| 29 | Balance the number of features with the number of data points. Having
    more features is not always better. |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 29 | 平衡特征数量与数据点数量。特征数量多并不总是更好。|'
- en: '| 30 | Use `KNNImputer` for data for classification tasks and `IterativeImputer`
    for data for regression tasks. |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 对于分类任务的数据，使用`KNNImputer`；对于回归任务的数据，使用`IterativeImputer`。|'
- en: '| 31 | Use the random forest classifier to reduce the attribute noise as it
    provides very good performance. |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 31 | 使用随机森林分类器来减少属性噪声，因为它提供了非常好的性能。|'
- en: '| 32 | Retain the original distribution of the data as much as possible as
    it reflects the empirical observations. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 32 | 尽可能保留数据的原始分布，因为它反映了经验观察。|'
- en: '| 33 | In large-scale software systems, if possible, rely on the machine learning
    models to handle noise in the data. |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 33 | 在大规模软件系统中，如果可能，依靠机器学习模型来处理数据中的噪声。|'
- en: 'Table 17.1: Best practices in the first part of this book'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 表17.1：本书第一部分的最佳实践
- en: The second part of this book was about *data acquisition and management*. We
    focused on machine learning from the perspective of the data – how to get orientation
    in the data, what kind of data exists, and how to process it.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本书第二部分讲述了*数据获取与管理*。我们专注于从数据的角度进行机器学习——如何在数据中找到方向，存在哪些类型的数据，以及如何处理它们。
- en: 'Therefore, the following best practices are related to data:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，以下最佳实践与数据相关：
- en: '| **ID** | **Best Practice** |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| **ID** | **最佳实践** |'
- en: '| --- | --- |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 34 | When working with numerical data, visualize it first, starting with
    the summary views of the data. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 34 | 当处理数值数据时，首先可视化它，从数据的汇总视图开始。|'
- en: '| 35 | When visualizing data on the aggregate level, focus on the strength
    of relationships and connections between the values. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 35 | 在可视化数据聚合层面时，关注值之间的关系和连接的强度。|'
- en: '| 36 | Diving deeper into individual analyses should be guided by the machine
    learning task at hand. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 36 | 深入分析个体分析应受当前机器学习任务的指导。|'
- en: '| 37 | When visualizing the metadata for images, make sure you visualize the
    images themselves. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 37 | 当可视化图像的元数据时，确保您可视化图像本身。|'
- en: '| 38 | Summary statistics for text data help with performing a sanity check
    of the data. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 38 | 文本数据的汇总统计有助于对数据进行合理性检查。|'
- en: '| 39 | Use feature engineering techniques if the data is complex but the task
    is simple – for example, creating a classification model. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 39 | 如果数据复杂但任务简单，请使用特征工程技术——例如，创建一个分类模型。|'
- en: '| 40 | Use PCA if the data is somehow linear and on similar scales. |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 40 | 如果数据在某种程度上是线性的并且具有相似的尺度，请使用PCA。|'
- en: '| 41 | Use t-SNE if you do not know the properties of the data and the dataset
    is large (>1,000 data points). |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 41 | 如果您不知道数据的属性并且数据集很大（>1,000个数据点），请使用t-SNE。|'
- en: '| 42 | Use autoencoders for numerical data when the dataset is really large
    since autoencoders are complex and require a lot of data for training. |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 42 | 当数据集非常大时（因为自动编码器复杂且需要大量数据进行训练），使用自动编码器对数值数据进行处理。|'
- en: '| 43 | Start with a small number of neurons in the bottleneck – usually one
    third of the number of columns. If the autoencoder does not learn, increase the
    number gradually. |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 43 | 在瓶颈处开始使用少量神经元——通常是列数的三分之一。如果自动编码器没有学习，则逐步增加数量。|'
- en: '| 44 | Use tokenizers for large language models such as BERT and word embeddings
    for simple tasks. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 44 | 对于BERT等大型语言模型，使用标记化器；对于简单任务，使用词嵌入。|'
- en: '| 45 | Use BoW tokenizers together with dictionaries when your task requires
    a pre-defined set of words. |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 45 | 当您的任务需要预定义的单词集时，请使用BoW分词器与字典一起使用。 |'
- en: '| 46 | Use the WordPiece tokenizer as your first choice. |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 46 | 将WordPiece分词器作为首选。 |'
- en: '| 47 | Use BPE when you’re working with large language models and large corpora
    of text. |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 47 | 当您处理大型语言模型和大型文本语料库时，请使用BPE。 |'
- en: '| 48 | Use the sentence piece tokenizer when whitespaces are important. |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 48 | 当空白符很重要时，请使用sentence piece分词器。 |'
- en: '| 49 | Use word embeddings (FastText) as a go-to model for designing classifiers
    or text. |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 49 | 使用词嵌入（FastText）作为设计分类器或文本的默认模型。 |'
- en: 'Table 17.2: Best practices in the second part of this book'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 表17.2：本书第二部分的最佳实践
- en: Once we worked with the data, we focused on algorithms, which comprise the other
    part of machine learning.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们处理了数据，我们就专注于算法，这是机器学习的另一部分。
- en: In the third part of this book, *Designing and Developing Machine Learning Systems*,
    our focus was on the software. We started by exploring which algorithms exist
    and how to choose the best ones. Starting from AutoML and working with Hugging
    Face provided us with a good platform to learn how to train and deploy machine
    learning systems.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第三部分《设计和开发机器学习系统》中，我们的重点是软件。我们首先探讨了哪些算法存在以及如何选择最佳算法。从AutoML开始，并与Hugging
    Face合作，为我们提供了一个良好的平台，以学习如何训练和部署机器学习系统。
- en: 'Here are its best practices:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是它的最佳实践：
- en: '| **ID** | **Best Practice** |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| **ID** | **最佳实践** |'
- en: '| --- | --- |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 50 | Use AutoML as the initial choice when training the classical machine
    learning models. |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 在训练经典机器学习模型时，将AutoML作为首选。 |'
- en: '| 51 | Use pre-trained models from Hugging Face or TensorFlow Hub to start
    with. |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 51 | 从Hugging Face或TensorFlow Hub开始使用预训练模型。 |'
- en: '| 52 | Work with the pre-trained networks to identify their limitations and
    then train the network on your dataset. |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 52 | 与预训练网络一起工作，以确定它们的局限性，然后在您的数据集上训练网络。 |'
- en: '| 53 | Instead of looking for more complex models, create a smarter pipeline.
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 53 | 而不是寻找更复杂的模型，创建一个更智能的管道。 |'
- en: '| 54 | If you want to understand your numerical data, use models that provide
    explainability, such as decision tree or random forest. |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 54 | 如果您想理解您的数值数据，请使用提供可解释性的模型，例如决策树或随机森林。 |'
- en: '| 55 | The best models are those that capture the empirical phenomena in the
    data. |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 55 | 最佳模型是那些能够捕捉数据中经验现象的模型。 |'
- en: '| 56 | Simple, but explainable, models can often capture the data in a good
    way. |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 56 | 简单但可解释的模型通常可以很好地捕捉数据。 |'
- en: '| 57 | Always make sure that the data points in both the train and test sets
    are separate. |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 57 | 总是确保训练集和测试集中的数据点是分开的。 |'
- en: '| 58 | Use NVidia CUDA (accelerated computing) for training advanced models
    such as BERT, GPT-3, and Autoencoders. |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 58 | 使用NVidia CUDA（加速计算）来训练BERT、GPT-3和自编码器等高级模型。 |'
- en: '| 59 | In addition to monitoring the loss, make sure you visualize the actual
    results of the generation. |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 59 | 除了监控损失之外，确保您可视化生成的实际结果。 |'
- en: '| 60 | Check the output of generative AI models so that it does not break the
    entire system or does not provide unethical responses. |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 60 | 检查生成式AI模型的输出，以确保它不会破坏整个系统或提供不道德的回应。 |'
- en: '| 61 | The model card should contain information about how the model was trained,
    how to use it, which tasks it supports, and how to reference the model. |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 61 | 模型卡片应包含有关模型如何训练、如何使用它、它支持哪些任务以及如何引用模型的信息。 |'
- en: '| 62 | Experiment with different models to find the best pipeline. |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 62 | 尝试不同的模型以找到最佳管道。 |'
- en: '| 63 | Use a professional testing framework such as Pytest. |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 63 | 使用像Pytest这样的专业测试框架。 |'
- en: '| 64 | Set up your test infrastructure based on your training data. |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 64 | 根据您的训练数据设置测试基础设施。 |'
- en: '| 65 | Treat models as units and prepare unit tests for them accordingly. |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 65 | 将模型视为单元，并相应地为其准备单元测试。 |'
- en: '| 66 | Identify the key aspects of the machine learning deployment and monitor
    these aspects accordingly. |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 66 | 识别机器学习部署的关键方面，并相应地监控这些方面。 |'
- en: '| 67 | Focus on the user task when designing the user interface of the machine
    learning model. |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 67 | 设计机器学习模型的用户界面时，请专注于用户任务。 |'
- en: '| 68 | Prepare your models for web deployment. |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 68 | 准备您的模型以进行Web部署。 |'
- en: '| 69 | Try to work with in-memory databases and dump them to disk very often.
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 69 | 尝试使用内存数据库，并非常频繁地将它们转储到磁盘。 |'
- en: 'Table 17.3: Best practices in the third part of this book'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表17.3：本书第三部分的最佳实践
- en: 'In the last part of this book, *Ethical Aspects of Data Management and Machine
    Learning System Development*, we explored the challenges that relate to machine
    learning from the perspective of ethics and legal aspects. We offered certain
    solutions, but they do not replace human judgment and human intelligence. In the
    final chapter, we returned to a more technical part and taught you how to work
    with ecosystems, closing this book by opening up new alleys – microservices and
    Docker:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的最后部分，“数据管理和机器学习系统开发中的伦理问题”，我们从伦理和法律的角度探讨了与机器学习相关联的挑战。我们提供了一些解决方案，但它们不能取代人类的判断和智慧。在最后一章，我们回到了更技术性的部分，教您如何与生态系统合作，通过开辟新的途径——微服务和Docker来结束本书：
- en: '| **ID** | **Best Practice** |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| **ID** | **最佳实践** |'
- en: '| --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 70 | If your model/software aims to help with the daily tasks of your users,
    make sure that you develop it as an add-in. |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 70 | 如果您的模型/软件旨在帮助用户完成日常任务，请确保将其开发为附加组件。|'
- en: '| 71 | If you create your own data for non-commercial purposes, use one of
    the permissive derivative licenses that limit your liability. |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 71 | 如果您出于非商业目的创建自己的数据，请使用限制您责任的宽松衍生许可证之一。|'
- en: '| 72 | Limit yourself to studying source code and other artifacts, and only
    use personal data with the consent of the subjects. |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 72 | 仅限于研究源代码和其他工件，并且只有在主体同意的情况下才使用个人数据。|'
- en: '| 73 | Any personal data should be stored behind authentication and access
    control to prevent malicious actors from accessing it. |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 73 | 应当将任何个人数据存储在身份验证和访问控制之后，以防止恶意行为者访问。|'
- en: '| 74 | If a dataset contains variables that can be prone to bias, use the disparity
    metric to get a quick orientation about the data. |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 74 | 如果数据集包含可能存在偏差的变量，请使用差异度量来快速了解数据。|'
- en: '| 75 | Complement automated bias management with regular audits. |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 结合定期的审计来补充自动化偏差管理。|'
- en: '| 76 | Use web services when deploying machine learning models to production.
    |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 76 | 在将机器学习模型部署到生产时，请使用网络服务。|'
- en: '| 77 | Use both a website and a Python API for the web services. |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 77 | 为网络服务同时使用网站和Python API。|'
- en: '| 78 | Dockerize your web services for both version control and portability.
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 将您的网络服务Docker化，以实现版本控制和可移植性。|'
- en: 'Table 17.4: Best practices in the fourth part of this book'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表17.4：本书第四部分的最佳实践
- en: The best practices presented in this book are based on my experiences in designing,
    developing, testing, and deploying machine learning systems. These best practices
    are not exhaustive, and we could find more, depending on our interests.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 本书提出的最佳实践基于我在设计、开发、测试和部署机器学习系统方面的经验。这些最佳实践并不全面，根据我们的兴趣，我们可能会找到更多。
- en: To look for these best practices, I strongly suggest taking a look at the research
    publications that appear continuously in this area. In particular, I recommend
    following the main conferences in AI – that is, NeurIPS and AAAI – as well as
    the main conferences in software engineering – that is, ICSE, ASE, and ESEC/FSE.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了寻找这些最佳实践，我强烈建议您查看该领域持续出现的科研出版物。特别是，我建议关注人工智能的主要会议——即NeurIPS和AAAI——以及软件工程的主要会议——即ICSE、ASE和ESEC/FSE。
- en: Current developments
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当前发展
- en: At the time of writing this book, the Technology Innovation Institute ([https://www.tii.ae/](https://www.tii.ae/))
    has just released its largest model – Falcon 170B. It is the largest fully open
    source model that is similar to the GPT-3.5 model. It shows the current direction
    of the research in large language models.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写这本书的时候，技术创新研究所([https://www.tii.ae/](https://www.tii.ae/))刚刚发布了其最大的模型——Falcon
    170B。这是与GPT-3.5模型相似的最大全开源模型。它展示了大型语言模型研究的当前方向。
- en: Although GPT-4 exists, which is larger by a factor of 1,000, we can develop
    very good software with moderately large models such as GPT-3.5\. This brings
    us to some of the current topics that we, as a community, need to discuss. One
    of them is the energy sustainability of these models. Falcon-170B requires 400
    GB of RAM (eight times that of an Nvidia A100 GPU) to execute (according to Hugging
    Face). We do not know how much hardware the GPT-4 model needs. The amount of electricity
    that it takes and the resources that it uses must be on par with what we get as
    value from that model.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在GPT-4这样的模型，其规模比GPT-3.5大1000倍，但我们仍然可以使用像GPT-3.5这样适度大的模型来开发非常好的软件。这让我们想到了一些我们作为社区需要讨论的当前话题。其中之一是这些模型的能源可持续性。Falcon-170B需要400
    GB的RAM来执行（根据Hugging Face的说法）。我们不知道GPT-4模型需要多少硬件。它消耗的电力和使用的资源必须与从该模型中获得的价值相当。
- en: We also approach limits to the conventional computational power when it comes
    to machine learning, which brings us to quantum computing (Cerezo, Verdon et al.
    2022). However, although the idea of embedding machine learning in quantum computing
    formalism is quite appealing, it is not without its challenges. Machine learning
    systems/models need to be re-designed to fit the new paradigm and the new paradigm
    needs to be more accessible for AI engineers and software engineers.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习方面，我们也接近了传统计算能力的极限，这让我们想到了量子计算（Cerezo，Verdon等人，2022）。然而，尽管将机器学习嵌入到量子计算形式主义中的想法非常吸引人，但它并非没有挑战。机器学习系统/模型需要重新设计以适应新的范式，而新的范式需要更容易为AI工程师和软件工程师所接受。
- en: When it comes to algorithms, it is *swarming* that gets increasingly more attention,
    mostly due to the attention behind the **Internet of Things** (**IoT**) (Rosenberg
    2016, Rajeesh Kumar, Jaya Lakshmi, et al. 2023). With the support of technologies
    such as 5G and 6G in telecommunication, these developments are clearly on the
    rise and will continue to rise. However, one of the current challenges is fragmenting
    the protocols and technologies, which leads to challenges related to cybersecurity
    and attacks on critical infrastructure.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到算法时，越来越受到关注的是*蜂群算法*，这主要归功于**物联网**（IoT）背后的关注（Rosenberg 2016，Rajeesh Kumar，Jaya
    Lakshmi等人，2023）。在5G和6G等电信技术的支持下，这些发展显然正在上升，并将继续上升。然而，当前的一个挑战是协议和技术的碎片化，这导致与网络安全和针对关键基础设施的攻击相关的问题。
- en: Yet another alley of research that is currently growing is the area of *graph
    neural networks* (Gao, Zheng, et al. 2023). As the current architectures are limited
    to linear data or data or data that can be linearized, they cannot handle certain
    tasks. Programming language models are one example of such an area – although
    they are capable of many tasks, they cannot consider execution graphs or similar
    elements at the moment. Therefore, the graph neural models are seen to be the
    next development, although the main challenge to address there is related to the
    computational power needed for training and inference in the graph neural models.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个目前正在增长的研究领域是*图神经网络*（Gao，Zheng等人，2023）。由于当前的架构仅限于线性数据或可以线性化的数据，它们无法处理某些任务。编程语言模型就是这样一个领域的例子——尽管它们能够执行许多任务，但目前它们无法考虑执行图或类似元素。因此，图神经网络被视为下一个发展方向，尽管在那里需要解决的主要挑战与图神经网络训练和推理所需的计算能力有关。
- en: At the same time, increasingly more studies are tackling the development of
    models and softer aspects of it, such as ethics, explainability, and their impact
    on society at large (Meskó and Topol 2023). Medicine, large language models, and
    the digitalization of society are just a few areas where intensive standardization
    of the work is ongoing.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，越来越多的研究正在解决模型及其软性方面的发展，如伦理、可解释性和它们对整个社会的影响（Meskó和Topol 2023）。医学、大型语言模型和社会的数字化只是正在进行的密集标准化工作的几个领域。
- en: My view on the future
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我对未来观点的看法
- en: Based on my observations of the machine learning landscape today, with a particular
    focus on software engineering, I can see a few trends.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我对当前机器学习领域的观察，特别是关注软件工程，我可以看到一些趋势。
- en: Language models will get better at completing software engineering tasks, such
    as requirements, testing, and documenting. This means that software engineers
    will be able to focus on their core work – engineering software – rather than
    on tedious, repetitive tasks. We will see models that will test software, document
    it, explain it, and maybe even repair it. The latest advancements in this field
    are very promising.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型将更好地完成软件工程任务，如需求、测试和文档编写。这意味着软件工程师将能够专注于他们的核心工作——工程软件——而不是枯燥、重复的任务。我们将看到能够测试软件、编写文档、解释软件，甚至可能修复软件的模型。该领域的最新进展非常有希望。
- en: Hybrid models will be more popular. Combining symbolic analysis and neural networks
    will gain traction and be able to assist us in finding advanced vulnerabilities
    in software, as well as identifying them before they are exploited. This will
    make our software more robust and more resilient over time.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 混合模型将更加流行。结合符号分析和神经网络将获得动力，并能够帮助我们找到软件中的高级漏洞，以及在它们被利用之前识别它们。这将使我们的软件随着时间的推移变得更加健壮和有弹性。
- en: Large models and the availability of significant computational power will help
    us also to detect anomalies in software operations. By analyzing logs, we will
    be able to predict aging and we will be able to direct maintenance effort. Again,
    we will be able to focus on software engineering rather than on analysis.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 大型模型和强大的计算能力也将帮助我们检测软件操作中的异常。通过分析日志，我们将能够预测老化，并将能够指导维护工作。再次强调，我们将能够专注于软件工程，而不是分析。
- en: And last, but not least, hybrid models will help us with design tasks. Combining
    image generation and other types of methods will help us in designing software
    – its architecture and detailed design, and even predicting the operational performance
    of the software.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，混合模型将帮助我们进行设计任务。结合图像生成和其他类型的方法将帮助我们设计软件——其架构和详细设计，甚至预测软件的操作性能。
- en: Final remarks
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的评论
- en: I hope that this book was interesting for you and that you have gained new knowledge
    in machine learning, AI, and engineering software. I hope that you can use this
    book as a reference and that you will use the associated code to create new products.
    I would also greatly appreciate it if you could let me know if you liked it, connect
    via LinkedIn, and contribute to this book’s GitHub repository. I will monitor
    it and integrate all pull requests that you may have.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这本书对您来说很有趣，并且您在机器学习、人工智能和工程软件方面获得了新的知识。我希望您可以将这本书作为参考，并使用相关的代码来创建新产品。如果您喜欢这本书，请告诉我，通过LinkedIn与我联系，并为这本书的GitHub仓库做出贡献。我会监控它，并整合您可能提出的所有pull
    requests。
- en: Before we part, I have one last best practice.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们分别之前，我还有一个最后的最佳实践。
- en: 'Best practice #79'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践#79
- en: Never stop learning.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 永远不要停止学习。
- en: Take this from a university professor. The field of machine learning grows quickly,
    with new models being introduced almost every week. Make sure that you observe
    the scientific publications in this area and commercial developments. This will
    help you keep your knowledge up-to-date and help you advance in your professional
    career.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以一位大学教授的身份来说，机器学习领域发展迅速，几乎每周都有新的模型被引入。请确保您关注该领域的科学出版物和商业发展。这将帮助您保持知识的更新，并帮助您在职业生涯中取得进步。
- en: References
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Cerezo, M., G. Verdon, H.-Y. Huang, L. Cincio and P. J. Coles (2022). Challenges
    and opportunities in quantum machine learning. Nature Computational Science* *2(9):
    567-576.*'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Cerezo, M., G. Verdon, H.-Y. Huang, L. Cincio和P. J. Coles (2022). 量子机器学习中的挑战与机遇。自然计算科学*
    *2(9): 567-576.*'
- en: '*Gao, C., Y. Zheng, N. Li, Y. Li, Y. Qin, J. Piao, Y. Quan, J. Chang, D. Jin
    and X. He (2023). A survey of graph neural networks for recommender systems: Challenges,
    methods, and directions**. ACM Transactions on Recommender Systems* *1(1): 1-51.*'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Gao, C., Y. Zheng, N. Li, Y. Li, Y. Qin, J. Piao, Y. Quan, J. Chang, D. Jin和X.
    He (2023). 推荐系统中图神经网络的研究综述：挑战、方法和方向**。ACM推荐系统交易* *1(1): 1-51.*'
- en: '*Meskó, B. and E. J. Topol (2023). The imperative for regulatory oversight
    of large language models (or generative AI) in healthcare. npj Digital Medicine*
    *6(1): 120.*'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Meskó, B.和E. J. Topol (2023). 在医疗保健中对大型语言模型（或生成式AI）进行监管审查的必要性。npj数字医学* *6(1):
    120.*'
- en: '*Rajeesh Kumar, N. V., N. Jaya Lakshmi, B. Mallala and V. Jadhav (2023). Secure
    trust aware multi-objective routing protocol based on battle competitive swarm
    optimization in IoT. Artificial* *Intelligence Review.*'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*拉杰什·库马尔，N. V.，N.贾亚拉什米，B.马拉拉和V.贾达夫 (2023). 基于战斗竞争蜂群优化的物联网安全信任感知多目标路由协议。* *人工智能评论*。'
- en: '*Rosenberg, L. (2016). Artificial Swarm Intelligence, a Human-in-the-loop approach
    to AI. Proceedings of the AAAI conference on* *artificial intelligence.*'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*罗森伯格，L. (2016). 人工蜂群智能：人工智能中的人机交互方法。* *AAAI人工智能会议论文集*。'
