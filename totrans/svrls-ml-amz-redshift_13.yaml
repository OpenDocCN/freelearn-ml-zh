- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Operationalizing and Optimizing Amazon Redshift ML Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have learned how to create many different types of ML models, we
    will show you how you can operationalize your model training pipelines. Once you
    have moved your model to production, you want to refresh the model regularly and
    automate the process to do this. Additionally, it is important to periodically
    evaluate your models to maintain and improve their accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will go through the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Operationalizing your ML models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing the Redshift model for accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter requires a web browser and access to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An AWS account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Amazon Redshift Serverless endpoint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Redshift Query Editor v2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Amazon EC2 Linux instance (optional)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can find the code used in this chapter here: [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/).'
  prefs: []
  type: TYPE_NORMAL
- en: Operationalizing your ML models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once a model is validated and used on a regular basis for running predictions,
    it should be operationalized. The reasons for this are to remove the manual tasks
    of retraining your models and to ensure that your model still retains high accuracy
    after your data distribution has changed over time, also referred to as **data
    drift**. When data drift occurs, you need to retrain the model using an updated
    training set.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will do a simple model retraining, then show you
    how you can create a version from an existing model.
  prefs: []
  type: TYPE_NORMAL
- en: Model retraining process without versioning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To walk through the retraining process, we will use one of our previously used
    models.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 7*](B19071_07.xhtml#_idTextAnchor111), we discussed different regression
    models, so let’s use the `chapter7_regressionmodel.predict_ticket_price_auto`
    model. This model solved a multi-input regression problem and **SageMaker Autopilot**
    chose the **XGBoost algorithm**.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s assume this model is performing well and, based on our data loading processes,
    we want to retrain this model weekly.
  prefs: []
  type: TYPE_NORMAL
- en: 'To retrain this model, we must first remove the existing model and then re-execute
    the `CREATE MODEL` command as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You can set this up to run on a regular schedule using various techniques,
    which could include using the Query Editor v2 scheduling feature or running scripts.
    For more information on scheduling queries with Query Editor v2, refer to the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.aws.amazon.com/redshift/latest/mgmt/query-editor-v2-schedule-query.html](https://docs.aws.amazon.com/redshift/latest/mgmt/query-editor-v2-schedule-query.html).'
  prefs: []
  type: TYPE_NORMAL
- en: The model retraining process with versioning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This approach of simply dropping and recreating the model might be fine in some
    cases, but there is no model history available since we are simply dropping and
    recreating the model. This makes comparing the newly trained model to previous
    versions very difficult, if not impossible.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, Redshift ML does not have native versioning capabilities.
    However, you can still do versioning by implementing a few simple SQL techniques
    and leveraging the **bring our own model** (**BYOM**) capability, which you learned
    about in [*Chapter 11*](B19071_11.xhtml#_idTextAnchor192).
  prefs: []
  type: TYPE_NORMAL
- en: BYOM is great for leveraging pre-built Amazon SageMaker models in order to run
    your inference queries in Amazon Redshift and you can also use BYOM for models
    that were built using Redshift ML, which means we can create a *version* of an
    existing model that was previously created by Redshift ML.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a quick refresher on the syntax of BYOM for local inference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We need the job name, the data types of the model inputs, and the output. We
    can get the information we need for the `CREATE MODEL` statement by running the
    `SHOW MODEL` statement on our existing model. Run the following command in Query
    Editor v2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 13.1 – \uFEFFThe SHOW MODEL output](img/B19071_13_01.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – The SHOW MODEL output
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the `CREATE MODEL` statement to create a version of the current
    model using the `SHOW MODEL` command. You will also need to include the function
    parameter types from *Figure 13**.1* in `FUNCTION` here and include the data type
    of `Target Column`(`FINAL_TICKET_PRICE`). Note that we append the date (`YYYYMMDD`)
    to the end of the model name and function name to create our version. You can
    run the following code in Query Editor v2 to create a version of your model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following `SHOW` `MODEL` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In *Figure 13**.2*, notice that **Inference Type** shows **Local**, which designates
    this as BYOM with local inference:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 13.2 – \uFEFFThe SHOW MODEL output](img/B19071_13_02.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – The SHOW MODEL output
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have learned how to create a version of a previously trained Redshift
    ML model, we will show you how you can automate this process.
  prefs: []
  type: TYPE_NORMAL
- en: Automating the CREATE MODEL statement for versioning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have included the scripts here: [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13.](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13\.
    )'
  prefs: []
  type: TYPE_NORMAL
- en: You can use these scripts and customize them as needed. These contain all the
    components needed to automate the process of performing model versioning. The
    example in this chapter uses Bash scripts with RSQL running on an EC2 instance.
    If you prefer, you can also install RSQL on Windows or macOS.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may find more information on using RSQL to interact with Amazon Redshift
    here: [https://docs.aws.amazon.com/redshift/latest/mgmt/rsql-query-tool-getting-started.html](https://docs.aws.amazon.com/redshift/latest/mgmt/rsql-query-tool-getting-started.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To download all the code for this book, you may run the commands given in the
    following link on an EC2 instance running on Linux or Windows or on your local
    Windows or Mac machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift.git](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift.git).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before running the scripts, we need to create the schema and the table needed
    to generate the `CREATE MODEL` command for the model version. You can run the
    following steps in Query Editor v2:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the schema:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the table to contain the metadata needed to auto-generate the `CREATE`
    `MODEL` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Initialize the `local_inf_ml_components` table.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Note that you will just need to initialize this table once, with the model
    name, schema name, the data type of the target value we are predicting, the **Amazon
    Resource Name** (**ARN**) of the IAM role, and the S3 bucket to be used for the
    Redshift ML artifacts. The table will get updated with the additional data needed
    as part of the automation script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to run the automation script. *Figure 13**.3* illustrates
    this flow using our `predict_ticket_price_auto` model from [*Chapter 7*](B19071_07.xhtml#_idTextAnchor111).
    **Step 1** creates the model version by using BYOM and appending the timestamp
    and **Step 2** drops and creates the new model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – Automation script steps 1 and 2](img/B19071_13_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – Automation script steps 1 and 2
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through the steps in *Figure 13**.3*.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – creating a version from the existing model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You may refer to the `step1_create_model_version.sh` script at [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13)
    or where you placed the file after running the `git` `clone` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contents of the `step1_create_model_version.sh` script are also shown in
    the following code snippet. As you can see, it calls other scripts and commands
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Before you execute this script, read through the following subsections as they
    contain instructions on some setup steps.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the show_model_sql command
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We have a simple script called `generate_show_model_sql.sh` with code as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This script takes as input the model name. In the script provided, we have already
    supplied the model name in the `step1_create_model_version.sh` driver script.
    You can modify this as needed for your models.
  prefs: []
  type: TYPE_NORMAL
- en: The script creates a `SHOW MODEL` command that is written to a file called `show_model.sql`
    to be read in the `show_model.sh` script.
  prefs: []
  type: TYPE_NORMAL
- en: Reading the SHOW MODEL output and writing it to a file
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This step executes an Amazon Redshift RSQL script called `show_model.sh`, which
    reads the `show_model.sql` file and writes the output to a file called `create_model.txt`.
  prefs: []
  type: TYPE_NORMAL
- en: Copying the SHOW MODEL output to the model info table
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This copies the `create_model.txt` file into an S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the SHOW MODEL output and prepping the table to generate `CREATE MODEL`
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This step executes another Amazon Redshift RSQL script called `prep_create_model.sh`,
    which performs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Creates and loads the `model_info` table
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updates `local_inf_ml_model_components` from the `model_info` table so that
    the `CREATE MODEL` statement can be generated for the model version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inserts the generated `CREATE MODEL` statement into the `create_model_sql` table
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating the SQL to create the model version
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This step calls an Amazon Redshift RSQL script called `generate_create_model_version_sql.sh`,
    which reads the `create_model` table and writes the SQL to a text file called
    `model_version.txt`.
  prefs: []
  type: TYPE_NORMAL
- en: Executing the SQL to create the model version
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This step calls an Amazon Redshift RSQL script called `execute_create_model_version.sh`,
    which creates the version of our previously created model.
  prefs: []
  type: TYPE_NORMAL
- en: Now you can drop and create your model since we have the model version.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – retraining your Redshift ML model to create a version from the existing
    model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This step calls an Amazon Redshift RSQL script called `retrain_model.sh`, which
    drops and creates our model. It references `retrain_model.sql`, which you can
    modify for your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have learned how to automate the process of retraining your Redshift
    ML models, let’s discuss how to optimize the accuracy of your models.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the Redshift models’ accuracy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will review best practices for maintaining the optimal accuracy
    of your models.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need to continually monitor your models over time to ensure the scores
    stay stable between model training runs. Consider the new version of the model
    we created here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – New model output](img/B19071_13_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – New model output
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a table similar to this and track each week’s mean square error (MSE)
    score from the `SHOW` `MODEL` output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The variance will be the difference in the score of each successive version
    of a model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check how your models are trending by writing a query like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: If variances are not within a reasonable amount, you will need to look at ways
    to improve the model scores.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore how we can improve the model quality by using more data and experimenting
    with different model types and algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Model quality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first best practice is to use more data to improve the model’s quality.
    Also, you can add more training time to your model by increasing the `MAX_RUNTIME`
    parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Ensure you are using a representative dataset for training and create at least
    a 10% sample for validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Experiment with different model types and algorithms to get the best model.
    For example, in [*Chapter 7*](B19071_07.xhtml#_idTextAnchor111), we tried two
    different algorithms for the multi-input regression models. On the first one,
    we tried linear learning and we got an MSE score of 701:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 13.5 – MSE score of \uFEFFthe linear learner model type](img/B19071_13_05.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 13.5 – MSE score of the linear learner model type
  prefs: []
  type: TYPE_NORMAL
- en: 'When we ran it again without specifying the model type, SageMaker Autopilot
    chose XGBoost as the model type and it gave a better MSE score of **0.711260**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.6 – MSE score of XGBoost model type](img/B19071_13_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.6 – MSE score of XGBoost model type
  prefs: []
  type: TYPE_NORMAL
- en: Model explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second best practice is to use the explainability report to better understand
    which inputs to your model carried the most weight.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following SQL command in Query Editor v2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns Shapley values for the inputs used to train the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: You will notice that `list_ticket_price` has the highest value of `36.364` –
    this means it was the highest weighted input. You can experiment by removing the
    input columns with very low weights as inputs to your model training. Check to
    see whether you still get the same approximate model score by removing unnecessary
    columns for the training input and helping improve training times.
  prefs: []
  type: TYPE_NORMAL
- en: Probabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For classification problems, leverage the built-in function that is generated
    so that you can see the probability of a given prediction. Refer to [*Chapter
    5*](B19071_05.xhtml#_idTextAnchor068) for detailed examples of this.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now take a look at some useful notebooks that are generated by Amazon
    SageMaker Autopilot.
  prefs: []
  type: TYPE_NORMAL
- en: Using SageMaker Autopilot notebooks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your Autopilot job generates a data exploration notebook and a candidate definition
    notebook. To view these notebooks, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the AWS console, search for `SageMaker`, then choose **Amazon SageMaker**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.7 – Choosing Amazon SageMaker](img/B19071_13_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.7 – Choosing Amazon SageMaker
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, choose **Studio**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.8 – Choosing Studio](img/B19071_13_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.8 – Choosing Studio
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, choose **Open Studio**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.9 – Choosing Open Studio](img/B19071_13_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.9 – Choosing Open Studio
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, choose **AutoML**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.10 – Choosing AutoML](img/B19071_13_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.10 – Choosing AutoML
  prefs: []
  type: TYPE_NORMAL
- en: 'After you choose **AutoML**, the following screen will show up:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.11 – List of model names](img/B19071_13_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.11 – List of model names
  prefs: []
  type: TYPE_NORMAL
- en: 'Choose the model name you want to evaluate. You can get this by using the AutoML
    job name from your `SHOW MODEL` output. In this example, I used `SHOW MODEL` on
    the `predict_ticket_price_auto` model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 13.12 – \uFEFFThe SHOW MODEL output](img/B19071_13_12.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 13.12 – The SHOW MODEL output
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see output like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.13 – AutoML best model](img/B19071_13_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.13 – AutoML best model
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 13**.13*, you can see a list of models that were trained, and the
    *best* model is highlighted. This also shows the objective of **Mse**, the values,
    and which algorithm was used, and there are links to view the model details, the
    candidate generation notebook, and the data exploration notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **View model details** – this is another way you can see feature importance
    or explainability:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.14 – Feature importance](img/B19071_13_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.14 – Feature importance
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also see the hyperparameters used by SageMaker Autopilot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.15 – Hyperparameters](img/B19071_13_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.15 – Hyperparameters
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, try clicking on **Open data** **exploration notebook**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.16 – Data exploration report](img/B19071_13_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.16 – Data exploration report
  prefs: []
  type: TYPE_NORMAL
- en: This will show you the data exploration report and you can see things such as
    **Target Analysis**, **Feature Summary**, **Duplicate Rows**, and other statistics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what `predict_ticket_price_auto` model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.17 – Target Analysis](img/B19071_13_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.17 – Target Analysis
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn more about the data exploration notebook, you may refer to this link:
    [https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-data-exploration-report.html](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-data-exploration-report.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, click on **Open candidate** **generation notebook**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.18 – Candidate definition notebook](img/B19071_13_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.18 – Candidate definition notebook
  prefs: []
  type: TYPE_NORMAL
- en: This notebook contains information about the processing steps, algorithms, and
    hyperparameters. To learn more about using the candidate generation notebook,
    refer to [https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-candidate-generation-notebook.html](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-candidate-generation-notebook.html).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned techniques to operationalize your models in Amazon
    Redshift ML.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed how you can create a version of your model. This is important to
    track the quality of your model over time and to be able to run inferences with
    different versions.
  prefs: []
  type: TYPE_NORMAL
- en: We then showed you how to optimize your Redshift ML models for accuracy and
    how you can use the notebooks generated by Amazon SageMaker Autopilot to deepen
    your understanding of tasks that Autopilot is performing.
  prefs: []
  type: TYPE_NORMAL
- en: 'We hope you have found this book useful. Our goal when we set out to write
    this book was to help you gain confidence in these main areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Gaining a better understanding of machine learning and how to use it to solve
    everyday business problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an end-to-end serverless architecture for ingestion, analytics,
    and machine learning using Redshift Serverless and Redshift ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating supervised and unsupervised models, and various techniques to influence
    your model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running inference queries at scale in Redshift to solve a variety of business
    problems using models created with Redshift ML or natively in Amazon SageMaker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We thank you very much for your time and investment in reading this book. We
    would welcome your feedback on how we can make Redshift and Redshift ML better.
    You can find us on LinkedIn.
  prefs: []
  type: TYPE_NORMAL
