- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Operationalizing and Optimizing Amazon Redshift ML Models
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have learned how to create many different types of ML models, we
    will show you how you can operationalize your model training pipelines. Once you
    have moved your model to production, you want to refresh the model regularly and
    automate the process to do this. Additionally, it is important to periodically
    evaluate your models to maintain and improve their accuracy.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will go through the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Operationalizing your ML models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing the Redshift model for accuracy
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter requires a web browser and access to the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: An AWS account
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Amazon Redshift Serverless endpoint
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Redshift Query Editor v2
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Amazon EC2 Linux instance (optional)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can find the code used in this chapter here: [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Operationalizing your ML models
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once a model is validated and used on a regular basis for running predictions,
    it should be operationalized. The reasons for this are to remove the manual tasks
    of retraining your models and to ensure that your model still retains high accuracy
    after your data distribution has changed over time, also referred to as **data
    drift**. When data drift occurs, you need to retrain the model using an updated
    training set.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will do a simple model retraining, then show you
    how you can create a version from an existing model.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Model retraining process without versioning
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To walk through the retraining process, we will use one of our previously used
    models.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 7*](B19071_07.xhtml#_idTextAnchor111), we discussed different regression
    models, so let’s use the `chapter7_regressionmodel.predict_ticket_price_auto`
    model. This model solved a multi-input regression problem and **SageMaker Autopilot**
    chose the **XGBoost algorithm**.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Let’s assume this model is performing well and, based on our data loading processes,
    we want to retrain this model weekly.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'To retrain this model, we must first remove the existing model and then re-execute
    the `CREATE MODEL` command as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can set this up to run on a regular schedule using various techniques,
    which could include using the Query Editor v2 scheduling feature or running scripts.
    For more information on scheduling queries with Query Editor v2, refer to the
    following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.aws.amazon.com/redshift/latest/mgmt/query-editor-v2-schedule-query.html](https://docs.aws.amazon.com/redshift/latest/mgmt/query-editor-v2-schedule-query.html).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: The model retraining process with versioning
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This approach of simply dropping and recreating the model might be fine in some
    cases, but there is no model history available since we are simply dropping and
    recreating the model. This makes comparing the newly trained model to previous
    versions very difficult, if not impossible.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, Redshift ML does not have native versioning capabilities.
    However, you can still do versioning by implementing a few simple SQL techniques
    and leveraging the **bring our own model** (**BYOM**) capability, which you learned
    about in [*Chapter 11*](B19071_11.xhtml#_idTextAnchor192).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: BYOM is great for leveraging pre-built Amazon SageMaker models in order to run
    your inference queries in Amazon Redshift and you can also use BYOM for models
    that were built using Redshift ML, which means we can create a *version* of an
    existing model that was previously created by Redshift ML.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a quick refresher on the syntax of BYOM for local inference:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We need the job name, the data types of the model inputs, and the output. We
    can get the information we need for the `CREATE MODEL` statement by running the
    `SHOW MODEL` statement on our existing model. Run the following command in Query
    Editor v2:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The result is as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 13.1 – \uFEFFThe SHOW MODEL output](img/B19071_13_01.jpg)"
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – The SHOW MODEL output
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the `CREATE MODEL` statement to create a version of the current
    model using the `SHOW MODEL` command. You will also need to include the function
    parameter types from *Figure 13**.1* in `FUNCTION` here and include the data type
    of `Target Column`(`FINAL_TICKET_PRICE`). Note that we append the date (`YYYYMMDD`)
    to the end of the model name and function name to create our version. You can
    run the following code in Query Editor v2 to create a version of your model:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Run the following `SHOW` `MODEL` command:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In *Figure 13**.2*, notice that **Inference Type** shows **Local**, which designates
    this as BYOM with local inference:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 13.2 – \uFEFFThe SHOW MODEL output](img/B19071_13_02.jpg)"
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – The SHOW MODEL output
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have learned how to create a version of a previously trained Redshift
    ML model, we will show you how you can automate this process.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Automating the CREATE MODEL statement for versioning
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have included the scripts here: [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13.](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13\.
    )'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: You can use these scripts and customize them as needed. These contain all the
    components needed to automate the process of performing model versioning. The
    example in this chapter uses Bash scripts with RSQL running on an EC2 instance.
    If you prefer, you can also install RSQL on Windows or macOS.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'You may find more information on using RSQL to interact with Amazon Redshift
    here: [https://docs.aws.amazon.com/redshift/latest/mgmt/rsql-query-tool-getting-started.html](https://docs.aws.amazon.com/redshift/latest/mgmt/rsql-query-tool-getting-started.html).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'To download all the code for this book, you may run the commands given in the
    following link on an EC2 instance running on Linux or Windows or on your local
    Windows or Mac machine:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift.git](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift.git).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Before running the scripts, we need to create the schema and the table needed
    to generate the `CREATE MODEL` command for the model version. You can run the
    following steps in Query Editor v2:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the schema:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create the table to contain the metadata needed to auto-generate the `CREATE`
    `MODEL` command:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Initialize the `local_inf_ml_components` table.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Note that you will just need to initialize this table once, with the model
    name, schema name, the data type of the target value we are predicting, the **Amazon
    Resource Name** (**ARN**) of the IAM role, and the S3 bucket to be used for the
    Redshift ML artifacts. The table will get updated with the additional data needed
    as part of the automation script:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we are ready to run the automation script. *Figure 13**.3* illustrates
    this flow using our `predict_ticket_price_auto` model from [*Chapter 7*](B19071_07.xhtml#_idTextAnchor111).
    **Step 1** creates the model version by using BYOM and appending the timestamp
    and **Step 2** drops and creates the new model:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – Automation script steps 1 and 2](img/B19071_13_03.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – Automation script steps 1 and 2
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through the steps in *Figure 13**.3*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – creating a version from the existing model
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You may refer to the `step1_create_model_version.sh` script at [https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/tree/main/CodeFiles/chapter13)
    or where you placed the file after running the `git` `clone` command.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'The contents of the `step1_create_model_version.sh` script are also shown in
    the following code snippet. As you can see, it calls other scripts and commands
    as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Before you execute this script, read through the following subsections as they
    contain instructions on some setup steps.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Creating the show_model_sql command
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We have a simple script called `generate_show_model_sql.sh` with code as shown
    here:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This script takes as input the model name. In the script provided, we have already
    supplied the model name in the `step1_create_model_version.sh` driver script.
    You can modify this as needed for your models.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: The script creates a `SHOW MODEL` command that is written to a file called `show_model.sql`
    to be read in the `show_model.sh` script.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Reading the SHOW MODEL output and writing it to a file
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This step executes an Amazon Redshift RSQL script called `show_model.sh`, which
    reads the `show_model.sql` file and writes the output to a file called `create_model.txt`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Copying the SHOW MODEL output to the model info table
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This copies the `create_model.txt` file into an S3 bucket.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Loading the SHOW MODEL output and prepping the table to generate `CREATE MODEL`
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This step executes another Amazon Redshift RSQL script called `prep_create_model.sh`,
    which performs the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Creates and loads the `model_info` table
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updates `local_inf_ml_model_components` from the `model_info` table so that
    the `CREATE MODEL` statement can be generated for the model version
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inserts the generated `CREATE MODEL` statement into the `create_model_sql` table
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating the SQL to create the model version
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This step calls an Amazon Redshift RSQL script called `generate_create_model_version_sql.sh`,
    which reads the `create_model` table and writes the SQL to a text file called
    `model_version.txt`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Executing the SQL to create the model version
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This step calls an Amazon Redshift RSQL script called `execute_create_model_version.sh`,
    which creates the version of our previously created model.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Now you can drop and create your model since we have the model version.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – retraining your Redshift ML model to create a version from the existing
    model
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This step calls an Amazon Redshift RSQL script called `retrain_model.sh`, which
    drops and creates our model. It references `retrain_model.sql`, which you can
    modify for your needs.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have learned how to automate the process of retraining your Redshift
    ML models, let’s discuss how to optimize the accuracy of your models.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the Redshift models’ accuracy
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will review best practices for maintaining the optimal accuracy
    of your models.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need to continually monitor your models over time to ensure the scores
    stay stable between model training runs. Consider the new version of the model
    we created here:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – New model output](img/B19071_13_04.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – New model output
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a table similar to this and track each week’s mean square error (MSE)
    score from the `SHOW` `MODEL` output:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The variance will be the difference in the score of each successive version
    of a model.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'Check how your models are trending by writing a query like this:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: If variances are not within a reasonable amount, you will need to look at ways
    to improve the model scores.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore how we can improve the model quality by using more data and experimenting
    with different model types and algorithms.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Model quality
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first best practice is to use more data to improve the model’s quality.
    Also, you can add more training time to your model by increasing the `MAX_RUNTIME`
    parameter.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Ensure you are using a representative dataset for training and create at least
    a 10% sample for validation.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'Experiment with different model types and algorithms to get the best model.
    For example, in [*Chapter 7*](B19071_07.xhtml#_idTextAnchor111), we tried two
    different algorithms for the multi-input regression models. On the first one,
    we tried linear learning and we got an MSE score of 701:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 13.5 – MSE score of \uFEFFthe linear learner model type](img/B19071_13_05.jpg)"
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: Figure 13.5 – MSE score of the linear learner model type
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'When we ran it again without specifying the model type, SageMaker Autopilot
    chose XGBoost as the model type and it gave a better MSE score of **0.711260**:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.6 – MSE score of XGBoost model type](img/B19071_13_06.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
- en: Figure 13.6 – MSE score of XGBoost model type
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Model explainability
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second best practice is to use the explainability report to better understand
    which inputs to your model carried the most weight.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following SQL command in Query Editor v2:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This returns Shapley values for the inputs used to train the model:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: You will notice that `list_ticket_price` has the highest value of `36.364` –
    this means it was the highest weighted input. You can experiment by removing the
    input columns with very low weights as inputs to your model training. Check to
    see whether you still get the same approximate model score by removing unnecessary
    columns for the training input and helping improve training times.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Probabilities
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For classification problems, leverage the built-in function that is generated
    so that you can see the probability of a given prediction. Refer to [*Chapter
    5*](B19071_05.xhtml#_idTextAnchor068) for detailed examples of this.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now take a look at some useful notebooks that are generated by Amazon
    SageMaker Autopilot.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Using SageMaker Autopilot notebooks
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your Autopilot job generates a data exploration notebook and a candidate definition
    notebook. To view these notebooks, follow these steps:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'In the AWS console, search for `SageMaker`, then choose **Amazon SageMaker**:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.7 – Choosing Amazon SageMaker](img/B19071_13_07.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
- en: Figure 13.7 – Choosing Amazon SageMaker
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, choose **Studio**:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.8 – Choosing Studio](img/B19071_13_08.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
- en: Figure 13.8 – Choosing Studio
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, choose **Open Studio**:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.9 – Choosing Open Studio](img/B19071_13_09.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: Figure 13.9 – Choosing Open Studio
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, choose **AutoML**:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.10 – Choosing AutoML](img/B19071_13_10.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
- en: Figure 13.10 – Choosing AutoML
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'After you choose **AutoML**, the following screen will show up:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.11 – List of model names](img/B19071_13_11.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
- en: Figure 13.11 – List of model names
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'Choose the model name you want to evaluate. You can get this by using the AutoML
    job name from your `SHOW MODEL` output. In this example, I used `SHOW MODEL` on
    the `predict_ticket_price_auto` model:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 13.12 – \uFEFFThe SHOW MODEL output](img/B19071_13_12.jpg)"
  id: totrans-146
  prefs: []
  type: TYPE_IMG
- en: Figure 13.12 – The SHOW MODEL output
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see output like this:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.13 – AutoML best model](img/B19071_13_13.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
- en: Figure 13.13 – AutoML best model
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 13**.13*, you can see a list of models that were trained, and the
    *best* model is highlighted. This also shows the objective of **Mse**, the values,
    and which algorithm was used, and there are links to view the model details, the
    candidate generation notebook, and the data exploration notebook.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **View model details** – this is another way you can see feature importance
    or explainability:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.14 – Feature importance](img/B19071_13_14.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
- en: Figure 13.14 – Feature importance
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also see the hyperparameters used by SageMaker Autopilot:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.15 – Hyperparameters](img/B19071_13_15.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
- en: Figure 13.15 – Hyperparameters
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, try clicking on **Open data** **exploration notebook**:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.16 – Data exploration report](img/B19071_13_16.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
- en: Figure 13.16 – Data exploration report
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: This will show you the data exploration report and you can see things such as
    **Target Analysis**, **Feature Summary**, **Duplicate Rows**, and other statistics.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what `predict_ticket_price_auto` model:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.17 – Target Analysis](img/B19071_13_17.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
- en: Figure 13.17 – Target Analysis
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn more about the data exploration notebook, you may refer to this link:
    [https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-data-exploration-report.html](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-data-exploration-report.html).'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, click on **Open candidate** **generation notebook**:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.18 – Candidate definition notebook](img/B19071_13_18.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: Figure 13.18 – Candidate definition notebook
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: This notebook contains information about the processing steps, algorithms, and
    hyperparameters. To learn more about using the candidate generation notebook,
    refer to [https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-candidate-generation-notebook.html](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-candidate-generation-notebook.html).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned techniques to operationalize your models in Amazon
    Redshift ML.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: We discussed how you can create a version of your model. This is important to
    track the quality of your model over time and to be able to run inferences with
    different versions.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: We then showed you how to optimize your Redshift ML models for accuracy and
    how you can use the notebooks generated by Amazon SageMaker Autopilot to deepen
    your understanding of tasks that Autopilot is performing.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'We hope you have found this book useful. Our goal when we set out to write
    this book was to help you gain confidence in these main areas:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Gaining a better understanding of machine learning and how to use it to solve
    everyday business problems
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an end-to-end serverless architecture for ingestion, analytics,
    and machine learning using Redshift Serverless and Redshift ML
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating supervised and unsupervised models, and various techniques to influence
    your model
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running inference queries at scale in Redshift to solve a variety of business
    problems using models created with Redshift ML or natively in Amazon SageMaker
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Redshift中进行大规模推理查询，以使用Redshift ML或直接在Amazon SageMaker中创建的模型解决各种商业问题
- en: We thank you very much for your time and investment in reading this book. We
    would welcome your feedback on how we can make Redshift and Redshift ML better.
    You can find us on LinkedIn.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们非常感谢您花时间阅读这本书，并欢迎您就如何使Redshift和Redshift ML变得更好提供反馈。您可以在LinkedIn上找到我们。
