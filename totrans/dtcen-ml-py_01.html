<html><head></head><body>
<div id="_idContainer016">
<h1 class="chapter-number" id="_idParaDest-16"><a id="_idTextAnchor015"/><span class="koboSpan" id="kobo.1.1">1</span></h1>
<h1 id="_idParaDest-17"><a id="_idTextAnchor016"/><span class="koboSpan" id="kobo.2.1">Exploring Data-Centric Machine Learning</span></h1>
<p><span class="koboSpan" id="kobo.3.1">This chapter provides a foundational understanding of what data-centric </span><strong class="bold"><span class="koboSpan" id="kobo.4.1">machine learning</span></strong><span class="koboSpan" id="kobo.5.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.6.1">ML</span></strong><span class="koboSpan" id="kobo.7.1">) is. </span><span class="koboSpan" id="kobo.7.2">We will also contrast data centricity with model centricity and compare the performance of the two approaches, using practical examples to illustrate key points. </span><span class="koboSpan" id="kobo.7.3">Through these practical examples, you will gain a strong appreciation for the potential of </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">data centricity.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">In this chapter, we will cover the following </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">main topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.11.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">data-centric ML</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Data-centric versus </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">model-centric ML</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">The importance of quality data </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">in ML</span></span></li>
</ul>
<h1 id="_idParaDest-18"><a id="_idTextAnchor017"/><span class="koboSpan" id="kobo.17.1">Understanding data-centric ML</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.18.1">Data-centric ML</span></strong><span class="koboSpan" id="kobo.19.1"> is</span><a id="_idIndexMarker000"/><span class="koboSpan" id="kobo.20.1"> the discipline of systematically engineering the data used to build ML and </span><strong class="bold"><span class="koboSpan" id="kobo.21.1">artificial intelligence</span></strong><span class="koboSpan" id="kobo.22.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.23.1">AI</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">) systems</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.25.1">1</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.27.1">The data-centric AI and ML movement is grounded in the philosophy that data quality is more important than data volume when it comes to building highly informative models. </span><span class="koboSpan" id="kobo.27.2">Put another way, it is possible to achieve more with a small but high-quality dataset than with a large but noisy dataset. </span><span class="koboSpan" id="kobo.27.3">For most ML use cases, it is not feasible to build models based on very large datasets, say millions of observations, simply because the volume of data doesn’t exist. </span><span class="koboSpan" id="kobo.27.4">In other words, the potential use of ML as a tool to solve certain problems is often ignored on the basis that the available dataset is </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">too small.</span></span></p>
<p><span class="koboSpan" id="kobo.29.1">But what if we can use ML to solve problems based on much smaller datasets, even down to less than 100 observations? </span><span class="koboSpan" id="kobo.29.2">This is one challenge the data-centric movement is attempting to solve through systematic data collection </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">and engineering.</span></span></p>
<p><span class="koboSpan" id="kobo.31.1">For most </span><a id="_idIndexMarker001"/><span class="koboSpan" id="kobo.32.1">ML use cases, the algorithm you need already exists. </span><span class="koboSpan" id="kobo.32.2">The quality of your input data (</span><em class="italic"><span class="koboSpan" id="kobo.33.1">x</span></em><span class="koboSpan" id="kobo.34.1">) and your dependent variable labels (</span><em class="italic"><span class="koboSpan" id="kobo.35.1">y</span></em><span class="koboSpan" id="kobo.36.1">) is what makes the difference. </span><span class="koboSpan" id="kobo.36.2">The traditional response to dealing with noise in a dataset is to get as much data as possible to average out anomalies. </span><span class="koboSpan" id="kobo.36.3">Data centricity tries to improve the signal in the data such that more data is </span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">not needed.</span></span></p>
<p><span class="koboSpan" id="kobo.38.1">It’s important to note that data centricity marks the next frontier for larger data solutions too. </span><span class="koboSpan" id="kobo.38.2">No matter how big or small your dataset is, it is the foundational ingredient in your ML solution. </span><span class="koboSpan" id="kobo.38.3">Let’s take a closer look at the different aspects of </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">data-centric ML.</span></span></p>
<h2 id="_idParaDest-19"><a id="_idTextAnchor018"/><span class="koboSpan" id="kobo.40.1">The origins of data centricity</span></h2>
<p><span class="koboSpan" id="kobo.41.1">The</span><a id="_idIndexMarker002"/><span class="koboSpan" id="kobo.42.1"> push toward a more data-centric approach to ML development has been spearheaded by famous data science pioneer, Dr. </span><span class="No-Break"><span class="koboSpan" id="kobo.43.1">Andrew Ng.</span></span></p>
<p><span class="koboSpan" id="kobo.44.1">Dr. </span><span class="koboSpan" id="kobo.44.2">Ng is the co-founder of the massive open online course platform Coursera and an adjunct professor in computer science at Stanford University. </span><span class="koboSpan" id="kobo.44.3">He is also the founder and CEO of DeepLearning.AI, an education company, and Landing AI</span><span class="superscript"><span class="koboSpan" id="kobo.45.1">2</span></span><span class="koboSpan" id="kobo.46.1">, an AI-driven visual inspection platform for manufacturing. </span><span class="koboSpan" id="kobo.46.2">He previously worked as chief scientist at Baidu and was the founding lead of the Google Brain team. </span><span class="koboSpan" id="kobo.46.3">His Coursera courses on various ML topics have been completed by millions of </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">students worldwide.</span></span></p>
<p><span class="koboSpan" id="kobo.48.1">Dr. </span><span class="koboSpan" id="kobo.48.2">Ng and his team at Landing AI build complex ML solutions, such as computer vision systems used to inspect manufacturing quality. </span><span class="koboSpan" id="kobo.48.3">Through this work, they observed that the following characteristics are typical of most </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">ML opportunities</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.50.1">3</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.52.1">The majority of potential ML use cases rely on datasets smaller than 10,000 observations. </span><span class="koboSpan" id="kobo.52.2">It is often very difficult or impossible to add more data to reduce the effects of noise, so improving data quality is essential to these </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">use cases.</span></span></li>
<li><span class="koboSpan" id="kobo.54.1">Even in very large datasets, subsets of the data will exhibit the behavior of a small dataset. </span><span class="koboSpan" id="kobo.54.2">As an example, Google’s search engine generates billions of searches every day, but 95% of the searches are based on keyword combinations that occur fewer than 10 times per month (in the US). </span><span class="koboSpan" id="kobo.54.3">15% of daily keyword combinations have never been </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">searched before</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.56.1">4</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.58.1">When the dataset is small, it is typically faster and easier to identify and remove noise in the data than it is to collect more data. </span><span class="koboSpan" id="kobo.58.2">For example, if a dataset of 500 observations has 10% mislabeled observations, it is usually easier to improve the data quality on this existing data than it is to collect a new set </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">of observations.</span></span></li>
<li><span class="koboSpan" id="kobo.60.1">ML solutions are commonly built on pretrained models and packages, with minimal tweaking or modification required. </span><span class="koboSpan" id="kobo.60.2">Improving model performance by enhancing data quality frequently yields better results than changing model parameters or adding </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">more data.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.62.1">Dr. </span><span class="koboSpan" id="kobo.62.2">Ng published </span><a id="_idIndexMarker003"/><span class="koboSpan" id="kobo.63.1">a comparison of Landing AI’s outcomes that illustrates the last point that we </span><span class="No-Break"><span class="koboSpan" id="kobo.64.1">just discussed.</span></span></p>
<p><span class="koboSpan" id="kobo.65.1">As shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.66.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.67.1">.1</span></em><span class="koboSpan" id="kobo.68.1">, Landing AI produced three defect detection solutions for their clients. </span><span class="koboSpan" id="kobo.68.2">In all three cases, the teams created a baseline model and then tried to improve upon this model using model-centric and data-centric </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">approaches, respectively:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer010">
<span class="koboSpan" id="kobo.70.1"><img alt="Figure 1.1 – Applying data-centric ML – Landing AI’s results (Source: A Chat with Andrew on MLOps: From Model-Centric to Data-Centric AI)" src="image/B19297_01_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.71.1">Figure 1.1 – Applying data-centric ML – Landing AI’s results (Source: A Chat with Andrew on MLOps: From Model-Centric to Data-Centric AI)</span></p>
<p><span class="koboSpan" id="kobo.72.1">In all three examples, the Landing AI teams were able to achieve the best results by following a data-centric approach over a model-centric approach. </span><span class="koboSpan" id="kobo.72.2">In one of three examples, model-centric techniques achieved a tiny 0.04% uplift on the baseline model performance, and in the other two examples, no improvement </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1">was achieved.</span></span></p>
<p><span class="koboSpan" id="kobo.74.1">In contrast, improving data quality consistently led to an improvement in the baseline model, and in two out of three cases quite substantially. </span><span class="koboSpan" id="kobo.74.2">The Landing AI teams spent about 2 weeks iteratively improving the training datasets to achieve </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">these results.</span></span></p>
<p><span class="koboSpan" id="kobo.76.1">Dr. </span><span class="koboSpan" id="kobo.76.2">Ng’s recommendation</span><a id="_idIndexMarker004"/><span class="koboSpan" id="kobo.77.1"> is clear: if you want to build relevant and impactful ML models regardless of the size of your dataset, you must put a lot of effort into systematically engineering your </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">input data.</span></span></p>
<p><span class="koboSpan" id="kobo.79.1">Logically, it makes sense that better data leads to better models and Landing AI’s results provide some empirical evidence for the same. </span><span class="koboSpan" id="kobo.79.2">Now, let’s have a look at why data centricity is the future of </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">ML development.</span></span></p>
<h2 id="_idParaDest-20"><a id="_idTextAnchor019"/><span class="koboSpan" id="kobo.81.1">The components of ML systems</span></h2>
<p><span class="koboSpan" id="kobo.82.1">ML systems are</span><a id="_idIndexMarker005"/><span class="koboSpan" id="kobo.83.1"> comprised of three </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">main parts:</span></span></p>
<p><span class="koboSpan" id="kobo.85.1">The data-centric approach considers systematic data engineering the key to the next ML breakthroughs for </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1">two reasons:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.87.1">Firstly, a model’s training data typically carries the most potential for improvement because it is the foundational ingredient in </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">any model.</span></span></li>
<li><span class="koboSpan" id="kobo.89.1">Secondly, the code and infrastructure components of ML systems are much further advanced than our methods and processes for consistently capturing </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">quality data.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.91.1">Over the last few decades, we have experienced a huge evolution in ML algorithms, data science tools, and compute and storage capacity, and our approach to operationalizing data science solutions has matured through</span><a id="_idIndexMarker006"/><span class="koboSpan" id="kobo.92.1"> practices such as </span><strong class="bold"><span class="koboSpan" id="kobo.93.1">ML </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.94.1">operations</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.95.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.96.1">MLOps</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.97.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.98.1">Open source tools such as Python and R make it relatively cheap and accessible for almost anyone with a computer to learn how to produce, tune, and validate ML models. </span><span class="koboSpan" id="kobo.98.2">The popularity of these tools is underpinned by the availability of a large number of prebuilt packages that can be installed for free from public libraries. </span><span class="koboSpan" id="kobo.98.3">These packages allow users to use common ML algorithms with just a few lines </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">of code.</span></span></p>
<p><span class="koboSpan" id="kobo.100.1">At the other end of the tooling spectrum, low-code and no-code </span><strong class="bold"><span class="koboSpan" id="kobo.101.1">automated ML</span></strong><span class="koboSpan" id="kobo.102.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.103.1">AutoML</span></strong><span class="koboSpan" id="kobo.104.1">) tools </span><a id="_idIndexMarker007"/><span class="koboSpan" id="kobo.105.1">allow non-experts with limited or no coding experience to use ML techniques with a few </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">mouse clicks.</span></span></p>
<p><span class="koboSpan" id="kobo.107.1">The</span><a id="_idIndexMarker008"/><span class="koboSpan" id="kobo.108.1"> evolution in cloud computing has provided us with elastic compute and storage capacity that can be scaled up or down relatively easily when demand calls for it (beware of the </span><span class="No-Break"><span class="koboSpan" id="kobo.109.1">variable costs!).</span></span></p>
<p><span class="koboSpan" id="kobo.110.1">In other words, we have solved a lot of the technical constraints surrounding ML models. </span><span class="koboSpan" id="kobo.110.2">The biggest opportunity for further upside now lies in improving the availability, accuracy, consistency, completeness, validity, and uniqueness of </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">input data.</span></span></p>
<p><span class="koboSpan" id="kobo.112.1">Let’s take a closer look </span><span class="No-Break"><span class="koboSpan" id="kobo.113.1">at why.</span></span></p>
<h2 id="_idParaDest-21"><a id="_idTextAnchor020"/><span class="koboSpan" id="kobo.114.1">Data is the foundational ingredient</span></h2>
<p><span class="koboSpan" id="kobo.115.1">Think of the analogous example of a chef wanting to create a world-renowned Michelin Star restaurant. </span><span class="koboSpan" id="kobo.115.2">The chef has spent a long time learning how to combine flavors and textures into wonderful recipes that will leave patrons delighted. </span><span class="koboSpan" id="kobo.115.3">After many years of practicing and honing their craft, they are ready to open their restaurant. </span><span class="koboSpan" id="kobo.115.4">They know what it takes to make their restaurant </span><span class="No-Break"><span class="koboSpan" id="kobo.116.1">a success.</span></span></p>
<p><span class="koboSpan" id="kobo.117.1">At the front of the restaurant, they must have a nicely laid out dining room with comfortable furniture, set up in a way that lets their guests enjoy each other’s company. </span><span class="koboSpan" id="kobo.117.2">To serve the guests, they need great waiters who will attend to customers’ every need, making sure orders are taken, glasses are filled, and tables are kept clean </span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">and tidy.</span></span></p>
<p><span class="koboSpan" id="kobo.119.1">But that’s not all. </span><span class="koboSpan" id="kobo.119.2">A successful restaurant must also have a fully equipped commercial kitchen capable of producing many meals quickly and consistently, no matter how many orders are put through at the same time. </span><span class="koboSpan" id="kobo.119.3">And then, of course, there is the food. </span><span class="koboSpan" id="kobo.119.4">The chef has created a wonderful menu full of carefully crafted recipes that will provide their guests with unique and delightful flavor sensations. </span><span class="koboSpan" id="kobo.119.5">They are all set to open their soon-to-be </span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">award-winning restaurant.</span></span></p>
<p><span class="koboSpan" id="kobo.121.1">However, on opening night, there is a problem. </span><span class="koboSpan" id="kobo.121.2">Mold has gone through some of the vegetables in the pantry and they must be thrown away. </span><span class="koboSpan" id="kobo.121.3">Some herbs and spices are out of stock and hard to come by easily. </span><span class="koboSpan" id="kobo.121.4">Lastly, the most popular dish on the menu contains red cabbage, but only green cabbage was delivered by the supplier. </span><span class="koboSpan" id="kobo.121.5">As a result, the meals are not delightful flavor sensations, but rather bland and average. </span><span class="koboSpan" id="kobo.121.6">The chef has built a perfect operation and a wonderful menu but paid too little attention to the most important and hardest-to-control element: </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">the ingredients.</span></span></p>
<p><span class="koboSpan" id="kobo.123.1">The ingredients are produced outside the restaurant and delivered by several different suppliers. </span><span class="koboSpan" id="kobo.123.2">If one or more parts of the supply chain are not delivering, then the final output will suffer, no matter how talented the </span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">chef is.</span></span></p>
<p><span class="koboSpan" id="kobo.125.1">The story of the restaurant illustrates why a more systematic approach to engineering high-quality datasets is the key to </span><span class="No-Break"><span class="koboSpan" id="kobo.126.1">better models.</span></span></p>
<p><span class="koboSpan" id="kobo.127.1">Like the </span><a id="_idIndexMarker009"/><span class="koboSpan" id="kobo.128.1">superstar chef needing the best ingredients to make their meals exceptional, data scientists often fall short of building highly impactful models because the input data isn’t as good or accessible as it should be. </span><span class="koboSpan" id="kobo.128.2">Instead of rotten vegetables, we have mislabeled observations. </span><span class="koboSpan" id="kobo.128.3">Instead of out-of-stock ingredients, we have missing values. </span><span class="koboSpan" id="kobo.128.4">Instead of the wrong kind of cabbage, we have generic or high-level labels with limited predictive power. </span><span class="koboSpan" id="kobo.128.5">Instead of a network of food suppliers, we have a plethora of data sources and technical platforms that are rarely purpose-built </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">for ML.</span></span></p>
<p><span class="koboSpan" id="kobo.130.1">Part of the reason for this lack of maturity in data collection has to do with the maturity of ML as a capability relative to other disciplines in the computer science sphere. </span><span class="koboSpan" id="kobo.130.2">It is common for people with only a superficial understanding of ML to view ML systems the same way they understand traditional </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">software applications.</span></span></p>
<p><span class="koboSpan" id="kobo.132.1">However, unlike traditional software, ML systems produce variable outputs that depend on a combinatory set of ever-changing data inputs. </span><span class="koboSpan" id="kobo.132.2">In ML, the data is part of the code. </span><span class="koboSpan" id="kobo.132.3">This is important because the data holds the most potential for varying the final model output. </span><span class="koboSpan" id="kobo.132.4">The breadth, depth, and accuracy of input features and observations are foundational to building impactful and reliable models. </span><span class="koboSpan" id="kobo.132.5">If the dataset is unrepresentative of the real-world population or scenarios you are trying to predict, then the model is unlikely to </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">be useful.</span></span></p>
<p><span class="koboSpan" id="kobo.134.1">At the same time, the dataset will determine most of the potential biases of the model; that is, whether the model is more likely to produce results that incorrectly favor one group over another. </span><span class="koboSpan" id="kobo.134.2">In short, the input data is the source of the most variability in an ML model and we want to use this variability to our advantage rather than it being a risk or </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1">a hindrance.</span></span></p>
<p><span class="koboSpan" id="kobo.136.1">As we move from data to algorithms and on to system infrastructure, we want the ML system to become increasingly standardized and unvarying. </span><span class="koboSpan" id="kobo.136.2">Following a data-centric approach, we want to have lots of the right kind of variability in the data (not noise!) while keeping our ML algorithms and overall operational infrastructure robust and stable. </span><span class="koboSpan" id="kobo.136.3">That way, we can iteratively improve model accuracy by improving data quality, while keeping everything </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">else stable.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.138.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.139.1">.2</span></em><span class="koboSpan" id="kobo.140.1"> provides</span><a id="_idIndexMarker010"/><span class="koboSpan" id="kobo.141.1"> an overview of the facets associated with each of the three components of ML systems – data, code, </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">and infrastructure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer011">
<span class="koboSpan" id="kobo.143.1"><img alt="Figure 1.2 – The components of ML systems" src="image/B19297_01_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.144.1">Figure 1.2 – The components of ML systems</span></p>
<p><span class="koboSpan" id="kobo.145.1">Under a data-centric approach, high-quality data is the foundation for robust ML systems. </span><span class="koboSpan" id="kobo.145.2">The biggest opportunities to improve an ML model are typically found in the input data rather than </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">the code.</span></span></p>
<p><span class="koboSpan" id="kobo.147.1">While it makes a lot of sense to focus on data quality over changes to model parameters, data scientists tend to focus on the latter because it is a lot easier to implement in the short term. </span><span class="koboSpan" id="kobo.147.2">Multiple models and hyperparameters can typically be tested within a very short timeframe following a traditional model-centric approach, but increasing the signal and reducing the noise in your modeling dataset seems like a complex and </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">time-consuming exercise.</span></span></p>
<p><span class="koboSpan" id="kobo.149.1">In part, this is because systematically improved data collection typically involves upstream process changes and the participation of various stakeholders in the organization. </span><span class="koboSpan" id="kobo.149.2">That is rarely something data scientists can do alone, and it requires the overall organization to appreciate the value and potential of data science to commit the appropriate time and resources to better data collection. </span><span class="koboSpan" id="kobo.149.3">Unfortunately, most organizations </span><a id="_idIndexMarker011"/><span class="koboSpan" id="kobo.150.1">waste more resources building and implementing suboptimal models based on poor data than the resources it would take to collect </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">better data.</span></span></p>
<p><span class="koboSpan" id="kobo.152.1">As we will learn in the following sections, a well-designed data-centric approach can overcome this challenge and usually unlocks many new ML opportunities in an organization. </span><span class="koboSpan" id="kobo.152.2">This is because data-centric ML requires everyone involved in the data pipeline to think more holistically about the structure and purpose of an </span><span class="No-Break"><span class="koboSpan" id="kobo.153.1">organization’s data.</span></span></p>
<p><span class="koboSpan" id="kobo.154.1">To further understand and appreciate the potential of a data-centric approach to model development, let’s compare data centricity with the more dominant </span><span class="No-Break"><span class="koboSpan" id="kobo.155.1">model-centric approach.</span></span></p>
<h1 id="_idParaDest-22"><a id="_idTextAnchor021"/><span class="koboSpan" id="kobo.156.1">Data-centric versus model-centric ML</span></h1>
<p><span class="koboSpan" id="kobo.157.1">So far, we</span><a id="_idIndexMarker012"/><span class="koboSpan" id="kobo.158.1"> have established that data centricity is about systematically engineering the data used to build ML models. </span><span class="koboSpan" id="kobo.158.2">The conventional and more prevalent model-centric approach to ML suggests that optimizing the model itself is the key to </span><span class="No-Break"><span class="koboSpan" id="kobo.159.1">better performance.</span></span></p>
<p><span class="koboSpan" id="kobo.160.1">As illustrated in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.161.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.162.1">.3</span></em><span class="koboSpan" id="kobo.163.1">, the central objective of a model-centric approach is improving the code underlying the model. </span><span class="koboSpan" id="kobo.163.2">Under a data-centric approach, the goal is to find a much larger upside in improved </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">data quality:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer012">
<span class="koboSpan" id="kobo.165.1"><img alt="Figure 1.3 – Building ML solutions via model-centric and data-centric workflows" src="image/B19297_01_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.166.1">Figure 1.3 – Building ML solutions via model-centric and data-centric workflows</span></p>
<p><span class="koboSpan" id="kobo.167.1">ML model</span><a id="_idIndexMarker013"/><span class="koboSpan" id="kobo.168.1"> development has traditionally focused on improving model performance mainly by optimizing the code. </span><span class="koboSpan" id="kobo.168.2">Under a data-centric approach, the focus shifts to achieving even larger performance enhancements, mainly by iteratively improving data quality. </span><span class="koboSpan" id="kobo.168.3">It is important to note that the data-centric approach sits on top of the principles and techniques that underpin model-centric ML, rather than replacing them. </span><span class="koboSpan" id="kobo.168.4">Both approaches consider the model and the data critical components of ML solutions. </span><span class="koboSpan" id="kobo.168.5">A solution will fail if either of the two is misconfigured, buggy, biased, or </span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">applied incorrectly.</span></span></p>
<p><span class="koboSpan" id="kobo.170.1">Model configuration is an important step under a data-centric approach and in the very short term, it is certainly quicker to seek incremental gains in model performance by optimizing the code. </span><span class="koboSpan" id="kobo.170.2">However, as we’ve discussed, there is limited upside in changing the recipe if you don’t have the right ingredients. </span><span class="koboSpan" id="kobo.170.3">In other words, the difference between the two approaches lies in where we put our focus and efforts into iteratively improving </span><span class="No-Break"><span class="koboSpan" id="kobo.171.1">model performance.</span></span></p>
<p><span class="koboSpan" id="kobo.172.1">As illustrated in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.173.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.174.1">.4</span></em><span class="koboSpan" id="kobo.175.1">, a model-centric approach treats the data as fixed input and focuses on model selection, parameter tuning, feature engineering, and adding more data as the main ways to improve model performance. </span><span class="koboSpan" id="kobo.175.2">A data-centric approach considers the model somewhat static and focuses on improving performance mainly through </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">data quality.</span></span></p>
<p><span class="koboSpan" id="kobo.177.1">Following a model-centric approach, we attempt to collect as much data as possible to crowd out any outliers in the data and reduce bias – the bigger the dataset, the better. </span><span class="koboSpan" id="kobo.177.2">Then, we engineer our model(s) to be as predictive as possible </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">without overfitting.</span></span></p>
<p><span class="koboSpan" id="kobo.179.1">This is in contrast</span><a id="_idIndexMarker014"/><span class="koboSpan" id="kobo.180.1"> to a data-centric approach, which has better data collection and labeling at source, on top of model selection and tuning. </span><span class="koboSpan" id="kobo.180.2">Data quality is improved even further through outlier detection, programmatic labeling, more systematic feature engineering, and synthetic data creation (these techniques are explained in depth in </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">subsequent chapters):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer013">
<span class="koboSpan" id="kobo.182.1"><img alt="Figure 1.4 – Comparing model-centric and data-centric ML approaches" src="image/B19297_01_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.183.1">Figure 1.4 – Comparing model-centric and data-centric ML approaches</span></p>
<p><span class="koboSpan" id="kobo.184.1">ML model improvement comes from two areas: improving the code and improving the data. </span><span class="koboSpan" id="kobo.184.2">While data collection and engineering processes might sound like a data engineer’s job, they really should be a key part of the data </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">scientist’s toolbox.</span></span></p>
<p><span class="koboSpan" id="kobo.186.1">Let’s take a look at what’s required of data scientists, data engineers, and other stakeholders under a </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">data-centric approach.</span></span></p>
<h2 id="_idParaDest-23"><a id="_idTextAnchor022"/><span class="koboSpan" id="kobo.188.1">Data centricity is a team sport</span></h2>
<p><span class="koboSpan" id="kobo.189.1">While it </span><a id="_idIndexMarker015"/><span class="koboSpan" id="kobo.190.1">makes a lot of sense to focus on data quality over changes to model parameters, data scientists tend to focus on the latter because it is a lot easier to implement in the short term. </span><span class="koboSpan" id="kobo.190.2">Multiple models and hyperparameters can typically be tested within a very short timeframe following a traditional model-centric approach, but increasing the signal and reducing the noise in your modeling dataset seems like a complex and time-consuming exercise that can’t easily be dealt with by a small team. </span><span class="koboSpan" id="kobo.190.3">Data-centric ML takes a lot more effort across the organization, whereas a model-centric approach largely relies on the data scientist’s skills and tools to increase </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">model performance.</span></span></p>
<p><span class="koboSpan" id="kobo.192.1">Data centricity is a team sport. </span><span class="koboSpan" id="kobo.192.2">Data centricity requires data scientists and others involved in ML development to acquire a new set of data quality-specific skills. </span><span class="koboSpan" id="kobo.192.3">The most important of these new data-centric skills and techniques is what we will teach you in </span><span class="No-Break"><span class="koboSpan" id="kobo.193.1">this book.</span></span></p>
<p><span class="koboSpan" id="kobo.194.1">Data </span><a id="_idIndexMarker016"/><span class="koboSpan" id="kobo.195.1">capture and labeling processes must be designed with data science in mind and performed by professionals with at least a foundational understanding of ML development. </span><span class="koboSpan" id="kobo.195.2">Data engineering processes and ETL layers must be structured to identify data quality issues and allow for iterative improvement of ML input data. </span><span class="koboSpan" id="kobo.195.3">All of this requires continuous collaboration between data scientists, data collectors, subject matter experts, data engineers, business leaders, and others involved in turning data </span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">into insights.</span></span></p>
<p><span class="koboSpan" id="kobo.197.1">To illustrate this point, </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.198.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.199.1">.5</span></em><span class="koboSpan" id="kobo.200.1"> compares the data-to-model process for both approaches. </span><span class="koboSpan" id="kobo.200.2">Depending on the size and purpose of your organization, there may be a wide range of roles involved in delivering ML solutions, such as data architects, ML engineers, data labelers, analysts, model validators, decision makers, project managers, and </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">product owners.</span></span></p>
<p><span class="koboSpan" id="kobo.202.1">However, in our simplified diagram in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.203.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.204.1">.5</span></em><span class="koboSpan" id="kobo.205.1">, three types of roles are involved in the process – a data scientist, a data engineer, and a subject </span><span class="No-Break"><span class="koboSpan" id="kobo.206.1">matter expert:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer014">
<span class="koboSpan" id="kobo.207.1"><img alt="Figure 1.5 – Data-centric versus model-centric roles and responsibilities" src="image/B19297_01_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.208.1">Figure 1.5 – Data-centric versus model-centric roles and responsibilities</span></p>
<p><span class="koboSpan" id="kobo.209.1">Stakeholders</span><a id="_idIndexMarker017"/><span class="koboSpan" id="kobo.210.1"> at the top of the data pipeline must be active participants in the process for an organization to be good at data collection and engineering for ML purposes. </span><span class="koboSpan" id="kobo.210.2">In short, data centricity requires a lot </span><span class="No-Break"><span class="koboSpan" id="kobo.211.1">of teamwork.</span></span></p>
<p><span class="koboSpan" id="kobo.212.1">Under a conventional model-centric approach, data creation typically starts with a data collection process, which may be automated, manual, or a mix of both. </span><span class="koboSpan" id="kobo.212.2">Examples include a customer entering details into a web page, a radiographer performing a CT scan, or a call center operator taking a recorded call. </span><span class="koboSpan" id="kobo.212.3">At this point, data has been captured for its primary operational purpose, but through the work of the data engineer, this information can also be transformed into an analytical dataset. </span><span class="koboSpan" id="kobo.212.4">The typical process requires a data engineer to extract, transform, and normalize the data in a database, data lake, data warehouse, </span><span class="No-Break"><span class="koboSpan" id="kobo.213.1">or equivalent.</span></span></p>
<p><span class="koboSpan" id="kobo.214.1">Once a data scientist gets a hold of the data, it typically goes through several steps to ensure accuracy, consistency, validity, and integrity are maintained. </span><span class="koboSpan" id="kobo.214.2">In other words, the data should be ready for use; however, any data scientist knows that this is rarely </span><span class="No-Break"><span class="koboSpan" id="kobo.215.1">the case.</span></span></p>
<p><span class="koboSpan" id="kobo.216.1">A common heuristic in data science is that 80% of the time it takes to build a new ML model is spent on finding, cleaning, and preparing the modeling data for use, while only 20% is spent on analysis and model building. </span><span class="koboSpan" id="kobo.216.2">Traditionally, this has been seen as a problem because data scientists are paid to work with the data to build models and perform analyses, and not spend most of their time </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1">preparing it.</span></span></p>
<p><span class="koboSpan" id="kobo.218.1">Following a </span><a id="_idIndexMarker018"/><span class="koboSpan" id="kobo.219.1">data-centric approach, data preparation becomes the most important part of the model-building process. </span><span class="koboSpan" id="kobo.219.2">Instead of asking "</span><em class="italic"><span class="koboSpan" id="kobo.220.1">how might we minimize the time spent on data prep?",</span></em><span class="koboSpan" id="kobo.221.1"> we instead ask "</span><em class="italic"><span class="koboSpan" id="kobo.222.1">how might we systematically optimize data collection and preparation?"</span></em><span class="koboSpan" id="kobo.223.1"> The problem is not that data scientists are spending a lot of time learning and enhancing their datasets. </span><span class="koboSpan" id="kobo.223.2">The problem is a lack of connectivity between ML development and other upstream data activities that allow data scientists, engineers, and subject matter experts to co-create faster and more </span><span class="No-Break"><span class="koboSpan" id="kobo.224.1">accurate results.</span></span></p>
<p><span class="koboSpan" id="kobo.225.1">In essence, data centricity is about establishing the processes, tools, and techniques to do this systematically. </span><span class="koboSpan" id="kobo.225.2">Subject matter experts are actively involved in key parts of the ML development process, including identifying outliers, validating data labels and model predictions, and developing new features and attributes that should be captured in </span><span class="No-Break"><span class="koboSpan" id="kobo.226.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.227.1">Data engineers and data scientists also gain additional responsibilities under a data-centric approach. </span><span class="koboSpan" id="kobo.227.2">The data engineer’s responsibilities must expand from building and maintaining data pipelines to being more directly involved in developing and maintaining high-quality features and labels for specific ML solutions. </span><span class="koboSpan" id="kobo.227.3">In turn, this requires data engineers and data scientists to understand each other’s roles and collaborate towards </span><span class="No-Break"><span class="koboSpan" id="kobo.228.1">common goals.</span></span></p>
<p><span class="koboSpan" id="kobo.229.1">In the next section, we will illustrate, through applied examples, the impact a data-centric approach can have on </span><span class="No-Break"><span class="koboSpan" id="kobo.230.1">ML opportunities.</span></span></p>
<h1 id="_idParaDest-24"><a id="_idTextAnchor023"/><span class="koboSpan" id="kobo.231.1">The importance of quality data in ML</span></h1>
<p><span class="koboSpan" id="kobo.232.1">So far, we</span><a id="_idIndexMarker019"/><span class="koboSpan" id="kobo.233.1"> have defined what data-centric ML is and how it compares to the conventional model-centric approach. </span><span class="koboSpan" id="kobo.233.2">In this section, we will examine what</span><a id="_idIndexMarker020"/><span class="koboSpan" id="kobo.234.1"> good data looks like </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">in practice.</span></span></p>
<p><span class="koboSpan" id="kobo.236.1">From a data-centric perspective, good data is </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1">as follows</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.238.1">5</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.240.1">Captured consistently</span></strong><span class="koboSpan" id="kobo.241.1">: Independent (</span><em class="italic"><span class="koboSpan" id="kobo.242.1">x</span></em><span class="koboSpan" id="kobo.243.1">) and dependent variables (</span><em class="italic"><span class="koboSpan" id="kobo.244.1">y</span></em><span class="koboSpan" id="kobo.245.1">) are </span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">labeled unambiguously</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.247.1">Full of signal and free of noise</span></strong><span class="koboSpan" id="kobo.248.1">: Input data covers a wide range of important observations and events in the smallest number of </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">observations possible</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.250.1">Designed for the business problem</span></strong><span class="koboSpan" id="kobo.251.1">: Data is designed and collected specifically for solving a business problem with ML, rather than the problem being solved with whatever data is </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">already available</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.253.1">Timely and relevant</span></strong><span class="koboSpan" id="kobo.254.1">: Independent and dependent variables provide an accurate representation of current trends (no data or </span><span class="No-Break"><span class="koboSpan" id="kobo.255.1">concept drift)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.256.1">At first </span><a id="_idIndexMarker021"/><span class="koboSpan" id="kobo.257.1">glance, this </span><a id="_idIndexMarker022"/><span class="koboSpan" id="kobo.258.1">sort of systematic data collection seems both expensive and time-consuming. </span><span class="koboSpan" id="kobo.258.2">However, in our experience, highly deliberate data collection is often a foundational requirement for getting the desired results </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">with ML.</span></span></p>
<p><span class="koboSpan" id="kobo.260.1">To appreciate the importance and potential of data centricity, let’s look at some applied examples of how data quality and systematic engineering of features make all </span><span class="No-Break"><span class="koboSpan" id="kobo.261.1">the difference.</span></span></p>
<h2 id="_idParaDest-25"><a id="_idTextAnchor024"/><span class="koboSpan" id="kobo.262.1">Identifying high-value legal cases with natural language processing</span></h2>
<p><span class="koboSpan" id="kobo.263.1">Our first </span><a id="_idIndexMarker023"/><span class="koboSpan" id="kobo.264.1">example of the pivotal importance of data quality comes from an ML solution built by Jonas and Manmohan at a large Australian legal </span><span class="No-Break"><span class="koboSpan" id="kobo.265.1">services firm.</span></span></p>
<p><span class="koboSpan" id="kobo.266.1">ML is a nascent discipline in legal services relative to comparable service industries such as banking, insurance, utilities, and telecommunications. </span><span class="koboSpan" id="kobo.266.2">This is due to the nature and complexity of the data available in legal services, as well as the risks and ethics associated with using ML in a </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">legal setting.</span></span></p>
<p><span class="koboSpan" id="kobo.268.1">Although the legal services industry is incredibly data-rich, data is often collected manually, stored in a textual format, and highly contextual to the particulars of the legal case. </span><span class="koboSpan" id="kobo.268.2">This textual data may come in a variety of formats, such as letters from medical professionals, legal contracts, counterparty communications, emails between lawyer and client, case notes, and </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">audio recordings.</span></span></p>
<p><span class="koboSpan" id="kobo.270.1">On top of that, the legal services industry is a high-stakes environment where a mistake or omission made by one party can win or lose the case altogether. </span><span class="koboSpan" id="kobo.270.2">Because of this, legal professionals tend to spend a lot of time and effort reviewing detailed documents and keeping track of key dates and steps in the legal process. </span><span class="koboSpan" id="kobo.270.3">The devil is in </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">the detail!</span></span></p>
<p><span class="koboSpan" id="kobo.272.1">The</span><a id="_idIndexMarker024"/><span class="koboSpan" id="kobo.273.1"> legal services firm is a no-win-no-fee plaintiff law firm representing people who have been injured or wronged physically or financially. </span><span class="koboSpan" id="kobo.273.2">The company fights on behalf of individuals or groups against the more powerful counterparties, such as insurance firms, negligent hospitals or doctors, and misbehaving corporations. </span><span class="koboSpan" id="kobo.273.3">The client only pays a fee if they win – otherwise, the firm bears </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">the loss.</span></span></p>
<p><span class="koboSpan" id="kobo.275.1">In 2022, the business identified an opportunity to use data science to find rare but high-value cases that could then be fast-tracked by specialist lawyers. </span><span class="koboSpan" id="kobo.275.2">The earlier in the process that these high-value cases could be identified, the better. </span><span class="koboSpan" id="kobo.275.3">So, the goal was to recognize them in the very first interview with </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">prospective clients.</span></span></p>
<p><span class="koboSpan" id="kobo.277.1">The initial project design followed a conventional model-centric approach. </span><span class="koboSpan" id="kobo.277.2">The data science team collected 2 years’ worth of case notes from prospective client interviews and created a flag for cases that had later turned out to be high-value (the dependent variable, </span><em class="italic"><span class="koboSpan" id="kobo.278.1">y</span></em><span class="koboSpan" id="kobo.279.1">). </span><span class="koboSpan" id="kobo.279.2">The team also used topic modeling to engineer new features to be included in the final input dataset. </span><strong class="bold"><span class="koboSpan" id="kobo.280.1">Topic modeling</span></strong><span class="koboSpan" id="kobo.281.1"> is an unsupervised ML technique that’s used to detect</span><a id="_idIndexMarker025"/><span class="koboSpan" id="kobo.282.1"> patterns across various documents or text snippets that can be grouped into </span><em class="italic"><span class="koboSpan" id="kobo.283.1">topics</span></em><span class="koboSpan" id="kobo.284.1">. </span><span class="koboSpan" id="kobo.284.2">These topics were then used as direct input into the initial model and also as a tool to explain </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">model predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.286.1">The initial model proved reasonably predictive, but the team faced several challenges that could only be solved by taking a </span><span class="No-Break"><span class="koboSpan" id="kobo.287.1">data-centric approach:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.288.1">Less than a thousand high-value cases were opened on an annual basis, so this was a </span><em class="italic"><span class="koboSpan" id="kobo.289.1">small data</span></em><span class="koboSpan" id="kobo.290.1"> problem, even </span><span class="No-Break"><span class="koboSpan" id="kobo.291.1">after oversampling.</span></span></li>
<li><span class="koboSpan" id="kobo.292.1">The main predictors were captured from case notes, which were in a semi-structured or unstructured format, and often free text. </span><span class="koboSpan" id="kobo.292.2">Although case notes followed some standards, each note taker had used their distinct vocabulary, shortenings, and formatting, making it difficult to create a standardized </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">modeling dataset.</span></span></li>
<li><span class="koboSpan" id="kobo.294.1">Because the input data was largely in free-text format, some very important facts were too vague for the model to pick up. </span><span class="koboSpan" id="kobo.294.2">For instance, it was important whether the legal case involved more than one injured person as this could change the case strategy altogether. </span><span class="koboSpan" id="kobo.294.3">Sometimes, each injured party would be called out explicitly and other times just referred to </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">as </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.296.1">they</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.298.1">Some details were left out of the case notes because they were either assumed knowledge by legal professionals or they would be obvious to a human reading the document as a whole. </span><span class="koboSpan" id="kobo.298.2">Unfortunately, this was not helpful to a </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">learning algorithm.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.300.1">The </span><a id="_idIndexMarker026"/><span class="koboSpan" id="kobo.301.1">team decided to take a data-centric approach and formed a cross-functional project team comprising a highly skilled lawyer, a data scientist, a data engineer, an operations manager, and a call center expert. </span><span class="koboSpan" id="kobo.301.2">Everyone on the team was an expert in one part of the overall process and together they provided lots of depth and breadth across client experience, legal, data, and </span><span class="No-Break"><span class="koboSpan" id="kobo.302.1">operational processes.</span></span></p>
<p><span class="koboSpan" id="kobo.303.1">Rather than improving model accuracy through feature engineering, the team altered the data capture altogether by designing a set of client questions that were highly predictive of whether a case was high value. </span><span class="koboSpan" id="kobo.303.2">The criteria for new questions were </span><span class="No-Break"><span class="koboSpan" id="kobo.304.1">as follows:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.305.1">It must provide very specific details on whether a case was high value </span><span class="No-Break"><span class="koboSpan" id="kobo.306.1">or not</span></span></li>
<li><span class="koboSpan" id="kobo.307.1">The format must be easily interpretable by humans and </span><span class="No-Break"><span class="koboSpan" id="kobo.308.1">algorithms alike</span></span></li>
<li><span class="koboSpan" id="kobo.309.1">It must be easy for the prospective client to answer new questions and the call center operator to capture </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">the information</span></span></li>
<li><span class="koboSpan" id="kobo.311.1">It must be easy to create a triaging process around the captured data such that the call center operator can take the right </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">action immediately</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.313.1">The previously mentioned criteria highlight why it is important to involve a wide group of subject matter experts in developing ML solutions. </span><span class="koboSpan" id="kobo.313.2">Everyone in the cross-functional team had specific knowledge that contributed to the finer details of the </span><span class="No-Break"><span class="koboSpan" id="kobo.314.1">overall solution.</span></span></p>
<p><span class="koboSpan" id="kobo.315.1">The team identified a handful of key questions that would be highly predictive of whether a case was high-value. </span><span class="koboSpan" id="kobo.315.2">These questions needed to be so specific that they could only be answered with a yes, no, or a quantity. </span><span class="koboSpan" id="kobo.315.3">For example, rather than looking for the word </span><em class="italic"><span class="koboSpan" id="kobo.316.1">they</span></em><span class="koboSpan" id="kobo.317.1"> in a free text field, the call center operator could simply ask </span><em class="italic"><span class="koboSpan" id="kobo.318.1">how many people were involved in the incident?</span></em><span class="koboSpan" id="kobo.319.1"> and record only a </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">numeric answer:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer015">
<span class="koboSpan" id="kobo.321.1"><img alt="Figure 1.6 – Hypothetical case notes before and after data-centric improvements" src="image/B19297_01_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.322.1">Figure 1.6 – Hypothetical case notes before and after data-centric improvements</span></p>
<p><span class="koboSpan" id="kobo.323.1">With</span><a id="_idIndexMarker027"/><span class="koboSpan" id="kobo.324.1"> these questions answered, every prospective case could be grouped into high, medium, and low probability of being a high-value case. </span><span class="koboSpan" id="kobo.324.2">The team then built a simple process that allowed call center operators to direct high-probability cases straight into a fast-track process handled by specialized lawyers. </span><span class="koboSpan" id="kobo.324.3">Other cases would continue to be monitored using an ML model to detect new facts that may push them into </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">high-value territory.</span></span></p>
<p><span class="koboSpan" id="kobo.326.1">The final solution was a success because it helped identify high-value cases faster and more accurately, but the benefits of taking a data-centric approach were much broader than that. </span><span class="koboSpan" id="kobo.326.2">The focus on improved data collection didn’t just create better data for ML purposes. </span><span class="koboSpan" id="kobo.326.3">It created a different kind of collaboration between people from across the business, ultimately leading to better-defined processes and a stronger focus on optimizing key moments in the </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">client journey.</span></span></p>
<h2 id="_idParaDest-26"><a id="_idTextAnchor025"/><span class="koboSpan" id="kobo.328.1">Predicting cardiac arrests in emergency calls</span></h2>
<p><span class="koboSpan" id="kobo.329.1">Another</span><a id="_idIndexMarker028"/><span class="koboSpan" id="kobo.330.1"> example comes from an </span><a id="_idIndexMarker029"/><span class="koboSpan" id="kobo.331.1">experimental study conducted at the </span><strong class="bold"><span class="koboSpan" id="kobo.332.1">Emergency Medical Dispatch Center</span></strong><span class="koboSpan" id="kobo.333.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.334.1">EMDC</span></strong><span class="koboSpan" id="kobo.335.1">) in </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">Copenhagen, Denmark</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.337.1">6</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.339.1">A team led by medical researcher </span><em class="italic"><span class="koboSpan" id="kobo.340.1">Stig Blomberg</span></em><span class="koboSpan" id="kobo.341.1"> worked to examine whether an ML solution could be used to identify out-of-hospital cardiac arrest by listening to the calls made to </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">the EMDC.</span></span></p>
<p><span class="koboSpan" id="kobo.343.1">The team trained and tested an ML model using audio recordings of emergency calls generated in 2014, with the primary goal of assisting medical dispatchers in the early detection of cardiac </span><span class="No-Break"><span class="koboSpan" id="kobo.344.1">arrest calls.</span></span></p>
<p><span class="koboSpan" id="kobo.345.1">The study found the ML solution to be faster and more accurate at identifying cases of cardiac arrest as measured by the model’s sensitivity. </span><span class="koboSpan" id="kobo.345.2">However, the researchers also discovered the following </span><a id="_idIndexMarker030"/><span class="koboSpan" id="kobo.346.1">limitations in following a </span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">model-centric approach:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.348.1">With no ability for structured feedback between ambulance paramedics and dispatchers, there was a lack of </span><em class="italic"><span class="koboSpan" id="kobo.349.1">learning</span></em><span class="koboSpan" id="kobo.350.1"> in the system. </span><span class="koboSpan" id="kobo.350.2">For instance, it would likely be possible to improve human and machine predictions of cardiac arrest by asking tailored and more structured questions of the caller, such as "</span><em class="italic"><span class="koboSpan" id="kobo.351.1">does he look pale?"</span></em><span class="koboSpan" id="kobo.352.1"> or "</span><em class="italic"><span class="koboSpan" id="kobo.353.1">can </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.354.1">he move?".</span></em></span></li>
<li><span class="koboSpan" id="kobo.355.1">Language barriers of non-native speakers impacted model performance. </span><span class="koboSpan" id="kobo.355.2">The ML solution worked best with Danish-speaking callers and was worse at identifying cardiac arrests in foreign-accent calls than the human dispatchers who might speak </span><span class="No-Break"><span class="koboSpan" id="kobo.356.1">several languages.</span></span></li>
<li><span class="koboSpan" id="kobo.357.1">Although the solution had a higher sensitivity (detection of true positives) than human dispatchers, less than one in five alerts were true positives. </span><span class="koboSpan" id="kobo.357.2">This created a high risk of alert fatigue among dispatchers, who ultimately bear the risk of acting on ML recommendations </span><span class="No-Break"><span class="koboSpan" id="kobo.358.1">or not.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.359.1">This case study is another prime example of an ML use case that requires a data-centric approach to achieve optimal results while managing risks and </span><span class="No-Break"><span class="koboSpan" id="kobo.360.1">ethics appropriately.</span></span></p>
<p><span class="koboSpan" id="kobo.361.1">Firstly, an ML solution classifying cardiac arrest calls will only ever be based on </span><em class="italic"><span class="koboSpan" id="kobo.362.1">small data</span></em><span class="koboSpan" id="kobo.363.1"> due to the nature and complexity of the underlying problem. </span><span class="koboSpan" id="kobo.363.2">In this case, it is not necessarily possible to just add more data to improve </span><span class="No-Break"><span class="koboSpan" id="kobo.364.1">model performance.</span></span></p>
<p><span class="koboSpan" id="kobo.365.1">With about 1,000 true cardiac arrests being reported per year from a population of circa 1.8 million people in Greater Copenhagen, even years’ worth of call recordings would not add up to a large dataset. </span><span class="koboSpan" id="kobo.365.2">Once you consider the many subsets in the data, such as foreign language speakers and those with non-native accents, the data becomes even </span><span class="No-Break"><span class="koboSpan" id="kobo.366.1">more fragmented.</span></span></p>
<p><span class="koboSpan" id="kobo.367.1">The risks</span><a id="_idIndexMarker031"/><span class="koboSpan" id="kobo.368.1"> and ethical concerns associated with producing wrong predictions (especially false negatives) for life-and-death situations mean that data labels must be carefully curated until any biases are reduced to an acceptable minimum. </span><span class="koboSpan" id="kobo.368.2">This requires an iterative process of reviewing data quality and enhancing </span><span class="No-Break"><span class="koboSpan" id="kobo.369.1">model features.</span></span></p>
<p><span class="koboSpan" id="kobo.370.1">Classifying cardiac arrest cases based on a short phone conversation is a complex exercise. </span><span class="koboSpan" id="kobo.370.2">It requires subject matter expertise, as well as training and experience from dispatchers and paramedics alike. </span><span class="koboSpan" id="kobo.370.3">Building a quality natural language dataset for ML purposes is largely about reducing ambiguity in the interpretation of the signal you’re looking for. </span><span class="koboSpan" id="kobo.370.4">This, in turn, requires the organization to define what matters in the process that is being modeled by involving subject matter experts in the design. </span><span class="koboSpan" id="kobo.370.5">You will learn how this is done in </span><a href="B19297_04.xhtml#_idTextAnchor056"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.371.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.372.1">, </span><em class="italic"><span class="koboSpan" id="kobo.373.1">Data Labeling is a </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.374.1">Collaborative Process</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.376.1">Being specific in how questions are asked and answered creates clarity for human agents (in this case, the dispatchers), as well as ML models. </span><span class="koboSpan" id="kobo.376.2">This example highlights how data centricity is not just about collecting better data for ML models. </span><span class="koboSpan" id="kobo.376.3">It is a golden opportunity to be more deliberate in defining and improving how people work and collaborate across </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">the organization.</span></span></p>
<p><span class="koboSpan" id="kobo.378.1">The two case studies you have just read through highlight the importance of carefully collecting and curating datasets to be high quality in terms of accuracy, validity, and contextual relevance. </span><span class="koboSpan" id="kobo.378.2">In some situations, data quality can be a matter of life </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">and death!</span></span></p>
<p><span class="koboSpan" id="kobo.380.1">As you will learn in </span><a href="B19297_02.xhtml#_idTextAnchor028"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.381.1">Chapter 2</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.382.1">, From Model-Centric to Data-Centric – ML’s Evolution</span></em><span class="koboSpan" id="kobo.383.1">, there is huge potential for ML to be a fantastic tool in high-stakes domains such as legal services and healthcare, so long as we can manage the risks associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.384.1">data quality.</span></span></p>
<p><span class="koboSpan" id="kobo.385.1">Now that we’ve discussed the different aspects of data-centric ML, let’s summarize what we’ve learned in </span><span class="No-Break"><span class="koboSpan" id="kobo.386.1">this chapter.</span></span></p>
<h1 id="_idParaDest-27"><a id="_idTextAnchor026"/><span class="koboSpan" id="kobo.387.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.388.1">In this chapter, we discussed the fundamentals of data-centric ML and its origins. </span><span class="koboSpan" id="kobo.388.2">We also learned how data centricity differs from model centricity, including the roles and responsibilities of key stakeholders in a typical organization using ML. </span><span class="koboSpan" id="kobo.388.3">At this point, you should have a solid understanding of data-centric ML and its additional potential compared to a more traditional model-centric approach. </span><span class="koboSpan" id="kobo.388.4">Hopefully, this will encourage you to use data-centric ML for your </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">next project.</span></span></p>
<p><span class="koboSpan" id="kobo.390.1">In the next chapter, we will discover why ML development has been mostly model-centric until now and explore further why data centricity is the key to the next phase of the evolution </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1">of AI.</span></span></p>
<h1 id="_idParaDest-28"><a id="_idTextAnchor027"/><span class="koboSpan" id="kobo.392.1">References</span></h1>
<ol>
<li><a href="https://datacentricai.org/"><span class="koboSpan" id="kobo.393.1">https://datacentricai.org/</span></a><span class="koboSpan" id="kobo.394.1">, viewed 10 </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">July 2022</span></span></li>
<li><a href="https://www.andrewng.org/"><span class="koboSpan" id="kobo.396.1">https://www.andrewng.org/</span></a><span class="koboSpan" id="kobo.397.1"> and </span><a href="https://www.coursera.org/instructor/andrewng"><span class="koboSpan" id="kobo.398.1">https://www.coursera.org/instructor/andrewng</span></a><span class="koboSpan" id="kobo.399.1">, viewed 6 </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1">July 2022</span></span></li>
<li><a href="https://www.youtube.com/watch?v=06-AZXmwHjo"><span class="koboSpan" id="kobo.401.1">https://www.youtube.com/watch?v=06-AZXmwHjo</span></a><span class="koboSpan" id="kobo.402.1">, viewed 2 </span><span class="No-Break"><span class="koboSpan" id="kobo.403.1">August 2022</span></span></li>
<li><a href="https://ahrefs.com/blog/long-tail-keywords/"><span class="koboSpan" id="kobo.404.1">https://ahrefs.com/blog/long-tail-keywords/</span></a><span class="koboSpan" id="kobo.405.1">, viewed 2 </span><span class="No-Break"><span class="koboSpan" id="kobo.406.1">August 2022</span></span></li>
<li><span class="koboSpan" id="kobo.407.1">Derived from </span><em class="italic"><span class="koboSpan" id="kobo.408.1">A Chat with Andrew on MLOps – From Model-centric to Data-Centric AI</span></em><span class="koboSpan" id="kobo.409.1">: </span><a href="https://www.youtube.com/watch?v=06-AZXmwHjo"><span class="koboSpan" id="kobo.410.1">https://www.youtube.com/watch?v=06-AZXmwHjo</span></a><span class="koboSpan" id="kobo.411.1">, viewed 2 </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1">August 2022</span></span></li>
<li><span class="koboSpan" id="kobo.413.1">Zicari et al.: </span><em class="italic"><span class="koboSpan" id="kobo.414.1">On assessing trustworthy AI in healthcare: Best practice for machine learning as a supportive tool to recognize cardiac arrest in emergency calls</span></em><span class="koboSpan" id="kobo.415.1">. </span><span class="koboSpan" id="kobo.415.2">Frontiers in Human </span><span class="No-Break"><span class="koboSpan" id="kobo.416.1">Dynamics (2021)</span></span></li>
</ol>
</div>
</body></html>