["```py\n    # Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n    movielens_data_url = (\n        \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\")\n    movielens_zip_file = keras.utils.get_file(\n        \"ml-latest-small.zip\", movielens_data_url, extract=False)\n    movie_datasets_path = Path(movielens_zip_file).parents[0]\n    movielens_dir = movie_datasets_path / \"ml-latest-small\"\n    with ZipFile(movielens_zip_file, \"r\") as zip:\n    zip.extractall(path=movie_datasets_path)\n    ```", "```py\n    # Load the Movie Ratings file\n    ratings_file = movielens_dir / \"ratings.csv\"\n    df = pd.read_csv(ratings_file)\n    ```", "```py\n    # Extract the unique user IDs from the 'userId' column and convert them to a list\n    user_ids = df[\"userId\"].unique().tolist()\n    # Create a dictionary that maps each user ID to a unique integer (encoded form)\n    user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n    # Create a dictionary that maps each unique integer back to its original user ID\n    userencoded2user = {i: x for i, x in enumerate(user_ids)}\n    # Extract the unique movie IDs from the 'movieId' column and convert them to a list\n    movie_ids = df[\"movieId\"].unique().tolist()\n    # Create a dictionary that maps each movie ID to a unique integer (encoded form)\n    movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n    # Create a dictionary that maps each unique integer back to its original movie ID\n    movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n    # Map the original user IDs in the 'userId' column to their encoded forms and store in a new column 'user'\n    df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n    # Map the original movie IDs in the 'movieId' column to their encoded forms and store in a new column 'movie'\n    df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n    ```", "```py\nclass RecommendationModel(keras.Model):\n    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n        super().__init__(**kwargs)\n        self.num_users = num_users\n        self.num_movies = num_movies\n        self.embedding_size = embedding_size\n        # User embeddings layer: Represents each user as a vector in the embedding space\n        self.user_embedding = layers.Embedding(\n            num_users, embedding_size,\n            embeddings_initializer=\"he_normal\",\n            embeddings_regularizer=keras.regularizers.l2(1e-6),)\n        self.user_bias = layers.Embedding(num_users, 1)\n        # Movie embeddings layer: Represents each movie as a vector in the embedding space\n        self.movie_embedding = layers.Embedding(\n            num_movies, embedding_size,\n            embeddings_initializer=\"he_normal\",\n            embeddings_regularizer=keras.regularizers.l2(1e-6),)\n        self.movie_bias = layers.Embedding(num_movies, 1)\n```", "```py\n# Forward pass: Given user and movie IDs, predict the rating\n    def call(self, inputs):\n        user_vector = self.user_embedding(inputs[:, 0])\n        user_bias = self.user_bias(inputs[:, 0])\n        movie_vector = self.movie_embedding(inputs[:, 1])\n        movie_bias = self.movie_bias(inputs[:, 1])\n        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n        x = dot_user_movie + user_bias + movie_bias\n        # The sigmoid activation forces the rating to between 0 and 1\n        return tf.nn.sigmoid(x))\n```", "```py\n# # Instantiate the Recommender model with the defined number of users, movies, and embedding size\nmodel = RecommendationModel(num_users, num_movies, EMBEDDING_SIZE)\n# Compile the Recommender model\nmodel.compile(\n    #Define loss function\n    loss=tf.keras.losses.BinaryCrossentropy(),\n    #Define Optimizer function\n optimizer=keras.optimizers.Adam(learning_rate=0.001))\n```", "```py\n# Train the model\nhistory = model.fit(\n    x=x_train,y=y_train,batch_size=64,\n    epochs=5,verbose=1,validation_data=(x_val, y_val),)\n```", "```py\n    #Load the metadata for the movies\n    movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n    # Pick a user and select their top recommendations.\n    user_id = df.userId.sample(1).iloc[0]\n    movies_watched_by_user = df[df.userId == user_id]\n    movies_not_watched = movie_df[~movie_df[\"movieId\"] .isin(\n        movies_watched_by_user.movieId.values)][\"movieId\"]\n    movies_not_watched = list(set(movies_not_watched).intersection(\n        set(movie2movie_encoded.keys())))\n    movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n    user_encoder = user2user_encoded.get(user_id)\n    #Create a array of data instances to be sent for predictions\n    user_prediction_array = np.hstack(([[user_encoder]] * len(movies_not_watched), movies_not_watched))\n    ```", "```py\n    #Get predicted ratings for the unwatched movies and the selected user\n    ratings = model.predict(user_movie_array).flatten()\n    ```", "```py\n    # Sort and pick top 10 ratings\n    movie_indices_top10 = ratings.argsort()[-10:][::-1]\n    movie_recommendations_ids = [\n        movie_encoded2movie.get(movies_not_watched[x][0]) for x in movie_indices_top10\n    ]\n    print(\"----\" * 10)\n    print(\"Top movies recommendations for user id: {}\".format(user_id))\n    print(\"----\" * 10)\n    recommended_movies = movie_df[movie_df[\"movieId\"].isin(\n        movie_recommendations_ids)]\n    for row in recommended_movies.itertuples():\n        print(row.title, \":\", row.genres)\n    ```", "```py\n    --------------------------------\n    Top 10 movie recommendations\n    --------------------------------\n    Volunteers (1985) : Comedy\n    Emperor's New Clothes, The (2001) : Comedy\n    Caveman (1981) : Comedy\n    Juwanna Mann (2002) : Comedy\n    Top Secret! (1984) : Comedy\n    Unfaithfully Yours (1948) : Comedy\n    Oh, God! You Devil (1984) : Comedy\n    Fish Story (Fisshu sutôrî) (2009) : Comedy\n    Kevin Smith: Too Fat For 40 (2010) : Comedy\n    War Dogs (2016) : Comedy\n    ```", "```py\n    # Save the model in GCS bucket so that we can import it into Vertex AI Model Registry\n    MODEL_DIR = BUCKET_URI + \"/model/\"\n    model.save(MODEL_DIR)\n    ```", "```py\n    #Define service container configuration\n    DEPLOY_GPU, DEPLOY_NGPU = (None, None)\n    TF = \"2.12\".replace(\".\", \"-\")\n    if DEPLOY_GPU:\n        DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n    else:\n        DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n    DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n        REGION.split(\"-\")[0], DEPLOY_VERSION)\n    #Upload the Model to Vertex AI Model Registry\n    model = aip.Model.upload(\n        display_name=\"recommender_model_chp15\",\n        artifact_uri=MODEL_DIR,\n        serving_container_image_uri=DEPLOY_IMAGE,\n        is_default_version=True,\n        version_aliases=[\"v1\"],\n        version_description=\"This is the first version of the model\",)\n    ```", "```py\n    endpoint = aip.Endpoint.create(\n        display_name=\"recommender_model_chp15\",\n        project=PROJECT_ID,\n        location=REGION,)\n    print(endpoint)\n    ```", "```py\n    #Deploy the model to the Vertex AI endpoint\n    DEPLOY_COMPUTE = \"n1-standard-4\" #Virtual Machine type\n    response = endpoint.deploy(\n        model=model,\n        deployed_model_display_name=\"example_\",\n        machine_type=DEPLOY_COMPUTE,)\n    print(endpoint)\n    ```", "```py\n    def predict_custom_trained_model_sample(\n        project: str,\n        endpoint_id: str,\n        instances: Union[Dict, List[Dict]],\n        location: str = \"us-central1\",\n        api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",):\n        # Initialize client that will be used to create and send requests.\n        client_options = {\"api_endpoint\": api_endpoint}\n        client = aiplatform.gapic.PredictionServiceClient(\n            client_options=client_options)\n        # The format of each instance should conform to the deployed model's prediction\n        instances = [\n            json_format.ParseDict(instance_dict, Value()) for instance_dict in instances]\n        parameters_dict = {}\n        parameters = json_format.ParseDict(parameters_dict, Value())\n        endpoint = client.endpoint_path(\n            project=project, location=location, endpoint=endpoint_id)\n        response = client.predict(\n            endpoint=endpoint, instances=instances, parameters=parameters)\n         print(\" deployed_model_id:\", response.deployed_model_id)\n        # The predictions are a google.protobuf.Value representation of the model's predictions.\n        predictions = response.predictions\n        return(predictions)\n    ```", "```py\n    # Pick a random user for whom we can try to predict movie predictions\n    user_id = df.userId.sample(1).iloc[0]\n    #Add filter for the category for which you need recommendations\n    genre_filter = \"Drama\"\n    ```", "```py\n        # Create Test Dataset for a User and the selected Genre\n        movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n        movies_watched_by_user = df[df.userId == user_id]\n        #Create Dataframe with Movies not watched by the User\n        movies_not_watched_df = movie_df[\n            (~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)) & (movie_df[\"genres\"].str.contains(genre_filter))\n        ][[\"movieId\",\"title\",\"genres\"]]\n        #Get the list of Movie Ids which can the be encoded using the movie id encoder we had built earlier\n        movies_not_watched = movies_not_watched_df[\"movieId\"]\n        movies_not_watched = list(\n            set(movies_not_watched).intersection(set(movie2movie_encoded.keys())))\n        movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n        #Get the encoded value of the user id based on the encoder built earlier\n        user_encoder = user2user_encoded.get(user_id)\n        user_movie_array = np.hstack(([[user_encoder]] * len(movies_not_watched), movies_not_watched))\n        #Create data instances that would be sent to the API for inference\n        instances = user_movie_array.tolist()\n        ```", "```py\n    # Get predicted ratings for the unwatched movies and the selected user\n    predictions = predict_custom_trained_model_sample(\n        project=endpoint.project,\n        endpoint_id=endpoint.name,\n        location=endpoint.location,\n        instances = instances)\n    ```", "```py\n    # Create a DataFrame from the predictions list/array\n    predictions_df = pd.DataFrame(predictions)\n    # Rename the column in the predictions DataFrame to 'rating'\n    predictions_df.columns = ['rating']\n    ```", "```py\n    instances_df = pd.DataFrame(instances)\n    # Rename the columns in the instances DataFrame to 'userId' and 'movieId' respectively\n    instances_df.columns = ['userId','movieId']\n    # Merge the instances and predictions DataFrames\n    combined_results = instances_df.join(predictions_df)\n    # Sort the results by the rating column in descending order\n    combined_results_sorted = combined_results.sort_values('rating',ascending=False)\n    # Filter the results to show only the top 15 results\n    combined_results_sorted_top = combined_results_sorted.head(15)[\"movieId\"].values\n    # Map the encoded Movie IDs to the actual Movie IDs\n    recommended_movie_ids = [\n        movie_encoded2movie.get(x) for x in combined_results_sorted_top]\n    ```", "```py\n    print(\"----\" * 10)\n    print(\"Top 15 recommended movies recommendations for User:\",user_id,\" and Genre\",genre_filter)\n    print(\"Genre:\",genre_filter)\n    print(\"----\" * 10)\n    recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n    for row in recommended_movies.itertuples():\n        print(row.title, \":\", row.genres)\n    ```", "```py\n    ----------------------------------------\n    Top 15 recommended movies recommendations for User: 551\n    Genre: Drama\n    --------------------------------\n    Stunt Man, The (1980) : Action|Adventure|Comedy|Drama|Romance|Thriller\n    Affair of the Necklace, The (2001) : Drama\n    Baran (2001) : Adventure|Drama|Romance\n    Business of Strangers, The (2001) : Action|Drama|Thriller\n    No Man's Land (2001) : Drama|War\n    Blue Angel, The (Blaue Engel, Der) (1930) : Drama\n    Moscow on the Hudson (1984) : Comedy|Drama\n    Iris (2001) : Drama\n    Kandahar (Safar e Ghandehar) (2001) : Drama\n    Lantana (2001) : Drama|Mystery|Thriller\n    Brothers (Brødre) (2004) : Drama\n    Flightplan (2005) : Action|Drama|Thriller\n    Green Street Hooligans (a.k.a. Hooligans) (2005) : Crime|Drama\n    History of Violence, A (2005) : Action|Crime|Drama|Thriller\n    Oliver Twist (2005) : Drama\n    ```"]