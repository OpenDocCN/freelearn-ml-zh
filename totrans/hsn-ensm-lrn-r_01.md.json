["```py\n> HT <- read.csv(\"../Data/Hypothyroid.csv\",header = TRUE,stringsAsFactors = F)\n> HT$Hypothyroid <- as.factor(HT$Hypothyroid)\n> HT2 <- HT[,c(\"Hypothyroid\",\"Age\",\"Gender\",\"TSH\",\"T3\",\"TT4\",\"T4U\",\"FTI\")]\n```", "```py\n> sapply(HT2,function(x) sum(is.na(x)))\nHypothyroid         Age      Gender         TSH          T3         TT4 \n          0         446          73         468         695         249 \n        T4U         FTI \n        248         247 \n```", "```py\n> HT2 <- na.omit(HT2)\n> set.seed(12345)\n> Train_Test <- sample(c(\"Train\",\"Test\"),nrow(HT2),replace=TRUE, prob=c(0.7,0.3))\n> head(Train_Test)\n[1] \"Test\"  \"Test\"  \"Test\"  \"Test\"  \"Train\" \"Train\"\n> HT2_Train <- HT2[Train_Test==\"Train\",]\n> HT2_TestX <- within(HT2[Train_Test==\"Test\",],rm(Hypothyroid))\n> HT2_TestY <- HT2[Train_Test==\"Test\",c(\"Hypothyroid\")]\n> HT2_Formula <- as.formula(\"Hypothyroid~.\")\n```", "```py\n> library(mlbench)\n> set.seed(123)\n> Waveform <- mlbench.waveform(5000)\n> table(Waveform$classes)\n   1    2    3 \n1687 1718 1595 \n> Waveform$classes <- ifelse(Waveform$classes!=3,1,2)\n> Waveform_DF <- data.frame(cbind(Waveform$x,Waveform$classes)) # Data Frame\n> names(Waveform_DF) <- c(paste0(\"X\",\".\",1:21),\"Classes\")\n> Waveform_DF$Classes <- as.factor(Waveform_DF$Classes)\n> table(Waveform_DF$Classes)\n   1    2 \n3405 1595 \n```", "```py\n> set.seed(12345)\n> Train_Test <- sample(c(\"Train\",\"Test\"),nrow(Waveform_DF),replace = TRUE,\n+ prob = c(0.7,0.3))\n> head(Train_Test)\n[1] \"Test\"  \"Test\"  \"Test\"  \"Test\"  \"Train\" \"Train\"\n> Waveform_DF_Train <- Waveform_DF[Train_Test==\"Train\",]\n> Waveform_DF_TestX <- within(Waveform_DF[Train_Test==\"Test\",],rm(Classes))\n> Waveform_DF_TestY <- Waveform_DF[Train_Test==\"Test\",\"Classes\"]\n> Waveform_DF_Formula <- as.formula(\"Classes~.\")\n```", "```py\n> library(RSADBE)\n> load(\"../Data/GC2.RData\")\n> table(GC2$good_bad)\n bad good \n 300  700 \n> set.seed(12345)\n> Train_Test <- sample(c(\"Train\",\"Test\"),nrow(GC2),replace = TRUE,prob=c(0.7,0.3))\n> head(Train_Test)\n[1] \"Test\"  \"Test\"  \"Test\"  \"Test\"  \"Train\" \"Train\"\n> GC2_Train <- GC2[Train_Test==\"Train\",]\n> GC2_TestX <- within(GC2[Train_Test==\"Test\",],rm(good_bad))\n> GC2_TestY <- GC2[Train_Test==\"Test\",\"good_bad\"]\n> GC2_Formula <- as.formula(\"good_bad~.\")\n```", "```py\n> data(\"iris\")\n> ir2 <- iris\n> ir2$Species <- ifelse(ir2$Species==\"setosa\",\"S\",\"NS\")\n> ir2$Species <- as.factor(ir2$Species)\n> set.seed(12345)\n> Train_Test <- sample(c(\"Train\",\"Test\"),nrow(ir2),replace = TRUE,prob=c(0.7,0.3))\n> head(Train_Test)\n[1] \"Test\"  \"Test\"  \"Test\"  \"Test\"  \"Train\" \"Train\"\n> ir2_Train <- ir2[Train_Test==\"Train\",]\n> ir2_TestX <- within(ir2[Train_Test==\"Test\",],rm(Species))\n> ir2_TestY <- ir2[Train_Test==\"Test\",\"Species\"]\n> ir2_Formula <- as.formula(\"Species~.\")\n```", "```py\n> data(\"PimaIndiansDiabetes\")\n> set.seed(12345)\n> Train_Test <- sample(c(\"Train\",\"Test\"),nrow(PimaIndiansDiabetes),replace = TRUE,\n+ prob = c(0.7,0.3))\n> head(Train_Test)\n[1] \"Test\"  \"Test\"  \"Test\"  \"Test\"  \"Train\" \"Train\"\n> PimaIndiansDiabetes_Train <- PimaIndiansDiabetes[Train_Test==\"Train\",]\n> PimaIndiansDiabetes_TestX <- within(PimaIndiansDiabetes[Train_Test==\"Test\",],\n+                                     rm(diabetes))\n> PimaIndiansDiabetes_TestY <- PimaIndiansDiabetes[Train_Test==\"Test\",\"diabetes\"]\n> PID_Formula <- as.formula(\"diabetes~.\")\n```", "```py\n> library(ACSWR)\nWarning message:\npackage 'ACSWR' was built under R version 3.4.1 \n> data(usc)\n> str(usc)\n'data.frame':\t47 obs. of  14 variables:\n $ R  : num  79.1 163.5 57.8 196.9 123.4 ...\n $ Age: int  151 143 142 136 141 121 127 131 157 140 ...\n $ S  : int  1 0 1 0 0 0 1 1 1 0 ...\n $ Ed : int  91 113 89 121 121 110 111 109 90 118 ...\n $ Ex0: int  58 103 45 149 109 118 82 115 65 71 ...\n $ Ex1: int  56 95 44 141 101 115 79 109 62 68 ...\n $ LF : int  510 583 533 577 591 547 519 542 553 632 ...\n $ M  : int  950 1012 969 994 985 964 982 969 955 1029 ...\n $ N  : int  33 13 18 157 18 25 4 50 39 7 ...\n $ NW : int  301 102 219 80 30 44 139 179 286 15 ...\n $ U1 : int  108 96 94 102 91 84 97 79 81 100 ...\n $ U2 : int  41 36 33 39 20 29 38 35 28 24 ...\n $ W  : int  394 557 318 673 578 689 620 472 421 526 ...\n $ X  : int  261 194 250 167 174 126 168 206 239 174 ...\n> set.seed(12345)\n> Train_Test <- sample(c(\"Train\",\"Test\"),nrow(usc),replace = TRUE,prob=c(0.7,0.3))\n> head(Train_Test)\n[1] \"Test\"  \"Test\"  \"Test\"  \"Test\"  \"Train\" \"Train\"\n> usc_Train <- usc[Train_Test==\"Train\",]\n> usc_TestX <- within(usc[Train_Test==\"Test\",],rm(R))\n> usc_TestY <- usc[Train_Test==\"Test\",\"R\"]\n> usc_Formula <- as.formula(\"R~.\")\n```", "```py\n> osvisit <- read.csv(\"../Data/osvisit.dat\", header= FALSE)\n> osv <- ts(osvisit$V1, start = 1977, frequency = 12)\n> class(osv)\n[1] \"ts\"\n> plot.ts(osv)\n```", "```py\n> library(factoextra)\n> data(\"multishapes\")\n> names(multishapes)\n[1] \"x\"     \"y\"     \"shape\"\n> table(multishapes$shape)\n  1   2   3   4   5   6 \n400 400 100 100  50  50 \n> plot(multishapes[,1],multishapes[,2],col=multishapes[,3])\n```", "```py\n> data(stiff)\n> sort(mahalanobis(stiff,colMeans(stiff),cov(stiff)),decreasing = TRUE)\n [1] 16.8474070168 12.2647549939  9.8980384087  7.6166439053\n [5]  6.2837628235  5.4770195915  5.2076098038  5.0557446013\n [9]  4.9883497928  4.5767867224  3.9900602512  3.5018290410\n[13]  3.3979804418  2.9951752177  2.6959023813  2.5838186338\n[17]  2.5385575365  2.3816049840  2.2191408683  1.9307771418\n[21]  1.4876569689  1.4649908273  1.3980776252  1.3632123553\n[25]  1.0792484215  0.7962095966  0.7665399704  0.6000128595\n[29]  0.4635158597  0.1295713581\n```", "```py\n> ntr <- nrow(HT2_Train) # Training size\n> nte <- nrow(HT2_TestX) # Test size\n> p <- ncol(HT2_TestX)\n> testY_numeric <- as.numeric(HT2_TestY)\n> LR_fit <- glm(HT2_Formula,data=HT2_Train,family = binomial())\nWarning message:\nglm.fit: fitted probabilities numerically 0 or 1 occurred \n> summary(LR_fit)\nCall:\nglm(formula = HT2_Formula, family = binomial(), data = HT2_Train)\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.6390   0.0076   0.0409   0.1068   3.5127  \nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -8.302025   2.365804  -3.509 0.000449 ***\nAge         -0.024422   0.012145  -2.011 0.044334 *  \nGenderMALE  -0.195656   0.464353  -0.421 0.673498    \nTSH         -0.008457   0.007530  -1.123 0.261384    \nT3           0.480986   0.347525   1.384 0.166348    \nTT4         -0.089122   0.028401  -3.138 0.001701 ** \nT4U          3.932253   1.801588   2.183 0.029061 *  \nFTI          0.197196   0.035123   5.614 1.97e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 609.00  on 1363  degrees of freedom\nResidual deviance: 181.42  on 1356  degrees of freedom\nAIC: 197.42\nNumber of Fisher Scoring iterations: 9\n> LR_Predict <- predict(LR_fit,newdata=HT2_TestX,type=\"response\")\n> LR_Predict_Bin <- ifelse(LR_Predict>0.5,2,1)\n> LR_Accuracy <- sum(LR_Predict_Bin==testY_numeric)/nte\n> LR_Accuracy\n[1] 0.9732704\n```", "```py\n> library(NeuralNetTools) \n> plotnet(rep(0,17),struct=c(3,2,2,1))\n> title(\"A Neural Network with Two Hidden Layers\")\n```", "```py\n> set.seed(12345)\n> NN_fit <- nnet(HT2_Formula,data = HT2_Train,size=p,trace=FALSE)\n> NN_Predict <- predict(NN_fit,newdata=HT2_TestX,type=\"class\")\n> NN_Accuracy <- sum(NN_Predict==HT2_TestY)/nte\n> NN_Accuracy\n[1] 0.9827044025\n> plotnet(NN_fit)\n> title(\"Neural Network for Hypothyroid Classification\")\n```", "```py\n> NB_fit <- naiveBayes(HT2_Formula,data=HT2_Train)\n> NB_predict <- predict(NB_fit,newdata=HT2_TestX)\nWarning message:\nIn data.matrix(newdata) : NAs introduced by coercion\n> NB_Accuracy <- sum(NB_predict==HT2_TestY)/nte\n> NB_Accuracy\n[1] 0.9732704403\n```", "```py\n> CT_fit <- rpart(HT2_Formula,data=HT2_Train)\n> plot(CT_fit,uniform=TRUE)\n> text(CT_fit)\n> CT_predict <- predict(CT_fit,newdata=HT2_TestX,type=\"class\")\n> CT_Accuracy <- sum(CT_predict==HT2_TestY)/nte\n> CT_Accuracy\n[1] 0.9874213836\n```", "```py\n> SVM_fit <- svm(HT2_Formula,data=HT2_Train)\n> SVM_predict <- predict(SVM_fit,newdata=HT2_TestX,type=\"class\")\n> SVM_Accuracy <- sum(SVM_predict==HT2_TestY)/nte\n> SVM_Accuracy\n[1] 0.9842767296\n```", "```py\n> Multiple_Model_Fit <- function(formula,train,testX,testY){\n+   ntr <- nrow(train) # Training size\n+   nte <- nrow(testX) # Test size\n+   p <- ncol(testX)\n+   testY_numeric <- as.numeric(testY)\n+   \n+   # Neural Network\n+   set.seed(12345)\n+   NN_fit <- nnet(formula,data = train,size=p,trace=FALSE)\n+   NN_Predict <- predict(NN_fit,newdata=testX,type=\"class\")\n+   NN_Accuracy <- sum(NN_Predict==testY)/nte\n+   \n+   # Logistic Regressiona\n+   LR_fit <- glm(formula,data=train,family = binomial())\n+   LR_Predict <- predict(LR_fit,newdata=testX,type=\"response\")\n+   LR_Predict_Bin <- ifelse(LR_Predict>0.5,2,1)\n+   LR_Accuracy <- sum(LR_Predict_Bin==testY_numeric)/nte\n+   \n+   # Naive Bayes\n+   NB_fit <- naiveBayes(formula,data=train)\n+   NB_predict <- predict(NB_fit,newdata=testX)\n+   NB_Accuracy <- sum(NB_predict==testY)/nte\n+   \n+   # Decision Tree\n+   CT_fit <- rpart(formula,data=train)\n+   CT_predict <- predict(CT_fit,newdata=testX,type=\"class\")\n+   CT_Accuracy <- sum(CT_predict==testY)/nte\n+   \n+   # Support Vector Machine\n+   svm_fit <- svm(formula,data=train)\n+   svm_predict <- predict(svm_fit,newdata=testX,type=\"class\")\n+   svm_Accuracy <- sum(svm_predict==testY)/nte\n+   \n+   Accu_Mat <- matrix(nrow=5,ncol=2)\n+   Accu_Mat[,1] <- c(\"Neural Network\",\"Logistic Regression\",\"Naive Bayes\",\n+                 \"Decision Tree\",\"Support Vector Machine\")\n+   Accu_Mat[,2] <- round(c(NN_Accuracy,LR_Accuracy,NB_Accuracy,\n+                     CT_Accuracy,svm_Accuracy),4)\n+   return(Accu_Mat)\n+   \n+ }\n```", "```py\n> Multiple_Model_Fit(formula=HT2_Formula,train=HT2_Train,\n+                    testX=HT2_TestX,\n+                    testY=HT2_TestY)\n     [,1]                     [,2]    \n[1,] \"Neural Network\"         \"0.989\" \n[2,] \"Logistic Regression\"    \"0.9733\"\n[3,] \"Naive Bayes\"            \"0.9733\"\n[4,] \"Decision Tree\"          \"0.9874\"\n[5,] \"Support Vector Machine\" \"0.9843\"\n```", "```py\n> Multiple_Model_Fit(formula=Waveform_DF_Formula,train=Waveform_DF_Train,\n+                    testX=Waveform_DF_TestX,\n+                    testY=Waveform_DF_TestY)\n     [,1]                     [,2]    \n[1,] \"Neural Network\"         \"0.884\" \n[2,] \"Logistic Regression\"    \"0.8873\"\n[3,] \"Naive Bayes\"            \"0.8601\"\n[4,] \"Decision Tree\"          \"0.8435\"\n[5,] \"Support Vector Machine\" \"0.9171\"\n> Multiple_Model_Fit(formula=GC2_Formula,train=GC2_Train,\n+                    testX=GC2_TestX,\n+                    testY =GC2_TestY )\n     [,1]                     [,2]    \n[1,] \"Neural Network\"         \"0.7252\"\n[2,] \"Logistic Regression\"    \"0.7572\"\n[3,] \"Naive Bayes\"            \"0.8083\"\n[4,] \"Decision Tree\"          \"0.7061\"\n[5,] \"Support Vector Machine\" \"0.754\" \n> Multiple_Model_Fit(formula=ir2_Formula,train=ir2_Train,\n+                    testX=ir2_TestX,\n+                    testY=ir2_TestY)\n     [,1]                     [,2]\n[1,] \"Neural Network\"         \"1\" \n[2,] \"Logistic Regression\"    \"1\" \n[3,] \"Naive Bayes\"            \"1\" \n[4,] \"Decision Tree\"          \"1\" \n[5,] \"Support Vector Machine\" \"1\"  \n> Multiple_Model_Fit(formula=PID_Formula,train=PimaIndiansDiabetes_Train,\n+                    testX=PimaIndiansDiabetes_TestX,\n+                    testY=PimaIndiansDiabetes_TestY)\n     [,1]                     [,2]    \n[1,] \"Neural Network\"         \"0.6732\"\n[2,] \"Logistic Regression\"    \"0.751\" \n[3,] \"Naive Bayes\"            \"0.7821\"\n[4,] \"Decision Tree\"          \"0.7588\"\n[5,] \"Support Vector Machine\" \"0.7665\"\n```", "```py\n> library(caret)\n> names(getModelInfo())\n  [1] \"ada\"                 \"AdaBag\"              \"AdaBoost.M1\" \n  [4] \"adaboost\"            \"amdai\"               \"ANFIS\" \n  [7] \"avNNet\"              \"awnb\"                \"awtan\"        \n\n[229] \"vbmpRadial\"          \"vglmAdjCat\"          \"vglmContRatio \n[232] \"vglmCumulative\"      \"widekernelpls\"       \"WM\" \n[235] \"wsrf\"                \"xgbLinear\"           \"xgbTree\" \n[238] \"xyf\"               \n```", "```py\n\nFigure 7: Caret providing a message to install the required R package\n\n```", "```py\n> load(\"../Data/GC2.RData\")\n> set.seed(12345)\n> Train_Test_Stack <- sample(c(\"Train\",\"Test\",\"Stack\"),nrow(GC2),replace = TRUE,prob = c(0.5,0.25,0.25))\n> GC2_Train <- GC2[Train_Test_Stack==\"Train\",]\n> GC2_Test <- GC2[Train_Test_Stack==\"Test\",]\n> GC2_Stack <- GC2[Train_Test_Stack==\"Stack\",]The dependent and independent variables will be marked next in character vectors for programming convenient. \n\n> # set label name and Exhogenous\n> Endogenous <- 'good_bad'\n> Exhogenous <- names(GC2_Train)[names(GC2_Train) != Endogenous]\n```", "```py\n> # Creating a caret control object for the number of \n> # cross-validations to be performed\n> myControl <- trainControl(method='cv', number=3, returnResamp='none')\n> # train all the ensemble models with GC2_Train\n> model_NB <- train(GC2_Train[,Exhogenous], GC2_Train[,Endogenous], \n+                    method='naive_bayes', trControl=myControl)\n> model_rpart <- train(GC2_Train[,Exhogenous], GC2_Train[,Endogenous], \n+                      method='rpart', trControl=myControl)\n> model_glm <- train(GC2_Train[,Exhogenous], GC2_Train[,Endogenous], \n+                        method='glm', trControl=myControl)\n```", "```py\n> # get predictions for each ensemble model for two last datasets\n> # and add them back to themselves\n> GC2_Test$NB_PROB <- predict(object=model_NB, GC2_Test[,Exhogenous],\n+                              type=\"prob\")[,1]\n> GC2_Test$rf_PROB <- predict(object=model_rpart, GC2_Test[,Exhogenous],\n+                             type=\"prob\")[,1]\n> GC2_Test$glm_PROB <- predict(object=model_glm, GC2_Test[,Exhogenous],\n+                                  type=\"prob\")[,1]\n> GC2_Stack$NB_PROB <- predict(object=model_NB, GC2_Stack[,Exhogenous],\n+                               type=\"prob\")[,1]\n> GC2_Stack$rf_PROB <- predict(object=model_rpart, GC2_Stack[,Exhogenous],\n+                              type=\"prob\")[,1]\n> GC2_Stack$glm_PROB <- predict(object=model_glm, GC2_Stack[,Exhogenous],\n+                                   type=\"prob\")[,1]\n```", "```py\n> # see how each individual model performed on its own\n> AUC_NB <- roc(GC2_Test[,Endogenous], GC2_Test$NB_PROB )\n> AUC_NB$auc\nArea under the curve: 0.7543\n> AUC_rf <- roc(GC2_Test[,Endogenous], GC2_Test$rf_PROB )\n> AUC_rf$auc\nArea under the curve: 0.6777\n> AUC_glm <- roc(GC2_Test[,Endogenous], GC2_Test$glm_PROB )\n> AUC_glm$auc\nArea under the curve: 0.7446\n```", "```py\n> # Stacking it together\n> Exhogenous2 <- names(GC2_Stack)[names(GC2_Stack) != Endogenous]\n> Stack_Model <- train(GC2_Stack[,Exhogenous2], GC2_Stack[,Endogenous], \n+                      method='naive_bayes', trControl=myControl)\n> Stack_Prediction <- predict(object=Stack_Model,GC2_Test[,Exhogenous2],type=\"prob\")[,1]\n> Stack_AUC <- roc(GC2_Test[,Endogenous],Stack_Prediction)\n> Stack_AUC$auc\nArea under the curve: 0.7631\n```", "```py\n> library(perm)\n> x <- c(18,20,22); y <- c(24,26,28)\n> t.test(x,y,var.equal = TRUE)\nTwo Sample t-test\ndata:  x and y\nt = -3.6742346, df = 4, p-value = 0.02131164\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -10.533915871  -1.466084129\nsample estimates:\nmean of x mean of y \n       20        26 \n```", "```py\n> permTS(x,y)\nExact Permutation Test (network algorithm)\ndata:  x and y\np-value = 0.1\nalternative hypothesis: true mean x - mean y is not equal to 0\nsample estimates:\nmean x - mean y \n             -6 \n```", "```py\n> x2 <- c(16,18,20,22); y2 <- c(24,26,28,30)\n> t.test(x2,y2,var.equal = TRUE)\nTwo Sample t-test\ndata:  x2 and y2\nt = -4.3817805, df = 6, p-value = 0.004659215\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -12.46742939  -3.53257061\nsample estimates:\nmean of x mean of y \n       19        27 \n> permTS(x2,y2)\nExact Permutation Test (network algorithm)\ndata:  x2 and y2\np-value = 0.02857143\nalternative hypothesis: true mean x2 - mean y2 is not equal to 0\nsample estimates:\nmean x2 - mean y2 \n               -8 \n```", "```py\n> table(LR_Predict_Bin,testY_numeric)\n              testY_numeric\nLR_Predict_Bin   1   2\n             1  32   7\n             2  10 587\n> table(NN_Predict,HT2_TestY)\n             HT2_TestY\nNN_Predict    hypothyroid negative\n  hypothyroid          41       22\n  negative              1      572\n> table(NB_predict,HT2_TestY)\n             HT2_TestY\nNB_predict    hypothyroid negative\n  hypothyroid          33        8\n  negative              9      586\n> table(CT_predict,HT2_TestY)\n             HT2_TestY\nCT_predict    hypothyroid negative\n  hypothyroid          38        4\n  negative              4      590\n> table(SVM_predict,HT2_TestY)\n             HT2_TestY\nSVM_predict   hypothyroid negative\n  hypothyroid          34        2\n  negative              8      592\n```", "```py\n> chisq.test(table(LR_Predict_Bin,testY_numeric))\nPearson's Chi-squared test with Yates' continuity correction\ndata:  table(LR_Predict_Bin, testY_numeric)\nX-squared = 370.53501, df = 1, p-value < 0.00000000000000022204\n> chisq.test(table(NN_Predict,HT2_TestY))\nPearson's Chi-squared test with Yates' continuity correction\ndata:  table(NN_Predict, HT2_TestY)\nX-squared = 377.22569, df = 1, p-value < 0.00000000000000022204\n> chisq.test(table(NB_predict,HT2_TestY))\nPearson's Chi-squared test with Yates' continuity correction\ndata:  table(NB_predict, HT2_TestY)\nX-squared = 375.18659, df = 1, p-value < 0.00000000000000022204\n> chisq.test(table(CT_predict,HT2_TestY))\nPearson's Chi-squared test with Yates' continuity correction\ndata:  table(CT_predict, HT2_TestY)\nX-squared = 498.44791, df = 1, p-value < 0.00000000000000022204\n> chisq.test(table(SVM_predict,HT2_TestY))\nPearson's Chi-squared test with Yates' continuity correction\ndata:  table(SVM_predict, HT2_TestY)\nX-squared = 462.41803, df = 1, p-value < 0.00000000000000022204\n> mcnemar.test(table(LR_Predict_Bin,testY_numeric))\nMcNemar's Chi-squared test with continuity correction\ndata:  table(LR_Predict_Bin, testY_numeric)\nMcNemar's chi-squared = 0.23529412, df = 1, p-value = 0.6276258\n> mcnemar.test(table(NN_Predict,HT2_TestY))\nMcNemar's Chi-squared test with continuity correction\ndata:  table(NN_Predict, HT2_TestY)\nMcNemar's chi-squared = 17.391304, df = 1, p-value = 0.00003042146\n> mcnemar.test(table(NB_predict,HT2_TestY))\nMcNemar's Chi-squared test with continuity correction\ndata:  table(NB_predict, HT2_TestY)\nMcNemar's chi-squared = 0, df = 1, p-value = 1\n> mcnemar.test(table(CT_predict,HT2_TestY))\nMcNemar's Chi-squared test\ndata:  table(CT_predict, HT2_TestY)\nMcNemar's chi-squared = 0, df = 1, p-value = 1\n> mcnemar.test(table(SVM_predict,HT2_TestY))\nMcNemar's Chi-squared test with continuity correction\ndata:  table(SVM_predict, HT2_TestY)\nMcNemar's chi-squared = 2.5, df = 1, p-value = 0.1138463\n```", "```py\n> library(pROC)\n> HT_NN_Prob <- predict(NN_fit,newdata=HT2_TestX,type=\"raw\")\n> HT_NN_roc <- roc(HT2_TestY,c(HT_NN_Prob))\n> HT_NN_roc$auc\nArea under the curve: 0.9723826\n> HT_CT_Prob <- predict(CT_fit,newdata=HT2_TestX,type=\"prob\")[,2]\n> HT_CT_roc <- roc(HT2_TestY,HT_CT_Prob)\n> HT_CT_roc$auc\nArea under the curve: 0.9598765\n> roc.test(HT_NN_roc,HT_CT_roc)\n\tDeLong's test for two correlated ROC curves\ndata:  HT_NN_roc and HT_CT_roc\nZ = 0.72452214, p-value = 0.4687452\nalternative hypothesis: true difference in AUC is not equal to 0\nsample estimates:\n AUC of roc1  AUC of roc2 \n0.9723825557 0.9598765432 \n```"]