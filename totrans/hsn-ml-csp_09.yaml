- en: Should I Take the Job – Decision Trees in Action
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我应该接受这份工作吗——决策树的实际应用
- en: 'This chapter will focus on:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点关注：
- en: Decision trees
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: How to create decision trees for your application
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何为您的应用程序创建决策树
- en: Understanding truth tables
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解真值表
- en: Visual intuition regarding false negatives and false positives
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于假阴性和假阳性的视觉直觉
- en: Before we dive right in, let's gain some background information which will be
    helpful to us.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨之前，让我们获取一些对我们有帮助的背景信息。
- en: For a decision tree to be complete and effective, it must contain all possibilities,
    meaning every pathway in and out. Event sequences must also be supplied and be
    mutually exclusive, meaning if one event happens, the other one cannot.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使决策树完整且有效，它必须包含所有可能性，这意味着每个进入和离开的路径。事件序列也必须提供，并且是互斥的，这意味着如果一个事件发生，另一个事件就不能发生。
- en: Decision trees are a form of **supervised machine learning**, in that we have
    to explain what the input and output should be. There are decision nodes and leaves.
    The leaves are the decisions, final or not, and the nodes are where decision splits
    occur.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是一种**监督式机器学习**的形式，这意味着我们必须解释输入和输出应该是什么。决策树中有决策节点和叶子节点。叶子节点是决策点，无论是最终决策还是非最终决策，而节点是决策分支发生的地方。
- en: Although there are many algorithms available for our use, we are going to use
    the **Iterative Dichotomizer 3** (**I****D3**) algorithm. During each recursive
    step, the attribute that best classifies the set of inputs we are working with
    is selected according to a criterion **(InfoGain**, **GainRatio**, and so on).
    It must be pointed out that regardless of the algorithm that we use, none are
    guaranteed to produce the smallest tree possible. This has a direct implication
    on the performance of our algorithm. Keep in mind that with decision trees, learning
    is based solely on heuristics, not true optimized criteria. Let's use an example
    to explain this further.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有许多算法可供我们使用，但我们将使用**迭代二分器3**（**ID3**）算法。在每次递归步骤中，根据一个标准（信息增益、增益率等）选择最佳分类我们正在处理的输入集的属性。必须指出的是，无论我们使用哪种算法，都没有保证能够产生可能的最小树。这直接影响了我们算法的性能。记住，在决策树中，学习仅基于启发式，而不是真正的优化标准。让我们用一个例子来进一步解释这一点。
- en: 'The following example is from [http://jmlr.csail.mit.edu/papers/volume8/esmeir07a/esmeir07a.pdf](http://jmlr.csail.mit.edu/papers/volume8/esmeir07a/esmeir07a.pdf),
    and it illustrates the XOR learning concept, which all of us developers are (or
    should be) familiar with. You will see this happen in a later example as well,
    but for now, **a[3]** and **a[4]** are completely irrelevant to the problem we
    are trying to solve. They have zero influence on our answer. That being said,
    the ID3 algorithm will select one of them to belong to the tree, and in fact,
    it will use **a[4]** as the root! Remember that this is heuristic learning of
    the algorithm and not optimized findings:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以下例子来自[http://jmlr.csail.mit.edu/papers/volume8/esmeir07a/esmeir07a.pdf](http://jmlr.csail.mit.edu/papers/volume8/esmeir07a/esmeir07a.pdf)，它说明了XOR学习概念，这是我们所有开发者（或应该熟悉）的。你将在后面的例子中看到这一点，但现在，**a[3]**和**a[4]**对我们试图解决的问题完全无关。它们对我们的答案没有影响。话虽如此，ID3算法将选择其中之一属于树，实际上，它将使用**a[4]**作为根！记住，这是算法的启发式学习，而不是优化发现：
- en: '![](img/ecc3b212-9667-450d-a320-6daea4b9b330.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ecc3b212-9667-450d-a320-6daea4b9b330.png)'
- en: Hopefully this visual will make it easier to understand what we mean. The goal
    here isn't to get too deep into decision tree mechanics and theory. After all
    of that, you might be asking why we are even talking about decision trees. Despite
    any issues they may have, decision trees work as the base for many algorithms,
    especially those that need a human description of the results. They are also the
    basis for the Viola & Jones (2001) real-time facial detection algorithm we used
    in an earlier chapter. As perhaps a better example, the **Kinect of Microsoft
    Xbox 360** uses decision trees as well.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这个视觉图能更容易地理解我们的意思。这里的目的是不要深入决策树的机械和理论。在所有这些之后，你可能会问为什么我们还在谈论决策树。尽管它们可能存在任何问题，决策树仍然是许多算法的基础，特别是那些需要人类描述结果的算法。它们也是我们在前一章中使用过的Viola
    & Jones（2001）实时面部检测算法的基础。作为一个更好的例子，微软Xbox 360的**Kinect**也使用了决策树。
- en: Once again, we will turn to the Accord.NET open source framework to illustrate
    our concept. In our sample, we'll be dealing with the following decision tree
    objects, so it's best that we discuss them upfront.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将再次转向 Accord.NET 开源框架来阐述我们的概念。在我们的示例中，我们将处理以下决策树对象，因此最好提前讨论它们。
- en: Decision tree
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树
- en: This is our main class.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的主要类。
- en: Decision node
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策节点
- en: This is a node for our decision tree. Each node may or may not have children
    associated with it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的决策树中的一个节点。每个节点可能或可能没有与之关联的子节点。
- en: Decision variable
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策变量
- en: This object defines the nature of each decision variable that the tree and nodes
    can process. The values can be ranges, continuous, or discrete.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个对象定义了树和节点可以处理的每个决策变量的性质。这些值可以是范围、连续或离散的。
- en: Decision branch node collection
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策分支节点集合
- en: This collection contains decision nodes grouped together with additional information
    about their decision variables for comparison.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个集合包含了一组决策节点，以及关于它们决策变量的额外信息，以便进行比较。
- en: 'Here is an example of a decision tree for determining financial risks. It is
    very easy to follow simply by navigating the nodes, making a decision as to which
    way to go, until you get to the final answer. In this case, someone is applying
    for credit and we need to make a decision on their credit worthiness. A decision
    tree is a great approach to solving this problem:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个用于确定财务风险的决策树的示例。通过简单地导航节点，决定走哪条路，直到得到最终答案，它非常容易跟随。在这种情况下，有人正在申请信贷，我们需要对其信用度做出决定。决策树是解决这个问题的绝佳方法：
- en: '![](img/6259d852-b213-4ae2-b21d-8336f635d200.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6259d852-b213-4ae2-b21d-8336f635d200.png)'
- en: With this simplistic visual diagram behind us, let's visit the problem we are
    trying to solve. It's one that all of us developers face (hopefully) from time
    to time.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们有了这个简单的视觉图之后，让我们来看看我们试图解决的问题。这是我们所有开发者（希望如此）时不时都会遇到的问题。
- en: Should I take the job?
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我是否应该接受这份工作？
- en: 'You have just been offered a new job, and you need to decide whether or not
    you are going to take it. There are a few things that are important for you to
    consider, so we will use those as input variables, or features, for our decision
    tree. Here is what is important to you: pay, benefits, company culture, and of
    course, *Can I work from home?*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚得到了一份新的工作，你需要决定是否接受这份工作。有一些事情对你来说很重要，所以我们将使用这些作为决策树的输入变量或特征。以下是你认为重要的因素：薪酬、福利、公司文化和当然，*我能否在家工作？*
- en: 'Rather than load data from disk storage, we are going to create an in-memory
    database and add our features this way. We will create `DataTable` and create
    `Columns` as features as shown here:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不会从磁盘存储加载数据，而是将创建一个内存数据库，并通过这种方式添加我们的特征。我们将创建`DataTable`并创建`Columns`作为特征，如下所示：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After this, we will load several rows of data, each with a different set of
    features, and our last column, `ShouldITakeJob` being a `Yes` or `No`, as our
    final decision:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，我们将加载几行数据，每行都有不同的特征集，以及我们的最后一列`ShouldITakeJob`，它可以是`是`或`否`，作为我们的最终决定：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once all of the data is created and in our table, we need to put our previous
    features into a form of representation that our computer can understand. Since
    all our features are categories, it doesn''t really matter how we represent them,
    if we are consistent. Since numbers are easier, we will convert our features (categories)
    to a code book through a process known as `Codification`. This `codebook` effectively
    transforms every value into an integer. Notice that we will pass in our `data`
    categories as input:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有数据都创建并放入我们的表中，我们需要将我们之前的功能以计算机可以理解的形式表示出来。由于所有我们的特征都是类别，如果我们保持一致，那么我们如何表示它们并不重要。由于数字更容易处理，我们将通过称为`编码`的过程将我们的特征（类别）转换为代码簿。这个`代码簿`有效地将每个值转换为一个整数。请注意，我们将我们的`data`类别作为输入传递：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next, we need to create decision variables for our decision tree to use. The
    tree will be trying to help us determine if we should take our new job offer or
    not. For this decision, there will be several categories of inputs, which we will
    specify in our decision variable array, and two possible decisions, `Yes` or `No`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要为我们的决策树创建决策变量。树将试图帮助我们确定是否应该接受我们的新工作邀请。对于这个决定，将有几个输入类别，我们将它们指定在我们的决策变量数组中，以及两个可能的决策，`是`或`否`。
- en: 'The `DecisionVariable` array will hold the name of each category as well as
    the total count of possible attributes for this category. For example, the `Pay`
    category has three possible values, `Good`, `Average`, or `Poor`. So, we specify
    the category name and the number `3`. We then repeat this for all our other categories
    except the last one, which is our decision:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`DecisionVariable`数组将保存每个类别的名称以及该类别可能属性的总量。例如，`Pay`类别有三个可能的值，`Good`、`Average`或`Poor`。因此，我们指定类别名称和数字`3`。然后我们对所有其他类别重复此操作，除了最后一个，即我们的决策：'
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now that we have our decision tree created, we have to teach it the problem
    we are trying to solve. At this point, it really knows nothing. In order to do
    that, we will have to create a learning algorithm for the tree to use. In our
    case, that would be the ID3 algorithm we discussed earlier. Since we have only
    categorical values for this sample, the ID3 algorithm is the simplest choice.
    Please feel free to replace it with C4.5, C5.0, or whatever you want to try:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了决策树，我们必须教会它我们要解决的问题。在这个阶段，它实际上什么也不知道。为了做到这一点，我们必须为树创建一个学习算法。在我们的例子中，那将是之前讨论过的ID3算法。由于这个样本只有分类值，ID3算法是最简单的选择。请随意将其替换为C4.5、C5.0或您想尝试的任何其他算法：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the learning algorithm has been run, it is trained and ready to use. We
    simply provide a sample dataset to the algorithm so that it can give us back an
    answer. In this case, the pay is good, the company culture is good, the benefits
    are good, and I can work from home. If the decision tree is trained properly,
    the answer is a resounding `Yes`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦运行了学习算法，它就被训练好并准备好使用。我们只需向算法提供一个样本数据集，它就能给我们一个答案。在这种情况下，工资好，公司文化好，福利好，我可以在家工作。如果决策树训练得当，答案将是响亮的`Yes`：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Next, we will turn our attention to using the `numl` open source machine learning
    package to show you another example of training and using a decision tree.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将关注使用`numl`开源机器学习包来向您展示另一个训练和使用决策树的示例。
- en: numl
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: numl
- en: '`numl` is a very famous open source machine learning toolkit. As with most
    machine learning frameworks, it too uses the `Iris` dataset for many of its examples,
    including the one we will use for decision trees.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`numl`是一个非常著名的开源机器学习工具包。与大多数机器学习框架一样，它也使用`Iris`数据集的许多示例，包括我们将用于决策树的示例。'
- en: 'Here is an example of our `numl` output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是`numl`输出的一个示例：
- en: '![](img/98c83b86-cbb0-45fe-9484-ca73bde79182.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/98c83b86-cbb0-45fe-9484-ca73bde79182.png)'
- en: 'Let''s take a look at the code behind that example:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看那个示例背后的代码：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Definitely not the most complex of functions, is it? This is the beauty of using
    `numl` in your applications; it's incredibly easy to use and to integrate.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这绝对不是最复杂的函数，对吧？这就是在您的应用程序中使用`numl`的美丽之处；它极其容易使用和集成。
- en: 'The preceding code creates a descriptor and `DecisionTreeGenerator`, loads
    the `Iris` dataset, and then generates a model. Here is just a sample of the data
    being loaded:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码创建了一个描述符和`DecisionTreeGenerator`，加载了`Iris`数据集，然后生成了一个模型。这里只是加载的数据的一个样本：
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: And so on...
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 等等...
- en: Accord.NET decision trees
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Accord.NET决策树
- en: The Accord.NET framework has its own decision tree example that we should point
    out as well. It takes a different, more graphical approach to decision trees,
    but the call is yours to make as to which you like and feel most comfortable with.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Accord.NET框架也有自己的决策树示例，我们应该指出这一点。它采用不同的、更图形化的方法来处理决策树，但选择权在您手中，您可以选择您喜欢和感觉最舒适的方法。
- en: 'Once the data is loaded you can create your decision tree and get it ready
    for learning. You will see a data plot similar to what you see here, using two
    categories, X and Y:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据加载完毕，您就可以创建决策树并为其学习做好准备。您将看到类似于这里的数据图，使用两个类别X和Y：
- en: '![](img/82332643-96dd-4752-b9b2-d7b2ee02fec0.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/82332643-96dd-4752-b9b2-d7b2ee02fec0.png)'
- en: 'The next tab will let you see the tree nodes, leafs, and decisions. There is
    also a top-down graphical view of the tree on the right. The most useful information
    is located within the Tree View on the left, where you can see the nodes, their
    values, and the decisions that were made:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个标签页将让您查看树节点、叶子和决策。在右侧还有一个树的从上到下的图形视图。最有用的信息位于左侧的树视图中，您可以在这里看到节点、它们的值和所做的决策：
- en: '![](img/4d2c9930-b95d-4b85-a279-73a823e9521a.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4d2c9930-b95d-4b85-a279-73a823e9521a.png)'
- en: 'Finally, the last tab will let you perform Model Testing:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，最后一个标签页将允许您执行模型测试：
- en: '![](img/53650f92-6a31-4922-939c-400023ae0da3.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/53650f92-6a31-4922-939c-400023ae0da3.png)'
- en: Learning code
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习代码
- en: 'Following is the learning code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些学习代码：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This value is then fed to a `ConfusionMatrix`. For those of you that are not
    familiar with this, let me briefly explain.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这个值随后被输入到`ConfusionMatrix`中。对于那些不熟悉这个的人来说，让我简要解释一下。
- en: Confusion matrix
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: A **confusion matrix** is a table used to describe the performance of a classification
    model. It is run on a test dataset for which the truth values are known. This
    is how we arrive at things such as the following.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**混淆矩阵**是一个用于描述分类模型性能的表格。它在一个已知真实值的测试数据集上运行。这就是我们得到如下内容的方式。'
- en: True positives
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 真阳性
- en: This is a case where we predicted yes, and this was the truth.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个我们预测会发生，而且事实确实发生了的情况。
- en: True negatives
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 真阴性
- en: This is a case where we predicted no, and this was the truth.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个我们预测不会发生，而且事实确实发生了的情况。
- en: False positives
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假阳性
- en: This is a case where we predicted yes but the truth was no. You might sometimes
    see this referred to as a **type 1** error.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个我们预测会发生的但事实并非如此的情况。你有时可能会看到这种情况被称为**I型**错误。
- en: False negatives
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假阴性
- en: This is a case where we predicted no but the truth was yes. You might sometimes
    see this referred to as **type II** error.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个我们预测不会发生但事实确实发生了的情况。你有时可能会看到这种情况被称为**II型**错误。
- en: Now, with all that being said, we need to talk about two other important terms,
    **precision** and **recall**.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，说到这里，我们需要讨论另外两个重要的术语，**精确度**和**召回率**。
- en: Let's describe them this way. For the past week, it has rained every day. That's
    7 days out of 7\. Simple enough. A week later, you are asked *How often did it
    rain last week?*
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们这样描述它们。在过去的一周里，每天都下雨。那就是7天中的7天。很简单。一周后，你被问及*上周下雨的频率是多少？*
- en: Recall
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 召回率
- en: It is the ratio of the number of days you correctly recalled the rain relative
    to the overall number of correct events. If you said it rained 7 days, that's
    100%. If you said it rained 4 days, then that's 57% recall. In this case, it means
    your recall was not so precise, so we have precision to recognize.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你在那一周内正确回忆起下雨的天数与总正确事件的数量的比率。如果你说下了7天雨，那就是100%。如果你说下了4天雨，那么那就是57%的召回率。在这种情况下，这意味着你的回忆并不那么精确，所以我们有精确度来识别。
- en: Precision
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精确度
- en: It is the ratio of times you correctly recalled it was going to rain, relative
    to the total number of days in that week.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你在那一周内正确回忆起将要下雨的次数与那一周总天数的比率。
- en: For us, if our machine learning algorithm is good at recall, it doesn't necessarily
    mean it's good at precision. Makes sense? That gets us into other things such
    as F1 scores, which we'll leave for another day.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们来说，如果我们的机器学习算法在召回率方面做得好，这并不意味着它在精确度方面也做得好。这说得通吗？这让我们进入了其他事物，比如F1分数，我们将在另一天讨论。
- en: Error type visualization
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误类型可视化
- en: 'Here are some visualizations that may be of help:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些可能有助于理解的可视化：
- en: '![](img/ea7d0942-166e-4cef-befb-29221e671d56.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ea7d0942-166e-4cef-befb-29221e671d56.png)'
- en: 'Identification of true positives versus false negatives:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 真阳性与假阴性的识别：
- en: '![](img/c1a2f8e6-bd4d-4696-ab9e-27bf8a3ca144.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c1a2f8e6-bd4d-4696-ab9e-27bf8a3ca144.png)'
- en: 'After using the confusion matrix to compute the statistics, the scatter plot
    is created and everything is identified:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用混淆矩阵计算统计数据后，会创建散点图，并识别所有内容：
- en: '![](img/d96075af-68b0-44bf-919b-1505b414d992.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d96075af-68b0-44bf-919b-1505b414d992.png)'
- en: Summary
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we devoted a lot of time towards decision trees; what they
    are, how we can use them, and how they can benefit us in our applications. In
    our next chapter we are going to enter the world of **Deep Belief Networks** (**DBNs**),
    what they are, and how we can use them. We'll even talk a little bit about what
    a computer dreams, when it dreams!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们投入了大量时间来介绍决策树；它们是什么，我们如何使用它们，以及它们如何在我们应用中带来好处。在下一章中，我们将进入**深度信念网络**（**DBNs**）的世界，了解它们是什么，以及我们如何使用它们。我们甚至还会谈谈计算机做梦时的情况！
- en: References
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Bishop, C. M., 2007\. *Pattern Recognition and Machine Learning (Information
    Science and Statistics).* 1st ed. 2006\. Corr. 2nd printing ed. s.l.: Springer.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bishop, C. M., 2007\. *模式识别与机器学习（信息科学和统计学).* 第1版，2006年校对第2次印刷版。s.l.: Springer.'
- en: Fayyad, U. M. & Irani, K. B., 1992\. [http://deepblue.lib.umich.edu/bitstream/2027.42/46964/1/10994_2004_Article_422458.pdf](http://deepblue.lib.umich.edu/bitstream/2027.42/46964/1/10994_2004_Article_422458.pdf).
    *Machine Learning,* January, 8(1), pp. 87-102.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fayyad, U. M. & Irani, K. B., 1992\. [http://deepblue.lib.umich.edu/bitstream/2027.42/46964/1/10994_2004_Article_422458.pdf](http://deepblue.lib.umich.edu/bitstream/2027.42/46964/1/10994_2004_Article_422458.pdf).
    *机器学习，* 1月，8(1)，第87-102页。
- en: Quinlan, J. R., 1986\. [http://www.dmi.unict.it/~apulvirenti/agd/Qui86.pdf](http://www.dmi.unict.it/~apulvirenti/agd/Qui86.pdf).
    *Machine Learning,* 1(1), pp. 81-106.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Quinlan, J. R., 1986\. [http://www.dmi.unict.it/~apulvirenti/agd/Qui86.pdf](http://www.dmi.unict.it/~apulvirenti/agd/Qui86.pdf).
    *Machine Learning,* 第 1 卷, 第 1 期, 第 81-106 页.
- en: 'Quinlan, J. R., 1993\. *C4.5: Programs for Machine Learning (Morgan Kaufmann
    Series in Machine Learning).* 1 ed. s.l.: Morgan Kaufmann.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Quinlan, J. R., 1993\. *C4.5: 机器学习程序 (Morgan Kaufmann 机器学习系列).* 第 1 版. s.l.:
    Morgan Kaufmann.'
- en: Shotton, J. et al., 2011\. [http://research.microsoft.com/apps/pubs/default.aspx?id=145347](http://research.microsoft.com/apps/pubs/default.aspx?id=145347)*.*
    s.l., s.n.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shotton, J. 等人, 2011\. [http://research.microsoft.com/apps/pubs/default.aspx?id=145347](http://research.microsoft.com/apps/pubs/default.aspx?id=145347)*.*
    s.l., s.n.
- en: Viola, P. & Jones, M., 2001\. *Robust Real-time Object Detection.* s.l., s.n.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Viola, P. & Jones, M., 2001\. *鲁棒实时目标检测.* s.l., s.n.
- en: 'Mitchell, T. M., 1997\. Decision Tree Learning. In:: *Machine Learning (McGraw-Hill
    Series in Computer Science).* s.l.: McGraw Hill.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mitchell, T. M., 1997\. 决策树学习. In:: *机器学习 (McGraw-Hill 计算机科学系列).* s.l.: McGraw
    Hill.'
- en: 'Mitchell, T. M., 1997\. *Machine Learning (McGraw-Hill Series in Computer Science).*
    Boston(MA): WCB/McGraw-Hill.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mitchell, T. M., 1997\. *机器学习 (McGraw-Hill 计算机科学系列).* 波士顿 (MA): WCB/McGraw-Hill.'
- en: Esmeir, S. & Markovitch, S., 2007\. [http://jmlr.csail.mit.edu/papers/volume8/esmeir07a/esmeir07a.pdf](http://jmlr.csail.mit.edu/papers/volume8/esmeir07a/esmeir07a.pdf).
    *J. Mach. Learn. Res.,* May, Volume 8, pp. 891-933.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Esmeir, S. & Markovitch, S., 2007\. [http://jmlr.csail.mit.edu/papers/volume8/esmeir07a/esmeir07a.pdf](http://jmlr.csail.mit.edu/papers/volume8/esmeir07a/esmeir07a.pdf).
    *J. Mach. Learn. Res.,* 五月, 第 8 卷, 第 891-933 页.
- en: Hyafil, L. & Rivest, R. L., 1976\. Constructing Optimal Binary Decision Trees
    is NP-complete. *Information Processing Letters,* 5(1), pp. 15-17.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hyafil, L. & Rivest, R. L., 1976\. 构建最优二叉决策树是 NP 完全的. *信息处理快报,* 第 5 卷, 第 1 期,
    第 15-17 页.
- en: '[https://en.wikipedia.org/wiki/Ross_Quinlan](https://en.wikipedia.org/wiki/Ross_Quinlan).'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://en.wikipedia.org/wiki/Ross_Quinlan](https://en.wikipedia.org/wiki/Ross_Quinlan).'
