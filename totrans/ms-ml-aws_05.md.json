["```py\nhousing_df = pd.read_csv(SRC_PATH + 'train.csv')\nhousing_df.head()\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nhousing_df_reordered = housing_df[[label] + training_features]\n\ntraining_df, test_df = train_test_split(housing_df_reordered, \n                                        test_size=0.2)\n```", "```py\nfrom sklearn.linear_model import LinearRegression\n\nregression = LinearRegression()\n\ntraining_features = ['crim', 'zn', 'indus', 'chas', 'nox', \n                     'rm', 'age', 'dis', 'tax', 'ptratio', 'lstat']\n\nmodel = regression.fit(training_df[training_features], \n                       training_df['medv'])\n```", "```py\ntest_df['predicted_medv'] = model.predict(test_df[training_features])\ntest_df.head()\n```", "```py\ntest_df[['medv', 'predicted_medv']].plot(kind='scatter', \n                                         x='medv', \n                                         y='predicted_medv')\n```", "```py\nfrom sklearn.metrics import r2_score\n\nr2_score(test_df['medv'], test_df['predicted_medv'])\n\n0.695\n```", "```py\nmodel.coef_\n\narray([-7.15121101e-02, 3.78566895e-02, -4.47104045e-02, 5.06817970e+00,\n -1.44690998e+01, 3.98249374e+00, -5.88738235e-03, -1.73656446e+00,\n 1.01325463e-03, -6.18943939e-01, -6.55278930e-01])\n\nmodel.intercept_\n32.20\n```", "```py\nhousing_df = sql.read.csv(SRC_PATH + 'train.csv', header=True, inferSchema=True)\n```", "```py\nfrom pyspark.ml.feature import VectorAssembler\n\ntraining_features = ['crim', 'zn', 'indus', 'chas', 'nox', \n                     'rm', 'age', 'dis', 'tax', 'ptratio', 'lstat']\n\nvector_assembler = VectorAssembler(inputCols=training_features, \n                                   outputCol=\"features\")\n\ndf_with_features_vector = vector_assembler.transform(housing_df)\n```", "```py\ntrain_df, test_df = df_with_features_vector.randomSplit([0.8, 0.2], \n                                                        seed=17)\n```", "```py\nfrom pyspark.ml.regression import LinearRegression\n\nlinear = LinearRegression(featuresCol=\"features\", labelCol=\"medv\")\nlinear_model = linear.fit(train_df)\n```", "```py\npredictions_df = linear_model.transform(test_df)\npredictions_df.show(3)\n```", "```py\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nevaluator = RegressionEvaluator(labelCol=\"medv\", \n                                predictionCol=\"prediction\", \n                                metricName=\"r2\")\nevaluator.evaluate(predictions_df)\n```", "```py\nimport sagemaker\nfrom sagemaker import get_execution_role\nimport json\nimport boto3\n\nsess = sagemaker.Session()\nrole = get_execution_role()\n\nbucket = \"mastering-ml-aws\"\nprefix = \"chapter3/linearmodels\"\n\ntrain_path = prefix + '/train'\nvalidation_path = prefix + '/validation'\n\nsess.upload_data(path='training-housing.csv', \n                 bucket=bucket, \n                 key_prefix=train_path)\nsess.upload_data(path='testing-housing.csv', \n                 bucket=bucket, \n                 key_prefix=validation_path)\n\ns3_train_data = 's3://{}/{}'.format(bucket, train_path)\ns3_validation_data = 's3://{}/{}'.format(bucket, validation_path)\n```", "```py\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\nfrom sagemaker.session import s3_input\n\ncontainer = get_image_uri(boto3.Session().region_name, 'linear-learner')\ns3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n\nlinear = sagemaker.estimator.Estimator(container,\n                                       role,\n                                       train_instance_count=1, \n                                       train_instance_type='ml.c4.xlarge',\n                                       output_path=s3_output_location,\n                                       sagemaker_session=sess)\n```", "```py\nlinear.set_hyperparameters(feature_dim=len(training_features),\npredictor_type='regressor',\nmini_batch_size=1)\n\nlinear.fit({'train': s3_input(s3_train_data, \ncontent_type='text/csv'), \n'test': s3_input(s3_validation_data, \ncontent_type='text/csv')})\n```", "```py\ntransformer = linear.transformer(instance_count=1, instance_type='ml.m4.xlarge', output_path=s3_output_location)\n\ntransformer.transform(s3_validation_data, content_type='text/csv')\ntransformer.wait()\n```", "```py\n {\"score\":18.911674499511719}\n {\"score\":41.916255950927734}\n {\"score\":20.833599090576172}\n {\"score\":38.696208953857422}\n```", "```py\npredictions = pd.read_json('testing-housing.csv.out',lines=True)\n```", "```py\nevaluation_df = pd.DataFrame({'actual':list(test_df[label]),\n                              'predicted':list(predictions['score'])})\n```", "```py\nfrom sklearn.metrics import r2_score\n\nr2_score(evaluation_df['actual'], evaluation_df['predicted'])\n```", "```py\nfrom pyspark.ml.classification import LogisticRegression\nlogistic_regression = LogisticRegression(featuresCol=\"features\", \n                                         labelCol=\"label\")\nlogistic_model = logistic_regression.fit(cleaned_training_df)\n```"]