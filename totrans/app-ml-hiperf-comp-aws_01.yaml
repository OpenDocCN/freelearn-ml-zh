- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: High-Performance Computing Fundamentals
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高性能计算（HPC）基础
- en: '**High-Performance Computing** (**HPC**) impacts every aspect of your life,
    from your morning coffee to driving a car to get to the office, knowing the weather
    forecast, your vaccinations, movies that you watch, flights that you take, games
    that you play, and many other aspects. Many of our actions leave a digital footprint,
    leading to the generation of massive amounts of data. In order to process such
    data, we need a large amount of processing power. HPC, also known as *accelerated
    computing*, aggregates the computing power from a cluster of nodes and divides
    the work among various interconnected processors, to achieve much higher performance
    than could be achieved by using a single computer or machine, as shown in *Figure
    1.1*. This helps in solving complex scientific and engineering problems, in critical
    business applications such as drug discovery, flight simulations, supply chain
    optimization, financial risk analysis, and so on:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**高性能计算**（**HPC**）影响着你生活的方方面面，从你的早晨咖啡到开车去办公室，了解天气预报，接种疫苗，观看的电影，乘坐的航班，玩的游戏，以及许多其他方面。我们中的许多行为都留下了数字足迹，导致产生了大量数据。为了处理这些数据，我们需要大量的处理能力。高性能计算（HPC），也称为*加速计算*，将来自节点集群的计算能力聚合起来，并将工作分配给各种相互连接的处理器，从而实现比使用单一计算机或机器所能达到的更高的性能，如图*图1.1*所示。这有助于解决复杂的科学和工程问题，在药物发现、飞行模拟、供应链优化、金融风险评估等关键业务应用中：'
- en: '![Figure 1.1 – HPC](img/B18493_01_001.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1 – HPC](img/B18493_01_001.jpg)'
- en: Figure 1.1 – HPC
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – HPC
- en: For example, drug discovery is a data-intensive process, which involves computationally
    heavy calculations to simulate how virus protein binds with human protein. This
    is an extremely expensive process and may take weeks or months to finish. With
    the unification of **Machine Learning** (**ML**) with accelerated computing, researchers
    can simulate drug interactions with protein with higher speed and accuracy. This
    leads to faster experimentation and significantly reduces the time to market.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，药物发现是一个数据密集型过程，涉及大量的计算来模拟病毒蛋白与人类蛋白的结合。这是一个极其昂贵的过程，可能需要数周或数月才能完成。通过将**机器学习**（**ML**）与加速计算相结合，研究人员可以以更高的速度和精度模拟药物与蛋白的相互作用。这导致实验速度加快，显著缩短了上市时间。
- en: In this chapter, we will learn the fundamentals and importance of HPC, followed
    by technological advancements in the area. We will understand the constraints
    and how developers can benefit from the elasticity of the cloud while still optimizing
    costs to innovate faster to gain a competitive business advantage.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习高性能计算（HPC）的基本原理和重要性，随后介绍该领域的技术进步。我们将了解限制因素以及开发者如何从云的弹性中受益，同时优化成本以更快地创新，从而获得竞争优势。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Why do we need HPC?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们为什么需要高性能计算（HPC）？
- en: Limitations of on-premises HPC
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原地高性能计算（HPC）的限制
- en: Benefits of doing HPC on the cloud
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在云上执行高性能计算（HPC）的好处
- en: Driving innovation across industries with HPC
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用高性能计算（HPC）推动各行业创新
- en: Why do we need HPC?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们为什么需要高性能计算（HPC）？
- en: According to Statista, the rate of growth of data globally is forecast to increase
    rapidly and reached 64.2 zettabytes in 2020\. By 2025, the volume of data is estimated
    to grow to more than 180 zettabytes. Due to the COVID-19 pandemic, data growth
    in 2020 reached a new high as more people were learning online and working remotely
    from home. As data is continuously increasing, the need to be able to analyze
    and process it also increases. This is where HPC is a useful mechanism. It helps
    organizations to think beyond their existing capabilities and explore possibilities
    with advanced computing technologies. Today HPC applications, which were once
    confined to large enterprises and academia, are trending across a wide range of
    industries. Some of these industries include material sciences, manufacturing,
    product quality improvement, genomics, numerical optimization, computational fluid
    dynamics, and many more. The list of applications for HPC will continue to increase,
    as cloud infrastructure is making it accessible to more organizations irrespective
    of their size, while still optimizing cost, helping to innovate faster and gain
    a competitive advantage.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Statista的数据，全球数据的增长速度预计将迅速增加，并在2020年达到64.2泽字节。到2025年，数据量预计将增长到超过180泽字节。由于COVID-19大流行，2020年的数据增长达到了新高，因为更多的人开始在线学习并远程在家工作。随着数据的持续增加，能够分析和处理数据的需求也在增加。这就是高性能计算发挥作用的地方。它帮助组织超越现有能力，并利用先进的计算技术探索可能性。如今，曾经仅限于大型企业和学术界的高性能计算应用正在各行各业中流行。这些行业包括材料科学、制造业、产品质量改进、基因组学、数值优化、计算流体动力学等。随着云基础设施使更多组织无论规模大小都能访问高性能计算，其应用列表将继续增加，同时优化成本，帮助更快地进行创新并获得竞争优势。
- en: Before we take a deeper look into doing HPC on the cloud, let’s understand the
    limitations of running HPC applications on-premises, and how we can overcome them
    by using specialized HPC services provided by the cloud.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们更深入地探讨在云上执行高性能计算之前，让我们了解在本地运行高性能计算应用的局限性，以及我们如何通过使用云提供的专业高性能计算服务来克服这些局限性。
- en: Limitations of on-premises HPC
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地高性能计算的局限性
- en: HPC applications are often based on complex models trained on a large amount
    of data, which require high-performing hardware such as **Graphical Processing
    Units** (**GPUs**) and software for distributing the workload among different
    machines. Some applications may need parallel processing while others may require
    low-latency and high-throughput networking. Similarly, applications such as gaming
    and video analysis may need performance acceleration using a fast input or output
    subsystem and GPUs. Catering to all of the different types of HPC applications
    on-premises might be daunting in terms of cost and maintenance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 高性能计算应用通常基于大量数据训练的复杂模型，这需要高性能硬件，如**图形处理单元**（**GPU**）以及在不同机器间分配工作负载的软件。一些应用可能需要并行处理，而其他应用可能需要低延迟和高吞吐量的网络。同样，游戏和视频分析等应用可能需要使用快速输入/输出子系统以及GPU来加速性能。在本地满足所有不同类型的高性能计算应用在成本和维护方面可能令人望而却步。
- en: 'Some of the well-known challenges include, but are not limited to, the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一些已知的挑战包括但不限于以下内容：
- en: High upfront capital investment
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高额前期资本投资
- en: Long procurement cycles
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 长采购周期
- en: Maintaining the infrastructure over its life cycle
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在整个生命周期内维护基础设施
- en: Technology refreshes
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技术更新
- en: Forecasting the annual budget and capacity requirement
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测年度预算和容量需求
- en: Due to the above-mentioned constraints, planning for an HPC system can be a
    grueling process, **Return On Investment** (**ROI**) for which might be difficult
    to justify. This can be a barrier to innovation, with slow growth, reduced efficiency,
    lost opportunities, and limited scalability and elasticity. Let’s understand the
    impact of each of these in detail.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于上述限制，规划一个高性能计算系统可能是一个艰巨的过程，其**投资回报率**（**ROI**）可能难以证明。这可能会成为创新的障碍，导致增长缓慢、效率降低、机会丧失以及可扩展性和弹性有限。让我们详细了解这些影响。
- en: Barrier to innovation
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创新障碍
- en: The constraints of on-premises infrastructure can limit the system design, which
    will be more focused on the availability of the hardware instead of the business
    use case. You might not consider some new ideas if they are not supported by the
    existing infrastructure, thus obstructing your creativity and hindering innovation
    within the organization.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本地基础设施的约束可能会限制系统设计，使其更多地关注硬件的可用性，而不是业务用例。如果你的一些新想法没有得到现有基础设施的支持，你可能会考虑不到这些想法，从而阻碍你的创造力和组织内的创新。
- en: Reduced efficiency
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 效率降低
- en: Once you finish developing the various components of the system, you might have
    to wait in long prioritized queues to test your jobs, which might take weeks,
    even if it takes only a few hours to run. On-premises infrastructure is designed
    to capitalize on the utilization of expensive hardware, often resulting in very
    convoluted policies for prioritizing the execution of jobs, thus decreasing your
    productivity and ability to innovate.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你完成了系统各个组件的开发，你可能不得不在优先级队列中等待很长时间来测试你的作业，这可能会花费数周时间，即使运行时间只需要几个小时。本地基础设施旨在利用昂贵的硬件，通常会导致非常复杂的作业执行优先级策略，从而降低你的生产力和创新能力。
- en: Lost opportunities
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错过的机会
- en: In order to take full advantage of the latest technology, organizations have
    to refresh their hardware. Earlier, the typical refresh cycle of three years was
    enough to stay current, to meet the demands of HPC workloads. However, due to
    fast technological advancements and a faster pace of innovation, organizations
    need to refresh their infrastructure more often, otherwise, it might have a larger
    downstream business impact in terms of revenue. For example, technologies such
    as **Artificial Intelligence** (**AI**), ML, data visualization, risk analysis
    of financial markets, and so on, are pushing the limits of on-premises infrastructure.
    Moreover, due to the advent of the cloud, a lot of these technologies are cloud
    native, and deliver higher performance on large datasets when running in the cloud,
    especially with workloads that use transient data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用最新技术，组织必须更新他们的硬件。以前，典型的三年更新周期足以保持最新状态，以满足高性能计算工作负载的需求。然而，由于技术进步迅速和创新步伐加快，组织需要更频繁地更新其基础设施，否则可能会对收入产生更大的下游业务影响。例如，人工智能（**AI**）、机器学习（ML）、数据可视化、金融市场风险分析等技术正在推动本地基础设施的极限。此外，由于云的出现，许多这些技术都是云原生，在云上运行时在大数据集上提供更高的性能，尤其是在使用临时数据的工作负载中。
- en: Limited scalability and elasticity
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性和弹性有限
- en: HPC applications rely heavily on infrastructure elements such as containers,
    GPUs, and serverless technologies, which are not readily available in an on-premises
    environment, and often have a long procurement and budget approval process. Moreover,
    maintaining these environments, making sure they are fully utilized, and even
    upgrading the OS or software packages, requires skills and dedicated resources.
    Deploying different types of HPC applications on the same hardware is very limiting
    in terms of scalability and flexibility and does not provide you with the right
    tools for the job.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 高性能计算应用严重依赖于容器、GPU和无服务器技术等基础设施元素，这些元素在本地环境中并不容易获得，并且通常有一个漫长的采购和预算审批流程。此外，维护这些环境，确保它们得到充分利用，甚至升级操作系统或软件包，都需要技能和专用资源。在相同的硬件上部署不同类型的高性能计算应用在可扩展性和灵活性方面非常有限，并且不能为你提供完成工作的正确工具。
- en: Now that we understand the limitations of doing HPC on-premises, let’s see how
    we can overcome them by running HPC workloads on the cloud.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了在本地进行高性能计算的限制，那么让我们看看我们如何通过在云上运行高性能计算工作负载来克服这些限制。
- en: Benefits of doing HPC on the cloud
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在云上运行高性能计算（HPC）的好处
- en: With virtually unlimited capacity on the cloud, you can move beyond the constraints
    of on-premises HPC. You can reimagine new approaches based on the business use
    case, experiment faster, and gain insights from large amounts of data, without
    the need for costly on-premises upgrades and long procurement cycles. You can
    run complex simulations and deep learning models in the cloud and quickly move
    from idea to market using scalable compute capacity, high-performance storage,
    and high-throughput networking. In summary, it enables you to drive innovation,
    collaborate among distributed teams, improve operational efficiency, and optimize
    performance and cost. Let’s take a deeper look into each of these benefits.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在云上几乎拥有无限容量，您可以超越本地高性能计算的限制。您可以根据业务用例重新构想新的方法，更快地进行实验，并从大量数据中获得洞察，而无需进行昂贵的本地升级和漫长的采购周期。您可以在云上运行复杂的模拟和深度学习模型，并利用可扩展的计算能力、高性能存储和高吞吐量网络，快速从想法过渡到市场。总之，它使您能够推动创新，在分布式团队之间协作，提高运营效率，并优化性能和成本。让我们更深入地了解这些益处的每一个。
- en: Drives innovation
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推动创新
- en: Moving HPC workloads to the cloud, helps you break barriers to innovation, and
    opens the door for unlimited possibilities. You can quickly fail forward, try
    out thousands of experiments, and make business decisions based on data. The benefit
    that I really like is that, once you solve the problem, it remains solved and
    you don’t have to revisit it after a system upgrade or a technology refresh. It
    eliminates reworking and the maintenance of hardware, lets you focus on the business
    use case, and enables you to quickly design, develop, and test new products. The
    elasticity offered by the cloud, allows you to grow and shrink the infrastructure
    as per the requirements. Additionally, cloud-based services offer native features,
    which remove the heavy lifting and let you adopt tested and verified HPC applications,
    without having to write and manage all the utility libraries on your own.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 将高性能计算（HPC）工作负载迁移到云端，有助于您打破创新的障碍，开启无限可能的大门。您可以快速失败并前进，尝试成千上万的实验，并基于数据进行商业决策。我最喜欢的益处是，一旦您解决了问题，它就会得到解决，您在系统升级或技术更新后无需重新审视。它消除了返工和硬件维护，让您专注于业务用例，并使您能够快速设计、开发和测试新产品。云提供的弹性，允许您根据需求扩展和缩减基础设施。此外，基于云的服务提供原生功能，这可以减轻负担，让您无需自己编写和管理所有实用程序库，即可采用经过测试和验证的高性能计算（HPC）应用程序。
- en: Enables secure collaboration among distributed teams
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使分布式团队之间能够安全协作
- en: HPC workloads on the cloud allow you to share designs, data, visualizations,
    and other artifacts globally with your teams, without the need to duplicate or
    proliferate sensitive data. For example, building a digital twin (a real-time
    digital counterpart of a physical object) can help in predictive maintenance.
    It can get the state of the object in real time and it monitors and diagnoses
    the object (asset) to optimize its performance and utilization. To build a digital
    twin, a cross-team skill set is needed, which might be remotely located to capture
    data from various IoT sensors, performing extensive what-if analysis and meticulously
    building a simulation model to develop an accurate representation of the physical
    object. The cloud provides a collaboration platform, where different teams can
    interact with a simulation model in near real time, without moving or copying
    data to different locations, and ensures compliance with rapidly changing industry
    regulations. Moreover, you can use native features and services offered by the
    cloud, for example, AWS IoT TwinMaker, which can use the existing data from multiple
    sources, create virtual replicas of physical systems, and combine 3D models to
    give you a holistic view of your operations faster and with less effort. With
    a broad global presence of HPC technologies on the cloud, it allows you to work
    together with your remote teams across different geographies without trading off
    security and cost.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Amplifies operational efficiency
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Operational efficiency** means that you are able to support the development
    and execution of workloads, gain insights, and continuously improve the processes
    that are supporting your applications. The design principles and best practices
    include automating processes, making frequent and reversible changes, refining
    your operations frequently, and being able to anticipate and recover from failures.
    Having your HPC applications on the cloud enables you to do that, as you can version
    control your infrastructure as code, similar to your application code, and integrate
    it with your **Continuous Integration** and **Continuous Delivery** (**CI/CD**)
    pipelines. Additionally, with on-demand access to unlimited compute capacity,
    you will no longer have to wait in long queues for your jobs to run. You can skip
    the wait and focus on solving business critical problems, providing you with the
    right tools for the right job.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Optimizes performance
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Performance optimization involves the ability to use resources efficiently and
    to be able to maintain them as the application changes or evolves. Some of the
    best practices include making the implementation easier for your team, using serverless
    architectures where possible, and being able to experiment faster. For example,
    developing ML models and integrating them into your application requires special
    expertise, which can be alleviated by using out-of-the-box models provided by
    cloud vendors, such as services in the AI and ML stack by AWS. Moreover, you can
    leverage the compute, storage, and networking services specially designed for
    HPC and eliminate long procurement cycles for specialized hardware. You can quickly
    carry out benchmarking or load testing and use that data to optimize your workloads
    without worrying about cost, as you only pay for the amount of time you are using
    the resources on the cloud. We will understand this concept more in *Chapters
    5*, *Data Analysis*, and [*Chapter 6*](B18493_06.xhtml#_idTextAnchor116), *Distributed
    Training of Machine Learning Models*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Optimizes cost
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cost optimization is a continuous process of monitoring and improving resource
    utilization over an application’s life cycle. By adopting the pay-as-you-go consumption
    model and increasing or decreasing the usage depending on the business needs,
    you can achieve potential cost savings. You can quickly commission and decommission
    HPC clusters in minutes, instead of days or weeks. This lets you gain access to
    resources rapidly, as and when needed. You can measure the overall efficiency
    by calculating the business value achieved and the cost of delivery. With this
    data, you can make informed decisions as well as understanding the gains from
    increasing the application’s functionality and reducing cost.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'Running HPC in the cloud helps you overcome the limitations associated with
    traditional on-premises infrastructure: fixed capacity, long procurement cycles,
    technology obsolescence, high upfront capital investment, maintaining the hardware,
    and applying regular **Operating System** (**OS**) and software updates. The cloud
    gives you unlimited HPC capacity virtually, with the latest technology to promote
    innovation, which helps you design your architecture based on business needs instead
    of available hardware, minimizes the need for job queues, and improves operational
    and performance efficiency while still optimizing cost.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s see how different industries such as **Autonomous Vehicles** (**AVs**),
    manufacturing, media and entertainment, life sciences, and financial services
    are driving innovation with HPC workloads.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Driving innovation across industries with HPC
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every industry and type of HPC application poses different kinds of challenges.
    The HPC solutions provided by cloud vendors such as AWS help all companies, irrespective
    of their size, which leads to emerging HPC applications such as reinforcement
    learning, digital twins, supply chain optimization, and AVs.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look at some of the use cases in life sciences and healthcare,
    AV, and supply chain optimization.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Life sciences and healthcare
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In life sciences and the healthcare domain, a large amount of sensitive and
    meaningful data is captured almost every minute of the day. Using HPC technology,
    we can harness this data to gain meaningful insights into critical diseases to
    save lives by reducing the time taken testing lab samples, drug discovery, and
    much more, as well as meeting the core security and compliance requirements.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: The following are some of the emerging applications in the healthcare and life
    sciences domain.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Genomics
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can use cloud services provided by AWS to store and share genomic data securely,
    which helps you build and run predictive or real-time applications to accelerate
    the journey from genomic data to genomic insights. This helps to reduce data processing
    times significantly and perform casual analysis of critical diseases such as cancer
    and Alzheimer’s.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Imaging
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using computer vision and data integration services, you can elevate image analysis
    and facilitate long-term data retention. For example, by using ML to analyze MRI
    or X-ray scans, radiology companies can improve operational efficiency and quickly
    generate lab reports for their patients. Some of the technologies provided by
    AWS for imaging include Amazon EC2 GPU instances, AWS Batch, AWS ParallelCluster,
    AWS DataSync, and Amazon SageMaker, which we will discuss in detail in subsequent
    chapters.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Computational chemistry and structure-based drug design
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Combining the state-of-the-art deep learning models for protein classification,
    advancements in protein structure solutions, and algorithms for describing 3D
    molecular models with HPC computing resources, allows you to grow and reduce the
    time to market drastically. For example, in a project performed by Novartis on
    the AWS cloud, where they were able to screen 10 million compounds against a common
    cancer target in less than a week, based on their internal calculations, if they
    had performed a similar experiment in-house, then it would have resulted in about
    a $40 million investment. By running this experiment on the cloud using AWS services
    and features, they were able to use their 39 years of computational chemistry
    data and knowledge. Moreover, it only took 9 hours and $4,232 to conduct the experiment,
    hence increasing their pace of innovation and experimentation. They were able
    to successfully identify three out of the ten million compounds, that were screened.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand some of the applications in the life sciences and healthcare
    domain, let us discuss how the automobile and transport industry is using HPC
    for building AVs.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: AVs
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The advancement of deep learning models such as reinforcement learning, object
    detection, and image segmentation, as well technological advancements in compute
    technology, and deploying models on edge devices, have paved the way for AV. In
    order to design and build an AV, all the components of the system have to work
    in tandem, including planning, perception, and control systems. It also requires
    collecting and processing massive amounts of data and using it to create a feedback
    loop, for vehicles to adjust their state based on the changing condition of the
    traffic on roads in real time. This entails having high I/O performance, networking,
    specialized hardware coprocessors such as GPUs or **Field Programmable Gate Arrays**
    (**FPGAs**), as well as analytics and deep learning frameworks. Moreover, before
    an AV can even start testing on actual roads, it has to undergo millions of miles
    of simulation to demonstrate safety performance, due to the high dimensionality
    of the environment, which is complex and time-consuming. By using the AWS cloud’s
    virtually unlimited compute and storage capacity, support for advanced deep learning
    frameworks, and purpose-built services, you can drive a faster time to market.
    For example, In 2017, Lyft, an American transportation company, launched its AV
    division. To enhance the performance and safety of its system, it uses petabytes
    of data collected from its AV fleet to execute millions of simulations every year,
    which involves a lot of compute power. To run these simulations at a lower cost,
    they decided to take advantage of unused compute capacity on the AWS cloud, by
    using Amazon EC2 Spot Instances, which also helped them to increase their capacity
    to run the simulations at this magnitude.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Next, let us understand supply chain optimization and its processes!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Supply chain optimization
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Supply chains are worldwide networks of manufacturers, distributors, suppliers,
    logistics, and e-commerce retailers that work together to get products from the
    factory to the customer’s door without delays or damage. By enabling information
    flow through these networks, you can automate decisions without any human intervention.
    The key attributes to consider are real-time inventory forecasts, end-to-end visibility,
    and the ability to track and trace the entire production process with unparalleled
    efficiency. Your teams will no longer have to handle the minuscular details associated
    with supply chain decisions. With automation and ML you can resolve bottlenecks
    in product movement. For example, in the event of a pandemic or natural disaster,
    you can quickly divert goods to alternative shipping routes without affecting
    their on-time delivery.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of using ML to improve supply chain processes:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '**Demand Forecasting**: You can combine a time series with additional correlated
    data, such as holidays, weather, and demographic events, and use deep learning
    models such as DeepAR to get more accurate results. This will help you to meet
    variable demand and avoid over-provisioning.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inventory Management**: You can automate inventory management using ML models
    to determine stock levels and reduce costs by preventing excess inventory. Moreover,
    you can use ML models for anomaly detection in your supply chain processes, which
    can help you in optimizing inventory management, and deflect potential issues
    more proactively, for example, by transferring stock to the right location using
    optimized routing ahead of time.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Boost Efficiency with Automated Product Quality Inspection**: By using computer
    vision models, you can identify product defects faster with improved consistency
    and accuracy at an early stage so that customers receive high-quality products
    in a timely fashion. This reduces the number of customer returns and insurance
    claims that are filed due to issues in product quality, thus saving costs and
    time.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the components of supply chain optimization discussed above need to work
    together as part of the workflow and therefore require low latency and high throughput
    in order to meet the goal of delivering an optimal quality product to a customer’s
    doorstep in a timely fashion. Using cloud services to build the workflow provides
    you with greater elasticity and scalability at an optimized cost. Moreover, with
    native purpose-built services, you can eliminate the heavy lifting and reduce
    the time to market.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started by understanding HPC fundamentals and its importance
    in processing massive amounts of data to gain meaningful insights. We then discussed
    the limitations of running HPC workloads on-premises, as different types of HPC
    applications will have different hardware and software requirements, which becomes
    time-consuming and costly to procure in-house. Moreover, it will hinder innovation
    as developers and engineers are limited to the availability of resources instead
    of the application requirements. Then, we talked about how having HPC workloads
    on the cloud can help in overcoming these limitations and foster collaboration
    across global teams, break barriers to innovation, improve architecture design,
    and optimize performance and cost. Cloud infrastructure has made the specialized
    hardware needed for HPC applications more accessible, which has led to innovation
    in this space across a wide range of industries. Therefore, in the last section,
    we discussed some emerging workloads in HPC, such as in life sciences and healthcare,
    supply chain optimization, and AVs, along with real-world examples.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive into data management and transfer, which is
    the first step to running HPC workloads on the cloud.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can check out the following links for additional information regarding
    this chapter’s topics:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.statista.com/statistics/871513/worldwide-data-created/](https://www.statista.com/statistics/871513/worldwide-data-created/)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://d1.awsstatic.com/whitepapers/Intro_to_HPC_on_AWS.pdf](https://d1.awsstatic.com/whitepapers/Intro_to_HPC_on_AWS.pdf)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/solutions/case-studies/novartis/](https://aws.amazon.com/solutions/case-studies/novartis/)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/solutions/case-studies/Lyft-level-5-spot/](https://aws.amazon.com/solutions/case-studies/Lyft-level-5-spot/)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://d1.awsstatic.com/psc-digital/2021/gc-700/supply-chain-ebook/Supply-Chain-eBook.pdf](https://d1.awsstatic.com/psc-digital/2021/gc-700/supply-chain-ebook/Supply-Chain-eBook.pdf)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://d1.awsstatic.com/HCLS%20Whitepaper%20.pdf](https://d1.awsstatic.com/HCLS%20Whitepaper%20.pdf)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
