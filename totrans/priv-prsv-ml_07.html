<html><head></head><body>
<div id="_idContainer071" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-87"><a id="_idTextAnchor095" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1.1">5</span></h1>
<h1 id="_idParaDest-88" class="calibre5"><a id="_idTextAnchor096" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.2.1">Developing Applications with Differential Privacy Using Open Source Frameworks</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.3.1">In this chapter, we will explore open source frameworks (</span><strong class="bold"><span class="kobospan" id="kobo.4.1">PyDP</span></strong><span class="kobospan" id="kobo.5.1">, </span><strong class="bold"><span class="kobospan" id="kobo.6.1">PipelineDP</span></strong><span class="kobospan" id="kobo.7.1">, </span><strong class="bold"><span class="kobospan" id="kobo.8.1">tmlt-analytics</span></strong><span class="kobospan" id="kobo.9.1">, </span><strong class="bold"><span class="kobospan" id="kobo.10.1">PySpark</span></strong><span class="kobospan" id="kobo.11.1">, </span><strong class="bold"><span class="kobospan" id="kobo.12.1">diffprivlib</span></strong><span class="kobospan" id="kobo.13.1">, </span><strong class="bold"><span class="kobospan" id="kobo.14.1">PyTorch</span></strong><span class="kobospan" id="kobo.15.1">, and </span><strong class="bold"><span class="kobospan" id="kobo.16.1">Opacus</span></strong><span class="kobospan" id="kobo.17.1">) used to develop machine learning, deep learning, and large-scale applications with the power of </span><span><span class="kobospan" id="kobo.18.1">differential privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.19.1">We will cover the following </span><span><span class="kobospan" id="kobo.20.1">main topics:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.21.1">Open source frameworks for implementing </span><span><span class="kobospan" id="kobo.22.1">differential privacy:</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.23.1">Introduction to the PyDP framework and its </span><span><span class="kobospan" id="kobo.24.1">key features</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.25.1">Examples and demonstrations of PyDP </span><span><span class="kobospan" id="kobo.26.1">in action</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.27.1">Developing a sample banking application with PyDP to showcase differential </span><span><span class="kobospan" id="kobo.28.1">privacy techniques</span></span></li></ul></li>
<li class="calibre11"><span class="kobospan" id="kobo.29.1">Protecting against membership </span><span><span class="kobospan" id="kobo.30.1">inference attacks:</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.31.1">Understanding membership inference attacks and their </span><span><span class="kobospan" id="kobo.32.1">potential risks</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.33.1">Techniques and strategies to safeguard against membership inference attacks when applying </span><span><span class="kobospan" id="kobo.34.1">differential privacy</span></span></li></ul></li>
<li class="calibre11"><span class="kobospan" id="kobo.35.1">Applying differential privacy on large datasets to protect </span><span><span class="kobospan" id="kobo.36.1">sensitive data:</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.37.1">Leveraging the open source PipelineDP framework to apply differential privacy on </span><span><span class="kobospan" id="kobo.38.1">large-scale datasets</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.39.1">Leveraging the open source Tumult Analytics and PySpark frameworks to apply differential privacy on </span><span><span class="kobospan" id="kobo.40.1">large datasets</span></span></li></ul></li>
<li class="calibre11"><span class="kobospan" id="kobo.41.1">Machine learning with </span><span><span class="kobospan" id="kobo.42.1">differential privacy:</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.43.1">Running a fraud detection classification model on synthetic data using </span><span><span class="kobospan" id="kobo.44.1">differential privacy</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.45.1">A clustering example, applying differential privacy using IBM’s open source </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.46.1">diffprivlib</span></strong></span><span><span class="kobospan" id="kobo.47.1"> framework</span></span></li></ul></li>
<li class="calibre11"><span class="kobospan" id="kobo.48.1">Deep learning with </span><span><span class="kobospan" id="kobo.49.1">differential privacy:</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.50.1">Implementing a fraud detection model using the PyTorch deep </span><span><span class="kobospan" id="kobo.51.1">learning framework</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.52.1">Utilizing the open source PyTorch and Opacus frameworks to develop deep learning models for fraud detection with </span><span><span class="kobospan" id="kobo.53.1">differential privacy</span></span></li></ul></li>
<li class="calibre11"><span class="kobospan" id="kobo.54.1">Differential privacy machine </span><span><span class="kobospan" id="kobo.55.1">learning frameworks</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.56.1">Limitations of differential privacy and some strategies to </span><span><span class="kobospan" id="kobo.57.1">overcome them</span></span></li>
</ul>
<h1 id="_idParaDest-89" class="calibre5"><a id="_idTextAnchor097" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.58.1">Open source frameworks to implement differential privacy</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.59.1">There are several open source frameworks available to implement differential privacy. </span><span class="kobospan" id="kobo.59.2">We will go through the PyDP framework in detail in </span><a id="_idIndexMarker397" class="pcalibre1 calibre6 pcalibre"/><span><span class="kobospan" id="kobo.60.1">this section.</span></span></p>
<h2 id="_idParaDest-90" class="calibre7"><a id="_idTextAnchor098" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.61.1">Introduction to the PyDP framework and its key features</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.62.1">Google has released an open </span><a id="_idIndexMarker398" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.63.1">source framework called differential privacy that facilitates the implementation of differential privacy. </span><span class="kobospan" id="kobo.63.2">This framework offers support for both ε- and (ε, δ)-differentially private statistics. </span><span class="kobospan" id="kobo.63.3">It includes various </span><a id="_idIndexMarker399" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.64.1">features such as the ability to introduce noise using Laplace and Gaussian mechanisms. </span><span class="kobospan" id="kobo.64.2">Additionally, the framework provides support for aggregated differential privacy algorithms including sum, count, mean, variance, and standard deviation. </span><span class="kobospan" id="kobo.64.3">The libraries within this framework are implemented in the C++, Java, and Go languages, and it also offers a </span><strong class="bold"><span class="kobospan" id="kobo.65.1">command-line interface</span></strong><span class="kobospan" id="kobo.66.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.67.1">CLI</span></strong><span class="kobospan" id="kobo.68.1">) to execute</span><a id="_idIndexMarker400" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.69.1"> differential privacy SQL queries. </span><span class="kobospan" id="kobo.69.2">For further information, you can visit the GitHub repository </span><span><span class="kobospan" id="kobo.70.1">at </span></span><a href="https://github.com/google/differential-privacy" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.71.1">https://github.com/google/differential-privacy</span></span></a><span><span class="kobospan" id="kobo.72.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.73.1">PyDP, developed by </span><a id="_idIndexMarker401" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.74.1">OpenMined in 2020, is another framework that implements Python wrapper functions for Google’s differential privacy tools. </span><span class="kobospan" id="kobo.74.2">While PyDP is not an exhaustive implementation of Google’s differential privacy toolkit, it supports a subset of ε-differentially private algorithms from Google’s toolkit. </span><span class="kobospan" id="kobo.74.3">These algorithms enable the generation of aggregate statistics over numeric datasets that contain private or sensitive information. </span><span class="kobospan" id="kobo.74.4">You can</span><a id="_idIndexMarker402" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.75.1"> find the PyDP framework </span><span><span class="kobospan" id="kobo.76.1">at </span></span><a href="https://github.com/OpenMined/PyDP" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.77.1">https://github.com/OpenMined/PyDP</span></span></a><span><span class="kobospan" id="kobo.78.1">.</span></span></p>
<h2 id="_idParaDest-91" class="calibre7"><a id="_idTextAnchor099" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.79.1">Examples and demonstrations of PyDP in action</span></h2>
<h3 class="calibre9"><span class="kobospan" id="kobo.80.1">Installation of PyDP</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.81.1">PyDP installation is done the </span><a id="_idIndexMarker403" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.82.1">same way as installing any other </span><span><span class="kobospan" id="kobo.83.1">Python package.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.84.1">For Python 3.x, use </span><span><span class="kobospan" id="kobo.85.1">the following:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.86.1">
pip3 install python-dp</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.87.1">For earlier versions of Python, use </span><span><span class="kobospan" id="kobo.88.1">this line:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.89.1">
pip install python-dp</span></pre>
<h3 class="calibre9"><span class="kobospan" id="kobo.90.1">Sample program to calculate the mean using PyDP</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.91.1">PyDP supports the Laplacian noise </span><a id="_idIndexMarker404" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.92.1">mechanism and offers a range of aggregate functions such as sum, average, count, and more. </span><span class="kobospan" id="kobo.92.2">When calculating the mean, PyDP requires the provision of bounds in the form of lower and upper values. </span><span class="kobospan" id="kobo.92.3">To facilitate this, PyDP provides a class called </span><strong class="source-inline"><span class="kobospan" id="kobo.93.1">BoundedMean</span></strong><span class="kobospan" id="kobo.94.1">, which offers the </span><span><span class="kobospan" id="kobo.95.1">following constructors:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.96.1">
BoundedMean(epsilon: float, delta: float = 0, lower_bound: int, upper_bound)
BoundedMean(epsilon: float)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.97.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.98.1">BoundedMean</span></strong><span class="kobospan" id="kobo.99.1"> class in PyDP is used to calculate the differentially private mean of bounded data. </span><span class="kobospan" id="kobo.99.2">It utilizes the epsilon and delta parameters to provide privacy guarantees. </span><span class="kobospan" id="kobo.99.3">This class supports the</span><a id="_idIndexMarker405" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.100.1"> Laplacian noise mechanism to add privacy-preserving noise to the </span><span><span class="kobospan" id="kobo.101.1">mean calculation.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.102.1">Here is example code to demonstrate the </span><span><span class="kobospan" id="kobo.103.1">bounded mean:</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.104.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.105.1">code: Sample_Mean_Using_PyDP.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.106.1">
import pydp as dp
import numpy as np
from pydp.algorithms.laplacian import BoundedMean
#Generate simple data number from 1 to 10 in an array
data = np.arange(1,10,1)
# privacy budget as 0.6, delta as 0 and lower and upper bounds as 1 and 10
x = BoundedMean(0.6,0,1,10)
privacy_mean = x.quick_result(data)
mean = np.mean(data)
print("Data", data)
print("Normal Mean", mean)
print("Mean with differential privacy",privacy_mean )</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.107.1">This results in the </span><span><span class="kobospan" id="kobo.108.1">following output:</span></span></p>
<pre class="source-code">
<strong class="bold1"><span class="kobospan1" id="kobo.109.1">Data [1 2 3 4 5 6 7 8 9]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.110.1">Normal Mean 5.0</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.111.1">Mean with differential privacy 6.960764656372703</span></strong></pre>
<h2 id="_idParaDest-92" class="calibre7"><a id="_idTextAnchor100" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.112.1">Developing a sample banking application with PyDP to showcase differential privacy techniques</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.113.1">In this application scenario, we take </span><a id="_idIndexMarker406" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.114.1">the example of a financial bank that aims to collaborate with merchants, companies, and other banks to launch a marketing campaign while safeguarding the sensitive personal information of its customers. </span><span class="kobospan" id="kobo.114.2">Customers make purchases using their credit or debit cards in two different scenarios: offline transactions at merchant outlets, where the cards are physically swiped (known as card-present transactions), and online transactions, where card details such as the card number, name, expiry date, and CVV are entered (known as card-not-present transactions). </span><span class="kobospan" id="kobo.114.3">The objective is to provide credit card transaction data to support the campaign without revealing individual </span><span><span class="kobospan" id="kobo.115.1">customer details.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.116.1">To successfully launch marketing campaigns or loyalty programs, the bank needs to share certain transaction details such as the type of purchases, transaction volumes, and transaction values associated with specific locations. </span><span class="kobospan" id="kobo.116.2">This information allows the bank to partner with interested banks/merchants, enabling the promotion of large-scale product sales and the delivery of benefits </span><span><span class="kobospan" id="kobo.117.1">to customers.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.118.1">In this context, we will synthetically generate a significant number of transactions using predefined business rules and calculate statistics such as count, average, and sum for each location. </span><span class="kobospan" id="kobo.118.2">The intention is to share these aggregated statistics with the partnering companies without compromising </span><span><span class="kobospan" id="kobo.119.1">customer privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.120.1">There are two approaches to sharing these statistics. </span><span class="kobospan" id="kobo.120.2">The first approach involves sharing the aggregates as they are, which may potentially reveal private information about individual customers. </span><span class="kobospan" id="kobo.120.3">The second approach utilizes differential privacy to generate the aggregates, ensuring that they do not leak any sensitive customer information while </span><span><span class="kobospan" id="kobo.121.1">preserving privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.122.1">By applying differential privacy techniques, the bank can protect customer privacy by introducing carefully calibrated noise to the aggregated statistics. </span><span class="kobospan" id="kobo.122.2">This noise ensures that the shared aggregates do not disclose specific individuals’ details while still providing valuable insights for the marketing campaign and loyalty </span><span><span class="kobospan" id="kobo.123.1">program planning.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.124.1">By adopting differential </span><a id="_idIndexMarker407" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.125.1">privacy, the bank can strike a balance between data utility and privacy protection, allowing it to collaborate with companies and merchants while maintaining the confidentiality of </span><span><span class="kobospan" id="kobo.126.1">customer information.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.127.1">Let’s generate the synthetic datasets needed to develop this </span><span><span class="kobospan" id="kobo.128.1">banking application.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.129.1">The following is the </span><span><span class="kobospan" id="kobo.130.1">customer data:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer056">
<span class="kobospan" id="kobo.131.1"><img alt="Figure 5.1 – Customer Dataset" src="image/B16573_05_01.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.132.1">Figure 5.1 – Customer Dataset</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.133.1">The dataset used in this context comprises various attributes, including the customer ID, the location represented as latitude and longitude coordinates, the number of transactions per day, and the average transaction amount. </span><span class="kobospan" id="kobo.133.2">It is important to note that the actual credit card</span><a id="_idIndexMarker408" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.134.1"> number, </span><strong class="bold"><span class="kobospan" id="kobo.135.1">Card Verification Value</span></strong><span class="kobospan" id="kobo.136.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.137.1">CVV</span></strong><span class="kobospan" id="kobo.138.1">) code, and the expiry date associated with each customer’s card are maintained in a separate table and are not shown in the provided</span><a id="_idIndexMarker409" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.139.1"> dataset. </span><span class="kobospan" id="kobo.139.2">Furthermore, these parameters are not utilized in generating the statistical information. </span><span class="kobospan" id="kobo.139.3">In this particular example, the transactions generated pertain to card-present scenarios occurring at various merchant</span><a id="_idIndexMarker410" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.140.1"> locations, using </span><strong class="bold"><span class="kobospan" id="kobo.141.1">point-of-sale</span></strong><span class="kobospan" id="kobo.142.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.143.1">POS</span></strong><span class="kobospan" id="kobo.144.1">) terminals to swipe </span><span><span class="kobospan" id="kobo.145.1">the cards.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.146.1">The following is the sample POS </span><span><span class="kobospan" id="kobo.147.1">terminal data:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer057">
<span class="kobospan" id="kobo.148.1"><img alt="Figure 5.2 – Terminal Dataset" src="image/B16573_05_02.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.149.1">Figure 5.2 – Terminal Dataset</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.150.1">In this scenario, it is assumed that customers predominantly visit nearby merchant outlets for their day-to-day purchases, with the distance between the customer’s location and the merchant locations typically falling within a range of around </span><span><span class="kobospan" id="kobo.151.1">5 miles.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.152.1">To generate the transactions, the Euclidean distance between the customer’s location and the available merchant locations is calculated. </span><span class="kobospan" id="kobo.152.2">Using this distance information, merchants are randomly selected from the nearby options. </span><span class="kobospan" id="kobo.152.3">This approach ensures that the generated transactions reflect the realistic behavior of customers going to nearby merchants within a specific distance radius for </span><span><span class="kobospan" id="kobo.153.1">their purchases.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.154.1">The following is the </span><span><span class="kobospan" id="kobo.155.1">transaction data:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer058">
<span class="kobospan" id="kobo.156.1"><img alt="Figure 5.3 – Transaction Dataset" src="image/B16573_05_03.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.157.1">Figure 5.3 – Transaction Dataset</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.158.1">Let’s generate aggregates using differential privacy on this dataset so that it can then be shared with merchants/banks in</span><a id="_idIndexMarker411" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.159.1"> order to design marketing campaigns and </span><span><span class="kobospan" id="kobo.160.1">loyalty programs.</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.161.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.162.1">code: Sample_Finance_App_DP.ipynb</span></em></span></p>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.163.1"># unzip the transactions.csv.zip file (provided in this book’s GitHub repo </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.164.1">as transactions.csv).</span></strong></span></p>
<p class="calibre3"><a href="https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%205/transactions.csv.zip" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.165.1">https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%205/transactions.csv.zip</span></span></a></p>
<p class="calibre3"><span><span class="kobospan" id="kobo.166.1">Data loading:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.167.1">
import pydp as dp
from pydp.algorithms.laplacian import BoundedSum, BoundedMean, Count, Max
import pandas as pd
url = "transactions.csv"
df_actual = pd.read_csv(url, sep=",")
df = df_actual[['TRANSACTION_ID',
'TX_DATETIME','CUSTOMER_ID','TERMINAL_ID','TX_AMOUNT']]
df.head()</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer059">
<span class="kobospan" id="kobo.168.1"><img alt="Figure 5.4 – Sample transaction data" src="image/B16573_05_04.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.169.1">Figure 5.4 – Sample transaction data</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.170.1">In this section, we will generate differentially private aggregates for various scenarios. </span><span class="kobospan" id="kobo.170.2">The focus will be on </span><a id="_idIndexMarker412" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.171.1">comparing the results obtained using traditional statistical methods with those achieved through differential privacy techniques. </span><span class="kobospan" id="kobo.171.2">The following scenarios will </span><span><span class="kobospan" id="kobo.172.1">be explored:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.173.1">Mean transaction amount for a </span><span><span class="kobospan" id="kobo.174.1">given terminal</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.175.1">Mean transaction amount for terminal IDs 1 </span><span><span class="kobospan" id="kobo.176.1">to 100</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.177.1">Number of customers who make purchases worth $25 or more via terminals 1 </span><span><span class="kobospan" id="kobo.178.1">to 100</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.179.1">Maximum transaction amount for a </span><span><span class="kobospan" id="kobo.180.1">given terminal</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.181.1">Sum of the transaction amounts for each terminal on a given day </span><span><span class="kobospan" id="kobo.182.1">or month</span></span></li>
</ul>
<h3 class="calibre9"><span class="kobospan" id="kobo.183.1">Mean transaction amount for a given terminal</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.184.1">In order to calculate the average transaction amount for a given day or month via a specific POS terminal, we can define the following methods. </span><span class="kobospan" id="kobo.184.2">These methods will be used to compare the results obtained using traditional statistical methods with the aggregates generated through</span><a id="_idIndexMarker413" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.185.1"> differential </span><span><span class="kobospan" id="kobo.186.1">privacy techniques:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.187.1">Traditional average calculation</span></strong><span class="kobospan" id="kobo.188.1">: We will implement a method that calculates the average transaction amount for a given day or month on a particular POS terminal using traditional statistical methods. </span><span class="kobospan" id="kobo.188.2">This method will take as input the relevant transaction data, such as the transaction amounts and the date of the day or month of interest. </span><span class="kobospan" id="kobo.188.3">The average will be computed by summing all the transaction amounts and dividing the sum by the total number of transactions on the specified day or month on the chosen POS terminal. </span><span class="kobospan" id="kobo.188.4">The traditional average will serve as a baseline </span><span><span class="kobospan" id="kobo.189.1">for comparison.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.190.1">Differentially private average calculation</span></strong><span class="kobospan" id="kobo.191.1">: We will develop a method that leverages differential privacy techniques to calculate the differentially private average transaction amount for a given day or month on the selected POS terminal. </span><span class="kobospan" id="kobo.191.2">This method will take the same input as the traditional average calculation method. </span><span class="kobospan" id="kobo.191.3">It will utilize differential privacy mechanisms, such as adding noise to the aggregated statistics, to protect the privacy of individual transactions while generating the average. </span><span class="kobospan" id="kobo.191.4">The differentially private average will provide a privacy-preserving alternative to the traditional average. </span><span class="kobospan" id="kobo.191.5">By utilizing these methods and comparing the results, we can assess the differences between the traditional average calculation and the average generated through differential </span><span><span class="kobospan" id="kobo.192.1">privacy techniques.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.193.1">This analysis will demonstrate the impact of differential privacy on aggregate calculations and highlight the trade-off between accuracy and privacy preservation in generating average transaction amounts on a given day or month via a specific </span><span><span class="kobospan" id="kobo.194.1">POS terminal:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.195.1">
def mean_tx_amount(tid:int) -&gt; float:
    dft = df[df["TERMINAL_ID"] == tid]
    return statistics.mean(list(dft["TX_AMOUNT"]))
mean_tx_amount(1)
</span><strong class="bold1"><span class="kobospan1" id="kobo.196.1">56.22097378277154</span></strong><span class="kobospan1" id="kobo.197.1">
# calculates mean applying differential privacy
def private_mean_tx_amount(privacy_budget: float, tid:int) -&gt; float:
    x = BoundedMean(privacy_budget,1,1,300)
    dft = df[df["TERMINAL_ID"] == id]
    return x.quick_result(list(dft["TX_AMOUNT"]))
private_mean_tx_amount(0.6,1)
</span><strong class="bold1"><span class="kobospan1" id="kobo.198.1">220.98103940917645</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.199.1">In the preceding calculation, we can see the average generated using the traditional method returns 56.22</span><a id="_idIndexMarker414" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.200.1"> whereas the differentially private version produces an average of 220.98 for POS terminal ID 1. </span><span class="kobospan" id="kobo.200.2">In this way, the private average helps not to disclose the </span><span><span class="kobospan" id="kobo.201.1">actual average.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.202.1">Mean transaction amount for terminal IDs 1 to 100</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.203.1">Let’s generate the  mean transaction </span><a id="_idIndexMarker415" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.204.1">amount for the terminals 1 to 100 and make use of the private mean function </span><span><span class="kobospan" id="kobo.205.1">defined earlier:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.206.1">
terminal_mean_vs_privacy_means=[]
for i in range (1, 100):
    mean = mean_tx_amount(i)
    privacy_mean = private_mean_tx_amount(0.9,i)
    terminal_mean_vs_privacy_means.append([i, mean,privacy_mean])
terminal_mean_vs_privacy_means_df =
pd.DataFrame(terminal_mean_vs_privacy_means,
columns=['Terminal Id','Mean','privacy_mean'])
terminal_mean_vs_privacy_means_df.head(10)</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer060">
<span class="kobospan" id="kobo.207.1"><img alt="Figure 5.5 – Actual Mean vs Privacy Mean" src="image/B16573_05_05.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.208.1">Figure 5.5 – Actual Mean vs Privacy Mean</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.209.1">In the following sections, we will also generate the count and sum of transaction amounts for a given day or </span><a id="_idIndexMarker416" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.210.1">month on a specific POS terminal and compare the results obtained using traditional statistical methods with those generated through differential </span><span><span class="kobospan" id="kobo.211.1">privacy techniques.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.212.1">Number of customers who make purchases worth $25 or more via terminals 1 to 100</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.213.1">Next, we will implement a method that calculates the number of customers who made purchases of $25 or more on terminals 1 </span><span><span class="kobospan" id="kobo.214.1">to 100.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.215.1">This method will take the transaction</span><a id="_idIndexMarker417" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.216.1"> data as input, including the terminal number and the corresponding transaction amounts. </span><span class="kobospan" id="kobo.216.2">It will iterate through the transactions for each terminal ID from 1 to 100 and count the number of customers whose transaction amounts exceed $25. </span><span class="kobospan" id="kobo.216.3">The count will provide an indication of the customer base that made higher-value purchases, helping to analyze the impact of differential privacy on identifying such customers. </span><span class="kobospan" id="kobo.216.4">By utilizing this method, we can compare the results obtained using traditional statistical methods with the counts generated through differential </span><span><span class="kobospan" id="kobo.217.1">privacy techniques.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.218.1">This analysis will shed light on the differences between the approaches and demonstrate the effectiveness of differential privacy in identifying customers who made purchases worth more than $25 for terminals 1 to 100 while preserving </span><span><span class="kobospan" id="kobo.219.1">individual privacy:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.220.1">
def count_tx_amount_above(limit: float,tid) -&gt; int:
    dft = df[df["TERMINAL_ID"] == tid]
    return dft[dft.TX_AMOUNT &gt; limit].count()[0]
count_tx_amount_above(25.0,1)
</span><strong class="bold1"><span class="kobospan1" id="kobo.221.1">232</span></strong><span class="kobospan1" id="kobo.222.1">
def private_tx_amount_above(privacy_budget: float, limit: float,tid:int) -&gt; float:
    dft = df[df["TERMINAL_ID"] == tid]
    x = Count(privacy_budget, dtype="float")
    return x.quick_result(list(dft[dft.TX_AMOUNT &gt; limit]["TX_AMOUNT"]))
private_tx_amount_above(0.1,25.0,1)
</span><strong class="bold1"><span class="kobospan1" id="kobo.223.1">257</span></strong><span class="kobospan1" id="kobo.224.1">
terminal_amount_vs_privacy_amont=[]
for i in range (1, 100):
    count = count_tx_amount_above(25.0,i)
    privacy_count = private_tx_amount_above(0.1,25.0,i)
    terminal_amount_vs_privacy_amont.append([i, count,privacy_count])
terminal_amount_vs_privacy_amont_df =
pd.DataFrame(terminal_amount_vs_privacy_amont, columns=['Terminal Id','Count','privacy_count'])
terminal_amount_vs_privacy_amont_df.head(10)</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer061">
<span class="kobospan" id="kobo.225.1"><img alt="Figure 5.6 – Actual transaction counts vs privacy added counts" src="image/B16573_05_06.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.226.1">Figure 5.6 – Actual transaction counts vs privacy added counts</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.227.1">By adopting this approach, we ensure that the actual count of customers who made purchases worth more than $25 is not revealed or shared with banks/merchants. </span><span class="kobospan" id="kobo.227.2">Instead, we provide those parties with differentially private counts, thus preserving individual privacy while still offering valuable insights. </span><span class="kobospan" id="kobo.227.3">This allows banks/merchants to launch loyalty programs </span><a id="_idIndexMarker418" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.228.1">based on the differentially private counts, tailoring their initiatives based on the available data. </span><span class="kobospan" id="kobo.228.2">Thus, by employing differential privacy techniques, institutions can strike a balance between providing useful information for loyalty programs and safeguarding the sensitive details of </span><span><span class="kobospan" id="kobo.229.1">individual customers.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.230.1">Maximum transaction amount for a given terminal</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.231.1">Let’s define the functions to </span><a id="_idIndexMarker419" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.232.1">calculate the maximum transaction amount and the differentially </span><span><span class="kobospan" id="kobo.233.1">private amount:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.234.1">
def max_tx_amount(tid:int) -&gt; int:
    dft = df[df["TERMINAL_ID"] == tid]
    return dft.max()["TX_AMOUNT"]
max_tx_amount(1)
</span><strong class="bold1"><span class="kobospan1" id="kobo.235.1">87</span></strong><span class="kobospan1" id="kobo.236.1">
def private_max_tx_amount(privacy_budget: float,tid:int) -&gt; int:
    dft = df[df["TERMINAL_ID"] == tid]
    x = Max(epsilon = privacy_budget, lower_bound = 100.0, upper_bound = 50000.0, dtype="float"
    return x.quick_result(list(dft["TX_AMOUNT"]))
private_max_tx_amount(0.5,1)
</span><strong class="bold1"><span class="kobospan1" id="kobo.237.1">167.51941105013407</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.238.1">As we can see in the</span><a id="_idIndexMarker420" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.239.1"> preceding code, by employing differential privacy techniques, we can calculate an approximate maximum transaction amount for a given terminal while preserving the privacy of individual transactions. </span><span class="kobospan" id="kobo.239.2">These values depend on the privacy budget. </span><span class="kobospan" id="kobo.239.3">This example used 0.5 as the privacy budget. </span><span class="kobospan" id="kobo.239.4">This allows us to share valuable aggregated information with banks/merchants without compromising the sensitive details of individual customers. </span><span class="kobospan" id="kobo.239.5">In this example, the actual maximum transaction amount is 87. </span><span class="kobospan" id="kobo.239.6">With added noise based on the privacy budget (i.e., 0.5) the value becomes 167. </span><span class="kobospan" id="kobo.239.7">Thus, it may not be very useful in terms of utility. </span><span class="kobospan" id="kobo.239.8">This illustrates the trade-off between privacy and utility. </span><span class="kobospan" id="kobo.239.9">One needs to experiment with different privacy budgets to decide the best fit for the use case/application, deciding whether they want prioritize more privacy </span><a id="_idIndexMarker421" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.240.1">and less utility or more utility with </span><span><span class="kobospan" id="kobo.241.1">less privacy.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.242.1">Sum of the transaction amounts for each terminal on a given day or month</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.243.1">Let’s define the functions to calculate the sum of the transaction amounts and the differentially </span><span><span class="kobospan" id="kobo.244.1">private amounts:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.245.1">
def sum_tx_amount(tid:int) -&gt; float:
    dft = df[df["TERMINAL_ID"] == tid]
    return dft.sum()["TX_AMOUNT"]
sum_tx_amount(1)
</span><strong class="bold1"><span class="kobospan1" id="kobo.246.1">15011</span></strong><span class="kobospan1" id="kobo.247.1">
def private_sum_tx_amount(privacy_budget: float, tid:int) -&gt; float:
    dft = df[df["TERMINAL_ID"] == tid]
    x = BoundedSum(epsilon = privacy_budget, delta = 0,
lower_bound= 100.0, upper_bound = 50000.0, dtype="float")
    return x.quick_result(list(dft["TX_AMOUNT"]))
private_sum_tx_amount(0.6,1)
</span><strong class="bold1"><span class="kobospan1" id="kobo.248.1">27759.46144104004</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.249.1">As an exercise, you can implement the </span><strong class="source-inline"><span class="kobospan" id="kobo.250.1">count</span></strong><span class="kobospan" id="kobo.251.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.252.1">sum</span></strong><span class="kobospan" id="kobo.253.1"> functions for all POS terminals and compare the results </span><a id="_idIndexMarker422" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.254.1">obtained using traditional statistical methods with those generated through differential </span><span><span class="kobospan" id="kobo.255.1">privacy techniques.</span></span></p>
<h1 id="_idParaDest-93" class="calibre5"><a id="_idTextAnchor101" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.256.1">Protecting against membership inference attacks</span></h1>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.257.1">Membership inference attacks</span></strong><span class="kobospan" id="kobo.258.1"> pose a significant threat to the privacy of individuals in machine learning systems. </span><span class="kobospan" id="kobo.258.2">These attacks aim to determine whether a specific data point was part of the training dataset used to create a machine learning model, potentially exposing sensitive information </span><a id="_idIndexMarker423" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.259.1">about individuals. </span><span class="kobospan" id="kobo.259.2">To mitigate the risk of such attacks, differential privacy techniques can </span><span><span class="kobospan" id="kobo.260.1">be employed.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.261.1">To protect against membership inference attacks using differential privacy, several approaches can </span><span><span class="kobospan" id="kobo.262.1">be adopted:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.263.1">Noise addition</span></strong><span class="kobospan" id="kobo.264.1">: During the training process, noise is added to the computations to introduce randomness and mask individual data points. </span><span class="kobospan" id="kobo.264.2">This makes it challenging for attackers to identify whether a specific data point was used in </span><span><span class="kobospan" id="kobo.265.1">the training.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.266.1">Privacy budget management</span></strong><span class="kobospan" id="kobo.267.1">: Differential privacy operates under a privacy budget that determines the maximum amount of privacy loss allowed. </span><span class="kobospan" id="kobo.267.2">By carefully managing and allocating the privacy budget, the risk of membership inference attacks can </span><span><span class="kobospan" id="kobo.268.1">be minimized.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.269.1">Generalization and aggregation</span></strong><span class="kobospan" id="kobo.270.1">: Applying generalization and aggregation techniques helps in obfuscating individual data points. </span><span class="kobospan" id="kobo.270.2">By grouping similar data points together, the information about any specific individual becomes </span><span><span class="kobospan" id="kobo.271.1">less distinguishable.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.272.1">Perturbation mechanisms</span></strong><span class="kobospan" id="kobo.273.1">: Utilizing perturbation mechanisms, such as adding noise to the model’s outputs or gradients, enhances privacy protection. </span><span class="kobospan" id="kobo.273.2">These mechanisms make it more challenging for attackers to infer membership </span><span><span class="kobospan" id="kobo.274.1">status accurately.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.275.1">Adversarial training</span></strong><span class="kobospan" id="kobo.276.1">: Incorporating adversarial training techniques helps in training models that are robust against membership inference attacks. </span><span class="kobospan" id="kobo.276.2">This involves training the model against a sophisticated attacker who tries to distinguish the presence of specific </span><span><span class="kobospan" id="kobo.277.1">data points.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.278.1">By combining these strategies and adopting a privacy-by-design approach, machine learning systems can better protect against membership inference attacks. </span><span class="kobospan" id="kobo.278.2">It is important to note that while differential privacy provides strong privacy guarantees, there might still be cases where additional privacy-preserving techniques or post-processing is necessary to</span><a id="_idIndexMarker424" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.279.1"> address specific </span><span><span class="kobospan" id="kobo.280.1">attack scenarios.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.281.1">Following is an example to </span><span><span class="kobospan" id="kobo.282.1">demonstrate this:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.283.1">Let’s generate two datasets that differ by exactly one record. </span><span class="kobospan" id="kobo.283.2">We’ll create a copy of the original dataset and refer to it as</span><a id="_idIndexMarker425" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.284.1"> the </span><strong class="bold"><span class="kobospan" id="kobo.285.1">redacted dataset</span></strong><span class="kobospan" id="kobo.286.1">. </span><span class="kobospan" id="kobo.286.2">In the redacted dataset, we’ll remove one record to create </span><span><span class="kobospan" id="kobo.287.1">the difference.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.288.1">Here’s how </span><span><span class="kobospan" id="kobo.289.1">to proceed:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.290.1">Start with the original dataset containing the desired records. </span><span class="kobospan" id="kobo.290.2">This dataset represents the baseline or complete set </span><span><span class="kobospan" id="kobo.291.1">of records.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.292.1">Create a copy of the original dataset and label it as </span><strong class="source-inline1"><span class="kobospan" id="kobo.293.1">redact_dataset</span></strong><span class="kobospan" id="kobo.294.1">. </span><span class="kobospan" id="kobo.294.2">This dataset will closely resemble the original dataset but with one record removed. </span><span class="kobospan" id="kobo.294.3">Choose any record from the redacted dataset and remove it to create the difference. </span><span class="kobospan" id="kobo.294.4">In the example, the first record </span><span><span class="kobospan" id="kobo.295.1">is removed.</span></span></li>
</ol>
<p class="calibre3"><span class="kobospan" id="kobo.296.1">By creating the redacted dataset as a modified version of the original dataset, specifically by removing one record, we establish a distinct dataset that differs from the original by only that </span><span><span class="kobospan" id="kobo.297.1">single record.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.298.1">Use the following source code to create a </span><span><span class="kobospan" id="kobo.299.1">redacted one.</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.300.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.301.1">code: Sample_Finance_App_DP.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.302.1">
import pandas as pd
url = "2023-07-08.csv"
df = pd.read_csv(url, sep=",")
redact_dataset = df.copy()
redact_dataset = redact_dataset[1:]
df.head()</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer062">
<span class="kobospan" id="kobo.303.1"><img alt="Figure 5.7 -  Sample transaction dataset" src="image/B16573_05_07.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.304.1">Figure 5.7 -  Sample transaction dataset</span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.305.1">
redact_dataset.head()</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer063">
<span class="kobospan" id="kobo.306.1"><img alt="Figure 5.8 – Redact dataset" src="image/B16573_05_08.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.307.1">Figure 5.8 – Redact dataset</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.308.1">We have removed just one record (customer ID 2079) from the original dataset, who made a transaction of $36. </span><span class="kobospan" id="kobo.308.2">This was done to form the </span><span><span class="kobospan" id="kobo.309.1">redacted dataset.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.310.1">Let’s calculate the sum of transaction amounts from the original dataset and the redacted dataset to determine the difference. </span><span class="kobospan" id="kobo.310.2">This difference will correspond to the exact transaction amount </span><a id="_idIndexMarker426" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.311.1">made by the customer with the </span><span><span class="kobospan" id="kobo.312.1">ID 2079:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.313.1">
sum_original_dataset = round(sum(df["TX_AMOUNT"].to_list()), 2)
sum_redact_dataset =
round(sum(redact_dataset["TX_AMOUNT"].to_list()), 2)
tx_amount_2079 = round((sum_original_dataset - sum_redact_dataset), 2)
tx_amount_2079
</span><strong class="bold1"><span class="kobospan1" id="kobo.314.1">36</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.315.1">Let’s apply differential privacy techniques to calculate the sum of transaction amounts from the original dataset and the redacted dataset. </span><span class="kobospan" id="kobo.315.2">The difference between these two sums should not reveal the exact transaction amount made by the customer with ID 2079. </span><span class="kobospan" id="kobo.315.3">Here’s how you can </span><span><span class="kobospan" id="kobo.316.1">approach this:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.317.1">Sum using differential privacy on the </span><span><span class="kobospan" id="kobo.318.1">original dataset:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.319.1">
dp_sum_original_dataset = BoundedSum(
    epsilon=1, lower_bound=1.0, upper_bound=500.0, dtype="float"
)
dp_sum_original_dataset.reset()
dp_sum_original_dataset.add_entries(
    df["TX_AMOUNT"].to_list()
)
dp_sum_og = round(dp_sum_original_dataset.result(), 2)
print(dp_sum_og)
</span><strong class="bold1"><span class="kobospan1" id="kobo.320.1">1300958.19</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.321.1">Sum using differential privacy </span><a id="_idIndexMarker427" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.322.1">on the </span><span><span class="kobospan" id="kobo.323.1">redacted dataset:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.324.1">
dp_redact_dataset = BoundedSum(epsilon=1, lower_bound=1.0, upper_bound=500.0, dtype="float")
dp_redact_dataset.add_entries(redact_dataset["TX_AMOUNT"].to_list())
dp_sum_redact = round(dp_redact_dataset.result(), 2)
print(dp_sum_redact)
</span><strong class="bold1"><span class="kobospan1" id="kobo.325.1">1302153.33</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.326.1">Difference between the two datasets using </span><span><span class="kobospan" id="kobo.327.1">differential privacy:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.328.1">
round(dp_sum_og - dp_sum_redact, 2)
</span><strong class="bold1"><span class="kobospan1" id="kobo.329.1">-1195.14</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.330.1">In this example, when calculating the sum of transaction amounts using differential privacy for both the original dataset and the redacted dataset, the difference between these two sums resulted in negative numbers. </span><span class="kobospan" id="kobo.330.2">However, it is important to note that these negative values do not represent the actual transaction amount made by customer </span><span><span class="kobospan" id="kobo.331.1">ID 2079.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.332.1">The negative values in the difference arise due to the inherent noise added during the differential privacy calculations. </span><span class="kobospan" id="kobo.332.2">Differential privacy techniques introduce randomization to protect individual privacy, and this random noise can sometimes lead to negative perturbations in the </span><span><span class="kobospan" id="kobo.333.1">aggregated results.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.334.1">Therefore, it is crucial to interpret these negative values correctly. </span><span class="kobospan" id="kobo.334.2">They should not be considered as the actual transaction amount made by customer ID 2079, but rather as an indication that the differential </span><a id="_idIndexMarker428" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.335.1">privacy mechanisms have successfully introduced noise to protect individual privacy while providing approximate </span><span><span class="kobospan" id="kobo.336.1">aggregate results.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.337.1">It is essential to understand that differential privacy focuses on preserving privacy rather than exactness in the calculated results. </span><span class="kobospan" id="kobo.337.2">The negative difference serves as a reminder of the privacy guarantees provided by differential privacy, ensuring that individual transaction details are safeguarded even in the presence of </span><span><span class="kobospan" id="kobo.338.1">aggregate computations.</span></span></p>
<h1 id="_idParaDest-94" class="calibre5"><a id="_idTextAnchor102" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.339.1">Applying differential privacy to large datasets</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.340.1">In the previous examples, we focused </span><a id="_idIndexMarker429" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.341.1">on calculating differentially private aggregates (such as count, sum, and average) on smaller datasets, involving a single terminal or a limited number of terminals. </span><span class="kobospan" id="kobo.341.2">However, in this section, we will explore how to generate differentially private aggregates on large datasets, including millions or even billions of records. </span><span class="kobospan" id="kobo.341.3">Specifically, we will consider a use case involving a dataset of approximately 5 million credit card transactions across 1,000 point-of-sale terminals and </span><span><span class="kobospan" id="kobo.342.1">5,000 customers.</span></span></p>
<h2 id="_idParaDest-95" class="calibre7"><a id="_idTextAnchor103" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.343.1">Use case – generating differentially private aggregates on a large dataset</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.344.1">Let’s generate the dataset comprising</span><a id="_idIndexMarker430" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.345.1"> credit card transactions recorded on a daily basis across 1,000 POS terminals. </span><span class="kobospan" id="kobo.345.2">These transactions involve a total of 5,000 customers, resulting in an extensive collection of approximately 5 </span><span><span class="kobospan" id="kobo.346.1">million records.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.347.1">To calculate differentially private aggregates on such a large dataset, specialized techniques and frameworks are employed to handle the scale and complexity of the data. </span><span class="kobospan" id="kobo.347.2">These techniques ensure that privacy is preserved while providing meaningful </span><span><span class="kobospan" id="kobo.348.1">aggregate statistics.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.349.1">By leveraging differential privacy on large datasets, organizations can extract valuable insights without compromising the privacy of individual customers. </span><span class="kobospan" id="kobo.349.2">The generated differentially private aggregates enable data-driven decision-making and analysis while protecting sensitive information. </span><span class="kobospan" id="kobo.349.3">It is worth noting that the methods and frameworks used to apply differential privacy on large datasets may vary depending on the specific requirements and available resources. </span><span class="kobospan" id="kobo.349.4">Techniques such as data partitioning, parallel processing, and optimized algorithms play a crucial role in efficiently computing differentially private aggregates on such </span><span><span class="kobospan" id="kobo.350.1">vast datasets.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.351.1">By understanding how to generate differentially private aggregates on large datasets, organizations can derive</span><a id="_idIndexMarker431" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.352.1"> actionable insights from their data while upholding the privacy of individuals involved in the transactions. </span><span class="kobospan" id="kobo.352.2">The dataset is organized in a specific format, with each day’s transactions stored in separate files that include the date in the filename. </span><span class="kobospan" id="kobo.352.3">To illustrate, let’s consider an example where the dataset corresponds to transactions on February 1, 2022. </span><span class="kobospan" id="kobo.352.4">The file for this day uses the </span><span><span class="kobospan" id="kobo.353.1">following format:</span></span></p>
<p class="calibre3"><span><span class="kobospan" id="kobo.354.1">Filename: </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.355.1">2022-02-01.csv</span></strong></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.356.1">The filename consists of the specific date in the format </span><strong class="source-inline"><span class="kobospan" id="kobo.357.1">YYYY-MM-DD</span></strong><span class="kobospan" id="kobo.358.1">. </span><span class="kobospan" id="kobo.358.2">In this case, </span><strong class="source-inline"><span class="kobospan" id="kobo.359.1">2022-02-01</span></strong><span class="kobospan" id="kobo.360.1"> represents the date of the transactions contained in </span><span><span class="kobospan" id="kobo.361.1">the file.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.362.1">The actual content of the file will be the transaction data for that specific day, including details such as customer ID, transaction amount, POS terminal ID, and any other </span><span><span class="kobospan" id="kobo.363.1">relevant information.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.364.1">This file format, where each day’s transactions are stored in separate files with the date included in the filename, helps in organizing and managing the </span><span><span class="kobospan" id="kobo.365.1">dataset chronologically.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.366.1">It enables easy retrieval </span><a id="_idIndexMarker432" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.367.1">and analysis of transaction data from specific dates, facilitating time-based analysis and </span><span><span class="kobospan" id="kobo.368.1">reporting tasks:</span></span></p>
<table class="no-table-style" id="table001-5">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.369.1">TRANSACTION_ID</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.370.1">TX_DATETIME</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.371.1">CUSTOMER_ID</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.372.1">TERMINAL_ID</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.373.1">TX_AMOUNT</span></strong></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.374.1">0</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.375.1">2023-02-01 00:43:37</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.376.1">901</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.377.1">8047</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.378.1">82</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.379.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.380.1">2023-02-01 01:20:13</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.381.1">2611</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.382.1">7777</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.383.1">15</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.384.1">2</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.385.1">2023-02-01 01:22:52</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.386.1">4212</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.387.1">3336</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.388.1">53</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.389.1">3</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.390.1">2023-02-01 01:26:40</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.391.1">1293</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.392.1">7432</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.393.1">59</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.394.1">4</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.395.1">2023-02-01 01:52:23</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.396.1">2499</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.397.1">1024</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.398.1">25</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.399.1">5</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.400.1">2023-02-01 02:11:03</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.401.1">2718</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.402.1">168</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.403.1">68</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.404.1">6</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.405.1">2023-02-01 02:11:56</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.406.1">2998</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.407.1">5513</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.408.1">80</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.409.1">Table 5.1 – First few rows of transactions data</span></p>
<table class="no-table-style" id="table002-4">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.410.1">TRANSACTION_ID</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.411.1">TX_DATETIME</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.412.1">CUSTOMER_ID</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.413.1">TERMINAL_ID</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.414.1">TX_AMOUNT</span></strong></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.415.1">24901</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.416.1">2023-02-02 01:34:52</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.417.1">4999</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.418.1">4536</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.419.1">43</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.420.1">24902</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.421.1">2023-02-02 01:44:39</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.422.1">580</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.423.1">3511</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.424.1">29</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.425.1">24903</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.426.1">2023-02-02 01:48:04</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.427.1">3309</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.428.1">7661</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.429.1">50</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.430.1">24904</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.431.1">2023-02-02 01:58:12</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.432.1">2919</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.433.1">5322</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.434.1">94</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.435.1">24905</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.436.1">2023-02-02 02:07:07</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.437.1">3868</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.438.1">3217</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.439.1">97</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.440.1">24906</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.441.1">2023-02-02 02:08:43</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.442.1">1822</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.443.1">489</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.444.1">15</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.445.1">Table 5.2 – Last few rows of transactions data</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.446.1">For our use case scenario, where the core exercise is to createdifferentially private aggregates , let’s assume that the system receives data covering several months, and the objective is to generate differentially private aggregates of transactions for each </span><span><span class="kobospan" id="kobo.447.1">POS terminal.</span></span></p>
<table class="no-table-style" id="table003-4">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<thead class="calibre18">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.448.1">POS Terminal</span></strong></span></p>
</td>
<td class="no-table-style2" colspan="3">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.449.1">Differentially </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.450.1">private aggregates</span></strong></span></p>
</td>
</tr>
</thead>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.451.1">Count</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.452.1">Sum</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.453.1">Average</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.454.1">1</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.455.1">2</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.456.1">3</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.457.1">4</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.458.1">..</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.459.1">Table 5.3 – Differentially private aggregates</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.460.1">While the use of frameworks such as Pytorch, pandas, and PyDP can be effective for generating differentially </span><a id="_idIndexMarker433" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.461.1">private aggregates, it is true that processing large datasets using these methods alone may be time-consuming and not scalable. </span><span class="kobospan" id="kobo.461.2">However, there are alternative approaches and tools available to address </span><span><span class="kobospan" id="kobo.462.1">these challenges.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.463.1">These approaches include </span><span><span class="kobospan" id="kobo.464.1">the following:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.465.1">Parallel processing</span></strong><span class="kobospan" id="kobo.466.1">: We could utilize parallel processing techniques to distribute the computation across multiple processors or machines. </span><span class="kobospan" id="kobo.466.2">This can significantly reduce the processing time and enable scalability when dealing with </span><span><span class="kobospan" id="kobo.467.1">large datasets.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.468.1">Distributed computing</span></strong><span class="kobospan" id="kobo.469.1">: We could employ distributed computing frameworks such as Apache Spark or Hadoop to handle big data processing. </span><span class="kobospan" id="kobo.469.2">These frameworks provide distributed data processing capabilities, allowing for efficient processing of </span><span><span class="kobospan" id="kobo.470.1">large-scale datasets.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.471.1">Cloud computing</span></strong><span class="kobospan" id="kobo.472.1">: We could leverage cloud computing platforms such as </span><strong class="bold"><span class="kobospan" id="kobo.473.1">Amazon Web Services</span></strong><span class="kobospan" id="kobo.474.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.475.1">AWS</span></strong><span class="kobospan" id="kobo.476.1">) or </span><strong class="bold"><span class="kobospan" id="kobo.477.1">Google Cloud Platform </span></strong><span class="kobospan" id="kobo.478.1">(</span><strong class="bold"><span class="kobospan" id="kobo.479.1">GCP</span></strong><span class="kobospan" id="kobo.480.1">) to harness the power of scalable infrastructure. </span><span class="kobospan" id="kobo.480.2">These platforms offer services such as Amazon EMR, Google Dataproc, or Azure HDInsight, which can handle large-scale data processing in a cost-effective and </span><span><span class="kobospan" id="kobo.481.1">scalable manner.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.482.1">Optimized differential privacy libraries</span></strong><span class="kobospan" id="kobo.483.1">: We could explore specialized differential privacy libraries, such as PipelineDP, TensorFlow Privacy, or Opacus, that are designed to provide efficient and scalable implementations of differential privacy algorithms. </span><span class="kobospan" id="kobo.483.2">These libraries offer optimizations specific to privacy-preserving computations, enabling faster, more </span><span><span class="kobospan" id="kobo.484.1">scalable processing.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.485.1">Data partitioning and pre-aggregation</span></strong><span class="kobospan" id="kobo.486.1">: We could divide the data into manageable partitions and perform pre-aggregation to reduce the overall computational load. </span><span class="kobospan" id="kobo.486.2">This approach can improve performance by minimizing the amount of data processed at </span><span><span class="kobospan" id="kobo.487.1">each step.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.488.1">By incorporating these </span><a id="_idIndexMarker434" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.489.1">approaches and tools, it is possible to overcome the challenges of processing large datasets when generating differentially private aggregates. </span><span class="kobospan" id="kobo.489.2">These methods can significantly reduce the processing time and enhance scalability, enabling organizations to efficiently analyze and derive insights from their data while </span><span><span class="kobospan" id="kobo.490.1">preserving privacy.</span></span></p>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.491.1">Here are some questions/designs </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.492.1">to consider:</span></strong></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.493.1">How can you solve or generate DP aggregates on </span><span><span class="kobospan" id="kobo.494.1">large datasets?</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.495.1">How can you partition the data? </span><span class="kobospan" id="kobo.495.2">(i.e., partitioning based on a date or on a </span><span><span class="kobospan" id="kobo.496.1">POS terminal)</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.497.1">How can you apply DP within a </span><span><span class="kobospan" id="kobo.498.1">given partition?</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.499.1">How do you find out the maximum and minimum value bounds to cacluate the (</span><span><span class="kobospan" id="kobo.500.1">clip) function</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.501.1">Should we apply DP (bounds/sensitivity) for each data value in a partition to generate the DP </span><span><span class="kobospan" id="kobo.502.1">aggregates? </span><span class="kobospan" id="kobo.502.2">OR</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.503.1">Should we generate statistical aggregates first and then apply DP within </span><span><span class="kobospan" id="kobo.504.1">the partition?</span></span></li></ul></li>
</ul>
<h2 id="_idParaDest-96" class="calibre7"><a id="_idTextAnchor104" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.505.1">PipelineDP high-level architecture</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.506.1">The PipelineDP framework is designed to </span><a id="_idIndexMarker435" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.507.1">address the questions and considerations mentioned earlier when generating differentially private aggregates for </span><span><span class="kobospan" id="kobo.508.1">large datasets.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.509.1">PipelineDP (</span><a href="https://pipelinedp.io" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.510.1">https://pipelinedp.io</span></a><span class="kobospan" id="kobo.511.1">) is an open source framework that supports generating differentially private aggregates on large datasets using open source frameworks such as Apache Spark and Apache Beam. </span><span class="kobospan" id="kobo.511.2">The PipelineDP framework was developed by Google in collaboration with OpenMined. </span><span class="kobospan" id="kobo.511.3">As of writing this book, the PipelineDP team has a disclaimer that this framework isn’t recommended for production deployments but is considered good enough for development mode and demonstration purposes to enhance </span><span><span class="kobospan" id="kobo.512.1">your understanding.</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer064">
<span class="kobospan" id="kobo.513.1"><img alt="Figure 5.9 – PipelineDP architecture" src="image/B16573_05_09.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.514.1">Figure 5.9 – PipelineDP architecture</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.515.1">PipelineDP provides APIs in three modes (Apache Spark, Apache Beam, and local mode) and access to their corresponding implementations through the </span><span><span class="kobospan" id="kobo.516.1">DP engine.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.517.1">Here are the key concepts used </span><span><span class="kobospan" id="kobo.518.1">in PipelineDP:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer065">
<span class="kobospan" id="kobo.519.1"><img alt="Figure 5.10 – Example to show privacy unit, privacy-id, and partition keys for sample data" src="image/B16573_05_10.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.520.1">Figure 5.10 – Example to show privacy unit, privacy-id, and partition keys for sample data</span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.521.1">Record</span></strong><span class="kobospan" id="kobo.522.1"> is an element in the input dataset </span><span><span class="kobospan" id="kobo.523.1">in PipelineDP.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.524.1">Partition</span></strong><span class="kobospan" id="kobo.525.1"> is a subset of the </span><a id="_idIndexMarker436" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.526.1">data corresponding to a given value of the aggregation criterion. </span><span class="kobospan" id="kobo.526.2">In our case, we want the results per POS terminal, so the partition will </span><span><span class="kobospan" id="kobo.527.1">be </span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.528.1">TERMINAL_D</span></strong></span><span><span class="kobospan" id="kobo.529.1">.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.530.1">Partition key</span></strong><span class="kobospan" id="kobo.531.1"> is the aggregation key corresponding to a partition. </span><span class="kobospan" id="kobo.531.2">TERMINAL_D is the partition key in </span><span><span class="kobospan" id="kobo.532.1">this example.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.533.1">Privacy unit</span></strong><span class="kobospan" id="kobo.534.1"> is the entity that we want to protect with </span><span><span class="kobospan" id="kobo.535.1">differential privacy.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.536.1">Privacy ID</span></strong><span class="kobospan" id="kobo.537.1"> is an identifier of a privacy unit. </span><span class="kobospan" id="kobo.537.2">In our example,  CUSTOMER_IDis the </span><span><span class="kobospan" id="kobo.538.1">privacy ID.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.539.1">Now that we understand the high-level architecture and key concepts, let’s implement differential privacy on a large dataset </span><span><span class="kobospan" id="kobo.540.1">using PipelineDP.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.541.1">The following line of code installs the </span><span><span class="kobospan" id="kobo.542.1">PipelineDP framework.</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.543.1">
pip install PipelineDP</span></pre>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.544.1">Source code : </span></em><span><em class="italic"><span class="kobospan" id="kobo.545.1">Large_Data_Sets-DP_PipelineDP.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.546.1">
Import pipeline_dp
Import pandas as pd
Import numpy as np
url ="transactions.csv"
df_actual = pd.read_csv(url, sep=",")
df_transactions = df_actual[['TRANSACTION_ID', 'TX_DATETIME','CUSTOMER_ID','TERMINAL_ID','TX_AMOUNT']]
df_transactions</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer066">
<span class="kobospan" id="kobo.547.1"><img alt="Figure 5.11 – Transactions data" src="image/B16573_05_11.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.548.1">Figure 5.11 – Transactions data</span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.549.1">
rows =
[index_row[1] for index_row in transactions_df.iterrows()]</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.550.1"> The following  code will produce the </span><a id="_idIndexMarker437" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.551.1">differentially private counts (total number of customers) for </span><span><span class="kobospan" id="kobo.552.1">each terminal:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.553.1">
#In this example we use a local backend, but Spark and Apache #backends also can be tried in a similar way by making use of the provided classes.
</span><span class="kobospan1" id="kobo.553.2">backend = pipeline_dp.LocalBackend()
# Define the total budget.
</span><span class="kobospan1" id="kobo.553.3">budget_accountant = pipeline_dp.NaiveBudgetAccountant(total_epsilon=1, total_delta=1e-6)
# Create DPEngine which will execute the logic to generate the aggregates
dp_engine = pipeline_dp.DPEngine(budget_accountant, backend)
# Define privacy ID, partition key, and aggregated value extractors.
</span><span class="kobospan1" id="kobo.553.4"># The aggregated value extractor isn't used for Count aggregates, but this is required for SUM, AVERAGE aggregates
data_extractors = pipeline_dp.DataExtractors(
   partition_extractor=lambda row: row.TERMINAL_ID,
   privacy_id_extractor=lambda row: row.CUSTOMER_ID,
   value_extractor=lambda row: 1)
# Configure the aggregation parameters. </span><span class="kobospan1" id="kobo.553.5">Number of partitions is 10000 because the number of terminals is 10,000
params = pipeline_dp.AggregateParams(
   noise_kind=pipeline_dp.NoiseKind.LAPLACE,
   metrics=[pipeline_dp.Metrics.COUNT],
   max_partitions_contributed=100,
   max_contributions_per_partition=10)
public_partitions=list(range(1, 10000))
#Create a computational graph for the aggregation.
</span><span class="kobospan1" id="kobo.553.6">dp_result = dp_engine.aggregate(rows, params, data_extractors, public_partitions)
#Compute budget per each DP operation.
</span><span class="kobospan1" id="kobo.553.7">budget_accountant.compute_budgets()
dp_result = list(dp_result)
dp_dict=dict(dp_result)
myKeys = list(dp_dict.keys())
myKeys.sort()
sorted_dict = {i: dp_dict[i] for I in myKeys}
print(sorted_dict)
dp_count = [0] * 100
for count_sum_per_day in dp_result:
  index =  count_sum_per_day[0] – 1
  dp_count[index] = count_sum_per_day[1][0]
  print(dp_count[index])</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.554.1">Now generate the actual counts and</span><a id="_idIndexMarker438" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.555.1"> compare them with differential </span><span><span class="kobospan" id="kobo.556.1">privacy ones:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.557.1">
df_counts = df_transactions.groupby(by='TERMINAL_ID').agg('count')
df_counts</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer067">
<span class="kobospan" id="kobo.558.1"><img alt="Figure 5.12 – Transactions aggregates" src="image/B16573_05_12.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.559.1">Figure 5.12 – Transactions aggregates</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.560.1">By utilizing the PipelineDP framework, we can address the challenges and considerations involved in generating differentially private aggregates for large datasets. </span><span class="kobospan" id="kobo.560.2">It provides a comprehensive solution that combines scalability, privacy preservation, and accurate aggregation, allowing us to effectively leverage differential privacy techniques for large-scale </span><span><span class="kobospan" id="kobo.561.1">data analysis.</span></span></p>
<h2 id="_idParaDest-97" class="calibre7"><a id="_idTextAnchor105" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.562.1">Tumult Analytics</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.563.1">Tumult Analytics is a robust and feature-rich Python library designed for performing aggregate queries on tabular data while ensuring the principles of differential privacy. </span><span class="kobospan" id="kobo.563.2">The library offers an intuitive interface, making it accessible to users familiar with SQL or PySpark. </span><span class="kobospan" id="kobo.563.3">It provides a wide range of </span><a id="_idIndexMarker439" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.564.1">aggregation functions, data transformation operators, and privacy definitions, ensuring versatility in analytical tasks. </span><span class="kobospan" id="kobo.564.2">Developed and maintained by a team of experts in differential privacy, Tumult Analytics guarantees reliability and is even utilized in production environments by reputable institutions such as the U.S. </span><span class="kobospan" id="kobo.564.3">Census Bureau. </span><span class="kobospan" id="kobo.564.4">Powered by Spark, the library demonstrates excellent scalability, enabling efficient processing of large datasets. </span><span class="kobospan" id="kobo.564.5">With its comprehensive functionality and emphasis on privacy preservation, Tumult Analytics is a valuable tool for data analysis with a focus on maintaining </span><span><span class="kobospan" id="kobo.565.1">data privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.566.1">The following is the citation for the Tumult Analytics open </span><span><span class="kobospan" id="kobo.567.1">source framework:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.568.1">
@software{tumultanalyticssoftware,
    author = {Tumult Labs},
    title = {Tumult {{Analytics}}},
    month = dec,
    year = 2022,
    version = {latest},
    url = {https://tmlt.dev}
}</span></pre>
<h3 class="calibre9"><span class="kobospan" id="kobo.569.1">Installation of Tumult Analytics</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.570.1">To utilize Tumult Analytics, it is essential to have Python installed, as the library is built using Python. </span><span class="kobospan" id="kobo.570.2">It is compatible with </span><a id="_idIndexMarker440" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.571.1">Python versions 3.7 to 3.10. </span><span class="kobospan" id="kobo.571.2">Additionally, since Tumult Analytics leverages PySpark for its computations, it is necessary to have Java 8 or 11 installed </span><span><span class="kobospan" id="kobo.572.1">as well.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.573.1">The following code installs the Tumult </span><span><span class="kobospan" id="kobo.574.1">Analytics framework.</span></span></p>
<pre class="console">
<strong class="source-inline2"><span class="kobospan1" id="kobo.575.1">pip3 install tmlt.analytics</span></strong></pre>
</div>


<div id="_idContainer071" class="calibre2">
<h3 class="calibre9"><span class="kobospan" id="kobo.576.1">Key features of Tumult Analytics</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.577.1">Tumult Analytics provides classes and methods to build aggregates on large datasets using differential privacy. </span><span class="kobospan" id="kobo.577.2">Some of the </span><a id="_idIndexMarker441" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.578.1">high-level classes are </span><span><span class="kobospan" id="kobo.579.1">as follows:</span></span></p>
<table class="no-table-style" id="table004-4">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.580.1">Class</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.581.1">Methods</span></strong></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.582.1">Session</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.583.1">(</span><span><span class="kobospan" id="kobo.584.1">tmlt.analytics.session)</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.585.1">The Session module offers a convenient interface for managing data sources and conducting differentially private queries on them. </span><span class="kobospan" id="kobo.585.2">Creating a session is straightforward, with Session.from_dataframe() for a simple session involving a single private data source or Session.Builder for more complex scenarios involving multiple data sources. </span><span class="kobospan" id="kobo.585.3">Once the session is set up, queries can be executed on the data using Session.evaluate(). </span><span class="kobospan" id="kobo.585.4">When initializing instance type of Session , PrivcyBudget is specified to ensure that the queries performed on the private data do not exceed this allocated budget. </span><span class="kobospan" id="kobo.585.5">By default, the Session instance enforces privacy protection at the row level. </span><span class="kobospan" id="kobo.585.6">This means that the queries prevent any potential attacker from deducing whether individual rows have been added or removed from the private tables. </span><span class="kobospan" id="kobo.585.7">However, this privacy guarantee applies only to the queries themselves and assumes that the private data is not utilized elsewhere in the </span><span><span class="kobospan" id="kobo.586.1">computation process.</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.587.1">PureDPBudget</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.588.1">(</span><span><span class="kobospan" id="kobo.589.1">tmlt.analytics.privacy_budget )</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.590.1">A privacy budget that provides pure </span><span><span class="kobospan" id="kobo.591.1">differential privacy.</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.592.1">ApproxDPBudget</span></span></p>
<p class="calibre3"><span><span class="kobospan" id="kobo.593.1">tmlt.analytics.privacy_budget )</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.594.1">A privacy budget that provides approximate </span><span><span class="kobospan" id="kobo.595.1">differential privacy.</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.596.1">QueryBuilder</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.597.1">(</span><span><span class="kobospan" id="kobo.598.1">tmlt.analytics.query_builder)</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.599.1">A high-level interface for specifying DP queries. </span><span class="kobospan" id="kobo.599.2">The QueryBuilder class can apply transformations, such as joins or filters, as well as compute aggregations including counts, sums, and </span><span><span class="kobospan" id="kobo.600.1">standard deviation.</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.601.1">KeySet</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.602.1">(</span><span><span class="kobospan" id="kobo.603.1">tmlt.analytics.keyset)</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.604.1">A KeySet </span><a id="_idIndexMarker442" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.605.1">specifies a list of values for one or more columns. </span><span class="kobospan" id="kobo.605.2">Currently, KeySets are used as a simpler way to specify domains for </span><span><strong class="source-inline"><span class="kobospan" id="kobo.606.1">groupb</span></strong></span><span><strong class="source-inline"><span class="kobospan" id="kobo.607.1">y</span></strong></span><span><span class="kobospan" id="kobo.608.1"> transformations</span></span><span><span class="kobospan" id="kobo.609.1">.</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.610.1">Table 5.4 – tmlt.analytics.session description</span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.611.1">Example application with Tumult Analytics</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.612.1">Let’s generate the aggregates using </span><a id="_idIndexMarker443" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.613.1">tmlt-analytics on the large dataset used in the previous section (i.e., our </span><span><span class="kobospan" id="kobo.614.1">transaction data).</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.615.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.616.1">code: DP_Large_Data_Sets_TMLT.ipynb</span></em></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.617.1">Let’s import the required Python packages </span><span><span class="kobospan" id="kobo.618.1">as follows:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.619.1">
import os
from pyspark import SparkFiles
from pyspark.sql import SparkSession
from tmlt.analytics.privacy_budget import PureDPBudget
from tmlt.analytics.protected_change import AddOneRow
from tmlt.analytics.query_builder import QueryBuilder
from tmlt.analytics.session import Session</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.620.1">Next, initialize the </span><span><span class="kobospan" id="kobo.621.1">Spark session:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.622.1">
spark = SparkSession.builder.getOrCreate()</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.623.1">Let’s load the dataset that contains information about credit card transactions. </span><span class="kobospan" id="kobo.623.2">We get the data from the local directory and load it into a </span><span><span class="kobospan" id="kobo.624.1">Spark DataFrame:</span></span></p>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.625.1">#Create a downloads directory and copy the transactions.csv file by unzipping the </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.626.1">transactions.csv.zip file:</span></strong></span></p>
<p class="calibre3"><a href="https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%205/transactions.csv.zip" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.627.1">https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%205/transactions.csv.zip</span></span></a></p>
<pre class="source-code"><span class="kobospan1" id="kobo.628.1">
spark.sparkContext.addFile(
    "/downloads/transactions.csv")
trans_df = spark.read.csv(
    SparkFiles.get("/downloads/transactions.csv"), header=True, inferSchema=True
)
trans_df.head(5)
</span><strong class="bold1"><span class="kobospan1" id="kobo.629.1">[Row(_c0=0, TRANSACTION_ID=0, TX_DATETIME=datetime.datetime(2023, 2, 1, 0, 43, 37), CUSTOMER_ID=901, TERMINAL_ID=8047, TX_AMOUNT=82, TX_TIME_SECONDS=2617, TX_TIME_DAYS=0),</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.630.1"> Row(_c0=1, TRANSACTION_ID=1, TX_DATETIME=datetime.datetime(2023, 2, 1, 1, 20, 13), CUSTOMER_ID=2611, TERMINAL_ID=7777, TX_AMOUNT=15, TX_TIME_SECONDS=4813, TX_TIME_DAYS=0),</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.631.1"> Row(_c0=2, TRANSACTION_ID=2, TX_DATETIME=datetime.datetime(2023, 2, 1, 1, 22, 52), CUSTOMER_ID=4212, TERMINAL_ID=3336, TX_AMOUNT=53, TX_TIME_SECONDS=4972, TX_TIME_DAYS=0),</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.632.1"> Row(_c0=3, TRANSACTION_ID=3, TX_DATETIME=datetime.datetime(2023, 2, 1, 1, 26, 40), CUSTOMER_ID=1293, TERMINAL_ID=7432, TX_AMOUNT=59, TX_TIME_SECONDS=5200, TX_TIME_DAYS=0),</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.633.1"> Row(_c0=4, TRANSACTION_ID=4, TX_DATETIME=datetime.datetime(2023, 2, 1, 1, 52, 23), CUSTOMER_ID=2499, TERMINAL_ID=1024, TX_AMOUNT=25, TX_TIME_SECONDS=6743, TX_TIME_DAYS=0)]</span></strong></pre>
<h3 class="calibre9"><span class="kobospan" id="kobo.634.1">Initiating a tmlt-analytics session</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.635.1">To perform queries using Tumult Analytics, the data needs to be encapsulated within a </span><strong class="source-inline"><span class="kobospan" id="kobo.636.1">Session</span></strong><span class="kobospan" id="kobo.637.1"> object, which facilitates </span><a id="_idIndexMarker444" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.638.1">query tracking and management. </span><span class="kobospan" id="kobo.638.2">The following code snippet demonstrates how to create a </span><strong class="source-inline"><span class="kobospan" id="kobo.639.1">Session</span></strong><span class="kobospan" id="kobo.640.1"> by wrapping a DataFrame containing private data using the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.641.1">from_dataframe()</span></strong></span><span><span class="kobospan" id="kobo.642.1"> method:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.643.1">
session = Session.from_dataframe(
    privacy_budget=PureDPBudget(3.5),
    source_id="transactions",
    dataframe=trans_df,
    protected_change=AddOneRow(),
)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.644.1">When a session is initialized with a finite privacy budget, it offers a straightforward interface promise: all queries executed on this session, collectively, will yield differentially private outcomes with a maximum epsilon value of 3.5. </span><span class="kobospan" id="kobo.644.2">Epsilon serves as a metric for quantifying potential privacy loss, where a lower epsilon implies a more stringent constraint on privacy loss and, consequently, a higher level of protection. </span><span class="kobospan" id="kobo.644.3">In this context, the interface promise corresponds to a privacy guarantee, ensuring a minimum level of safeguarding for </span><span><span class="kobospan" id="kobo.645.1">private data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.646.1">In addition to the data itself, several additional pieces of information </span><span><span class="kobospan" id="kobo.647.1">are required:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.648.1">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.649.1">privacy_budget</span></strong><span class="kobospan" id="kobo.650.1"> parameter specifies the privacy guarantee that the session </span><span><span class="kobospan" id="kobo.651.1">will provide.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.652.1">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.653.1">source_id</span></strong><span class="kobospan" id="kobo.654.1"> parameter serves as an identifier for the DataFrame. </span><span class="kobospan" id="kobo.654.2">It will be used to reference this specific DataFrame when </span><span><span class="kobospan" id="kobo.655.1">constructing queries.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.656.1">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.657.1">protected_change</span></strong><span class="kobospan" id="kobo.658.1"> parameter defines the unit of data for which the differential privacy guarantee is applied. </span><span class="kobospan" id="kobo.658.2">In this example, </span><strong class="source-inline1"><span class="kobospan" id="kobo.659.1">AddOneRow()</span></strong><span class="kobospan" id="kobo.660.1"> is used to protect individual rows </span><a id="_idIndexMarker445" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.661.1">within </span><span><span class="kobospan" id="kobo.662.1">the dataset.</span></span></li>
</ul>
<h3 class="calibre9"><span class="kobospan" id="kobo.663.1">Exeucting DP queries using Session</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.664.1">Our first query finds the number of</span><a id="_idIndexMarker446" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.665.1"> total transactions in the data with </span><span><span class="kobospan" id="kobo.666.1">DP enabled:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.667.1">
count_query = QueryBuilder("transactions").count()</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.668.1">To execute the query on the desired private data, we utilize </span><strong class="source-inline"><span class="kobospan" id="kobo.669.1">QueryBuilder("transactions")</span></strong><span class="kobospan" id="kobo.670.1"> in the first step, which indicates the specific source data (data source) we want to query, corresponding to the </span><strong class="source-inline"><span class="kobospan" id="kobo.671.1">source_id</span></strong><span class="kobospan" id="kobo.672.1"> parameter specified earlier. </span><span class="kobospan" id="kobo.672.2">In the following line, the </span><strong class="source-inline"><span class="kobospan" id="kobo.673.1">count()</span></strong><span class="kobospan" id="kobo.674.1"> statement is used to retrieve the total number of records in the dataset. </span><span class="kobospan" id="kobo.674.2">Once the query is constructed, we proceed to run it on the data by employing the </span><strong class="source-inline"><span class="kobospan" id="kobo.675.1">evaluate</span></strong><span class="kobospan" id="kobo.676.1"> method of our session. </span><span class="kobospan" id="kobo.676.2">To accomplish this, we allocate a privacy budget to the evaluation process. </span><span class="kobospan" id="kobo.676.3">In this case, we evaluate the query with differential privacy, setting ε=1 as the </span><span><span class="kobospan" id="kobo.677.1">privacy parameter:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.678.1">
total_count = session.evaluate(
    count_query,
  privacy_budget=PureDPBudget(epsilon=1)
)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.679.1">The results of the query are returned as a Spark DataFrame. </span><span class="kobospan" id="kobo.679.2">We can see them using the </span><strong class="source-inline"><span class="kobospan" id="kobo.680.1">show()</span></strong><span class="kobospan" id="kobo.681.1"> method of this DataFrame. </span><span class="kobospan" id="kobo.681.2">We have utilized 1 out of 3.5 of our allocated privacy budget for this query, so the remaining privacy budget will </span><span><span class="kobospan" id="kobo.682.1">be 2.5:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.683.1">
total_count.show()
</span><strong class="bold1"><span class="kobospan1" id="kobo.684.1">+-------+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.685.1">|  count|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.686.1">+-------+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.687.1">|4557168|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.688.1">+-------+</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.689.1">If you are following along with the example and executing the code, you may observe varying values. </span><span class="kobospan" id="kobo.689.2">This variation is a fundamental aspect of differential privacy, as it introduces randomization (referred to as</span><a id="_idIndexMarker447" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.690.1"> noise) during query execution. </span><span class="kobospan" id="kobo.690.2">To showcase this characteristic, let’s proceed to evaluate the same query one more time and see </span><span><span class="kobospan" id="kobo.691.1">the result.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.692.1">The amount of noise </span><a id="_idIndexMarker448" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.693.1">added to the query computation can vary based on the privacy parameters, the type of aggregation, and the underlying data. </span><span class="kobospan" id="kobo.693.2">However, in many instances, the query result still provides reliable insights into the original data. </span><span class="kobospan" id="kobo.693.3">In this particular scenario, we can confirm this by executing a count query directly on the original DataFrame, which will yield the true and </span><span><span class="kobospan" id="kobo.694.1">accurate result:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.695.1">
total_count = trans_df.count()
print(total_count)
</span><strong class="bold1"><span class="kobospan1" id="kobo.696.1">4557166</span></strong></pre>
<h3 class="calibre9"><span class="kobospan" id="kobo.697.1">Playing with privacy budgets</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.698.1">Describe the session object to</span><a id="_idIndexMarker449" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.699.1"> know the attributes and the remaining </span><span><span class="kobospan" id="kobo.700.1">privacy budget.</span></span></p>
<pre class="source-code">
<strong class="source-inline2"><span class="kobospan1" id="kobo.701.1">session.describe()</span></strong><span class="kobospan1" id="kobo.702.1">
The session has a remaining privacy budget of PureDPBudget(epsilon=2.5).
</span><span class="kobospan1" id="kobo.702.2">The following private tables are available:
Table 'transactions' (no constraints):
  Columns:
    - '_c0'              INTEGER
    - 'TRANSACTION_ID'   INTEGER
    - 'TX_DATETIME'      TIMESTAMP
    - 'CUSTOMER_ID'      INTEGER
    - 'TERMINAL_ID'      INTEGER
    - 'TX_AMOUNT'        INTEGER
    - 'TX_TIME_SECONDS'  INTEGER
    - 'TX_TIME_DAYS'     INTEGER</span></pre>
<h3 class="calibre9"><span class="kobospan" id="kobo.703.1">Utilizing privacy budgets with privacy queries</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.704.1">Let’s find out the number of </span><a id="_idIndexMarker450" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.705.1">customers whose purchases are worth less </span><span><span class="kobospan" id="kobo.706.1">than $25.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.707.1">This query consumes epsilon=1 out of our </span><span><span class="kobospan" id="kobo.708.1">total budget:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.709.1">
low_purchagers= QueryBuilder("transactions").filter("TX_AMOUNT &lt; 25").count()
low_purchagers_count = session.evaluate(
    low_purchagers,
    privacy_budget=PureDPBudget(epsilon=1),
)
low_purchagers_count.show()
</span><strong class="bold1"><span class="kobospan1" id="kobo.710.1">+-------+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.711.1">|  count|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.712.1">+-------+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.713.1">|1024844|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.714.1">+-------+</span></strong><span class="kobospan1" id="kobo.715.1">
print(session.remaining_privacy_budget)
</span><strong class="bold1"><span class="kobospan1" id="kobo.716.1">PureDPBudget(epsilon=1.5)</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.717.1">We have utilized 1 unit of our </span><a id="_idIndexMarker451" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.718.1">remaining total privacy budget of 2.5, so there is 1.5 left. </span><span class="kobospan" id="kobo.718.2">Let’s try another query to consume another 1 unit of the </span><span><span class="kobospan" id="kobo.719.1">privacy budget:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.720.1">Let’s find out the number of customers whose purchases are greater than $25 but less </span><span><span class="kobospan" id="kobo.721.1">than $50.</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.722.1">
med_purchagers= QueryBuilder("transactions").filter("TX_AMOUNT &gt;25 AND TX_AMOUNT &lt;50").count()
med_purchagers_count = session.evaluate(
    med_purchagers,
    privacy_budget=PureDPBudget(epsilon=1),
)
med_purchagers_count.show()
</span><strong class="bold1"><span class="kobospan1" id="kobo.723.1">+-------+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.724.1">|  count|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.725.1">+-------+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.726.1">|1165384|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.727.1">+-------+</span></strong><span class="kobospan1" id="kobo.728.1">
print(session.remaining_privacy_budget)
</span><strong class="bold1"><span class="kobospan1" id="kobo.729.1">PureDPBudget(epsilon=0.5)</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.730.1">We have utilized a budget of 3 out of a total of 3.5, so there is 0.5 left. </span><span class="kobospan" id="kobo.730.2">Let’s try another query to consume the privacy budget of 1 (run the query more than the available budget and observe </span><span><span class="kobospan" id="kobo.731.1">the results).</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.732.1">
high_purchagers= QueryBuilder("transactions").filter("TX_AMOUNT &gt; 50").count()
high_purchagers_count = session.evaluate(
    high_purchagers,
    privacy_budget=PureDPBudget(epsilon=1),
)
high_purchagers_count.show()</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.733.1">It will throw a </span><a id="_idIndexMarker452" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.734.1">runtime error </span><span><span class="kobospan" id="kobo.735.1">as follows:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.736.1">
---------------------------------------------------------------------------
InsufficientBudgetError                   Traceback (most recent call last)
/usr/local/lib/python3.10/dist-packages/tmlt/analytics/session.py in evaluate(self, query_expr, privacy_budget)
   1283             try:
-&gt; 1284                 answers = self._accountant.measure(
   1285                     measurement, d_out=adjusted_budget.value
/usr/local/lib/python3.10/dist-packages/tmlt/core/measurements/interactive_measurements.py in measure(self, measurement, d_out)
   1343         if not self._privacy_budget.can_spend_budget(d_out):
-&gt; 1344             raise InsufficientBudgetError(
   1345                 self.privacy_budget,
InsufficientBudgetError: PrivacyAccountant's remaining privacy budget is 1/2, which is insufficient for this operation that requires privacy loss 1.
</span><span class="kobospan1" id="kobo.736.2">RuntimeError: Cannot answer query without exceeding the Session privacy budget.
</span><span class="kobospan1" id="kobo.736.3">Requested: ε=1.000
Remaining: ε=0.500
Difference: ε=0.500</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.737.1">Let’s display the</span><a id="_idIndexMarker453" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.738.1"> remaining privacy budget for use in the </span><span><span class="kobospan" id="kobo.739.1">subsequent queries.</span></span></p>
<p class="calibre3"><span><strong class="source-inline"><span class="kobospan" id="kobo.740.1">print(session.remaining_privacy_budget)</span></strong></span></p>
<pre class="console"><span class="kobospan1" id="kobo.741.1">
PureDPBudget(epsilon=0.5)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.742.1">Rewrite the last query so that it will make use of the remaining available budget so that the privacy budget is used completely, instead of wasting the unused budget. </span><span class="kobospan" id="kobo.742.2">In this case, we will not specify the privacy budget as 1 or 2, but will make use of the remaining privacy budget from the </span><strong class="source-inline"><span class="kobospan" id="kobo.743.1">Session</span></strong> <span><span class="kobospan" id="kobo.744.1">class itself:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.745.1">
high_purchagers= QueryBuilder("transactions").filter("TX_AMOUNT &gt; 50").count()
high_purchagers_count = session.evaluate(
    high_purchagers,
    privacy_budget=session.remaining_privacy_budget,
)
high_purchagers_count.show()
</span><strong class="bold1"><span class="kobospan1" id="kobo.746.1">+-------+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.747.1">|  count|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.748.1">+-------+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.749.1">|2271804|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.750.1">+-------+</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.751.1">Total number of high</span><a id="_idIndexMarker454" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.752.1"> purchase counts by applying </span><span><span class="kobospan" id="kobo.753.1">differential privacy.</span></span></p>
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.754.1">Groupby queries</span></strong></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.755.1">In Tumult Analytics, the KeySet class is utilized to define the list of groupby keys. </span><span class="kobospan" id="kobo.755.2">It allows us to specify both the columns by which we intend to group the data and the potential values associated with those columns. </span><span class="kobospan" id="kobo.755.3">The KeySet class serves as a convenient means of specifying the grouping criteria in </span><span><span class="kobospan" id="kobo.756.1">Tumult Analytics.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.757.1">Let’s now write a query to find the average transaction amount on each terminal (taking just the first 10 terminals for </span><span><span class="kobospan" id="kobo.758.1">this example).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.759.1">Create a session with the privacy budget set </span><span><span class="kobospan" id="kobo.760.1">to 2.5:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.761.1">
budget = PureDPBudget(epsilon=2.5) # maximum budget consumed in the Session
session = Session.from_dataframe(
    privacy_budget=budget,
    source_id="transactions",
    dataframe=trans_df,
    protected_change=AddOneRow(),
)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.762.1">Make use of the </span><strong class="source-inline"><span class="kobospan" id="kobo.763.1">KeySet</span></strong><span class="kobospan" id="kobo.764.1"> class and define the groupby column (TERMINAL_ID) or columns and values as well, </span><span><span class="kobospan" id="kobo.765.1">to filter:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.766.1">
from tmlt.analytics.keyset import KeySet
terminal_ids = KeySet.from_dict({
    "TERMINAL_ID": [
        1,2,3,4,5,6,7,8,9,10
    ]
})</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.767.1">Execute the query and</span><a id="_idIndexMarker455" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.768.1"> provide the lower and upper bounds to </span><span><span class="kobospan" id="kobo.769.1">clip </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.770.1">TX_AMOUNT</span></strong></span><span><span class="kobospan" id="kobo.771.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.772.1">
average_purchase_query = (
    QueryBuilder("transactions")
    .groupby(terminal_ids)
    .average("TX_AMOUNT", low=5, high=100)
)
average_purchages= session.evaluate(
    average_purchase_query,
    privacy_budget=PureDPBudget(1),
)
average_purchages.show(truncate=False)
</span><strong class="bold1"><span class="kobospan1" id="kobo.773.1">+-----------+------------------+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.774.1">|TERMINAL_ID|TX_AMOUNT_average |</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.775.1">+-----------+------------------+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.776.1">|1          |55.93609022556391 |</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.777.1">|2          |52.93446601941748 |</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.778.1">|3          |40.95974576271186 |</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.779.1">|4          |52.02414486921529 |</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.780.1">|5          |47.511428571428574|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.781.1">|6          |52.276595744680854|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.782.1">|7          |51.566233766233765|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.783.1">|8          |50.12273641851107 |</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.784.1">|9          |52.88358208955224 |</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.785.1">|10         |48.98945147679325 |</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.786.1">+-----------+------------------+</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.787.1">In this way, we </span><a id="_idIndexMarker456" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.788.1">can generate the aggregates using differential privacy, ensuring they are not the same as the </span><span><span class="kobospan" id="kobo.789.1">actual aggregates.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.790.1">Queries using privacy IDs</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.791.1">Previously, we focused on working with </span><a id="_idIndexMarker457" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.792.1">tables where each individual in the dataset was linked to a single row. </span><span class="kobospan" id="kobo.792.2">However, this is not always the case. </span><span class="kobospan" id="kobo.792.3">In certain datasets, it is possible for the same individual to appear in multiple rows. </span><span class="kobospan" id="kobo.792.4">In such cases, it is typical to assign a unique identifier to each person (i.e., across different rows). </span><span class="kobospan" id="kobo.792.5">The objective then shifts toward concealing whether all the rows associated with a particular identifier are present in </span><span><span class="kobospan" id="kobo.793.1">the data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.794.1">Tumult Analytics refers to these identifiers as privacy IDs. </span><span class="kobospan" id="kobo.794.2">Each privacy ID corresponds to a one-to-one mapping with a person or any other entity that requires protection. </span><span class="kobospan" id="kobo.794.3">The aim is to safeguard the privacy of individuals or entities by preserving the anonymity of their presence within the dataset. </span><span class="kobospan" id="kobo.794.4">This can be achieved by making use of the </span><strong class="source-inline"><span class="kobospan" id="kobo.795.1">AddRowsWithID</span></strong><span class="kobospan" id="kobo.796.1"> protected </span><a id="_idIndexMarker458" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.797.1">change. </span><span class="kobospan" id="kobo.797.2">This protected change will prevent arbitrarily adding and removing many rows all sharing the </span><span><span class="kobospan" id="kobo.798.1">same ID.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.799.1">Initializing  a session with the </span><span><span class="kobospan" id="kobo.800.1">privacy ID:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.801.1">
from tmlt.analytics.protected_change import AddRowsWithID
budget = PureDPBudget(epsilon=2.5) # maximum budget consumed in the Session
session = Session.from_dataframe(
    privacy_budget=budget,
    source_id="transactions",
    dataframe=trans_df,
    protected_change=AddRowsWithID(id_column="CUSTOMER_ID"),
)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.802.1">Execute the query with the </span><span><span class="kobospan" id="kobo.803.1">privacy ID:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.804.1">
keyset = KeySet.from_dataframe(
    trans_df.select("TERMINAL_ID", "TX_AMOUNT")
)
count_query = (
    QueryBuilder("transactions")
    .groupby(keyset)
    .count()
)
result = session.evaluate(count_query, PureDPBudget(1))</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.805.1">Let’s execute this code and observe </span><span><span class="kobospan" id="kobo.806.1">the output:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.807.1">
RuntimeError: A constraint on the number of rows contributed by each ID is needed to perform this query (e.g. </span><span class="kobospan1" id="kobo.807.2">MaxRowsPerID).</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.808.1">This error arises due to the absence of a constraint on the number of rows a single individual can contribute to the dataset. </span><span class="kobospan" id="kobo.808.2">It is possible for a single customer to do many transactions, even exceeding 1,000 or more. </span><span class="kobospan" id="kobo.808.3">However, differential privacy necessitates concealing the influence of an individual’s data through the introduction of </span><span><span class="kobospan" id="kobo.809.1">statistical noise.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.810.1">In order to address this</span><a id="_idIndexMarker459" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.811.1"> issue, it is necessary to establish a restriction on the maximum influence that a single customer can exert on the computed statistic before conducting aggregations. </span><span class="kobospan" id="kobo.811.2">This constraint is enforced on the data to mitigate any potential impact. </span><span class="kobospan" id="kobo.811.3">The most straightforward constraint, known as </span><strong class="source-inline"><span class="kobospan" id="kobo.812.1">MaxRowsPerID</span></strong><span class="kobospan" id="kobo.813.1">, restricts the total number of rows contributed by each privacy ID. </span><span class="kobospan" id="kobo.813.2">To enforce this constraint, we can simply pass it as a parameter to the </span><strong class="source-inline"><span class="kobospan" id="kobo.814.1">enforce()</span></strong><span class="kobospan" id="kobo.815.1"> operation. </span><span class="kobospan" id="kobo.815.2">For the specific query at hand, we will set the maximum number of contributed rows per library member </span><span><span class="kobospan" id="kobo.816.1">to 100:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.817.1">
from tmlt.analytics.constraints import (
    MaxGroupsPerID,
    MaxRowsPerGroupPerID,
    MaxRowsPerID,
)
keyset = KeySet.from_dataframe(
    trans_df.select("TERMINAL_ID", "TX_AMOUNT")
)
count_query = (
    QueryBuilder("transactions")
    .enforce(MaxRowsPerID(100))
    .groupby(keyset)
    .count()
)
result = session.evaluate(count_query, PureDPBudget(1))
top_five = result.sort("count", ascending=False).limit(5)
top_five.show()
</span><strong class="bold1"><span class="kobospan1" id="kobo.818.1">+-----------+---------+-----+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.819.1">|TERMINAL_ID|TX_AMOUNT|count|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.820.1">+-----------+---------+-----+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.821.1">|       3001|       98| 1240|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.822.1">|       3536|       42| 1217|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.823.1">|       4359|       71| 1212|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.824.1">|       9137|       97| 1145|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.825.1">|       7179|       76| 1143|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.826.1">+-----------+---------+-----+</span></strong><span class="kobospan1" id="kobo.827.1">
result.show()
</span><strong class="bold1"><span class="kobospan1" id="kobo.828.1">+-----------+---------+-----+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.829.1">|TERMINAL_ID|TX_AMOUNT|count|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.830.1">+-----------+---------+-----+</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.831.1">|          0|        4|  401|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.832.1">|          0|        7|  224|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.833.1">|          0|       11|   -7|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.834.1">|          0|       12|  131|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.835.1">|          0|       16|  -35|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.836.1">|          0|       18|  -68|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.837.1">|          0|       20| -126|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.838.1">|          0|       24|  -46|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.839.1">|          0|       26| -162|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.840.1">|          0|       28|  -30|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.841.1">|          0|       31|  447|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.842.1">|          0|       33|   23|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.843.1">|          0|       35|   20|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.844.1">|          0|       44|   96|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.845.1">|          0|       49|  -56|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.846.1">|          0|       51|  211|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.847.1">|          0|       58|  -88|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.848.1">|          0|       59|  -27|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.849.1">|          0|       60| -254|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.850.1">|          0|       61|  525|</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.851.1">+-----------+---------+-----+</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.852.1">The preceding output</span><a id="_idIndexMarker460" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.853.1"> only showing the top </span><span><span class="kobospan" id="kobo.854.1">20 rows.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.855.1">Tumult Analytics provides filters, joins, and transformations of the data to execute complex queries, apply differential privacy to large datasets, and make use of Spark distributed processing. </span><span class="kobospan" id="kobo.855.2">We</span><a id="_idIndexMarker461" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.856.1"> have covered the basic key features, but there are many more features to explore based on the use cases in </span><span><span class="kobospan" id="kobo.857.1">the application/system.</span></span></p>
<h1 id="_idParaDest-98" class="calibre5"><a id="_idTextAnchor106" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.858.1">Machine learning using differential privacy</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.859.1">In this section, our objective is to develop a machine learning classification model that can accurately distinguish </span><a id="_idIndexMarker462" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.860.1">between fraudulent and genuine credit card transactions. </span><span class="kobospan" id="kobo.860.2">To ensure privacy protection, we will also apply differential privacy techniques to the model. </span><span class="kobospan" id="kobo.860.3">The classification model will be trained on a labeled dataset </span><a id="_idIndexMarker463" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.861.1">consisting of historical credit card transactions, where each transaction is labeled as either fraudulent or genuine. </span><span class="kobospan" id="kobo.861.2">Popular machine learning algorithms such as logistic regression, decision trees, or neural networks can be applied to build the classification model and will make use of neural networks in </span><span><span class="kobospan" id="kobo.862.1">our case.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.863.1">To incorporate differential privacy, we will leverage techniques such as the addition of noise to the training process and the use of privacy-preserving algorithms. </span><span class="kobospan" id="kobo.863.2">These techniques ensure that the model’s training process and subsequent predictions do not compromise the privacy of individual transactions or sensitive </span><span><span class="kobospan" id="kobo.864.1">customer information.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.865.1">By integrating differential privacy into the classification model, we can provide robust privacy guarantees while maintaining high accuracy in identifying fraudulent transactions. </span><span class="kobospan" id="kobo.865.2">This ensures that the model can effectively protect customers’ privacy and prevent unauthorized access to sensitive </span><span><span class="kobospan" id="kobo.866.1">financial data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.867.1">Throughout this section, we will explore the steps involved in training the classification model, evaluating its performance, and applying differential privacy techniques to enhance privacy protection. </span><span class="kobospan" id="kobo.867.2">By the end, we will have a powerful model capable of accurately classifying credit card transactions as either fraudulent or genuine while ensuring the privacy of the </span><span><span class="kobospan" id="kobo.868.1">individuals involved.</span></span></p>
<h2 id="_idParaDest-99" class="calibre7"><a id="_idTextAnchor107" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.869.1">Synthetic Dataset Generation: Introducing Fraudulent Transactions</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.870.1">We will make use of the same transaction</span><a id="_idIndexMarker464" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.871.1"> data used earlier, add another column to the dataset called </span><strong class="source-inline"><span class="kobospan" id="kobo.872.1">TX_FRAUD</span></strong><span class="kobospan" id="kobo.873.1">, and mark any transaction greater than $75 as fraudulent. </span><span class="kobospan" id="kobo.873.2">This obviously doesn’t reflect the real world, but we will generate our example synthetic data using this rule. </span><span class="kobospan" id="kobo.873.3">In this dataset, roughly 25% of the data is marked as fraudulent </span><a id="_idIndexMarker465" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.874.1">transactions while 75% of the data is genuine. </span><span class="kobospan" id="kobo.874.2">In a real-world scenario, fraudulent transactions will likely be less than 1% in most datasets, which is </span><span><span class="kobospan" id="kobo.875.1">highly imbalanced.</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.876.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.877.1">code: Fraud_Transactions_Generator.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.878.1">
import pandas as pd
import numpy as np
url="transactions.csv"
df_actual = pd.read_csv(url, sep=",")
df_actual.head()
df_transactions = df_actual[['TRANSACTION_ID', 'TX_DATETIME','CUSTOMER_ID','TERMINAL_ID','TX_AMOUNT']]
df_transactions
df_transactions.insert(5, 'TX_FRAUD', 0, True)
df_transactions</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer068">
<span class="kobospan" id="kobo.879.1"><img alt="Figure 5.13 – Transactions Data" src="image/B16573_05_13.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.880.1">Figure 5.13 – Transactions Data</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.881.1">4557166</span><a id="_idIndexMarker466" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.882.1"> rows × </span><span><span class="kobospan" id="kobo.883.1">6 columns</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.884.1">
df_transactions.loc[df_transactions.TX_AMOUNT&gt;75, 'TX_FRAUD']=1
nb_frauds=df_transactions.TX_FRAUD.sum()
print("Number of fraud transaction",nb_frauds)
</span><strong class="bold1"><span class="kobospan1" id="kobo.885.1">Number of fraud transaction 1106783</span></strong><span class="kobospan1" id="kobo.886.1">
df_transactions.head()</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer069">
<span class="kobospan" id="kobo.887.1"><img alt="Figure 5.14 – First few rows of transactions data" src="image/B16573_05_14.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.888.1">Figure 5.14 – First few rows of transactions data</span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.889.1">
df_transactions.to_csv("fraud_transactions.csv")</span></pre>
<h2 id="_idParaDest-100" class="calibre7"><a id="_idTextAnchor108" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.890.1">Develop a classification model using scikit-learn</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.891.1">The following are the</span><a id="_idIndexMarker467" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.892.1"> high-level steps for developing a </span><span><span class="kobospan" id="kobo.893.1">classification model:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.894.1">Load the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.895.1">fraud_transactions</span></strong></span><span><span class="kobospan" id="kobo.896.1"> dataset.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.897.1">Split the dataset into</span><a id="_idIndexMarker468" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.898.1"> train and test in the ratio </span><span><span class="kobospan" id="kobo.899.1">of (70:30).</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.900.1">Initialize the classifier (logistic regression from </span><span><span class="kobospan" id="kobo.901.1">sci-kit learn).</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.902.1">Train the classifier with the training data (70% of </span><span><span class="kobospan" id="kobo.903.1">the transactions).</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.904.1">Find out the accuracy of the classifier with the test dataset (30% of </span><span><span class="kobospan" id="kobo.905.1">the transactions).</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.906.1">Find out the calculated weights/coefficient used in the </span><strong class="source-inline1"><span class="kobospan" id="kobo.907.1">decision</span></strong><span class="kobospan" id="kobo.908.1"> function and intercept from the logistic </span><span><span class="kobospan" id="kobo.909.1">regression model.</span></span></li>
</ol>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.910.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.911.1">code: Noise_Gradient_Final.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.912.1">
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
import numpy as np
import pandas as pd
url = "fraud_transactions.csv"
df_actual = pd.read_csv(url, sep=",")
df_transactions =
df_actual[['CUSTOMER_ID','TERMINAL_ID','TX_AMOUNT','TX_FRAUD']]
df_transactions</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer070">
<span class="kobospan" id="kobo.913.1"><img alt="Figure 5.15 – Fraud transactions dataset" src="image/B16573_05_15.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.914.1">Figure 5.15 – Fraud transactions dataset</span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.915.1">
print('No Frauds', round(df_transactions['TX_FRAUD'].value_counts()[0]/len(df_transactions) * 100,2), '% of the dataset')
print('Frauds', round(df_transactions['TX_FRAUD'].value_counts()[1]/len(df_transactions) * 100,2), '% of the dataset')
No Frauds 75.71 % of the dataset
Frauds 24.29 % of the dataset
X = df_transactions.drop('TX_FRAUD', axis=1)
y = df_transactions['TX_FRAUD']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
# Turn the values into an array for feeding the classification algorithms.
</span><span class="kobospan1" id="kobo.915.2">X_train = X_train.values
X_test = X_test.values
y_train = y_train.values
y_test = y_test.values
logreg = LogisticRegression(random_state=0)
logreg.fit(X_train, y_train)
training_score = cross_val_score(logreg, X_train, y_train, cv=2)
print('Logistic Regression Cross Validation Score: ',
round(training_score.mean() * 100, 2).astype(str) + '%')
</span><strong class="bold1"><span class="kobospan1" id="kobo.916.1">Logistic Regression Cross Validation Score: 100.0%</span></strong><span class="kobospan1" id="kobo.917.1">
np.sum(logreg.predict(X_test) == y_test)/X_test.shape[0]
</span><strong class="bold1"><span class="kobospan1" id="kobo.918.1">1.0</span></strong><span class="kobospan1" id="kobo.919.1">
logreg.intercept_[0], logreg.coef_[0]
</span><strong class="bold1"><span class="kobospan1" id="kobo.920.1">(-1168.308115256604,</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.921.1"> array([-2.47724513e-05, 3.17749573e-06, 1.54748556e+01]))</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.922.1">Once we know the gradients/coefficients of the classifier and intercept as well, then it will be easy to calculate</span><a id="_idIndexMarker469" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.923.1"> the predictions. </span><span class="kobospan" id="kobo.923.2">In</span><a id="_idIndexMarker470" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.924.1"> our case, we have three features, </span><strong class="source-inline"><span class="kobospan" id="kobo.925.1">CUSTOMER_ID</span></strong><span class="kobospan" id="kobo.926.1">, </span><strong class="source-inline"><span class="kobospan" id="kobo.927.1">TERMINAL_ID</span></strong><span class="kobospan" id="kobo.928.1">, and </span><strong class="source-inline"><span class="kobospan" id="kobo.929.1">TRANSACTON_AMOUNT</span></strong><span class="kobospan" id="kobo.930.1">. </span><span class="kobospan" id="kobo.930.2">The linear equation will come with </span><span><span class="kobospan" id="kobo.931.1">three features:</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.932.1">y = w1 * x1   +  w2 * x2  + w3 * x3  + b</span></em></p>
<p class="calibre3"><span class="kobospan" id="kobo.933.1">Once we know the feature values (x1, x2, x3…. </span><span class="kobospan" id="kobo.933.2">xn), weights (w1, w2, w3, …, wn), and b value (bias /intercept), then we can calculate the y-hat value (predictions). </span><span class="kobospan" id="kobo.933.3">Logistic regression uses a logistic function to estimate/predict the probabilities. </span><span class="kobospan" id="kobo.933.4">In our case, it will be </span><span><span class="kobospan" id="kobo.934.1">the following:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.935.1">y-hat = 1.0 /  1.0 + e </span><span class="superscript"><span class="kobospan1" id="kobo.936.1">– (w1 * x1   +  w2 * x2  + w3 * x3  + </span></span><span><span class="superscript"><span class="kobospan1" id="kobo.937.1">b)</span></span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.938.1">We will take one actual transaction and calculate the prediction value using the weights obtained from </span><span><span class="kobospan" id="kobo.939.1">the model:</span></span></p>
<table class="no-table-style" id="table005-3">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.940.1">CUSTOMER_ID</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.941.1">TERMINAL_ID</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.942.1">TX_AMOUNT</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.943.1">TX_FRAUD</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.944.1">79</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.945.1">3115</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.946.1">78</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.947.1">1</span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.948.1">Table 5.16 – Prediction for CUSTOMER_ID</span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.949.1">
data=[79,3115,78]
weights = [-2.47724513e-05, 3.17749573e-06, 1.54748556e+01]
intercept = -1168.308115256604
def predict(data,coefficients,intercept):
    yhat = intercept
    for i in range(len(data)):
        yhat += coefficients[i] * data[i]
    return 1.0 / (1.0 + np.exp(-yhat))
yhat = predict(data,weights,intercept)
yhat
</span><strong class="bold1"><span class="kobospan1" id="kobo.950.1">1.0</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.951.1">Logistic regression uses the</span><a id="_idIndexMarker471" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.952.1"> stochastic gradient descent algorithm internally in order to </span><span><span class="kobospan" id="kobo.953.1">calculate gradients/coefficients.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.954.1">Let’s implement our own stochastic gradient</span><a id="_idIndexMarker472" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.955.1"> descent algorithm to calculate the weights instead of using the scikit-learn-provided one in the logistic </span><span><span class="kobospan" id="kobo.956.1">regression model.</span></span></p>
<h2 id="_idParaDest-101" class="calibre7"><a id="_idTextAnchor109" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.957.1">High-level implementation of the SGD algorithm</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.958.1">The steps to implement the SGD </span><a id="_idIndexMarker473" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.959.1">algorithm are </span><span><span class="kobospan" id="kobo.960.1">as follows:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.961.1">Initialize the initial weights with all zeros (one zero for each feature and the bias/intercept also as zero): Initial weights = [0,0,0] </span><span><span class="kobospan" id="kobo.962.1">and intercept=0</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.963.1">Do the following for each row in the </span><span><span class="kobospan" id="kobo.964.1">training data:</span></span><ol class="calibre20"><li class="alphabets"><span class="kobospan" id="kobo.965.1">Calculate the predictions based on the initial weights </span><span><span class="kobospan" id="kobo.966.1">and intercept.</span></span></li><li class="alphabets"><span class="kobospan" id="kobo.967.1">Find out the error between the actual value and the </span><span><span class="kobospan" id="kobo.968.1">predicted value:</span></span></li></ol><p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.969.1">Error = Actual Value – </span></em><span><em class="italic"><span class="kobospan" id="kobo.970.1">Predicted Value</span></em></span></p><ol class="calibre20"><li class="alphabets" value="3"><span class="kobospan" id="kobo.971.1">Update the intercept based on the error and the learning </span><span><span class="kobospan" id="kobo.972.1">rate value:</span></span></li></ol><p class="calibre3"><span class="kobospan" id="kobo.973.1">intercept= intercept + l_rate * error * yhat * (1.0 - </span><span><span class="kobospan" id="kobo.974.1">yhat)</span></span></p><ol class="calibre20"><li class="alphabets" value="4"><span class="kobospan" id="kobo.975.1">Update the weights for all training data in the </span><span><span class="kobospan" id="kobo.976.1">training set.</span></span></li></ol></li>
<li class="calibre11"><span class="kobospan" id="kobo.977.1">Based on the number </span><a id="_idIndexMarker474" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.978.1">of epochs, repeat the </span><span><span class="kobospan" id="kobo.979.1">preceding steps.</span></span></li>
</ol>
<pre class="source-code"><span class="kobospan1" id="kobo.980.1">
def predict(data,coefficients,intercept):
    yhat = intercept
    for i in range(len(data)):
        yhat += coefficients[i] * data[i]
    return 1.0 / (1.0 + np.exp(-yhat))
def final_gradients(gradients):
    length_grads=len(grads)
    avg_grads=[0,0,0]
    for i in range(0,length_grads):
        avg_grads[0]+=grads[i][0]
        avg_grads[1]+=grads[i][1]
        avg_grads[2]+=grads[i][2]
    avg_grads=[i/length_grads for i in avg_grads]
    return avg_grads
def sgd(train,y_train,l_rate, n_epoch):
    coef = [0,0,0]
    final_grads = [0,0,0]
    intercept = 0
    for epoch in range(n_epoch):
        predictions=[]
        gradients=[]
        sum_error = 0.0
        for i in range(len(train)):
            yhat = predict(train[i], coef,intercept)
            predictions.append(yhat)
            error = y_train[i] - yhat
            sum_error += error**2
            intercept= intercept + l_rate * error * yhat * (1.0 - yhat)
## intercept
            temp=train[i]
            for j in range(3):
                coef[j] = coef[j] + l_rate * error * yhat * (1.0 - yhat) * temp[j]
            gradients.append(coef)
        final_grads = final_gradients(gradients)
        print('&gt;epoch=%d, lrate=%.3f, error=%.3f, intercept=%.3f '% (epoch, l_rate, sum_error,intercept))
    return final_grads
l_rate = 0.24
n_epoch = 4
coef = sgd(X_train[:10],y_train[:10],l_rate, n_epoch)
print(coef)
&gt;epoch=0, lrate=0.240, error=2.250, intercept=-0.030
&gt;epoch=1, lrate=0.240, error=2.000, intercept=-0.030
&gt;epoch=2, lrate=0.240, error=2.000, intercept=-0.030
&gt;epoch=3, lrate=0.240, error=2.000, intercept=-0.030
[-136.44000000000003, -263.88000000000005, -0.5099999999999999]</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.981.1">In this way, we can calculate</span><a id="_idIndexMarker475" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.982.1"> the coefficients. </span><span class="kobospan" id="kobo.982.2">The final coefficients are calculated as the average of </span><span><span class="kobospan" id="kobo.983.1">all coefficients/gradients.</span></span></p>
<h2 id="_idParaDest-102" class="calibre7"><a id="_idTextAnchor110" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.984.1">Applying differential privacy options using machine learning</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.985.1">Applying differential privacy to the </span><a id="_idIndexMarker476" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.986.1">preceding algorithm means generating gradients with differential privacy so that the model doesn’t reveal the details of the training examples. </span><span class="kobospan" id="kobo.986.2">When applying differential privacy to SGD, the objective is to incorporate privacy protection into the training process of the machine learning model. </span><span class="kobospan" id="kobo.986.3">This involves adding noise to the gradients computed during the SGD optimization steps to ensure that the trained model does not reveal specific details about any individual </span><span><span class="kobospan" id="kobo.987.1">data point.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.988.1">The addition of noise in SGD with differential privacy helps prevent potential privacy breaches by making it difficult to distinguish the impact of any particular training example on the model’s updates. </span><span class="kobospan" id="kobo.988.2">It ensures that the model’s parameters do not memorize or overfit specific training samples, thereby offering privacy guarantees for the individuals whose data was used in the </span><span><span class="kobospan" id="kobo.989.1">training process.</span></span></p>
<h2 id="_idParaDest-103" class="calibre7"><a id="_idTextAnchor111" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.990.1">Generating gradients using differential privacy</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.991.1">There are two approaches</span><a id="_idIndexMarker477" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.992.1"> for generating gradients using differential privacy in the context of </span><span><span class="kobospan" id="kobo.993.1">machine learning.</span></span></p>
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.994.1">Approach 1:</span></strong></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.995.1">Generate the final gradients using the normal SGD algorithm on the </span><span><span class="kobospan" id="kobo.996.1">training data.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.997.1">Calculate the sum of the gradients obtained from the preceding </span><span><span class="kobospan" id="kobo.998.1">SGD step.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.999.1">Add noise to the sum of the gradients using the Laplace mechanism, taking into account the desired sensitivity and </span><span><span class="kobospan" id="kobo.1000.1">privacy budget.</span></span></li>
</ol>
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.1001.1">Approach 2:</span></strong></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.1002.1">Apply the clipping method to each training example or the overall </span><span><span class="kobospan" id="kobo.1003.1">training data.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1004.1">Generate gradients using the clipped training </span><span><span class="kobospan" id="kobo.1005.1">data inputs.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1006.1">Compute the sum of the gradients obtained in the </span><span><span class="kobospan" id="kobo.1007.1">previous step.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1008.1">Add noise to the sum of the gradients using either the Gaussian or Laplace mechanism, considering the desired sensitivity and </span><span><span class="kobospan" id="kobo.1009.1">privacy budget.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1010.1">Calculate the count of the training examples using differential privacy, treating it as a count query with sensitivity set to 1 and utilizing the required </span><span><span class="kobospan" id="kobo.1011.1">privacy budget.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1012.1">Compute the average of the noisy gradients sum and the noisy count to obtain the differentially private </span><span><span class="kobospan" id="kobo.1013.1">gradients average.</span></span></li>
</ol>
<p class="calibre3"><span class="kobospan" id="kobo.1014.1">Both approaches aim to incorporate differential privacy into the gradient calculation process, thereby protecting the privacy of individual training examples while training the machine learning model. </span><span class="kobospan" id="kobo.1014.2">The choice between the two approaches depends on the specific requirements of the application and the desired level of </span><span><span class="kobospan" id="kobo.1015.1">privacy guarantees.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1016.1">By adding appropriate noise and applying privacy-preserving mechanisms, these approaches ensure that the gradients used for updating the model parameters do not reveal sensitive information about individual training examples. </span><span class="kobospan" id="kobo.1016.2">This enables the training process to</span><a id="_idIndexMarker478" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1017.1"> provide privacy guarantees while still achieving accurate and reliable </span><span><span class="kobospan" id="kobo.1018.1">model performance.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1019.1">Let’s now implement </span><em class="italic"><span class="kobospan" id="kobo.1020.1">Approach 2</span></em><span class="kobospan" id="kobo.1021.1"> for our fraud </span><span><span class="kobospan" id="kobo.1022.1">detection example.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1023.1">As we know, clipping is the process of setting the lower and upper bounds for the data, so implement the following </span><span><strong class="source-inline"><span class="kobospan" id="kobo.1024.1">clip</span></strong></span><span><span class="kobospan" id="kobo.1025.1"> function:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.1026.1">
def clip(iv, b):
    norm = np.linalg.norm(iv, ord=2)
    if norm &gt; b:
        return b * (iv / norm)
    else:
        return iv
print( clip([[4548, 8796,   17]],5.0) )
[[2.29645183 4.44142267 0.00858392]]
clip(X_train[:5], 5)
array([[1.35772596e+00, 2.62589215e+00, 5.07505304e-03],
       [3.40625619e-01, 2.83605905e-02, 1.55236917e-02],
       [1.41504420e+00, 1.98583840e+00, 1.52251591e-02],
       [1.06964206e+00, 1.67446897e+00, 2.08972772e-02],
       [6.95282267e-01, 2.50737474e+00, 1.19413013e-03]])
def dp_final_gradients(gradients):
    length_grads=len(grads)
    sensitivity = 1
    epsilon= 0.8
    noise = np.random.laplace(loc=0, scale=sensitivity/epsilon)
    noise_lenth = length_grads + noise
    avg_grads=[0,0,0]
    for i in range(0,length_grads):
        avg_grads[0]+=grads[i][0]
        avg_grads[1]+=grads[i][1]
        avg_grads[2]+=grads[i][2]
        avg_grads=[i/noise_lenth for i in avg_grads]
    return avg_grads
def dp_sgd(train,y_train,l_rate, n_epoch):
    train = clip(train, 5)
    coef = [0,0,0]
    final_grads = [0,0,0]
    intercept = 0
    for epoch in range(n_epoch):
        predictions=[]
        gradients=[]
        sum_error = 0.0
        for i in range(len(train)):
            yhat = predict(train[i], coef,intercept)
            predictions.append(yhat)
            error = y_train[i] - yhat
            sum_error += error**2
            intercept= intercept + l_rate * error * yhat * (1.0 - yhat)
## intercept
            temp=train[i]
            for j in range(3):
                coef[j] = coef[j] + l_rate * error * yhat * (1.0 - yhat) * temp[j]
            gradients.append(coef)
        final_grads = dp_final_gradients(gradients)
        print('&gt;epoch=%d, lrate=%.3f, error=%.3f, intercept=%.3f '% (epoch, l_rate, sum_error,intercept))
    return final_grads
l_rate = 0.24
n_epoch = 4
print("Gradients using Normal SGD ")
coef = sgd(X_train[:10],y_train[:10],l_rate, n_epoch)
print("Gradients using Differentially Private SGD ")
coef = dp_sgd(X_train[:10],y_train[:10],l_rate, n_epoch)
print(coef)
</span><strong class="bold1"><span class="kobospan1" id="kobo.1027.1">Gradients using Normal SGD</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1028.1">&gt;epoch=0, lrate=0.240, error=2.250, intercept=-0.030</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1029.1">&gt;epoch=1, lrate=0.240, error=2.000, intercept=-0.030</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1030.1">&gt;epoch=2, lrate=0.240, error=2.000, intercept=-0.030</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1031.1">&gt;epoch=3, lrate=0.240, error=2.000, intercept=-0.030</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1032.1">[-136.44000000000003, -263.88000000000005, -0.5099999999999999]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1033.1">Gradients using Differentially Private SGD</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1034.1">&gt;epoch=0, lrate=0.240, error=2.146, intercept=-0.127</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1035.1">&gt;epoch=1, lrate=0.240, error=1.654, intercept=-0.193</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1036.1">&gt;epoch=2, lrate=0.240, error=1.478, intercept=-0.229</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1037.1">&gt;epoch=3, lrate=0.240, error=1.396, intercept=-0.249</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1038.1">[-115.01700212848986, -222.44713076565455, -0.42992283117509383]</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.1039.1">By combining SGD with </span><a id="_idIndexMarker479" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1040.1">differential privacy, as we have done here, we can develop machine learning models that not only provide accurate predictions but also offer privacy protection for sensitive data. </span><span class="kobospan" id="kobo.1040.2">It enables organizations to leverage large-scale datasets while adhering to privacy regulations and </span><span><span class="kobospan" id="kobo.1041.1">ethical considerations.</span></span></p>
<h2 id="_idParaDest-104" class="calibre7"><a id="_idTextAnchor112" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1042.1">Clustering using differential privacy</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.1043.1">Let’s consider a scenario where we have a dataset of users’ browsing behavior. </span><span class="kobospan" id="kobo.1043.2">The goal of k-means clustering in this </span><a id="_idIndexMarker480" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1044.1">context is to identify </span><em class="italic"><span class="kobospan" id="kobo.1045.1">k</span></em><span class="kobospan" id="kobo.1046.1"> points, referred to as cluster centers, that minimize the sum of squared distances of the data points from their nearest cluster center. </span><span class="kobospan" id="kobo.1046.2">This partitioning allows us </span><a id="_idIndexMarker481" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1047.1">to group the users based on their browsing patterns. </span><span class="kobospan" id="kobo.1047.2">Additionally, we can assign new users to a group based on the closest cluster center. </span><span class="kobospan" id="kobo.1047.3">However, the release of the cluster</span><a id="_idIndexMarker482" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1048.1"> centers could potentially reveal sensitive information about specific users. </span><span class="kobospan" id="kobo.1048.2">For instance, if a particular user’s browsing behavior is significantly different from the majority, the standard k-means clustering algorithm might assign a cluster center specifically to this user, thereby disclosing sensitive details about their browsing habits. </span><span class="kobospan" id="kobo.1048.3">To address this privacy concern, we will implement clustering with differential privacy. </span><span class="kobospan" id="kobo.1048.4">By doing so, we aim to protect the privacy of individual users while still providing meaningful clustering results based on their </span><span><span class="kobospan" id="kobo.1049.1">browsing behavior.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1050.1">First, to illustrate the nature of the problem, let’s generate our cluster centroids without </span><span><span class="kobospan" id="kobo.1051.1">differential privacy:</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.1052.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.1053.1">code: Clustering_Differential_Privacy_diffprivlib.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.1054.1">
import numpy as np
from scipy import stats
from sklearn.cluster import KMeans
# Example dataset
data = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])
#apply clustering on this dataset and cluster the data 2 clusters
kmeans = KMeans(n_clusters=2)
kmeans.fit(data)
clusters = kmeans.labels_
original_centroids = kmeans.cluster_centers_
# Print the original data points, clusters and centroids
print("Original Data Points:\n", data)
print("Clusters:\n", clusters)
print("Original Centroids:\n", original_centroids)
</span><strong class="bold1"><span class="kobospan1" id="kobo.1055.1">Original Data Points:</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1056.1"> [[ 1.   2. </span><span class="kobospan1" id="kobo.1056.2">]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1057.1"> [ 1.5  1.8]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1058.1"> [ 5.   8. </span><span class="kobospan1" id="kobo.1058.2">]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1059.1"> [ 8.   8. </span><span class="kobospan1" id="kobo.1059.2">]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1060.1"> [ 1.   0.6]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1061.1"> [ 9.  11. </span><span class="kobospan1" id="kobo.1061.2">]]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1062.1">Clusters:</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1063.1"> [1 1 0 0 1 0]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1064.1">Original Centroids:</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1065.1"> [[7.33333333 9.        ]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1066.1"> [1.16666667 1.46666667]]</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.1067.1">In the preceding example, we have a synthetic dataset with two sensitive data attributes. </span><span class="kobospan" id="kobo.1067.2">We perform clustering using the KMeans algorithm from scikit-learn without incorporating differential privacy. </span><span class="kobospan" id="kobo.1067.3">We retrieve the cluster centroids using the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.1068.1">cluster_centers_</span></strong></span><span><span class="kobospan" id="kobo.1069.1"> attribute.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1070.1">The problem with this approach is</span><a id="_idIndexMarker483" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1071.1"> that the cluster centroids, which represent the center of each cluster, can reveal sensitive information about the data. </span><span class="kobospan" id="kobo.1071.2">In this case, the cluster centroids could potentially </span><a id="_idIndexMarker484" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1072.1">expose the mean values of the sensitive attributes. </span><span class="kobospan" id="kobo.1072.2">To address this privacy concern, differential privacy techniques can be applied to add noise to the cluster centroids, making it more challenging to infer sensitive information. </span><span class="kobospan" id="kobo.1072.3">However, note that the application of differential privacy in clustering algorithms requires careful consideration of privacy-utility trade-offs and appropriate privacy </span><span><span class="kobospan" id="kobo.1073.1">parameter selection.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1074.1">Let’s generate the centroids by adding noise to </span><span><span class="kobospan" id="kobo.1075.1">the datasets.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1076.1">Follow </span><span><span class="kobospan" id="kobo.1077.1">these steps:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.1078.1">Define the </span><strong class="source-inline1"><span class="kobospan" id="kobo.1079.1">add_noise</span></strong><span class="kobospan" id="kobo.1080.1"> function, which takes the original data, privacy parameter epsilon, and sensitivity as inputs. </span><span class="kobospan" id="kobo.1080.2">It generates Laplace-distributed noise and adds it to the data points. </span><span class="kobospan" id="kobo.1080.3">The noise is scaled by the sensitivity and privacy </span><span><span class="kobospan" id="kobo.1081.1">parameter epsilon.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1082.1">Calculate the sensitivity, which is the maximum change in data points due to the addition or removal of a single data point. </span><span class="kobospan" id="kobo.1082.2">In this case, we calculate the maximum absolute difference between any data point and the mean of </span><span><span class="kobospan" id="kobo.1083.1">the dataset.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1084.1">Specify the privacy parameter epsilon, which determines the amount of noise to be added. </span><span class="kobospan" id="kobo.1084.2">Add noise to the data points using the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.1085.1">add_noise</span></strong></span><span><span class="kobospan" id="kobo.1086.1"> function.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1087.1">Perform clustering on the noisy data using k-means clustering with two clusters. </span><span class="kobospan" id="kobo.1087.2">Retrieve the cluster labels assigned by the algorithm. </span><span class="kobospan" id="kobo.1087.3">Print the original data points, noisy data points, and</span><a id="_idIndexMarker485" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1088.1"> the clusters assigned to</span><a id="_idIndexMarker486" class="pcalibre1 calibre6 pcalibre"/> <span><span class="kobospan" id="kobo.1089.1">each point.</span></span></li>
</ol>
<pre class="source-code"><span class="kobospan1" id="kobo.1090.1">
def add_noise(data, epsilon, sensitivity):
    beta = sensitivity / epsilon
    laplace_noise = np.random.laplace(0, beta, data.shape)
    noisy_data = data + laplace_noise
    return noisy_data
# Sensitivity is the maximum change in data points due to the
addition or removal of a single data point
sensitivity = np.max(np.abs(data - np.mean(data, axis=0)))
# Privacy parameter epsilon determines the amount of noise to be added
epsilon = 0.1
# Add noise to the data points
noisy_data = add_noise(data, epsilon, sensitivity)
# Perform clustering on the noisy data
kmeans = KMeans(n_clusters=2)
kmeans.fit(noisy_data)
noisy_clusters = kmeans.labels_
noise_centroids = kmeans.cluster_centers_
print("Noisy Data Points:\n", noisy_data)
print("Noisy Clusters:\n", noisy_clusters)
print("Noisy Centroids :\n", noise_centroids)
Noisy Data Points:
 [[ -8.22894996 -25.09225801]
 [ 48.29852161 -93.63432789]
 [  2.61671234  86.87531981]
 [ 10.03114688   7.72529685]
 [-27.57009962  59.88763296]
 [ 16.99705384 -94.28428515]]
Noisy Clusters:
 [1 1 0 0 0 1]
Noisy Centroids :
 [[ -4.97408014  51.49608321]
 [ 19.0222085  -71.00362369]]</span></pre>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.1091.1">Generating differentially private centroids using IBM’s diffprivlib framework as an alternative method to the same use case “browsing </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.1092.1">behaviour scenario”.</span></strong></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1093.1">The diffprivlib framework is a Python library that provides tools and algorithms for performing differentially private data analysis. </span><strong class="source-inline"><span class="kobospan" id="kobo.1094.1">Diffprivlib</span></strong><span class="kobospan" id="kobo.1095.1"> consists of four main components that contribute to </span><span><span class="kobospan" id="kobo.1096.1">its functionality:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1097.1">Mechanisms</span></strong><span class="kobospan" id="kobo.1098.1">: These components serve as the fundamental building blocks of differential privacy and are utilized in all models implementing differential privacy. </span><span class="kobospan" id="kobo.1098.2">Mechanisms in diffprivlib are customizable and designed for use by experts who are</span><a id="_idIndexMarker487" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1099.1"> implementing their </span><span><span class="kobospan" id="kobo.1100.1">own models.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1101.1">Models</span></strong><span class="kobospan" id="kobo.1102.1">: This module </span><a id="_idIndexMarker488" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1103.1">encompasses machine learning models integrated with differential privacy. </span><strong class="source-inline1"><span class="kobospan" id="kobo.1104.1">Diffprivlib</span></strong><span class="kobospan" id="kobo.1105.1"> provides a variety of models that implement differential privacy, including clustering, classification, regression, dimensionality reduction, and preprocessing. </span><span class="kobospan" id="kobo.1105.2">These models are designed to ensure privacy while performing their </span><span><span class="kobospan" id="kobo.1106.1">respective tasks.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1107.1">Tools</span></strong><span class="kobospan" id="kobo.1108.1">: </span><strong class="source-inline1"><span class="kobospan" id="kobo.1109.1">Diffprivlib</span></strong><span class="kobospan" id="kobo.1110.1"> offers a range of generic tools designed for differentially private data analysis. </span><span class="kobospan" id="kobo.1110.2">These tools provide functionalities such as differentially private histograms, which adhere to the same format as NumPy’s histogram function. </span><span class="kobospan" id="kobo.1110.3">They enable users to perform various data analysis tasks while </span><span><span class="kobospan" id="kobo.1111.1">preserving privacy.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1112.1">Accountant</span></strong><span class="kobospan" id="kobo.1113.1">: The accountant component includes the </span><strong class="source-inline1"><span class="kobospan" id="kobo.1114.1">BudgetAccountant</span></strong><span class="kobospan" id="kobo.1115.1"> class, which facilitates the tracking of privacy budgets and calculation of total privacy loss using advanced composition techniques. </span><span class="kobospan" id="kobo.1115.2">This feature is crucial for managing and controlling privacy expenditure across multiple differentially private operations, ensuring that privacy guarantees are maintained. </span><span class="kobospan" id="kobo.1115.3">Together, these components in diffprivlib contribute to a comprehensive framework for implementing differential privacy in various data analysis scenarios. </span><span class="kobospan" id="kobo.1115.4">They provide the necessary tools, models, mechanisms, and privacy accounting capabilities to support privacy-preserving data </span><span><span class="kobospan" id="kobo.1116.1">analysis tasks.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.1117.1">Let’s generate cluster centroids</span><a id="_idIndexMarker489" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1118.1"> using the </span><span><span class="kobospan" id="kobo.1119.1">diffprivlib framework.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1120.1">Install the </span><strong class="source-inline"><span class="kobospan" id="kobo.1121.1">diffprivlib</span></strong><span class="kobospan" id="kobo.1122.1"> framework </span><span><span class="kobospan" id="kobo.1123.1">using </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.1124.1">pip</span></strong></span><span><span class="kobospan" id="kobo.1125.1">:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.1126.1">
!pip3 install diffprivlib</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.1127.1">Follow </span><span><span class="kobospan" id="kobo.1128.1">these steps:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.1129.1">Import the </span><strong class="source-inline1"><span class="kobospan" id="kobo.1130.1">KMeans</span></strong><span class="kobospan" id="kobo.1131.1"> class </span><span><span class="kobospan" id="kobo.1132.1">from </span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.1133.1">diffprivlib.models</span></strong></span><span><span class="kobospan" id="kobo.1134.1">.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1135.1">Specify the epsilon </span><a id="_idIndexMarker490" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1136.1">privacy parameter=, which determines the strength of </span><span><span class="kobospan" id="kobo.1137.1">privacy protection.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1138.1">Create an instance of KMeans with the </span><strong class="source-inline1"><span class="kobospan" id="kobo.1139.1">epsilon</span></strong><span class="kobospan" id="kobo.1140.1"> parameter and the desired number </span><span><span class="kobospan" id="kobo.1141.1">of clusters.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1142.1">Fit the differentially private KMeans model to the data using the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.1143.1">fit</span></strong></span><span><span class="kobospan" id="kobo.1144.1"> method.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1145.1">Finally, retrieve the differentially private cluster centroids using the </span><strong class="source-inline1"><span class="kobospan" id="kobo.1146.1">cluster_centers_</span></strong><span class="kobospan" id="kobo.1147.1"> attribute of the </span><span><span class="kobospan" id="kobo.1148.1">KMeans model.</span></span></li>
</ol>
<pre class="source-code"><span class="kobospan1" id="kobo.1149.1">
from diffprivlib.models import KMeans
epsilon = 1.0
# Perform clustering with differential privacy
dp_kmeans = KMeans(epsilon=epsilon, n_clusters=2)
dp_kmeans.fit(data)
# Get the differentially private cluster centroids
dp_centroids = dp_kmeans.cluster_centers_
# Print the differentially private cluster centroids
print("Differentially Private Cluster Centroids:\n", dp_centroids)
</span><strong class="bold1"><span class="kobospan1" id="kobo.1150.1">Differentially Private Cluster Centroids:</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1151.1"> [[8.71915573 9.51643083]</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1152.1"> [5.96366996 3.84980361]]</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.1153.1">It’s important to note that </span><a id="_idIndexMarker491" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1154.1">differential privacy in diffprivlib operates under the assumption of a trusted curator, where privacy guarantees are provided if the curator follows the privacy-preserving </span><span><span class="kobospan" id="kobo.1155.1">mechanisms correctly.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1156.1">However, for a complete</span><a id="_idIndexMarker492" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1157.1"> implementation of differential privacy, additional considerations, such as the choice of appropriate privacy parameters and the impact on data utility, should be </span><span><span class="kobospan" id="kobo.1158.1">carefully addressed.</span></span></p>
<h1 id="_idParaDest-105" class="calibre5"><a id="_idTextAnchor113" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1159.1">Deep learning using differential privacy</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.1160.1">In this section, we will focus on developing a fraud detection model using the PyTorch framework. </span><span class="kobospan" id="kobo.1160.2">Additionally, we will train deep learning models with differential privacy using open source frameworks such as PyTorch and Opacus. </span><span class="kobospan" id="kobo.1160.3">Using the PyTorch framework, we will develop a deep learning model specifically designed for fraud detection. </span><span class="kobospan" id="kobo.1160.4">PyTorch is a popular </span><a id="_idIndexMarker493" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1161.1">open source deep learning library that provides a flexible and efficient platform for building and training neural networks. </span><span class="kobospan" id="kobo.1161.2">Its rich set of tools and APIs make it well-suited for developing sophisticated</span><a id="_idIndexMarker494" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1162.1"> machine </span><span><span class="kobospan" id="kobo.1163.1">learning models.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1164.1">To incorporate differential privacy into the training process, we will utilize the Opacus library. </span><span class="kobospan" id="kobo.1164.2">Opacus is an open source PyTorch extension that provides tools for training deep learning models with differential privacy. </span><span class="kobospan" id="kobo.1164.3">It offers mechanisms such as gradient clipping, noise addition, and privacy analysis, which help ensure that the trained model preserves the privacy of individual </span><span><span class="kobospan" id="kobo.1165.1">data points.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1166.1">By combining PyTorch and Opacus, we can train deep learning models with differential privacy for fraud detection. </span><span class="kobospan" id="kobo.1166.2">This approach allows us to benefit from the expressive power of deep learning while adhering to privacy regulations and protecting sensitive information. </span><span class="kobospan" id="kobo.1166.3">Throughout this section, we will explore techniques for data preprocessing, model architecture design, training, and evaluation. </span><span class="kobospan" id="kobo.1166.4">We will consider the unique challenges and considerations associated with fraud detection, such as imbalanced datasets, feature engineering, and performance </span><span><span class="kobospan" id="kobo.1167.1">evaluation metrics.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1168.1">By the end of this section, you will have a comprehensive understanding of how to develop a fraud detection model using PyTorch and train it with differential privacy using frameworks such as Opacus. </span><span class="kobospan" id="kobo.1168.2">This knowledge will empower you to build robust and privacy-preserving machine learning models for fraud detection and </span><span><span class="kobospan" id="kobo.1169.1">similar applications.</span></span></p>
<h2 id="_idParaDest-106" class="calibre7"><a id="_idTextAnchor114" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1170.1">Fraud detection model using PyTorch</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.1171.1">In order to develop a </span><a id="_idIndexMarker495" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1172.1">deep learning model using PyTorch, we can follow the steps </span><a id="_idIndexMarker496" class="pcalibre1 calibre6 pcalibre"/><span><span class="kobospan" id="kobo.1173.1">outlined next:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1174.1">Load the transaction data</span></strong><span class="kobospan" id="kobo.1175.1">: Start by loading the transaction data into a pandas </span><span><span class="kobospan" id="kobo.1176.1">DataFrame object.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1177.1">Split the data</span></strong><span class="kobospan" id="kobo.1178.1">: Split the loaded data into training and </span><span><span class="kobospan" id="kobo.1179.1">testing sets.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1180.1">Convert the data to PyTorch tensors</span></strong><span class="kobospan" id="kobo.1181.1">: To work with PyTorch, we need to convert the data into PyTorch tensors. </span><span class="kobospan" id="kobo.1181.2">PyTorch tensors are efficient data structures that allow us to perform computations using the GPU for accelerated training. </span><span class="kobospan" id="kobo.1181.3">We use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.1182.1">torch.tensor</span></strong><span class="kobospan" id="kobo.1183.1"> function to convert </span><span><span class="kobospan" id="kobo.1184.1">the data.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1185.1">Create a simple linear model</span></strong><span class="kobospan" id="kobo.1186.1">: Define a deep learning model architecture using PyTorch’s </span><strong class="source-inline1"><span class="kobospan" id="kobo.1187.1">nn.Module</span></strong><span class="kobospan" id="kobo.1188.1"> class. </span><span class="kobospan" id="kobo.1188.2">For a simple linear model, we use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.1189.1">nn.Linear</span></strong><span class="kobospan" id="kobo.1190.1"> module </span><a id="_idIndexMarker497" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1191.1">to create a linear layer. </span><span class="kobospan" id="kobo.1191.2">To classify transactions as fraud or not, we add a sigmoid layer at the end </span><a id="_idIndexMarker498" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1192.1">of the model using the </span><strong class="source-inline1"><span class="kobospan" id="kobo.1193.1">nn.Sigmoid</span></strong> <span><span class="kobospan" id="kobo.1194.1">activation function.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1195.1">Train the model</span></strong><span class="kobospan" id="kobo.1196.1">: Set up the training loop to iterate over the training data and update the model’s parameters based on the defined loss function and optimization algorithm. </span><span class="kobospan" id="kobo.1196.2">Use PyTorch’s </span><strong class="source-inline1"><span class="kobospan" id="kobo.1197.1">nn.CrossEntropyLoss</span></strong><span class="kobospan" id="kobo.1198.1"> as the loss function and select an appropriate optimizer such as </span><strong class="source-inline1"><span class="kobospan" id="kobo.1199.1">torch.optim.SGD</span></strong><span class="kobospan" id="kobo.1200.1"> or </span><strong class="source-inline1"><span class="kobospan" id="kobo.1201.1">torch.optim.Adam</span></strong><span class="kobospan" id="kobo.1202.1"> for updating the </span><span><span class="kobospan" id="kobo.1203.1">model’s parameters.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1204.1">Monitor the loss</span></strong><span class="kobospan" id="kobo.1205.1">: During training, keep track of the loss at each step. </span><span class="kobospan" id="kobo.1205.2">The loss represents the discrepancy between the predicted outputs of the model and the true labels. </span><span class="kobospan" id="kobo.1205.3">By monitoring the loss, you can assess the progress of the model’s training and make adjustments </span><span><span class="kobospan" id="kobo.1206.1">if necessary.</span></span></li>
</ol>
<p class="calibre3"><span class="kobospan" id="kobo.1207.1">By following these steps, we develop a deep learning model using PyTorch for fraud detection. </span><span class="kobospan" id="kobo.1207.2">It’s important to note that this is a simplified overview, and you may need to customize the model architecture, incorporate additional layers or techniques, and fine-tune hyperparameters based on the specific requirements of your fraud </span><span><span class="kobospan" id="kobo.1208.1">detection task.</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.1209.1">Source Code: </span></em><span><em class="italic"><span class="kobospan" id="kobo.1210.1">Fraud_Detection_Deep Learning.ipynb</span></em></span></p>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.1211.1"># unzip the fraud_transactions.csv.zip file (provided in the GitHub repo of this book </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.1212.1">as fraud_transactions.csv)</span></strong></span></p>
<p class="calibre3"><a href="https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%205/fraud_transactions.csv.zip" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.1213.1">https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%205/fraud_transactions.csv.zip</span></span></a></p>
<pre class="source-code"><span class="kobospan1" id="kobo.1214.1">
import pandas as pd
import torch
url ="fraud_transactions.csv"
df_actual = pd.read_csv(url, sep=",")
df_actual.head()
df_transactions = df_actual[['CUSTOMER_ID','TERMINAL_ID','TX_AMOUNT','TX_FRAUD']]
df_transactions=df_transactions.head(50000)
df_transactions
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedShuffleSplit
print("No of Fraud Transactions:", df_transactions['TX_FRAUD'].value_counts()[0])
print("No of Non Fraud Transactions:", df_transactions['TX_FRAUD'].value_counts()[1])
print('No Frauds', round(df_transactions['TX_FRAUD'].value_counts()[0]/len(df_transactions) * 100,2), '% of the dataset')
print('Frauds', round(df_transactions['TX_FRAUD'].value_counts()[1]/len(df_transactions) * 100,2), '% of the dataset')
</span><strong class="bold1"><span class="kobospan1" id="kobo.1215.1">No of Fraud Transactions: 37870</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1216.1">No of Non Fraud Transactions: 12130</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1217.1">No Frauds 75.74 % of the dataset</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1218.1">Frauds 24.26 % of the dataset</span></strong><span class="kobospan1" id="kobo.1219.1">
X = df_transactions.drop('TX_FRAUD', axis=1)
y = df_transactions['TX_FRAUD']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
# Convert into Pytorch Tensors
x_train = torch.FloatTensor(X_train.values)
x_test = torch.FloatTensor(X_test.values)
y_train = torch.FloatTensor(y_train.values)
y_test = torch.FloatTensor(y_test.values)
if torch.cuda.is_available():
    DEVICE = "cuda"
else:
    DEVICE = "cpu"
print("Selected device is",DEVICE)
class FraudDataset(torch.utils.data.Dataset):
    def __init__(self, x, y):
        'Initialization'
        self.x = x
        self.y = y
    def __len__(self):
        'Returns the total number of samples'
        return len(self.x)
    def __getitem__(self, index):
        'Generates one sample of data'
        # Select sample index
        if self.y is not None:
            return self.x[index].to(DEVICE), self.y[index].to(DEVICE)
        else:
            return self.x[index].to(DEVICE)
train_loader_params = {'batch_size': 64,
          'shuffle': True,
          'num_workers': 0}
test_loader_params = {'batch_size': 64,
          'num_workers': 0}
# Loaders
training_set = FraudDataset(x_train, y_train)
testing_set = FraudDataset(x_test, y_test)
train_loader = torch.utils.data.DataLoader(training_set, **train_loader_params)
test_loader = torch.utils.data.DataLoader(testing_set, **test_loader_params)
class SimpleFraudMLP(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.first_sec = torch.nn.Sequential(
                           torch.nn.Linear(3, 450),
                           torch.nn.ReLU(),
        )
        self.second_sec = torch.nn.Sequential(
                           torch.nn.Linear(450, 450),
                           torch.nn.ReLU(),
                           torch.nn.Linear(450, 1),
                           torch.nn.Sigmoid(),
        )
    def forward(self, x):
        return self.second_sec(self.first_sec(x))
fraud_nn_model = SimpleFraudMLP().to(DEVICE)
from torch import nn, optim
loss_func = torch.nn.BCELoss().to(DEVICE)
optimizer = torch.optim.SGD(fraud_nn_model.parameters(), lr = 0.07)
def train(fraud_nn_mode,num_epochs):
    fraud_nn_model.train()
    for epoch in range(num_epochs):
          for x_batch, y_batch in train_loader:
            output = fraud_nn_model(x_train)
            print(output.squeeze())
            print(y_train)
            loss = loss_func(output.squeeze(), y_train)
# clear gradients for this training step
            optimizer.zero_grad()
# backpropagation, compute gradients
            loss.backward()
# apply gradients
            optimizer.step()
            print(epoch, loss.item())
    pass
train (fraud_nn_model, 10)
</span><strong class="bold1"><span class="kobospan1" id="kobo.1220.1">tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=&lt;SqueezeBackward0&gt;)</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1221.1">tensor([1., 1., 1.,  ..., 0., 0., 0.])</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1222.1">0 24.191429138183594</span></strong></pre>
<h2 id="_idParaDest-107" class="calibre7"><a id="_idTextAnchor115" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1223.1">Fraud detection model with differential privacy using the Opacus framework</span></h2>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.1224.1">Opacus</span></strong><span class="kobospan" id="kobo.1225.1">, an open source library, is the PyTorch implementation of the SGD-DP algorithm that supports differential privacy. </span><span class="kobospan" id="kobo.1225.2">Opacus preserves the privacy of each training sample while limiting</span><a id="_idIndexMarker499" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1226.1"> the impact on the accuracy of the final model. </span><span class="kobospan" id="kobo.1226.2">In this way, the privacy of outliers is also preserved. </span><span class="kobospan" id="kobo.1226.3">Opacus adds noise to the gradients in every iteration to prevent the model from </span><a id="_idIndexMarker500" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1227.1">simply memorizing the training examples. </span><span class="kobospan" id="kobo.1227.2">Opacus adds noise at the right scale (too much noise will reduce the accuracy, and too little won’t help to protect privacy) by looking at the norm of </span><span><span class="kobospan" id="kobo.1228.1">the gradients.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1229.1">More details about Opacus can be found </span><span><span class="kobospan" id="kobo.1230.1">at </span></span><a href="https://opacus.ai/" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.1231.1">https://opacus.ai/</span></span></a><span><span class="kobospan" id="kobo.1232.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1233.1">Installing the Opacus library is done with the following code (I used the following version in this </span><span><span class="kobospan" id="kobo.1234.1">example: </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.1235.1">opacus==1.1.2</span></strong></span><span><span class="kobospan" id="kobo.1236.1">):</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.1237.1">
pip install opacus==1.1.2</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.1238.1">We will develop the same deep learning model and train it with differential privacy using the Opacus framework </span><span><span class="kobospan" id="kobo.1239.1">with PyTorch.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1240.1">Implement the </span><span><span class="kobospan" id="kobo.1241.1">following steps:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.1242.1">Load the </span><span><span class="kobospan" id="kobo.1243.1">transaction data.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1244.1">Split the data into train and test data sets using </span><span><span class="kobospan" id="kobo.1245.1">pandas DataFrames.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1246.1">Convert the data into </span><span><span class="kobospan" id="kobo.1247.1">PyTorch tensors.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1248.1">Create a simple linear model and use the sigmoid layer at the end to classify transactions as fraud </span><span><span class="kobospan" id="kobo.1249.1">or not.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1250.1">Make the model a </span><a id="_idIndexMarker501" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1251.1">private one (i.e., apply differential privacy to the model) using the instance of </span><strong class="source-inline1"><span class="kobospan" id="kobo.1252.1">PrivacyEngine</span></strong><span class="kobospan" id="kobo.1253.1"> provided by Opacus to protect the </span><span><span class="kobospan" id="kobo.1254.1">training data.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.1255.1">Train the model and </span><a id="_idIndexMarker502" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1256.1">measure the epsilon (</span><span><span class="kobospan" id="kobo.1257.1">privacy budget).</span></span></li>
</ol>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.1258.1">Source : </span></em><span><em class="italic"><span class="kobospan" id="kobo.1259.1">Fraud_Detection_DP.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.1260.1">
import pandas as pd
url=" fraud_transactions.csv"
df_actual = pd.read_csv(url, sep=",")
df_actual.head()
df_transactions = df_actual[['CUSTOMER_ID','TERMINAL_ID','TX_AMOUNT','TX_FRAUD']]
df_transactions=df_transactions.head(50000)
df_transactions
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedShuffleSplit
print("No of Fraud Transactions:", df_transactions['TX_FRAUD'].value_counts()[0])
print("No of Non Fraud Transactions:", df_transactions['TX_FRAUD'].value_counts()[1])
print('No Frauds', round(df_transactions['TX_FRAUD'].value_counts()[0]/len(df_transactions) * 100,2), '% of the dataset')
print('Frauds', round(df_transactions['TX_FRAUD'].value_counts()[1]/len(df_transactions) * 100,2), '% of the dataset')
X = df_transactions.drop('TX_FRAUD', axis=1)
y = df_transactions['TX_FRAUD']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
x_train = torch.FloatTensor(X_train.values)
x_test = torch.FloatTensor(X_test.values)
y_train = torch.FloatTensor(y_train.values)
y_test = torch.FloatTensor(y_test.values)
if torch.cuda.is_available():
    DEVICE = "cuda"
else:
    DEVICE = "cpu"
print("Selected device is",DEVICE)
class FraudDataset(torch.utils.data.Dataset):
    def __init__(self, x, y):
        'Initialization'
        self.x = x
        self.y = y
    def __len__(self):
        'Returns the total number of samples'
        return len(self.x)
    def __getitem__(self, index):
        'Generates one sample of data'
        # Select sample index
        if self.y is not None:
            return self.x[index].to(DEVICE), self.y[index].to(DEVICE)
        else:
            return self.x[index].to(DEVICE)
train_loader_params = {'batch_size': 64,
          'shuffle': True,
          'num_workers': 0}
test_loader_params = {'batch_size': 64,
          'num_workers': 0}
# Generators
training_set = FraudDataset(x_train, y_train)
testing_set = FraudDataset(x_test, y_test)
train_loader = torch.utils.data.DataLoader(training_set, **train_loader_params)
test_loader = torch.utils.data.DataLoader(testing_set, **test_loader_params)
fraud_nn_model = SimpleFraudMLP().to(DEVICE)
import warnings
warnings.simplefilter("ignore")
MAX_GRAD_NORM = 1.2
EPSILON = 90.0
DELTA = 1e-5
EPOCHS = 20
LR = 1e-3
from opacus.validators import ModuleValidator
errors = ModuleValidator.validate(fraud_nn_model, strict=False)
errors[-5:]
from torch import nn, optim
#loss_func = nn.CrossEntropyLoss()
loss_func = torch.nn.BCELoss().to(DEVICE)
optimizer = torch.optim.SGD(fraud_nn_model.parameters(), lr = 0.07)
from opacus import PrivacyEngine
fraud_nn_model.train()
privacy_engine = PrivacyEngine()
model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(
    module=fraud_nn_model,
    optimizer=optimizer,
    data_loader=train_loader,
    epochs=EPOCHS,
    target_epsilon=EPSILON,
    target_delta=DELTA,
    max_grad_norm=MAX_GRAD_NORM,
)
print(f"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}")
import numpy as np
import time
n_epochs = 10
#Setting the model in training mode
fraud_nn_model.train()
#Training loop
start_time=time.time()
epochs_train_losses = []
epochs_test_losses = []
for epoch in range(n_epochs):
    train_loss=[]
    train_loss1=0
    for x_batch, y_batch in train_loader:
        fraud_nn_model.train()
        y_pred = fraud_nn_model(x_batch)
        loss = loss_func(y_pred.squeeze(), y_batch)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        train_loss.append(loss.item())
        train_loss1 += loss.item()*x_batch.size(0)
    epsilon = privacy_engine.get_epsilon(DELTA)
    print('ε epsilon{}    : delta:{}'.format(epsilon, DELTA))
    epochs_train_losses.append(np.mean(train_loss))
    print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))
</span><strong class="bold1"><span class="kobospan1" id="kobo.1261.1">ε epsilon33.98911164791893    : delta:1e-05</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1262.1">Epoch 0: train loss: 22.66661006201338</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1263.1">ε epsilon38.786904746786384    : delta:1e-05</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1264.1">Epoch 1: train loss: 23.087044257350552</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1265.1">ε epsilon42.819749628256126    : delta:1e-05</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1266.1">Epoch 2: train loss: 23.234367423345226</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1267.1">ε epsilon46.852594509725854    : delta:1e-05</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1268.1">Epoch 3: train loss: 23.257508610022786</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1269.1">ε epsilon50.8854393911956    : delta:1e-05</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1270.1">Epoch 4: train loss: 23.949310037727983</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1271.1">ε epsilon54.91828427266533    : delta:1e-05</span></strong>
<strong class="bold1"><span class="kobospan1" id="kobo.1272.1">Epoch 5: train loss: 22.498504093839657</span></strong></pre>
<p class="calibre3"><span class="kobospan" id="kobo.1273.1">In each epoch, the </span><a id="_idIndexMarker503" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1274.1">training loss fluctuates, but</span><a id="_idIndexMarker504" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1275.1"> at the same time, privacy loss (budget) </span><span><span class="kobospan" id="kobo.1276.1">ε increases.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1277.1">In this way, deep learning models can be trained for differential privacy with minimal code changes using Opacus and protect the training </span><span><span class="kobospan" id="kobo.1278.1">data’s privacy.</span></span></p>
<h1 id="_idParaDest-108" class="calibre5"><a id="_idTextAnchor116" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1279.1">Differential privacy machine learning frameworks</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.1280.1">The following are some of the popular </span><a id="_idIndexMarker505" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1281.1">differential privacy machine </span><span><span class="kobospan" id="kobo.1282.1">learning frameworks:</span></span></p>
<table class="no-table-style" id="table006-3">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<thead class="calibre18">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.1283.1">Framework</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.1284.1">Implementation</span></span></p>
</td>
</tr>
</thead>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.1285.1">Opacus</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.1286.1">PyTorch.</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.1287.1">Tensor </span><span><span class="kobospan" id="kobo.1288.1">Flow Privacy</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.1289.1">TensorFlow.</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.1290.1">Pyvacy</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.1291.1">TensorFlow Privacy, but </span><span><span class="kobospan" id="kobo.1292.1">for PyTorch.</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.1293.1">JAX(DP)</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.1294.1">JAX is Autograd</span><span lang="ar-SA" xml:lang="ar-SA"><span class="kobospan" id="kobo.1295.1"> and </span></span><span class="kobospan" id="kobo.1296.1">XLA, brought together for high-performance machine </span><span><span class="kobospan" id="kobo.1297.1">learning research.</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.1298.1">Pysyft</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="source-inline"><span class="kobospan" id="kobo.1299.1">Pysyft</span></strong><span class="kobospan" id="kobo.1300.1"> is a Python library for private, secure machine learning using federated learning and differential privacy. </span><span class="kobospan" id="kobo.1300.2">It allows for secure and private training and inference of machine learning models across </span><span><span class="kobospan" id="kobo.1301.1">multiple devices.</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.1302.1">Table 5.17 – DP ML frameworks</span></p>
<h1 id="_idParaDest-109" class="calibre5"><a id="_idTextAnchor117" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1303.1">Limitations of differential privacy and strategies to overcome them</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.1304.1">Differential privacy has gained </span><a id="_idIndexMarker506" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1305.1">significant attention and adoption in both academia and industry due to its ability to</span><a id="_idIndexMarker507" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1306.1"> balance privacy and utility. </span><span class="kobospan" id="kobo.1306.2">However, like any other technique, differential privacy has its limitations and challenges that need to be addressed to ensure its effective implementation. </span><span class="kobospan" id="kobo.1306.3">Following are some of the major limitations of differential privacy and potential strategies to </span><span><span class="kobospan" id="kobo.1307.1">overcome them:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1308.1">Noise and utility trade-off</span></strong><span class="kobospan" id="kobo.1309.1">: Differential privacy achieves privacy by adding noise to query responses, which introduces a trade-off between privacy and utility. </span><span class="kobospan" id="kobo.1309.2">The amount of noise added determines the level of privacy, but excessive noise can significantly reduce the utility of the released data. </span><span class="kobospan" id="kobo.1309.3">Striking the right balance between privacy and utility is </span><span><span class="kobospan" id="kobo.1310.1">a challenge.</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1311.1">Strategy to overcome</span></strong><span class="kobospan" id="kobo.1312.1">: One approach to mitigating this limitation is to design better algorithms that minimize the impact of noise on utility. </span><span class="kobospan" id="kobo.1312.2">Researchers are constantly </span><a id="_idIndexMarker508" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1313.1">developing advanced mechanisms and techniques to optimize the noise injection process, such as </span><a id="_idIndexMarker509" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1314.1">adaptive noise calibration, privacy amplification through subsampling, or leveraging machine learning to generate more accurate and </span><span><span class="kobospan" id="kobo.1315.1">privacy-preserving responses.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1316.1">Inference attacks</span></strong><span class="kobospan" id="kobo.1317.1">: Differential privacy focuses on protecting individual privacy by limiting the influence of a single record. </span><span class="kobospan" id="kobo.1317.2">However, adversaries may employ sophisticated inference attacks to glean information by combining multiple noisy queries or utilizing external side information. </span><span class="kobospan" id="kobo.1317.3">These attacks exploit patterns or correlations present in the data to infer </span><span><span class="kobospan" id="kobo.1318.1">sensitive details.</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1319.1">Strategy to overcome</span></strong><span class="kobospan" id="kobo.1320.1">: To overcome inference attacks, additional privacy-preserving techniques can be combined with differential privacy. </span><span class="kobospan" id="kobo.1320.2">For instance, secure </span><strong class="bold"><span class="kobospan" id="kobo.1321.1">multi-party computation (MPC)</span></strong><span class="kobospan" id="kobo.1322.1"> protocols can be used to compute </span><a id="_idIndexMarker510" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1323.1">aggregate statistics without revealing individual data points, thereby enhancing </span><span><span class="kobospan" id="kobo.1324.1">privacy protection.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1325.1">Privacy budget exhaustion</span></strong><span class="kobospan" id="kobo.1326.1">: Differential privacy employs a privacy budget, which represents the maximum allowable privacy loss over a sequence of queries. </span><span class="kobospan" id="kobo.1326.2">Each query consumes a portion of this budget, and once it is depleted, no further queries can be made while maintaining differential privacy guarantees. </span><span class="kobospan" id="kobo.1326.3">This limitation poses a challenge in scenarios where a large number of queries need to </span><span><span class="kobospan" id="kobo.1327.1">be answered.</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1328.1">Strategy to overcome</span></strong><span class="kobospan" id="kobo.1329.1">: One approach to address privacy budget exhaustion is to allocate budgets dynamically based on the sensitivity of the data or the specific context of the queries. </span><span class="kobospan" id="kobo.1329.2">By adapting the budget allocation strategy, it is possible</span><a id="_idIndexMarker511" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1330.1"> to optimize the utility of the released data and extend the </span><a id="_idIndexMarker512" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1331.1">number of allowable queries without compromising privacy. </span><span class="kobospan" id="kobo.1331.2">Additionally, advanced composition techniques, such as Rényi differential privacy, can be employed to manage privacy budgets more effectively and allow for </span><span><span class="kobospan" id="kobo.1332.1">finer-grained control.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1333.1">External data and auxiliary information</span></strong><span class="kobospan" id="kobo.1334.1">: Differential privacy assumes that the released data is the only source of information available to an adversary. </span><span class="kobospan" id="kobo.1334.2">However, adversaries could potentially leverage external data sources or auxiliary information to improve their attacks. </span><span class="kobospan" id="kobo.1334.3">These external sources might reveal additional details about individuals or contain correlated data, making it challenging to maintain </span><span><span class="kobospan" id="kobo.1335.1">privacy guarantees.</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1336.1">Strategy to overcome</span></strong><span class="kobospan" id="kobo.1337.1">: To overcome this limitation, it is crucial to carefully analyze the potential impact of external data sources and auxiliary information on privacy. </span><span class="kobospan" id="kobo.1337.2">Adapting data integration techniques, such as secure multiparty computation or cryptographic protocols, can help protect against attacks that exploit external information. </span><span class="kobospan" id="kobo.1337.3">Moreover, proactive measures such as data de-identification and minimizing data linkage can further enhance privacy protection against </span><span><span class="kobospan" id="kobo.1338.1">such threats.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1339.1">Limited support for complex data types</span></strong><span class="kobospan" id="kobo.1340.1">: Differential privacy has predominantly focused on numerical or categorical data, which limits its applicability to more complex data types such as text, images, or graphs. </span><span class="kobospan" id="kobo.1340.2">Preserving privacy in these domains while maintaining meaningful utility poses </span><span><span class="kobospan" id="kobo.1341.1">a challenge.</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1342.1">Strategy to overcome</span></strong><span class="kobospan" id="kobo.1343.1">: Researchers are actively exploring techniques to extend differential privacy to complex data types. </span><span class="kobospan" id="kobo.1343.2">For example, for text data, approaches such as differentially private text generation or privacy-preserving NLP models are being developed. </span><span class="kobospan" id="kobo.1343.3">For images, techniques such as differentially private deep learning or generative adversarial networks with privacy guarantees are being investigated. </span><span class="kobospan" id="kobo.1343.4">These advancements aim to provide privacy guarantees </span><a id="_idIndexMarker513" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1344.1">for a wider range of data types. </span><span class="kobospan" id="kobo.1344.2">LLMs trained with differential </span><a id="_idIndexMarker514" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1345.1">privacy also expose certain privacy leaks. </span><span class="kobospan" id="kobo.1345.2">For more information, we strongly suggest reading the research paper </span><span><span class="kobospan" id="kobo.1346.1">at </span></span><a href="https://arxiv.org/pdf/2202.05520.pdf" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.1347.1">https://arxiv.org/pdf/2202.05520.pdf</span></span></a><span><span class="kobospan" id="kobo.1348.1">.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1349.1">Limited protection against insider attacks</span></strong><span class="kobospan" id="kobo.1350.1">: Differential privacy primarily focuses on protecting data against external adversaries. </span><span class="kobospan" id="kobo.1350.2">However, it may not be as effective in scenarios where insider attacks are a concern. </span><span class="kobospan" id="kobo.1350.3">Insiders with access to the raw data might intentionally modify the data or use their knowledge to </span><span><span class="kobospan" id="kobo.1351.1">breach privacy.</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1352.1">Strategy to overcome</span></strong><span class="kobospan" id="kobo.1353.1">: Combining differential privacy with additional security measures can help mitigate insider attacks. </span><span class="kobospan" id="kobo.1353.2">Techniques such as secure enclaves or secure hardware can be employed to protect the privacy of sensitive data even from those with direct access. </span><span class="kobospan" id="kobo.1353.3">Employing access controls, audit logs, and strict data governance policies can also deter insider threats and ensure accountability. </span><span class="kobospan" id="kobo.1353.4">We will learn more about secure enclaves in </span><a href="B16573_09.xhtml#_idTextAnchor204" class="pcalibre1 calibre6 pcalibre"><span><em class="italic"><span class="kobospan" id="kobo.1354.1">Chapter 9</span></em></span></a><span><span class="kobospan" id="kobo.1355.1">.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1356.1">Difficulty in preserving temporal privacy</span></strong><span class="kobospan" id="kobo.1357.1">: Differential privacy is primarily designed for static datasets, and it can be challenging to preserve privacy when dealing with temporal data or time-series analysis. </span><span class="kobospan" id="kobo.1357.2">Temporal correlations in the data can potentially lead to privacy breaches or </span><span><span class="kobospan" id="kobo.1358.1">inference attacks.</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1359.1">Strategy to overcome</span></strong><span class="kobospan" id="kobo.1360.1">: To address temporal privacy concerns, researchers are exploring techniques such as personalized differential privacy, where privacy parameters are adjusted based on an individual’s data history. </span><span class="kobospan" id="kobo.1360.2">Another approach involves introducing temporal consistency mechanisms that consider the correlation between consecutive queries or time intervals while preserving privacy. </span><span class="kobospan" id="kobo.1360.3">These techniques aim to protect privacy in dynamic and</span><a id="_idIndexMarker515" class="pcalibre1 calibre6 pcalibre"/> <span><span class="kobospan" id="kobo.1361.1">evolving datasets.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1362.1">Limited support for machine learning models</span></strong><span class="kobospan" id="kobo.1363.1">: Differential privacy techniques often pose</span><a id="_idIndexMarker516" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1364.1"> challenges when applied to machine learning models, especially deep learning architectures. </span><span class="kobospan" id="kobo.1364.2">The perturbation of model parameters or gradients may degrade the model’s performance or </span><span><span class="kobospan" id="kobo.1365.1">introduce vulnerabilities.</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1366.1">Strategy to overcome</span></strong><span class="kobospan" id="kobo.1367.1">: To overcome this limitation, researchers are developing privacy-preserving machine learning techniques tailored to differential privacy. </span><span class="kobospan" id="kobo.1367.2">Techniques such as federated learning, where models are trained on decentralized data without sharing sensitive information, can ensure privacy while maintaining utility. </span><span class="kobospan" id="kobo.1367.3">Additionally, advancements in privacy-preserving deep learning algorithms, such as differentially private stochastic gradient descent, aim to strike a balance between model performance and privacy guarantees. </span><span class="kobospan" id="kobo.1367.4">We will cover federated learning in more depth in the </span><span><span class="kobospan" id="kobo.1368.1">next chapter.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1369.1">Lack of standardization and interoperability</span></strong><span class="kobospan" id="kobo.1370.1">: The absence of standardized frameworks and interoperability can hinder the widespread adoption of differential privacy. </span><span class="kobospan" id="kobo.1370.2">Different implementations and approaches make it challenging to compare results or integrate privacy-preserving techniques across different platforms </span><span><span class="kobospan" id="kobo.1371.1">or systems.</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.1372.1">Strategy to overcome</span></strong><span class="kobospan" id="kobo.1373.1">: Establishing standardized guidelines and frameworks can help address the interoperability challenge. </span><span class="kobospan" id="kobo.1373.2">Organizations and industry consortia can collaborate to develop common APIs, protocols, and evaluation metrics for differential privacy. </span><span class="kobospan" id="kobo.1373.3">Efforts in open source libraries and tools, along with community-driven initiatives, can facilitate knowledge sharing and enable </span><a id="_idIndexMarker517" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1374.1">seamless integration of differential privacy techniques into </span><a id="_idIndexMarker518" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1375.1">existing systems </span><span><span class="kobospan" id="kobo.1376.1">and workflows.</span></span></li></ul></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.1377.1">Overall, while differential algorithms have many advantages, they are not a one-size-fits-all solution, and careful consideration must be taken when using them in </span><span><span class="kobospan" id="kobo.1378.1">practical applications.</span></span></p>
<h1 id="_idParaDest-110" class="calibre5"><a id="_idTextAnchor118" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1379.1">Summary</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.1380.1">In summary, in this chapter, we went through open source frameworks including PyDP, PipelineDP, Tumult Analytics, and PySpark in order to implement differential privacy. </span><span class="kobospan" id="kobo.1380.2">We implemented fraud detection machine learning models with and without differential privacy by developing a private stochastic gradient descent algorithm. </span><span class="kobospan" id="kobo.1380.3">We also implemented deep learning models and trained the models with differential privacy using the Opacus framework, which is based on PyTorch. </span><span class="kobospan" id="kobo.1380.4">Finally, we covered the limitations of differential privacy and strategies to overcome </span><span><span class="kobospan" id="kobo.1381.1">these limitations.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1382.1">In the next chapter, we’ll learn about the need for federated learning as we deep dive into it, covering the algorithms used and the frameworks that support federated learning, and explore an end-to-end implementation of a fraud detection use case using </span><span><span class="kobospan" id="kobo.1383.1">federated learning.</span></span></p>
</div>
</body></html>