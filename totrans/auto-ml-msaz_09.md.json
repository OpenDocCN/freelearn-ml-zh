["```py\n    !git clone https://github.com/microsoft/solution-accelerator-many-models\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    import os\n    import datetime as dt\n    from azureml.core import Workspace, Dataset, Datastore\n    from scripts.helper import split_data\n    ```", "```py\n    ManyModelsSample =\\\n    pd.read_csv('ManyModelsSampleData.csv', header = 0)\n    ```", "```py\n    target_path = 'MMSA_Sample_Folder' \n    os.makedirs(target_path, exist_ok=True)\n    ```", "```py\n    ManyModelsSample\n    ```", "```py\n    ManyModelsSample['Date'] =\\\n    ManyModelsSample['Date'].apply(lambda x:\\\n    dt.datetime.strptime(x, '%m/%d/%Y'))\n    ```", "```py\n    for x, y in ManyModelsSample.groupby('Store'):\n        y.to_csv('MMSA_Sample_Folder/{}.csv'.format(x),\\\n     header=True, index_label=False)\n    ```", "```py\n    timestamp_column = 'Date'\n    split_date = '2021-03-01'\n    ```", "```py\n    train_path, inference_path = split_data(target_path, \\\n    timestamp_column, split_date)\n    ```", "```py\n    ws = Workspace.from_config()\n    ```", "```py\n    datastore = ws.get_default_datastore()\n    ```", "```py\n    ds_train_path = target_path + '_train'\n    datastore.upload(src_dir=train_path, \\\n    target_path=ds_train_path, overwrite=True)\n    ```", "```py\n    ds_inference_path = target_path + '_inference'\n    datastore.upload(src_dir=inference_path, \\\n    target_path=ds_inference_path, overwrite=True)\n    ```", "```py\n    ds_train = \\\n    Dataset.File.from_files(path=\\\n    datastore.path(ds_train_path), validate=False)\n    ds_inference = Dataset.File.from_files(path=\\\n    datastore.path(ds_inference_path), validate=False)\n    ```", "```py\n    dataset_name = 'MMSA_Sample'\n    train_dataset_name = dataset_name + '_train'\n    inference_dataset_name = dataset_name + '_inference'\n    ```", "```py\n    ds_train.register(ws, train_dataset_name, create_new_version=True)\n    ds_inference.register(ws, inference_dataset_name, create_new_version=True)\n    ```", "```py\n    from azureml.core import Workspace, Datastore, Dataset\n    from azureml.core import Experiment\n    from azureml.core.compute import ComputeTarget\n    import pandas as pd\n    import os\n    ```", "```py\n    from azureml.contrib.automl.pipeline.steps import AutoMLPipelineBuilder\n    from azureml.pipeline.core import Pipeline\n    from scripts.helper import get_training_output\n    import logging\n    ```", "```py\n    ws = Workspace.from_config()\n    ```", "```py\n    dstore = ws.get_default_datastore()\n    ```", "```py\n    experiment = Experiment(ws, 'manymodels-training-pipeline-pandas-data')\n    ```", "```py\n    filedst_10_models = Dataset.get_by_name(ws, name = 'MMSA_Sample_train')\n    filedst_10_models_input =\\\n    filedst_10_models.as_named_input('MMSA_Sample_train')\n    ```", "```py\n    compute = \"compute-cluster\"\n    ```", "```py\n    partition_column_names = ['Store']  \n    ```", "```py\n    automl_settings = {\n        \"task\" : 'forecasting',\n        \"primary_metric\" : \\\n        'normalized_root_mean_squared_error',\n        \"iteration_timeout_minutes\" : 10, \n        \"iterations\" : 15,\n        \"experiment_timeout_hours\" : 1,\n        \"label_column_name\" : 'Sales',\n        \"n_cross_validations\" : 3,\n        \"verbosity\" : logging.INFO, \n        \"debug_log\": 'automl_pandas_debug.txt',\n        \"time_column_name\": 'Date',\n        \"max_horizon\" : 31,\n        \"track_child_runs\": False,\n        \"partition_column_names\": partition_column_names,\n        \"grain_column_names\": ['Store'],\n        \"pipeline_fetch_max_batch_size\": 15\n    }\n    ```", "```py\n    train_steps =\\\n    AutoMLPipelineBuilder.get_many_models_train_steps(\n    experiment=experiment,\n                       automl_settings=automl_settings,\n                       train_data=filedst_10_models_input,\n                       compute_target=compute,\n                       partition_column_names=\\\n                       partition_column_names,\n                       node_count=4,\n                       process_count_per_node=4,\n                       run_invocation_timeout=3700,\n                       output_datastore=dstore)\n    ```", "```py\n    pipeline = Pipeline(workspace=ws, steps=train_steps)\n    run = experiment.submit(pipeline)\n    ```", "```py\n    run.wait_for_completion(show_output=True) \n    ```", "```py\n    published_pipeline = pipeline.publish(name = \\\n    'MMSA_pandas', description = 'MMSA Solution using a pandas dataframe', \\\n    version = '1', continue_on_step_failure = False)\n    ```", "```py\n    training_pipeline_run_id =\"your pipeline run id\"\n    training_experiment_name = \"your training experiment name\" \n    ```", "```py\n    from azureml.core import Workspace, Datastore, Dataset\n    from azureml.core import Experiment\n    import pandas as pd\n    import os\n    from azureml.core.compute import ComputeTarget\n    from azureml.contrib.automl.pipeline.steps import AutoMLPipelineBuilder\n    from azureml.pipeline.core import Pipeline\n    ```", "```py\n    import shutil\n    import sys \n    from scripts.helper import get_forecasting_output\n    ```", "```py\n    ws = Workspace.from_config()\n    ```", "```py\n    dstore = ws.get_default_datastore()\n    ```", "```py\n    experiment = Experiment(ws, 'manymodels-forecasting-pipeline-pandas-data')\n    ```", "```py\n    filedst_10_models = Dataset.get_by_name(ws, name = 'MMSA_Sample_inference')\n    filedst_10_models_input =\\\n    filedst_10_models.as_named_input('MMSA_Sample_inference')\n    ```", "```py\n    compute = \"compute-cluster\"\n    ```", "```py\n    training_experiment_name = \"manymodels-training-pipeline-pandas-data\"\n    training_pipeline_run_id =\"your-run-ID\"\n    ```", "```py\n    partition_column_names = ['Store']\n    ```", "```py\n    inference_steps =\\\n    AutoMLPipelineBuilder.get_many_models_batch_inference_steps(\\\n                        experiment=experiment,\n                        inference_data=\\\n                        filedst_10_models_input,\n                        compute_target=compute,\n                        node_count=4,\n                        process_count_per_node=4,\n                        run_invocation_timeout=300,\n                        train_experiment_name=\\\n                        training_experiment_name,\n                        train_run_id=\\\n                        training_pipeline_run_id,\n                        partition_column_names=\\\n                        partition_column_names,\n                        time_column_name=\"Date\",\n                        target_column_name=\"Sales\")\n    ```", "```py\n    pipeline = Pipeline(workspace=ws, steps=train_steps)\n    run = experiment.submit(pipeline)\n    ```", "```py\n    run.wait_for_completion(show_output=True) \n    ```", "```py\n    published_pipeline = pipeline.publish(name = 'automl_score_many_models_pandas',\n                       description = \\\n                      'MMSA Solution using x data',\n                       version = '1',\n                       continue_on_step_failure = False)\n    ```", "```py\n    forecasting_results_name = \"forecasting_results\"\n    forecasting_output_name =\\\n    \"many_models_inference_output\"\n    forecast_file = get_forecasting_output(run,\\\n    forecasting_results_name, forecasting_output_name)\n    df = pd.read_csv(forecast_file, delimiter=\" \",\\\n    header=None)\n    df.columns = [\"Date\", \"Store\", \"Sales\", \"Predicted\" ]\n    df.head(10)\n    ```"]