<html><head></head><body>
		<div id="_idContainer129">
			<h1 id="_idParaDest-148"><a id="_idTextAnchor172"/><a id="_idTextAnchor173"/><em class="italic">Chapter 12</em>: Advanced Topics with MLflow</h1>
			<p>In this chapter, we will cover advanced topics to address common situations and use cases whereby you can leverage your MLflow knowledge by using different types of models from the ones exposed in the rest of the book, to ensure a breadth of feature coverage and exposure to assorted topics.</p>
			<p>Specifically, we will look at the following sections in this chapter: </p>
			<ul>
				<li>Exploring MLflow use cases with AutoML</li>
				<li>Intergrating MLflow with other languages</li>
				<li>Understanding MLflow plugins</li>
			</ul>
			<p>We will represent each of the cases with a brief description of the problem and solutions in a pattern format—namely, a problem context and a solution approach.</p>
			<p>The different sections of this chapter don't present continuity as they address different issues.</p>
			<h1 id="_idParaDest-149"><a id="_idTextAnchor174"/>Technical requirements</h1>
			<p>For this chapter, you will need the following prerequisites: </p>
			<ul>
				<li>The latest version of Docker installed on your machine. If you don't already have it installed, please follow the instructions at <a href="https://docs.docker.com/get-docker/">https://docs.docker.com/get-docker/</a>.</li>
				<li>The latest version of Docker Compose installed—please follow the instructions at <a href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a>.</li>
				<li>Access to Git in the command line, and installed as described at <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">https://git-scm.com/book/en/v2/Getting-Started-Installing-Git</a>.</li>
				<li>Access to a Bash terminal (Linux or Windows). </li>
				<li>Access to a browser.</li>
				<li>Python 3.5+ installed.</li>
				<li>The latest version of your ML library installed locally as described in <a href="B16783_04_Final_SB_epub.xhtml#_idTextAnchor081"><em class="italic">Chapter 4</em></a>, <em class="italic">Experiment Management in MLflow</em>.</li>
			</ul>
			<h1 id="_idParaDest-150"><a id="_idTextAnchor175"/>Exploring MLflow use cases with AutoML </h1>
			<p>Executing an <a id="_idIndexMarker440"/>ML project requires a breadth <a id="_idIndexMarker441"/>of knowledge in multiple areas and, in a lot of cases, deep technical steps of expertise. One emergent technique to <a id="_idIndexMarker442"/>ease the adoption and accelerate <strong class="bold">time to market</strong> (<strong class="bold">TTM</strong>) in projects is the use of <strong class="bold">automated machine learning</strong> (<strong class="bold">AutoML</strong>), where some of the activities of the <a id="_idIndexMarker443"/>model developer are automated. It basically consists of automating steps in ML in a twofold approach, outlined as follows:</p>
			<ul>
				<li><strong class="bold">Feature selection</strong>: Using <a id="_idIndexMarker444"/>optimization techniques (for example, Bayesian techniques) to select the best features as input to a model </li>
				<li><strong class="bold">Modeling</strong>: Automatically <a id="_idIndexMarker445"/>identifying a set of models to use by testing multiple algorithms using hyperparameter optimization techniques</li>
			</ul>
			<p>We will explore <a id="_idIndexMarker446"/>the integration of MLflow with an ML library called PyCaret (<a href="https://pycaret.org/">https://pycaret.org/</a>) that allows us to leverage its AutoML techniques and log the process in MLflow so that you can automatically obtain the best performance for your problem.</p>
			<p>We will look next at the use case of pyStock in the book and will look at automatically modeling based on our training data. </p>
			<h2 id="_idParaDest-151"><a id="_idTextAnchor176"/>AutoML pyStock classification use case</h2>
			<p>For <a id="_idIndexMarker447"/>this section, we will work on a solution that you can follow along with (https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter12/automl_pycaret) with the notebook and our project dataset. We will execute the following steps in order to implement AutoML for our use case:</p>
			<ol>
				<li>Let's start <a id="_idIndexMarker448"/>by installing the full version of PyCaret, as follows:<p class="source-code">pip install pycaret==2.3.1</p></li>
				<li>First, we should import the necessary libraries, like so:<p class="source-code">import pandas</p><p class="source-code">import pycaret</p></li>
				<li>Then, we read all the training data, like this:<p class="source-code">data=pandas.read_csv("training_data.csv",header='infer')</p></li>
				<li>Next, we set up the project data and load the input data, as follows:<p class="source-code">from pycaret.classification import *</p><p class="source-code">s = setup(data, target = 'target',  log_experiment = True, experiment_name = 'psystock')</p><p>Here is the output:</p><div id="_idContainer119" class="IMG---Figure"><img src="image/image0018.jpg" alt="Figure 12.1 – Automatic feature inference&#13;&#10;"/></div><p class="figure-caption">Figure 12.1 – Automatic feature inference</p></li>
				<li>Then, we <a id="_idIndexMarker449"/>execute <strong class="source-inline">compare_models()</strong>, like this:<p class="source-code">best = compare_models()</p><p>Here is the output:</p><div id="_idContainer120" class="IMG---Figure"><img src="image/image0029.jpg" alt="Figure 12.2 – Different types of models&#13;&#10;"/></div><p class="figure-caption">Figure 12.2 – Different types of models</p></li>
				<li>Select <a id="_idIndexMarker450"/>your best model by running the following command:<p class="source-code">best = compare_models()</p></li>
				<li>Run MLflow <a id="_idIndexMarker451"/>to check all the models (in the following <strong class="bold">Uniform Resource Locator</strong> (<strong class="bold">URL</strong>): http://127.0.0.1:5000/#/experiments/1), and you should then see a screen like this:</li>
			</ol>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="image/image0038.jpg" alt=""/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.3 – Models logged in MLflow</p>
			<p>We will <a id="_idIndexMarker452"/>next look at implementing AutoML in a scenario where we don't have targets. We will need to use anomaly detection, a non-supervised ML technique.</p>
			<h2 id="_idParaDest-152"><a id="_idTextAnchor177"/>AutoML – anomaly detection in fraud</h2>
			<p>For this <a id="_idIndexMarker453"/>section, we will work on a solution that you can follow along with (https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter12/automl_pycaret_fraud) with the notebook and our project dataset. We will execute the following steps in order to implement AutoML for our use case:</p>
			<ol>
				<li value="1">First, we should import the libraries, like so:<p class="source-code">import pandas</p><p class="source-code">import pycaret</p></li>
				<li>Then, we read all the training data, like this:<p class="source-code">data=pandas.read_csv("credit_card.csv",header='infer')</p><p>Here is the output:</p><div id="_idContainer122" class="IMG---Figure"><img src="image/image0049.jpg" alt="Figure 12.4 – Models automatically available in MLflow&#13;&#10;"/></div><p class="figure-caption">Figure 12.4 – Models automatically available in MLflow</p></li>
				<li>Next, we set <a id="_idIndexMarker454"/>up the project data and load the input data, as follows:<p class="source-code">from pycaret.anomaly import *</p><p class="source-code">s = setup(df,  log_experiment = True, experiment_name = 'psystock_anomaly'))</p></li>
				<li>Then, we execute <strong class="source-inline">compare_models()</strong>, like this:<p class="source-code">models()</p><p>Here is the output:</p><div id="_idContainer123" class="IMG---Figure"><img src="image/image0057.jpg" alt="Figure 12.5 – Different types of models&#13;&#10;"/></div><p class="figure-caption">Figure 12.5 – Different types of models</p></li>
				<li>Then, execute <a id="_idIndexMarker455"/>your chosen anomaly detection model, as follows:<p class="source-code">iforest = create_model('iforest', fraction = 0.1)</p><p class="source-code">iforest_results = assign_model(iforest)</p><p class="source-code">iforest_results.head()</p></li>
				<li>Next, run MLflow to check all the models (at the following URL: http://127.0.0.1:5000/#/experiments/1), and you should see a screen like this: </li>
			</ol>
			<div>
				<div id="_idContainer124" class="IMG---Figure">
					<img src="image/image0066.jpg" alt="Figure 12.6 – Models automatically available in MLflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.6 – Models automatically available in MLflow</p>
			<p>At this <a id="_idIndexMarker456"/>stage, you should be able to leverage the knowledge you have gained throughout the book to use the models identified in this book for models in production. We will next look at intergrating MLflow with other languages—in this case, Java.</p>
			<h1 id="_idParaDest-153"><a id="_idTextAnchor178"/>Integrating MLflow with other languages </h1>
			<p>MLflow is primarily a tool ingrained in the Python ecosystem in the ML space. At its core, MLflow <a id="_idIndexMarker457"/>components provide a <strong class="bold">REpresentational State Transfer</strong> (<strong class="bold">REST</strong>) interface. As long as <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>) wrappers are made, the underlying code is accessible from <a id="_idIndexMarker458"/>any language with REST support. The REST <a id="_idIndexMarker459"/>interface is extensively documented in <a href="https://www.mlflow.org/docs/latest/rest-api.html">https://www.mlflow.org/docs/latest/rest-api.html</a>; most of the integration into other languages is about providing layers to access the API in a concise, language-specific library. </p>
			<h2 id="_idParaDest-154"><a id="_idTextAnchor179"/>MLflow Java example</h2>
			<p>Multiple teams <a id="_idIndexMarker460"/>in the ML space are inserted in a context where multiple languages are used. One of the most important platforms on large-scale distributed <a id="_idIndexMarker461"/>systems is <strong class="bold">Java Virtual Machine</strong> (<strong class="bold">JVM</strong>). Being able to implement systems that can interact with Java-based systems is paramount <a id="_idIndexMarker462"/>for a smooth integration of MLflow with the wider <strong class="bold">information technology</strong> (<strong class="bold">IT</strong>) infrastructure.</p>
			<p>We will show an example of using MLflow in Java (you can have access to the code here: https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter12/psystock-java-example). In order to use MLflow in Java, you will have to execute the following steps:</p>
			<ol>
				<li value="1">Install Java and the Java build tool called <strong class="source-inline">Maven</strong>, as directed by <a href="https://maven.apache.org/install.html">https://maven.apache.org/install.html</a>.</li>
				<li>Create a dependencies <strong class="source-inline">pom.xml</strong> file with the MLflow client dependency, as follows:<p class="source-code">&lt;project&gt;</p><p class="source-code">…</p><p class="source-code">  &lt;dependencies&gt;</p><p class="source-code">    &lt;dependency&gt;</p><p class="source-code">      &lt;groupId&gt;org.mlflow&lt;/groupId&gt;</p><p class="source-code">      &lt;artifactId&gt;mlflow-client&lt;/artifactId&gt;</p><p class="source-code">      &lt;version&gt;1.17.0&lt;/version&gt;..</p><p class="source-code">  &lt;/dependency&gt;</p><p class="source-code">…</p><p class="source-code">&lt;/project&gt;</p></li>
				<li>Implement <a id="_idIndexMarker463"/>your main class, like this:<p class="source-code">package ai.psystock.jclient;</p><p class="source-code">import org.mlflow.tracking.MlflowClient;</p><p class="source-code">import org.mlflow.tracking.MlflowContext;</p><p class="source-code">import java.io.File;</p><p class="source-code">import java.io.PrintWriter;</p><p class="source-code">public class Main {</p><p class="source-code">    public static void main(String[] args) {</p><p class="source-code">        MlflowClient mlflowClient=new MlflowClient();</p><p class="source-code">        String runId="test";</p><p class="source-code">        RunStatus = RunStatus.FINISHED;</p><p class="source-code">        </p><p class="source-code">        MlflowContext = new MlflowContext();</p><p class="source-code">        MlflowClient client = mlflowContext.getClient();</p><p class="source-code">        </p><p class="source-code">        client.logParam("test","alpha", "0.5");</p><p class="source-code">        client.logMetric("test","rmse", 0.786);</p><p class="source-code">        client.setTag("test","origin","HelloWorldFluent Java Example");</p><p class="source-code">         mlflowClient.setTerminated(runId, runStatus, System.currentTimeMillis());</p><p class="source-code">    }</p><p class="source-code">}</p></li>
				<li>Build your project with Maven, as follows:<p class="source-code">mvn clean package</p></li>
				<li>Execute your <a id="_idIndexMarker464"/>Java project by running the following code:<p class="source-code">java -jar ./target/java-maven-command-line-1.0-SNAPSHOT.jar</p></li>
			</ol>
			<p>At this stage, MLflow is natively integrated into the Python ecosystem. It provides links to other ecosystems similar to what we demonstrated in this chapter with the JVM language. We will next explore an example in the R language.</p>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor180"/>MLflow R example</h2>
			<p>We will show an example of using MLflow in R using the Databricks environment (you can have <a id="_idIndexMarker465"/>access to the code here: <a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter12/mlflow-example-r">https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter12/mlflow-example-r</a>). You can import the notebook from the Databricks Community Edition environment and explore the code from there.</p>
			<p>In this section, we will run a random forest classifier in R over the standard dataset available as an R package, called <strong class="source-inline">Pima.tf</strong> (<a href="https://rdrr.io/cran/MASS/man/Pima.tr.html">https://rdrr.io/cran/MASS/man/Pima.tr.html</a>). This is a simple dataset with a set of biomedical features to detect whether a specific patient has diabetes or not. </p>
			<p>In order to create a notebook for your R example code, you need to execute the following steps:</p>
			<ol>
				<li value="1">Sign up to Databricks Community Edition at <a href="https://community.cloud.databricks.com/">https://community.cloud.databricks.com/</a> and create an account.</li>
				<li>Log in to your account with your just-created credentials.</li>
				<li>Create a <a id="_idIndexMarker466"/>cluster to use for your workloads. You are allowed to have clusters for your workloads with a limit of 15 <strong class="bold">gigabytes</strong> (<strong class="bold">GB</strong>) of <strong class="bold">random-access memory</strong> (<strong class="bold">RAM</strong>) and with usage for a defined period of time. <p>You can see an overview of the cluster-creation process in the following screenshot:</p><div id="_idContainer125" class="IMG---Figure"><img src="image/Image_007.jpg" alt="Figure 12.7 – Creating a cluster in Databricks Community Edition&#13;&#10;"/></div><p class="figure-caption">Figure 12.7 – Creating a cluster in Databricks Community Edition</p></li>
				<li>Create a new notebook in your Databricks platform on your landing workspace page by clicking on the <strong class="bold">Create a Blank Notebook</strong> button in the top right of the page, as illustrated in the following screenshot:<div id="_idContainer126" class="IMG---Figure"><img src="image/Image_008.jpg" alt="Figure 12.8 – Creating a new notebook in Databricks Community Edition&#13;&#10;"/></div><p class="figure-caption">Figure 12.8 – Creating a new notebook in Databricks Community Edition</p></li>
				<li>We are now <a id="_idIndexMarker467"/>ready to start a notebook to execute a basic training job in this managed environment. You can start by clicking on <strong class="bold">New Notebook</strong> in your workspace. You need to set the default language as <strong class="bold">R</strong> and attach the notebook to your cluster created in the previous chapter.<p>You can see an overview of the notebook-creation process in the following screenshot:</p><div id="_idContainer127" class="IMG---Figure"><img src="image/Image_009.jpg" alt="Figure 12.9 – Adding details of your new R notebook&#13;&#10;"/></div><p class="figure-caption">Figure 12.9 – Adding details of your new R notebook</p></li>
				<li>You start on <a id="_idIndexMarker468"/>your notebook by importing the MLflow dependencies through <strong class="source-inline">install.packages</strong> and by instantiating the library, as follows:<p class="source-code">install.packages("mlflow")</p><p class="source-code">library(mlflow)</p><p class="source-code">install_mlflow()</p></li>
				<li>We will now proceed to install extra packages with the data we will need to be able to execute our example. In this particular example, we will be using the <strong class="source-inline">carrier</strong> package to facilitate the manipulation of remote functions and log information about them. We will also include the <strong class="source-inline">MASS</strong> package, which contains the dataset we will be using in this example. The <strong class="source-inline">el071</strong> package and <strong class="source-inline">randomforest</strong> will be used for statistical functions and to run the prediction classifier. Here is the code you will need:<p class="source-code">install.packages("carrier")</p><p class="source-code">install.packages("e1071")</p><p class="source-code"> </p><p class="source-code">library(MASS)</p><p class="source-code">library(caret)</p><p class="source-code">library(e1071)</p><p class="source-code">library(randomForest)</p><p class="source-code">library(SparkR)</p><p class="source-code">library(carrier)</p></li>
				<li>Next, we will focus on starting the experiment by starting a block of code with this line of code: <strong class="source-inline">with(mlflow_start_run(), {</strong>. This will basically allow us to start logging the <a id="_idIndexMarker469"/>model parameters through the <strong class="source-inline">mlflow_log_param</strong> function. In the following case, we will be logging in MLflow the number of trees (<strong class="source-inline">ntree</strong>) and the number of features randomly sampled (<strong class="source-inline">mtry</strong>) at each split of the algorithm. The code is illustrated in the following snippet:<p class="source-code">with(mlflow_start_run(), {</p><p class="source-code">  </p><p class="source-code">  # Set the model parameters</p><p class="source-code">  ntree &lt;- 100</p><p class="source-code">  mtry &lt;- 3</p><p class="source-code">    # Log the model parameters used for this run</p><p class="source-code">  mlflow_log_param("ntree", ntree)</p><p class="source-code">  mlflow_log_param("mtry", mtry)</p></li>
				<li>In the next two lines, we instantiate the <strong class="source-inline">random forest</strong> algorithm by specifying the <strong class="source-inline">Pima.tr</strong> training dataset and adding the algorithm parameters. We then predict using the <strong class="source-inline">Pima.te</strong> test data. The code is illustrated in the following snippet:<p class="source-code">  rf &lt;- randomForest(type ~ ., data=Pima.tr, ntree=ntree, mtry=mtry)</p><p class="source-code">  </p><p class="source-code">  pred &lt;- predict(rf, newdata=Pima.te[,1:7])</p></li>
				<li>We can now <a id="_idIndexMarker470"/>focus on calculating metrics around model performance—in this case, specificity and sensitivity—through the <strong class="source-inline">confusionMatrix</strong> method available in the <strong class="source-inline">caret</strong> package, as follows:<p class="source-code"># Define metrics to evaluate the model</p><p class="source-code">  cm &lt;- confusionMatrix(pred, reference = Pima.te[,8])</p><p class="source-code">  sensitivity &lt;- cm[["byClass"]]["Sensitivity"]</p><p class="source-code">  specificity &lt;- cm[["byClass"]]["Specificity"]</p><p class="source-code">  </p><p class="source-code">  # Log the value of the metrics </p><p class="source-code">  mlflow_log_metric("sensitivity", sensitivity)</p><p class="source-code">  mlflow_log_metric("specificity", specificity)</p></li>
				<li>We can now focus on uploading a confusion matrix plot based on previous metrics. The method in R to achieve logging of the model is <strong class="source-inline">mlflow_log_artifact</strong>. Here's the code you'll need:<p class="source-code">  # Log the value of the metrics </p><p class="source-code">    # Create and plot confusion matrix</p><p class="source-code">  png(filename="confusion_matrix_plot.png")</p><p class="source-code">  barplot(as.matrix(cm), main="Results",</p><p class="source-code">         xlab="Observed", ylim=c(0,200), col=c("green","blue"),</p><p class="source-code">         legend=rownames(cm), beside=TRUE)</p><p class="source-code">  dev.off()</p><p class="source-code">  </p><p class="source-code">  # Save the plot and log it as an artifact</p><p class="source-code">  mlflow_log_artifact("confusion_matrix_plot.png")</p></li>
				<li>Finally, we can serialize the model function and log it in MLflow so that it can be reusable from <a id="_idIndexMarker471"/>another R notebook, by using the <strong class="source-inline">crate</strong> method available on the <strong class="source-inline">carrier</strong> package. We end up logging the model with <strong class="source-inline">mlflow_log_model</strong> and closing the code with a bracket on the last line, as illustrated in the following code snippet:<p class="source-code">  predictor &lt;- crate(function(x) predict(rf,.x))</p><p class="source-code">  mlflow_log_model(predictor, "model")     </p><p class="source-code">})</p></li>
				<li>You are now free to explore the <strong class="bold">Experiment</strong> tab on your environment, and you should have access to your model log and be able to explore the metrics and details of the run, as shown in the following screenshot: </li>
			</ol>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="image/Image0102.jpg" alt="Figure 12.10 – Models automatically available in MLflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.10 – Models automatically available in MLflow</p>
			<p>In this section, we explored examples in Java and R, extremely relevant languages in the ML ecosystem for both engineers and data scientists. We will now delve into extending MLflow functionalities through plugins.</p>
			<h1 id="_idParaDest-156"><a id="_idTextAnchor181"/>Understanding MLflow plugins</h1>
			<p>As an ML engineer, multiple times in your project you can reach the limits of a framework. MLflow <a id="_idIndexMarker472"/>provides an extension system through its plugin features. A plugin architecture allows the extensibility and adaptability of a software system.</p>
			<p>MLflow allows the creation of the following types of plugins:</p>
			<ul>
				<li><strong class="bold">Tracking store plugins</strong>: This type of plugin controls and tweaks the store that you use to log your experiment metrics in a specific type of data store.</li>
				<li><strong class="bold">Artifact repository</strong>: You are able to override the artifact repositories with your own <a id="_idIndexMarker473"/>storage system—for example, adding an artifact repository based on the <strong class="bold">Hadoop Distributed File System</strong> (<strong class="bold">HDFS</strong>) or any object store specific to your environment, overriding API calls such as <strong class="source-inline">log_artifact</strong> and <strong class="source-inline">download_artifacts</strong>.</li>
				<li><strong class="bold">Running context providers</strong>: You can update how your system logs information about the context—for instance, tags such as <strong class="source-inline">git_tags</strong> and <strong class="source-inline">repo_uri</strong>, and other relevant elements of the context of your system.</li>
				<li><strong class="bold">Model Registry store</strong>: This feature allows you to customize where your models <a id="_idIndexMarker474"/>are stored; you can store them—for instance—in a <strong class="bold">Secure File Transfer Protocol</strong> (<strong class="bold">SFTP</strong>) system if this is the only way you might store the models of your production infrastructure. This feature can be advantageous in regulated environments where only a limited set of services and your Model Registry store need to adapt to the situation.</li>
				<li><strong class="bold">MLflow project deployment</strong>: This type of plugin controls and tweaks how you deploy. In a case where your deployment is not for an environment supported by MLflow, you can use this feature to specialize the way you deploy.</li>
				<li><strong class="bold">Request header provider</strong>: Enables you to control and add extra values to outgoing <a id="_idIndexMarker475"/>REST requests from MLflow. One example would be if all <strong class="bold">HyperText Transfer Protocol</strong> (<strong class="bold">HTTP</strong>) requests <a id="_idIndexMarker476"/>needed a header key related to a security token in your network that integrates with the company <strong class="bold">single sign-on</strong> (<strong class="bold">SSO</strong>). </li>
				<li><strong class="bold">Project backend</strong>: This gives extensibility to run MLflow in different execution environments. For instance, Kubernetes is a backend as well as Sagemaker, so the integration of MLflow and the environment where models will be deployed needs specific code for each situation.</li>
			</ul>
			<p>To create a plugin, you will <a id="_idIndexMarker477"/>have to create a Python package that overrides a specific module in MLflow. We will develop step by step an example MLflow plugin from the official documentation. You can follow along with the following repository URL: https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter12/mlflow-psystock-plugin. To run through the process, follow these next steps:</p>
			<ol>
				<li value="1">Define your plugin in the <strong class="source-inline">setup.py</strong> file. The <strong class="source-inline">install_requires=["mlflow"]</strong> line of code bundles MLflow with your package, being sufficient to install your new plugin package, and it will create a changed instance of MLflow. The code is illustrated in the following snippet:<p class="source-code">setup(</p><p class="source-code">    name="mflow-psystock-deployment-plugin",</p><p class="source-code">    # Require MLflow as a dependency of the plugin, so that plugin users can simply install</p><p class="source-code">    # the plugin and then immediately use it with MLflow</p><p class="source-code">    install_requires=["mlflow"],</p><p class="source-code">    entry_points={</p><p class="source-code">        "mlflow.deployments": " psystock target= psystock. deployment_plugin"</p><p class="source-code">    }</p><p class="source-code">)</p></li>
				<li>Create a package namespace empty file in a folder called <strong class="source-inline">mlflow-psystock-deployment/_init_.py</strong> to signal the creation of a package.</li>
				<li>The next step involves overriding the creation of a file with methods that we want in our <a id="_idIndexMarker478"/>plugin to override the default behavior in MLflow.<p>In our specific case, we will be looking at overriding the <strong class="source-inline">BaseDeploymentClient</strong> class in MLflow, which basically means that we need to implement all the methods. We will implement a set of dummy methods to illustrate the process, starting with the <strong class="source-inline">create_deployment</strong> and <strong class="source-inline">update_deployment</strong> methods, as follows:</p><p class="source-code">import os</p><p class="source-code">from mlflow.deployments import BaseDeploymentClient</p><p class="source-code">p_deployment_name = "pystock"</p><p class="source-code">class PluginDeploymentClient(BaseDeploymentClient):</p><p class="source-code">    def create_deployment(self, name, model_uri, flavor=None, config=None):</p><p class="source-code">        if config and config.get("raiseError") == "True":</p><p class="source-code">            raise RuntimeError("Error requested")</p><p class="source-code">        return {"name": f_deployment_name, "flavor": flavor}</p><p class="source-code">    def delete_deployment(self, name):</p><p class="source-code">        return None</p><p class="source-code">    def update_deployment(self, name, model_uri=None, flavor=None, config=None):</p><p class="source-code">        return {"flavor": flavor}</p></li>
				<li>We then <a id="_idIndexMarker479"/>implement the <strong class="source-inline">list_deployments</strong> and  <strong class="source-inline">get_deployments</strong> methods, as follows:<p class="source-code">    def list_deployments(self):</p><p class="source-code">        if os.environ.get("raiseError") == "True":</p><p class="source-code">            raise RuntimeError("Error requested")</p><p class="source-code">        return [f_deployment_name]</p><p class="source-code">    def get_deployment(self, name):</p><p class="source-code">        return {"key1": "val1", "key2": "val2"}</p><p class="source-code">    def predict(self, deployment_name, df):</p><p class="source-code">        return "1"</p><p class="source-code">def run_local(name, model_uri, flavor=None, config=None):</p><p class="source-code">    print(</p><p class="source-code">        "Deployed locally at the key {} using the model from {}. ".format(name, model_uri)</p><p class="source-code">        + "It's flavor is {} and config is {}".format(flavor, config)</p><p class="source-code">    )</p><p>The <strong class="source-inline">run_local(name, model_uri, flavor=None, config=None)</strong> method is the main method that will be executed upon instantiation of this plugin.</p></li>
				<li>You can <a id="_idIndexMarker480"/>now install your plugin on top of <strong class="bold">MLflow</strong> by running the foll<a id="_idTextAnchor182"/>owing command:<p class="source-code">pip install-e .</p></li>
			</ol>
			<p>We conclude the book with this section on extending MLflow with new functionalities, allowing you as an ML engineer to extend MLflow whenever it makes sense. </p>
			<h1 id="_idParaDest-157"><a id="_idTextAnchor183"/>Summary</h1>
			<p>In this chapter, we addressed some use cases, with example MLflow pipelines. We looked at implementing AutoML in two different scenarios. Where we don't have targets, we will need to use anomaly detection as an unsupervised ML technique. The use of non-Python-based platforms was addressed, and we concluded with how to extend MLflow with plugins.</p>
			<p>At this stage, we have addressed a good breadth and depth of topics in the area of ML engineering using MLflow. Your next step is definitely to explore more, and leverage on your project the techniques learned in this book.</p>
			<h1 id="_idParaDest-158"><a id="_idTextAnchor184"/>Further reading</h1>
			<p>In order to further your knowledge, you can consult the documentation at the following links: </p>
			<ul>
				<li><a href="https://pycaret.org/about">https://pycaret.org/about</a></li>
				<li><a href="https://www.mlflow.org/docs/latest/plugins.html">https://www.mlflow.org/docs/latest/plugins.html</a></li>
			</ul>
		</div>
	</body></html>