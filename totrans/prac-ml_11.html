<html><head></head><body><div class="chapter" title="Chapter&#xA0;11.&#xA0;Deep learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch11"/>Chapter 11. Deep learning</h1></div></div></div><p>Until now, we covered a few supervised, semi-supervised, unsupervised, and reinforcement learning techniques and algorithms. In this chapter, we will cover neural networks and its relationship with the deep learning practices. The traditional learning approach was about writing programs that tell the computer what to do, but neural networks are about learning and finding solutions using observational data that forms a primary source of input. This technique's success depends on how the neural networks are trained (that is, the quality of the observational data). Deep learning refers to methods of learning the previously referenced neural networks.</p><p>The advancement in technology has taken these techniques to new heights where these techniques demonstrate superior performance, and are used to solve some key non-trivial requirements in computer vision, speech recognition, and <a id="id1168" class="indexterm"/>
<span class="strong"><strong>Natural Language Processing</strong></span> (<span class="strong"><strong>NLP</strong></span>). Large companies such as Facebook and Google, among many others, have adopted deep learning practices on a substantial basis.</p><p>The primary aim of this chapter is to enforce mastering the neural networks and related deep learning techniques conceptually. With the aid of a complex pattern recognition problem, this chapter covers the procedure to develop a typical neural network, which you will be able to use to solve a problem of a similar complexity. The following representation shows all the learning methods covered in this book, highlighting the primary subject of learning in this chapter—<span class="emphasis"><em>Deep learning</em></span>.</p><div class="mediaobject"><img src="graphics/B03980_11_01.jpg" alt="Deep learning"/></div><p>The chapter covers the following topics in depth:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A quick revisit of the purpose of Machine learning, types of learning, and the context of deep learning with details on a particular problem that it solves.</li><li class="listitem" style="list-style-type: disc">An overview of neural networks:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Human brain as the primary inspiration for neural networks</li><li class="listitem" style="list-style-type: disc">The types of neural network architectures and some basic models of neurons</li><li class="listitem" style="list-style-type: disc">A simple learning example (digit recognition)</li><li class="listitem" style="list-style-type: disc">An overview of perceptrons, the first generation of neural networks and what they are capable of doing and what they are not capable of doing</li></ul></div></li><li class="listitem" style="list-style-type: disc">An overview of linear and logistic output neurons. An introduction to back the propagation algorithm and applying the derivatives of back propagation algorithm for solving some real-world problems</li><li class="listitem" style="list-style-type: disc">The concepts of cognitive science, the softmax output function, and handling multi-output scenarios</li><li class="listitem" style="list-style-type: disc">Applying convolution nets and the problem of object or digit recognition</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Recurrent neural networks</strong></span> (<span class="strong"><strong>RNN</strong></span>) and<a id="id1169" class="indexterm"/> Gradient descent method</li><li class="listitem" style="list-style-type: disc">Signal processing as the principle of component analysis and autoencoders; the types of autoencoders which are deep and shallow autoencoders</li><li class="listitem" style="list-style-type: disc">A hands-on implementation of exercises using Apache Mahout, R, Julia, Python (scikit-learn), and Apache Spark</li></ul></div><div class="section" title="Background"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec52"/>Background</h1></div></div></div><p>Let's first recap the premise of Machine learning and reinforce the purpose and context of learning methods. As we learned, Machine learning is about training machines by building models using observational data, against directly writing specific instructions that define the model for the data to address a particular classification or a prediction problem. The word <span class="emphasis"><em>model</em></span> is nothing but a <span class="emphasis"><em>system</em></span> in this context.</p><p>The program or system is built using data and hence, looks as though it's very different from a hand-written one. If the data changes, the program also adapts to it for the next level of training on the new data. So all it needs is the ability to process large-scale as opposed to getting a skilled programmer to write for all the conditions that could still prove to be heavily erroneous.</p><p>We have an example of a Machine learning system called spam detector. The primary purpose of this system is to identify which mail is spam and which is not. In this case, the spam detector is not coded to handle every type of mail; instead, it learns from the data. Hence, it is always true that the precision of these models depends on how good the observational data is. In other words, the features extracted from the raw data should typically cover all the states of data for the model to be accurate. Feature extractors are built to extract standard features from the given sample of data that the classifier or a predictor uses.</p><p>Some more examples include recognizing patterns such as speech recognition, object recognition, face detection, and more.</p><p>Deep learning is a type of Machine learning that attempts to learn prominent features from the given data, and thus tries to reduce the task of building a feature extractor for every category of data (for example, image, voice, and so on.). For a face detection requirement, a deep learning algorithm records or learns features such as the length of the nose, the distance between the eyes, the color of the eyeballs, and so on. This data is used to address a classification or a prediction problem and is evidently very different from the traditional <a id="id1170" class="indexterm"/>
<span class="strong"><strong>shallow learning algorithm</strong></span>.</p><div class="section" title="The human brain"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec127"/>The human brain</h2></div></div></div><p>The human brain is <a id="id1171" class="indexterm"/>known to be one of the most implausible organs in the human body. The brain is essentially what makes us, humans, intelligent. It is responsible for building our perceptions based on what we experience regarding our senses of touch, smell, sight, vision, and sound. These experiences are collected and stored as memories and emotions. Inherently, the brain is what makes us intelligent without which, we probably are just primitive organisms in the world.</p><p>The brain of a newborn infant is capable of solving problems that any complex and powerful machine cannot solve. In fact, just within a few days of birth, the baby starts recognizing the face and voice of his/her parents and starts showing the expressions of longing to see them when they are not around. Over a period, they begin associating sounds with objects and can even recognize an object given a sight. Now, how do they do this? If they come across a dog, how do they recognize it to be a dog; also, do they associate a barking sound with it and mimic the same sound?</p><p>It is simple. Every time the infant comes across a dog, his/her parents qualify it to be a dog, and this reinforces the child's model. In case they qualify the child to be wrong, the child's model would incorporate this information. So, a dog has long ears, long nose, four legs, a long tail, and can be of different colors such as black, white or brown, making a barking sound. These characteristics are recognized through sight and sound that an infant's brain records. The observational data thus collected drives the recognition of any new object henceforth.</p><p>Now, let's say the infant sees <a id="id1172" class="indexterm"/>a wolf for the first time; he/she would identify a wolf to be a dog by looking at the similarity of its characteristics s. Now, if the parent feeds in the definite differences on the first sighting, for example, a difference in the sound that it makes, then it becomes a new experience and is stored in memory, which is applied to the next sighting. With the assimilation of more and more such examples, the child's model becomes more and more accurate; this process is very subconscious.</p><p>For several years, we have been working toward building machines that can be intelligent with brains as those of humans. We are talking about robots that can behave as humans do and can perform a particular job with similar efficiency to humans beings, such as driving a car, cleaning a house, and so on. Now, what does it take to build machines as robots? We probably need to build some super-complex computational systems that solve the problems our brain can solve in no time. This field that works on building artificially intelligent systems is called deep learning.</p><p>Following are some formal definitions of deep learning:</p><p>According to Wikipedia, Deep learning is a set of algorithms for machine learning that attempts to model high-level abstractions in data by using model architectures composed of multiple non-linear transformations.</p><p>According to <a class="ulink" href="http://deeplearning.net/">http://deeplearning.net/</a>, Deep learning<a id="id1173" class="indexterm"/> is the new area of Machine learning <a id="id1174" class="indexterm"/>research that has been introduced with the objective of moving Machine learning closer to one of its original goals—Artificial Intelligence.</p><p>This subject has evolved over several years; the following table lists research areas across the years:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Research Area</p>
</th><th style="text-align: left" valign="bottom">
<p>Year</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Neural networks</p>
</td><td style="text-align: left" valign="top">
<p>1960</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Multilayer Perceptrons</p>
</td><td style="text-align: left" valign="top">
<p>1985</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Restricted Boltzmann Machine</p>
</td><td style="text-align: left" valign="top">
<p>1986</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Support Vector Machine</p>
</td><td style="text-align: left" valign="top">
<p>1995</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Hinton presents the <a id="id1175" class="indexterm"/>
<span class="strong"><strong>Deep Belief Network</strong></span> (<span class="strong"><strong>DBN</strong></span>)</p>
<p>New interests in deep learning and RBM</p>
<p>State of the art MNIST</p>
</td><td style="text-align: left" valign="top">
<p>2005</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Deep Recurrent Neural Network</p>
</td><td style="text-align: left" valign="top">
<p>2009</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Convolutional DBN</p>
</td><td style="text-align: left" valign="top">
<p>2010</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Max-Pooling CDBN</p>
</td><td style="text-align: left" valign="top">
<p>2011</p>
</td></tr></tbody></table></div><p>Among many others, some <a id="id1176" class="indexterm"/>key contributors to this field are Geoffrey Hinton, Yann LeCun, Honglak Lee, Andrew Y. Ng, and Yoshua Bengio.</p><p>The following concept model<a id="id1177" class="indexterm"/> covers different areas of Deep learning and the scope of topics covered in this chapter:</p><div class="mediaobject"><img src="graphics/B03980_11_02.jpg" alt="The human brain"/></div><p>Let's look at a simple problem on hand; the requirement is to recognize the digits from the handwritten script given here:</p><div class="mediaobject"><img src="graphics/B03980_11_03.jpg" alt="The human brain"/></div><p>For a human brain, this is very simple as we can recognize the digits as 287635. The simplicity with which our brain interprets the digits is perceptive that it undermines the complexity involved in this<a id="id1178" class="indexterm"/> process. Our brain is trained to intercept different visuals progressively due to the presence of visual cortices, with each cortex containing more than 140 million neurons that have billions of connections between them. In short, our brain is no less than a supercomputer that has evolved over several millions of years and is known to adapt well to the visual world.</p><p>If a computer program has to crack the recognition of the digits, what should be the rules to identify and differentiate a digit from another?</p><p>Neural networks are one such field being researched for several years and is known to address the need for multilayered learning. The overall idea is to feed a large number of handwritten digits; an example of this data (training) is shown in the following image, and that can learn from these examples. This means the rules are automatically inferred from the provided training data. So, the larger the training dataset, the more accurate would be the prediction. If we are posed with a problem to differentiate the digit 1 from the digit 7 or the digit 6 from the digit 0, some minor differences will need to be learned. For a zero, the distance between the starting and ending point is minimal or nothing.</p><div class="mediaobject"><img src="graphics/B03980_11_04.jpg" alt="The human brain"/></div><p>The difference is basically because these learning methods have been targeted to mimic a human brain. Let's see what makes this a difficult problem to solve.</p><p>In summary, with <a id="id1179" class="indexterm"/>deep learning being a subset of Machine learning, we know that this involves the technique of feeding examples and a model that can evaluate the pattern to evolve it in case it makes a mistake. Thus, over a period of time, this model would solve the problem with the best possible accuracy.</p><p>If this needs to be represented mathematically, let's define our model to be a function <span class="emphasis"><em>f(x,θ)</em></span>.</p><p>Here, <span class="emphasis"><em>x</em></span> is the input that is provided as a vector of values and <span class="emphasis"><em>θ</em></span> is a reference vector that the model uses to predict or classify <span class="emphasis"><em>x</em></span>. So, it is <span class="emphasis"><em>θ</em></span> that we need to expose to a maximum set of examples in order to improve the accuracy.</p><p>Let's take an example; if we were to predict whether a visitor to a restaurant would come back based on two factors—one is the amount of bill (<span class="emphasis"><em>x<sub>1</sub></em></span>) and the other is his/her age(<span class="emphasis"><em>x<sub>2</sub></em></span>). When we collect data for a specific duration of time and analyze it for an output value that can be 1(in case the visitor came back) or -1(if the visitor has not come back). The data, when plotted, can take any form—from a linear relationship or any other complex form, as shown here:</p><div class="mediaobject"><img src="graphics/B03980_11_05.jpg" alt="The human brain"/></div><p>Something like a linear relationship looks straight forward and more complex relationships complicate the dynamics of the model. Can parameter <span class="emphasis"><em>θ</em></span> have an optimal value at all? We might have to apply optimization techniques and in the next sections to follow, we will cover these techniques such as perceptrons and gradient descent methods among others. If we want to develop a program to do this, we need to know what our brain does to recognize these digits, and even if we knew, these programs might be very complex in nature.</p></div><div class="section" title="Neural networks"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec128"/>Neural networks</h2></div></div></div><p>Neural computations <a id="id1180" class="indexterm"/>have been a primary interest of the study to understand how parallel computations work in neurons (the concept of flexible connections) and solve practical problems like a human brain does. Let's now look at the core fundamental unit of the human brain, the <span class="emphasis"><em>neuron</em></span>:</p><div class="mediaobject"><img src="graphics/B03980_11_06.jpg" alt="Neural networks"/></div><div class="section" title="Neuron"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec105"/>Neuron</h3></div></div></div><p>The human brain<a id="id1181" class="indexterm"/> is all about <a id="id1182" class="indexterm"/>neurons and connections. A neuron is the smallest part of the brain, and if we take a small rice grain sized piece of the brain, it is known to contain at least 10000 neurons. Every neuron on an average has around 6000 connections with other neurons. If we look at the general structure of a neuron, it looks as follows.</p><p>Every feeling that we humans go through, be it thought or emotion, is because of these millions of cells in our brain called neurons. As a result of these neurons communicating with each other by passing messages, humans feel, act, and form perceptions. The diagram here depicts the biological neural structure and its parts:</p><div class="mediaobject"><img src="graphics/B03980_11_07.jpg" alt="Neuron"/></div><p>Every neuron <a id="id1183" class="indexterm"/>has a <a id="id1184" class="indexterm"/>central cell body; as any cell, in general, it has an axon and a dendritic tree that are responsible for sending and receiving messages respectively with other neurons. The place where axons connect to the dendritic tree is called a synapse. The synapses themselves have an interesting structure. They contain transmitter molecules that trigger transmission, which can either be positive or negative in nature.</p><p>The inputs to the neurons are aggregated, and when they exceed the threshold, an electrical spike is transmitted to the next neuron.</p></div><div class="section" title="Synapses"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec106"/>Synapses</h3></div></div></div><p>The following <a id="id1185" class="indexterm"/>diagram depicts the<a id="id1186" class="indexterm"/> model of a synapse depicting the flow of messages from axon to dendrite. The job of the synapse is not just the transmission of messages, but in fact, adapt themselves to the flow of signals and have the ability to learn from past activities.</p><div class="mediaobject"><img src="graphics/B03980_11_08.jpg" alt="Synapses"/></div><p>As an analogy in the<a id="id1187" class="indexterm"/> field of<a id="id1188" class="indexterm"/> Machine learning, the strength of the incoming connection is determined on the basis of how often it is used, and thus its impact on the neuron output is determined. This is how new concepts are learned by humans subconsciously.</p><p>There can additionally be external factors such as medication or body chemistry that might impact this learning process.</p><p>Now we will finally summarize how the learning happens inside the brain with the help of the following list:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Neurons communicate with other neurons or sometimes receptors. The cortical neurons use spikes for communication.</li><li class="listitem" style="list-style-type: disc">The strengths of connections between neurons can change. They can take positive or negative values by either establishing and removing connections between neurons or by strengthening the connection based on the influence that a neuron can have over the other. A process<a id="id1189" class="indexterm"/> called <span class="strong"><strong>long-term potentiation</strong></span> (<span class="strong"><strong>LTP</strong></span>) occurs that results in this long-term impact.</li><li class="listitem" style="list-style-type: disc">There are about 1011 neurons having weights that make the computations that the human brain can do more efficiently than a workstation.</li><li class="listitem" style="list-style-type: disc">Finally, the brain is modular; different parts of the cortex are responsible for doing different things. Some tasks infuse more blood flow in some regions over the other and thus, ensuring different results.</li></ul></div><p>Before schematizing the <a id="id1190" class="indexterm"/>neuron model into the <span class="strong"><strong>artificial neural network</strong></span> (<span class="strong"><strong>ANN</strong></span>), let us<a id="id1191" class="indexterm"/> first look at different types, categories, or aspects of neurons, and in <a id="id1192" class="indexterm"/>specific the Artificial neuron or Perceptron, the deep learning equivalent of a biological neuron. This approach is known to have produced extremely efficient results in some of the use cases we listed in the previous section. ANNs are also called feed-forward neural networks, <span class="strong"><strong>Multi-Layer Perceptrons</strong></span> (<span class="strong"><strong>MLP</strong></span>), and<a id="id1193" class="indexterm"/>, recently, deep networks or learning. One of the important characteristics has been the need for feature engineering, whereas deep learning represents applications that require minimum feature engineering, where learning happens through multiple learned layers of neurons.</p></div><div class="section" title="Artificial neurons or perceptrons"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec107"/>Artificial neurons or perceptrons</h3></div></div></div><p>It is obvious that<a id="id1194" class="indexterm"/> artificial neurons draw inspiration from biological neurons, as represented previously. The features of an artificial neuron are listed here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">There is a set of inputs received from other neurons that activate the neuron in context</li><li class="listitem" style="list-style-type: disc">There is an output transmitter that transfers signals or an activation of the other neurons</li><li class="listitem" style="list-style-type: disc">Finally, the core processing unit is responsible for producing output activations from the input activations</li></ul></div><p>Idealizing for a neuron is a<a id="id1195" class="indexterm"/> process that is applied to building models. In short, it is a simplification process. Once simplified, it is possible to apply mathematics and relate analogies. To this case, we can easily add complexities and make the model robust under identified conditions. Necessary care needs to be taken in ensuring that none of the significantly contributing aspects are removed as a part of the simplification process.</p><div class="section" title="Linear neurons"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec36"/>Linear neurons</h4></div></div></div><p>Linear neurons are the <a id="id1196" class="indexterm"/>simplest form <a id="id1197" class="indexterm"/>of neurons; they can be represented as follows:</p><div class="mediaobject"><img src="graphics/B03980_11_10.jpg" alt="Linear neurons"/></div><p>The output <span class="emphasis"><em>y</em></span> is a summation of the product of the input <span class="emphasis"><em>x<sub>i</sub></em></span> and its weight <span class="emphasis"><em>w<sub>i</sub></em></span>. This is mathematically represented as shown here:</p><div class="mediaobject"><img src="graphics/B03980_11_41.jpg" alt="Linear neurons"/></div><p>Here, <span class="emphasis"><em>b</em></span> is the bias.</p><p>A graph representation of the previous equation is given as follows:</p><div class="mediaobject"><img src="graphics/B03980_11_11.jpg" alt="Linear neurons"/></div></div><div class="section" title="Rectified linear neurons / linear threshold neurons"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec37"/>Rectified linear neurons / linear threshold neurons</h4></div></div></div><p>Rectified linear neurons<a id="id1198" class="indexterm"/> are similar to linear neurons, as explained in the preceding section, with<a id="id1199" class="indexterm"/> a minor difference where the output parameter<a id="id1200" class="indexterm"/> value is set to zero in cases where it is<a id="id1201" class="indexterm"/> less than (&lt;) zero (0), and in case the output value is greater than (&gt;) zero (0), it continues to remain as the linear weighted sum of the inputs:</p><div class="mediaobject"><img src="graphics/B03980_11_12.jpg" alt="Rectified linear neurons / linear threshold neurons"/></div></div><div class="section" title="Binary threshold neurons"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec38"/>Binary threshold neurons</h4></div></div></div><p>The binary threshold<a id="id1202" class="indexterm"/> neurons were introduced by McCulloch and Pitts in 1943. This<a id="id1203" class="indexterm"/> class of neurons first have the weighted sum of the inputs computed, similar to the linear neurons. If this value exceeds a defined threshold, a fixed size spike to activity is sent out. This spike is called as the <span class="emphasis"><em>truth value of a proposition</em></span>. Another important point is the output. The output at any given point in time is binary (0 or 1).</p><p>The equation that demonstrates this behavior is given here:</p><div class="mediaobject"><img src="graphics/B03980_11_42.jpg" alt="Binary threshold neurons"/></div><p>And</p><p>
<span class="emphasis"><em>y = 1</em></span> if <span class="emphasis"><em>z ≥ θ</em></span>,</p><p>
<span class="emphasis"><em>y = 0</em></span> otherwise</p><p>here <span class="emphasis"><em>θ = -b (bias)</em></span>
</p><p>(OR)</p><div class="mediaobject"><img src="graphics/B03980_11_43.jpg" alt="Binary threshold neurons"/></div><p>And</p><p>
<span class="emphasis"><em>y = 1</em></span> if <span class="emphasis"><em>z ≥ 0</em></span>,</p><p>
<span class="emphasis"><em>y = 0</em></span> otherwise</p><p>Moreover, a graphical representation of the previous equation is given here:</p><div class="mediaobject"><img src="graphics/B03980_11_13.jpg" alt="Binary threshold neurons"/></div></div><div class="section" title="Sigmoid neurons"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec39"/>Sigmoid neurons</h4></div></div></div><p>Sigmoid neurons<a id="id1204" class="indexterm"/> are highly adopted in artificial neural networks. These neurons are<a id="id1205" class="indexterm"/> known to provide the output that is smooth, real-valued, and therefore a bounded function of all the inputs. Unlike the types of the neurons that we have seen until now, these neurons use the logistic function.</p><p>The logistic function is known to have an easy-to-calculate derivative that makes learning easy. This derivative value is used in computing the weights. Following is the equation for the sigmoid neuron output:</p><div class="mediaobject"><img src="graphics/B03980_11_44.jpg" alt="Sigmoid neurons"/></div><div class="mediaobject"><img src="graphics/B03980_11_45.jpg" alt="Sigmoid neurons"/></div><p>The<a id="id1206" class="indexterm"/> diagrammatic/graphical<a id="id1207" class="indexterm"/> representation is as follows:</p><div class="mediaobject"><img src="graphics/B03980_11_14.jpg" alt="Sigmoid neurons"/></div></div><div class="section" title="Stochastic binary neurons"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec40"/>Stochastic binary neurons</h4></div></div></div><p>Stochastic binary <a id="id1208" class="indexterm"/>neurons use the same equation as logistic units, with one<a id="id1209" class="indexterm"/> important difference that the output is measured for a probabilistic value, which measures the probability of producing a spike in a short window of time. So, the equation looks like this:</p><div class="mediaobject"><img src="graphics/B03980_11_46.jpg" alt="Stochastic binary neurons"/></div><div class="mediaobject"><img src="graphics/B03980_11_47.jpg" alt="Stochastic binary neurons"/></div><p>Moreover, the graphical <a id="id1210" class="indexterm"/>representation of this equation is:</p><div class="mediaobject"><img src="graphics/B03980_11_15.jpg" alt="Stochastic binary neurons"/></div><p>Overall, what we can<a id="id1211" class="indexterm"/> observe is that each neuron takes in a weighted sum of a bunch of inputs on which a non-linear activation function is applied. Rectified linear function is typically applied for solving regression problems and for classification problems, logistic functions are applied. A generic representation of this can be given as follows:</p><div class="mediaobject"><img src="graphics/B03980_11_16.jpg" alt="Stochastic binary neurons"/></div><p>Now, these inputs can be <a id="id1212" class="indexterm"/>fed into a series of layers of neurons. Let's look at <a id="id1213" class="indexterm"/>what happens next and how this happens. The input layer pushes input values; the hidden layers of neurons then take the values as input. It is possible to have multiple layers within these hidden layers, where the output from one layer feeds as the input to the subsequent layer. Each of these layers can be responsible for the specialized learning. Moreover, finally, the last in the hidden layer feeds into the final output layer. This typical structure of an ANN is illustrated next. Every circle in the next diagram represents a neuron. The concept of the <span class="strong"><strong>Credit Assignment Path</strong></span> (<span class="strong"><strong>CAP</strong></span>)<a id="id1214" class="indexterm"/> refers to the path from input to output. In the feed-forward networks, the length of the path is the total number of hidden layers along with the output layer. The following diagram shows a feed-forward neural network with a single hidden layer and connections between layers:</p><div class="mediaobject"><img src="graphics/B03980_11_17.jpg" alt="Stochastic binary neurons"/></div><p>The case of two<a id="id1215" class="indexterm"/> hidden <a id="id1216" class="indexterm"/>layers are shown in here:</p><div class="mediaobject"><img src="graphics/B03980_11_18.jpg" alt="Stochastic binary neurons"/></div></div></div><div class="section" title="Neural Network size"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec108"/>Neural Network size</h3></div></div></div><p>Computing the number of <a id="id1217" class="indexterm"/>neurons or parameters is shown here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">For the single layer network:<p>Total number of neurons = 4 + 2 = 6 (inputs are not counted)</p><p>Total weights = [3 x 4] + [4 x 2] = 20</p><p>Total bias = 4 + 2 = 6, for 26 learnable parameters.</p></li><li class="listitem" style="list-style-type: disc">For the two layer network:<p>Total number of neurons = 4 + 4 + 1 = 9 (inputs are not counted)</p><p>Total weights = [3 x 4] + [4 x 4] + [4 x 1] = 12 + 16 + 4 = 32</p><p>Total bias = 4 + 4 + 1 = 9 for 41 learnable parameters</p></li></ul></div><p>So, what is the optimal size of neural networks? It is important to identify the possible number of hidden layers along with the size of each layer. These decisions determine the capacity of the network. A higher value helps to support a higher capacity.</p><p>Let's take an example where we will try three different sizes of the hidden layer by obtaining the following classifiers:</p><div class="mediaobject"><img src="graphics/B03980_11_19.jpg" alt="Neural Network size"/></div><p>Clearly, with more neurons, functions with higher complexity can be expressed, which is good, but we need to watch out for the over-fitting case. So, a smaller-sized network works well for simpler data. With the increasing data complexity, the need for a bigger size arises. The trade-off is always between handling the complexity of the model versus. over-fitting. Deep learning addresses this problem as it applies complex models to extremely complex <a id="id1218" class="indexterm"/>problems and handles over-fitting by taking additional measures.</p><div class="section" title="An example"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl5sec13"/>An example</h4></div></div></div><p>A face<a id="id1219" class="indexterm"/> recognition case using the multi-layered perceptron approach is shown next:</p><div class="mediaobject"><img src="graphics/B03980_11_20.jpg" alt="An example"/></div><p>Multiple layers take this image as input and finally, a classifier definition is created and stored.</p><div class="mediaobject"><img src="graphics/B03980_11_21.jpg" alt="An example"/></div><p>Given a photograph, each layer focuses on learning a specific part of the photograph and finally stores the output pixels.</p><p>Some key notes on the weights and error measures are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The training data is the source of learning the weights of neurons</li><li class="listitem" style="list-style-type: disc">The error measure or the cost function is different from the regression and classification problems. For classification, log functions are applied, and for regression, least square measures are used.</li><li class="listitem" style="list-style-type: disc">These methods <a id="id1220" class="indexterm"/>help to keep these error measures in check by updating the weights using convex optimization techniques such as decent gradient methods</li></ul></div></div></div><div class="section" title="Neural network types"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec109"/>Neural network types</h3></div></div></div><p>In this section, we will cover <a id="id1221" class="indexterm"/>some key types of neural networks. The following concept map lists a few principal types of neural networks:</p><div class="mediaobject"><img src="graphics/B03980_11_22.jpg" alt="Neural network types"/></div><div class="section" title="Multilayer fully connected feedforward networks or Multilayer Perceptrons (MLP)"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec42"/>Multilayer fully connected feedforward networks or Multilayer Perceptrons (MLP)</h4></div></div></div><p>As <a id="id1222" class="indexterm"/>covered in the <a id="id1223" class="indexterm"/>introductory sections about neural<a id="id1224" class="indexterm"/> networks, an MLP has multiple layers where the<a id="id1225" class="indexterm"/> output of one layer feeds as an input to a subsequent layer. A multilayer perceptron is represented as shown in the following diagram:</p><div class="mediaobject"><img src="graphics/B03980_11_23.jpg" alt="Multilayer fully connected feedforward networks or Multilayer Perceptrons (MLP)"/></div></div><div class="section" title="Jordan networks"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec43"/>Jordan networks</h4></div></div></div><p>Jordan networks <a id="id1226" class="indexterm"/>are partially recurrent networks. These networks are the<a id="id1227" class="indexterm"/> current feedforward networks with a difference of having additional context neurons inside the input layer. These context neurons are self-imposed and created using the direct feedback from input neurons. In Jordon networks, the number of context neurons is always equal to the input neurons. The following diagram depicts the difference in the input layer:</p><div class="mediaobject"><img src="graphics/B03980_11_48.jpg" alt="Jordan networks"/></div></div><div class="section" title="Elman networks"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec44"/>Elman networks</h4></div></div></div><p>Elman networks, just<a id="id1228" class="indexterm"/> as Jordon networks, are partially recurrent feedforward networks. These <a id="id1229" class="indexterm"/>networks also have context neurons, but in this case, the main difference is that the context neurons receive the feed from the output neurons, and not from the hidden layers. There is no direct correlation between the number of context neurons and input neurons; rather, the number of context neurons is the same as the number of hidden neurons. This, in turn, makes this model more flexible, just as the number of hidden neurons do on a case-by-case basis:</p><div class="mediaobject"><img src="graphics/B03980_11_49.jpg" alt="Elman networks"/></div></div><div class="section" title="Radial Bias Function (RBF) networks"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec45"/>Radial Bias Function (RBF) networks</h4></div></div></div><p>Radial Bias Function networks<a id="id1230" class="indexterm"/> are also feed-forward<a id="id1231" class="indexterm"/> neural networks. These networks have a special hidden layer of special neurons called radially symmetric neurons. These neurons are for converting the distance value between the input vector and the center using a Gaussian measure. The advantage of this additional layer is that it gives an additional capability to determine the number of layers required without a manual intervention. The choice of the linear function determines the optimal output layer. Therefore, the learning happens relatively faster in these networks even in comparison to back propagation.</p><p>The only downside of this method is its ability to handle large input vectors. The diagram below depicts the hidden layer of radially symmetric neurons.</p><div class="mediaobject"><img src="graphics/B03980_11_50.jpg" alt="Radial Bias Function (RBF) networks"/></div></div><div class="section" title="Hopfield networks"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec46"/>Hopfield networks</h4></div></div></div><p>Hopfield networks <a id="id1232" class="indexterm"/>work around a concept called <span class="emphasis"><em>energy of network</em></span>. This is <a id="id1233" class="indexterm"/>nothing but an optimal local minima of the network that defines an equilibrium state for the functionality. Hopfield networks target the state of achieving this equilibrium state. An equilibrium state is when the output of one layer becomes equal to the output of the previous layer. The following diagram depicts how the input and output states are checked and managed in the Hopfield network:</p><div class="mediaobject"><img src="graphics/B03980_11_51.jpg" alt="Hopfield networks"/></div></div><div class="section" title="Dynamic Learning Vector Quantization (DLVQ) networks"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec47"/>Dynamic Learning Vector Quantization (DLVQ) networks</h4></div></div></div><p>The <span class="strong"><strong>Dynamic Learning Vector Quantization</strong></span> (<span class="strong"><strong>DLVQ</strong></span>) network model is another variation of<a id="id1234" class="indexterm"/> neural networks that<a id="id1235" class="indexterm"/> starts with a smaller number hidden layers and dynamically generates these hidden layers. It is important to have similarities in patterns that belong to the same class; hence, this algorithm best suits classification problems, such as recognition of patterns, digits, and so on.</p></div><div class="section" title="Gradient descent method"><div class="titlepage"><div><div><h4 class="title"><a id="ch11lvl4sec48"/>Gradient descent method</h4></div></div></div><p>In this section, we will look at <a id="id1236" class="indexterm"/>one of the most popular ways of optimizing the <a id="id1237" class="indexterm"/>neural network, minimizing the cost function, minimizing errors, and improving the accuracy of the neural network: the Gradient descent method. The graph here shows the actual versus. The predicted value along with the<a id="id1238" class="indexterm"/> cases of inaccuracy in the <a id="id1239" class="indexterm"/>predictions:</p><div class="mediaobject"><img src="graphics/B03980_11_52.jpg" alt="Gradient descent method"/></div></div></div></div><div class="section" title="Backpropagation algorithm"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec129"/>Backpropagation algorithm</h2></div></div></div><p>Taking forward the <a id="id1240" class="indexterm"/>topic of training the networks, the Gradient descent algorithm helps neural networks to learn the weights and biases. Moreover, to compute the gradient of the cost function, we use an algorithm called backpropagation. Backpropagation was first discussed in the 1970s and became more prominent regarding its application only in the 1980s. It was proven that neural network learning was much faster when backpropagation algorithm was employed.</p><p>In the earlier sections of this chapter, we saw how a matrix-based algorithm works; a similar notation is used for the backpropagations algorithm. For a given weight <span class="emphasis"><em>w</em></span> and bias <span class="emphasis"><em>b</em></span>, the cost function C has two partial derivatives which are <span class="emphasis"><em>∂C/∂w</em></span> and <span class="emphasis"><em>∂C/∂b</em></span>.</p><p>Some key assumptions regarding the cost function for backpropagation are stated here. Let's assume that the cost function is defined by the equation here:</p><div class="mediaobject"><img src="graphics/B03980_11_53.jpg" alt="Backpropagation algorithm"/></div><p>Where, <span class="emphasis"><em>n</em></span> = number of training examples</p><p>
<span class="emphasis"><em>x</em></span> = sum across the individual training sets</p><p>
<span class="emphasis"><em>y</em></span> = <span class="emphasis"><em>y(x)</em></span> is the expected output</p><p>
<span class="emphasis"><em>L</em></span> = total number of layers in the neural network</p><p>
<span class="emphasis"><em>a<sup>L</sup></em></span> = <span class="emphasis"><em>a<sup>L</sup>(x)</em></span> is the output activation vector</p><p>Assumption 1: The overall cost function can be an average of the individual cost functions. For <span class="emphasis"><em>x</em></span> individual<a id="id1241" class="indexterm"/> training sets, the cost function can now be stated as follows:</p><div class="mediaobject"><img src="graphics/B03980_11_54.jpg" alt="Backpropagation algorithm"/></div><p>Moreover, the cost function for an individual training set can be as follows:</p><div class="mediaobject"><img src="graphics/B03980_11_55.jpg" alt="Backpropagation algorithm"/></div><p>With this assumption, since we can compute the partial derivatives for each training set <span class="emphasis"><em>x</em></span> as ∂<sub>x</sub>C/∂w and ∂<sub>x</sub>C/∂b, the overall partial derivative functions ∂C/∂w and ∂C/∂b can be an average of the partial derivatives for each training set.</p><p>Assumption 2: This hypothesis is about the cost function <span class="emphasis"><em>C</em></span> that <span class="emphasis"><em>C</em></span> can be the function of outputs from the neural networks as shown here:</p><div class="mediaobject"><img src="graphics/B03980_11_56.jpg" alt="Backpropagation algorithm"/></div><p>Extending the previous <a id="id1242" class="indexterm"/>equation of the cost function, the quadratic cost function for each training example set <span class="emphasis"><em>x</em></span> can now be written as follows. We can see how this acts as a function of the output activations as well.</p><div class="mediaobject"><img src="graphics/B03980_11_57.jpg" alt="Backpropagation algorithm"/></div><p>Back propagation is about the impact the weights and bias have on the overall cost function value.</p><p>First, we compute the error in the <span class="emphasis"><em>j<sup>th</sup></em></span> neuron in the <span class="emphasis"><em>l<sup>th</sup></em></span> layer, <span class="emphasis"><em>δ<sup>l</sup><sub>j</sub></em></span>, and then use this value to calculate the partial derivatives that relate to this error <span class="emphasis"><em>δ<sup>l</sup><sub>j</sub></em></span>:</p><div class="mediaobject"><img src="graphics/B03980_11_58.jpg" alt="Backpropagation algorithm"/></div><p>The error function <span class="emphasis"><em>δ<sup>l</sup><sub>j</sub></em></span> of the <span class="emphasis"><em>j<sup>th</sup></em></span> neuron in the <span class="emphasis"><em>l<sup>th</sup></em></span> layer can be defined as:</p><div class="mediaobject"><img src="graphics/B03980_11_59.jpg" alt="Backpropagation algorithm"/></div><p>Thus, the error for the layer <span class="emphasis"><em>L</em></span> <span class="emphasis"><em>δ<sup>L</sup></em></span> can be computed as well. This, in turn, helps to compute the gradient of the cost function.</p><p>The following equations <a id="id1243" class="indexterm"/>are used by the back propagation algorithm in sequence, as shown here:</p><p>Equation 1: The computing error in the layer <span class="emphasis"><em>L</em></span>, <span class="emphasis"><em>δ<sup>L</sup></em></span>, given the neuron at the position <span class="emphasis"><em>j</em></span>.</p><div class="mediaobject"><img src="graphics/B03980_11_60.jpg" alt="Backpropagation algorithm"/></div><p>Equation 2: The computing error in the layer <span class="emphasis"><em>L</em></span>, <span class="emphasis"><em>δ<sup>L</sup></em></span>, given the error in the next layer <span class="emphasis"><em>δ<sup>L+1</sup></em></span>.</p><div class="mediaobject"><img src="graphics/B03980_11_61.jpg" alt="Backpropagation algorithm"/></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note10"/>Note</h3><p>The Hadamard product is a matrix multiplication technique that is used for element-wise matrix multiplication as shown here:</p><div class="mediaobject"><img src="graphics/B03980_11_62.jpg" alt="Backpropagation algorithm"/></div></div></div><p>The notation <span class="inlinemediaobject"><img src="graphics/B03980_11_70.jpg" alt="Backpropagation algorithm"/></span> is used to<a id="id1244" class="indexterm"/> represent this method.</p><p>Equation 3: This equation measures the impact on the cost and gives a change in the bias:</p><div class="mediaobject"><img src="graphics/B03980_11_34.jpg" alt="Backpropagation algorithm"/></div><p>Moreover, we will get the following from equations 1 and 2:</p><div class="mediaobject"><img src="graphics/B03980_11_35.jpg" alt="Backpropagation algorithm"/></div><p>This is because the error value is the same as the rate of change of the partial derivative.</p><p>Equation 4: This equation<a id="id1245" class="indexterm"/> is used to compute the rate of change of the cost as a relationship to the weight.</p><div class="mediaobject"><img src="graphics/B03980_11_36.jpg" alt="Backpropagation algorithm"/></div><p>At every stage of these algorithms, there is some kind of learning that impacts the overall output from the network.</p><p>The final backpropagation algorithm as compiled is explained here:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The input layer <span class="emphasis"><em>x</em></span>, and for <span class="emphasis"><em>x =1</em></span> Set the activation as <span class="emphasis"><em>a<sup>1</sup></em></span>.</li><li class="listitem">For each of the other layers <span class="emphasis"><em>L = 2, 3, 4 …. L</em></span>, compute the activations as:<div class="mediaobject"><img src="graphics/B03980_11_37.jpg" alt="Backpropagation algorithm"/></div></li><li class="listitem">Compute the error <span class="emphasis"><em>δ<sup>L</sup></em></span> using equations 1 and 2.</li><li class="listitem">Backpropagate the error for <span class="emphasis"><em>l = L-1, L-2, … 2</em></span>, 1 using the equation 3.</li><li class="listitem">Finally, compute the gradient of the cost function using equation 4.</li></ol></div><p>If we observe the algorithm, the error vectors <span class="emphasis"><em>δ<sup>l</sup></em></span> are calculated backwards, starting from the output layer. This is the fact that the cost is a function of outputs from the network. To understand the impact of earlier weights on the cost, a chain rule needs to be applied that works backwards through all the layers.</p></div><div class="section" title="Softmax regression technique"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec130"/>Softmax regression technique</h2></div></div></div><p>Softmax regression <a id="id1246" class="indexterm"/>is also known as multinomial logistic regression. This section does not cover the concept of logistic regression in depth as it is covered in the chapter related to a regression in this book. Instead, we will specifically look at understanding how this technique is employed in digit recognition-related problems in deep learning use cases.</p><p>This technique is a special case of the logistic regression that works for multiple classes. As we learned, the result of logistic regression is a binary value <span class="emphasis"><em>{0,1}</em></span>. Softmax regression facilitates handling <span class="emphasis"><em>y(i)&lt;--{1,…,n}</em></span>, where <span class="emphasis"><em>n</em></span> is the number of classes against the binary classification. In the MNIST digit recognition case, the value <span class="emphasis"><em>n</em></span> is 10, representing 10 different classes. For example, in the MNIST digit recognition task, we would have <span class="emphasis"><em>K=10</em></span> different classes.</p><p>As a result of its ability to process multiple classes, this technique is used actively in neural network-based, problem-solving areas.</p></div></div></div>
<div class="section" title="Deep learning taxonomy"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec53"/>Deep learning taxonomy</h1></div></div></div><p>The feature learning taxonomy for deep<a id="id1247" class="indexterm"/> learning cases is depicted here:</p><div class="mediaobject"><img src="graphics/B03980_11_63.jpg" alt="Deep learning taxonomy"/></div><p>Some of the <a id="id1248" class="indexterm"/>frameworks that are used to implement neural network applications are listed here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Theano is a Python library</li><li class="listitem" style="list-style-type: disc">Torch a Lua programming language</li><li class="listitem" style="list-style-type: disc">Deeplearning4J is an open, source Java-based framework that works with Spark and Hadoop</li><li class="listitem" style="list-style-type: disc">Caffe is a C++ based framework</li></ul></div><div class="section" title="Convolutional neural networks (CNN/ConvNets)"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec131"/>Convolutional neural networks (CNN/ConvNets)</h2></div></div></div><p>CNN, also known as<a id="id1249" class="indexterm"/> convolution nets (ConvNets), are<a id="id1250" class="indexterm"/> a variation of the regular neural networks.</p><p>Let us recap the function of the regular neural network. Regular neural networks have a single vector-based input that is transformed through a series of hidden layers where the neurons in each layer are connected with the neurons in its neighboring layers. The last layer in this series provides the output. This layer is called the output layer.</p><p>When the input to the neural network is an image and does not just fit into a single vector structure, the complexity grows. CNN have this slight variation where the input is assumed as a three-dimensional vector having depth (D), height (H) and width (W). This assumption changes the way the neural network is organized and the way it functions. The following diagram compares the standard three layers neural network with the CNN.</p><div class="mediaobject"><img src="graphics/B03980_11_38.jpg" alt="Convolutional neural networks (CNN/ConvNets)"/></div><p>As we see, the convolutional net shown previously arranges neurons in a three-dimensional way; every layer in the network transforms this into a 3D output of neuron activations.</p><p>Convolution network architecture comprises a fixed set of layers designated for specialized functions. The most critical layers are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Convolutional layer</strong></span> (<span class="strong"><strong>CONV</strong></span>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Pooling layer</strong></span> (<span class="strong"><strong>POOL</strong></span>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Full-connected </strong></span>(<span class="strong"><strong>FC</strong></span>) layer</li></ul></div><p>In some cases, the activation function is written as another layer (RELU); a distinct normalization layer for FC layer conversion may exist.</p><div class="section" title="Convolutional layer (CONV)"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec110"/>Convolutional layer (CONV)</h3></div></div></div><p>The convolutional <a id="id1251" class="indexterm"/>layer forms the core of convolution nets. This layer is responsible for holding the neurons in a three-dimensional format and is therefore responsible for a three-dimensional output. The following is an example of an input volume with the dimensions 32 x 32 x 3. As shown, each neuron is connected to a particular input region. Along the depth, there can be many neurons; we can see five neurons in the example.</p><div class="mediaobject"><img src="graphics/B03980_11_39.jpg" alt="Convolutional layer (CONV)"/></div><p>The diagram here shows how the net convolution function works in the neuron function representation:</p><div class="mediaobject"><img src="graphics/B03980_11_40.jpg" alt="Convolutional layer (CONV)"/></div><p>That said, the core function <a id="id1252" class="indexterm"/>of the neuron remains unchanged and is responsible for computing the product of weights and the inputs followed by an observation of non-linear behavior. The only difference is the restrictions on the connectivity to the local regions.</p></div><div class="section" title="Pooling layer (POOL)"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec111"/>Pooling layer (POOL)</h3></div></div></div><p>There can be <a id="id1253" class="indexterm"/>multiple convolution layers and, between these convolution layers, there can be a pooling layer. The pooling layer is responsible for reducing the chances of over-fitting by reducing the spatial size of the input volume. The reduction of the spatial size implies reducing the number of parameters or the amount of computations in the network. The MAX functions contribute to reducing the spatial size. The pooling layers use the MAX functions and apply it on every slice in the three-dimensional representation, sliced depth-wise. Usually, the pooling layers apply filters of size 2 X 2 applied along both width and height. This can discard around 75% of the activations.</p><p>Overall, the pooling layer has the following characteristics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Always considers a volume size of W1×H1×D1 as an input</li><li class="listitem" style="list-style-type: disc">Applies stride S and spatial extent F and generates the W2×H2×D2 output where:<p>W2=(W1−F)/S+1</p><p>H2=(H1−F)/S+1</p><p>D2=D1</p></li></ul></div></div><div class="section" title="Fully connected layer (FC)"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec112"/>Fully connected layer (FC)</h3></div></div></div><p>The fully<a id="id1254" class="indexterm"/> connected layer is very similar to the regular or traditional neural networks, responsible for establishing extensive connections to the previous layer activations. The connection activations are computed using matrix multiplication techniques. More details on this can be found upon referring to the earlier sections of this chapter.</p></div></div><div class="section" title="Recurrent Neural Networks (RNNs)"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec132"/>Recurrent Neural Networks (RNNs)</h2></div></div></div><p>RNNs are a special <a id="id1255" class="indexterm"/>case of neural networks that are known to be very <a id="id1256" class="indexterm"/>efficient in remembering information, because the hidden state is stored in a distributed manner, and so it can hold more information about the experiences. These networks also apply non-linear functions to update the hidden state. The following diagram depicts how the hidden states link in RNNs:</p><div class="mediaobject"><img src="graphics/B03980_11_64.jpg" alt="Recurrent Neural Networks (RNNs)"/></div><p>In most of the real world <a id="id1257" class="indexterm"/>examples, the inputs and outputs are not<a id="id1258" class="indexterm"/> independent of each other. For example, if we had to predict the next word, it would be important for us to know the words that came before it. As the word suggests, "Recurrent" Neural Networks execute the same task over and over again, where the input of one execution is the output of the previous execution. Usually, RNNs are known to go back only a few steps in the past and not always through all the iterations. The following diagram depicts how RNNs work; it shows how RNNs unfold across iterations:</p><div class="mediaobject"><img src="graphics/B03980_11_65.jpg" alt="Recurrent Neural Networks (RNNs)"/></div><p>In the previous<a id="id1259" class="indexterm"/> example, the requirement was to predict the next <a id="id1260" class="indexterm"/>word, and if there were five words in the input, then RNN unfolds upto five layers.</p></div><div class="section" title="Restricted Boltzmann Machines (RBMs)"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec133"/>Restricted Boltzmann Machines (RBMs)</h2></div></div></div><p>RBMs came into existence to solve the <a id="id1261" class="indexterm"/>difficulty in training RNNs. The rise of <a id="id1262" class="indexterm"/>restricted recurrent models to handle these training difficulties simplified the problem context, and additionally, learning algorithms are applied to solve the problem. The Hopfield Neural Network is an example of a restricted model that addresses the previously described problem.</p><p>As a first step, Boltzmann machines came into existence. These models were a special case of Hopfield Neural Networks with a stochastic element. In this case, the neurons were of two categories: the ones that resulted in visible states and the others in hidden states. This was also similar to the Hidden Markov's model. A RBM is again a special case of Boltzmann machine, where the difference is primarily to do with the absence of connections between the neurons in the same layer. So, for the given states of the neurons of one group, the states of the neurons in the other group are independent. The following diagram depicts a typical RBN structure and the previous definition:</p><div class="mediaobject"><img src="graphics/B03980_11_66.jpg" alt="Restricted Boltzmann Machines (RBMs)"/></div><p>Taking this <a id="id1263" class="indexterm"/>definition further for a deeper interpretation, some <a id="id1264" class="indexterm"/>visible states of neurons are observable, and there are hidden states of neurons that are not visible or cannot directly be seen. There are a few probabilistic conclusions made on the hidden states based on the available visible states, and this is how the training model is formed.</p><p>In an RBM, the connectivity is restricted, and this, in turn, eases the inferencing and learning. It typically takes only one step to reach an equilibrium state with the visible states clamped. The following formula shows how the probability of the hidden state is computed, given that the information about the visible states is provided:</p><div class="mediaobject"><img src="graphics/B03980_11_67.jpg" alt="Restricted Boltzmann Machines (RBMs)"/></div></div><div class="section" title="Deep Boltzmann Machines (DBMs)"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec134"/>Deep Boltzmann Machines (DBMs)</h2></div></div></div><p>DBMs are a special case of<a id="id1265" class="indexterm"/> conventional Boltzmann machines with a lot of <a id="id1266" class="indexterm"/>missing connections, and, unlike the sequential stochastic updates, parallel updates are allowed for ensuring efficiency in the model.</p><p>DBMs restrict the connections between hidden variables and primarily use unlabeled data for training the models. Labeled data is used for fine-tuning the model. The following diagram depicts the general structure of a three-layered DBM:</p><div class="mediaobject"><img src="graphics/B03980_11_68.jpg" alt="Deep Boltzmann Machines (DBMs)"/></div></div><div class="section" title="Autoencoders"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec135"/>Autoencoders</h2></div></div></div><p>Before we understand <a id="id1267" class="indexterm"/>autoencoders, let's first learn about <a id="id1268" class="indexterm"/>
<span class="strong"><strong>autoassociators</strong></span> (<span class="strong"><strong>AAs</strong></span>). The goal of AAs is to receive an input to the maximum possible precision.</p><p>The purpose of an AA is to <a id="id1269" class="indexterm"/>receive the output as an image of the input as precisely as possible. There are two categories of AAs: one is generating AAs, and the second is synthesizing AAs. RBMs covered in the previous section are categorized as generating AAs, and autoencoders synthesize AAs.</p><p>An autoencoder is a type of neural network that has a single open layer. Applying backpropagation and unsupervised learning techniques, autoencoders start with an assumption that the target value is equal to the input value, <span class="emphasis"><em>y = x</em></span>. The following diagram depicts an autoencoder that learns the function <span class="emphasis"><em>h<sub>W,b</sub> (x) ≈ x</em></span>:</p><div class="mediaobject"><img src="graphics/B03980_11_69.jpg" alt="Autoencoders"/></div><p>The layer in the <a id="id1270" class="indexterm"/>middle is open, and as depicted in the previous <a id="id1271" class="indexterm"/>diagram, for optimal output, it is essential for this layer to have lesser number of neurons than that of the input layer. The goal of this model is to learn an approximation to the identity function in such a way that the values of <span class="strong"><strong>Layer L<sub>3</sub></strong></span> are equal to values in <span class="strong"><strong>Layer L<sub>1</sub></strong></span>.</p><p>The data is compressed when it passes through the input to output layers. When an image of certain pixels, say 100 pixels (10 X 10 pixels), is input to the model for a hidden layer with 50 neurons, the expectation is that the network tries to compress the image by keeping the pixel configuration intact. This kind of compression is possible only if there are hidden interconnections and other characteristic correlations that can reduce the input data.</p><p>Another variation of an autoencoder is<a id="id1272" class="indexterm"/> <span class="strong"><strong>denoising autoencoder</strong></span> (<span class="strong"><strong>DA</strong></span>). The difference in this variation of<a id="id1273" class="indexterm"/> autoencoder is its additional capability to <a id="id1274" class="indexterm"/>recover and restore the state impacted by the corrupt input data.</p></div></div>
<div class="section" title="Implementing ANNs and Deep learning methods"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec54"/>Implementing ANNs and Deep learning methods</h1></div></div></div><p>Refer to the source code <a id="id1275" class="indexterm"/>provided for this chapter for implementing <a id="id1276" class="indexterm"/>artificial neural networks and other deep learning methods covered in this chapters (source code path <code class="literal">.../chapter11/...</code> under each of the folders for the technologies).</p><div class="section" title="Using Mahout"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec136"/>Using Mahout</h2></div></div></div><p>Refer to<a id="id1277" class="indexterm"/> the <a id="id1278" class="indexterm"/>folder <code class="literal">.../mahout/chapter11/annexample/</code>.</p><p>Refer to <a id="id1279" class="indexterm"/>the<a id="id1280" class="indexterm"/> folder <code class="literal">.../mahout/chapter11/dlexample/</code>.</p></div><div class="section" title="Using R"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec137"/>Using R</h2></div></div></div><p>Refer to<a id="id1281" class="indexterm"/> the <a id="id1282" class="indexterm"/>folder <code class="literal">.../r/chapter11/annexample/</code>.</p><p>Refer<a id="id1283" class="indexterm"/> to the <a id="id1284" class="indexterm"/>folder <code class="literal">.../r/chapter11/dlexample/</code>.</p></div><div class="section" title="Using Spark"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec138"/>Using Spark</h2></div></div></div><p>Refer<a id="id1285" class="indexterm"/> to the<a id="id1286" class="indexterm"/> folder <code class="literal">.../spark/chapter11/annexample/</code>.</p><p>Refer <a id="id1287" class="indexterm"/>to the<a id="id1288" class="indexterm"/> folder <code class="literal">.../spark/chapter11/dlexample/</code>.</p></div><div class="section" title="Using Python (Scikit-learn)"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec139"/>Using Python (Scikit-learn)</h2></div></div></div><p>Refer<a id="id1289" class="indexterm"/> to<a id="id1290" class="indexterm"/> the<a id="id1291" class="indexterm"/> folder <code class="literal">.../python-scikit-learn/chapter11/annexample/</code>.</p><p>Refer to the<a id="id1292" class="indexterm"/> folder <code class="literal">.../python-scikit-learn/chapter11/dlexample/</code>.</p></div><div class="section" title="Using Julia"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec140"/>Using Julia</h2></div></div></div><p>Refer<a id="id1293" class="indexterm"/> to the<a id="id1294" class="indexterm"/> folder <code class="literal">.../julia/chapter11/annexample/</code>.</p><p>Refer<a id="id1295" class="indexterm"/> to the<a id="id1296" class="indexterm"/> folder <code class="literal">.../julia/chapter11/dlexample/</code>.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec55"/>Summary</h1></div></div></div><p>In this chapter, we covered the model of a biological neuron and how an artificial neuron is related to its function. You learned the core concepts of neural networks, and how fully connected layers work. We have also explored some key activation functions that are used in conjunction with matrix multiplication.</p></div></body></html>