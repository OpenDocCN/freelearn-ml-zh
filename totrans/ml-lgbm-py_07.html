<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer065">
<h1 class="chapter-number" id="_idParaDest-114"><a id="_idTextAnchor116"/>7</h1>
<h1 id="_idParaDest-115"><a id="_idTextAnchor117"/>AutoML with LightGBM and FLAML</h1>
<p>In the previous chapter, we discussed two case studies that showed end-to-end examples of how to approach data science problems. Of the steps involved in the typical data science life cycle, often, the most time-consuming tasks are preparing the data, finding the correct models, and tuning <span class="No-Break">the models.</span></p>
<p>This chapter looks at the concept of automated machine learning. Automated machine learning systems seek to automate some or all parts of the machine learning life cycle. We will look at <strong class="bold">FLAML</strong>, a library<a id="_idIndexMarker472"/> that automates the process’s model selection and tuning steps using efficient hyperparameter <span class="No-Break">optimization algorithms.</span></p>
<p>Lastly, we will present a case study using FLAML and another open source tool called Featuretools. Practical usage of FLAML will be discussed and shown. We will also show FLAML’s zero-shot AutoML functionality, which bypasses <span class="No-Break">tuning altogether.</span></p>
<p>The main topics of this chapter are <span class="No-Break">as follows:</span></p>
<ul>
<li>An introduction to automatic <span class="No-Break">machine learning</span></li>
<li>FLAML <span class="No-Break">for AutoML</span></li>
<li>Case study – using FLAML <span class="No-Break">with LightGBM</span></li>
</ul>
<h1 id="_idParaDest-116"><a id="_idTextAnchor118"/>Technical requirements</h1>
<p>The chapter includes examples and code excerpts showcasing using FLAML with LightGBM for AutoML use cases. Complete examples and instructions for setting up a suitable environment for this chapter are available <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-7"><span class="No-Break">https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-7</span></a><span class="No-Break">.</span></p>
<h1 id="_idParaDest-117"><a id="_idTextAnchor119"/>Automated machine learning</h1>
<p><strong class="bold">Automated machine learning</strong> (<strong class="bold">AutoML</strong>) is a burgeoning field that aims to automate complex aspects of ML workflows, allowing for more efficient and accessible deployment of ML models. The<a id="_idIndexMarker473"/> advent of AutoML reflects the increasing sophistication of artificial intelligence and ML technologies and their permeation into various industry and research sectors. It aims to alleviate some of the complex, time-consuming aspects of the data science process, allowing for broader usage and more accessible application of <span class="No-Break">ML technologies.</span></p>
<p>For software engineers well versed in ML and data science processes, the increasing complexity of ML models and the expanding universe of algorithms can pose a significant challenge. Building a robust, high-performing model requires substantial expertise, time, and computational resources to select suitable algorithms, tune hyperparameters, and conduct in-depth comparisons. AutoML has emerged as a solution to these challenges, aiming to automate these complex, frequently <span class="No-Break">labor-intensive tasks.</span></p>
<p>AutoML also serves to democratize the field of ML. By abstracting away some of the complexities of data engineering and model building and tuning, AutoML makes it possible for individuals and organizations with less experience in ML to leverage these powerful technologies. As a result, ML can be effective in a broader array of contexts, with more individuals and organizations capable of deploying <span class="No-Break">ML solutions.</span></p>
<p>AutoML systems are available at various levels of complexity. Although all AutoML systems aim to simplify the ML workflow, most systems and tools only focus on parts of the workflow. Commonly, steps such as data preprocessing, feature engineering, model selection, and hyperparameter tuning are automated. Such automation saves time and can improve the robustness and performance of ML models by systematically exploring a more comprehensive array of options that may be overlooked or unexplored due to human biases or <span class="No-Break">time constraints.</span></p>
<h2 id="_idParaDest-118"><a id="_idTextAnchor120"/>Automating feature engineering</h2>
<p>As discussed in <a href="B16690_06.xhtml#_idTextAnchor094"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <em class="italic">Solving Real-World Data Science Problems with LightGBM</em>, data cleaning <a id="_idIndexMarker474"/>and feature engineering are critical parts of the ML workflow. They involve dealing with unusable data, handling missing<a id="_idIndexMarker475"/> values, and creating meaningful features that can be fed into the model. Manual feature engineering can be particularly challenging and time-consuming. AutoML systems aim to handle these tasks effectively, enabling automated feature extraction and transformation, leading to more <span class="No-Break">robust models.</span></p>
<p>Data cleaning automation is typically achieved by following specific well-known techniques for dealing with problems such as outliers and missing values. In previous chapters, we applied some of these techniques manually: outliers can be tested statistically and capped or truncated. Missing values are typically imputed using descriptive statistics such as the mean or the mode. AutoML systems either use heuristic algorithms and tests to select the best techniques to clean the data or take multiple approaches and tests that work best by training models against <span class="No-Break">the data.</span></p>
<p>The methods for automating feature engineering are often similar: many possible transformations are applied to all existing features, and the usefulness of the generated features is tested after modeling. Examples of how transformations generate features can be found in the following <span class="No-Break">case study.</span></p>
<p>Another method for automating feature engineering is extracting features using rules based on the data type of the features. For example, the day, week, month, and year could be extracted from a date field. Or the number of characters, lemmas, stems, or embeddings of word or sentence features could <span class="No-Break">be calculated.</span></p>
<p>As you may notice, the application of feature engineering automation techniques relies on technical information about the features at hand, typically the data type, alongside correlation and relationships with other features. Importantly, there is no domain knowledge applied when creating new features. This highlights one of the shortcomings of AutoML: it cannot handle specific, domain-driven decisions that require human expertise. For example, consider a diabetes dataset with a feature for fasting blood sugar. A medical professional (domain expert) knows that an individual with a fasting blood sugar of 100 to 125 mg/dL is considered prediabetic, and any higher is considered diabetic. This continuous feature can be engineered to specific classes: normal, prediabetic, and <a id="_idIndexMarker476"/>diabetic, simplifying the data for modeling. A <a id="_idIndexMarker477"/>transformation like this is not possible to achieve with <span class="No-Break">AutoML systems.</span></p>
<h2 id="_idParaDest-119"><a id="_idTextAnchor121"/>Automating model selection and tuning</h2>
<p>Areas where AutoML is<a id="_idIndexMarker478"/> particularly useful are<a id="_idIndexMarker479"/> model selection and hyperparameter tuning. Given the plethora of algorithms available, choosing the best one for a particular dataset and problem can be daunting. AutoML systems use various techniques, including Bayesian optimization and meta-learning, to select the best model. They also automate the tuning of hyperparameters to maximize <span class="No-Break">model performance.</span></p>
<p>AutoML systems can provide automated cross-validation, reducing the risk of overfitting and ensuring the model’s generalizability to unseen data. Once the optimal model is selected and trained, many AutoML tools can also help with deployment, making the model available for inference on <span class="No-Break">new data.</span></p>
<p>Beyond the <a id="_idIndexMarker480"/>initial model deployment, some AutoML <a id="_idIndexMarker481"/>solutions also provide value in ongoing model monitoring and maintenance. As real-world data evolves, models may suffer from drift, and their performance can degrade. AutoML can help monitor model performance and retrain the model as needed, ensuring that your ML system remains effective in the <span class="No-Break">long run.</span></p>
<h2 id="_idParaDest-120"><a id="_idTextAnchor122"/>Risks of using AutoML systems</h2>
<p>As <a id="_idIndexMarker482"/>mentioned previously, AutoML systems typically use no domain knowledge to aid in feature engineering, model selection, or other automation. Instead, a brute-force or scattershot approach of try and see <span class="No-Break">is used.</span></p>
<p>The “black box” nature of some AutoML systems can also make it challenging to interpret decisions made by the system, making it less suitable for applications that require high levels <span class="No-Break">of explainability.</span></p>
<p>Therefore, it’s still essential to have a data scientist or domain expert in the loop, working alongside the AutoML system, to identify and act on opportunities where domain knowledge can lead to better models. However, AutoML systems sometimes hinder the data scientist instead of enabling them by creating one extra layer between the scientist and <span class="No-Break">the data.</span></p>
<p>We’ve already seen one AutoML framework in action. Optuna, which we discussed in <a href="B16690_05.xhtml#_idTextAnchor083"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, <em class="italic">LightGBM Parameter Optimization with Optuna</em>, is an example of an AutoML framework focusing on hyperparameter tuning. In the next section, we discuss another AutoML <span class="No-Break">framework: FLAML.</span></p>
<h1 id="_idParaDest-121"><a id="_idTextAnchor123"/>Introducing FLAML</h1>
<p><strong class="bold">FLAML</strong> (<strong class="bold">Fast and Lightweight AutoML</strong>) is a Python library developed by Microsoft Research <em class="italic">[1]</em>. It is designed to produce<a id="_idIndexMarker483"/> high-quality ML models with low computational cost automatically. The primary aim of FLAML is to minimize the resources required to tune hyperparameters and identify optimal ML models, making AutoML more accessible and cost-effective, particularly for users with <span class="No-Break">budget constraints.</span></p>
<p>FLAML offers several key features that set it apart. One of these is its efficiency. It provides a fast and lightweight solution for ML tasks, minimizing the time and computational resources needed. It achieves this without compromising the quality of the models it produces. FLAML also emphasizes its versatility across various ML algorithms and various <span class="No-Break">application domains.</span></p>
<p>The core of FLAML’s efficiency lies in its novel, cost-effective search algorithms. These algorithms intelligently explore the hyperparameter space, initially focusing on “cheap” configurations. It gradually explores more “expensive” configurations as it gains more insights into the search space. This ensures a balanced exploration and exploitation, delivering optimized models within user-specified time and <span class="No-Break">resource budgets.</span></p>
<p>FLAML also excels at the model selection process. It supports various ML algorithms, including XGBoost, LightGBM, CatBoost, RandomForest, and various linear models. The library can automatically choose the best algorithm for a given dataset and optimize its hyperparameters, providing users with an optimal model without extensive <span class="No-Break">manual intervention.</span></p>
<p>FLAML provides a straightforward, intuitive API that integrates seamlessly with existing Python-based data science and ML workflows. Users specify the dataset, a time budget (in seconds), and the optimization task, and FLAML handles the rest. This user-friendliness and efficiency make it a practical choice for ML beginners and seasoned practitioners looking to expedite <span class="No-Break">their workflows.</span></p>
<p>The novelty <a id="_idIndexMarker484"/>behind FLAML’s efficiency <a id="_idIndexMarker485"/>comes from its <strong class="bold">hyperparameter optimization</strong> (<strong class="bold">HPO</strong>) algorithms. FLAML <a id="_idIndexMarker486"/>provides two <a id="_idIndexMarker487"/>HPO <a id="_idIndexMarker488"/>algorithms: <strong class="bold">Cost Frugal Optimization</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="bold">BlendSearch</strong></span><span class="No-Break">.</span></p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor124"/>Cost Frugal Optimization</h2>
<p><strong class="bold">Cost Frugal Optimization</strong> (<strong class="bold">CFO</strong>) is a<a id="_idIndexMarker489"/> local search method that <a id="_idIndexMarker490"/>leverages random direct search to explore the hyperparameter space <em class="italic">[2]</em>. The CFO algorithm starts with a low-cost hyperparameter configuration (for LightGBM, a low-cost configuration would, for instance, have few boosted trees). It takes randomized steps for a fixed number of iterations in the hyperparameter space toward higher cost <span class="No-Break">parameter regions.</span></p>
<p>The CFO step size is adaptive, meaning the algorithm lowers the step size if there is no improvement for several iterations. Doing so means large step sizes aren’t taken in unpromising directions with <span class="No-Break">high cost.</span></p>
<p>CFO also utilizes random restarts. As a local search algorithm, CFO can get stuck in local optima. If no progress is made and the step size is already small, the algorithm restarts at a <span class="No-Break">random point.</span></p>
<p>In summary, CFO quickly (with large step sizes) attempts to reach more promising regions in the search space, using as little of the optimization budget as possible (by starting in low-cost regions). CFO continues the search while the optimization budget allows, restarting in random areas if stagnation occurs. FLAML allows the user to set the optimization budget <span class="No-Break">in seconds.</span></p>
<h2 id="_idParaDest-123"><a id="_idTextAnchor125"/>BlendSearch</h2>
<p>FLAML <a id="_idIndexMarker491"/>provides an alternative to <a id="_idIndexMarker492"/>the CFO algorithm in BlendSearch. BlendSearch differs from CFO by running both a global and local search process using a multithreaded <span class="No-Break">approach </span><span class="No-Break"><em class="italic">[3]</em></span><span class="No-Break">.</span></p>
<p>Similar to CFO, BlendSearch starts with a low-cost configuration and proceeds with a local search. However, unlike CFO, BlendSearch does not wait for the local search to stagnate before exploring new regions. Instead, a global search algorithm (such as Bayesian optimization) continually suggests new starting points. Starting points are filtered based on their distance to existing points and prioritized in terms <span class="No-Break">of cost.</span></p>
<p>Each iteration of BlendSearch then chooses whether to continue a local search or start at a new global search point based on the performance in the previous iteration. Like CFO, configurations proposed by the global search method are validated <span class="No-Break">for viability.</span></p>
<p>As <a id="_idIndexMarker493"/>BlendSearch uses global <a id="_idIndexMarker494"/>optimization, BlendSearch is less prone to getting stuck in local minima. BlendSearch is recommended over CFO if the hyperparameter search space is highly complex. It’s often a good idea to try CFO first and only switch to BlendSearch if CFO <span class="No-Break">is struggling.</span></p>
<h2 id="_idParaDest-124"><a id="_idTextAnchor126"/>FLAML limitations</h2>
<p>Despite its advantages, FLAML<a id="_idIndexMarker495"/> also has its limitations. The library’s automated processes may not consistently outperform manual tuning by experts, particularly for complex, domain-specific tasks. Also, as with other AutoML solutions, the interpretability of the produced models can be challenging, especially when dealing with models such as boosted trees or <span class="No-Break">neural networks.</span></p>
<p>FLAML only performs the model selection and tuning part of the ML process. These are some of the most time-consuming parts of model development, but FLAML does not provide the functionality to perform feature engineering or <span class="No-Break">data preparation.</span></p>
<p>The following section presents a case study of using FLAML with LightGBM, showcasing everyday use cases, different optimization algorithms, and FLAML’s <span class="No-Break">zero-shot AutoML.</span></p>
<h1 id="_idParaDest-125"><a id="_idTextAnchor127"/>Case study – using FLAML with LightGBM</h1>
<p>We will use the<a id="_idIndexMarker496"/> Wind Turbine dataset from the previous chapter for the case study. The dataset is cleaned as before, imputing missing values and capping outliers to appropriate ranges. However, we take a different approach to feature engineering. To further explore AutoML, we use an open source framework <span class="No-Break">called Featuretools.</span></p>
<h2 id="_idParaDest-126"><a id="_idTextAnchor128"/>Feature engineering</h2>
<p><strong class="bold">Featuretools</strong> (<a href="https://featuretools.alteryx.com/en/stable/#">https://featuretools.alteryx.com/en/stable/#</a>) is an open source framework for<a id="_idIndexMarker497"/> automated <a id="_idIndexMarker498"/>feature engineering. Specifically, Featuretools is well suited to <a id="_idIndexMarker499"/>transforming relational datasets and <span class="No-Break">temporal data.</span></p>
<p>As discussed<a id="_idIndexMarker500"/> in the previous section, automated feature engineering tools typically use combinatorial transformations of features to generate new features for the dataset. Featuretools supports <a id="_idIndexMarker501"/>feature transformations through their <strong class="bold">Deep Feature Synthesis</strong> (<span class="No-Break"><strong class="bold">DFS</strong></span><span class="No-Break">) process.</span></p>
<p>As an example, consider<a id="_idIndexMarker502"/> a dataset of online customer web sessions. Typical features that could be useful in such a dataset are the total sessions a customer visited the site for, or the month a customer signed up. Using Featuretools and DFS, this can be achieved using the following code (courtesy <span class="No-Break">of </span><a href="https://featuretools.alteryx.com/"><span class="No-Break">https://featuretools.alteryx.com/</span></a><span class="No-Break">):</span></p>
<pre class="source-code">
feature_matrix, feature_defs = ft.dfs(
    entityset=es,
    target_dataframe_name="customers",
    agg_primitives=["count"],
    trans_primitives=["month"],
    max_depth=1,
)
feature_matrix</pre>
<p>Two <a id="_idIndexMarker503"/>transformations are being applied here: a transformation for “<strong class="source-inline">month</strong>” and an aggregation for “<strong class="source-inline">count</strong>”. With these transformations, the month would be automatically extracted from any dates present for a customer (such as the join date), and the count aggregations would be calculated for each customer (such as the number of sessions or transactions). Featuretools has a rich set of transformations and aggregations available. <a href="https://featuretools.alteryx.com/en/stable/api_reference.xhtml">A complete list is available <span class="No-Break">at </span><span class="No-Break">https://featuretools.alteryx.</span></a><span class="No-Break">com/en/stable/api_reference.xhtml</span><span class="No-Break">.</span></p>
<p>Let’s see how we can use Featuretools to engineer the features for the Wind <span class="No-Break">Turbine dataset.</span></p>
<h3>Using Featuretools with the Wind Turbine dataset</h3>
<p>We<a id="_idIndexMarker504"/> must perform two feature engineering<a id="_idIndexMarker505"/> tasks for our dataset: engineer features for the datetime field and encode categorical features. To get started, we create an <strong class="source-inline">EntitySet</strong> for <span class="No-Break">our data:</span></p>
<pre class="source-code">
es = ft.EntitySet(id="wind-turbine")
es = es.add_dataframe(
    dataframe_name="wind-turbine",
    dataframe=df,
    index="tracking_id"
)</pre>
<p><strong class="source-inline">EntitySet</strong> tells <a id="_idIndexMarker506"/>the Featuretools framework the entities and<a id="_idIndexMarker507"/> relationships we work with within <a id="_idIndexMarker508"/>the data. Customer is an example of an entity in the earlier example; for this case, it’s Wind Turbines. We then pass the data frame and the column to be used as <span class="No-Break">an index.</span></p>
<p>We then apply <strong class="source-inline">dfs</strong> and <strong class="source-inline">encode_features</strong> to engineer the features for <span class="No-Break">our dataset:</span></p>
<pre class="source-code">
feature_matrix, feature_defs = ft.dfs(
    entityset=es, target_dataframe_name="wind-turbine",
    trans_primitives=["day", "year", "month", "weekday"],
    max_depth=1)
feature_matrix_enc, features_enc = ft.encode_features(
    feature_matrix, feature_defs)</pre>
<p>The preceding code extracts the day, year, month, and weekday for each of our wind turbine measurements. The feature encoding then automatically one-hot encodes the categorical features for our dataset, including the <span class="No-Break">new datefields.</span></p>
<p>The following is an excerpt from the dataset column list showing some of the columns created <span class="No-Break">by Featuretools:</span></p>
<pre class="source-code">
...
'cloud_level = Low',
'cloud_level = Medium',
'cloud_level = Extremely Low',
'cloud_level is unknown',
'MONTH(datetime) = 1',
'MONTH(datetime) = 2',
...
'MONTH(datetime) = 8',
'MONTH(datetime) = 9',
'MONTH(datetime) = 11',
'MONTH(datetime) is unknown',
...
'YEAR(datetime) = 2019',
'YEAR(datetime) = 2018',
'YEAR(datetime) is unknown'</pre>
<p>Note the <a id="_idIndexMarker509"/>one-hot encoding of categorical<a id="_idIndexMarker510"/> features: each value is now split into a separate column. This includes columns for unknown values (for example, <strong class="source-inline">YEAR(datetime) is unknown</strong>), which illustrates another way of dealing with missing values in categorical features. Instead of imputing a value by using something such as the mode, we have a column that signals to the model (<strong class="source-inline">true</strong> or <strong class="source-inline">false</strong>) that the value <span class="No-Break">is missing.</span></p>
<p>The automated feature engineering has increased our column count from 22 columns to 66 columns. This illustrates another general caveat with automated feature engineering and AutoML: automation may lead to overcomplicated datasets. In <a href="B16690_06.xhtml#_idTextAnchor094"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <em class="italic">Solving Real-World Data Science Problems with LightGBM</em>, we could encode features selectively based on our understanding of the learning algorithm. LightGBM can automatically<a id="_idIndexMarker511"/> handle categorical features; therefore, one-hot encoding is superfluous if LightGBM is the only learning <span class="No-Break">algorithm used.</span></p>
<p>Additionally, the datefields could be handled numerically. By applying our knowledge of the problem and algorithm, we can reduce the dimensionality of the learning problem, thereby <a id="_idIndexMarker512"/>simplifying it. The ease of use of <a id="_idIndexMarker513"/>automated systems has to be balanced with the manual effort of expert feature engineering, which could save time <span class="No-Break">later on.</span></p>
<p>The dataset is now ready for model development; we’ve completed the feature engineering for our dataset using only two lines <span class="No-Break">of code.</span></p>
<h2 id="_idParaDest-127"><a id="_idTextAnchor129"/>FLAML AutoML</h2>
<p>We will <a id="_idIndexMarker514"/>now look at model selection and tuning. We will use <a id="_idIndexMarker515"/>FLAML to compare five different models: LightGBM, RandomForest, XGBoost, ExtraTrees, and a limited-depth version of XGBoost. We would also like to find optimal parameters for the best model. This entire process is possible in two lines of code <span class="No-Break">with FLAML:</span></p>
<pre class="source-code">
automl = flaml.AutoML()
automl.fit(X, y, task="regression", time_budget=60)</pre>
<p>The preceding code fits an optimal regression model within a time budget of 60 seconds. FLAML automatically uses a holdout set to calculate validation results and then proceeds with optimization, using CFO as the tuner <span class="No-Break">by default.</span></p>
<p>The AutoML class provides “task-oriented AutoML.” The user sets the learning task, and FLAML does the rest. Among others, the following tasks are supported: classification, regression, time-series forecasting and time-series classification, ranking, and NLP-related tasks such as summarization and word <span class="No-Break">token classification.</span></p>
<p>The call to <strong class="source-inline">fit</strong> is customizable. For example, we could customize it <span class="No-Break">as follows:</span></p>
<pre class="source-code">
automl = flaml.AutoML()
custom_hp = {
    "learning_rate": {
        "domain": flaml.tune.loguniform(0.0001, 0.05)
    }
}
automl.fit(X, y, task="regression", time_budget=120,
           metric="mse",
           estimator_list=['lgbm', 'xgboost', 'rf'],
           custom_hp={
               "lgbm": custom_hp
           },
           hpo_method="bs")</pre>
<p>Here, we customize the hyperparameter search space by explicitly declaring the learning rate as a log-scaled uniform variable within a range. Other options for setting the search space for parameters are uniform sampling, random integer sampling, and choice-based sampling for <span class="No-Break">categorical parameters.</span></p>
<p>Furthermore, we set the estimator list to focus on only three modeling algorithms: LightGBM, Random Forest, and XGBoost. Lastly, we can customize the HPO algorithm, and here, we set it to BlendSearch, which uses the multithreaded optimization approach <span class="No-Break">discussed earlier.</span></p>
<p>A complete list of customizations is available <span class="No-Break">at </span><span class="No-Break">https://microsoft.github.io/FLAML/docs/reference/automl/automl/#automl-objects</span><span class="No-Break">.</span></p>
<p>Once <strong class="source-inline">fit</strong> has<a id="_idIndexMarker516"/> been called, we can use the AutoML-trained model as we would any other. FLAML <a id="_idIndexMarker517"/>provides a scikit-learn-style API for prediction and probability-based prediction (for <span class="No-Break">classification problems).</span></p>
<p>The following code creates predictions from the given data and calculates metrics and <span class="No-Break">feature importance:</span></p>
<pre class="source-code">
y_pred = automl.predict(X)
print(f"r2: {1 - sklearn_metric_loss_score('r2',
    y_pred, y)}")
print(f"MSE: {sklearn_metric_loss_score('mse',
    y_pred, y)}")
r2: 0.9878605489721696
MSE: 0.08090827806554425</pre>
<p>We can also get the best hyperparameter configuration for the winning model and for each of the models trialed by calling <span class="No-Break">the following:</span></p>
<pre class="source-code">
print(automl.best_config)
print(automl.best_config_per_estimator)
print(automl.time_to_find_best_model)</pre>
<p>A final notable feature of <a id="_idIndexMarker518"/>FLAML is zero-shot AutoML, which bypasses the need for model <span class="No-Break">tuning entirely.</span></p>
<h2 id="_idParaDest-128"><a id="_idTextAnchor130"/>Zero-shot AutoML</h2>
<p><strong class="bold">Zero-shot AutoML</strong> is a<a id="_idIndexMarker519"/> FLAML feature where hyperparameter optimization is not performed. Instead, suitable hyperparameter configurations are determined <a id="_idIndexMarker520"/>offline by analyzing the performance of an algorithm on a wide variety of datasets. The process can be described <span class="No-Break">as follows:</span></p>
<ol>
<li>Before building <span class="No-Break">a model:</span><ul><li>Train models on many datasets <span class="No-Break">using AutoML</span></li><li>Store all datasets’ hyperparameter configurations, evaluation results, and metadata as a <span class="No-Break">zero-shot solution</span></li></ul></li>
<li>When building a model for a <span class="No-Break">new problem:</span><ul><li>Use FLAML to analyze the new dataset against the zero-shot solution results and determine <span class="No-Break">suitable hyperparameters</span></li><li>Train a model on the new dataset using <span class="No-Break">the hyperparameters</span></li></ul></li>
</ol>
<p>The first step is performed only once for a given model type (such as LightGBM). Thereafter, a new model can be built for any new problem without tuning. The solution is “zero-shot” because suitable parameters are used on the first fit for a <span class="No-Break">new dataset.</span></p>
<p>FLAML’s zero-shot AutoML <a id="_idIndexMarker521"/>approach has <span class="No-Break">many advantages:</span></p>
<ul>
<li>As mentioned, no tuning is involved, sparing much computational effort and time when solving a <span class="No-Break">new problem</span></li>
<li>Since no tuning is required, a validation dataset is not required either, and more of the data may be used <span class="No-Break">for training</span></li>
<li>Even less involvement is required by <span class="No-Break">the user</span></li>
<li>Often, no<a id="_idIndexMarker522"/> code changes are required, as we’ll <span class="No-Break">see next</span></li>
</ul>
<p>Of course, creating the zero-shot solution for a model type is still arduous, requiring varied datasets and much computation to train many models. Fortunately, FLAML provides pretrained zero-shot solutions for many popular models, including LightGBM, XGBoost, and scikit-learn’s <span class="No-Break">random forests.</span></p>
<p>To use a zero-shot solution, replace the regular LightGBM import with the <span class="No-Break">FLAML-wrapped version:</span></p>
<pre class="source-code">
from flaml.default import LGBMRegressor
zs_model = LGBMRegressor()
zs_model.fit(X, y)</pre>
<p>Calling <strong class="source-inline">fit</strong> analyzes the data in <strong class="source-inline">X</strong>, selects suitable parameters, and trains the model using those parameters. Training is performed only once, and no tuning <span class="No-Break">is done.</span></p>
<p>This <a id="_idIndexMarker523"/>concludes our case study of FLAML. As we have seen, FLAML provides an intuitive API for sophisticated model selection and tuning functionality, which could spare much effort when working on an <span class="No-Break">ML problem.</span></p>
<h1 id="_idParaDest-129"><a id="_idTextAnchor131"/>Summary</h1>
<p>In summary, this chapter discussed AutoML systems and their uses. Typical approaches to automating feature engineering, model selection, and tuning were discussed. We also mentioned the risks and caveats associated with using <span class="No-Break">these systems.</span></p>
<p>The chapter also introduced FLAML, a library for AutoML that provides tools for automating the model selection and tuning process. We also presented CFO and BlendSearch, two efficient hyperparameter optimization algorithms provided <span class="No-Break">by FLAML.</span></p>
<p>The practicalities of applying FLAML were shown in the form of a case study. In addition to FLAML, we showcased an open source tool called Featuretools, which provides functionality to automate feature engineering. We showed how to develop optimized models in fixed-time budgets using FLAML. Finally, we provided examples of using FLAML’s zero-shot AutoML functionality, which analyzes datasets against configurations for known problems to determine suitable hyperparameters, eliminating the need for <span class="No-Break">model tuning.</span></p>
<p>The next chapter discusses building ML pipelines around LightGBM models, focusing on exporting, packaging, and deploying LightGBM models <span class="No-Break">for production.</span></p>
<h1 id="_idParaDest-130"><a id="_idTextAnchor132"/>References</h1>
<table class="No-Table-Style" id="table001-7">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><em class="italic">[</em><span class="No-Break"><em class="italic">1]</em></span></p>
</td>
<td class="No-Table-Style">
<p><em class="italic">C. Wang, Q. Wu, M. Weimer, and E. Zhu, “FLAML: A Fast and Lightweight AutoML Library,” in </em><span class="No-Break"><em class="italic">MLSys, 2021.</em></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><em class="italic">[</em><span class="No-Break"><em class="italic">2]</em></span></p>
</td>
<td class="No-Table-Style">
<p><em class="italic">Q. Wu, C. Wang and S. Huang, Frugal Optimization for Cost-related </em><span class="No-Break"><em class="italic">Hyperparameters, 2020.</em></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><em class="italic">[</em><span class="No-Break"><em class="italic">3]</em></span></p>
</td>
<td class="No-Table-Style">
<p><em class="italic">C. Wang, Q. Wu, S. Huang, and A. Saied, “Economical Hyperparameter Optimization With Blended Search Strategy,” in </em><span class="No-Break"><em class="italic">ICLR, 2021.</em></span></p>
</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="sbo-rt-content"><div class="Content" id="_idContainer066">
<h1 id="_idParaDest-131" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor133"/>Part 3: Production-ready Machine Learning with LightGBM</h1>
<p>In Part 3, we will delve into the practical applications of ML solutions in production environments. We will uncover the intricacies of machine learning pipelines, ensuring systematic data processing and model building for consistent results. MLOps, a confluence of DevOps and ML, takes center stage, highlighting the importance of deploying and maintaining robust ML systems in real-world scenarios. Through hands-on examples, we will explore the deployment of ML pipelines on platforms (like Google Cloud, Amazon SageMaker, and the innovative PostgresML) emphasizing the unique advantages each offers. Lastly, distributed computing and GPU-based training will be explored, showcasing methods to expedite training processes and manage larger datasets efficiently. This concluding part will emphasize the seamless integration of ML into practical, production-ready solutions, equipping readers with the knowledge to bring their models to life in <span class="No-Break">dynamic environments.</span></p>
<p>This part will include the <span class="No-Break">following chapters:</span></p>
<ul>
<li><a href="B16690_08.xhtml#_idTextAnchor134"><em class="italic">Chapter 8</em></a><em class="italic">, Machine Learning Pipelines and MLOps with LightGBM</em></li>
<li><a href="B16690_09.xhtml#_idTextAnchor146"><em class="italic">Chapter 9</em></a><em class="italic">, LightGBM MLOps with AWS SageMaker</em></li>
<li><a href="B16690_10.xhtml#_idTextAnchor162"><em class="italic">Chapter 10</em></a><em class="italic">, LightGBM </em><em class="italic">M</em><em class="italic">odels with PostgresML</em></li>
<li><a href="B16690_11.xhtml#_idTextAnchor177"><em class="italic">Chapter 11</em></a><em class="italic">, Distributed and GPU-based Learning with LightGBM</em></li>
</ul>
</div>
<div>
<div id="_idContainer067">
</div>
</div>
<div>
<div id="_idContainer068">
</div>
</div>
<div>
<div id="_idContainer069">
</div>
</div>
<div>
<div id="_idContainer070">
</div>
</div>
<div>
<div id="_idContainer071">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer072">
</div>
</div>
<div>
<div id="_idContainer073">
</div>
</div>
<div>
<div id="_idContainer074">
</div>
</div>
</div></body></html>