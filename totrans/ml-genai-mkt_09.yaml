- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating Compelling Content with Zero-Shot Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having introduced the promise of large language models in *Chapter 5*, we will
    go deeper into related topics in this chapter, extending our analysis from their
    role in data augmentation and sentiment analysis to their broader impact across
    different domains. This chapter introduces **zero-shot learning** (**ZSL**), a
    method in machine learning where a model can correctly make predictions for new,
    unseen classes without having received any specific training examples for those
    classes. It discusses the potential of ZSL and its application within the area
    of generative AI to create marketing copy. The discussion highlights how ZSL,
    an efficient tool to complement traditional marketing content creation processes,
    can revolutionize the generation of marketing copy.
  prefs: []
  type: TYPE_NORMAL
- en: We will start with an in-depth discussion of the core principles of generative
    AI and navigate through the capabilities and limitations of these technologies,
    which will set the stage for our subsequent exploration of the importance of pre-trained
    models. We will finish the chapter with a practical walkthrough of ZSL, using
    hands-on examples to illustrate the flexibility of this approach and how we can
    use it to generate marketing content. This will equip you with the skills to understand
    and leverage this technique to elevate your marketing strategies to new heights.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of the chapter, you will be well versed in:'
  prefs: []
  type: TYPE_NORMAL
- en: The fundamentals of generative AI and its versatile applications in marketing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The principles of ZSL and its value in improving the efficiency of traditional
    content creation processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practical strategies and considerations when applying ZSL to create marketing
    copy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fundamentals of generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Generative AI** (**GenAI**) refers to a subset of AI capable of generating
    new content, be it text, images, videos, or even synthetic data, that mirrors
    real-world examples. Unlike traditional AI models, which are designed to interpret,
    classify, or predict data based on inputs, GenAI takes it a step further by creating
    new, previously unseen outputs. It does this by understanding and learning from
    existing data patterns to produce novel outputs that maintain a logical continuity
    with the input data.'
  prefs: []
  type: TYPE_NORMAL
- en: We were introduced to GenAI in *Chapter 1*, and we further touched upon it and
    its applications for sentiment analysis in *Chapter 5*. Before beginning our discussion
    of pre-trained models and ZSL, we will explore the fundamental technical considerations
    of GenAI, what it is (and is not), and why it’s so impactful for generating marketing
    content. While the focus of the hands-on examples in this chapter will involve
    text generation, important concepts that power GenAI’s capabilities in other applications
    such as images and video will also be discussed.
  prefs: []
  type: TYPE_NORMAL
- en: A probabilistic approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At the heart of GenAI is a probabilistic approach to modeling data distributions.
    This involves learning the underlying probability distribution of a dataset to
    generate new samples from that same distribution. A cornerstone of this approach
    is Bayesian inference, a principle that updates the probability of a hypothesis
    as more evidence or information becomes available. For instance, consider a simple
    equation that forms the mathematical foundation on which Bayesian inference is
    built, Bayes’ Theorem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'where:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(*A*∣*B*) is the posterior probability of hypothesis *A*, given the evidence
    *B*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P*(*B*∣*A*) is the likelihood of observing evidence *B*, given that hypothesis
    *A* is true'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P*(*A*) is the prior probability of hypothesis *A*, or how likely we believe
    *A* to be true before seeing the evidence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P*(*B*) is the probability of observing the evidence under all possible hypotheses'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bayes’ Theorem – a pillar of probabilistic reasoning**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Bayes’ Theorem is not just a cornerstone of GenAI but also a fundamental principle
    across a wide range of disciplines, from statistics and computer science to philosophy
    and medicine. At its core, Bayes’ Theorem allows us to refine our hypotheses in
    light of new evidence, offering a rigorous mathematical approach to the concept
    of learning from experience.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When extending the principles of Bayesian inference and incorporating deep learning
    models such as **recurrent neural networks** (**RNNs**), **long short-term memory
    networks** (**LSTMs**), or transformers to the generation of sequences, we enter
    the realm of conditional probabilities. This sequence generation process can be
    viewed through the lens of predicting each element based on its predecessors,
    a concept foundational not just to video and audio but also to time series modeling
    and other forms of sequential data generation applications, including text.
  prefs: []
  type: TYPE_NORMAL
- en: Training GenAI models involves vast amounts of data, and in the case of text,
    these must be broken down into smaller units known as tokens. These tokens often
    consist of subword units or phrases, making the models more efficient in understanding
    and generating natural language. The process of tokenizing text is crucial because
    it allows a model to learn the probability distribution of different sequences
    of words or subwords.
  prefs: []
  type: TYPE_NORMAL
- en: When we tokenize text, we break it down into manageable pieces that a model
    can process. Each token is then used as an input to the model during training.
    The model learns to predict the probability of the next token in a sequence, given
    the previous tokens. This probabilistic approach is where Bayesian principles
    come into play. By continuously updating the probability distribution of tokens
    as new data is introduced, the model becomes better at generating coherent and
    contextually relevant outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, in text generation, a model might predict the next word in a sentence
    based on the preceding words. This prediction process involves calculating the
    conditional probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_002.png)'
  prefs: []
  type: TYPE_IMG
- en: where *x*[t] represents the token at time *t* and *P*(*x*[t]∣*x*[1],*x*[2],…,*x*[t-1])
    denotes the probability of generating *x*[t], given the sequence of all preceding
    tokens.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of video and audio generation, leveraging deep learning models
    informed by Bayesian principles helps in understanding and predicting temporal
    progression. Each frame or audio sample at time *t*(*x*[t])is predicated on the
    sequence of all previous frames or samples (*x*[1],*x*[2],…,*x*[t-1]). Mathematically,
    this relationship is captured by the previous equation:'
  prefs: []
  type: TYPE_NORMAL
- en: where *x*[t] represents the frame or audio sample at time *t* and ![](img/B30999_09_004.png)
    denotes the probability of generating *x*[t], given the sequence of all preceding
    samples.
  prefs: []
  type: TYPE_NORMAL
- en: '**Source code and data**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.9](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.9)'
  prefs: []
  type: TYPE_NORMAL
- en: Foundational models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several important foundational models in GenAI, each contributing
    uniquely to applications in image, text, and sequence generation. This section
    will cover some of the most important and widely used cases, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Generative adversarial networks** (**GANs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variational autoencoders** (**VAEs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Long short-term memory networks** (**LSTMs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformer-based models like the **Generative Pre-Trained Transformer** (**GPT**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While comprehensive implementation examples and theory for each of these models
    are outside the scope of this chapter, we will discuss the core concepts for each
    model type, as well as provide simplified, illustrative examples of their architectures,
    in order to understand the importance of these models for marketing applications.
    In *Chapter 12*, we will extend our discussion to mention further model advances
    that have garnered more recent attention for their promise in advancing the field
    of GenAI.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exploring ML models with Google Colab notebooks**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Training your own state-of-the-art ML model can be computationally expensive.
    However, using Google Colab notebooks, you can train and tweak models without
    any setup on your own machine. The following are links to get started:'
  prefs: []
  type: TYPE_NORMAL
- en: '**GANs** forhigh-quality image generation: [https://colab.research.google.com/drive/1uwPlY-4P_6fJ59SFRtgZLebVGgwGrUQu](https://colab.research.google.com/drive/1uwPlY-4P_6fJ59SFRtgZLebVGgwGrUQu
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**VAEs** for image reconstruction: [https://colab.research.google.com/github/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb](https://colab.research.google.com/github/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GPTs** for language processing: [https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing](https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LSTMs** for time series forecasting: [https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_recurrent-modern/lstm.ipynb](https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_recurrent-modern/lstm.ipynb)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative adversarial networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'GANs have found applications across a wide range of domains, from image generation
    and style transfer to data augmentation and beyond. They are particularly impactful
    in applications where realistic image generation is crucial, and they have been
    used by NVIDIA and Adobe in their photo editing software to generate and modify
    images. Their applications include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Content creation**: GANs can generate high-quality, realistic images, artwork,
    and videos, enabling new forms of creative content production'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image-to-image translation**: Applications like photo enhancement, photo-realistic
    rendering from sketches, and domain adaptation, such as day-to-night and summer-to-winter
    transformations, leverage GANs to transform images from one domain to another
    while preserving contextual details'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'At their core, GANs consist of two neural networks that are trained simultaneously
    through a competitive process:'
  prefs: []
  type: TYPE_NORMAL
- en: The generator (*G*) aims to generate data that is indistinguishable from real
    data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The discriminator (*D*) aims to accurately classify data as real or generated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This can be illustrated by the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a generator  Description automatically generated](img/B30999_09_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: GAN workflow'
  prefs: []
  type: TYPE_NORMAL
- en: The objective function for a GAN encapsulates the training dynamics between
    the generator and discriminator, creating a dynamic where both models improve
    in response to each other’s performance. This is similar to a two-player game
    where each player’s success is based on outsmarting their opponent. The game,
    in GAN’s case, reaches equilibrium when the generator produces perfect replicas
    of the real data, making it impossible for the discriminator to distinguish real
    from fake, which ideally results in a `0.5` probability of guessing correctly
    by the discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: For GANs to be highly effective at tasks such as high-resolution image generation,
    both the generator and discriminator architectures must be carefully designed.
    This can involve incorporating advanced architectures that are effective at handling
    spatial hierarchy data, such as **convolutional neural networks** (**CNNs**).
  prefs: []
  type: TYPE_NORMAL
- en: '**What are CNNs?**'
  prefs: []
  type: TYPE_NORMAL
- en: CNNs are a cornerstone of machine learning for processing spatial data, such
    as images. They identify patterns using convolutional filters, excelling in tasks
    that require an understanding of spatial hierarchies. This makes CNNs indispensable
    in many GAN applications for image generation and recognition.
  prefs: []
  type: TYPE_NORMAL
- en: In image-based GAN applications, the generator uses techniques to expand latent
    representations into detailed images, while the discriminator applies methods
    to reduce the dimensionality of the input image to assess its authenticity efficiently.
    The latent dimension, serving as the seed to generate new data instances, is a
    compact, high-dimensional space, encapsulating potential data variations in a
    compressed format.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the process for building the core structure of a simplified
    GAN for images, using Python, with the key steps described here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the libraries needed to build the generator and discriminator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the generator model, which takes a latent space vector and produces
    a 28x28 image through a series of dense layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the discriminator model, which takes an image and classifies it as real
    or generated through a series of dense layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Further technical considerations are necessary to address common challenges,
    such as limited output diversity and ensuring that the generated data is varied
    while still closely mirroring the real data distribution. These considerations
    include the choice of the activation function (`relu` for non-linear transformations),
    techniques to ensure consistent input distribution across layers, and strategies
    such as randomly omitting units during training to prevent overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more details on this, you can refer to the recent paper on GANs: [https://www.researchgate.net/publication/380573076_Understanding_GANs_fundamentals_variants_training_challenges_applications_and_open_problems](https://www.researchgate.net/publication/380573076_Understanding_GANs_fundamentals_variants_training_challenges_applications_and_open_problems).'
  prefs: []
  type: TYPE_NORMAL
- en: Variational autoencoders
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'VAEs present a different approach to generative modeling as compared to GANs.
    VAEs offer a probabilistic way of learning latent representations of data and
    consist of two main components:'
  prefs: []
  type: TYPE_NORMAL
- en: The encoder compresses input data into a latent space representation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The decoder reconstructs the data from this latent space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unlike traditional autoencoders, VAEs introduce a probabilistic twist where,
    rather than encoding input as a single point, they encode it as a distribution
    over the latent space.
  prefs: []
  type: TYPE_NORMAL
- en: '**The versatile applications of VAEs**'
  prefs: []
  type: TYPE_NORMAL
- en: VAEs are instrumental in understanding and modeling complex distributions of
    data. One key area where VAEs excel is in data imputation, where they can predict
    missing information or forecast future trends in time-series data.
  prefs: []
  type: TYPE_NORMAL
- en: The loss function for VAEs combines reconstruction loss with the **Kullback-Leibler**
    (**KL**) divergence between the learned latent variable distribution and the prior
    distribution. The reconstruction loss measures how well the generated outputs
    match the original inputs, ensuring that a model creates accurate reproductions
    of the data, and the KL divergence acts as a form of regularization during training
    that ensures the model learns efficient and meaningful data representations. This
    regularization prevents the model from overfitting by encouraging it to generate
    outputs that are not just accurate but also generalize well to new, unseen data.
    By combining these two components, the VAE learns to produce high-quality, diverse
    outputs and encourages the model to learn efficient encodings of the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a simplified example of constructing a VAE using Keras:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use a flattened 28x28 image input as another example, and we will first
    sample from the latent distribution in the `sampling()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then use the encoder to map the inputs into latent space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then use the decoder to reconstruct the image from the latent space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For the effective application of VAEs, selecting the right architecture for
    the encoder and decoder is crucial, often involving densely connected layers for
    basic tasks or more sophisticated structures, like CNNs, for image data. The dimensionality
    of the latent space is also vital – it must be large enough to capture relevant
    data variations but not so large that it leads to overfitting or meaningless reconstructions.
    When designed correctly, VAEs offer a principled approach to generative modeling,
    balancing the need for accurate data reconstruction with the flexibility to generate
    new, diverse samples from learned data distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Long short-term memory networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LSTMs are a specialized type of RNN designed to learn long-term dependencies
    in sequential data. RNNs are a class of neural networks that include loops, allowing
    information to persist by passing it from one step of the network to the next.
    This looping mechanism makes RNNs suitable for processing sequences of data such
    as time series or text. However, standard RNNs often struggle with learning long-range
    dependencies, due to issues like vanishing and exploding gradients. This occurs
    because, during backpropagation, gradients can become exponentially small (vanish)
    or large (explode), making it difficult to update the network weights effectively.
    LSTMs address these challenges with a more complex internal structure that allows
    them to remember information for longer periods effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The defining feature of LSTMs that enables them to remember information more
    effectively is their cell state, along with three types of gates: input, output,
    and forget gates. These components work together to regulate the flow of information,
    allowing a network to remember important information over long periods and to
    forget irrelevant data.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Key components of an LSTM**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Core to the LSTM are its cell state and gates with the following functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input gate**: How much new information to store in the cell state'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forget gate**: What information is discarded from the cell state'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output gate**: The output of the cell state to the next layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code sets up a simple LSTM network for time-series prediction
    that could be used to predict the next day’s sales, based on different features
    from the previous day. In this architecture, we allow for 10 days to be captured
    by `sequence_length` and then 5 features by `num_feature`, which could include
    data points such as web traffic or previous sales. The LSTM layer with 50 units
    learns to recognize patterns in the sequence data, while the `Dense` layer outputs
    the prediction. Finally, the model is compiled with the Adam optimizer and mean
    squared error (`mse`) loss function, common choices for regression tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To demonstrate the training process, we can generate synthetic time-series
    data that mimics sales prediction data. The synthetic data includes a base sine
    wave with added noise, simulating daily patterns with random fluctuations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'After training, we can evaluate the model on test data by comparing the predicted
    sales values with the actual values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The code produces the following plot, showing how a simple LSTM model with
    training can quickly provide useful predictions for metrics, such as sales, if
    given appropriate input features:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.2: Output of an LSTM sales prediction model'
  prefs: []
  type: TYPE_NORMAL
- en: Transformers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Transformer-based models, such as the GPT series, have revolutionized natural
    language processing by introducing a model architecture that excels in capturing
    context and relationships within data. The core innovation of transformer models
    is the attention mechanism, which enables a model to weigh the importance of different
    parts of the input data differently. This mechanism allows GPT and similar models
    to understand the context and generate text that is coherent and contextually
    relevant.
  prefs: []
  type: TYPE_NORMAL
- en: 'GPT models leverage the transformer architecture for generative tasks, trained
    on vast amounts of text data to understand language patterns, grammar, and context.
    This pre-training enables GPT models to generate text that is highly coherent
    and contextually relevant to the input prompts. While building a GPT from scratch
    is a formidable task, at the conceptual level, there are some key components within
    a GPT architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Embedding layer**: Converts token indices to dense vectors of fixed size'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-head attention**: Allows a model to focus on different parts of the
    input sequence simultaneously, capturing various contextual relationships'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Layer normalization and residual connections**: Help stabilize and optimize
    the training process, ensuring that gradients flow smoothly throughout a network'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows how a simplified GPT-like architecture can be created
    using Keras with the aforementioned components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**The power of self-attention in GPT**'
  prefs: []
  type: TYPE_NORMAL
- en: Self-attention, the key innovation behind GPT models, allows a network to weigh
    the importance of different words in a sentence, enhancing its understanding of
    context and relationships between words.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more, check out the paper *Attention Is All You Need* by Illia Polosukhin
    et al. ([https://arxiv.org/pdf/1706.03762](https://arxiv.org/pdf/1706.03762)).
  prefs: []
  type: TYPE_NORMAL
- en: When GenAI is the right fit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While GenAI brings new realms of possibility to content creation and digital
    marketing, understanding its limitations is also crucial. GenAI shines in environments
    that demand innovation, creativity, and the ability to scale personalized content
    dynamically. More generally, GenAI can be a great fitfor your marketing campaign
    in the following cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Brainstorming for creative campaigns**: Generating unique and compelling
    content, be it text, image, or video, to facilitate brainstorming for creative
    marketing campaigns that stand out in a crowded digital landscape. For example,
    we will use GenAI to generate text for a new product launch in this chapter and
    *Chapter 10*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dynamic content personalization**: Enabling marketers to tailor content at
    scale while still addressing individual user preferences and behaviors, in order
    to increase engagement and conversion rates. For instance, we will show how GenAI
    combined with **retrieval-augmented generation** (**RAG**) can be used to create
    personalized recommendations and email content, based on individual browsing history
    and purchase behavior, in *Chapter 11*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efficiency in content production**: Automating the content generation process,
    significantly reducing the time and resources needed to produce marketing materials.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, GenAI isn’t a one-size-fits-all solution, particularly in marketing
    scenarios where accuracy and deep contextual understanding are needed. For example,
    its application in highly regulated industries or in sensitive campaigns around
    social issues, where a misstep can significantly impact a brand’s reputation,
    must be done with caution. While GenAI can help with brainstorming in these cases,
    the unpredictability of GenAI content could pose significant risks if deployed
    without careful monitoring.Further discussion of this topic will be presented
    in *Chapter 13*, along with strategies to improve its contextual understanding
    in *Chapters 10* and *11*.
  prefs: []
  type: TYPE_NORMAL
- en: '**GenAI in highly regulated industries**'
  prefs: []
  type: TYPE_NORMAL
- en: When applying GenAI in sectors like healthcare, financial services, insurance,
    and legal services, adherence to stringent regulatory standards is crucial. Marketing
    content for these applications requires extra scrutiny, as they must not only
    be accurate and transparent but also align with industry-specific compliance measures.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to pre-trained models and ZSL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building on the foundations of GenAI discussed in the chapter so far, we will
    now introduce some core concepts related to pre-trained models and **zero-shot
    learning** (**ZSL**). These concepts underly how models can take vast amounts
    of existing data to create realistic, new outputs for scenarios that have not
    yet been encountered, with little to no additional training. With a focus on text
    data, we will discuss how contextual embeddings and semantic proximity are two
    key concepts that facilitate this capability. With this knowledge, you will be
    equipped to understand and apply these concepts in this chapter and the ones to
    come.
  prefs: []
  type: TYPE_NORMAL
- en: Contextual embeddings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Contextual embeddings, enabled by advancements such as the LSTM and GPT models
    discussed earlier, are fundamental to how **large language models** (**LLM**s)
    interpret and generate language. As discussed in *Chapter 5*, embeddings are dense
    vector representations of data that capture key features in a high-dimensional
    space. Early models like Word2Vec and GloVe generate static embeddings where the
    same word always has the same vector. In contrast, advanced models like BERT and
    GPT create contextual embeddings, where word representations change based on their
    usage in context. Effective NLP embeddings preserve the semantic relationships
    of the original data, meaning similar vectors are closer together in vector space.
    This adaptability is foundational for applications such as ZSL, which rely on
    a model’s ability to apply learned knowledge to new tasks without specific training
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Earlier in the chapter in the exploration of GenAI’s probabilistic nature, we
    noted how text generation is analogous to sequence prediction in video or audio,
    in that the relevance of each piece of data depends on its predecessors. As an
    analogy, consider how Google’s auto-suggest feature adapts suggestions based on
    the context of the words already entered. This same concept underpins the transformative
    potential of models like BERT, which analyzes text from both preceding and subsequent
    contexts to enhance language comprehension and prediction accuracy, via their
    contextual embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: GPT models take it a step further and adopt an autoregressive framework. The
    term “autoregressive” means that a model makes predictions based on its own previous
    outputs, meaning that it anticipates the subsequent word based on all preceding
    outputs of the model as context. For example, when developing a content calendar
    for a marketing blog, a GPT model can analyze past articles and trending topics
    to suggest new posts that align with the brand’s voice and audience interests.
    This is unlike transformer-based models, which can look at both preceding and
    following words simultaneously, as discussed earlier in the chapter. However,
    such autoregressive models can offer more nuanced text generation, enabling them
    to create narratives with a level of coherence that bidirectional models may not
    achieve as seamlessly.
  prefs: []
  type: TYPE_NORMAL
- en: '**The importance of contextual embeddings**'
  prefs: []
  type: TYPE_NORMAL
- en: Contextual embeddings from LSTM or GPT models allow for nuanced understanding
    by evaluating more of the text in its entirety.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in filling in the blank in “The stormy seas calmed as the ___
    sailed into the harbor,” a model leveraging both prior and subsequent context
    could infer “ship” with greater accuracy, whereas a more naive model with only
    prior context might inaccurately predict the word “day.”
  prefs: []
  type: TYPE_NORMAL
- en: Semantic proximity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Transitioning from our discussion on contextual embeddings and their critical
    role in language models, we will now explore **semantic proximity**. Contextual
    embeddings not only enhance the understanding of text by considering its dynamic
    contexts; they also serve as a fundamental tool in evaluating the semantic relationships
    between words or phrases within that text. This nuanced understanding is pivotal
    when we examine the concept of semantic proximity, which involves quantifying
    how closely related or distant two linguistic items are in meaning.
  prefs: []
  type: TYPE_NORMAL
- en: For example, consider the phrases “limited-time offer” and “exclusive deal.”
    These phrases have close semantic proximity because they both relate to targeted
    promotions for potential customers. Conversely, the phrases “limited-time offer”
    and “customer feedback” would have a much larger semantic distance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Semantic proximity is effectively assessed through methods such as cosine similarity,
    which measures the angle between vectors representing these items in a high-dimensional
    space. This metric, rooted in the geometry of vector spaces, provides a clear,
    mathematical way to capture and compare the meanings encoded by embeddings. Mathematically,
    cosine similarity is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_005.png)'
  prefs: []
  type: TYPE_IMG
- en: where *A* and *B* are vectors (semantic embeddings for a word, phrase, document,
    etc), *A*⋅*B* denotes their dot product, and ∥*A*∥ and ∥*B*∥ represent their magnitudes.
    The value of cosine similarity ranges from -1 to 1\. A value of 1 implies that
    the vectors are identical in direction, indicating maximum similarity. A value
    of 0 implies that the vectors are orthogonal, indicating no similarity.
  prefs: []
  type: TYPE_NORMAL
- en: 'While, in practice, many sophisticated text embeddings are high-dimensional
    and can range from hundreds to thousands of dimensions, we can more easily illustrate
    the concept of cosine similarity in 2D space via two vectors. In the following
    code, we illustrate the calculation of cosine similarity using vectors *A* and
    *B*, with the angle associated with their cosine similarity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B30999_09_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.3: Visualization of cosine similarity between two vectors, A and B,
    showing their angular relationship in 2D space'
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing from the mathematical foundation of cosine similarity, we can apply
    this same concept to explore the polysemous nature of words in different contexts.
    Consider the word “light” used in two different sentences:'
  prefs: []
  type: TYPE_NORMAL
- en: '*He turned on the* **light** *to read*.'
  prefs: []
  type: TYPE_NORMAL
- en: '*The* **light** *fabric was perfect for summer*.'
  prefs: []
  type: TYPE_NORMAL
- en: These sentences demonstrate different semantic instances of the word “light,”
    and by employing contextual embedding models like BERT, we can quantify the semantic
    differences of “light” in these cases using cosine similarity.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, in the following code, we:'
  prefs: []
  type: TYPE_NORMAL
- en: Import libraries and load the pre-trained BERT model and tokenizer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tokenize the sentences, converting them into the format expected by the BERT
    model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pass the tokenized sentences through the BERT model to obtain the embeddings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract embeddings for the word “light” by finding the index of the word in
    each tokenized sentence and extracting its corresponding embedding from the model
    output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute cosine similarity and print the result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To do this, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: A cosine similarity value ranges from -1 to 1\. As mentioned earlier, a value
    of 1 indicates identical vectors, while a value of 0 implies orthogonal vectors
    with no similarity. In this case, a cosine similarity of 0.48 suggests that the
    embeddings for “light” in the two sentences are somewhat similar but not identical.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-trained models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pre-trained models are machine learning algorithms that have been previously
    trained on large datasets to perform general tasks, such as understanding natural
    language or recognizing objects in images. The utility of pre-trained models is
    fundamentally rooted in their use of the embeddings they were trained on. For
    text, these embeddings not only enable models to grasp context dynamically but
    also serve as the foundation to adapt these models for specific tasks, such as
    sentiment analysis, as discussed in *Chapter 5*, with minimal to no additional
    training. This adaptability is critical for applications such as ZSL.
  prefs: []
  type: TYPE_NORMAL
- en: The advent of pre-trained models democratized access to state-of-the-art AI
    by offering a base model that can be fine-tuned or used for inference directly.
    These models not only reduce the cost and time to deployment for AI-driven solutions
    but also the need for computational resources and energy consumption, making AI
    both more accessible and environmentally friendly. In the marketing domain, pre-trained
    models offer significant advantages. They enable marketers to quickly deploy advanced
    AI solutions for tasks such as personalized content creation, customer sentiment
    analysis, and targeted advertising.
  prefs: []
  type: TYPE_NORMAL
- en: Sophisticated AI models that were previously attainable only for large or highly
    specialized technology companies are now a possibility for smaller-sized businesses,
    and even individual consumers, at a fraction of the cost. For perspective, training
    a model such as GPT-3 from scratch was estimated to be in the millions of dollars
    at the time of its release in 2020, a figure that encapsulates computational costs
    and human expertise. Today, a user can perform inference to generate text using
    this same (or a more advanced) model through the company’s API, at the cost of
    a few cents for hundreds of words of content.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key components of a pre-trained model are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Weights**: They represent the learned parameters from training datasets and
    encode a wide range of knowledge and patterns needed for transfer learning'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Architecture**: The model’s structure, detailing how inputs are processed
    through various layers to generate outputs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pre-processing steps**: Procedures like tokenization and normalization to
    ensure data compatibility with the model’s training'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s look at these components in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Model weights
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Model weights are at the core of neural networks, including pre-trained models.
    Weights are the refined parameters developed through extensive training to minimize
    loss, acting as a repository of a model’s learned knowledge. For instance, in
    language models like GPT, these weights capture the intricacies of language, such
    as grammar and context, enabling the generation of text that’s not only coherent
    but also contextually rich. The effectiveness of pre-trained models in tasks like
    ZSL stems from these weights, which enable you to generalize from the model’s
    training data to new, unseen data with remarkable accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand where the model weights come from, consider the case of
    an **artificial neural network** (**ANN**), as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.4: Example ANN architecture from Chapter 6'
  prefs: []
  type: TYPE_NORMAL
- en: 'This consists of three main layers: the input layer, the hidden layer, and
    the output layer. During training, neural networks undergo forward and backward
    propagation. Forward propagation involves feeding data through a network to generate
    an output, while backward propagation adjusts weights based on the error of the
    predictions. Through these iterations, the network learns the optimal weights
    for each neuron, minimizing prediction error and enhancing a model’s performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Model architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The architecture of a pre-trained model goes hand in hand with its weights.
    It delineates the structure of how data is processed and transformed across the
    model’s layers and also guides the adaptability of the model to perform novel
    tasks. For example, deeper language model architectures might be better suited
    for complex reasoning tasks, while models with specially configured attention
    mechanisms can offer finer control over the focus of the model during inference.
    For image recognition, the intermediate representations produced by these models,
    such as features extracted at various layers by a pre-trained CNN, can also serve
    as a valuable starting point for classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'When understanding a machine learning model’s architecture, it can be helpful
    to plot it and its parameters to visualize its key aspects. Here, we illustrate
    this using Keras’s `plot_model()`, as a demonstration of a simple LSTM model composed
    of two LSTM layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B30999_09_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.5: A simple LSTM-based neural network architecture'
  prefs: []
  type: TYPE_NORMAL
- en: 'This visualization clearly delineates the model’s structure, showing the progression
    from input through two LSTM layers, each with 64 units (or neurons), to a final
    dense output layer configured with 10 softmax units for class prediction. Based
    on the labels given in the figure, the structure can be further broken down as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input layer (lstm_input)**: Takes in data with a shape of `(10, 128)`, processing
    sequences of 10 timesteps, each with 128 features'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**First LSTM layer (lstm)**: Contains 64 units and returns sequences, processing
    the input and passing on sequences of the same length to the next LSTM layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Second LSTM layer (lstm_1)**: Also has 64 units but does not return sequences,
    compressing the output from the first LSTM layer into a single vector'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dense output layer (dense)**: The final layer is a dense layer with 10 units
    and a softmax activation function, outputting a probability distribution over
    10 classes (categories or labels)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preprocessing steps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Preprocessing steps are crucial for ensuring that data is compatible with a
    pre-trained model’s training procedure. Here are a couple of examples:'
  prefs: []
  type: TYPE_NORMAL
- en: NLP **tokenization** breaks down text into words or subwords that are consistent
    with what an LLM model expects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For images, **normalization** can adjust image pixel values to a common scale
    to facilitate a model’s ability to learn from and generate predictions for data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These preprocessing steps are essential for leveraging pre-trained models effectively,
    ensuring that input data mirrors the form of the data that the model was trained
    on.
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Following our exploration of pre-trained models and their fundamental components,
    we will now shift our focus to their application in ZSL. As we will discuss later,
    the fundamentals behind ZSL allow marketers to dynamically generate relevant content
    and even target their marketing campaigns to individual consumers in near real
    time. Before we get to those examples, this section will provide some background
    on ZSL and how it enables models to apply learned knowledge and infer information
    about tasks or classes that were not explicitly covered during their training.
    This capability extends the utility of pre-trained models, allowing them to generalize
    across unseen data and scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Mechanics of learning and prediction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At its core, ZSL operates by using transformations and mappings of the input
    and output in a high-dimensional embedding space, using two primary functions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'An **embedding function** *f*: ![](img/B30999_09_006.png) that transforms input
    – such as images or text – into feature vectors within the embedding space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A **semantic attribute function** *g*: ![](img/B30999_09_007.png) that associates
    class labels with semantic attributes in the same embedding space. These attributes
    describe classes in terms of universal, distinguishable features, existing within
    an attribute space *A*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As a simplified example, take a case where ZSL is applied to distinguish between
    animals. The embedding function *f*: ![](img/B30999_09_008.png) would transform
    visual images of the animal into high-dimensional feature vectors within the embedding
    space – for example, taking images of a sparrow and an eagle that are processed
    to show distinct feature vectors, representing their visual characteristics. Simultaneously,
    the semantic attribute function *g*: ![](img/B30999_09_009.png) maps class labels,
    like *sparrow* and *eagle*, to vectors in the same embedding space based on semantic
    attributes. Attributes for *sparrow* might include `[′small_size′, ′brown_color′,
    ′has_wings′]`, whereas *eagle* could be characterized by `[′large_size′, ′sharp_beak′,
    ′has_wings′]`. These attributes are then quantified, where `small_size` might
    be encoded as `0.2` on a size scale, and `large_size` as `0.8`.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.6: Example mappings from an input image or class label to an embedding
    space'
  prefs: []
  type: TYPE_NORMAL
- en: By placing both images and class attributes within the same embedding space,
    as shown in *Figure 9.6*, a model can match an image’s feature vector to the closest
    class attribute vector. This matching is facilitated even if the model has never
    seen an image of a sparrow or eagle during training, by recognizing the overlap
    in their attributes with those of known classes. To find the best class match,
    the algorithm is tasked with the optimization of a compatibility function, which
    quantifies the match between an input’s feature vector and a class’s attribute
    vector. The ZSL prediction then involves selecting the class that maximizes compatibility
    for an unseen instance.
  prefs: []
  type: TYPE_NORMAL
- en: Output parameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are a number of key parameters that can be specified to influence the
    output of ZSL models. These parameters tailor the output by adjusting the behavior
    of the model during the sampling process. Three of the most common ones used in
    the context of text generation with models like GPT include:'
  prefs: []
  type: TYPE_NORMAL
- en: Temperature
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Top P (nucleus sampling)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequency penalty
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By influencing how the model’s outputs are sampled from the probability distribution
    generated by the compatibility function, each of these parameters allows adjustments
    in the creativity, coherence, and diversity of the model’s outputs. The following
    sections provide further detail on the theory underlying each of these parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Temperature
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The temperature parameter plays a crucial role in determining the level of
    randomness or confidence in the prediction distribution. Mathematically, adjusting
    the temperature modifies the `softmax` function used to calculate the probabilities
    of the next word in the following manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_010.png)'
  prefs: []
  type: TYPE_IMG
- en: where *T* is the temperature and logit represents the raw outputs from the model.
    A lower temperature sharpens the distribution, making the model’s predictions
    more deterministic and less varied, whereas a higher temperature flattens the
    distribution, encouraging diversity in the predictions at the cost of potentially
    introducing less coherence, as the model becomes more likely to sample less probable
    words.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the concept, let’s consider a predictive text generation scenario
    of the next word in the sentence “`The cat sat on the ___.`" For simplicity, assume
    our model considers five possible completions: “`mat`,” “`tree`,” “`ball`,” “`bed`,”
    and “`tabl`e,” with the initial logits reflecting their probabilities (assigned
    manually in this case for simplicity). We can use the following code to produce
    a visualization, demonstrating how changing the temperature parameter *T* affects
    the `softmax` function, altering the probability distribution of these potential
    next words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.7: Visualization of the impact of the temperature parameter on softmax
    probability distributions for potential next words in the sentence “The cat sat
    on the ___”'
  prefs: []
  type: TYPE_NORMAL
- en: As illustrated in the graph, at lower temperatures the distribution is sharper,
    concentrating the probability mass on fewer, more likely outcomes, like “`bed`.”
    As the temperature increases, the distribution becomes flatter, giving a higher
    probability to a broader set of potentially less likely word outcomes, such as
    `table` or `mat`.
  prefs: []
  type: TYPE_NORMAL
- en: Top P
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Top P, or **nucleus sampling**, offers a dynamic way to focus the generation
    process on the most plausible set of outcomes. Instead of considering the entire
    vocabulary, the model limits its choices to the smallest set of words whose cumulative
    probability exceeds the threshold P.
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach can be thought of as dynamically adjusting the breadth of consideration
    based on the model’s confidence, according to the formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_011.png)'
  prefs: []
  type: TYPE_IMG
- en: where *N* is the number of words considered and *P*(*w*[i]) is the probability
    of the *i*^(th) word. This technique helps maintain a balance between variety
    and relevance, ensuring that the generated text remains plausible without being
    overly constrained by the most likely predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Frequency penalty
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The **frequency penalty** addresses the tendency of models to repeat the same
    words or phrases, enhancing the diversity of the output. It modifies the probability
    of each word based on its previous occurrences in the generated text:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_012.png)'
  prefs: []
  type: TYPE_IMG
- en: where *P*(*w*[i]) is the original probability of the word *w*[i] and *Occurrence*
    (*w*[i]) is the number of times *w*[i] has appeared in the text so far. This adjustment
    encourages the exploration of new vocabulary and ideas by penalizing words that
    the model has already used, promoting a richer and more varied output.
  prefs: []
  type: TYPE_NORMAL
- en: ZSL for marketing copy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now discuss the practical application of ZSL through the example of
    an e-commerce brand that is launching new lines of eco-friendly kitchenware and
    fashion products. Traditionally, creating compelling product descriptions and
    promotional content could require significant research and creative effort from
    writers familiar with a brand’s tone and the intricacies of sustainable design.
    However, with ZSL, the brand can input a concise description of the product line,
    emphasizing keywords like “sustainable” and “eco-friendly activewear,” into a
    pre-trained model, immediately producing an output of brand-appropriate content
    that is ready for consideration across digital platforms. By automating these
    initial stages of content generation, the brand can now focus more on higher value
    efforts like strategy, engagement, and analyzing the effectiveness of its marketing
    efforts.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, to integrate ZSL effectively into your marketing strategy, consider
    the following iterative process as a template:'
  prefs: []
  type: TYPE_NORMAL
- en: Define your content goals and the key messages you want to communicate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create concise prompts that encapsulate these goals and messages, incorporating
    relevant keywords and themes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Experiment with different parameters (`temperature`, `Top P`, and `frequency
    penalty`) to adjust the style and diversity of the generated content.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate multiple content variations to explore different angles and ideas.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review and refine the output, selecting the best options that align with your
    brand’s tone and objectives.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the generated content as a starting point for further customization and
    optimization, based on audience feedback and performance metrics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following subsections, we will focus on steps 1–4 of the preceding workflow,
    with steps 5 and 6 covered by examples in the chapters that will follow.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing for ZSL in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To demonstrate the Python setup process for ZSL, this section will walk through
    the basic steps of using both freely available, open-source models, as well as
    more advanced models requiring paid API-based implementations. We will demonstrate
    the former with models available in the Hugging Face Transformers library, and
    we will demonstrate the setup for the latter using OpenAI’s API service.
  prefs: []
  type: TYPE_NORMAL
- en: '**Staying ahead with Hugging Face updates**'
  prefs: []
  type: TYPE_NORMAL
- en: Hugging Face’s Transformers library frequently updates, making advanced models
    that were previously behind paid API services freely available. For the latest
    Hugging Face models available, consult their documentation at `https://huggingface.co/models`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic setup for ZSL tasks using the gpt2 model available on Hugging Face
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this prompt results in an output such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We can contrast this with the output that is returned from a model with the
    same parameters but using the more advanced text generation capabilities of OpenAI’s
    GPT-4\. Executing this model currently requires the creation of an OpenAI account
    and then generating an API key that can be substituted in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in a response such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: It’s evident from these two responses that advanced models like GPT-4 significantly
    enhance the relevancy and quality of the generated content. This is because, compared
    to GPT-2, GPT-4 incorporates major advancements in deep learning architectures,
    larger training datasets, and more sophisticated fine-tuning techniques. For this
    reason, we will use results obtained from GPT-4 for the remainder of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: However, the key to leveraging ZSL effectively lies not just in a model’s capabilities
    but also in effectively choosing the input information that shapes the output.
    The most critical aspects here include creating an effective prompt, as well as
    setting other parameters such as temperature and Top P, as discussed earlier in
    the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '**Use the outputs of LLMs with caution**'
  prefs: []
  type: TYPE_NORMAL
- en: Relying directly on the output of any LLM for critical campaign content without
    human review can be risky! Always consider treating the initial outputs of GenAI
    models as a creative starting point, and then iterate and refine them as needed
    to ensure alignment with your brand’s voice and objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an effective prompt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating an effective prompt is the most crucial step in leveraging ZSL for
    marketing copy. In ZSL, the prompt effectively becomes the instruction manual
    for a model, telling it what kind of content to generate, as well as its style,
    tone, and substance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some guidelines around how to formulate prompts that will
    elicit the best possible marketing copy content from the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Clarity**: Ensure that your prompt is specific about what you want, whether
    it’s a product description, headline, or call to action.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Contextual**: Provide sufficient background to guide a model. For eco-friendly
    products, mention key selling points like sustainability or biodegradability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Creative**: While clarity is crucial, leaving room for creativity can yield
    surprising and innovative results. Phrases like “Imagine...” or “Create a story
    where...” can be particularly powerful.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Concise**: Lengthy prompts can dilute the focus. Aim for brevity while including
    essential details, ensuring that a model stays on topic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following sections, we will illustrate the impact of prompt quality
    through examples, with different types of marketing copy. While good prompts elicit
    detailed, relevant, and engaging content, poor prompts can lead to vague and uninspiring
    outputs. To generate these responses, we will define the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This function will be used with different prompt types in the examples that
    follow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example 1: Product descriptions'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this example, we will generate product descriptions for our e-commerce brand,
    which is launching new lines of eco-friendly kitchenware.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a poor prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s look at the following example of a good prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This prompt produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: From a marketing perspective, this example demonstrates the significance of
    creating detailed and audience-specific prompts with clear requirements when using
    ZSL for product descriptions, as well as how this leads to more specificity in
    the generated response. However, it is worth noting that older consumers may value
    more straightforward, factual information and, therefore, may favor the more generic
    prompt’s response from an engagement standpoint. Tailoring GenAI outputs at the
    level of the individual consumer can be crucial as well and is a topic discussed
    in *Chapter 11*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example 2: Blog post titles'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In our next example, we will focus on another type of marketing copy by generating
    blog post titles for our e-commerce brand.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll start by generating a poor prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s an example of a good prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us a more engaging result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Comparing these prompts for blog post titles illustrates the impact of specificity
    and audience targeting on content effectiveness, where a specific prompt highlighting
    biodegradable kitchenware creates content aligned more with sustainability. In
    contrast, a vague prompt results in a generic title that would fail to differentiate
    itself amid a sea of similar content. To tailor the language produced by LLMs
    even further, we can also use **few-shot learning** (**FSL**), the topic of the
    next chapter. Used effectively, FSL can achieve the same specificity in language
    but in a way that’s aligned with a brand’s unique voice, in order to distinguish
    LLM outputs from what other LLMs might produce, even when given the same prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '**Navigating topical content with AI**'
  prefs: []
  type: TYPE_NORMAL
- en: When generating blog posts, understanding your model’s training data recency
    is crucial. Without current data or web search capabilities, you risk creating
    content based on outdated trends that lack the necessary context for relevant
    outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example 3: Social media captions'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this example, we will generate an Instagram caption for a post about our
    e-commerce brand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a poor prompt first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This yields the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will look at an example of a good prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The difference between these two prompts for Instagram captions illustrates
    how a specific prompt generates a caption that not only engages with its witty
    language but also directly appeals to eco-conscious consumers, likely increasing
    likes, shares, and comments – all crucial metrics on social platforms. In contrast,
    the vague prompt results in a generic and broad caption that, while informative,
    lacks a focused appeal and may fail to capture the attention of certain potential
    customers looking for eco-friendly products.
  prefs: []
  type: TYPE_NORMAL
- en: Impact of parameter tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While creating an effective prompt lays the groundwork, fine-tuning the model’s
    parameters is equally essential to align the generated content with the desired
    marketing style. In this section, we will explore how adjusting parameters like
    temperature and Top P affect the output of a language model. Transitioning from
    kitchenware, we will demonstrate this by generating marketing slogans for an eco-friendly
    and sustainable fashion line launch.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will do this by defining the following Python function, outputting sets
    of three variants of the slogan for each alteration to one of these parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s use the base case, with both `temperature` and `Top P` set to values
    of `1.0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s tweak each parameter and see the output that we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Temperature**: Increasing temperature makes responses more diverse and creative
    but potentially less coherent:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This produces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Conversely, lowering the temperature results in more predictable and consistent
    outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, the prompt produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '**Top P**: Reducing `top_p` from its maximum value of 1.0 narrows the possible
    variety of generated slogans by making the model more conservative, as it tends
    to select only the most probable outputs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This produces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Through these examples, we can observe the significant impact that parameter
    adjustments can have on the nature of generated content. This demonstrates the
    importance of parameter tuning in creating marketing slogans that are not only
    relevant and engaging but also tailored to the style and message of a brand.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we went on a journey through GenAI, and ZSL, and their transformative
    potential in marketing content creation. We introduced foundational GenAI concepts
    and discussed the mechanisms that allow these models to generate text, images,
    and more, with a particular focus on text generation. Analyzing contextual embeddings
    and semantic proximity highlighted the nuances that pre-trained models like GPT
    and BERT bring to understanding and generating language with remarkable adaptability
    and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Central to our discussion was the application of ZSL in creating marketing copy,
    which allows brands to generate compelling content without the need for extensive
    training data. We outlined a strategic process to integrate ZSL into marketing
    strategies with the help of examples that emphasize the importance of creating
    clear, contextual, and creative prompts. This step-by-step approach – defining
    content goals, experimenting with parameters, and refining outputs – enables marketers
    to harness the power of LLMs effectively. We also learned how adjusting parameters
    such as temperature and Top P can help fine-tune the creativity, coherence, and
    diversity of the generated content. These practical insights will help you optimize
    marketing copy to align with brand messaging and campaign objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Looking ahead, the next chapter progresses into the more advanced territories
    of few-shot and transfer learning. Building on the ZSL foundation, we will explore
    how these techniques can further refine GenAI models for on-target messaging.
    This involves adapting models to new contexts with minimal examples (FSL) and
    updating them with brand or customer-specific information (transfer learning),
    ensuring consistency and relevance in the generated content.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/genai](https://packt.link/genai)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code12856128601808671.png)'
  prefs: []
  type: TYPE_IMG
