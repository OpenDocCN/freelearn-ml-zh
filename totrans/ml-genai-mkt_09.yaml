- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Creating Compelling Content with Zero-Shot Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用零样本学习创建引人入胜的内容
- en: Having introduced the promise of large language models in *Chapter 5*, we will
    go deeper into related topics in this chapter, extending our analysis from their
    role in data augmentation and sentiment analysis to their broader impact across
    different domains. This chapter introduces **zero-shot learning** (**ZSL**), a
    method in machine learning where a model can correctly make predictions for new,
    unseen classes without having received any specific training examples for those
    classes. It discusses the potential of ZSL and its application within the area
    of generative AI to create marketing copy. The discussion highlights how ZSL,
    an efficient tool to complement traditional marketing content creation processes,
    can revolutionize the generation of marketing copy.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第五章**中介绍了大型语言模型的潜力之后，我们将在本章深入探讨相关主题，将我们的分析从其在数据增强和情感分析中的作用扩展到其在不同领域的更广泛影响。本章介绍了**零样本学习**（**ZSL**），这是一种机器学习方法，模型可以在没有为这些类别接收任何特定训练示例的情况下，正确地对新、未见过的类别进行预测。它讨论了ZSL的潜力及其在生成式人工智能领域创建营销文案中的应用。讨论突出了ZSL作为一种高效工具，可以补充传统的营销内容创作流程，如何革命性地改变营销文案的生成。
- en: We will start with an in-depth discussion of the core principles of generative
    AI and navigate through the capabilities and limitations of these technologies,
    which will set the stage for our subsequent exploration of the importance of pre-trained
    models. We will finish the chapter with a practical walkthrough of ZSL, using
    hands-on examples to illustrate the flexibility of this approach and how we can
    use it to generate marketing content. This will equip you with the skills to understand
    and leverage this technique to elevate your marketing strategies to new heights.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将深入讨论生成式人工智能的核心原则，并探讨这些技术的能力和局限性，这将为我们随后对预训练模型重要性的探索奠定基础。我们将以ZSL的实际操作演练结束本章，通过动手示例展示这种方法的优势以及我们如何利用它来生成营销内容。这将使你具备理解和利用这项技术，将你的营销策略提升到新高度的能力。
- en: 'By the end of the chapter, you will be well versed in:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将熟练掌握：
- en: The fundamentals of generative AI and its versatile applications in marketing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式人工智能的基础及其在市场营销中的多方面应用
- en: The principles of ZSL and its value in improving the efficiency of traditional
    content creation processes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ZSL的原则及其在提高传统内容创作流程效率中的价值
- en: Practical strategies and considerations when applying ZSL to create marketing
    copy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在应用ZSL创建营销文案时的实际策略和考虑因素
- en: Fundamentals of generative AI
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式人工智能的基础
- en: '**Generative AI** (**GenAI**) refers to a subset of AI capable of generating
    new content, be it text, images, videos, or even synthetic data, that mirrors
    real-world examples. Unlike traditional AI models, which are designed to interpret,
    classify, or predict data based on inputs, GenAI takes it a step further by creating
    new, previously unseen outputs. It does this by understanding and learning from
    existing data patterns to produce novel outputs that maintain a logical continuity
    with the input data.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成式人工智能**（**GenAI**）是指能够生成新内容的人工智能子集，无论是文本、图像、视频，甚至是反映现实世界示例的合成数据。与旨在根据输入解释、分类或预测数据的传统AI模型不同，GenAI更进一步，通过理解和学习现有数据模式来产生新的、以前未见过的输出。它通过理解并从现有数据模式中学习，以产生与输入数据保持逻辑连续性的新颖输出。'
- en: We were introduced to GenAI in *Chapter 1*, and we further touched upon it and
    its applications for sentiment analysis in *Chapter 5*. Before beginning our discussion
    of pre-trained models and ZSL, we will explore the fundamental technical considerations
    of GenAI, what it is (and is not), and why it’s so impactful for generating marketing
    content. While the focus of the hands-on examples in this chapter will involve
    text generation, important concepts that power GenAI’s capabilities in other applications
    such as images and video will also be discussed.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在**第一章**中介绍了GenAI，并在**第五章**中进一步探讨了它及其在情感分析中的应用。在开始我们关于预训练模型和ZSL的讨论之前，我们将探讨GenAI的基本技术考虑因素，它是什么（以及不是什么），以及为什么它对生成营销内容有如此大的影响。虽然本章的动手示例将涉及文本生成，但也将讨论支撑GenAI在其他应用（如图像和视频）中能力的重要概念。
- en: A probabilistic approach
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概率方法
- en: 'At the heart of GenAI is a probabilistic approach to modeling data distributions.
    This involves learning the underlying probability distribution of a dataset to
    generate new samples from that same distribution. A cornerstone of this approach
    is Bayesian inference, a principle that updates the probability of a hypothesis
    as more evidence or information becomes available. For instance, consider a simple
    equation that forms the mathematical foundation on which Bayesian inference is
    built, Bayes’ Theorem:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI 的核心是对数据分布的概率建模方法。这涉及到学习数据集的潜在概率分布，以从同一分布中生成新的样本。这种方法的一个基石是贝叶斯推理，这是一个随着更多证据或信息的出现而更新假设概率的原则。例如，考虑一个简单的方程，它是贝叶斯推理数学基础的基石，即贝叶斯定理：
- en: '![](img/B30999_09_001.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_09_001.png)'
- en: 'where:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '*P*(*A*∣*B*) is the posterior probability of hypothesis *A*, given the evidence
    *B*'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*A*∣*B*) 是在证据 *B* 下假设 *A* 的后验概率'
- en: '*P*(*B*∣*A*) is the likelihood of observing evidence *B*, given that hypothesis
    *A* is true'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*B*∣*A*) 是在假设 *A* 为真的情况下观察证据 *B* 的可能性'
- en: '*P*(*A*) is the prior probability of hypothesis *A*, or how likely we believe
    *A* to be true before seeing the evidence'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*A*) 是假设 *A* 的先验概率，或者在我们看到证据之前我们认为 *A* 为真的可能性'
- en: '*P*(*B*) is the probability of observing the evidence under all possible hypotheses'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*B*) 是在所有可能假设下观察证据 *B* 的概率'
- en: '**Bayes’ Theorem – a pillar of probabilistic reasoning**'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**贝叶斯定理 – 概率推理的支柱**'
- en: Bayes’ Theorem is not just a cornerstone of GenAI but also a fundamental principle
    across a wide range of disciplines, from statistics and computer science to philosophy
    and medicine. At its core, Bayes’ Theorem allows us to refine our hypotheses in
    light of new evidence, offering a rigorous mathematical approach to the concept
    of learning from experience.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 贝叶斯定理不仅是 GenAI 的基石，也是统计学、计算机科学、哲学和医学等多个学科的基本原则。在其核心，贝叶斯定理允许我们在新证据的背景下完善我们的假设，为从经验中学习这一概念提供了一种严谨的数学方法。
- en: When extending the principles of Bayesian inference and incorporating deep learning
    models such as **recurrent neural networks** (**RNNs**), **long short-term memory
    networks** (**LSTMs**), or transformers to the generation of sequences, we enter
    the realm of conditional probabilities. This sequence generation process can be
    viewed through the lens of predicting each element based on its predecessors,
    a concept foundational not just to video and audio but also to time series modeling
    and other forms of sequential data generation applications, including text.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当将贝叶斯推理的原则扩展并融入如**循环神经网络**（**RNNs**）、**长短期记忆网络**（**LSTMs**）或转换器等深度学习模型到序列生成中时，我们进入了条件概率的领域。这个序列生成过程可以通过预测每个元素基于其前驱元素的概念来观察，这一概念不仅对视频和音频至关重要，也对时间序列建模和其他形式的序列数据生成应用，包括文本，至关重要。
- en: Training GenAI models involves vast amounts of data, and in the case of text,
    these must be broken down into smaller units known as tokens. These tokens often
    consist of subword units or phrases, making the models more efficient in understanding
    and generating natural language. The process of tokenizing text is crucial because
    it allows a model to learn the probability distribution of different sequences
    of words or subwords.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 GenAI 模型需要大量的数据，在文本的情况下，这些数据必须被分解成更小的单元，称为标记。这些标记通常由子词单元或短语组成，这使得模型在理解和生成自然语言方面更加高效。文本标记化过程至关重要，因为它允许模型学习不同序列的单词或子词的概率分布。
- en: When we tokenize text, we break it down into manageable pieces that a model
    can process. Each token is then used as an input to the model during training.
    The model learns to predict the probability of the next token in a sequence, given
    the previous tokens. This probabilistic approach is where Bayesian principles
    come into play. By continuously updating the probability distribution of tokens
    as new data is introduced, the model becomes better at generating coherent and
    contextually relevant outputs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对文本进行标记化时，我们将其分解成模型可以处理的可管理部分。然后，每个标记在训练期间被用作模型的输入。模型学习预测序列中下一个标记的概率，给定之前的标记。这种概率方法正是贝叶斯原理发挥作用的地方。通过随着新数据的引入不断更新标记的概率分布，模型在生成连贯且上下文相关的输出方面变得更加出色。
- en: 'For example, in text generation, a model might predict the next word in a sentence
    based on the preceding words. This prediction process involves calculating the
    conditional probability:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_002.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: where *x*[t] represents the token at time *t* and *P*(*x*[t]∣*x*[1],*x*[2],…,*x*[t-1])
    denotes the probability of generating *x*[t], given the sequence of all preceding
    tokens.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of video and audio generation, leveraging deep learning models
    informed by Bayesian principles helps in understanding and predicting temporal
    progression. Each frame or audio sample at time *t*(*x*[t])is predicated on the
    sequence of all previous frames or samples (*x*[1],*x*[2],…,*x*[t-1]). Mathematically,
    this relationship is captured by the previous equation:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: where *x*[t] represents the frame or audio sample at time *t* and ![](img/B30999_09_004.png)
    denotes the probability of generating *x*[t], given the sequence of all preceding
    samples.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '**Source code and data**:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.9](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.9)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Foundational models
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several important foundational models in GenAI, each contributing
    uniquely to applications in image, text, and sequence generation. This section
    will cover some of the most important and widely used cases, such as:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '**Generative adversarial networks** (**GANs**)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variational autoencoders** (**VAEs**)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Long short-term memory networks** (**LSTMs**)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformer-based models like the **Generative Pre-Trained Transformer** (**GPT**)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While comprehensive implementation examples and theory for each of these models
    are outside the scope of this chapter, we will discuss the core concepts for each
    model type, as well as provide simplified, illustrative examples of their architectures,
    in order to understand the importance of these models for marketing applications.
    In *Chapter 12*, we will extend our discussion to mention further model advances
    that have garnered more recent attention for their promise in advancing the field
    of GenAI.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '**Exploring ML models with Google Colab notebooks**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 'Training your own state-of-the-art ML model can be computationally expensive.
    However, using Google Colab notebooks, you can train and tweak models without
    any setup on your own machine. The following are links to get started:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '**GANs** forhigh-quality image generation: [https://colab.research.google.com/drive/1uwPlY-4P_6fJ59SFRtgZLebVGgwGrUQu](https://colab.research.google.com/drive/1uwPlY-4P_6fJ59SFRtgZLebVGgwGrUQu
    )'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**VAEs** for image reconstruction: [https://colab.research.google.com/github/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb](https://colab.research.google.com/github/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb
    )'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GPTs** for language processing: [https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing](https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing
    )'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LSTMs** for time series forecasting: [https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_recurrent-modern/lstm.ipynb](https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_recurrent-modern/lstm.ipynb)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative adversarial networks
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'GANs have found applications across a wide range of domains, from image generation
    and style transfer to data augmentation and beyond. They are particularly impactful
    in applications where realistic image generation is crucial, and they have been
    used by NVIDIA and Adobe in their photo editing software to generate and modify
    images. Their applications include the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**Content creation**: GANs can generate high-quality, realistic images, artwork,
    and videos, enabling new forms of creative content production'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image-to-image translation**: Applications like photo enhancement, photo-realistic
    rendering from sketches, and domain adaptation, such as day-to-night and summer-to-winter
    transformations, leverage GANs to transform images from one domain to another
    while preserving contextual details'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'At their core, GANs consist of two neural networks that are trained simultaneously
    through a competitive process:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: The generator (*G*) aims to generate data that is indistinguishable from real
    data
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The discriminator (*D*) aims to accurately classify data as real or generated
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This can be illustrated by the following figure:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a generator  Description automatically generated](img/B30999_09_01.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: GAN workflow'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: The objective function for a GAN encapsulates the training dynamics between
    the generator and discriminator, creating a dynamic where both models improve
    in response to each other’s performance. This is similar to a two-player game
    where each player’s success is based on outsmarting their opponent. The game,
    in GAN’s case, reaches equilibrium when the generator produces perfect replicas
    of the real data, making it impossible for the discriminator to distinguish real
    from fake, which ideally results in a `0.5` probability of guessing correctly
    by the discriminator.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: For GANs to be highly effective at tasks such as high-resolution image generation,
    both the generator and discriminator architectures must be carefully designed.
    This can involve incorporating advanced architectures that are effective at handling
    spatial hierarchy data, such as **convolutional neural networks** (**CNNs**).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '**What are CNNs?**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: CNNs are a cornerstone of machine learning for processing spatial data, such
    as images. They identify patterns using convolutional filters, excelling in tasks
    that require an understanding of spatial hierarchies. This makes CNNs indispensable
    in many GAN applications for image generation and recognition.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: In image-based GAN applications, the generator uses techniques to expand latent
    representations into detailed images, while the discriminator applies methods
    to reduce the dimensionality of the input image to assess its authenticity efficiently.
    The latent dimension, serving as the seed to generate new data instances, is a
    compact, high-dimensional space, encapsulating potential data variations in a
    compressed format.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于图像的GAN应用中，生成器使用技术将潜在表示扩展到详细图像，而判别器则应用方法降低输入图像的维度以高效地评估其真实性。潜在维度，作为生成新数据实例的种子，是一个紧凑的高维空间，以压缩格式封装潜在的数据变化。
- en: 'The following code shows the process for building the core structure of a simplified
    GAN for images, using Python, with the key steps described here:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了使用Python构建简化GAN图像核心结构的流程，其中关键步骤在此描述：
- en: 'Import the libraries needed to build the generator and discriminator:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入构建生成器和判别器所需的库：
- en: '[PRE0]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Define the generator model, which takes a latent space vector and produces
    a 28x28 image through a series of dense layers:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义生成器模型，它接受一个潜在空间向量并通过一系列密集层生成一个28x28的图像：
- en: '[PRE1]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Define the discriminator model, which takes an image and classifies it as real
    or generated through a series of dense layers:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义判别器模型，它接受一个图像并通过一系列密集层将其分类为真实或生成：
- en: '[PRE2]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Further technical considerations are necessary to address common challenges,
    such as limited output diversity and ensuring that the generated data is varied
    while still closely mirroring the real data distribution. These considerations
    include the choice of the activation function (`relu` for non-linear transformations),
    techniques to ensure consistent input distribution across layers, and strategies
    such as randomly omitting units during training to prevent overfitting.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决常见的挑战，如输出多样性有限和确保生成数据在保持与真实数据分布紧密相似的同时具有多样性，需要进一步的技术考虑。这些考虑包括激活函数（用于非线性变换的`relu`）的选择、确保层间输入分布一致的技术，以及如训练期间随机省略单元以防止过拟合的策略。
- en: 'For more details on this, you can refer to the recent paper on GANs: [https://www.researchgate.net/publication/380573076_Understanding_GANs_fundamentals_variants_training_challenges_applications_and_open_problems](https://www.researchgate.net/publication/380573076_Understanding_GANs_fundamentals_variants_training_challenges_applications_and_open_problems).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于这方面的细节，您可以参考关于GANs的最新论文：[https://www.researchgate.net/publication/380573076_Understanding_GANs_fundamentals_variants_training_challenges_applications_and_open_problems](https://www.researchgate.net/publication/380573076_Understanding_GANs_fundamentals_variants_training_challenges_applications_and_open_problems)。
- en: Variational autoencoders
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 变分自编码器
- en: 'VAEs present a different approach to generative modeling as compared to GANs.
    VAEs offer a probabilistic way of learning latent representations of data and
    consist of two main components:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 与GANs相比，VAEs（变分自编码器）在生成建模方面提出了不同的方法。VAEs提供了一种概率学习数据潜在表示的方法，并包含两个主要组件：
- en: The encoder compresses input data into a latent space representation
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器将输入数据压缩到潜在空间表示
- en: The decoder reconstructs the data from this latent space
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解码器从该潜在空间重建数据
- en: Unlike traditional autoencoders, VAEs introduce a probabilistic twist where,
    rather than encoding input as a single point, they encode it as a distribution
    over the latent space.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的自动编码器不同，VAEs引入了一种概率转折，即它们不是将输入编码为单个点，而是将其编码为潜在空间上的分布。
- en: '**The versatile applications of VAEs**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**VAEs的多用途应用**'
- en: VAEs are instrumental in understanding and modeling complex distributions of
    data. One key area where VAEs excel is in data imputation, where they can predict
    missing information or forecast future trends in time-series data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: VAEs在理解和建模复杂数据分布方面发挥着重要作用。VAEs表现优异的关键领域之一是数据插补，其中它们可以预测缺失信息或预测时间序列数据的未来趋势。
- en: The loss function for VAEs combines reconstruction loss with the **Kullback-Leibler**
    (**KL**) divergence between the learned latent variable distribution and the prior
    distribution. The reconstruction loss measures how well the generated outputs
    match the original inputs, ensuring that a model creates accurate reproductions
    of the data, and the KL divergence acts as a form of regularization during training
    that ensures the model learns efficient and meaningful data representations. This
    regularization prevents the model from overfitting by encouraging it to generate
    outputs that are not just accurate but also generalize well to new, unseen data.
    By combining these two components, the VAE learns to produce high-quality, diverse
    outputs and encourages the model to learn efficient encodings of the data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: VAE（变分自编码器）的损失函数结合了重建损失与学习到的潜在变量分布与先验分布之间的**Kullback-Leibler**（KL）散度。重建损失衡量生成的输出与原始输入匹配的程度，确保模型能够创建准确的数据复制品，而KL散度在训练期间充当正则化形式，确保模型学习到高效且有意义的数据表示。这种正则化通过鼓励模型生成不仅准确而且对新、未见数据具有良好泛化能力的输出，防止模型过拟合。通过结合这两个组件，VAE学习生成高质量、多样化的输出，并鼓励模型学习数据的有效编码。
- en: 'The following is a simplified example of constructing a VAE using Keras:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个使用Keras构建VAE的简化示例：
- en: 'We will use a flattened 28x28 image input as another example, and we will first
    sample from the latent distribution in the `sampling()` function:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用一个28x28的扁平图像输入作为另一个示例，我们首先在`sampling()`函数中从潜在分布中采样：
- en: '[PRE3]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We then use the encoder to map the inputs into latent space:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们随后使用编码器将输入映射到潜在空间：
- en: '[PRE4]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We then use the decoder to reconstruct the image from the latent space:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们随后使用解码器从潜在空间重建图像：
- en: '[PRE5]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For the effective application of VAEs, selecting the right architecture for
    the encoder and decoder is crucial, often involving densely connected layers for
    basic tasks or more sophisticated structures, like CNNs, for image data. The dimensionality
    of the latent space is also vital – it must be large enough to capture relevant
    data variations but not so large that it leads to overfitting or meaningless reconstructions.
    When designed correctly, VAEs offer a principled approach to generative modeling,
    balancing the need for accurate data reconstruction with the flexibility to generate
    new, diverse samples from learned data distributions.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于VAE的有效应用，选择合适的编码器和解码器架构至关重要，通常涉及密集连接层进行基本任务，或更复杂的结构，如CNN（卷积神经网络）进行图像数据。潜在空间的空间维度也非常关键——它必须足够大以捕捉相关的数据变化，但不能太大以至于导致过拟合或无意义的重建。当设计正确时，VAE提供了一种原则性的生成建模方法，在准确数据重建的需求与从学习到的数据分布生成新、多样化样本的灵活性之间取得平衡。
- en: Long short-term memory networks
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 长短期记忆网络
- en: LSTMs are a specialized type of RNN designed to learn long-term dependencies
    in sequential data. RNNs are a class of neural networks that include loops, allowing
    information to persist by passing it from one step of the network to the next.
    This looping mechanism makes RNNs suitable for processing sequences of data such
    as time series or text. However, standard RNNs often struggle with learning long-range
    dependencies, due to issues like vanishing and exploding gradients. This occurs
    because, during backpropagation, gradients can become exponentially small (vanish)
    or large (explode), making it difficult to update the network weights effectively.
    LSTMs address these challenges with a more complex internal structure that allows
    them to remember information for longer periods effectively.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM是一种专门设计的RNN（循环神经网络），用于学习序列数据中的长期依赖关系。RNN是一类包含循环的神经网络，允许信息通过将信息从一个网络步骤传递到下一个步骤来持续存在。这种循环机制使RNN适合处理时间序列或文本等数据序列。然而，标准RNN由于梯度消失和梯度爆炸等问题，在学习长期依赖关系时往往遇到困难。这是因为，在反向传播过程中，梯度可能变得非常小（消失）或非常大（爆炸），这使得有效地更新网络权重变得困难。LSTM通过一个更复杂的内部结构来解决这些挑战，使其能够有效地记住信息更长时间。
- en: 'The defining feature of LSTMs that enables them to remember information more
    effectively is their cell state, along with three types of gates: input, output,
    and forget gates. These components work together to regulate the flow of information,
    allowing a network to remember important information over long periods and to
    forget irrelevant data.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM（长短期记忆网络）的显著特征是它们能够更有效地记住信息，这得益于它们的细胞状态以及三种类型的门：输入门、输出门和遗忘门。这些组件共同工作，调节信息的流动，使网络能够在长时间内记住重要信息，并忘记无关数据。
- en: '**Key components of an LSTM**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**LSTM的关键组件**'
- en: 'Core to the LSTM are its cell state and gates with the following functions:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM的核心是其细胞状态和具有以下功能的门：
- en: '**Input gate**: How much new information to store in the cell state'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入门**：决定在细胞状态中存储多少新信息'
- en: '**Forget gate**: What information is discarded from the cell state'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遗忘门**：从细胞状态中丢弃哪些信息'
- en: '**Output gate**: The output of the cell state to the next layer'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出门**：细胞状态输出到下一层'
- en: 'The following code sets up a simple LSTM network for time-series prediction
    that could be used to predict the next day’s sales, based on different features
    from the previous day. In this architecture, we allow for 10 days to be captured
    by `sequence_length` and then 5 features by `num_feature`, which could include
    data points such as web traffic or previous sales. The LSTM layer with 50 units
    learns to recognize patterns in the sequence data, while the `Dense` layer outputs
    the prediction. Finally, the model is compiled with the Adam optimizer and mean
    squared error (`mse`) loss function, common choices for regression tasks:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码设置了一个简单的LSTM网络，用于时间序列预测，可用于根据前一天的不同特征预测第二天销售额。在这个架构中，我们允许`sequence_length`捕获10天的数据，然后通过`num_feature`捕获5个特征，这些特征可能包括如网站流量或之前的销售额等数据点。具有50个单位的LSTM层学习识别序列数据中的模式，而`Dense`层输出预测。最后，该模型使用Adam优化器和均方误差(`mse`)损失函数编译，这些是回归任务的常见选择：
- en: '[PRE6]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To demonstrate the training process, we can generate synthetic time-series
    data that mimics sales prediction data. The synthetic data includes a base sine
    wave with added noise, simulating daily patterns with random fluctuations:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示训练过程，我们可以生成模拟销售预测数据的合成时间序列数据。合成数据包括一个基本正弦波和添加的噪声，模拟具有随机波动的每日模式：
- en: '[PRE7]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After training, we can evaluate the model on test data by comparing the predicted
    sales values with the actual values:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后，我们可以通过比较预测的销售额值与实际值来在测试数据上评估模型：
- en: '[PRE8]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The code produces the following plot, showing how a simple LSTM model with
    training can quickly provide useful predictions for metrics, such as sales, if
    given appropriate input features:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 代码生成了以下图表，展示了如何通过训练一个简单的LSTM模型，如果给定适当的输入特征，可以快速提供有用的预测，例如销售额：
- en: '![](img/B30999_09_02.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_09_02.png)'
- en: 'Figure 9.2: Output of an LSTM sales prediction model'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2：LSTM销售预测模型的输出
- en: Transformers
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Transformer**'
- en: Transformer-based models, such as the GPT series, have revolutionized natural
    language processing by introducing a model architecture that excels in capturing
    context and relationships within data. The core innovation of transformer models
    is the attention mechanism, which enables a model to weigh the importance of different
    parts of the input data differently. This mechanism allows GPT and similar models
    to understand the context and generate text that is coherent and contextually
    relevant.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Transformer的模型，如GPT系列，通过引入一个在捕捉数据中的上下文和关系方面表现卓越的模型架构，彻底改变了自然语言处理。Transformer模型的核心创新是注意力机制，它使模型能够根据输入数据的不同部分以不同的方式权衡其重要性。这种机制允许GPT和类似模型理解上下文并生成连贯且上下文相关的文本。
- en: 'GPT models leverage the transformer architecture for generative tasks, trained
    on vast amounts of text data to understand language patterns, grammar, and context.
    This pre-training enables GPT models to generate text that is highly coherent
    and contextually relevant to the input prompts. While building a GPT from scratch
    is a formidable task, at the conceptual level, there are some key components within
    a GPT architecture:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: GPT模型利用Transformer架构进行生成任务，在大量文本数据上进行训练以理解语言模式、语法和上下文。这种预训练使GPT模型能够根据输入提示生成高度连贯且上下文相关的文本。虽然从头开始构建GPT是一个艰巨的任务，但在概念层面上，GPT架构中存在一些关键组件：
- en: '**Embedding layer**: Converts token indices to dense vectors of fixed size'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入层**：将标记索引转换为固定大小的密集向量'
- en: '**Multi-head attention**: Allows a model to focus on different parts of the
    input sequence simultaneously, capturing various contextual relationships'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多头注意力**：允许模型同时关注输入序列的不同部分，捕捉各种上下文关系'
- en: '**Layer normalization and residual connections**: Help stabilize and optimize
    the training process, ensuring that gradients flow smoothly throughout a network'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层归一化和残差连接**：有助于稳定和优化训练过程，确保梯度在整个网络中顺畅流动'
- en: 'The following code shows how a simplified GPT-like architecture can be created
    using Keras with the aforementioned components:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何使用Keras和上述组件创建一个简化的类似GPT的架构：
- en: '[PRE9]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**The power of self-attention in GPT**'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**GPT中自注意力的力量**'
- en: Self-attention, the key innovation behind GPT models, allows a network to weigh
    the importance of different words in a sentence, enhancing its understanding of
    context and relationships between words.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 自注意力是GPT模型背后的关键创新，它允许网络权衡句子中不同单词的重要性，增强其对上下文和单词之间关系的理解。
- en: To learn more, check out the paper *Attention Is All You Need* by Illia Polosukhin
    et al. ([https://arxiv.org/pdf/1706.03762](https://arxiv.org/pdf/1706.03762)).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多信息，请参阅Illia Polosukhin等人撰写的论文《Attention Is All You Need》（[https://arxiv.org/pdf/1706.03762](https://arxiv.org/pdf/1706.03762)）。
- en: When GenAI is the right fit
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当GenAI是合适的选择时
- en: 'While GenAI brings new realms of possibility to content creation and digital
    marketing, understanding its limitations is also crucial. GenAI shines in environments
    that demand innovation, creativity, and the ability to scale personalized content
    dynamically. More generally, GenAI can be a great fitfor your marketing campaign
    in the following cases:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然GenAI为内容创作和数字营销带来了新的可能性，但了解其局限性同样重要。GenAI在需要创新、创造力和动态扩展个性化内容的环境下表现出色。更普遍地说，以下情况下，GenAI可以成为您营销活动的绝佳选择：
- en: '**Brainstorming for creative campaigns**: Generating unique and compelling
    content, be it text, image, or video, to facilitate brainstorming for creative
    marketing campaigns that stand out in a crowded digital landscape. For example,
    we will use GenAI to generate text for a new product launch in this chapter and
    *Chapter 10*.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创意活动的头脑风暴**：生成独特且引人入胜的内容，无论是文本、图像还是视频，以促进创意营销活动的头脑风暴，使其在拥挤的数字领域中脱颖而出。例如，我们将在本章和第10章中使用GenAI生成新产品发布文案。'
- en: '**Dynamic content personalization**: Enabling marketers to tailor content at
    scale while still addressing individual user preferences and behaviors, in order
    to increase engagement and conversion rates. For instance, we will show how GenAI
    combined with **retrieval-augmented generation** (**RAG**) can be used to create
    personalized recommendations and email content, based on individual browsing history
    and purchase behavior, in *Chapter 11*.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态内容个性化**：使营销人员能够大规模定制内容，同时仍然关注个别用户的偏好和行为，以提高参与度和转化率。例如，我们将在第11章中展示如何将GenAI与**检索增强生成**（**RAG**）相结合，根据个人的浏览历史和购买行为创建个性化的推荐和电子邮件内容。'
- en: '**Efficiency in content production**: Automating the content generation process,
    significantly reducing the time and resources needed to produce marketing materials.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容生产效率**：自动化内容生成过程，显著减少生产营销材料所需的时间和资源。'
- en: However, GenAI isn’t a one-size-fits-all solution, particularly in marketing
    scenarios where accuracy and deep contextual understanding are needed. For example,
    its application in highly regulated industries or in sensitive campaigns around
    social issues, where a misstep can significantly impact a brand’s reputation,
    must be done with caution. While GenAI can help with brainstorming in these cases,
    the unpredictability of GenAI content could pose significant risks if deployed
    without careful monitoring.Further discussion of this topic will be presented
    in *Chapter 13*, along with strategies to improve its contextual understanding
    in *Chapters 10* and *11*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，GenAI并非万能的解决方案，尤其是在需要准确性和深度上下文理解的营销场景中。例如，在高度监管的行业或围绕社会问题的敏感活动中，任何失误都可能对品牌声誉造成重大影响，因此必须谨慎行事。虽然GenAI可以帮助这些情况下的头脑风暴，但如果未经仔细监控就部署GenAI内容，其不可预测性可能会带来重大风险。关于这一主题的进一步讨论将在第13章中呈现，以及在第10章和第11章中介绍提高其上下文理解策略。
- en: '**GenAI in highly regulated industries**'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**GenAI在高度监管的行业中的应用**'
- en: When applying GenAI in sectors like healthcare, financial services, insurance,
    and legal services, adherence to stringent regulatory standards is crucial. Marketing
    content for these applications requires extra scrutiny, as they must not only
    be accurate and transparent but also align with industry-specific compliance measures.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当在医疗保健、金融服务、保险和法律服务等行业应用GenAI时，遵守严格的监管标准至关重要。这些应用的营销内容需要额外的审查，因为它们不仅需要准确和透明，还需要符合行业特定的合规措施。
- en: Introduction to pre-trained models and ZSL
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预训练模型和ZSL的介绍
- en: Building on the foundations of GenAI discussed in the chapter so far, we will
    now introduce some core concepts related to pre-trained models and **zero-shot
    learning** (**ZSL**). These concepts underly how models can take vast amounts
    of existing data to create realistic, new outputs for scenarios that have not
    yet been encountered, with little to no additional training. With a focus on text
    data, we will discuss how contextual embeddings and semantic proximity are two
    key concepts that facilitate this capability. With this knowledge, you will be
    equipped to understand and apply these concepts in this chapter and the ones to
    come.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Contextual embeddings
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Contextual embeddings, enabled by advancements such as the LSTM and GPT models
    discussed earlier, are fundamental to how **large language models** (**LLM**s)
    interpret and generate language. As discussed in *Chapter 5*, embeddings are dense
    vector representations of data that capture key features in a high-dimensional
    space. Early models like Word2Vec and GloVe generate static embeddings where the
    same word always has the same vector. In contrast, advanced models like BERT and
    GPT create contextual embeddings, where word representations change based on their
    usage in context. Effective NLP embeddings preserve the semantic relationships
    of the original data, meaning similar vectors are closer together in vector space.
    This adaptability is foundational for applications such as ZSL, which rely on
    a model’s ability to apply learned knowledge to new tasks without specific training
    data.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Earlier in the chapter in the exploration of GenAI’s probabilistic nature, we
    noted how text generation is analogous to sequence prediction in video or audio,
    in that the relevance of each piece of data depends on its predecessors. As an
    analogy, consider how Google’s auto-suggest feature adapts suggestions based on
    the context of the words already entered. This same concept underpins the transformative
    potential of models like BERT, which analyzes text from both preceding and subsequent
    contexts to enhance language comprehension and prediction accuracy, via their
    contextual embeddings.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: GPT models take it a step further and adopt an autoregressive framework. The
    term “autoregressive” means that a model makes predictions based on its own previous
    outputs, meaning that it anticipates the subsequent word based on all preceding
    outputs of the model as context. For example, when developing a content calendar
    for a marketing blog, a GPT model can analyze past articles and trending topics
    to suggest new posts that align with the brand’s voice and audience interests.
    This is unlike transformer-based models, which can look at both preceding and
    following words simultaneously, as discussed earlier in the chapter. However,
    such autoregressive models can offer more nuanced text generation, enabling them
    to create narratives with a level of coherence that bidirectional models may not
    achieve as seamlessly.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '**The importance of contextual embeddings**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Contextual embeddings from LSTM or GPT models allow for nuanced understanding
    by evaluating more of the text in its entirety.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in filling in the blank in “The stormy seas calmed as the ___
    sailed into the harbor,” a model leveraging both prior and subsequent context
    could infer “ship” with greater accuracy, whereas a more naive model with only
    prior context might inaccurately predict the word “day.”
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Semantic proximity
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Transitioning from our discussion on contextual embeddings and their critical
    role in language models, we will now explore **semantic proximity**. Contextual
    embeddings not only enhance the understanding of text by considering its dynamic
    contexts; they also serve as a fundamental tool in evaluating the semantic relationships
    between words or phrases within that text. This nuanced understanding is pivotal
    when we examine the concept of semantic proximity, which involves quantifying
    how closely related or distant two linguistic items are in meaning.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: For example, consider the phrases “limited-time offer” and “exclusive deal.”
    These phrases have close semantic proximity because they both relate to targeted
    promotions for potential customers. Conversely, the phrases “limited-time offer”
    and “customer feedback” would have a much larger semantic distance.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'Semantic proximity is effectively assessed through methods such as cosine similarity,
    which measures the angle between vectors representing these items in a high-dimensional
    space. This metric, rooted in the geometry of vector spaces, provides a clear,
    mathematical way to capture and compare the meanings encoded by embeddings. Mathematically,
    cosine similarity is given by:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_005.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
- en: where *A* and *B* are vectors (semantic embeddings for a word, phrase, document,
    etc), *A*⋅*B* denotes their dot product, and ∥*A*∥ and ∥*B*∥ represent their magnitudes.
    The value of cosine similarity ranges from -1 to 1\. A value of 1 implies that
    the vectors are identical in direction, indicating maximum similarity. A value
    of 0 implies that the vectors are orthogonal, indicating no similarity.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'While, in practice, many sophisticated text embeddings are high-dimensional
    and can range from hundreds to thousands of dimensions, we can more easily illustrate
    the concept of cosine similarity in 2D space via two vectors. In the following
    code, we illustrate the calculation of cosine similarity using vectors *A* and
    *B*, with the angle associated with their cosine similarity:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](img/B30999_09_03.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.3: Visualization of cosine similarity between two vectors, A and B,
    showing their angular relationship in 2D space'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing from the mathematical foundation of cosine similarity, we can apply
    this same concept to explore the polysemous nature of words in different contexts.
    Consider the word “light” used in two different sentences:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '*He turned on the* **light** *to read*.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '*The* **light** *fabric was perfect for summer*.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: These sentences demonstrate different semantic instances of the word “light,”
    and by employing contextual embedding models like BERT, we can quantify the semantic
    differences of “light” in these cases using cosine similarity.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, in the following code, we:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Import libraries and load the pre-trained BERT model and tokenizer.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tokenize the sentences, converting them into the format expected by the BERT
    model.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pass the tokenized sentences through the BERT model to obtain the embeddings.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract embeddings for the word “light” by finding the index of the word in
    each tokenized sentence and extracting its corresponding embedding from the model
    output.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute cosine similarity and print the result.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To do this, use the following code:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: A cosine similarity value ranges from -1 to 1\. As mentioned earlier, a value
    of 1 indicates identical vectors, while a value of 0 implies orthogonal vectors
    with no similarity. In this case, a cosine similarity of 0.48 suggests that the
    embeddings for “light” in the two sentences are somewhat similar but not identical.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Pre-trained models
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pre-trained models are machine learning algorithms that have been previously
    trained on large datasets to perform general tasks, such as understanding natural
    language or recognizing objects in images. The utility of pre-trained models is
    fundamentally rooted in their use of the embeddings they were trained on. For
    text, these embeddings not only enable models to grasp context dynamically but
    also serve as the foundation to adapt these models for specific tasks, such as
    sentiment analysis, as discussed in *Chapter 5*, with minimal to no additional
    training. This adaptability is critical for applications such as ZSL.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: The advent of pre-trained models democratized access to state-of-the-art AI
    by offering a base model that can be fine-tuned or used for inference directly.
    These models not only reduce the cost and time to deployment for AI-driven solutions
    but also the need for computational resources and energy consumption, making AI
    both more accessible and environmentally friendly. In the marketing domain, pre-trained
    models offer significant advantages. They enable marketers to quickly deploy advanced
    AI solutions for tasks such as personalized content creation, customer sentiment
    analysis, and targeted advertising.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Sophisticated AI models that were previously attainable only for large or highly
    specialized technology companies are now a possibility for smaller-sized businesses,
    and even individual consumers, at a fraction of the cost. For perspective, training
    a model such as GPT-3 from scratch was estimated to be in the millions of dollars
    at the time of its release in 2020, a figure that encapsulates computational costs
    and human expertise. Today, a user can perform inference to generate text using
    this same (or a more advanced) model through the company’s API, at the cost of
    a few cents for hundreds of words of content.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'The key components of a pre-trained model are:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '**Weights**: They represent the learned parameters from training datasets and
    encode a wide range of knowledge and patterns needed for transfer learning'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Architecture**: The model’s structure, detailing how inputs are processed
    through various layers to generate outputs'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pre-processing steps**: Procedures like tokenization and normalization to
    ensure data compatibility with the model’s training'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s look at these components in detail.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Model weights
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Model weights are at the core of neural networks, including pre-trained models.
    Weights are the refined parameters developed through extensive training to minimize
    loss, acting as a repository of a model’s learned knowledge. For instance, in
    language models like GPT, these weights capture the intricacies of language, such
    as grammar and context, enabling the generation of text that’s not only coherent
    but also contextually rich. The effectiveness of pre-trained models in tasks like
    ZSL stems from these weights, which enable you to generalize from the model’s
    training data to new, unseen data with remarkable accuracy.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand where the model weights come from, consider the case of
    an **artificial neural network** (**ANN**), as shown in the following figure:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_04.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.4: Example ANN architecture from Chapter 6'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'This consists of three main layers: the input layer, the hidden layer, and
    the output layer. During training, neural networks undergo forward and backward
    propagation. Forward propagation involves feeding data through a network to generate
    an output, while backward propagation adjusts weights based on the error of the
    predictions. Through these iterations, the network learns the optimal weights
    for each neuron, minimizing prediction error and enhancing a model’s performance.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Model architecture
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The architecture of a pre-trained model goes hand in hand with its weights.
    It delineates the structure of how data is processed and transformed across the
    model’s layers and also guides the adaptability of the model to perform novel
    tasks. For example, deeper language model architectures might be better suited
    for complex reasoning tasks, while models with specially configured attention
    mechanisms can offer finer control over the focus of the model during inference.
    For image recognition, the intermediate representations produced by these models,
    such as features extracted at various layers by a pre-trained CNN, can also serve
    as a valuable starting point for classification tasks.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'When understanding a machine learning model’s architecture, it can be helpful
    to plot it and its parameters to visualize its key aspects. Here, we illustrate
    this using Keras’s `plot_model()`, as a demonstration of a simple LSTM model composed
    of two LSTM layers:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](img/B30999_09_05.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.5: A simple LSTM-based neural network architecture'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'This visualization clearly delineates the model’s structure, showing the progression
    from input through two LSTM layers, each with 64 units (or neurons), to a final
    dense output layer configured with 10 softmax units for class prediction. Based
    on the labels given in the figure, the structure can be further broken down as
    follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '**Input layer (lstm_input)**: Takes in data with a shape of `(10, 128)`, processing
    sequences of 10 timesteps, each with 128 features'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**First LSTM layer (lstm)**: Contains 64 units and returns sequences, processing
    the input and passing on sequences of the same length to the next LSTM layer'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Second LSTM layer (lstm_1)**: Also has 64 units but does not return sequences,
    compressing the output from the first LSTM layer into a single vector'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dense output layer (dense)**: The final layer is a dense layer with 10 units
    and a softmax activation function, outputting a probability distribution over
    10 classes (categories or labels)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preprocessing steps
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Preprocessing steps are crucial for ensuring that data is compatible with a
    pre-trained model’s training procedure. Here are a couple of examples:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: NLP **tokenization** breaks down text into words or subwords that are consistent
    with what an LLM model expects
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For images, **normalization** can adjust image pixel values to a common scale
    to facilitate a model’s ability to learn from and generate predictions for data
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These preprocessing steps are essential for leveraging pre-trained models effectively,
    ensuring that input data mirrors the form of the data that the model was trained
    on.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot learning
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Following our exploration of pre-trained models and their fundamental components,
    we will now shift our focus to their application in ZSL. As we will discuss later,
    the fundamentals behind ZSL allow marketers to dynamically generate relevant content
    and even target their marketing campaigns to individual consumers in near real
    time. Before we get to those examples, this section will provide some background
    on ZSL and how it enables models to apply learned knowledge and infer information
    about tasks or classes that were not explicitly covered during their training.
    This capability extends the utility of pre-trained models, allowing them to generalize
    across unseen data and scenarios.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Mechanics of learning and prediction
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At its core, ZSL operates by using transformations and mappings of the input
    and output in a high-dimensional embedding space, using two primary functions:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'An **embedding function** *f*: ![](img/B30999_09_006.png) that transforms input
    – such as images or text – into feature vectors within the embedding space.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A **semantic attribute function** *g*: ![](img/B30999_09_007.png) that associates
    class labels with semantic attributes in the same embedding space. These attributes
    describe classes in terms of universal, distinguishable features, existing within
    an attribute space *A*.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As a simplified example, take a case where ZSL is applied to distinguish between
    animals. The embedding function *f*: ![](img/B30999_09_008.png) would transform
    visual images of the animal into high-dimensional feature vectors within the embedding
    space – for example, taking images of a sparrow and an eagle that are processed
    to show distinct feature vectors, representing their visual characteristics. Simultaneously,
    the semantic attribute function *g*: ![](img/B30999_09_009.png) maps class labels,
    like *sparrow* and *eagle*, to vectors in the same embedding space based on semantic
    attributes. Attributes for *sparrow* might include `[′small_size′, ′brown_color′,
    ′has_wings′]`, whereas *eagle* could be characterized by `[′large_size′, ′sharp_beak′,
    ′has_wings′]`. These attributes are then quantified, where `small_size` might
    be encoded as `0.2` on a size scale, and `large_size` as `0.8`.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_06.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.6: Example mappings from an input image or class label to an embedding
    space'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: By placing both images and class attributes within the same embedding space,
    as shown in *Figure 9.6*, a model can match an image’s feature vector to the closest
    class attribute vector. This matching is facilitated even if the model has never
    seen an image of a sparrow or eagle during training, by recognizing the overlap
    in their attributes with those of known classes. To find the best class match,
    the algorithm is tasked with the optimization of a compatibility function, which
    quantifies the match between an input’s feature vector and a class’s attribute
    vector. The ZSL prediction then involves selecting the class that maximizes compatibility
    for an unseen instance.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Output parameters
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are a number of key parameters that can be specified to influence the
    output of ZSL models. These parameters tailor the output by adjusting the behavior
    of the model during the sampling process. Three of the most common ones used in
    the context of text generation with models like GPT include:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Temperature
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Top P (nucleus sampling)
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequency penalty
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By influencing how the model’s outputs are sampled from the probability distribution
    generated by the compatibility function, each of these parameters allows adjustments
    in the creativity, coherence, and diversity of the model’s outputs. The following
    sections provide further detail on the theory underlying each of these parameters.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Temperature
  id: totrans-200
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The temperature parameter plays a crucial role in determining the level of
    randomness or confidence in the prediction distribution. Mathematically, adjusting
    the temperature modifies the `softmax` function used to calculate the probabilities
    of the next word in the following manner:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_010.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
- en: where *T* is the temperature and logit represents the raw outputs from the model.
    A lower temperature sharpens the distribution, making the model’s predictions
    more deterministic and less varied, whereas a higher temperature flattens the
    distribution, encouraging diversity in the predictions at the cost of potentially
    introducing less coherence, as the model becomes more likely to sample less probable
    words.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the concept, let’s consider a predictive text generation scenario
    of the next word in the sentence “`The cat sat on the ___.`" For simplicity, assume
    our model considers five possible completions: “`mat`,” “`tree`,” “`ball`,” “`bed`,”
    and “`tabl`e,” with the initial logits reflecting their probabilities (assigned
    manually in this case for simplicity). We can use the following code to produce
    a visualization, demonstrating how changing the temperature parameter *T* affects
    the `softmax` function, altering the probability distribution of these potential
    next words:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This gives us the following output:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_07.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.7: Visualization of the impact of the temperature parameter on softmax
    probability distributions for potential next words in the sentence “The cat sat
    on the ___”'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: As illustrated in the graph, at lower temperatures the distribution is sharper,
    concentrating the probability mass on fewer, more likely outcomes, like “`bed`.”
    As the temperature increases, the distribution becomes flatter, giving a higher
    probability to a broader set of potentially less likely word outcomes, such as
    `table` or `mat`.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Top P
  id: totrans-210
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Top P, or **nucleus sampling**, offers a dynamic way to focus the generation
    process on the most plausible set of outcomes. Instead of considering the entire
    vocabulary, the model limits its choices to the smallest set of words whose cumulative
    probability exceeds the threshold P.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach can be thought of as dynamically adjusting the breadth of consideration
    based on the model’s confidence, according to the formula:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_011.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
- en: where *N* is the number of words considered and *P*(*w*[i]) is the probability
    of the *i*^(th) word. This technique helps maintain a balance between variety
    and relevance, ensuring that the generated text remains plausible without being
    overly constrained by the most likely predictions.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Frequency penalty
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The **frequency penalty** addresses the tendency of models to repeat the same
    words or phrases, enhancing the diversity of the output. It modifies the probability
    of each word based on its previous occurrences in the generated text:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B30999_09_012.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
- en: where *P*(*w*[i]) is the original probability of the word *w*[i] and *Occurrence*
    (*w*[i]) is the number of times *w*[i] has appeared in the text so far. This adjustment
    encourages the exploration of new vocabulary and ideas by penalizing words that
    the model has already used, promoting a richer and more varied output.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: ZSL for marketing copy
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now discuss the practical application of ZSL through the example of
    an e-commerce brand that is launching new lines of eco-friendly kitchenware and
    fashion products. Traditionally, creating compelling product descriptions and
    promotional content could require significant research and creative effort from
    writers familiar with a brand’s tone and the intricacies of sustainable design.
    However, with ZSL, the brand can input a concise description of the product line,
    emphasizing keywords like “sustainable” and “eco-friendly activewear,” into a
    pre-trained model, immediately producing an output of brand-appropriate content
    that is ready for consideration across digital platforms. By automating these
    initial stages of content generation, the brand can now focus more on higher value
    efforts like strategy, engagement, and analyzing the effectiveness of its marketing
    efforts.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, to integrate ZSL effectively into your marketing strategy, consider
    the following iterative process as a template:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Define your content goals and the key messages you want to communicate.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create concise prompts that encapsulate these goals and messages, incorporating
    relevant keywords and themes.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Experiment with different parameters (`temperature`, `Top P`, and `frequency
    penalty`) to adjust the style and diversity of the generated content.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate multiple content variations to explore different angles and ideas.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review and refine the output, selecting the best options that align with your
    brand’s tone and objectives.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the generated content as a starting point for further customization and
    optimization, based on audience feedback and performance metrics.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following subsections, we will focus on steps 1–4 of the preceding workflow,
    with steps 5 and 6 covered by examples in the chapters that will follow.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Preparing for ZSL in Python
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To demonstrate the Python setup process for ZSL, this section will walk through
    the basic steps of using both freely available, open-source models, as well as
    more advanced models requiring paid API-based implementations. We will demonstrate
    the former with models available in the Hugging Face Transformers library, and
    we will demonstrate the setup for the latter using OpenAI’s API service.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '**Staying ahead with Hugging Face updates**'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Hugging Face’s Transformers library frequently updates, making advanced models
    that were previously behind paid API services freely available. For the latest
    Hugging Face models available, consult their documentation at `https://huggingface.co/models`.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic setup for ZSL tasks using the gpt2 model available on Hugging Face
    is:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Running this prompt results in an output such as the following:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can contrast this with the output that is returned from a model with the
    same parameters but using the more advanced text generation capabilities of OpenAI’s
    GPT-4\. Executing this model currently requires the creation of an OpenAI account
    and then generating an API key that can be substituted in the following code:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This results in a response such as:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: It’s evident from these two responses that advanced models like GPT-4 significantly
    enhance the relevancy and quality of the generated content. This is because, compared
    to GPT-2, GPT-4 incorporates major advancements in deep learning architectures,
    larger training datasets, and more sophisticated fine-tuning techniques. For this
    reason, we will use results obtained from GPT-4 for the remainder of this chapter.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: However, the key to leveraging ZSL effectively lies not just in a model’s capabilities
    but also in effectively choosing the input information that shapes the output.
    The most critical aspects here include creating an effective prompt, as well as
    setting other parameters such as temperature and Top P, as discussed earlier in
    the chapter.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '**Use the outputs of LLMs with caution**'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Relying directly on the output of any LLM for critical campaign content without
    human review can be risky! Always consider treating the initial outputs of GenAI
    models as a creative starting point, and then iterate and refine them as needed
    to ensure alignment with your brand’s voice and objectives.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Creating an effective prompt
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating an effective prompt is the most crucial step in leveraging ZSL for
    marketing copy. In ZSL, the prompt effectively becomes the instruction manual
    for a model, telling it what kind of content to generate, as well as its style,
    tone, and substance.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some guidelines around how to formulate prompts that will
    elicit the best possible marketing copy content from the model:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '**Clarity**: Ensure that your prompt is specific about what you want, whether
    it’s a product description, headline, or call to action.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Contextual**: Provide sufficient background to guide a model. For eco-friendly
    products, mention key selling points like sustainability or biodegradability.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Creative**: While clarity is crucial, leaving room for creativity can yield
    surprising and innovative results. Phrases like “Imagine...” or “Create a story
    where...” can be particularly powerful.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Concise**: Lengthy prompts can dilute the focus. Aim for brevity while including
    essential details, ensuring that a model stays on topic.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following sections, we will illustrate the impact of prompt quality
    through examples, with different types of marketing copy. While good prompts elicit
    detailed, relevant, and engaging content, poor prompts can lead to vague and uninspiring
    outputs. To generate these responses, we will define the following function:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This function will be used with different prompt types in the examples that
    follow.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: 'Example 1: Product descriptions'
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this example, we will generate product descriptions for our e-commerce brand,
    which is launching new lines of eco-friendly kitchenware.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a poor prompt:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This produces:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, let’s look at the following example of a good prompt:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This prompt produces the following output:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: From a marketing perspective, this example demonstrates the significance of
    creating detailed and audience-specific prompts with clear requirements when using
    ZSL for product descriptions, as well as how this leads to more specificity in
    the generated response. However, it is worth noting that older consumers may value
    more straightforward, factual information and, therefore, may favor the more generic
    prompt’s response from an engagement standpoint. Tailoring GenAI outputs at the
    level of the individual consumer can be crucial as well and is a topic discussed
    in *Chapter 11*.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: 'Example 2: Blog post titles'
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In our next example, we will focus on another type of marketing copy by generating
    blog post titles for our e-commerce brand.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll start by generating a poor prompt:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This produces the following:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here’s an example of a good prompt:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This gives us a more engaging result:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Comparing these prompts for blog post titles illustrates the impact of specificity
    and audience targeting on content effectiveness, where a specific prompt highlighting
    biodegradable kitchenware creates content aligned more with sustainability. In
    contrast, a vague prompt results in a generic title that would fail to differentiate
    itself amid a sea of similar content. To tailor the language produced by LLMs
    even further, we can also use **few-shot learning** (**FSL**), the topic of the
    next chapter. Used effectively, FSL can achieve the same specificity in language
    but in a way that’s aligned with a brand’s unique voice, in order to distinguish
    LLM outputs from what other LLMs might produce, even when given the same prompt.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '**Navigating topical content with AI**'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: When generating blog posts, understanding your model’s training data recency
    is crucial. Without current data or web search capabilities, you risk creating
    content based on outdated trends that lack the necessary context for relevant
    outputs.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: 'Example 3: Social media captions'
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this example, we will generate an Instagram caption for a post about our
    e-commerce brand.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a poor prompt first:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This yields the following:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, we will look at an example of a good prompt:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This produces:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The difference between these two prompts for Instagram captions illustrates
    how a specific prompt generates a caption that not only engages with its witty
    language but also directly appeals to eco-conscious consumers, likely increasing
    likes, shares, and comments – all crucial metrics on social platforms. In contrast,
    the vague prompt results in a generic and broad caption that, while informative,
    lacks a focused appeal and may fail to capture the attention of certain potential
    customers looking for eco-friendly products.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Impact of parameter tuning
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While creating an effective prompt lays the groundwork, fine-tuning the model’s
    parameters is equally essential to align the generated content with the desired
    marketing style. In this section, we will explore how adjusting parameters like
    temperature and Top P affect the output of a language model. Transitioning from
    kitchenware, we will demonstrate this by generating marketing slogans for an eco-friendly
    and sustainable fashion line launch.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: 'We will do this by defining the following Python function, outputting sets
    of three variants of the slogan for each alteration to one of these parameters:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let’s use the base case, with both `temperature` and `Top P` set to values
    of `1.0`:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This produces:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, let’s tweak each parameter and see the output that we get:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '**Temperature**: Increasing temperature makes responses more diverse and creative
    but potentially less coherent:'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This produces:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Conversely, lowering the temperature results in more predictable and consistent
    outputs:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'This time, the prompt produces the following output:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '**Top P**: Reducing `top_p` from its maximum value of 1.0 narrows the possible
    variety of generated slogans by making the model more conservative, as it tends
    to select only the most probable outputs:'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This produces:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Through these examples, we can observe the significant impact that parameter
    adjustments can have on the nature of generated content. This demonstrates the
    importance of parameter tuning in creating marketing slogans that are not only
    relevant and engaging but also tailored to the style and message of a brand.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we went on a journey through GenAI, and ZSL, and their transformative
    potential in marketing content creation. We introduced foundational GenAI concepts
    and discussed the mechanisms that allow these models to generate text, images,
    and more, with a particular focus on text generation. Analyzing contextual embeddings
    and semantic proximity highlighted the nuances that pre-trained models like GPT
    and BERT bring to understanding and generating language with remarkable adaptability
    and accuracy.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Central to our discussion was the application of ZSL in creating marketing copy,
    which allows brands to generate compelling content without the need for extensive
    training data. We outlined a strategic process to integrate ZSL into marketing
    strategies with the help of examples that emphasize the importance of creating
    clear, contextual, and creative prompts. This step-by-step approach – defining
    content goals, experimenting with parameters, and refining outputs – enables marketers
    to harness the power of LLMs effectively. We also learned how adjusting parameters
    such as temperature and Top P can help fine-tune the creativity, coherence, and
    diversity of the generated content. These practical insights will help you optimize
    marketing copy to align with brand messaging and campaign objectives.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Looking ahead, the next chapter progresses into the more advanced territories
    of few-shot and transfer learning. Building on the ZSL foundation, we will explore
    how these techniques can further refine GenAI models for on-target messaging.
    This involves adapting models to new contexts with minimal examples (FSL) and
    updating them with brand or customer-specific information (transfer learning),
    ensuring consistency and relevance in the generated content.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/genai](https://packt.link/genai)'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code12856128601808671.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
