- en: Working with Data in OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have whetted our appetite for machine learning, it is time to delve
    a little deeper into the different parts that make up a typical machine learning
    system.
  prefs: []
  type: TYPE_NORMAL
- en: Far too often, you hear someone throw around the phrase, *J**ust apply machine
    learning to your data!*, as if that will instantly solve all of your problems.
    You can imagine that the reality of this is much more intricate, although, I will
    admit that nowadays, it is incredibly easy to build your own machine learning
    system simply by cutting and pasting a few lines of code from the internet. However,
    to build a system that is truly powerful and effective, it is essential to have
    a firm grasp of the underlying concepts and an intimate knowledge of the strengths
    and weaknesses of each method. So, don't worry if you don't consider yourself
    a machine learning expert just yet. Good things take time.
  prefs: []
  type: TYPE_NORMAL
- en: Earlier, I described machine learning as a subfield of artificial intelligence.
    This might be true—mainly for historical reasons—but most often, machine learning
    is simply about making sense of data. Therefore, it might be more suitable to
    think of machine learning as a subfield of data science, where we build mathematical
    models to help us to understand data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, this chapter is all about data. We want to learn how data fits in with
    machine learning and how to work with data using the tools of our choice: OpenCV
    and Python.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the machine learning workflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding training data and test data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning how to load, store, edit, and visualize data with OpenCV and Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can refer to the code for this chapter from the following link: [https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter02](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter02).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a summary of the software and hardware requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: You will need OpenCV version 4.1.x (4.1.0 or 4.1.1 will both work just fine).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will need Python version 3.6 (any Python version 3.x will be fine).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will need Anaconda Python 3 for installing Python and the required modules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use any OS—macOS, Windows, and Linux-based OSes along with this book.
    We recommend you have at least 4 GB RAM in your system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You don't need to have a GPU to run the code provided along with this book.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the machine learning workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier, machine learning is all about building mathematical models
    to understand data. The learning aspect enters this process when we give a machine
    learning model the capability to adjust its **internal parameters**; we can tweak
    these parameters so that the model explains the data better. In a sense, this
    can be understood as the model learning from the data. Once the model has learned
    enough—whatever that means—we can ask it to explain newly observed data.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical classification process is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f30a037e-5be4-4b0f-ad02-06e546ea42f3.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's break it down step by step.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing to notice is that machine learning problems are always split
    into (at least) two distinct phases:'
  prefs: []
  type: TYPE_NORMAL
- en: A **training phase**, during which we aim to train a machine learning model
    on a set of data that we call the **training dataset**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A test phase, during which we evaluate the learned (or finalized) machine learning model on
    a new set of never-before-seen data that we call the **test dataset**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The importance of splitting our data into a training set and test set cannot
    be understated. We always evaluate our models on an independent test set because
    we are interested in knowing how well our models **generalize to new data**. In
    the end, isn''t this what learning is all about—be it machine learning or human
    learning? Think back to school, when you were a learner yourself: the problems
    you had to solve as part of your homework would never show up in exactly the same
    form in the final exam. The same scrutiny should be applied to a machine learning
    model; we are not so much interested in how well our models can memorize a set
    of data points (such as a homework problem), but we want to know how our models
    will use what they have learned to solve new problems (such as the ones that show up
    in a final exam) and explain new data points.'
  prefs: []
  type: TYPE_NORMAL
- en: The workflow of an advanced machine learning problem will typically include
    a third set of data termed a **validation dataset**. For now, this distinction
    is not important. A validation set is typically formed by further partitioning
    the training dataset. It is used in advanced concepts such as model selection,
    which we will talk about in [Chapter 11](904bc419-cb0e-44cd-ae3f-8ce97e15baa2.xhtml), *Selecting
    the Right Model with Hyperparameter Tuning*, when we have become proficient in
    building machine learning systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next thing to notice is that machine learning is really all about the **data**.
    Data enters the previously described workflow diagram in its raw form—whatever
    that means—and is used in both training and test phases. Data can be anything
    from images and movies to text documents and audio files. Therefore, in its raw
    form, data might be made of pixels, letters, words, or even worse: pure bits.
    It is easy to see that data in such a raw form might not be very convenient to
    work with. Instead, we have to find ways to **preprocess** the data to bring it
    into a form that is easy to **parse or use the data**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data preprocessing comes in two stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature selection**: This is the process of identifying important attributes (or
    features) in the data. Possible features of an image might be the location of
    edges, corners, or ridges. You might already be familiar with some more advanced
    feature descriptors that OpenCV provides, such as **Speeded Up Robust Features**
    (**SURF**) or the **Histogram of Oriented Gradients** (**HOG**). Although these
    features can be applied to any image, they might not be that important (or work
    that well) for our specific task. For example, if our task was to distinguish
    between clean and dirty water, the most important feature might turn out to be
    the color of the water, and the use of SURF or HOG features might not help us
    much.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature extraction**: This is the actual process of transforming the raw
    data into the desired **feature space**. An example would be the **Harris operator**,
    which allows us to extract corners (that is, a selected feature) in an image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A more advanced topic is the process of inventing informative features, which
    is known as **feature engineering**. After all, before people could select from
    popular features, someone had to invent them first. This is often more important
    for the success of our algorithm than the choice of the algorithm itself. We will
    talk about feature engineering extensively in [Chapter 4](142fec63-a847-4cde-9de9-c34805d2bb84.xhtml), *Representing
    Data and Engineering Features*.
  prefs: []
  type: TYPE_NORMAL
- en: Don't let naming **conventions** confuse you! Sometimes, feature selection and
    feature extraction are hard to distinguish, mainly because of how things are named.
    For example, SURF stands for both the feature extractor as well as the actual
    name of the features. The same is true for the **S****cale-Invariant Feature Transform**
    (**SIFT**), which is a feature extractor that yields what is known as **SIFT** **features**.
    Unfortunately, both the algorithms are patented and cannot be used for commercial
    purposes. We won't be sharing any code about either algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The last point to be made is that, in supervised learning, every data point
    must have a **label**. A label identifies a data point either of belonging to
    a certain class of things (such as cat or dog) or of having a certain value (such
    as the price of a house). At the end of the day, the goal of a supervised machine
    learning system is to predict the label of all data points in the test set (as
    shown in the previous diagram). We do this by learning regularities in the training
    data, using the labels that come with it, and then testing our performance on
    the test set.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, to build a functioning machine learning system, we first have to
    cover how to load, store, and manipulate data. How do you even do that in OpenCV
    with Python?
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with data using OpenCV and Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The world of data is full of various kinds of data types. This, at times, makes
    it very difficult for users to distinguish between the data type to use for a
    particular value. Here, we will try to keep it simple by treating everything as
    an array, except the scalar values, which will retain their standard data types.
    So, images will become 2D arrays because they have width and height. A 1D array
    could be a sound clip with intensity varying over time.
  prefs: []
  type: TYPE_NORMAL
- en: If you have mostly been using OpenCV's C++ **Application Programming Interface**
    (**API**) and plan on continuing to do so, you might find that dealing with data
    in C++ can be a bit of a pain. Not only will you have to deal with the syntactic
    overhead of the ...
  prefs: []
  type: TYPE_NORMAL
- en: Starting a new IPython or Jupyter session
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we can get our hands on NumPy, we need to open an IPython shell or start
    a Jupyter Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a Terminal as we did in the previous chapter and navigate to the `OpenCV-ML` directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Activate the `conda` environment we created in the previous chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Start a new IPython or Jupyter session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If you chose to start an IPython session, the program should have greeted you
    with a welcome message like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The line starting with `In [1]` is where you type in your regular Python commands.
    In addition, you can also use the *Tab* key while typing the names of variables
    and functions to have IPython automatically complete them.
  prefs: []
  type: TYPE_NORMAL
- en: A limited number of Unix and macOS system shell commands work too—such as `ls` and `pwd`.
    You can run any shell command by prefixing it with `!`, such as `!ping www.github.com`.
    For more information, check out the official IPython reference at [https://ipython.org/ipython-doc/3/interactive/tutorial.html](https://ipython.org/ipython-doc/3/interactive/tutorial.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you chose to start a Jupyter session, a new window should have opened in
    your web browser that is pointing to `http://localhost:8888`. You want to create
    a new notebook by clicking on New in the top-right corner and selecting Notebooks
    (Python 3):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9e67e509-0fd8-4871-bee8-3ef9963f27bf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This will open a new window that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8ed28073-144e-4935-929d-3b781ce55abd.png)'
  prefs: []
  type: TYPE_IMG
- en: The cell (which looks like the preceding textbox) labeled with `In [ ]` is the
    same as the command line in an IPython session. Now you can start typing your
    Python code!
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with data using Python's NumPy package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I am assuming that you already have NumPy installed in your virtual environment
    if you have installed Anaconda. If you have used Python's standard distribution
    or any other distribution, you can go to [http://www.numpy.org](http://www.numpy.org) and
    follow the installation instructions provided there.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, it's okay if you aren't a Python expert yet. Who knows,
    perhaps you're just now switching from OpenCV's C++ API. This is all fine. I wanted
    to give you a quick overview of how to get started with NumPy. If you are a more
    advanced Python user, you can simply skip this section.
  prefs: []
  type: TYPE_NORMAL
- en: Once you are familiar with NumPy, you will find that most scientific computing
    tools in the Python world are built around ...
  prefs: []
  type: TYPE_NORMAL
- en: Importing NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once you start a new IPython or Jupyter session, you can import the NumPy module
    and verify its version as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Recall that in the Jupyter Notebook, you can hit *Ctrl* + *Enter* to execute
    a cell once you have typed the command. Alternatively, *Shift* + *Enter* executes
    the cell and automatically inserts or selects the cell below it. Check out all
    of the keyboard shortcuts by clicking on Help | Keyboard Shortcut or take a quick
    tour by clicking on Help | User Interface Tour.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the parts of the package discussed here, I would recommend using NumPy
    version 1.8 or later. By convention, you''ll find that most people in the scientific
    Python world will import NumPy using `np` as an alias:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Throughout this chapter and the rest of this book, we will stick to the same
    convention.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding NumPy arrays
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You might already know that Python is a **weakly typed language**. This means
    that you do not have to specify a data type whenever you create a new variable.
    For example, the following will automatically be represented as an integer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can double-check this by typing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As the standard Python implementation is written in C, every Python object is
    basically a C structure in disguise. This is true even for integers in Python,
    which are actually pointers to compound C structures that contain more than just
    the **raw** integer value. Therefore, the default C data type used to represent
    Python integers will depend on your system architecture (that is, whether it is
    a 32-bit ...
  prefs: []
  type: TYPE_NORMAL
- en: Accessing single array elements by indexing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you have used Python''s standard list indexing before, then you won''t find many
    issues with indexing in NumPy. In a 1D array, the *i*^(th) value (counting from
    zero) can be accessed by specifying the desired index in square brackets, just
    as with Python lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'To index from the end of the array, you can use negative indices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a few other cool tricks for **slicing arrays**, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: I encourage you to play around with these arrays yourself!
  prefs: []
  type: TYPE_NORMAL
- en: The general form of slicing arrays in NumPy is the same as it is for standard
    Python lists. To access a slice of an array, `x`, use `x[start:stop:step]`. If
    any of these are unspecified, they default to the `start=0`, `stop=size of dimension`, `step=1` values.
  prefs: []
  type: TYPE_NORMAL
- en: Creating multidimensional arrays
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Arrays need not be limited to lists. In fact, they can have an arbitrary number
    of dimensions. In machine learning, we will often deal with at least 2D arrays,
    where the column index stands for the values of a particular feature and the rows
    contain the actual feature values.
  prefs: []
  type: TYPE_NORMAL
- en: 'With NumPy, it is easy to create multidimensional arrays from scratch. Let''s
    say that we want to create an array with three rows and five columns, with all
    of the elements initialized to zero. If we don''t specify a data type, NumPy will
    default to using floats:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As you probably know from your OpenCV days, this ...
  prefs: []
  type: TYPE_NORMAL
- en: Loading external datasets in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks to the SciPy community, there are many resources out there for getting
    our hands on some data.
  prefs: []
  type: TYPE_NORMAL
- en: 'A particularly useful resource comes in the form of the `sklearn.datasets` package
    of **scikit-learn**. This package comes preinstalled with some small datasets
    that do not require us to download any files from external websites. These datasets
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`load_boston`: The Boston dataset contains housing prices in different suburbs
    of Boston along with several interesting features such as per capita crime rate
    by town, proportion of residential land, and number of non-retail business'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`load_iris`: The Iris dataset contains three different types of Iris flowers
    (Setosa, Versicolor, and Virginica), along with four features describing the width
    and length of the sepals and petals'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`load_diabetes`: The diabetes dataset lets us classify patients as having diabetes
    or not, based on features such as patient age, sex, body mass index, average blood
    pressure, and six blood serum measurements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`load_digits`: The digits dataset contains 8 x 8 pixel images of the digits
    *0-9*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`load_linnerud`: The Linnerud dataset contains 3 physiological variables and
    3 exercise variables measured on 20 middle-aged men in a fitness club'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Also, scikit-learn allows us to download datasets directly from external repositories,
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`fetch_olivetti_faces`: The Olivetti faces dataset contains 10 different images
    each of 40 distinct subjects'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fetch_20newsgroups`: The 20 newsgroup dataset contains around 18,000 newsgroup
    posts on 20 topics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Even better, it is possible to download datasets directly from the machine
    learning database at [http://openml.org](http://mldata.org). For example, to download
    the Iris flower dataset, simply type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The Iris flower database contains a total of `150` samples with `4` features—sepal
    length, sepal width, petal length, and petal width. The data is divided into three
    classes—Iris Setosa, Iris Versicolour, and Iris Virginica. Data and labels are
    delivered in two separate containers, which we can inspect as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that `iris_data` contains `150` samples, each with `4` features
    (and that's why the number 4 is in the shape). Labels are stored in `iris_target`,
    where there is only one label per sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can further inspect the values of all targets, but we don''t just want to
    print them all. Instead, we are interested to see all distinct target values,
    which is easy to do with NumPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Another Python library for data analysis that you should have heard about is **pandas**
    ([http://pandas.pydata.org](http://pandas.pydata.org)). pandas implements several
    powerful data operations for both databases and spreadsheets. However great the
    library, at this point, pandas is a bit too advanced for our purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the data using Matplotlib
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Knowing how to load data is of limited use if we don't know how to look at the
    data. Thankfully, there is **Matplotlib**!
  prefs: []
  type: TYPE_NORMAL
- en: Matplotlib is a multiplatform data visualization library built on NumPy arrays—see,
    I promised you NumPy would show up again. It was conceived by John Hunter in 2002,
    originally designed as a patch to IPython to enable interactive MATLAB-style plotting
    from the command line. In more recent years, newer and shinier tools have popped
    up to eventually replace Matplotlib (such as `ggplot` and `ggvis` in the R language),
    but Matplotlib remains essential as a well-tested, cross-platform graphics engine.
  prefs: []
  type: TYPE_NORMAL
- en: Importing Matplotlib
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You might be in luck again: if you followed the advice outlined in the previous
    chapter and installed the Python Anaconda stack, you already have Matplotlib installed
    and are ready to go. Otherwise, you might want to visit [http://matplotlib.org](http://matplotlib.org/) for
    installation instructions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as we used the `np` shorthand for NumPy, we will use some standard shorthand
    for the Matplotlib imports:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The `plt` interface is what we will use most often, as we shall see throughout
    this book.
  prefs: []
  type: TYPE_NORMAL
- en: Producing a simple plot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Without further ado, let's create our first plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say that we want to produce a simple line plot of the sine function, `sin(x)`.
    We want the function to be evaluated at all points on the *x *axis where `0 <
    x < 10`. We will use NumPy''s `linspace` function to create a linear spacing on
    the *x* axis, from `x` values `0` to `10`, and a total of `100` sampling points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We can evaluate the `sin` function at all points, `x`, using NumPy''s `sin` function,
    and visualize the result by calling the `plot` function of `plt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Did you try it yourself? What happened? Did anything show up?
  prefs: []
  type: TYPE_NORMAL
- en: The thing is, depending on where you are running this script, you might not
    ...
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing data from an external dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a final test for this chapter, let's visualize some data from an external
    dataset, such as the `digits` dataset from scikit-learn.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will need three tools for visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: scikit-learn for the actual data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy for data processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matplotlib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, let''s start by importing all of these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The first step is to actually load the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If we remember correctly, `digits` is supposed to have two different fields:
    a `data` field containing the actual image data and a `target` field containing
    the image labels. Rather than trusting our memory, we should simply investigate
    the `digits` object. We do this by typing out its name, adding a period, and then
    hitting the *Tab* key: `digits.<TAB>`. This will reveal that the `digits` object
    also contains some other fields, such as one called `images`. The two fields, `images` and `data`,
    seem to simply differ by shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In both cases, the first dimension corresponds to the number of images in the
    dataset. However, `data` has all of the pixels lined up in one big vector, whereas `images` preserves
    the 8 x 8 spatial arrangement of each image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, if we wanted to plot a single image, the `images` field would be more
    appropriate. First, we grab a single image from the dataset using NumPy''s array
    slicing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are saying that we want to grab the first row in the 1,797-item-long
    array and all of the corresponding *8 x 8 = 64* pixels. We can then plot the image
    using the `imshow` function of `plt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command gives the following output. Note that the image is blurred
    because we have resized it to a larger size. The original image''s size is just
    8 x 8:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6a72066a-c69e-45d7-9756-b26d35d259a3.png)'
  prefs: []
  type: TYPE_IMG
- en: In addition, I also specified a colormap with the `cmap` argument. By default,
    Matplotlib uses MATLAB's default colormap **jet**. However, in the case of grayscale
    images, the **gray** colormap makes more sense.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can plot a whole number of digit samples using the `subplot` function
    of `plt`. The `subplot` function is the same as in MATLAB, where we specify the
    number of rows, number of columns, and current subplot index (starts counting
    at `1`). We will use a `for` loop to iterate over the first 10 images in the dataset
    and every image gets assigned its own subplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This leads to the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/30a0d81b-b5e2-49c8-8801-99dc8677959b.png)'
  prefs: []
  type: TYPE_IMG
- en: Another great resource for all sorts of datasets is the machine learning repository
    of my alma mater, the University of California, Irvine: [http://archive.ics.uci.edu/ml/index.php](http://archive.ics.uci.edu/ml/index.php).
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with data using OpenCV's TrainData container in C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the sake of completeness and for those who insist on using the C++ API of OpenCV,
    let's do a quick detour on OpenCV's `TrainData` container, which allows us to
    load numerical data from `.csv` files.
  prefs: []
  type: TYPE_NORMAL
- en: Among other things, in C++, the `ml` module contains a class called `TrainData`,
    which provides a container to work with data in C++. Its functionality is limited
    to reading (preferably) numerical data from `.csv` files (containing comma-separated
    values). Hence, if the data that you want to work with comes in a neatly organized `.csv` file,
    this class will save you a lot of time. If your data comes from a different source,
    I'm afraid your best option might be to create a `.csv` file by hand, using ...
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we talked about a typical workflow to deal with machine learning
    problems: how we can extract informative features from raw data, how we can use
    data and labels to train a machine learning model, and how we can use the finalized
    model to predict new data labels. We learned that it is essential to split data
    into a training set and test set, as this is the only way to know how well a model
    will generalize to new data points.'
  prefs: []
  type: TYPE_NORMAL
- en: On the software side of things, we significantly improved our Python skills.
    We learned how to use NumPy arrays to store and manipulate data and how to use
    Matplotlib for data visualization. We talked about scikit-learn and its many useful
    data resources. Finally, we also addressed OpenCV's own `TrainData` container,
    which provides some relief for users of OpenCV's C++ API.
  prefs: []
  type: TYPE_NORMAL
- en: With these tools in hand, we are now ready to implement our first real machine
    learning model! In the next chapter, we will focus on supervised learning and
    its two main problem categories, classification and regression.
  prefs: []
  type: TYPE_NORMAL
