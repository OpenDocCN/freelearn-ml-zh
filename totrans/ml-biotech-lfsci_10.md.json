["```py\nimport numpy as np\ndef sigmoid_function(x):\n    return 1 / (1 + np.exp(-x))\n```", "```py\nx1 = np.linspace(-10, 10, 100)\ny1 = [sigmoid_function(i) for i in x1]\nplt.plot(x1,y1)\n```", "```py\nx2 = np.linspace(-5, 5, 100)\ny2 = np.tanh(x2)\nplt.plot(x2, y2)\n```", "```py\ndef relu_function(x):\n    return np.array([0, x]).max()\nx3 = np.linspace(-5, 5, 100)\ny3 = [relu_function(i) for i in x3]\nplt.plot(x3, y3)\n```", "```py\ndef softmax_function(x):\n    ex = np.exp(x - np.max(x))\n    return ex / ex.sum()\nx4 = [1, 2, 3, 4, 5]\ny4 = softmax_function(x4)\nprint(y4)\n```", "```py\n    from sklearn.datasets import make_blobs\n    X, y = make_blobs(n_samples=2000, centers=2, n_features=4, random_state=1, cluster_std=5)\n    ```", "```py\n    from sklearn.preprocessing import MinMaxScaler\n    scalar = MinMaxScaler()\n    scalar.fit(X)\n    X_scaled = scalar.transform(X)\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)\n    ```", "```py\n    dfx_train = pd.DataFrame(X_train, columns=[\"Feature1\", \"Feature2\", \"Feature3\", \"Feature4\"])\n    dfx_train.head()\n    ```", "```py\n    sns.scatterplot(x=dfx_train.Feature1, y=dfx_train.Feature2, hue=y_train)\n    ```", "```py\n    from keras.models import Sequential\n    model = Sequential()\n    ```", "```py\n    from keras.layers import Dense\n    model.add(Dense(4, input_shape=(4,), activation='relu', name=\"DenseLayer1\")) \n    ```", "```py\n    model.summary()\n    ```", "```py\n    model.add(Dense(8, activation='relu', name=\"DenseLayer2\"))\n    ```", "```py\n    model.add(Dense(1, activation='sigmoid', name=\"DenseLayer3\"))\n    ```", "```py\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n    ```", "```py\n    history = model.fit(X_train, y_train, epochs=50, verbose=1, validation_split=0.2)\n    ```", "```py\n    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\").ravel()\n    from sklearn.metrics import classification_report\n    print(classification_report(y_pred, y_test))\n    ```", "```py\n    fig = plt.figure(figsize=(10,10))\n    # total_rows, total_columns, subplot_index(1st, 2nd, etc..)\n    plt.subplot(2, 2, 1)\n    plt.title(\"Accuracy\", fontsize=15)\n    plt.xlabel(\"Epochs\", fontsize=15)\n    plt.ylabel(\"Accuracy (%)\", fontsize=15)\n    plt.plot(history.history[\"val_accuracy\"], label='Validation Accuracy', linestyle='dashed')\n    plt.plot(history.history[\"accuracy\"], label='Training Accuracy')\n    plt.legend([\"Validation\", \"Training\"], loc=\"lower right\")\n    plt.subplot(2, 2, 2)\n    plt.title(\"Loss\", fontsize=15)\n    plt.xlabel(\"Epochs\", fontsize=15)\n    plt.ylabel(\"Loss\", fontsize=15)\n    plt.plot(history.history[\"val_loss\"], label='Validation loss', linestyle='dashed')\n    plt.plot(history.history[\"loss\"], label='Training loss')\n    plt.legend([\"Validation\", \"Training\"], loc=\"lower left\")\n    ```", "```py\nimport pandas as pd\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n```", "```py\nPATH = \"../../../datasets/dataset_pfam/\"\nfiles = []\nfor i in range(8):\n    df = pd.read_csv(PATH+f\"dataset_pfam_seq_sd{i+1}.csv\", index_col=None, header=0)\n    files.append(df)\n\ndf = pd.concat(files, axis=0, ignore_index=True)\ndf.shape\n```", "```py\ndf.isna().sum()\n```", "```py\ndf[\"family_accession\"].groupby(df[\"family_accession\"]).value_counts().nlargest(10)\n```", "```py\nsns.displot(df[\"sequence\"].apply(lambda x: len(x)), bins=75, height=4, aspect=2) \n```", "```py\ndf_filt = df.groupby(\"family_accession\").filter(lambda x: len(x) > 1200)\n```", "```py\ndf_bal = df_filt.groupby('family_accession').apply(lambda x: x.sample(1200))\n```", "```py\ndf_red = df_bal[[\"family_accession\", \"sequence\"]].reset_index(drop=True)\ndf_red.head()\n```", "```py\nnum_classes = len(df_red.family_accession.value_counts())\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test = train_test_split(df_red, test_size=0.25)\nX_val, X_test = train_test_split(X_test, test_size=0.50)\n```", "```py\naa_seq_dict = {'A': 1,'C': 2,'D': 3,'E': 4,'F': 5,'G': 6,'H': 7,'I': 8,'K': 9,'L': 10,'M': 11,'N': 12,'P': 13,'Q': 14,'R': 15,'S': 16,'T': 17,'V': 18,'W': 19,'Y': 20}\n```", "```py\ndef aa_seq_encoder(data):\n    full_sequence_list = []\n    for i in data['sequence'].values:\n        row_sequence_list = []\n        for j in i:\n            row_sequence_list.append(aa_seq_dict.get(j, 0))\n        full_sequence_list.append(np.array(row_sequence_list))\n    return full_sequence_list\n\nX_train_encode = aa_seq_encoder(X_train) \nX_val_encode = aa_seq_encoder(X_val) \nX_test_encode = aa_seq_encoder(X_test)\n```", "```py\nfrom keras.preprocessing.sequence import pad_sequences\nmax_length = 100\nX_train_padded = pad_sequences(X_train_encode, maxlen=max_length, padding='post', truncating='post')\nX_val_padded = pad_sequences(X_val_encode, maxlen=max_length, padding='post', truncating='post')\nX_test_padded = pad_sequences(X_test_encode, maxlen=max_length, padding='post', truncating='post')\n```", "```py\nX_train.sequence[1][:30]\n'LRDLRHFLAVAEEGHIGRAAARLHLSQPPL'\n```", "```py\nX_train_encode[1][:30]\narray([ 7, 10, 15, 18, 10,  3, 18, 16, 14, 17, 15,  5, 12, 10,  7, 16, 15, 12, 12,  8, 18,  4, 14,  5, 17,  4,  2])\n```", "```py\nX_train_padded[1][:30]\narray([ 7, 10, 15, 18, 10,  3, 18, 16, 14, 17, 15,  5, 12, 10,  7, 16, 15, 12, 12,  8, 18,  4, 14,  5, 17,  4,  2,  0,  0,  0])\n```", "```py\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny_train_enc = le.fit_transform(X_train['family_accession'])\ny_val_enc = le.transform(X_val['family_accession'])\ny_test_enc = le.transform(X_test['family_accession'])\n```", "```py\nfrom tensorflow.keras.utils import to_categorical\ny_train = to_categorical(y_train_enc)\ny_val = to_categorical(y_val_enc)\ny_test = to_categorical(y_test_enc)\n```", "```py\nX_train['family_accession']\n```", "```py\ny_train_enc\narray([ 4,  3, 21, ..., 10, 15, 12], dtype=int64)\n```", "```py\ny_train[5]\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)\n```", "```py\n    import tensorflow as tf\n    from keras.models import Sequential\n    from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Input, Bidirectional, LSTM, Dropout\n    from keras.layers.embeddings import Embedding\n    from keras.regularizers import l2\n    from keras.models import Model\n    import mlflow\n    import mlflow.keras\n    ```", "```py\n    model = Sequential()\n    model.add(Embedding(21, 8, input_length=max_length, name=\"EmbeddingLayer\"))\n    ```", "```py\n    model.add(Bidirectional(LSTM(8), name=\"BidirectionalLayer\"))\n    ```", "```py\n    model.add(Dropout(0.2, name=\"DropoutLayer\"))\n    ```", "```py\n    model.add(Dense(28, activation='softmax', name=\"DenseLayer\"))\n    ```", "```py\n    opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    ```", "```py\n    from keras.callbacks import EarlyStopping\n    es = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n    ```", "```py\n    mlflow.keras.autolog()\n    history = model.fit(\n        X_train_padded, y_train,\n        epochs=30, batch_size=256,\n        validation_data=(X_val_padded, y_val),\n        callbacks=[es]\n        )\n    ```", "```py\n!mlflow ui\n```", "```py\nfrom sklearn.metrics import confusion_matrix\ny_pred = model.predict(X_test_padded)\ncf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n```", "```py\nimport seaborn as sns\nplt.figure(figsize=(15,10))\nsns.heatmap(cf_matrix, annot=True, fmt='', cmap='Blues')\n```"]