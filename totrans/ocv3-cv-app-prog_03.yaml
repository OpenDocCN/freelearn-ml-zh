- en: Chapter 3. Processing the Colors of an Image
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章 处理图像的颜色
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Comparing colors using the Strategy design pattern
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用策略设计模式比较颜色
- en: Segmenting an image with the GrabCut algorithm
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GrabCut算法分割图像
- en: Converting color representations
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换颜色表示
- en: Representing colors with hue, saturation, and brightness
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用色调、饱和度和亮度表示颜色
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: The ability to see the world in colors is one of the important characteristics
    of the human visual system. The retina of the human eye includes specialized photoreceptors,
    called cones, which are responsible for the perception of colors. There are three
    types of cones that differ in the wavelength range of light they absorb; using
    the stimuli from these different cells, the human brain is able to create color
    perception. Most other animals only have rod cells, which are photoreceptors with
    better light sensitivity but that cover the full spectrum of visible light without
    color discrimination. In the human eye, rods are mainly located at the periphery
    of the retina, while the cones are concentrated in the central part.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 能够用颜色看世界是人类视觉系统的一个重要特征。人眼视网膜包括称为锥状体的特殊光感受器，它们负责感知颜色。有三种类型的锥状体，它们在吸收光波的波长范围上有所不同；通过这些不同细胞产生的刺激，人脑能够创造出颜色感知。大多数其他动物只有棒状细胞，这些是具有更好光敏感性的光感受器，但它们覆盖了整个可见光谱而没有颜色区分。在人眼中，棒状细胞主要位于视网膜的边缘，而锥状体则集中在中央部分。
- en: In digital imaging, colors are generally reproduced by using the red, green,
    and blue additive primary colors. These have been selected because when they are
    combined together, they can produce a wide gamut of different colors. In fact,
    this choice of primaries mimics well the trichromatic color perception of the
    human visual system as the different cone cells have sensitivity located around
    the red, green, and blue spectrum. In this chapter, you will play with the pixel
    color and see how an image can be segmented based on the color information. In
    addition, you will learn that it can sometimes be useful to use a different color
    representation when performing color image processing.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在数字成像中，颜色通常是通过使用红色、绿色和蓝色加色原色来再现的。这些颜色被选中是因为当它们组合在一起时，可以产生广泛的颜色范围。实际上，这种原色选择很好地模仿了人类视觉系统的三色色觉，因为不同的锥状细胞对红色、绿色和蓝色光谱的敏感性位于周围。在本章中，你将玩转像素颜色，看看图像可以根据颜色信息进行分割。此外，你将了解到在执行颜色图像处理时，有时使用不同的颜色表示可能是有用的。
- en: Comparing colors using the Strategy design pattern
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用策略设计模式比较颜色
- en: Let's say we want to build a simple algorithm that will identify all of the
    pixels in an image that have a given color. For this, the algorithm has to accept
    an image and a color as input and will return a binary image showing the pixels
    that have the specified color. The tolerance with which we want to accept a color
    will be another parameter to be specified before running the algorithm.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要构建一个简单的算法，该算法能够识别图像中所有具有给定颜色的像素。为此，算法必须接受一个图像和一个颜色作为输入，并将返回一个二值图像，显示具有指定颜色的像素。我们希望接受颜色的容差将作为在运行算法之前要指定的另一个参数。
- en: In order to accomplish this objective, this recipe will use the **Strategy design
    pattern**. This object-oriented design pattern constitutes an excellent way of
    encapsulating an algorithm in a class. It becomes then easier to replace a given
    algorithm with another one, or to chain several algorithms together in order to
    build a more complex process. In addition, this pattern facilitates the deployment
    of an algorithm by hiding as much of its complexity as possible behind an intuitive
    programming interface.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一目标，这个食谱将使用**策略设计模式**。这种面向对象的设计模式构成了将算法封装在类中的绝佳方式。这样，替换给定算法为另一个算法，或者将几个算法链接在一起以构建更复杂的过程，就变得更容易了。此外，这个模式通过尽可能隐藏其复杂性，简化了算法的部署，提供了一个直观的编程接口。
- en: How to do it…
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Once an algorithm has been encapsulated in a class using the Strategy design
    pattern, it can be deployed by creating an instance of this class. Typically,
    the instance will be created when the program is initialized. At the time of construction,
    the class instance will initialize the different parameters of the algorithm with
    their default values so that it will immediately be ready to be used. The algorithm's
    parameter values can also be read and set using appropriate methods. In the case
    of an application with a GUI, these parameters can be displayed and modified using
    different widgets (text fields, sliders, and so on) so that a user can easily
    play with them.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦使用策略设计模式将算法封装在类中，就可以通过创建这个类的实例来部署它。通常，实例将在程序初始化时创建。在构建时，类实例将使用它们的默认值初始化算法的不同参数，以便它立即可以投入使用。也可以使用适当的方法读取和设置算法的参数值。在具有GUI的应用程序的情况下，可以使用不同的小部件（文本字段、滑块等）显示和修改这些参数，以便用户可以轻松地玩弄它们。
- en: 'We will show you the structure of a `Strategy` class in the next section; let''s
    start with an example of how it can be deployed and used. Let''s write a simple
    `main` function that will run our proposed color detection algorithm:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节向您展示`Strategy`类的结构；让我们从一个示例开始，看看它是如何部署和使用的。让我们编写一个简单的`main`函数，该函数将运行我们提出的颜色检测算法：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Running this program to detect a blue sky in the colored version of the *Castle*
    image presented in the previous chapter produces the following output:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此程序以检测前一章中展示的彩色版本*城堡*图像中的蓝色天空，产生以下输出：
- en: '![How to do it…](img/image_03_002.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![如何做到这一点…](img/image_03_002.jpg)'
- en: Here, a white pixel indicates a positive detection of the sought color, and
    black indicates negative.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，白色像素表示对所需颜色的积极检测，而黑色表示消极。
- en: Obviously, the algorithm we encapsulated in this class is relatively simple
    (as we will see next, it is composed of just one scanning loop and one tolerance
    parameter). The Strategy design pattern becomes really powerful when the algorithm
    to be implemented is more complex, has many steps, and includes several parameters.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们在这个类中封装的算法相对简单（正如我们将在下一节看到的，它只由一个扫描循环和一个容差参数组成）。当要实现的算法更复杂、有多个步骤并包含多个参数时，策略设计模式变得非常强大。
- en: How it works…
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'The core process of this algorithm is easy to build. It is a simple scanning
    loop that goes over each pixel, comparing its color with the target color. Using
    what we learned in the *Scanning an image with iterators* recipe of the previous
    chapter, this loop can be written as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法的核心过程很容易构建。它是一个简单的扫描循环，遍历每个像素，比较其颜色与目标颜色。使用我们在上一章的*使用迭代器扫描图像*配方中学到的知识，这个循环可以写成以下形式：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `cv::Mat` variable image refers to the input image, while `result` refers
    to the binary output image. Therefore, the first step consists of setting up the
    required iterators. The scanning loop then becomes easy to implement. Note that
    the input image iterators are declared `const` as the values of their elements
    are not modified. The distance between the current pixel color and the target
    color is evaluated for each pixel in order to check whether it is within the tolerance
    parameter defined by `maxDist`. If that is the case, the value `255` (white) is
    then assigned to the output image; if not, `0` (black) is assigned. To compute
    the distance to the target color, the `getDistanceToTargetColor` method is used.
    There are different ways to compute this distance.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv::Mat`变量`image`指向输入图像，而`result`指向二值输出图像。因此，第一步是设置所需的迭代器。然后扫描循环就很容易实现了。请注意，输入图像迭代器被声明为`const`，因为它们的元素值没有被修改。对每个像素的当前像素颜色和目标颜色之间的距离进行评估，以检查它是否在由`maxDist`定义的容差参数内。如果是这样，则将值`255`（白色）分配给输出图像；如果不是，则分配`0`（黑色）。为了计算到目标颜色的距离，使用`getDistanceToTargetColor`方法。计算这个距离有不同的方法。'
- en: 'One could, for example, calculate the Euclidean distance between the three
    vectors that contain the RGB color values. To keep this computation simple, we
    sum the absolute differences of the RGB values (this is also known as the **city-block
    distance**). Note that in modern architecture, a floating-point Euclidean distance
    can be faster to compute than a simple city-block distance (in addition, you can
    also use squared Euclidean distances to avoid the costly square-root); this is
    also something to take into consideration in your design. Also, for more flexibility,
    we write the `getDistanceToTargetColor` method in terms of a `getColorDistance`
    method, as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，可以计算包含RGB颜色值的三个向量之间的欧几里得距离。为了使这个计算简单，我们求和RGB值的绝对差（这也被称为**曼哈顿距离**）。请注意，在现代架构中，浮点欧几里得距离可能比简单的曼哈顿距离计算更快（此外，您还可以使用平方欧几里得距离以避免昂贵的平方根运算）；这也是您在设计时需要考虑的事情。此外，为了增加灵活性，我们以`getColorDistance`方法的形式编写了`getDistanceToTargetColor`方法，如下所示：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note how we used `cv::Vec3d` to hold the three unsigned chars that represent
    the RGB values of a color. The `target` variable obviously refers to the specified
    target color, and as we will see, it is defined as a member variable in the class
    algorithm that we will define. Now, let''s complete the definition of the processing
    method. Users will provide an input image, and the result will be returned once
    the image scanning is completed:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们如何使用`cv::Vec3d`来存储代表颜色RGB值的三个无符号字符。`target`变量显然指的是指定的目标颜色，正如我们将看到的，它被定义为我们将定义的类算法中的一个成员变量。现在，让我们完成处理方法的定义。用户将提供一个输入图像，一旦图像扫描完成，结果就会被返回：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Each time this method is called, it is important to check if the output image
    that contains the resulting binary map needs to be reallocated to fit the size
    of the input image. This is why we use the `create` method of `cv::Mat`. Remember
    that this method will only proceed to reallocation if the specified size and/or
    depth do not correspond to the current image structure.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 每次调用此方法时，都需要检查包含结果二值图的输出图像是否需要重新分配以适应输入图像的大小。这就是为什么我们使用`cv::Mat`的`create`方法。请记住，此方法只有在指定的尺寸和/或深度与当前图像结构不对应时才会进行重新分配。
- en: 'Now that we have the core processing method defined, let''s see what additional
    methods should be added in order to deploy this algorithm. We have previously
    determined what input and output data our algorithm requires. Therefore, we define
    the class attributes that will hold this data:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了核心处理方法，让我们看看还需要添加哪些附加方法才能部署此算法。我们之前已经确定了我们的算法需要哪些输入和输出数据。因此，我们定义了将持有这些数据的类属性：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In order to create an instance of the class that encapsulates our algorithm
    (which we have named `ColorDetector`), we need to define a constructor. Remember
    that one of the objectives of the Strategy design pattern is to make algorithm
    deployment as easy as possible. The simplest constructor that can be defined is
    an empty one. It will create an instance of the class algorithm in a valid state.
    We then want the constructor to initialize all the input parameters to their default
    values (or the values that are known to generally give a good result). In our
    case, we decided that a distance of `100` is generally an acceptable tolerance
    parameter. We also set the default target color. We chose black for no particular
    reason. The idea is to make sure we always start with predictable and valid input
    values:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建一个封装我们算法的类实例（我们将其命名为`ColorDetector`），我们需要定义一个构造函数。请记住，策略设计模式的一个目标是将算法部署尽可能简单。可以定义的最简单的构造函数是一个空的。它将创建一个处于有效状态的类算法实例。然后我们希望构造函数将所有输入参数初始化为其默认值（或通常能给出良好结果的值）。在我们的情况下，我们决定`100`的距离通常是一个可接受的容差参数。我们还设置了默认的目标颜色。我们选择黑色没有特别的原因。目的是确保我们始终以可预测和有效的输入值开始：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Another option would have been not create an empty constructor and rather force
    the user to input a target color and a color distance in a more elaborated constructor:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择可能是不要创建一个空的构造函数，而是强制用户在更复杂的构造函数中输入目标颜色和颜色距离：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'At this point, a user who creates an instance of our class algorithm can immediately
    call the process method with a valid image and obtain a valid output. This is
    another objective of the Strategy pattern, that is, to make sure that the algorithm
    always runs with valid parameters. Obviously, the users of this class will want
    to use their own settings. This is done by providing the user with the appropriate
    getters and setters. Let''s start with the `color` tolerance parameter:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，创建我们类算法实例的用户可以立即使用有效的图像调用 process 方法并获得有效的输出。这是策略模式的一个目标，即确保算法始终使用有效的参数运行。显然，这个类的用户将想要使用他们自己的设置。这是通过为用户提供适当的获取器和设置器来实现的。让我们从
    `color` 容忍度参数开始：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Note how we first check the validity of the input. Again, this is to make sure
    that our algorithm will never be run in an invalid state. The target color can
    be set in a similar manner, as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们首先检查输入的有效性。再次强调，这是为了确保我们的算法永远不会在无效状态下运行。目标颜色可以以类似的方式设置，如下所示：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This time, it is interesting to note that we have provided the user with two
    definitions of the `setTargetColor` method. In the first version of the definition,
    the three color components are specified as three arguments, while in the second
    version, `cv::Vec3b` is used to hold the color values. Again, the objective is
    to facilitate the use of our class algorithm. The users can simply select the
    setter that best fits their needs.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，有趣的是，我们为用户提供了 `setTargetColor` 方法的两种定义。在定义的第一版本中，三个颜色分量被指定为三个参数，而在第二版本中，使用
    `cv::Vec3b` 来存储颜色值。再次强调，目的是为了方便使用我们的类算法。用户可以简单地选择最适合他们需求的设置器。
- en: There's more…
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The example algorithm used in this recipe consisted of identifying the pixels
    of an image that has a color sufficiently close to a specified target color. This
    computation could have been done otherwise. Interestingly, an OpenCV function
    performs a similar task in order to extract a connected component of a given color.
    Also, the implementation of a Strategy design pattern could be complemented using
    function objects. Finally, OpenCV has defined a base class, `cv::Algorithm`, that
    implements the Strategy design pattern concepts.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中使用的示例算法包括识别图像中颜色足够接近指定目标颜色的像素。这个计算可以以其他方式完成。有趣的是，OpenCV 函数执行类似任务以提取给定颜色的连通组件。此外，可以使用函数对象来补充实现策略设计模式。最后，OpenCV
    定义了一个基类 `cv::Algorithm`，它实现了策略设计模式的概念。
- en: Computing the distance between two color vectors
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算两个颜色向量之间的距离
- en: 'To compute the distance between two color vectors, we used the following simple
    formula:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算两个颜色向量之间的距离，我们使用了以下简单的公式：
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'However, OpenCV includes a function to compute the Euclidean norm of a vector.
    Consequently, we could have computed our distance as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，OpenCV 包含一个用于计算向量欧几里得范数的函数。因此，我们可以按照以下方式计算我们的距离：
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: A very similar result would then be obtained using this definition of the `getDistance`
    method. Here, we use `cv::Vec3i` (a 3-vector array of integers) because the result
    of the subtraction is an integer value.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个 `getDistance` 方法定义，可以得到一个非常相似的结果。在这里，我们使用 `cv::Vec3i`（一个整数的3向量数组）因为减法的结果是一个整数值。
- en: 'It is also interesting to recall from [Chapter 2](ch02.html "Chapter 2. Manipulating
    Pixels") , *Manipulating Pixels*, that the OpenCV matrix and vector data structures
    include a definition of the basic arithmetic operators. Consequently, one could
    have proposed the following definition for the distance computation:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 还有趣的是，回顾一下[第2章](ch02.html "第2章. 操作像素")，*操作像素*，OpenCV 的矩阵和向量数据结构包括基本算术运算符的定义。因此，可以提出以下距离计算的以下定义：
- en: '[PRE11]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This definition may look right at the first glance; however, it is wrong. This
    is because all these operators always include a call to `saturate_cast` (see the
    *Scanning an image with neighbor access* recipe in the previous chapter) in order
    to ensure that the results stay within the domain of the input type (here, it
    is `uchar`). Therefore, in the cases where the target value is greater than the
    corresponding color value, the value `0` will be assigned instead of the negative
    value that one would have expected. A correct formulation would then be as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定义乍一看可能看起来是正确的；然而，它是错误的。这是因为所有这些操作始终包含对`saturate_cast`（参见前一章的*使用邻域访问扫描图像*食谱）的调用，以确保结果保持在输入类型的域内（在这里是`uchar`）。因此，当目标值大于相应的颜色值时，将分配`0`值而不是预期的负值。正确表述应该是如下：
- en: '[PRE12]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: However, using two function calls to compute the distance between two 3-vector
    arrays is inefficient.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用两次函数调用计算两个3向量数组的距离是不高效的。
- en: Using OpenCV functions
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用OpenCV函数
- en: 'In this recipe, we used a loop with iterators in order to perform our computation.
    Alternatively, we could have achieved the same result by calling a sequence of
    OpenCV functions. The color detection method will then be written as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们使用带迭代器的循环来执行我们的计算。作为替代，我们也可以通过调用一系列OpenCV函数来达到相同的结果。颜色检测方法将如下编写：
- en: '[PRE13]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This method uses the `absdiff` function, which computes the absolute difference
    between the pixels of an image and, in this case, a scalar value. Instead of a
    scalar value, another image can be provided as the second argument to this function.
    In the latter case, a pixel-by-pixel difference will be applied; consequently,
    the two images must be of the same size. The individual channels of the difference
    image are then extracted using the `split` function (discussed in the *There's
    more...* section of the *Performing simple image arithmetic* recipe of [Chapter
    2](ch02.html "Chapter 2. Manipulating Pixels") , *Manipulating Pixels*) in order
    to be able to add them together. It is important to note that the result of this
    sum may sometimes be greater than `255`, but because saturation is always applied,
    the result will be stopped at `255`. The consequence is that with this version,
    the `maxDist` parameter must also be less than `256`; this should be corrected
    if you consider this behavior unacceptable.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用`absdiff`函数，该函数计算图像像素与标量值之间的绝对差值。除了标量值之外，还可以提供另一个图像作为此函数的第二个参数。在后一种情况下，将应用逐像素差异；因此，两个图像必须具有相同的大小。然后使用`split`函数（在[第2章](ch02.html
    "第2章. 操作像素")的*执行简单图像算术*食谱的*There's more...*部分中讨论，*操作像素*）提取差异图像的各个通道，以便能够将它们相加。需要注意的是，这个总和有时可能大于`255`，但由于总是应用饱和度，结果将被限制在`255`。结果是，在这个版本中，`maxDist`参数也必须小于`256`；如果你认为这种行为不可接受，应该进行修正。
- en: The last step is to create a binary image by using the `cv::threshold` function.
    This function is commonly used to compare all the pixels with a threshold value
    (the third parameter), and in the regular thresholding mode (`cv::THRESH_BINARY`),
    it assigns the defined maximum value (the fourth parameter) to all the pixels
    greater than the specified threshold and `0` to the other pixels. Here, we used
    the inverse mode (`cv::THRESH_BINARY_INV`) in which the defined maximum value
    is assigned to the pixels that have a value lower than or equal to the threshold.
    Of interest are also the `cv::THRESH_TOZERO` and `cv::THRESH_TOZERO_INV` modes,
    which leave the pixels greater than or lower than the threshold unchanged.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是通过使用`cv::threshold`函数创建二值图像。这个函数通常用于将所有像素与阈值值（第三个参数）进行比较，在常规阈值模式（`cv::THRESH_BINARY`）中，它将定义的最大值（第四个参数）分配给所有大于指定阈值的像素，并将`0`分配给其他像素。在这里，我们使用了逆模式（`cv::THRESH_BINARY_INV`），其中定义的最大值被分配给值低于或等于阈值的像素。同样值得注意的是`cv::THRESH_TOZERO`和`cv::THRESH_TOZERO_INV`模式，它们将保持大于或小于阈值的像素不变。
- en: Using the OpenCV functions is generally a good idea. You can then quickly build
    complex applications and potentially reduce the number of bugs. The result is
    often more efficient (thanks to the optimization efforts invested by the OpenCV
    contributors). However, when many intermediate steps are performed, you may find
    that the resulting method consumes more memory.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用OpenCV函数通常是一个好主意。这样，你可以快速构建复杂的应用程序，并可能减少错误数量。结果通常更高效（归功于OpenCV贡献者的优化努力）。然而，当执行许多中间步骤时，你可能会发现结果方法消耗了更多的内存。
- en: The floodFill function
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: floodFill函数
- en: 'Our `ColorDetector` class identifies the pixels in an image that have a color
    similar to a given target color. The decision to accept or not a pixel is simply
    made on a per-pixel basis. The `cv::floodFill` function proceeds in a very similar
    way with one important difference: in this case, the decision to accept a pixel
    also depends on the state of its neighbors. The idea is to identify a connected
    area of a certain color. The user specifies a starting pixel location and tolerance
    parameters that determine color similarity.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`ColorDetector`类识别图像中与给定目标颜色相似的颜色像素。是否接受或拒绝像素的决定是简单地基于每个像素进行的。`cv::floodFill`函数以非常相似的方式进行，但有一个重要的区别：在这种情况下，接受像素的决定也取决于其邻居的状态。这个想法是识别一定颜色的连通区域。用户指定一个起始像素位置和确定颜色相似性的容差参数。
- en: 'The seed pixel defines the color that is seek and from this seed location,
    the neighbors are considered in order to identify pixels of similar color; then
    the neighbors of the accepted neighbors are also considered and so on. This way,
    one area of constant color will be extracted from the image. For example, to detect
    the blue sky area in our example image, you could proceed as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 种子像素定义了要寻找的颜色，并且从这个种子位置开始，考虑邻居以识别相似颜色的像素；然后考虑接受邻居的邻居，依此类推。这样，可以从图像中提取出一个颜色恒定的区域。例如，为了检测示例图像中的蓝色天空区域，你可以按以下步骤进行：
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The seed pixel (`100`, `50`) is located in the sky. All connected pixels will
    be tested and the ones having a similar color will be repainted in a new color
    specified by the third parameter. To determine if a color is similar or not, different
    thresholds are defined independently for values that are higher or lower than
    the reference color. Here, we used fixed range mode, which implies that the tested
    pixels will all be compared to the seed pixel''s color. The default mode is the
    one where each tested pixel is compared to the color of its neighbors. The result
    obtained is as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 种子像素（`100`, `50`）位于天空。所有连通像素都将被测试，颜色相似的像素将被重新着色为第三个参数指定的新颜色。为了确定颜色是否相似，为高于或低于参考颜色的值独立定义了不同的阈值。在这里，我们使用了固定范围模式，这意味着测试的像素都将与种子像素的颜色进行比较。默认模式是每个测试像素与其邻居的颜色进行比较。得到的结果如下：
- en: '![The floodFill function](img/image_03_003.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![floodFill函数](img/image_03_003.jpg)'
- en: A single connected area is repainted by the algorithm (here, we painted the
    sky in white). Therefore, even if there are some pixels somewhere else with a
    similar color (in the water, for instance), these ones would not be identified
    unless they were connected to the sky area.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 算法将单个连通区域重新着色（在这里，我们将天空涂成了白色）。因此，即使在其他地方有一些颜色相似的像素（例如水中），除非它们与天空区域连通，否则这些像素不会被识别。
- en: Functor or function object
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 函数对象或函数对象
- en: 'Using the C++ operator overloading, it is possible to create a class for which
    its instances behave as functions. The idea is to overload the `operator()` method
    so that a call to the processing method of a class looks exactly like a simple
    function call. The resulting class instance is called a function object, or a
    **functor**. Often, a functor includes a full constructor such that it can be
    used immediately after being created. For example, you can define the full constructor
    of your `ColorDetector` class as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用C++运算符重载，可以创建一个其实例表现得像函数的类。这个想法是重载`operator()`方法，使得对类处理方法的调用看起来就像一个简单的函数调用。结果类实例被称为函数对象，或**函数对象**。通常，函数对象包括一个完整的构造函数，这样它就可以在创建后立即使用。例如，你可以定义你的`ColorDetector`类的完整构造函数如下：
- en: '[PRE15]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Obviously, you can still use the setters and getters that have been defined
    previously. The functor method can be defined as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，你仍然可以使用之前定义的设置器和获取器。函数对象方法可以定义如下：
- en: '[PRE16]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To detect a given color with this functor method, simply write the following
    code snippet:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这个函数方法检测给定的颜色，只需编写以下代码片段：
- en: '[PRE17]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As you can see, the call to the color detection method now looks like a function
    call.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，对颜色检测方法的调用现在看起来像是一个函数调用。
- en: The OpenCV base class for algorithms
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法的OpenCV基类
- en: OpenCV offers many algorithms that perform various computer vision tasks. To
    facilitate their use, most of these algorithms have been made subclass of a generic
    base class called `cv::Algorithm`. This one implements some of the concepts dictated
    by the Strategy design pattern. First, all these algorithms are created dynamically
    using a specialized static method that makes sure that the algorithm is always
    created in a valid state (that is, with valid default values for the unspecified
    parameters). Let's consider, for example, one of these subclasses, `cv::ORB`;
    this one is an interest point operator that will be discussed in the *Detecting
    FAST features at Multiple Scales* recipe in  [Chapter 8](ch08.html "Chapter 8. Detecting
    Interest Points") , *Detecting Interest Points*. Here, we simply use it as an
    illustrative example of an algorithm.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV提供了许多执行各种计算机视觉任务的算法。为了便于使用，这些算法中的大多数都被制作成了名为`cv::Algorithm`的通用基类的子类。这个类实现了一些由策略设计模式指定的概念。首先，所有这些算法都是通过一个专门的静态方法动态创建的，该方法确保算法始终处于有效状态（即，对于未指定的参数具有有效的默认值）。以这些子类中的一个为例，`cv::ORB`；这是一个兴趣点算子，将在第8章中讨论的*在多个尺度上检测FAST特征*食谱中讨论，*检测兴趣点*。在这里，我们只是简单地将其用作算法的说明性示例。
- en: 'An instance of this algorithm is therefore created as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，创建此算法的实例如下：
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Once created, the algorithm can then be used. For example, the generic methods
    `read` and `write` can be used to load or store the state of the algorithm. The
    algorithms also have specialized methods (in the case of ORB, for example, the
    methods `detect` and `compute` can be used to trigger its main computational units).
    Algorithms also have specialized setter methods that allows specifying their internal
    parameters. Note that we could have declared the pointer as `cv::Ptr<cv::Algorithm>`
    but, in this case, we would not be able to use its specialized methods.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 创建后，算法就可以使用了。例如，可以使用通用的`read`和`write`方法来加载或存储算法的状态。算法还有专门的方法（例如，对于ORB，可以使用`detect`和`compute`方法来触发其主要计算单元）。算法还有专门的设置方法，允许指定其内部参数。请注意，我们本来可以将指针声明为`cv::Ptr<cv::Algorithm>`，但在这种情况下，我们就无法使用其专门的方法。
- en: See also
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The policy-based class design, introduced by A. Alexandrescu, is an interesting
    variant of the Strategy design pattern in which algorithms are selected at compile
    time
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由A. Alexandrescu引入的策略类设计是策略设计模式的一个有趣变体，其中算法在编译时被选择
- en: The *Converting color representation* recipe introduces the concept of perceptually
    uniform color spaces to achieve more intuitive color comparison
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*转换颜色表示*食谱介绍了感知均匀颜色空间的概念，以实现更直观的颜色比较'
- en: Segmenting an image with the GrabCut algorithm
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GrabCut算法分割图像
- en: 'The previous recipe showed how color information can be useful to segment an
    image into area corresponding to specific elements of a scene. Objects often have
    distinctive colors, and these ones can often be extracted by identifying areas
    of similar colors. OpenCV proposes an implementation of a popular algorithm for
    image segmentation: the **GrabCut** algorithm. GrabCut is a complex and computationally
    expensive algorithm, but it generally produces very accurate results. It is the
    best algorithm to use when you want to extract a foreground object in a still
    image (for example, to cut and paste an object from one picture to another).'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的食谱展示了如何利用颜色信息将图像分割成与场景特定元素相对应的区域。物体通常具有独特的颜色，这些颜色通常可以通过识别相似颜色的区域来提取。OpenCV提出了一种图像分割流行算法的实现：**GrabCut**算法。GrabCut是一个复杂且计算量大的算法，但它通常会产生非常准确的结果。当你想要从静态图像中提取前景对象时（例如，从一个图片中剪切并粘贴到另一个图片中），这是最好的算法。
- en: How to do it…
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: The `cv::grabCut` function is easy to use. You just need to input an image and
    label some of its pixels as belonging to the background or to the foreground.
    Based on this partial labeling, the algorithm will then determine a foreground/
    background segmentation for the complete image.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv::grabCut`函数易于使用。你只需要输入一个图像，并标记其中一些像素属于背景或前景。基于这种部分标记，算法将确定整个图像的前景/背景分割。'
- en: 'One way to specify a partial foreground/background labeling for an input image
    is by defining a rectangle inside which the foreground object is included:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为输入图像指定部分前景/背景标记的一种方法是在其中定义一个包含前景对象的矩形：
- en: '[PRE19]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This defines the following area in the image:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这在图像中定义了以下区域：
- en: '![How to do it…](img/image_03_004.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![如何做…](img/image_03_004.jpg)'
- en: 'All the pixels outside this rectangle will then be marked as background. In
    addition to the input image and its segmentation image, calling the `cv::grabCut`
    function requires the definition of two matrices, which will contain the models
    built by the algorithm as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这个矩形以外的像素都将被标记为背景。除了输入图像及其分割图像外，调用`cv::grabCut`函数还需要定义两个矩阵，这两个矩阵将包含算法构建的模型，如下所示：
- en: '[PRE20]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Note how we specified that we are using the bounding rectangle mode with the
    `cv::GC_INIT_WITH_RECT` flag as the last argument of the function (the next section,
    *How it works...*, will discuss the other available mode). The input/output segmentation
    image can have one of the following four values:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们如何指定使用`cv::GC_INIT_WITH_RECT`标志作为函数的最后一个参数来使用边界矩形模式。输入/输出分割图像可以具有以下四个值之一：
- en: '`cv::GC_BGD`: This is the value of the pixels that certainly belong to the
    background (for example, pixels outside the rectangle in our example)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv::GC_BGD`：这是属于背景的像素的值（例如，在我们例子中的矩形外的像素）'
- en: '`cv::GC_FGD`: This is the value of the pixels that certainly belong to the
    foreground (there are none in our example)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv::GC_FGD`：这是属于前景的像素的值（在我们例子中没有这样的像素）'
- en: '`cv::GC_PR_BGD`: This is the value of the pixels that probably belong to the
    background'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv::GC_PR_BGD`：这是可能属于背景的像素的值'
- en: '`cv::GC_PR_FGD`: This is the value of the pixels that probably belong to the
    foreground (that is, the initial value of the pixels inside the rectangle in our
    example)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv::GC_PR_FGD`：这是可能属于前景的像素的值（即我们例子中矩形内像素的初始值）'
- en: 'We get a binary image of the segmentation by extracting the pixels that have
    a value equal to `cv::GC_PR_FGD`. This is accomplished with the following code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通过提取具有等于`cv::GC_PR_FGD`值的像素，我们得到了分割的二值图像。这是通过以下代码实现的：
- en: '[PRE21]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'To extract all the foreground pixels, that is, with values equal to `cv::GC_PR_FGD`
    or `cv::GC_FGD`, it is possible to check the value of the first bit, as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要提取所有前景像素，即具有等于`cv::GC_PR_FGD`或`cv::GC_FGD`值的像素，可以通过检查第一个位来检查值，如下所示：
- en: '[PRE22]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This is possible because these constants are defined as values `1` and `3`,
    while the other two (`cv::GC_BGD` and `cv::GC_PR_BGD`) are defined as `0` and
    `2`. In our example, the same result is obtained because the segmentation image
    does not contain the `cv::GC_FGD` pixels (only the `cv::GC_BGD` pixels have been
    inputted).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为这些常量被定义为值`1`和`3`，而其他两个（`cv::GC_BGD`和`cv::GC_PR_BGD`）被定义为`0`和`2`。在我们例子中，由于分割图像不包含`cv::GC_FGD`像素（只有`cv::GC_BGD`像素被输入），因此得到了相同的结果。
- en: 'The following image is then obtained:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后得到以下图像：
- en: '![How to do it…](img/image_03_005.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![如何做…](img/image_03_005.jpg)'
- en: How it works…
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In the preceding example, the GrabCut algorithm was able to extract the foreground
    object by simply specifying a rectangle inside which this objects (the castle)
    was contained. Alternatively, one could also assign the values `cv::GC_BGD` and
    `cv::GC_FGD` to some specific pixels of the input image, which are provided by
    using a mask image as the second argument of the `cv::grabCut` function. You would
    then specify `GC_INIT_WITH_MASK` as the input mode flag. These input labels could
    be obtained, for example, by asking a user to interactively mark a few elements
    of the image. It is also possible to combine these two input modes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，GrabCut算法能够通过简单地指定一个包含这个对象（城堡）的矩形来提取前景对象。或者，也可以将`cv::GC_BGD`和`cv::GC_FGD`的值分配给输入图像的一些特定像素，这些像素是通过使用掩码图像作为`cv::grabCut`函数的第二个参数提供的。然后，你会指定`GC_INIT_WITH_MASK`作为输入模式标志。这些输入标签可以通过要求用户交互式标记图像的一些元素来获得。也可以将这两种输入模式结合起来。
- en: Using this input information, the GrabCut algorithm creates the background/foreground
    segmentation by proceeding as follows. Initially, a foreground label (`cv::GC_PR_FGD`)
    is tentatively assigned to all the unmarked pixels. Based on the current classification,
    the algorithm groups the pixels into clusters of similar colors (that is, `K`
    clusters for the background and `K` clusters for the foreground). The next step
    is to determine a background/ foreground segmentation by introducing boundaries
    between the foreground and background pixels.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此输入信息，GrabCut算法通过以下步骤创建背景/前景分割。最初，将前景标签(`cv::GC_PR_FGD`)暂时分配给所有未标记的像素。根据当前的分类，算法将像素分组为相似颜色的簇（即，背景和前景各有`K`个簇）。下一步是通过在前景和背景像素之间引入边界来确定背景/前景分割。
- en: This is done through an optimization process that tries to connect pixels with
    similar labels, and that imposes a penalty for placing a boundary in the regions
    of relatively uniform intensity. This optimization problem can be efficiently
    solved using the Graph Cuts algorithm, a method that can find the optimal solution
    of a problem by representing it as a connected graph on which cuts are applied
    in order to compose an optimal configuration. The obtained segmentation produces
    new labels for the pixels.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过一个优化过程来完成的，该过程试图连接具有相似标签的像素，并对在相对均匀强度区域放置边界施加惩罚。这个问题可以使用图割算法有效地解决，这是一种通过将其表示为应用切割以组成最优配置的连接图来找到问题最优解的方法。得到的分割为像素产生新的标签。
- en: The clustering process can then be repeated, and a new optimal segmentation
    is found again, and so on. Therefore, the GrabCut algorithm is an iterative procedure
    that gradually improves the segmentation result. Depending on the complexity of
    the scene, a good solution can be found in more or less number of iterations (in
    easy cases, one iteration would be enough).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以重复聚类过程，再次找到新的最优分割，依此类推。因此，GrabCut算法是一个迭代过程，逐渐改进分割结果。根据场景的复杂性，可以在更多或更少的迭代次数中找到良好的解决方案（在简单情况下，一次迭代就足够了）。
- en: This explains the argument of the function where the user can specify the number
    of iterations to be applied. The two internal models maintained by the algorithm
    are passed as an argument of the function (and returned). Therefore, it is possible
    to call the function with the models of the last run again if one wishes to improve
    the segmentation result by performing additional iterations.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这解释了函数的参数，用户可以指定要应用的迭代次数。算法维护的两个内部模型作为函数的参数（并返回）。因此，如果希望通过执行额外的迭代来改进分割结果，可以再次使用上次运行的模型调用该函数。
- en: See also
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'The article *GrabCut: Interactive Foreground Extraction using Iterated Graph
    Cuts* in *ACM Transactions on Graphics (SIGGRAPH) volume 23, issue 3, August 2004,
    C. Rother, V. Kolmogorov, and A. Blake* describes the GrabCut algorithm in detail'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '文章*GrabCut: Interactive Foreground Extraction using Iterated Graph Cuts*发表在*ACM
    Transactions on Graphics (SIGGRAPH) 第23卷，第3期，2004年8月，C. Rother, V. Kolmogorov,
    和 A. Blake*上，详细描述了GrabCut算法。'
- en: The *Segmenting images using watersheds* recipe in [Chapter 5](ch05.html "Chapter 5. Transforming
    Images with Morphological Operations"), *Transforming Images with Morphological
    Operations*, presents another image segmentation algorithm
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第5章](ch05.html "第5章. 使用形态学操作变换图像")的*使用形态学操作变换图像*中，*使用分水岭分割图像*菜谱介绍了另一种图像分割算法。
- en: Converting color representations
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换颜色表示
- en: The RGB color space is based on the use of the red, green, and blue additive
    primary colors. We saw in the first recipe of this chapter that these primaries
    have been chosen because they can produce a good range of colors well aligned
    with the human visual system. It is often the default color space in digital imagery
    because this is the way color images are acquired, that is, through the use of
    red, green, and blue filters. Additionally, the red, green, and blue channels
    are normalized such that when combined in equal amounts, a gray-level intensity
    is obtained, that is, from black `(0,0,0)` to white `(255,255,255)`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: RGB颜色空间基于红色、绿色和蓝色加色原色的使用。我们在本章的第一个菜谱中看到，这些原色被选择是因为它们可以产生与人类视觉系统良好对齐的广泛颜色范围。这通常是数字图像中的默认颜色空间，因为这是获取彩色图像的方式，即通过使用红色、绿色和蓝色过滤器。此外，红色、绿色和蓝色通道被归一化，以便当以相等比例组合时，可以获得灰度强度，即从黑色`(0,0,0)`到白色`(255,255,255)`。
- en: Unfortunately, computing the distance between the colors using the RGB color
    space is not the best way to measure the similarity between two given colors.
    Indeed, RGB is not a **perceptually uniform color space**. This means that two
    colors at a given distance might look very similar, while two other colors separated
    by the same distance might look very different.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 很遗憾，使用RGB颜色空间计算颜色之间的距离并不是衡量两种给定颜色相似度的最佳方式。实际上，RGB不是一个**感知均匀的颜色空间**。这意味着在给定距离的两个颜色可能看起来非常相似，而相隔相同距离的另外两种颜色可能看起来非常不同。
- en: To solve this problem, other color representations that have the property of
    being perceptually uniform have been introduced. In particular, the **CIE L*a*b***
    is one such color model. By converting our images to this representation, the
    Euclidean distance between an image pixel and the target color will then be a
    meaningful measure of the visual similarity between the two colors. In this recipe,
    we will show you how to convert colors from one representation to another in order
    to work with other color spaces.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，已经引入了具有感知均匀特性的其他颜色表示方法。特别是，**CIE L*a*b**是一个这样的颜色模型。通过将我们的图像转换为这种表示，图像像素与目标颜色之间的欧几里得距离将是一个衡量两种颜色视觉相似度的有意义的度量。在本菜谱中，我们将向您展示如何将颜色从一种表示转换为另一种表示，以便在其他颜色空间中工作。
- en: How to do it…
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'Conversion of images between different color spaces is easily done through
    the use of the `cv::cvtColor` OpenCV function. Let''s revisit the `ColorDetector`
    class of the first recipe of this chapter, *Comparing colors using the Strategy
    design pattern*. We now convert the input image to the CIE L*a*b* color space
    at the beginning of the process method:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`cv::cvtColor` OpenCV函数，不同颜色空间之间的图像转换可以轻松完成。让我们回顾一下本章第一道菜谱中的`ColorDetector`类，*使用策略设计模式比较颜色*。我们现在在过程方法的开始将输入图像转换为CIE
    L*a*b*颜色空间：
- en: '[PRE23]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `converted` variable contains the image after color conversion. In the
    `ColorDetector` class, it is defined as a class attribute:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`converted`变量包含颜色转换后的图像。在`ColorDetector`类中，它被定义为类属性：'
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You also need to convert the input target color. You can do this by creating
    a temporary image that contains only one pixel. Note that you need to keep the
    same signature as in the earlier recipes, that is, the user continues to supply
    the target color in RGB:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要转换输入的目标颜色。你可以通过创建一个只包含一个像素的临时图像来完成这个操作。请注意，你需要保持与早期菜谱中相同的签名，即用户继续以RGB格式提供目标颜色：
- en: '[PRE25]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: If the application of the preceding recipe is compiled with this modified class,
    it will now detect the pixels of the target color using the CIE L*a*b* color model.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将先前的菜谱应用编译与这个修改过的类一起，它现在将使用CIE L*a*b*颜色模型检测目标颜色的像素。
- en: How it works…
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: When an image is converted from one color space to another, a linear or nonlinear
    transformation is applied on each input pixel to produce the output pixels. The
    pixel type of the output image will match the one of the input image. Even if
    you work with 8-bit pixels most of the time, you can also use a color conversion
    with floating-point images (in which case, the pixel values are generally assumed
    to vary between `0` and `1.0`) or with integer images (with pixels generally varying
    between `0` and `65535`). However, the exact domain of the pixel values depends
    on the specific color space and destination image type. For example, with the
    `CIE L*a*b*` color space, the `L` channel, which represents the brightness of
    each pixel, varies between `0` and `100`, and it is rescaled between `0` and `255`
    in the case of the 8-bit images.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 当图像从一个颜色空间转换为另一个颜色空间时，会对每个输入像素应用线性或非线性变换以生成输出像素。输出图像的像素类型将与输入图像的类型相匹配。即使你大多数时候使用8位像素，你也可以使用浮点图像（在这种情况下，像素值通常假设在`0`和`1.0`之间变化）或整数图像（像素值通常在`0`和`65535`之间变化）进行颜色转换。然而，像素值的精确范围取决于特定的颜色空间和目标图像类型。例如，对于`CIE
    L*a*b*`颜色空间，表示每个像素亮度的`L`通道在`0`和`100`之间变化，在8位图像的情况下，它被重新缩放到`0`和`255`之间。
- en: The `a` and `b` channels correspond to the chromaticity components. These channels
    contain information about the color of a pixel, independent of its brightness.
    Their values vary between `-127` and `127`; for 8-bit images, `128` is added to
    each value in order to make it fit within the `0` to `255` interval. However,
    note that the 8-bit color conversion will introduce rounding errors that will
    make the transformation imperfectly reversible.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`a`和`b`通道对应于色度成分。这些通道包含有关像素颜色的信息，与其亮度无关。它们的值在`-127`到`127`之间变化；对于8位图像，将`128`添加到每个值，以便使其适合`0`到`255`区间。然而，请注意，8位颜色转换将引入舍入误差，这将使转换不完全可逆。'
- en: Most commonly used color spaces are available. It is just a question of providing
    the right color space conversion code to the OpenCV function (for CIE L*a*b*,
    this code is `CV_BGR2Lab`). Among these is YCrCb, which is the color space used
    in JPEG compression. To convert a color space from BGR to YCrCb, the code will
    be `CV_BGR2YCrCb`. Note that all the conversions that involve the three regular
    primary colors, red, green, and blue, are available in the RGB and BGR order.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数常用的颜色空间都可用。这只是一个向OpenCV函数提供正确的颜色空间转换代码的问题（对于CIE L*a*b*，此代码为`CV_BGR2Lab`）。其中之一是YCrCb，这是JPEG压缩中使用的颜色空间。要将颜色空间从BGR转换为YCrCb，代码将是`CV_BGR2YCrCb`。请注意，涉及三种常规原色（红色、绿色和蓝色）的所有转换都在RGB和BGR顺序中可用。
- en: The **CIE L*u*v*** color space is another perceptually uniform color space.
    You can convert from BGR to CIE L*u*v by using the `CV_BGR2Luv` code. Both L*a*b*
    and L*u*v* use the same conversion formula for the brightness channel but use
    a different representation for the chromaticity channels. Also, note that since
    these two color spaces distort the RGB color domain in order to make it perceptually
    uniform, these transformations are nonlinear (therefore, they are costly to compute).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**CIE L*u*v**颜色空间是另一个感知均匀的颜色空间。您可以使用`CV_BGR2Luv`代码将BGR转换为CIE L*u*v。L*a*b*和L*u*v*使用相同的转换公式来表示亮度通道，但使用不同的表示来表示色度通道。此外，请注意，由于这两个颜色空间为了使其感知均匀而扭曲RGB颜色域，这些转换是非线性的（因此，它们在计算上成本较高）。'
- en: There is also the CIE XYZ color space (with the `CV_BGR2XYZ` code). It is a
    standard color space used to represent any perceptible color in a device-independent
    way. In the computation of the L*u*v and L*a*b color spaces, the XYZ color space
    is used as an intermediate representation. The transformation between RGB and
    XYZ is linear. It is also interesting to note that the `Y` channel corresponds
    to a gray-level version of the image.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有CIE XYZ颜色空间（使用`CV_BGR2XYZ`代码）。这是一个标准颜色空间，用于以设备无关的方式表示任何可感知的颜色。在计算L*u*v和L*a*b颜色空间时，XYZ颜色空间被用作中间表示。RGB和XYZ之间的转换是线性的。值得注意的是，`Y`通道对应于图像的灰度版本。
- en: HSV and HLS are interesting color spaces because they decompose the colors into
    their hue and saturation components plus the value or luminance component, which
    is a more natural way for humans to describe colors. The next recipe will present
    this color space.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: HSV和HLS是有趣的颜色空间，因为它们将颜色分解为其色调和饱和度成分以及亮度或亮度成分，这是人类描述颜色的一种更自然的方式。下一配方将介绍这个颜色空间。
- en: 'You can also convert color images to gray-level intensities. The output will
    be a one-channel image:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以将彩色图像转换为灰度强度。输出将是一个单通道图像：
- en: '[PRE26]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: It is also possible to do the conversion in the other direction, but the three
    channels of the resulting color image will then be identically filled with the
    corresponding values in the gray-level image.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以在相反的方向进行转换，但结果的颜色图像的三个通道将完全填充与灰度图像中相应的值。
- en: See also
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Using the mean shift algorithm to find an object* recipe in [Chapter 4](ch04.html
    "Chapter 4. Counting the Pixels with Histograms"), *Counting the Pixels with Histograms*,
    uses the HSV color space in order to find an object in an image.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第4章](ch04.html "第4章。使用直方图计数像素")中“使用直方图计数像素”的*使用均值漂移算法查找对象*配方使用HSV颜色空间来在图像中查找对象。'
- en: 'Many good references are available on the color space theory. Among them, the
    following is a complete reference: *The Structure and Properties of Color Spaces
    and the Representation of Color Images, E. Dubois, Morgan and Claypool Publishers,
    2009*.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于颜色空间理论有许多好的参考资料。其中之一是：*《颜色空间的结构和性质以及颜色图像的表示》，E. Dubois，Morgan and Claypool
    Publishers，2009*。
- en: Representing colors with hue, saturation, and brightness
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用色调、饱和度和亮度表示颜色
- en: In this chapter, we played with image colors. We used different color spaces
    and tried to identify image areas of uniform color. The RGB color space was initially
    considered, and although it is an effective representation for the capture and
    display of colors in electronic imaging systems, this representation is not very
    intuitive. Indeed, this is not the way humans think about colors; they most often
    describe colors in terms of their tint, brightness, or colorfulness (that is,
    whether it is a vivid or pastel color). A color space based on the concept of
    hue, saturation, and brightness has then been introduced to help users to specify
    the colors using properties that are more intuitive to them. In this recipe, we
    will explore the concepts of hue, saturation, and brightness as a means to describe
    colors.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们玩转了图像颜色。我们使用了不同的颜色空间，并试图识别具有均匀颜色的图像区域。最初考虑了RGB颜色空间，尽管它对于电子成像系统中的颜色捕捉和显示是有效的表示，但这种表示并不直观。确实，这不是人类思考颜色的方式；他们通常用色调、亮度或饱和度（即是否是鲜艳或柔和的颜色）来描述颜色。因此，引入了一个基于色调、饱和度和亮度的颜色空间，以帮助用户使用对他们来说更直观的属性来指定颜色。在本菜谱中，我们将探讨色调、饱和度和亮度作为描述颜色的手段。
- en: How to do it...
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The conversion of a BGR image into another color space is done using the `cv::cvtColor`
    function that was explored in the previous recipe. Here, we will use the `CV_BGR2HSV`
    conversion code:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 将BGR图像转换为另一个颜色空间是通过使用在上一节中探讨的`cv::cvtColor`函数来完成的。在这里，我们将使用`CV_BGR2HSV`转换代码：
- en: '[PRE27]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We can go back to the BGR space using the `CV_HSV2BGR` code. We can visualize
    each of the HSV components by splitting the converted image channels into three
    independent images, as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`CV_HSV2BGR`代码回到BGR空间。我们可以通过将转换后的图像通道分割成三个独立的图像来可视化每个HSV分量，如下所示：
- en: '[PRE28]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note that the third channel is the value of the color, that is, an approximate
    measure of the brightness of the color. Since we are working on 8-bit images,
    OpenCV rescales the channel values to cover the `0` to `255` range (except for
    the hue, which is rescaled between `0` and `0180` as it will be explained in the
    next section). This is very convenient as we are able to display these channels
    as gray-level images.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，第三个通道是颜色的值，即颜色的亮度的大致度量。由于我们正在处理8位图像，OpenCV会将通道值重新缩放到`0`到`255`的范围（除了色调，它将在下一节中解释，将重新缩放到`0`到`0180`）。这非常方便，因为我们能够将这些通道作为灰度图像显示。
- en: 'The value channel of the castle image will then look as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 城堡图像的亮度通道将看起来如下：
- en: '![How to do it...](img/image_03_008.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/image_03_008.jpg)'
- en: 'The same image in the saturation channel will look as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 同一图像在饱和度通道中将看起来如下：
- en: '![How to do it...](img/image_03_010.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/image_03_010.jpg)'
- en: 'Finally, the image with the hue channel is as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，带有色调通道的图像如下：
- en: '![How to do it...](img/B05388_03_07.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/B05388_03_07.jpg)'
- en: These images are interpreted in the next section.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图像将在下一节中进行解释。
- en: How it works…
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: The hue/saturation/value color space has been introduced because this representation
    corresponds to the way humans tend to naturally organize colors. Indeed, humans
    prefer to describe colors with intuitive attributes such as tint, colorfulness,
    and brightness. These three attributes are the basis of most phenomenal color
    spaces. **Hue** designates the dominant color; the names that we give to colors
    (such as green, yellow, blue, and red) correspond to the different hue values.
    **Saturation** tells us how vivid the color is; pastel colors have low saturation,
    while the colors of the rainbow are highly saturated. Finally, brightness is a
    subjective attribute that refers to the luminosity of a color. Other phenomenal
    color spaces use the concept of color **value** or color **lightness** as a way
    to characterize the relative color intensity.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 引入色调/饱和度/值颜色空间是因为这种表示方式与人类自然组织颜色的方式相对应。确实，人类更喜欢用直观的属性来描述颜色，如色调、饱和度和亮度。这三个属性是大多数现象颜色空间的基础。**色调**表示主导颜色；我们给颜色起的名字（如绿色、黄色、蓝色和红色）对应于不同的色调值。**饱和度**告诉我们颜色的鲜艳程度；柔和的颜色饱和度低，而彩虹的颜色饱和度高。最后，亮度是一个主观属性，指的是颜色的亮度。其他现象颜色空间使用颜色**值**或颜色**亮度**的概念作为表征相对颜色强度的方法。
- en: 'These color components try to mimic the intuitive human perception of colors.
    In consequence, there is no standard definition for them. In the literature, you
    will find several different definitions and formulae of the hue, saturation, and
    brightness. OpenCV proposes two implementations of phenomenal color spaces: the
    HSV and the HLS color spaces. The conversion formulas are slightly different,
    but they give very similar results.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这些颜色组件试图模仿人类对颜色的直观感知。因此，它们没有标准定义。在文献中，你会找到关于色调、饱和度和亮度的不同定义和公式。OpenCV提出了两种现象颜色空间的实现：HSV和HLS颜色空间。转换公式略有不同，但它们给出非常相似的结果。
- en: The value component is probably the easiest to interpret. In the OpenCV implementation
    of the HSV space, it is defined as the maximum value of the three BGR components.
    It is a very simplistic implementation of the brightness concept. For a definition
    of brightness that matches the human visual system better, you should use the
    L channel of the perceptually uniform L*a*b* and L*u*v* color spaces. For example,
    the L channel takes into account the fact that a green color appears to human
    brighter than, for instance, a blue color of same intensity.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 值组件可能是最容易解释的。在OpenCV实现的HSV空间中，它被定义为三个BGR组件的最大值。这是亮度概念的一种非常简单的实现。为了获得更符合人类视觉系统的亮度定义，你应该使用感知均匀的L*a*b*和L*u*v*颜色空间的L通道。例如，L通道考虑了绿色颜色看起来比相同强度的蓝色颜色更亮的事实。
- en: 'To compute the saturation, OpenCV uses a formula based on the minimum and maximum
    values of the BGR components:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算饱和度，OpenCV使用基于BGR组件最小值和最大值的公式：
- en: '![How it works…](img/B05388_03_13.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理…](img/B05388_03_13.jpg)'
- en: The idea is that a grayscale color in which the three R, G, and B components
    are all equal will correspond to a perfectly desaturated color; therefore, it
    will have a saturation value of `0`. Saturation is a value between `0` and `1.0`.
    For 8-bit images, saturation is rescaled to a value between `0` and `255`, and
    when displayed as a gray-level image, brighter areas correspond to the colors
    that have a higher saturation color.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 想法是，在灰度颜色中，三个R、G和B组件都相等时，将对应于完全未饱和的颜色；因此，它将有一个饱和度值为`0`。饱和度是一个介于`0`和`1.0`之间的值。对于8位图像，饱和度被缩放到介于`0`和`255`之间的值，并且当以灰度图像显示时，亮度区域对应于饱和度更高的颜色。
- en: For example, from the saturation image in the previous section, it can be seen
    that the blue of the water is more saturated than the light blue pastel color
    of the sky, as expected. The different shades of gray have, by definition, a saturation
    value equal to zero (because, in this case, all three BGR components are equal).
    This can be observed on the different roofs of the castle, which are made of a
    dark gray stone. Finally, in the saturation image, you may have noticed some white
    spots located in areas that correspond to very dark regions of the original image.
    These are a consequence of the used definition for saturation. Indeed, because
    saturation measures only the relative difference between the maximum and minimum
    BGR values, a triplet such as `(1,0,0)` gives a perfect saturation of `1.0`, even
    if this color would be seen as black. Consequently, the saturation values measured
    in dark regions are unreliable and should not be considered.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，从上一节的饱和度图像中可以看出，水的蓝色比天空的浅蓝色粉彩颜色饱和度更高，正如预期的那样。根据定义，不同灰度的饱和度值等于零（因为在这种情况下，所有三个BGR组件都相等）。这可以在城堡的不同屋顶上观察到，这些屋顶是由深灰色石头制成的。最后，在饱和度图像中，你可能已经注意到一些位于原始图像非常暗区域对应的白色斑点。这是使用饱和度定义的结果。事实上，因为饱和度只测量最大和最小BGR值之间的相对差异，所以像`(1,0,0)`这样的三元组给出完美的饱和度`1.0`，即使这种颜色看起来是黑色的。因此，在暗区域测量的饱和度值是不可靠的，不应予以考虑。
- en: The hue of a color is generally represented by an angle value between `0` and
    `360`, with the red color at `0` degrees. In the case of an 8-bit image, OpenCV
    divides this angle by two to fit within the 1-byte range. Therefore, each hue
    value corresponds to a given color tint independent of its brightness and saturation.
    For example, both the sky and the water have the same hue value, approximately
    `200` degrees (intensity, `100`), which corresponds to the blue shade; the green
    color of the trees in the background has a hue of around `90` degrees. It is important
    to note that hue is less reliable when evaluated for colors that have a very low
    saturation.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色的色调通常用一个介于 `0` 到 `360` 度之间的角度值来表示，红色在 `0` 度。在 8 位图像的情况下，OpenCV 将这个角度值除以二，以便适应
    1 字节的范围。因此，每个色调值对应于一种特定的颜色色调，与其亮度和饱和度无关。例如，天空和水都有相同的色调值，大约是 `200` 度（强度，`100`），这对应于蓝色调；背景中树木的绿色色调大约是
    `90` 度。需要注意的是，当评估饱和度非常低的颜色时，色调的可靠性较低。
- en: 'The HSB color space is often represented by a cone, where each point inside
    corresponds to a particular color. The angular position corresponds to the hue
    of the color, the saturation is the distance from the central axis, and the brightness
    is given by the height. The tip of the cone corresponds to the black color for
    which the hue and saturation are undefined:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: HSB 颜色空间通常用一个圆锥体来表示，其中圆锥体内部的每一个点都对应着一种特定的颜色。角度位置对应于颜色的色调，饱和度是距离中心轴的距离，亮度由高度决定。圆锥体的尖端对应于黑色，其色调和饱和度都是未定义的：
- en: '![How it works…](img/image_03_014.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理…](img/image_03_014.jpg)'
- en: We can also generate an artificial image that will illustrate the different
    hue/saturation combinations.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以生成一个将展示不同色调/饱和度组合的人工图像。
- en: '[PRE29]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The columns of the following screenshot show the different possible hues (from
    0 to 180), while the different lines illustrate the effect of saturation; the
    top part of the image shows fully saturated colors while the bottom part corresponds
    to unsaturated colors. A brightness value of `255` has been attributed to all
    the displayed colors:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个截图的列显示了不同的可能色调（从 0 到 180），而不同的线条说明了饱和度的影响；图像的上半部分显示了完全饱和的颜色，而下半部分则对应于不饱和的颜色。所有显示的颜色都被赋予了`255`的亮度值：
- en: '![How it works…](img/image_03_015.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理…](img/image_03_015.jpg)'
- en: 'Interesting effects can be created by playing with the HSV values. Several
    color effects that can be created using photo editing software are accomplished
    from this color space. For example, you may decide to modify an image by assigning
    a constant brightness to all the pixels of an image without changing the hue and
    saturation. This can be done as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调整 HSV 值可以创造出有趣的效果。使用照片编辑软件可以创建出多种颜色效果，这些效果都来自于这个颜色空间。例如，你可能决定通过为图像的所有像素分配一个恒定的亮度来修改图像，而不改变色调和饱和度。这可以按以下方式完成：
- en: '[PRE30]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This gives the following image, which now looks like a drawing.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下图像，现在看起来像一幅画。
- en: '![How it works…](img/image_03_017.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理…](img/image_03_017.jpg)'
- en: There's more…
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The HSV color space can also be very convenient to use when you want to look
    for objects of specific colors.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想寻找特定颜色的物体时，HSV 颜色空间也非常方便使用。
- en: Using colors for detection - skin tone detection
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用颜色进行检测 - 肤色检测
- en: Color information can be very useful for the initial detection of specific objects.
    For example, the detection of road signs in a driver-assistance application could
    rely on the colors of standard signs in order to quickly identify potential road
    sign candidates. The detection of skin color is another example in which the detected
    skin regions could be used as an indicator of the presence of a human in an image;
    this approach is very often used in gesture recognition where skin tone detection
    is used to detect hand positions.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色信息对于特定物体的初始检测非常有用。例如，在驾驶辅助应用中检测路标可能依赖于标准路标的颜色，以便快速识别潜在的路标候选者。检测肤色是另一个例子，检测到的皮肤区域可以用作图像中存在人类的指示器；这种方法在手势识别中非常常用，其中肤色检测用于检测手的位置。
- en: 'In general, to detect an object using color, you first need to collect a large
    database of image samples that contain the object captured from different viewing
    conditions. These will be used to define the parameters of your classifier. You
    also need to select the color representation that you will use for classification.
    For skin tone detection, many studies have shown that skin color from the diverse
    ethnical groups clusters well in the hue/saturation space. For this reason, we
    will simply use the hue and saturation values to identify the skin tones in the
    following image:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，要使用颜色检测一个对象，你首先需要收集一个包含从不同观察条件下捕获的对象的大数据库图像样本。这些将被用来定义你的分类器的参数。你还需要选择你将用于分类的颜色表示。对于肤色检测，许多研究表明，来自不同种族群体的肤色在色调/饱和度空间中聚类良好。因此，我们将简单地使用色调和饱和度值来识别以下图像中的肤色：
- en: '![Using colors for detection - skin tone detection](img/image_03_018.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![使用颜色进行检测 - 肤色检测](img/image_03_018.jpg)'
- en: 'We have defined a function that classifies the pixels of an image as skin or
    non-skin simply based on an interval of values (the minimum and maximum hue, and
    the minimum and maximum saturation):'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个函数，该函数仅基于一组值（最小和最大色调，以及最小和最大饱和度）将图像的像素分类为肤色或非肤色：
- en: '[PRE31]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Having a large set of skin (and non-skin) samples at our disposal, we could
    have used a probabilistic approach in which the likelihood of observing a given
    color in the skin class versus that of observing the same color in the non-skin
    class would have been estimated. Here, we empirically define an acceptable hue/saturation
    interval for our test image (remember that the 8-bit version of the hue goes from
    `0` to `180` and saturation goes from `0` to `255`):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有大量肤色（和非肤色）样本，我们可以使用一种概率方法，其中将估计在肤色类别中观察到给定颜色的可能性与在非肤色类别中观察到相同颜色的可能性。在这里，我们根据经验定义了我们测试图像的可接受色调/饱和度区间（记住，色调的8位版本从`0`到`180`，饱和度从`0`到`255`）：
- en: '[PRE32]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following detection image is obtained as the result:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下检测图像是作为结果获得的：
- en: '![Using colors for detection - skin tone detection](img/image_03_020.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![使用颜色进行检测 - 肤色检测](img/image_03_020.jpg)'
- en: Note that, for simplicity, we have not considered color brightness in the detection.
    In practice, excluding brighter colors would have reduced the possibility of wrongly
    detecting a bright reddish colors as skin. Obviously, a reliable and accurate
    detection of skin color would require a much more elaborate analysis. It is also
    very difficult to guarantee good detection across different images because many
    factors influence color rendering in photography, such as white balancing and
    lighting conditions. Nevertheless, as shown here, using hue/saturation information
    as an initial detector gives us acceptable results.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，为了简化，我们没有在检测中考虑颜色亮度。实际上，排除较亮的颜色会减少错误地将明亮的红色视为肤色的可能性。显然，要可靠且准确地检测肤色，需要进行更复杂的分析。同时，由于许多因素会影响摄影中的颜色渲染，如白平衡和光照条件，因此很难保证在不同图像上都能获得良好的检测效果。尽管如此，正如这里所示，使用色调/饱和度信息作为初始检测器可以给我们带来可接受的结果。
- en: See also
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考内容
- en: '[Chapter 5](ch05.html "Chapter 5. Transforming Images with Morphological Operations"),
    *Transforming Images with Morphological Operations*, shows you how to post-process
    binary images obtained from detection'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第五章](ch05.html "第五章. 使用形态学操作转换图像"), 《使用形态学操作转换图像》展示了如何对检测得到的二值图像进行后处理'
- en: The article, *A survey of skin-color modeling and detection methods, Pattern
    Recognition, vol. 40, 2007, P. Kakumanu, S. Makrogiannis, N. Bourbakis*, reviews
    different methods of skin detection
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文章《皮肤颜色建模与检测方法综述，模式识别，第40卷，2007年，作者：Kakumanu P.，Makrogiannis S.，Bourbakis N.》回顾了不同的皮肤检测方法
