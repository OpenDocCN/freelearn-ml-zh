["```py\n    import pandas\n    import numpy as np\n    import mlflow\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.metrics import f1_score, confusion_matrix\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n    df = (spark.read.option(\"header\",\"true\").csv(\"/FileStore/tables/training_data.csv\"))\n    pandas_df = df.toPandas()\n    X=pandas_df.iloc[:,:-1]\n    Y=pandas_df.iloc[:,-1]\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=4284, stratify=Y)\n    ```", "```py\n    mlflow.sklearn.autolog()\n    model = LogisticRegression()\n    with mlflow.start_run(run_name='logistic_regression_model_baseline') as run:\n        model.fit(X_train, y_train)\n        preds = model.predict(X_test)\n    ```", "```py\n    import mlflow\n    logged_model = 'runs:/6815b44128e14df2b356c9db23b7f936/model'\n    df = spark.read.format(\"csv\").load(\"dbfs:/FileStore/shared_uploads/ input.csv\")\n    # Load model as a Spark UDF.\n    loaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model)\n    # Predict on a Spark DataFrame.\n    df.withColumn('predictions', loaded_model()).collect()\n    ```", "```py\n    import argparse\n    from functools import partial\n    import mlflow\n    import mlflow.sklearn\n    from cuml.metrics.accuracy import accuracy_score\n    from cuml.preprocessing.model_selection import train_test_split\n    from cuml.ensemble import RandomForestClassifier\n    from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n    ```", "```py\n    def load_data(fpath):\n        import cudf\n        df = cudf.read_parquet(fpath)\n        X = df.drop([\"ArrDelayBinary\"], axis=1)\n        y = df[\"ArrDelayBinary\"].astype(\"int32\")\n        return train_test_split(X, y, test_size=0.2)Start the ray server \n    ray.init()\n    client = serve.start()\n    ```", "```py\n    def _train(params, fpath):\n        max_depth, max_features, n_estimators = params\n        max_depth, max_features, n_estimators = (int(max_\n    depth), float(max_features), int(n_estimators))\n        X_train, X_test, y_train, y_test = load_data(fpath)\n        mod = RandomForestClassifier(\n            max_depth=max_depth, max_features=max_features, n_estimators=n_estimators\n        )\n        mod.fit(X_train, y_train)\n        preds = mod.predict(X_test)\n        acc = accuracy_score(y_test, preds)\n        mlparams = {\n            \"max_depth\": str(max_depth),\n            \"max_features\": str(max_features),\n            \"n_estimators\": str(n_estimators),\n        }\n        mlflow.log_params(mlparams)\n        mlflow.log_metric(\"accuracy\", acc)\n        mlflow.sklearn.log_model(mod, \"saved_models\")\n        return {\"loss\": acc, \"status\": STATUS_OK}\n    ```", "```py\n    def train(params, fpath, hyperopt=False):\n\n        with mlflow.start_run(nested=True):\n            return _train(params, fpath, hyperopt)\n    ```", "```py\n    if __name__ == \"__main__\":\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\"--algo\", default=\"tpe\", \n    choices=[\"tpe\"], type=str)\n        parser.add_argument(\"--conda-env\", required=True, type=str)\n        parser.add_argument(\"--fpath\", required=True, type=str)\n        args = parser.parse_args()\n    ```", "```py\n        search_space = [\n            hp.uniform(\"max_depth\", 5, 20),\n            hp.uniform(\"max_features\", 0.1, 1.0),\n            hp.uniform(\"n_estimators\", 150, 1000),\n        ]\n        trials = Trials()\n        algorithm = tpe.suggest if args.algo == \"tpe\" else None\n        fn = partial(train, fpath=args.fpath, hyperopt=True)\n        experid = 0\n    ```", "```py\n        artifact_path = \"Airline-Demo\"\n        artifact_uri = None\n        with mlflow.start_run(run_name=\"RAPIDS-Hyperopt\"):\n            argmin = fmin(fn=fn, space=search_space, algo=algorithm, max_evals=2, trials=trials)\n            print(\"===========\")\n            fn = partial(train, fpath=args.fpath, hyperopt=False)\n            final_model = fn(tuple(argmin.values()))\n            mlflow.sklearn.log_model(\n                final_model,\n                artifact_path=artifact_path,\n                registered_model_name=\"rapids_mlflow_cli\",\n                conda_env=\"envs/conda.yaml\",\n            )\n    ```", "```py\n    pip install -U ray\n    ```", "```py\n    import ray\n    from ray import serve\n    import mlflow.pyfunc\n    ```", "```py\n    class MLflowBackend:\n        def __init__(self, model_uri):\n            self.model = mlflow.pyfunc.load_model(model_\n    uri=model_uri)\n        async def __call__(self, request):\n            return self.model.predict(request.data)\n    ```", "```py\n    ray.init()\n    client = serve.start()\n    ```", "```py\n    model_uri = \"./tmp/0/31fc9974587243d181fdbebfd4d2b6ad/artifacts/model\"\n    client.create_backend(\"mlflow_backend\", MLflowBackend, model_uri)\n    ```", "```py\n    ray start --head # Start local Ray cluster.\n    serve start # Start Serve on the local Ray cluster.\n    ```"]