["```py\n\nbuying 0      v-high, high, med, low\n\nmaintenance 1  v-high, high, med, low\n\ndoors 2       2, 3, 4, 5-more\n\npersons 3     2, 4, more\n\nlug_boot 4    small, med, big\n\nsafety 5      low, med, high\n\ncar evaluation 6 unacc,acc,good,vgood\n\n```", "```py\n'acc': 0, 'unacc': 2, 'good': 1, 'vgood': 3\n```", "```py\n\nclass HMM:\n\n def __init__(self):\n\nself.pi = pi\n\n self.A = A\n\n self.B = B\n\n```", "```py\n\n def ViterbiSequence(self,observations):\n\n deltas = [{}]\n\n seq = {}\n\n N = self.A.shape[0]\n\n states = [i for i in range(N)]\n\n T = len(observations)\n\n #initialization\n\n for s in states:\n\n deltas[0][s] = self.pi[s]*self.B[s,observations[0]]\n\n seq[s] = [s]\n\n #compute Viterbi\n\n for t in range(1,T):\n\n deltas.append({})\n\n newseq = {}\n\n for s in states:\n\n (delta,state) = max((deltas[t-1][s0]*self.A[s0,s]*self.B[s,observations[t]],s0) for s0 in states)\n\n deltas[t][s] = delta\n\n newseq[s] = seq[state] + [s]\n\n seq = newseq\n\n (delta,state) = max((deltas[T-1][s],s) for s in states)\n\n return  delta,' sequence: ', seq[state]\n\n def maxProbSequence(self,observations):\n\n N = self.A.shape[0]\n\n states = [i for i in range(N)]\n\n T = len(observations)\n\n M = self.B.shape[1]\n\n # alpha_t(i) = P(O_1 O_2 ... O_t, q_t = S_i | hmm)\n\n # Initialize alpha\n\n alpha = np.zeros((N,T))\n\n c = np.zeros(T) #scale factors\n\n alpha[:,0] = pi.T * self.B[:,observations[0]]\n\n c[0] = 1.0/np.sum(alpha[:,0])\n\n alpha[:,0] = c[0] * alpha[:,0]\n\n # Update alpha for each observation step\n\n for t in range(1,T):\n\n alpha[:,t] = np.dot(alpha[:,t-1].T, self.A).T * self.B[:,observations[t]]\n\n c[t] = 1.0/np.sum(alpha[:,t])\n\n alpha[:,t] = c[t] * alpha[:,t]\n\n # beta_t(i) = P(O_t+1 O_t+2 ... O_T | q_t = S_i , hmm)\n\n # Initialize beta\n\n beta = np.zeros((N,T))\n\n beta[:,T-1] = 1\n\n beta[:,T-1] = c[T-1] * beta[:,T-1]\n\n # Update beta backwards froT end of sequence\n\n for t in range(len(observations)-1,0,-1):\n\n beta[:,t-1] = np.dot(self.A, (self.B[:,observations[t]] * beta[:,t]))\n\n beta[:,t-1] = c[t-1] * beta[:,t-1]\n\n norm = np.sum(alpha[:,T-1])\n\n seq = ''\n\n for t in range(T):\n\n g,state = max(((beta[i,t]*alpha[i,t])/norm,i) for i in states)\n\n seq +=str(state)\n\n return seq\n\n```", "```py\n\npi = np.array([0.6, 0.4])\n\nA = np.array([[0.7, 0.3],\n\n [0.6, 0.4]])\n\nB = np.array([[0.7, 0.1, 0.2],\n\n [0.1, 0.6, 0.3]]) \n\nhmmguess = HMM(pi,A,B) \n\nprint 'Viterbi sequence:',hmmguess.ViterbiSequence(np.array([0,1,0,2]))\n\nprint 'max prob sequence:',hmmguess.maxProbSequence(np.array([0,1,0,2])) \n\n```", "```py\n\nViterbi: (0.0044, 'sequence: ', [0, 1, 0, 0])\n\nMax prob sequence: 0100\n\n```", "```py\n\n def train(self,observations,criterion):\n\n N = self.A.shape[0]\n\n T = len(observations)\n\n M = self.B.shape[1]\n\n A = self.A\n\n B = self.B\n\n pi = copy(self.pi)\n\n convergence = False\n\n while not convergence:\n\n # alpha_t(i) = P(O_1 O_2 ... O_t, q_t = S_i | hmm)\n\n # Initialize alpha\n\n alpha = np.zeros((N,T))\n\n c = np.zeros(T) #scale factors\n\n alpha[:,0] = pi.T * self.B[:,observations[0]]\n\n c[0] = 1.0/np.sum(alpha[:,0])\n\n alpha[:,0] = c[0] * alpha[:,0]\n\n # Update alpha for each observation step\n\n for t in range(1,T):\n\n alpha[:,t] = np.dot(alpha[:,t-1].T, self.A).T * self.B[:,observations[t]]\n\n c[t] = 1.0/np.sum(alpha[:,t])\n\n alpha[:,t] = c[t] * alpha[:,t]\n\n #P(O=O_0,O_1,...,O_T-1 | hmm)\n\n P_O = np.sum(alpha[:,T-1])\n\n # beta_t(i) = P(O_t+1 O_t+2 ... O_T | q_t = S_i , hmm)\n\n # Initialize beta\n\n beta = np.zeros((N,T))\n\n beta[:,T-1] = 1\n\n beta[:,T-1] = c[T-1] * beta[:,T-1]\n\n # Update beta backwards froT end of sequence\n\n for t in range(len(observations)-1,0,-1):\n\n beta[:,t-1] = np.dot(self.A, (self.B[:,observations[t]] * beta[:,t]))\n\n beta[:,t-1] = c[t-1] * beta[:,t-1]\n\n gi = np.zeros((N,N,T-1));\n\n for t in range(T-1):\n\n for i in range(N):\n\n gamma_num = alpha[i,t] * self.A[i,:] * self.B[:,observations[t+1]].T * \\\n\n beta[:,t+1].T\n\n gi[i,:,t] = gamma_num / P_O\n\n # gamma_t(i) = P(q_t = S_i | O, hmm)\n\n gamma = np.squeeze(np.sum(gi,axis=1))\n\n # Need final gamma element for new B\n\n prod =  (alpha[:,T-1] * beta[:,T-1]).reshape((-1,1))\n\n gamma_T = prod/P_O\n\n gamma = np.hstack((gamma,  gamma_T)) #append one Tore to gamma!!!\n\n newpi = gamma[:,0]\n\n newA = np.sum(gi,2) / np.sum(gamma[:,:-1],axis=1).reshape((-1,1))\n\n newB = copy(B)\n\n sumgamma = np.sum(gamma,axis=1)\n\n for ob_k in range(M):\n\n list_k = observations == ob_k\n\n newB[:,ob_k] = np.sum(gamma[:,list_k],axis=1) / sumgamma\n\n if np.max(abs(pi - newpi)) < criterion and \\\n\n np.max(abs(A - newA)) < criterion and \\\n\n np.max(abs(B - newB)) < criterion:\n\n convergence = True;\n\n A[:],B[:],pi[:] = newA,newB,newpi\n\n self.A[:] = newA\n\n self.B[:] = newB\n\n self.pi[:] = newpi\n\n self.gamma = gamma\n\n```"]