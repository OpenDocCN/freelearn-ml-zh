<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer259">
			<h1 id="_idParaDest-203"><em class="italic"><a id="_idTextAnchor202"/>Chapter 13</em>: Building a Recommendation Engine in Azure</h1>
			<p>In the previous chapter, we discussed distributed training methods for ML models, and you learned how to train distributed ML models efficiently in Azure. In this chapter, we will dive into traditional and modern recommendation engines, which often combine technologies and techniques covered in the previous chapters.</p>
			<p>First, we will take a quick look at the different types of recommendation engines, what data is needed for each type, and what can be recommended using these different approaches. This will help you understand when to choose from non-personalized, content-based, or rating-based recommenders.</p>
			<p>After this, we will dive into content-based recommendations, namely item-item and user-user recommenders, based on feature vectors and similarity. You will learn about cosine distance to measure the similarity between feature vectors and feature engineering techniques to avoid common pitfalls while building content-based recommendation engines.</p>
			<p>Subsequently, we will discuss rating-based recommendations that can be used once enough user-item interaction data has been collected. You will learn the difference between implicit and explicit ratings, develop your own implicit metric function, and think about the recency of user ratings.</p>
			<p>In the section following this, we will combine content- and rating-based recommenders into a single hybrid recommender and learn about state-of-the-art techniques for modern recommendation engines. You will implement two recommenders using Azure Machine Learning, one using Python and one using Azure Machine Learning designer – the graphical UI of Azure Machine Learning.</p>
			<p>In the last section, we will look into an online recommender system as a service using reinforcement learning – Azure Personalizer. Having understood both content- and rating-based methods, you will learn how to improve your recommendations on the fly using a fitness function and online learning.</p>
			<p>The following topics will be covered in this chapter:</p>
			<ul>
				<li>An introduction to recommendation engines</li>
				<li>A content-based recommender system</li>
				<li>Collaborative filtering – a rating-based recommender system</li>
				<li>Combining content and ratings in hybrid recommendation engines</li>
				<li>Automatic optimization through reinforcement learning</li>
			</ul>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor203"/>Technical requirements</h1>
			<p>In this chapter, we will use the following Python libraries and versions to create content- and rating-based recommendation engines, as well as hybrid and online recommenders:</p>
			<ul>
				<li><strong class="source-inline">azureml-core 1.34.0 </strong></li>
				<li><strong class="source-inline">azureml-sdk 1.34.0 </strong></li>
				<li><strong class="source-inline">numpy 1.19.5 </strong></li>
				<li><strong class="source-inline">scipy 1.7.1 </strong></li>
				<li><strong class="source-inline">pandas 1.3.2 </strong></li>
				<li><strong class="source-inline">scikit-learn 0.24.2 </strong></li>
				<li><strong class="source-inline">lightgbm 3.2.1 </strong></li>
				<li><strong class="source-inline">pyspark 3.2.0 </strong></li>
				<li><strong class="source-inline">azure-cognitiveservices-personalizer 0.1.0</strong></li>
			</ul>
			<p>Similar to previous chapters, you can run this code using either a local Python interpreter or a notebook environment hosted in Azure Machine Learning.</p>
			<p>For the Matchbox recommender example, you need to use Azure Machine Learning designer in your Azure Machine Learning workspace. For Azure Personalizer, you need to set up an Azure Personalizer resource in the Azure portal.</p>
			<p>All code examples in this chapter can be found in the GitHub repository for this book: <a href="https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter13">https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter13</a>.</p>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor204"/>Introduction to recommendation engines</h1>
			<p>In today's digital world, recommendation engines <a id="_idIndexMarker1472"/>are ubiquitous among many industries. Many online businesses, such as streaming, shopping, news, and social media, rely at their core on recommending the most relevant articles, news, and items to their users. How often have you clicked on a suggested video on YouTube, scrolled through your Facebook feed, listened to a personalized playlist on Spotify, or clicked on a recommended item on Amazon?</p>
			<p>If you ask yourself what the term <em class="italic">relevant</em> means for the different services and industries, you are on the right track. In order to recommend relevant information to the user, we need to first define a relevancy metric, and a way to describe and compare different items and their similarity. These two properties are the key to understanding the different recommendation engines. We will learn more about this in the following sections of this chapter.</p>
			<p>While the purpose<a id="_idIndexMarker1473"/> of a recommendation engine is clear to most people, the different approaches are usually not. Hence, in order to better understand this, in this chapter, we will compare the different types of recommender systems and give some examples of them that you might have seen in your daily life. It's also worth mentioning that many services implement more than one of these approaches to produce great recommendations.</p>
			<p>The easiest<a id="_idIndexMarker1474"/> recommendation engines and methods are <em class="italic">non-personalized</em> recommendations. They <a id="_idIndexMarker1475"/>are often used to show global interest (for example, Twitter global trends, popular Netflix shows, and a news website's front page) or trends where no user data is available. A good example is the recommendations of any streaming service that appear when you register and log into the service for the first time.</p>
			<p>Once you log into a web<a id="_idIndexMarker1476"/> service and start using it moderately, you are usually confronted <a id="_idIndexMarker1477"/>with <em class="italic">content-based recommendations</em>. Content-based recommenders look for similar items or items of similar users, based on the item and user profile features. User profile items <a id="_idIndexMarker1478"/>can contain many personality-based or socio-demographic traits including the following:</p>
			<ul>
				<li>Age</li>
				<li>Gender</li>
				<li>Nationality</li>
				<li>Country of residence</li>
				<li>Mother tongue</li>
			</ul>
			<p>Imagine<a id="_idIndexMarker1479"/> logging into Amazon without having bought anything there yet. Most recommended items will be similar to the ones you just viewed or the ones matching your demographics and location.</p>
			<p>Once enough interaction data is available, you will start seeing <em class="italic">rating-based recommendations</em>, a<a id="_idIndexMarker1480"/> method that is also <a id="_idIndexMarker1481"/>called collaborative filtering. In rating-based recommenders, the users' interactions <a id="_idIndexMarker1482"/>with items are transformed into explicit or implicit ratings. Based on these ratings, recommendations are made based on similar recommendations given by other users. Rating a movie on Netflix is an explicit rating, while watching a full 20-minute documentary on YouTube is an implicit rating. Therefore, a user will be shown movies liked by other people who also liked the movie that you just rated. And similarly, YouTube will show videos watched by other users who also watched the video you just saw.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Microsoft provides many different implementations for popular recommendation engines in their GitHub repository at <a href="https://github.com/Microsoft/Recommenders/">https://github.com/Microsoft/Recommenders/</a>. This makes it easy to get started, pick the right algorithm, and implement, train, and deploy a recommendation engine on Azure.</p>
			<p>The next natural step is to combine both content- and rating-based recommenders into a single <em class="italic">hybrid recommendation engine</em> that <a id="_idIndexMarker1483"/>can <a id="_idIndexMarker1484"/>deal with both user ratings and cold-start users, who are users without ratings. The benefit of this approach is that both recommender systems are optimized together and create a combined recommendation. Azure Machine Learning Studio (classic) and Azure Machine Learning designer provide the building blocks to train and deploy the Matchbox recommender, an online<a id="_idIndexMarker1485"/> Bayesian hybrid <a id="_idIndexMarker1486"/>recommendation engine built by Microsoft Research.</p>
			<p>Another exciting new development in the past year was the introduction of hybrid online recommender optimization based on reinforcement learning. By providing a fitness function for the user rating, the algorithm can continuously learn to optimize this function. In the last section of this chapter, we will take a look at Azure Personalizer, a reinforcement learning-based recommendation engine as a service.</p>
			<p>Let's dive right into the methods discussed and develop some example solutions for scalable recommendation engines in Azure.</p>
			<h1 id="_idParaDest-206"><a id="_idTextAnchor205"/>A content-based recommender system</h1>
			<p>We first start with <a id="_idIndexMarker1487"/>content-based recommendations, as they are the most similar to what we previously discussed in this book. The term <em class="italic">content</em> refers <a id="_idIndexMarker1488"/>to the usage of only an item's or user's content information in the shape of a (numeric) feature vector. The way to arrive at a feature vector from an item (an article in a web shop) or a user (a browser session in a web service) is through data mining, data pre-processing, and feature engineering – skills you learned in the previous chapters.</p>
			<p>Using users' and items' feature vectors, we <a id="_idIndexMarker1489"/>can divide<a id="_idIndexMarker1490"/> content-based recommendations into roughly two approaches:</p>
			<ul>
				<li>Item-item similarity</li>
				<li>User-user similarity</li>
			</ul>
			<p>Hence, recommendations <a id="_idIndexMarker1491"/>are based on the similarity of items or the similarity of users. Both approaches work great in cases <a id="_idIndexMarker1492"/>where little to no interaction data between user and items is available (for example, a user with no purchase history on Amazon, no search history on YouTube, or no movies yet watched on Netflix – the so-called cold-start problem).</p>
			<p>You will always have to deal with the cold-start problem the moment you decide to roll out recommendations or the moment a new user starts using your service. In both cases, you don't have sufficient user-item interactions (so-called ratings) available and need to recommend items based on content only.</p>
			<p>For the <a id="_idIndexMarker1493"/>first approach, we design a system that recommends similar items to the one a user currently interacts with. When a user looks at an item, the recommender returns the most similar items. The<a id="_idIndexMarker1494"/> item similarity is based on the similarity of the item's feature vectors – we will see in the subsequent section how to compute this similarity. This approach can be used when no or little user interaction data is available. <em class="italic">Figure 13.1</em> visualizes this approach of recommending similar items based on content features and a single user interaction:</p>
			<div>
				<div id="_idContainer248" class="IMG---Figure">
					<img src="image/B17928_13_01.jpg" alt="Figure 13.1 – Finding similar products using a content-based recommendation " width="872" height="292"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.1 – Finding similar products using a content-based recommendation</p>
			<p>Creating a playlist on Spotify will yield a box with recommended songs at the bottom, as shown in <em class="italic">Figure 13.2</em>. We can see that the recommended songs are based on the songs in the playlist; hence, it is similar content:</p>
			<div>
				<div id="_idContainer249" class="IMG---Figure">
					<img src="image/B17928_13_02.jpg" alt="Figure 13.2 – Spotify's recommended songs " width="1081" height="732"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.2 – Spotify's recommended songs</p>
			<p>We can<a id="_idIndexMarker1495"/> see songs<a id="_idIndexMarker1496"/> listed that are similar to the ones in the playlist – similar in terms of genre, style, artists, and many more features.</p>
			<p>Clicking on a product on Amazon will yield a box with related products at the bottom of the page, as shown in <em class="italic">Figure 13.3</em>. Again, similar products mean it is a content-based recommendation:</p>
			<div>
				<div id="_idContainer250" class="IMG---Figure">
					<img src="image/B17928_13_03.jpg" alt="Figure 13.3 – Amazon's recommended products " width="1242" height="468"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.3 – Amazon's recommended products</p>
			<p>This recommendation has nothing to do with your previous shopping experience and can be displayed even when no user-purchase history is found.</p>
			<p>In the second approach, the <a id="_idIndexMarker1497"/>system recommends similar users based on a user profile. From those similar users, we <a id="_idIndexMarker1498"/>can then select the favorite items and present them as a recommendation. Please note that in digital systems, the user profile can be implicitly defined via location (for example, through an IP address), language, demographic, and device fingerprinting. This technique can be used when user-item interaction data is available from other users but not for the current user. <em class="italic">Figure 13.4</em> visualizes this recommendation of the purchases of a similar user based on content features:</p>
			<div>
				<div id="_idContainer251" class="IMG---Figure">
					<img src="image/B17928_13_04.jpg" alt="Figure 13.4 – Finding similar users using a content-based recommendation " width="930" height="314"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.4 – Finding similar users using a content-based recommendation</p>
			<p>From a user's perspective, it is usually hard to distinguish between this kind of recommendation and a non-personalized recommendation (for example, the top products in your location for your demographic or your language – all properties that can be extracted from your browser's fingerprint).</p>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor206"/>Measuring the similarity between items</h2>
			<p>The <a id="_idIndexMarker1499"/>crucial part of training a content-based recommendation engine is to specify a metric that can measure and rank the <a id="_idIndexMarker1500"/>similarity between two items. A popular choice is <a id="_idIndexMarker1501"/>to use the <strong class="bold">cosine similarity</strong> or <strong class="bold">cosine distance</strong> between the items' feature vectors to measure the similarity between two items. The <em class="italic">cosine similarity</em> is <a id="_idIndexMarker1502"/>computed as the cosine of the angle between two vectors where a vector is an observation in the dataset. The <em class="italic">cosine distance</em> is computed as 1 minus the cosine similarity. <em class="italic">Figure 13.5</em> shows two numeric feature vectors and the cosine distance between the feature vectors:</p>
			<div>
				<div id="_idContainer252" class="IMG---Figure">
					<img src="image/B17928_13_05.jpg" alt="Figure 13.5 – Cosine distance " width="921" height="461"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.5 – Cosine distance</p>
			<p>We can see in <a id="_idIndexMarker1503"/>the figure that if both vectors are the same, the cosine distance between the two vectors is 0. On the other hand, the cosine similarity yields 1 when both vectors are pointing in the same direction, and 0 when both vectors are orthogonal to each other; hence, there is no similarity between the observations.</p>
			<p>If you are unsure, you can always compute the cosine distance or similarity between two feature vectors using the following code (make sure that your DataFrame (<strong class="source-inline">df</strong>) has no additional <strong class="source-inline">id</strong> column and all columns are numeric):</p>
			<p class="source-code">from scipy import spatial</p>
			<p class="source-code">f1 = df.iloc[0, :]</p>
			<p class="source-code">f2 = df.iloc[1, :]</p>
			<p class="source-code"># compute the cosine distance between the first 2 rows</p>
			<p class="source-code">cosine_distance = spatial.distance.cosine(f1, f2)</p>
			<p class="source-code">print(cosine_distance)</p>
			<p class="source-code"># compute the cosine similarity between the first 2 rows</p>
			<p class="source-code">cosine_similarity = 1 - spatial.distance.cosine(f1, f2)</p>
			<p class="source-code">print(cosine_similarity)</p>
			<p>Looking<a id="_idIndexMarker1504"/> at the preceding snippet, I recommend you pick a few rows from your dataset, estimate their similarity (1 if they are the same or 0 if they are completely different), and then compute the cosine similarity using the aforementioned approach. If your guess and the computed approach are very different and you don't understand the reason, you'd better go back to data pre-processing and feature engineering. In the next section, you will learn the most common mistakes in feature engineering for recommender systems.</p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor207"/>Feature engineering for content-based recommenders</h2>
			<p>Training a<a id="_idIndexMarker1505"/> content-based recommendation engine is very similar to training a classical ML model. For end-to-end ML pipelines, all the steps, such as data preparation, training, validation, optimization, and deployment, are the same and use very similar or even the same tools and libraries as any traditional embedding, clustering, regression, or classification technique.</p>
			<p>As for <a id="_idIndexMarker1506"/>most other ML algorithms, great<a id="_idIndexMarker1507"/> feature engineering is the key to good results from a recommendation engine. The difficulty for clustering-based recommenders is that most embeddings and similarity metrics only work in numeric space. While other techniques, such as tree-based classifiers, give you more freedom in the structure of input data, many clustering techniques require numeric features.</p>
			<p>Another important factor for training content-based recommenders is the semantic meaning of <a id="_idIndexMarker1508"/>categorical features. Therefore, you most likely want to use advanced natural language processing<strong class="bold"> </strong>methods to embed categorical features into numerical space to capture this semantic meaning and provide it for the recommendation engine. The reason for the effect of categorical features in recommendation systems is based on the way similarity is measured.</p>
			<p>As we discussed in the previous section, a similarity is often expressed/measured as the cosine similarity and, hence, computing the cosine between two feature vectors. Therefore, even if there is only a single different character between two categorical values, those categorical values would yield a similarity of 0 using one-hot encoding – although they<a id="_idIndexMarker1509"/> are semantically very similar. Using simple label encoding, the results are even less obvious. With label encoding, the resulting similarity is now not only 0 but a non-interpretable value different from 0.</p>
			<p>Therefore, we<a id="_idIndexMarker1510"/> recommend semantic embedding of nominal/textual variables in order to capture their semantic meaning in numeric space and avoid common pitfalls, with categorical embeddings leaking into the similarity metric.</p>
			<p>In general, there are two possible ways to implement content-based recommenders. If you are looking for a pure similarity, you can use any non-supervised embedding and clustering technique for finding similar items or users. The second possibility is to implement the recommender as a regression or classification technique. With this, you can predict a discrete or continuous value of relevance for all items, only considering item features or combinations of an item and user features. We will take a look at an example method in the subsequent section.</p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor208"/>Content-based recommendations using gradient boosted trees</h2>
			<p>For our <a id="_idIndexMarker1511"/>content-based model, we will use<a id="_idIndexMarker1512"/> the <em class="italic">Criteo dataset</em> to<a id="_idIndexMarker1513"/> predict the <strong class="bold">Click-Through Rate</strong> (<strong class="bold">CTR</strong>) per article, based on article features. We will use the predicted CTR to recommend articles with the highest predicted CTR. As you can see, it's very simple to formulate a <a id="_idIndexMarker1514"/>content-based recommendation engine as a standard classification or regression problem.</p>
			<p>For this example, we will use a gradient-boosted tree regressor from LightGBM. The model to predict the CTR is very similar to any regression model previously trained in this book. Let's get started:</p>
			<ol>
				<li>First, we define the parameters for the LightGBM model:<p class="source-code">params = {</p><p class="source-code">    'task': 'train',</p><p class="source-code">    'boosting_type': 'gbdt',</p><p class="source-code">    'num_class': 1,</p><p class="source-code">    'objective': "binary",</p><p class="source-code">    'metric': "auc",</p><p class="source-code">    'num_leaves': 64,</p><p class="source-code">    'min_data': 20,</p><p class="source-code">    'boost_from_average': True,</p><p class="source-code">    'feature_fraction': 0.8,</p><p class="source-code">    'learning_rate': 0.15,</p><p class="source-code">}</p></li>
				<li>Next, we <a id="_idIndexMarker1515"/>define <a id="_idIndexMarker1516"/>the training and test set as LightGBM datasets:<p class="source-code">lgb_train = lgb.Dataset(x_train,</p><p class="source-code">                        y_train.reshape(-1),</p><p class="source-code">                        params=params)</p><p class="source-code">lgb_test = lgb.Dataset(x_test,</p><p class="source-code">                       y_test.reshape(-1),</p><p class="source-code">                       reference=lgb_train)</p></li>
				<li>Using this information, we can now train the model:<p class="source-code">lgb_model = lgb.train(params,</p><p class="source-code">                      lgb_train,</p><p class="source-code">                      num_boost_round=100)</p></li>
				<li>Finally, we can evaluate the model performance by predicting the CTR and computing the area under the ROC curve as an error metric:<p class="source-code">y_pred = lgb_model.predict(x_test)</p><p class="source-code">auc = roc_auc_score(np.asarray(y_test.reshape(-1)), </p><p class="source-code">                    np.asarray(y_pred))</p></li>
			</ol>
			<p>Great! You have<a id="_idIndexMarker1517"/> learned to create recommendations based on item similarities. However, these recommendations have a poor diversity and will only recommend similar items. Therefore, they can be used when no user-item interaction data is available but <a id="_idIndexMarker1518"/>will perform poorly once the user is active on your service. A better recommendation engine would recommend a variety of different items to help users explore and discover new and unrelated items they might like. This is exactly what we will do with collaborative filtering in the next section.</p>
			<h1 id="_idParaDest-210"><a id="_idTextAnchor209"/>Collaborative filtering – a rating-based recommender system</h1>
			<p>By recommending only similar items or items from similar users, your users might get bored of the recommendations provided due to the lack of diversity and variety. Once a user starts<a id="_idIndexMarker1519"/> interacting with a service (for example, watching videos on YouTube, reading and liking posts on Facebook, or rating movies on Netflix), we want to provide them with great personalized recommendations and relevant content to keep them happy and engaged. A great way to do so is to provide a good mix of similar content and new content to explore and discover.</p>
			<p>Collaborative filtering is a popular approach for providing such diverse recommendations by comparing user-item interactions, finding other users who interact with similar items, and recommending items that those users also interacted with. It's almost as if you were to build many custom stereotypes and recommend other items consumed from by same stereotype. <em class="italic">Figure 13.6</em> illustrates this example:</p>
			<div>
				<div id="_idContainer253" class="IMG---Figure">
					<img src="image/B17928_13_06.jpg" alt="Figure 13.6 – Finding similar user ratings using collaborative filtering " width="892" height="297"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.6 – Finding similar user ratings using collaborative filtering</p>
			<p>As the person<a id="_idIndexMarker1520"/> on the left buys similar items to the person on the right, we can recommend a new item to the person on the left that the person on the right bought. In this case, the user-item interaction is a person buying a product. However, in recommender language, we speak about ratings as a term summarizing all possible interactions between a user and an item. Let's look at building such a <a id="_idIndexMarker1521"/>rating function (also called a feedback function).</p>
			<p>One great example of amazing rating-based recommendations are the personalized recommended playlists in Spotify, as shown in <em class="italic">Figure 13.7</em>. In contrast to the previous Spotify recommendation at the bottom of each playlist, these recommendations are personalized based on my interaction history and feedback:</p>
			<div>
				<div id="_idContainer254" class="IMG---Figure">
					<img src="image/B17928_13_07.jpg" alt="Figure 13.7 – Spotify's rating-based song recommendation " width="1262" height="747"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.7 – Spotify's rating-based song recommendation</p>
			<p>These <a id="_idIndexMarker1522"/>playlists contain songs similar to the ones I listened to and that are also listened to by other people with my taste. Another nifty extension is that the song recommendations are categorized by genre into these six playlists.</p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor210"/>What is a rating? Explicit feedback versus implicit feedback</h2>
			<p>A <strong class="bold">feedback function</strong> (or rating) quantifies <a id="_idIndexMarker1523"/>the interaction between a user and an<a id="_idIndexMarker1524"/> item. We differentiate between two types of feedback – explicit ratings (or non-observable feedback) and implicit ratings (or directly observable feedback). An <strong class="bold">explicit rating</strong> would be <a id="_idIndexMarker1525"/>leaving a five-star review<a id="_idIndexMarker1526"/> of a product on Amazon, whereas <a id="_idIndexMarker1527"/>an <strong class="bold">implicit rating</strong> is <a id="_idIndexMarker1528"/>buying the <a id="_idIndexMarker1529"/>said product. While the former is a biased decision of the user, the latter can be objectively observed and evaluated.</p>
			<p>The most obvious form<a id="_idIndexMarker1530"/> of rating is<a id="_idIndexMarker1531"/> to explicitly ask the user for feedback – for example, to rate a certain movie, song, article, or the helpfulness of a support document. This is the method most people think about when first implementing recommendations engines. In the case of an explicit rating, we cannot directly observe the user's sentiment but must rely on the user's ability to quantify their sentiment with a rating, such as rating a movie on an ordinal scale from one to five.</p>
			<p>There are<a id="_idIndexMarker1532"/> many problems with <a id="_idIndexMarker1533"/>explicit ratings – especially on ordinal scales (for example, stars from one to five) – that we should consider when building our feedback function. Most people will have a bias when rating items on an ordinal scale – for example, some users might rate a movie 3/5 if they are unsatisfied and 5/5 if they liked the movie, while other users might rate 1/5 for a bad movie, 3/5 for a good one, and only very rarely 5/5 for an exceptional one.</p>
			<p>Therefore, the <a id="_idIndexMarker1534"/>ordinal scales either need to be normalized across users or you'll need to use a binary scale (such as thumbs up/thumbs down) to collect binary feedback. Binary feedback is usually much easier to handle, as we can remove the user bias from the feedback function, simplify the error metric, and therefore provide better recommendations. Many popular streaming services nowadays collect binary (thumbs up/thumbs down, star/unstar, and so on) feedback.</p>
			<p>Here is a little snippet to help normalize user ratings. It applies a normalization across each group of user ratings:</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">def normalize_ratings(df,</p>
			<p class="source-code">                      rating_col="rating",</p>
			<p class="source-code">                      user_col="user"):    </p>
			<p class="source-code">    groups = df.groupby(user_col)[rating_col]    </p>
			<p class="source-code">    # computes group-wise mean/std    </p>
			<p class="source-code">    mean = groups.transform(np.mean)    </p>
			<p class="source-code">    std = groups.transform(np.std)    </p>
			<p class="source-code">    return (df[rating_col] - mean) / std</p>
			<p class="source-code">df["rating_normalized"] = normalize_ratings(df)</p>
			<p>Another popular<a id="_idIndexMarker1535"/> way to train recommender systems is to build an implicit feedback function based on the <a id="_idIndexMarker1536"/>direct observation of an implicit user rating. This has the benefit that the user feedback is unbiased. Common implicit ratings include the user adding an item to the cart, the user buying the item, the user scrolling to the end of the article, and the user watching the full video to the end.</p>
			<p>One additional <a id="_idIndexMarker1537"/>problem to consider is that the way a user interacts with items will change over time. This could be due to a user's habit due to consuming more and more items on the service or changing user preferences. Recommending a video to you that you once liked in your childhood might not be helpful to another adult. Similar to this user drift, the popularity of items will also change over time. Recommending the song <em class="italic">Somebody That I Used to Know</em> to a user today might not lead to the same CTR as in 2011. Therefore, we also must model time and account for temporal drift in our item ratings and feedback function.</p>
			<p>The time drift of explicit or implicit ratings can be modeled using exponential time decay on the numeric rating. Depending on the business rules, we can, for example, use explicit ratings with a binary scale [1, -1] and exponentially decay these ratings with a half-life time of 1 year. Hence, after 1 year, a rating of 1 becomes 0.5; after 2 years, it becomes 0.25, and so on. Here is a snippet to exponentially decay your ratings:</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">def cumsum_days(s, duration='D'):    </p>
			<p class="source-code">    diff = s.diff().astype('timedelta64[%s]' % duration)</p>
			<p class="source-code">    return diff.fillna(0).cumsum().values</p>
			<p class="source-code">    </p>
			<p class="source-code">def decay_ratings(df,</p>
			<p class="source-code">                  decay=1,</p>
			<p class="source-code">                  rating_col="rating",</p>
			<p class="source-code">                  time_col="t"):</p>
			<p class="source-code">    weight = np.exp(-cumsum_days(df[time_col]) * decay)</p>
			<p class="source-code">    return df[rating_col] * weight</p>
			<p class="source-code">half_life_t = 1</p>
			<p class="source-code">decay = np.log(2) / half_life_t</p>
			<p class="source-code">df["rating_decayed"] = decay_ratings(df, decay=decay)</p>
			<p>We<a id="_idIndexMarker1538"/> learned that the choice of a <a id="_idIndexMarker1539"/>proper feedback function matters greatly <a id="_idIndexMarker1540"/>and is as important for designing a rating-based recommendation engine as feature engineering is for content-based recommenders.</p>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor211"/>Predicting the missing ratings to make a recommendation</h2>
			<p>By collecting user-item ratings, we generate a sparse user-item-rating matrix that looks similar to <em class="italic">Figure 13.8</em>. <a id="_idIndexMarker1541"/>However, in order to make a recommendation, we first need to fill the unknown ratings displayed red in the diagram. Collaborative filtering is about filling the blank rows or columns of the user-item-ratings matrix, depending on the prediction use case:</p>
			<div>
				<div id="_idContainer255" class="IMG---Figure">
					<img src="image/B17928_13_08.jpg" alt="Figure 13.8 – The user-item-ratings matrix " width="936" height="240"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.8 – The user-item-ratings matrix</p>
			<p>To recommend the best movie for Alice, we only need to compute the first row of the rating matrix, whereas to compute the best candidates for Terminator, we only need to compute the last column of the matrix. It is important to know that we don't have to compute the whole matrix all the time, which helps to significantly improve the recommendation performance.</p>
			<p>You can also<a id="_idIndexMarker1542"/> probably already guess that this matrix will get really, really large as the number of users and/or items grows. Therefore, we need an efficient parallelizable algorithm for computing the blank ratings in order to make a recommendation. The most popular method to solve this problem is to use matrix factorization and, hence, decompose the matrix into a product of two lower dimensional matrices. These two matrices and their dimensions can be interpreted as user trait and item trait matrices; by way of analogy, the dimension refers to the number of different distinct traits – the so-called latent representation.</p>
			<p>Once the latent representation is known, we can fill the missing ratings by multiplying the correct rows and columns from the latent trait matrices. A recommendation can then be made by using the top <em class="italic">n</em> highest computed ratings. But that's enough of the theory – let's look at an example <a id="_idIndexMarker1543"/>using the <strong class="bold">Alternating Least Square</strong> (<strong class="bold">ALS</strong>) method to perform the matrix factorization in <strong class="source-inline">PySpark</strong>. Apart from the method, everything else in the pipeline is the same as in a standard ML pipeline.</p>
			<p>Similar to all previous pipelines, we also compute a training and testing set for validating the model performance using a grouped selection algorithm (for example, <strong class="source-inline">LeavePGroupsOut</strong> and <strong class="source-inline">GroupShuffleSplit</strong>), performing training, optimizing the hyperparameters, validating the model test performance, and eventually, stacking multiple models together. As in many other methods, most models are trained using gradient descent. We can also use a standard regression loss function, such as the <strong class="bold">RMSE</strong>, to <a id="_idIndexMarker1544"/>compute the fit of our recommendations on the test set. Let's dive into the example.</p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor212"/>Scalable recommendations using ALS factorization</h2>
			<p>To train a large <a id="_idIndexMarker1545"/>collaborative filtering model using matrix factorization, we need an algorithm that is easily distributable. The ALS algorithm <a id="_idIndexMarker1546"/>of the Spark <strong class="source-inline">MLlib</strong> package is an excellent choice – however, many other algorithms for factorizing matrices are available, such as <em class="italic">Bayesian personalized ranking</em>, FastAI's <em class="italic">EmbeddingDotBias</em>, or <em class="italic">neural collaborative filtering</em>.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">A summary of example applications using the preceding methods can be found on Microsoft's GitHub repository at <a href="https://github.com/Microsoft/Recommenders">https://github.com/Microsoft/Recommenders</a>.</p>
			<p>By using Spark, or more precisely PySpark – the Python bindings for Spark and its libraries – we can take <a id="_idIndexMarker1547"/>advantage of the distributed computing framework of Spark. While it's possible to run Spark on a single-node, single-core process locally, it can be easily distributed to a cluster with hundreds and thousands of nodes. Hence, it is a good choice, as your code automatically becomes scalable if your input data scales and exceeds the memory limits of a single node:</p>
			<ol>
				<li value="1">Let's first create and parametrize an ALS estimator in PySpark using <strong class="source-inline">MLlib</strong>, the standard ML library of Spark. We will find <strong class="source-inline">ALS</strong> in the recommendation package of <strong class="source-inline">MLlib</strong>:<p class="source-code">import pyspark</p><p class="source-code">from pyspark.ml.recommendation import ALS</p><p class="source-code">sc = pyspark.SparkContext('local[*]')</p><p class="source-code">n_iter = 10</p><p class="source-code">rank = 10</p><p class="source-code">l2_reg = 1</p><p class="source-code">als = ALS() \</p><p class="source-code">    .setMaxIter(n_iter) \</p><p class="source-code">    .setRank(rank) \</p><p class="source-code">    .setRegParam(l2_reg)</p></li>
			</ol>
			<p>In the preceding code, we initialize the <strong class="source-inline">ALS</strong> estimator and define the number of iterations for gradient descent optimization, the rank of the latent trait matrices, and the L2 regularization constant.</p>
			<ol>
				<li value="2">Next, we fit the model using this estimator:<p class="source-code">model = als.fit(train_data)</p></li>
				<li>That's all we have to do. Once the model is successfully trained, we can now predict the ratings for the test set by calling the <strong class="source-inline">transform</strong> method on the trained model:<p class="source-code">y_test = model.transform(test_data)</p></li>
				<li>To compute the performance of the recommendations, we use a regression evaluator and the <strong class="source-inline">rmse</strong> metric as a scoring function:<p class="source-code">from pyspark.ml.evaluation import RegressionEvaluator</p><p class="source-code">scoring = RegressionEvaluator(metricName="rmse",</p><p class="source-code">                              labelCol="rating",</p><p class="source-code">                              predictionCol="y")</p></li>
				<li>To compute the <strong class="source-inline">rmse</strong> score, we simply call the <strong class="source-inline">evaluate</strong> method on the <strong class="source-inline">scoring</strong> object:<p class="source-code">rmse = scoring.evaluate(y_test)</p></li>
			</ol>
			<p>Congratulations! You <a id="_idIndexMarker1548"/>successfully implemented a rating-based recommendation engine with a collaborative filtering approach by factorizing the user-item-ratings matrix. Have you realized that this approach is similar to finding the eigenvectors of a matrix and that they can be interpreted as user stereotypes (or user tastes, traits, and so on)? While this approach is great for creating diverse recommendations, it requires the availability of (many) user-item ratings. Therefore, it would work great in a service with a lot of user interaction and poorly with completely new users (the cold-start problem).</p>
			<h1 id="_idParaDest-214"><a id="_idTextAnchor213"/>Combining content and ratings in hybrid recommendation engines</h1>
			<p>Instead of<a id="_idIndexMarker1549"/> seeing rating-based recommenders as a successor to content-based recommenders, you should consider them as a different recommender after having acquired enough user-item interaction data to provide rating-only recommendations. In most practical cases, a recommendation engine will exist for both approaches – either as two distinct algorithms or a single hybrid model. In this section, we will look into training such a hybrid model.</p>
			<p>To <a id="_idIndexMarker1550"/>build a state-of-the-art recommender using<a id="_idIndexMarker1551"/> the <strong class="bold">Matchbox recommender</strong>, open Azure Machine Learning designer and add the building blocks for the Matchbox recommender to the canvas, as shown in the following diagram. As we can see, the recommender can now take ratings and user and item features as input to create a hybrid recommendation model:</p>
			<div>
				<div id="_idContainer256" class="IMG---Figure">
					<img src="image/B17928_13_09.jpg" alt="Figure 13.9 – The Matchbox recommender in Azure Machine Learning designer " width="1125" height="944"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.9 – The Matchbox recommender in Azure Machine Learning designer</p>
			<p>In order to <a id="_idIndexMarker1552"/>configure the <a id="_idIndexMarker1553"/>Matchbox recommender, we need to configure the number of traits and, hence, the dimensions of the latent space matrices. We set this value to 10. Similar to the content-based recommender, instead of feeding raw unprocessed feature vectors into the recommender, we should pre-process the data and encode categorical variables using advanced NLP techniques.</p>
			<p>Once you have built the recommendation engine in Azure Machine Learning designer, you simply press <strong class="bold">Run</strong> to train the model. You can also pull-request input and output blocks to the canvas to deploy this model as a web service.</p>
			<p>Currently, the Matchbox recommender is only available through the graphical interface. However, you can use<a id="_idIndexMarker1554"/> other hybrid models, such as Extreme Deep Factorization Machines and Wide and Deep, to train hybrid recommenders from Python. </p>
			<p>Hybrid recommenders <a id="_idIndexMarker1555"/>are very powerful, as they help avoid the cold-start problem but refine recommendations based on ratings once a user provides item ratings. However, the additional ratings are only used to refine predictions, and similar to all previous techniques, hybrid recommenders have to be trained before being deployed.</p>
			<p>In the next section, we will take a look at recommenders that can be deployed without any user ratings and trained online while users interact with items – recommenders based on reinforcement learning.</p>
			<h1 id="_idParaDest-215"><a id="_idTextAnchor214"/>Automatic optimization through reinforcement learning</h1>
			<p>You can<a id="_idIndexMarker1556"/> improve your recommendations by providing online training techniques, which will retrain your recommender <a id="_idIndexMarker1557"/>systems after every user-item interaction. By replacing the feedback function with a reward function and adding a reinforcement learning model, we can now make recommendations, make decisions, and optimize choices that optimize the reward function.</p>
			<p>This is a fantastic new approach to training recommender models. The Azure Personalizer service offers exactly this functionality – to make and optimize decisions and choices by providing contextual features and a reward function to the user. Azure Personalizer uses contextual bandits, an approach to reinforcement learning that is framed around making decisions or choices between discrete actions in a given context.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Under the hood, Azure Personalizer uses the Vowpal Wabbit (<a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki">https://github.com/VowpalWabbit/vowpal_wabbit/wiki</a>) learning system from Microsoft Research to provide high-throughput and low-latency optimization for the recommendation system.</p>
			<p>From a developer's perspective, Azure Personalizer is quite easy to use. The basic recommender API consists of two main requests, the rank request and the reward request. During<a id="_idIndexMarker1558"/> the rank request, we send the user features of the current user, plus all possible item features, to the API which returns a ranking of those items and an event ID in the response.</p>
			<p>Using this<a id="_idIndexMarker1559"/> response, we can present the items to the user who will then interact with these items. Whenever the user creates implicit feedback (for example, they click on an item or scroll to the end of the item), we make a second call to the service, this time to the reward API. In this request, we only send the event ID and the reward (a numeric value) to the service. This will trigger another training iteration using the new reward and the previously submitted user and item features. Hence, with each iteration and each service call, we optimize the performance of the recommendation engine.</p>
			<p>Azure Personalizer SDKs are available for many different languages and are mainly wrappers around the official REST API. In order to install the Python SDK, run the following command in your shell:</p>
			<p class="source-code">pip install azure-cognitiveservices-personalizer</p>
			<p>Now, go to the Azure portal and deploy an instance of Azure Personalizer from your portal and configure the <strong class="bold">Rewards</strong> and <strong class="bold">Exploration</strong> settings, as discussed in the following paragraphs.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">You can find <a id="_idIndexMarker1560"/>more information about Azure Personalizer configurations in the official documentation at <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/personalizer/how-to-settings">https://docs.microsoft.com/en-us/azure/cognitive-services/personalizer/how-to-settings</a>.</p>
			<p>First, you need to configure how long the algorithm should wait to collect rewards for a certain event, as shown in <em class="italic">Figure 13.10</em>. Up to this time, rewards are collected and aggregated by the reward aggregation function. You can also define the model update frequency, which allows you to train your model frequently when requiring recommendations for quick-changing user behaviors. It makes sense to set the reward time and model update frequency to the same value – for example, 10 minutes:</p>
			<div>
				<div id="_idContainer257" class="IMG---Figure">
					<img src="image/B17928_13_10.jpg" alt="Figure 13.10 – Rewards settings " width="690" height="280"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.10 – Rewards settings</p>
			<p>In the <a id="_idIndexMarker1561"/>preceding figure, we can also select the aggregation function for rewards collected on the same event <a id="_idIndexMarker1562"/>during the reward wait time. The possible options are <strong class="bold">Earliest</strong> and <strong class="bold">Sum</strong> – hence, using only the first reward or a sum of all rewards in the reward period.</p>
			<p>The <strong class="bold">Exploration</strong> setting makes the algorithm explore alternative patterns over time, which is very helpful in discovering a diverse set of items through exploration. It can be set through the percentage of rank calls used for exploration, as shown in <em class="italic">Figure 13.11</em>:</p>
			<div>
				<div id="_idContainer258" class="IMG---Figure">
					<img src="image/B17928_13_11.jpg" alt="Figure 13.11 – Exploration settings " width="628" height="150"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.11 – Exploration settings</p>
			<p>Hence, in 20% of the calls, the model won't return the highest ranked item but will randomly explore new items and their rewards. It sounds reasonable that the value for exploration should be greater than 0% to let the reinforcement algorithm try variations of items over time and set lower than 100% to avoid making the algorithm completely random.</p>
			<p>Let's embed a recommendation engine in your application using Python:</p>
			<ol>
				<li value="1">Let's grab your resource key, open a Python environment, and start implementing the rank and reward calls. First, we define the API URLs for both calls:<p class="source-code">personalization_base_url = </p><p class="source-code">  "https://&lt;name&gt;.cognitiveservices.azure.com/"</p><p class="source-code">resource_key = "&lt;your-resource-key&gt;"</p><p class="source-code">rank_url = personalization_base_url \</p><p class="source-code">    + "personalizer/v1.0/rank"</p><p class="source-code">reward_url = personalization_base_url \</p><p class="source-code">    + "personalizer/v1.0/events/"</p></li>
				<li>Next, we <a id="_idIndexMarker1563"/>create a unique <strong class="source-inline">eventid</strong> function and an object containing the user features of <a id="_idIndexMarker1564"/>the current user and the item features of all possible actions. Once the request is constructed, we can send it to the rank API:<p class="source-code">eventid = uuid.uuid4().hex</p><p class="source-code">data = {</p><p class="source-code">    "eventid": eventid,</p><p class="source-code">    "contextFeatures": user_features,</p><p class="source-code">    "actions": item_features</p><p class="source-code">}</p><p class="source-code">response = requests.post(rank_url,</p><p class="source-code">                         headers=headers,</p><p class="source-code">                         json=data)</p></li>
				<li>The response contains the ranking of the possible items/actions and a probability value, as well as the winning item under the <strong class="source-inline">rewardActionId</strong> property:<p class="source-code">{</p><p class="source-code">  "result": {</p><p class="source-code">    "ranking": [</p><p class="source-code">      {</p><p class="source-code">        "id": "ai-for-earth",</p><p class="source-code">        "probability": 0.664000034</p><p class="source-code">      }, ...</p><p class="source-code">    ],</p><p class="source-code">    "eventId": "482d82bc-2ff8-4721-8e92-607310a0a415",</p><p class="source-code">    "rewardActionId": "ai-for-earth"</p><p class="source-code">  }</p><p class="source-code">}</p></li>
				<li>Let's <a id="_idIndexMarker1565"/>parse <strong class="source-inline">rewardActionId</strong> from <strong class="source-inline">response</strong> – this contains the winning item and, hence, the <a id="_idIndexMarker1566"/>recommended action for the user:<p class="source-code">action_id = response.json()["rewardActionId"]</p><p class="source-code">prediction = json.dumps(action_id).replace('"','')</p></li>
				<li>Using this ranking, we can return the winning item to the user based on <strong class="source-inline">rewardActionId</strong>. We now give the user some time to interact with the item. Finally, we use this ID to return the tracked implicit feedback as a reward value to the reward API:<p class="source-code">reward_url = reward_url + eventid + "/reward"</p><p class="source-code">response = requests.post(reward_url,</p><p class="source-code">                         headers=headers,</p><p class="source-code">                         json = {"value": reward})</p></li>
			</ol>
			<p>That's all you need to embed a fully online self-training recommendation engine in your application <a id="_idIndexMarker1567"/>using Python <a id="_idIndexMarker1568"/>and Azure Personalizer. It's that simple. As previously mentioned, other SDKs that wrap the API calls are available for many other languages.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">A demo of Personalizer to test the reward function, as well as the request and response of the service, can be found at <a href="https://personalizationdemo.azurewebsites.net/">https://personalizationdemo.azurewebsites.net/</a>.</p>
			<p class="callout">Detailed up-to-date examples for other languages are provided on GitHub at <a href="https://github.com/Azure-Samples/cognitive-services-personalizer-samples">https://github.com/Azure-Samples/cognitive-services-personalizer-samples</a>.</p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor215"/>Summary</h1>
			<p>In this chapter, we discussed the need for different types of recommendation engines, from non-personalized ones to rating- and content-based ones, as well as hybrid models.</p>
			<p>We learned that content-based recommendation engines use feature vectors and cosine similarity to compute similar items and users based on content alone. This allows us to make recommendations via <em class="italic">k-means clustering</em> or <em class="italic">tree-based regression</em> models. One important consideration is the embedding of categorical data, which, if possible, should use semantic embedding to avoid confusing similarities based on one-hot or label encodings.</p>
			<p>Rating-based recommendations or collaborative filtering methods rely on user-item interactions, so-called ratings, or feedback. While explicit feedback is the most obvious possibility for collecting user ratings through ordinal or binary scales, we need to make sure that those ratings are properly normalized.</p>
			<p>Another possibility is to directly observe the feedback through implicit ratings – for example, a user bought a product, clicked on an article, scrolled a page until the end, or watched a whole video until the end. However, these ratings will also be affected by user preference drift over time, as well as item popularity over time. To avoid this, you can use exponential time decay to decrease ratings over time.</p>
			<p>Rating-based methods are great for providing diverse recommendations but require a lot of existing ratings for a good performance. Hence, they are often combined with content-based recommendations to fight this cold-start problem. Therefore, popular state-of-the-art recommendation models often combine both methods in a single hybrid model, of which the <em class="italic">Matchbox recommender</em> is one such example.</p>
			<p>Finally, you learned about the possibility of using reinforcement learning to optimize the recommender's feedback function on the fly. <em class="italic">Azure Personalizer</em> is a service that can be used to create hybrid online recommenders.</p>
			<p>In the next chapter, we will look into deploying our trained models as batch or real-time scoring systems directly from the Azure Machine Learning service.</p>
		</div>
	</div>
</div>
</body></html>