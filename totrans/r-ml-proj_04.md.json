["```py\n# reading first 1000 reviews\nreviews_text<-readLines('/home/sunil/Desktop/sentiment_analysis/amazon _reviews_polarity.csv', n = 1000)\n# converting the reviews_text character vector to a dataframe\nreviews_text<-data.frame(reviews_text)\n# visualizing the dataframe\nView(reviews_text)\n```", "```py\n# separating the sentiment and the review text\n# post separation the first column will have the first 4 characters\n# second column will have the rest of the characters\n# first column should be named \"Sentiment\"\n# second column to be named \"SentimentText\"\nlibrary(tidyr)\nreviews_text<-separate(data = reviews_text, col = reviews_text, into = c(\"Sentiment\", \"SentimentText\"), sep = 4)\n# viewing the dataset post the column split\nView(reviews_text)\n```", "```py\n# Retaining only alphanumeric values in the sentiment column\nreviews_text$Sentiment<-gsub(\"[^[:alnum:] ]\",\"\",reviews_text$Sentiment)\n# Retaining only alphanumeric values in the sentiment text\nreviews_text$SentimentText<-gsub(\"[^[:alnum:] ]\",\" \",reviews_text$SentimentText)\n# Replacing multiple spaces in the text with single space\nreviews_text$SentimentText<-gsub(\"(?<=[\\\\s])\\\\s*|^\\\\s+|\\\\s+$\", \"\", reviews_text$SentimentText, perl=TRUE)\n# Viewing the dataset\nView(reviews_text)\n# Writing the output to a file that can be consumed in other projects\nwrite.table(reviews_text,file = \"/home/sunil/Desktop/sentiment_analysis/Sentiment Analysis Dataset.csv\",row.names = F,col.names = T,sep=',')\n```", "```py\n__label__<X>  <Text>\n```", "```py\n# reading the first 1000 reviews from the dataset\nreviews_text<-readLines('/home/sunil/Desktop/sentiment_analysis/amazon _reviews_polarity.csv', n = 1000)\n# basic EDA to confirm that the data is read correctly\nprint(class(reviews_text))\nprint(length(reviews_text))\nprint(head(reviews_text,2))\n# replacing the positive sentiment value 2 with __label__2\nreviews_text<-gsub(\"\\\\\\\"2\\\\\\\",\",\"__label__2 \",reviews_text)\n# replacing the negative sentiment value 1 with __label__1\nreviews_text<-gsub(\"\\\\\\\"1\\\\\\\",\",\"__label__1 \",reviews_text)\n# removing the unnecessary \\\" characters\nreviews_text<-gsub(\"\\\\\\\"\",\" \",reviews_text)\n# replacing multiple spaces in the text with single space\nreviews_text<-gsub(\"(?<=[\\\\s])\\\\s*|^\\\\s+|\\\\s+$\", \"\", reviews_text, perl=TRUE)\n# Basic EDA post the required processing to confirm input is as desired\nprint(\"EDA POST PROCESSING\")\nprint(class(reviews_text))\nprint(length(reviews_text))\nprint(head(reviews_text,2))\n# writing the revamped file to the directory so we could use it with\n# fastText sentiment analyzer project\nfileConn<-file(\"/home/sunil/Desktop/sentiment_analysis/Sentiment Analysis Dataset_ft.txt\")\nwriteLines(reviews_text, fileConn)\nclose(fileConn)\n```", "```py\n[1] \"EDA PRIOR TO PROCESSING\"\n[1] \"character\"\n[1] 1000\n[1] \"\\\"2\\\",\\\"Stuning even for the non-gamer\\\",\\\"This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\\"\"                                                                                  \n[2] \"\\\"2\\\",\\\"The best soundtrack ever to anything.\\\",\\\"I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\\"\"\n[1] \"EDA POST PROCESSING\"\n[1] \"character\"\n[1] 1000\\\n[1] \"__label__2 Stuning even for the non-gamer , This sound track was beautiful! It paints the senery in your mind so well I would recommend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\"                                                                                   \n[2] \"__label__2 The best soundtrack ever to anything. , I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade. The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\"\n```", "```py\n# including the required libraries\nlibrary(SnowballC)\nlibrary(tm)\n# setting the working directory where the text reviews dataset is located\n# recollect that we pre-processed and transformed the raw dataset format\nsetwd('/home/sunil/Desktop/sentiment_analysis/')\n# reading the transformed file as a dataframe\ntext <- read.table(file='Sentiment Analysis Dataset.csv', sep=',',header = TRUE)\n# checking the dataframe to confirm everything is in tact\nprint(dim(text))\nView(text)\n```", "```py\n> print(dim(text))\n[1] 1000 2\n> View(text)\n```", "```py\n# transforming the text into volatile corpus\ntrain_corp = VCorpus(VectorSource(text$SentimentText))\nprint(train_corp)\n```", "```py\n> print(train_corp)\n<<VCorpus>>\nMetadata:  corpus specific: 0, document level (indexed): 0\nContent:  documents: 1000\n```", "```py\n# creating document term matrix\ndtm_train <- DocumentTermMatrix(train_corp, control = list(\n  tolower = TRUE,removeNumbers = TRUE,\n  stopwords = TRUE,\n  removePunctuation = TRUE,\n  stemming = TRUE\n))\n# Basic EDA on dtm\ninspect(dtm_train)\n```", "```py\n> inspect(dtm_train)\n<<DocumentTermMatrix (documents: 1000, terms: 5794)>>\nNon-/sparse entries: 34494/5759506\nSparsity           : 99%\nMaximal term length: 21\nWeighting          : term frequency (tf)\nSample             :\n     Terms\nDocs  book can get great just like love one read time\n  111    0   3   2     0    0    0    2   1    0    2\n  162    4   1   0     0    0    1    0   0    1    0\n  190    0   0   0     0    0    0    0   0    0    0\n  230    0   1   1     0    0    0    1   0    0    0\n  304    0   0   0     0    0    3    0   2    0    0\n  399    0   0   0     0    0    0    0   0    0    0\n  431    9   1   0     0    0    1    2   0    0    1\n  456    1   0   0     0    0    0    0   1    2    0\n  618    0   2   3     1    4    1    3   1    0    1\n  72     0   0   1     0    2    0    0   1    0    1\n```", "```py\n# Removing sparse terms\ndtm_train= removeSparseTerms(dtm_train, 0.99)\ninspect(dtm_train)\n```", "```py\n> inspect(dtm_train)\n<<DocumentTermMatrix (documents: 1000, terms: 686)>>\nNon-/sparse entries: 23204/662796\nSparsity           : 97%\nMaximal term length: 10\nWeighting          : term frequency (tf)\nSample             :\n     Terms\nDocs  book can get great just like love one read time\n  174    0   0   1     1    1    2    0   2    0    1\n  304    0   0   0     0    0    3    0   2    0    0\n  355    3   0   0     0    1    1    2   3    1    0\n  380    4   1   0     0    1    0    0   1    0    2\n  465    5   0   1     1    0    0    0   2    6    0\n  618    0   2   3     1    4    1    3   1    0    1\n  72     0   0   1     0    2    0    0   1    0    1\n  836    1   0   0     0    0    3    0   0    5    1\n  866    8   0   1     0    0    1    0   0    4    0\n  959    0   0   2     1    1    0    0   2    0    1\n```", "```py\n# splitting the train and test DTM\ndtm_train_train <- dtm_train[1:800, ]\ndtm_train_test <- dtm_train[801:1000, ]\ndtm_train_train_labels <- as.factor(as.character(text[1:800, ]$Sentiment))\ndtm_train_test_labels <- as.factor(as.character(text[801:1000, ]$Sentiment))\n```", "```py\ncellconvert<- function(x) {\nx <- ifelse(x > 0, \"Y\", \"N\")\n}\n```", "```py\n# applying the function to rows in training and test datasets\ndtm_train_train <- apply(dtm_train_train, MARGIN = 2,cellconvert)\ndtm_train_test <- apply(dtm_train_test, MARGIN = 2,cellconvert)\n# inspecting the train dtm to confirm all is in tact\nView(dtm_train_train)\n```", "```py\n# training the naive bayes classifier on the training dtm\nlibrary(e1071)\nnb_senti_classifier=naiveBayes(dtm_train_train,dtm_train_train_labels)\n# printing the summary of the model created\nsummary(nb_senti_classifier)\n```", "```py\n> summary(nb_senti_classifier)\n        Length Class  Mode    \napriori   2    table  numeric \ntables  686    -none- list    \nlevels    2    -none- character\ncall      3    -none- call  \n```", "```py\n# making predictions on the test data dtm\nnb_predicts<-predict(nb_senti_classifier, dtm_train_test,type=\"class\")\n# printing the predictions from the model\nprint(nb_predicts)\n```", "```py\n[1] 1 1 2 1 1 1 1 1 1 2 2 1 2 2 2 2 1 2 1 1 2 1 2 1 1 1 2 2 1 2 2 2 2 1 2 1 1 1 1 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 2 2 1 2 2 2 2 1 2 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 2 1 1 1 1 2 2 2 2 2 1 1 1 2 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 1 2 2 1 2 2 1 1 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 2 1 2 2 1 1 1 1 2\nLevels: 1 2\n```", "```py\n# computing accuracy of the model\nlibrary(rminer)\nprint(mmetric(nb_predicts, dtm_train_test_labels, c(\"ACC\")))\n```", "```py\n[1] 79\n```", "```py\nmodel.similarity('woman','man')\n```", "```py\n0.73723527\n```", "```py\nmodel.doesnt_match('breakfast cereal dinner lunch';.split())\n```", "```py\n'cereal'\n```", "```py\nmodel.most_similar(positive=['woman','king'],negative=['man'],topn=1)\n```", "```py\nqueen: 0.508\n```", "```py\n# including the required library\nlibrary(softmaxreg)\n# importing the word2vec pretrained vector into memory\ndata(word2vec)\n```", "```py\nView(word2vec)\n```", "```py\ndim(word2vec)\n```", "```py\n[1] 12853 21\n```", "```py\n# function to get word vector for each review\ndocVectors = function(x)\n{\n  wordEmbed(x, word2vec, meanVec = TRUE)\n}\n# setting the working directory and reading the reviews dataset\nsetwd('/home/sunil/Desktop/sentiment_analysis/')\ntext = read.csv(file='Sentiment Analysis Dataset.csv', header = TRUE)\n# applying the docVector function on each of the reviews\n# storing the matrix of word vectors as temp\ntemp=t(sapply(text$SentimentText, docVectors))\n# visualizing the word vectors output\nView(temp)\n```", "```py\ndim(temp)\n```", "```py\n1000 20\n```", "```py\n# splitting the dataset into train and test\ntemp_train=temp[1:800,]\ntemp_test=temp[801:1000,]\nlabels_train=as.factor(as.character(text[1:800,]$Sentiment))\nlabels_test=as.factor(as.character(text[801:1000,]$Sentiment))\n# including the random forest library\nlibrary(randomForest)\n# training a model using random forest classifier with training dataset\n# observe that we are using 20 trees to create the model\nrf_senti_classifier=randomForest(temp_train, labels_train,ntree=20)\nprint(rf_senti_classifier)\n```", "```py\nrandomForest(x = temp_train, y = labels_train, ntree = 20)\n               Type of random forest: classification\n                     Number of trees: 20\nNo. of variables tried at each split: 4\n        OOB estimate of  error rate: 44.25%\nConfusion matrix:\n    1   2 class.error\n1 238 172   0.4195122\n2 182 208   0.4666667\n```", "```py\n# making predictions on the dataset\nrf_predicts<-predict(rf_senti_classifier, temp_test)\nlibrary(rminer)\nprint(mmetric(rf_predicts, labels_test, c(\"ACC\")))\n```", "```py\n[1] 62.5\n```", "```py\n# including the required library\nlibrary(text2vec)\n# setting the working directory\nsetwd('/home/sunil/Desktop/sentiment_analysis/')\n# reading the dataset\ntext = read.csv(file='Sentiment Analysis Dataset.csv', header = TRUE)\n# subsetting only the review text so as to create Glove word embedding\nwiki = as.character(text$SentimentText)\n# Create iterator over tokens\ntokens = space_tokenizer(wiki)\n# Create vocabulary. Terms will be unigrams (simple words).\nit = itoken(tokens, progressbar = FALSE)\nvocab = create_vocabulary(it)\n# consider a term in the vocabulary if and only if the term has appeared aleast three times in the dataset\nvocab = prune_vocabulary(vocab, term_count_min = 3L)\n# Use the filtered vocabulary\nvectorizer = vocab_vectorizer(vocab)\n# use window of 5 for context words and create a term co-occurance matrix\ntcm = create_tcm(it, vectorizer, skip_grams_window = 5L)\n# create the glove embedding for each each in the vocab and\n# the dimension of the word embedding should set to 50\n# x_max is the maximum number of co-occurrences to use in the weighting\n# function\n# note that training the word embedding is time consuming - be patient\nglove = GlobalVectors$new(word_vectors_size = 50, vocabulary = vocab, x_max = 100)\nwv_main = glove$fit_transform(tcm, n_iter = 10, convergence_tol = 0.01)\n```", "```py\nINFO [2018-10-30 06:58:14] 2018-10-30 06:58:14 - epoch 1, expected cost 0.0231\nINFO [2018-10-30 06:58:15] 2018-10-30 06:58:15 - epoch 2, expected cost 0.0139\nINFO [2018-10-30 06:58:15] 2018-10-30 06:58:15 - epoch 3, expected cost 0.0114\nINFO [2018-10-30 06:58:15] 2018-10-30 06:58:15 - epoch 4, expected cost 0.0100\nINFO [2018-10-30 06:58:15] 2018-10-30 06:58:15 - epoch 5, expected cost 0.0091\nINFO [2018-10-30 06:58:15] 2018-10-30 06:58:15 - epoch 6, expected cost 0.0084\nINFO [2018-10-30 06:58:16] 2018-10-30 06:58:16 - epoch 7, expected cost 0.0079\nINFO [2018-10-30 06:58:16] 2018-10-30 06:58:16 - epoch 8, expected cost 0.0074\nINFO [2018-10-30 06:58:16] 2018-10-30 06:58:16 - epoch 9, expected cost 0.0071\nINFO [2018-10-30 06:58:16] 2018-10-30 06:58:16 - epoch 10, expected cost 0.0068\n```", "```py\n# Glove model learns two sets of word vectors - main and context.\n# both matrices may be added to get the combined word vector\nwv_context = glove$components\nword_vectors = wv_main + t(wv_context)\n# converting the word_vector to a dataframe for visualization\nword_vectors=data.frame(word_vectors)\n# the word for each embedding is set as row name by default\n# using the tibble library rownames_to_column function, the rownames is copied as first column of the dataframe\n# we also name the first column of the dataframe as words\nlibrary(tibble)\nword_vectors=rownames_to_column(word_vectors, var = \"words\")\nView(word_vectors)\n```", "```py\nlibrary(softmaxreg)\ndocVectors = function(x)\n{\n  wordEmbed(x, word_vectors, meanVec = TRUE)\n}\n# applying the function docVectors function on the entire reviews dataset\n# this will result in word embedding representation of the entire reviews # dataset\ntemp=t(sapply(text$SentimentText, docVectors))\nView(temp)\n```", "```py\n# splitting the dataset into train and test portions\ntemp_train=temp[1:800,]\ntemp_test=temp[801:1000,]\nlabels_train=as.factor(as.character(text[1:800,]$Sentiment))\nlabels_test=as.factor(as.character(text[801:1000,]$Sentiment))\n# using randomforest to build a model on train data\nlibrary(randomForest)\nrf_senti_classifier=randomForest(temp_train, labels_train,ntree=20)\nprint(rf_senti_classifier)\n```", "```py\nCall:\n randomForest(x = temp_train, y = labels_train, ntree = 20)\n               Type of random forest: classification\n                     Number of trees: 20\nNo. of variables tried at each split: 7\n\n        OOB estimate of  error rate: 42.12%\nConfusion matrix:\n    1   2 class.error\n1 250 160   0.3902439\n2 177 213   0.4538462\n```", "```py\n# predicting labels using the randomforest model created\nrf_predicts<-predict(rf_senti_classifier, temp_test)\n# estimating the accuracy from the predictions\nlibrary(rminer)\nprint(mmetric(rf_predicts, labels_test, c(\"ACC\")))\n```", "```py\n[1] 66.5\n```", "```py\n# loading the required libary\nlibrary(fastTextR)\n# setting the working directory\nsetwd('/home/sunil/Desktop/sentiment_analysis/')\n# reading the input reviews file\n# recollect that fastText needs the file in a specific format and we created one compatiable file in\n# \"Understanding the Amazon Reviews Dataset\" section of this chaptertext = readLines(\"Sentiment Analysis Dataset_ft.txt\")\n# Viewing the text vector for conformation\nView(text)\n```", "```py\n# dividing the reviews into training and test\ntemp_train=text[1:800]temp_test=text[801:1000]\n# Viewing the train datasets for confirmation\nView(temp_train)\n```", "```py\nView(temp_test)\n```", "```py\n# creating txt file for train and test dataset\n# the fasttext function expects files to be passed for training and testing\nfileConn<-file(\"/home/sunil/Desktop/sentiment_analysis/train.ft.txt\")\nwriteLines(temp_train, fileConn)\nclose(fileConn)\nfileConn<-file(\"/home/sunil/Desktop/sentiment_analysis/test.ft.txt\")\nwriteLines(temp_test, fileConn)\nclose(fileConn)\n# creating a test file with no labels\n# recollect the original test dataset has labels in it\n# as the dataset is just a subset obtained from full dataset\ntemp_test_nolabel<- gsub(\"__label__1\", \"\", temp_test, perl=TRUE)\ntemp_test_nolabel<- gsub(\"__label__2\", \"\", temp_test_nolabel, perl=TRUE)\n```", "```py\nView(temp_test_nolabel)\n```", "```py\nfileConn<-file(\"/home/sunil/Desktop/sentiment_analysis/test_nolabel.ft.txt\")\nwriteLines(temp_test_nolabel, fileConn)\nclose(fileConn)\n# training a supervised classification model with training dataset file\nmodel<-fasttext(\"/home/sunil/Desktop/sentiment_analysis/train.ft.txt\",\nmethod = \"supervised\", control = ft.control(nthreads = 3L))\n# Obtain all the words from a previously trained model=\nwords<-get_words(model)\n# viewing the words for confirmation. These are the set of words present  # in our training data\nView(words)\n```", "```py\n# Obtain word vectors from a previously trained model.\nword_vec<-get_word_vectors(model, words)\n# Viewing the word vectors for each word in our training dataset\n# observe that the word embedding dimension is 5\nView(word_vec)\n```", "```py\n# predicting the labels for the reviews in the no labels test dataset\n# and writing it to a file for future reference\npredict(model, newdata_file= \"/home/sunil/Desktop/sentiment_analysis/test_nolabel.ft.txt\",result_file=\"/home/sunil/Desktop/sentiment_analysis/fasttext_result.txt\")\n# getting the predictions into a dataframe so as to compute performance   # measurementft_preds<-predict(model, newdata_file= \"/home/sunil/Desktop/sentiment_analysis/test_nolabel.ft.txt\")\n# reading the test file to extract the actual labels\nreviewstestfile<\nreadLines(\"/home/sunil/Desktop/sentiment_analysis/test.ft.txt\")\n# extracting just the labels frm each line\nlibrary(stringi)\nactlabels<-stri_extract_first(reviewstestfile, regex=\"\\\\w+\")\n# converting the actual labels and predicted labels into factors\nactlabels<-as.factor(as.character(actlabels))\nft_preds<-as.factor(as.character(ft_preds))\n# getting the estimate of the accuracy\nlibrary(rminer)\nprint(mmetric(actlabels, ft_preds, c(\"ACC\")))\n```", "```py\n[1] 58\n```"]