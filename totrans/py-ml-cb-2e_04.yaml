- en: Clustering with Unsupervised Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用无监督学习进行聚类
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下食谱：
- en: Clustering data using the k-means algorithm
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用k-means算法进行聚类数据
- en: Compressing an image using vector quantization
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用矢量量化压缩图像
- en: Grouping data using agglomerative clustering
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用层次聚类对数据进行分组
- en: Evaluating the performance of clustering algorithms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估聚类算法的性能
- en: Estimating the number of clusters using the **Density-Based Spatial Clustering
    of Applications with Noise** (**DBSCAN**) algorithm
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**基于密度的空间聚类应用噪声**（**DBSCAN**）算法估计簇的数量
- en: Finding patterns in stock market data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在股票市场数据中寻找模式
- en: Building a customer segmentation model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建客户细分模型
- en: Using autoencoders to reconstruct handwritten digit images
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自动编码器重建手写数字图像
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To address the recipes in this chapter, you will need the following files (which
    are available on GitHub):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理本章中的食谱，你需要以下文件（可在GitHub上找到）：
- en: '`kmeans.py`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kmeans.py`'
- en: '`data_multivar.txt`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_multivar.txt`'
- en: '`vector_quantization.py`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vector_quantization.py`'
- en: '`flower_image.jpg`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flower_image.jpg`'
- en: '`agglomerative.py`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`agglomerative.py`'
- en: '`performance.py`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`performance.py`'
- en: '`data_perf.txt`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_perf.txt`'
- en: '`estimate_clusters.py`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`estimate_clusters.py`'
- en: '`stock_market.py`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stock_market.py`'
- en: '`symbol_map.json`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`symbol_map.json`'
- en: '`stock_market_data.xlsx`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stock_market_data.xlsx`'
- en: '`customer_segmentation.py`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`customer_segmentation.py`'
- en: '`wholesale.csv`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wholesale.csv`'
- en: '`AutoencMnist.py`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AutoencMnist.py`'
- en: Introduction
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: '**Unsupervised learning** is a paradigm in machine learning where we build
    models without relying on labeled training data. Up to this point, we have dealt
    with data that was labeled in some way. This means that learning algorithms can
    look at this data and learn to categorize it them based on labels. In the world
    of unsupervised learning, we don''t have this opportunity! These algorithms are
    used when we want to find subgroups within datasets using a similarity metric.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**无监督学习**是机器学习中的一个范例，其中我们构建模型而不依赖于标记的训练数据。到目前为止，我们处理的数据都是以某种方式标记的。这意味着学习算法可以查看这些数据，并学习根据标签对其进行分类。在无监督学习的世界中，我们没有这种机会！这些算法用于当我们想要使用相似度度量在数据集中找到子组时。'
- en: In unsupervised learning, information from the database is automatically extracted.
    All this takes place without prior knowledge of the content to be analyzed. In
    unsupervised learning, there is no information on the classes that the examples
    belong to, or on the output corresponding to a given input. We want a model that
    can discover interesting properties, such as groups with similar characteristics,
    which happens in **clustering**. An example of the application of these algorithms
    is a search engine. These applications are able to create a list of links related
    to our search, starting from one or more keywords.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督学习中，数据库中的信息会自动提取。所有这些都是在没有分析内容先验知识的情况下发生的。在无监督学习中，没有关于示例所属类别或对应给定输入的输出的信息。我们希望有一个模型能够发现有趣的属性，例如具有相似特征的组，这在**聚类**中发生。这些算法的应用示例是搜索引擎。这些应用能够根据一个或多个关键词创建与我们的搜索相关的链接列表。
- en: These algorithms work by comparing data and looking for similarities or differences. The
    validity of these algorithms depends on the usefulness of the information they
    can extract from the database. Available data only concerns the set of features
    that describe each example.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法通过比较数据和寻找相似性或差异来工作。这些算法的有效性取决于它们可以从数据库中提取信息的有用性。可用的数据仅涉及描述每个示例的特征集。
- en: One of the most common methods is clustering. You will have heard this term
    being used quite frequently; we mainly use it for data analysis when we want to
    find clusters in our data. These clusters are usually found by using a certain
    kind of similarity measure, such as the Euclidean distance. Unsupervised learning
    is used extensively in many fields, such as data mining, medical imaging, stock
    market analysis, computer vision, and market segmentation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的方法之一是聚类。你可能已经经常听到这个术语被使用；当我们想要在我们的数据中找到簇时，我们主要使用它进行数据分析。这些簇通常是通过使用某种相似度度量来找到的，例如欧几里得距离。无监督学习在许多领域得到广泛应用，例如数据挖掘、医学成像、股票市场分析、计算机视觉和市场细分。
- en: Clustering data using the k-means algorithm
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用k-means算法进行聚类数据
- en: The k-means algorithm is one of the most popular clustering algorithms. This
    algorithm is used to divide the input data into *k* subgroups using various attributes
    of the data. Grouping is achieved using an optimization technique where we try
    to minimize the sum of squares of distances between the datapoints and the corresponding
    centroid of the cluster.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: k-means 算法是最受欢迎的聚类算法之一。此算法使用数据的各种属性将输入数据划分为 *k* 个子组。通过一种优化技术实现分组，我们试图最小化数据点与簇对应质心之间的距离平方和。
- en: Getting ready
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use the k-means algorithm to group the data into four
    clusters identified by the relative centroid. We will also be able to trace the
    boundaries to identify the areas of relevance of each cluster.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方法中，我们将使用 k-means 算法将数据分组到由相对质心标识的四个簇中。我们还将能够追踪边界以识别每个簇的相关区域。
- en: How to do it...
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how to perform a clustering data analysis using the k-means algorithm:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 k-means 算法进行聚类数据分析：
- en: 'The full code for this recipe is given in the `kmeans.py` file that has already
    been provided to you. Now let''s take a look at how it''s built. Create a new
    Python file, and import the following packages:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此方法的完整代码在您已经提供的 `kmeans.py` 文件中给出。现在让我们看看它是如何构建的。创建一个新的 Python 文件，并导入以下包：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now let''s load the input data and define the number of clusters. We will use
    the `data_multivar.txt` file that has already been provided to you:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们加载输入数据并定义簇的数量。我们将使用您已经提供的 `data_multivar.txt` 文件：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We need to see what the input data looks like. Let''s go ahead and add the
    following lines of code to the Python file:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要看看输入数据的样子。让我们继续在 Python 文件中添加以下代码行：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If you run this code, you will get the following output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将得到以下输出：
- en: '![](img/f52083d0-7d25-42dd-ad1c-8a8e09e83f0a.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f52083d0-7d25-42dd-ad1c-8a8e09e83f0a.png)'
- en: 'We are now ready to train the model. Let''s initialize the `kmeans` object
    and train it:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备好训练模型了。让我们初始化 `kmeans` 对象并对其进行训练：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now that the data is trained, we need to visualize the boundaries. Let''s go
    ahead and add the following lines of code to the Python file:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据训练完成后，我们需要可视化边界。让我们继续在 Python 文件中添加以下代码行：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We just evaluated the model across a grid of points. Let''s plot these results
    to view the boundaries:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们刚刚在点网格上评估了模型。让我们绘制这些结果以查看边界：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now let''s overlay `centroids` on top of it:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们在它上面叠加 `centroids`：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If you run this code, you should see the following output:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你应该看到以下输出：
- en: '![](img/c419f851-27a7-4d45-adca-58f674a4ca79.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c419f851-27a7-4d45-adca-58f674a4ca79.png)'
- en: The four centroids and their boundaries are sufficiently highlighted.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 四个质心和它们的边界被充分突出显示。
- en: How it works...
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: K-means was developed by James MacQueen, who, in 1967, designed it for the purpose
    of dividing groups of objects into *k* partitions based on their attributes. It
    is a variation of the **expectation-maximization** (**EM**) algorithm, whose objective
    is to determine the groups of k data generated by Gaussian distributions. The
    difference between the two algorithms lies in the Euclidean distance calculation
    method. In k-means, it is assumed that the attributes of the object can be represented
    as vectors, and thus form a vector space. The goal is to minimize the total intra-cluster
    variance (or standard deviation). Each cluster is identified by a centroid.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 算法是由詹姆斯·麦克昆（James MacQueen）开发的，他在 1967 年设计它是为了根据对象的属性将对象分组到 *k* 个分区。它是
    **期望最大化**（**expectation-maximization**，简称 **EM**）算法的一种变体，其目标是确定由高斯分布生成的 k 个数据点所属的组。两种算法之间的区别在于欧几里得距离计算方法。在
    k-means 中，假设对象的属性可以表示为向量，从而形成一个向量空间。目标是使总簇内方差（或标准差）最小化。每个簇由一个质心来标识。
- en: 'The algorithm follows an iterative procedure, as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 算法遵循以下迭代过程：
- en: Choose the number of *k* clusters
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 *k* 个簇的数量
- en: Initially, create *k* partitions and assign each entry partition either randomly,
    or by using some heuristic information
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始时创建 *k* 个分区，并将每个条目分区随机分配，或者使用一些启发式信息
- en: Calculate the centroid of each group
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个组的质心
- en: Calculate the distance between each observation and each cluster centroid
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个观测值与每个簇质心之间的距离
- en: Then, construct a new partition by associating each entry point with the cluster
    whose centroid is closer to it
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过将每个数据点与最近的质心关联来构建一个新的分区
- en: The centroid for new clusters is recalculated
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新簇的质心被重新计算
- en: Repeat steps 4 to 6 until the algorithm converges
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤4到6，直到算法收敛
- en: There's more…
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: The purpose of the algorithm is to locate *k* centroids, one for each cluster.
    The position of each centroid is of particular importance as different positions
    cause different results. The best choice is to put them as far apart as possible
    from each other. When this is done, you must associate each object with the nearest
    centroid. In this way, we will get a first grouping. After finishing the first
    cycle, we go to the next one by recalculating the new *k* centroids as the cluster's
    barycenter using the previous one. Once you locate these new *k* centroids, you
    need to make a new connection between the same dataset and the new closest centroid.
    At the end of these operations, a new cycle is performed. Due to this cycle, we
    can note that the *k* centroids change their position step by step until they
    are modified. So, the centroid no longer moves.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法的目的是定位*k*个质心，每个聚类一个。每个质心的位置尤其重要，因为不同的位置会导致不同的结果。最佳选择是将它们尽可能地彼此分开。当这样做的时候，你必须将每个对象与最近的质心关联起来。这样，我们将得到一个初步分组。完成第一次循环后，我们通过重新计算新的*k*个质心作为簇的重心来进入下一个循环。一旦定位到这些新的*k*个质心，你需要在新数据集和新的最近质心之间建立新的连接。在这些操作结束时，执行一个新的循环。由于这个循环，我们可以注意到*k*个质心会逐步改变位置，直到它们被修改。因此，质心不再移动。
- en: See also
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料还有
- en: Refer to the official documentation of the `sklearn.cluster.KMeans` function: [https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档中的`sklearn.cluster.KMeans`函数：[https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit)
- en: Refer to *MATLAB for Machine Learning,* Giuseppe Ciaburro, Packt Publishing
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考Giuseppe Ciaburro的《MATLAB for Machine Learning》，Packt Publishing
- en: Refer to *K Means* (from Stanford University): [http://stanford.edu/~cpiech/cs221/handouts/kmeans.html](http://stanford.edu/~cpiech/cs221/handouts/kmeans.html)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考来自斯坦福大学的《K Means》[http://stanford.edu/~cpiech/cs221/handouts/kmeans.html](http://stanford.edu/~cpiech/cs221/handouts/kmeans.html)
- en: 'Refer to *K-means and Hierarchical Clustering* (by Andrew Moore): [https://www.autonlab.org/tutorials/kmeans.html](https://www.autonlab.org/tutorials/kmeans.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考Andrew Moore的《K-means and Hierarchical Clustering》[https://www.autonlab.org/tutorials/kmeans.html](https://www.autonlab.org/tutorials/kmeans.html)
- en: Compressing an image using vector quantization
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用矢量量化压缩图像
- en: One of the main applications of k-means clustering is **vector quantization**.
    Simply speaking, vector quantization is the *N*-dimensional version of rounding
    off. When we deal with one-dimensional data, such as numbers, we use the rounding-off
    technique to reduce the memory needed to store that value. For example, instead
    of storing 23.73473572, we just store 23.73 if we want to be accurate up to the
    second decimal place. Or, we can just store 24 if we don't care about decimal
    places. It depends on our needs and the trade-off that we are willing to make.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: k均值聚类的最主要应用之一是**矢量量化**。简单来说，矢量量化是四舍五入的*N*维版本。当我们处理一维数据，例如数字时，我们使用四舍五入技术来减少存储该值所需的内存。例如，如果我们只想精确到小数点后第二位，我们只需存储23.73；或者，如果我们不关心小数位，我们可以只存储24。这取决于我们的需求和愿意做出的权衡。
- en: Similarly, when we extend this concept to *N*-dimensional data, it becomes vector
    quantization. Of course, there are more nuances to it! Vector quantization is
    popularly used in image compression where we store each pixel using fewer bits
    than the original image to achieve compression.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，当我们将这个概念扩展到*N*维数据时，它就变成了矢量量化。当然，其中还有很多细微之处！矢量量化在图像压缩中非常流行，我们使用比原始图像更少的位数来存储每个像素，以达到压缩的目的。
- en: Getting ready
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use a sample image and then we will compress the image
    further by reducing the number of bits.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用一个示例图像，然后我们将通过减少位数进一步压缩图像。
- en: How to do it...
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how to compress an image using vector quantization:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用矢量量化来压缩图像：
- en: 'The full code for this recipe is given in the `vector_quantization.py` file
    that has already been provided to you. Let''s take a look at how it''s built.
    We''ll start by importing the required packages. Create a new Python file, and
    add the following lines:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该菜谱的完整代码在已经提供给你的`vector_quantization.py`文件中给出。让我们看看它是如何构建的。我们首先导入所需的包。创建一个新的Python文件，并添加以下行：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let''s create a function to parse the input arguments. We will be able to pass
    the image and the number of bits per pixel as input arguments:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个函数来解析输入参数。我们将能够传递图像和每像素位数作为输入参数：
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s create a function to compress the input image:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个函数来压缩输入图像：
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once we compress the image, we need to see how it affects the quality. Let''s
    define a function to plot the output image:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 压缩图像后，我们需要看看它如何影响质量。让我们定义一个函数来绘制输出图像：
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We are now ready to use all these functions. Let''s define the main function
    that takes the input arguments, processes them, and extracts the output image:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备好使用所有这些函数。让我们定义一个主要函数，它接受输入参数，处理它们，并提取输出图像：
- en: '[PRE11]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s load the input image:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载输入图像：
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, let''s compress this image using the input argument:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用输入参数来压缩这张图像：
- en: '[PRE13]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We are now ready to run the code; run the following command on your Terminal:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备好运行代码；在你的终端上运行以下命令：
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following results are returned:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The input image looks like the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像看起来如下：
- en: '![](img/6181237a-5430-43f0-a546-4ee71d70d93d.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6181237a-5430-43f0-a546-4ee71d70d93d.png)'
- en: 'You should get a compressed image as the output:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到一个压缩图像作为输出：
- en: '![](img/49e1ef5c-cf08-4c49-ac10-998b7b994ed2.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/49e1ef5c-cf08-4c49-ac10-998b7b994ed2.png)'
- en: 'Let''s compress the image further by reducing the number of bits to `2`. Run
    the following command on your Terminal:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们进一步压缩图像，通过减少位数到`2`。在你的终端上运行以下命令：
- en: '[PRE16]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The following results are returned:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE17]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You should get the following compressed image as the output:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下压缩图像作为输出：
- en: '![](img/dd4dc96c-a349-4d91-a4f6-09dff2fc2014.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dd4dc96c-a349-4d91-a4f6-09dff2fc2014.png)'
- en: 'If you reduce the number of bits to `1`, you can see that it will become a
    binary image with black and white as the only two colors. Run the following command:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你将位数减少到`1`，你可以看到它将变成只有黑白两种颜色的二值图像。运行以下命令：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The following results are returned:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You will get the following output:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你将得到以下输出：
- en: '![](img/ce68373c-4432-44be-bee8-62aa506869df.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce68373c-4432-44be-bee8-62aa506869df.png)'
- en: We have seen how, by compressing the image further, the quality of the image
    has undergone considerable downsizing.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，通过进一步压缩图像，图像质量已经大幅下降。
- en: How it works...
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Vector quantization is an algorithm used for signal compression, image coding,
    and speech. We use geometric criteria (the Euclidean distance) to find clusters.
    It is, therefore, an example of unsupervised training. It is a technique that
    allows the modeling of probability density functions through the distribution
    of prototype vectors. Vector quantization divides a large set of points (vectors)
    into clusters by using a similar number of points closer to them. Each cluster
    is illustrated by its centroid point (as in k-means).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 向量量化是一种用于信号压缩、图像编码和语音的算法。我们使用几何标准（欧几里得距离）来寻找簇。因此，它是一个无监督训练的例子。这是一种通过原型向量的分布来建模概率密度函数的技术。向量量化通过使用与它们更接近的相似数量的点来将大量点（向量）划分为簇。每个簇由其质心点（如k-means）表示。
- en: There's more…
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'The vector quantization algorithm can be used to divide a dataset into a number
    of clusters. The algorithm is based on the calculation of the Euclidean distance
    for the allocation of the samples to the cluster, to which it belongs. The algorithm
    consists of the following steps:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 向量量化算法可以用来将数据集划分为多个簇。该算法基于计算欧几里得距离来分配样本到它们所属的簇。算法包括以下步骤：
- en: At the beginning, all the vectors are assigned to the same cluster, whose centroid
    is calculated as the mean value of all the vectors.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开始时，所有向量都被分配到同一个簇，其质心是所有向量的平均值。
- en: For each centroid, a perturbation is introduced that generates two new cluster
    centers. The old representative is discarded.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个质心，引入一个扰动，生成两个新的簇中心。旧的代表性被丢弃。
- en: Each carrier is reassigned to one of the new clusters according to the minimum
    distance criterion.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个载体根据最小距离标准重新分配到新的簇中。
- en: The new representatives are calculated as the average value of the vectors assigned
    to each cluster. These will be the new centers of the cluster.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新的代表性是分配给每个簇的向量的平均值。这些将成为簇的新中心。
- en: If the end criterion is met, the algorithm terminates. If not, return to step
    2.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果满足结束条件，算法终止。如果不满足，返回步骤2。
- en: See also
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to the official documentation of the `sklearn.cluster.KMeans` function: [https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit)
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档的`sklearn.cluster.KMeans`函数：[https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit)
- en: 'Refer to *Image Compression Using Vector Quantization Algorithms: A Review*:
    [https://pdfs.semanticscholar.org/24d2/db6db81f1000b74246d22641e83390fb1065.pdf](https://pdfs.semanticscholar.org/24d2/db6db81f1000b74246d22641e83390fb1065.pdf)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考论文《基于矢量量化算法的图像压缩：综述》：[https://pdfs.semanticscholar.org/24d2/db6db81f1000b74246d22641e83390fb1065.pdf](https://pdfs.semanticscholar.org/24d2/db6db81f1000b74246d22641e83390fb1065.pdf)
- en: 'Refer to the *Argparse Tutorial*: [https://docs.python.org/2/howto/argparse.html](https://docs.python.org/2/howto/argparse.html)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档的`Argparse教程`：[https://docs.python.org/2/howto/argparse.html](https://docs.python.org/2/howto/argparse.html)
- en: 'Refer to the official documentation of the `scipy.misc.imread` function: [https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imread.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imread.html)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档的`scipy.misc.imread`函数：[https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imread.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imread.html)
- en: Grouping data using agglomerative clustering
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用聚合聚类分组数据
- en: Before we talk about agglomerative clustering, we need to understand **hierarchical
    clustering**. Hierarchical clustering refers to a set of clustering algorithms
    that creates tree-like clusters by consecutively splitting or merging them, and
    they are represented using a tree. Hierarchical clustering algorithms can be either
    bottom-up or top-down. Now, what does this mean? In bottom-up algorithms, each
    datapoint is treated as a separate cluster with a single object. These clusters
    are then successively merged until all the clusters are merged into a single giant
    cluster. This is called **agglomerative clustering**. On the other hand, top-down
    algorithms start with a giant cluster and successively split these clusters until
    individual datapoints are reached.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论层次聚类之前，我们需要了解**层次聚类**。层次聚类是指一系列通过连续分割或合并来创建树状聚类的聚类算法，它们使用树来表示。层次聚类算法可以是自底向上或自顶向下。那么，这意味着什么呢？在自底向上的算法中，每个数据点被视为一个单独的聚类，包含一个对象。然后这些聚类依次合并，直到所有聚类合并成一个巨大的聚类。这被称为**聚合聚类**。另一方面，自顶向下的算法从一个巨大的聚类开始，依次分割这些聚类，直到达到单个数据点。
- en: Getting ready
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In hierarchical clustering, we construct clusters by partitioning the instances recursively using a
    top-down or bottom-up fashion. We can divide these methods as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在层次聚类中，我们通过递归地使用自顶向下或自底向上的方式对实例进行分区来构建聚类。我们可以将这些方法分为以下几类：
- en: '**Agglomerative algorithm** (bottom-up): Here, we obtain the solution from
    individual statistical units. At each iteration, we aggregate the most closely-related
    statistical units and the procedure ends when a single cluster is formed.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合算法**（自底向上）：在这里，我们从单个统计单元获得解决方案。在每次迭代中，我们聚合最相关的统计单元，直到形成一个单一的聚类为止。'
- en: '**Divisive algorithm** (top-down): Here, all units are in the same class and
    the unit that is not similar to others is added to a new cluster for each subsequent
    iteration.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**划分算法**（自顶向下）：在这里，所有单元属于同一个类别，并且与其它单元不相似的单元在每个后续迭代中添加到一个新的聚类中。'
- en: Both methods result in a dendrogram. This represents a nested group of objects,
    and the similarity levels at which the groups change. By cutting the dendrogram
    at the desired similarity level, we can get a clustering of data objects. The
    merging or division of clusters is performed using a similarity measure, which optimizes
    a criterion.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '这两种方法都会产生一个树状图。这代表了一个嵌套的对象组，以及组之间变化的相似性水平。通过在所需的相似性水平处切割树状图，我们可以得到数据对象的聚类。聚类的合并或分割是通过一个相似性度量来完成的，该度量优化了一个标准。 '
- en: How to do it...
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how to group data using agglomerative clustering:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用聚合聚类来分组数据：
- en: 'The full code for this recipe is given in the `agglomerative.py` file that''s
    provided to you. Now let''s look at how it''s built. Create a new Python file,
    and import the necessary packages:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个菜谱的完整代码在提供的`agglomerative.py`文件中给出。现在让我们看看它是如何构建的。创建一个新的Python文件，并导入必要的包：
- en: '[PRE20]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s define the function that we need to perform agglomerative clustering:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个执行聚合聚类的函数：
- en: '[PRE21]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s extract the labels and specify the shapes of the markers for the graph:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们提取标签并指定图形中标记的形状：
- en: '[PRE22]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Iterate through the datapoints and plot them accordingly using different markers:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历数据点并相应地使用不同的标记进行绘图：
- en: '[PRE23]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'In order to demonstrate the advantage of agglomerative clustering, we need
    to run it on datapoints that are linked spatially, but also located close to each
    other in space. We want the linked datapoints to belong to the same cluster, as
    opposed to datapoints that are just spatially close to each other. Let''s, now
    define a function to get a set of datapoints on a spiral:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了展示聚合聚类的优势，我们需要在空间上连接且空间上彼此靠近的数据点上运行它。我们希望连接的数据点属于同一簇，而不是仅仅空间上彼此靠近的数据点。现在让我们定义一个函数来获取螺旋线上的数据点集：
- en: '[PRE24]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In the previous function, we added some noise to the curve because it adds
    some uncertainty. Let''s define this function:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前面的函数中，我们向曲线添加了一些噪声，因为它增加了一些不确定性。让我们定义这个函数：
- en: '[PRE25]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now let''s define another function to get datapoints located on a rose curve:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们定义另一个函数来获取位于玫瑰曲线上的数据点：
- en: '[PRE26]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Just to add more variety, let''s also define a `hypotrochoid` function:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了增加更多多样性，让我们也定义一个`hypotrochoid`函数：
- en: '[PRE27]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We are now ready to define the main function:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备好定义主函数：
- en: '[PRE28]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'If you run this code, you will get the following output if we don''t use any
    connectivity:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行此代码，如果我们不使用任何连通性，你将得到以下输出：
- en: '![](img/b1dce003-053b-48c0-a77a-37baa6c1acef.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1dce003-053b-48c0-a77a-37baa6c1acef.png)'
- en: 'The second output diagram looks like the following:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个输出图看起来如下：
- en: '![](img/9229b70e-c4ed-468d-b2f1-f545c25cf904.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9229b70e-c4ed-468d-b2f1-f545c25cf904.png)'
- en: As you can see, using the connectivity feature enables us to group the datapoints
    that are linked to each other as opposed to clustering them, based on their spatial
    locations.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，使用连通性功能使我们能够将相互连接的数据点分组，而不是根据它们的空间位置进行聚类。
- en: How it works...
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In agglomerative clustering, each observation begins in its cluster and the
    clusters are subsequently combined. The strategies for joining the clusters are
    as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在聚合聚类中，每个观测开始于其簇，随后簇被合并。合并簇的策略如下：
- en: Ward clustering minimizes the sum of squared differences within all the clusters.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伍德聚类最小化所有簇内平方差的和。
- en: Maximum or complete linkage is used to minimize the maximum distance between
    observations of pairs of clusters.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大或完全链接用于最小化观测对簇之间的最大距离。
- en: Average linkage is used to minimize the average of the distances between all
    observations of pairs of clusters.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均链接用于最小化所有观测对簇之间的距离的平均值。
- en: Single linkage is used to minimize the distance between the closest observations
    of pairs of clusters.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单链接用于最小化观测对簇之间最近观察的距离。
- en: There's more…
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: To decide what clusters must be combined, it is necessary to define a measure
    of dissimilarity between the clusters. In most hierarchical clustering methods,
    specific metrics are used to quantify the distance between two pairs of elements,
    and a linking criterion that defines the dissimilarity of two sets of elements
    (clusters) as a function of the distance between pairs of elements in the two
    sets.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了决定哪些簇必须合并，有必要定义簇之间差异的度量。在大多数层次聚类方法中，使用特定的指标来量化两个元素对之间的距离，以及一个链接标准，它将两个元素集（簇）之间的差异定义为两个集中元素对之间距离的函数。
- en: 'These common metrics are as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这些常用指标如下：
- en: The Euclidean distance
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欧几里得距离
- en: The Manhattan distance
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曼哈顿距离
- en: The uniform rule
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均匀规则
- en: The Mahalanobis distance, which corrects data by different scales and correlations
    in variables
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马哈拉诺比斯距离，它通过变量不同的尺度和相关性来校正数据
- en: The angle between the two vectors
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个向量之间的角度
- en: The Hamming distance, which measures the minimum number of substitutions required
    to change one member into another
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 汉明距离，它衡量将一个成员转换为另一个成员所需的最小替换次数
- en: See also
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'Refer to the official documentation of the `sklearn.cluster.AgglomerativeClustering`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅`sklearn.cluster.AgglomerativeClustering`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)
- en: 'Refer to *Hierarchical agglomerative clustering* (from Stanford University):
    [https://nlp.stanford.edu/IR-book/html/htmledition/hierarchical-agglomerative-clustering-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/hierarchical-agglomerative-clustering-1.html)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考来自斯坦福大学的*层次聚类*（[https://nlp.stanford.edu/IR-book/html/htmledition/hierarchical-agglomerative-clustering-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/hierarchical-agglomerative-clustering-1.html)）
- en: Evaluating the performance of clustering algorithms
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估聚类算法的性能
- en: So far, we have built different clustering algorithms, but haven't measured
    their performance. In supervised learning, the predicted values with the original
    labels are compared to calculate their accuracy. In contrast, in unsupervised
    learning, we have no labels, so we need to find a way to measure the performance
    of our algorithms.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经构建了不同的聚类算法，但还没有测量它们的性能。在监督学习中，将原始标签与预测值进行比较来计算它们的准确率。相比之下，在无监督学习中，我们没有标签，因此我们需要找到一种方法来衡量我们算法的性能。
- en: Getting ready
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'A good way to measure a clustering algorithm is by seeing how well the clusters
    are separated. Are the clusters well separated? Are the datapoints in a cluster
    that is tight enough? We need a metric that can quantify this behavior. We will
    use a metric called the **silhouette coefficient** score. This score is defined
    for each datapoint; this coefficient is defined as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 评估聚类算法的一个好方法是看簇之间的分离程度。簇是否分离得很好？簇中的数据点是否足够紧密？我们需要一个可以量化这种行为的指标。我们将使用一个称为**轮廓系数**的指标。这个分数为每个数据点定义；这个系数的定义如下：
- en: '![](img/f5ad7de6-612e-4fb8-ba61-d236a35d0e99.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f5ad7de6-612e-4fb8-ba61-d236a35d0e99.png)'
- en: Here, ***x*** is the average distance between the current datapoint and all
    the other datapoints in the same cluster, and ***y*** is the average distance
    between the current datapoint and all the datapoints in the next nearest cluster.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，***x***是当前数据点到同一簇中所有其他数据点的平均距离，而***y***是当前数据点到下一个最近簇中所有数据点的平均距离。
- en: How to do it...
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how to evaluate the performance of clustering algorithms:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何评估聚类算法的性能：
- en: 'The full code for this recipe is given in the `performance.py` file that has
    already been provided to you. Now let''s look at how it''s built. Create a new
    Python file, and import the following packages:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个菜谱的完整代码在已经提供给你的`performance.py`文件中给出。现在让我们看看它是如何构建的。创建一个新的Python文件，并导入以下包：
- en: '[PRE29]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Let''s load the input data from the `data_perf.txt` file that has already been
    provided to you:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从已经提供给你的`data_perf.txt`文件中加载输入数据：
- en: '[PRE30]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In order to determine the optimal number of clusters, let''s iterate through
    a range of values and see where it peaks:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了确定最佳簇的数量，让我们遍历一系列值并查看它在何处达到峰值：
- en: '[PRE31]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now let''s plot the graph to see where it peaked:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们绘制图表以查看它在何处达到峰值：
- en: '[PRE32]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'If you run this code, you will get the following output on the Terminal:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行这段代码，你将在终端上得到以下输出：
- en: '[PRE33]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The bar graph looks like the following:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 柱状图看起来如下：
- en: '![](img/4b2c8314-3f41-4f14-a81c-ef837e330f53.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4b2c8314-3f41-4f14-a81c-ef837e330f53.png)'
- en: 'As with these scores, the best configuration is five clusters. Let''s see what
    the data actually looks like:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 就像这些分数一样，最佳配置是五个簇。让我们看看数据实际上看起来是什么样子：
- en: '![](img/590cfb57-6f65-4c5a-a6bb-9dcf70fbb065.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/590cfb57-6f65-4c5a-a6bb-9dcf70fbb065.png)'
- en: We can visually confirm that the data, in fact, has five clusters. We just took
    the example of a small dataset that contains five distinct clusters. This method
    becomes very useful when you are dealing with a huge dataset that contains high-dimensional
    data that cannot be visualized easily.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直观地确认数据实际上有五个簇。我们只是以包含五个不同簇的小数据集为例。当你处理包含无法轻易可视化的高维数据的巨大数据集时，这种方法变得非常有用。
- en: How it works...
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The `sklearn.metrics.silhouette_score` function computes the mean silhouette
    coefficient of all the samples. For each sample, two distances are calculated:
    the mean intra-cluster distance (***x***), and the mean nearest-cluster distance
    (***y***). The silhouette coefficient for a sample is given by the following equation:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.metrics.silhouette_score`函数计算所有样本的平均轮廓系数。对于每个样本，计算两个距离：平均簇内距离（***x***）和平均最近簇距离（***y***）。一个样本的轮廓系数由以下方程给出：'
- en: '![](img/29e29ff3-2b2f-40df-b587-5f0a192a6547.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/29e29ff3-2b2f-40df-b587-5f0a192a6547.png)'
- en: Essentially, **y** is the distance between a sample and the nearest cluster
    that does not include the sample.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，**y**是样本与不包含样本的最近簇之间的距离。
- en: There's more…
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: The best value is 1, and the worst value is -1\. 0 represents clusters that
    overlap, while values of less than 0 mean that that particular sample has been
    attached to the wrong cluster.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳值为1，最差值为-1。0表示重叠的簇，而小于0的值表示该特定样本被错误地附加到簇中。
- en: See also
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'Refer to the official documentation of the `sklearn.metrics.silhouette_score`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参考`sklearn.metrics.silhouette_score`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)
- en: Refer to *Silhouette* (from Wikipedia):[https://en.wikipedia.org/wiki/Silhouette_(clustering)](https://en.wikipedia.org/wiki/Silhouette_(clustering))
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考维基百科上的*轮廓*（来自维基百科）：[https://en.wikipedia.org/wiki/Silhouette_(clustering)](https://en.wikipedia.org/wiki/Silhouette_(clustering))
- en: Estimating the number of clusters using the DBSCAN algorithm
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用DBSCAN算法估计簇数
- en: When we discussed the k-means algorithm, we saw that we had to give the number
    of clusters as one of the input parameters. In the real world, we won't have this
    information available. We can definitely sweep the parameter space to find out
    the optimal number of clusters using the silhouette coefficient score, but this
    will be an expensive process! A method that returns the number of clusters in
    our data will be an excellent solution to the problem. DBSCAN does just that for
    us.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论k-means算法时，我们看到了必须给出簇的数量作为输入参数之一。在现实世界中，我们不会有这样的信息可用。我们可以肯定地扫描参数空间，使用轮廓系数得分找出最佳簇数，但这将是一个昂贵的流程！一个返回我们数据中簇数的方法将是解决这个问题的绝佳解决方案。DBSCAN正是为我们做到这一点。
- en: Getting ready
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will perform a DBSCAN analysis using the `sklearn.cluster.DBSCAN`
    function. We will use the same data that we used in the previous *Evaluating the
    performance of clustering algorithms* (`data_perf.txt`) recipe, to compare the
    two methods used.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用`sklearn.cluster.DBSCAN`函数执行DBSCAN分析。我们将使用与之前*评估聚类算法性能*（`data_perf.txt`）菜谱中相同的相同数据，以比较两种方法。
- en: How to do it...
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how to automatically estimate the number of clusters using the DBSCAN
    algorithm:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用DBSCAN算法自动估计簇数：
- en: 'The full code for this recipe is given in the `estimate_clusters.py` file that
    has already been provided to you. Now let''s look at how it''s built. Create a
    new Python file, and import the necessary packages:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此菜谱的完整代码已在`estimate_clusters.py`文件中提供。现在让我们看看它是如何构建的。创建一个新的Python文件，并导入必要的包：
- en: '[PRE34]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Load the input data from the `data_perf.txt` file. This is the same file that
    we used in the previous recipe, which will help us to compare the methods on the
    same dataset:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`data_perf.txt`文件中加载数据。这是我们在上一个菜谱中使用的相同文件，这将帮助我们比较同一数据集上的方法：
- en: '[PRE35]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We need to find the best parameter, so let''s initialize a few variables:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要找到最佳参数，所以让我们初始化几个变量：
- en: '[PRE36]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let''s sweep the parameter space:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们扫描参数空间：
- en: '[PRE37]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'For each iteration, we need to extract the performance metric:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每次迭代，我们需要提取性能指标：
- en: '[PRE38]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We need to store the best score and its associated epsilon value:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要存储最佳得分及其相关的epsilon值：
- en: '[PRE39]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let''s now plot the bar graph, as follows:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们现在绘制条形图，如下所示：
- en: '[PRE40]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Let''s store the best models and labels:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们存储最佳模型和标签：
- en: '[PRE41]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Some datapoints may remain unassigned. We need to identify them, as follows:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些数据点可能保持未分配。我们需要识别它们，如下所示：
- en: '[PRE42]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Extract the number of clusters, as follows:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式提取簇数：
- en: '[PRE43]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We need to extract all the core samples, as follows:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要提取所有核心样本，如下所示：
- en: '[PRE44]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let''s visualize the resultant clusters. We will start by extracting the set
    of unique labels and specifying different markers:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们可视化结果簇。我们将首先提取唯一标签并指定不同的标记：
- en: '[PRE45]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Now let''s iterate through the clusters and plot the datapoints using different
    markers:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们遍历簇并使用不同的标记绘制数据点：
- en: '[PRE46]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'If you run this code, you will get the following output on your Terminal:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端上得到以下输出：
- en: '[PRE47]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'This will produce the following bar graph:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下条形图：
- en: '![](img/f2c69ed2-a6e1-4d57-ab31-461187a0346c.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f2c69ed2-a6e1-4d57-ab31-461187a0346c.png)'
- en: 'Let''s take a look at the labeled datapoints, along with unassigned datapoints
    marked by solid points in the following output:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看标记的数据点和以下输出中用实心点标记的未分配数据点：
- en: '![](img/de991d06-5c2c-464e-a4d3-d4529a12031c.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/de991d06-5c2c-464e-a4d3-d4529a12031c.png)'
- en: How it works...
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: DBSCAN works by treating datapoints as groups of dense clusters. If a point
    belongs to a cluster, then there should be a lot of other points that belong to
    the same cluster. One of the parameters that we can control is the maximum distance
    of this point from other points. This is called **epsilon**. No two points in
    a given cluster should be further away than epsilon. One of the main advantages
    of this method is that it can deal with outliers. If there are some points located
    alone in a low-density area, DBSCAN will detect these points as outliers as opposed
    to forcing them into a cluster.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCAN 通过将数据点视为密集簇的组来工作。如果一个点属于一个簇，那么应该有很多其他点也属于同一个簇。我们可以控制的参数之一是此点与其他点之间的最大距离。这被称为**epsilon**。给定簇中的任意两点之间的距离不应超过
    epsilon。这种方法的主要优点之一是它可以处理异常值。如果有一些点位于低密度区域中孤立存在，DBSCAN 将将这些点检测为异常值，而不是强迫它们进入一个簇。
- en: There's more…
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容…
- en: 'DBSCAN presents the following pros and cons:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCAN 具有以下优缺点：
- en: '| **Pros** | **Cons** |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| **优点** | **缺点** |'
- en: '|'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: It does not require to know the number of a priori clusters.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不需要事先知道簇的数量。
- en: It can find clusters of arbitrary forms.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以找到任意形状的簇。
- en: It requires only two parameters.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它只需要两个参数。
- en: '|'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: The quality of clustering depends on its distance measurement.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类的质量取决于其距离度量。
- en: It is not able to classify datasets with large differences in density.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它无法对密度差异大的数据集进行分类。
- en: '|'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: See also
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考信息
- en: 'Refer to the official documentation of the `sklearn.cluster.DBSCAN` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档中的 `sklearn.cluster.DBSCAN` 函数：[https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)
- en: Refer to *DBSCAN* (from Wikipedia):[https://en.wikipedia.org/wiki/DBSCAN](https://en.wikipedia.org/wiki/DBSCAN)
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考信息：*DBSCAN*（来自维基百科）：[https://en.wikipedia.org/wiki/DBSCAN](https://en.wikipedia.org/wiki/DBSCAN)
- en: 'Refer to *Density-based Methods* (from the University at Buffalo): [https://cse.buffalo.edu/~jing/cse601/fa12/materials/clustering_density.pdf](https://cse.buffalo.edu/~jing/cse601/fa12/materials/clustering_density.pdf)'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考信息：*基于密度的方法*（来自布法罗大学）：[https://cse.buffalo.edu/~jing/cse601/fa12/materials/clustering_density.pdf](https://cse.buffalo.edu/~jing/cse601/fa12/materials/clustering_density.pdf)
- en: Finding patterns in stock market data
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在股票市场数据中寻找模式
- en: Let's see how we can use unsupervised learning for stock market analysis. Since
    we don't know how many clusters there are, we'll use an algorithm called **affinity
    propagation** (**AP**) on the cluster. It tries to find a representative datapoint
    for each cluster in our data, along with measures of similarity between pairs
    of datapoints, and considers all our datapoints as potential representatives,
    also called **exemplars**, of their respective clusters.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用无监督学习进行股票市场分析。由于我们不知道有多少个簇，我们将在簇上使用一个称为**亲和传播**（**AP**）的算法。它试图为我们数据中的每个簇找到一个代表性的数据点，以及数据点对之间的相似度度量，并将所有数据点视为其各自簇的潜在代表，也称为**示例**。
- en: Getting ready
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will analyze the stock market variations of companies over
    a specified duration. Our goal is to then find out what companies behave similarly
    in terms of their quotes over time.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将分析公司在指定时间段内的股票市场变化。我们的目标是找出哪些公司在时间上的报价行为相似。
- en: How to do it...
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how to find patterns in stock market data:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何寻找股票市场数据中的模式：
- en: 'The full code for this recipe is given in the `stock_market.py` file that has
    already been provided to you. Now let''s look at how it''s built. Create a new
    Python file, and import the following packages:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此菜谱的完整代码已在提供的 `stock_market.py` 文件中给出。现在让我们看看它是如何构建的。创建一个新的 Python 文件，并导入以下包：
- en: '[PRE48]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We need a file that contains all the symbols and the associated names. This
    information is located in the `symbol_map.json` file provided to you. Let''s load
    this, as follows:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要一个包含所有符号及其相关名称的文件。这些信息位于提供的 `symbol_map.json` 文件中。让我们按照以下方式加载它：
- en: '[PRE49]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Let''s read the data from the `symbol_map.json` file:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从 `symbol_map.json` 文件中读取数据：
- en: '[PRE50]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now let''s load the data. We will use an Excel file (`stock_market_data.xlsx`);
    this is a multisheet file, one for each symbol:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们加载数据。我们将使用一个 Excel 文件（`stock_market_data.xlsx`）；这是一个多工作表文件，每个符号对应一个：
- en: '[PRE51]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'As we need some feature points for analysis, we will use the difference between
    the opening and closing quotes every day to analyze the data:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们需要一些特征点进行分析，我们将使用每天开盘价和收盘价之间的差异来分析数据：
- en: '[PRE52]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Let''s build a graph model:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们构建一个图模型：
- en: '[PRE53]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We need to standardize the data before we use it:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们使用之前，我们需要标准化数据：
- en: '[PRE54]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Now let''s train the model using this data:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们使用这些数据来训练模型：
- en: '[PRE55]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We are now ready to build the clustering model, as follows:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经准备好构建聚类模型，如下所示：
- en: '[PRE56]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'If you run this code, you will get the following output on the Terminal:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在终端得到以下输出：
- en: '[PRE57]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Eight clusters are identified. From an initial analysis, we can see that the
    grouped companies seem to treat the same products: IT, banks, engineering, detergents,
    and computers.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 识别出八个簇。从初步分析中，我们可以看到，分组的公司似乎对待相同的产品：IT、银行、工程、洗涤剂和计算机。
- en: How it works...
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: AP is a clustering algorithm based on the concept of passing messages between
    points (item). Unlike clustering algorithms such as k-means, AP does not require
    the cluster number to be defined a priori. AP searches for representative members
    (exemplars) of the set of inputs, which are, in fact, representative of the individual
    clusters.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: AP是一种基于点（项目）之间传递消息概念的聚类算法。与k-means等聚类算法不同，AP不需要预先定义聚类数量。AP搜索输入集的代表成员（样本），实际上这些成员代表了各个簇。
- en: The central point of the AP algorithm is the identification of a subset of exemplars.
    In the input, a matrix of similarity is taken between pairs of data. The data
    exchanges real values as messages until suitable specimens emerge, and consequently,
    good clusters are obtained.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: AP算法的核心是识别一组样本。在输入中，取数据对之间的相似性矩阵。数据作为消息交换实值，直到出现合适的样本，从而获得良好的簇。
- en: There's more…
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容…
- en: To perform AP clustering, the `sklearn.cluster.affinity_propagation()` function
    was used. In the case of training samples with similar similarities and preferences,
    the assignment of cluster centers and labels depends on preference. If the preference
    is less than the similarities, a single cluster center and a 0 label for each
    sample will be returned. Otherwise, each training sample becomes its cluster center
    and a unique mark is assigned.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行AP聚类，使用了`sklearn.cluster.affinity_propagation()`函数。在具有相似相似度和偏好的训练样本的情况下，聚类中心和标签的分配取决于偏好。如果偏好小于相似度，则将返回单个聚类中心和每个样本的0标签。否则，每个训练样本将成为其聚类中心，并分配一个唯一的标记。
- en: See also
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to the official documentation of the `sklearn.cluster.affinity_propagation()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.cluster.affinity_propagation.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.affinity_propagation.html)
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档中的`sklearn.cluster.affinity_propagation()`函数：[https://scikit-learn.org/stable/modules/generated/sklearn.cluster.affinity_propagation.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.affinity_propagation.html)
- en: 'Refer to *AFFINITY PROPAGATION: CLUSTERING DATA BY PASSING MESSAGES* (from
    Toronto University): [http://www.cs.columbia.edu/~delbert/docs/DDueck-thesis_small.pdf](http://www.cs.columbia.edu/~delbert/docs/DDueck-thesis_small.pdf).'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考来自多伦多大学的*亲和传播：通过传递消息聚类数据*（[http://www.cs.columbia.edu/~delbert/docs/DDueck-thesis_small.pdf](http://www.cs.columbia.edu/~delbert/docs/DDueck-thesis_small.pdf)）。
- en: Building a customer segmentation model
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建客户细分模型
- en: One of the main applications of unsupervised learning is market segmentation.
    This is when we don't have labeled data available all the time, but it's important
    to segment the market so that people can target individual groups. This is very
    useful in advertising, inventory management, implementing strategies for distribution,
    and mass media. Let's go ahead and apply unsupervised learning to one such use case
    to see how it can be useful.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习的主要应用之一是市场细分。这是当我们不是始终有标记数据可用时的情况，但重要的是要对市场进行细分，以便人们可以针对个体群体。这在广告、库存管理、实施分销策略和大众媒体中非常有用。让我们来应用无监督学习到一个这样的用例，看看它如何有用。
- en: Getting ready
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will be dealing with a wholesale vendor and his customers. We will be using
    the data available at [https://archive.ics.uci.edu/ml/datasets/Wholesale+customers](https://archive.ics.uci.edu/ml/datasets/Wholesale+customers).
    The spreadsheet contains data regarding the consumption of different types of
    items by their customers and our goal is to find clusters so that they can optimize
    their sales and distribution strategy.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将处理一个批发商及其客户。我们将使用可用的数据[https://archive.ics.uci.edu/ml/datasets/Wholesale+customers](https://archive.ics.uci.edu/ml/datasets/Wholesale+customers)。电子表格包含客户对不同类型商品消费的数据，我们的目标是找到簇，以便他们可以优化他们的销售和分销策略。
- en: How to do it...
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现它…
- en: 'Let''s see how to build a customer segmentation model:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建一个客户细分模型：
- en: 'The full code for this recipe is given in the `customer_segmentation.py` file
    that has already been provided to you. Now let''s look at how it''s built. Create
    a new Python file, and import the following packages:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个菜谱的完整代码在已经提供给你的`customer_segmentation.py`文件中给出。现在让我们看看它是如何构建的。创建一个新的Python文件，并导入以下包：
- en: '[PRE58]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Let''s load the input data from the `wholesale.csv` file that''s already provided
    to you:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载`wholesale.csv`文件中的输入数据，该文件已经提供给你：
- en: '[PRE59]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Let''s build a mean shift model:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们构建一个均值漂移模型：
- en: '[PRE60]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Let''s print the centroids of clusters that we obtained, as follows:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们按照以下方式打印我们获得的簇中心：
- en: '[PRE61]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Let''s visualize a couple of features to get a sense of the output:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们可视化一些特征以获得输出的感觉：
- en: '[PRE62]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'If you run this code, you will get the following output on the Terminal:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在终端上得到以下输出：
- en: '![](img/a543761c-e0ec-4210-9eb4-6e34a1859023.png)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a543761c-e0ec-4210-9eb4-6e34a1859023.png)'
- en: 'You will get the following output that depicts the centroids for the features, *milk*
    and *groceries,* where milk is on the *x* axis and groceries is on the *y* axis:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 你将得到以下输出，描述了特征的中心点，*牛奶*和*杂货*，其中牛奶位于*x*轴上，杂货位于*y*轴上：
- en: '![](img/8db5b4ab-144e-41b1-99ed-35e5e3204271.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8db5b4ab-144e-41b1-99ed-35e5e3204271.png)'
- en: In this output, the eight centroids of the identified clusters are clearly represented.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个输出中，已识别簇的八个中心点被清晰地表示出来。
- en: How it works...
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this recipe, we have faced a clustering problem by using the mean shift algorithm.
    It is a clustering type that assigns datapoints to clusters in an iterative manner
    by moving points to the mode. The mode is the value that appears most frequently.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们通过使用均值漂移算法来面对聚类问题。这是一种通过移动点到众数的方式来迭代地将数据点分配到簇中的聚类类型。众数是出现频率最高的值。
- en: The algorithm assigns iteratively each data point to the centroid of the nearest
    cluster. The centroid of the nearest cluster is determined by where most of the
    neighboring points are located. Thus, at each iteration, each data point approaches
    the point where the greatest number of points is located, which is, or will lead
    to, the cluster center. When the algorithm stops, each point is assigned to a
    cluster. Unlike the k-means algorithm, the mean shift algorithm is not required
    in advance to specify the number of clusters; this is determined automatically
    by the algorithm. The mean shift algorithm is widely used in the field of image
    processing and artificial vision.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 算法迭代地将每个数据点分配到最近簇的中心。最近簇的中心由大多数邻近点所在的位置确定。因此，在每次迭代中，每个数据点都会接近位于最多点的地方，这即是或会导致簇中心。当算法停止时，每个点都会被分配到一个簇中。与k-means算法不同，均值漂移算法不需要事先指定簇的数量；这是由算法自动确定的。均值漂移算法在图像处理和人工智能领域得到了广泛的应用。
- en: There's more…
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: To perform the mean shift clustering, a `sklearn.cluster.MeanShift()` function
    was used. This function carries out a mean shift clustering using a flat kernel.
    The mean shift clustering allows us to identify point aggregates in a uniform
    density of samples. Candidates for the centroids are updated with the average
    of points within a given region. These points are then filtered in a postprocessing
    phase to eliminate possible duplicates to form the final set of centroids.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行均值漂移聚类，使用了`sklearn.cluster.MeanShift()`函数。此函数使用平坦核执行均值漂移聚类。均值漂移聚类使我们能够在均匀密度的样本中识别点聚集。候选中心点通过给定区域内点的平均值进行更新。然后，在后期处理阶段过滤这些点以消除可能的重复，形成最终的中心点集。
- en: See also
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: 'Refer to the official documentation of the `sklearn.cluster.MeanShift()` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html#sklearn-cluster-meanshift](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html#sklearn-cluster-meanshift)'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档的`sklearn.cluster.MeanShift()`函数：[https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html#sklearn-cluster-meanshift](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html#sklearn-cluster-meanshift)
- en: 'Refer to *Mean Shift: A Robust Approach Toward Feature Space Analysis* (by
    Dorin Comaniciu , Peter Meer): [https://courses.csail.mit.edu/6.869/handouts/PAMIMeanshift.pdf](https://courses.csail.mit.edu/6.869/handouts/PAMIMeanshift.pdf)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '参考由Dorin Comaniciu和Peter Meer撰写的《Mean Shift: A Robust Approach Toward Feature
    Space Analysis》（[https://courses.csail.mit.edu/6.869/handouts/PAMIMeanshift.pdf](https://courses.csail.mit.edu/6.869/handouts/PAMIMeanshift.pdf)）'
- en: Using autoencoders to reconstruct handwritten digit images
  id: totrans-330
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自动编码器重建手写数字图像
- en: 'An autoencoder is a neural network whose purpose is to code its input into
    small dimensions, and for the result that is obtained to be able to reconstruct
    the input itself. Autoencoders are made up by the union of the following two subnets:
    encoder and decoder. A loss function is added to these functions and it is calculated
    as the distance between the amount of information loss between the compressed
    representation of the data and the decompressed representation. The encoder and
    the decoder will be differentiable with respect to the distance function, so the
    parameters of the encoding and decoding functions can be optimized to minimize
    the loss of reconstruction, using the gradient stochastic.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 自动编码器是一种神经网络，其目的是将输入编码到小维度，并使获得的结果能够重建输入本身。自动编码器由以下两个子网络组成：编码器和解码器。添加了一个损失函数到这些函数中，它是数据压缩表示和分解表示之间信息损失量的距离。编码器和解码器将与距离函数可微分，因此编码和解码函数的参数可以被优化以最小化重建损失，使用梯度随机化。
- en: Getting ready
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: '**Handwriting recognition** (**HWR**) is widely used in modern technology.
    The written text image can be taken offline from a piece of paper by optical scanning
    (**optical character recognition**, **OCR**), or intelligent word recognition.
    Calligraphy recognition shows the ability of a computer to receive and interpret
    input that can be understood by hand from sources such as paper documents, touchscreens,
    photographs, and other devices. HWR consists of various techniques that generally
    require OCR. However, a complete script recognition system also manages formatting,
    carries out correct character segmentation, and finds the most plausible words.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '**手写识别**（**HWR**）在现代技术中得到了广泛应用。书写文本图像可以通过光学扫描（**光学字符识别**，**OCR**）或智能文字识别从纸张上离线获取。书法识别展示了计算机接收和解释手写输入的能力，这些输入可以从纸张文件、触摸屏、照片和其他设备等来源理解。HWR包括各种技术，通常需要OCR。然而，一个完整的脚本识别系统还管理格式，执行正确的字符分割，并找到最可能的单词。'
- en: The **Modified National Institute of Standards and Technology** (**MNIST**)
    is a large database of handwritten digits. It has a set of 70,000 examples of
    data. It is a subset of MNIST's larger dataset. The digits are of 28 x 28 pixel
    resolution and are stored in a matrix of 70,000 rows and 785 columns; 784 columns
    form each pixel value from the 28 x 28 matrix, and one value is the actual digit.
    The digits have been size-normalized and centered in a fixed-size image.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '**修改后的国家标准与技术研究院**（**MNIST**）是一个包含手写数字的大型数据库。它包含70,000个数据示例。它是MNIST更大数据集的一个子集。数字的分辨率为28
    x 28像素，存储在一个70,000行和785列的矩阵中；784列形成28 x 28矩阵中每个像素值，一个值是实际的数字。这些数字已经被尺寸归一化和居中在固定大小的图像中。'
- en: How to do it...
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how to build autoencoders to reconstruct handwritten digit images:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建自动编码器来重建手写数字图像：
- en: 'The full code for this recipe is given in the `AutoencMnist.py` file that has
    already been provided to you. Let''s look at how it''s built. Create a new Python
    file, and import the following package:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此菜谱的完整代码已提供在`AutoencMnist.py`文件中。让我们看看它是如何构建的。创建一个新的Python文件，并导入以下包：
- en: '[PRE63]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'To import the MNIST dataset, the following code must be used:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要导入MNIST数据集，必须使用以下代码：
- en: '[PRE64]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'After importing the dataset, we have printed the shape of the data, and the
    following results are returned:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入数据集后，我们打印了数据的形状，以下结果被返回：
- en: '[PRE65]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The 70,000 items in the database were divided into 60,000 items for training,
    and 10,000 items for testing. The data output is represented by integers in the
    range 0 to 9\. Let''s check it as follows:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据库中的70,000个项目被分为60,000个项目用于训练，10,000个项目用于测试。数据输出由0到9范围内的整数表示。让我们如下进行检查：
- en: '[PRE66]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The following results are printed:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下结果将被打印：
- en: '[PRE67]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'It may be useful to analyze the distribution of the two values in the available
    arrays. To start, we count the number of occurrences:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析可用的数组中两个值的分布可能是有用的。首先，我们计算出现的次数：
- en: '[PRE68]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The following results are returned:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下结果被返回：
- en: '[PRE69]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'We can also see it in a graph, as follows:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们也可以在图中看到它，如下所示：
- en: '[PRE70]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'To compare the results obtained on both output datasets (`YTrain` and `YTest`),
    two histograms were traced and displayed side by side, as shown in the following
    output:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了比较在两个输出数据集（`YTrain`和`YTest`）上获得的结果，我们绘制并并排显示了两个直方图，如下所示：
- en: '![](img/0a15b2ac-7b88-48a3-85ec-65d2e28bcc5e.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0a15b2ac-7b88-48a3-85ec-65d2e28bcc5e.png)'
- en: From the analysis of the previous output, we can see that in both datasets,
    the 10 digits are represented in the same proportions. In fact, the bars seem
    to have the same dimensions, even if the vertical axis has different ranges.
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从前面的输出分析中，我们可以看到在两个数据集中，10个数字以相同的比例表示。事实上，柱状图似乎具有相同的尺寸，即使垂直轴有不同的范围。
- en: 'Now, we have to normalize all values between 0 and 1:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须将所有值归一化到0和1之间：
- en: '[PRE71]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'To reduce the dimensionality, we will flatten the 28 x 28 images into vectors
    of size 784:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了降低维度，我们将28 x 28的图像展平成大小为784的向量：
- en: '[PRE72]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Now, we will build the model using the Keras functional API. Let''s start importing
    the libraries:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将使用Keras功能API构建模型。让我们开始导入库：
- en: '[PRE73]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Then, we can build the Keras model, as follows:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以构建Keras模型，如下所示：
- en: '[PRE74]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The following output shows the model architecture:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示了模型架构：
- en: '![](img/ac5cbb23-0a56-4f4f-a28c-1f5537a38961.png)'
  id: totrans-365
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ac5cbb23-0a56-4f4f-a28c-1f5537a38961.png)'
- en: 'So, we have to configure the model for training. To do this, we will use the
    `compile` method, as follows:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们必须为训练配置模型。为此，我们将使用`compile`方法，如下所示：
- en: '[PRE75]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'At this point, we can train the model, as follows:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以训练模型，如下所示：
- en: '[PRE76]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Our model is now ready, so we can use it to rebuild the handwritten digits
    automatically. To do this, we will use the `predict()` method:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的模式现在准备好了，我们可以使用它来自动重建手写数字。为此，我们将使用`predict()`方法：
- en: '[PRE77]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'We have now finished; the model has been trained and will later be used to
    make predictions. So, we can just print the starting handwritten digits and those
    that were reconstructed from our model. Of course, we will do it only for some
    of the 60,000 digits contained in the dataset. In fact, we will limit ourselves
    to displaying the first five; we will also use the `matplotlib` library in this
    case:'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经完成了；模型已经被训练，并将随后用于做出预测。因此，我们可以打印出起始的手写数字以及从我们的模型中重建的数字。当然，我们只会对数据集中包含的60,000个数字中的部分进行操作。实际上，我们将限制自己只显示前五个；在这种情况下，我们还将使用`matplotlib`库：
- en: '[PRE78]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The results are shown in the following output:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![](img/8aa1ffc4-1688-4590-9ec6-94b3f059c7f7.png)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8aa1ffc4-1688-4590-9ec6-94b3f059c7f7.png)'
- en: As you can see in the preceding output, the result is very close to the original,
    meaning that the model works well.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在前面的输出中看到的，结果非常接近原始数据，这意味着模型运行良好。
- en: How it works...
  id: totrans-377
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: An autoencoder is a neural network whose purpose is to code its input into small
    dimensions and the result obtained so as to be able to reconstruct the input itself.
    Autoencoders are made up of a union of the following two subnets.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一种神经网络，其目的是将输入编码到小维度，并得到的结果以便能够重建输入本身。自编码器由以下两个子网络的组合组成。
- en: 'First, we have an encoder that calculates the following function:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们有一个编码器，它计算以下函数：
- en: '![](img/4f384c7f-ab17-490d-affa-84c1b17d111b.png)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4f384c7f-ab17-490d-affa-84c1b17d111b.png)'
- en: Given an *x* input, the encoder encodes it in a z variable, which is also called
    a latent variable. *z* usually has much smaller dimensions than *x*.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个*x*输入，编码器将其编码到z变量中，这个变量也称为潜在变量。*z*通常比*x*小得多。
- en: 'Second, we have a decoder that calculates the following function:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，我们有一个解码器，它计算以下函数：
- en: '![](img/defee6c0-e241-476b-bfdb-ad8bbf6ac0c3.png)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/defee6c0-e241-476b-bfdb-ad8bbf6ac0c3.png)'
- en: Since *z* is the code of *x* produced by the encoder, the decoder must decode
    it so that *x'* is similar to *x*. The training of autoencoders is intended to
    minimize the mean squared error between the input and the result.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 *z* 是编码器产生的 *x* 的代码，解码器必须将其解码，以便 *x'* 与 *x* 相似。自动编码器的训练旨在最小化输入和结果之间的均方误差。
- en: There's more…
  id: totrans-385
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Keras is a Python library that provides a simple and clean way to create a range
    of deep learning models. The Keras code was released under the MIT license. Keras
    has been structured based on austerity and simplicity, and it provides a programming
    model without ornaments to maximize readability. It allows neural networks to
    be expressed in a very modular way, considering models as a sequence or a single
    graph.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 是一个 Python 库，它提供了一种简单且清晰的方式来创建各种深度学习模型。Keras 代码是在 MIT 许可证下发布的。Keras 基于简约和简洁的原则构建，它提供了一个无装饰的编程模型，以最大化可读性。它允许以非常模块化的方式表达神经网络，将模型视为一个序列或单个图。
- en: See also
  id: totrans-387
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: Refer to the official documentation of the Keras library: [https://keras.io/](https://keras.io/)
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅 Keras 库的官方文档：[https://keras.io/](https://keras.io/)
- en: Refer to *Keras 2.x Projects*, Giuseppe Ciaburro, Packt Publishing.
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅《Keras 2.x Projects》，作者 Giuseppe Ciaburro，Packt Publishing 出版。
