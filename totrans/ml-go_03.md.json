["```py\nobservation,prediction\n22.1,17.9\n10.4,9.1\n9.3,7.8\n18.5,14.2\n12.9,15.6\n7.2,7.4\n11.8,9.7\n...\n```", "```py\nobservation,prediction,error\n22.1,17.9,4.2\n10.4,9.1,1.3\n9.3,7.8,1.5\n18.5,14.2,4.3\n12.9,15.6,-2.7\n7.2,7.4,-0.2\n11.8,9.7,2.1\n...\n```", "```py\n// Open the continuous observations and predictions.\nf, err := os.Open(\"continuous_data.csv\")\nif err != nil {\n    log.Fatal(err)\n}\ndefer f.Close()\n\n// Create a new CSV reader reading from the opened file.\nreader := csv.NewReader(f)\n\n// observed and predicted will hold the parsed observed and predicted values\n// form the continuous data file.\nvar observed []float64\nvar predicted []float64\n\n// line will track row numbers for logging.\nline := 1\n// Read in the records looking for unexpected types in the columns.\nfor {\n\n    // Read in a row. Check if we are at the end of the file.\n    record, err := reader.Read()\n    if err == io.EOF {\n        break\n    }\n\n    // Skip the header.\n    if line == 1 {\n        line++\n        continue\n    }\n\n    // Read in the observed and predicted values.\n    observedVal, err := strconv.ParseFloat(record[0], 64)\n    if err != nil {\n        log.Printf(\"Parsing line %d failed, unexpected type\\n\", line)\n        continue\n    }\n\n    predictedVal, err := strconv.ParseFloat(record[1], 64)\n    if err != nil {\n        log.Printf(\"Parsing line %d failed, unexpected type\\n\", line)\n        continue\n    }\n\n    // Append the record to our slice, if it has the expected type.\n    observed = append(observed, observedVal)\n    predicted = append(predicted, predictedVal)\n    line++\n}\n\n// Calculate the mean absolute error and mean squared error.\nvar mAE float64\nvar mSE float64\nfor idx, oVal := range observed {\n    mAE += math.Abs(oVal-predicted[idx]) / float64(len(observed))\n    mSE += math.Pow(oVal-predicted[idx], 2) / float64(len(observed))\n}\n\n// Output the MAE and MSE value to standard out.\nfmt.Printf(\"\\nMAE = %0.2f\\n\", mAE)\nfmt.Printf(\"\\nMSE = %0.2f\\n\\n\", mSE)\n```", "```py\n$ go build\n$ ./myprogram \n\nMAE = 2.55\n\nMSE = 10.51\n```", "```py\n// Calculate the R^2 value.\nrSquared := stat.RSquaredFrom(observed, predicted, nil)\n\n// Output the R^2 value to standard out.\nfmt.Printf(\"\\nR^2 = %0.2f\\n\\n\", rSquared)\n```", "```py\n$ go build\n$ ./myprogram     \n\nR^2 = 0.37\n```", "```py\nobserved,predicted\n0,0\n0,1\n2,2\n1,1\n1,1\n0,0\n2,0\n0,0\n...\n```", "```py\n// Open the binary observations and predictions.\nf, err := os.Open(\"labeled.csv\")\nif err != nil {\n    log.Fatal(err)\n}\ndefer f.Close()\n\n// Create a new CSV reader reading from the opened file.\nreader := csv.NewReader(f)\n\n// observed and predicted will hold the parsed observed and predicted values\n// form the labeled data file.\nvar observed []int\nvar predicted []int\n```", "```py\n// line will track row numbers for logging.\nline := 1\n\n// Read in the records looking for unexpected types in the columns.\nfor {\n\n    // Read in a row. Check if we are at the end of the file.\n    record, err := reader.Read()\n    if err == io.EOF {\n        break\n    }\n\n    // Skip the header.\n    if line == 1 {\n        line++\n        continue\n    }\n\n    // Read in the observed and predicted values.\n    observedVal, err := strconv.Atoi(record[0])\n    if err != nil {\n        log.Printf(\"Parsing line %d failed, unexpected type\\n\", line)\n        continue\n    }\n\n    predictedVal, err := strconv.Atoi(record[1])\n    if err != nil {\n        log.Printf(\"Parsing line %d failed, unexpected type\\n\", line)\n        continue\n    }\n\n    // Append the record to our slice, if it has the expected type.\n    observed = append(observed, observedVal)\n    predicted = append(predicted, predictedVal)\n    line++\n}\n\n// This variable will hold our count of true positive and\n// true negative values.\nvar truePosNeg int\n\n// Accumulate the true positive/negative count.\nfor idx, oVal := range observed {\n    if oVal == predicted[idx] {\n        truePosNeg++\n    }\n}\n\n// Calculate the accuracy (subset accuracy).\naccuracy := float64(truePosNeg) / float64(len(observed))\n\n// Output the Accuracy value to standard out.\nfmt.Printf(\"\\nAccuracy = %0.2f\\n\\n\", accuracy)\n```", "```py\n$ go build\n$ ./myprogram\n\nAccuracy = 0.97\n```", "```py\n// classes contains the three possible classes in the labeled data.\nclasses := []int{0, 1, 2}\n\n// Loop over each class.\nfor _, class := range classes {\n\n    // These variables will hold our count of true positives and\n    // our count of false positives.\n    var truePos int\n    var falsePos int\n    var falseNeg int\n\n    // Accumulate the true positive and false positive counts.\n    for idx, oVal := range observed {\n\n        switch oVal {\n\n        // If the observed value is the relevant class, we should check to\n        // see if we predicted that class.\n        case class:\n            if predicted[idx] == class {\n                truePos++\n                continue\n            }\n\n            falseNeg++\n\n        // If the observed value is a different class, we should \n        // check to see if we predicted a false positive.\n        default:\n            if predicted[idx] == class {\n                falsePos++\n            }\n        }\n    }\n\n    // Calculate the precision.\n    precision := float64(truePos) / float64(truePos+falsePos)\n\n    // Calculate the recall.\n    recall := float64(truePos) / float64(truePos+falseNeg)\n\n    // Output the precision value to standard out.\n    fmt.Printf(\"\\nPrecision (class %d) = %0.2f\", class, precision)\n    fmt.Printf(\"\\nRecall (class %d) = %0.2f\\n\\n\", class, recall)\n}\n```", "```py\n$ go build\n$ ./myprogram\n\nPrecision (class 0) = 1.00\nRecall (class 0) = 1.00\n\nPrecision (class 1) = 0.96\nRecall (class 1) = 0.94\n\nPrecision (class 2) = 0.94\nRecall (class 2) = 0.96\n```", "```py\nfunc ROC(n int, y []float64, classes []bool, weights []float64) (tpr, fpr []float64)\n```", "```py\n// Define our scores and classes.\nscores := []float64{0.1, 0.35, 0.4, 0.8}\nclasses := []bool{true, false, true, false}\n\n// Calculate the true positive rates (recalls) and\n// false positive rates.\ntpr, fpr := stat.ROC(0, scores, classes, nil)\n// Compute the Area Under Curve.\nauc := integrate.Trapezoidal(fpr, tpr)\n\n// Output the results to standard out.\nfmt.Printf(\"true positive rate: %v\\n\", tpr)\nfmt.Printf(\"false positive rate: %v\\n\", fpr)\nfmt.Printf(\"auc: %v\\n\", auc)\n```", "```py\n$ go build\n$ ./myprogram \ntrue positive rate: [0 0.5 0.5 1 1]\nfalse positive rate: [0 0 0.5 0.5 1]\nauc: 0.75\n```", "```py\nage,sex,bmi,map,tc,ldl,hdl,tch,ltg,glu,y\n0.0380759064334,0.0506801187398,0.0616962065187,0.021872354995,-0.0442234984244,-0.0348207628377,-0.043400845652,-0.00259226199818,0.0199084208763,-0.0176461251598,151.0\n-0.00188201652779,-0.044641636507,-0.0514740612388,-0.0263278347174,-0.00844872411122,-0.0191633397482,0.0744115640788,-0.0394933828741,-0.0683297436244,-0.0922040496268,75.0\n0.0852989062967,0.0506801187398,0.0444512133366,-0.00567061055493,-0.0455994512826,-0.0341944659141,-0.0323559322398,-0.00259226199818,0.00286377051894,-0.0259303389895,141.0\n-0.0890629393523,-0.044641636507,-0.0115950145052,-0.0366564467986,0.0121905687618,0.0249905933641,-0.0360375700439,0.0343088588777,0.0226920225667,-0.00936191133014,206.0\n0.00538306037425,-0.044641636507,-0.0363846922045,0.021872354995,0.00393485161259,0.0155961395104,0.00814208360519,-0.00259226199818,-0.0319914449414,-0.0466408735636,135.0\n...\n```", "```py\n// Open the diabetes dataset file.\nf, err := os.Open(\"diabetes.csv\")\nif err != nil {\n    log.Fatal(err)\n}\ndefer f.Close()\n\n// Create a dataframe from the CSV file.\n// The types of the columns will be inferred.\ndiabetesDF := dataframe.ReadCSV(f)\n\n// Calculate the number of elements in each set.\ntrainingNum := (4 * diabetesDF.Nrow()) / 5\ntestNum := diabetesDF.Nrow() / 5\nif trainingNum+testNum < diabetesDF.Nrow() {\n    trainingNum++\n}\n\n// Create the subset indices.\ntrainingIdx := make([]int, trainingNum)\ntestIdx := make([]int, testNum)\n\n// Enumerate the training indices.\nfor i := 0; i < trainingNum; i++ {\n    trainingIdx[i] = i\n}\n\n// Enumerate the test indices.\nfor i := 0; i < testNum; i++ {\n    testIdx[i] = trainingNum + i\n}\n\n// Create the subset dataframes.\ntrainingDF := diabetesDF.Subset(trainingIdx)\ntestDF := diabetesDF.Subset(testIdx)\n\n// Create a map that will be used in writing the data\n// to files.\nsetMap := map[int]dataframe.DataFrame{\n    0: trainingDF,\n    1: testDF,\n}\n\n// Create the respective files.\nfor idx, setName := range []string{\"training.csv\", \"test.csv\"} {\n\n    // Save the filtered dataset file.\n    f, err := os.Create(setName)\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // Create a buffered writer.\n    w := bufio.NewWriter(f)\n\n    // Write the dataframe out as a CSV.\n    if err := setMap[idx].WriteCSV(w); err != nil {\n        log.Fatal(err)\n    }\n}\n```", "```py\n$ go build\n$ ./myprogram \n$ wc -l *.csv\n   443 diabetes.csv\n    89 test.csv\n   355 training.csv\n   887 total\n```", "```py\nfunc GenerateCrossFoldValidationConfusionMatrices(data base.FixedDataGrid, cls base.Classifier, folds int) ([]ConfusionMatrix, error)\n```", "```py\n// Define the decision tree model.\ntree := trees.NewID3DecisionTree(param)\n\n// Perform the cross validation.\ncfs, err := evaluation.GenerateCrossFoldValidationConfusionMatrices(myData, tree, 5)\nif err != nil {\n    panic(err)\n}\n\n// Calculate the metrics.\nmean, variance := evaluation.GetCrossValidatedMetric(cfs, evaluation.GetAccuracy)\nstdev := math.Sqrt(variance)\n\n// Output the results to standard out.\nfmt.Printf(\"%0.2f\\t\\t%.2f (+/- %.2f)\\n\", param, mean, stdev*2)\n```"]