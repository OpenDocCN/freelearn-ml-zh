- en: Autoencoders
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自编码器
- en: In this chapter, we are going to look at an unsupervised model family whose
    performance has been boosted by modern deep learning techniques. Autoencoders
    offer a different approach to classic problems such as dimensionality reduction
    or dictionary learning, but unlike many other algorithms, they don't suffer the
    capacity limitations that affect many famous models. Moreover, they can exploit
    specific neural layers (such as convolutions) to extract pieces of information
    based on specialized criteria. In this way, the internal representations can be
    more robust to different kinds of distortions and much more efficient in terms
    of the amount of information they can process.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨一个无监督模型家族，其性能通过现代深度学习技术得到了提升。自编码器为经典问题如降维或字典学习提供了一种不同的方法，但与许多其他算法不同，它们不受影响许多著名模型的容量限制。此外，它们可以利用特定的神经网络层（如卷积）根据专门的标准提取信息片段。这样，内部表示可以更稳健地抵抗不同类型的扭曲，并且在处理信息量方面更加高效。
- en: 'In particular, we are going to discuss the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是我们将要讨论以下内容：
- en: Standard autoencoders
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准自编码器
- en: Denoising autoencoders
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 去噪自编码器
- en: Sparse autoencoders
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稀疏自编码器
- en: Variational autoencoders
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变分自编码器
- en: Autoencoders
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自编码器
- en: In the previous chapters, we discussed how real datasets are very often high-dimensional
    representations of samples that lie on low-dimensional manifolds (this is one
    of the semi-supervised pattern's assumptions, but it's generally true). As the
    complexity of a model is proportional to the dimensionality of the input data,
    many techniques have been analyzed and optimized in order to reduce the actual
    number of *valid components*. For example, PCA selects the features according
    to the relative explained variance, while ICA and generic dictionary learning
    techniques look for basic atoms that can be combined to rebuild the original samples.
    In this chapter, we are going to analyze a family of models based on a slightly
    different approach, but whose capabilities are dramatically increased by the employment
    of deep learning methods.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们讨论了真实数据集通常是非常高维的样本表示，这些样本位于低维流形上（这是半监督模式假设之一，但通常是正确的）。由于模型的复杂性与输入数据的维度成正比，许多技术已经被分析和优化，以减少实际的有效组件数量。例如，PCA根据相对解释方差选择特征，而ICA和通用字典学习方法寻找可以组合以重建原始样本的基本原子。在本章中，我们将分析一类基于略有不同方法但能力显著增强的深度学习方法。
- en: 'A generic **autoencoder** is a model that is split into two separate (but not
    completely autonomous) components called an **Encoder** and a **Decoder**. The
    task of the encoder is to transform an input sample into an encoded feature vector,
    while the task of the decoder is the opposite: rebuilding the original sample
    using the feature vector as input. The following diagram shows a schematic representation
    of a generic model:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一个通用的**自编码器**是一个分为两个独立（但并非完全自主）组件的模型，称为**编码器**和**解码器**。编码器的任务是转换输入样本为一个编码特征向量，而解码器的任务正好相反：使用特征向量作为输入重建原始样本。以下图显示了通用模型的示意图：
- en: '![](img/d193d496-7b5e-494f-bd76-4dd061a611ec.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d193d496-7b5e-494f-bd76-4dd061a611ec.png)'
- en: Schema of a generic autoencoder
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通用自编码器架构
- en: 'More formally, we can describe the encoder as a parametrized function:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，我们可以将编码器描述为一个参数化函数：
- en: '![](img/1119ad07-4885-4d70-b284-6a7605a9e978.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1119ad07-4885-4d70-b284-6a7605a9e978.png)'
- en: 'The output *z[i]* is a vectorial code whose dimensionality is normally quite
    lower than the inputs. Analogously, the decoder is described as the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 *z[i]* 是一个向量码，其维度通常远低于输入。类似地，解码器被描述如下：
- en: '![](img/a57ab307-c63a-4395-9098-440a507acab1.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a57ab307-c63a-4395-9098-440a507acab1.png)'
- en: 'The goal of a standard algorithm is to minimize a cost function that is proportional
    to the reconstruction error. A classic method is based on the mean squared error
    (working on a dataset with *M* samples):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 标准算法的目标是最小化与重建误差成比例的成本函数。一种经典的方法是基于均方误差（在包含 *M* 个样本的数据集上工作）：
- en: '![](img/b1579613-65da-42f3-b2ec-7c8a3acc242f.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b1579613-65da-42f3-b2ec-7c8a3acc242f.png)'
- en: 'This function depends only on the input samples (which are constant) and the
    parameter vectors; therefore, this is *de facto* an unsupervised method where
    we can control the internal structure and the constraints imposed on the *z[i ]*code.
    From a probabilistic viewpoint, if the input *x**[i ]*samples are drawn from a *p(X) *data-generating
    process, our goal is to find a *q(•) *parametric distribution that minimizes the
    Kullback–Leibler divergence with *p(X)*. Considering the previous definitions,
    we can define *q(•**)* as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数只依赖于输入样本（它们是常数）和参数向量；因此，这实际上是一种无监督方法，我们可以控制内部结构和施加在 *z[i]* 代码上的约束。从概率论的角度来看，如果输入
    *x**[i]* 样本是从 *p(X)* 数据生成过程中抽取的，我们的目标是找到一个 *q(•)* 参数分布，使其与 *p(X)* 的 Kullback–Leibler
    散度最小化。考虑到之前的定义，我们可以将 *q(•)* 定义如下：
- en: '![](img/1901744e-a487-4f9d-95eb-2e26367c1a69.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1901744e-a487-4f9d-95eb-2e26367c1a69.png)'
- en: 'Therefore, the Kullback–Leibler divergence becomes the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Kullback–Leibler 散度变为以下：
- en: '![](img/8ccc7428-9f9d-4003-8477-430246f12cdf.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8ccc7428-9f9d-4003-8477-430246f12cdf.png)'
- en: 'The first term represents the negative entropy of the original distribution,
    which is constant and isn''t involved in the optimization process. The other term
    is the cross-entropy between the *p* and *q*. If we assume Gaussian distributions
    for *p* and *q*, the mean squared error is proportional to the cross-entropy (for
    optimization purposes, it''s equivalent to it), and therefore this cost function
    is still valid under a probabilistic approach. Alternatively, it''s possible to
    consider Bernoulli distributions for *p* and *q*, and the cross-entropy becomes
    the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个项代表原始分布的负熵，它是常数，不参与优化过程。另一个项是 *p* 和 *q* 之间的交叉熵。如果我们假设 *p* 和 *q* 是高斯分布，均方误差与交叉熵成正比（对于优化目的，它等同于交叉熵），因此这个成本函数在概率方法下仍然有效。或者，我们可以考虑
    *p* 和 *q* 是伯努利分布，交叉熵变为以下：
- en: '![](img/57185459-91e2-4b61-9fee-75335a8af9c2.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57185459-91e2-4b61-9fee-75335a8af9c2.png)'
- en: The main difference between the two approaches is that while a mean squared
    error can be applied to *x[i] ∈ ℜ^q* (or multidimensional matrices), Bernoulli
    distributions need *x[i]* *∈ [0, 1]*^(*q* )(formally, this condition should be
    *x[i] ∈ {0, 1}^q*; however, the optimization can also be successfully performed
    when the values are not binary). The same constraint is necessary for the reconstructions;
    therefore, when using neural networks, the most common choice is to employ sigmoid
    layers.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法的主要区别在于，虽然均方误差可以应用于 *x[i] ∈ ℜ^q*（或多维矩阵），但伯努利分布需要 *x[i]* *∈ [0, 1]*^(*q*)（形式上，这个条件应该是
    *x[i] ∈ {0, 1}^q*；然而，当值不是二进制时，优化也可以成功进行）。对于重建，也需要相同的约束；因此，当使用神经网络时，最常见的选择是使用 sigmoid
    层。
- en: An example of a deep convolutional autoencoder with TensorFlow
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 中的深度卷积自编码器示例
- en: This example (like all the others in this and the following chapters) is based
    on TensorFlow (for information about the installation of TensorFlow, please refer
    to the information box at the end of the section), because this framework allows
    a greater flexibility that is sometimes much more problematic with Keras. We will
    approach this example pragmatically, and so we are not going to explore all the
    features because they are beyond the scope of this book; however, interested readers
    can refer to *Deep Learning with TensorFlow - Second Edition, Zaccone G., Karim
    R., Packt*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子（以及本章和以下章节中的所有其他例子）基于 TensorFlow（有关 TensorFlow 的安装信息，请参阅本节末尾的信息框），因为这个框架允许更大的灵活性，这在
    Keras 中有时会带来更多问题。我们将实用主义地处理这个例子，因此我们不会探索所有功能，因为它们超出了本书的范围；然而，感兴趣的读者可以参考 *《TensorFlow
    深度学习 第二版》，作者：Zaccone G.，Karim R.，Packt*。
- en: 'In this example, we are going to create a deep convolutional autoencoder and
    train it using the Fashion MNIST dataset. The first step is loading the data (using
    the Keras helper function), normalizing, and in order to speed up the computation,
    limiting the training set to 1,000 samples:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将创建一个深度卷积自编码器，并使用 Fashion MNIST 数据集进行训练。第一步是加载数据（使用 Keras 辅助函数），归一化，为了加快计算速度，将训练集限制为
    1,000 个样本：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'At this point, we can create the `Graph`, setting up the whole architecture,
    which is made up of the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以创建 `Graph`，设置整个架构，它由以下部分组成：
- en: 'The encoder (all layers have padding "same" and ReLU activation):'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器（所有层都有填充 "same" 和 ReLU 激活）：
- en: Convolution with 32 filters, kernel size equal to (3 × 3), and strides (2 ×
    2)
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用32个滤波器，核大小为（3 × 3），步长（2 × 2）的卷积
- en: Convolution with 64 filters, kernel size equal to (3 × 3), and strides (1× 1)
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用64个滤波器，核大小为（3 × 3），步长（1× 1）的卷积
- en: Convolution with 128 filters, kernel size equal to (3 × 3), and strides (1 ×
    1)
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用128个滤波器，核大小为（3 × 3），步长（1 × 1）的卷积
- en: 'The decoder:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解码器：
- en: Transpose convolution with 128 filters, kernel size equal to (3 × 3), and strides
    (2 × 2)
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用128个滤波器，核大小为（3 × 3），步长（2 × 2）的转置卷积
- en: Transpose convolution with 64 filters, kernel size equal to (3 × 3), and strides
    (1× 1)
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用64个滤波器，核大小为（3 × 3），步长（1× 1）的转置卷积
- en: Transpose convolution with 32 filters, kernel size equal to (3 × 3), and strides
    (1 × 1)
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用32个滤波器，核大小为（3 × 3），步长（1 × 1）的转置卷积
- en: Transpose convolution with 1 filter, kernel size equal to (3 × 3), strides (1 ×
    1), and sigmoid activation
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用1个滤波器，核大小为（3 × 3），步长（1 × 1）和sigmoid激活的转置卷积
- en: 'As the images are (28 × 28), we prefer to resize each batch to the dimensions
    of (32 × 32) to easily manage all the subsequent operations that are based on
    sizes which are a power of 2:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像大小为（28 × 28），我们更愿意将每个批次调整到（32 × 32）的尺寸，以便轻松管理所有基于2的幂次大小的后续操作：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The loss function is a standard L2 without any other constraint. I invite the
    reader to test different optimizers and learning rates to employ a solution that
    guarantees the minimum loss value. After defining the `Graph`, it''s possible
    to set up an `InteractiveSession` (or a standard one), initialize all variables,
    and begin the training process:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数是一个标准的L2，没有任何其他约束。我邀请读者测试不同的优化器和学习率，以采用保证最小损失值的解决方案。在定义了`Graph`之后，可以设置一个`InteractiveSession`（或标准会话），初始化所有变量，并开始训练过程：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once the training process is finished, we can check the average code length
    for the whole dataset (this information is useful to compare this result with
    the one achieved by imposing a sparsity constraint):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练过程完成，我们可以检查整个数据集的平均编码长度（这个信息对于比较通过施加稀疏性约束得到的结果很有用）：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This value is very small, indicating that the representations are already rather
    sparse; however, we are going to compare it with the mean obtained by a sparse
    autoencoder. We can now process a few images (10) by encoding and decoding them:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个值非常小，表明表示已经相当稀疏；然而，我们将它与稀疏自编码器得到的平均值进行比较。现在我们可以通过编码和解码处理一些图像（10个）：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The result is shown in the following figure:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![](img/107520ee-94a1-4dc3-ba5b-f6416cf0d4f5.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/107520ee-94a1-4dc3-ba5b-f6416cf0d4f5.png)'
- en: Original images (upper row); decoded images (lower row)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 原始图像（上排）；解码图像（下排）
- en: As you can see, the reconstructions are rather lossy, but the autoencoder successfully
    learned how to reduce the dimensionality of the input samples. As an exercise,
    I invite the reader to split the code into two separate sections (encoder and
    decoder) and to optimize the architecture in order to achieve better accuracy
    on the whole Fashion MNIST dataset.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，重建过程相当损失较大，但自动编码器成功学会了如何降低输入样本的维度。作为一个练习，我邀请读者将代码分成两个独立的部分（编码器和解码器），并优化架构以在整个Fashion
    MNIST数据集上实现更高的准确率。
- en: TensorFlow is available for Linux, Windows, and OS X with both CPU and CUDA
    GPU support. In many cases, it's possible to install it using the `pip install
    -U tensorflow `command; however, I suggest that you read the updated instructions
    for each platform at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow适用于Linux、Windows和OS X，支持CPU和CUDA GPU。在许多情况下，可以使用`pip install -U tensorflow`命令安装它；然而，我建议您阅读每个平台的更新说明，请参阅[https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)。
- en: Denoising autoencoders
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 去噪自编码器
- en: 'Autoencoders can be used to determine under-complete representations of a dataset;
    however, Bengio et al. (in P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and
    P. Manzagol''s book *Stacked Denoising Autoencoders: Learning Useful Representations
    in a Deep Network with a Local Denoising Criterion,* from the *Journal* *of Machine
    Learning Research 11/2010*) proposed to use them not to learn the exact representation
    of a sample in order to rebuild it from a low-dimensional code, but rather to
    denoise input samples. This is not a brand new idea, because, for example, Hopfield
    networks (proposed a few decades ago) had the same purpose, but its limitations
    in terms of capacity led researchers to look for different methods. Nowadays,
    deep autoencoders can easily manage high-dimensional data (such as images) with a
    consequent space requirement, that''s why many people are now reconsidering the
    idea of teaching a network how to rebuild a sample image starting from a corrupted
    one.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '自动编码器可以用来确定数据集的欠完备表示；然而，Bengio等人（在P. Vincent, H. Larochelle, I. Lajoie, Y.
    Bengio和P. Manzagol的书籍《Stacked Denoising Autoencoders: Learning Useful Representations
    in a Deep Network with a Local Denoising Criterion》中，该书籍来自《Journal of Machine
    Learning Research 11/2010》）提出使用它们不是为了学习样本的精确表示以便从低维代码重建它，而是为了去噪输入样本。这并不是一个全新的想法，因为例如Hopfield网络（几十年前提出）有相同的目的，但其在容量方面的限制导致研究人员寻找不同的方法。如今，深度自动编码器可以轻松处理高维数据（如图像），这随之而来的空间需求，这就是为什么现在许多人正在重新考虑如何教会网络从损坏的图像开始重建样本图像的想法。'
- en: 'Formally, there are not many differences between denoising autoencoders and
    standard autoencoders. However, in this case, the encoder must work with noisy
    samples:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，去噪自动编码器和标准自动编码器之间没有太多区别。然而，在这种情况下，编码器必须与噪声样本一起工作：
- en: '![](img/9b1ba7e8-705a-4b9a-a017-59bd6da0cf05.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9b1ba7e8-705a-4b9a-a017-59bd6da0cf05.png)'
- en: 'The decoder''s cost function remains the same. If the noise is sampled for
    each batch, repeating the process for a sufficiently large number of iterations
    allows the autoencoder to learn how to rebuild the original image when some fragments
    are missing or corrupted. To achieve this goal, the authors suggested different
    possible kinds of noise. The most common choice is to sample Gaussian noise, which
    has some helpful features and is coherent with many real noisy processes:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器的损失函数保持不变。如果为每个批次采样噪声，重复足够多的迭代次数，允许自动编码器学习如何在某些片段缺失或损坏时重建原始图像。为了达到这个目标，作者们提出了不同类型的噪声。最常见的选择是采样高斯噪声，它具有一些有用的特性，并且与许多真实的噪声过程相一致：
- en: '![](img/59e89e7a-90c5-44d8-90db-4500f1499453.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/59e89e7a-90c5-44d8-90db-4500f1499453.png)'
- en: 'Another possibility is to employ an input dropout layer, zeroing some random
    elements:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可能性是使用输入丢弃层，将一些随机元素置零：
- en: '![](img/495a9795-f1a1-4574-a0ac-4a0deda8a2c4.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/495a9795-f1a1-4574-a0ac-4a0deda8a2c4.png)'
- en: 'This choice is clearly more drastic, and the rate must be properly tuned. A
    very large number of dropped pixels can irreversibly delete many pieces of information
    and the reconstruction can become more difficult and *rigid* (our purpose is to
    extend the autoencoder''s ability to other samples drawn from the same distribution).
    Alternatively, it''s possible to mix up Gaussian noise and the dropout''s, switching
    between them with a fixed probability. Clearly, the models must be more complex
    than standard autoencoders because now they have to cope with missing information;
    the same concept applies to the code length: very under-complete code wouldn''t
    be able to provide all the elements needed to reconstruct the original image in
    the most accurate way. I suggest testing all the possibilities, in particular
    when the noise is constrained by external conditions (for example, old photos
    or messages transmitted through channels affected by precise noise processes).
    If the model must also be employed for never-before-seen samples, it''s extremely
    important to select samples that represent the true distribution, using data augmentation
    techniques (limited to operations compatible with the specific problem) whenever
    the number of elements is not enough to reach the desired level of accuracy.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这种选择显然更为激进，并且必须适当调整比率。大量丢失的像素可能会不可逆地删除许多信息，重建可能会变得更加困难且*刚性*（我们的目的是扩展自动编码器对从同一分布中抽取的其他样本的能力）。或者，可以混合高斯噪声和dropout的噪声，以固定的概率在它们之间切换。显然，模型必须比标准自动编码器更复杂，因为现在它们必须处理缺失的信息；同样的概念也适用于代码长度：非常不完整的代码无法提供重建原始图像所需的所有元素，以最准确的方式。我建议测试所有可能性，特别是在噪声受外部条件限制时（例如，旧照片或通过受精确噪声过程影响的信道传输的消息）。如果模型还必须用于从未见过的样本，选择代表真实分布的样本至关重要，当元素数量不足以达到所需的精度水平时，使用数据增强技术（限于与特定问题兼容的操作）。
- en: An example of a denoising autoencoder with TensorFlow
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow中的去噪自动编码器示例
- en: 'In this example (based on the previous one), we are going to employ a very
    similar architecture, but as the goal is denoising the images, we will impose
    a code length equal to (width × height), setting all the strides to (1 × 1), and
    therefore we won''t need to resize the images anymore:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例（基于上一个例子）中，我们将采用一个非常相似的架构，但由于目标是去噪图像，我们将设置代码长度等于（宽度 × 高度），将所有步长设置为（1 × 1），因此我们不再需要调整图像大小：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In this case, we need to pass both the noisy images (through the `placeholder
    input_noisy_images`) and the original ones (which are used to compute the final
    L2 loss function). For our example, we have decided to employ Gaussian noise with
    a standard deviation of `σ = 0.2` (clipping the final values so that they are
    always constrained between 0 and 1):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们需要传递噪声图像（通过`placeholder input_noisy_images`）和原始图像（用于计算最终的L2损失函数）。在我们的例子中，我们决定使用标准差为`σ
    = 0.2`的高斯噪声（剪辑最终值，以确保它们始终介于0和1之间）：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The result after 200 epochs is shown in the following figure:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 经过200个epoch后的结果如图所示：
- en: '![](img/430f3d36-e54f-4420-9fd4-622f797a49ac.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/430f3d36-e54f-4420-9fd4-622f797a49ac.png)'
- en: Noisy samples (upper row); denoised samples (lower row)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声样本（上排）；去噪样本（下排）
- en: The denoising autoencoder has successfully learned to rebuild the original images
    in the presence of Gaussian noise. I invite the reader to test other methods (such
    as using an initial dropout) and increase the noise level to understand what the
    maximum corruption is that this model can effectively remove.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 去噪自动编码器已经成功地学会了在有高斯噪声的情况下重建原始图像。我邀请读者测试其他方法（例如使用初始dropout）并提高噪声水平，以了解该模型可以有效地去除的最大破坏程度。
- en: Sparse autoencoders
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稀疏自动编码器
- en: 'In general, standard autoencoders produce dense internal representations. This
    means that most of the values are different from zero. In some cases, however,
    it''s more useful to have sparse codes that can better represent the atoms belonging
    to a dictionary. In this case, if *z[i]* = (0, 0, *z[i]^n*, ..., 0, *z[i]^m*,
    ...), we can consider each sample as the overlap of specific atoms weighted accordingly.
    To achieve this objective, we can simply apply an L1 penalty to the code layer,
    as explained in [Chapter 1](acff0775-f21c-4b6d-8ef2-c78713e21364.xhtml), *Machine
    Learning* *Models* *Fundamentals*. The loss function for a single sample therefore
    becomes the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，标准自编码器产生密集的内部表示。这意味着大多数值与零不同。然而，在某些情况下，具有稀疏代码可能更有用，可以更好地表示属于字典的原子。在这种情况下，如果*z[i]*
    = (0, 0, *z[i]^n*, ..., 0, *z[i]^m*, ...), 我们可以将每个样本视为特定原子的加权重叠。为了实现这一目标，我们可以简单地应用L1惩罚到代码层，如[第1章](acff0775-f21c-4b6d-8ef2-c78713e21364.xhtml)中所述，*机器学习*
    *模型* *基础*。因此，单个样本的损失函数变为以下：
- en: '![](img/29b6cc9e-af0c-4533-b5a7-f578a866da9d.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/29b6cc9e-af0c-4533-b5a7-f578a866da9d.png)'
- en: In this case, we need to consider the extra hyperparameter α, which must be
    tuned to increase the sparsity without a negative impact on the accuracy. As a
    general rule of thumb, I suggest starting with a value equal to 0.01 and reducing
    it until the desired result has been achieved. In most cases, higher values yield
    very poor performance, and therefore they are generally avoided.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们需要考虑额外的超参数α，它必须调整以在不影响准确性的情况下增加稀疏度。作为一个一般性的经验法则，我建议从等于0.01的值开始，并减少它，直到达到期望的结果。在大多数情况下，更高的值会导致非常糟糕的性能，因此通常避免使用。
- en: 'A different approach has been proposed by Andrew Ng (in his book *Sparse Autoencoder,
    CS294A, Stanford University*). If we consider the code layer as a set of independent
    Bernoulli random variables, we can enforce sparsity by considering a generic reference
    Bernoulli variable with a very low mean (for example, *p[r]* = 0.01) and adding
    the Kullback–Leibler divergence between the generic element *z[i]^((j))* and *p[r]*
    to the cost function. For a single sample, the extra term is as follows (*p* is
    the code length):'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Andrew Ng（在他的书*稀疏自编码器，CS294A，斯坦福大学*）提出了不同的方法。如果我们将代码层视为一组独立的伯努利随机变量，我们可以通过考虑一个具有非常低平均值（例如，*p[r]*
    = 0.01）的通用参考伯努利变量，并将通用元素*z[i]^((j))*与*p[r]*之间的Kullback-Leibler散度添加到成本函数中，来强制执行稀疏性。对于单个样本，额外的项如下（*p*是代码长度）：
- en: '![](img/b39a7eec-78fc-4f40-9149-a3f3a69ef8c7.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b39a7eec-78fc-4f40-9149-a3f3a69ef8c7.png)'
- en: 'The resulting loss function becomes the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 结果损失函数变为以下：
- en: '![](img/f84c138c-77bb-4cfa-8f0e-0b072d9360dc.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f84c138c-77bb-4cfa-8f0e-0b072d9360dc.png)'
- en: The effect of this penalty is similar to L1 (with the same considerations about
    the α hyperparameter), but many experiments have confirmed that the resulting
    cost function is easier to optimize, and it's possible to achieve the same level
    of sparsity that reaches higher reconstruction accuracies. When working with sparse
    autoencoders, the code length is often larger because of the assumption that a
    single element is made up of a small number of atoms (compared to the dictionary
    size). As a result, I suggest that you evaluate the level of sparsity with different
    code lengths and select the combination that maximizes the former and minimizes
    the latter.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这种惩罚的效果类似于L1（考虑相同的α超参数问题），但许多实验已经证实，由此产生的成本函数更容易优化，并且可以达到达到更高重建精度的相同稀疏度。当与稀疏自编码器一起工作时，由于假设单个元素由少量原子组成（与字典大小相比），代码长度通常较大。因此，我建议您用不同的代码长度评估稀疏度水平，并选择最大化前者同时最小化后者的组合。
- en: Adding sparseness to the Fashion MNIST deep convolutional autoencoder
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向Fashion MNIST深度卷积自编码器添加稀疏性
- en: 'In this example, we are going to add an L1 regularization term to the cost
    function that was defined in the first exercise:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将在第一个练习中定义的成本函数中添加一个L1正则化项：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The training process is exactly the same, and therefore we can directly show
    the final code mean after 200 epochs:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程完全相同，因此我们可以直接展示200个epoch后的最终代码均值：
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see, the mean is now lower, indicating that more code values are
    close to 0\. I invite the reader to implement the other strategy, considering
    that it's easier to create a constant vector filled with small values (for example,
    0.01) and exploit the vectorization properties offered by TensorFlow. I also suggest
    simplifying the Kullback–Leibler divergence by splitting it into an entropy term
    *H(p[r])* (which is constant) and a cross-entropy *H(z, p[r])* term.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，均值现在更低，这表明更多的代码值接近 0。我邀请读者实现其他策略，考虑到创建一个填充小值（例如，0.01）的常量向量更容易，并且可以利用 TensorFlow
    提供的向量化特性。我还建议通过将其拆分为熵项 *H(p[r])*（这是常数）和交叉熵 *H(z, p[r])* 项来简化 Kullback–Leibler
    散度。
- en: Variational autoencoders
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变分自动编码器
- en: A **variational autoencoder** (**VAE**) is a generative model proposed by Kingma
    and Wellin (in their work *Auto-Encoding Variational Bayes, arXiv:1312.6114 [stat.ML]*)
    that partially resembles a standard autoencoder, but it has some fundamental internal
    differences. The goal, in fact, is not finding an encoded representation of a
    dataset, but determining the parameters of a generative process that is able to
    yield all possible outputs given an input data-generating process.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**变分自动编码器**（**VAE**）是由 Kingma 和 Wellin 提出的一种生成模型（在他们的工作 *Auto-Encoding Variational
    Bayes, arXiv:1312.6114 [stat.ML]* 中），它在某种程度上类似于标准自动编码器，但它有一些基本的内部差异。实际上，目标不是找到数据集的编码表示，而是确定一个生成过程的参数，该过程能够根据输入数据生成过程产生所有可能的输出。'
- en: 'Let''s take the example of a model based on a learnable parameter vector *θ*
    and a set of latent variables *z* that have a probability density function *p(z;θ)*.
    Our goal can therefore be expressed as the research of the *θ* parameters that
    maximize the likelihood of the marginalized distribution *p(x;**θ)* (obtained
    through the integration of the joint probability *p(x,z;θ*)):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个基于可学习参数向量 *θ* 和一组具有概率密度函数 *p(z;θ)* 的潜在变量 *z* 的模型为例。因此，我们的目标可以表达为研究 *θ*
    参数，以最大化边缘分布 *p(x;**θ)*（通过联合概率 *p(x,z;θ)* 的积分获得）的可能性：
- en: '![](img/95315e07-cf03-4353-bb7a-4a7128d08681.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/95315e07-cf03-4353-bb7a-4a7128d08681.png)'
- en: If this problem could be easily solved in closed form, a large set of samples
    drawn from the *p(x)* data generating process would be enough to find a *p(x;θ)*
    good approximation. Unfortunately, the previous expression is intractable in the
    majority of cases because the true prior *p(z)* is unknown (this is a secondary
    issue, as we can easily make some helpful assumptions) and the posterior distribution
    *p(x|z;θ)* is almost always close to zero. The first problem can be solved by
    selecting a simple prior (the most common choice is *z ∼ N(0, I)*), but the second
    one is still very hard because only a few *z* values can lead to the generation
    of acceptable samples. This is particularly true when the dataset is very high
    dimensional and complex (for example, images). Even if there are millions of combinations,
    only a small number of them can yield realistic samples (if the images are photos
    of cars, we expect four wheels in the lower part, but it's still possible to generate
    samples where the wheels are on the top). For this reason, we need to exploit
    a method to reduce the sample space. Variational Bayesian methods (read *C.* Fox
    and S. Roberts's work *A Tutorial on Variational Bayesian Inference* from *Orchid*
    for further information) are based on the idea of employing *proxy* distributions,
    which are easy to sample and, in this case, whose density is very high (that is,
    the probability of generating a reasonable output is much higher than the true
    posterior).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个问题可以很容易地以闭式形式解决，那么从数据生成过程 *p(x)* 中抽取的大量样本就足以找到好的 *p(x;θ)* 近似。不幸的是，由于真实的先验
    *p(z)* 未知（这是一个次要问题，因为我们可以轻易地做出一些有用的假设），并且后验分布 *p(x|z;θ)* 几乎总是接近零，所以前面的表达式在大多数情况下都是不可处理的。第一个问题可以通过选择一个简单的先验（最常见的选择是
    *z ∼ N(0, I)*）来解决，但第二个问题仍然非常困难，因为只有少数 *z* 值可以导致生成可接受的样本。这尤其适用于数据集非常高维和复杂（例如，图像）的情况。即使有数百万种组合，也只有少数可以产生真实的样本（如果图像是汽车的照片，我们期望在下半部分有四个轮子，但仍然有可能生成轮子在顶部的样本）。因此，我们需要利用一种方法来减少样本空间。变分贝叶斯方法（阅读
    *C.* Fox 和 S. Roberts 的作品 *A Tutorial on Variational Bayesian Inference* 来自 *Orchid*
    以获取更多信息）基于使用 *代理* 分布的想法，这些分布易于采样，在这种情况下，其密度非常高（即生成合理输出的概率远高于真实后验）。
- en: 'In this case, we define an approximate posterior, considering the architecture
    of a standard autoencoder. In particular, we can introduce a *q(z|x;θ[q])* distribution
    that acts as an encoder (that doesn''t behave determinastically anymore), which
    can be easily modeled with a neural network. Our goal, of course, is to find the
    best *θ[q]* parameter set to maximize the similarity between *q* and the true
    posterior distribution *p(z|x;θ)*. This result can be achieved by minimizing the
    Kullback–Leibler divergence:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们定义一个近似后验，考虑到标准自动编码器的架构。特别是，我们可以引入一个 *q(z|x;θ[q])* 分布，它充当一个编码器（不再表现出确定性），可以用神经网络轻松建模。我们的目标，当然是找到最佳的
    *θ[q]* 参数集，以最大化 *q* 与真实后验分布 *p(z|x;θ)* 之间的相似性。这个结果可以通过最小化 Kullback–Leibler 散度来实现：
- en: '![](img/b18cfc5e-0f3f-46ae-851c-b4794a60d700.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b18cfc5e-0f3f-46ae-851c-b4794a60d700.png)'
- en: 'In the last formula, the term *log p(x;**θ)* doesn''t depend on *z*, and therefore
    it can be extracted from the expected value operator and the expression can be
    manipulated to simplify it:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个公式中，项 *log p(x;**θ)* 不依赖于 *z*，因此可以从期望值算子中提取出来，并且表达式可以被操作以简化它：
- en: '![](img/96a6d5c0-f5c8-4920-9ca5-8736ae50a881.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96a6d5c0-f5c8-4920-9ca5-8736ae50a881.png)'
- en: 'The equation can be also rewritten as the following:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 该方程也可以重写为以下形式：
- en: '![](img/56866363-4d7f-4463-8c41-e41f7ae56d30.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/56866363-4d7f-4463-8c41-e41f7ae56d30.png)'
- en: On the right-hand side, we now have the term **ELBO** (short for **evidence
    lower bound**) and the Kullback–Leibler divergence between the probabilistic encoder
    *q(z|x;θ[q])* and the true posterior distribution *p(z|x;**θ)*. As we want to
    maximize the log-probability of a sample under the *θ* parametrization, and considering
    that the KL divergence is always non-negative, we can only work with the ELBO
    (which is a lot easier to manage than the other term). Indeed, the loss function
    that we are going to optimize is the negative ELBO. To achieve this goal, we need
    two more important steps.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在右侧，我们现在有项 **ELBO**（简称 **证据下界**）和概率编码器 *q(z|x;θ[q])* 与真实后验分布 *p(z|x;**θ)* 之间的
    Kullback–Leibler 散度。由于我们想要最大化在 *θ* 参数化下的样本的对数概率，并且考虑到 KL 散度总是非负的，我们只能处理 ELBO（这比其他项更容易管理）。实际上，我们将优化的损失函数是负
    ELBO。为了实现这个目标，我们需要两个更重要的步骤。
- en: 'The first one is choosing an appropriate structure for *q(z|x;θ[q])*. As *p(z;θ)*
    is assumed to be normal, we can supposedly model *q(z|x;θ[q])* as a multivariate
    Gaussian distribution, splitting the probabilistic encoder into two blocks fed
    with the same lower layers:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个选择是为 *q(z|x;θ[q]*) 选择一个合适的结构。由于假设 *p(z;θ)* 是正态分布，我们可以假设将 *q(z|x;θ[q]*) 模型化为一个多元高斯分布，将概率编码器分为两个块，这两个块使用相同的底层：
- en: A mean *μ(z|x;θ[q])* generator that outputs a *μ[i] ∈ ℜ^p* vector
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个均值生成器 *μ(z|x;θ[q])*，输出一个 *μ[i] ∈ ℜ^p* 向量
- en: A *Σ(z|x;θ[q]**)* covariance generator (assuming a diagonal matrix) that outputs
    a *σ[i] ∈ ℜ^p* vector so that *Σ[i]=*diag*(σ[i])*
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个协方差生成器 *Σ(z|x;θ[q]**)*（假设为对角矩阵），输出一个 *σ[i] ∈ ℜ^p* 向量，使得 *Σ[i]=*diag*(σ[i])*
- en: 'In this way, *q(z|x;θ[q]**) = N(μ(z|x;θ[q]), Σ(z|x;θ[q]))*, and therefore the
    second term on the right-hand side is the Kullback*-*Leibler divergence between
    two Gaussian distributions that can be easily expressed as follows (*p* is the
    dimension of both the mean and covariance vector):'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，*q(z|x;θ[q]**) = N(μ(z|x;θ[q]), Σ(z|x;θ[q]))*，因此右手边的第二项是两个高斯分布之间的 Kullback*-*Leibler
    散度，可以很容易地表示如下（*p* 是均值和协方差向量的维度）：
- en: '![](img/8f7f2056-f177-4232-85d8-b8000a39adcb.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f7f2056-f177-4232-85d8-b8000a39adcb.png)'
- en: This operation is simpler than expected because, as *Σ* is diagonal, the trace
    corresponds to the sum of the elements *Σ[1]* + *Σ[2]* + [...] + *Σ[p]* and log(|*Σ*|)
    = log(*Σ[1]Σ[2]...Σ[p]*) = log *Σ[1]* + log *Σ[2]* + ... + log *Σ[p]*.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作比预期的要简单，因为，由于 *Σ* 是对角矩阵，迹对应于元素 *Σ[1]* + *Σ[2]* + [...] + *Σ[p]* 的和，并且 log(|*Σ*|)
    = log(*Σ[1]Σ[2]...Σ[p]*) = log *Σ[1]* + log *Σ[2]* + ... + log *Σ[p]*.
- en: 'At this point, maximizing the right-hand side of the previous expression is
    equivalent to maximizing the expected value of the log probability to generate
    acceptable samples and minimizing the discrepancy between the normal prior and
    the Gaussian distribution synthesized by the encoder. Everything seems much simpler
    now, but there is still a problem to solve. We want to use neural networks and
    the stochastic gradient descent algorithm, and therefore we need differentiable
    functions. As the Kullback*-*Leibler divergence can be computed only using minibatches
    with *n* elements (the approximation becomes close to the true value after a sufficient
    number of iterations), it''s necessary to sample *n* values from the distribution
    *N(μ(z|x;θ[q]), Σ(z|x;θ[q]**)*) and, unfortunately, this operation is not differentiable.
    To solve this problem, the authors suggested a reparameterization trick: instead
    of sampling from *q(z|x;θ[q])*, we can sample from a normal distribution, *ε ∼
    N(0, I)*, and build the actual samples as *μ(z|x;θ[q])* + *ε · Σ(z|x;θ[q])*².
    Considering that *ε* is a constant vector during a batch (both the forward and
    backward phases), it''s easy to compute the gradient with respect to the previous
    expression and optimize both the decoder and the encoder.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，最大化上一个表达式的右侧等同于最大化生成可接受样本的期望对数概率，并最小化正态先验与编码器合成的高斯分布之间的差异。现在看起来似乎简单多了，但仍然有一个问题需要解决。我们希望使用神经网络和随机梯度下降算法，因此我们需要可微函数。由于Kullback-Leibler散度只能使用包含*n*个元素的minibatch（在足够多的迭代后，近似值接近真实值），因此有必要从分布*N(μ(z|x;θ[q]),
    Σ(z|x;θ[q]))*中采样*n*个值，而且不幸的是，这个操作是不可微分的。为了解决这个问题，作者提出了一种重新参数化技巧：我们不是从*q(z|x;θ[q])*中采样，而是可以从一个正态分布中采样，*ε
    ∼ N(0, I)*，并构建实际的样本作为*μ(z|x;θ[q])* + *ε · Σ(z|x;θ[q])*²。考虑到*ε*在批次中是一个常数向量（正向和反向阶段都是），很容易计算相对于前面表达式的梯度并优化解码器和编码器。
- en: 'The last element to consider is the first term on the right-hand side of the
    expression that we want to maximize:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要考虑的最后一个元素是我们要最大化的表达式的右侧的第一个项：
- en: '![](img/f5497892-3ca4-4615-becd-3f428a38df72.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f5497892-3ca4-4615-becd-3f428a38df72.png)'
- en: 'This term represents the negative cross-entropy between the actual distribution
    and the reconstructed one. As discussed in the first section, there are two feasible
    choices: Gaussian or Bernoulli distributions. In general, variational autoencoders
    employ a Bernoulli distribution with input samples and reconstruction values constrained
    between 0 and 1\. However, many experiments have confirmed that the mean squared
    error can speed up the training process, and therefore I suggest that the reader
    test both methods and pick the one that guarantees the best performance (both
    in terms of accuracy and training speed).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这个术语表示实际分布与重建分布之间的负交叉熵。如第一部分所述，有两种可行选择：高斯分布或伯努利分布。一般来说，变分自编码器使用伯努利分布，输入样本和重建值被限制在0和1之间。然而，许多实验已经证实均方误差可以加速训练过程，因此我建议读者测试这两种方法，并选择保证最佳性能的方法（无论是准确性还是训练速度）。
- en: An example of a variational autoencoder with TensorFlow
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow中的变分自编码器示例
- en: 'Let''s continue working with the Fashion MNIST dataset to build a variational
    autoencoder. As explained, the output of the encoder is now split into two components:
    the mean and covariance vectors (both with dimensions equal to *(width · height)*)
    and the decoder input is obtained by sampling from a normal distribution and projecting
    the code components. The complete `Graph` is as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用Fashion MNIST数据集来构建变分自编码器。如解释所述，编码器的输出现在分为两个部分：均值和协方差向量（两者维度都等于*(width
    · height)*）和解码器输入是通过从正态分布中采样并将代码组件投影得到的。完整的`Graph`如下：
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As you can see, the only differences are as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，唯一的区别如下：
- en: The generation of the encoder input is `(normal_samples * code_std) + code_mean`
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器输入的生成是`(normal_samples * code_std) + code_mean`
- en: The use of sigmoid cross-entropy as reconstruction loss
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用sigmoid交叉熵作为重建损失
- en: The presence of the Kullback*-*Leibler divergence as a regularization term
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kullback-Leibler散度作为正则化项的存在
- en: 'The training process is identical to the first example in this chapter, as
    the sampling operations are performed directly by TensorFlow. The result after
    200 epochs is shown in the following figure:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程与本章第一个示例相同，因为采样操作是由TensorFlow直接执行的。200个epoch后的结果如下所示：
- en: '![](img/ab30ddbf-f422-4504-95ea-388e16d1561c.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ab30ddbf-f422-4504-95ea-388e16d1561c.png)'
- en: Variational autoencoder output
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 变分自动编码器输出
- en: As an exercise, I invite the reader to use RGB datasets (such as Cifar-10, which
    is found at [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html))
    to test the generation ability of the VAE by comparing the output samples with
    the one drawn from the original distribution.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 作为练习，我邀请读者使用RGB数据集（例如Cifar-10，可在[https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)找到）来测试VAE的生成能力，通过比较输出样本与从原始分布中抽取的样本进行比较。
- en: In these kinds of experiments, where the random numbers are generated by both
    NumPy and TensorFlow, the random seeds are always set equal to 1,000 (`np.random.seed(1000)`
    and `tf.set_random_seed(1000)`). Other values or subsequent tests without resetting
    the seeds can yield slightly different results.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这类实验中，随机数由NumPy和TensorFlow共同生成，随机种子始终设置为1,000（`np.random.seed(1000)`和`tf.set_random_seed(1000)`）。其他值或未重置种子的后续测试可能会产生略微不同的结果。
- en: Summary
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we presented autoencoders as unsupervised models that can
    learn to represent high-dimensional datasets with lower-dimensional codes. They
    are structured into two separate blocks (which, however, are trained together):
    an encoder, responsible for mapping the input sample to an internal representation,
    and a decoder, which must perform the inverse operation, rebuilding the original
    image starting from the code.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将自动编码器作为无监督模型介绍，它可以学习用低维代码表示高维数据集。它们被结构化为两个独立的模块（尽管它们是共同训练的）：一个编码器，负责将输入样本映射到内部表示，以及一个解码器，它必须执行逆操作，从代码重建原始图像。
- en: We have also discussed how autoencoders can be used to denoise samples and how
    it's possible to impose a sparsity constraint on the code layer to resemble the
    concept of standard dictionary learning. The last topic was about a slightly different
    pattern called a variational autoencoder. The idea is to build a generative model
    that is able to reproduce all the possible samples belonging to a training distribution.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了如何使用自动编码器来去噪样本，以及如何对代码层施加稀疏性约束，以类似于标准字典学习的概念。最后一个主题是关于一种稍微不同的模式，称为变分自动编码器。其想法是构建一个生成模型，能够重现属于训练分布的所有可能的样本。
- en: In the next chapter, we are going to briefly introduce a very important model
    family called **generative adversarial networks** (**GANs**), which are not very
    different from the purposes of a variational autoencoder, but which have a much
    more flexible approach.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将简要介绍一个非常重要的模型家族，称为**生成对抗网络**（**GANs**），它与变分自动编码器的目的非常相似，但采用了更加灵活的方法。
