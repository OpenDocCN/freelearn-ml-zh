- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Time Series Analysis and Forecasting with MATLAB
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Time series data constitutes a sequence of measurements gathered over a certain
    period. These measurements, which are tied to a specific variable, occur at regular
    intervals. An essential characteristic of time series data lies in the significance
    of its order; the arrangement of observations on a timeline conveys meaningful
    patterns. Altering this order can completely reshape the data’s meaning. Sequential
    data is a broader concept that encompasses any data presented in a sequential
    manner, which includes time series data. In this chapter, we will delve into the
    fundamental concepts surrounding sequential data, elucidating how to construct
    models that capture patterns within time series or any sequential data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the basic concepts of time series data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting statistics from sequential data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a model to predict stock market data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with imbalanced datasets in MATLAB
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will introduce basic machine learning concepts. To understand
    these topics, a basic knowledge of algebra and mathematical modeling is needed.
    You will also require a working knowledge of MATLAB.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'To work with the MATLAB code in this chapter, you will need the following files
    (available on GitHub at [https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition](https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition)):'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '`Nile.csv`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TSLA.csv`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TeslaStockForecasting.m`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the basic concepts of time series data
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A time series represents a chronological sequence of recorded observations,
    such as monthly revenue, daily stock prices, weekly interest rates, annual profits,
    and more. The primary objective of time series analysis is to examine the historical
    progression of a phenomenon over time to anticipate its future trajectory. This
    predictive insight is derived from the assumption that recurring patterns observed
    in the past will continue to manifest in the future. We will explore the concepts
    of predictive forecasting and various forecasting methodologies, providing a detailed
    description of both.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Understanding predictive forecasting
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Predicting the trajectory of variables is immensely significant when it comes
    to formulating plans and policies for any endeavor. For instance, when planning
    a company’s production strategy, it isn’t sufficient to merely understand whether
    the demand for products or services is on the rise or declining. It’s imperative
    to forecast the future trends in product demand, pricing dynamics, and the costs
    of raw materials. Collectively, these elements wield substantial influence over
    production activities.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Forecasts hold a pivotal position at the core of the entire decision-making
    procedure. When forecasts are imprecise or insufficient, there exists a substantial
    risk of rendering the conclusions drawn from intricate decision models ineffective.
    The phrase *forecasting process* encompasses a range of intricate activities,
    whether overt or covert, that ultimately culminate in the creation of a forecast.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 预测在整个决策过程中占据核心地位。当预测不精确或不足时，存在使从复杂的决策模型中得出的结论无效的实质性风险。“预测过程”一词涵盖了各种复杂活动，无论是明显的还是隐秘的，最终都归结为预测的创建。
- en: The terms *forecast* and *prediction* are frequently used interchangeably, but
    it’s beneficial to differentiate their meanings. Forecasting involves associating
    probabilities with future events or defining confidence intervals to estimate
    the range of values likely to occur in the future. On the contrary, prediction
    entails identifying the exact value a measurable quantity will take on in the
    future. Consequently, it’s straightforward to connect forecasts with the predictions
    made by employing traditional inferential statistical tools to derive corresponding
    confidence intervals. The primary goal of all forecasting models is to determine
    an estimation of the anticipated value, coupled with an estimation of the potential
    error the forecasting model may generate.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 术语*预测*和*预测*经常被互换使用，但区分它们的含义是有益的。预测涉及将概率与未来事件相关联或定义置信区间以估计未来可能发生值的范围。相反，预测包括确定一个可测量量在未来的确切值。因此，通过使用传统的推断统计工具来推导相应的置信区间，将预测与使用这些工具做出的预测联系起来是直接的。所有预测模型的主要目标是确定预期值的估计，以及预测模型可能产生的潜在误差的估计。
- en: The forecast horizon is a crucial factor that distinguishes the forecasting
    process significantly. Forecasts can pertain to the immediate future, spanning
    up to 12 months, and serving as a foundation for operational decision-making.
    This might involve predicting product demand for the next 2 months. Alternatively,
    forecasts may extend into the medium term, ranging from 12 to 24 months, supporting
    decisions related to production planning. In the third scenario, forecasts are
    aimed at a more distant future, beyond the 24-month mark. In this case, they are
    crafted to underpin managerial decisions concerning company development plans.
    Across these three scenarios, each characterized by a short, medium, or long prediction
    horizon, the objectives of decision-makers seeking to utilize these forecasts
    differ significantly. Likewise, the level of precision and detail required for
    these respective forecasts also varies.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 预测范围是区分预测过程的关键因素。预测可以涉及短期未来，长达12个月，作为运营决策的基础。这可能包括预测未来2个月的产品需求。或者，预测可以延伸到中期，从12个月到24个月，支持与生产计划相关的决策。在第三种情况下，预测针对的是更远的未来，超过24个月。在这种情况下，它们被制定来支持有关公司发展计划的经理决策。在这三种情况下，每个都由短期、中期或长期预测范围特征化，寻求利用这些预测的决策者的目标差异很大。同样，对这些相应预测所需的精确度和详细程度也各不相同。
- en: Introducing forecasting methodologies
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍预测方法
- en: Forecasting methodologies refer to the various techniques and approaches that
    are used to predict future values, trends, or events based on historical data
    and patterns. These methodologies are essential in a wide range of fields, including
    economics, finance, business, and meteorology, among others. Forecasting methodologies
    vary primarily depending on the characteristics and intended purposes of the decisions
    they support. Factors such as the time horizon’s duration, the quality and consistency
    of historical data, and the specific attributes of the product being forecasted,
    such as its stage in the life cycle, play significant roles in determining the
    appropriate forecasting method.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 预测方法是指基于历史数据和模式预测未来值、趋势或事件的各种技术和方法。这些方法在包括经济学、金融、商业和气象学在内的众多领域中至关重要。预测方法主要取决于它们支持决策的特征和目的。诸如时间跨度的持续时间、历史数据的质和一致性，以及被预测产品的特定属性（如其在生命周期中的阶段）等因素在确定适当的预测方法中起着重要作用。
- en: 'In essence, forecasting methods can be categorized into two major groups: **quantitative
    methods** and **qualitative methods**.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，预测方法可以分为两大类：**定量方法**和**定性方法**。
- en: Explaining quantitative forecasting methods
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解释定量预测方法
- en: 'Quantitative methods are employed when there is sufficient quantitative data
    available, enabling predictions of future outcomes based on historical data. Typically,
    these methods find application in making short - to intermediate-term decisions.
    Here are some examples of quantitative prediction methods:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当有足够的定量数据可用时，会采用定量方法，这使得基于历史数据对未来结果进行预测成为可能。通常，这些方法用于做出短期至中期决策。以下是一些定量预测方法的例子：
- en: '**Time series analysis**: In this method, the phenomenon to be predicted is
    treated as an opaque entity, and the focus is not on identifying influencing factors.
    The objective of this approach is to recognize past patterns in the phenomenon’s
    evolution and extend those patterns into the future to make predictions. In simpler
    terms, predictions are based on the historical behavior of the phenomenon over
    time rather than being linked to explanatory variables. For example, this approach
    is often used in analyzing sales trends, GDP trends, and similar data.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间序列分析**：在这种方法中，要预测的现象被视为一个不透明的实体，重点不在于识别影响因素。这种方法的目标是识别现象演变中的过去模式，并将这些模式扩展到未来以进行预测。简单来说，预测基于现象随时间的历史行为，而不是与解释变量相关联。例如，这种方法常用于分析销售趋势、GDP趋势和类似数据。'
- en: '**Regression analysis**: Regression models quantify the correlation between
    one or more predictor variables and a response variable. These methods operate
    under the assumption that the variable to be forecasted can be associated with
    one or more independent or explanatory variables. This method is suitable for
    predicting numerical outcomes and is commonly used in economics, finance, and
    social sciences. For instance, the demand for consumer goods in a household is
    believed to be influenced by factors such as income, the ages of household members,
    and other related variables.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归分析**：回归模型量化了一个或多个预测变量与响应变量之间的相关性。这些方法基于这样一个假设，即要预测的变量可以与一个或多个独立或解释变量相关联。这种方法适用于预测数值结果，并且在经济学、金融和社会科学中常用。例如，家庭对消费品的需求被认为受收入、家庭成员的年龄和其他相关变量的影响。'
- en: '**Exponential smoothing**: Exponential smoothing techniques allocate exponentially
    decreasing weights to previous observations, prioritizing the significance of
    more recent data points. This helps in smoothing out noise and identifying trends
    in time series data.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指数平滑**：指数平滑技术为先前观察分配指数递减的权重，优先考虑较近数据点的显著性。这有助于平滑噪声并识别时间序列数据中的趋势。'
- en: '**Machine learning**: Machine learning algorithms, including decision trees,
    random forests, and neural networks, find application in forecasting tasks, especially
    when handling extensive datasets or intricate relationships. They can capture
    non-linear patterns and are increasingly employed in various forecasting applications.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习**：包括决策树、随机森林和神经网络在内的机器学习算法在预测任务中找到应用，尤其是在处理大量数据集或复杂关系时。它们可以捕捉非线性模式，并在各种预测应用中越来越被采用。'
- en: 'These methods are applicable under the following conditions:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法在以下条件下适用：
- en: Sufficient historical data is accessible regarding the phenomenon’s previous
    patterns
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于现象先前模式的历史数据是可获得的
- en: It is possible to quantify this historical information
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以量化这些历史信息
- en: It can be reasonably assumed that the attributes characterizing past trends
    will persist into the future, allowing for accurate forecasting
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以合理地假设，表征过去趋势的属性将延续到未来，从而允许进行准确的预测
- en: In essence, quantitative methods are employed when there is an ample supply
    of quantifiable historical data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，当有足够的可量化历史数据时，会采用定量方法。
- en: Describing qualitative forecasting methodologies
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 描述定性预测方法
- en: 'Qualitative methods primarily rely on judgments, making them dependent on the
    viewpoints and assessments of consumers and experts. These methods come into play
    when quantitative data is scarce, yet ample qualitative information is available.
    Here are a few instances illustrating the application of qualitative methods:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 定性方法主要依赖于判断，这使得它们依赖于消费者和专家的观点和评估。当定量数据稀缺而定性信息充足时，这些方法就会发挥作用。以下是一些说明定性方法应用的实例：
- en: '**Expert judgment**: Qualitative forecasting often relies on the expertise
    and opinions of subject matter experts. The Delphi method and expert panels are
    examples of techniques that gather input from knowledgeable individuals.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专家判断**：定性预测通常依赖于领域专家的专业知识和意见。德尔菲法和专家小组是收集知识渊博的个人意见的技术示例。'
- en: '**Market research**: Qualitative research methods, such as surveys, focus groups,
    and customer interviews, are used to gather information about consumer preferences,
    behaviors, and market trends. This data can be valuable for predicting future
    market conditions.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**市场研究**：定性研究方法，如调查、焦点小组和客户访谈，用于收集有关消费者偏好、行为和市场趋势的信息。这些数据对于预测未来的市场条件非常有价值。'
- en: '**Scenario analysis**: Qualitative forecasting can involve the creation of
    multiple scenarios or narratives about possible future events. Decision-makers
    then consider these scenarios to make informed decisions.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**情景分析**：定性预测可以包括创建关于可能未来事件的多个情景或叙述。决策者随后考虑这些情景以做出明智的决策。'
- en: '**Historical analogy**: This method involves making predictions based on similarities
    with past events or situations. It can be useful when dealing with unique or novel
    situations.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**历史类比**：这种方法涉及根据与过去事件或情况的相似性进行预测。在处理独特或新颖的情况时，这可能是有用的。'
- en: '**Expert systems**: Expert systems and AI-driven tools can assist in qualitative
    forecasting by aggregating and interpreting data from various sources to provide
    insights and predictions.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专家系统**：专家系统和由人工智能驱动的工具可以通过汇总和解释来自各种来源的数据来协助进行定性预测，从而提供洞察和预测。'
- en: The choice between quantitative and qualitative methods for forecasting depends
    on various factors, including the nature of the data, the availability of historical
    information, the specific forecasting goals, and the level of subjectivity involved.
    In many cases, a combination of both quantitative and qualitative methods is used
    to improve the accuracy and robustness of forecasts, especially in complex decision-making
    contexts.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 预测中定量方法和定性方法的选择取决于多种因素，包括数据的性质、历史信息的可用性、特定的预测目标以及涉及的主观程度。在许多情况下，结合使用定量和定性方法可以提高预测的准确性和稳健性，尤其是在复杂的决策环境中。
- en: Time series analysis
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间序列分析
- en: A time series represents a collection of observations related to a phenomenon,
    recorded at consecutive time points or intervals. These intervals are typically,
    though not always, evenly spaced or of uniform duration. Instances of time series
    data include diverse elements such as trends in commodity prices, stock market
    indices, the BTP/BUND spread, and unemployment rates.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列代表了一系列与现象相关的观察结果，这些观察结果是在连续的时间点或间隔上记录的。这些间隔通常是均匀的，尽管不总是这样。时间序列数据的实例包括商品价格趋势、股票市场指数、BTP/BUND利差和失业率等多样化的元素。
- en: Unlike classical statistics, which frequently assumes that independent observations
    stem from a single random variable, time series analysis presupposes *n* observations
    derived from a multitude of dependent random variables. Consequently, the analysis
    of a time series entails a procedure aimed at deciphering the underlying generating
    process behind the observed data, as opposed to treating each observation as independent
    and identically distributed.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 与经常假设独立观察结果来自单个随机变量的经典统计学不同，时间序列分析假设有 *n* 个观察结果来自众多相互依赖的随机变量。因此，时间序列分析涉及一个旨在解读观察数据背后的潜在生成过程的程序，而不是将每个观察结果视为独立且同分布的。
- en: 'Based on the data collected, time series data can be divided into two main
    types:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 根据收集到的数据，时间序列数据可以分为两大类：
- en: '**Continuous time series**: Data is recorded continuously over a specific period
    without any gaps or interruptions. This type of time series is common in applications
    such as sensor data, where measurements are taken at very short intervals, often
    in real time. Examples include temperature readings recorded every second, stock
    prices updated every minute, or heart rate monitoring over continuous intervals.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**连续时间序列**：数据在特定时期内连续记录，没有任何间隔或中断。这种类型的时间序列在传感器数据等应用中很常见，其中测量是在非常短的时间间隔内进行的，通常是在实时。例如，每秒记录的温度读数、每分钟更新的股票价格或连续间隔的心率监测。'
- en: '**Discrete time series**: Data is recorded at specific, discrete time intervals,
    which may not necessarily be evenly spaced. These intervals can be daily, weekly,
    monthly, annually, or any other predetermined period. Discrete time series data
    is often used in economic, financial, and social sciences to analyze trends and
    patterns over time. Examples include monthly sales figures, annual GDP growth
    rates, or weekly website traffic statistics.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离散时间序列**：数据在特定的、离散的时间间隔内记录，这些间隔不一定均匀。这些间隔可以是每日、每周、每月、每年或任何其他预定的周期。离散时间序列数据常用于经济、金融和社会科学中，以分析随时间变化的趋势和模式。例如，包括月度销售额、年度GDP增长率或周度网站流量统计。'
- en: The choice between continuous and discrete time series depends on the nature
    of the data being collected and the specific objectives of the analysis. Each
    type of time series has its own set of statistical techniques and tools that are
    used for modeling, forecasting, and extracting meaningful insights.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 选择连续时间序列和离散时间序列取决于收集数据的性质和分析的具体目标。每种类型的时间序列都有其自己的统计技术和工具，用于建模、预测和提取有意义的见解。
- en: 'Time series data can also be categorized into two main types based on the underlying
    nature of the data-generating process:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据也可以根据数据生成过程的潜在性质分为两大类：
- en: '**Deterministic time series**: This type is characterized by a clear and predictable
    pattern or relationship between data points. The data values in a deterministic
    time series follow a specific mathematical function or rule. Deterministic patterns
    can be expressed as mathematical equations or formulas and may include periodic
    or seasonal variations, trends, or specific mathematical relationships. Deterministic
    time series often exhibit little or no randomness, making them highly predictable.
    Examples of this type of time series are a sine wave representing daily temperature
    variations over a year, a linear trend in stock prices, where prices consistently
    increase or decrease over time, and monthly sales figures influenced by a known
    seasonal pattern, such as holiday sales.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**确定性时间序列**：这种类型的特点是数据点之间存在清晰且可预测的模式或关系。确定性时间序列中的数据值遵循特定的数学函数或规则。确定性模式可以用数学方程式或公式表示，可能包括周期性或季节性变化、趋势或特定的数学关系。确定性时间序列通常表现出很少或没有随机性，使其高度可预测。这类时间序列的例子包括表示一年内每日温度变化的正弦波、股价的线性趋势，其中价格随着时间的推移持续增加或减少，以及受已知季节性模式（如假日销售）影响的月度销售额。'
- en: '**Stochastic time series**: This is characterized by randomness, and the data
    points are not governed by a specific deterministic rule. Instead, they are influenced
    by random or probabilistic factors. Stochastic time series exhibit inherent randomness,
    making it challenging to predict future values with certainty. They often involve
    elements of uncertainty, noise, and randomness that cannot be fully explained
    by a deterministic model. Statistical techniques, such as **Autoregressive Integrated
    Moving Average** (**ARIMA**) models or state-space models, are commonly used to
    analyze and forecast stochastic time series. Examples of this type of time series
    are stock prices, which are influenced by a multitude of unpredictable factors
    and exhibit daily fluctuations that cannot be precisely predicted, daily weather
    conditions, where variables such as rainfall or temperature can vary randomly,
    and daily website traffic, which is influenced by user behavior and external factors,
    resulting in random fluctuations.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机时间序列**：这种类型的特点是随机性，数据点不受特定确定性规则的支配。相反，它们受随机或概率因素的影响。随机时间序列表现出固有的随机性，使得确定性地预测未来值变得具有挑战性。它们通常涉及不确定性、噪声和随机性等元素，这些元素不能完全由确定性模型解释。统计技术，如**自回归积分移动平均**（**ARIMA**）模型或状态空间模型，通常用于分析和预测随机时间序列。这类时间序列的例子包括受多种不可预测因素影响的股价，其每日波动无法精确预测，每日天气条件，其中降雨量或温度等变量可能随机变化，以及受用户行为和外部因素影响的每日网站流量，导致随机波动。'
- en: In practice, many real-world time series data contains a combination of deterministic
    and stochastic components. Analyzing and modeling time series data effectively
    often requires identifying and separating these components to gain insights and
    make accurate forecasts or predictions. Deterministic models are useful when the
    underlying patterns are well defined and stable, while stochastic models are employed
    when randomness plays a significant role in the data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，许多现实世界的时序数据包含确定性和随机性成分的组合。有效地分析和建模时序数据通常需要识别和分离这些成分，以获得洞察力并做出准确的预测或预测。当潜在模式定义良好且稳定时，确定性模型是有用的，而当随机性在数据中扮演重要角色时，则采用随机模型。
- en: 'Indeed, when dealing with time series data that exhibits both deterministic
    and stochastic components, it is common to represent the series as the sum of
    these two contributions. This approach allows for a more comprehensive understanding
    of the data and facilitates modeling and analysis. Mathematically, it can be expressed
    as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，当处理同时表现出确定性和随机性成分的时序数据时，通常将序列表示为这两个贡献的总和。这种方法有助于更全面地理解数据，并促进建模和分析。数学上，它可以表示如下：
- en: Y t = f(t) + w(t)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Y t = f(t) + w(t)
- en: 'Here, we have the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们有以下内容：
- en: '*Y**t*: This represents the observed time series data at time *t*'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Y**t*：这代表时间*t*观察到的时序数据'
- en: '*f(t)*: This represents the deterministic component or contribution at time
    *t*'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f(t)*：这代表时间*t*的确定性成分或贡献'
- en: '*w(t)*: This represents the stochastic (random) component or contribution at
    time *t*'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w(t)*：这代表时间*t*的随机（随机）成分或贡献'
- en: 'By decomposing the time series into its deterministic and stochastic parts,
    analysts and researchers can do the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将时序分解为其确定性和随机部分，分析师和研究人员可以进行以下操作：
- en: '**Analyze trends**: The deterministic component often includes trends, seasonality,
    and other structured patterns that can be analyzed separately to understand the
    underlying dynamics.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分析趋势**：确定性成分通常包括趋势、季节性和其他可以单独分析的有序模式，以了解潜在的动态。'
- en: '**Model stochastic behavior**: The stochastic component captures the random
    fluctuations and noise in the data. Models such as **ARIMA** or **Generalized
    Autoregressive Conditional Heteroskedasticity** (**GARCH**) can be applied to
    this component for forecasting or risk assessment.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型随机行为**：随机成分捕捉数据中的随机波动和噪声。例如，**ARIMA**或**广义自回归条件异方差性**（**GARCH**）等模型可以应用于该成分进行预测或风险评估。'
- en: This decomposition approach enhances the ability to make forecasts, identify
    anomalies, and gain insights into the factors influencing the time series data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分解方法增强了做出预测、识别异常和深入了解影响时序数据因素的能力。
- en: Using time denoted as *t = 1 …. T*, we represent the sequence, yt. Time serves
    as the critical parameter governing the sequence of events that must not be overlooked.
    Consequently, understanding the temporal dimension’s position of observation becomes
    essential. Typically, this information is depicted as the pair of values (*t*,
    *yt*) on a Cartesian graph, creating a continuous line graph that conveys the
    impression of continuous detection of the phenomenon. This graphical representation
    is commonly known as a time series plot (*Figure 9**.1*).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用时间表示为*t = 1 …. T*，我们表示序列，yt。时间作为控制事件序列的关键参数，不容忽视。因此，理解观察时间维度的位置变得至关重要。通常，这种信息以(*t*,
    *yt*)对的形式表示在笛卡尔图上，创建一个连续的线图，传达连续检测现象的印象。这种图形表示通常被称为时序图（*图9**.1*）。
- en: 'To understand how a series plot can be drawn, we can use the `Nile.csv` file
    in this book’s GitHub repository. This file provides data on the annual flow of
    the Nile river at Aswan from 1871 to 1970, measured in units of 108 cubic meters.
    We can import this dataset into MATLAB using the following code:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何绘制序列图，我们可以使用本书GitHub仓库中的`Nile.csv`文件。此文件提供了从1871年到1970年阿斯旺尼罗河年流量的数据，以108立方米的单位测量。我们可以使用以下代码将此数据集导入MATLAB：
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To draw a time series plot, we can use the following command:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要绘制时序图，我们可以使用以下命令：
- en: '[PRE1]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We used the dot format, where `time` and `Nile` are the names of the two features
    selected. The following time series plot will be drawn:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了点格式，其中`time`和`Nile`是所选两个特征的名称。以下时序图将被绘制：
- en: "![Figure 9.1 – Measurements of the annual flow of the Nile \uFEFFriver at Aswan](img/B21156_09_01.jpg)"
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图9.1 – 阿斯旺尼罗河年流量测量](img/B21156_09_01.jpg)'
- en: Figure 9.1 – Measurements of the annual flow of the Nile river at Aswan
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 – 阿斯旺尼罗河年流量测量
- en: As shown in *Figure 9**.1*, there appears to be a significant change point in
    the data around 1898, suggesting a notable shift or change in the river’s flow
    characteristics during that period.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图9**.1*所示，数据在1898年左右似乎有一个显著的变化点，表明在该时期河流流量特征发生了显著的变化或转变。
- en: A time series plot provides an immediate insight into trends, recurring patterns,
    and other systematic behaviors that evolve. In the previous graph, we can see
    annual data exhibiting a consistent declining trend spanning a considerable time
    frame. Notably, there is a recurring zigzag pattern due to the data being recorded
    monthly, which is indicative of seasonality. It’s worth noting that the high peaks
    occur consistently during months when rainfall is anticipated.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列图可以立即揭示趋势、重复模式和其他随时间演变的系统性行为。在前面的图表中，我们可以看到年度数据表现出持续下降的趋势，跨越相当长的时间框架。值得注意的是，由于数据是按月记录的，因此存在重复的锯齿形模式，这表明季节性。值得注意的是，在预期降雨的月份，高峰值出现得非常一致。
- en: Univariate analysis of time series aims to decipher the dynamic processes that
    underlie the series and predict future occurrences of the phenomenon. In this
    analysis, we focus exclusively on the data pairs (*t, yt*), where *t = 1, …..,T*.
    The crucial concept here is that both past and present data contain valuable information
    for forecasting the future development of the phenomenon.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列的单变量分析旨在解码序列背后的动态过程，并预测现象未来的发生。在此分析中，我们专注于数据对(*t, yt*)，其中*t = 1, ……,T*。这里的关键概念是，过去和现在的数据都包含对未来现象发展趋势进行预测的有价值信息。
- en: However, it’s essential to recognize that univariate analysis might be overly
    restrictive in some cases. Often, we possess information related to phenomena
    associated with the one under consideration, which should be suitably integrated
    to enhance the model’s predictive capabilities. Nevertheless, univariate analysis
    serves as a valuable baseline, allowing us to validate more sophisticated modeling
    approaches.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们必须认识到，在某些情况下，单变量分析可能过于限制。通常，我们拥有与所考虑现象相关的信息，这些信息应适当整合以增强模型的预测能力。尽管如此，单变量分析仍然是一个有价值的基线，使我们能够验证更复杂的建模方法。
- en: 'In a time series plot, four distinct patterns can be identified concerning
    the progression of time:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列图中，可以识别出关于时间进展的四种不同模式：
- en: '**Horizontal pattern**: In this scenario, the series fluctuates around a constant
    value, which is typically the series average. Such a series is referred to as
    being stationary on average. This pattern is commonly encountered in quality control,
    where processes are consistently maintained around an average value.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水平模式**：在这种情况下，序列围绕一个常数值波动，这通常是序列的平均值。这样的序列被称为平均上稳定。这种模式在质量控制中很常见，其中过程始终保持在平均值周围。'
- en: '**Seasonal pattern**: A seasonal pattern emerges when the series is influenced
    by recurring seasonal factors, such as monthly, semi-annual, or quarterly variations.
    Products such as ice cream, soft drinks, and electricity consumption often exhibit
    seasonal patterns. These series, which are influenced by seasonality, are also
    known as periodic series since the seasonal cycle repeats at fixed intervals.
    In the case of annual data, seasonality may not be evident.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**季节性模式**：当序列受到诸如月度、半年或季度等重复季节性因素的影响时，就会出现季节性模式。如冰淇淋、软饮料和电力消耗等产品通常表现出季节性模式。这些受季节性影响的时间序列也被称为周期性序列，因为季节性循环在固定间隔内重复。在年度数据的情况下，季节性可能不明显。'
- en: '**Cyclic pattern**: The presence of a cyclic pattern is characterized by irregular
    increases and decreases in the series that do not follow a fixed period. This
    distinguishes cyclic fluctuations from seasonal ones. Furthermore, cyclic oscillations
    typically exhibit larger amplitudes compared to seasonal variations. In economic
    series, cyclic patterns are driven by economic expansions and contractions resulting
    from speculative phenomena.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**周期性模式**：周期性模式的特点是序列中存在不规则的增加和减少，这些变化并不遵循固定的周期。这区别于季节性波动。此外，周期性振荡通常比季节性变化具有更大的振幅。在经济序列中，周期性模式是由投机现象引起的经济扩张和收缩所驱动的。'
- en: '**Trend**: Trends are recognized by sustained, long-term increases or decreases
    in the series. For instance, the global population series exemplifies an increasing
    trend, while the monthly beer sales series may not display any discernible trend
    and instead possesses a stable horizontal background pattern.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**趋势**：趋势通过序列中持续的、长期的增长或下降来识别。例如，全球人口序列体现了增长趋势，而每月啤酒销售序列可能不显示任何可辨别的趋势，而是具有稳定的水平背景模式。'
- en: Many time series exhibit a combination of these patterns, and it is precisely
    this kind of complexity that adds a high level of interest to the forecasting
    task. Forecasting methods must possess the capability to discern and replicate
    the various components of the series. This involves the assumption that past patterns
    will persist and continue to manifest their characteristic features in the future.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 许多时间序列都表现出这些模式的组合，正是这种复杂性为预测任务增添了高度的兴趣。预测方法必须具备辨别和复制序列各种成分的能力。这涉及到过去模式将持续并继续在未来表现出其特征特征的假设。
- en: The classical approach to time series analysis involves dissecting the deterministic
    portion of the series into a set of signal components, which convey the structural
    information of the series while filtering out the negligible noise. In practical
    terms, our objective is to identify some of the previously mentioned patterns
    within the time series trend.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列分析的经典方法涉及将序列的确定性部分分解成一系列信号成分，这些成分传达了序列的结构信息，同时过滤掉了可忽略的噪声。在实践中，我们的目标是识别时间序列趋势中的一些先前提到的模式。
- en: 'In time series analysis, three fundamental components are used to model and
    understand the underlying patterns in the data: trend, seasonal, and residual
    components. These components help decompose a time series into its constituent
    parts, making it easier to analyze and forecast the data accurately:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列分析中，使用三个基本成分来建模和理解数据中的潜在模式：趋势、季节和残差成分。这些成分有助于将时间序列分解为其组成部分，使其更容易分析和准确预测数据：
- en: '**Trend component**: It represents the long-term, systematic, and often smooth
    movement or direction in the time series. It reflects the underlying, sustained
    changes or growth (increasing trend) or declines (decreasing trend) in the data
    over an extended period. The trend component aims to capture the overall behavior
    of the time series, making it essential for understanding its fundamental trajectory.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**趋势成分**：它代表了时间序列中的长期、系统性和通常平滑的运动或方向。它反映了数据在较长时间内的潜在、持续的变动或增长（增长趋势）或下降（下降趋势）。趋势成分旨在捕捉时间序列的整体行为，对于理解其基本轨迹至关重要。'
- en: '**Seasonal component**: It accounts for the recurring patterns or fluctuations
    in the time series that follow a fixed and known period. These patterns repeat
    at regular intervals, such as daily, monthly, quarterly, or annually. Seasonality
    is often linked to external factors such as weather, holidays, or business cycles
    and tends to recur predictably over time.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**季节成分**：它解释了时间序列中遵循固定和已知周期的重复模式或波动。这些模式以固定的时间间隔重复，如每日、每月、每季度或每年。季节性通常与外部因素有关，如天气、假日或商业周期，并且随着时间的推移具有可预测的重复性。'
- en: '**Residual component**: This component, also known as the error or noise, represents
    the random fluctuations or unexplained variability in the time series data. It
    includes all the information not accounted for by the trend and seasonal components.
    Analyzing the residual component helps identify irregularities, outliers, or unexpected
    events in the data.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**残差成分**：这个成分，也称为误差或噪声，代表了时间序列数据中的随机波动或未解释的变异性。它包括趋势和季节成分未考虑的所有信息。分析残差成分有助于识别数据中的不规则性、异常值或意外事件。'
- en: Mathematically, a time series (*Y**t*) can be expressed as the sum of these
    three components. Decomposing a time series into these components is a fundamental
    step in time series analysis. Once separated, analysts can model each component
    individually, apply appropriate statistical techniques, and make more accurate
    forecasts. This decomposition helps in understanding the underlying dynamics of
    the data and can provide valuable insights for decision-making and forecasting.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，一个时间序列（*Y**t*）可以表示为这三个成分的总和。将时间序列分解为这些成分是时间序列分析的基本步骤。一旦分离，分析师可以单独对每个成分进行建模，应用适当的统计技术，并做出更准确的预测。这种分解有助于理解数据的潜在动态，并为决策和预测提供有价值的见解。
- en: Let’s see the different approaches to time series modeling and how it is possible
    to extract knowledge from these types of data.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Extracting statistics from sequential data
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Time series data represents a sequence of measurements gathered over a certain
    period. These measurements are linked to a specific variable and are obtained
    at regular intervals. An essential characteristic of time series data is its inherent
    order, where the arrangement of observations along a timeline conveys significant
    information. Altering the sequence can completely change the data’s meaning. Sequential
    data, on a broader scale, encompasses any data presented sequentially, including
    time series data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Our primary goal is to develop models that capture the underlying patterns within
    time series data or any sequential data. These models are instrumental in describing
    essential aspects of the time series patterns. They enable us to explore how past
    data influences the future, examine correlations between datasets, make future
    predictions, or control variables based on specific metrics. To visually represent
    time series data, we commonly employ line charts or bar graphs. Time series data
    analysis finds extensive use in various domains, including finance, signal processing,
    weather forecasting, trajectory prediction, earthquake prediction, and any field
    dealing with temporal data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: In the realm of time series and sequential data analysis, the models we construct
    must consider data ordering and extract relationships among adjacent data points.
    Now, let’s explore some MATLAB code examples for analyzing time series and sequential
    data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Converting a dataset into a time series format in MATLAB
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A time series represents a sequence of observations of a phenomenon collected
    at consecutive moments or time intervals, typically evenly spaced or of consistent
    duration, although not necessarily so. It’s crucial to recognize that time plays
    a fundamental role in the analysis of a time series. To begin, we need to develop
    proficiency in handling data that portrays a prolonged observation of a specific
    phenomenon. Our initial step will involve learning how to transform a sequence
    of observations into time series data and then visualizing it.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: In MATLAB, to adequately handle time series data, we can use the `timetable`
    object. A timetable is a specialized form of a table that’s designed for handling
    time series data. Similar to regular tables, timetables store data variables organized
    by columns, allowing for various data types and sizes, so long as they share the
    same number of rows. In addition to this flexibility, timetables offer specific
    functions tailored for time-related operations, enabling alignment, combination,
    and calculations involving timestamped data across one or more timetables.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: The row times in a timetable consist of datetime or duration values that serve
    as labels for individual rows. You can access and manipulate a timetable by row
    time and variable. To access specific elements within a timetable, you can use
    round parentheses, *()*, to retrieve a subtable or curly braces, *{}*, to extract
    their contents. Furthermore, you can reference variables and the row times vector
    using their respective names. To identify and annotate events within a timetable,
    you can associate an event table with it. Event tables contain a record of event
    times, corresponding event labels, and additional event-related details.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin with, we will see how it is possible to create a timetable from such
    data. Suppose we have stored data about the flow of a river, measured at different
    times, in a timetable. In addition to archiving, schedules provide functions to
    synchronize data with specified times. In addition, we can note the time to add
    more information about the measurement conditions and other variables to be measured.
    Therefore, we can associate a time with the variables present in the workspace.
    The values present in the variable containing the times become the times of the
    object lines. All the other input arguments become time-dependent variables. Let’s
    learn how to format timetable data:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, we must create the vector containing the variables, starting with
    the time vector:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'First, we have the time of the measurements, then the value of the temperatures
    measured in this place at this time, and finally the values of the river flow
    measured in units of 108 cubic meters. To set the time format, we used the `datetime()`
    function: a datetime array contains information about the year, month, day, hour,
    minute, and second components associated with each recorded point in time, adhering
    to the proleptic ISO calendar system. Additionally, datetime arrays offer versatile
    formats for displaying output and parsing input text, support for storing fractional
    seconds with precision down to nanoseconds, and properties to handle considerations
    such as time zones, daylight saving time, and leap seconds.'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The data that’s used is corrected and added to the time vector in a format
    compatible with the type of data. Now, we can use the `timetable()` function to
    create the object:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'A new timetable object was created in the MATLAB workspace. We can check the
    object’s type as follows:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To understand how the `timetable()` function handles the data, we will print
    the object that was created, as follows:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The timeline can also be constructed based on specific values of some parameters.
    For example, we can use the `RiverFlow` variable already available in the MATLAB
    workspace to associate each of its values with a specific time value defined in
    a specific timeline. For example, we can define a time step as follows:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We set `TimeStep` to one year and `StartTime` to 1870\. By doing this, one value
    of `RiverFlow` is associated with a new year starting from 1870 with an increment
    of one year.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Understanding time series slicing
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Slicing and dicing are two expressions that are used in the context of datasets,
    signifying the process of partitioning a substantial dataset into smaller segments
    or examining it from various perspectives to gain deeper insights. These terms
    draw an analogy from culinary terminology, describing two fundamental knife techniques
    that chefs must proficiently execute. Slicing entails cutting, whereas dicing
    involves cutting food into finely uniform sections, often performed consecutively.
    In data analysis, the concept of slice and dice typically encompasses the systematic
    breakdown of a large dataset into more manageable portions to extract additional
    information.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: In MATLAB, a timetable is a specialized form of table that links a specific
    time with each row. You can efficiently extract time-related subsets of its data
    through various methods, such as identifying times within a specified range or
    matching recurring time intervals.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'After learning how to create a timetable object from variables in the workspace,
    we can learn how to import and manipulate an external file into MATLAB as a timetable
    object:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `.csv` file we used in the *Exploring the basic concepts of
    time series* *data* section. I’m referring to the `Nile.csv` file; we can import
    this file using the following command:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, let’s learn how to access this specific type of data. You can employ dot
    notation to retrieve the row times of a timetable. Furthermore, you can access
    specific variables by using dot notation individually or access all the data within
    a timetable using its name, as we just did.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To display the first two lines of the time series object, we can use the following
    command:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following data is printed:'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To access only the data of one variable, we can use dot notation, as follows:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Retrieve the entirety of the timetable data as a matrix using the `NileRiverFlowData.Variables`
    syntax. This syntax relies on the second dimension name of the timetable and is
    functionally identical to accessing all contents through curly brace indexing:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: However, it’s important to note that the resulting matrix does not incorporate
    row times as the row times vector is considered metadata within the timetable
    and not treated as a variable. In cases where the timetable data cannot be effectively
    concatenated into a matrix, an error message will be generated.
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To locate data within a particular range, you can utilize the `timerange` function,
    which establishes time-based subscripts for indexing. For example, you can set
    up a range that commences on January 1, 1880, and concludes on January 1, 1920\.
    It’s important to note that by default, the `timerange` function defines a half-open
    interval that includes the left endpoint but excludes the right endpoint:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we can slice a portion of the dataset defined from this range, as follows:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The new dataset contains data starting from January 1, 1880, and ending on January
    1, 1919.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Resampling time series data in MATLAB
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s see how it’s possible to resample time series data in MATLAB. This task
    involves changing the frequency or time intervals of the data while preserving
    the essential information. This can be useful for various purposes, such as aggregating
    data to a coarser time scale, interpolating data to a finer time scale, or aligning
    data from different sources with a common time grid. MATLAB provides several functions
    and methods for resampling time series data. Here’s a basic example of how to
    do it.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by using the `retime()` function, as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This function resamples or consolidates data within a timetable while addressing
    issues related to duplicate or irregular time entries. The `retime()` function
    generates a timetable by incorporating variables from the initial data and enforces
    a consistent time step for the row times. This function resamples or consolidates
    data within the initial variables based on the specified method. `retime()` can
    be applied to interpolate data values from initial values at different timestamps,
    aggregate data into time intervals, eliminate rows with duplicate timestamps in
    the timetable, and transform an irregular timetable into a regular one by imposing
    regularly spaced row times, as defined by the new *time step*.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we resampled the dataset by adding the weekly data starting
    from the monthly, but there are different ways to resample data. We performed
    data value interpolation based on the adjacent rows. It is essential that the
    input timetable has sorted and distinct row times. There are four different types
    of interpolation available:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '`linear`: Linear interpolation'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spline`: Piecewise cubic spline interpolation'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pchip`: Shape-preserving piecewise cubic interpolation'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`makima`: Modified Akima cubic Hermite interpolation'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are the possibilities to aggregate the time series data using the same
    function (`retime()`). The `retime()` function offers aggregation options, including
    the mean. For example, we can compute the mean values monthly for the given data:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In this way, we aggregated the previously resampled weekly data using the average
    as the aggregation criterion.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Moving average
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A moving average is a commonly used method for analyzing time series data. It
    involves calculating the average of a set of data points within a specific window
    or time interval as it moves through the time series. This helps to smooth out
    fluctuations and highlight underlying trends in the data. There are different
    types of moving averages, such as the **simple moving average** (**SMA**) and
    the **exponential moving average** (**EMA**), each with its characteristics and
    use cases.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 'SMA is a basic and widely used method for analyzing time series data. It is
    a statistical calculation that helps smooth out fluctuations in data to identify
    trends or patterns. Here’s how you calculate SMA:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Choose a specific period or window.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each data point, take the average of the data points within that time window.
    This involves adding up the values over the chosen period and dividing by the
    number of data points in that window.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move the window one time step forward and calculate the average again. Repeat
    this process for each data point.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The result is a series of averages that represent the trend in the data over
    the chosen period. SMAs are commonly used for various purposes, including identifying
    trends, smoothing out noise in time series data, and making forecasts. For example,
    if you are interested in calculating a 10-day SMA for daily stock prices, you
    would average the closing prices of the last 10 days to get a moving average value
    for each day. This moving average can help you identify the general direction
    of the stock’s price trend over those 10 days.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'In MATLAB, you can calculate an SMA for a time series using the `movmean()`
    function, which is available in the Statistics and Machine Learning Toolbox. Let’s
    learn how to use the `movmean()` function with a practical example:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll start by defining the window size for the SMA:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We defined a five-year window to calculate the moving average.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we can calculate the moving average:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `movmean()` function generates an array of local mean values for k-point
    neighborhoods. Each mean is computed by sliding a window with a length of *k*
    across adjacent elements of the array, *A*. If *k* is an odd number, the window
    centers around the current position’s element. For even values of *k*, the window
    centers around the current and preceding elements. The window size adjusts automatically
    at the array’s endpoints when there are insufficient elements to fill it. In such
    cases, the average is calculated based on the elements that fit within the window.
    The resulting array, denoted as *M*, maintains the same dimensions as array *A*.
    When *A* is a one-dimensional vector, `movmean()` processes it along the vector’s
    length. For multidimensional arrays, `movmean()` operates along the first dimension
    of *A* without a size of 1.
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The EMA is a variant of the moving average, placing greater emphasis on recent
    data points. This characteristic renders it more responsive to short-term price
    fluctuations when compared to the SMA. To calculate an EMA, follow these steps:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Choose a specific period, typically represented as *N*.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the multiplier, which is often referred to as the “smoothing factor”
    or “weighting multiplier.” This is usually calculated as *2 / (N +* *1)*.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start with the EMA for the first data point, which is typically the SMA for
    the first *N* data points.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the subsequent data points, calculate the EMA using the following formula:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: EMA(current) = (Price(current) − EMA(previous)) * Multiplier + EMA(previous)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we have the following:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '*EMA(current)* is the EMA for the current data point'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Price(current)* is the price of the asset at the current time'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*EMA(previous)* is the EMA for the previous data point'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Multiplier* is the smoothing factor calculated in *Step 2*'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The EMA assigns more weight to recent data points, and as a result, it reacts
    more quickly to price changes than the SMA. It’s commonly used in technical analysis
    to identify trends and potential reversal points in financial markets, such as
    stocks, currencies, and commodities. Traders and analysts often use different
    EMA periods to analyze short-term and long-term trends.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: MATLAB, for instance, provides functions such as `movavg()` to calculate various
    types of moving averages, including the EMA. You can use this function to compute
    EMAs in MATLAB. Remember that the `movavg()` function requires the use of Financial
    Toolbox.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by defining the type of moving average, after which we define the
    window size and calculate the EMA:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The EMA also calculates an average over a specific time window, but it assigns
    more weight to recent data points. It gives exponentially decreasing weight to
    older data points. The EMA is more responsive to recent changes in the data. It
    reacts quickly to price changes, making it suitable for short-term trend analysis
    and capturing price reversals.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Exponential smoothing
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Exponential smoothing is a time series forecasting method that is used to make
    predictions about future data points based on past observations. It is particularly
    useful for data with a trend or seasonal component. Exponential smoothing assigns
    exponentially decreasing weights to past data points, with the most recent observations
    receiving the highest weights. EMA and exponential smoothing are both techniques
    that are used in time series analysis to capture trends and patterns. However,
    they differ in their formulations and applications. EMA, a subtype of exponential
    smoothing, places higher emphasis on recent data points by assigning them greater
    weight in the calculation. The mathematical expression for the EMA explicitly
    includes a smoothing parameter (alpha), offering a straightforward approach to
    adjusting the impact of recent versus older observations. Conversely, exponential
    smoothing is a broader term that encompasses various smoothing techniques, with
    the EMA being a specific instance. While the EMA requires an initial value for
    the calculation, exponential smoothing, in general, demands an initial value that
    significantly influences the overall smoothing process.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several variations of exponential smoothing, including the following:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '**Simple exponential smoothing** (**SES**): This is used for univariate time
    series data without a trend or seasonality. It uses a single smoothing parameter
    (alpha) to assign weights to past observations. The forecast for the next period
    is a weighted average of the most recent observation and the previous forecast.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Holt’s linear exponential smoothing**: This is used for data with a linear
    trend but no seasonality. It extends SES by introducing two smoothing parameters,
    alpha for the level and beta for the trend. It calculates the level and trend
    separately and uses them to make forecasts.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Holt-Winters exponential smoothing**: This is used for data with both a trend
    and seasonality. It extends Holt’s linear exponential smoothing by adding a third
    smoothing parameter, gamma, for the seasonal component. It models and forecasts
    the level, trend, and seasonal components.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The basic idea behind exponential smoothing is to assign exponentially decreasing
    weights to past observations, giving more importance to recent data, and making
    the method adaptive to changes in the data pattern. Exponential smoothing is widely
    used in time series forecasting applications, such as sales forecasting, demand
    forecasting, and financial market predictions.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Double and triple smoothing are advanced techniques in time series analysis,
    building upon the foundation of exponential smoothing. Double smoothing incorporates
    an additional level of smoothing to address trends, introducing a trend-smoothing
    parameter alongside the data-smoothing parameter. This method enhances the model’s
    ability to capture and forecast trends effectively. Triple smoothing, or the Holt-Winters
    method, goes a step further by incorporating seasonality components. It includes
    parameters for data smoothing, trend smoothing, and seasonality smoothing, making
    it particularly robust for time series data with consistent patterns. These techniques
    provide nuanced tools for capturing and forecasting complex trends and seasonal
    variations.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'In MATLAB, you can implement various types of exponential smoothing using functions
    and libraries related to time series analysis and forecasting. These functions
    often provide tools to estimate the smoothing parameters and make forecasts based
    on your data. Let’s take a closer look:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by defining the smoothing parameter (`alpha`):'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can adjust `alpha` based on our needs (`0` < `alpha` <= `1`). After that,
    we must initialize the forecast with the first data point:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Finally, we must calculate the SES forecast:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we can display the forecasts:'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The `alpha` parameter controls the smoothing level, with lower values making
    the forecast more responsive to recent data and higher values making it smoother.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we analyzed some statistical methods for extracting information
    from a time series. Now, let’s see a practical case in which we predict the performance
    of a company’s shares using recurrent networks.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a model to predict the stock market
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Predicting stock market movements is a complex and challenging endeavor. It
    involves analyzing various factors and data points to forecast the future direction
    of stock prices. Fundamental analysts examine a company’s financial health, including
    its revenue, earnings, debt levels, and growth prospects. They also consider macroeconomic
    factors such as interest rates, inflation, and government policies that can impact
    the overall market. Technical analysts study historical price and volume data,
    looking for patterns and trends in stock charts. They use tools such as moving
    averages, support and resistance levels, and various technical indicators to make
    predictions. Identifying current market trends and understanding market cycles
    can provide insights into potential future movements. Bull markets, bear markets,
    and sideways markets can affect stock prices differently. Predictions are inherently
    uncertain, and risk management is crucial. Diversifying a portfolio, setting stop-loss
    orders, and using proper position sizing can help manage risks associated with
    predictions.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Some traders and investors use machine learning and **artificial intelligence**
    (**AI**) algorithms to analyze vast amounts of data and identify potential patterns
    or trends in the market. Stock market predictions can range from short-term (days
    or weeks) to long-term (years). The chosen will depend on the investment strategy
    and goals. It’s important to remember that past stock market performance is not
    a guarantee of future results. Market conditions can change rapidly and unpredictably.
    Stock market predictions involve a combination of financial analysis, technical
    analysis, sentiment analysis, and consideration of various external factors. While
    some investors and traders may use predictions as part of their decision-making
    process, it’s essential to approach them with caution and maintain a diversified
    portfolio to manage risk effectively.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will delve into the application of the **L****ong short-term
    memory** (**LSTM**) model for forecasting the future stock price of a highly renowned
    corporation: Tesla Inc. This is an American **electric** **vehicle** (**EV**)
    and clean energy company founded in 2003 by Elon Musk, JB Straubel, Martin Eberhard,
    Marc Tarpenning, and Ian Wright. It is headquartered in Palo Alto, California.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate Tesla’s stock price performance, we will utilize data encompassing
    the stock prices from November 6, 2010, to October 5, 2023, sourced from the NASDAQ
    GS stock quotes. It is also possible to adjust the timeframe if needed, beyond
    the default interval provided.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'The data was acquired from the Yahoo! Finance website: [https://finance.yahoo.com/quote/TSLA](https://finance.yahoo.com/quote/TSLA).'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 9**.2* shows a screenshot of the Yahoo! Finance website:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – The Yahoo! Finance website](img/B21156_09_02.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – The Yahoo! Finance website
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: 'This CSV file includes the following attributes:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '**Date**: Date of quote'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Open**: Open price'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High**: High price'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Low**: Low price'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Close**: Close price adjusted for splits'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adj Close**: Close price adjusted for both dividends and splits'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Volume**: Exchange volume'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The information within the CSV file is labeled as `TSLA.csv`. To start, let’s
    investigate the process of importing this data into the MATLAB workspace:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'We will import the data in timetable format using the following command:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As always, we should be in the folder containing the `TSLA.csv` file or add
    this folder to the MATLAB path.
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Before embarking on data prediction using the LSTM method, we will commence
    with an exploratory analysis to glean insights into the data distribution and
    extract preliminary knowledge. To glean preliminary insights from the imported
    dataset, we can utilize the `summary()` function:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following results are printed:'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: A summary of the data was returned with some statistics on all the variables
    in the dataset. For example, we can read the number of records (`157`) and the
    min, median, and max values of all variables. Based on the preliminary analysis
    of the results, it is evident that Tesla’s stock prices have undergone a significant
    transformation over the past 13 years. Specifically, the minimum value stands
    at $1.5927, while the maximum value reaches $381.59.
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Upon reviewing the dataset’s content, our next step involves conducting an
    initial visual exploratory analysis, wherein we will generate a graphical representation
    of the stock prices over the years:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The following chart will be drawn (*Figure 9**.3*):'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Stock prices of Tesla Inc. from 2010 to 2023](img/B21156_09_03.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Stock prices of Tesla Inc. from 2010 to 2023
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Examining the preceding graph reveals a substantial increase in prices over
    time. Commencing in 2020, this upsurge follows an exponential trend. Let’s delve
    deeper into understanding the fluctuations that the Tesla stock has documented
    over time.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the evolution of a phenomenon becomes intriguing not only by examining
    its time series graph but also by drawing comparisons between the intensity of
    the phenomenon at distinct time points. This involves calculating variations in
    intensity from one period to another. Additionally, analyzing the trend of changes
    in the phenomenon between contiguous periods can offer valuable insights.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We represent a time series as *Y1*, ..., *Yt*, ..., *Yn*. As explained in the
    *Time series analysis* section, a time series reflects the chronological recording
    of experimental observations of a variable. This variable can encompass various
    elements, such as price trends, stock market indices, spreads, and unemployment
    rates. Essentially, it functions as a sequence of time-ordered data points from
    which we endeavor to extract insights for characterizing the observed phenomenon
    and predicting future values.
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To measure the variation between two distinct time points (referred to as *t*
    and *t + 1*), we can compute the following ratio:'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Y t+1 − Y t _ Y t
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This index, commonly known as “percentage change,” represents a percentage ratio.
    It specifically denotes the percentage rate of variation in the phenomenon, *Y*,
    at time *t + 1* compared to the preceding time, *t*. Utilizing the percentage
    change method provides a more accurate depiction of how data has evolved over
    a specified timeframe.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This approach is applied not only in monitoring the prices of individual securities
    and major market indices but also in comparing the values of various currencies.
    When preparing balance sheets with comparative financial statements, it is typical
    to include specific asset prices at different time junctures, accompanied by the
    corresponding percentage changes during those periods.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To calculate percentage changes in MATLAB, we can use the following code:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The `diff()` function computes the differences between consecutive elements
    of an array along the first dimension where the size of that dimension is not
    equal to 1.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can plot the results obtained as a bar plot to see how the differences are
    distributed on the time:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '*Figure 9**.4* shows the bar plot of percentage changes over the years:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Percentage changes over the years](img/B21156_09_04.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Percentage changes over the years
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Percentage changes in the stock market play a crucial role in providing valuable
    insights and serving various functions. For example, percentage changes allow
    investors and analysts to measure the performance of individual stocks, portfolios,
    or entire market indices over specific periods. This helps in assessing whether
    investments have grown or declined in value. Understanding percentage changes
    helps investors gauge the volatility and risk associated with a particular stock
    or asset. Stocks with larger percentage fluctuations are generally considered
    riskier investments.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: After calculating the percentage changes, we can move on to the return concept;
    return refers to the profit or loss that an investor realizes from their investments
    in stocks. Returns are typically expressed as a percentage and represent the change
    in the value of an investment over a specific period.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculating the return from stock prices in MATLAB involves taking the percentage
    change in prices over a specific period. We have just loaded stock price data
    into MATLAB as a matrix. We checked that the data was organized with prices in
    chronological order. After that, we calculated the percentage change in stock
    prices from one period to the next. Now, we can calculate various types of returns,
    such as price return (capital gain) or total return (including income). For price
    return, simply sum the percentage changes, as follows:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The following result is obtained:'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This is a great return from the Tesla stock market that’s excellent for those
    who have held stocks for the last three years.
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Our goal is to leverage the data within this dataset to forecast the Tesla
    stock price based on the information provided in the `.csv` file. To train the
    network, we require both input and output data. The input is defined by the data
    contained within the dataset. Consequently, we must generate our output. We will
    achieve this by assuming our objective is to forecast the Tesla stock price at
    time *t + 1* based on the information available at time *t*. As a result, we will
    establish the following formula:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Input = TeslaData . Close(t)
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Output = TeslaData . Close(t + 1)
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is a sequence-to-sequence regression problem, such as a deep learning approach
    where the goal is to predict a sequence of continuous values as an output, given
    a sequence of input data. It is commonly used for tasks such as time series forecasting,
    natural language processing, and any other problem where the output is a sequence
    of numerical values. In this context, the model learns to map an input sequence
    to an output sequence, and the length of the input and output sequences can vary.
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A recurrent network possesses memory, and this memory is preserved by defining
    the time step. The time step determines how many steps into the past backpropagation
    are considered when computing gradients for weight updates during training. In
    this context, we establish *TimeStep = 1*. Let’s prepare the data based on this
    assumption:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Within this code, `XData` represents the input variable, equivalent to data
    at time *t*, while `YData` signifies the output value for the subsequent period,
    namely data at time *t +* *1*.
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To address this type of problem, we can use an LSTM network. LSTM is a type
    of **recurrent neural network** (**RNN**) architecture that’s designed to address
    the vanishing gradient problem that can occur when training traditional RNNs.
    LSTM models are especially effective for processing and making predictions on
    sequences of data. They are built around the concept of memory cells, which can
    store information over long sequences. These memory cells possess the capability
    to learn and remember patterns, rendering them well suited for tasks involving
    sequential data. Such tasks include time series analysis, natural language processing,
    and speech recognition.
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The ideal lag value should be chosen based on the autocorrelation plot together
    with domain knowledge. To evaluate the performance of an LSTM model, long sequences
    (more lags) should be considered. Even an auto-regressive model would perform
    well for *lag=1*.
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'LSTM models have three fundamental gates that control the flow of information
    within the network:'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Forget gate**: This is responsible for deciding which information from the
    previous cell state should be either forgotten or retained'
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Input gate**: This determines which new information should be stored in the
    cell state'
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output gate**: This regulates the information to be output from the cell
    state'
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The cell state runs horizontally across the top of the LSTM and acts as a conveyor
    belt, allowing information to flow from one time step to another. The gates help
    regulate the flow of information into and out of the cell state.
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We start by setting some parameters:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'After that, we have to build the architecture of the deep network:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Six layers were used:'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`sequenceInputLayer`: A sequence input layer receives sequential data and performs
    data normalization before feeding it into a neural network.'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lstmLayer`: An LSTM layer, as part of an RNN, specializes in capturing long-term
    dependencies within time series and sequential data. This layer facilitates additive
    interactions, contributing to enhanced gradient flow over extended sequences during
    the training process. Two parameters were passed: the number of hidden units and
    the output mode as a sequence. One argument was supplied: the quantity of hidden
    units, also referred to as the hidden size, denoted as a positive integer. This
    parameter determines the volume of information retained by the layer across time
    steps, encapsulated in the hidden state. The hidden state can encompass data from
    all preceding time steps, irrespective of the sequence length. Oversizing the
    number of hidden units may lead to overfitting the training data. Additionally,
    the output mode is specified with one of two values: `sequence`, which produces
    the entire sequence as output, and `last`, which generates output for the last
    time step of the sequence.'
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fullyConnectedLayer`: A fully connected layer multiplies the input with a
    weight matrix and subsequently incorporates a bias vector.'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dropoutLayer`: This is used for regularization during training. It helps prevent
    overfitting by randomly setting a fraction of the input units to 0 during each
    forward and backward pass. This encourages the network to learn more robust and
    generalized features.'
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fullyConnectedLayer`: The last fully connected layer is often used for making
    predictions based on the features learned by the preceding layers in the network.'
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`regressionLayer`: This is a layer that’s used in deep learning for regression
    tasks. Regression tasks involve predicting continuous numerical values, as opposed
    to classification tasks, which involve predicting categories or classes. `regressionLayer`
    is specifically designed for regression problems, and it is commonly used in neural
    networks for tasks such as predicting stock prices, house prices, temperature
    forecasting, and various other numerical predictions. `regressionLayer` is responsible
    for calculating the loss between the predicted values generated by the neural
    network and the actual target values during training. It employs a loss function
    to gauge the dissimilarity between the predicted values and the ground truth values.
    Common loss functions employed in regression tasks encompass **mean squared error**
    (**MSE**), **mean absolute error** (**MAE**), and Huber loss, among others.'
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After that, we have to specify the training options:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'As the optimization algorithm, we set the Adam optimizer, a popular optimization
    algorithm used in training deep neural networks. It is known for its ability to
    efficiently handle non-stationary objectives, high-dimensional parameter spaces,
    and noisy gradient information. Adam combines the benefits of both the RMSprop
    optimizer and momentum-based methods. We also set the number of training epochs:
    an epoch is one complete pass through the entire training dataset. Training may
    stop early based on validation performance to avoid overfitting. We set an appropriate
    learning rate for the optimizer. You may need to experiment with different learning
    rates to find the one that works best for your problem.'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we can train the network:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The following results are printed (*Figure 9**.5*):'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.5 – LSTM training process](img/B21156_09_05.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – LSTM training process
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can use the network to predict the performance of stocks. Each value
    will be predicted starting from the previous one with a time step equal to 1:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The `predict()` function forecasts outcomes by employing a well-trained deep
    learning neural network. To evaluate the performance of the prediction, we can
    use **root mean square error** (**RMSE**), which is calculated as follows:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: RMSE is a widely utilized metric in statistics and machine learning for quantifying
    the average magnitude of errors or differences between predicted and actual values.
    It calculates the square root of the mean of the squared differences between predicted
    values and true values. RMSE serves as a means to evaluate the accuracy of a predictive
    model or the quality of predictions.
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following value is returned:'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'To appreciate the prediction capacity of the model based on LSTMs, let’s draw
    a graph of the performance of the Tesla stock and compare it with that predicted
    by our model:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The following graph is printed (*Figure 9**.6*):'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.6 – Actual values versus predicted values](img/B21156_09_06.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – Actual values versus predicted values
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: We can appreciate the goodness of the forecast in periods in which the situation
    does not undergo major variations. On the contrary, a certain deviation is noted
    in correspondence with the periods of greatest fluctuation of the security, demonstrating
    that it is necessary to consider further information for a correct prediction.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s see what we can do when we must work with unbalanced data.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with imbalanced datasets in MATLAB
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dealing with imbalanced datasets is a common challenge in machine learning,
    particularly in classification tasks where one class significantly outnumbers
    the other(s). Handling imbalanced datasets is crucial because models trained on
    such data may exhibit bias toward the majority class and perform poorly in predicting
    the minority class.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Understanding oversampling
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Oversampling is a method that’s employed to tackle class imbalance in a dataset
    by augmenting the number of instances belonging to the minority class. The aim
    is to balance the class distribution and prevent machine learning models from
    being biased toward the majority class. Oversampling is particularly useful when
    you have limited data for the minority class. There are several methods for oversampling,
    including the following:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '**Random oversampling**: In random oversampling, you randomly select and duplicate
    instances from the minority class until the class distribution is balanced. This
    method is straightforward but may lead to overfitting as it introduces duplicate
    data points.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synthetic Minority Over-sampling Technique** (**SMOTE**): SMOTE is a popular
    oversampling method that creates synthetic samples for the minority class. It
    works by selecting a minority class instance and its *k* nearest neighbors. Then,
    it generates synthetic data points along the line segments connecting the chosen
    instance and its neighbors. SMOTE helps to prevent overfitting and can be more
    effective than random oversampling.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adaptive Synthetic Sampling** (**ADASYN**): ADASYN is an extension of SMOTE
    that’s designed to generate additional synthetic samples for minority class instances
    that pose greater difficulty in classification. It considers the distribution
    of the data and assigns different weights to different instances.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Borderline-SMOTE**: Borderline-SMOTE is a variation of SMOTE that specifically
    targets instances near the borderline between the minority and majority classes.
    It generates synthetic samples for these borderline instances to improve classification
    performance.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Minority Synthetic Over-sampling Technique** (**MSMOTE**): MSMOTE is an extension
    of SMOTE that takes into account the density of minority class instances. It generates
    synthetic samples based on the local density of the data points.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random oversampling with noise**: This technique involves adding a small
    amount of random noise to the duplicated instances during random oversampling.
    This helps to reduce overfitting.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Informed oversampling**: Informed oversampling methods consider domain knowledge
    or specific characteristics of the data to guide the generation of synthetic samples.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The choice of oversampling method depends on the characteristics of your dataset
    and the problem you are trying to solve. Experimenting with different techniques
    and evaluating the impact on model performance using appropriate metrics (for
    example, F1 score, precision-recall curves, and so on) is often necessary to determine
    the most effective oversampling strategy for your specific use case. It’s important
    to note that oversampling may not always be the best solution, and you should
    also consider other techniques, such as undersampling, cost-sensitive learning,
    and ensemble methods, to address class imbalance effectively.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Exploring undersampling
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Undersampling is a technique that’s used to address class imbalance in a dataset
    by reducing the number of instances in the majority class. The goal is to create
    a more balanced class distribution, which can help machine learning models avoid
    bias toward the majority class. Undersampling can be a useful approach when you
    have a large amount of data in the majority class and want to avoid the potential
    issues of overfitting that may arise with oversampling the minority class. Here
    are some key points to consider when exploring undersampling:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '**Random undersampling**: In random undersampling, you randomly select and
    remove instances from the majority class until the class distribution is balanced.
    This method is simple but may lead to the loss of valuable data.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster-centroid undersampling**: Cluster-centroid undersampling involves
    clustering the majority class instances and selecting a representative centroid
    from each cluster to form a smaller dataset. This method retains diversity within
    the majority class and is less likely to remove informative data.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tomek links**: Tomek links are pairs of instances from different classes
    that are close to each other but classified incorrectly. Removing the majority
    class instance of a Tomek link can help improve the boundary between classes.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Edited nearest neighbors** (**ENN**): ENN identifies and removes instances
    from the majority class that do not agree with their neighbors in terms of class
    labels. ENN can help in reducing noisy samples in the majority class.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**One-sided selection**: One-sided selection combines both Tomek links and
    ENN. It uses Tomek links to identify problematic instances and then uses ENN to
    remove them.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NearMiss undersampling**: This method selects the majority class instances
    that are closest to minority class instances based on distance metrics. NearMiss
    algorithms ensure that the selected majority class instances are close to the
    minority class, thus helping in improving class separation.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Informed undersampling**: Informed undersampling methods consider domain
    knowledge or specific characteristics of the data to guide the selection of instances
    from the majority class.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When exploring undersampling, it’s important to consider various aspects. First,
    choose the undersampling method that is most appropriate for your dataset. The
    method you choose should depend on the nature of your data, the problem you are
    trying to solve, and the potential impact on model performance. Also, undersampling
    may lead to a loss of information, especially if the majority class contains important
    data points. Be cautious when applying this technique, and consider whether you
    can obtain more data for the minority class or explore other methods such as oversampling,
    cost-sensitive learning, or ensemble methods. Remember to evaluate your model’s
    performance using appropriate metrics, and experiment with different approaches
    to find the best solution for your specific use case. For instance, suppose you
    have a dataset with 10,000 credit card transactions, out of which only 100 are
    fraudulent. In this case, you might undersample the non-fraudulent transactions
    to create a more balanced dataset. You could randomly select, say, 500 non-fraudulent
    transactions, resulting in a new dataset with 500 non-fraudulent and 100 fraudulent
    transactions.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Discovering cost-sensitive learning
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cost-sensitive learning is a machine learning approach that considers the varying
    costs of misclassifying different classes in a classification problem. In traditional
    machine learning, all misclassifications are treated equally. However, in many
    real-world applications, misclassifying one class may have more severe consequences
    or higher associated costs than misclassifying another class. Cost-sensitive learning
    aims to optimize the model to minimize these specific costs.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: Cost-sensitive learning is related to but different from handling class imbalance.
    While class imbalance focuses on the unequal distribution of classes, cost-sensitive
    learning considers the associated costs of misclassification. Cost-sensitive learning
    often involves the use of cost matrices, which specify the costs of different
    types of misclassifications. These matrices assign different costs for false positives,
    false negatives, true positives, and true negatives.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: In cost-sensitive learning, the decision threshold for classification can be
    adjusted to minimize the expected cost. This means that the model might be more
    or less conservative in its predictions, depending on the cost matrix. Various
    machine learning algorithms can be adapted to handle cost-sensitive learning.
    Some algorithms allow you to specify class-specific misclassification costs. For
    example, in decision trees or ensemble methods, you can assign weights to classes
    based on their costs.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: When working with cost-sensitive learning, it’s important to consider evaluation
    metrics that reflect the cost-effectiveness of the model, such as the weighted
    F1 score or cost-sensitive versions of precision and recall. Cost-sensitive learning
    is often applied to anomaly detection problems. In such cases, you want to detect
    rare and potentially costly events, such as fraud detection in financial transactions.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that cost-sensitive learning involves trade-offs. Reducing the
    cost of one type of error may increase the cost of another. Careful consideration
    and domain knowledge are required when designing the cost matrix. Cost-sensitive
    learning is a valuable approach in situations where misclassification costs are
    not uniform, and it can help optimize machine learning models for specific real-world
    applications. It’s an essential technique for decision-making systems where the
    consequences of different errors can be significantly different.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored several key concepts in the field of data analysis
    and predictive modeling. We started by discussing the basics of time series data,
    which refers to data that is collected over a certain period and contains a sequential
    order. The extraction of statistics from such sequential data is then highlighted
    as an important step in analyzing and understanding patterns within the data.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: This chapter also emphasized the implementation of a model to predict stock
    market data. This involves using various techniques and algorithms to analyze
    historical stock market data, identify patterns and trends, and make predictions
    about future stock prices.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, this chapter addressed the challenge of dealing with imbalanced datasets
    in MATLAB. An imbalanced dataset refers to a situation where the distribution
    of classes within the dataset is significantly skewed, making it difficult to
    train a model accurately. We discussed methods and strategies to handle imbalanced
    datasets within the MATLAB programming environment.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Overall, this chapter focused on the importance of understanding and analyzing
    time series data, extracting meaningful statistics, implementing predictive models
    for stock market data, and addressing the challenges of imbalanced datasets in
    MATLAB.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will understand the basic concepts of recommender systems,
    how to identify similar users in a dataset, and how to implement a practical case
    of recommender systems using MATLAB. Finally, we will understand model compression,
    pruning, and quantization for efficient inference on edge devices.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
