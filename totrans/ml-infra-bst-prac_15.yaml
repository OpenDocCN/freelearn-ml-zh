- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Designing Machine Learning Pipelines (MLOps) and Their Testing
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计机器学习流水线（MLOps）及其测试
- en: MLOps, short for machine learning (ML) operations, is a set of practices and
    techniques aimed at streamlining the deployment, management, and monitoring of
    ML models in production environments. It borrows concepts from the DevOps (development
    and operations) approach, adapting them to the unique challenges posed by ML.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps，即机器学习（ML）运维，是一套旨在简化机器学习模型在生产环境中部署、管理和监控的实践和技术。它借鉴了DevOps（开发和运维）方法的概念，将其适应机器学习所面临的独特挑战。
- en: The main goal of MLOps is to bridge the gap between data science and operations
    teams, fostering collaboration and ensuring that ML projects can be effectively
    and reliably deployed at scale. MLOps helps to automate and optimize the entire
    ML life cycle, from model development to deployment and maintenance, thus improving
    the efficiency and effectiveness of ML systems in production.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps的主要目标是弥合数据科学团队和运维团队之间的差距，促进协作，并确保机器学习项目能够有效地和可靠地在规模上部署。MLOps有助于自动化和优化整个机器学习生命周期，从模型开发到部署和维护，从而提高生产中机器学习系统的效率和效果。
- en: In this chapter, we learn how ML systems are designed and operated in practice.
    The chapter shows how pipelines are turned into a software system, with a focus
    on testing ML pipelines and their deployment at Hugging Face.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习如何在实践中设计和操作机器学习系统。本章展示了如何将流水线转化为软件系统，重点关注在Hugging Face上测试机器学习流水线和它们的部署。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下主要主题：
- en: What ML pipelines are
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是机器学习流水线
- en: ML pipelines – how to use ML in the system in practice
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习流水线 – 如何在实际系统中使用机器学习
- en: Raw data-based pipelines
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于原始数据的流水线
- en: Feature-based pipelines
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于特征的流水线
- en: Testing of ML pipelines
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习流水线的测试
- en: Monitoring ML systems at runtime
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控运行时的机器学习系统
- en: What ML pipelines are
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习流水线
- en: Undoubtedly, in recent years, the field of ML has witnessed remarkable advancements,
    revolutionizing industries and empowering innovative applications. As the demand
    for more sophisticated and accurate models grows, so does the complexity of developing
    and deploying them effectively. The industrial introduction of ML systems called
    for more rigorous testing and validation of these ML-based systems. In response
    to these challenges, the concept of ML pipelines has emerged as a crucial framework
    to streamline the entire ML development process, from data preprocessing and feature
    engineering to model training and deployment. This chapter explores the applications
    of MLOps in the context of both cutting-edge **deep learning** (**DL**) models
    such as **Generative Pre-trained Transformer** (**GPT**) and traditional classical
    ML models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，在过去的几年里，机器学习领域取得了显著的进步，颠覆了行业并赋予了创新应用以力量。随着对更复杂和精确的模型的需求增长，开发和有效部署它们的复杂性也在增加。机器学习系统的工业应用需要对这些基于机器学习的系统进行更严格测试和验证。为了应对这些挑战，机器学习流水线的概念应运而生，成为简化整个机器学习开发过程的关键框架，从数据预处理和特征工程到模型训练和部署。本章探讨了MLOps在尖端**深度学习**（**DL**）模型如**生成预训练转换器**（**GPT**）和传统经典机器学习模型中的应用。
- en: We begin by exploring the underlying concepts of ML pipelines, stressing their
    importance in organizing the ML workflow and promoting collaboration between data
    scientists and engineers. We synthesize a lot of knowledge presented in the previous
    chapters – data quality assessment, model inference, and monitoring.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先探讨机器学习流水线的潜在概念，强调其在组织机器学习工作流程和促进数据科学家与工程师之间协作的重要性。我们综合了前几章中提出的许多知识——数据质量评估、模型推理和监控。
- en: Next, we discuss the unique characteristics and considerations involved in building
    pipelines for GPT models and similar, leveraging their pre-trained nature to tackle
    a wide range of language tasks. We explore the intricacies of fine-tuning GPT
    models on domain-specific data and the challenges of incorporating them into production
    systems.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论构建GPT模型及其类似模型的流水线的独特特性和考虑因素，利用它们的预训练特性来处理广泛的语言任务。我们探讨了在特定领域数据上微调GPT模型的复杂性以及将它们纳入生产系统的挑战。
- en: Following the exploration of GPT pipelines, we shift our focus to classical
    ML models, examining the feature engineering process and its role in extracting
    relevant information from raw data. We delve into the diverse landscape of traditional
    ML algorithms, understanding when to use each approach, and their trade-offs in
    different scenarios.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索了GPT管道之后，我们将注意力转向经典机器学习模型，检查特征工程过程及其在从原始数据中提取相关信息中的作用。我们深入研究传统机器学习算法的多样化领域，了解何时使用每种方法，以及在不同场景中的权衡。
- en: Finally, we show how to test ML pipelines, and we emphasize the significance
    of model evaluation and validation in assessing performance and ensuring robustness
    in production environments. Additionally, we examine strategies for model monitoring
    and maintenance, safeguarding against concept drift and guaranteeing continuous
    performance improvement.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们展示了如何测试机器学习管道，并强调模型评估和验证在评估性能和确保生产环境中的鲁棒性方面的重要性。此外，我们探讨了模型监控和维护的策略，以防止概念漂移并保证持续的性能改进。
- en: ML pipelines
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习管道
- en: An ML pipeline is a systematic and automated process that organizes the various
    stages of an ML workflow. It encompasses the steps involved in preparing data,
    training an ML model, evaluating its performance, and deploying it for use in
    real-world applications. The primary goal of an ML pipeline is to streamline the
    end-to-end ML process, making it more efficient, reproducible, and scalable.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）管道是一个系统化和自动化的过程，它组织了机器学习工作流程的各个阶段。它包括准备数据、训练机器学习模型、评估其性能以及将其部署到实际应用中的步骤。机器学习管道的主要目标是简化端到端的机器学习过程，使其更加高效、可重复和可扩展。
- en: 'An ML pipeline typically consists of the following essential components:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道通常包括以下基本组件：
- en: '**Data collection, preprocessing, and wrangling**: In this initial stage, relevant
    data is gathered from various sources and prepared for model training. Data preprocessing
    involves cleaning, transforming, and normalizing the data to ensure it is in a
    suitable format for the ML algorithm.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集、预处理和整理**：在这个初始阶段，从各种来源收集相关数据，并准备用于模型训练。数据预处理涉及清理、转换和归一化数据，以确保数据适合机器学习算法。'
- en: '**Feature engineering and selection**: Feature engineering involves selecting
    and creating relevant features (input variables) from the raw data that will help
    the model learn patterns and make accurate predictions. Proper feature selection
    is crucial in improving model performance and reducing computational overhead.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程和选择**：特征工程涉及从原始数据中选择和创建有助于模型学习模式和做出准确预测的相关特征（输入变量）。适当的特征选择对于提高模型性能和减少计算开销至关重要。'
- en: '**Model selection and training**: In this stage, one or more ML algorithms
    are chosen, and the model is trained on the prepared data. Model training involves
    learning underlying patterns and relationships in the data to make predictions
    or classifications.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型选择和训练**：在这个阶段，选择一个或多个机器学习算法，并在准备好的数据上训练模型。模型训练涉及学习数据中的潜在模式和关系，以进行预测或分类。'
- en: '**Model evaluation and validation**: The trained model is evaluated using metrics
    such as accuracy, precision, recall, F1-score, and so on, to assess its performance
    on unseen data. Cross-validation techniques are often used to ensure the model’s
    generalization capability.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型评估和验证**：使用准确率、精确率、召回率、F1分数等指标来评估训练好的模型在未见数据上的性能。通常使用交叉验证技术来确保模型的一般化能力。'
- en: '**Hyperparameter tuning**: Many ML algorithms have hyperparameters, which are
    adjustable parameters that control the model’s behavior. Hyperparameter tuning
    involves finding the optimal values for these parameters to improve the model’s
    performance.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超参数调整**：许多机器学习算法都有超参数，这些是可以调整的参数，控制模型的行为。超参数调整涉及找到这些参数的最佳值，以提高模型性能。'
- en: '**Model deployment**: Once the model has been trained and validated, it is
    deployed into a production environment, where it can make predictions on new,
    unseen data. Model deployment may involve integrating the model into existing
    applications or systems.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署**：一旦模型经过训练和验证，它就会被部署到生产环境中，在那里它可以在新的、未见过的数据上进行预测。模型部署可能涉及将模型集成到现有的应用程序或系统中。'
- en: '**Model monitoring and maintenance**: After deployment, the model’s performance
    is continuously monitored to detect any issues or drift in performance. Regular
    maintenance may involve retraining the model with new data to ensure it remains
    accurate and up to date.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型监控和维护**：部署后，持续监控模型的性能，以检测任何性能问题或漂移。定期的维护可能包括使用新数据重新训练模型，以确保其保持准确性和时效性。'
- en: 'An ML pipeline provides a structured framework for managing the complexity
    of ML projects, enabling data scientists and engineers to collaborate more effectively
    and ensuring that models can be developed and deployed reliably and efficiently.
    It promotes reproducibility, scalability, and ease of experimentation, facilitating
    the development of high-quality ML solutions. *Figure 12**.1* shows a conceptual
    model of an ML pipeline, which we introduced in [*Chapter 2*](B19548_02.xhtml#_idTextAnchor023):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道为管理机器学习项目的复杂性提供了一个结构化框架，使数据科学家和工程师能够更有效地协作，并确保模型可以可靠且高效地开发和部署。它促进了可重复性、可扩展性和实验的简便性，促进了高质量机器学习解决方案的开发。*图12*.*1*展示了机器学习管道的概念模型，我们在[*第2章*](B19548_02.xhtml#_idTextAnchor023)中介绍了它。
- en: '![Figure 12.1 – ML pipeline: a conceptual overview](img/B19548_12_1.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图12.1 – 机器学习管道：概念概述](img/B19548_12_1.jpg)'
- en: 'Figure 12.1 – ML pipeline: a conceptual overview'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 – 机器学习管道：概念概述
- en: We covered the elements of the blue-shaded elements in the previous chapters,
    and here, we focus mostly on the parts that are not covered yet. However, before
    we dive into the technical elements of this pipeline, let us introduce the concept
    of MLOps.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在之前的章节中介绍了蓝色阴影元素的要素，在这里，我们主要关注尚未涉及的部分。然而，在我们深入探讨这个管道的技术要素之前，让我们先介绍MLOps的概念。
- en: Elements of MLOps
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps的要素
- en: As the main goal of MLOps is to bridge the gap between data science and operations
    teams, MLOps automates and optimizes the entire ML life cycle, from model development
    to deployment and maintenance, thus improving the efficiency and effectiveness
    of ML systems in production.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps的主要目标是弥合数据科学和运维团队之间的差距，因此MLOps自动化并优化了整个机器学习生命周期，从模型开发到部署和维护，从而提高了生产中机器学习系统的效率和效果。
- en: 'Key components and practices in MLOps include:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps中的关键组件和实践包括：
- en: '**Version control**: Applying **version control systems** (**VCSs**) such as
    Git to manage and track changes in ML code, datasets, and model versions. This
    enables easy collaboration, reproducibility, and tracking of model improvements.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本控制**：应用**版本控制系统**（VCSs）如Git来管理和跟踪机器学习代码、数据集和模型版本的变更。这使协作、可重复性和模型改进的跟踪变得容易。'
- en: '**Continuous integration and continuous deployment (CI/CD)**: Leveraging CI/CD
    pipelines to automate the testing, integration, and deployment of ML models. This
    helps ensure that changes to the code base are seamlessly deployed to production
    while maintaining high-quality standards.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续集成和持续部署（CI/CD）**：利用CI/CD管道来自动化机器学习模型的测试、集成和部署。这有助于确保代码库的更改能够无缝部署到生产中，同时保持高质量标准。'
- en: '**Model packaging**: Creating standardized, reproducible, and shareable containers
    or packages for ML models, making it easier to deploy them across different environments
    consistently.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型打包**：为机器学习模型创建标准化的、可重复的、可共享的容器或包，使其在不同环境中一致部署变得更容易。'
- en: '**Model monitoring**: Implementing monitoring and logging solutions to keep
    track of the model’s performance and behavior in real time. This helps detect
    issues early and ensure the model’s ongoing reliability.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型监控**：实施监控和日志记录解决方案，以实时跟踪模型的性能和行为。这有助于早期发现问题并确保模型的持续可靠性。'
- en: '**Scalability and infrastructure management**: Designing and managing the underlying
    infrastructure to support the demands of the ML models in production, ensuring
    they can handle increased workloads and scale efficiently.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性和基础设施管理**：设计和管理底层基础设施以支持生产中机器学习模型的需求，确保它们能够处理增加的工作负载并高效扩展。'
- en: '**Model governance and compliance**: Implementing processes and tools to ensure
    compliance with legal and ethical requirements, privacy regulations, and company
    policies when deploying and using ML models.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型治理和合规性**：实施流程和工具以确保在部署和使用机器学习模型时符合法律和伦理要求、隐私法规和公司政策。'
- en: '**Collaboration and communication**: Facilitating effective communication and
    collaboration between data scientists, engineers, and other stakeholders involved
    in the ML deployment process.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协作与沟通**：促进数据科学家、工程师以及其他参与ML部署流程的利益相关者之间的有效沟通和协作。'
- en: By adopting MLOps principles, organizations can accelerate the development and
    deployment of ML models while maintaining their reliability and effectiveness
    in real-world applications. It also helps reduce the risk of deployment failures
    and promotes a culture of collaboration and continuous improvement within data
    science and operations teams.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 通过采用MLOps原则，组织可以在保持模型在实际应用中的可靠性和有效性的同时，加速ML模型的开发和部署。这也有助于降低部署失败的风险，并在数据科学和运营团队中促进协作和持续改进的文化。
- en: ML pipelines – how to use ML in the system in practice
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML管道 – 如何在实际系统中使用ML
- en: Training and validating ML models on a local platform is the beginning of the
    process of using an ML pipeline. After all, it would be of limited use if we had
    to retrain the ML models on every computer from our customers.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地平台上训练和验证ML模型是使用ML管道的过程的开始。毕竟，如果我们不得不在客户的每一台计算机上重新训练ML模型，那么这将非常有限。
- en: Therefore, we often deploy ML models to a model repository. There are a few
    popular ones, but the one that is used by the largest community is the HuggingFace
    repository. In that repository, we can deploy both the models and datasets and
    even create spaces where the models can be used for experiments without the need
    to download them. Let us deploy the model trained in [*Chapter 11*](B19548_11.xhtml#_idTextAnchor132)
    to that repository. For that, we need to have an account at huggingface.com, and
    then we can start.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们通常将ML模型部署到模型仓库中。有几个流行的仓库，但使用最大社区的是HuggingFace仓库。在那个仓库中，我们可以部署模型和数据集，甚至创建模型可以用于实验的空间，而无需下载它们。让我们将训练好的模型部署到[*第11章*](B19548_11.xhtml#_idTextAnchor132)中的那个仓库。为此，我们需要在huggingface.com上有一个账户，然后我们就可以开始了。
- en: Deploying models to HuggingFace
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将模型部署到HuggingFace
- en: 'First, we need to create a new model using the **New** button on the main page,
    as in *Figure 12**.2*:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要使用主页上的**新建**按钮创建一个新的模型，如图*图12.2*所示：
- en: '![Figure 12.2 – New button to create a model](img/B19548_12_2.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图12.2 – 创建模型的新按钮](img/B19548_12_2.jpg)'
- en: Figure 12.2 – New button to create a model
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 – 创建模型的新按钮
- en: 'Then, we fill in information about our model to create space for it. *Figure
    12**.3* presents a screenshot of this process. In the form, we fill in the name
    of the model, whether it should be private or public, and we choose a license
    for it. In this example, we go with the MIT License, which is very permissive
    and allows everyone to use, reuse, and redistribute the model as long as they
    include the MIT License text along with it:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们填写有关我们模型的信息，为其创建空间。*图12.3*展示了这个过程的一个截图。在表单中，我们填写模型的名称、是否为私有或公共，并为它选择一个许可证。在这个例子中，我们选择了MIT许可证，这是一个非常宽松的许可证，允许每个人只要包含MIT许可证文本，就可以使用、重新使用和重新分发模型：
- en: '![Figure 12.3 – Model metadata card](img/B19548_12_3.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图12.3 – 模型元数据卡片](img/B19548_12_3.jpg)'
- en: Figure 12.3 – Model metadata card
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 – 模型元数据卡片
- en: 'Once the model has been created, we get a space where we can start deploying
    the model. The empty space looks like the one in *Figure 12**.4*:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型创建完成，我们就可以开始部署模型了。空余空间看起来就像*图12.4*中的那样：
- en: '![Figure 12.4 – Empty model space](img/B19548_12_4.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图12.4 – 空余模型空间](img/B19548_12_4.jpg)'
- en: Figure 12.4 – Empty model space
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 – 空余模型空间
- en: 'The top menu contains four options, but the first two are the most important
    ones – **Model card** and **Files and versions**. The model card is a short description
    of the model. It can contain any kind of information, but the most common information
    is how to use the model. We follow this convention and prepare the model card
    as shown in *Figure 12**.5*:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 顶部菜单包含四个选项，但前两个是最重要的 – **模型卡片**和**文件和版本**。模型卡片是对模型的简要描述。它可以包含任何类型的信息，但最常见的信息是模型的使用方法。我们遵循这个惯例，并按照*图12.5*所示准备模型卡片：
- en: '![Figure 12.5 – The beginning of the model card for our wolfBERTa model](img/B19548_12_5.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图12.5 – 我们wolfBERTa模型卡片的开头](img/B19548_12_5.jpg)'
- en: Figure 12.5 – The beginning of the model card for our wolfBERTa model
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 – 我们wolfBERTa模型卡片的开头
- en: 'Best practice #60'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #60'
- en: The model card should contain information about how the model was trained, how
    to use it, which tasks it supports, and how to reference the model.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 模型卡片应包含有关模型如何训练、如何使用它、它支持哪些任务以及如何引用模型的信息。
- en: Since HuggingFace is a community, it is important to properly document models
    created and provide information on how the models were trained and what they can
    do. Therefore, my best practice is to include all that information in the model
    card. Many models include also information about how to contact the authors and
    whether the models had been pre-trained before they were trained.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于HuggingFace是一个社区，因此正确记录创建的模型并提供有关模型如何训练以及它们能做什么的信息非常重要。因此，我的最佳实践是将所有这些信息包含在模型卡片中。许多模型还包括有关如何联系作者以及模型在训练之前是否已经预训练的信息。
- en: 'Once the model card is ready, we can move to the `Readme.txt` – the model card),
    and we can add actual model files (see *Figure 12**.6*):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型卡片准备就绪，我们就可以转到`Readme.txt`（即模型卡片），并可以添加实际的模型文件（见*图12.6*）：
- en: '![Figure 12.6 – Files and versions of models; we can add a model by using the
    Add file button in the top right-hand corner](img/B19548_12_6.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图12.6 – 模型的文件和版本；我们可以在右上角使用“添加文件”按钮添加模型](img/B19548_12_6.jpg)'
- en: Figure 12.6 – Files and versions of models; we can add a model by using the
    Add file button in the top right-hand corner
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 – 模型的文件和版本；我们可以在右上角使用“添加文件”按钮添加模型
- en: 'Once we click on the `wolfBERTa` subfolder. That folder contains the following
    files:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们点击`wolfBERTa`子文件夹。该文件夹包含以下文件：
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The first two entries are the model checkpoints; that is, the versions of the
    model saved during our training process. These two folders are not important for
    the deployment, and therefore they will be ignored. The rest of the files should
    be copied to the newly created model repository at HuggingFace.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个条目是模型检查点；即我们在训练过程中保存的模型版本。这两个文件夹对于部署来说并不重要，因此将被忽略。其余的文件应复制到HuggingFace上新建的模型仓库中。
- en: 'The model, after uploading, should look something like the one presented in
    *Figure 12**.7*:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 模型上传后，应该看起来像*图12.7*中展示的那样：
- en: '![Figure 12.7 – Model uploaded to the HuggingFace repository](img/B19548_12_7.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图12.7 – 上传到HuggingFace仓库的模型](img/B19548_12_7.jpg)'
- en: Figure 12.7 – Model uploaded to the HuggingFace repository
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7 – 上传到HuggingFace仓库的模型
- en: 'After this, the model is ready to be used by the community. What we can also
    do is create an inference API for the community to quickly test our models. It
    is provided to us automatically once we go back to the **Model card** menu, under
    the **Hosted inference API** section (right-hand side of *Figure 12**.8*):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，该模型就准备好供社区使用了。我们还可以为社区创建一个推理API，以便他们快速测试我们的模型。一旦我们回到**模型卡片**菜单，在**托管推理API**部分（*图12.8*的右侧）就会自动提供给我们：
- en: '![Figure 12.8 – Hosted inference API provided automatically for our model](img/B19548_12_8.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图12.8 – 为我们的模型自动提供的托管推理API](img/B19548_12_8.jpg)'
- en: Figure 12.8 – Hosted inference API provided automatically for our model
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 – 为我们的模型自动提供的托管推理API
- en: When we input `int HTTP_get(<mask>)`, we ask the model to provide the input
    parameter for that function. The results show that the most probable token is
    `void` and the second in line is the `int` token. Both are relevant as they are
    types used in parameters, but they are probably not going to make this program
    compile, so we would need to develop a loop that would predict more than just
    one token for the program. It probably needs a bit more training as well.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们输入`int HTTP_get(<mask>)`时，我们要求模型为该函数提供输入参数。结果显示，最可能的标记是`void`，其次是`int`标记。这两个都是相关的，因为它们是参数中使用的类型，但它们可能不会使这个程序编译，因此我们需要开发一个循环，预测程序中的不止一个标记。可能还需要更多的训练。
- en: Now, we have a fully deployed model that can be used in other applications without
    much hassle.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个完全部署的模型，可以在其他应用中使用而无需太多麻烦。
- en: Downloading models from HuggingFace
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从HuggingFace下载模型
- en: 'We have already seen how to download a model from HuggingFace, but for the
    sake of completeness, let’s see how this is done for the `wolfBERTa` model. Essentially,
    we follow the model card and use the following Python code fragment:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何从HuggingFace下载模型，但为了完整性，让我们看看如何为`wolfBERTa`模型执行此操作。本质上，我们遵循模型卡片并使用以下Python代码片段：
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This code fragment downloads the model and uses an `unmasker` interface to
    make an inference using the `fill-mask` pipeline. The pipeline allows you to input
    a sentence with a `<mask>` masked token, and the model will attempt to predict
    the most suitable word to fill in the masked position. The three lines of this
    code fragment do the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码片段下载模型并使用 `unmasker` 接口通过 `fill-mask` 管道进行推理。该管道允许您输入一个带有 `<mask>` 掩码标记的句子，模型将尝试预测最适合填充掩码位置的单词。此代码片段中的三行代码执行以下操作：
- en: '`from transformers import pipeline`: This line imports the pipeline function
    from the `transformer`s library. The pipeline function simplifies the process
    of using pre-trained models for various **natural language processing** (**NLP**)
    tasks.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from transformers import pipeline`: 这行代码从 `transformer`s 库中导入管道函数。管道函数简化了使用预训练模型进行各种**自然语言处理**（**NLP**）任务的过程。'
- en: '`unmasker = pipeline(''fill-mask'', model=''mstaron/wolfBERTa'')`: This line
    creates a new pipeline named `unmasker` for the task. The pipeline will use the
    pre-trained `wolfBERTa` model.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unmasker = pipeline(''fill-mask'', model=''mstaron/wolfBERTa'')`: 这行代码为任务创建了一个名为
    `unmasker` 的新管道。该管道将使用预训练的 `wolfBERTa` 模型。'
- en: '`unmasker("Hello I''m a <mask> model.")`: This line utilizes the `unmasker`
    pipeline to predict the word that best fits the masked position in the given sentence.
    The `<mask>` token indicates the position where the model should try to fill in
    a word.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unmasker("Hello I''m a <mask> model.")`: 这行代码利用 `unmasker` 管道来预测最适合给定句子中掩码位置的单词。`<mask>`
    标记表示模型应尝试填充单词的位置。'
- en: When this line is executed, the pipeline will call the `wolfBERTa` model, which
    will make predictions based on the provided sentence. The model will predict the
    word that it finds to best complete the sentence in the position of the `<``mask>`
    token.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行此行代码时，管道将调用 `wolfBERTa` 模型，并根据提供的句子进行预测。该模型将在 `<mask>` 标记的位置预测最佳单词以完成句子。
- en: One can use other models in a very similar way. The main advantage of a community
    model hub such as HuggingFace is that it provides a great way to uniformly manage
    models and pipelines and allows us to quickly exchange models in software products.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 可以以非常相似的方式使用其他模型。像 HuggingFace 这样的社区模型中心的主要优势是它提供了一种统一管理模型和管道的绝佳方式，并允许我们在软件产品中快速交换模型。
- en: Raw data-based pipelines
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于原始数据的管道
- en: Creating a full pipeline can be a daunting task and requires creating customized
    tools for all models and all kinds of data. It allows us to optimize how we use
    the models, but it requires a lot of effort. The main rationale behind pipelines
    is that they link two areas of ML – the model and its computational capabilities
    with the task and the data from the domain. Luckily for us, the main model hubs
    such as HuggingFace have an API that provides ML pipelines automatically. Pipelines
    in HuggingFace are related to the model and provided by the framework based on
    the model’s architecture, input, and output.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 创建完整的管道可能是一项艰巨的任务，需要为所有模型和所有类型的数据创建定制工具。它允许我们优化模型的使用方式，但需要付出大量努力。管道背后的主要理念是将机器学习的两个领域——模型及其计算能力与任务和领域数据联系起来。幸运的是，对于像
    HuggingFace 这样的主要模型中心，它们提供了一个API，可以自动提供机器学习管道。HuggingFace 中的管道与模型相关，并由基于模型架构、输入和输出的框架提供。
- en: Pipelines for NLP-related tasks
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与自然语言处理相关的管道
- en: Text classification is a pipeline designed to classify text input into predefined
    categories or classes. It’s particularly useful for tasks such as **sentiment
    analysis** (**SA**), topic categorization, spam detection, intent recognition,
    and so on. The pipeline typically employs pre-trained models fine-tuned on specific
    datasets for different classification tasks. We have seen similar capabilities
    in *Part I* of this book when we used ML for SA of code reviews.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分类是一个管道，旨在将文本输入分类到预定义的类别或类别中。它特别适用于**情感分析**（**SA**）、主题分类、垃圾邮件检测、意图识别等任务。该管道通常采用针对不同分类任务在特定数据集上微调的预训练模型。我们在本书的第一部分使用机器学习进行代码审查的情感分析时，已经看到了类似的功能。
- en: 'An example is presented in the following code fragment:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段提供了一个示例：
- en: '[PRE2]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The code fragment shows that there are essentially two lines of code (in boldface)
    that we need to instantiate the pipeline, as we’ve also seen before.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 代码片段显示，实际上我们需要实例化管道的代码有两行（粗体显示），正如我们之前所见。
- en: Text generation is another pipeline that allows the generating of text using
    pre-trained language models, such as GPT-3, based on a provided prompt or seed
    text. It’s capable of generating human-like text for various applications, such
    as chatbots, creative writing, **question answering** (**QA**), and more.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成是另一个允许使用预训练语言模型（如GPT-3）根据提供的提示或种子文本生成文本的流程。它能够为各种应用生成类似人类的文本，例如聊天机器人、创意写作、**问答**（**QA**）等。
- en: 'An example is presented in the following code fragment:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了这样的一个示例：
- en: '[PRE3]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Summarization is a pipeline designed to summarize longer texts into shorter,
    coherent summaries. It utilizes transformer-based models that have been trained
    on large datasets with a focus on the summarization task. The pipeline is exemplified
    in the following code fragment:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要是设计用于将较长的文本总结为较短、连贯的摘要的流程。它利用了在大型数据集上针对摘要任务进行训练的基于transformer的模型。以下代码片段展示了该流程的示例：
- en: '[PRE4]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'There are more pipelines in the HuggingFace `transformers` API, so I encourage
    you to take a look at these pipelines. However, my best practice related to pipelines
    is this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: HuggingFace的`transformers` API中还有更多流程，所以我鼓励您查看这些流程。然而，我关于流程的最佳实践是这样的：
- en: 'Best practice #61'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #61'
- en: Experiment with different models to find the best pipeline.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试不同的模型以找到最佳流程。
- en: Since the API provides the same pipeline for similar models, changing the model
    or its version is quite simple. Therefore, we can create a product based on a
    model that has similar (but not the same) capabilities as the model that we use
    and simultaneously train the model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 由于API为类似模型提供了相同的流程，因此更改模型或其版本相当简单。因此，我们可以基于具有类似（但不同）功能（但不是相同）的模型创建产品，并同时训练模型。
- en: Pipelines for images
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像流程
- en: Pipelines for image processing are designed specifically for tasks related to
    image processing. The HuggingFace hub contains several of these pipelines, with
    the following ones being the most popular.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图像处理流程专门设计用于与图像处理相关的任务。HuggingFace hub包含这些流程中的几个，以下是一些最受欢迎的。
- en: 'Image classification is designed specifically to classify an image to a specific
    class. It is the same kind of task as is probably the most widely known – classifying
    an image to be “cat”, “dog”, or “car”. The following code example (from the HuggingFace
    tutorial) shows the usage of an image classification pipeline:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类专门设计用于将图像分类到特定类别。这与可能是最广为人知的任务相同——将图像分类为“猫”、“狗”或“车”。以下代码示例（来自HuggingFace教程）展示了图像分类流程的使用：
- en: '[PRE5]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The preceding code fragment shows that an image classification pipeline is created
    equally easily (if not easier) as pipelines for text analysis tasks.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段表明，创建图像分类流程与创建文本分析任务的流程一样容易（如果不是更容易）。
- en: 'An image segmentation pipeline is used when we want to add a so-called semantic
    map to an image (see *Figure 12**.9*):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要向图像添加所谓的语义地图时，会使用图像分割流程（见*图12.9*）：
- en: '![Figure 12.9 – Semantic map of an image, the same as we saw in Chapter 3](img/B19548_12_9.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图12.9 – 图像的语义地图，与我们第3章中看到的一样](img/B19548_12_9.jpg)'
- en: Figure 12.9 – Semantic map of an image, the same as we saw in [*Chapter 3*](B19548_03.xhtml#_idTextAnchor038)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 – 图像的语义地图，与我们第3章中看到的一样[*第3章*](B19548_03.xhtml#_idTextAnchor038)
- en: 'An example code fragment that contains such a pipeline is presented next (again,
    from the HuggingFace tutorial):'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例代码片段（同样来自HuggingFace教程）展示了包含此类流程的示例代码：
- en: '[PRE6]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The preceding code fragment creates an image segmentation pipeline, uses it,
    and stores the results in a `segments` list. The last line of the list prints
    the label of the first segment. Using the `segments[0]["mask"].size` statement,
    we can receive the size of the image map in pixels.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段创建了一个图像分割流程，使用它并将结果存储在`segments`列表中。列表的最后一行打印出第一个分割的标签。使用`segments[0]["mask"].size`语句，我们可以接收到图像地图的像素大小。
- en: 'An object detection pipeline is used for tasks that require the recognition
    of objects of a predefined class in the image. We have seen an example of this
    task in [*Chapter 3*](B19548_03.xhtml#_idTextAnchor038) already. The code for
    this kind of pipeline looks very similar to the previous ones:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测流程用于需要识别图像中预定义类别对象的任务。我们已经在[*第3章*](B19548_03.xhtml#_idTextAnchor038)中看到了这个任务的示例。此类流程的代码看起来与前几个非常相似：
- en: '[PRE7]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Executing this code creates a list of bounding boxes of objects detected in
    the image, together with its bounding boxes. My best practices related to the
    use of pipelines for images are the same as for language tasks.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此代码将创建一个包含图像中检测到的对象的边界框列表，以及其边界框。我在使用管道处理图像方面的最佳实践与语言任务相同。
- en: Feature-based pipelines
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于特征的管道
- en: Feature-based pipelines do not have specific classes because they are much lower
    level. They are the `model.fit()` and `model.predict()` statements from the standard
    Python ML implementation. These pipelines require software developers to prepare
    the data manually and also to take care of the results manually; that is, by implementing
    preprocessing steps such as converting data to tables using one-hot encoding and
    post-processing steps such as converting the data into a human-readable output.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 基于特征的管道没有特定的类，因为它们处于更低级别。它们是标准 Python 机器学习实现中的 `model.fit()` 和 `model.predict()`
    语句。这些管道要求软件开发者手动准备数据，并手动处理结果；也就是说，通过实现预处理步骤，如使用独热编码将数据转换为表格，以及后处理步骤，如将数据转换为人类可读的输出。
- en: An example of this kind of pipeline was the prediction of defects that we have
    seen in the previous parts of the book; therefore, they do not need to be repeated.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这种管道的一个例子是预测书中前几部分中看到的缺陷；因此，它们不需要重复。
- en: What is important, however, is that all pipelines are the way that link the
    ML domain with the software engineering domain. The first activity that I do after
    developing a pipeline is to test it.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，重要的是，所有管道都是将机器学习领域与软件工程领域联系起来的方式。我在开发管道后的第一个活动就是对其进行测试。
- en: Testing of ML pipelines
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习管道的测试
- en: Testing of ML pipelines is done at multiple levels, starting with unit tests
    and moving up toward integration (component) tests and then to system and acceptance
    tests. In these tests, two elements are important – the model itself and the data
    (for the model and the oracle).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道的测试在多个层面上进行，从单元测试开始，然后向上发展到集成（组件）测试，最后到系统测试和验收测试。在这些测试中，有两个元素很重要——模型本身和数据（对于模型和预言机）。
- en: 'Although we can use the unit test framework included in Python, I strongly
    recommend using the Pytest framework instead, due to its simplicity and flexibility.
    We can install this framework by simply using this command:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以使用 Python 内置的单元测试框架，但我强烈推荐使用 Pytest 框架，因为它简单灵活。我们可以通过以下命令安装此框架：
- en: '[PRE8]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: That will download and install the required packages.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这将下载并安装所需的包。
- en: 'Best practice #62'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #62'
- en: Use a professional testing framework such as Pytest.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像 Pytest 这样的专业测试框架。
- en: Using a professional framework provides us with the compatibility required by
    MLOps principles. We can share our models, data, source code, and all other elements
    without the need for cumbersome setup and installation of the frameworks themselves.
    For Python, I recommend using the Pytest framework as it is well known, widely
    used, and supported by a large community.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用专业框架为我们提供了 MLOps 原则所需的兼容性。我们可以共享我们的模型、数据、源代码以及所有其他元素，而无需繁琐地设置和安装框架本身。对于 Python，我推荐使用
    Pytest 框架，因为它广为人知，被广泛使用，并且得到一个庞大社区的支持。
- en: 'Here is a code fragment that downloads a model and prepares it for being tested:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个下载模型并为其测试做准备代码片段：
- en: '[PRE9]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This code snippet is used to load and set up a pre-trained language model,
    specifically the `SingBERTa` model, using the Hugging Face `transformers` library.
    It contains the following elements:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码用于加载和设置预训练的语言模型，特别是 `SingBERTa` 模型，使用 Hugging Face 的 `transformers` 库。它包含以下元素：
- en: 'Import the necessary modules from the `transformers` library:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `transformers` 库导入必要的模块：
- en: '`AutoTokenizer`: This class is used to automatically select the appropriate
    tokenizer for the pre-trained model.'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`AutoTokenizer`：这个类用于自动选择适合预训练模型的适当分词器。'
- en: '`AutoModelForMaskedLM`: This class is used to automatically select the appropriate
    model for **masked language modeling** (**MLM**) tasks.'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`AutoModelForMaskedLM`：这个类用于自动选择适合 **掩码语言模型**（**MLM**）任务的适当模型。'
- en: 'Load the tokenizer and model for the pre-trained `SingBERTa` model:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载预训练的 `SingBERTa` 模型的分词器和模型：
- en: '`tokenizer = AutoTokenizer.from_pretrained(''mstaron/SingBERTa'')`: This line
    loads the tokenizer for the pre-trained `SingBERTa` model from the Hugging Face
    model hub.'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`tokenizer = AutoTokenizer.from_pretrained(''mstaron/SingBERTa'')`：这一行从 Hugging
    Face 模型库中加载预训练的 `SingBERTa` 模型的分词器。'
- en: '`model = AutoModelForMaskedLM.from_pretrained("mstaron/SingBERTa")`: This line
    loads the pre-trained `SingBERTa` model.'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`model = AutoModelForMaskedLM.from_pretrained("mstaron/SingBERTa")`：这一行加载预训练的`SingBERTa`模型。'
- en: 'Import the feature extraction pipeline:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入特征提取管道：
- en: '`from transformers import pipeline`: This line imports the pipeline class from
    the `transformers` library, which allows us to easily create pipelines for various
    NLP tasks.'
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`from transformers import pipeline`：这一行从`transformers`库中导入管道类，这使得我们能够轻松地为各种NLP任务创建管道。'
- en: 'Create a feature extraction pipeline:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建特征提取管道：
- en: '`features = pipeline("feature-extraction", model=model, tokenizer=tokenizer,
    return_tensor=False)`: This line creates a pipeline for feature extraction. The
    pipeline uses the pre-trained model and tokenizer loaded earlier to extract embedding
    vectors from the input text. The `return_tensor=False` argument ensures that the
    output will be in a non-tensor format (likely NumPy arrays or Python lists).'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`features = pipeline("feature-extraction", model=model, tokenizer=tokenizer,
    return_tensor=False)`：这一行创建一个用于特征提取的管道。该管道使用之前加载的预训练模型和分词器从输入文本中提取嵌入向量。`return_tensor=False`参数确保输出将以非张量格式（可能是NumPy数组或Python列表）返回。'
- en: 'With this setup, you can now use the `features` pipeline to extract embedding
    vectors from text input using the pre-trained `SingBERTa` model without the need
    for any additional training. We’ve seen this model being used before, so here,
    let us focus on its testing. The following code fragment is a test case to check
    that the model has been downloaded correctly and that it is ready to be used:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个设置，你现在可以使用`features`管道从文本输入中提取嵌入向量，而无需进行任何额外的训练，使用预训练的`SingBERTa`模型。我们之前已经看到过这个模型的使用，所以在这里，让我们专注于它的测试。以下代码片段是一个测试用例，用于检查模型是否已正确下载并且准备好使用：
- en: '[PRE10]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This code fragment defines a `test_features()` test function. The purpose of
    this function is to test the correctness of the feature extraction pipeline created
    in the previous code snippet by comparing the embeddings of the word `"Test"`
    obtained from the pipeline to the expected embeddings stored in a JSON file named
    `''test.json''`. The content of that file is our oracle, and it is a large vector
    of numbers that we use to compare to the actual model output:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码片段定义了一个`test_features()`测试函数。该函数的目的是通过将管道从之前代码片段中创建的特征提取管道获得的单词`"Test"`的嵌入与存储在名为`'test.json'`的JSON文件中的预期嵌入进行比较来测试特征提取管道的正确性。该文件的内容是我们的预言，它是一个包含大量数字的大向量，我们用它来与实际模型输出进行比较：
- en: '`lstFeatures = features("Test")`: This line uses the previously defined `features`
    pipeline to extract embeddings for the word `"Test"`. The `features` pipeline
    was created using the pre-trained `SingBERTa` model and tokenizer. The pipeline
    takes the input `"Test"`, processes it through the tokenizer, passes it through
    the model, and returns embedding vectors as `lstFeatures`.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lstFeatures = features("Test")`：这一行使用之前定义的`features`管道提取单词`"Test"`的嵌入。`features`管道是使用预训练的`SingBERTa`模型和分词器创建的。该管道将输入`"Test"`通过分词器处理，然后通过模型，并返回嵌入向量作为`lstFeatures`。'
- en: '`with open(''test.json'', ''r'') as f:`: This line opens the `''test.json''`
    file in read mode using a context manager (`with` statement).'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`with open(''test.json'', ''r'') as f:`：这一行使用上下文管理器（`with`语句）以读取模式打开`''test.json''`文件。'
- en: '`lstEmbeddings = json.load(f)`: This line reads the contents of the `''test.json''`
    file and loads its content into the `lstEmbeddings` variable. The JSON file should
    contain a list of embedding vectors representing the expected embeddings for the
    word `"Test"`.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lstEmbeddings = json.load(f)`：这一行读取`''test.json''`文件的内容，并将其内容加载到`lstEmbeddings`变量中。该JSON文件应包含表示预期嵌入的单词`"Test"`的嵌入向量的列表。'
- en: '`assert lstFeatures[0][0] == lstEmbeddings`: This line performs an assertion
    to check if the embedding vector obtained from the pipeline (`lstFeatures[0][0]`)
    is equal to the expected embedding vector (oracle) from the JSON file (`lstEmbeddings`).
    A comparison is made by checking whether the elements at the same position in
    both lists are the same.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`assert lstFeatures[0][0] == lstEmbeddings`：这一行执行断言以检查从管道获得的嵌入向量（`lstFeatures[0][0]`）是否等于从JSON文件中获得的预期嵌入向量（预言）。通过检查两个列表中相同位置的元素是否相同来进行比较。'
- en: If the assertion is `true` (that is, the pipeline’s extracted embedding vector
    is the same as the expected vector from the JSON file), the test will pass without
    any output. However, if the assertion is `false` (that is, the embeddings do not
    match), the test framework (Pytest) marks this test case as failed.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果断言为`true`（即管道提取的嵌入向量与JSON文件中预期的向量相同），则测试将通过而没有任何输出。然而，如果断言为`false`（即嵌入不匹配），则测试框架（Pytest）将此测试用例标记为失败。
- en: 'In order to execute the tests, we can write the following statement in the
    same directory as our project:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行测试，我们可以在与我们的项目相同的目录中编写以下语句：
- en: '[PRE11]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In our case, this results in the following output (redacted for brevity):'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，这导致以下输出（为了简洁起见，已省略）：
- en: '[PRE12]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This fragment shows that the framework found one test case (`collected 1 item`)
    and that it executed it. It also says that the test case passed in 4.17 seconds.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这个片段显示，框架找到了一个测试用例（`收集了1个条目`）并执行了它。它还说明该测试用例在4.17秒内通过。
- en: Therefore, here comes my next best practice.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，接下来是我的下一个最佳实践。
- en: 'Best practice #63'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #63'
- en: Set up your test infrastructure based on your training data.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的训练数据设置测试基础设施。
- en: Since the models are inherently probabilistic, it is best to test the models
    based on the training data. Here, I do not mean that we test the performance in
    the sense of ML, like accuracy. I mean that we test that the models actually work.
    By using the same data as we used for the training, we can check whether the models’
    inference is correct for the data that we used before. Therefore, I mean this
    as testing in the software engineering sense of this term.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型本质上是概率性的，因此最好基于训练数据来测试模型。这里，我的意思不是我们在机器学习（ML）的意义上测试性能，比如准确性。我的意思是测试模型是否真正工作。通过使用与训练相同的相同数据，我们可以检查模型对之前使用的数据的推理是否正确。因此，我指的是在软件工程意义上这个词的测试。
- en: 'Now, analogous to the language models presented previously, we can use a similar
    approach to test a classical ML model. It’s sometimes called a zero-table test.
    In this test, we use simple data with one data point only to test that the model’s
    predictions are correct. Here is how we set up such a test:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，类似于之前提出的语言模型，我们可以使用类似的方法来测试一个经典ML模型。有时这被称为零表测试。在这个测试中，我们使用只有一个数据点的简单数据来测试模型的预测是否正确。以下是设置此类测试的方法：
- en: '[PRE13]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This fragment of the code uses the `joblib` library to load an ML model. In
    this case, it is a model that we used in [*Chapter 10*](B19548_10.xhtml#_idTextAnchor121)
    when we trained a classical ML model. It is a decision tree model.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码片段使用`joblib`库加载一个ML模型。在这种情况下，它是我们训练经典ML模型时在[*第10章*](B19548_10.xhtml#_idTextAnchor121)中使用的模型。它是一个决策树模型。
- en: Then, the program reads the same dataset that we used for training the model
    so that the format of the data is exactly the same. In this case, we can expect
    the same results that we used for the training dataset. For more complex models,
    we can create such a table by making one inference directly after the model has
    been trained and before it was saved.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，程序读取我们用于训练模型的相同数据集，以确保数据的格式与训练数据集完全相同。在这种情况下，我们可以期望得到与训练数据集相同的结果。对于更复杂的模型，我们可以在模型训练后直接进行一次推理，在保存模型之前创建这样的表。
- en: 'Now, we can define three test cases in the following code fragment:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在以下代码片段中定义三个测试用例：
- en: '[PRE14]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The first test function (`test_model_not_null`) checks if the `model` variable,
    which is expected to hold the trained ML model, is not `null`. If the model is
    `null` (that is, it does not exist), the `assert` statement will raise an exception,
    indicating that the test has failed.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个测试函数（`test_model_not_null`）检查`model`变量，该变量预期将包含训练好的ML模型，是否不是`null`。如果模型是`null`（即不存在），则`assert`语句将引发异常，表示测试失败。
- en: 'The second test function (`test_model_predicts_class_correctly`) checks whether
    the model predicts class 1 correctly for the given dataset. It does so by doing
    the following:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个测试函数（`test_model_predicts_class_correctly`）检查模型是否正确预测了给定数据集的类别1。它是通过以下方式完成的：
- en: Preparing the `X` input features by dropping the `'Defect'` column from the
    `dfDataAnt13` DataFrame, assuming that `'Defect'` is the target column (class
    label).
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过从`dfDataAnt13` DataFrame中删除`'Defect'`列来准备`X`输入特征，假设`'Defect'`是目标列（类别标签）。
- en: Using the trained model (`model.predict(X)`) to make predictions on the `X`
    input features.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用训练好的模型（`model.predict(X)`）对`X`输入特征进行预测。
- en: Asserting that the first prediction (`model.predict(X)[0]`) should be equal
    to 1 (class 1). If the model predicts class 1 correctly, the test passes; otherwise,
    it raises an exception, indicating a test failure.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 断言第一次预测（`model.predict(X)[0]`）应该等于1（类别1）。如果模型正确预测类别1，则测试通过；否则，将引发异常，表示测试失败。
- en: 'The third test case (`test_model_predicts_class_0_correctly`) checks whether
    the model predicts class 0 correctly for the given dataset. It follows a similar
    process as the previous test:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个测试用例（`test_model_predicts_class_0_correctly`）检查模型是否正确预测给定数据集的类别0。它遵循与上一个测试类似的过程：
- en: Preparing the `X` input features by dropping the `'Defect'` column from the
    `dfDataAnt13` DataFrame.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过从`dfDataAnt13` DataFrame中删除`'Defect'`列来准备`X`输入特征。
- en: Using the trained model (`model.predict(X)`) to make predictions on the `X`
    input features.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用训练好的模型（`model.predict(X)`）对`X`输入特征进行预测。
- en: Asserting that the second prediction (`model.predict(X)[1]`) should be equal
    to 0 (class 0). If the model predicts class 0 correctly, the test passes; otherwise,
    it raises an exception, indicating a test failure.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 断言第二次预测（`model.predict(X)[1]`）应该等于0（类别0）。如果模型正确预测类别0，则测试通过；否则，将引发异常，表示测试失败。
- en: 'These tests verify the integrity and correctness of the trained model and ensure
    it performs as expected on the given dataset. The output from executing the tests
    is shown as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这些测试验证了训练模型的完整性和正确性，并确保它在给定的数据集上按预期执行。以下是执行测试的输出：
- en: '[PRE15]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The Pytest framework found all of our tests and showed that three (out of four)
    are in the `chapter_12_classical_ml_test.py` file and one is in the `chapter_12_downloaded_model_test.py`
    file.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Pytest框架找到了我们所有的测试，并显示其中三个（四个中的三个）位于`chapter_12_classical_ml_test.py`文件中，另一个位于`chapter_12_downloaded_model_test.py`文件中。
- en: 'My next best practice is, therefore, this:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我的下一个最佳实践是：
- en: 'Best practice #64'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践#64
- en: Treat models as units and prepare unit tests for them accordingly.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型视为单元并相应地为它们准备单元测试。
- en: I recommend treating ML models as units (the same as modules) and using unit
    testing practices for them. This helps to reduce the effects of the probabilistic
    nature of the models and provides us with the possibility to check whether the
    model works correctly. It helps to debug the entire software system afterward.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议将ML模型视为单元（与模块相同）并为其使用单元测试实践。这有助于减少模型概率性质的影响，并为我们提供了检查模型是否正确工作的可能性。它有助于在之后调试整个软件系统。
- en: Monitoring ML systems at runtime
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控ML系统运行时
- en: Monitoring pipelines in production is a critical aspect of MLOps to ensure the
    performance, reliability, and accuracy of deployed ML models. This includes several
    practices.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 监控生产中的管道是MLOps的关键方面，以确保部署的ML模型的表现、可靠性和准确性。这包括几个实践。
- en: The first practice is logging and collecting metrics. This activity includes
    instrumenting the ML code with logging statements to capture relevant information
    during model training and inference. Key metrics to monitor are model accuracy,
    data drift, latency, and throughput. Popular logging and monitoring frameworks
    include Prometheus, Grafana, and **Elasticsearch, Logstash, and** **Kibana** (**ELK**).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个实践是记录和收集指标。这项活动包括在ML代码中添加日志语句，以在模型训练和推理期间捕获相关信息。要监控的关键指标包括模型准确性、数据漂移、延迟和吞吐量。流行的日志和监控框架包括Prometheus、Grafana以及**Elasticsearch、Logstash和**
    **Kibana**（**ELK**）。
- en: The second one is alerting, which is a setup of alerts based on predefined thresholds
    for key metrics. This helps in proactively identifying issues or anomalies in
    the production pipeline. When an alert is triggered, the appropriate team members
    can be notified to investigate and address the problem promptly.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是警报，它基于预定义的关键指标阈值设置警报。这有助于在生产管道中主动识别问题或异常。当警报被触发时，适当的团队成员可以被通知进行调查并迅速解决问题。
- en: Data drift detection is the third activity, which includes monitoring the distribution
    of incoming data to identify data drift. Data drift refers to changes in data
    distribution over time, which can impact model performance.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 数据漂移检测是第三项活动，包括监控输入数据的分布以识别数据漂移。数据漂移指的是数据分布随时间的变化，这可能会影响模型性能。
- en: The fourth activity is performance monitoring, where the MLOps team continuously
    tracks the performance of the deployed model. They measure inference times, prediction
    accuracy, and other relevant metrics, and they monitor for performance degradation,
    which might occur due to changes in data, infrastructure, or dependencies.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to these four main activities, an MLOps team has also the following
    responsibilities:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '**Error analysis**: Using tools to analyze and log errors encountered during
    inference and understanding the nature of errors can help improve the model or
    identify issues in the data or system.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model versioning**: Keep track of model versions and their performance over
    time, and (if needed) roll back to previous versions if issues arise with the
    latest deployment.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Environment monitoring**: Monitoring the infrastructure and environment where
    the model is deployed with KPIs such as CPU/memory utilization, and network traffic
    and looking for performance bottlenecks.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security and compliance**: Ensuring that the deployed models adhere to security
    and compliance standards as well as monitor access logs and any suspicious activities.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User feedback**: Collecting, analyzing, and incorporating user feedback into
    the monitoring and inference process. MLOps solicits feedback from end users to
    understand the model’s performance from a real-world perspective.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By monitoring pipelines effectively, MLOps can quickly respond to any issues
    that arise, deliver better user experiences, and maintain the overall health of
    your ML systems. However, monitoring all of the aforementioned aspects is rather
    effort-intensive, and not all MLOps teams have the resources to do that. Therefore,
    my last best practice in this chapter is this:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'Best practice #65'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Identify key aspects of the ML deployment and monitor these aspects accordingly.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Although this sounds straightforward, it is not always easy to identify key
    aspects. I usually start by prioritizing the monitoring of the infrastructure
    and logging and collecting metrics. Monitoring of the infrastructure is important
    as any kind of problems quickly propagate to customers and result in losing credibility
    and even business. Monitoring metrics and logging gives a great insight into the
    operation of ML systems and prevents a lot of problems with the production of
    ML systems.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Constructing ML pipelines concludes the part of the book that focuses on the
    core technical aspects of ML. Pipelines are important for ensuring that the ML
    models are used according to best practices in software engineering.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: However, ML pipelines are still not a complete ML system. They can only provide
    inference of the data and provide an output. For the pipelines to function effectively,
    they need to be connected to other parts of the system such as the user interface
    and storage. That is the content of the next chapter.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*A. Lima*, *L. Monteiro*, and *A.P. Furtado*, *MLOps: Practices, Maturity Models,
    Roles, Tools, and Challenges-A Systematic Literature Review*. *ICEIS (1), 2022:*
    *p. 308-320*.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*A. Lima*，*L. Monteiro*，和 *A.P. Furtado*，*MLOps：实践、成熟度模型、角色、工具和挑战的系统文献综述*。*ICEIS
    (1)，2022:* *p. 308-320*。'
- en: '*John, M.M.*, *Olsson, H.H.*, and *Bosch, J.*, *Towards MLOps: A framework
    and maturity model*. In *2021 47th Euromicro Conference on Software Engineering
    and Advanced Applications (SEAA)*. *2021*. *IEEE*.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*John, M.M.*，*Olsson, H.H.*，和 *Bosch, J.*，*迈向MLOps：一个框架和成熟度模型*。在*2021年第47届欧姆尼微软件工程和高级应用会议（SEAA）*。*2021*。*IEEE*。'
- en: '*Staron, M. et al.*, *Industrial experiences from evolving measurement systems
    into self‐healing systems for improved availability*. *Software: Practice and
    Experience*, *2018*. *48(3):* *p. 719-739*.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Staron, M. et al.*, *从演化的测量系统到自愈系统以提高可用性的工业经验*。*软件：实践与经验*，*2018*。*48(3)*：*p.
    719-739*。'
