<html><head></head><body><div><div><h1 class="header-title">Getting Started with OpenCV with CUDA Support</h1>
                
            
            
                
<p>So far, we have seen all the concepts related to parallel programming using CUDA and how it can leverage the GPU for acceleration. From this chapter on, we will try to use the concept of parallel programming in CUDA for computer vision applications. Though we have worked on matrices, we have not worked on actual images. Basically, working on images is similar to manipulation of two-dimensional matrices. We will not develop the entire code from scratch for computer vision applications in CUDA, but we will use the popular computer vision library that is called OpenCV. Though this book assumes that the reader has some familiarity with working with OpenCV, this chapter revises the concepts of using OpenCV in C++. This chapter describes the installation of the OpenCV library with CUDA support on Windows and Ubuntu. Then it describes how to test this installation and run a simple program. This chapter describes the use of OpenCV in working with images and videos by developing simple codes for it. This chapter also compares the performance of a program with CUDA support to one without it.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Introduction to image processing and computer vision</li>
<li>Introduction to OpenCV with CUDA support</li>
<li>Installation of OpenCV with CUDA support on Windows and Ubuntu</li>
<li>Working with images using OpenCV</li>
<li>Working with videos using OpenCV</li>
<li>Arithmetic and logical operations on images</li>
<li>Color-space conversions and image thresholding</li>
<li>Performance comparison between CPU and GPU OpenCV programs</li>
</ul>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>This chapter requires a basic understanding of image processing and computer vision. It needs familiarity with the basic C or C++ programming language and all the code samples explained in previous chapters. All of the code used in this chapter can be downloaded from the following GitHub link: <a href="https://github.com/PacktPublishing/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA">https://github.com/PacktPublishing/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA</a>. The code can be executed on any operating system, though it has only been tested on Ubuntu 16.04. </p>
<p>Check out the following video to see the Code in Action:<br/>
<a href="http://bit.ly/2xF5cQV">http://bit.ly/2xF5cQV</a></p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Introduction to image processing and computer vision</h1>
                
            
            
                
<p>The volume of image and video data available in the world is increasing day by day. The increasing use of mobile devices to capture images and use of the internet to post them has allowed production of enormous amounts of video and image data every day. Image processing and computer vision are used in many applications across various domains. Doctors use MRI and X-ray images for medical diagnoses. Space scientists and chemical engineers use images for space exploration and analysis of various genes at the molecular level. Images can be used to develop autonomous vehicles and video surveillance applications. They can also be used in agricultural applications and to identify faulty products during manufacturing.  All these applications need to process images on a computer at a high speed. We are not going to look at how images are captured by a camera sensor and converted into digital images for computer storage. In this book, we will only cover the processing of an image on a computer, where we assume it is already stored.  </p>
<p>Many people use the terms <strong>image processing</strong> and <strong>computer vision</strong> interchangeably. However, there is a difference between these two fields. Image processing is concerned with improving the visual quality of images by modifying pixel values, whereas computer vision is concerned with extracting important information from the images. So in image processing, both input and output are images, while in computer vision, input is an image but output is the information extracted from that image. Both have a wide variety of applications, but image processing is mainly used at the pre-processing stage of computer vision applications.</p>
<p>An image is stored as a multidimensional matrix. So processing an image on a computer is nothing more than manipulating this matrix. We saw how to work with matrices in CUDA in previous chapters. The code for reading, manipulating, and displaying images in CUDA might get very long, tedious, and hard to debug. So we will use a library that contains APIs for all of these functions and which can leverage the advantage of CUDA-GPU acceleration for processing images. This library is called OpenCV, which is an acronym for Open Computer Vision. In the next section, this library is explained in detail. </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Introduction to OpenCV</h1>
                
            
            
                
<p>OpenCV is a computer vision library developed with computational efficiency in mind and keeping the focus on real-time performance. It is written in C/C++ and it contains more than a hundred functions that help in computer vision applications. The main advantage of OpenCV is that it is open source and released under a Berkley software distribution (BSD) license which allows free use of OpenCV in research and commercial applications. This library has an interface in C, C++, Java, and Python languages and it can be used in all operating systems, such as Windows, Linux, macOS, and Android, without modifying a single line of code. </p>
<p>This library can also take advantage of multi-core processing and OpenGL and CUDA for parallel processing. As OpenCV is lightweight, it can be used on embedded platforms such as Raspberry Pi as well. This makes it ideal for deploying computer vision applications on embedded systems in real-life scenarios. We are going to explore this in the next few chapters. These features have made OpenCV a default choice for computer vision developers. It has a wide developer base and user community that helps constantly in improving the library. The downloads for OpenCV are in the millions and increasing day by day. The other popular computer vision and image processing tool is MATLAB, so you might wonder what are the advantages of using OpenCV over MATLAB. The following table shows a comparison between these two tools:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td><strong>Parameter</strong></td>
<td><strong>OpenCV</strong></td>
<td><strong>MATLAB</strong></td>
</tr>
<tr>
<td>Program speed</td>
<td>Higher because it is developed using C/C++</td>
<td>Lower than OpenCV</td>
</tr>
<tr>
<td>Resources needed</td>
<td>OpenCV is a lightweight library so it consumes very little memory both in terms of hard disk and RAM. A normal OpenCV program will require less than 100MB RAM.</td>
<td>MATLAB is very bulky. The latest MATLAB version installation can consume more than 15 GB space on the hard disk and a large chunk of RAM (more than 1 GB) when it is in use. </td>
</tr>
<tr>
<td>Portability</td>
<td>OpenCV can run on all operating systems that can run C language.</td>
<td>MATLAB can only run on Windows, Linux, and MAC.</td>
</tr>
<tr>
<td>Cost</td>
<td>The use of OpenCV in commercial or academic applications is completely free.</td>
<td>MATLAB is a licensed software so you have to pay a large amount to use it in your academic or commercial applications.</td>
</tr>
<tr>
<td>Ease of use</td>
<td>OpenCV is comparatively difficult to use as it has less documentation and difficult to remember syntax. It also does not have its own development environment.</td>
<td>MATLAB has its own integrated development environment with built-in help resources, which makes it easy for a new programmer to use.</td>
</tr>
</tbody>
</table>
<p> </p>
<p>MATLAB and OpenCV both have their pros and cons. But when we want to use computer vision in embedded applications and take advantage of parallel processing, OpenCV is the ideal choice. So, in this book, OpenCV is described for accelerating computer vision applications using GPU and CUDA. OpenCV has APIs in C, C++, Python, and Java. It is written in C/C++ so API in those languages will be the fastest. Moreover, CUDA acceleration is more supported in C/C++ API, so, in this book, we will use OpenCV with C/C++ API. In the next section, we will see how to install OpenCV on various operating systems. </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Installation of OpenCV with CUDA support</h1>
                
            
            
                
<p>Installation of OpenCV with CUDA is not as trivial as you might think. It involves many steps. In this section, all the steps for installing OpenCV in Windows and Ubuntu are explained with screenshots, so you can set your environment up easily. </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Installation of OpenCV on Windows</h1>
                
            
            
                
<p>This section explains the steps needed to install OpenCV with CUDA on a Windows operating system. The steps are performed on the Windows 10 operating system, but it will work on any Windows operating system.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Using pre-built binaries</h1>
                
            
            
                
<p>There are pre-built binaries available for OpenCV that can be downloaded and used directly in your program. It doesn't take full advantage of CUDA so it is not recommended for this book. The following steps describe the procedure for installing OpenCV without CUDA support on Windows:</p>
<ol>
<li>Make sure that Microsoft Visual Studio is installed for a compilation of C Programs.</li>
</ol>
<ol start="2">
<li>Download the latest version of OpenCV from  <a href="https://sourceforge.net/projects/opencvlibrary/files/opencv-win/">https://sourceforge.net/projects/opencvlibrary/files/opencv-win/.</a></li>
<li>Double click on the downloaded <kbd>.exe</kbd> file and extract it to your folder of choice. Here we are extracting it to the <kbd>C://opencv</kbd> folder.</li>
<li>Set up the environment variable <kbd>OPENCV_DIR</kbd> by right-clicking on My Computer | Advance Setting | Environment Variables | New. Set its value as <kbd>C:\opencv\build\x64\vc14</kbd>, as shown in the following screenshot. Here <kbd>vc14</kbd> will depend on the version of Microsoft Visual Studio:</li>
</ol>
<div><img class="alignnone size-full wp-image-312 image-border" src="img/606ed750-2439-463b-b0b6-3815c01e63fc.png" style="" width="648" height="161"/></div>
<p>Now you can use this installation for OpenCV applications using C/C++.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Building libraries from source</h1>
                
            
            
                
<p>If you want to compile OpenCV with CUDA support, follow these steps for installation:</p>
<ol>
<li>OpenCV with CUDA will require a C compiler and GPU compiler. It will require Microsoft Visual Studio and the latest CUDA installation. The procedure to install them is covered in <a href="26a373fe-8ec0-40bf-afb7-7db6a1d414c9.xhtml">Chapter 1</a>, <em>Introducing CUDA and Getting Started with CUDA</em>. So before moving ahead, please check that they are installed properly.</li>
<li> Download the source for the latest version of OpenCV by visiting the link:  <a href="https://github.com/opencv/opencv/">https://github.com/opencv/opencv/.</a></li>
<li>There are some extra modules that are not included in OpenCV, but they are available in the extra module call <kbd>opencv_contrib</kbd>, which can be installed along with OpenCV. The functions available in this module are not stable; once they get stable they are moved to an actual OpenCV source. If you want to install this module, download it from  <a href="https://github.com/opencv/opencv_contrib">https://github.com/opencv/opencv_contrib</a>. </li>
</ol>
<ol start="4">
<li>Install <kbd>cmake</kbd> from the following link: <a href="https://cmake.org/download/">https://cmake.org/download/</a>. It is needed for compilation of OpenCV library.</li>
<li>Extract ZIP files of <kbd>opencv</kbd> and <kbd>opencv_contrib</kbd> in any folder. Here they are extracted to the <kbd>C://opencv</kbd> and <kbd>C://opencv_contrib</kbd> folders.</li>
<li>Open CMake to compile OpenCV. In that, you need to select the path for the OpenCV source and select the folder in which this source will be built. It is shown in the following screenshot:</li>
</ol>
<div><img class="alignnone size-full wp-image-313 image-border" src="img/9f635157-9dfd-44cb-817d-d335ace45c08.png" style="" width="874" height="142"/></div>
<ol start="7">
<li>Then click on Configure. It will start configuring the source. CMake will try to locate as many packages as possible based on the path settings in system variables.  The configuration process is shown in the following screenshot:</li>
</ol>
<div><img class="alignnone size-full wp-image-314 image-border" src="img/41581058-10c5-48e3-a6bb-de9426d5ab7c.png" style="" width="1366" height="466"/></div>
<ol start="8">
<li>If some of the packages are not located then you can locate them manually. To configure OpenCV for installation with CUDA support, you have to check the <kbd>WITH_CUDA</kbd> variable, as shown in the following screenshot, and then click on Configure again:</li>
</ol>
<p class="mce-root"/>
<div><img class="alignnone size-full wp-image-315 image-border" src="img/c7737d63-7130-496a-813c-c2f520cf7032.png" style="" width="1366" height="466"/></div>
<ol start="9">
<li>After configuration is finished, click on Generate. This will create the Visual Studio project file based on the version of Visual Studio you select. When generating is finished, the window should be something like the following:</li>
</ol>
<div><img class="alignnone size-full wp-image-316 image-border" src="img/84795d15-01df-4596-87d8-c2246c7ad24c.png" style="" width="1366" height="768"/></div>
<ol start="10">
<li>Go to the build directory of the <kbd>opencv</kbd> folder and find the Visual Studio project with the name <kbd>OpenCV.sln</kbd>, as shown in the following screenshot:</li>
</ol>
<div><img class="alignnone size-full wp-image-317 image-border" src="img/df0e50fe-ae0a-4e56-8257-7a2e68527283.png" style="" width="1366" height="768"/></div>
<ol start="11">
<li>This will open the project in Microsoft Visual Studio. In Solution Explorer, find the project with the name <kbd>ALL_BUILD</kbd>. Right-click on it and build it. Build this project for both debug and release options in Visual Studio. This is shown in the following screenshot:</li>
</ol>
<div><img class="alignnone size-full wp-image-318 image-border" src="img/2ad145cd-82b8-41fd-82a2-968014946b3e.png" style="" width="596" height="437"/></div>
<ol start="12">
<li>It will take a long time to build this entire project, though it will vary depending on your processor and Visual Studio version. After successful completion of the build operation, you are ready to use the OpenCV library in your C/C++ projects.  </li>
<li class="CDPAlignCenter CDPAlign">
<p>Set up the environment variable <kbd>OPENCV_DIR</kbd> by right-clicking on My Computer | Advance System Settings | Environment Variables | New. Set its value as <kbd>C:\opencv\build\x64\vc14</kbd>. Here, <kbd>vc14</kbd> will depend on your version of Microsoft Visual Studio:</p>
<img class="alignnone size-full wp-image-319 image-border" src="img/7d03c092-2e34-4298-ae54-ad8745b9d353.png" style="width:44.00em;height:11.00em;" width="649" height="162"/></li>
</ol>
<p>You can check the installation by going to the <kbd>C://opencv/build/bin/Debug</kbd> directory and running any .exe application.</p>
<p class="mce-root"/>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Installation of OpenCV with CUDA support on Linux</h1>
                
            
            
                
<p>This section covers the installation steps for OpenCV with CUDA support on a Linux operating system. The steps are tested on Ubuntu 16.04, but they should work on any Unix distribution:</p>
<ol>
<li>OpenCV with CUDA will require the latest CUDA installation. The procedure to install it is covered in <a href="26a373fe-8ec0-40bf-afb7-7db6a1d414c9.xhtml">Chapter 1</a>, <em>Introducing CUDA and Getting Started with CUDA</em>. So before moving ahead, please check that it is installed properly. You can check the installation of the CUDA toolkit and supporting Nvidia device driver by executing the <kbd>nvidia-smi</kbd> command. You should see output similar to the following if your installation is working correctly:</li>
</ol>
<div><img class="alignnone size-full wp-image-320 image-border" src="img/c762a017-2657-418f-94ef-14748c67ccb6.png" style="" width="728" height="351"/></div>
<ol start="2">
<li> Download the source for the latest version of OpenCV by visiting the link:  <a href="https://github.com/opencv/opencv/">https://github.com/opencv/opencv/</a> . Extract it to the <kbd>opencv</kbd> folder.</li>
<li>There are some extra modules that are not included in OpenCV, but they are available in the extra module called <kbd>opencv_contrib</kbd>, which can be installed along with OpenCV. The functions available in this module are not stable; once they get stable, they are moved to an actual OpenCV source. If you want to install this module, download it from:  <a href="https://github.com/opencv/opencv_contrib">https://github.com/opencv/opencv_contrib</a>.  Extract it to the <kbd>opencv_contrib</kbd> folder in the same directory as the <kbd>opencv</kbd> folder.</li>
<li>Open the <kbd>opencv</kbd> folder and create a build directory. Then go inside this newly created <kbd>build</kbd> directory. These steps can be done by executing the following commands from the Command Prompt:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ cd opencv</strong><br/><strong>$ mkdir build</strong><br/><strong>$ cd build</strong> </pre>
<ol start="5">
<li>The <kbd>cmake</kbd> command is used to compile <kbd>opencv</kbd> with CUDA support. Make sure the <kbd>WITH_CUDA</kbd> flag is set to ON in this command, along with a proper path for extra modules downloaded and saved in the <kbd>opencv_contrib</kbd> directory. The entire <kbd>cmake</kbd> command is shown as follows:</li>
</ol>
<pre style="padding-left: 60px" class="crayon-line crayon-striped-line"><strong>cmake -D CMAKE_BUILD_TYPE=RELEASE CMAKE_INSTALL_PREFIX=/usr/local WITH_CUDA=ON  ENABLE_FAST_MATH=1 CUDA_FAST_MATH=1 -D WITH_CUBLAS=1 OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules BUILD_EXAMPLES=ON ..</strong></pre>
<p style="padding-left: 60px">It will start the configuration and creation of <kbd>makefile</kbd>. It will locate all the extra modules based on the values in the system path. The output of the <kbd>cmake</kbd> command with selected CUDA installation is shown in the following screenshot:</p>
<div><img class="alignnone size-full wp-image-321 image-border" src="img/06be479f-05cd-42fc-a510-53ccc596d596.png" style="" width="1366" height="768"/></div>
<ol start="6">
<li>CMake will create a makefile in the build directory after successful configuration. To compile OpenCV using this makefile, execute the command <kbd>make -j8</kbd> from the command window, as shown:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-322 image-border" src="img/55fffc1b-2d4a-4160-85a5-4ee9d82fca62.png" style="width:113.83em;height:64.00em;" width="1366" height="768"/></p>
<ol start="7">
<li> After successful compilation, to install OpenCV, you have to execute the command <kbd>sudo make install</kbd> from the command line. The following will be the output of that command:</li>
</ol>
<div><img class="alignnone size-full wp-image-323 image-border" src="img/90375fda-7aac-4c29-bd19-2deb9aa8974b.png" style="" width="1366" height="768"/></div>
<ol start="8">
<li>Run the <kbd>sudo ldconfig</kbd>  command to finish the installation. It creates the necessary links and cache to the <kbd>opencv</kbd> libraries.</li>
<li>You can check the installation by running any example from the <kbd>opencv/samples/gpu</kbd> folder. </li>
</ol>
<p>For using OpenCV in the program, you have to include the <kbd>opencv2/opencv.hpp</kbd> header file. This header file will include all other header files necessary for the program. So all the OpenCV programs have to include this header file on the top. </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Working with images in OpenCV</h1>
                
            
            
                
<p>Now that OpenCV is installed on the system, we can start using it to work with images. In this section, we will learn how images are represented inside OpenCV, develop programs to read an image, display an image, and save an image to disk. We will also see the method for creating synthetic images in OpenCV. We will also use OpenCV to draw different shapes on an image. Along with this, important syntax and features of OpenCV will be explained.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Image representation inside OpenCV</h1>
                
            
            
                
<p>As described earlier, images are nothing but two-dimensional arrays, so they should be stored as an array inside a computer for processing. OpenCV provides a <kbd>Mat</kbd> class, which is nothing but an image container used to store an image.  The <kbd>Mat</kbd> object can be created and assigned to an image in two separate lines as follows:</p>
<pre>Mat img;<br/>img= imread("cameraman.tif");</pre>
<p>The data type of an image and size of the two-dimensional array can also be defined while creating an object. The data type of an image is very important as it signifies the number of channels and number of bits used to specify a single pixel value. Grayscale images have a single channel, while color images are a combination of three separate channels: Red, Green, and Blue.</p>
<p>The number of bits used for a single pixel specifies the number of discrete gray level values. An 8-bit image can have gray levels between 0 and 255, while 16-bit images can have gray levels between 0 to 65,535. OpenCV supports many data types with <kbd>CV_8U</kbd> as default, which indicates an 8-bit unsigned image with a single channel. It is equivalent to <kbd>CV_8UC1</kbd>. The color images can be specified as <kbd>CV_8UC3</kbd>, which indicates an 8-bit unsigned image with three channels. OpenCV supports up to 512 channels. Five or more channels have to be defined in round brackets, for example, <kbd>CV_8UC(5)</kbd> which indicates an 8-bit image with five channels.  OpenCV also supports signed numbers so the  data type can also be <kbd>CV_16SC3</kbd>, which specifies a 16-bit signed image with three channels.</p>
<p>A <kbd>Mat</kbd> object can be used to define the size of an image. This is also called the resolution of an image. It indicates the number of pixels in horizontal and vertical directions. Normally, the resolution of an image is defined in terms of width <kbd>x</kbd> height. While the size of an array in a <kbd>Mat</kbd> object should be defined in terms of the number of rows <kbd>x</kbd> number of columns. Some examples of using Mat to define image containers are shown as follows:</p>
<pre>Mat img1(6,6,CV_8UC1); <br/>//This defines img1 object with size of 6x6, unsigned 8-bit integers and single channel.<br/><br/>Mat img2(256,256, CV_32FC1)<br/>//This defines img2 object with size of 256x256, 32 bit floating point numbers and single channel.<br/><br/>Mat img3(1960,1024, CV_64FC3)<br/>//This defines img3 object with size of 1960x1024, 64 bit floating point numbers and three channels.</pre>
<p>The resolution and size of the image will determine the space needed to save an image on disk. Suppose the size of a color image with three channels is 1024 x 1024, then it will take 3 x 1024 x 1024 bytes = 3 MB to store the image on disk. In the next section, we will see how to use this Mat object and OpenCV to read and display an image. </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Reading and displaying an image</h1>
                
            
            
                
<p>In this section, we will try to develop the code for reading and displaying an image using C++ and OpenCV. The entire code for this is as follows it is then explained line by line: </p>
<pre>#include &lt;opencv2/opencv.hpp&gt;<br/>#include &lt;iostream&gt;<br/><br/>using namespace cv;<br/>using namespace std;<br/><br/>int main(int argc, char** argv)<br/>{<br/>  // Read the image <br/>  Mat img = imread("images/cameraman.tif",0);<br/><br/>  // Check for failure in reading an Image<br/>  if (img.empty()) <br/>  {<br/>    cout &lt;&lt; "Could not open an image" &lt;&lt; endl;<br/>    return -1;<br/>  }<br/>  //Name of the window<br/>  String win_name = "My First Opencv Program"; <br/><br/>  // Create a window<br/>  namedWindow(win_name); <br/><br/>  // Show our image inside the created window.<br/>  imshow(win_name, img); <br/><br/>  // Wait for any keystroke in the window <br/>  waitKey(0); <br/><br/>  //destroy the created window<br/>  destroyWindow(win_name); <br/><br/>  return 0;<br/>}</pre>
<p>The program starts with including header files for standard input-output and image processing. </p>
<p>The functions from the <kbd>std</kbd> namespace, such as <kbd>cout</kbd> and <kbd>endl</kbd>, are used in the program, so the <kbd>std</kbd> namespace is added.  All of the OpenCV classes and functions are defined using the <kbd>cv</kbd> namespace. So, to use functions defined in the <kbd>cv</kbd> namespace, we are specifying the <kbd>using namespace cv</kbd> line. If that line is omitted, then every function in the <kbd>cv</kbd> namespace has to be used in the following way:</p>
<pre>Mat img = cv::imread("cameraman.tif")</pre>
<p>The <kbd>main</kbd> function contains the code for reading and displaying an image. The <kbd>imread</kbd> command is used to read an image in OpenCV. It returns a <kbd>Mat</kbd> object. The <kbd>imread</kbd> command has two arguments. The first argument is the name of an image along with its path. The path can be specified in two ways. You can specify a fully qualified path of an image in your PC or you can specify a relative path of an image from your code file. In the preceding example, the relative path is used, where an image is located in the images folder that is in the same directory as the code file.</p>
<p>The second argument is optional and specifies whether the image is to be read as a grayscale or color image. If the image is to be read as a color image, then specify <kbd>IMREAD_COLOR</kbd> or <kbd>1</kbd>. If the image is to be read as a grayscale image, then specify <kbd>IMREAD_GRAYSCALE</kbd> or <kbd>0</kbd>. If the image is to be read in its saved form, then specify <kbd>IMREAD_UNCHANGED</kbd> or <kbd>-1</kbd> as a second argument. If an image is read as a color image, the <kbd>imread</kbd> command will return three channels starting with <strong>blue, green,</strong> and <strong>red</strong> (<strong>BGR</strong> format). If the second argument is not provided, then the default value is <kbd>IMREAD_COLOR</kbd>   which reads an image as a color image.</p>
<p>If, somehow, the image can't be read or it is not available on the disk, then the <kbd>imread</kbd> command will return a <kbd>Null Mat</kbd> object. If this happens, there is no need to continue with further image processing code and we can exit at this point by notifying the user about the error. This is handled by the code inside the <kbd>if</kbd> loop.</p>
<p>A window in which an image will be displayed should be created. OpenCV provides a function called <kbd>namedWindow</kbd> for that. It requires two arguments. The first argument is the name of the window. It has to be a string. The second argument specifies the size of the window that is to be created. It can take two values: <kbd>WINDOW_AUTOSIZE</kbd> or <kbd>WINDOW_NORMAL</kbd>. If <kbd>WINDOW_AUTOSIZE</kbd> is specified, then the user will not be able to resize the window and the image will be displayed in its original size. If <kbd>WINDOW_NORMAL</kbd> is specified, the user will be able to resize the window. This argument is optional and its default value is <kbd>WINDOW_AUTOSIZE</kbd> if it is not specified.  </p>
<p>To display an image in the created window, the <kbd>imshow</kbd> command is used. This command requires two arguments. The first argument is the name of the window created using the <kbd>namedWindow</kbd> command and the second argument is the image variable that has to be displayed. This variable has to be a <kbd>Mat</kbd> object. For displaying multiple images, separate windows with unique names have to be created. The name of the window will appear as a title on the image window.</p>
<p>The <kbd>imshow</kbd> function should be provided for enough time to display an image in the created window. This is done by using the <kbd>waitKey</kbd> function. So the <kbd>imshow</kbd> function should be followed by the <kbd>waitkey</kbd> function in all OpenCV programs, otherwise the image will not be displayed. <kbd>waitKey</kbd> is a  keyboard binding function and it accepts one argument, which is a time in milliseconds. It will wait, for a specified time, for a keystroke, then it will move to the next line of code. If no argument is specified or 0 is specified, it will wait for an indefinite time period for a keystroke. It will move to the next line only when any key is pressed on the keyboard. We can also detect whether a specific key is pressed and, depending on the key pressed, we can make certain decisions. We will use this feature later on in this chapter.</p>
<p>All the windows created for displaying the windows need to be closed before the termination of the program. This can be done using the <kbd>distroyAllWindows</kbd> function. It will close all the windows created using the <kbd>namedWindow</kbd> function during the program for displaying an image. There is a function called <kbd>distroyWindow</kbd>, which closes specific windows. The name of the window should be provided as an argument to the <kbd>distroyWindow</kbd> function. </p>
<p>For the execution of a program, just copy the code and paste it in Visual Studio if using it on Windows, or make a <kbd>cpp</kbd> file of it in Ubuntu. The build method is similar to a normal <kbd>cpp</kbd> application in Visual Studio, so it is not repeated here. For execution on Ubuntu, execute the following commands on the command prompt from the folder of a saved <kbd>cpp</kbd> file:</p>
<pre>For compilation:<br/><strong>$ g++ -std = c++11 image_read.cpp 'pkg_config --libs --cflags opencv' -o image_read<br/></strong><br/>For execution:<br/><strong>$./image_read</strong></pre>
<p>The output of the preceding program after execution is as follows:</p>
<div><img class="alignnone size-full wp-image-324 image-border" src="img/58a6a2e2-b9d8-4d65-825d-67030a139f50.png" style="" width="256" height="286"/></div>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Reading and displaying a color image</h1>
                
            
            
                
<p>In the preceding program, the second argument for <kbd>imread</kbd> is specified as <kbd>0</kbd>, which means that it will read an image as a grayscale image. Suppose you want to read any color image. To do this, you can change the <kbd>imread</kbd> command in the following way:</p>
<pre>Mat img = imread("images/autumn.tif",1);</pre>
<p>The second argument is specified as <kbd>1</kbd>, which means that it will read an image in BGR form. It is important to note that OpenCV's <kbd>imread</kbd> and <kbd>imshow</kbd> use BGR format for color images, which is different from the RGB format used by MATLAB and other image processing tools. The output after changing <kbd>imread</kbd> is as follows:</p>
<div><img class="alignnone size-full wp-image-325 image-border" src="img/24136c64-3fed-4032-9994-7838909c8bd7.png" style="" width="343" height="235"/></div>
<p>The same image can be read as a grayscale image even though it is a color image by providing <kbd>0</kbd> as a second argument. This will convert an image into grayscale implicitly and then read. The image will look as follows:</p>
<div><img class="alignnone size-full wp-image-326 image-border" src="img/b67b560c-af73-49b1-8b00-e581f251d2f4.png" style="" width="344" height="233"/></div>
<p>It is very important to remember how you are reading the image using the <kbd>imread</kbd> function because it will affect your program's other image processing code.</p>
<p>To summarize, in this section, we saw how to read an image and display it using OpenCV. In the process, we also learned about some important functions available in OpenCV. In the next section, we will see how to create a synthetic image using OpenCV.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Creating images using OpenCV</h1>
                
            
            
                
<p>Sometimes, we may encounter the need to create our own image or draw some shapes on top of existing images. Or we may want to draw bounding boxes around a detected object or display labels on an image. So in this section, we will see how to create blank grayscale and color images. We will also see the functions for drawing lines, rectangles, ellipses, circles, and text on images.</p>
<p>To create an empty black image of the size 256 x 256, the following code can be used:</p>
<pre>#include &lt;opencv2/opencv.hpp&gt;<br/>#include &lt;iostream&gt;<br/><br/>using namespace cv;<br/>using namespace std;<br/><br/>int main(int argc, char** argv)<br/>{<br/>  //Create blank black grayscale Image with size 256x256<br/>  Mat img(256, 256, CV_8UC1, Scalar(0)); <br/>  String win_name = "Blank Image"; <br/>  namedWindow(win_name); <br/>  imshow(win_name, img); <br/>  waitKey(0); <br/>  destroyWindow(win_name); <br/>  return 0;<br/>}</pre>
<p>The code is more or less similar to the code developed for reading an image, but instead of using the <kbd>imread</kbd> command here, the image is created using the constructor of the <kbd>Mat</kbd> class only. As discussed earlier, we can provide the size and data type while creating a <kbd>Mat</kbd> object. So while creating an <kbd>img</kbd> object, we have provided four arguments. The first two arguments specify the size of an image, which first defines the number of rows (height) and second defines the number of columns (width). The third argument defines the data type of an image. We have used <kbd>CV_8UC1</kbd>, which means an 8-bit unsigned integer image with a single channel. The last argument specifies the initialization value for all pixels in an array.</p>
<p>Here we have used 0, which is the value for black. When this program is executed, it will create a black image of size 256 x 256, as follows:</p>
<div><img class="alignnone size-full wp-image-327 image-border" src="img/b9972d80-a784-4e1b-9351-ea9b5f797e87.png" style="" width="254" height="285"/></div>
<p>Similar code can be used for creating blank images of any color, as follows:</p>
<pre>#include &lt;opencv2/opencv.hpp&gt;<br/>#include &lt;iostream&gt;<br/><br/>using namespace cv;<br/>using namespace std;<br/><br/>int main(int argc, char** argv)<br/>{<br/>  //Create blank blue color Image with size 256x256<br/>  Mat img(256, 256, CV_8UC3, Scalar(255,0,0)); <br/>  String win_name = "Blank Blue Color Image"; <br/>  namedWindow(win_name); <br/>  imshow(win_name, img); <br/>  waitKey(0); <br/>  destroyWindow(win_name); <br/>  return 0;<br/>}<br/> </pre>
<p>While creating a <kbd>Mat</kbd> object, instead of using the <kbd>CV_8UC1</kbd> data type, <kbd>CV_8UC3</kbd> is used, which specifies an 8-bit image with three channels. So there are 24 bits for a single pixel. The fourth argument specifies the starting pixel values. It is specified using the scalar keyword and a tuple of three values specifying starting values in all three channels. Here, the blue channel is initialized with 255, the green channel is initialized with 0, and red channel is initialized with 0. This will create an image of size 256 x 256 in blue. Different combinations of values in tuple will create different colors. The output of the preceding program is as follows:</p>
<div><img class="alignnone size-full wp-image-328 image-border" src="img/1e87d4d9-3416-4414-a587-247befa168cd.png" style="" width="250" height="234"/></div>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Drawing shapes on the blank image</h1>
                
            
            
                
<p>To start drawing different shapes on an image, we will start by creating a blank black image of arbitrary size with the following command:</p>
<pre>Mat img(512, 512, CV_8UC3, Scalar(0,0,0)); </pre>
<p>This command will create a black image of the size 512 x 512. Now, we will start by drawing different shapes on this image. </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Drawing a line</h1>
                
            
            
                
<p>A line can be specified by two points: the start point and end point. To draw a line on the image, these two points have to be specified. The function to draw a line on an image is as follows:</p>
<pre>line(img,Point(0,0),Point(511,511),Scalar(0,255,0),7);</pre>
<p>The line function has five arguments. The first argument specifies the image on which a line needs to be drawn, the second and third arguments define the start point and end points, respectively. The points are defined using the <kbd>Point</kbd> class constructor, which takes <em>x</em> and <em>y</em> coordinates of an image as argument. The fourth argument specifies the color of the line. It is specified as a tuple of B, G, and R values. Here, the value taken is <kbd>(0,255,0)</kbd>, which specifies green. The fifth argument is the thickness of the line. Its value is taken as 7 pixels wide. This function also has an optional <kbd>linetype</kbd> argument. The preceding function will draw a diagonal green line of 7 pixels wide from <kbd>(0,0)</kbd> to <kbd>(511,511)</kbd>.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Drawing a rectangle</h1>
                
            
            
                
<p>A rectangle can be specified using two extreme diagonal points. OpenCV provides a function for drawing a rectangle on an image that has syntax as follows:</p>
<pre>rectangle(img,Point(384,0),Point(510,128),Scalar(255,255,0),5);</pre>
<p>The rectangle function has five arguments. The first argument is the image on which the rectangle is to be drawn. The second argument is the top-left point of the rectangle. The third argument is the bottom-right point of the rectangle. The fourth argument specifies the color of the border. It is specified as <kbd>(255,255,0)</kbd>, which is a mix of blue and green, giving cyan. The fifth argument is the thickness of the border. If the fifth argument is specified as <kbd>-1</kbd>, the shape will be filled with color. So the preceding function will draw a rectangle with two extreme points, <kbd>(384,0)</kbd> and <kbd>(510,128)</kbd>, in cyan with a border thickness of 5 pixels.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Drawing a circle</h1>
                
            
            
                
<p>A circle can be specified by a center and its radius. OpenCV provides a function for drawing a circle on an image that has syntax as follows:</p>
<pre>circle(img,Point(447,63), 63, Scalar(0,0,255), -1);</pre>
<p>The circle function has five arguments. The first argument is the image on which a circle needs to be drawn. The second argument specifies the center point for that circle and the third argument specifies the radius. The fourth argument specifies the color of the circle. The value taken is <kbd>(0,0,255)</kbd>, which is red. The fifth argument is the thickness of the border. Here, it is <kbd>-1</kbd>, which means the circle will be filled with red color. </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Drawing an ellipse</h1>
                
            
            
                
<p>OpenCV provides a function for drawing an ellipse on an image that has syntax as follows:</p>
<pre>ellipse(img,Point(256,256),Point(100,100),0,0,180,255,-1);</pre>
<p>The ellipse function has many arguments. The first argument specifies the image on which an ellipse needs to be drawn. The second argument specifies the center of the ellipse. The third argument specifies the box size under which the ellipse will be drawn. The fourth argument specifies the angle by which the ellipse needs to be rotated. It is taken as <kbd>0</kbd> degrees. The fifth and sixth argument specifies the range of angles for which the ellipse needs to be drawn. It is taken as <kbd>0</kbd> to <kbd>180</kbd> degrees. So only half the ellipse will be drawn. The next argument specifies the color of the ellipse, which is specified only as <kbd>255.</kbd> It is the same as <kbd>(255,0,0)</kbd>, which is blue.  The final argument specifies the thickness of the border. It is taken as <kbd>-1</kbd>, so the ellipse will be filled with blue.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Writing text on an image</h1>
                
            
            
                
<p>OpenCV provides a function for writing text on an image, which is <kbd>putText</kbd>. The syntax for the function is as follows:</p>
<pre>putText( img, "OpenCV!", Point(10,500), FONT_HERSHEY_SIMPLEX, 3,Scalar(255, 255, 255), 5, 8 );</pre>
<p>The <kbd>putText</kbd> function has many arguments. The first argument is the image on which text is to be written. The second argument is the text as a String data type, which we want to write on an image. The third argument specifies the bottom-left corner of the text. The fourth argument specifies the font type. There are many font types available in OpenCV, for which you can check OpenCV documentation.  The fifth argument specifies the scale of the font. The sixth argument is the color of the text. It is taken as <kbd>(255,255,255)</kbd>, which makes white. The seventh argument is the thickness of the text, which is taken as <kbd>5</kbd>, and the last argument specifies linetype, which is taken as <kbd>8</kbd>.</p>
<p>We have seen separate functions for drawing shapes on an empty black image. The following code shows the combination of all the functions previously discussed:</p>
<pre>#include &lt;opencv2/opencv.hpp&gt;<br/>#include &lt;iostream&gt;<br/><br/>using namespace cv;<br/>using namespace std;<br/><br/>int main(int argc, char** argv)<br/>{<br/> <br/>  Mat img(512, 512, CV_8UC3, Scalar(0,0,0)); <br/>  line(img,Point(0,0),Point(511,511),Scalar(0,255,0),7);<br/>  rectangle(img,Point(384,0),Point(510,128),Scalar(255,255,0),5);<br/>  circle(img,Point(447,63), 63, Scalar(0,0,255), -1);<br/>  ellipse(img,Point(256,256),Point(100,100),0,0,180,255,-1);<br/>  putText( img, "OpenCV!", Point(10,500), FONT_HERSHEY_SIMPLEX, 3,Scalar(255, 255,  255), 5, 8 );<br/>  String win_name = "Shapes on blank Image"; <br/>  namedWindow(win_name); <br/>  imshow(win_name, img); <br/>  waitKey(0); <br/>  destroyWindow(win_name); <br/>  return 0;<br/>}</pre>
<p>The output image for the preceding code is as follows:</p>
<div><img class="alignnone size-full wp-image-329 image-border" src="img/64132bc6-ebc6-4a44-af34-897ba587faa8.png" style="" width="515" height="519"/></div>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Saving an image to a file</h1>
                
            
            
                
<p>Images can also be saved to a disk from the OpenCV program. This is helpful when we want to store our processed image to a disk on a computer. OpenCV provides the <kbd>imwrite</kbd> function to do this operation. The syntax of this function is as follows:</p>
<pre class="prettyprint prettyprinted">bool flag = imwrite("images/save_image.jpg", img);</pre>
<p>The <kbd>imwrite</kbd> function takes two arguments. The first argument is the name of the file you want to save along with its path. The second argument is the <kbd>img</kbd> variable that you want to save. This function returns a Boolean value that indicates whether the file is saved successfully or not on a disk. </p>
<p>In this section, we have worked with images using OpenCV. In the next section, we will work with videos, which are nothing but a sequence of images, using OpenCV.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Working with videos in OpenCV</h1>
                
            
            
                
<p>This section will show the process for reading videos from a file and webcam using OpenCV. It will also describe the process for saving videos to a file. This can also work with USB cameras attached to computers. Videos are nothing more than a sequence of images. Though OpenCV is not optimized for video processing applications, it does a decent job with it. OpenCV is not able to capture audio, so we have to use some other utilities with OpenCV to capture both audio and video.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Working with video stored on a computer</h1>
                
            
            
                
<p>This section describes the process of reading a video file stored on a computer. All the frames from a video will be read one by one, operated upon, and displayed on the screen in all video processing applications using OpenCV.</p>
<p>The following code is for reading and displaying video—a line-by-line explanation is then given:</p>
<pre>#include &lt;opencv2/opencv.hpp&gt;<br/>#include &lt;iostream&gt;<br/>using namespace cv;<br/>using namespace std;<br/>int main(int argc, char* argv[])<br/>{<br/>  //open the video file from PC<br/>  VideoCapture cap("images/rhinos.avi"); <br/>  // if not success, exit program<br/>  if (cap.isOpened() == false) <br/>  {<br/>    cout &lt;&lt; "Cannot open the video file" &lt;&lt; endl;<br/>    return -1;<br/>  }<br/>  cout&lt;&lt;"Press Q to Quit" &lt;&lt; endl;<br/>  String win_name = "First Video";<br/>  namedWindow(win_name); <br/>  while (true)<br/>  {<br/>    Mat frame;<br/>    // read a frame<br/>    bool flag = cap.read(frame); <br/><br/>    //Breaking the while loop at the end of the video<br/>    if (flag == false) <br/>    {<br/>      break;<br/>    }<br/>    //display the frame <br/>    imshow(win_name, frame);<br/>    //Wait for 100 ms and key 'q' for exit<br/>    if (waitKey(100) == 'q')<br/>    {<br/>      break;<br/>    }<br/>  }<br/>  destroyWindow(win_name);<br/>  return 0;<br/>}</pre>
<p>After including libraries, the first thing that needs to be done inside the main function for processing video is to create an object of <kbd>VideoCapture</kbd>. The <kbd>VideoCapture</kbd> class has many constructors available for working with videos. When we want to work with video files stored on a computer, we need to provide the name of the video along with its path as an argument to the constructor while creating an object of <kbd>VideoCapture</kbd>.</p>
<p>This object provides many methods and properties that give information related to a video. We will see those as and when they are required. It provides the <kbd>isopened</kbd> property, which indicates whether the object creation was successful and whether or not video is available. It returns a Boolean value. If <kbd>cap.isopened</kbd> is <kbd>false</kbd>, the video is not available so there is no need to go any further in the program. So that is handled by an <kbd>if</kbd> loop, which exits the program after notifying the user when a video is not available. </p>
<p>The <kbd>VideoCapture</kbd> class provides a read method that captures the frames one by one. To process the entire video, we have to start a continuous loop that runs until the end of the video. The infinite <kbd>while</kbd> loop can do this job. Inside the <kbd>while</kbd> loop, the first frame is read using the read method. This method has one argument. It is a Mat object in which we want to store the frame. It returns a Boolean value that indicates whether the frame has been read successfully or not. When the loop has reached the end of video, this Boolean will return <kbd>false</kbd>, indicating there is no frame available. This flag is checked continuously in the loop for the end of the video; and if it is detected, we come out of the <kbd>while</kbd> loop using the <kbd>break</kbd> statement.</p>
<p>The frame is a single image, so displaying the process for that is the same as we saw earlier. In the preceding code, the <kbd>waitKey</kbd> function is used inside an <kbd>if</kbd> statement. It is waiting for 100 ms after every frame for a keystroke. The <kbd>if</kbd> statement is checking whether the keystroke is <kbd>q</kbd> or not. If it is <kbd>q</kbd>, it means that the user wants to quit the video so the break statement is included inside <kbd>if</kbd>.</p>
<p>This code will terminate display of the video either when the whole video is finished or the user presses <kbd>q</kbd> on the keyboard. Throughout this book, we will use this coding practice while processing videos. The output of the preceding program is as follows. The screenshot is a frame from a video:</p>
<div><img class="alignnone size-full wp-image-330 image-border" src="img/0fb84cb8-4eb4-4e8b-8652-97e2aac8a371.png" style="" width="318" height="266"/></div>
<p>We have used 100 ms delay between every frame. What do you think will happen when you decrease this value to, maybe, 10 ms? The answer is, each frame will be displayed faster. It does not mean the frame rate of the video changes. It just means that the delay between frames is reduced. If you want to see the actual frame rate of the video, you can use the <kbd>CAP_PROP_FPS</kbd> property of the <kbd>cap</kbd> object. It can be displayed with the following code:</p>
<pre class="prettyprint prettyprinted">double frames_per_second = cap.get(CAP_PROP_FPS); 
cout &lt;&lt; "Frames per seconds of the video is : " &lt;&lt; frames_per_second ;</pre>
<p>The <kbd>cap</kbd> object also has other properties, such as <kbd>CAP_PROP_FRAME_WIDTH</kbd> and <kbd>CAP_PROP_FRAME_HEIGHT</kbd>, which indicate the width and height of the frames. It can also be fetched with the <kbd>get</kbd> method. These properties can be set by using a <kbd>set</kbd> method of cap object. The <kbd>set</kbd> method has two arguments. The first argument is the <kbd>name</kbd> of the property and the second argument is the <kbd>value</kbd> we want to set.</p>
<p>This section described the method to read a video from a file. The next section will show the process for working with videos from either a webcam or USB camera.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Working with videos from a webcam</h1>
                
            
            
                
<p>This section describes the process for capturing a video from a webcam or USB camera attached to a computer. The good part of OpenCV is that this same code will work for laptop and any embedded system that can run C/C++. This helps in deploying computer vision applications on any hardware platforms. The code for capturing video and displaying it is as follows: </p>
<pre>#include &lt;opencv2/opencv.hpp&gt;<br/>#include &lt;iostream&gt;<br/><br/>using namespace cv;<br/>using namespace std;<br/><br/>int main(int argc, char* argv[])<br/>{<br/>  //open the Webcam<br/>  VideoCapture cap(0); <br/>  // if not success, exit program<br/>  if (cap.isOpened() == false) <br/>  {<br/>    cout &lt;&lt; "Cannot open Webcam" &lt;&lt; endl;<br/>    return -1;<br/>  }<br/>  //get the frames rate of the video from webcam<br/>  double frames_per_second = cap.get(CAP_PROP_FPS); <br/>  cout &lt;&lt; "Frames per seconds : " &lt;&lt; frames_per_second &lt;&lt; endl;<br/>  cout&lt;&lt;"Press Q to Quit" &lt;&lt;endl;<br/>  String win_name = "Webcam Video";<br/>  namedWindow(win_name); //create a window<br/>  while (true)<br/>  {<br/>    Mat frame;<br/>    bool flag = cap.read(frame); // read a new frame from video <br/>    //show the frame in the created window<br/>    imshow(win_name, frame);<br/>    if (waitKey(1) == 'q')<br/>    {<br/>      break;<br/>    }<br/>  }<br/>  return 0;<br/>}</pre>
<p>While capturing video from a webcam or USB camera, the device ID for that camera needs to be provided as an argument to the constructor of the <kbd>VideoCapture</kbd> object. The primary camera connected will have a device ID zero. The webcam of a laptop or USB camera (when there is no webcam) will have device ID zero. If there are multiple cameras connected to a device, their device ID will be <kbd>(0,1)</kbd>, and so on. In the preceding code, zero indicates that the primary camera will be used by the code to capture the video. </p>
<p>The other code is more or less similar to the code for reading video from a file. Here, the frame rate of the video is also fetched and displayed.  The frames will be read one by one at a 1 ms interval and displayed on the window created. You have to press <kbd>q</kbd> to terminate the operation. The output of video captured using the webcam is as follows:</p>
<div><img class="alignnone size-full wp-image-331 image-border" src="img/bbd291d5-2c10-41d3-a2ed-85d868e0a1e4.png" style="" width="638" height="509"/></div>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Saving video to a disk</h1>
                
            
            
                
<p>To save video from the OpenCV program, we need to create an object of the <kbd>VideoWriter</kbd> class. The code to save a video to a file is as follows:  </p>
<pre class="prettyprint prettyprinted">Size frame_size(640, 640);
int frames_per_second = 30;

VideoWriter v_writer("images/video.avi", VideoWriter::fourcc('M', 'J', 'P', 'G'), frames_per_second, frame_size, true); <br/><br/>//Inside while loop<br/>v_writer.write(frame); <br/><br/>//After finishing video write<br/>v_writer.release();<br/></pre>
<p>While creating an object of the <kbd>VideoWriter</kbd> class, the constructor takes five arguments. The first argument is the name of the video file you want to save along with the absolute or relative path. The second argument is the four character code used for video codec. It is created using the <kbd>VideoWriter::fourcc</kbd> function. Here we are using motion JPEG codec, so the four character code for it is <kbd>'M'</kbd>, <kbd>'J'</kbd>, <kbd>'P'</kbd>, and <kbd>'G'</kbd>. There are other codecs that can be used depending on your requirements and operating system. The third argument is frames per second. It can be specified as an integer variable previously defined or an integer value directly in the function. In the preceding code, <kbd>30</kbd> frames per second is used. The fourth argument is the size of the frame. It is defined using the <kbd>size</kbd> keyword with two arguments, <kbd>frame_width</kbd> and <kbd>frame_height</kbd>. It is taken as 640 x 640 in the preceding code. The fifth argument specifies whether the frame to be stored is color or grayscale. If its true, the frame is saved as a color frame.</p>
<p>To start writing frames using the <kbd>VideoWriter</kbd> object, OpenCV provides a <kbd>write</kbd> method. This method is used to write frames into video one by one, so it is included inside an infinite <kbd>while</kbd> loop. This method takes only one argument, which is the name of the frame variable. The size of the frame should be the same as the size specified while creating the <kbd>VideoWriter</kbd> object. It is important to flush and close the video file created after writing is finished. This can be done by releasing the created <kbd>VideoWriter</kbd> object using the <kbd>release</kbd> method. </p>
<p>To summarize, in this section we looked at the process of reading video from a file or camera attached to a device. We have also seen the code for writing a video to a file. From the next section onward, we will see how we can operate on images or videos using OpenCV with CUDA acceleration.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Basic computer vision applications using the OpenCV CUDA module</h1>
                
            
            
                
<p>In earlier chapters, we saw that CUDA provides an excellent interface to utilize the parallel computing capability of GPU to accelerate complex computing applications. In this section, we will see how we can utilize the capability of CUDA alongside OpenCV for computer vision applications.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Introduction to the OpenCV CUDA module</h1>
                
            
            
                
<p>OpenCV has a CUDA module that has hundreds of functions that can utilize GPU capabilities. It is only supported on Nvidia GPUs because it uses Nvidia CUDA runtime in the background. OpenCV has to be compiled with the <kbd>WITH_CUDA</kbd> flag set to ON for using the CUDA module.</p>
<p>One great feature of using the CUDA module of OpenCV is that it provides a similar API to regular OpenCV API. It also does not require detailed knowledge of programming in CUDA, although knowledge of CUDA and GPU architecture will not do any harm. The researchers have shown that using functions with CUDA acceleration can provide 5x-100x speedup over similar CPU functions. </p>
<p>In the next section, we will see how to use the CUDA module along with OpenCV in various computer vision and image processing applications that operate on individual pixels of an image.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Arithmetic and logical operations on images</h1>
                
            
            
                
<p>In this section, we will see how to perform various arithmetic and logical operations on images. We will use functions defined in the CUDA module of OpenCV to perform these operations. </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Addition of two images</h1>
                
            
            
                
<p>The addition of two images can be performed when two images are of the same size. OpenCV provides an <kbd>add</kbd> function inside the <kbd>cv::cuda</kbd> namespace for addition operation. It performs pixel-wise addition of two images. Suppose in two images, the pixel at <kbd>(0,0)</kbd> has intensity values 100 and 150 respectively. The intensity value in the resultant image will be 250, which is the addition of two intensity values. OpenCV addition is a saturated operation, which means that if an answer of addition goes above 255, it will be saturated at 255. The code to perform addition is as follows: </p>
<pre>#include &lt;iostream&gt;<br/>#include "opencv2/opencv.hpp"<br/><br/>int main (int argc, char* argv[])<br/>{<br/>  //Read Two Images <br/>  cv::Mat h_img1 = cv::imread("images/cameraman.tif");<br/>  cv::Mat h_img2 = cv::imread("images/circles.png");<br/>  //Create Memory for storing Images on device<br/>  cv::cuda::GpuMat d_result1,d_img1, d_img2;<br/>  cv::Mat h_result1;<br/>  //Upload Images to device     <br/>  d_img1.upload(h_img1);<br/>  d_img2.upload(h_img2);<br/><br/>  cv::cuda::add(d_img1,d_img2, d_result1);<br/>  //Download Result back to host<br/>  d_result1.download(h_result1);<br/>  cv::imshow("Image1 ", h_img1);<br/>  cv::imshow("Image2 ", h_img2);<br/>  cv::imshow("Result addition ", h_result1);<br/>  cv::imwrite("images/result_add.png", h_result1);<br/>  cv::waitKey();<br/>  return 0;<br/>}</pre>
<p>When any computer vision operation needs to be performed on GPU, the images have to be stored on device memory. The memory for it can be allocated with the <kbd>gpumat</kbd> keyword, which is similar to the Mat type used for host memory. The images are read in the same way as earlier. Two images are read for addition and stored in host memory. These images are copied to device memory using the <kbd>upload</kbd> method of device <kbd>memory</kbd> variable. The host image variable is passed as a parameter to this method.</p>
<p>The function in the GPU CUDA module is defined in the <kbd>cv::cuda</kbd> namespace. It requires images on device memory as its arguments. The add function from the CUDA module is used for image addition. It requires three arguments. The first two arguments are two images that are to be added and the last argument is the destination in which the result will be stored. All three variables should be defined using <kbd>gpumat</kbd>.</p>
<p>The resultant image is copied back to the host using the download method of the device variable. The host <kbd>img</kbd> variable, in which the result will be copied, is provided as an argument to the download method. Then this image is displayed and stored on the disk using the same functions explained in the last section. The output of the program is as follows:</p>
<div><img class="alignnone size-full wp-image-332 image-border" src="img/11f0673e-6243-40ea-a63c-3ed65d56effe.png" style="" width="803" height="291"/></div>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Subtracting two images</h1>
                
            
            
                
<p>Other arithmetic operations can be performed on images using OpenCV and CUDA. The <kbd>subtract</kbd> function is provided by OpenCV to subtract two images. It is also a saturated operation, which means that when the answer of subtraction goes below zero, it will be saturated to zero. The syntax of the subtract command is as follows: </p>
<pre>//d_result1 = d_img1 - d_img2<br/>cv::cuda::subtract(d_img1, d_img2,d_result1);</pre>
<p>Again, two images to be subtracted are provided as the first two arguments and the resultant image is provided as the third argument. The result of the subtraction between two images is as follows:</p>
<div><img class="alignnone size-full wp-image-333 image-border" src="img/c0ea336f-3adf-482f-b9f8-e36d6f7dfc19.png" style="" width="817" height="296"/></div>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Image blending</h1>
                
            
            
                
<p>Sometimes there is a need to blend two images with different proportions, instead of directly adding two images. Image blending can be represented mathematically by the following equation:</p>
<pre>result = α * img1 + β * img2 + γ </pre>
<p>This can be easily accomplished with the <kbd>addWeighted</kbd> function inside OpenCV. The syntax of the function is as follows:</p>
<pre>cv::cuda::addWeighted(d_img1,0.7,d_img2,0.3,0,d_result1)</pre>
<p>The function has six arguments. The first argument is the first source image, the second argument is a weight of the first image for blending, the third argument is the second source image, the fourth argument is a weight of the second image for blending, and the fifth argument is the constant gamma to be added while blending. The final argument specifies the destination in which the result needs to be stored. The function given takes 70 percent of <kbd>img1</kbd> and 30 percent of <kbd>img2</kbd> for blending. The output for this function is as follows:</p>
<div><img class="alignnone size-full wp-image-334 image-border" src="img/a4c7e83e-3a4d-48aa-ac63-21bfee47ade3.png" style="" width="811" height="288"/></div>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Image inversion</h1>
                
            
            
                
<p>Apart from arithmetic operations, OpenCV also provides Boolean operations that work on individual bits. It includes AND, OR, NOT, and so on. AND and OR are very useful for masking operations, as we will see later on. The NOT operation is used for inverting an image where black is converted to white and white is converted to black. It can be represented by the following equation:</p>
<pre>result_image = 255 - input_image</pre>
<p>In the equation, <kbd>255</kbd> indicates maximum intensity value for an 8-bit image. The program for doing image inversion is as follows: </p>
<pre>#include &lt;iostream&gt;<br/>#include "opencv2/opencv.hpp"<br/><br/>int main (int argc, char* argv[])<br/>{<br/>  cv::Mat h_img1 = cv::imread("images/circles.png");<br/>  //Create Device variables<br/>  cv::cuda::GpuMat d_result1,d_img1;<br/>  cv::Mat h_result1;     <br/>  //Upload Image to device<br/>  d_img1.upload(h_img1);<br/><br/>  cv::cuda::bitwise_not(d_img1,d_result1);<br/>    <br/>  //Download result back  to host<br/>  d_result1.download(h_result1);<br/>  cv::imshow("Result inversion ", h_result1);<br/>  cv::imwrite("images/result_inversion.png", h_result1);<br/>  cv::waitKey();<br/>  return 0;<br/>}</pre>
<p>The program is similar to the program for arithmetic operations. The <kbd>bitwise_not</kbd> function is used for image inversion. The image should be a grayscale image. It takes two arguments. The first argument indicates the source image to be inverted and the second argument indicates the destination in which the inverted image is to be stored. The output of the <kbd>bitwise_not</kbd> operation is as follows:</p>
<div><img class="alignnone size-full wp-image-335 image-border" src="img/3c8c110f-a1f8-4b8d-a6d0-cd6e5b734a5d.png" style="" width="532" height="288"/></div>
<p>As can be seen, by doing an inversion, white is converted to black and black is converted to white.</p>
<p>To summarize, in this section, we have seen various arithmetic and logical operations using OpenCV and CUDA. In the next section, we will see some more computer vision operations that are widely used in computer vision applications.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Changing the color space of an image</h1>
                
            
            
                
<p>As described earlier, OpenCV can read an image as a grayscale image or as a color image, with three channels green, blue, and red, which is called BGR format. Other image processing software and algorithms work on RGB images, where the red channel is followed by green and blue. There are many other color formats that can be used for certain applications. These include the HSV color space, where the three channels are Hue, Saturation, and Value. Hue represents color value, saturation indicates the gray level in the color, and value represents the brightness of the color. The other color space is YCrCb, which is also very useful. This system represents colors in an image in terms of one luminance component: luma (Y), and two chrominance components: chroma(Cb and Cr).</p>
<p>There are many other color spaces available that are supported by OpenCV, such as XYZ, HLS, Lab and so on. OpenCV supports more than 150 color conversion methods. The conversion from one color space to another can be accomplished by using the <kbd>cvtColor</kbd> function available in OpenCV. An example of using this function for changing between various color space is as follows:</p>
<pre>#include &lt;iostream&gt;<br/>#include "opencv2/opencv.hpp"<br/><br/>int main (int argc, char* argv[])<br/>{<br/>  cv::Mat h_img1 = cv::imread("images/autumn.tif");<br/>  //Define device variables<br/>  cv::cuda::GpuMat d_result1,d_result2,d_result3,d_result4,d_img1;<br/>  //Upload Image to device<br/>  d_img1.upload(h_img1);<br/><br/>  //Convert image to different color spaces<br/>  cv::cuda::cvtColor(d_img1, d_result1,cv::COLOR_BGR2GRAY);<br/>  cv::cuda::cvtColor(d_img1, d_result2,cv::COLOR_BGR2RGB);<br/>  cv::cuda::cvtColor(d_img1, d_result3,cv::COLOR_BGR2HSV);<br/>  cv::cuda::cvtColor(d_img1, d_result4,cv::COLOR_BGR2YCrCb);<br/>        <br/>  cv::Mat h_result1,h_result2,h_result3,h_result4;<br/>  //Download results back to host<br/>  d_result1.download(h_result1);<br/>  d_result2.download(h_result2);<br/>  d_result3.download(h_result3);<br/>  d_result4.download(h_result4);<br/> <br/>  cv::imshow("Result in Gray ", h_result1);<br/>  cv::imshow("Result in RGB", h_result2);<br/>  cv::imshow("Result in HSV ", h_result3);<br/>  cv::imshow("Result in YCrCb ", h_result4);<br/>        <br/>  cv::waitKey();<br/>  return 0;<br/>}</pre>
<p>The <kbd>imshow</kbd> function expects color images in BGR color format, so the output of other color formats using <kbd>imshow</kbd> might not be visually attractive.  The output of the preceding program with the same image in different color formats is as follows:</p>
<div><img class="alignnone size-full wp-image-336 image-border" src="img/404cfcdd-2a72-4031-999f-029adccc4214.png" style="" width="1084" height="465"/></div>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Image thresholding</h1>
                
            
            
                
<p>Image thresholding is a very simple image segmentation technique used to extract important regions from a grayscale image based on certain intensity values. In this technique, if the pixel value is greater than a certain threshold value, it is assigned one value, otherwise it is assigned another value.</p>
<p>The function used for image thresholding in OpenCV and CUDA is <kbd>cv::cuda::threshold.</kbd> This function has many arguments. The first argument is the source image, which should be a grayscale image. The second argument is the destination in which the result is to be stored. The third argument is the threshold value, which is used to segment the pixel values. The fourth argument is the <kbd>maxVal</kbd> constant, which represents the value to be given if the pixel value is more than the threshold value. OpenCV provides different types of thresholding techniques and it is decided by the last argument of the function. These thresholding types are as follows:</p>
<ul>
<li><kbd>cv:.THRESH_BINARY</kbd>: If the intensity of the pixel is greater than the threshold, set that pixel intensity equal to the <kbd>maxVal</kbd> constant. Otherwise set that pixel intensity to zero.</li>
<li><kbd>cv::THRESH_BINARY_INV</kbd>: If the intensity of the pixel is greater than the threshold, set that pixel intensity equal to zero. Otherwise set that pixel intensity to <kbd>maxVal</kbd> constant.</li>
<li><kbd>cv::THRESH_TRUNC</kbd>: This is basically a truncation operation. If the intensity of the pixel is greater than the threshold, set that pixel intensity equal to the threshold. Otherwise, keep the intensity value as it is.</li>
<li><kbd>cv::THRESH_TOZERO</kbd>: If the intensity of the pixel is greater than the threshold, keep the pixel intensity as it is. Otherwise set that pixel intensity to zero.</li>
<li><kbd>cv::THRESH_TOZERO_INV</kbd>: If the intensity of the pixel is greater than the threshold, set that pixel intensity equal to zero. Otherwise keep the pixel intensity as it is.</li>
</ul>
<p class="mce-root">The program to implement all these thresholding techniques using OpenCV and CUDA is as follows:</p>
<pre>#include &lt;iostream&gt;<br/>#include "opencv2/opencv.hpp"<br/><br/>int main (int argc, char* argv[])<br/>{<br/>  cv::Mat h_img1 = cv::imread("images/cameraman.tif", 0);<br/>  //Define device variables<br/>  cv::cuda::GpuMat d_result1,d_result2,d_result3,d_result4,d_result5, d_img1;<br/>  //Upload image on device<br/>  d_img1.upload(h_img1);<br/><br/>  //Perform different thresholding techniques on device<br/>  cv::cuda::threshold(d_img1, d_result1, 128.0, 255.0, cv::THRESH_BINARY);<br/>  cv::cuda::threshold(d_img1, d_result2, 128.0, 255.0, cv::THRESH_BINARY_INV);<br/>  cv::cuda::threshold(d_img1, d_result3, 128.0, 255.0, cv::THRESH_TRUNC);<br/>  cv::cuda::threshold(d_img1, d_result4, 128.0, 255.0, cv::THRESH_TOZERO);<br/>  cv::cuda::threshold(d_img1, d_result5, 128.0, 255.0, cv::THRESH_TOZERO_INV);<br/><br/>  cv::Mat h_result1,h_result2,h_result3,h_result4,h_result5;<br/>  //Copy results back to host<br/>  d_result1.download(h_result1);<br/>  d_result2.download(h_result2);<br/>  d_result3.download(h_result3);<br/>  d_result4.download(h_result4);<br/>  d_result5.download(h_result5);<br/>  cv::imshow("Result Threshhold binary ", h_result1);<br/>  cv::imshow("Result Threshhold binary inverse ", h_result2);<br/>  cv::imshow("Result Threshhold truncated ", h_result3);<br/>  cv::imshow("Result Threshhold truncated to zero ", h_result4);<br/>  cv::imshow("Result Threshhold truncated to zero inverse ", h_result5);<br/>  cv::waitKey();<br/><br/>  return 0;<br/>}</pre>
<p>In the <kbd>cv::cuda::threshold</kbd> function for all thresholding techniques, 128 is taken as a threshold for pixel intensity, which is a midpoint between black (0) and white (255). The <kbd>maxVal</kbd> constant is taken as 255, which will be used to update pixel intensity when it exceeds the threshold. The other program is similar to other OpenCV programs seen earlier.</p>
<p>The output of the program is as follows, which displays the input image along with the output of all five thresholding techniques:</p>
<div><img class="alignnone size-full wp-image-337 image-border" src="img/692261da-2d53-4030-8607-b9325fd0ac3f.png" style="" width="802" height="577"/></div>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Performance comparison of OpenCV applications with and without CUDA support</h1>
                
            
            
                
<p>The performance of image processing algorithms can be measured in terms of the time it takes to process a single image. When algorithms work on video, performance is measured in terms of frames per second, which indicates the number of frames it can process in a second. When the algorithm can process more than 30 frames per second, it can be considered to work in real time. We can also measure the performance of our algorithms implemented in OpenCV, which will be discussed in this section.</p>
<p>As we discussed earlier, when OpenCV is built with CUDA compatibility, it can increase the performance of algorithms drastically. OpenCV functions in the CUDA module are optimized to utilize GPU parallel processing capability. OpenCV also provides similar functions that only run on CPU. In this section, we will compare the performance of thresholding operations built in the last section with and without using GPU. We will compare the performance of the thresholding operation in terms of the time taken to process one image and frames per second. The code to implement thresholding on CPU and measure performance is as follows:</p>
<pre>#include &lt;iostream&gt;<br/>#include "opencv2/opencv.hpp"<br/>using namespace cv;<br/>using namespace std;<br/><br/>int main (int argc, char* argv[])<br/>{<br/>  cv::Mat src = cv::imread("images/cameraman.tif", 0);<br/>  cv::Mat result_host1,result_host2,result_host3,result_host4,result_host5;<br/><br/>  //Get initial time in miliseconds<br/>  int64 work_begin = getTickCount(); <br/>  cv::threshold(src, result_host1, 128.0, 255.0, cv::THRESH_BINARY);<br/>  cv::threshold(src, result_host2, 128.0, 255.0,   cv::THRESH_BINARY_INV);<br/>  cv::threshold(src, result_host3, 128.0, 255.0, cv::THRESH_TRUNC);<br/>  cv::threshold(src, result_host4, 128.0, 255.0, cv::THRESH_TOZERO);<br/>  cv::threshold(src, result_host5, 128.0, 255.0, cv::THRESH_TOZERO_INV);<br/><br/>  //Get time after work has finished     <br/>  int64 delta = getTickCount() - work_begin;<br/>  //Frequency of timer<br/>  double freq = getTickFrequency();<br/>  double work_fps = freq / delta;<br/>  std::cout&lt;&lt;"Performance of Thresholding on CPU: " &lt;&lt;std::endl;<br/>  std::cout &lt;&lt;"Time: " &lt;&lt; (1/work_fps) &lt;&lt;std::endl;<br/>  std::cout &lt;&lt;"FPS: " &lt;&lt;work_fps &lt;&lt;std::endl;<br/>  return 0;<br/>}</pre>
<p>In the preceding code, the threshold function from the <kbd>cv</kbd> namespace is used, which only uses CPU for execution, rather than the <kbd>cv::cuda</kbd> module. The performance of the algorithm is measured using the <kbd>gettickcount</kbd> and <kbd>gettickfrequency</kbd> functions. The <kbd>gettickcount</kbd> function returns the time, in milliseconds, that has passed after starting the system. We measured the time ticks before and after the execution of the code that operates on the image. The difference between the time ticks indicates the ticks passed during an execution of the algorithm to process an image. This time is measured in the <kbd>delta</kbd> variable.  The <kbd>gettickfrequncy</kbd> function returns the frequency of the timer. Total time taken to process an image can be measured by dividing the time ticks by the frequency of the timer. The inverse of this time indicates <strong>frames per second</strong> (<strong>FPS</strong>). Both these performance measures are printed on the console for thresholding application on the CPU. The output on the console is as follows:</p>
<div><img class="alignnone size-full wp-image-338 image-border" src="img/31947360-0451-4b22-a563-b6a753f4af42.png" style="" width="324" height="55"/></div>
<p>As can be seen from the output, the CPU takes <kbd>0.169766</kbd> seconds to process one image, which is equal to <kbd>5.89046</kbd> FPS.  Now we will implement the same algorithm on GPU and try to measure the performance of the code. As per the discussion earlier, this should increase the performance of the algorithm drastically. The code for GPU implementation is as follows: </p>
<pre>#include &lt;iostream&gt;<br/>#include "opencv2/opencv.hpp"<br/><br/>int main (int argc, char* argv[])<br/>{<br/>  cv::Mat h_img1 = cv::imread("images/cameraman.tif", 0);<br/>  cv::cuda::GpuMat d_result1,d_result2,d_result3,d_result4,d_result5, d_img1;<br/>  //Measure initial time ticks<br/>  int64 work_begin = getTickCount(); <br/>  d_img1.upload(h_img1);<br/>  cv::cuda::threshold(d_img1, d_result1, 128.0, 255.0,   cv::THRESH_BINARY);<br/>  cv::cuda::threshold(d_img1, d_result2, 128.0, 255.0,   cv::THRESH_BINARY_INV);<br/>  cv::cuda::threshold(d_img1, d_result3, 128.0, 255.0, cv::THRESH_TRUNC);<br/>  cv::cuda::threshold(d_img1, d_result4, 128.0, 255.0, cv::THRESH_TOZERO);<br/>  cv::cuda::threshold(d_img1, d_result5, 128.0, 255.0, cv::THRESH_TOZERO_INV);<br/><br/>  cv::Mat h_result1,h_result2,h_result3,h_result4,h_result5;<br/>  d_result1.download(h_result1);<br/>  d_result2.download(h_result2);<br/>  d_result3.download(h_result3);<br/>  d_result4.download(h_result4);<br/>  d_result5.download(h_result5);<br/>  //Measure difference in time ticks<br/>  int64 delta = getTickCount() - work_begin;<br/>  double freq = getTickFrequency();<br/>  //Measure frames per second<br/>  double work_fps = freq / delta;<br/>  std::cout &lt;&lt;"Performance of Thresholding on GPU: " &lt;&lt;std::endl;<br/>  std::cout &lt;&lt;"Time: " &lt;&lt; (1/work_fps) &lt;&lt;std::endl;<br/>  std::cout &lt;&lt;"FPS: " &lt;&lt;work_fps &lt;&lt;std::endl;<br/>  return 0;<br/>}</pre>
<p>In the code, the functions are used from the <kbd>cv::cuda</kbd> module, which is optimized for GPU parallel processing capabilities. The images are copied to device memory, operated upon on GPU, and copied back to host. The performance measures are calculated in a similar way as preceding and printed on the console. The output of the program is as follows:</p>
<div><img class="alignnone size-full wp-image-339 image-border" src="img/c5bae944-450a-4c02-ac8b-4bbc4d1d08ba.png" style="" width="325" height="57"/></div>
<p>As can be seen, ,GPU implementation only takes <kbd>0.55</kbd> ms to process a single image, which is equal to <kbd>1816</kbd> FPS. This is a drastic improvement over a CPU implementation, though it must be kept in mind that this is a very simple application and not ideal for performance comparison between CPU and GPU. This application was shown simply to make you familiar with how one can measure the performance of any code in OpenCV.</p>
<p>A more realistic comparison of CPU and GPU performance can be made by running the example codes provided in the OpenCV installation in the <kbd>samples/gpu</kbd> directory.  One of the codes, <kbd>hog.cpp</kbd>, calculates the <strong>histogram of oriented</strong> (<strong>HoG</strong>) features from an image and classifies it using <strong>Support Vector Machine</strong> (<strong>SVM</strong>).  Though details of algorithms are out of the scope of this book, it gives you an idea about performance improvement while using GPU implementations. The performance comparison on webcam video is as follows:</p>
<div><img class="alignnone size-full wp-image-340 image-border" src="img/41657f1b-89cb-4c02-b19e-cf5b51ce8aad.png" style="" width="674" height="294"/></div>
<p>As can be seen, while we use only CPU, the performance of the code is around 13 FPS, and if we use GPU, it increases to 24 FPS, which is almost double the CPU performance.  This will give you an idea about the importance of using CUDA with OpenCV. </p>
<p>To summarize, in this section we looked at a comparison between the performance of OpenCV using CUDA (GPU) and without using CUDA (CPU). It reemphasizes the notion that use of CUDA will improve the performance of computer vision applications drastically.  </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we started with the introduction of computer vision and image processing. We described OpenCV library, which is specifically made for computer vision applications, and how it is different from other computer vision software. OpenCV can leverage the parallel processing capability of GPU by using CUDA. We looked at the installation procedure for OpenCV with CUDA in all operating systems. We described the process to read an image from disk, display it on screen, and save it back to disk. Videos are nothing more than a sequence of images. We learned to work with videos from disk as well as videos captured from camera.  We developed several image processing applications that do different operations on images, such as arithmetic operations, logical operations, color space conversions, and thresholding. In the last section, we compared the performance of the same algorithm on CPU and GPU in terms of time taken to process an image and FPS. So at the end of this chapter, you have an idea of the usefulness of OpenCV with CUDA in computer vision applications and how to write simple code using it. In the next chapter, we will build upon this knowledge and try to develop some more useful computer vision applications, such as filtering, edge detection, and morphological operations using OpenCV.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Questions</h1>
                
            
            
                
<ol>
<li> State the difference between terms computer vision and image processing</li>
<li> Why is OpenCV ideal for deploying computer vision applications on embedded systems</li>
<li> Write an OpenCV command to initialize 1960 x 1960 color image with red color</li>
<li>Write a program to capture frames from a webcam and save it to disk</li>
<li>Which color format is used by OpenCV to read and display a color image</li>
<li>Write a program to capture video from webcam, convert it to grayscale and display on the screen</li>
<li>Write a program to measure the performance of add and subtract operation on GPU</li>
<li>Write a program for bitwise AND and OR operation on images and explain how it can be used for masking</li>
</ol>


            

            
        
    </div></div></body></html>