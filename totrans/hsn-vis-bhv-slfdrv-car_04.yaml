- en: '*Chapter 3*: Lane Detection'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第3章*：车道检测'
- en: 'This chapter will show one of the incredible things possible using computer
    vision in general and OpenCV in particular: lane detection. You will learn how
    to analyze an image and build more and more visual knowledge about it, one step
    after another, applying several filtering techniques, replacing noise and approximation
    with a better understanding of the image, until you will be able to detect where
    the lanes are on a straight road or on a turn, and we will apply this pipeline
    to a video to highlight the road.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将展示使用计算机视觉（特别是OpenCV）可以实现的一些令人难以置信的事情：车道检测。你将学习如何分析图像并逐步构建更多的视觉知识，应用多种过滤技术，用对图像的更好理解来替换噪声和近似，直到你能够检测到直道上或转弯处的车道位置，然后我们将把这个流程应用到视频中，以突出道路。
- en: You will see that this method relies on several assumptions that might not be
    true in the real world, though it can be adjusted to correct for that. Hopefully,
    you will find this chapter quite interesting.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到这种方法依赖于几个可能在实际世界中不成立的假设，尽管它可以进行调整以纠正这一点。希望你会觉得这一章很有趣。
- en: 'We will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Detecting lanes in a road
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在道路上检测车道
- en: Color spaces
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 颜色空间
- en: Perspective correction
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 透视校正
- en: Edge detection
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边缘检测
- en: Thresholding
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阈值
- en: Histograms
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直方图
- en: The sliding window algorithm
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滑动窗口算法
- en: Polynomial fitting
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式拟合
- en: Video filtering
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频滤波
- en: By the end of this chapter, you will be able to design a pipeline that is able
    to detect the lanes on a road, using OpenCV.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够设计一个流程，使用OpenCV检测道路上的车道线。
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Our lane detection pipeline requires quite a lot of code. We will explain the
    main concepts, and you can find the full code on GitHub at [https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter3](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter3).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的车道检测流程需要相当多的代码。我们将解释主要概念，并且你可以在GitHub上找到完整的代码，链接为[https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter3](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter3)。
- en: 'For the instructions and code in this chapter, you need the following:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章中的说明和代码，你需要以下内容：
- en: Python 3.7
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.7
- en: The OpenCV-Python module
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV-Python模块
- en: The NumPy module
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy模块
- en: The Matplotlib module
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib模块
- en: 'To identify the lanes, we need some images and a video. While it''s easy to
    find some open source database to use for this, they are usually only available
    for non-commercial purposes. For this reason, in this book, we will use images
    and video generated by two open source projects: CARLA, a simulator useful for
    autonomous driving tasks, and Speed Dreams, an open source video game. All the
    techniques also work with real-world footage, and you are encouraged to try them
    on some public datasets, such as CULane or KITTI.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别车道，我们需要一些图像和一段视频。虽然很容易找到一些开源数据库来使用，但它们通常仅供非商业用途。因此，在这本书中，我们将使用两个开源项目生成的图像和视频：CARLA，一个用于自动驾驶任务的模拟器，以及Speed
    Dreams，一个开源视频游戏。所有技术也适用于现实世界的视频，我们鼓励你尝试在CULane或KITTI等公共数据集上使用它们。
- en: 'The Code in Action videos for this chapter can be found here:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的“代码在行动”视频可以在以下位置找到：
- en: '[https://bit.ly/37pjxnO](https://bit.ly/37pjxnO)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://bit.ly/37pjxnO](https://bit.ly/37pjxnO)'
- en: How to perform thresholding
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何执行阈值操作
- en: While for a human it is easy to follow a lane, for a computer, this is not something
    that is so simple. One problem is that an image of the road has too much information.
    We need to simplify it, selecting only the parts of the image that we are interested
    in. We will only analyze the part of the image with the lane, but we also need
    to separate the lane from the rest of the image, for example, using color selection.
    After all, the road is typically black or dark, and lanes are usually white or
    yellow.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于人类来说，跟随车道线很容易，但对于计算机来说，这并不是那么简单。一个问题是一个道路图像包含太多的信息。我们需要简化它，只选择我们感兴趣的部分。我们将只分析图像中车道线部分，但我们也需要将车道线从图像的其余部分分离出来，例如，使用颜色选择。毕竟，道路通常是黑色或深色的，而车道通常是白色或黄色的。
- en: In the next sections, we will analyze different color spaces, to see which one
    is most useful for thresholding.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将分析不同的颜色空间，以查看哪一个对阈值化最有用。
- en: How thresholding works on different color spaces
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阈值在不同颜色空间上的工作原理
- en: From a practical point of view, a color space is a way to decompose the colors
    of an image. You are most likely comfortable with RGB, but there are others.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际角度来看，颜色空间是分解图像颜色的一种方式。您可能最熟悉RGB，但还有其他颜色空间。
- en: 'OpenCV supports several color spaces, and as part of this pipeline, we need
    to choose the two best channels from a variety of color spaces. Why do we want
    to use two different channels? For two reasons:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV支持多种颜色空间，作为此流程的一部分，我们需要从各种颜色空间中选择两个最佳通道。我们为什么要使用两个不同的通道？有两个原因：
- en: A color space that is good for white lanes might not be good for yellow ones.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于白色车道来说，一个好的颜色空间可能不适合黄色车道。
- en: When there are difficult frames (for example, with shadows on the road or if
    the lane is discolored), one channel could be less affected than another one.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当存在困难的帧（例如，道路上存在阴影或车道变色时），一个通道可能比另一个通道受影响较小。
- en: This might not be strictly necessary for our example, as the lanes are always
    white, but it is definitely useful in real life.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例来说，这可能不是严格必要的，因为车道总是白色的，但在现实生活中这绝对是有用的。
- en: We will now see how our test image appears in different color spaces, but bear
    in mind that your case might be different.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将看到我们的测试图像在不同颜色空间中的外观，但请记住，您的情况可能不同。
- en: RGB/BGR
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RGB/BGR
- en: 'The starting point will be the following image:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 起始点将是以下图像：
- en: '![Figure 3.1 – Reference image, from Speed Dreams](img/B16322_03_01.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1 – 参考图像，来自Speed Dreams](img/B16322_03_01.jpg)'
- en: Figure 3.1 – Reference image, from Speed Dreams
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – 参考图像，来自Speed Dreams
- en: 'The image can, of course, be decomposed into three channels: red, green, and
    blue. As we know, OpenCV stores the image as BGR (meaning, the first byte is the
    blue channel, not the red channel), but conceptually, there is no difference.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图像当然可以分解为三个通道：红色、绿色和蓝色。正如我们所知，OpenCV以BGR（意味着，第一个字节是蓝色通道，而不是红色通道）存储图像，但从概念上讲，没有区别。
- en: 'These are the three channels once separated:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是分离后的三个通道：
- en: '![Figure 3.2 – BGR channels: blue, green, and red channels](img/B16322_03_02.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2 – BGR通道：蓝色、绿色和红色通道](img/B16322_03_02.jpg)'
- en: 'Figure 3.2 – BGR channels: blue, green, and red channels'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – BGR通道：蓝色、绿色和红色通道
- en: 'They all seem fine. We can try to separate the lane by selecting the white
    pixels. As the white color is (`255, 255, 255`), we could leave some margin and
    select the colors above 180 on the scale. To do this operation, we need to create
    a black image with the same size as the selected channel, then paint all the pixels
    that are above 180 in the original channel white:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 它们看起来都很好。我们可以尝试通过选择白色像素来分离车道。由于白色颜色是（`255, 255, 255`），我们可以留出一些余地并选择高于180的颜色的像素。为了执行此操作，我们需要创建一个与所选通道相同大小的黑色图像，然后在原始通道中所有高于180的像素上涂成白色：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This is how the output appears:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是输出看起来像这样：
- en: '![Figure 3.3 – BGR channels: blue, green, and red channels, threshold above
    180](img/B16322_03_03.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3 – BGR通道：蓝色、绿色和红色通道，阈值为180以上](img/B16322_03_03.jpg)'
- en: 'Figure 3.3 – BGR channels: blue, green, and red channels, threshold above 180'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 – BGR通道：蓝色、绿色和红色通道，阈值为180以上
- en: They all seem good. The red channel also shows part of the car, but since we
    will not analyze that part of the image, it is not a problem. As the white color
    has the same value in the red, green, and blue channels, it is kind of expected
    that the lane should be visible on all three channels. This would not be true
    for yellow lanes, though.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 它们看起来都很好。红色通道也显示了汽车的一部分，但由于我们不会分析图像的这一部分，所以这不是问题。由于白色在红色、绿色和蓝色通道中具有相同的值，所以在所有三个通道上都能看到车道是预料之中的。然而，对于黄色车道来说，情况并非如此。
- en: The value that we choose for the threshold is very important, and unfortunately,
    it is dependent on the colors used for the lane and on the situation of the road;
    light conditions and shadows will also affect it.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择的阈值非常重要，不幸的是，它取决于车道使用的颜色和道路情况；光线条件和阴影也会影响它。
- en: 'The following figure shows a totally different threshold, 20-120:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了完全不同的阈值，20-120：
- en: '![Figure 3.4 – BGR channels: blue, green, and red channels, threshold in the
    range 20-120](img/B16322_03_04.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图3.4 – BGR通道：蓝色、绿色和红色通道，阈值为20-120](img/B16322_03_04.jpg)'
- en: 'Figure 3.4 – BGR channels: blue, green, and red channels, threshold in the
    range 20-120'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – BGR通道：蓝色、绿色和红色通道，阈值为20-120
- en: 'You can select the pixels in the 20-120 range with the following code:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下代码选择20-120范围内的像素：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The image is probably still usable, as long as you consider that the lane is
    black, but it would not be recommended.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 只要考虑车道是黑色的，图像可能仍然可用，但这并不推荐。
- en: HLS
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HLS
- en: 'The HLS color space divides the color into hue, lightness, and saturation.
    The result is sometimes surprising:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: HLS颜色空间将颜色分为色调、亮度和饱和度。结果有时会令人惊讶：
- en: '![Figure 3.5 – HLS channels: hue, lightness, and saturation](img/B16322_03_05.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5 – HLS通道：色调、亮度和饱和度](img/B16322_03_05.jpg)'
- en: 'Figure 3.5 – HLS channels: hue, lightness, and saturation'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – HLS通道：色调、亮度和饱和度
- en: The hue channel is pretty bad, noisy, and low resolution, while the lightness
    seems to perform well. The saturation seems to be unable to detect our lane.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 色调通道相当糟糕，噪声大，分辨率低，而亮度似乎表现良好。饱和度似乎无法检测到我们的车道。
- en: 'Let''s try some thresholding:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一些阈值：
- en: '![Figure 3.6 – HLS channels: hue, lightness, and saturation, threshold above
    160](img/B16322_03_06.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图3.6 – HLS通道：色调、亮度和饱和度，阈值高于160](img/B16322_03_06.jpg)'
- en: 'Figure 3.6 – HLS channels: hue, lightness, and saturation, threshold above
    160'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 – HLS通道：色调、亮度和饱和度，阈值高于160
- en: The threshold shows that lightness is still a good candidate.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值显示，亮度仍然是一个好的候选者。
- en: HSV
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HSV
- en: 'The HSV color space divides the color into hue, saturation, and value, and
    it is related to HLS. The result is therefore similar to HLS:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: HSV颜色空间将颜色分为色调、饱和度和值，它与HLS相关。因此，结果是类似于HLS的：
- en: '![Figure 3.7 – HSV channels: hue, saturation, and value](img/B16322_03_07.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图3.7 – HSV通道：色调、饱和度和值](img/B16322_03_07.jpg)'
- en: 'Figure 3.7 – HSV channels: hue, saturation, and value'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 – HSV通道：色调、饱和度和值
- en: 'Hue and saturation are not useful to us, but value looks fine with thresholding
    applied:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 色调和不饱和度对我们来说没有用，但应用阈值后的亮度看起来不错：
- en: '![Figure 3.8 – HSV channels: hue, saturation, and value, threshold above 160](img/B16322_03_08.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图3.8 – HSV通道：色调、饱和度和值，阈值高于160](img/B16322_03_08.jpg)'
- en: 'Figure 3.8 – HSV channels: hue, saturation, and value, threshold above 160'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 – HSV通道：色调、饱和度和值，阈值高于160
- en: As expected, the threshold of value looks good.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期，值的阈值看起来不错。
- en: LAB
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LAB
- en: 'The LAB (CIELAB or CIE L*a*b*) color space divides the color into L* (lightness,
    from black to white), a* (from green to red), and b* (from blue to yellow):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: LAB（CIELAB或CIE L*a*b*）颜色空间将颜色分为L*（亮度，从黑色到白色）、a*（从绿色到红色）和b*（从蓝色到黄色）：
- en: '![Figure 3.9 – LAB channels: L*, a*, and b*](img/B16322_03_09.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图3.9 – LAB通道：L*、a*和b*](img/B16322_03_09.jpg)'
- en: 'Figure 3.9 – LAB channels: L*, a*, and b*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9 – LAB通道：L*、a*和b*
- en: 'L* seems fine, while a* and b* are not useful to us:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: L*看起来不错，而a*和b*对我们来说没有用：
- en: '![Figure 3.10 – LAB channels: L*, a*, and b*, threshold above 160](img/B16322_03_10.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图3.10 – LAB通道：L*、a*和b*，阈值高于160](img/B16322_03_10.jpg)'
- en: 'Figure 3.10 – LAB channels: L*, a*, and b*, threshold above 160'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 – LAB通道：L*、a*和b*，阈值高于160
- en: YCbCr
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: YCbCr
- en: 'YCbCr is the last color space that we will analyze. It divides the image into
    Luma (Y) and two chroma components (Cb and Cr):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: YCbCr是我们将要分析的最后一个颜色空间。它将图像分为亮度（Y）和两个色度分量（Cb和Cr）：
- en: '![Figure 3.11 – YCbCr channels: Y, Cb, and Cr](img/B16322_03_11.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图3.11 – YCbCr通道：Y、Cb和Cr](img/B16322_03_11.jpg)'
- en: 'Figure 3.11 – YCbCr channels: Y, Cb, and Cr'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11 – YCbCr通道：Y、Cb和Cr
- en: 'This is the result when we apply a threshold:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这是应用阈值后的结果：
- en: '![Figure 3.12 – YCbCr channels: Y, Cb, and Cr, threshold above 160](img/B16322_03_12.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图3.12 – YCbCr通道：Y、Cb和Cr，阈值高于160](img/B16322_03_12.jpg)'
- en: 'Figure 3.12 – YCbCr channels: Y, Cb, and Cr, threshold above 160'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 – YCbCr通道：Y、Cb和Cr，阈值高于160
- en: The threshold confirms the validity of the Luma channel.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值证实了亮度通道的有效性。
- en: Our choice
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的选择
- en: After some experiments, it seems that the green channel can be used for edge
    detection, and the L channel from the HLS space could be used as additional thresholding,
    so we'll stick to these. These settings should be also fine for a yellow line,
    while different colors might require different thresholds.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一些实验，似乎绿色通道可以用于边缘检测，而HLS空间中的L通道可以用作额外的阈值，因此我们将坚持这些设置。这些设置对于黄色线条也应该适用，而不同的颜色可能需要不同的阈值。
- en: Perspective correction
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 透视校正
- en: 'Let''s take a step back and start simple. The easiest case that we can have
    is with a straight lane. Let''s see how it looks:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们退一步，从简单开始。我们可以拥有的最简单的情况是直线车道。让我们看看它看起来如何：
- en: '![Figure 3.13 – Straight lane, from Speed Dreams](img/B16322_03_13.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图3.13 – 直线车道，来自Speed Dreams](img/B16322_03_13.jpg)'
- en: Figure 3.13 – Straight lane, from Speed Dreams
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13 – 直线车道，来自Speed Dreams
- en: If we were flying over the road, and watching it from a bird's eye view, the
    lanes would be parallel, but in the picture, they are not, because of the perspective.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们飞越道路，并从鸟瞰的角度观察，车道线将是平行的，但在图片中，由于透视，它们并不是平行的。
- en: The perspective depends on the focal length of the lens (lenses with a shorter
    focal length show a stronger perspective) and the position of the camera. Once
    the camera is mounted on a car, the perspective is fixed, so we can take it into
    consideration and correct the image.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 透视取决于镜头的焦距（焦距较短的镜头显示的透视更强）和摄像机的位置。一旦摄像机安装在汽车上，透视就固定了，因此我们可以考虑这一点并校正图像。
- en: 'OpenCV has a method to compute the perspective transformation: `getPerspectiveTransform()`.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV有一个计算透视变换的方法：`getPerspectiveTransform()`。
- en: 'It takes two parameters, both arrays of four points, identifying the trapezoid
    of the perspective. One array is the source and one array is the destination.
    This means that the same method can be used to compute the inverse transformation,
    by just swapping the parameters:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 它需要两个参数，都是四个点的数组，用于标识透视的梯形。一个数组是源，一个数组是目标。这意味着可以使用相同的方法通过交换参数来计算逆变换：
- en: '[PRE2]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We need to select the area around the lanes, plus a small margin:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要选择车道线周围的区域，以及一个小边距：
- en: '![Figure 3.14 – Trapezoid with the region of interest around the lanes](img/B16322_03_14.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图3.14 – 带有车道线周围感兴趣区域的梯形](img/B16322_03_14.jpg)'
- en: Figure 3.14 – Trapezoid with the region of interest around the lanes
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 – 带有车道线周围感兴趣区域的梯形
- en: In our case, the destination is a rectangle (as we want to make it straight).
    *Figure 3.14* shows the green trapezoid (the `src` variable in the previous code)
    with the original perspective and the white rectangle (the `dst` variable in the
    previous code), which is the desired perspective. Please notice that for clarity,
    they have been drawn as overlapping, but the coordinates of the rectangle passed
    as a parameter are shifted, as if it was starting at *X* coordinate 0.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，目标是一个矩形（因为我们希望它变得笔直）。*图3.14*显示了带有原始视角的绿色梯形（前一段代码中的`src`变量）和白色矩形（前一段代码中的`dst`变量），这是期望的视角。请注意，为了清晰起见，它们被绘制为重叠的，但矩形的坐标作为参数传递时发生了偏移，就像它从*X*坐标0开始一样。
- en: 'We can now apply the perspective correction and get our bird''s eye view:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以应用透视校正并获取我们的鸟瞰视图：
- en: '[PRE3]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `warpPerspective()` method accepts four parameters:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`warpPerspective()`方法接受四个参数：'
- en: The source image.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源图像。
- en: The transformation matrix, obtained from `getPerspectiveTransform()`.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`getPerspectiveTransform()`获得的变换矩阵。
- en: The size of the output image. In our case, the width is the same as the original
    image, but the height is only the height of the trapezoid/rectangle.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出图像的大小。在我们的情况下，宽度与原始图像相同，但高度只是梯形/矩形的宽度。
- en: Some flags, to specify the interpolation. `INTER_LINEAR` is a common choice,
    but I recommend experimenting, and to give `INTER_LANCZOS4` a try.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些标志，用于指定插值。`INTER_LINEAR`是一个常见的选项，但我建议进行实验，并尝试使用`INTER_LANCZOS4`。
- en: 'This is the result of warp using `INTER_LINEAR`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是使用`INTER_LINEAR`进行扭曲的结果：
- en: '![Figure 3.15 – Warped with INTER_LINEAR](img/B16322_03_15.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图3.15 – 使用INTER_LINEAR扭曲](img/B16322_03_15.jpg)'
- en: Figure 3.15 – Warped with INTER_LINEAR
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 – 使用INTER_LINEAR扭曲
- en: 'This is the result using `INTER_LANCZOS4`:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用`INTER_LANCZOS4`的结果：
- en: '![Figure 3.16 – Warped with INTER_LANCZOS4](img/B16322_03_16.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图3.16 – 使用INTER_LANCZOS4扭曲](img/B16322_03_16.jpg)'
- en: Figure 3.16 – Warped with INTER_LANCZOS4
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16 – 使用INTER_LANCZOS4扭曲
- en: They are very similar, but a closer look shows that the interpolation performed
    with the `LANCZOS4` resampling is sharper. We will see later that at the end of
    the pipeline, the difference is significant.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 它们非常相似，但仔细观察会发现，使用`LANCZOS4`重采样进行的插值更清晰。我们将在后面看到，在管道的末端，差异是显著的。
- en: What is clear in both images is that our lines are now vertical, which intuitively
    could help us.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在两张图片中都很清楚的是，我们的线条现在是垂直的，这直观上可能有助于我们。
- en: We'll see in the next section how to leverage this image.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中看到如何利用这张图像。
- en: Edge detection
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘检测
- en: 'The next step is detecting the edges, and we will use the green channel for
    that, as during our experiments, it gave good results. Please be aware that you
    need to experiment with the images and videos taken from the country where you
    plan to run the software, and with many different light conditions. Most likely,
    based on the color of the lines and the colors in the image, you might want to
    choose a different channel, possibly from another color space; you can convert
    the image into different color spaces using `cvtColor()`, for example:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是检测边缘，我们将使用绿色通道来完成这项工作，因为在我们的实验中，它给出了良好的结果。请注意，您需要根据您计划运行软件的国家/地区以及许多不同的光照条件对图像和视频进行实验。很可能会根据线条的颜色和图像中的颜色，您可能需要选择不同的通道，可能是来自另一个颜色空间；您可以使用`cvtColor()`等函数将图像转换为不同的颜色空间：
- en: '[PRE4]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We will stick to green.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将坚持使用绿色。
- en: 'OpenCV has several ways to compute edge detection, and we are going to use
    Scharr, as it performs quite well. Scharr computes a derivative, so it detects
    the difference in colors in the image. We are interested in the *X* axis, and
    we want the result to be a 64-bit float, so our call would be like this:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV有几种计算边缘检测的方法，我们将使用Scharr，因为它表现相当不错。Scharr计算导数，因此它检测图像中的颜色差异。我们对X轴感兴趣，并且希望结果是一个64位的浮点数，所以我们的调用将如下所示：
- en: '[PRE5]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As Scharr computes a derivative, the values can be both positive and negative.
    We are not interested in the sign, but only in the fact that there is an edge.
    So, we will take the absolute value:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Scharr计算导数，值可以是正的也可以是负的。我们感兴趣的并不是符号，而只是存在边缘的事实。因此，我们将取绝对值：
- en: '[PRE6]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Another issue is that the values are not bounded on the 0-255 value range that
    we expect on a single channel image, and the values are floating points, while
    we need an 8-bit integer. We can fix both the issues with the following line:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是我们期望的单通道图像上的0-255值范围内的值没有界限，而值是浮点数，而我们需要一个8位的整数。我们可以通过以下行解决这两个问题：
- en: '[PRE7]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This is the result:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 3.17 – Edge detection with Scharr, scaled and with absolute values](img/B16322_03_17.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: 图3.17 – 使用Scharr进行边缘检测，缩放并取绝对值
- en: Figure 3.17 – Edge detection with Scharr, scaled and with absolute values
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17 – 使用Scharr进行边缘检测，缩放并取绝对值
- en: 'At this point, we can apply thresholding to convert the image into black and
    white, to better isolate the pixels of the lanes. We need to choose the intensity
    of the pixels to select, and in this case, we can go for 20-120; we will select
    only pixels that have at least an intensity value of 20, and not more than 120:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以应用阈值将图像转换为黑白，以便更好地隔离车道像素。我们需要选择要选择的像素强度，在这种情况下，我们可以选择20-120；我们只选择至少具有20的强度值且不超过120的像素：
- en: '[PRE8]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `zeros_like()` method creates an array full of zeros, with the same shape
    of the image, and the second line sets all the pixels with an intensity between
    20 and 120 to 255.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`zeros_like()`方法创建一个全零数组，其形状与图像相同，第二行将强度在20到120之间的所有像素设置为255。'
- en: 'This is the result:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 3.18 – Result after applying a threshold of 20](img/B16322_03_18.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![图3.18 – 应用20阈值后的结果](img/B16322_03_18.jpg)'
- en: Figure 3.18 – Result after applying a threshold of 20
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18 – 应用20阈值后的结果
- en: 'The lanes are now very visible, but there is some noise. We can reduce that
    by increasing the threshold:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，车道非常明显，但有一些噪声。我们可以通过提高阈值来减少噪声：
- en: '[PRE9]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This is how the output appears:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是输出显示的样子：
- en: '![Figure 3.19 – Result after applying a threshold of 50](img/B16322_03_19.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图3.19 – 应用50阈值后的结果](img/B16322_03_19.jpg)'
- en: Figure 3.19 – Result after applying a threshold of 50
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.19 – 应用50阈值后的结果
- en: Now, there is less noise, but we lost the lines on the top.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，噪声更少，但我们失去了顶部的线条。
- en: We will now describe a technique that can help us to retain the full line without
    having an excessive amount of noise.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，噪声更少，但我们失去了顶部的线条。
- en: Interpolated threshold
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插值阈值
- en: 'In practice, we don''t have to choose between selecting the whole line with
    a lot of noise and reducing the noise while detecting only part of the line. We
    could apply a higher threshold to the bottom (where we have more resolution, a
    sharper image, and more noise) and a lower threshold on the top (there, we get
    less contrast, a weaker detection, and less noise, as the pixels are stretched
    by the perspective correction, naturally blurring them). We can just interpolate
    between the thresholds:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们不必在用很多噪声选择整条线与在检测到部分线的同时减少噪声之间做出选择。我们可以对底部（那里我们分辨率更高，图像更清晰，噪声更多）应用更高的阈值，而在顶部（那里我们得到的对比度更低，检测更弱，噪声更少，因为像素被透视校正拉伸，自然地模糊了）应用较低的阈值。我们可以在阈值之间进行插值：
- en: '[PRE10]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s see the result:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看结果：
- en: '![Figure 3.20 – Result after applying an interpolated threshold, from 15 to
    60](img/B16322_03_20.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.20 – 应用插值阈值后的结果，从 15 到 60](img/B16322_03_20.jpg)'
- en: Figure 3.20 – Result after applying an interpolated threshold, from 15 to 60
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.20 – 应用插值阈值后的结果，从 15 到 60
- en: Now, we can have less noise at the bottom and detect weaker signals at the top.
    However, while a human can visually identify the lanes, for the computer, they
    are still just pixels in an image, so there is still work to do. But we simplified
    the image very much, and we are making good progress.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在底部有更少的噪声，并在顶部检测到更弱的信号。然而，虽然人类可以直观地识别车道，但对于计算机来说，它们仍然只是图像中的像素，所以还有工作要做。但我们极大地简化了图像，并且我们正在取得良好的进展。
- en: Combined threshold
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组合阈值
- en: As we mentioned earlier, we also wanted to use the threshold on another channel,
    without edge detection. We chose the L channel of HLS.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，我们也想在另一个通道上使用阈值，而不进行边缘检测。我们选择了 HLS 的 L 通道。
- en: 'This is the result of thresholding above 140:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这是超过 140 的阈值的结果：
- en: '![Figure 3.21 – L channel with the threshold above 140](img/B16322_03_21.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.21 – L 通道，阈值超过 140](img/B16322_03_21.jpg)'
- en: Figure 3.21 – L channel with the threshold above 140
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.21 – L 通道，阈值超过 140
- en: 'Not bad. Now, we can combine it with the edge:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 还不错。现在，我们可以将其与边缘结合起来：
- en: '![Figure 3.22 – Combination of the two thresholds](img/B16322_03_22.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.22 – 两个阈值的组合](img/B16322_03_22.jpg)'
- en: Figure 3.22 – Combination of the two thresholds
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.22 – 两个阈值的组合
- en: The result is noisier, but also more robust.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 结果更嘈杂，但也更稳健。
- en: 'Before moving forward, let''s introduce a picture with a turn:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续前进之前，让我们引入一个带有转弯的图片：
- en: '![Figure 3.23 – Lane with a turn, from Speed Dreams](img/B16322_03_23.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.23 – 转弯车道，来自 Speed Dreams](img/B16322_03_23.jpg)'
- en: Figure 3.23 – Lane with a turn, from Speed Dreams
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.23 – 转弯车道，来自 Speed Dreams
- en: 'This is the threshold:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这是阈值：
- en: '![Figure 3.24 – Lane with a turn, after the threshold](img/B16322_03_24.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.24 – 转弯车道，阈值之后](img/B16322_03_24.jpg)'
- en: Figure 3.24 – Lane with a turn, after the threshold
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.24 – 转弯车道，阈值之后
- en: It still looks good, but we can see that, because of the turn, we no longer
    have a vertical line. In fact, at the top of the image, the lines are basically
    horizontal.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 它仍然看起来不错，但我们可以看到，由于转弯，我们不再有垂直线。事实上，在图像的顶部，线条基本上是水平的。
- en: Finding the lanes using histograms
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用直方图查找车道
- en: 'How could we understand, more or less, where the lanes are? Visually, for a
    human, the answer is simple: the lane is a long line. But what about a computer?'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何或多或少地理解车道在哪里？对于人类来说，答案是简单的：车道是一条长线。但对于计算机来说呢？
- en: 'If we talk about vertical lines, one way could be to count the pixels that
    are white, on a certain column. But if we check the image with a turn, that might
    not work. However, if we reduce our attention to the bottom part of the image,
    the lines are a bit more vertical:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们谈论垂直线，一种方法可以是计算某一列中白色的像素。但是，如果我们检查转弯的图像，那可能不起作用。然而，如果我们把注意力减少到图像的底部，线条就有点更垂直了：
- en: '![Figure 3.25 – Lane with a turn, after the threshold, the bottom part](img/B16322_03_25.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.25 – 转弯车道，阈值之后，底部部分](img/B16322_03_25.jpg)'
- en: Figure 3.25 – Lane with a turn, after the threshold, the bottom part
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.25 – 转弯车道，阈值之后，底部部分
- en: 'We can now count the pixels by column:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以按列计数像素：
- en: '[PRE11]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To save the histogram as a graph, in a file, we can use Matplotlib:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要将直方图保存为文件中的图形，我们可以使用 Matplotlib：
- en: '[PRE12]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We obtain the following result:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了以下结果：
- en: '![Figure 3.26 – Left: histogram of a straight lane, right: histogram of a lane
    with a turn](img/Figure__3_26__Edited.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.26 – 左：直线路道的直方图，右：转弯车道的直方图](img/Figure__3_26__Edited.jpg)'
- en: 'Figure 3.26 – Left: histogram of a straight lane, right: histogram of a lane
    with a turn'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.26 – 左：直线车道的直方图，右：转弯车道的直方图
- en: The X coordinates on the histogram represent the pixels; as our image has a
    resolution of 1024x600, the histogram shows 1,024 data points, with the peaks
    centered around the pixels where the lanes are.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图上的X坐标代表像素；由于我们的图像分辨率为1024x600，直方图显示了1,024个数据点，峰值集中在车道所在像素周围。
- en: As we can see, in the case of a straight lane, the histogram identifies the
    two lines quite clearly; with a turn, the histogram is less clear (because the
    line makes a turn and, therefore, the white pixels are spread a bit around), but
    it's still usable. We can also see that in the case of a dotted line, the peek
    in the histogram is less pronounced, but it is still there.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，在直线车道的情况下，直方图清楚地识别了两条线；在转弯的情况下，直方图不太清晰（因为线条转弯，因此白色像素在周围稍微分散），但它仍然可用。我们还可以看到，在虚线线的情况下，直方图中的峰值不太明显，但它仍然存在。
- en: This looks promising!
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来很有希望！
- en: 'Now, we need a way to detect the two peaks. We can use `argmax()` from NumPy,
    which returns the index of the maximum element of an array, which is one of our
    peaks. However, we need two. For this, we can split the array into two halves,
    and select one peak on each one:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要一种方法来检测两个峰值。我们可以使用NumPy的`argmax()`函数，它返回数组中最大元素的索引，这是我们其中一个峰值。然而，我们需要两个。为此，我们可以将数组分成两半，并在每一半中选择一个峰值：
- en: '[PRE13]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now we have the indexes, which represent the *X* coordinate of the peaks. The
    value itself (for example, `histogram[index]`) can be considered the confidence
    of having identified the lane, as more pixels mean more confidence.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了索引，它们代表峰值的X坐标。这个值本身（例如，`histogram[index]`）可以被认为是识别车道线的置信度，因为更多的像素意味着更高的置信度。
- en: The sliding window algorithm
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 滑动窗口算法
- en: While we are making progress, the image still has some noise, meaning there
    are pixels that can reduce the precision. In addition, we only know where the
    line starts.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在取得进展时，图像仍然有一些噪声，这意味着有一些像素可以降低精度。此外，我们只知道线条的起始位置。
- en: 'The solution is to focus on the area around the line – after all, there is
    no reason to work on the whole warped image; we could start at the bottom of the
    line and proceed to "follow it." This is probably one case where an image is worth
    a thousand words, so this is what we want to achieve:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案是专注于线条周围的区域——毕竟，没有必要在整个扭曲的图像上工作；我们可以从线条的底部开始，然后“跟随”它。这可能是图像胜过千言万语的例子，所以这是我们想要达到的：
- en: '![Figure 3.27 – Top: sliding window, bottom: histogram](img/Figure_3.27_UPDATED.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图3.27 – 顶部：滑动窗口，底部：直方图](img/Figure_3.27_UPDATED.jpg)'
- en: 'Figure 3.27 – Top: sliding window, bottom: histogram'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.27 – 顶部：滑动窗口，底部：直方图
- en: On the upper part of *Figure 3.27*, each rectangle represents a window of interest.
    The first window on the bottom of each lane is centered on the respective peak
    of the histogram. Then, we need a way to "follow the line." The width of each
    window is dependent on the margin that we want to have, while the height depends
    on the number of windows that we want to have. These two numbers can be changed
    to reach a balance between a better detection (reducing the unwanted points and
    therefore the noise) and the possibility to detect more difficult turns, with
    a smaller radius (which will require the windows to be repositioned faster).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在图3.27的上部，每个矩形代表一个感兴趣窗口。每个通道底部的第一个窗口位于直方图相应峰值的中心。然后，我们需要一种“跟随线条”的方法。每个窗口的宽度取决于我们想要的边距，而高度取决于我们想要的窗口数量。这两个数字可以改变以达到更好的检测（减少不需要的点以及因此的噪声）和检测更困难转弯的可能性，半径更小（这将要求窗口更快地重新定位）。
- en: As this algorithm requires quite some code, we will focus on the left lane for
    clarity, but the same computations need to also be performed for the right lane.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此算法需要相当多的代码，我们将专注于左侧车道以保持清晰，但相同的计算也需要对右侧车道进行。
- en: Initialization
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化
- en: 'We are only interested in the pixels that have been selected by the thresholding.
    We can use `nonzero()` from NumPy:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只对被阈值选择的像素感兴趣。我们可以使用NumPy的`nonzero()`函数：
- en: '[PRE14]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `non_zero` variable will contain the coordinates of the pixels that are
    white, then `non_zero_x` will contain the *X* coordinates, and `non_zero_y` the
    *Y* coordinates.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`non_zero`变量将包含白色像素的坐标，然后`non_zero_x`将包含X坐标，而`non_zero_y`将包含Y坐标。'
- en: 'We also need to set `margin`, the movement that we are allowing to the lane
    (for example, half of the window width of the sliding window), and `min_pixels`,
    the minimum number of pixels that we want to detect to accept a new position for
    the sliding window. Below this threshold, we will not update it:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要设置 `margin`，即允许车道移动的距离（例如，滑动窗口窗口宽度的一半），以及 `min_pixels`，这是我们想要检测以接受滑动窗口新位置的最小像素数。低于此阈值，我们不会更新它：
- en: '[PRE15]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Coordinates of the sliding windows
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 滑动窗口的坐标
- en: The `left_x` variable will contain the position of the left lane, and we need
    to initialize it with the value obtained from the histogram.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`left_x` 变量将包含左侧车道的位置，我们需要用从直方图获得的价值初始化它。'
- en: 'After setting the stage, we can now cycle through all the windows, and the
    variable that we will use as the index is `idx_window`. The *X* range is computed
    from the last position, adding the margin:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置好场景后，我们现在可以遍历所有窗口，我们将使用的索引变量是 `idx_window`。*X* 范围是从最后的位置计算的，加上 `margin`：
- en: '[PRE16]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The *Y* range is determined by the index of the window that we are analyzing:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '*Y* 范围由我们正在分析的窗口的索引确定：'
- en: '[PRE17]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now, we need to select the pixels that are white (from `non_zero_x` and `non_zero_y`)
    and constrained in the window that we are analyzing.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要选择白色像素（来自 `non_zero_x` 和 `non_zero_y`）并且被我们正在分析的窗口所约束的像素。
- en: 'The NumPy array can be filtered using overloaded operators. To count all the
    *Y* coordinates that are above `win_y_bottom`, we can, therefore, simply use the
    following expression:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 数组可以使用重载运算符进行过滤。为了计算所有在 `win_y_bottom` 之上的 *Y* 坐标，我们可以简单地使用以下表达式：
- en: '[PRE18]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The result is an array with `True` in the pixels selected and `False` on the
    other ones.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个数组，选中的像素为 `True`，其他像素为 `False`。
- en: 'But what we need is pixels between `win_y_top` and `win_y_bottom`:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们需要的是 `win_y_top` 和 `win_y_bottom` 之间的像素：
- en: '[PRE19]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We also need the *X* coordinates, which must be between `win_x_left_min` and
    `win_x_left_max`. As we need to just count the points, we can add a `nonzero()`
    call:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要 *X* 坐标，它必须在 `win_x_left_min` 和 `win_x_left_max` 之间。由于我们只需要计数，我们可以添加一个
    `nonzero()` 调用：
- en: '[PRE20]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We need to select the first element because our array is inside another array
    of one single element.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要选择第一个元素，因为我们的数组位于另一个只有一个元素的数组内部。
- en: 'We will also keep all these values in a variable, to draw the line above the
    lane later:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将把这些值保存在一个变量中，以便稍后绘制车道线：
- en: '[PRE21]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we just need to update the left lane position with the average of the
    positions, but only if there are enough points:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们只需要更新左侧车道的位置，取位置的平均值，但前提是有足够多的点：
- en: '[PRE22]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Polynomial fitting
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多项式拟合
- en: 'Now, we have potentially selected thousands of points, but we need to make
    sense of them and obtain a line. For this, we can use `polyfit()`, a method that
    can approximate a series of points with a polynomial of the specified degree;
    a second-degree polynomial will be enough for us:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可能已经选择了成千上万的点，但我们需要理解它们并得到一条线。为此，我们可以使用 `polyfit()` 方法，该方法可以用指定次数的多项式来近似一系列点；对于二次多项式对我们来说就足够了：
- en: '[PRE23]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Please notice that `polyfit()` accepts the parameters in the order `(X, Y)`,
    while we provide them in the order `(Y, X)`. We do so because by mathematical
    convention, in a polynomial, *X* is known and *Y* is computed based on *X* (for
    example, *Y = X^2 + 3*X+5*). However, we know *Y* and we need to compute *X*,
    so we need to provide them in the opposite order.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`polyfit()` 函数接受参数的顺序为 `(X, Y)`，而我们所提供的顺序为 `(Y, X)`。我们这样做是因为按照数学惯例，在多项式中，*X*
    是已知的，而 *Y* 是基于 *X* 计算得出的（例如，*Y = X^2 + 3*X + 5*）。然而，我们知道 *Y* 并需要计算 *X*，因此我们需要以相反的顺序提供它们。
- en: We are almost done.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎完成了。
- en: 'The *Y* coordinates are simply a range:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '*Y* 坐标只是一个范围：'
- en: '[PRE24]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then, we need to compute *X* from *Y*, using the generic formula for a polynomial
    of the second degree (reversed on *X* and *Y*):'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要从 *Y* 计算出 *X*，使用二次多项式的通用公式（在 *X* 和 *Y* 上反转）：
- en: '*x = Ay^2 + By + C;*'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '*x = Ay^2 + By + C*；'
- en: 'This is the code:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码：
- en: '[PRE25]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This is where we are now:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们现在的位置：
- en: '![Figure 3.28 – Lanes drawn on the warped image](img/B16322_03_28.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.28 – 在扭曲图像上绘制的车道](img/B16322_03_28.jpg)'
- en: Figure 3.28 – Lanes drawn on the warped image
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.28 – 在扭曲图像上绘制的车道
- en: 'We can now call `perspectiveTransform()` with the inverse perspective transformation
    to move the pixels to their position in the image. This is the final result:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用逆透视变换调用 `perspectiveTransform()` 来移动像素到图像中的相应位置。这是最终结果：
- en: '![Figure 3.29 – Lane detected on the image](img/B16322_03_29.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.29 – 图像上检测到的车道](img/B16322_03_29.jpg)'
- en: Figure 3.29 – Lane detected on the image
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.29 – 图像上检测到的车道
- en: Congratulations! It has not been particularly easy, but you can now detect a
    lane on a frame, under the correct conditions. Unfortunately, not all the frames
    will be good enough for this. Let's see in the next section how we can use the
    temporal evolution of the video stream to filter the data and improve the precision.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！这并不特别容易，但现在你可以在正确的条件下检测到帧上的车道。不幸的是，并不是所有的帧都足够好来进行这项检测。让我们在下一节中看看我们如何可以使用视频流的时序演变来过滤数据并提高精度。
- en: Enhancing a video
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增强视频
- en: Analyzing a video stream in real time can be a challenge from a computational
    point of view, but usually, it offers the possibility to improve precision, as
    we can build on knowledge from the previous frames and filter the result.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 从计算角度来看，实时分析视频流可能是一个挑战，但通常，它提供了提高精度的可能性，因为我们可以在前一帧的知识基础上构建并过滤结果。
- en: We will now see two techniques that can be used to detect lanes with better
    precision when working with video streams.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看到两种技术，当处理视频流时，可以使用这些技术以更高的精度检测车道。
- en: Partial histogram
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部分直方图
- en: 'If we assume that we correctly detected a lane in the previous few frames,
    then the lane on the current frame should be in a similar position. This assumption
    is affected by the speed of the car and the frame rate of the camera: the faster
    the car, the more the lane could change. Conversely, the faster the camera, the
    less the lane could have moved between two frames. In a real self-driving car,
    both these values are known, so they can be taken into consideration if required.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们假设在前几帧中正确检测到了车道，那么当前帧上的车道应该处于相似的位置。这个假设受汽车速度和相机帧率的影响：汽车越快，车道变化就越大。相反，相机越快，车道在两帧之间移动就越少。在现实中的自动驾驶汽车中，这两个值都是已知的，因此如果需要，可以将其考虑在内。
- en: From a practical point of view, this means we can limit the part of the histogram
    that we analyze, to avoid false detections, analyzing only some histogram pixels
    (for example, 30) around the average of some of the previous frames.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际的角度来看，这意味着我们可以限制我们分析直方图的区域，以避免错误检测，只分析一些之前帧平均值的周围的一些直方图像素（例如，30）。
- en: Rolling average
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 滚动平均
- en: The main result of our detection is the three values of the polynomial fit,
    for each lane. Following the same principle of the previous section, we can deduce
    that they cannot change much between frames, so we could consider the average
    of some of the previous frames, to reduce noise.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检测的主要结果是每个车道的多项式拟合的三个值。遵循上一节相同的原理，我们可以推断出它们在帧之间不会变化太多，因此我们可以考虑一些之前帧的平均值，以减少噪声。
- en: There is a technique called the **exponentially weighted moving average** (or
    rolling average), which can be used to easily compute an approximate average on
    some of the last values of a stream of values.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种称为**指数加权移动平均**（或滚动平均）的技术，可以用来轻松计算值流中最后一些值的近似平均值。
- en: 'Given `beta`, a parameter greater than zero and typically close to one, the
    moving average can be computed like this:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 给定 `beta`，一个大于零且通常接近一的参数，移动平均可以按以下方式计算：
- en: '[PRE26]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As an indication, the number of frames that most affect the average is given
    by the following:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个指示，影响平均值的帧数如下：
- en: '[PRE27]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: So, `beta = 0.9` would average 10 frames, and `beta = 0.95` would average 20
    frames.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`beta = 0.9` 会平均10帧，而 `beta = 0.95` 会平均20帧。
- en: This concludes the chapter. I invite you to check the full code on GitHub and
    to play around with it. You can find some real-life footage and try to identify
    the lanes there.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了本章。我邀请您在GitHub上查看完整的代码，并尝试对其进行操作。您可以在那里找到一些真实的视频片段并尝试识别车道。
- en: And don't forget to apply the **camera calibration**, if you can.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 并且不要忘记应用**相机标定**，如果可能的话。
- en: Summary
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we built a nice pipeline to detect lanes. First, we analyzed
    different color spaces, such as RGB, HLS, and HSV, to see which channels would
    be more useful to detect lanes. Then, we used perspective correction, with `getPerspectiveTransform()`,
    to obtain a *bird's eye view* and make parallel lines on the road also look parallel
    on the image we analyzed.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们构建了一个很好的车道检测流程。首先，我们分析了不同的颜色空间，如RGB、HLS和HSV，以查看哪些通道对检测车道更有用。然后，我们使用`getPerspectiveTransform()`进行透视校正，以获得*鸟瞰图*并使道路上的平行线在分析的图像上也看起来平行。
- en: We used edge detection with `Scharr()` to detect edges and make our analysis
    more robust than using only a color threshold, and we combined the two. We then
    computed a histogram to detect where the lanes start, and we used the "sliding
    window" technique to "follow" the lane in the image.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`Scharr()`进行边缘检测，以检测边缘并使我们的分析比仅使用颜色阈值更稳健，并将两者结合起来。然后我们计算直方图以检测车道开始的位置，并使用“滑动窗口”技术来“跟随”图像中的车道。
- en: 'Then, we used `polyfit()` to fit a second-order polynomial on the pixels detected,
    making sense of them, and we used the coefficients returned by the function to
    generate our curve, after having applied reverse perspective correction on them.
    Finally, we discussed two techniques that can be applied to a video stream to
    improve the precision: partial histogram and rolling average.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`polyfit()`在检测到的像素上拟合一个二次多项式，使它们有意义，并使用函数返回的系数来生成我们的曲线，在它们上应用反向透视校正后。最后，我们讨论了两种可以应用于视频流以提高精度的技术：部分直方图和滚动平均值。
- en: Using all these techniques together, you can now build a pipeline that can detect
    the lanes on a road.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 使用所有这些技术一起，你现在可以构建一个能够检测道路上车道线的管道。
- en: In the next chapter, we will introduce deep learning and neural networks, powerful
    tools that we can use to accomplish even more complex computer vision tasks.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍深度学习和神经网络，这些是强大的工具，我们可以使用它们来完成更复杂的计算机视觉任务。
- en: Questions
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Can you name some color spaces, other than RGB?
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能列举一些除了RGB之外的颜色空间吗？
- en: Why do we apply perspective correction?
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们要应用透视校正？
- en: How can we detect where the lane starts?
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何检测车道开始的位置？
- en: Which technique can you use to *follow the lane* in the image?
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用哪种技术来*跟随图像中的车道*？
- en: If you have many points forming more or less a lane, how can you convert them
    into a line?
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你有很多点大致形成一个车道，你如何将它们转换成一条线？
- en: Which function can you use for edge detection?
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用哪个函数进行边缘检测？
- en: What can you use to compute the average of the last *N* positions of the lane?
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用什么来计算最后*N*个位置的平均值？
