- en: '*Chapter 1*: Machine Learning Fundamentals'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For many decades, researchers have been trying to simulate human brain activity
    through the field known as **artificial intelligence**, **AI** for short. In 1956,
    a group of people met at the Dartmouth Summer Research Project on Artificial Intelligence,
    an event that is widely accepted as the first group discussion about AI as we
    know it today. Researchers were trying to prove that many aspects of the learning
    process could be precisely described and, therefore, automated and replicated
    by a machine. Today, we know they were right!
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Many other terms appeared in this field, such as **machine learning** (**ML**)
    and **deep learning** (**DL**). These sub-areas of AI have also been evolving
    for many decades (granted, nothing here is new to the science). However, with
    the natural advance of the information society and, more recently, the advent
    of **big data** platforms, AI applications have been reborn with much more power
    and applicability. Power, because now we have more computational resources to
    simulate and implement them; applicability, because now information is everywhere.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Even more recently, cloud services providers have put AI in the cloud. This
    is helping all sizes of companies to either reduce their operational costs or
    even letting them sample AI applications (considering that it could be too costly
    for a small company to maintain its own data center).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'That brings us to the goal of this chapter: being able to describe what the
    terms AI, ML, and DL mean, as well as understanding all the nuances of an ML pipeline.
    Avoiding confusion on these terms and knowing what exactly an ML pipeline is will
    allow you to properly select your services, develop your applications, and master
    the AWS Machine Learning Specialty exam.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'The main topics of this chapter are as follows:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Comparing AI, ML, and DL
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifying supervised, unsupervised, and reinforcement learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The CRISP-DM modeling life cycle
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data splitting
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling expectations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing ML frameworks
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML in the cloud
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparing AI, ML, and DL
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AI is a broad field that studies different ways to create systems and machines
    that will solve problems by simulating human intelligence. There are different
    levels of sophistication to create these programs and machines, which go from
    simple, rule-based engines to complex, self-learning systems. AI covers, but is
    not limited to, the following sub-areas:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Robotics
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Natural language processing
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rule-based systems
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The area we are particularly interested in now is ML.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Examining ML
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ML is a sub-area of AI that aims to create systems and machines that are able
    to learn from experience, without being explicitly programmed. As the name suggests,
    the system is able to observe its running environment, learn, and adapt itself
    without human intervention. Algorithms behind ML systems usually extract and improve
    knowledge from the data that is available to them, as well as conditions (such
    as **hyperparameters**), and feed back after trying different approaches to solve
    a particular problem:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ML是人工智能的一个子领域，旨在创建能够从经验中学习，而不需要明确编程的系统。正如其名称所暗示的，系统能够观察其运行环境，学习，并在没有人为干预的情况下适应自己。ML系统背后的算法通常从它们可用的数据中提取和改进知识，以及条件（如**超参数**），并在尝试不同的方法来解决特定问题后进行反馈：
- en: '![Figure 1.1 – Heirarchy of AI, ML, DL'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 1.1 – 人工智能、机器学习、深度学习的层次结构'
- en: '](img/B16735_01_001.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16735_01_001.jpg]'
- en: Figure 1.1 – Heirarchy of AI, ML, DL
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 人工智能、机器学习、深度学习的层次结构
- en: There are different types of ML algorithms; for instance, we can list decision
    tree-based, probabilistic-based, and neural networks. Each of these classes might
    have dozens of specific algorithms. Most of them will be covered in later sections
    of this book.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同类型的ML算法；例如，我们可以列出基于决策树、基于概率和神经网络。每个类别可能都有数十种特定的算法。大多数算法将在本书的后续章节中介绍。
- en: 'As you might have noticed in *Figure 1.1*, we can be even more specific and
    break the ML field down into another very important topic for the Machine Learning
    Specialty exam: DL.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图1.1*中可能已经注意到的，我们可以更加具体，将机器学习领域细分为机器学习专业考试中另一个非常重要的主题：深度学习。
- en: Examining DL
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查深度学习
- en: DL is a subset of ML that aims to propose algorithms that connect multiple layers
    to solve a particular problem. The knowledge is then passed through layer by layer
    until the optimal solution is found. The most common type of DL algorithm is deep
    neural networks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: DL（深度学习）是ML（机器学习）的一个子集，旨在提出将多个层次连接起来以解决特定问题的算法。知识随后通过一层层传递，直到找到最佳解决方案。最常见类型的DL算法是深度神经网络。
- en: At the time of writing this book, DL is a very hot topic in the field of ML.
    Most of the current state-of-the-art algorithms for machine translation, image
    captioning, and computer vision were proposed in the past few years and are a
    part of DL.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，DL是机器学习领域的一个非常热门的话题。目前大多数最先进的机器翻译、图像标题和计算机视觉算法都是在过去几年提出的，并且是深度学习的一部分。
- en: Now that we have an overview of types of AI, let's look at some of the ways
    we can classify ML.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对人工智能的类型有了概述，让我们来看看我们可以如何对机器学习进行分类。
- en: Classifying supervised, unsupervised, and reinforcement learning
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对监督学习、无监督学习和强化学习进行分类
- en: 'ML is a very extensive field of study; that''s why it is very important to
    have a clear definition of its sub-divisions. From a very broad perspective, we
    can split ML algorithms into two main classes: **supervised learning** and **unsupervised
    learning**.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ML是一个非常广泛的研究领域；这就是为什么对其子领域有一个清晰的定义非常重要。从非常广泛的角度来看，我们可以将ML算法分为两大类：**监督学习**和**无监督学习**。
- en: Introducing supervised learning
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍监督学习
- en: 'Supervised algorithms use a class or label (from the input data) as support
    to find and validate the optimal solution. In *Figure 1.2*, there is a dataset
    that aims to classify fraudulent transactions from a bank:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 监督算法使用一个类别或标签（来自输入数据）作为支持来找到和验证最佳解决方案。在*图1.2*中，有一个旨在从银行中分类欺诈交易的数据库：
- en: '![Figure 1.2 – Sample dataset for supervised learning'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 1.2 – 监督学习样本数据集'
- en: '](img/B16735_01_002.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16735_01_002.jpg]'
- en: Figure 1.2 – Sample dataset for supervised learning
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – 监督学习样本数据集
- en: The first four columns are known as **features**, or **independent variables**,
    and they can be used by a supervised algorithm to find fraudulent patterns. For
    example, by combining those four features (day of the week, EST hour, transaction
    amount, and merchant type) and six observations (each row is technically one observation),
    you can infer that e-commerce transactions with a value greater than $5,000 and
    processed at night are potentially fraudulent cases.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 前四列被称为**特征**或**独立变量**，它们可以被监督算法用来找到欺诈模式。例如，通过结合这四个特征（星期几、EST小时、交易金额和商家类型）以及六个观察值（每一行实际上是观察值之一），你可以推断出价值超过5,000美元且在夜间处理的电子商务交易可能是欺诈案例。
- en: Important note
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In a real scenario, we should have more observations in order to have statistical
    support to make this type of inference.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际场景中，我们应该有更多的观察值，以便为这种类型的推断提供统计支持。
- en: The key point is that we were able to infer a potential fraudulent pattern just
    because we knew, *a priori*, what is fraud and what is not fraud. This information
    is present in the last column of *Figure 1.2* and is commonly referred to as a
    target variable, label, response variable, or dependent variable. If the input
    dataset has a target variable, you should be able to apply supervised learning.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点在于，我们能够推断出一个潜在的欺诈模式，仅仅因为我们事先知道什么是欺诈，什么不是欺诈。这种信息存在于*图1.2*的最后列，通常被称为目标变量、标签、响应变量或因变量。如果输入数据集有一个目标变量，你应该能够应用监督学习。
- en: 'In supervised learning, the target variable might store different types of
    data. For instance, it could be a binary column (yes or no), a multi-class column
    (class A, B, or C), or even a numerical column (any real number, such as a transaction
    amount). According to the data type of the target variable, you will find which
    type of supervised learning your problem refers to. *Figure 1.3* shows how to
    classify supervised learning into two main groups: **classification** and **regression**
    algorithms:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，目标变量可能存储不同类型的数据。例如，它可能是一个二元列（是或否），一个多类列（A类、B类或C类），甚至是一个数值列（任何实数，例如交易金额）。根据目标变量的数据类型，你可以找到你的问题属于哪种类型的监督学习。*图1.3*展示了如何将监督学习分为两大类：**分类**和**回归**算法：
- en: '![Figure 1.3 – Choosing the right type of supervised learning given the target
    variable'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.3 – 根据目标变量选择合适的监督学习类型'
- en: '](img/B16735_01_003.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_01_003.jpg)'
- en: Figure 1.3 – Choosing the right type of supervised learning given the target
    variable
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – 根据目标变量选择合适的监督学习类型
- en: While classification algorithms predict a class (either binary or multiple classes),
    regression algorithms predict a real number (either continuous or discrete).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 而分类算法预测一个类别（要么是二元的，要么是多类的），回归算法预测一个实数（要么是连续的，要么是离散的）。
- en: 'Understanding data types is important to make the right decisions on ML projects.
    We can split data types into two main categories: numerical and categorical data.
    Numerical data can then be split into continuous or discrete subclasses, while
    categorical data might refer to ordinal or nominal data:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 理解数据类型对于在机器学习项目中做出正确的决策非常重要。我们可以将数据类型分为两大类：数值数据和分类数据。数值数据可以进一步分为连续或离散子类，而分类数据可能指的是有序或名义数据：
- en: '*Numerical/discrete data* refers to individual and countable items (for example,
    the number of students in a classroom or the number of items in an online shopping
    cart).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数值/离散数据*指的是单个和可数的项目（例如，教室里的学生数量或在线购物车中的商品数量）。'
- en: '*Numerical/continuous data* refers to an infinite number of possible measurements
    and they often carry decimal points (for example, temperature).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数值/连续数据*指的是无限多的可能测量值，它们通常带有小数点（例如，温度）。'
- en: '*Categorical/nominal data* refers to labeled variables with no quantitative
    value (for example, name or gender).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分类/名义数据*指的是没有定量值的标记变量（例如，姓名或性别）。'
- en: '*Categorical/ordinal data* adds the sense of order to a labeled variable (for
    example, education level or employee title level).'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分类/有序数据*为标记变量增加了顺序感（例如，教育水平或员工职称等级）。'
- en: 'In other words, when choosing an algorithm for your project, you should ask
    yourself: do I have a target variable? Does it store categorical or numerical
    data? Answering these questions will put you in a better position to choose a
    potential algorithm that will solve your problem.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，在选择项目算法时，你应该问自己：我有一个目标变量吗？它存储的是分类数据还是数值数据？回答这些问题将使你处于更好的位置来选择一个可能解决问题的潜在算法。
- en: However, what if you don't have a target variable? In that case, we are facing
    unsupervised learning. Unsupervised problems do not provide labeled data; instead,
    they provide all the independent variables (or features) that will allow unsupervised
    algorithms to find patterns in the data. The most common type of unsupervised
    learning is **clustering**, which aims to group the observations of the dataset
    into different clusters, purely based on their features. Observations from the
    same cluster are expected to be similar to each other, but very different from
    observations from other clusters. Clustering will be covered in more detail in
    future chapters of this book.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你没有目标变量怎么办？在这种情况下，我们面临的是无监督学习。无监督问题不提供标记数据；相反，它们提供所有独立的变量（或特征），这将允许无监督算法在数据中找到模式。最常见的一种无监督学习是**聚类**，其目的是将数据集的观测值分组到不同的簇中，纯粹基于它们的特征。来自同一簇的观测值预计将彼此相似，但与其他簇的观测值非常不同。聚类将在本书的后续章节中更详细地介绍。
- en: '**Semi-supervised learning** is also present in the ML literature. This type
    of algorithm is able to learn from partially labeled data (some observations contain
    a label and others do not).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**半监督学习**在机器学习文献中也有所提及。这类算法能够从部分标记的数据（一些观测值包含标签，而另一些则没有）中学习。'
- en: Finally, another learning approach that has been taken by another class of ML
    algorithms is **reinforcement learning**. This approach rewards the system based
    on the good decisions that it has made autonomously; in other words, the system
    learns by experience.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，另一种被另一类机器学习算法采用的学习方法是**强化学习**。这种方法根据系统自主做出的良好决策进行奖励；换句话说，系统通过经验学习。
- en: We have been discussing learning approaches and classes of algorithms at a very
    broad level. However, it is time to get specific and introduce the term **model**.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在非常广泛地讨论学习方法和算法类别。然而，现在是时候具体化并引入**模型**这个术语了。
- en: The CRISP-DM modeling life cycle
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CRISP-DM建模生命周期
- en: '**Modeling** is a very common term used in ML when we want to specify the steps
    taken to solve a particular problem. For example, we could create a binary classification
    model to predict whether those transactions from *Figure 1.2* are fraudulent or
    not.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**建模**是机器学习中一个非常常见的术语，当我们想要指定解决特定问题的步骤时使用。例如，我们可以创建一个二元分类模型来预测*图1.2*中的交易是否为欺诈。'
- en: 'A model, in this context, represents all the steps to create a solution as
    a whole, which includes (but is not limited to) the algorithm. The **Cross-Industry
    Standard Process for Data Mining**, more commonly referred to as **CRISP-DM**,
    is one of the methodologies that provides guidance on the common steps we should
    follow to create models. This methodology is widely used by the market and is
    covered in the AWS Machine Learning Specialty exam:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个背景下，一个模型代表创建解决方案的所有步骤，作为一个整体，包括（但不限于）算法。**跨行业数据挖掘标准流程**，更常被称为**CRISP-DM**，是提供指导我们应遵循的常见步骤以创建模型的方法之一。这种方法在市场上被广泛使用，并在AWS机器学习专业考试中有所涉及：
- en: '![Figure 1.4 – CRISP-DM methodology'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.4 – CRISP-DM方法论'
- en: '](img/B16735_01_004.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16735_01_004.jpg](img/B16735_01_004.jpg)'
- en: Figure 1.4 – CRISP-DM methodology
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – CRISP-DM方法论
- en: Everything starts with business understanding, which will produce the business
    objectives (including success criteria), situation assessment, data mining goals,
    and project plan (with an initial assessment of tools and techniques). During
    the situation assessment, we should also look into an inventory of resources,
    requirements, assumptions and constraints, risks, terminology, costs, and benefits.
    Every single assumption and success criterion matters when we are modeling.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一切始于业务理解，这将产生业务目标（包括成功标准），情况评估，数据挖掘目标，以及项目计划（包括对工具和技术的初步评估）。在情况评估期间，我们还应该考虑资源清单、需求、假设和约束、风险、术语、成本和收益。当我们建模时，每一个假设和成功标准都很重要。
- en: Then we pass on to data understanding, where we will collect raw data, describe
    it, explore it, and check its quality. This is an initial assessment of the data
    that will be used to create the model. Again, data scientists must be skeptical.
    You must be sure you understand all the nuances of the data and its source.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们进入数据理解阶段，在这个阶段我们将收集原始数据，描述它，探索它，并检查其质量。这是对将要用于创建模型的数据的初步评估。再次强调，数据科学家必须保持怀疑态度。你必须确保你理解数据的所有细微差别及其来源。
- en: The data preparation phase is actually the one that usually consumes most of
    the time during modeling. In this phase, we need to select and filter the data,
    clean it according to the task that needs to be performed, come up with new attributes,
    integrate the data with other data sources, and format it as expected by the algorithm
    that will be applied. These tasks are often called **feature engineering**.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备阶段实际上是建模过程中通常耗时最多的一个阶段。在这个阶段，我们需要选择和过滤数据，根据需要执行的任务对其进行清理，提出新的属性，将数据与其他数据源集成，并按照将要应用的算法的预期格式化。这些任务通常被称为**特征工程**。
- en: 'Once the data is prepared, we can finally start the modeling phase. Here is
    where the algorithms come in. We should start by ensuring the selection of the
    right technique. Remember: according to the presence or absence of a target variable
    (and its data type), we will have different algorithms to choose from. Each modeling
    technique might carry some implicit assumptions of which we have to be aware.
    For example, if you choose a multiple linear regression algorithm to predict house
    prices, you should be aware that this type of model expects a linear relationship
    between the variables of your data.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据准备就绪，我们就可以最终开始建模阶段。这是算法发挥作用的地方。我们应该首先确保选择正确的技术。记住：根据是否存在目标变量（及其数据类型），我们将有不同的算法可供选择。每种建模技术可能都包含一些隐含的假设，我们必须意识到。例如，如果你选择多重线性回归算法来预测房价，你应该意识到这种类型的模型期望你的数据变量之间存在线性关系。
- en: There are hundreds of algorithms out there and each of them might have its own
    assumptions. After choosing the ones that you want to test in your project, you
    should spend some time checking their specifics. In later chapters of this book,
    we will cover some of them.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有许多算法，每个算法可能都有自己的假设。在选择你想要在项目中测试的算法之后，你应该花一些时间检查它们的细节。本书的后续章节中，我们将介绍其中的一些。
- en: Important note
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Some algorithms incorporate in their logic what we call **feature selection**.
    This is a step where the most important features will be selected to build your
    best model. Decision trees are examples of algorithms that perform feature selection
    automatically. We will cover feature selection in more detail later on, since
    there are different ways to select the best variables for your model.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一些算法在其逻辑中包含了我们所说的**特征选择**。这是一个选择最重要的特征以构建最佳模型的过程。决策树是自动执行特征选择的算法的例子。我们将在稍后更详细地介绍特征选择，因为有不同的方法来选择最适合你模型的变量。
- en: During the modeling phase, you should also design a testing approach for the
    model, defining which evaluation metrics will be used and how the data will be
    split. With that in place, you can finally build the model by setting the hyperparameters
    of the algorithm and feeding the model with data. This process of feeding the
    algorithm with data to find a good estimator is known as the **training process**.
    The data used to feed the model is known as **training data**. There are different
    ways to organize the training and **testing data**, which we will cover in this
    chapter.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在建模阶段，你还应该为模型设计一个测试方法，定义将使用哪些评估指标以及数据如何分割。有了这些，你就可以通过设置算法的超参数并给模型提供数据来最终构建模型。这个过程被称为**训练过程**。用于给模型提供数据的数据被称为**训练数据**。有不同方式来组织训练和**测试数据**，我们将在本章中介绍。
- en: Important note
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: ML algorithms are built by parameters and hyperparameters. These are learned
    from the data. For example, a decision-tree-based algorithm might learn from the
    training data that a particular feature should compose its root level based on
    information gain assessments. Hyperparameters, on the other hand, are used to
    control the learning process. Taking the same example about decision trees, we
    could specify the maximum allowed depth of the tree by specifying a pre-defined
    hyperparameter of any decision tree algorithm (regardless of the underlining training
    data). Hyperparameter tuning is a very important topic in the exam and will be
    covered in fine-grained detail later on.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法是由参数和超参数构建的。这些是从数据中学习得到的。例如，基于决策树的算法可能从训练数据中学习到，某个特征应该根据信息增益评估来组成其根级别。另一方面，超参数用于控制学习过程。以相同的决策树示例，我们可以通过指定任何决策树算法（无论其底层训练数据如何）的预定义超参数来指定树的最大允许深度。超参数调整是考试中的一个非常重要的话题，我们将在稍后详细讨论。
- en: Once the model is trained, we can evaluate and review results in order to propose
    the next steps. If results are not acceptable (based on our business success criteria),
    we should come back to earlier steps to check what else can be done to improve
    the model results. It can either be a small tuning in the hyperparameters of the
    algorithm, a new data preparation step, or even a redefinition of business drivers.
    On the other hand, if the model quality is acceptable, we can move to the deployment
    phase.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，我们可以评估和审查结果，以便提出下一步的行动计划。如果结果不符合我们的业务成功标准，我们应该回到早期步骤，检查还能做些什么来改善模型结果。这可能包括对算法的超参数进行微调，增加新的数据处理步骤，甚至重新定义业务驱动因素。另一方面，如果模型质量可以接受，我们可以进入部署阶段。
- en: 'In this last phase of the CRISP-DM methodology, we have to think about the
    deployment plan, monitoring, and maintenance of the model. We usually look at
    this step from two perspectives: training and inference. The **training pipeline**
    consists of those steps needed to train the model, which includes data preparation,
    hyperparameter definition, data splitting, and model training itself. Somehow,
    we must store all the model artifacts somewhere, since they will be used by the
    next pipeline that needs to be developed: the **inference pipeline**.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在CRISP-DM方法的最后一个阶段，我们必须考虑模型的部署计划、监控和维护。我们通常从两个角度来考虑这一步：训练和推理。**训练流程**包括训练模型所需的步骤，这包括数据准备、超参数定义、数据拆分和模型训练本身。我们必须在某处存储所有模型工件，因为它们将被下一个需要开发的流程使用：**推理流程**。
- en: The inference pipeline just uses model artifacts to execute the model against
    brand-new observations (data that has never been seen by the model during the
    training phase). For example, if the model was trained to identify fraudulent
    transactions, this is the time where new transactions will pass through the model
    to be classified.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 推理流程仅使用模型工件来对全新的观测（在训练阶段从未被模型见过的数据）执行模型。例如，如果模型被训练来识别欺诈交易，那么这就是新交易将通过模型进行分类的时候。
- en: In general, models are trained once (through the training pipeline) and executed
    many times (through the inference pipeline). However, after some time, it is expected
    that there will be some model degradation, also known as **model drift**. This
    phenomenon happens because the model is usually trained in a static training set
    that aims to represent the business scenario at a given point in time; however,
    businesses evolve, and it might be necessary to retrain the model on more recent
    data to capture new business aspects. That's why it is important to keep tracking
    model performance even after model deployment.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，模型只通过训练流程进行一次训练，并通过推理流程多次执行。然而，经过一段时间后，预期会出现一些模型退化，也称为**模型漂移**。这种现象发生是因为模型通常在静态的训练集上训练，旨在代表某一时间点的业务场景；然而，业务是不断发展的，可能需要使用更近期的数据重新训练模型以捕捉新的业务方面。这就是为什么在模型部署后，跟踪模型性能同样重要的原因。
- en: 'The CRISP-DM methodology is so important to the context of the AWS Machine
    Learning Specialty exam that, if you look at the four domains covered by AWS,
    you will realize that they were generalized from the CRISP-DM stages: data engineering,
    exploratory data analysis, modeling, and ML implementation and operations.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: CRISP-DM方法对于AWS机器学习专业考试的内容至关重要，如果你查看AWS涵盖的四个领域，你会意识到它们是从CRISP-DM阶段概括出来的：数据工程、探索性数据分析、建模和机器学习实施与运营。
- en: We now understand all the key stages of a modeling pipeline and we know that
    the algorithm itself is just part of a broad process! Next, let's see how we can
    split our data to create and validate ML models.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经理解了建模流程的所有关键阶段，并且我们知道算法本身只是广泛过程的一部分！接下来，让我们看看我们如何拆分数据以创建和验证机器学习模型。
- en: Data splitting
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据拆分
- en: Training and evaluating ML models are key tasks of the modeling pipeline. ML
    algorithms need data to find relationships among features in order to make inferences,
    but those inferences need to be validated before they are moved to production
    environments.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和评估机器学习模型是建模流程中的关键任务。机器学习算法需要数据来发现特征之间的关系，以便进行推断，但这些推断在移至生产环境之前需要得到验证。
- en: The dataset used to train ML models is commonly called the training set. This
    training data must be able to represent the real environment where the model will
    be used; it will be useless if that requirement is not met.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练机器学习模型的集合通常被称为训练集。这些训练数据必须能够代表模型将使用的真实环境；如果不符合这一要求，将毫无用处。
- en: Coming back to our fraud example presented in *Figure 1.2*, based on the training
    data, we found that e-commerce transactions with a value greater than $5,000 and
    processed at night are potentially fraudulent cases. With that in mind, after
    applying the model in a production environment, the model is supposed to flag
    similar cases, as learned during the training process.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们在*图1.2*中提出的欺诈示例，根据训练数据，我们发现价值超过5,000美元且在夜间处理的电子商务交易可能是欺诈案例。考虑到这一点，在将模型应用于生产环境后，模型应该标记出在训练过程中学习到的类似案例。
- en: 'Therefore, if those cases only exist in the training set, the model will flag
    **false positive** cases in production environments. The opposite scenario is
    also valid: if there is a particular fraud case in production data, not reflected
    in the training data, the model will flag a lot of **false negative** cases. False
    positives and false negatives ratios are just two of many quality metrics that
    we can use for model validation. These metrics will be covered in much more detail
    later on.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果这些情况仅存在于训练集中，模型将在生产环境中标记**假阳性**案例。相反的情况也是有效的：如果生产数据中存在某个未反映在训练数据中的欺诈案例，模型将标记大量的**假阴性**案例。假阳性和假阴性比率只是我们可以用于模型验证的许多质量指标中的两个。这些指标将在稍后的内容中详细讨论。
- en: 'By this point, you should have a clear understanding of the importance of having
    a good training set. Now, supposing we do have a valid training set, how could
    we have some level of confidence that this model will perform well in production
    environments? The answer is: using testing and validation sets:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您应该已经清楚地理解了拥有一个好的训练集的重要性。现在，假设我们确实有一个有效的训练集，我们如何能够有一定程度的信心认为这个模型将在生产环境中表现良好？答案是：使用测试集和验证集：
- en: '![Figure 1.5 – Data splitting'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.5 – 数据拆分]'
- en: '](img/B16735_01_005.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片B16735_01_005.jpg]'
- en: Figure 1.5 – Data splitting
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 – 数据拆分
- en: '*Figure 1.5* shows the different types of data splitting that we can have during
    training and inference pipelines. The training data is the one used to create
    the model and the testing data is the one used to extract final model quality
    metrics. The testing data *cannot* be used during the training process for any
    reason other than to extract model metrics.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.5*展示了在训练和推理管道中我们可以有的不同数据拆分方式。训练数据是用于创建模型的数据，而测试数据是用于提取最终模型质量指标的数据。出于任何原因，除了提取模型指标之外，测试数据都不能在训练过程中使用。'
- en: 'The reason to avoid using the testing data during training is simple: we *cannot*
    let the model learn on top of the data that will be used to validate it. This
    technique of holding one piece of the data for testing is often called **hold-out
    validation**.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 避免在训练过程中使用测试数据的原因很简单：我们**不能**让模型在用于验证的数据之上进行学习。这种保留一部分数据用于测试的技术通常被称为**保留法验证**。
- en: The box on the right side of *Figure 1.5* represents the production data. Production
    data usually comes in continuously and we have to execute the inference pipeline
    in order to extract model results from it. No training, nor any other type of
    recalculation, is performed on top of production data; we just have to pass it
    through the inference pipeline as it is.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.5*右侧的框代表生产数据。生产数据通常连续不断地到来，我们必须执行推理管道以从中提取模型结果。在生产数据上不进行任何训练，也不进行任何其他类型的重新计算；我们只需将其作为它本身通过推理管道即可。'
- en: From a technical perspective, most of the ML libraries implement training steps
    with the `.fit` method, while inference steps are implemented by the `.transform`
    *or* `.predict` method. Again, this is just a common pattern used by most ML libraries,
    but be aware that you might find different name conventions across ML libraries.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术角度来看，大多数机器学习库使用`.fit`方法实现训练步骤，而推理步骤则通过`.transform`或`.predict`方法实现。再次强调，这只是一个大多数机器学习库使用的常见模式，但请注意，您可能会在不同的机器学习库中找到不同的命名约定。
- en: Still looking at *Figure 1.5*, there is another box, close to the training data,
    named **validation data**. This is a subset of the training set often used to
    support the creation of the best model, before moving to the testing phase. We
    will talk about that box in much more detail, but first, let's explain why we
    need them.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting and underfitting
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ML models might suffer from two types of fitting issues: **overfitting** and
    **underfitting**. Overfitting means that your model performs very well in the
    training data, but cannot be generalized to other datasets, such as testing and,
    even worse, production data. In other words, if you have an overfitted model,
    it only works on your training data.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: When we are building ML models, we want to create solutions that are able to
    generalize what they have learned and infer decisions on other datasets that follow
    the same data distribution. A model that only works on the data that it was trained
    on is useless. Overfitting usually happens due to the large number of features
    or the lack of configuration of the hyperparameters of the algorithm.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, underfitted models cannot fit the data during the training
    phase. As a result, they are so generic that they can't perform well with the
    training, testing, or production data. Underfitting usually happens due to the
    lack of good features/observations or due to the lack of time to train the model
    (some algorithms need more iterations to properly fit the model).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Both overfitting and underfitting need to be avoided. There are many modeling
    techniques to work around that. For instance, let's focus on the commonly used
    **cross-validation** technique and its relationship with the validation box showed
    in *Figure 1.5*.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Applying cross-validation and measuring overfitting
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cross-validation is a technique where we split the training set into training
    and validation sets. The model is then trained on the training set and tested
    on the validation set. The most common cross-validation strategy is known as **k-fold
    cross validation**, where *k* is the number of splits of the training set.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'Using k-fold cross-validation and assuming the value of *k* equals 10, we are
    splitting the train set into 10 folds. The model will be trained and tested 10
    times. On each iteration, it uses nine splits for training and leaves one split
    for testing. After 10 executions, the evaluation metrics extracted from each iteration
    are averaged and will represent the final model performance during the training
    phase, as shown in *Figure 1.6*:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6 – Cross-validation in action'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16735_01_006.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.6 – Cross-validation in action
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Another common cross-validation technique is known as **leave one out cross-validation**
    (**LOOCV**). In this approach, the model is executed many times and, with each
    iteration, one observation is separated for testing and all the others are used
    for training.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many advantages of using cross-validation during training:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: We mitigate overfitting in the training data, since the model is always trained
    on a particular chunk of data and tested on another chunk that hasn't been used
    for training.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We avoid overfitting in the test data, since there is no need to keep using
    the testing data to optimize the model.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We expose the presence of overfitting or underfitting. If the model performance
    in the training/validation data is very different from the performance observed
    in the testing data, something is wrong.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's elaborate a little more on the third item on that list, since this is
    covered in the AWS Machine Learning Specialty exam. Let's assume we are creating
    a binary classification model, using cross-validation during training and using
    a testing set to extract final metrics (hold-out validation). If we get 80% accuracy
    in the cross-validation results and 50% accuracy in the testing set, it means
    that the model was overfitted to the train set, and cannot be generalized to the
    test set.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if we get 50% accuracy in the training set and 80% accuracy
    in the test set, there is a systemic issue in the data. It is very likely that
    the training and testing sets do not follow the same distribution.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy is a model evaluation metric commonly used on classification models.
    It measures how often the model made a correct decision during its inference process.
    We have selected this metric just for the sake of example, but be aware that there
    are many other evaluation metrics applicable for each type of model (which will
    be covered at the appropriate time).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping methods
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cross-validation is a good strategy to validate ML models, and you should try
    it in your daily activities as a data scientist. However, you should also know
    about other resampling techniques available out there. **Bootstrapping** is one
    of them.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: While cross-validation works **with no replacement**, a bootstrapping approach
    works **with replacement**. With replacement means that, while you are drawing
    multiple random samples from a population dataset, the same observation might
    be duplicated across samples.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'Usually, bootstrapping is not used to validate models as we do in the traditional
    cross-validation approach. The reason is simple: since it works with replacement,
    the same observation used for training could potentially be used for testing,
    too. This would result in inflated model performance metrics, since the estimator
    is likely to be correct when predicting an observation that was already seen in
    the training set.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping is often used by ML algorithms in an embedded way that requires
    resampling capabilities to process the data. In this context, bootstrapping is
    not being used to *validate* the model, but to *create* the model. **Random forest**,
    which will be covered in the algorithms chapter, is one of those algorithms that
    uses bootstrapping internally for model building.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Designing a good data splitting/sampling strategy is crucial to the success
    of the model or the algorithm. You should come up with different approaches to
    split your data, check how the model is performing on each split, and make sure
    those splits represent the real scenario where the model will be used.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: The variance versus bias trade-off
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Any ML model is supposed to contain errors. There are three types of errors
    that we can find on models: **bias** error, **variance** error, and **unexplained**
    error. The last one, as expected, cannot be explained. It is often related to
    the context of the problem and the relationships between the variables, and we
    can''t control it.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: The other two errors can be controlled during modeling. We usually say that
    there is a trade-off between bias and variance errors because one will influence
    the other. In this case, increasing bias will decrease variance and vice versa.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Bias error relates to assumptions taken by the model to learn the target function,
    the one that we want to solve. Some types of algorithms, such as linear algorithms,
    usually carry over that type of error because they make a lot of assumptions during
    model training. For example, linear models assume that the relationship present
    in the data is linear. Linear regression and logistic regression are types of
    algorithms that, in general, contain high bias. Decision trees, on the other hand,
    are types of algorithms that make fewer assumptions about the data and contain
    less bias.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Variance relates to the difference of estimations that the model performs on
    different training data. Models with high variance usually overfit to the training
    set. Decision trees are examples of algorithms with high variance (they usually
    rely a lot on specifics of the training set, failing to generalize), and linear/logistic
    regression are examples of algorithms with low variance. It does not mean that
    decision trees are bad estimators; it just means that we need to prune (optimize)
    them during training.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: That said, the goal of any model is to minimize both bias and variance. However,
    as already mentioned, each one will impact the other in the opposite direction.
    For the sake of demonstration, let's use a decision tree to understand how this
    trade-off works.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees are nonlinear algorithms and often contain low bias and high
    variance. In order to decrease variance, we can prune the tree and set the `max_depth`
    hyperparameter (the maximum allowed depth of the tree) to 10\. That will force
    a more generic model, reducing variance. However, that change will also force
    the model to make more assumptions (since it is now more generic) and increase
    bias.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Shuffling your training set
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you know what variance and data splitting are, let's dive a little
    deeper into the training dataset requirements. You are very likely to find questions
    around data shuffling in the exam. This process consists of randomizing your training
    dataset before you start using it to fit an algorithm.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Data shuffling will help the algorithm to reduce variance by creating a more
    generalizable model. For example, let's say your training represents a binary
    classification problem and it is sorted by the target variable (all cases belonging
    to class "0" appear first, then all the cases belonging to class "1").
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: When you fit an algorithm on this sorted data (especially some algorithms that
    rely on **batch processing**), it will take strong assumptions on the pattern
    of one of the classes, since it is very likely that it won't be able to create
    random batches of data with a good representation of both classes. Once the algorithm
    builds strong assumptions about the training data, it might be difficult for it
    to change them.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Some algorithms are able to execute the training process by fitting the data
    in chunks, also known as batches. This approach lets the model learn more frequently,
    since it will make partial assumptions after processing each batch of data (instead
    of making decisions only after processing the entire dataset).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, there is no need to shuffle the test set, since it will be
    used only by the inference process to check model performance.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Modeling expectations
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have talked about model building, validation, and management. Let's
    complete the foundations of ML by talking about a couple of other expectations
    while modeling.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'The first one is **parsimony**. Parsimony describes models that offer the simplest
    explanation and fits the best results when compared with other models. Here''s
    an example: while creating a linear regression model, you realize that adding
    10 more features will improve your model performance by 0.001%. In this scenario,
    you should consider whether this performance improvement is worth the cost of
    parsimony (since your model will become more complex). Sometimes it is worth it,
    but most of the time it is not. You need to be skeptical and think according to
    your business case.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'Parsimony directly supports **interpretability**. The simpler your model is,
    the easier it is to explain it. However, there is a battle between interpretability
    and **predictivity**: if you focus on predictive power, you are likely to lose
    some interpretability. Again, be a proper data scientist and select what is better
    for your use case.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Introducing ML frameworks
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Being aware of some ML frameworks will put you in a much better position to
    pass the AWS Machine Learning Specialty exam. There is no need to master these
    frameworks, since this is not a framework-specific certification; however, knowing
    some common terms and solutions will help you to understand the context of the
    problems/questions.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '**scikit-learn** is probably the most important ML framework that you should
    be aware of. This is an open source Python package that provides implementations
    of ML algorithms such as decision trees, support vector machines, linear regression,
    and many others. It also implements classes for data preprocessing, for example,
    one-hot encoding, a label encoder, principal component analysis, and so on. All
    these preprocessing methods (and many others) will be covered in later sections
    of this book.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'The downside of scikit-learn is the fact that it needs customization to scale
    up through multiple machines. There is another ML library that is very popular
    because of the fact that it can handle multiprocessing straight away: **Spark''s
    ML library**.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: As the name suggests, this is an ML library that runs on top of **Apache Spark**,
    which is a unified analytical multi-processing framework used to process data
    on multiple machines. AWS offers a specific service that allows developers to
    create Spark clusters with a few clicks, known as **EMR**.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: The Spark ML library is in constant development. As of the time of writing,
    it offers support to many ML classes of algorithms, such as classification and
    regression, clustering, and collaborative filtering. It also offers support for
    basic statistics computation, such as correlations and some hypothesis tests,
    as well as many data transformations, such as one-hot encoding, principal component
    analysis, min-max scaling, and others.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Another very popular ML framework is known as **TensorFlow**. This ML framework
    was created by the Google team and it is used for numerical computation and large-scale
    ML model development. TensorFlow implements not only traditional ML algorithms,
    but also DL models.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is considered a low-level API for model development, which means
    that it can be very complex to develop more sophisticated models, such as **transformers**,
    for text mining. As an attempt to facilitate model development, other ML frameworks
    were built on top of TensorFlow to make it easier. One of these high-level frameworks
    is **Keras**. With Keras, developers can create complex DL models with just a
    few lines of code. More recently, Keras was incorporated into TensorFlow and it
    can be now called inside the TensorFlow library.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '**MXNet** is another open source DL library. Using MXNet, we can scale up neural
    network-based models using multiple GPUs running on multiples machines. It also
    supports different programming languages, such as Python, R, Scala, and Java.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '**Graphical processing unit** (**GPU**) support is particularly important in
    DL libraries such as TensorFlow and MXNet. These libraries allow developers to
    create and deploy neural network-based models with multiple layers. The training
    process of neural networks relies a lot on matrix operations, which perform much
    better on GPUs than on CPUs. That''s why these DL libraries offer GPU support.
    AWS also offers EC2 instances with GPU enabled.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: These ML frameworks need a special channel to communicate with GPU units. NVIDIA,
    the most common supplier of GPUs nowadays, has created an API called the **Compute
    Unified Device Architecture** (**CUDA**). CUDA is used to configure GPU units
    on NVIDIA devices, for example, setting up caching memory and the number of threads
    needed to train a neural network model. There is no need to master CUDA or GPU
    architecture for the AWS Machine Learning Specialty exam, but you definitely need
    to know what they are and how DL models take advantage of them.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Last, but not least, you should also be aware of some development frameworks
    widely used by the data science community, but not necessarily to do ML. These
    frameworks interoperate with ML libraries to facilitate data manipulation and
    calculations. For example, **pandas** is a Python library that provides data processing
    capabilities, and **NumPy** is an open source Python library that provides numerical
    computing.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: These terms and libraries are so incorporated into data scientists' daily routines
    that they might come up during the exam to explain some problem domain for you.
    Being aware of what they are will help you to quickly understand the context of
    the question.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: ML in the cloud
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML has gone to the cloud and developers can now use it as a service. AWS has
    implemented ML services in different levels of abstraction. ML application services,
    for example, aim to offer out-of-the-box solutions for specific problem domains.
    **AWS Lex** is a very clear example of an ML application as a service, where people
    can implement chatbots with minimum development.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '**AWS Rekognition** is another example, which aims to identify objects, people,
    text, scenes, and activities in images and videos. AWS provides many other ML
    application services that will be covered in the next chapter of this book.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Apart from application services, AWS also provides ML development platforms,
    which is the case with **SageMaker**. Unlike out-of-the-box services such as AWS
    Lex and Rekognition, SageMaker is a development platform that will let you build,
    train, and deploy your own models with much more flexibility.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker speeds up the development and deployment process by automatically
    handling the necessary infrastructure for the training and inference pipelines
    of your models. Behind the scenes, SageMaker orchestrates other AWS services (such
    as EC2 instances, load balancers, auto-scaling, and so on) to create a scalable
    environment for ML projects. SageMaker is probably the most important service
    that you should master for the AWS Machine Learning Specialty exam, and it will
    be covered in detail in a separate section. For now, you should focus on understanding
    the different approaches that AWS uses to offers ML-related services.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'The third option that AWS offers for deploying ML models is the most generic
    and flexible one: you can deploy ML models by combining different AWS services
    and managing them individually. This is essentially doing what SageMaker does
    for you, building your applications from scratch. For example, you could use EC2
    instances, load balancers, auto-scaling, and an API gateway to create an inference
    pipeline to a particular model. If you prefer, you can also use AWS serverless
    architecture to deploy your solution, for example, using **AWS Lambda functions**.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now heading to the end of this chapter, where we have covered several
    important topics about the foundations of ML. We started the chapter with a theoretical
    discussion about AI, ML, and DL and how this entire field has grown over the past
    few years due to the advent of big data platforms and cloud providers.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: We then moved on to the differences between supervised, unsupervised, and reinforcement
    learning, highlighting some use cases related to each of them. This is likely
    to be a topic in the AWS Machine Learning Specialty exam.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: We discussed that an ML model is built in many different stages and the algorithm
    itself is just one part of the modeling process. We also covered the expected
    behaviors of a good model.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: We did a deep dive into data splitting, where we talked about different approaches
    to train and validate models, and we covered the mythic battle between variance
    and bias. We completed the chapter by talking about ML frameworks and services.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Coming up next, you will learn about AWS application services for ML, such as
    Amazon Polly, Amazon Rekognition, Amazon Transcribe, and many other AI-related
    AWS services. But first, let's look into some sample questions to give you an
    idea of what you could expect in the exam.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have been hired to automate an audible response unit from a call center
    company. Every time a new customer's call comes in, the system must be able to
    understand the current load of the service as well as the goal of the call and
    recommend the right path in the audible response unit. The company does not have
    labeled data to supervise the model; it must take an approach to learn by experience
    (trial and error) and every time the algorithm makes a good recommendation of
    path, it will be rewarded. Which type of machine learning approach would best
    fit this project?
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Unsupervised learning
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Reinforcement learning
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Supervised learning
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) DL
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b, Since there is no labeled data and the agent needs to learn by experience,
    reinforcement learning is more appropriate for this use case. Another important
    fact in the question is that the agent is rewarded for good decisions.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You are working in a marketing department of a big company and you need to segment
    your customers based on their buying behavior. Which type of ML approach would
    best fit this project?
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Unsupervised learning
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Reinforcement learning
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Supervised learning
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) DL
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a, Clustering (which is an unsupervised learning approach) is the most common
    type of algorithm to work with data segmentation/clusters.
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You are working in a retail company that needs to forecast sales for the next
    few months. Which type of ML approach would best fit this project?
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Unsupervised learning
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Reinforcement learning
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Supervised learning
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) DL
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c, Forecasting is a type of supervised learning that aims to predict a numerical
    value; hence, it might be framed as a regression problem and supervised learning.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A manufacturing company needs to understand how much money they are spending
    on each stage of their production chain. Which type of ML approach would best
    fit this project?
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Unsupervised learning.
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Reinforcement learning.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Supervised learning.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) ML is not required.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d, ML is everywhere, but not everything needs ML. In this case, there is no
    need to use ML since the company should be able to collect their costs from each
    stage of the production chain and sum it up.
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which one of the following learning approaches gives us state-of-the-art algorithms
    to implement chatbots?
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Unsupervised learning
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Reinforcement learning
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Supervised learning
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) DL
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d, DL has provided state-of-the-art algorithms in the field of natural language
    processing.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You receive a training set from another team to create a binary classification
    model. They have told you that the dataset was already shuffled and ready for
    modeling. You have decided to take a quick look at how a particular algorithm,
    based on a neural network, would perform on it. You then split the data into train
    and test sets and run your algorithm. However, the results look very odd. It seems
    that the algorithm could not converge to an optimal solution. What would be your
    first line of investigation on this issue?
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Make sure the algorithm used is able to handle binary classification models.
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Take a look at the proportion of data of each class and make sure they are
    balanced.
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Shuffle the dataset before starting working on it.
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Make sure you are using the right hyperparameters of the chosen algorithm.
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c, Data scientists must be skeptical about their work. Do not make assumptions
    about the data without prior validation. At this point in the book, you might
    not be aware of the specifics of neural networks, but you know that ML models
    are very sensitive to the data they are training on. You should double-check the
    assumptions that were passed to you before taking other decisions. By the way,
    shuffling your training data is the first thing you should do. This is likely
    to be present in the exam.
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have created a classification model to predict whether a banking transaction
    is fraud or not. During the modeling phase, your model was performing very well
    on both the training and testing sets. When you executed the model in a production
    environment, people started to complain about the low accuracy of the model. Assuming
    that there was no overfitting/underfitting problem during the training phase,
    what would be your first line of investigation?
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) The training and testing sets do not follow the same distribution.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) The training set used to create this model does not represent the real environment
    where the model was deployed.
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) The algorithm used in the final solution could not generalize enough to identify
    fraud cases in production.
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Since all ML models contain errors, we can't infer their performance in production
    systems.
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b, Data sampling is very challenging, and you should always make sure your training
    data can represent the production data as precisely as possible. In this case,
    there was no evidence that the training and testing sets were invalid, since the
    model was able to perform well and consistently on both sets of data. Since the
    problem happens to appear only in production systems, there might have been a
    systematic issue in the training that is causing the issue.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You are training a classification model with 500 features that achieves 90%
    accuracy in the training set. However, when you run it in the test set, you get
    only 70% accuracy. Which of the following options are valid approaches to solve
    this problem (select all that apply)?
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Reduce the number of features.
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Add extra features.
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Implement cross-validation during the training process.
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Select another algorithm.
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a, c, This is clearly an overfitting issue. In order to solve this type of problem,
    you could reduce the excessive number of features (which will reduce the complexity
    of the model and make it less dependent on the training set). Additionally, you
    could also implement cross-validation during the training process.
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You are training a neural network model and want to execute the training process
    as quickly as possible. Which of the following hardware architectures would be
    most helpful to you to speed up the training process of neural networks?
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Use a machine with a CPU that implements multi-thread processing.
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Use a machine with GPU processing.
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Increase the amount of RAM of the machine.
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Use a machine with SSD storage.
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b, Although you might take some benefits from multi-thread processing and large
    amounts of RAM, using a GPU to train a neural network will give you the best performance.
    You will learn much more about neural networks in later chapters of this book,
    but you already know that they perform a lot of matrix calculations during training,
    which is better supported by the GPU rather than the CPU.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following statements is *not* true about data resampling?
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Cross-validation is a data resampling technique that helps to avoid overfitting
    during model training.
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Bootstrapping is a data resampling technique often embedded in ML models
    that needs resampling capabilities to estimate the target function.
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) The parameter *k* in k-fold cross-validation specifies how many samples will
    be created.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Bootstrapping works without replacement.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answer
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d, All the statements about cross-validation and bootstrapping are correct except
    option *d*, since bootstrapping works with replacement (the same observations
    might appear on different splits).
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
