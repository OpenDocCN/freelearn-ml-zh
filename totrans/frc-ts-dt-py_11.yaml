- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Managing Uncertainty Intervals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Forecasting is essentially predicting the future, and with any prediction, there
    will be a particular amount of uncertainty. Quantifying this uncertainty provides
    an analyst with an understanding of how reliable their forecasts are, and provides
    their manager the confidence required to stake a lot of capital on a decision.
  prefs: []
  type: TYPE_NORMAL
- en: Prophet was designed from the ground up with uncertainty modeling in mind. Although
    you interact with it using either **Python** or **R**, the underlying model is
    built in the **Stan** programming language, a probabilistic language that allows
    Prophet to perform **Bayesian sampling** in an efficient manner to provide a deeper
    understanding of the uncertainty in the model, and thus the business risk of the
    forecast.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three sources of uncertainty that contribute to the total uncertainty
    in your Prophet model:'
  prefs: []
  type: TYPE_NORMAL
- en: Uncertainty in the trend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uncertainty in the seasonality, holidays, and additional regressors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uncertainty due to noise in the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The last of these is an inherent attribute of whatever data you are using,
    but the first two can be modeled and examined. In this chapter, you will learn
    how Prophet models uncertainty, how you can control it in your model, and how
    you can use these uncertainty estimations to quantify risk. Specifically, this
    chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Modeling uncertainty in trends
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling uncertainty in seasonality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data files and code for the examples in this chapter can be found at [https://github.com/PacktPublishing/Forecasting-Time-Series-Data-with-Prophet-Second-Edition](https://github.com/PacktPublishing/Forecasting-Time-Series-Data-with-Prophet-Second-Edition).
  prefs: []
  type: TYPE_NORMAL
- en: Modeling uncertainty in trends
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You may have noticed in different component plots throughout this book that
    the trend shows uncertainty bounds, while the seasonality curves do not. By default,
    Prophet only estimates uncertainty in the trend, plus uncertainty due to random
    noise in the data. The noise is modeled as a normal distribution around the trend
    and trend uncertainty is modeled with **maximum a posteriori** (**MAP**) **estimation**.
  prefs: []
  type: TYPE_NORMAL
- en: MAP estimation is an optimization problem that is solved with **Monte Carlo
    simulations**. Named after the famous casino in Monaco, the Monte Carlo method
    uses repeated random sampling to estimate an unknown value, usually used when
    closed-form equations are either non-existent or computationally difficult.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B19630_06.xhtml#_idTextAnchor375), *Forecasting Holiday Effects*,
    we talked about `model.fit(df)` call.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at some Prophet parameters you can use to control trend uncertainty.
    We’re going to use a new dataset in this chapter, covering the number of crimes
    reported to the Baltimore police department each day from 2011 through 2019\.
    Let’s begin with our imports and loading the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If you plot the data, you’ll see that it has a relatively flat trend, seasonality,
    and a couple of outliers. In particular, I have drawn a dashed line in the following
    graph at the level of 250 crimes per day. There are two data points above this
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Baltimore crime data](img/Fig_11.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – Baltimore crime data
  prefs: []
  type: TYPE_NORMAL
- en: 'Although those points probably won’t affect our forecasts as much as the outliers
    did in the National Geographic data we looked at in [*Chapter 10*](B19630_10.xhtml#_idTextAnchor641),
    *Accounting for Outliers and Special Events*, let’s remove them and avoid any
    potential issues as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we imported NumPy and set the random seed. MAP estimation is a deterministic
    calculation in Prophet, so you will always get the same trend repeatedly (or,
    very nearly the same trend, due to slight differences in how different machines
    handle floating-point numbers). However, the uncertainty intervals are randomly
    created. With 1,000 iterations, they should be very similar in repeated experiments,
    but if no random seed was set, then your plots may not match those in this book.
    Furthermore, **Markov chain Monte Carlo** (**MCMC**) sampling, which is used when
    uncertainty estimates for seasonality are needed and will be discussed later in
    this chapter, does add randomness to the trend calculations. Setting the random
    seed will ensure that you get the same results as this book.
  prefs: []
  type: TYPE_NORMAL
- en: The biggest source of uncertainty in the Prophet forecast comes from the potential
    for future trend changes. When training the model, Prophet runs through many Monte
    Carlo simulations for the future, assuming that future trend changepoints will
    occur with the same frequency and magnitude as the historical changepoints. For
    this reason, a time series with large-magnitude changepoints in its history will
    see very wide trend uncertainty; we saw this with the National Geographic Instagram
    data in *Figure 10**.7* from [*Chapter 10*](B19630_10.xhtml#_idTextAnchor641),
    *Accounting for Outliers and* *Special Events*.
  prefs: []
  type: TYPE_NORMAL
- en: The number of Monte Carlo simulations Prophet runs through is set with the `uncertainty_samples`
    argument during model instantiation. By default, it is set to `1000`, so Prophet
    simulates 1,000 different future trend lines and uses these to estimate uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s build our first model explicitly stating this default by setting `uncertainty_samples=1000`
    when instantiating our model. We’ll then fit the model, create a five-year forecast,
    and plot it with the changepoints. For this Baltimore crime data, we can keep
    all the other defaults during model instantiation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'It looks like crime in Baltimore was up in 2011 at the beginning of the dataset,
    dropped a bit over the next few years, and then rose again, before dropping. Prophet
    continues this trend onward into the future:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Baltimore crime forecast with 1,000 uncertainty samples](img/Fig_11.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.2 – Baltimore crime forecast with 1,000 uncertainty samples
  prefs: []
  type: TYPE_NORMAL
- en: 'The uncertainty (the lighter-shaded area in the plot) exists throughout both
    the historical and future points. Now, let’s plot the components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The trend uncertainty only exists in the forecasted future; there is no uncertainty
    evident in the historical data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – Baltimore crime components plot with 1,000 uncertainty samples](img/Fig_11.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.3 – Baltimore crime components plot with 1,000 uncertainty samples
  prefs: []
  type: TYPE_NORMAL
- en: This is because all historical uncertainty is attributed to noise. As I said
    earlier, the noise is modeled as a normal distribution around the prediction.
    As trend uncertainty is due to uncertainty with future trend changepoints, trend
    uncertainty only exists in the future. The total uncertainty seen in *Figure 11**.2*
    is the noise uncertainty plus the trend uncertainty. Also, the Prophet team notes
    that their assumption that future trend changes will never be of greater magnitude
    than previous trend changes is a very limiting assumption, and so you should not
    expect to get extremely accurate coverage on uncertainty intervals.
  prefs: []
  type: TYPE_NORMAL
- en: 'When Prophet ran through those 1,000 iterations to estimate future trend changes,
    it saved each result in the `predictive_samples` attribute of the model. This
    is a dictionary with keys of `''yhat''` and `''trend''`, storing, respectively,
    the estimated values for the total prediction and the prediction of just the trend,
    for each iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'By plotting `samples[''trend'']` against `future[''ds'']`, for each sample,
    you can see each of Prophet’s 1,000 potential trend simulations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4 – Baltimore crime trend with 1,000 uncertainty samples](img/Fig_11.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.4 – Baltimore crime trend with 1,000 uncertainty samples
  prefs: []
  type: TYPE_NORMAL
- en: By default, Prophet has an uncertainty interval of 80%. Each of those 1,000
    possible trend lines are equally probable within an 80% confidence level. Because
    future uncertainty is estimated from future potential changepoints, which are,
    in turn, estimated from previous changepoints, increasing or decreasing the number
    of previous changepoints through the use of `changepoint_prior_scale` will have
    a matching effect on uncertainty bounds.
  prefs: []
  type: TYPE_NORMAL
- en: It is usually unnecessary to change the number of uncertainty samples to anything
    other than the default. Increasing it will give you a better estimate of uncertainty,
    at the cost of computing time, but 1,000 samples is usually plenty to get a good
    estimate. Setting the argument to either `uncertainty_samples=0` or `uncertainty_samples=False`
    is a special case, though, which disables uncertainty estimation and speeds up
    calculations significantly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The uncertainty level can be controlled through the `interval_width` argument.
    If you want more confidence in your uncertainty levels, you may want to increase
    this value; decreasing it will give you tighter limits but less confidence. Let’s
    increase the width to `0.99`, for a 99% confidence level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'I’ll only plot the trend, as that is where the effect of this change is most
    evident:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Compare the following diagram with the trend component in *Figure 11**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Baltimore crime trend with a 99% uncertainty interval width](img/Fig_11.5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5 – Baltimore crime trend with a 99% uncertainty interval width
  prefs: []
  type: TYPE_NORMAL
- en: The width of uncertainty is much greater in this plot. Because we want higher
    confidence that the bounds contain the true trend, we have to expand the bounds
    to provide this higher certainty.
  prefs: []
  type: TYPE_NORMAL
- en: You’ve been modeling trend uncertainty throughout this book. But now you want
    to see uncertainty bounds in seasonality as well. In the next section, you’ll
    learn how to accomplish this.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling uncertainty in seasonality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MAP estimation is very fast, which is why it is Prophet’s default mode, but
    it will not work with seasonalities, so a different method is needed. To model
    seasonality uncertainty, Prophet needs to use an MCMC method. A **Markov chain**
    is a model that describes a sequence of events, with the probability of each event
    depending upon the state in the previous event. Prophet models seasonal uncertainty
    with this chained sequence and uses the Monte Carlo method, which was described
    at the beginning of the previous section, to repeat the sequence many times.
  prefs: []
  type: TYPE_NORMAL
- en: The downside is that MCMC sampling is slow; on a macOS or Linux machine, you
    should expect fitting times of several minutes instead of several seconds. On
    a Windows machine, unfortunately, the PyStan API, which interfaces with Prophet’s
    model in the Stan language, has upstream issues, meaning MCMC sampling is extremely
    slow. Depending upon the number of data points, fitting a model on a Windows machine
    can sometimes take several hours.
  prefs: []
  type: TYPE_NORMAL
- en: The Prophet team recommends that users on Windows machines work with Prophet
    in R or use Python in a Linux virtual machine. Another alternative is to use Google’s
    Colab notebooks, which are similar to cloud-hosted Jupyter notebooks. They are
    free to use and are built in Linux, so they do not face the PyStan issues that
    Windows does. You can access them at [https://colab.research.google.com/](https://colab.research.google.com/).
  prefs: []
  type: TYPE_NORMAL
- en: 'With that caveat out of the way, let’s see how to model uncertainty in seasonality.
    We will leave the default `1000` uncertainty samples that we’ve used so far and
    add a different argument for `mcmc_samples`. If you set this argument to `0`,
    Prophet will revert to MAP estimation and only provide uncertainty in the trend
    component, reverting to the models we created in the previous examples in this
    chapter. We will use 300 MCMC samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'After fitting and predicting, we plot the forecast. The first thing that may
    jump out at you is the number of changepoints, as can be seen in the following
    graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.6 – Baltimore crime forecast with 300 MCMC samples](img/Fig_11.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.6 – Baltimore crime forecast with 300 MCMC samples
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll deal with that changepoint issue in a bit. Now though, let’s look at
    the components plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You should now see uncertainty intervals around both the `weekly` and `yearly`
    seasonalities as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Baltimore crime components plot with 300 MCMC samples](img/Fig_11.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.7 – Baltimore crime components plot with 300 MCMC samples
  prefs: []
  type: TYPE_NORMAL
- en: Had we added holidays or any additional regressors, you’d see uncertainty intervals
    there, too. Go ahead and try it out yourself, using the Divvy example from [*Chapter
    9*](B19630_09.xhtml#_idTextAnchor599), *Including* *Additional Regressors*.
  prefs: []
  type: TYPE_NORMAL
- en: In this model, we accepted the default `uncertainty_samples=1000` argument and
    set `mcmc_samples=300`. When Prophet runs its MCMC method, it uses a total of
    four chains (although this value can be changed using the keyword `chains` argument
    in the `fit` call). The `mcmc_samples` argument is the total number of samples
    generated per chain. This is different from the `uncertainty_samples` argument,
    which is the total number of sampled trend lines to generate.
  prefs: []
  type: TYPE_NORMAL
- en: When `mcmc_samples=0`, Prophet will generate exactly the number of potential
    trend lines as defined in the `uncertainty_samples` argument. However, when `mcmc_samples`
    is any value greater than zero, Prophet will generate *at least* the number of
    potential trend lines as defined in the `uncertainty_samples` argument, but potentially
    more as it needs to have the same number of iterations per chain. That all may
    be rather confusing, but it is just a small technicality. The only practical effect
    you may notice is that `model.predictive_samples(future)` may have fractionally
    more rows than you specified in `uncertainty_samples`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s get back to those changepoints. Why were there so many when performing
    MCMC sampling? If you remember from [*Chapter 8*](B19630_08.xhtml#_idTextAnchor537),
    *Influencing Trend Changepoints*, Prophet sets a high number of potential changepoints
    and tries to set their magnitude as low as possible. This works fine with MAP
    estimation. In a Bayesian analysis, however, as is the case in MCMC sampling,
    there is a well-known phenomenon that causes the parameters not to shrink in the
    same way.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a plot of the changepoint magnitudes of our first model shown in *Figure
    11**.2*, and our most recent model, in *Figure 11**.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Changepoint magnitudes resulting from different uncertainty
    estimations](img/Fig_11.8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.8 – Changepoint magnitudes resulting from different uncertainty estimations
  prefs: []
  type: TYPE_NORMAL
- en: The problem we have is not one of our modeling, just one of visualization. The
    two dashed lines in the preceding graphs show the default `0.01` threshold for
    plotting changepoint magnitudes in the `add_changepoints_to_plot` function (the
    dotted lines show an increased threshold of `0.1`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Changepoints that extend beyond this line were plotted in *Figure 11**.2*.
    The model plotted in *Figure 11**.6* has many more changepoints extending beyond
    this line, so they are plotted, too. However, the extra changepoints cancel each
    other out. They are negative and then positive. The overall effect is that the
    trends in both *Figure 11**.2* and *Figure 11**.6* are nearly identical:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 11.9 – Trend lines resulting from different changepoint uncertainty\
    \ estimations\uFEFF](img/Fig_11.9.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 11.9 – Trend lines resulting from different changepoint uncertainty estimations
  prefs: []
  type: TYPE_NORMAL
- en: 'The lesson from this is not to worry too much about it. If you want a more
    reasonable number of changepoints on your plot, feel free to change the `threshold`
    argument when adding the changepoints. Here, we change it to `0.1`, the level
    marked in *Figure 11**.8* with the dotted line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we see a similar number of changepoints as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.10 – Baltimore crime forecast with an increased changepoint threshold](img/Fig_11.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 – Baltimore crime forecast with an increased changepoint threshold
  prefs: []
  type: TYPE_NORMAL
- en: They are different changepoints but remember that this is just an issue that
    cropped up with visualization. The final trend in both models was very similar.
    The slight differences that arise are due to the different statistical sampling
    techniques; neither technique is more correct than the other – they are both estimations
    of the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'This isn’t always the case though. Sometimes you’ll see too many dramatic trend
    changes with MCMC sampling. If this happens, you can simply decrease your `changepoint_prior_scale`
    value and rein in those changepoint magnitudes a bit. For example, let’s decrease
    it from the `0.05` default value we’ve been using down to `0.03`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'At this level, we have fewer significant changepoints than in *Figure 11**.6*,
    as can be seen in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11 – Baltimore crime forecast with increased changepoint regularization](img/Fig_11.11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11 – Baltimore crime forecast with increased changepoint regularization
  prefs: []
  type: TYPE_NORMAL
- en: 'If we compare the trend lines, we see that this regularized line matches the
    original MAP estimation ever so slightly better:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 11.12 – Trend lines resulting from different changepoint prior scales\uFEFF\
    ](img/Fig_11.12.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 11.12 – Trend lines resulting from different changepoint prior scales
  prefs: []
  type: TYPE_NORMAL
- en: If you use MCMC sampling, just be sure to pay attention to the increased number
    of changepoints. If your trend line appears to be overfitting, you can simply
    reduce the changepoint prior scale to control it.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Uncertainty intervals are a vital tool for understanding your forecast. No prediction
    of the future can carry absolute confidence. By explicitly stating the confidence
    level in your model, you provide your audience with an understanding of the risk
    involved in the model’s predictions, to better guide their decisions.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you learned that all models built in previous chapters used
    MAP estimations to create confidence levels. This method requires less time to
    compute than the alternative, MCMC sampling, but can only model uncertainty in
    the trend component. Often, this is enough. However, for those times when you
    also need uncertainty stated for seasonality, holidays, or extra regressors, you
    also learned how to apply MCMC sampling in Prophet to build a more comprehensive
    model of uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you learned about an inherent weakness of MCMC sampling in terms of
    its ability to apply regularization to trend changepoints. You will usually see
    a larger quantity of significant changepoints in a Prophet model built with MCMC
    sampling than one built with MAP estimation. It is for this reason that you learned
    to pay close attention to trend overfitting when using MCMC sampling and to tune
    your changepoint prior scale accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you’ll learn about cross-validation in Prophet. You may
    be familiar with k-fold cross-validation from other machine learning applications;
    k-fold fails with time series. We will cover a different method, called forward
    chaining.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 3: Diagnostics and Evaluation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This final section will be about model evaluation and the next steps. You will
    learn how to use Prophet’s built-in performance metrics to compare different models
    in a statistically robust way and how to visualize their performance. Finally,
    the section will close out with some additional features of Prophet that could
    be used when deploying Prophet in real-world use cases, where updating models
    and sharing results are likely to be frequent occurrences.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 12*](B19630_12.xhtml#_idTextAnchor794), *Performing Cross-Validation*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 13*](B19630_13.xhtml#_idTextAnchor839), *Evaluating Performance Metrics*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 14*](B19630_14.xhtml#_idTextAnchor927), *Productionalizing Prophet*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
