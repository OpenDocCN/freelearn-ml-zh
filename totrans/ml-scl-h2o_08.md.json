["```py\nspark\n```", "```py\nfrom pysparkling import *\n```", "```py\nhc = H2OContext.getOrCreate()\n```", "```py\ndatafile = \"AmazonReviews_Train.csv\"\n```", "```py\nreviews_spark = spark.read.load(datafile, format=\"csv\",\n```", "```py\n    sep=\",\", inferSchema=\"true\", header=\"true\")\n```", "```py\nimport h2o\n```", "```py\nreviews_h2o = h2o.upload_file(datafile)\n```", "```py\nreviews_spark = hc.as_spark_frame(reviews_h2o)\n```", "```py\nreviews_spark.printSchema()\n```", "```py\nwith open('schema.json','w') as f:\n```", "```py\n    f.write(str(reviews_spark.schema.json()))\n```", "```py\nfrom pyspark.ml.feature import SQLTransformer\n```", "```py\ncolSelect = SQLTransformer(\n```", "```py\n    statement=\"\"\"\n```", "```py\n    SELECT Score, \n```", "```py\n           from_unixtime(Time) as Time, \n```", "```py\n           Summary \n```", "```py\n    FROM __THIS__\"\"\")\n```", "```py\nselected = colSelect.transform(reviews_spark)\n```", "```py\nselected.show(n=10, truncate=False)\n```", "```py\nexpandTime = SQLTransformer(\n```", "```py\n    statement=\"\"\"\n```", "```py\n    SELECT Score,\n```", "```py\n           Summary, \n```", "```py\n           dayofmonth(Time) as Day, \n```", "```py\n           month(Time) as Month, \n```", "```py\n           year(Time) as Year, \n```", "```py\n           weekofyear(Time) as WeekNum, \n```", "```py\n           date_format(Time, 'EEE') as Weekday, \n```", "```py\n           hour(Time) as HourOfDay, \n```", "```py\n           IF(date_format(Time, 'EEE')='Sat' OR\n```", "```py\n              date_format(Time, 'EEE')='Sun', 1, 0) as\n```", "```py\n              Weekend, \n```", "```py\n        CASE \n```", "```py\n          WHEN month(TIME)=12 OR month(Time)<=2 THEN 'Winter' \n```", "```py\n          WHEN month(TIME)>=3 OR month(Time)<=5 THEN 'Spring' \n```", "```py\n          WHEN month(TIME)>=6 AND month(Time)<=9 THEN 'Summer' \n```", "```py\n          ELSE 'Fall' \n```", "```py\n        END as Season \n```", "```py\n    FROM __THIS__\"\"\")\n```", "```py\nexpanded = expandTime.transform(selected)\n```", "```py\nexpanded.show(n=10)\n```", "```py\ncreateResponse = SQLTransformer(\n```", "```py\n    statement=\"\"\"\n```", "```py\n    SELECT IF(Score < 3,'Negative', 'Positive') as Sentiment,\n```", "```py\n           Day, Month, Year, WeekNum, Weekday, HourOfDay, \n```", "```py\n           Weekend, Season, Summary\n```", "```py\n    FROM __THIS__ WHERE Score != 3\"\"\")\n```", "```py\ncreated = createResponse.transform(expanded)\n```", "```py\ncreated.show(n=10)\n```", "```py\nfrom pyspark.ml.feature import RegexTokenizer\n```", "```py\nregexTokenizer = RegexTokenizer(inputCol = \"Summary\",\n```", "```py\n                                outputCol = \"Tokenized\",\n```", "```py\n                                pattern = \"[!,\\\"]\",\n```", "```py\n                                toLowercase = True)\n```", "```py\ntokenized = regexTokenizer.transform(created)\n```", "```py\ntokenized.select([\"Tokenized\"]).show(n = 10, \n```", "```py\n    truncate = False)\n```", "```py\nremoveStopWords = StopWordsRemover(\n```", "```py\n    inputCol = regexTokenizer.getOutputCol(),\n```", "```py\n    outputCol = \"CleanedSummary\", \n```", "```py\n    caseSensitive = False)\n```", "```py\nstopWordsRemoved = removeStopWords.transform(tokenized)\n```", "```py\nstopWordsRemoved.select([\"Tokenized\", \n```", "```py\n                         \"CleanedSummary\"]).show(\n```", "```py\n    n = 10, truncate = False)\n```", "```py\nfrom pyspark.ml.feature import CountVectorizer \n```", "```py\ncountVectorizer = CountVectorizer(\n```", "```py\n    inputCol = removeStopWords.getOutputCol(),\n```", "```py\n    outputCol = \"frequencies\",\n```", "```py\n    minDF = 100 )\n```", "```py\ncountVecModel = countVectorizer.fit(stopWordsRemoved)\n```", "```py\nprint(\"Vocabulary size is \" +\n```", "```py\n   str(len(countVecModel.vocabulary)))\n```", "```py\nprint(countVecModel.vocabulary[:7])\n```", "```py\nvectorized = countVecModel.transform(stopWordsRemoved)\n```", "```py\nvectorized.select([\"CleanedSummary\", \"frequencies\"]).show(\n```", "```py\n                  n = 10, truncate = False)\n```", "```py\nfrom pyspark.ml.feature import IDF\n```", "```py\nidf = IDF(inputCol = countVectorizer.getOutputCol(),\n```", "```py\n          outputCol = \"TFIDF\",\n```", "```py\n          minDocFreq = 1)\n```", "```py\nidfModel = idf.fit(vectorized)\n```", "```py\nafterIdf = idfModel.transform(vectorized)\n```", "```py\nafterIdf.select([\"Sentiment\", \"CleanedSummary\",\n```", "```py\n    \"TFIDF\"]).show(n = 5, truncate = False, vertical = True)\n```", "```py\nfinalSelect = SQLTransformer(\n```", "```py\n    statement=\"\"\"\n```", "```py\n    SELECT Sentiment, Day, Month, Year, WeekNum, Weekday,\n```", "```py\n           HourOfDay, Weekend, Season, TFIDF\n```", "```py\n    FROM __THIS__ \"\"\")\n```", "```py\nimport h2o\n```", "```py\nfrom pysparkling.ml import ColumnPruner, H2OXGBoost\n```", "```py\nxgboost = H2OXGBoost(splitRatio = 0.8, labelCol = \"Sentiment\")\n```", "```py\nfrom pyspark.ml import Pipeline\n```", "```py\npipeline = Pipeline(stages = [\n```", "```py\n    colSelect, expandTime, createResponse, regexTokenizer,\n```", "```py\n    removeStopWords, countVectorizer, idf, finalSelect,\n```", "```py\n    xgboost])\n```", "```py\nmodel = pipeline.fit(reviews_spark)\n```", "```py\npredictions = model.transform(input_data)\n```", "```py\ndf = h2o.import_file(\"creditcardfraud.csv\")\n```", "```py\niso = h2o.estimators.H2OIsolationForestEstimator(\n```", "```py\n    ntrees = 100, seed = 12345)\n```", "```py\niso.train(x = df.col_names[0:31], training_frame = df)\n```", "```py\npredictions = iso.predict(df)\n```", "```py\npredictions\n```", "```py\nquantile = 0.95\n```", "```py\nquantile_frame = predictions.quantile([quantile])\n```", "```py\nquantile_frame\n```", "```py\nthreshold = quantile_frame[0, \"predictQuantiles\"]\n```", "```py\npredictions[\"predicted_class\"] = \\\n```", "```py\n    predictions[\"predict\"] > threshold\n```", "```py\npredictions[\"class\"] = df[\"class\"]\n```", "```py\npredictions\n```"]